<doc id="24075" url="https://en.wikipedia.org/wiki?curid=24075" title="Conventional PCI">
Conventional PCI

Conventional PCI, often shortened to PCI, is a local computer bus for attaching hardware devices in a computer. PCI is the initialism for Peripheral Component Interconnect and is part of the PCI Local Bus standard. The PCI bus supports the functions found on a processor bus but in a standardized format that is independent of any particular processor's native bus. Devices connected to the PCI bus appear to a bus master to be connected directly to its own bus and are assigned addresses in the processor's address space. It is a parallel bus, synchronous to a single bus clock.
Attached devices can take either the form of an integrated circuit fitted onto the motherboard itself (called a "planar device" in the PCI specification) or an expansion card that fits into a slot. The PCI Local Bus was first implemented in IBM PC compatibles, where it displaced the combination of several slow ISA slots and one fast VESA Local Bus slot as the bus configuration. It has subsequently been adopted for other computer types. Typical PCI cards used in PCs include: network cards, sound cards, modems, extra ports such as USB or serial, TV tuner cards and disk controllers. PCI video cards replaced ISA and VESA cards until growing bandwidth requirements outgrew the capabilities of PCI. The preferred interface for video cards then became AGP, itself a superset of conventional PCI, before giving way to PCI Express.
The first version of conventional PCI found in consumer desktop computers was a 32-bit bus using a 33 MHz bus clock and 5 V signalling, although the PCI 1.0 standard provided for a 64-bit variant as well. These have one locating notch in the card. Version 2.0 of the PCI standard introduced 3.3 V slots, physically distinguished by a flipped physical connector to preventing accidental insertion of 5 V cards. Universal cards, which can operate on either voltage, have two notches. Version 2.1 of the PCI standard introduced optional 66 MHz operation. A server-oriented variant of conventional PCI, called PCI-X (PCI Extended) operated at frequencies up to 133 MHz for PCI-X 1.0 and up to 533 MHz for PCI-X 2.0. An internal connector for laptop cards, called Mini PCI, was introduced in version 2.2 of the PCI specification. The PCI bus was also adopted for an external laptop connector standard the CardBus. The first PCI specification was developed by Intel, but subsequent development of the standard became the responsibility of the PCI Special Interest Group (PCI-SIG).
Conventional PCI and PCI-X are sometimes called Parallel PCI in order to distinguish them technologically from their more recent successor PCI Express, which adopted a serial, lane-based architecture. Conventional PCI's heyday in the desktop computer market was approximately the decade 1995–2005. PCI and PCI-X have become obsolete for most purposes; however, they are still common on modern desktops for the purposes of backwards compatibility and the low relative cost to produce. Many kinds of devices previously available on PCI expansion cards are now commonly integrated onto motherboards or available in universal serial bus and PCI Express versions.
History.
Work on PCI began at Intel's Architecture Development Lab .
A team of Intel engineers (composed primarily of ADL engineers) defined the architecture and developed a proof of concept chipset and platform (Saturn) partnering with teams in the company's desktop PC systems and core logic product organizations. The original PCI architecture team included, among others, Dave Carson, Norm Rasmussen, Brad Hosler, Ed Solari, Bruce Young, Gary Solomon, Ali Oztaskin, Tom Sakoda, Rich Haslam, Jeff Rabe, and Steve Fischer.
PCI was immediately put to use in servers, replacing MCA and EISA as the server expansion bus of choice. In mainstream PCs, PCI was slower to replace VESA Local Bus (VLB), and did not gain significant market penetration until late 1994 in second-generation Pentium PCs. By 1996, VLB was all but extinct, and manufacturers had adopted PCI even for 486 computers. EISA continued to be used alongside PCI through 2000. Apple Computer adopted PCI for professional Power Macintosh computers (replacing NuBus) in mid-1995, and the consumer Performa product line (replacing LC PDS) in mid-1996.
The 64-bit version of plain PCI remained rare in practice though, although it was used for example by all (post-iMac) G3 and G4 Power Macintosh computers.
Later revisions of PCI added new features and performance improvements, including a 66 MHz 3.3 V standard and 133 MHz PCI-X, and the adaptation of PCI signaling to other form factors. Both PCI-X 1.0b and PCI-X 2.0 are backward compatible with some PCI standards.
The PCI-SIG introduced the serial PCI Express in . At the same time, they renamed "PCI" as "Conventional PCI". Since then, motherboard manufacturers have included progressively fewer Conventional PCI slots in favor of the new standard. Many new motherboards do not provide conventional PCI slots at all, as of late 2013.
Auto configuration.
PCI provides separate memory and I/O port address spaces for the x86 processor family, 64 and 32 bits, respectively. Addresses in these address spaces are assigned by software. A third address space, called the PCI Configuration Space, which uses a fixed addressing scheme, allows software to determine the amount of memory and I/O address space needed by each device. Each device can request up to six areas of memory space or I/O port space via its configuration space registers.
In a typical system, the firmware (or operating system) queries all PCI buses at startup time (via PCI Configuration Space) to find out what devices are present and what system resources (memory space, I/O space, interrupt lines, etc.) each needs. It then allocates the resources and tells each device what its allocation is.
The PCI configuration space also contains a small amount of device type information, which helps an operating system choose device drivers for it, or at least to have a dialogue with a user about the system configuration.
Devices may have an on-board ROM containing executable code for x86 or PA-RISC processors, an Open Firmware driver, or an EFI driver. These are typically necessary for devices used during system startup, before device drivers are loaded by the operating system.
In addition, there are PCI Latency Timers that are a mechanism for PCI Bus-Mastering devices to share the PCI bus fairly. "Fair" in this case means that devices will not use such a large portion of the available PCI bus bandwidth that other devices are not able to get needed work done. Note, this does not apply to PCI Express.
Interrupts.
Devices are required to follow a protocol so that the interrupt lines can be shared. The PCI bus includes four interrupt lines, all of which are available to each device. However, they are not wired in parallel as are the other PCI bus lines. The positions of the interrupt lines rotate between slots, so what appears to one device as the INTA# line is INTB# to the next and INTC# to the one after that. Single-function devices use their INTA# for interrupt signaling, so the device load is spread fairly evenly across the four available interrupt lines. This alleviates a common problem with sharing interrupts.
The mapping of PCI interrupt lines onto system interrupt lines, through the PCI host bridge, is implementation-dependent. Platform-specific BIOS code is meant to know this, and set the "interrupt line" field in each device's configuration space indicating which IRQ it is connected to.
PCI interrupt lines are level-triggered. This was chosen over edge-triggering in order to gain an advantage when servicing a shared interrupt line, and for robustness: edge triggered interrupts are easy to miss.
Later revisions of the PCI specification add support for message-signaled interrupts. In this system, a device signals its need for service by performing a memory write, rather than by asserting a dedicated line. This alleviates the problem of scarcity of interrupt lines. Even if interrupt vectors are still shared, it does not suffer the sharing problems of level-triggered interrupts. It also resolves the routing problem, because the memory write is not unpredictably modified between device and host. Finally, because the message signaling is in-band, it resolves some synchronization problems that can occur with posted writes and out-of-band interrupt lines.
PCI Express does not have physical interrupt lines at all. It uses message-signaled interrupts exclusively.
Conventional hardware specifications.
These specifications represent the most common version of PCI used in normal PCs.
The PCI specification also provides options for 3.3 V signaling, 64-bit bus width, and 66 MHz clocking, but these are not commonly encountered outside of PCI-X support on server motherboards.
The PCI bus arbiter performs bus arbitration among multiple masters on the PCI bus. Any number of bus masters can reside on the PCI bus, as well as requests for the bus. One pair of request and grant signals is dedicated to each bus master.
Card voltage and keying.
Typical PCI cards have either one or two key notches, depending on their signaling voltage. Cards requiring 3.3 volts have a notch 56.21 mm from the card backplate; those requiring 5 volts have a notch 104.47 mm from the backplate. "Universal cards" accepting either voltage have both key notches. This allows cards to be fitted only into slots with a voltage they support.
Connector pinout.
The PCI connector is defined as having 62 contacts on each side of the edge connector, but two or four of them are replaced by key notches, so a card has 60 or 58 contacts on each side. Pin 1 is closest to the backplate. B and A sides are as follows, looking down into the motherboard connector.
64-bit PCI extends this by an additional 32 contacts on each side which provide ADC/BE[7:4#, the PAR64 parity signal, and a number of power and ground pins.
Most lines are connected to each slot in parallel. The exceptions are:
Notes:
Mixing of 32-bit and 64-bit PCI cards in different width slots.
Most 32-bit PCI cards will function properly in 64-bit PCI-X slots, but the bus clock rate will be limited to the clock frequency of the slowest card, an inherent limitation of PCI's shared bus topology. For example, when a PCI 2.3, 66-MHz peripheral is installed into a PCI-X bus capable of 133 MHz, the entire bus backplane will be limited to 66 MHz. To get around this limitation, many motherboards have multiple PCI/PCI-X buses, with one bus intended for use with high-speed PCI-X peripherals, and the other bus intended for general-purpose peripherals.
Many 64-bit PCI-X cards are designed to work in 32-bit mode if inserted in shorter 32-bit connectors, with some loss of performance. An example of this is the Adaptec 29160 64-bit SCSI interface card. However, some 64-bit PCI-X cards do not work in standard 32-bit PCI slots.
Installing a 64-bit PCI-X card in a 32-bit slot will leave the 64-bit portion of the card edge connector not connected and overhanging. This requires that there be no motherboard components positioned so as to mechanically obstruct the overhanging portion of the card edge connector.
Physical card dimensions.
The maximum width of a PCI card is 15.24 mm (0.6 inches). Two bracket heights have been specified, known as full-height and low-profile. The bracket or backplate is the part that fastens to the card cage to stabilize the card. It also usually contains external connectors, so it attaches in a window in the computer case so any connectors are accessible from outside. The backplate is typically fixed to the case by either a 6-32 or M3 screw, or with a separate hold-down bracket that is part of the case.
For each bracket height two different lengths have been specified for a total of four lengths, known as full-length and half-length for full-height cards, and MD1 and MD2 for low-profile cards.
Full-height cards.
The original full-height cards are defined by a bracket height of 120 mm (4.7 inches). The height of a full-height cards itself is nominally 107 mm (4.2 inches). The height includes the card edge connector.
Two lengths have been defined for full-height cards, known as full-length and half-length.
Full-length full-height card.
The original full-length full-height PCI card (also known as full-size) is specified as a length of 312 mm (12.283 inches) and a height of 107 mm (4.2 inches). However, most modern PCI cards are half-length or smaller (see below) and many modern PC cases cannot accommodate the length of a full-size card. Note, this length is the length of the printed circuit board; it does not include the angled short leg of the metal bracket (which does affect e.g. packaging dimensions). Some high power PCI products have active cooling systems that extend past the nominal dimensions. Likewise, some may take up more than one slot space: these are referred to as double-wide or triple-wide cards, accordingly.
Half-length full-height card.
A half-length full-height card has a length of up to 175.26 mm (6.9 inches) and a height of up to 107 mm (4.2 inches). The actual dimensions of many cards described as half-length full-height are lower than these maxiums and they will still fit any standard full-height PCI slot as long as they use a properly located full-height bracket.
This is in fact the practical ("de facto") standard now the majority of modern PCI cards fit inside this envelope.
Low-profile cards.
Low-profile PCI cards (also known as LPPCI or half-height cards) are defined by a bracket reduced in height to 79.2 mm (3.118 inches). The low-profile specification assumes a 3.3 volt PCI slot. The retention screw has also been moved 1.35 mm closer to the fold in the bracket.
The low profile card itself has a maximum height of 64.41 mm (2.536 inches) including the edge connector.
The smaller bracket will not fit a standard desktop, tower or 3U rack-mount PC case, but will fit in many newer small form-factor (SFF) desktop cases or in a 2U rack-mount case. These cards may be known by other names such as "slim".
Many manufacturers supply both types of bracket with cards, where the bracket is typically attached to the card with a pair of screws allowing the installer to easily change it.
The PCI-SIG has defined two standard lengths for low-profile cards, known as MD1 and MD2.
MD1 low-profile card.
MD1 defines the shortest 32-bit PCI card length, 119.91 mm (4.721 inches) and a maximum height of 64.41 mm (2.536 inches).
MD2 low-profile card.
MD2 defines the maximum length of a low profile PCI card as 167.64 mm (6.600 inches) and a maximum height of 64.41 mm (2.536 inches). Any low profile PCI card longer than the MD1 length is considered an MD2 card. This is the most common low-profile card form-factor.
Beside conventional PCI, many PCI Express cards are also described as MD2 low-profile form-factor.
Mini PCI.
Mini PCI was added to PCI version 2.2 for use in laptops; it uses a 32-bit, 33 MHz bus with powered connections (3.3 V only; 5 V is limited to 100 mA) and support for bus mastering and DMA. The standard size for Mini PCI cards is approximately a quarter of their full-sized counterparts. There is no access to the card from outside the case, unlike desktop PCI cards with brackets carrying connectors. This limits the kinds of functions a Mini PCI card can perform.
Many Mini PCI devices were developed such as Wi-Fi, Fast Ethernet, Bluetooth, modems (often Winmodems), sound cards, cryptographic accelerators, SCSI, IDE–ATA, SATA controllers and combination cards. Mini PCI cards can be used with regular PCI-equipped hardware, using Mini PCI-to-PCI "converters". Mini PCI has been superseded by the much narrower PCI Express Mini Card.
Technical details of Mini PCI.
Mini PCI cards have a 2 W maximum power consumption, which limits the functionality that can be implemented in this form factor. They also are required to support the CLKRUN# PCI signal used to start and stop the PCI clock for power management purposes.
There are three card form factors: Type I, Type II, and Type III cards. The card connector used for each type include: Type I and II use a 100-pin stacking connector, while Type III uses a 124-pin edge connector, i.e. the connector for Types I and II differs from that for Type III, where the connector is on the edge of a card, like with a SO-DIMM. The additional 24 pins provide the extra signals required to route I/O back through the system connector (audio, AC-Link, LAN, phone-line interface). Type II cards have RJ11 and RJ45 mounted connectors. These cards must be located at the edge of the computer or docking station so that the RJ11 and RJ45 ports can be mounted for external access.
Mini PCI is distinct from 144-pin Micro PCI.
PC/104-Plus and PCI-104.
The PC/104-Plus and PCI-104 embedded form factors include a stacking 120 pin PCI connector.
Other physical variations.
Typically consumer systems specify "N × PCI slots" without specifying actual dimensions of the space available. In some small-form-factor systems, this may not be sufficient to allow even "half-length" PCI cards to fit. Despite this limitation, these systems are still useful because many modern PCI cards are considerably smaller than half-length.
PCI bus transactions.
PCI bus traffic consists of a series of PCI bus transactions. Each transaction consists of an "address phase" followed by one or more "data phases". The direction of the data phases may be from initiator to target (write transaction) or vice versa (read transaction), but all of the data phases must be in the same direction. Either party may pause or halt the data phases at any point. (One common example is a low-performance PCI device that does not support burst transactions, and always halts a transaction after the first data phase.)
Any PCI device may initiate a transaction. First, it must request permission from a PCI bus arbiter on the motherboard. The arbiter grants permission to one of the requesting devices. The initiator begins the address phase by broadcasting a 32-bit address plus a 4-bit command code, then waits for a target to respond. All other devices examine this address and one of them responds a few cycles later.
64-bit addressing is done using a two-stage address phase. The initiator broadcasts the low 32 address bits, accompanied by a special "dual address cycle" command code. Devices which do not support 64-bit addressing can simply not respond to that command code. The next cycle, the initiator transmits the high 32 address bits, plus the real command code. The transaction operates identically from that point on. To ensure compatibility with 32-bit PCI devices, it is forbidden to use a dual address cycle if not necessary, i.e. if the high-order address bits are all zero.
While the PCI bus transfers 32 bits per data phase, the initiator transmits 4 active-low byte enable signals indicating which 8-bit bytes are to be considered significant. In particular, a write must affect only the enabled bytes in the target PCI device. They are of little importance for memory reads, but I/O reads might have side effects. The PCI standard explicitly allows a data phase with no bytes enabled, which must behave as a no-op.
PCI address spaces.
PCI has three address spaces: memory, I/O address, and configuration.
Memory addresses are 32 bits (optionally 64 bits) in size, support caching and can be burst transactions.
I/O addresses are for compatibility with the Intel x86 architecture's I/O port address space. Although the PCI bus specification allows burst transactions in any address space, most devices only support it for memory addresses and not I/O.
Finally, PCI configuration space provides access to 256 bytes of special configuration registers per PCI device. Each PCI slot gets its own configuration space address range. The registers are used to configure devices memory and I/O address ranges they should respond to from transaction initiators. When a computer is first turned on, all PCI devices respond only to their configuration space accesses. The computer's BIOS scans for devices and assigns Memory and I/O address ranges to them.
If an address is not claimed by any device, the transaction initiator's address phase will time out causing the initiator to abort the operation. In case of reads, it is customary to supply all-ones for the read data value (0xFFFFFFFF) in this case. PCI devices therefore generally attempt to avoid using the all-ones value in important status registers, so that such an error can be easily detected by software.
PCI command codes.
There are 16 possible 4-bit command codes, and 12 of them are assigned. With the exception of the unique dual address cycle, the least significant bit of the command code indicates whether the following data phases are a read (data sent from target to initiator) or a write (data sent from an initiator to target). PCI targets must examine the command code as well as the address and not respond to address phases which specify an unsupported command code.
The commands that refer to cache lines depend on the PCI configuration space cache line size register being set up properly; they may not be used until that has been done.
PCI bus latency.
Soon after promulgation of the PCI specification, it was discovered that lengthy transactions by some devices, due to slow acknowledgments, long data bursts, or some combination, could cause buffer underrun or overrun in other devices. Recommendations on the timing of individual phases in Revision 2.0 were made mandatory in revision 2.1:
Additionally, as of revision 2.1, all initiators capable of bursting more than two data phases must implement a programmable latency timer. The timer starts counting clock cycles when a transaction starts (initiator asserts FRAME#). If the timer has expired "and" the arbiter has removed GNT#, then the initiator must terminate the transaction at the next legal opportunity. This is usually the next data phase, but Memory Write and Invalidate transactions must continue to the end of the cache line.
Delayed transactions.
Devices unable to meet those timing restrictions must use a combination of posted writes (for memory writes) and delayed transactions (for other writes and all reads). In a delayed transaction, the target records the transaction (including the write data) internally and aborts (asserts STOP# rather than TRDY#) the first data phase. The initiator "must" retry exactly the same transaction later. In the interim, the target internally performs the transaction, and waits for the retried transaction. When the retried transaction is seen, the buffered result is delivered.
A device may be the target of other transactions while completing one delayed transaction; it must remember the transaction type, address, byte selects and (if a write) data value, and only complete the correct transaction.
If the target has a limit on the number of delayed transactions that it can record internally (simple targets may impose a limit of 1), it will force those transactions to retry without recording them. They will be dealt with when the current delayed transaction is completed. If two initiators attempt the same transaction, a delayed transaction begun by one may have its result delivered to the other; this is harmless.
A target abandons a delayed transaction when a retry succeeds in delivering the buffered result, the bus is reset, or when 215=32768 clock cycles (approximately 1 ms) elapse without seeing a retry. The latter should never happen in normal operation, but it prevents a deadlock of the whole bus if one initiator is reset or malfunctions.
PCI bus bridges.
The PCI standard permits multiple independent PCI buses to be connected by bus bridges that will forward operations on one bus to another when required. Although conventional PCI tends not to use many bus bridges, PCI express systems use many; each PCI express slot appears to be a separate bus, connected by a bridge to the others.
Posted writes.
Generally, when a bus bridge sees a transaction on one bus that must be forwarded to the other, the original transaction must wait until the forwarded transaction completes before a result is ready. One notable exception occurs in the case of memory writes. Here, the bridge may record the write data internally (if it has room) and signal completion of the write before the forwarded write has completed. Or, indeed, before it has begun. Such "sent but not yet arrived" writes are referred to as "posted writes", by analogy with a postal mail message. Although they offer great opportunity for performance gains, the rules governing what is permissible are somewhat intricate.
Combining, merging, and collapsing.
The PCI standard permits bus bridges to convert multiple bus transactions into one larger transaction under certain situations. This can improve the efficiency of the PCI bus.
PCI bus signals.
PCI bus transactions are controlled by five main control signals, two driven by the initiator of a transaction (FRAME# and IRDY#), and three driven by the target (DEVSEL#, TRDY#, and STOP#). There are two additional arbitration signals (REQ# and GNT#) which are used to obtain permission to initiate a transaction. All are active-low, meaning that the active or "asserted" state is a low voltage. Pull-up resistors on the motherboard ensure they will remain high (inactive or "deasserted") if not driven by any device, but the PCI bus does not depend on the resistors to "change" the signal level; all devices drive the signals high for one cycle before ceasing to drive the signals.
Signal timing.
All PCI bus signals are sampled on the rising edge of the clock. Signals nominally change on the falling edge of the clock, giving each PCI device approximately one half a clock cycle to decide how to respond to the signals it observed on the rising edge, and one half a clock cycle to transmit its response to the other device.
The PCI bus requires that every time the device driving a PCI bus signal changes, one "turnaround cycle" must elapse between the time the one device stops driving the signal and the other device starts. Without this, there might be a period when both devices were driving the signal, which would interfere with bus operation.
The combination of this turnaround cycle and the requirement to drive a control line high for one cycle before ceasing to drive it means that each of the main control lines must be high for a minimum of two cycles when changing owners. The PCI bus protocol is designed so this is rarely a limitation; only in a few special cases (notably fast back-to-back transactions) is it necessary to insert additional delay to meet this requirement.
Arbitration.
Any device on a PCI bus that is capable of acting as a bus master may initiate a transaction with any other device. To ensure that only one transaction is initiated at a time, each master must first wait for a bus grant signal, GNT#, from an arbiter located on the motherboard. Each device has a separate request line REQ# that requests the bus, but the arbiter may "park" the bus grant signal at any device if there are no current requests.
The arbiter may remove GNT# at any time. A device which loses GNT# may complete its current transaction, but may not start one (by asserting FRAME#) unless it observes GNT# asserted the cycle before it begins.
The arbiter may also provide GNT# at any time, including during another master's transaction. During a transaction, either FRAME# or IRDY# or both are asserted; when both are deasserted, the bus is idle. A device may initiate a transaction at any time that GNT# is asserted and the bus is idle.
Address phase.
A PCI bus transaction begins with an "address phase". The initiator, seeing that it has GNT# and the bus is idle, drives the target address onto the ADlines, the associated command (e.g. memory read, or I/O write) on the C/BE[3:0# lines, and pulls FRAME# low.
Each other device examines the address and command and decides whether to respond as the target by asserting DEVSEL#. A device must respond by asserting DEVSEL# within 3 cycles. Devices which promise to respond within 1 or 2 cycles are said to have "fast DEVSEL" or "medium DEVSEL", respectively. (Actually, the time to respond is 2.5 cycles, since PCI devices must transmit all signals half a cycle early so that they can be received three cycles later.)
Note that a device must latch the address on the first cycle; the initiator is required to remove the address and command from the bus on the following cycle, even before receiving a DEVSEL# response. The additional time is available only for interpreting the address and command after it is captured.
On the fifth cycle of the address phase (or earlier if all other devices have medium DEVSEL or faster), a catch-all "subtractive decoding" is allowed for some address ranges. This is commonly used by an ISA bus bridge for addresses within its range (24 bits for memory and 16 bits for I/O).
On the sixth cycle, if there has been no response, the initiator may abort the transaction by deasserting FRAME#. This is known as "master abort termination" and it is customary for PCI bus bridges to return all-ones data (0xFFFFFFFF) in this case. PCI devices therefore are generally designed to avoid using the all-ones value in important status registers, so that such an error can be easily detected by software.
Address phase timing.
On the rising edge of clock 0, the initiator observes FRAME# and IRDY# both high, and GNT# low, so it drives the address, command, and asserts FRAME# in time for the rising edge of clock 1. Targets latch the address and begin decoding it. They may respond with DEVSEL# in time for clock 2 (fast DEVSEL), 3 (medium) or 4 (slow). Subtractive decode devices, seeing no other response by clock 4, may respond on clock 5. If the master does not see a response by clock 5, it will terminate the transaction and remove FRAME# on clock 6.
TRDY# and STOP# are deasserted (high) during the address phase. The initiator may assert IRDY# as soon as it is ready to transfer data, which could theoretically be as soon as clock 2.
Dual-cycle address.
To allow 64-bit addressing, a master will present the address over two consecutive cycles. First, it sends the low-order address bits with a special "dual-cycle address" command on the C/BE[3:0]#. On the following cycle, it sends the high-order address bits and the actual command. Dual-address cycles are forbidden if the high-order address bits are zero, so devices which do not support 64-bit addressing can simply not respond to dual cycle commands.
Configuration access.
Addresses for PCI configuration space access are decoded specially. For these, the low-order address lines specify the offset of the desired PCI configuration register, and the high-order address lines are ignored. Instead, an additional address signal, the IDSEL input, must be high before a device may assert DEVSEL#. Each slot connects a different high-order address line to the IDSEL pin, and is selected using one-hot encoding on the upper address lines.
Data phases.
After the address phase (specifically, beginning with the cycle that DEVSEL# goes low) comes a burst of one or more "data phases". In all cases, the initiator drives active-low byte select signals on the C/BElines, but the data on the AD[31:0 may be driven by the initiator (in case of writes) or target (in case of reads).
During data phases, the C/BE[3:0]# lines are interpreted as active-low "byte enables". In case of a write, the asserted signals indicate which of the four bytes on the AD bus are to be written to the addressed location. In the case of a read, they indicate which bytes the initiator is interested in. For reads, it is always legal to ignore the byte enable signals and simply return all 32 bits; cacheable memory resources are required to always return 32 valid bits. The byte enables are mainly useful for I/O space accesses where reads have side effects.
A data phase with all four C/BE# lines deasserted is explicitly permitted by the PCI standard, and must have no effect on the target other than to advance the address in the burst access in progress.
The data phase continues until both parties are ready to complete the transfer and continue to the next data phase. The initiator asserts IRDY# ("initiator ready") when it no longer needs to wait, while the target asserts TRDY# ("target ready"). Whichever side is providing the data must drive it on the AD bus before asserting its ready signal.
Once one of the participants asserts its ready signal, it may not become un-ready or otherwise alter its control signals until the end of the data phase. The data recipient must latch the AD bus each cycle until it sees both IRDY# and TRDY# asserted, which marks the end of the current data phase and indicates that the just-latched data is the word to be transferred.
To maintain full burst speed, the data sender then has half a clock cycle after seeing both IRDY# and TRDY# asserted to drive the next word onto the AD bus.
This continues the address cycle illustrated above, assuming a single address cycle with medium DEVSEL, so the target responds in time for clock 3.
However, at that time, neither side is ready to transfer data. For clock 4, the initiator is ready, but the target is not. On clock 5, both are ready, and a data transfer takes place (as indicated by the vertical lines). For clock 6, the target is ready to transfer, but the initiator is not. On clock 7, the initiator becomes ready, and data is transferred. For clocks 8 and 9, both sides remain ready to transfer data, and data is transferred at the maximum possible rate (32 bits per clock cycle).
In case of a read, clock 2 is reserved for turning around the AD bus, so the target is not permitted to drive data on the bus even if it is capable of fast DEVSEL.
Fast DEVSEL# on reads.
A target that supports fast DEVSEL could in theory begin responding to a read the cycle after the address is presented. This cycle is, however, reserved for AD bus turnaround. Thus, a target may not drive the AD bus (and thus may not assert TRDY#) on the second cycle of a transaction. Note that most targets will not be this fast and will not need any special logic to enforce this condition.
Ending transactions.
Either side may request that a burst end after the current data phase. Simple PCI devices that do not support multi-word bursts will always request this immediately. Even devices that do support bursts will have some limit on the maximum length they can support, such as the end of their addressable memory.
Initiator burst termination.
The initiator can mark any data phase as the final one in a transaction by deasserting FRAME# at the same time as it asserts IRDY#. The cycle after the target asserts TRDY#, the final data transfer is complete, both sides deassert their respective RDY# signals, and the bus is idle again. The master may not deassert FRAME# before asserting IRDY#, nor may it deassert FRAME# while waiting, with IRDY# asserted, for the target to assert TRDY#.
The only minor exception is a "master abort termination", when no target responds with DEVSEL#. Obviously, it is pointless to wait for TRDY# in such a case. However, even in this case, the master must assert IRDY# for at least one cycle after deasserting FRAME#. (Commonly, a master will assert IRDY# before receiving DEVSEL#, so it must simply hold IRDY# asserted for one cycle longer.) This is to ensure that bus turnaround timing rules are obeyed on the FRAME# line.
Target burst termination.
The target requests the initiator end a burst by asserting STOP#. The initiator will then end the transaction by deasserting FRAME# at the next legal opportunity; if it wishes to transfer more data, it will continue in a separate transaction. There are several ways for the target to do this:
There will always be at least one more cycle after a target-initiated disconnection, to allow the master to deassert FRAME#. There are two sub-cases, which take the same amount of time, but one requires an additional data phase:
If the initiator ends the burst at the same time as the target requests disconnection, there is no additional bus cycle.
Burst addressing.
For memory space accesses, the words in a burst may be accessed in several orders. The unnecessary low-order address bits AD[1:0] are used to convey the initiator's requested order. A target which does not support a particular order must terminate the burst after the first word. Some of these orders depend on the cache line size, which is configurable on all PCI devices.
If the starting offset within the cache line is zero, all of these modes reduce to the same order.
Cache line toggle and cache line wrap modes are two forms of critical-word-first cache line fetching. Toggle mode XORs the supplied address with an incrementing counter. This is the native order for Intel 486 and Pentium processors. It has the advantage that it is not necessary to know the cache line size to implement it.
PCI version 2.1 obsoleted toggle mode and added the cache line wrap mode,[http://download.intel.com/design/chipsets/applnots/27301101.pdf] where fetching proceeds linearly, wrapping around at the end of each cache line. When one cache line is completely fetched, fetching jumps to the starting offset in the next cache line.
Note that most PCI devices only support a limited range of typical cache line sizes; if the cache line size is programmed to an unexpected value, they force single-word access.
PCI also supports burst access to I/O and configuration space, but only linear mode is supported. (This is rarely used, and may be buggy in some devices; they may not support it, but not properly force single-word access either.)
Transaction examples.
This is the highest-possible speed four-word write burst, terminated by the master:
On clock edge 1, the initiator starts a transaction by driving an address, command, and asserting FRAME# The other signals are idle (indicated by ^^^), pulled high by the motherboard's pull-up resistors. That might be their turnaround cycle. On cycle 2, the target asserts both DEVSEL# and TRDY#. As the initiator is also ready, a data transfer occurs. This repeats for three more cycles, but before the last one (clock edge 5), the master deasserts FRAME#, indicating that this is the end. On clock edge 6, the AD bus and FRAME# are undriven (turnaround cycle) and the other control lines are driven high for 1 cycle. On clock edge 7, another initiator can start a different transaction. This is also the turnaround cycle for the other control lines.
The equivalent read burst takes one more cycle, because the target must wait 1 cycle for the AD bus to turn around before it may assert TRDY#:
A high-speed burst terminated by the target will have an extra cycle at the end:
On clock edge 6, the target indicates that it wants to stop (with data), but the initiator is already holding IRDY# low, so there is a fifth data phase (clock edge 7), during which no data is transferred.
Parity.
The PCI bus detects parity errors, but does not attempt to correct them by retrying operations; it is purely a failure indication. Due to this, there is no need to detect the parity error before it has happened, and the PCI bus actually detects it a few cycles later. During a data phase, whichever device is driving the ADlines computes even parity over them and the C/BE[3:0# lines, and sends that out the PAR line one cycle later. All access rules and turnaround cycles for the AD bus apply to the PAR line, just one cycle later. The device listening on the AD bus checks the received parity and asserts the PERR# (parity error) line one cycle after that. This generally generates a processor interrupt, and the processor can search the PCI bus for the device which detected the error.
The PERR# line is only used during data phases, once a target has been selected. If a parity error is detected during an address phase (or the data phase of a Special Cycle), the devices which observe it assert the SERR# (System error) line.
Even when some bytes are masked by the C/BE# lines and not in use, they must still have "some" defined value, and this value must be used to compute the parity.
Fast back-to-back transactions.
Due to the need for a turnaround cycle between different devices driving PCI bus signals, in general it is necessary to have an idle cycle between PCI bus transactions. However, in some circumstances it is permitted to skip this idle cycle, going directly from the final cycle of one transfer (IRDY# asserted, FRAME# deasserted) to the first cycle of the next (FRAME# asserted, IRDY# deasserted).
An initiator may only perform back-to-back transactions when:
Additional timing constraints may come from the need to turn around are the target control lines, particularly DEVSEL#. The target deasserts DEVSEL#, driving it high, in the cycle following the final data phase, which in the case of back-to-back transactions is the first cycle of the address phase. The second cycle of the address phase is then reserved for DEVSEL# turnaround, so if the target is different from the previous one, it must not assert DEVSEL# until the third cycle (medium DEVSEL speed).
One case where this problem cannot arise is if the initiator knows somehow (presumably because the addresses share sufficient high-order bits) that the second transfer is addressed to the same target as the previous one. In that case, it may perform back-to-back transactions. All PCI targets must support this.
It is also possible for the target keeps track of the requirements. If it never does fast DEVSEL, they are met trivially. If it does, it must wait until medium DEVSEL time unless:
Targets which have this capability indicate it by a special bit in a PCI configuration register, and if all targets on a bus have it, all initiators may use back-to-back transfers freely.
A subtractive decoding bus bridge must know to expect this extra delay in the event of back-to-back cycles in order to advertise back-to-back support.
64-bit PCI.
Starting from revision 2.1, the PCI specification includes optional 64-bit support. This is provided via an extended connector which provides the 64-bit bus extensions ADC/BE[7:4#, and PAR64, and a number of additional power and ground pins. The 64-bit PCI connector can be distinguished from a 32-bit connector by the additional 64-bit segment.
Memory transactions between 64-bit devices may use all 64 bits to double the data transfer rate. Non-memory transactions (including configuration and I/O space accesses) may not use the 64-bit extension. During a 64-bit burst, burst addressing works just as in a 32-bit transfer, but the address is incremented twice per data phase. The starting address must be 64-bit aligned; i.e. AD2 must be 0. The data corresponding to the intervening addresses (with AD2 = 1) is carried on the upper half of the AD bus.
To initiate a 64-bit transaction, the initiator drives the starting address on the AD bus and asserts REQ64# at the same time as FRAME#. If the selected target can support a 64-bit transfer for this transaction, it replies by asserting ACK64# at the same time as DEVSEL#. Note that a target may decide on a per-transaction basis whether to allow a 64-bit transfer.
If REQ64# is asserted during the address phase, the initiator also drives the high 32 bits of the address and a copy of the bus command on the high half of the bus. If the address requires 64 bits, a dual address cycle is still required, but the high half of the bus carries the upper half of the address and the final command code during both address phase cycles; this allows a 64-bit target to see the entire address and begin responding earlier.
If the initiator sees DEVSEL# asserted without ACK64#, it performs 32-bit data phases. The data which would have been transferred on the upper half of the bus during the first data phase is instead transferred during the second data phase. Typically, the initiator drives all 64 bits of data before seeing DEVSEL#. If ACK64# is missing, it may cease driving the upper half of the data bus.
The REQ64# and ACK64# lines are held asserted for the entire transaction save the last data phase, and deasserted at the same time as FRAME# and DEVSEL#, respectively.
The PAR64 line operates just like the PAR line, but provides even parity over ADand C/BE[7:4#. It is only valid for address phases if REQ64# is asserted. PAR64 is only valid for data phases if both REQ64# and ACK64# are asserted.
Cache snooping (obsolete).
PCI originally included optional support for write-back cache coherence. This required support by cacheable memory targets, which would listen to two pins from the cache on the bus, SDONE (snoop done) and SBO# (snoop backoff).
Because this was rarely implemented in practice, it was deleted from revision 2.2 of the PCI specification, and the pins re-used for SMBus access in revision 2.3.
The cache would watch all memory accesses, without asserting DEVSEL#. If it noticed an access that might be cached, it would drive SDONE low (snoop not done). A coherence-supporting target would avoid completing a data phase (asserting TRDY#) until it observed SDONE high.
In the case of a write to data that was clean in the cache, the cache would only have to invalidate its copy, and would assert SDONE as soon as this was established. However, if the cache contained dirty data, the cache would have to write it back before the access could proceed. so it would assert SBO# when raising SDONE. This would signal the active target to assert STOP# rather than TRDY#, causing the initiator to disconnect and retry the operation later. In the meantime, the cache would arbitrate for the bus and write its data back to memory.
Targets supporting cache coherency are also required to terminate bursts before they cross cache lines.
Development tools.
When developing and/or troubleshooting the PCI bus, examination of hardware signals can be very important. Logic analyzers and bus analyzers are tools which collect, analyze, and decode signals for users to view in useful ways.

</doc>
<doc id="24077" url="https://en.wikipedia.org/wiki?curid=24077" title="Portable Document Format">
Portable Document Format

The Portable Document Format (PDF) is a file format used to present documents in a manner independent of application software, hardware, and operating systems. Each PDF file encapsulates a complete description of a fixed-layout flat document, including the text, fonts, graphics, and other information needed to display it. --> In 1991, Adobe Systems' co-founder John Warnock outlined a system called "Camelot" that developed into PDF.
Adobe Systems made the PDF specification available free of charge in 1993. PDF was a proprietary format controlled by Adobe, until it was officially released as an open standard on July 1, 2008, and published by the International Organization for Standardization as ISO 32000-1:2008, at which time control of the specification passed to an ISO Committee of volunteer industry experts. In 2008, Adobe published a Public Patent License to ISO 32000-1 granting royalty-free rights for all patents owned by Adobe that are necessary to make, use, sell, and distribute PDF compliant implementations. However, there are still some proprietary technologies defined only by Adobe, such as Adobe XML Forms Architecture and JavaScript for Acrobat, which are referenced by ISO 32000-1 as normative and indispensable for the application of the ISO 32000-1 specification. These proprietary technologies are not standardized and their specification is published only on Adobe’s website. The ISO committee is actively standardizing many of these as part of ISO 32000-2.
History.
PDF was developed in the early 1990s as a way to share documents, including text formatting and inline images, among computer users of disparate platforms who may not have access to mutually-compatible application software. It was among a number of competing formats such as DjVu, Envoy, Common Ground Digital Paper, Farallon Replica and even Adobe's own PostScript format. In those early years before the rise of the World Wide Web and HTML documents, PDF was popular mainly in desktop publishing workflows.
PDF's adoption in the early days of the format's history was slow. Adobe Acrobat, Adobe's suite for reading and creating PDF files, was not freely available; early versions of PDF had no support for external hyperlinks, reducing its usefulness on the Internet; the larger size of a PDF document compared to plain text required longer download times over the slower modems common at the time; and rendering PDF files was slow on the less powerful machines of the day.
Adobe distributed its Acrobat Reader (now Adobe Reader) program free of charge from version 2.0 onwards, and continued supporting the original PDF, which eventually became the "de facto" standard for fixed-format electronic documents.
In 2008 Adobe Systems' PDF Reference 1.7 became ISO 32000:1:2008. Thereafter, further development of PDF (including PDF 2.0) is conducted by ISO's TC 171 SC 2 WG 8 with the participation of Adobe Systems and other subject matter experts.
Adobe specifications.
From 1993-2006 Adobe Systems changed the PDF specification several times to add new features. Various aspects of Adobe's Extension Levels published after 2006 have been accepted into working drafts of ISO 32000-2 (PDF 2.0), but developers are cautioned that Adobe's Extensions are not part of the PDF standard.
The ISO standard ISO 32000-1:2008 and Adobe PDF 1.7 are technically consistent. Adobe declared that it is not producing a PDF 1.8 Reference. Future versions of the PDF Specification will be produced by ISO technical committees. However, Adobe published documents specifying what proprietary extended features for PDF, beyond ISO 32000-1 (PDF 1.7), are supported in its newly released products. This makes use of the extensibility features of PDF as documented in ISO 32000-1 in Annex E.
The specifications for PDF are backward inclusive. The PDF 1.7 specification includes all of the functionality previously documented in the Adobe PDF Specifications for versions 1.0 through 1.6. Where Adobe removed certain features of PDF from their standard, they are not contained in ISO 32000-1 either. Some features are marked as deprecated.
PDF documents conforming to ISO 32000-1 carry the PDF version number 1.7. Documents containing Adobe extended features still carry the PDF base version number 1.7 but also contain an indication of which extension was followed during document creation.
ISO Standardization.
Since 1995, Adobe participated in some of the working groups that create technical specifications for publication by ISO and cooperated within the ISO process on specialized subsets of PDF standards for specific industries and purposes (e.g. PDF/X or PDF/A). The purpose of specialized subsets of the full PDF specification is to remove those functions that are not needed or can be problematic for specific purposes and to require some usage of functions that are only optional (not mandatory) in the full PDF specification.
On January 29, 2007, Adobe announced that it would release the full Portable Document Format 1.7 specification to the American National Standards Institute (ANSI) and the Enterprise Content Management Association (AIIM), for the purpose of publication by the International Organization for Standardization (ISO). ISO will produce future versions of the PDF specification and Adobe will be only one of the ISO technical committee members.
ISO standards for "full function PDF" are published under the formal number ISO 32000. Full function PDF specification means that it is not only a subset of Adobe PDF specification; in the case of ISO 32000-1 the full function PDF includes everything defined in Adobe's PDF 1.7 specification. However, Adobe later published extensions that are not part of the ISO standard. There are also proprietary functions in the PDF specification, that are only referenced as external specifications.
Standardized subsets of PDF.
The following specialized subsets of PDF specification has been standardized as ISO standards (or are in standardization process):
There is also the "PDF/H", a.k.a. "PDF Healthcare", a best practices guide (BPG), supplemented by an Implementation Guide (IG), published in 2008. PDF Healthcare is not a standard or proposed standard, but only a guide for use with existing standards and other technologies. It is supported by the standards development organizations ASTM and AIIM. PDF/H BPG is based on PDF 1.6.
PDF 1.7.
The final revised documentation for PDF 1.7 was approved by ISO Technical Committee 171 in January 2008 and published as ISO 32000-1:2008 on July 1, 2008 and titled "Document management – Portable document format – Part 1: PDF 1.7".
ISO 32000-1:2008 is the first ISO standard for full function PDF. The previous ISO PDF standards (PDF/A, PDF/X, etc.) are intended for more specialized uses. ISO 32000-1 includes all of the functionality previously documented in the Adobe PDF Specifications for versions 1.0 through 1.6. Adobe removed certain features of PDF from previous versions; these features are not contained in PDF 1.7 either.
The ISO 32000-1 document was prepared by Adobe Systems Incorporated based upon "PDF Reference, sixth edition, Adobe Portable Document Format version 1.7, November 2006". It was reviewed, edited and adopted under a special fast-track procedure, by "ISO Technical Committee 171 (ISO/TC 171), Document management application, Subcommittee SC 2, Application issues", in parallel with its approval by the ISO member bodies.
According to the ISO PDF standard abstract:
"ISO 32000-1:2008 specifies a digital form for representing electronic documents to enable users to exchange and view electronic documents independent of the environment they were created in or the environment they are viewed or printed in. It is intended for the developer of software that creates PDF files (conforming writers), software that reads existing PDF files and interprets their contents for display and interaction (conforming readers) and PDF products that read and/or write PDF files for a variety of other purposes (conforming products)."
Some proprietary specifications under the control of Adobe Systems (e.g. Adobe Acrobat JavaScript or XML Forms Architecture) are in the normative references of ISO 32000-1 and are indispensable for the application of ISO 32000-1.
PDF 2.0.
A new version of the PDF specification, ISO 32000-2 (PDF 2.0) is under development by ISO's TC 171 SC 2 WG 8 Committee. To provide more time to develop the document the original ISO project was cancelled in 2012 and a New Project item was started.
The goals of the ISO committee developing PDF 2.0 include evolutionary enhancement and refinement of the PDF language and deprecation of features that are no longer used (e.g. Form XObject names) and standardization of Adobe proprietary specifications (e.g. Adobe JavaScript, Rich Text).
ISO TC 171 SC 2 WG 8.
Formed in 2008 to curate the PDF Reference as an ISO Standard, Working Group 8 typically meets twice a year, with members from ten or more countries attending in each instance.
Technical foundations.
The PDF combines three technologies:
PostScript.
PostScript is a page description language run in an interpreter to generate an image, a process requiring many resources. It can handle not just graphics, but standard features of programming languages such as codice_1 and codice_2 commands. PDF is largely based on PostScript but simplified to remove flow control features like these, while graphics commands such as codice_3 remain.
Often, the PostScript-like PDF code is generated from a source PostScript file. The graphics commands that are output by the PostScript code are collected and tokenized; any files, graphics, or fonts to which the document refers also are collected; then, everything is compressed to a single file. Therefore, the entire PostScript world (fonts, layout, measurements) remains intact.
As a document format, PDF has several advantages over PostScript:
Technical overview.
File structure.
PDF was originally a textual format but allows inclusion of binary data since version 1.1. A PDF file starts with a header containing the magic number and the version of the format such as codice_4. The percent sign (codice_5) is also used to introduce comments in the code. The format is a subset of a COS ("Carousel" Object Structure) format, which is also used with FDF files. A COS tree file consists primarily of "objects", of which there are eight types:
Objects may be either "direct" (embedded in another object) or "indirect". Indirect objects are numbered with an "object number" and a "generation number" and defined between the codice_10 and codice_11 keywords. An index table, also called the cross-reference table and marked with the codice_12 keyword, follows the main body and gives the byte offset of each indirect object from the start of the file. This design allows for efficient random access to the objects in the file, and also allows for small changes to be made without rewriting the entire file ("incremental update"). Beginning with PDF version 1.5, indirect objects may also be located in special streams known as "object streams". This technique reduces the size of files that have large numbers of small indirect objects and is especially useful for "Tagged PDF".
At the end of a PDF file is a trailer introduced with the codice_13 keyword. It contains a dictionary, an offset to the start of the cross-reference table (the codice_12 keyword), and the codice_15 end-of-file marker. The dictionary contains a reference to the root object of the tree structure, which is also known as the "catalog", the count of indirect objects in the cross-reference table, and other optional information.
There are two layouts to the PDF files: non-linear (not "optimized") and linear ("optimized"). Non-linear PDF files consume less disk space than their linear counterparts, though they are slower to access because portions of the data required to assemble pages of the document are scattered throughout the PDF file. Linear PDF files (also called "optimized" or "web optimized" PDF files) are constructed in a manner that enables them to be read in a Web browser plugin without waiting for the entire file to download, since they are written to disk in a linear (as in page order) fashion. PDF files may be optimized using Adobe Acrobat software or QPDF.
Imaging model.
The basic design of how graphics are represented in PDF is very similar to that of PostScript, except for the use of transparency, which was added in PDF 1.4.
PDF graphics use a device-independent Cartesian coordinate system to describe the surface of a page. A PDF page description can use a matrix to scale, rotate, or skew graphical elements. A key concept in PDF is that of the "graphics state", which is a collection of graphical parameters that may be changed, saved, and restored by a "page description". PDF has (as of version 1.6) 24 graphics state properties, of which some of the most important are:
Vector graphics.
Vector graphics in PDF, as in PostScript, are constructed with "paths". Paths are usually composed of lines and cubic Bézier curves, but can also be constructed from the outlines of text. Unlike PostScript, PDF does not allow a single path to mix text outlines with lines and curves. Paths can be stroked, filled, or used for clipping. Strokes and fills can use any color set in the graphics state, including "patterns".
PDF supports several types of patterns. The simplest is the "tiling pattern" in which a piece of artwork is specified to be drawn repeatedly. This may be a "colored tiling pattern", with the colors specified in the pattern object, or an "uncolored tiling pattern", which defers color specification to the time the pattern is drawn. Beginning with PDF 1.3 there is also a "shading pattern", which draws continuously varying colors. There are seven types of shading pattern of which the simplest are the "axial shade" (Type 2) and "radial shade" (Type 3). 
Raster images.
Raster images in PDF (called "Image XObjects") are represented by dictionaries with an associated stream. The dictionary describes properties of the image, and the stream contains the image data. (Less commonly, a raster image may be embedded directly in a page description as an "inline image".) Images are typically "filtered" for compression purposes. Image filters supported in PDF include the general purpose filters
Normally all image content in a PDF is embedded in the file. But PDF allows image data to be stored in external files by the use of "external streams" or "Alternate Images". Standardized subsets of PDF, including PDF/A and PDF/X, prohibit these features.
Text.
Text in PDF is represented by "text elements" in page content streams. A text element specifies that "characters" should be drawn at certain positions. The characters are specified using the "encoding" of a selected "font resource".
Fonts.
A font object in PDF is a description of a digital typeface. It may either describe the characteristics of a typeface, or it may include an embedded "font file". The latter case is called an "embedded font" while the former is called an "unembedded font". The font files that may be embedded are based on widely used standard digital font formats: Type 1 (and its compressed variant CFF), TrueType, and (beginning with PDF 1.6) OpenType. Additionally PDF supports the Type 3 variant in which the components of the font are described by PDF graphic operators. 
Standard Type 1 Fonts (Standard 14 Fonts).
Fourteen typefaces, known as the "standard 14 fonts", have a special significance in PDF documents:
These fonts are sometimes called the "base fourteen fonts". These fonts, or suitable substitute fonts with the same metrics, must always be available in all PDF readers and so need not be embedded in a PDF. PDF viewers must know about the metrics of these fonts. Other fonts may be substituted if they are not embedded in a PDF.
Encodings.
Within text strings, characters are shown using "character codes" (integers) that map to glyphs in the current font using an "encoding". There are a number of predefined encodings, including "WinAnsi", "MacRoman", and a large number of encodings for East Asian languages, and a font can have its own built-in encoding. (Although the WinAnsi and MacRoman encodings are derived from the historical properties of the Windows and Macintosh operating systems, fonts using these encodings work equally well on any platform.) PDF can specify a predefined encoding to use, the font's built-in encoding or provide a lookup table of differences to a predefined or built-in encoding (not recommended with TrueType fonts). The encoding mechanisms in PDF were designed for Type 1 fonts, and the rules for applying them to TrueType fonts are complex.
For large fonts or fonts with non-standard glyphs, the special encodings "Identity-H" (for horizontal writing) and "Identity-V" (for vertical) are used. With such fonts it is necessary to provide a "ToUnicode" table if semantic information about the characters is to be preserved.
Transparency.
The original imaging model of PDF was, like PostScript's, "opaque": each object drawn on the page completely replaced anything previously marked in the same location. In PDF 1.4 the imaging model was extended to allow transparency. When transparency is used, new objects interact with previously marked objects to produce blending effects. The addition of transparency to PDF was done by means of new extensions that were designed to be ignored in products written to the PDF 1.3 and earlier specifications. As a result, files that use a small amount of transparency might view acceptably in older viewers, but files making extensive use of transparency could be viewed incorrectly in an older viewer without warning.
The transparency extensions are based on the key concepts of "transparency groups", "blending modes", "shape", and "alpha". The model is closely aligned with the features of Adobe Illustrator version 9. The blend modes were based on those used by Adobe Photoshop at the time. When the PDF 1.4 specification was published, the formulas for calculating blend modes were kept secret by Adobe. They have since been published.
The concept of a transparency group in PDF specification is independent of existing notions of "group" or "layer" in applications such as Adobe Illustrator. Those groupings reflect logical relationships among objects that are meaningful when editing those objects,
but they are not part of the imaging model.
Interactive elements.
PDF files may contain interactive elements such as annotations, form fields, video and Flash animation.
Rich Media PDF is a term that is used to describe interactive content that can be embedded or linked to inside of a PDF. This content must be produced using the Flash file format. When Adobe bought Macromedia, the jewel of the company was Flash, and the Flash player was embedded inside Adobe Acrobat and Adobe Reader, removing the need for third-party plug-ins such as Flash, QuickTime, or Windows Media. Unfortunately, this caused a rift with Apple as QuickTime video was prohibited from PDF. Rich Media expert Robert Connolly believes this event triggered the war between Apple and Adobe over the Flash iPhone/iPad dispute. Rich Media PDF will not operate in Apple's iOS devices such as the iPad and interactivity is limited.
Interactive Forms is a mechanism to add forms to the PDF file format.
PDF currently supports two different methods for integrating data and PDF forms. Both formats today coexist in PDF specification:
AcroForms.
AcroForms were introduced in the PDF 1.2 format. AcroForms permit using objects ("e.g." text boxes, Radio buttons, "etc.") and some code ("e.g." JavaScript).
Alongside the standard PDF action types, interactive forms (AcroForms) support submitting, resetting, and importing data. The "submit" action transmits the names and values of selected interactive form fields to a specified uniform resource locator (URL). Interactive form field names and values may be submitted in any of the following formats, (depending on the settings of the action’s ExportFormat, SubmitPDF, and XFDF flags):
AcroForms can keep form field values in external stand-alone files containing key:value pairs. The external files may use Forms Data Format (FDF) and XML Forms Data Format (XFDF) files. The usage rights (UR) signatures define rights for import form data files in FDF, XFDF and text (CSV/TSV) formats, and export form data files in FDF and XFDF formats.
Forms Data Format (FDF).
The Forms Data Format (FDF) is based on PDF, it uses the same syntax and has essentially the same file structure, but is much simpler than PDF, since the body of an FDF document consists of only one required object. Forms Data Format is defined in the PDF specification (since PDF 1.2). The Forms Data Format can be used when submitting form data to a server, receiving the response, and incorporating into the interactive form. It can also be used to export form data to stand-alone files that can be imported back into the corresponding PDF interactive form. Beginning in PDF 1.3, FDF can be used to define a container for annotations that are separate from the PDF document they apply to. FDF typically encapsulates information such as X.509 certificates, requests for certificates, directory settings, timestamp server settings, and embedded PDF files for network transmission. The FDF uses the MIME content type application/vnd.fdf, filename extension .fdf and on Mac OS it uses file type 'FDF'. Support for importing and exporting FDF stand-alone files is not widely implemented in free or freeware PDF software. For example, there is no import/export support in Evince, Okular, Poppler, KPDF or Sumatra PDF, however, Evince, Okular and Poppler support filling in of PDF Acroforms and saving filled data inside the PDF file. Import support for stand-alone FDF files is implemented in Adobe Reader; export and import support (including saving of FDF data in PDF) is for example implemented in Foxit Reader and PDF-XChange Viewer Free; saving of FDF data in a PDF file is also supported in pdftk.
XML Forms Data Format (XFDF).
XML Forms Data Format (XFDF) is the XML version of Forms Data Format, but the XFDF implements only a subset of FDF containing forms and annotations. There are not XFDF equivalents for some entries in the FDF dictionary - such as the Status, Encoding, JavaScript, Pages keys, EmbeddedFDFs, Differences and Target. In addition, XFDF does not allow the spawning, or addition, of new pages based on the given data; as can be done when using an FDF file. The XFDF specification is referenced (but not included) in PDF 1.5 specification (and in later versions). It is described separately in "XML Forms Data Format Specification". The PDF 1.4 specification allowed form submissions in XML format, but this was replaced by submissions in XFDF format in the PDF 1.5 specification. XFDF conforms to the XML standard. As of November 2014, XFDF 3.0 is in the ISO/IEC standardization process under the formal name "ISO/CD 19444-1 - Document management - XML forms data format - Part 1: XFDF 3.0".
XFDF can be used the same way as FDF; e.g., form data is submitted to a server, modifications are made, then sent back and the new form data is imported in an interactive form. It can also be used to export form data to stand-alone files that can be imported back into the corresponding PDF interactive form. A support for importing and exporting XFDF stand-alone files is not widely implemented in free or freeware PDF software. Import of XFDF is implemented in Adobe Reader 5 and later versions; import and export is implemented in PDF-XChange Viewer Free; embedding of XFDF data in PDF form is implemented in pdftk (pdf toolkit).
Adobe XML Forms Architecture (XFA).
In the PDF 1.5 format, Adobe Systems introduced a new, proprietary format for forms, namely Adobe XML Forms Architecture (XFA) forms. The XFA 2.02 is referenced in the PDF 1.5 specification (and also in later versions) but is described separately in "Adobe XML Forms Architecture (XFA) Specification", which has several versions. XFA specification is not included in ISO 32000-1 PDF 1.7 and is only referenced as an external proprietary specification created by Adobe. XFA was not standardized as an ISO standard. In 2011 the ISO Committee (TC 171/SC 2/WG 8) urged Adobe Systems to submit the XFA Specification for standardization.
Adobe XFA Forms are not compatible with AcroForms. Adobe Reader contains "disabled features" for use of XFA Forms, that activate only when opening a PDF document that was created using enabling technology available only from Adobe. The XFA Forms are not compatible with Adobe Reader prior to version 6.
XFA forms can be created and used as PDF files or as XDP (XML Data Package) files. The format of an XFA resource in PDF is described by the XML Data Package Specification. The XDP may be a standalone document or it may in turn be carried inside a PDF document. XDP provides a mechanism for packaging form components within a surrounding XML container. An XDP can also package a PDF file, along with XML form and template data. PDF may contain XFA (in XDP format), but also XFA may contain PDF. When the XFA (XML Forms Architecture) grammars used for an XFA form are moved from one application to another, they must be packaged as an XML Data Package.
When the PDF and XFA are combined, the result is a form in which each page of the XFA form overlays a PDF background. This architecture is
sometimes referred to as XFAF (XFA Foreground). The alternative is to express all of the form, including boilerplate, directly in XFA (without using PDF, or only using "Shell PDF" which is a container for XFA with minimal skeleton of PDF markup, or using a pre-rendered depiction of a static XFA form as PDF pages). It is sometimes called "full" XFA.
Starting with PDF 1.5, the text contents of variable text form fields, as well as markup annotations may include formatting information (style information). These rich text strings are XML documents that conform to the rich text conventions specified for the XML Forms Architecture specification 2.02, which is itself a subset of the XHTML 1.0 specification, augmented with a restricted set of CSS2 style attributes.
In PDF 1.6, PDF supports the rich text elements and attributes specified in the XML Forms Architecture (XFA) Specification, 2.2.
In PDF 1.7, PDF supports the rich text elements and attributes specified in the XML Forms Architecture (XFA) Specification, 2.4.
Most PDF processors do not handle XFA content. When generating a shell PDF it is recommended to include in the PDF markup a simple one-page PDF image displaying a warning message (e.g. "To view the full contents of this document, you need a later version of the PDF viewer.", etc.). PDF processors that can render XFA content should either not display the supplied warning page image or replace it quickly with the dynamic form content. Examples of PDF software with some support of XFA rendering include Adobe Reader for Windows, Linux, Mac OS X (but not Adobe Reader Mobile for Android or iOS) or Nuance PDF Reader.
Logical structure and accessibility.
A "tagged" PDF (ISO 32000-1:2008 14.8) includes document structure and semantics information to enable reliable text extraction and accessibility. Technically speaking, tagged PDF is a stylized use of the format that builds on the logical structure framework introduced in PDF 1.3. Tagged PDF defines a set of standard structure types and attributes that allow page content (text, graphics, and images) to be extracted and reused for other purposes.
Tagged PDF is not required in situations where a PDF file is intended only for print. Since the feature is optional, and since the rules for Tagged PDF as specified in ISO 32000-1 are relatively vague, support for tagged PDF amongst consuming devices, including assistive technology (AT), is uneven.
An AIIM project to develop an ISO-standardized subset of PDF specifically targeted at accessibility began in 2004, eventually becoming PDF/UA.
Security and signatures.
A PDF file may be encrypted for security, or digitally signed for authentication.
The standard security provided by Acrobat PDF consists of two different methods and two different passwords, "user password", which encrypts the file and prevents opening, and "owner password", which specifies operations that should be restricted even when the document is decrypted, which can include: printing, copying text and graphics out of the document, modifying the document, or adding or modifying text notes and AcroForm fields. The user password (controls opening) encrypts the file and requires password cracking to defeat, with difficulty depending on password strength and encryption method – it is potentially very secure (assuming good password and encryption method without known attacks). The owner password (controls operations) does not encrypt the file, and instead relies on client software to respect these restrictions, and is not secure. An "owner password" can be removed by many commonly available "PDF cracking" software, including some free online services. Thus, the use restrictions that a document author places on a PDF document are not secure, and cannot be assured once the file is distributed; this warning is displayed when applying such restrictions using Adobe Acrobat software to create or edit PDF files.
Even without removing the password, most freeware or open source PDF readers ignore the permission "protections" and allow the user to print or make copy of excerpts of the text as if the document were not limited by password protection.
Some solutions, like Adobe's LiveCycle Rights Management, are more robust means of information rights management, which can not only restrict who can open documents but also reliably enforce permissions in ways that the standard security handler does not.
Usage rights.
Beginning with PDF 1.5, Usage rights (UR) signatures are used to enable additional interactive features that are not available by default in a particular PDF viewer application. The signature is used to validate that the permissions have been granted by a bona fide granting authority. For example, it can be used to allow a user:
For example, Adobe Systems grants permissions to enable additional features in Adobe Reader, using public-key cryptography. Adobe Reader verifies that the signature uses a certificate from an Adobe-authorized certificate authority. The PDF 1.5 specification declares that other PDF viewer applications are free to use this same mechanism for their own purposes.
File attachments.
PDF files can have document-level and page-level file attachments, which the reader can access and open or save to their local filesystem. PDF attachments can be added to existing PDF files for example using pdftk. Adobe Reader provides support for attachments, and poppler-based readers like Evince or Okular also have some support for document-level attachments.
Metadata.
PDF files can contain two types of metadata. The first is the Document Information Dictionary, a set of key/value fields such as author, title, subject, creation and update dates. This is stored in the optional Info trailer of the file. A small set of fields is defined, and can be extended with additional text values if required.
Later, in PDF 1.4, support was added for the Metadata Streams, using the Extensible Metadata Platform (XMP) to add XML standards-based extensible metadata as used in other file formats. This allows metadata to be attached to any stream in the document, such as information about embedded illustrations, as well as the whole document (attaching to the document catalog), using an extensible schema.
Intellectual property.
Anyone may create applications that can read and write PDF files without having to pay royalties to Adobe Systems; Adobe holds patents to PDF, but licenses them for royalty-free use in developing software complying with its PDF specification.
Future.
ISO 32000-2: Next-generation PDF.
Known in PDF syntax terms as "PDF-2.0", ISO 32000-2 will be the first update to the PDF specification developed entirely within the ISO Committee process (TC 171 SC 2 WG 8). Publication of ISO 32000-2 is expected in the first half of 2016. Interested parties resident in TC 171 Member or Observer countries and wishing to participate should contact their country's Member Body or the secretary of TC 171 SC 2. Members of the PDF Association may review and comment on drafts via the PDF Association's Category A liaison with ISO TC 171 SC 2.
Mars.
Adobe was exploring an XML-based next-generation PDF code-named Mars.
The format of graphic elements of Mars was sometimes described simply as "SVG", but according to the version 0.8 draft specification of November 2007 (§3 Mars SVG Support) the format was actually merely similar to SVG: it contained both additions to and subtractions from SVG, so it was in general neither viewable by nor creatable with standard SVG tools: some things looked noticeably different between SVG viewers and Mars viewers.
Adobe Systems ceased development of Mars in 2008.
Technical issues.
Scanned documents.
PDF files created by scanning hard-copy documents containing primarily text do not have the same structure as a PDF file of the same document created directly. The scanned document internally contains a picture of the document, with no information about the text. As far as a user can see it is just another PDF file, with a name and extension indistinguishable from any other; a good scan may look exactly the same as a native PDF file, although a visually poor-quality file, often with skewed pages, gives away its nature. However, the file size will be different, and it will not be possible to search for text. For a scan of adequate quality it is possible with suitable software to regenerate the text of the document with Optical character recognition (OCR), and embed it in the file so as to make it searchable, subject to the accuracy of the OCR.
Accessibility.
PDF files can be created specifically to be accessible for disabled people. PDF file formats in use can include tags (XML), text equivalents, captions, audio descriptions, etc. Tagged PDF is required in the PDF/A-1a specification. Some software can automatically produce tagged PDFs, but this feature is not always enabled by default. Leading screen readers, including JAWS, Window-Eyes, Hal, and Kurzweil 1000 and 3000 can read tagged PDFs aloud, as can later versions of the Acrobat and Acrobat Reader programs. Moreover, tagged PDFs can be re-flowed and magnified for readers with visual impairments. Problems remain with adding tags to older PDFs and those that are generated from scanned documents. In these cases, accessibility tags and re-flowing are unavailable, and must be created either manually or with OCR techniques. These processes are inaccessible to some disabled people.
One of the significant challenges with PDF accessibility is that PDF documents have three distinct views, which, depending on the document's creation, can be inconsistent with each other. The three views are (i) the physical view, (ii) the tags view, and (iii) the content view. The physical view is displayed and printed (what most people consider a PDF document). The tags view is what screen readers and other assistive technologies use to deliver a high-quality navigation and reading experience to users with disabilities. The content view is based on the physical order of objects within the PDF's content stream and may be displayed by software that does not fully support the tags view, such as the Reflow feature in Adobe's Reader.
PDF/UA, the International Standard for accessible PDF based on ISO 32000-1 was published as ISO 14289-1 in 2012, and establishes normative language for accessible PDF technology.
Viruses and exploits.
PDF attachments carrying viruses were first discovered in 2001. The virus, named "OUTLOOK.PDFWorm" or "Peachy", uses Microsoft Outlook to send itself as an attachment to an Adobe PDF file. It was activated with Adobe Acrobat, but not with Acrobat Reader.
From time to time, new vulnerabilities are discovered in various versions of Adobe Reader, prompting the company to issue security fixes. Other PDF readers are also susceptible. One aggravating factor is that a PDF reader can be configured to start automatically if a web page has an embedded PDF file, providing a vector for attack. If a malicious web page contains an infected PDF file that takes advantage of a vulnerability in the PDF reader, the system may be compromised even if the browser is secure. Some of these vulnerabilities are a result of the PDF standard allowing PDF documents to be scripted with JavaScript. Disabling JavaScript execution in the PDF reader can help mitigate such future exploits, although it does not protect against exploits in other parts of the PDF viewing software. Security experts say that JavaScript is not essential for a PDF reader, and that the security benefit that comes from disabling JavaScript outweighs any compatibility issues caused. One way of avoiding PDF file exploits is to have a local or web service convert files to another format before viewing.
On March 30, 2010 security researcher Didier Stevens reported an Adobe Reader and Foxit Reader exploit that runs a malicious executable if the user allows it to launch when asked.
Usage restrictions and monitoring.
PDFs may be encrypted so that a password is needed to view or edit the contents. The PDF Reference defines both 40-bit and 128-bit encryption, both making use of a complex system of RC4 and MD5. The PDF Reference also defines ways that third parties can define their own encryption systems for PDF.
PDF files may also contain embedded DRM restrictions that provide further controls that limit copying, editing or printing. The restrictions on copying, editing, or printing depend on the reader software to obey them, so the security they provide is limited.
The PDF Reference has technical details for an end-user overview. Like HTML files, PDF files may submit information to a web server. This could be used to track the IP address of the client PC, a process known as phoning home. After update 7.0.5 to Acrobat Reader, the user is notified "... via a dialogue box that the author of the file is auditing usage of the file, and be offered the option of continuing."
Through its LiveCycle Policy Server product, Adobe provides a method to set security policies on specific documents. This can include requiring a user to authenticate and limiting the period during which a document can be accessed or amount of time a document can be opened while offline. Once a PDF document is tied to a policy server and a specific policy, that policy can be changed or revoked by the owner. This controls documents that are otherwise "in the wild." Each document open and close event can also be tracked by the policy server. Policy servers can be set up privately or Adobe offers a public service through Adobe Online Services. As with other forms of DRM, adherence to these policies and restrictions may or may not be enforced by the reader software being used.
Default display settings.
PDF documents can contain display settings, including the page display layout and zoom level. Adobe Reader uses these settings to override the user's default settings when opening the document. The free Adobe Reader cannot remove these settings.
Content.
A PDF file is often a combination of vector graphics, text, and bitmap graphics. The basic types of content in a PDF are:
In later PDF revisions, a PDF document can also support links (inside document or web page), forms, JavaScript (initially available as plugin for Acrobat 3.0), or any other types of embedded contents that can be handled using plug-ins.
PDF 1.6 supports interactive 3D documents embedded in the PDF - 3D drawings can be embedded using U3D or PRC and various other data formats.
Two PDF files that look similar on a computer screen may be of very different sizes. For example, a high resolution raster image takes more space than a low resolution one. Typically higher resolution is needed for printing documents than for displaying them on screen. Other things that may increase the size of a file is embedding full fonts, especially for Asiatic scripts, and storing text as graphics.
Software.
PDF viewers are generally provided free of charge, and many versions are available from a variety of sources.
There are many software options for creating PDFs, including the PDF printing capabilities built into Mac OS X and most Linux distributions, LibreOffice, Microsoft Office 2007 (if updated to SP2), WordPerfect 9, Scribus, numerous PDF print drivers for Microsoft Windows, the pdfTeX typesetting system, the DocBook PDF tools, applications developed around Ghostscript and Adobe Acrobat itself as well as Adobe InDesign, Adobe FrameMaker, Adobe Illustrator, Adobe Photoshop. Google's online office suite Google Docs also allows for uploading, and saving to PDF.
Raster image processors (RIPs) are used to convert PDF files into a raster format suitable for imaging onto paper and other media in printers, digital production presses and prepress in a process known as rasterisation. RIPs capable of processing PDF directly include the Adobe PDF Print Engine from Adobe Systems and Jaws and the Harlequin RIP from Global Graphics.
Editing.
There is specialized software for editing PDF files, though the choices are much more limited and often more expensive than creating and editing standard editable document formats. Version 0.46 and later of Inkscape allows PDF editing through an intermediate translation step involving Poppler.
Serif PagePlus can open, edit and save existing PDF documents, as well as publishing of documents created in the package.
Enfocus PitStop Pro, a plugin for Acrobat, allows manual and automatic editing of PDF files, while the free Enfocus Browser makes it possible to edit the low-level structure of a PDF.
Dochub, is a free online PDF editing tool that can be used without purchasing anything.
Annotation.
Adobe Acrobat is one example of proprietary software that allows the user to annotate, highlight, and add notes to already created PDF files. One UNIX application available as free software (under the GNU General Public License) is PDFedit. Another GPL-licensed application native to the unix environment is Xournal. Xournal allows for annotating in different fonts and colours, as well as a rule for quickly underlining and highlighting lines of text or paragraphs. Xournal also has a shape recognition tool for squares, rectangles and circles. In Xournal annotations may be moved, copied and pasted. The freeware Foxit Reader, available for Microsoft Windows, OS X and Linux, allows annotating documents. Tracker Software's PDF-XChange Viewer allows annotations and markups without restrictions in its freeware alternative. Apple's Mac OS X's integrated PDF viewer, Preview, does also enable annotations as does the freeware Skim, with the latter supporting interaction with LaTeX, SyncTeX, and PDFSync and integration with BibDesk reference management software. Freeware Qiqqa can create an annotation report that summarizes all the annotations and notes one has made across their library of PDFs.
For mobile annotation, iAnnotate PDF (from Branchfire) and GoodReader (from Aji) allow annotation of PDFs as well as exporting summaries of the annotations.
There are also web annotation systems that support annotation in pdf and other documents formats, e.g., A.nnotate, crocodoc, WebNotes.
In cases where PDFs are expected to have all of the functionality of paper documents, ink annotation is required. Some programs that accept ink input from the mouse may not be responsive enough for handwriting input on a tablet. Existing solutions on the PC include PDF Annotator and Qiqqa.
Other.
Examples of PDF software as online services including Scribd for viewing and storing, Pdfvue for online editing, and Zamzar for PDF Conversion.
In 1993 the Jaws raster image processor from Global Graphics became the first shipping prepress RIP that interpreted PDF natively without conversion to another format. The company released an upgrade to their Harlequin RIP with the same capability in 1997.
Agfa-Gevaert introduced and shipped Apogee, the first prepress workflow system based on PDF, in 1997.
Many commercial offset printers have accepted the submission of press-ready PDF files as a print source, specifically the PDF/X-1a subset and variations of the same. The submission of press-ready PDF files are a replacement for the problematic need for receiving collected native working files.
PDF was selected as the "native" metafile format for Mac OS X, replacing the PICT format of the earlier Mac OS. The imaging model of the Quartz graphics layer is based on the model common to Display PostScript and PDF, leading to the nickname "Display PDF". The Preview application can display PDF files, as can version 2.0 and later of the Safari web browser. System-level support for PDF allows Mac OS X applications to create PDF documents automatically, provided they support the OS-standard printing architecture. The files are then exported in PDF 1.3 format according to the file header. When taking a screenshot under Mac OS X versions 10.0 through 10.3, the image was also captured as a PDF; later versions save screen captures as a PNG file, though this behaviour can be set back to PDF if desired.
Some desktop printers also support direct PDF printing, which can interpret PDF data without external help. Currently, all PDF capable printers also support PostScript, but most PostScript printers do not support direct PDF printing.
The Free Software Foundation once considered one of their high priority projects to be "developing a free, high-quality and fully functional set of libraries and programs that implement the PDF file format and associated technologies to the ISO 32000 standard." In 2011, however, the GNU PDF project was removed from the list of "high priority projects" due to the maturation of the Poppler library, which has enjoyed wider use in applications such as Evince with the GNOME desktop environment. Poppler is based on Xpdf code base. There are also commercial development libraries available as listed in List of PDF software.
The Apache PDFBox project of the Apache Software Foundation is an open source Java library for working with PDF documents. PDFBox is licensed under the Apache License.

</doc>
<doc id="24080" url="https://en.wikipedia.org/wiki?curid=24080" title="PostScript">
PostScript

PostScript (PS) is a computer language for creating vector graphics. It is a dynamically typed, concatenative programming language and was created at Adobe Systems by John Warnock, Charles Geschke, Doug Brotz, Ed Taft and Bill Paxton in 1982-4. It is used as a page description language in the electronic and desktop publishing areas.
History.
The concepts of the PostScript language were seeded in 1976 when John Warnock was working at Evans & Sutherland, a computer graphics company. At that time John Warnock was developing an interpreter for a large three-dimensional graphics database of New York harbor. Warnock conceived the Design System language to process the graphics.
Concurrently, researchers at Xerox PARC had developed the first laser printer and had recognized the need for a standard means of defining page images. In 1975-76 Bob Sproull and William Newman developed the Press format, which was eventually used in the Xerox Star system to drive laser printers. But Press, a data format rather than a language, lacked flexibility, and PARC mounted the Interpress effort to create a successor.
In 1978 Evans & Sutherland asked Warnock to move from the San Francisco Bay Area to their main headquarters in Utah, but he was not interested in moving. He then joined Xerox PARC to work with Martin Newell. They rewrote Design System to create J & M (for "John and Martin") which was used for VLSI design and the investigation of type and graphics printing. This work later evolved and expanded into the Interpress language.
Warnock left with Chuck Geschke and founded Adobe Systems in December 1982. They, together with Doug Brotz, Ed Taft and Bill Paxton created a simpler language, similar to Interpress, called PostScript, which went on the market in 1984. At about this time they were visited by Steve Jobs, who urged them to adapt PostScript to be used as the language for driving laser printers.
In March 1985, the Apple LaserWriter was the first printer to ship with PostScript, sparking the desktop publishing (DTP) revolution in the mid-1980s. The combination of technical merits and widespread availability made PostScript a language of choice for graphical output for printing applications. For a time an interpreter (sometimes referred to as a RIP for Raster Image Processor) for the PostScript language was a common component of laser printers, into the 1990s.
However, the cost of implementation was high; computers output raw PS code that would be interpreted by the printer into a raster image at the printer's natural resolution. This required high performance microprocessors and ample memory. The LaserWriter used a 12 MHz Motorola 68000, making it faster than any of the Macintosh computers to which it attached. When the laser printer engines themselves cost over a thousand dollars the added cost of PS was marginal. But as printer mechanisms fell in price, the cost of implementing PS became too great a fraction of overall printer cost; in addition, with desktop computers becoming more powerful, it no longer made sense to offload the rasterisation work onto the resource-constrained printer. By 2001, few lower-end printer models came with support for PostScript, largely due to growing competition from much cheaper non-PostScript ink jet printers, and new software-based methods to render PostScript images on the computer, making them suitable for any printer; PDF, a descendant of PostScript, provides one such method, and has largely replaced PostScript as "de facto" standard for electronic document distribution.
On high-end printers, PostScript processors remain common, and their use can dramatically reduce the CPU work involved in printing documents, transferring the work of rendering PostScript images from the computer to the printer.
PostScript Level 1.
The first version of the PostScript language was released to the market in 1984. The term "Level 1" was added when Level 2 was introduced.
PostScript Level 2.
PostScript Level 2 was introduced in 1991, and included several improvements: improved speed and reliability, support for in-RIP separations, image decompression (for example, JPEG images could be rendered by a PostScript program), support for composite fonts, and the form mechanism for caching reusable content.
PostScript 3.
PostScript 3 (Adobe dropped the "level" terminology in favor of simple versioning) came at the end of 1997, and along with many new dictionary-based versions of older operators, introduced better color handling, and new filters (which allow in-program compression/decompression, program chunking, and advanced error-handling).
PostScript 3 was significant in terms of replacing the existing proprietary color electronic prepress systems, then widely used for magazine production, through the introduction of smooth shading operations with up to 4096 shades of grey (rather than the 256 available in PostScript Level 2), as well as DeviceN, a color space that allowed the addition of additional ink colors (called spot colors) into composite color pages.
Use in printing.
Before PostScript.
Prior to the introduction of PostScript, printers were designed to print character output given the text—typically in ASCII—as input. There were a number of technologies for this task, but most shared the property that the glyphs were physically difficult to change, as they were stamped onto typewriter keys, bands of metal, or optical plates.
This changed to some degree with the increasing popularity of dot matrix printers. The characters on these systems were drawn as a series of dots, as defined by a font table inside the printer. As they grew in sophistication, dot matrix printers started including several built-in fonts from which the user could select, and some models allowed users to upload their own custom glyphs into the printer.
Dot matrix printers also introduced the ability to print raster graphics. The graphics were interpreted by the computer and sent as a series of dots to the printer using a series of escape sequences. These printer control languages varied from printer to printer, requiring program authors to create numerous drivers.
Vector graphics printing was left to special-purpose devices, called plotters. Almost all plotters did share a common command language, HPGL, but were of limited use for anything other than printing graphics. In addition, they tended to be expensive and slow, and thus rare.
PostScript printing.
Laser printers combine the best features of both printers and plotters. Like plotters, laser printers offer high quality line art, and like dot-matrix printers, they are able to generate pages of text and raster graphics. Unlike either printers or plotters, however, a laser printer makes it possible to position high-quality graphics and text on the same page. PostScript made it possible to fully exploit these characteristics, by offering a single control language that could be used on any brand of printer.
PostScript went beyond the typical printer control language and was a complete programming language of its own. Many applications can transform a document into a PostScript program whose execution will result in the original document. This program can be sent to an interpreter in a printer, which results in a printed document, or to one inside another application, which will display the document on-screen. Since the document-program is the same regardless of its destination, it is called "device-independent".
PostScript is noteworthy for implementing on-the fly rasterization; everything, even text, is specified in terms of straight lines and cubic Bézier curves (previously found only in CAD applications), which allows arbitrary scaling, rotating and other transformations. When the PostScript program is interpreted, the interpreter converts these instructions into the dots needed to form the output. For this reason PostScript interpreters are occasionally called PostScript Raster Image Processors, or RIPs.
Font handling.
Almost as complex as PostScript itself is its handling of fonts. The font system uses the PS graphics primitives to draw glyphs as line art, which can then be rendered at any resolution. A number of typographic issues had to be considered with this approach.
One issue is that fonts do not actually scale linearly at small sizes; features of the glyphs will become proportionally too large or small and they start to look wrong. PostScript avoided this problem with the inclusion of font hinting, in which additional information is provided in horizontal or vertical bands to help identify the features in each letter that are important for the rasterizer to maintain. The result was significantly better-looking fonts even at low resolution; it had formerly been believed that hand-tuned bitmap fonts were required for this task.
At the time, the technology for including these hints in fonts was carefully guarded, and the hinted fonts were compressed and encrypted into what Adobe called a "Type 1 Font" (also known as "PostScript Type 1 Font", "PS1", "T1" or "Adobe Type 1"). Type 1 was effectively a simplification of the PS system to store outline information only, as opposed to being a complete language (PDF is similar in this regard). Adobe would then sell licenses to the Type 1 technology to those wanting to add hints to their own fonts. Those who did not license the technology were left with the "Type 3 Font" (also known as "PostScript Type 3 Font", "PS3" or "T3"). Type 3 fonts allowed for all the sophistication of the PostScript language, but without the standardized approach to hinting.
The Type 2 font format was designed to be used with Compact Font Format (CFF) charstrings, and was implemented to reduce the overall font file size. The CFF/Type2 format later became the basis for handling PostScript outlines in OpenType fonts.
The CID-keyed font format was also designed, to solve the problems in the OCF/Type 0 fonts, for addressing the complex Asian-language (CJK) encoding and very large character set issues. The CID-keyed font format can be used with the Type 1 font format for standard CID-keyed fonts, or Type 2 for CID-keyed OpenType fonts.
To compete with Adobe's system, Apple designed their own system, TrueType, around 1991. Immediately following the announcement of TrueType, Adobe published the specification for the Type 1 font format. Retail tools such as Altsys Fontographer (acquired by Macromedia in January 1995, owned by FontLab since May 2005) added the ability to create Type 1 fonts. Since then, many free Type 1 fonts have been released; for instance, the fonts used with the TeX typesetting system are available in this format.
In the early 1990s there were several other systems for storing outline-based fonts, developed by Bitstream and METAFONT for instance, but none included a general-purpose printing solution and they were therefore not widely used.
In the late 1990s, Adobe joined Microsoft in developing OpenType, essentially a functional superset of the Type 1 and TrueType formats. When printed to a PostScript output device, the unneeded parts of the OpenType font are omitted, and what is sent to the device by the driver is the same as it would be for a TrueType or Type 1 font, depending on which kind of outlines were present in the OpenType font.
Other implementations.
In the 1980s, Adobe drew most of its revenue from the licensing fees for their implementation of PostScript for printers, known as a raster image processor or "RIP". As a number of new RISC-based platforms became available in the mid-1980s, some found Adobe's support of the new machines to be lacking.
This and issues of cost led to third-party implementations of PostScript becoming common, particularly in low-cost printers (where the licensing fee was the sticking point) or in high-end typesetting equipment (where the quest for speed demanded support for new platforms faster than Adobe could provide). At one point, Microsoft licensed to Apple a PostScript-compatible interpreter it had bought called TrueImage, and Apple licensing to Microsoft its new font format, TrueType. Apple ended up reaching an accord with Adobe and licensed genuine PostScript for its printers, but TrueType became the standard outline font technology for both Windows and the Macintosh.
Today, third-party PostScript-compatible interpreters are widely used in printers and multifunction peripherals (MFPs). For example, CSR plc's IPS PS3 interpreter, formerly known as PhoenixPage, is standard in many printers and MFPs, including those developed by Hewlett-Packard and sold under the LaserJet and Color LaserJet lines. Other third-party PostScript solutions used by print and MFP manufacturers include Jaws and the Harlequin RIP, both by Global Graphics. A free software version, with several other applications, is Ghostscript. Several compatible interpreters are listed on the Undocumented Printing Wiki.
Some basic, inexpensive laser printers do not support PostScript, instead coming with drivers that simply rasterize the platform's native graphics formats rather than converting them to PostScript first. When PostScript support is needed for such a printer, Ghostscript can be used. There are also a number of commercial PostScript interpreters, such as TeleType Co.'s T-Script.
Use as a display system.
PostScript became commercially successful due to the introduction of the graphical user interface, allowing designers to directly lay out pages for eventual output on laser printers. However, the GUI's own graphics systems were generally much less sophisticated than PostScript; Apple's QuickDraw, for instance, supported only basic lines and arcs, not the complex B-splines and advanced region filling options of PostScript. In order to take full advantage of PostScript printing, applications on the computers had to re-implement those features using the host platform's own graphics system. This led to numerous issues where the on-screen layout would not exactly match the printed output, due to differences in the implementation of these features.
As computer power grew, it became possible to host the PS system in the computer rather than the printer. This led to the natural evolution of PS from a printing system to one that could also be used as the host's own graphics language. There were numerous advantages to this approach; not only did it help eliminate the possibility of different output on screen and printer, but it also provided a powerful graphics system for the computer, and allowed the printers to be "dumb" at a time when the cost of the laser engines was falling. In a production setting, using PostScript as a display system meant that the host computer could render low-resolution to the screen, higher resolution to the printer, or simply send the PS code to a smart printer for offboard printing.
However, PostScript was written with printing in mind, and had numerous features that made it unsuitable for direct use in an interactive display system. In particular, PS was based on the idea of collecting up PS commands until the codice_1 command was seen, at which point all of the commands read up to that point were interpreted and output. In an interactive system this was clearly not appropriate. Nor did PS have any sort of interactivity built in; for example, supporting hit detection for mouse interactivity obviously did not apply when PS was being used on a printer.
When Steve Jobs left Apple and started NeXT, he pitched Adobe on the idea of using PS as the display system for his new workstation computers. The result was Display PostScript, or DPS. DPS added basic functionality to improve performance by changing many string lookups into 32 bit integers, adding support for direct output with every command, and adding functions to allow the GUI to inspect the diagram. Additionally, a set of "bindings" was provided to allow PS code to be called directly from the C programming language. NeXT used these bindings in their NeXTStep system to provide an object oriented graphics system. Although DPS was written in conjunction with NeXT, Adobe sold it commercially and it was a common feature of most Unix workstations in the 1990s.
Sun Microsystems took another approach, creating NeWS. Instead of DPS's concept of allowing PS to interact with C programs, NeWS instead extended PS into a language suitable for running the entire GUI of a computer. Sun added a number of new commands for timers, mouse control, interrupts and other systems needed for interactivity, and added data structures and language elements to allow it to be completely object oriented internally. A complete GUI, three in fact, were written in NeWS and provided for a time on their workstations. However, the ongoing efforts to standardize the X11 system led to its introduction and widespread use on Sun systems, and NeWS never became widely used.
The language.
PostScript is a Turing-complete programming language, belonging to the concatenative group. Typically, PostScript programs are not produced by humans, but by other programs. However, it is possible to write computer programs in PostScript just like any other programming language.
PostScript is an interpreted, stack-based language similar to Forth but with strong dynamic typing, data structures inspired by those found in Lisp, scoped memory and, since language level 2, garbage collection. The language syntax uses reverse Polish notation, which makes the order of operations unambiguous, but reading a program requires some practice, because one has to keep the layout of the stack in mind. Most "operators" (what other languages term "functions") take their arguments from the stack, and place their results onto the stack. "Literals" (for example, numbers) have the effect of placing a copy of themselves on the stack. Sophisticated data structures can be built on the "array" and "dictionary" types, but cannot be declared to the type system, which sees them all only as arrays and dictionaries, so any further typing discipline to be applied to such user-defined "types" is left to the code that implements them.
The character "%" is used to introduce comments in PostScript programs. As a general convention, every PostScript program should start with the characters "%!PS" as an interpreter directive so that all devices will properly interpret it as PostScript.
"Hello world".
A Hello World program, the customary way to show a small example of a complete program in a given language, might look like this in PostScript (level 2):
<syntaxhighlight lang=postscript>
</syntaxhighlight>
or if the output device has a console
<syntaxhighlight lang=postscript>
</syntaxhighlight>
Units of length.
PostScript uses the point as its unit of length. However, unlike some of the other versions of the point, PostScript uses exactly 72 points to the inch. Thus:
For example, in order to draw a vertical line of 4 cm length, it is sufficient to type:
More readably and idiomatically, one might use the following equivalent, which demonstrates a simple procedure definition and the use of the mathematical operators codice_2 and codice_3:
Most implementations of PostScript use single-precision reals (24-bit mantissa), so it is not meaningful to use more than 9 decimal digits to specify a real number, and performing calculations may produce unacceptable round-off errors.

</doc>
<doc id="24082" url="https://en.wikipedia.org/wiki?curid=24082" title="Pole vault">
Pole vault

Pole vaulting is a track and field event in which a person uses a long, flexible pole (which today is usually made either of fiberglass or carbon fiber) as an aid to jump over a bar. Pole jumping competitions were known to the ancient Greeks, Cretans and Celts. It has been a full medal event at the Olympic Games since 1896 for men and 2000 for women.
It is typically classified as one of the four major jumping events in athletics, alongside the high jump, long jump and triple jump. It is unusual among track and field sports in that it requires a significant amount of specialised equipment in order to participate, even at a basic level. A number of elite pole vaulters have had backgrounds in gymnastics, including world record breakers Yelena Isinbayeva and Brian Sternberg, reflecting the similar physical attributes required for the sports. Running speed, however, may be the most important skill required.
History.
Poles were used as a practical means of passing over natural obstacles in marshy places such as provinces of Friesland in the Netherlands, along the North Sea, and the great level of the Fens across Cambridgeshire, Huntingdonshire, Lincolnshire and Norfolk. Artificial draining of these marshes created a network of open drains or canals intersecting each other. To cross these without getting wet, while avoiding tedious roundabout journeys over bridges, a stack of jumping poles was kept at every house and used for vaulting over the canals. Venetian gondoliers have traditionally used punting poles for moving to the shore from their boat.
Distance pole vaulting competitions continue to be held annually in the lowlands around the North Sea. These far-jumping competitions (Frysk: "Fierljeppen") are not based on height.
In his book "The Mechanics of the Pole Vault," Richard Ganslen reports that the London Gymnastic Society under Professor Voelker held measured pole vaulting events in 1826, involving 1,300 participants and recording heights up to . Other early pole vaulting competitions where height was measured took place at the Ulverston Football and Cricket Club, Lancashire, north of the sands (now Cumbria) in 1843. Modern competition began around 1850 in Germany, when pole vaulting was added to the exercises of the Turner gymnastic clubs by Johann C. F. GutsMuths and Friedrich L. Jahn. In Great Britain, it was first practiced at the Caledonian Games.
Initially, vaulting poles were made from stiff materials such as bamboo or aluminum. The introduction of flexible vaulting poles in the early 1950s made from composites such as fiberglass or carbon fiber allowed vaulters to achieve greater height. Physical attributes such as speed, agility and strength are essential to pole vaulting effectively, but technical skill is an equally if not more important element. The object of pole vaulting is to clear a bar or crossbar supported upon two uprights (standards) without knocking it down.
Modern vaulting.
Today, athletes compete in the pole vault as one of the four jumping events in track and field. Because the high jump and pole vault are both vertical jumps, the competitions are conducted similarly. Each athlete can choose what height they would like to enter the competition. Once they enter, they have three attempts to clear the height. If a height is cleared, the vaulter advances to the next height, where they will have three more attempts. Once the vaulter has three consecutive misses, they are out of the competition and the highest height they cleared is their result. A "no height", often denoted "NH", refers to the failure of a vaulter to clear any bar during the competition.
Once the vaulter enters the competition, they can choose to pass heights. If a vaulter achieves a miss on their first attempt at a height, they can pass to the next height, but they will only have two attempts at that height, as they will be out once they achieve three consecutive misses. Similarly, after earning two misses at a height, they could pass to the next height, when they would have only one attempt.
The competitor who clears the highest height is the winner. If two or more vaulters have finished with the same height, the tie is broken by the number of misses at the final height. If the tied vaulters have the same number of misses at the last height cleared, the tie is broken by the total number of misses in the competition.
If there is still a tie for first place, a jump-off occurs to break the tie. Marks achieved in this type of jump-off are considered valid and count for any purpose that a mark achieved in a normal competition would.
If a tie in the other places still exists, a jump-off is not normally conducted, unless the competition is a qualifying meet, and the tie exists in the final qualifying spot. In this case, an administrative jump-off is conducted to break the tie, but the marks are not considered valid for any other purpose than breaking the tie.
A jump-off is a sudden death competition in which the tied vaulters attempt the same height, starting with the last attempted height. If both vaulters miss, the bar goes down by a small increment, and if both clear, the bar goes up by a small increment. A jump-off ends when one vaulter clears and the other misses. Each vaulter gets one attempt at each height until one makes and one misses.
The equipment and rules for pole vaulting are similar to the high jump. Unlike high jump, however, the athlete in the vault has the ability to select the horizontal position of the bar before each jump and can place it a distance beyond the back of the box, the metal pit that the pole is placed into immediately before takeoff. The range of distance the vaulter may place the standards varies depending on the level of competition.
If the pole used by the athlete dislodges the bar from the uprights, a foul attempt is ruled, even if the athlete has cleared the height. An athlete does not benefit from quickly leaving the landing pad before the bar has fallen. The exception to this rule if the vaulter is vaulting outdoors and has made a clear effort to throw the pole back, but the wind has blown the pole into the bar; this counts as a clearance. This call is made at the discretion of the pole vault official. If the pole breaks during the execution of a vault, it is considered an equipment failure and is ruled a non-jump, neither a make nor a miss. Other types of equipment failure include the standards slipping down or the wind dislodging the bar when no contact was made by the vaulter.
Each athlete has a set amount of time in which to make an attempt. The amount of time varies by level of competition and the number of vaulters remaining. If the vaulter fails to begin an attempt within this time, the vaulter is charged with a time foul and the attempt is a miss.
Poles are manufactured with ratings corresponding to the vaulter's maximum weight. Some organizations forbid vaulters to use poles rated below their weight as a safety precaution. The recommended weight corresponds to a flex rating that is determined by the manufacturer by placing a standardized amount of stress (most commonly a 50 lb weight) on the pole and measuring how much the center of the pole is displaced. Therefore, two poles rated at the same weight are not necessarily the same stiffness.
Because pole stiffness and length are important factors to a vaulter's performance, it is not uncommon for an elite vaulter to carry as many as 10 poles to a competition. The effective properties of a pole can be changed by gripping the pole higher or lower in relation to the top of the pole. The left and right handgrips are typically a bit more than shoulder width apart. Poles are manufactured for people of all skill levels and body sizes, with sizes as short as 3.05m (10 feet) to as long as 5.30 m (17 feet 4.5 inches), with a wide range of weight ratings. Each manufacturer determines the weight rating for the pole and the location of the maximum handhold band.
However speed is the most essential element to higher jumps, because the energy produced by the run (1/2 x mass x speed^2) is converted to vertical propulsion (mass x height x gravity(9.81)).
Technology.
Competitive pole vaulting began using solid ash poles. As the heights attained increased, the bamboo poles gave way to tubular aluminum, which was tapered at each end. Today's pole vaulters benefit from poles produced by wrapping pre-cut sheets of fiberglass that contains resin around a metal pole mandrel, to produce a slightly curved pole that bends more easily under the compression caused by an athlete's take-off. The shape of the fiberglass sheets and the amount of fiberglass used is carefully planned to provide the desired length and stiffness of pole. Different fiber types, including carbon-fiber, are used to give poles specific characteristics intended to promote higher jumps. In recent years, carbon fiber has been added to the commonly used E-glass and S-glass materials to create a lighter pole.
As in the high jump, the landing area was originally a heap of sawdust or sand where athletes landed on their feet. As technology enabled higher vaults, mats evolved into bags of large chunks of foam. Today's high-tech mats are foam usually thick. Mats are growing larger in area as well to minimize risk of injury. Proper landing technique is on the back or shoulders. Landing on the feet should be avoided, to eliminate the risk of injury to the lower extremities, particularly ankle sprains.
Rule changes over the years have resulted in larger landing areas and additional padding of all hard and unyielding surfaces.
The pole vault crossbar has evolved from a triangular aluminum bar to a round fiberglass bar with rubber ends. This is balanced on standards and can be knocked off when it is hit by a pole vaulter or the pole. Rule changes have led to shorter pegs and crossbar ends that are semi-circular.
Technique.
Although many techniques are used by vaulters at various skill levels to clear the bar, the generally accepted technical model can be broken down into several phases:
Approach.
During the approach the pole vaulter sprints down the runway in such a way as to achieve maximum speed and correct position to initiate takeoff at the end of the approach. Top class vaulters use approaches with 18 to 22 strides, often referred to as a "step" in which every other foot is counted as one step. The run-up to the vaulting pit begins forcefully with the vaulter running powerfully in a relaxed, upright position with knees lifted and torso leaning very slightly forward. The head, shoulders and hips are aligned, the vaulter increasing speed as the body becomes erect. The tip of the vaulting pole is angled higher than eye level until three paces from takeoff, when the pole tip descends efficiently, amplifying run speed as the pole is planted into the vault box. The faster the vaulter can run and the more efficient his/her take-off is, the greater the potential energy that can be achieved and used during the vault.
Plant and take-off.
The plant and take off is initiated typically three steps out from the final step. Vaulters will usually count their steps backwards from their starting point to the box only counting the steps taken on the left foot (vice versa for left-handers) except for the second step from the box, which is taken by the right foot. For example; a vaulter on a "ten count" (referring to the number of counted steps from the starting point to the box) would count backwards from ten, only counting the steps taken with the left foot, until the last three steps taken and both feet are counted as three, two, one. These last three steps are normally quicker than the previous strides and are referred to as the "turn-over". The goal of this phase is to efficiently translate the kinetic energy accumulated from the approach into potential energy stored by the elasticity of the pole, and to gain as much initial vertical height as possible by jumping off the ground. The plant starts with the vaulter raising his arms up from around the hips or mid-torso until they are fully outstretched above his head, with the right arm extended directly above the head and the left arm extended perpendicular to the pole (vice versa for left-handed vaulters). At the same time, the vaulter is dropping the pole tip into the box. On the final step, the vaulter jumps off the trail leg which should always remain straight and then drives the front knee forward. As the pole slides into the back of the box the pole begins to bend and the vaulter continues up and forward, leaving the trail leg angled down and behind him.
Swing up.
The swing and row simply consists of the vaulter swinging his trail leg forward and rowing the pole, bringing his top arm down to the hips, while trying to keep the trail leg straight to store more potential energy into the pole, the rowing motion also keeps the pole bent for a longer period of time for the vaulter to get into optimum position. Once in a "U" shape the left arm hugs the pole tight to efficiently use the recoil within the pole. The goal is to carry out these motions as thoroughly and as quickly as possible; it is a race against the unbending of the pole. Effectively, this causes a double pendulum motion, with the top of the pole moving forward and pivoting from the box, while the vaulter acts as a second pendulum pivoting from the right hand. This action gives the vaulter the best position possible to be "ejected" off the pole. The swing continues until the hips are above the head and the arms are pulling the pole close to the chest; from there the vaulter shoots his legs up over the cross bar while keeping the pole close.
Extension.
The extension refers to the extension of the hips upward with outstretched legs as the shoulders drive down, causing the vaulter to be positioned upside down. This position is often referred to as "inversion". While this phase is executed, the pole begins to recoil, propelling the vaulter quickly upward. The hands of the vaulter remain close to his body as they move from the shins back to the region around the hips and upper torso.
Turn.
The turn is executed immediately after or even during the end of the rockback. As the name implies, the vaulter turns 180° toward the pole while extending the arms down past the head and shoulders. Typically the vaulter will begin to angle his body toward the bar as the turn is executed, although ideally the vaulter will remain as vertical as possible. A more accurate description of this phase of the vault may be "the spin" because the vaulter spins around an imaginary axis from head to toe.
Fly-away.
This is often highly emphasized by spectators and novice vaulters, but it is arguably the easiest phase of the vault and is a result of proper execution of previous phases. This phase mainly consists of the vaulter pushing off the pole and releasing it so it falls away from the bar and mats. As his/her body goes over and around the bar, the vaulter is facing the bar. Rotation of the body over the bar occurs naturally, and the vaulter's main concern is making sure that his/her arms, face and any other appendages do not knock the bar off as he/she goes over. The vaulter should land near the middle of the foam landing mats, or pits, face up.
Six metres club.
The "six metres club" consists of pole vaulters who have reached at least 6.00. In 1985 Sergey Bubka became the first pole vaulter to clear six metres.
Five metres club.
Women have an even more exclusive club clearing 5 metres. Yelena Isinbayeva was the first to clear on July 22, 2005. It was not until March 2, 2013 when Jenn Suhr cleared indoors that a second woman joined the club. Since August 2, 2015, four women have moved within 10 cm of becoming the third member of the club.
Milestones.
This is a list of the first time a milestone height was cleared.

</doc>
<doc id="24083" url="https://en.wikipedia.org/wiki?curid=24083" title="Party of European Socialists">
Party of European Socialists

The Party of European Socialists (PES) is a social-democratic European political party. The PES comprises national-level political parties primarily from member states of the European Union (EU) and other nations of the European continent. The PES member parties are themselves mostly members of the Progressive Alliance or Socialist International. The political group in the European Parliament of the PES is the Progressive Alliance of Socialists and Democrats (S&D). The PES also operates in the Committee of the Regions (in the PES Group in the Committee of the Regions) and the European Council. The PES is currently led by Sergei Stanishev, former Prime Minister of Bulgaria.
The PES includes major parties such as the Italian Democratic Party (PD), the British Labour Party, French Socialist Party (PS), Social Democratic Party of Germany (SPD), Spanish Socialist Workers' Party (PSOE) and also has member parties in all EU states.
Name.
The party's English name is "Party of European Socialists". In addition, the following names are used in other languages:
In March 2014 following the congress in Rome, the PES added the tagline "Socialists and Democrats" to its name following the admission of the Democratic Party into the organisation.
History.
1960s.
In 1961, the Socialists in the European Parliament attempted to produce a common "European Socialist" "Programme" but were neglected due to the applications of Britain, Denmark, Ireland and Norway to join the European Communities. The Socialist's 1962 congress pushed for greater democratisation and powers for Parliament though it was only in 1969 that this possibility was examined by the member states.
1970s.
In 1973, Denmark, Ireland and the United Kingdom joined the European Community bringing in new parties from these countries. The enlarged Socialist Congress met in Bonn and inaugurated the "Confederation of the Socialist Parties of the European Community". The Congress also passed a resolution on social policy, including the right to decent work, social security, democracy and equality in the European economy. In 1978, the Confederation of Socialist Parties approved the first common European election Manifesto. It focused on several goals among which the most important were to ensure a right to decent work, fight pollution, end discrimination, protect the consumer and promote peace, human rights and civil liberties.
1980s.
The Luxembourg Congress approved the first Statue of the Confederation of Socialist Parties in 1980. The accession of Greece in 1981, followed by Spain and Portugal in 1986 brought in more parties. In 1984 another common Socialist election manifesto was approved at a congress in Luxembourg. The Manifesto proposed a socialist remedy for the economic crisis by establishing a link between industrial production, protection of the fundamental social benefits and the fight for an improved quality of life.
1990s.
In 1992, with the European Communities becoming the European Union and with the Treaty of Maastricht establishing the framework for political parties at the European Level, the Confederation was able to mobilize a majority of delegates in favour of transforming the Confederation into the "Party of European Socialists". The first programme of the party concentrated on job creation, democracy, gender equality, environmental and consumer protection, peace and security, regulation of immigration, discouragement of racism and fighting organised crime.
Along with the Socialist Group in the European Parliament, the founding members of the PES were the Social Democratic Party of Austria, the Socialist Party (Francophone) and the Socialist Party (Flemish) of Belgium, the Social Democrats of Denmark, the Socialist Party of France, the Social Democratic Party of Germany, the Panhellenic Socialist Movement of Greece, the Labour Party of Ireland, the Italian Democratic Socialist Party, Italian Socialist Party and Democratic Party of the Left of Italy, the Luxembourg Socialist Workers' Party, the Labour Party of the Netherlands, Socialist Party of Portugal, the Spanish Socialist Workers' Party, Swedish Social Democratic Party and the Labour Party and Social Democratic and Labour Party of the UK.
2000s.
In 2004 Poul Nyrup Rasmussen defeated Giuliano Amato to be elected President of the PES, succeeding Robin Cook in the post. He was re-elected for a further 2.5 years at the PES Congress in Porto on 8 December 2006 and for another 2.5 years at the Prague Congress in 2009.
In 2010, the Foundation for European Progressive Studies was founded as the political foundation of the PES.
He resigned at the PES Progressive Convention of Brussels on 24 November 2011, and was replaced by Sergei Dmitrievich Stanishev, chairman of the Bulgarian Socialist Party (BSP), elected PES Interim President, by acclamation, by the PES Presidency.
On the same day, the PES Council made the decision that the next PES candidate for Commission President would be democratically elected through a PES presidential primary taking place in January 2014.
Brussels Congress, 28–29 September 2012.
The Party of European Socialists (PES) held its latest Congress in Brussels on 28–29 September 2012. These congresses are organized every two and a half years, once during the year of the elections for the European Parliament, and once at mid-term. The latest Congress elected Sergei Stanishev as PES President, as well as four deputies: Jean-Christophe Cambadélis (1st Vice-President – PS), Elena Valenciano (PSOE), Jan Royall (Labour) and Katarina Nevedalova (Smer-SD) and prepared the 2014 European elections. The same Congress elected Achim Post (SPD) as new Secretary General.
The congress also adopted a process presented by the PES as "more democratic and transparent" for the selection of their candidate for the Presidency of the European Commission in 2014.
Presidents.
Presidents of the Party of European Socialists and its predecessors.
Organisation.
There are thirty-two full member parties from all the twenty-eight member states and Norway. There are a further eleven associate and ten observer parties. PES is an associated organisation of the Socialist International. Young European Socialists is the youth organisation of PES and "PES Women" is the party's women's organisation, led by Zita Gurmai.
The parties meet at the party "Congress" twice every five years to decide on political orientation, such as adopting manifestos ahead of elections. Every year that the Congress does not meet, the Council (a quarter Congress) shapes PES policy. The Congress also elects the party's President, Vice Presidents and the "Presidency".
The President (currently former Prime Minister of Bulgaria Sergei Stanishev) represents the party on a daily basis and chairs the Presidency, which also consists of the Secretary General, President of the S&D group in Parliament and one representative per full/associate member party and organisation. They may also be joined by the President of the European Parliament (if a PES member), a PES European Commissioner and a representative from associate parties and organisations.
The "Leader's Conference" brings together Prime Ministers and Party Leaders from PES parties three to four times a year to agree strategies and resolutions.
In December 2009, the PES decided to put forward a candidate for Commission President at all subsequent elections. On the 1st of March, 2014, the PES organised for the first time a European election Congress where a Common Manifesto was adopted and the Common Candidate designate for the post of Commission President, Martin Schulz, was elected by over a thousand participants in Rome, Italy. PES member parties across Europe joined forces to campaign for the European elections, and a mass grassroots movement sprang up in support of Martin Schulz, aiming to ‘knock the vote’ in support of his candidacy.
PES in the European institutions.
European Commission.
European Commissioners are meant to remain independent, however there has been an increasing degree of politicisation within the Commission. In the current European Commission, eight of the Commissioners belong to the PES family.
European Council.
The PES has eight out of the 28 heads of State or Government that attend the PES summits in preparation for the European Council:
European Council and Council of Ministers.
Party-alignment at the European Council is often loose, but has been the basis of some intergovernmental cooperation. At present ten countries are led by a PES-affiliated leader, who represents that state at the European Council: Austria (Werner Faymann), Croatia (Zoran Milanovic), the Czech Republic (Bohuslav Sobotka), France (François Hollande), Italy (Matteo Renzi), Lithuania (Algirdas Butkevičius), Malta (Joseph Muscat), Romania (Victor Ponta), Slovakia (Robert Fico and Sweden Stefan Löfven).
The makeup of national delegations to the Council of Ministers is at some times subject to coalitions: for the above governments led by a PES party, that party may not be present in all Council configurations; in other governments led by non-PES parties a PES minister may be its representative for certain portfolios. PES is in coalition in a further seven countries: Finland, Germany, Greece, Ireland, Luxembourg, The Netherlands and Slovenia.
Committee of the Regions.
PES has 122 members in the Committee of the Regions as of 2014.
Member parties.
It has 33 full members from 27 of the 28 EU states plus Norway, although not all of them have elected MEPs.

</doc>
<doc id="24085" url="https://en.wikipedia.org/wiki?curid=24085" title="Phenol">
Phenol

Phenol, also known as carbolic acid, is an aromatic organic compound with the molecular formula C6H5OH. It is a white crystalline solid that is volatile. The molecule consists of a phenyl group (−C6H5) bonded to a hydroxyl group (−OH). It is mildly acidic and requires careful handling due to its propensity to cause chemical burns.
Phenol was first extracted from coal tar, but today is produced on a large scale (about 7 billion kg/year) from petroleum. It is an important industrial commodity as a precursor to many materials and useful compounds. It is primarily used to synthesize plastics and related materials. Phenol and its chemical derivatives are essential for production of polycarbonates, epoxies, Bakelite, nylon, detergents, herbicides such as phenoxy herbicides, and numerous pharmaceutical drugs.
Although similar to alcohols, phenols have unique properties. Unlike alcohols, where the hydroxyl group is bound to a saturated carbon atom, phenols have the hydroxyl group attached to an unsaturated aromatic (alternating double and single bond) hydrocarbon benzene ring. Phenols have greater acidity than alcohols because of the stabilization of the conjugate base through resonance in the aromatic ring.
Properties.
Phenol is an organic compound..Phenol is appreciably soluble in water, with about 84.2 g dissolving in 1000 mL (0.88 M). Homogeneous mixtures of phenol and water at phenol to water mass ratios of ~2.6 and higher are possible. The sodium salt of phenol, sodium phenoxide, is far more water-soluble.
Acidity.
Phenol is weakly acidic and at high pHs gives the phenolate anion C6H5O− (also called phenoxide):
Compared to aliphatic alcohols, phenol is about 1 million times more acidic, although it is still considered a weak acid. It reacts completely with aqueous NaOH to lose H+, whereas most alcohols react only partially. Phenols are less acidic than carboxylic acids, and even carbonic acid.
One explanation for the increased acidity over alcohols is resonance stabilization of the phenoxide anion by the aromatic ring. In this way, the negative charge on oxygen is delocalized on to the ortho and para carbon atoms. In another explanation, increased acidity is the result of orbital overlap between the oxygen's lone pairs and the aromatic system. In a third, the dominant effect is the induction from the sp2 hybridised carbons; the comparatively more powerful inductive withdrawal of electron density that is provided by the sp2 system compared to an sp3 system allows for great stabilization of the oxyanion.
The pKa of the enol of acetone is 10.9, comparable to that for phenol. The acidities of phenol and acetone enol diverge in the gas phase owing to the effects of solvation. About of the increased acidity of phenol is attributable to inductive effects, with resonance accounting for the remaining difference.
Phenoxide anion.
The phenoxide anion has a similar nucleophilicity to free amines, with the further advantage that its conjugate acid (neutral phenol) does not become entirely deactivated as a nucleophile even in moderately acidic conditions. Phenols are sometimes used in peptide synthesis to "activate" carboxylic acids or esters to form activated esters. Phenolate esters are more stable toward hydrolysis than acid anhydrides and acyl halides but are sufficiently reactive under mild conditions to facilitate the formation of amide bonds.
Tautomerism.
Phenol exhibits keto-enol tautomerism with its unstable keto tautomer cyclohexadienone, but only a tiny fraction of phenol exists as the keto form. The equilibrium constant for enolisation is approximately 10−13, meaning that only one in every ten trillion molecules is in the keto form at any moment. The small amount of stabilisation gained by exchanging a C=C bond for a C=O bond is more than offset by the large destabilisation resulting from the loss of aromaticity. Phenol therefore exists essentially entirely in the enol form.
Phenoxides are enolates stabilised by aromaticity. Under normal circumstances, phenoxide is more reactive at the oxygen position, but the oxygen position is a "hard" nucleophile whereas the alpha-carbon positions tend to be "soft".
Reactions.
Phenol is highly reactive toward electrophilic aromatic substitution as the oxygen atom's pi electrons donate electron density into the ring. By this general approach, many groups can be appended to the ring, via halogenation, acylation, sulfonation, and other processes. However, phenol's ring is so strongly activated—second only to aniline—that bromination or chlorination of phenol leads to substitution on all carbons ortho and para to the hydroxy group, not only on one carbon. Phenol reacts with dilute nitric acid at room temperature to give a mixture of 2-nitrophenol and 4-nitrophenol while with concentrated nitric acid, more nitro groups get substituted on the ring to give 2,4,6-trinitrophenol which is known as picric acid.
Aqueous solution of phenol is weakly acidic and turns blue litmus slightly to red. Phenol is easily neutralized by sodium hydroxide forming sodium phenate or phenolate. But being weaker than carbonic acid, it cannot be neutralized by sodium bicarbonate or sodium carbonate to liberate carbon dioxide
When a mixture of phenol and benzoyl chloride are shaken in presence of dilute sodium hydroxide solution, phenyl benzoate is formed. This is an example of the Schotten-Baumann reaction:
Phenol is reduced to benzene when it is distilled with zinc dust. The same when phenol vapour is passed over granules of zinc at 400 °C:
When phenol is reacted with diazomethane in the presence of boron trifluoride (BF3), anisole is obtained as the main product and nitrogen gas
When phenol reacts with iron(III) chloride solution, an intense violet-purple solution is formed.
Production.
Because of phenol's commercial importance, many methods have been developed for its production. The dominant current route, accounting for 95% of production (2003), is the cumene process, which involves the partial oxidation of cumene (isopropylbenzene) via the Hock rearrangement:
Acetone is produced as a by-product. Compared to most other processes, the cumene process uses relatively mild synthesis conditions, and relatively inexpensive raw materials. However, to operate economically, there must be demand for both phenol, and the acetone by-product.
An early commercial route, developed by Bayer and Monsanto in the early 1900s, begins with the reaction of a strong base with benzenesulfonate:
Other methods under consideration involve:
In the Lummus Process, the oxidation of toluene to benzoic acid is conducted separately.
Phenol is also a recoverable byproduct of coal pyrolysis.
Uses.
The major uses of phenol, consuming two thirds of its production, involve its conversion to precursors for plastics. Condensation with acetone gives bisphenol-A, a key precursor to polycarbonates and epoxide resins. Condensation of phenol, alkylphenols, or diphenols with formaldehyde gives phenolic resins, a famous example of which is Bakelite. Partial hydrogenation of phenol gives cyclohexanone, a precursor to nylon. Nonionic detergents are produced by alkylation of phenol to give the alkylphenols, e.g., nonylphenol, which are then subjected to ethoxylation.
Phenol is also a versatile precursor to a large collection of drugs, most notably aspirin but also many herbicides and pharmaceutical drugs. Phenol is also used as an oral anesthetic/analgesic in products such as Chloraseptic or other brand name and generic equivalents, commonly used to temporarily treat pharyngitis.
Phenol is a component in liquid/liquid phenol–chloroform extraction technique used in molecular biology for obtaining nucleic acids from tissues or cell culture samples. Depending on the pH of the solution either DNA or RNA can be extracted.
Niche uses.
Phenol is so inexpensive that it attracts many small-scale uses. It once was widely used as an antiseptic, especially as carbolic soap, from the early 1900s to the 1970s. It is a component of industrial paint strippers used in the aviation industry for the removal of epoxy, polyurethane and other chemically resistant coatings.
Phenol derivatives are also used in the preparation of cosmetics including sunscreens, hair colorings, and skin lightening preparations.
Concentrated phenol liquids are commonly used for permanent treatment of ingrown toe and finger nails, a procedure known as a chemical matrixectomy. The procedure was first described by Otto Boll in 1945. Since that time it has become the chemical of choice for chemical matrixectomies performed by podiatrists.
Phenol spray is used medically to help sore throat.
History.
Phenol was discovered in 1834 by Friedlieb Ferdinand Runge, who extracted it (in impure form) from coal tar. Runge called phenol "Karbolsäure" (coal-oil-acid, carbolic acid). Coal tar remained the primary source until the development of the petrochemical industry. In 1841, the French chemist Auguste Laurent obtained phenol in pure form.
In 1836, Auguste Laurent coined the name "phène" for benzene; this is the root of the word "phenol" and "phenyl". In 1843, French chemist Charles Gerhardt coined the name "phénol".
The antiseptic properties of phenol were used by Sir Joseph Lister (1827–1912) in his pioneering technique of antiseptic surgery. Lister decided that the wounds themselves had to be thoroughly cleaned. He then covered the wounds with a piece of rag or lint covered in phenol, or carbolic acid as he called it. The skin irritation caused by continual exposure to phenol eventually led to the substitution of aseptic (germ-free) techniques in surgery.
Phenol is the active ingredient in some oral analgesics such as Chloraseptic spray and Carmex.
Phenol was the main ingredient of the Carbolic Smoke Ball, an ineffective device marketed in London in the 19th century as protection against influenza and other ailments, and the subject of the famous law case Carlill v Carbolic Smoke Ball Company.
Second World War.
The toxic effect of phenol on the central nervous system, discussed below, causes sudden collapse and loss of consciousness in both humans and animals; a state of cramping precedes these symptoms because of the motor activity controlled by the central nervous system. Injections of phenol were used as a means of individual execution by the Nazis during the Second World War. It was originally used by the Nazis in 1939 as part of Action T4. Although Zyklon-B pellets were used in the gas chambers to exterminate large groups of people, the Nazis learned that extermination of smaller groups was more economical by injection of each victim with phenol. Phenol injections were given to thousands of people, especially at Auschwitz-Birkenau. Approximately one gram is sufficient to cause death. One of the best known inmates to be executed with a phenol injection in Auschwitz was St. Maximilian Kolbe, a Polish Catholic priest who volunteered to undergo two weeks of starvation and dehydration in the place of another inmate.
Natural occurrences.
Phenol is a normal metabolic product, excreted in quantities up to 40 mg/L in human urine.
The temporal gland secretion of male elephants showed the presence of phenol and 4-methylphenol during musth.
It is also one of the chemical compounds found in castoreum. This compound is gathered from the plants the beaver eats.
Occurrence in whisky.
Phenol is a measurable component in the aroma and taste of the distinctive Islay scotch whisky, generally ~30 ppm, but it can be over 160ppm in the malted barley used to produce whisky. This amount is different and presumably higher than the amount in the distillate.
Biodegradation.
"Cryptanaerobacter phenolicus" is a bacterium species that produces benzoate from phenol via 4-hydroxybenzoate. "Rhodococcus phenolicus" is a bacterium species able to degrade phenol as sole carbon sources.
Toxicity.
Phenol and its vapors are corrosive to the eyes, the skin, and the respiratory tract. Its corrosive effect on skin and mucous membranes is due to a protein-degenerating effect. Repeated or prolonged skin contact with phenol may cause dermatitis, or even second and third-degree burns. Inhalation of phenol vapor may cause lung edema. The substance may cause harmful effects on the central nervous system and heart, resulting in dysrhythmia, seizures, and coma. The kidneys may be affected as well. Long-term or repeated exposure of the substance may have harmful effects on the liver and kidneys. There is no evidence that phenol causes cancer in humans. Besides its hydrophobic effects, another mechanism for the toxicity of phenol may be the formation of phenoxyl radicals.
Since phenol is absorbed through the skin relatively quickly, systemic poisoning can occur in addition to the local caustic burns. Resorptive poisoning by a large quantity of phenol can occur even with only a small area of skin, rapidly leading to paralysis of the central nervous system and a severe drop in body temperature. The for oral toxicity is 300–500 mg/kg for dogs, rabbits, or mice; the minimum lethal human dose was cited as 140 mg/kg. The Agency for Toxic Substances and Disease Registry (ATSDR), U.S. Department of Health and Human Services states the fatal dose for ingestion of phenol is from 1 to 32 g.
Chemical burns from skin exposures can be decontaminated by washing with polyethylene glycol, isopropyl alcohol, or perhaps even copious amounts of water. Removal of contaminated clothing is required, as well as immediate hospital treatment for large splashes. This is particularly important if the phenol is mixed with chloroform (a commonly-used mixture in molecular biology for DNA and RNA purification). Phenol is also a reproductive toxin causing increased risk of abortion and low birth weight indicating retarded development in utero.
Phenols.
The word "phenol" is also used to refer to any compound that contains a six-membered aromatic ring, bonded directly to a hydroxyl group (-OH). Thus, phenols are a class of organic compounds of which the phenol discussed in this article is the simplest member.

</doc>
<doc id="24086" url="https://en.wikipedia.org/wiki?curid=24086" title="Protagoras">
Protagoras

Protagoras (; ; c. 490 – c. 420 BC) was a pre-Socratic Greek philosopher and is numbered as one of the sophists by Plato. In his dialogue, "Protagoras", Plato credits him with having invented the role of the professional sophist.
He also is believed to have created a major controversy during ancient times through his statement that, "Man is the measure of all things", interpreted by Plato to mean that there is no absolute truth, but that which individuals deem to be the truth. Although there is reason to question the extent of the interpretation of his arguments that has followed, that concept of individual relativity was revolutionary for the time, and contrasted with other philosophical doctrines that claimed the universe was based on something objective, outside of human influence or perceptions.
Background.
Protagoras was born in Abdera, Thrace, in Ancient Greece. According to Aulus Gellius, he originally made his living as a porter, but one day he was seen by the philosopher Democritus carrying a load of small pieces of wood he had tied with a short cord. Democritus realized that Protagoras had tied the load together with such perfect geometric accuracy that he must be a mathematical prodigy. Democritus promptly took him into his own household and taught him philosophy. Protagoras became well known in Athens and even became a friend of Pericles.
The dates of his lifetime are not recorded, but extrapolated from writings that have survived the ages. In "Protagoras" Plato wrote that, before a gathering of Socrates, Prodicus, and Hippias, Protagoras stated that he was old enough to be the father of any of them. This suggests a birth date of not later than 490 BC. In the "Meno" he is said to have died at approximately the age of 70, after 40 years as a practicing Sophist. His death, then, may be presumed to have occurred circa 420 BC, but is not known for certain, since assumptions about it are based on an apparently fake story about his trial for impiety in Athens.
Plutarch wrote that Pericles and Protagoras spent a whole day discussing an interesting point of legal responsibility, that probably involved a more philosophical question of causation: "In an athletic contest a man had been accidentally hit and killed with a javelin. Was his death to be attributed to the javelin, to the man who threw it, or to the authorities responsible for the conduct of the games?"
Philosophy.
Despite being mentored by Democritus, Protagoras did not share his enthusiasm for the pursuit of mathematics. "For perceptible lines are not the kind of things the geometer talks about, since no perceptible thing is straight or curved in that way, nor is a circle tangent to a ruler at a point, but the way Protagoras used to say in refuting the geometers" (Aristotles, Metaphysics 997b34-998a4). Protagoras was skeptical about the application of theoretical mathematics to the natural world; he did not believe they were really worth studying at all. According to Philodemus, Protagoras said that "The subject matter is unknowable and the terminology distasteful". Nonetheless, mathematics was considered to be by some a very viable form of art, and Protagoras says on the arts, "art ("tekhnê") without practice and practice without art are nothing" (Stobaeus, "Selections" 3.29.80).
Protagoras also was known as a teacher who addressed subjects connected to virtue and political life. He especially was involved in the question of whether virtue could be taught, a commonplace issue of fifth century BC Greece, that has been related to modern readers through Plato's dialogue. Rather than educators who offered specific, practical training in rhetoric or public speaking, Protagoras attempted to formulate a reasoned understanding, on a very general level, of a wide range of human phenomena, including language and education. In Plato's "Protagoras", he claims to teach "the proper management of one's own affairs, how best to run one's household, and the management of public affairs, how to make the most effective contribution to the affairs of the city by word and action".
He also seems to have had an interest in "orthoepeia"—the correct use of words—although this topic is more strongly associated with his fellow sophist Prodicus. In his eponymous Platonic dialogue, Protagoras interprets a poem by Simonides, focusing on the use of words, their literal meaning, and the author's original intent. This type of education would have been useful for the interpretation of laws and other written documents in the Athenian courts. Diogenes Laërtius reports that Protagoras devised a taxonomy of speech acts such as assertion, question, answer, command, etc. Aristotle also says that Protagoras worked on the classification and proper use of grammatical gender.
The titles of his books such as, "Technique of Eristics" ("Technē Eristikōn", literally "Practice of Wranglings", with wrestling used as a metaphor for intellectual debate) prove that Protagoras also was a teacher of rhetoric and argumentation. Diogenes Laërtius states that he was one of the first to take part in rhetorical contests in the Olympic games.
Relativism.
Protagoras also said that on any matter, there are two arguments ("logoi") opposed to one another, and according to Aristotle, Protagoras was criticized for having claimed "to make the weaker argument stronger ("ton hēttō logon kreittō poiein")".
Protagoras is credited with the philosophy of relativism, which he discusses in his work, "Truth" (also known as "Refutations"). Although knowledge of his work is limited, discussion of Protagoras' relativism is based on one of his most famous statements: "Man is the measure of all things: of the things that are, that they are, of the things that are not, that they are not." By this, Protagoras meant that each individual is the measure of how things are perceived by that individual. Therefore, things are, or are not, true according to how the individual perceives them. For example, Person X may believe that the weather is cold, whereas Person Y may believe that the weather is hot. According to the philosophy of Protagoras, there is no absolute evaluation of the nature of a temperature because the evaluation will be relative to who is perceiving it. Therefore, to Person X, the weather is cold, whereas to Person Y, the weather is hot. This philosophy implies that there are no absolute "truths". The truth, according to Protagoras, is relative, and differs according to each individual.
As with many fragments of the pre-Socratic philosophers, this phrase has been passed down through the ages, without any context, and consequently, its meaning is open to interpretation. His use of the word χρήματα ("chrēmata", "things used") instead of the general word ὄντα ("onta", "entities") signifies, however, that Protagoras was referring to things that are used by, or in some way, related to, humans, such as properties, social entities, ideas, feelings, judgments, which originate in the human mind. Protagoras did not suggest that humans must be the measure of the motion of the stars, the growing of plants, or the activity of volcanoes.
As many modern thinkers will, Plato ascribes relativism to Protagoras and uses his predecessor's teachings as a foil for his own commitment to objective and transcendent realities and values. Plato ascribes to Protagoras an early form of what today, John Wild would label, phenomenalism. That being an assertion that something that is, or appears for a single individual, is true or real for that individual.
However, as described in Plato's "Theaetetus", Protagoras's views allow that some views may result from an ill body or mind. He stressed that although all views may appear equally true, and perhaps, should be equally respected, they certainly are not of equal gravity. One view may be useful and advantageous to the person who has it, while the perception of another may prove harmful. Hence, Protagoras believed that the sophist was there to teach the student how to discriminate between them, i.e., to teach "virtue".
Both Plato and Aristotle argue against some of Protagoras's claims regarding relativity; however, they argue that the concept provides Protagoras with too convenient an exemption from his own theory and that relativism is true for him yet false for those who do not believe it. They claim that by asserting that truth is relative, Protagoras then could say that whatever further theory he proposed "must" be true.
Because knowledge of most of his work is limited or missing, modern attempts to apply the Protagoras theory of relativism tend to result in disagreement and refer to scientific reasoning. Carol Poster states that with a modern preference toward scientific reasoning and objective truth, for example, rather than considering individuals evaluating their sense of comfort, a modern philosopher would look at a modern instrument, the thermometer, objectively to see the scientific measure of the temperature, whereas the Greek method would entail looking at larger philosophical implications.
Agnosticism.
Protagoras also was a proponent of agnosticism. Reportedly, in his lost work, "On the Gods", he wrote: "Concerning the gods, I have no means of knowing whether they exist or not, nor of what sort they may be, because of the obscurity of the subject, and the brevity of human life". According to Diogenes Laërtius, the outspoken, agnostic position taken by Protagoras aroused anger, causing the Athenians to expel him from the city, and all copies of his book were collected and burned in the marketplace. The deliberate destruction of his works also is mentioned by Cicero.
The classicist John Burnet doubts this account, however, as both Diogenes Laërtius and Cicero wrote hundreds of years later and as no such persecution of Protagoras is mentioned by contemporaries who make extensive references to this philosopher. Burnet notes that even if some copies of the Protagoras books were burned, enough of them survived to be known and discussed in the following century.
Spectrum of topics.
Nonetheless, very few fragments from Protagoras have survived, although he is known to have written several different works: "Antilogiae" and "Truth". The latter is cited by Plato, and was known alternatively as, "The Throws" (a wrestling term referring to the attempt to floor an opponent). It began with the "Man is the measure" (ἄνθρωπος μέτρον) pronouncement. According to Diogenes Laërtius other books by Protagoras include: "On the Gods", "Art of Eristics", "Imperative", "On Ambition", "On Incorrect Human Actions", "On those in Hades", "On Sciences", "On Virtues", "On the Original State of Things" and "Trial over a Fee".

</doc>
<doc id="24091" url="https://en.wikipedia.org/wiki?curid=24091" title="Puritans">
Puritans

The Puritans were a group of English Reformed Protestants in the 16th and 17th centuries who sought to "purify" the Church of England from all Roman Catholic practices, maintaining that the Church of England was only partially reformed. Puritanism in this sense was founded by some of the returning clergy exiled under Mary I shortly after the accession of Elizabeth I of England in 1558 as an activist movement within the Church of England.
Overview.
Puritanism played a major role in English history during the first half of the 17th century, but is still a matter of debate. The English Civil War was first defined as a "Puritan Revolution" by Samuel Rawson Gardiner in the 19th century. Anti-Catholic feeling was stoked by John Pym, a significant and alarmist politician at the time of the Grand Remonstrance of 1641; but revisionist historians such as Kevin Sharpe have cast doubt on the simple outlines of this description.
Puritans were blocked from changing the established church from within and were severely restricted in England by laws controlling the practice of religion. Their beliefs, however, were transported by the emigration of congregations to the Netherlands (and later to New England in North America) and by evangelical clergy to Ireland (and later to Wales), and were spread into lay society and parts of the educational system, particularly certain colleges of the University of Cambridge. They took on distinctive beliefs about clerical dress and in opposition to the episcopal system, particularly after the 1619 conclusions of the Synod of Dort were resisted by the English bishops. They largely adopted Sabbatarianism in the 17th century, and were influenced by millennialism.
The Puritans were in alliance with the growing commercial world, with the parliamentary opposition to the royal prerogative, and with the Scottish Presbyterians in the late 1630s with whom they had much in common. Consequently, they became a major political force in England and came to power as a result of the First English Civil War (1642–46). Almost all Puritan clergy left the Church of England after the Restoration of 1660 and the 1662 Uniformity Act, some becoming nonconformist ministers. The nature of the movement in England changed radically, although it retained its character for a much longer period in New England.
Puritans by definition were dissatisfied with the limited extent of the English Reformation and with the Church of England's tolerance of practices which they associated with the Catholic Church. They formed and identified with various religious groups advocating greater purity of worship and doctrine, as well as personal and group piety. Puritans adopted a Reformed theology and, in that sense, were Calvinists (as were many of their earlier opponents), but they also took note of radical criticisms of Zwingli in Zurich and Calvin in Geneva. In church polity, some advocated separation from all other established Christian denominations in favor of autonomous gathered churches. These separatist and independent strands of Puritanism became prominent in the 1640s, when the supporters of a Presbyterian polity in the Westminster Assembly were unable to forge a new English national church.
The Puritans were never a formally defined sect or religious division within Protestantism, and the term "Puritan" itself was rarely used to describe people after the turn of the 18th century. Some Puritan ideals became incorporated into the Church of England, such as the formal rejection of Roman Catholicism; some fell out of favor, such as the beliefs in demonic possession; some were absorbed into the many Protestant sects that emerged in the late 17th and early 18th centuries in the Americas and Britain. The Congregationalist tradition, widely considered to be a part of the Reformed tradition, claims descent from the Puritans.
Terminology.
Historically, the word "Puritan" was considered a pejorative term that characterized Protestant groups as extremists, similar to the Cathars of France. According to Thomas Fuller, writing in his "Church History", the term dates to 1564. Archbishop Matthew Parker of that time used it and "precisian" with the sense of the modern "stickler". In modern times, the word "puritan" is often used to mean "against pleasure".
The "Puritan" movement referred to the desire and goal of purifying the Church of England and Roman Catholic Church from within, in contrast to the "Separatists" who believed that the established churches could not be reformed and the only hope was to set up separate churches. In this sense, the term "Puritan" was coined in the 1560s, when it first appeared as a term of abuse for those who found the Elizabethan Religious Settlement of 1559 inadequate. The term Puritan was therefore not intended to refer to strict morality, a common misinterpretation, but to a reforming attitude towards established churches.
The Godly.
The word "Puritan" was applied unevenly to a number of Protestant churches (and religious groups within the Anglican Church) from the late 16th century onwards. Puritans did not originally use the term for themselves. The practitioners knew themselves as members of particular churches or movements, and not by a single term. "Precisemen" and "Precisians" were other early derogatory terms for Puritans, who preferred to call themselves "the godly". 17th century English Puritan preacher Thomas Watson used "the godly" to describe Puritans in the title of one of his more famous works "The Godly Man's Picture".
Puritans and Separatists.
Some Puritans are known as "non-separating Puritans": those who were not satisfied with the Reformation of the Church of England but who remained within it, advocating further reforms. This group disagreed among themselves about how much further reformation was possible or even necessary. Some thought that the Church of England was so corrupt that true Christians should separate from it altogether; they are known as "separating Puritans" or simply "Separatists". The term "Puritan" in the wider sense includes both groups. Separatists had no particular Church title. Many of the "Mayflower" Pilgrims were referred to only as Separatists.
John Winthrop and the other main leaders of emigration to New England in 1629 were non-separating Puritans. However, John Robinson and William Brewster, the Pilgrims' Plymouth Colony leaders, were separatists. There is no current consensus among historians whether Separatists can properly be counted as Puritans.
Separating Puritans were called "Dissenters," especially after the English Restoration of 1660. The 1662 Uniformity Act caused almost all Puritan clergy to leave the Church of England, the so-called Great Ejection or Black Bartholomew's Day, see below. Some of these 2000 "ejected" clergymen became nonconformist ministers (later Congregationalists, Baptists, Unitarians, Presbyterians, etc.). The movement in England changed radically at this time, though this change was not as immediate across the Atlantic (see History of the Puritans in North America).
Puritans and killjoys.
In modern usage, the word "puritan" is often used to describe someone who adheres to strict, joyless moral or religious principles. In this usage, Hedonism and puritanism are antonyms. In fact, Puritans embraced sexuality but placed it in the context of marriage. Peter Gay writes of the Puritans' standard reputation for "dour prudery" as a "misreading that went unquestioned in the nineteenth century", commenting how unpuritanical they were in favour of married sexuality, and in opposition to the Catholic veneration of virginity, citing Edward Taylor and John Cotton. One Puritan settlement in Western Massachusetts banished a husband and sent him into exile because he refused to fulfill his marital duties to his wife.
Summary history.
Puritanism has a historical importance over a period of a century, followed by 50 years of development in New England. It changed character and emphasis almost decade-by-decade over that time.
Elizabethan Puritanism.
Elizabethan Puritanism contended with the Elizabethan religious settlement, with little to show for it. The Lambeth Articles of 1595, a high-water mark for Calvinism within the Church of England, failed to receive royal approval.
Jacobean Puritanism.
The accession of James I brought the Millenary Petition, a Puritan manifesto of 1603 for reform of the English church, but James wanted a new religious settlement along different lines. He called the Hampton Court Conference in 1604, and heard the teachings of four prominent Puritan leaders there, including Laurence Chaderton, but largely sided with his bishops. He was well informed on theological matters by his education and Scottish upbringing, and he dealt shortly with the peevish legacy of Elizabethan Puritanism, pursuing an eirenic religious policy, in which he was arbiter.
Many of his episcopal appointments were Calvinists, notably James Montague, who was an influential courtier. Puritans still opposed much of the Catholic summation in the Church of England, notably the "Book of Common Prayer", but also the use of non-secular vestments (cap and gown) during services, the sign of the Cross in baptism, and kneeling to receive Holy Communion. The Puritan movement was subjected to repression by some of the bishops under both Elizabeth and James, though other bishops were more tolerant and, in many places, individual ministers were able to omit disliked portions of the "Book of Common Prayer".
The Puritan movement of Jacobean times became distinctive by adaptation and compromise, with the emergence of "semi-separatism," "moderate puritanism," the writings of William Bradshaw, who adopted the term "Puritan" as self-identification, and the beginnings of congregationalism. Most Puritans of this period were non-separating and remained within the Church of England, and Separatists who left the Church of England altogether were numerically much fewer.
Fragmentation and political failure.
The Puritan movement in England was riven over decades by emigration and inconsistent interpretations of Scripture, as well as some political differences that surfaced at that time.
The Westminster Assembly was called in 1643, assembling clergy of the Church of England. The Assembly was able to agree to the Westminster Confession of Faith doctrinally, a consistent Reformed theological position. The "Directory of Public Worship" was made official in 1645, and the larger framework (now called the Westminster Standards) was adopted by the Church of Scotland. In England, the Standards were contested by Independents up to 1660.
The Westminster Divines, on the other hand, were divided over questions of church polity and split into factions supporting a reformed episcopacy, presbyterianism, congregationalism, and Erastianism. The membership of the Assembly was heavily weighted towards the Presbyterians, but Oliver Cromwell was a Congregationalist separatist who imposed his doctrines upon them. The Church of England of the Interregnum was run along Presbyterian lines but never became a national Presbyterian church, such as existed in Scotland, and England was not the theocratic state which leading Puritans had called for as "godly rule".
Great Ejection and Dissenters.
At the time of the English Restoration in 1660, the Savoy Conference was called to determine a new religious settlement for England and Wales. Under the Act of Uniformity 1662, the Church of England was restored to its pre-Civil War constitution with only minor changes, and the Puritans found themselves sidelined. A traditional estimate of historian Calamy is that around 2,400 Puritan clergy left the Church in the "Great Ejection" of 1662. At this point, the term "Dissenter" came to include "Puritan," but more accurately described those (clergy or lay) who "dissented" from the "1662 Book of Common Prayer".
The Dissenters divided themselves from all Christians in the Church of England and established their own separatist congregations in the 1660s and 1670s. An estimated 1,800 of the ejected clergy continued in some fashion as ministers of religion, according to Richard Baxter. The government initially attempted to suppress these schismatic organisations by the Clarendon Code. There followed a period in which schemes of "comprehension" were proposed, under which Presbyterians could be brought back into the Church of England, but nothing resulted from them. The Whigs opposed the court religious policies and argued that the Dissenters should be allowed to worship separately from the established Church, and this position ultimately prevailed when the Toleration Act was passed in the wake of the Glorious Revolution in 1689. This permitted the licensing of Dissenting ministers and the building of chapels. The term "Nonconformist" generally replaced the term "Dissenter" from the middle of the 18th century.
Beliefs.
The idea of personal Biblical interpretation through the Holy Spirit was central to Puritan beliefs, though it was shared with most Protestants in general at that time. Puritans sought both individual and corporate conformity to the teaching of the Bible, with moral purity pursued down to the smallest detail, as well as ecclesiastical purity to the highest level. They believed that man existed for the glory of God, that his first concern in life was to do God's will and so to receive future happiness. They believed that Jesus Christ was the center of public and personal affairs, and was to be exalted above all other names.
Diversity.
Various strands of Calvinistic theology in the 17th century were taken up by different parts of the Puritan movement and, in particular, Amyraldism was adopted by some influential figures, including John Davenant, Samuel Ward and, to some extent, Richard Baxter. In the same fashion, there is no theory of church polity that is uniquely Puritan, and ideology differed beyond opposition to Erastianism (state control), though even that had its small group of supporters in the Westminster Assembly. Some approved of the existing church hierarchy with bishops, but others sought to reform the Episcopal churches on the Presbyterian model. Some Separatist Puritans were Presbyterian, but most were early Congregationalists. The separating Congregationalists believed that the Divine Right of Kings was heresy but, on the other hand, there were many royalist Presbyterians, in terms of allegiance in the political struggle.
Migration also brought out differences and brought together Puritan communities with their own regional customs and beliefs. The New World Puritans' policies of church governance diverged from those remaining in the British Isles, who faced different issues.
Demonology.
Puritans believed in the active existence of demonic forces, as did almost all Christians of this period. Puritan pastors undertook exorcisms for demonic possession in some high-profile cases, and believed in some allegations of witchcraft. Exorcist John Darrell was supported by Arthur Hildersham in the case of Thomas Darling. Samuel Harsnett, a skeptic on witchcraft and possession, attacked Darrell. However, Harsnett was in the minority, and many clergy, not only Puritans, believed in witchcraft and possession. The possession case of Richard Dugdale was taken up by ejected nonconformist Thomas Jollie and other local ministers in 1689.
The context of the Salem witch trials of 1692–1693 shows the intricacy of trying to place "Puritan" beliefs as distinctive. The publication of "Saducismus Triumphatus", an anti-skeptical tract that has been implicated in the moral panic at Salem, involved Joseph Glanvill (a latitudinarian) and Henry More (a Cambridge Platonist) as editors, and Anthony Horneck, an evangelical German Anglican, as translator of a pamphlet about a Swedish witch hunt. None of these was a Puritan. Glanvill and More had been vehemently opposed in the 1670s by skeptic John Webster, an Independent and sometime chaplain to the Parliamentary forces.
Millennialism.
Puritan millennialism has been placed in the broader context of European Reformed beliefs about the millennium and interpretation of Biblical prophecy, for which representative figures of the period were Johannes Piscator, Thomas Brightman, Joseph Mede, Johannes Heinrich Alsted, and John Amos Comenius. Both Brightman and Mede were Puritan by conviction, and so are identified as such by their biographers, though neither clashed with the church authorities. David Brady describes a "lull before the storm" in the early 17th century, in which "reasonably restrained and systematic" Protestant exegesis of the Book of Revelation was seen with Brightman, Mede, and Hugh Broughton, after which "apocalyptic literature became too easily debased" as it became more populist and less scholarly.
William Lamont argues that, within the church, the Elizabethan millennial beliefs of John Foxe became sidelined, with Puritans adopting instead the "centrifugal" doctrines of Thomas Brightman, while the Laudians replaced the "centripetal" attitude of Foxe to the "Christian Emperor" by the national and episcopal Church closer to home, with its royal head, as leading the Protestant world "iure divino" (by divine right). Viggo Norskov Olsen writes that Mede "broke fully away from the Augustinian-Foxian tradition, and is the link between Brightman and the premillennialism of the 17th century".
The dam broke in 1641 when the traditional retrospective reverence for Thomas Cranmer and other martyred bishops in the "Acts and Monuments" was displaced by forward-looking attitudes to prophecy among radical Puritans.
Cultural consequences.
Some strong religious beliefs common to Puritans had direct impacts on culture. Education was essential to the masses so that they could read the Bible for themselves.
The opposition to acting as public performance, typified by William Prynne's book Histriomastix, was not a concern with drama as a form. John Milton wrote "Samson Agonistes" as verse drama, and had contemplated writing "Paradise Lost" in that form at an early stage. N.H. Keeble writes:
But the sexualization of Restoration theatre was attacked as strongly as ever by Thomas Gouge, as Keeble points out. Puritans eliminated the use of musical instruments in their religious services for theological and practical reasons. The only music remaining in church services was the setting of the psalms. Church organs were commonly damaged or destroyed in the Civil War period, such as when an axe was taken to the organ of Worcester Cathedral in 1642.
Family life.
Based on Biblical portrayals of Adam and Eve, Puritans believed that marriage was rooted in procreation, love, and, most importantly, salvation. Husbands were the spiritual heads of the household, while women were to demonstrate religious piety and obedience under male authority. Furthermore, marriage represented not only the relationship between husband and wife, but also the relationship between spouses and God. Puritan husbands commanded authority through family direction and prayer. The female relationship to her husband and to God was marked by submissiveness and humility.
Thomas Gataker describes Puritan marriage as:
The paradox created by female inferiority in the public sphere and the spiritual equality of men and women in marriage, then, gave way to the informal authority of women concerning matters of the home and childrearing. With the consent of their husbands, wives made important decisions concerning the labour of their children, property, and the management of inns and taverns owned by their husbands. Pious Puritan mothers laboured for their children's righteousness and salvation, connecting women directly to matters of religion and morality. In her poem titled "In Reference to her Children," poet Anne Bradstreet reflects on her role as a mother:
Bradstreet alludes to the temporality of motherhood by comparing her children to a flock of birds on the precipice of leaving home. While Puritans praised the obedience of young children, they also believed that, by separating children from their mothers at adolescence, children could better sustain a superior relationship with God. A child could only be redeemed through religious education and obedience. Girls carried the additional burden of Eve's corruption and were catechised separately from boys at adolescence. Boys' education prepared them for vocations and leadership roles, while girls were educated for domestic and religious purposes. The pinnacle of achievement for children in Puritan society, however, occurred with the conversion process.
Puritans viewed the relationship between master and servant similarly to that of parent and child. Just as parents were expected to uphold Puritan religious values in the home, masters assumed the parental responsibility of housing and educating young servants. Older servants also dwelt with masters and were cared for in the event of illness or injury. African-American and Indian servants were likely excluded from such benefits.
New England Puritans.
Puritans left for New England, particularly in the years after 1630, supporting the founding of the Massachusetts Bay Colony and other settlements. The large-scale Puritan emigration to New England ceased by 1641, with around 21,000 having moved across the Atlantic. This English-speaking population in America did not all consist of original colonists, since many returned to England shortly after arriving on the continent, but it produced more than 16 million descendants. This so-called "Great Migration" is not so named because of sheer numbers, which were much less than the number of English citizens who emigrated to Virginia and the Caribbean during this time. The rapid growth of the New England colonies (around 700,000 by 1790) was almost entirely due to the high birth rate and lower death rate per year.
Puritan hegemony lasted for at least a century. That century can be broken down into three parts: the generation of John Cotton and Richard Mather, 1630–1661 from the founding to the Restoration, years of virtual independence and nearly autonomous development; the generation of Increase Mather, 1662–1689 from the Restoration and the Halfway Covenant to the Glorious Revolution, years of struggle with the British crown; and the generation of Cotton Mather, 1689–1728 from the overthrow of Edmund Andros (in which Cotton Mather played a part) and the new charter, mediated by Increase Mather, to the death of Cotton Mather.
Education.
In the area of education, New England differed from its mother country, where nothing in English statute required schoolmasters or the literacy of children. The Puritan model of education in New England was unique, with the possible exception of Scotland. John Winthrop claimed in 1630 that the society which they would form in New England would be "as a city upon a hill," and the colony leaders would educate all. These were men of letters. They had attended Oxford or Cambridge and communicated with intellectuals all over Europe. In 1636, they founded the school that soon became Harvard College.
Besides the Bible, children needed to read to "understand ... the capital laws of this country," as the Massachusetts code declared, order being of the utmost importance, and children not taught to read would grow "barbarous" (the 1648 amendment to the Massachusetts law and the 1650 Connecticut code both used the word "barbarisme"). By the 1670s, all New England colonies except Rhode Island had passed legislation that mandated literacy for children. In 1647, Massachusetts passed a law that required towns to hire a schoolmaster to teach writing.
Forms of schooling ranged from dame schools to "Latin" schools for boys already literate in English and ready to master preparatory grammar for Latin, Hebrew, and Greek. Reading schools were often the single source of education for girls, whereas boys would go to the town grammar schools. Gender largely determined educational practices; women introduced all children to reading, and men taught boys in higher pursuits. Latin grammar schools did not accept girls (nor did Harvard), since grammar schools were designed to "instruct youth so far as they may be fited for the university," and girls could play no role in the ministry. Most evidence suggests that girls could not attend the less ambitious town schools, the lower-tier writing-reading schools mandated for townships of over 50 families.
Restrictions and pleasures.
The Plymouth Colony Puritans of New England disapproved of Christmas celebrations, as did some other Protestant churches of the time. Celebration was outlawed in Boston from 1659. The ban was revoked in 1681 by the English-appointed governor Edmund Andros, who also revoked a Puritan ban on festivities on Saturday nights. Nevertheless, it was not until the mid-19th century that celebrating Christmas became fashionable in the Boston region. Likewise, the colonies banned many secular entertainments on moral grounds, such as games of chance, maypoles, and drama.
They were not, however, opposed to drinking alcohol in moderation. Early New England laws banning the sale of alcohol to Native Americans were criticised because it was "not fit to deprive Indians of any lawfull comfort aloweth to all men by the use of wine." Laws banned the practice of individuals toasting each other, with the explanation that it led to wasting God's gift of beer and wine, as well as being carnal. Bounds were not set on enjoying sexuality within the bounds of marriage, as a gift from God. In fact, spouses were disciplined if they did not perform their sexual marital duties, in accordance with 1 Corinthians 7 and other biblical passages. Women and men were equally expected to fulfill marital responsibilities. Women and men could file for divorce based on this issue alone. In Massachusetts colony, which had some of the most liberal colonial divorce laws, one out of every six divorce petitions was filed on the basis on male impotence. An issue which held significant cultural ramifications, Puritans publicly punished drunkenness and sexual relations outside marriage.
Opposition to other religious views.
The Puritans exhibited intolerance to other religious views, including Quaker, Anglican and Baptist theologies. The Puritans of the Massachusetts Bay Colony were the most active of the New England persecutors of Quakers, and the persecuting spirit was shared by the Plymouth Colony and the colonies along the Connecticut river.
In 1660, one of the most notable victims of the religious intolerance was English Quaker Mary Dyer, who was hanged in Boston for repeatedly defying a Puritan law banning Quakers from the colony. She was one of the four executed Quakers known as the Boston martyrs. The hanging of Dyer on Boston Common marked the beginning of the end of the Puritan theocracy. In 1661, King Charles II explicitly forbade Massachusetts from executing anyone for professing Quakerism. In 1684, England revoked the Massachusetts charter, sent over a royal governor to enforce English laws in 1686 and, in 1689, passed a broad Toleration Act.
The first two of the four Boston martyrs were executed by the Puritans on October 27, 1659, and in memory of this, October 27 is now International Religious Freedom Day to recognize the importance of freedom of religion. Anti-Catholic sentiment appeared in New England with the first Pilgrim and Puritan settlers. In 1647, Massachusetts passed a law prohibiting any Jesuit Roman Catholic priests from entering territory under Puritan jurisdiction. Any suspected person who could not clear himself was to be banished from the colony; a second offense carried a death penalty.
The Puritan spirit in the United States.
Alexis de Tocqueville suggested in "Democracy in America" that Puritanism was the very thing that provided a firm foundation for American democracy. As Sheldon Wolin puts it, "Tocqueville was aware of the harshness and bigotry of the early colonists". However, on the other hand, he saw them as "archaic survivals, not only in their piety and discipline but in their democratic practices". The theme of a religious basis of economic discipline is echoed in sociologist Max Weber's work, but both de Tocqueville and Weber argued that this discipline was not a force of economic determinism, but one factor among many that should be considered when evaluating the relative economic success of the Puritans.
Historiography.
The literature on Puritans, particularly biographical literature on individual Puritan ministers, was already voluminous in the 17th century and, indeed, the interests of Puritans in the narratives of early life and conversions made the recording of the internal lives important to them. The historical literature on Puritans is, however, quite problematic and subject to controversies over interpretation. The early writings are those of the defeated, excluded and victims. The great interest of authors of the 19th century in Puritan figures was routinely accused in the 20th century of consisting of anachronism and the reading back of contemporary concerns.
A debate continues on the definition of "Puritanism". English historian Patrick Collinson believes that "Puritanism had no content beyond what was attributed to it by its opponents." The analysis of "mainstream Puritanism" in terms of the evolution from it of Separatist and antinomian groups that did not flourish, and others that continue to this day, such as Baptists and Quakers, can suffer in this way. The national context (England and Wales, as well as the kingdoms of Scotland and Ireland) frames the definition of Puritans, but was not a self-identification for those Protestants who saw the progress of the Thirty Years' War from 1620 as directly bearing on their denomination, and as a continuation of the religious wars of the previous century, carried on by the English Civil Wars. English historian Christopher Hill, who has contributed Marxist analyses of Puritan concerns that are more respected than accepted, writes of the 1630s, old church lands, and the accusations that William Laud was a crypto-Catholic:
Puritans were politically important in England, but it is debated whether the movement was in any way a party with policies and leaders before the early 1640s. While Puritanism in New England was important culturally for a group of colonial pioneers in America, there have been many studies trying to pin down exactly what the identifiable cultural component was. Fundamentally, historians remain dissatisfied with the grouping as "Puritan" as a working concept for historical explanation. The conception of a Protestant work ethic, identified more closely with Calvinist or Puritan principles, has been criticised at its root, mainly as a "post hoc ergo propter hoc" fallacy aligning economic success with a narrow religious scheme.

</doc>
<doc id="24092" url="https://en.wikipedia.org/wiki?curid=24092" title="Paul">
Paul

Paul may refer to:
See also.
Romanian derivatives:

</doc>
<doc id="24093" url="https://en.wikipedia.org/wiki?curid=24093" title="Palestinian National Authority">
Palestinian National Authority

The Palestinian National Authority (PA or PNA; "") is the interim self-government body established in 1994 following the Gaza–Jericho Agreement to govern the Gaza Strip and Areas A and B of the West Bank, as a consequence of the 1993 Oslo Accords. Following elections in 2006 and the subsequent Gaza conflict between the Fatah and Hamas parties, its authority had extended only in areas A and B of the West Bank. Since January 2013, the Fatah-controlled Palestinian Authority uses the name "State of Palestine" on official documents.
The Palestinian Authority was formed in 1994, pursuant to the Oslo Accords between the Palestine Liberation Organization (PLO) and the government of Israel, as a five-year interim body. Further negotiations were then meant to take place between the two parties regarding its final status. According to the Oslo Accords, the Palestinian Authority was designated to have exclusive control over both security-related and civilian issues in Palestinian urban areas (referred to as "Area A") and only civilian control over Palestinian rural areas ("Area B"). The remainder of the territories, including Israeli settlements, the Jordan Valley region and bypass roads between Palestinian communities, were to remain under Israeli control ("Area C"). East Jerusalem was excluded from the Accords. Negotiations with several Israeli governments had resulted in the Authority gaining further control of some areas, but control was then lost in some areas when the Israel Defense Forces (IDF) retook several strategic positions during the Second ("Al-Aqsa") Intifada. In 2005, after the Second Intifada, Israel withdrew unilaterally from its settlements in the Gaza Strip, thereby expanding Palestinian Authority control to the entire strip while Israel retained to control the crossing points, airspace and the waters off its coast.
In the Palestinian legislative elections on 25 January 2006, Hamas emerged victorious and nominated Ismail Haniyeh as the Authority's Prime Minister. However, the national unity Palestinian government effectively collapsed, when a violent conflict between Hamas and Fatah erupted, mainly in the Gaza Strip. After the Gaza Strip was taken over by Hamas on 14 June 2007, the Authority's Chairman Mahmoud Abbas dismissed the Hamas-led unity government and appointed Salam Fayyad as Prime Minister, dismissing Haniyeh. The move wasn't recognized by Hamas, thus resulting in two separate administrations – the Fatah-led Palestinian Authority in the West Bank and a rival Hamas government in the Gaza Strip. The reconciliation process to unite the Palestinian governments achieved some progress over the years, but had failed to produce a re-unification.
The PA received financial assistance from the European Union and the United States (approximately US$1 billion combined in 2005). All direct aid was suspended on 7 April 2006, as a result of the Hamas victory in parliamentary elections. Shortly thereafter, aid payments resumed, but were channeled directly to the offices of Mahmoud Abbas in the West Bank. Since 9 January 2009, when Mahmoud Abbas' term as President was supposed to have ended and elections were to have been called, Hamas supporters and many in the Gaza Strip have withdrawn recognition for his Presidency and instead consider Aziz Dweik, who served as the speaker of the house in the Palestinian Legislative Council, to be the acting President until new elections can be held.
In 2011, representatives of the Authority failed to have their United Nations (UN) status upgraded, although their UNESCO status was upgraded to state representation. In November 2012, however, the United Nations voted to recognize Palestine as a non-member UN observer state.
History.
Establishment.
The Palestinian Authority was created by the Gaza–Jericho Agreement, pursuant to the 1993 Oslo Accords. The Gaza–Jericho Agreement was signed on 4 May 1994 and included an Israeli withdrawal from the Jericho area and partially from the Gaza Strip, and detailed the creation of the Palestinian Authority and the Palestinian Civil Police Force.
The PA was envisioned as an interim organization to administer a limited form of Palestinian self-governance in the Areas A and B in the West Bank and Gaza Strip for a period of five years, during which final-status negotiations would take place. The Palestinian Central Council, itself acting on behalf of the Palestine National Council of the PLO, implemented this agreement in a meeting convened in Tunis from 10–11 October 1993, making the Palestinian Authority accountable to the PLO Executive Committee.
The administrative responsibilities accorded to the PA were limited to civil matters and internal security and did not include external security or foreign affairs. Palestinians in the diaspora and inside Israel were not eligible to vote in elections for the offices of the Palestinian Authority. The PA was legally separate from the Palestine Liberation Organization (PLO), which continues to enjoy international recognition as the sole legitimate representative of the Palestinian people, representing them at the United Nations under the name "Palestine".
General elections were held for its first legislative body, the Palestinian Legislative Council, on 20 January 1996. The expiration of the body's term was 4 May 1999, but elections were not held because of the "prevailing coercive situation".
Second Intifada.
On 7 July 2004, the Quartet of Middle East mediators informed Ahmed Qurei, Prime Minister of the PA from 2003 to 2006, that they were "sick and tired" of the Palestinians failure to carry out promised reforms: "If security reforms are not done, there will be no (more) international support and no funding from the international community"
On 18 July 2004, United States President George W. Bush stated that the establishment of a Palestinian state by the end of 2005 was unlikely due to instability and violence in the Palestinian Authority.
Following Arafat's death on 11 November 2004, Rawhi Fattouh, leader of the Palestinian Legislative Council became Acting President of the Palestinian Authority as provided for in Article 54(2) of the Authority's Basic Law and Palestinian Elections Law.
On 19 April 2005, Vladimir Putin the president of Russia agreed to aid the Palestinian Authority stating, "We support the efforts of President Abbas to reform the security services and fight against terrorism [...] If we are waiting for President Abbas to fight terrorism, he cannot do it with the resources he has now. [...] We will give the Palestinian Authority technical help by sending equipment, training people. We will give the Palestinian Authority helicopters and also communication equipment."
The Palestinian Authority became responsible for civil administration in some rural areas, as well as security in the major cities of the West Bank and the Gaza Strip. Although the five-year interim period expired in 1999, the final status agreement has yet to be concluded despite attempts such as the 2000 Camp David Summit, the Taba Summit, and the unofficial Geneva Accords.
In August 2005, Israeli Prime Minister Ariel Sharon began his disengagement from the Gaza Strip, ceding full effective internal control of the Strip to the Palestinian Authority but retained control of its borders including air and sea (except for the Egyptian border). This increased the percentage of land in the Gaza Strip nominally governed by the PA from 60 percent to 100 percent.
Hamas–Fatah conflict.
Palestinian legislative elections took place on 25 January 2006. Hamas was victorious and Ismail Haniyeh was nominated as Prime Minister on 16 February 2006 and sworn in on 29 March 2006. However, when a Hamas-led Palestinian government was formed, the Quartet (United States, Russia, United Nations, and European Union) conditioned future foreign assistance to the Palestinian Authority (PA) on the future government's commitment to non-violence, recognition of the State of Israel, and acceptance of previous agreements. Hamas rejected these demands, which resulted in the Quartet suspension of its foreign assistance program and Israel imposed economic sanctions.
In December 2006, Ismail Haniyeh, Prime Minister of the PA, declared that the PA will never recognize Israel: "We will never recognize the usurper Zionist government and will continue our jihad-like movement until the liberation of Jerusalem."
In an attempt to resolve the financial and diplomatic impasse, the Hamas-led government together with Fatah Chairman Mahmoud Abbas agreed to form a unity government. As a result, Haniyeh resigned on 15 February 2007 as part of the agreement. The unity government was finally formed on 18 March 2007 under Prime Minister Ismail Haniyeh and consisted of members from Hamas, Fatah and other parties and independents. The situation in the Gaza strip however quickly deteriorated into an open feud between the Hamas and Fatah, which eventually resulted in the "Brothers` War".
After the takeover in Gaza by Hamas on 14 June 2007, Palestinian Authority Chairman Abbas dismissed the government and on 15 June 2007 appointed Salam Fayyad Prime Minister to form a new government. Though the new government's authority is claimed to extend to all Palestinian territories, in effect it became limited to the Palestinian Authority controlled areas of the West Bank, as Hamas hasn't recognized the move. The Fayyad government has won widespread international support. Egypt, Jordan, and Saudi Arabia said in late June 2007 that the West Bank-based Cabinet formed by Fayyad was the sole legitimate Palestinian government, and Egypt moved its embassy from Gaza to the West Bank. Hamas, which government has an effective control of the Gaza Strip since 2007, faces international diplomatic and economic isolation.
In 2013, political analyst Hillel Frisch from Bar-Ilan University’s BESA Center, noted that "The PA is playing a double game...with regards to battling Hamas, there’s coordination if not cooperation with Israel. But on the political front, the PA is trying to generate a popular intifada."
Two administrations (2007–present).
Since the Hamas-Fatah split in 2007, the Fatah-dominated Palestinian Authority, based in areas of the West Bank had stabilized, though no significant economic growth had been achieved. Politically, until 2012, there had also been no progress in promotion of PNA status in the UN, as well as no progress in negotiations with Israel. Ramallah-based Palestinian Authority stayed out of the Gaza War in 2008–2009, which followed the six-month truce, between Hamas and Israel which ended on 19 December 2008. Hamas claimed that Israel broke the truce on 4 November 2008, though Israel blamed Hamas for an increasing rocket fire directed at southern Israeli towns and cities. The 2008–2009 Israel–Gaza conflict began on 27 December 2008 (11:30 a.m. local time; 09:30 UTC). Though condemning Israel over attacks on Gaza, the Palestinian Authority erected no actions during the conflict of Israel with Hamas.
The reconciliation process between Fatah and Hamas reached intermediate results by the two governments, most notably the agreement in Cairo on 27 April 2011, but with no final solution. Though the two agreed to form a unity government, and to hold elections in both territories within 12 months of the establishment of such a government, it had not been implemented. The 2011 deal also promised the entry of Hamas into the Palestine Liberation Organization and holding of elections to its Palestine National Council decision-making body, which was not implemented as well. The deal was further ratified in the 2012 Hamas–Fatah Doha agreement, which was made with the background of Hamas relocation from Damascus, due to the simmering Syrian civil war.
Since late August 2012, Palestinian National Authority has been swept with social protests aiming against the cost of living. The protesters targeted the Palestinian Prime Minister Salam Fayyad, calling for his resignation. Some anti-government protests turned violent. On 11 September, Palestinian Prime Minister issued a decree on lowering the fuel prices and cutting salaries of top officials.
In July 2012, it was reported that Hamas Government in Gaza was considering to declare the independence of the Gaza Strip with the help of Egypt.
On 23 April 2014 Ismail Haniyeh, the prime minister of Hamas, and a senior Palestine Liberation Organisation delegation dispatched by Palestinian President Mahmoud Abbas signed the Fatah–Hamas Gaza Agreement at Gaza City in an attempt to create reconciliation in the Fatah–Hamas conflict. It stated that a unity government should be formed within five weeks, ahead of a presidential and parliamentary election within six months. The Palestinian unity government of 2014 formed on 2 June 2014 as a national and political union under Palestinian president Mahmoud Abbas. The European Union, the United Nations, the United States, China, India, Russia and Turkey all agreed to work with it. The Israeli government condemned the unity government because it views Hamas as a terrorist organization. The Palestinian unity government first convened in Gaza on 9 October 2014 to discuss the reconstruction of the Gaza Strip following the 2014 Israel–Gaza conflict. On 30 November 2014, Hamas declared that the unity government had ended with the expiration of the six-month term. But Fatah subsequently denied the claim, and said that the government is still in force.
On 7-8 February 2016, Fatah and Hamas held talks in Doha, Qatar in an attempt to implement the 2014 agreements. Hamas official told "Al-Monitor" on 8 March, that the talks did not succeed and that discussions continued between the two movements. He also said that the foreign pressures on the Palestinian Authority to not implement the reconciliation terms is the main obstacle in the talks. In a Feb. 25 statement to local newspaper "Felesteen", Hamas foreign relations chief Osama Hamdan accused the United States and Israel of blocking Palestinian reconciliation. The United States is putting pressure on the PA to not reconcile with Hamas until the latter recognizes the Quartet on the Middle East’s conditions, including the recognition of Israel, which Hamas rejects. After the 2014 agreement, US President Barack Obama said in April 2014 that President Mahmoud Abbas’ decision to form a national unity government with Hamas was “unhelpful” and undermined the negotiations with Israel. Amin Maqboul, secretary-general of Fatah's Revolutionary Council, told "Al-Monitor", “Hamas did not stick to the 2014 agreement, as it has yet to hand over the reins of power over Gaza to the national consensus government and continues to control the crossings. Should Hamas continue down this path, we have to go to the polls immediately and let the people choose who they want to rule.”
2013 name change.
The UN has permitted the PLO to title its representative office to the UN as "The Permanent Observer Mission of the State of Palestine to the United Nations", and Palestine has started to re-title its name accordingly on postal stamps, official documents and passports, whilst it has instructed its diplomats to officially represent 'The State of Palestine', as opposed to the 'Palestine National Authority'. Additionally, on 17 December 2012, UN Chief of Protocol Yeocheol Yoon decided that "the designation of 'State of Palestine' shall be used by the Secretariat in all official United Nations documents". However, in a speech in 2016 president Abbas said that "The Palestinian Authority exists and it is here," and "The Palestinian Authority is one of our achievements and we won’t give it up." 
Geography.
The Palestinian Territories refers to the Gaza Strip and the West Bank (including East Jerusalem). The Palestinian Authority currently administers some 39% of the West Bank. 61% of the West bank remains under direct Israeli military and civilian control. East Jerusalem was unilaterally annexed by Israel in 1980, prior to the formation of the PA. Since 2007 Gaza has been governed by the Hamas Government in Gaza.
Politics and internal structure.
The politics of the Palestinian Authority take place within the framework of a semi-presidential multi-party republic, with the Palestinian Legislative Council (PLC), an executive President, and a Prime Minister leading a Cabinet. According to the Palestinian Basic Law which was signed by Arafat in 2002 after a long delay, the current structure of the PA is based on three separate branches of power: executive, legislative, and judiciary. The PA was created by, is ultimately accountable to, and has historically been associated with, the Palestine Liberation Organization (PLO), with whom Israel negotiated the Oslo Accords.
The PLC is an elected body of 132 representatives, which must confirm the Prime Minister upon nomination by the President, and which must approve all government cabinet positions proposed by the Prime Minister. The Judicial Branch has yet to be formalized. The President of the PA is directly elected by the people, and the holder of this position is also considered to be the commander-in-chief of the armed forces. In an amendment to the Basic Law approved in 2003, the president appoints the Prime Minister who is also chief of the security services in the Palestinian territories. The Prime Minister chooses a cabinet of ministers and runs the government, reporting directly to the President.
Parliamentary elections were conducted in January 2006 after the passage of an overhauled election law that increased the number of seats from 88 to 132. The Chairman of the PLO, Yasser Arafat, was elected as President of PA in a landslide victory in 1996.
Arafat's administration was criticized for its lack of democracy, widespread corruption among officials, and the division of power among families and numerous governmental agencies with overlapping functions. Both Israel and the US declared they lost trust in Arafat as a partner and refused to negotiate with him, regarding him as linked to terrorism. Arafat denied this, and was visited by other leaders around the world up until his death. However, this began a push for change in the Palestinian leadership. In 2003, Mahmoud Abbas resigned because of lack of support from Israel, the US, and Arafat himself. He won the presidency on 9 January 2005 with 62% of the vote. Former prime minister Ahmed Qureia formed his government on 24 February 2005 to wide international praise because, for the first time, most ministries were headed by experts in their field as opposed to political appointees.
The presidential mandate of Mahmoud Abbas expired in 2009 and he is no longer recognised by Hamas, among others, as the legitimate Palestinian leader. According to Palestinian documents leaked to the Al Jazeera news organization, the United States has threatened to cut off funding to the Palestinian Authority should there be a change in the Palestinian leadership in the West Bank. In February 2011, the Palestinian Authority announced that parliamentary and presidential elections would be held by September 2011.
On 27 April 2011, Fatah's Azzam al-Ahmad announced the party's signing of a memorandum of understanding with Hamas' leadership, a major step towards reconciliation effectively paving the way for a unity government. The deal was formally announced in Cairo, and was co-ordinated under the mediation of Egypt's new intelligence director Murad Muwafi. The deal came amidst an international campaign for statehood advanced by the Abbas administration, which is expected to culminate in a request for admission into the General Assembly as a member state in September. As part of the deal, the two factions agreed to hold elections in both territories within twelve months of the creation of a transitional government. In response to the announcement, Israeli Prime Minister Netanyahu warned that the Authority must choose whether it wants "peace with Israel or peace with Hamas".
Political parties and elections.
From the establishment of the Palestinian Authority in 1993 until the death of Yasser Arafat in late 2004, only one election had taken place. All other elections were deferred for various reasons.
A single election for president and the legislature took place in 1996. The next presidential and legislative elections were scheduled for 2001, but were delayed following the outbreak of the Al-Aqsa Intifada. Following Arafat's death, elections for the President of the Authority were announced for 9 January 2005. The PLO leader Mahmoud Abbas won 62.3% of the vote, while Dr. Mustafa Barghouti, a physician and independent candidate, won 19.8%.
On 10 May 2004, the Palestinian Cabinet announced that municipal elections would take place for the first time. Elections were announced for August 2004 in Jericho, followed by certain municipalities in the Gaza Strip. In July 2004 these elections were postponed. Issues with voter registration are said to have contributed to the delay. Municipal elections finally took place for council officials in Jericho and 25 other towns and villages in the West Bank on 23 December 2004. On 27 January 2005, the first round of the municipal elections took place in the Gaza Strip for officials in 10 local councils. Further rounds in the West Bank took place in May 2005.
Elections for a new Palestinian Legislative Council (PLC) were scheduled for July 2005 by Acting Palestinian Authority President Rawhi Fattuh in January 2005. These elections were postponed by Mahmoud Abbas after major changes to the Election Law were enacted by the PLC which required more time for the Palestinian Central Elections Committee to process and prepare. Among these changes were the expansion of the number of parliament seats from 88 to 132, with half of the seats to be competed for in 16 localities, and the other half to be elected in proportion to party votes from a nationwide pool of candidates.
The following organizations, listed in alphabetic order, have taken part in recent popular elections inside the Palestinian Authority:
October 2006 polls showed that Fatah and Hamas had equal strength.
On 14 June 2007, after the Battle of Gaza (2007), Palestine president Mahmoud Abbas dismissed the Hamas-led government, leaving the government under his control for 30 days, after which the temporary government had to be approved by the Palestinian Legislative Council.
Law.
Human rights.
In theory the Palestinian Authority has guaranteed freedom of assembly to the Palestinian citizens residing in its territory. Nevertheless, the right to demonstrate for opponents of the PA regime or of PA policy has become increasingly subject to police control and restriction and is a source of concern for human rights groups.
The Fatah–Hamas conflict has further limited the freedom of the press in the PA territories and the distribution of opposing voices in Hamas-controlled Gaza and the West Bank where Fatah still has more influence. According to the Ramallah-based Palestinian Center for Development and Media Freedoms, in 2011, there were more assaults on Palestinian press freedom from the PA than from Israel. In July 2010, with the easing of the blockade of the Gaza Strip, Israel allowed the distribution of the pro-Fatah newspapers al-Quds, al-Ayyam and al-Hayat al-Jadida to Gaza, but Hamas prevented Gazan distributors from retrieving the shipment. The Palestinian Centre for Human Rights (PCHR) condemned the Hamas restrictions of distribution of the West Bank newspapers in Gaza, and also condemned the Fatah-led government in the West Bank for restricting publication and distribution of the Gazan newspapers al-Resala and Falastin.
Women have full suffrage in the PA. In the 2006 elections, women made up 47 percent of registered voters. Prior to the elections, the election law was amended to introduce a quota for women on the national party lists, resulting in 22 per cent of candidates on the national lists being women. The quota's effectiveness was illustrated in comparison with the district elections, where there was no quota, and only 15 of the 414 candidates were women.
Selling land or housing to Jews is punishable by death, some high-profile cases got high media coverage.
Hamas has begun enforcing some Islamic standards of dress for women in the PA; women must don headscarves in order to enter government ministry buildings. In July 2010, Hamas banned the smoking of hookah by women in public. They claimed that it was to reduce the increasing number of divorces.
In June 2011, the Independent Commission for Human Rights published a report whose findings included that the Palestinians in the West Bank and the Gaza Strip were subjected in 2010 to an "almost systematic campaign" of human rights abuses by the Palestinian Authority and Hamas, as well as by Israeli authorities, with the security forces belonging to the PA and Hamas being responsible for torture, arrests and arbitrary detentions.
Crime and law enforcement.
Violence against civilians.
The Palestinian Human Rights Monitoring Group reports that through ""everyday disagreements and clashes between the various political factions, families and cities that a complete picture of Palestinian society is painted. These divisions have during the course of the al Aqsa Intifada also led to an increasingly violent ‘Intrafada’. In the 10-year period from 1993 to 2003, 16% of Palestinian civilian deaths were caused by Palestinian groups or individuals"."
Erika Waak reports in "The Humanist" ""Of the total number of Palestinian civilians killed during this period by both Israeli and Palestinian security forces, 16 percent were the victims of Palestinian security forces."" Accusations of collaboration with Israel are used to target and kill individual Palestinians:
""Those who are convicted have either been caught helping Israelis, spoken out against Arafat, or are involved in rival criminal gangs, and these individuals are hanged after summary trials. Arafat creates an environment where the violence continues while silencing would-be critics, and although he could make the violence impossible, he doesn't stop it.""
Freedom House's annual survey of political rights and civil liberties, Freedom in the World 2001–2002, reports ""Civil liberties declined due to: shooting deaths of Palestinian civilians by Palestinian security personnel; the summary trial and executions of alleged collaborators by the Palestinian Authority (PA); extrajudicial killings of suspected collaborators by militias; and the apparent official encouragement of Palestinian youth to confront Israeli soldiers, thus placing them directly in harm's way.""
Palestinian security forces have, as of March 2005, not made any arrests for the October 2003 killing of three American members of a diplomatic convoy in the Gaza Strip. Moussa Arafat, head of the Palestinian Military Intelligence and a cousin of then Palestinian Authority Chairman Yasser Arafat has stated that, regarding the United States pressure to arrest the killers; "They know that we are in a very critical position and that clashing with any Palestinian party under the presence of the occupation is an issue that will present many problems for us". Since the October 2003 attack, United States diplomats have been banned from entering the Gaza Strip.
Violence against officials (2001–2004).
On 22 April 2001, Jaweed al-Ghussein, former Chairman of the Palestine National Fund, was abducted from Abu Dhabi, UAE flown to Arish, Egypt, driven across the border to Gaza where he was held hostage by the Palestinian Authority. The Minister of Justice Freh Abu Mediane protested and resigned over the illegality. Haider Abdel Shafi Chief Delegate in the Madrid Peace Process and leading Palestinian protested at his incaceration and demanded his immediate release. The PCCR (Palestinian Commission on Citizens Rights) took the case up. The Attorney General Sorani declared there was no legality. The Red Cross was denied access to him. Amnesty International asked for his release. The United Nations Working Group on Arbitrary Detention determined he was being held 'manifestly with no legal justification' and appointed a Special Rapporteur on torture.
On 15 October 2003, three members of a United States diplomatic convoy were killed and additional members of the convoy wounded three kilometers south of the Erez Crossing into the Gaza Strip by a terrorist bomb. The perpetrators remain at large.
In February 2004, Ghassan Shaqawa, the mayor of Nablus, filed his resignation from office in protest of the Palestinian Authority's lack of action against the armed militias rampaging the city and the multiple attempts by some Palestinians to assassinate him. Gaza's police Chief, General Saib al-Ajez would later say: 'This internal conflict between police and militants cannot happen. It is forbidden. We are a single nation and many people know each other and it is not easy to kill someone who is bearing a weapon to defend his nation."
Karen Abu Zayd, deputy commissioner general for the UN Relief and Works Agency in the Gaza Strip stated on 29 February 2004: "What has begun to be more visible is the beginning of the breakdown of law and order, all the groups have their own militias, and they are very organized. It's factions trying to exercise their powers."
Ghazi al-Jabali, the Gaza Strip Chief of Police, since 1994 has been the target of repeated attacks by Palestinians. In March 2004, his offices were targeted by gunfire. In April 2004, a bomb was detonated destroying the front of his house. On 17 July 2004, he was kidnapped at gunpoint following an ambush of his convoy and wounding of two bodyguards. He was released several hours later. Less than six hours later, Colonel Khaled Abu Aloula, director of military coordination in the southern part of Gaza was abducted.
On the eve of 17 July, Fatah movement members kidnapped 5 French citizens (3 men and 2 women) and held them hostage in Red Crescent Society building in Khan Yunis:
On 18 July, Arafat replaced Ghazi al-Jabali, with his nephew Moussa Arafat, sparking violent riots in Rafah and Khan Yunis in which members of the al-Aqsa Martyrs' Brigades burned PA offices and opened fire on Palestinian policemen. During the riots at least one Palestinian was killed and dozen more seriously wounded.
On 20 July 2004 David Satterfield, the second-in-charge at the United States Department of State Near East desk stated in a hearing before the Senate that the Palestinian Authority had failed to arrest the Palestinian terrorists who had murdered three members of an American diplomatic convoy traveling in the Gaza Strip on 15 October 2003. Satterfield stated:
On 21 July, Nabil Amar, former Minister of Information and a cabinet member and a member of the Palestinian Legislative Council, was shot by masked gunmen, after an interview with a television channel in which he criticized Yasser Arafat and called for reforms in the PA.
Regarding the descent into chaos Cabinet minister Qadura Fares stated on 21 July 2004:
On 22 July 2004, The United Nations elevated its threat warning level for the Gaza Strip to "Phase Four" (one less than the maximum "Phase Five") and planned to evacuate non-essential foreign staff from the Gaza Strip.
On 23 July 2004, an Arab boy was shot and killed by Palestinian terrorists of the Al-Aqsa Martyrs' Brigades after he and his family physically opposed their attempt to set up a Qassam rocket launcher outside the family's house. Five other individuals were wounded in the incident.
On 31 July, Palestinian kidnappers in Nablus seized 3 foreign nationals, an American, British and Irish citizen. They were later released. Also, a PA security forces HQ building was burnt down in Jenin by the al Aqsa Martyrs' Brigades. A leader of Al Aqsa Martyrs Brigades said they torched the building because new mayor Qadorrah Moussa, appointed by Arafat, had refused to pay salaries to Al Aqsa members or to cooperate with the group.
On 8 August 2004 the Justice Minister Nahed Arreyes resigned stating that he has been stripped of much of his authority over the legal system. The year before, Yasser Arafat created a rival agency to the Justice Ministry and was accused of continuing to control the judiciary and in particular the state prosecutors.
On 10 August 2004, a report by an investigation committee Palestinian Legislative Council for the reasons for the anarchy and chaos in the PA was published by Haaretz daily newspaper. The report put the main blame on Yasser Arafat and the PA's security forces, which "have failed to make a clear political decision to end it".
The report states,
The report also calls to stop shooting Qassam rockets and mortar shells on Israeli settlements because of it hurts "Palestinian interests".
Hakham Balawi said:
Despite the criticism against Yasser Arafat, the troubles continued. On 24 August, the Lieutenant Commander of the Palestinian General Intelligence in the Gaza Strip, Tareq Abu-Rajab, was shot by group of armed men. He was seriously injured.
On 31 August, the Jenin Martyrs Brigades, the armed wing of the Popular Resistance Committees, threaten to kill Minister Nabil Shaath for participating in a conference in Italy attended by Israeli Foreign Minister Silvan Shalom, declaring "He will be sentenced to death if he enters. The decision cannot be rescinded, we call upon his bodyguards to abandon his convoy in order to save their lives."
On 8 September, Prime Minister Ahmed Qurei, threatens to resign, again. Three weeks have elapsed since he retracted is resignation, originally tendered six weeks ago.
On 12 October, Moussa Arafat, cousin of Yasser Arafat and a top security official in the Gaza Strip, survived a car bomb assassination attempt. Recently the Popular Resistance Committees threatened Moussa Arafat with retaliation for an alleged attempt to assassinate its leader, Mohammed Nashabat.
On 14 October, Palestinian Prime Minister Ahmed Qurei stated that the Palestinian Authority is unable to stop the spreading anarchy. While routinely blaming Israel for the PA's problems, he pointed out that the many PA security forces are hobbled by corruption and factional feuding. Due to the lack of governmentals reforms demanded by international peace mediators, Palestinian legislators demanded Qurei present a report on the matter by 20 October, at which point they will decide upon holding a no-confidence vote.
On 19 October, a group of Al-Aqsa Martyrs' Brigades members, led by Zakaria Zubeidi, seized buildings belonging to the Palestinian Finance ministry and Palestinian parliament in Jenin.
According to Mosab Hassan Yousef, the CIA has provided sophisticated electronic eavesdropping equipment to the Palestinian Authority that has been used against suspected Palestinian militants. However, the equipment has also been used against Shin Bet informants.
Palestinian measures to keep law and order.
In 2006, after the Hamas victory, the Palestinian interior minister formed an Executive Force for the police. However, the PA president objected and after clashes between Hamas and Fatah, a redeployment of the force was made and efforts started in order to integrate it with the police force.
In 2011, Amira Hass reported that in sections of Area B of the West Bank, especially around the towns of Abu Dis and Sawahera, a security paradox was evolving: while the Oslo Accords stipulate that the Israeli Army have authority to police Area B, they weren't; and though the Palestinian security forces were prepared to deal with criminal activity in this Area, they had to wait for Israeli permission to enter, and were thus ineffective. Hass also reported that as a result of this paradox, Abu Dis and surrounding areas were becoming a haven for weapons smugglers, drug dealers, and other criminals.
As of 2013, Palestinian security forces continue to coordinate with Israeli troops in tracking Islamic militants in the West Bank.
Administrative divisions.
After the signing of the Oslo Accords, the West bank and the Gaza Strip were divided into areas (A, B, and C) and governorates:
Since the Battle of Gaza (2007) most of the Gaza Strip has been in control of the Hamas, with the Palestinian Authority stating it is officially no longer in control of the Gaza Strip.
West Bank governorates.
The PNA divides its territories into governorates:
Gaza Strip governorates.
Since 2007, a Hamas-led government rather than the PA has exercised control in the Gaza Strip.
Foreign relations.
The Palestinian National Authority (PNA) foreign relations are conducted by the minister of foreign affairs. The PNA is represented abroad by the Palestine Liberation Organization (PLO), which maintains a network of missions and embassies. In states that recognise the State of Palestine it maintains embassies and in other states it maintains "delegations" or "missions".
Representations of foreign states to the Palestinian Authority are performed by "missions" or "offices" in Ramallah and Gaza. States that recognise the State of Palestine also accredit to the PLO (as the government-in-exile of the State of Palestine) non-resident ambassadors residing in third countries.
On 5 January 2013, following the 2012 UNGA resolution, Palestinian President Abbas ordered all Palestinian embassies to change any official reference to the Palestinian Authority into State of Palestine.
The Palestinian Authority is included in the European Union's European Neighbourhood Policy (ENP), which aims at bringing the EU and its neighbours closer.
Palestinian Authority passport.
In April 1995, the Palestinian Authority, pursuant to the Oslo Accords with the State of Israel, started to issue passports to Palestinian residents of the Gaza Strip and West Bank. The appearance of the passport and details about its issuance are described in Appendix C of Annex II (Protocol Concerning Civil Affairs) of Gaza-Jericho Agreement signed by Israel and the PLO on 4 May 1994. The Palestinian Authority does not issue the passports on behalf of the proclaimed State of Palestine. The passports bear the inscription: ""This passport/travel document is issued pursuant to the Palestinian Self Government Agreement according to Oslo Agreement signed in Washington on 13/9/1993"". By September 1995, the passport had been recognised by 29 states, some of them (e.g. the United States) recognise it only as a travel document (see further details below): Algeria, Bahrain, Bulgaria, People's Republic of China, Cyprus, Egypt, France, Germany, Greece, India, Iran, Jordan, Malta, Morocco, the Netherlands, Pakistan, Qatar, Romania, Russia, Saudi Arabia, Sudan, South Africa, Spain, Sweden, Switzerland, Tunisia, Turkey, the United Arab Emirates, the United Kingdom, and the United States.
While the U.S. Government recognises Palestinian Authority passports as travel documents, it does not view them as conferring citizenship, since they are not issued by a government that they recognise. Consular officials representing the Governments of Egypt, Jordan and the United Arab Emirates, when asked by the Resource Information Center of UNHCR in May 2002, would not comment on whether their governments viewed PA passports as conferring any proof of citizenship or residency, but did say that the passports, along with valid visas or other necessary papers, would allow their holders to travel to their countries.
The Palestinian Authority has said that anyone born in Palestine carrying a birth certificate attesting to that can apply for a PA passport. Whether or not Palestinians born outside Palestine could apply was not clear to the PA Representative questioned by UNHCR representatives in May 2002. The PA representative also said even if those applying met the PA's eligibility criteria, the Israeli government placed additional restrictions on the actual issuance of passports.
In October 2007, a Japanese Justice Ministry official said, "Given that the Palestinian Authority has improved itself to almost a full-fledged state and issues its own passports, we have decided to accept the Palestinian nationality." The decision followed a recommendation by a ruling party panel on nationality that Palestinians should no longer be treated as stateless.
Legal action against PNA.
In February 2015 in a civil case considered by a US federal court the Palestinian Authority and Palestine Liberation Organization were found liable for the death and injuries of US citizens in a number of terrorist attacks in Israel from 2001 to 2004. The damages are to be $655.5 million.
Police forces.
The creation of a Palestinian police force was called for under the Oslo Accords. The first Palestinian police force of 9,000 was deployed in Jericho in 1994, and later in Gaza. These forces initially struggled to control security in the areas in which it had partial controlled and because of this Israel delayed expansion of the area to be administered by the PA. By 1996, the PA security forces were estimated to include anywhere from 40,000 to 80,000 recruits. PA security forces employ some armored cars, and a limited number carry automatic weapons. Some Palestinians opposed to or critical of the peace process perceive the Palestinian security forces to be little more than a proxy of the State of Israel.
Economy.
The Gaza International Airport was built by the PA in the city of Rafah, but operated for only a brief period before being destroyed by Israel following the outbreak of Al-Aqsa Intifada in 2000. A sea port was also being constructed in Gaza but was never completed.
Some Palestinians are dependent on access to the Israeli job market. During the 1990s, some Israeli companies began to replace Palestinians with foreign workers. The process was found to be economical and also addressed security concerns. This hurt the Palestinian economy, in particular in the Gaza strip, where 45.7% of the population is under the poverty line according to the CIA World Factbook, but it also affected the West Bank.
Budget.
According to the World Bank, the budget deficit in PNA was about $800 million in 2005, with nearly half of it financed by donors. The World Bank stated, "The PA's fiscal situation has become increasingly unsustainable mainly as a result of uncontrolled government consumption, in particular a rapidly increasing public sector wage bill, expanding social transfer schemes and rising net lending."
In June 2011, Prime Minister Salam Fayyad stated that the Palestinian Authority is facing a financial crisis because funds pledged by donor nations have not arrived on time. Fayyad said that "In 2011, we have been receiving $52.5 million dollars a month from the Arab countries, which is much less than the amount they committed to deliver." 
In June 2012, the Palestinian Authority was unable to pay its workers' salaries as a result of their financial issues, including a cutback in aid from foreign donors, and Arab countries not fulfilling their pledges to send money to the Palestinian Authority, in which the Palestinian Authority is heavily dependent. Finance Minister Nabil Kassis called the crisis "the worst" in three years. Adding to the complications are the fact that in the same month, the head of the Palestine Monetary Authority, Jihad Al-Wazir, stated that the Palestinian Authority reached the maximum limit of borrowing from Palestinian banks.
In July 2012, Prime Minister Salam Fayyad urged Arab countries to send the money they promised, which amounts to tens of millions of dollars, as they have not made good on their pledges, while Western donors have. The Palestinian labor minister Ahmed Majdalani also warned of the consequences of a shortfall in the delivery of aid from Arab donor nations.
In order to help the Palestinian Authority solve its crisis, Israel sought $1 billion in loans from the International Monetary Fund, intending to transfer this loan to the Palestinian Authority who would pay them back when possible. The IMF rejected the proposal because it feared setting a precedent of making IMF money available to non-state entities, like the Palestinian Authority, which as a non-state cannot directly request or receive IMF funding.
In mid-July 2012, it was announced that Saudi Arabia would imminently send $100 million to the Palestinian Authority to help relieve them of their financial crisis. Still, the Palestinian Authority is seeking the support of other countries to send more money to help fix a budget deficit that is approximately $1.5 billion for 2012, and it is estimated that they need approximately $500 million more. Ghassan Khatib, a Palestinian Authority spokesman, said, "This $100 million is important and significant because it's coming from a leading Arab state, and this hopefully can be an example for other countries to follow... We will remain in need of external funding. Whenever it is affected, then we will be in crisis."
By 15 July 2012, Palestinian Authority workers received only 60% of their salaries for June, which caused discontent against the government.
In a "goodwill gesture" to the Palestinian Authority to renew dialogue with Israel, Israeli Prime Minister Benjamin Netanyahu and Finance Minister Yuval Steinitz decided to give Ramallah an NIS 180 million advance on tax money it transfers on a monthly basis. The Israeli government’s economic cabinet also decided to increase the number of Palestinian construction workers allowed in Israel by approximately 5,000. One Israeli official said that the money helped the Palestinian Authority pay its salaries before Ramadan, and it was part of Israel’s policy of helping to "preserve the Palestinian economy."
The World Bank issued a report in July 2012 that the Palestinian economy cannot sustain statehood as long as it continues to heavily rely on foreign donations and the private sector fails to thrive. The report said that the Palestinian Authority is unlikely to reach fiscal sustainability until a peace deal is achieved that allows the private sector to experience rapid and sustained growth. The World Bank report also blamed the financial issues on the absence of a final status agreement that would allow for a two-state solution to the Israeli-Arab conflict.
As of May 2011 the Palestinian Authority spent $4.5 million per month paying Palestinian prisoners. The payments include monthly amounts such as NIS 12,000 ($3,000) to prisoners who have been imprisoned for over 30 years. The salaries, funded by the PA, are given to Fatah, Hamas, and Islamic Jihad prisoners, despite financial hardships by the Palestinian Authority. These payments make up 6% of the PA's budget.
, the PA has a debt of 1.8 bln NIS to the Israel Electric Corporation.
Corruption.
A poll conducted by the Palestinian Center for Policy and Survey Research revealed that 71% of Palestinians believe there is corruption in the Palestinian Authority institutions in the West Bank, and 57% say there is corruption in the institutions of the dismissed Palestinian government in the Gaza Strip. 34% say that there is no freedom of the press in the West Bank, 21% say that there is press freedom in the West Bank, and 41% say there is to a certain extent. 29% of Palestinians say people in the West Bank can criticize the government in the West Bank without fear.
At a hearing of the House Committee on Foreign Affairs in the United States Congress on 10 July 2012, titled "Chronic Kleptocracy: Corruption within the Palestinian Political Establishment," it was stated that there is serious corruption within the political establishment and in financial transactions. The experts, analysts, and specialists testified on corruption within financial transactions concerning Mahmoud Abbas, his sons Yasser and Tareq, and the Palestine Investment Fund, among others, as well as on the limiting of freedom of the press, crushing political opposition, and cracking down on protestors. According to Representative Steve Chabot, who testified at the hearing, "Reports suggest that Palestinian President Mahmoud Abbas, like his predecessor Yassir Arafat, has used his position of power to line his own pockets as well as those of his cohort of cronies, including his sons, Yasser and Tareq. The Palestinian Investment Fund, for example, was intended to serve the interests of the Palestinian population and was supposed to be transparent, accountable, and independent of the Palestinian political leadership. Instead it is surrounded by allegations of favoritism and fraud." Concerning Abbas' children, Chabot stated that "Even more disturbingly, Yasser and Tareq Abbas—who have amassed a great deal of wealth and economic power—have enriched themselves with U.S. taxpayer money. They have allegedly received hundreds of thousands of dollars in USAID contracts."
In April 2013, the Palestinian organization Coalition for Transparency in Palestine said it was investigating 29 claims of stolen public funds. In addition, they said that that PA "has problems with money laundering, nepotism and misusing official positions." Twelve earlier claims were investigated and sent to the courts for resolution. In response, Palestinian Authority Justice Minister Ali Muhanna said that they have "made large strides in reducing corruption."
International aid.
The majority of aid to the Palestinian Authority comes from the United States and European Union. According to figures released by the PA, only 22 percent of the $530,000,000 received since the beginning of 2010 came from Arab donors. The remaining came from Western donors and organizations. The total amount of foreign aid received directly by the PA was $1.4 billion in 2009 and $1.8 billion in 2008.
Palestinian leaders stated the Arab world was "continuing to ignore" repeated requests for help.
The US and the EU responded to Hamas' political victory by stopping direct aid to the PA, while the US imposed a financial blockade on PA's banks, impeding some of the Arab League's funds (e.g. Saudi Arabia and Qatar) from being transferred to the PA. On 6 and 7 May 2006, hundreds of Palestinians demonstrated in Gaza and the West Bank demanding payment of their wages.
In 2013 there are 150,000 government employees. Income to run the government to serve about 4 million citizens, comes from donations from other countries.
Economic sanctions following January 2006 legislative elections.
Following the January 2006 legislative elections, won by Hamas, the Quartet (the United States, Russia, the European Union, and the United Nations) threatened to cut funds to the Palestinian Authority. On 2 February 2006, according to the AFP, the PA accused Israel of "practicing collective punishment after it snubbed US calls to unblock funds owed to the Palestinians." Prime minister Ahmed Qorei "said he was hopeful of finding alternative funding to meet the budget shortfall of around 50 million dollars, needed to pay the wages of public sector workers, and which should have been handed over by Israel on the first of the month." The US Department criticized Israel for refusing to quickly unblock the funds. The funds were later unblocked. However, the "New York Times" alleged on 14 February 2006 that a "destabilization plan" of the United States and Israel, aimed against Hamas, winner of the January 2006 legislative elections, centered "largely on money" and cutting all funds to the PA once Hamas takes power, in order to delegitimize it in the eyes of the Palestinians. According to the news article, "The Palestinian Authority has a monthly cash deficit of some $60 million to $70 million after it receives between $50 million and $55 million a month from Israel in taxes and customs duties collected by Israeli officials at the borders but owed to the Palestinians." Beginning March 2006, "the Palestinian Authority will face a cash deficit of at least $110 million a month, or more than $1 billion a year, which it needs to pay full salaries to its 140,000 employees, who are the breadwinners for at least one-third of the Palestinian population. The employment figure includes some 58,000 members of the security forces, most of which are affiliated with the defeated Fatah movement." Since 25 January elections, "the Palestinian stock market has already fallen about 20 percent", while the "Authority has exhausted its borrowing capacity with local banks."
Use of European Union assistance.
In February 2004, it was reported that the European Union (EU) anti-fraud office (OLAF) was studying documents suggesting that Yasser Arafat and the Palestinian Authority had diverted tens of millions of dollars in EU funds to organizations involved in terrorist attacks, such as the Al-Aqsa Martyrs Brigades. However, in August 2004, a provisional assessment stated that "To date, there is no evidence that funds from the non-targeted EU Direct Budget Assistance to the Palestinian Authority have been used to finance illegal activities, including terrorism."
US foreign aid packages.
The US House for Foreign Operations announced a foreign assistance package to the Palestinian Authority that included provisions that would bar the government from receiving aid if it seeks statehood at the UN or includes Hamas in a unity government. The bill would provide $513 million for the Palestinian Authority.
Payments to Palestinian prisoners in Israeli prisons.
On 22 July 2004, Salam Fayyad, PA Minister of Finance, in an article in the Palestinian weekly, "The Jerusalem Times", detailed the following payments to Palestinians imprisoned by the Israeli authorities:
In February 2011, The Jerusalem Post revealed that the PA was paying monthly salaries to members of Hamas who are in Israeli prisons.
In March 2009, an extra 800 shekels ($190) was added to the stipends given to Palestinians affiliated with PLO factions in Israeli prisons, as confirmed by the head of Palestinian Prisoner Society in Nablus Ra'ed Amer. Each PLO-affiliated prisoner receives 1,000 shekels ($238) per month, an extra 300 shekels ($71) if they are married, and an extra 50 shekels ($12) for each child.
James G. Lindsay.
James G. Lindsay a former UNRWA general-counsel and fellow researcher for Washington Institute for Near East Policy published a report regarding the use of international aid in the Palestinian Authority. Lindsay argued that internationally funded construction projects in the West Bank should try to minimize foreign labor and maximize the participation of Palestinian workers and management to ensure economic expansion through salaries, job training, and improved infrastructure. Lindsay stated that some financial control should stay in international hands to avoid "nepotism or corruption".
Lindsay has also argued that in any peace settlement acceptable to Israel "there will be few, if any, Palestinian refugees returning to Israel proper".
Lindsay suggested that internationally funded construction projects should try to benefit West Bank refugees who are willing to give up their longstanding demand for a "right of return". Lindsay also claimed that projects that will improve the living conditions of West Bank refugees could also be seen as part of the reparations or damages to be paid to refugees in any likely Israeli-Palestinian agreement. Lindsay criticized the Palestinian Authority treatment of these refugees:
PA projects are not likely to address refugee needs, however, since the PA has traditionally deferred to the UN Relief and Works Agency (UNRWA) regarding infrastructure in refugee camps.
External links.
Government
Israel and the Palestinian Authority

</doc>
<doc id="24095" url="https://en.wikipedia.org/wiki?curid=24095" title="Diana, Princess of Wales">
Diana, Princess of Wales

Diana, Princess of Wales (Diana Frances; "née" Spencer; 1 July 1961 – 31 August 1997), was the first wife of Charles, Prince of Wales, who is the eldest child and heir apparent of Queen Elizabeth II.
Diana was born into a family of British nobility with royal ancestry as "The Honourable" Diana Spencer. She was the fourth child and third daughter of John Spencer, Viscount Althorp and the Honourable Frances Roche. She grew up in Park House, situated on the Sandringham estate, and was educated in England and Switzerland. In 1975, after her father inherited the title of Earl Spencer, she became "Lady" Diana Spencer.
Her wedding to the Prince of Wales on 29 July 1981, held at St Paul's Cathedral, reached a global television audience of over 750 million people. While married, Diana bore the titles Princess of Wales, Duchess of Cornwall, Duchess of Rothesay, Countess of Chester, and Baroness of Renfrew. The marriage produced two sons, the princes William and Harry, who were then respectively second and third in the line of succession to the British throne. As Princess of Wales, Diana undertook royal duties on behalf of the Queen and represented her at functions overseas. She was celebrated for her charity work and for her support of the International Campaign to Ban Landmines. She was involved with dozens of charities including London's Great Ormond Street Hospital for children, of which she was president from 1989.
Diana remained the object of worldwide media scrutiny during and after her marriage, which ended in divorce on 28 August 1996. Media attention and public mourning were extensive after her death in a car crash in Paris on 31 August 1997 and subsequent televised funeral.
Early life.
Diana was born on 1 July 1961, in Park House, Sandringham, Norfolk. She was the fourth of five children of John Spencer, Viscount Althorp (1924–1992) and his first wife, Frances (née Roche; 1936–2004). The Spencer family has been closely allied with the British Royal Family for several generations. Both of Diana's grandmothers had served as ladies in waiting to Queen Elizabeth The Queen Mother. The Spencers were hoping for a boy to carry on the family line, and no name was chosen for a week, until they settled on Diana Frances, after her mother and Diana Russell, Duchess of Bedford, her distant relative who was also known as "Lady Diana Spencer" before marriage and was a prospective Princess of Wales. Diana was baptised at St. Mary Magdalene Church, Sandringham. Diana had three siblings: Sarah, Jane, and Charles. An infant brother, John, died shortly after his birth in 1960. The desire for an heir added strain to the Spencers' marriage, and Lady Althorp was reportedly sent to Harley Street clinics in London to determine the cause of the "problem". The experience was described as "humiliating" by Diana's younger brother, Charles: "It was a dreadful time for my parents and probably the root of their divorce because I don't think they ever got over it." Diana grew up in Park House, situated on the Sandringham estate. The Spencers leased the house from its owner, Queen Elizabeth II. The Royal Family frequently holidayed at the neighbouring Sandringham House, and Diana played with Princes Andrew and Edward as a child.
Diana was seven years old when her parents divorced, after her mother had an affair with Peter Shand Kydd. The two were married in 1969. Diana lived with her mother in London during her parents' separation in 1967. However, during Christmas holidays that year, Lord Althorp refused to let Diana and her brother Charles return to London with Lady Althorp. Shortly afterwards, Lord Althorp won custody of Diana and her brother with support from his former mother-in-law, Ruth Roche, Baroness Fermoy. In 1972, Lord Althorp began a relationship with Raine, Countess of Dartmouth, the only daughter of Alexander McCorquodale and Dame Barbara Cartland. They married at Caxton Hall, London in 1976. Diana became known as "Lady" Diana after her father inherited the title of Earl Spencer in 1975, at which point her father moved the family from Park House to Althorp, the Spencer seat in Northampton.
Education and career.
Diana began her education at Silfield Private School in Gayton, Norfolk, and moved to Riddlesworth Hall School, an all-girls boarding school near Diss, when she was nine. She joined her sisters at West Heath Girls' School in Sevenoaks, Kent, in 1973. She did not shine academically, failing her O-levels twice. Her outstanding community spirit was recognised with an award from West Heath. She left West Heath when she was sixteen. Her brother Charles recalls her as being quite shy up until that time. She showed a talent for music as an accomplished pianist. Diana also excelled in swimming and diving, and studied ballet and tap dance.
After attending Institut Alpin Videmanette, a finishing school in Rougemont, Switzerland, for one term in 1978, Diana returned to London, where she shared her mother's flat with two school friends. In London, she took an advanced cooking course, but seldom cooked for her roommates. She took a series of low-paying jobs; she worked as a dance instructor for youth until a skiing accident caused her to miss three months of work. She then found employment as a playgroup pre-school assistant, did some cleaning work for her sister Sarah and several of her friends, and acted as a hostess at parties. Diana spent time working as a nanny for the Robertsons, an American family living in London, and worked as a nursery teacher at the Young England School in Pimlico. In July 1979, her mother bought her a flat at Coleherne Court in Earls Court as an 18th birthday present. She lived there with three flatmates until February 25, 1981.
Marriage to the Prince of Wales.
Diana first met Charles, Prince of Wales, in November 1977 when he and Diana's sister, Lady Sarah, were dating. He took a serious interest in her as a potential bride during the summer of 1980, when they were guests at a country weekend, where she watched him play polo. The relationship developed as he invited her for a sailing weekend to Cowes aboard the royal yacht "Britannia". This was followed by an invitation to Balmoral (the Royal Family's Scottish residence) to meet his family a weekend in November 1980. Lady Diana was well received by the Queen, the Duke of Edinburgh, and Queen Elizabeth The Queen Mother. The couple subsequently courted in London. The prince proposed on 6 February 1981, and Lady Diana accepted, but their engagement was kept secret for the next few weeks.
Engagement and wedding.
Their engagement became official on 24 February 1981. Lady Diana selected a large engagement ring consisting of 14 solitaire diamonds surrounding a 12-carat oval blue Ceylon sapphire set in 18-carat white gold, similar to her mother's engagement ring. The ring was made by the then Crown jewellers Garrard but, unusually for a ring for a member of the Royal Family, it was not unique; it was featured in Garrard's jewellery collection. In 2010 the ring became the engagement ring of Catherine, Duchess of Cambridge. It was copied by jewellers all over the world. The Queen Mother gave Lady Diana a sapphire and diamond brooch as an engagement present.
Following the engagement Lady Diana left her job at the nursery and lived at Clarence House, then home of the Queen Mother, for a short period. She then lived at Buckingham Palace until the wedding. Her first public appearance with Prince Charles was in a charity ball in March 1981 at Goldsmiths' Hall, where she met Princess Grace of Monaco.
Twenty-year-old Diana became Princess of Wales when she married the Prince of Wales on 29 July 1981 at St Paul's Cathedral, which offered more seating than Westminster Abbey, generally used for royal nuptials. Widely described as a "fairytale wedding", it was watched by a global television audience of 750 million while 600,000 people lined the streets to catch a glimpse of the couple en route to the ceremony.
At the altar, Diana accidentally reversed the order of Charles's first two names, saying "Philip Charles" Arthur George instead. She did not say that she would "obey" him; that traditional vow was left out at the couple's request, which caused some comment at the time. Diana wore a dress valued at £9,000 with a 25-foot (7.62-metre) train. Music and songs used during the wedding included the "Prince of Denmark's March", "I Vow to Thee, My Country", "Pomp and Circumstance No.4", and "God Save the Queen".
After becoming Princess of Wales, Diana automatically acquired rank as the third-highest female in the United Kingdom Order of Precedence (after the Queen and the Queen Mother), and was fifth or sixth in the orders of precedence of her other realms, following the Queen, the relevant viceroy, the Duke of Edinburgh, and the Prince of Wales. Within a few years of the wedding, the Queen extended Diana visible tokens of membership in the Royal Family; she lent the Princess a tiara and granted her the badge of the Royal Family Order of Queen Elizabeth II.
Children.
The couple made their homes at Kensington Palace and at Highgrove House, near Tetbury. On 5 November 1981, the Princess' first pregnancy was officially announced. After Diana fell down a staircase at Sandringham in January 1982, 12 weeks into her first pregnancy, the royal gynaecologist Sir George Pinker was summoned from London. He found that although she had suffered severe bruising, the foetus was uninjured. In the private Lindo Wing of St Mary's Hospital in Paddington, London, on 21 June 1982, under the care of Pinker, the Princess gave birth to her and the Prince's first son and heir, William Arthur Philip Louis. Amidst some media criticism, she decided to take William, still a baby, on her first major tours of Australia and New Zealand, but the decision was popularly applauded. By her own admission, the Princess of Wales had not initially intended to take William until it was suggested by Malcolm Fraser, the Australian prime minister.
A second son, Henry Charles Albert David, was born on 15 September 1984. The Princess asserted she and the Prince were closest during her pregnancy with Harry (as the younger prince has always been known). She was aware their second child was a boy, but did not share the knowledge with anyone else, including the Prince of Wales. Persistent suggestions that Harry's father is not Charles but James Hewitt, with whom Diana had an affair, have been based on alleged physical similarity between Hewitt and Harry. However, Harry had already been born by the time the affair between Hewitt and Diana began.
Diana gave her sons wider experiences than are usual for royal children. She rarely deferred to the Prince or to the Royal Family, and was often intransigent when it came to the children. She chose their first given names, dismissed a royal family nanny and engaged one of her own choosing, selected their schools and clothing, planned their outings, and took them to school herself as often as her schedule permitted. She also organised her public duties around their timetables.
Problems and separation.
Within five years of her marriage, the couple's incompatibility and age difference (almost 13 years), as well as Diana's concern about Charles's relationship with Camilla Parker Bowles, became visible and damaging to their marriage. During the early 1990s, the marriage of the Prince and Princess of Wales fell apart, an event at first suppressed, then sensationalised, by the world media. Both the Princess and Prince spoke to the press through friends, each blaming the other for the marriage's demise.
The chronology of the break-up identifies reported difficulties between the Prince and Princess as early as 1985. The Prince of Wales resumed his affair with his now-married former girlfriend, Camilla Parker Bowles; later, the Princess of Wales began a relationship with Major James Hewitt. These affairs were exposed in May 1992 with the publication of "Diana: Her True Story" by Andrew Morton. It was serialised in "The Sunday Times" before its publication. The book, which also laid bare the Princess' allegedly suicidal unhappiness, caused a media storm. During 1992 and 1993, leaked tapes of telephone conversations negatively reflected on both the royal antagonists. Tape recordings of the Princess and James Gilbey were made available by "The Sun" newspaper's hotline in August 1992. Transcripts of taped intimate conversations were published by "The Sun" in August 1992. The article's title, "Squidgygate", referenced Gilbey's affectionate nickname for Diana. The next to surface, in November 1992, were the leaked "Camillagate" tapes, intimate exchanges between the Prince of Wales and Camilla, published in "Today" and the "Daily Mirror".
In the meantime, rumours had begun to surface about the Princess of Wales's relationship with Hewitt, her and her children's former riding instructor. These would be brought into the open by the publication in 1994 of a 1994 book by Anna Pasternak titled "Princess in Love", which was filmed under the same title in a movie directed by David Greene in 1996. The Princess of Wales was portrayed by Julie Cox and James Hewitt was portrayed by Christopher Villiers.
In December 1992, Prime Minister John Major announced the couple's "amicable separation" to the House of Commons, and the full Camillagate transcript was published a month later in the newspapers, in January 1993. On 3 December 1993, the Princess of Wales announced her withdrawal from public life.
The Prince of Wales sought public understanding via a televised interview with Jonathan Dimbleby on 29 June 1994. In this he confirmed his own extramarital affair with Camilla Parker Bowles, saying that he had rekindled their association in 1986, only after his marriage to the Princess had "irretrievably broken down".
While she blamed Camilla Parker Bowles for her marital troubles because of her previous relationship with the Prince, the Princess at some point began to believe that he had other affairs. In October 1993, she wrote to a friend that she believed her husband was now in love with Tiggy Legge-Bourke and wanted to marry her. Legge-Bourke had been hired by the Prince as a young companion for his sons while they were in his care, and the Princess was resentful of Legge-Bourke and her relationship with the young princes.
Diana's aunt-in-law, Princess Margaret, Countess of Snowdon, burnt "highly personal" letters that Diana wrote to the Queen Mother in 1993 because she thought they were considered to be "so private". Biographer William Shawcross wrote: "No doubt Princess Margaret felt that she was protecting her mother and other members of the family". He considered Princess Margaret's action to be "understandable, although regrettable from a historical viewpoint".
Divorce.
The Princess of Wales was interviewed for the BBC current affairs show "Panorama" by journalist Martin Bashir; the interview was broadcast on 20 November 1995. Of her relationship with Hewitt, the Princess said to Bashir, "Yes, I adored him. Yes, I was in love with him. But I was very let down him." Referring to her husband's affair with Camilla Parker Bowles, she said, "Well, there were three of us in this marriage, so it was a bit crowded." Of herself, she said, "I'd like to be a queen of people's hearts." On the Prince of Wales' suitability for kingship, she stated, "Because I know the character I would think that the top job, as I call it, would bring enormous limitations to him, and I don't know whether he could adapt to that."
On 20 December 1995, Buckingham Palace publicly announced the Queen had sent letters to the Prince and Princess of Wales advising them to divorce. The Queen's move was backed by the Prime Minister and by senior Privy Counsellors, and, according to the BBC, was decided after two weeks of talks. Prince Charles formally agreed to the divorce in a written statement soon after. In February 1996, the Princess announced her agreement after negotiations with the Prince and representatives of the Queen, irritating Buckingham Palace by issuing her own announcement of the divorce agreement and its terms. In July 1996, the couple agreed on the terms of their divorce.
This followed shortly after the Princess' accusation that Tiggy Legge-Bourke had aborted the Prince's child, after which Legge-Bourke instructed Peter Carter-Ruck to demand an apology. Diana's secretary Patrick Jephson resigned shortly before the story broke, later writing that the Princess had "exulted in accusing Legge-Bourke of having had an abortion".
The divorce was finalised on 28 August 1996. Diana received a lump sum settlement of £17 million as well as £400,000 per year. The couple signed a confidentiality agreement that prohibited them from discussing the details of the divorce or of their married life.
Days before the decree absolute of divorce, Letters Patent were issued with general rules to regulate royal titles after divorce. As she was no longer married to the Prince of Wales, Diana lost the style "Her Royal Highness" and instead was styled "Diana, Princess of Wales". As the mother of the prince expected to one day ascend to the throne, she was accorded the same precedence she enjoyed during her marriage. Prince William was reported to have reassured his mother: "Don't worry, Mummy, I will give it back to you one day when I am King." Almost a year before, according to Tina Brown, the Duke of Edinburgh had warned the Princess of Wales: "If you don't behave, my girl, we'll take your title away." She is said to have replied: "My title is a lot older than yours, Philip."
Buckingham Palace stated the Princess of Wales was still a member of the Royal Family, as she was the mother of the second and third in line to the throne. This was confirmed by the Deputy Coroner of the Queen's Household, Baroness Butler-Sloss, after a pre-hearing on 8 January 2007: "I am satisfied that at her death, Diana, Princess of Wales continued to be considered as a member of the Royal Household." This appears to have been confirmed in the High Court judicial review matter of "Al Fayed & Ors v Butler-Sloss". In that case, three High Court judges accepted submissions that "the very name 'Coroner to the Queen's Household' gave the appearance of partiality in the context of inquests into the deaths of two people, one of whom was a member of the Royal Family and the other was not."
Royal duties.
Public appearances.
The Princess of Wales attended the State Opening of Parliament for the first time on 4 November 1981. She attended the Trooping the Colour for the first time in June 1982, making her appearance on the balcony of Buckingham Palace afterwards. Also in 1982, Diana accompanied the Prince of Wales to the Netherlands and was created a Grand Cross of the Order of the Crown by Queen Beatrix of the Netherlands. In 1983, she accompanied the Prince on a tour of Australia and New Zealand with Prince William, where they met with representatives of the Māori people.
Their visit to Canada in June and July 1983 included a trip to Edmonton to open the 1983 Summer Universiade and a stop in Newfoundland to commemorate the 400th anniversary of that island's acquisition by the Crown.
In April 1985, the Prince and Princess of Wales visited Italy, and were later joined by Princes William and Harry. They met with President Alessandro Pertini. Their visit to the Holy See included a private audience with Pope John Paul II. In November 1985, the couple visited the United States, meeting President Ronald Reagan and First Lady Nancy Reagan at the White House. 1986 was a busy year for Diana. With the Prince of Wales she embarked on a tour of Japan, Indonesia, Spain, and Canada. In Canada they visited Expo 86.
In February 1987, the Prince and Princess of Wales visited Portugal. The visit coincided with the anniversary of the signing of the Treaty of Windsor (1386). A banquet was held at the Ajuda National Palace. In 1987, they visited Germany and France. In 1988, the Prince and Princess of Wales visited Thailand and toured Australia for the bicentenary celebrations. In 1989, they visited the Arab States of the Persian Gulf. The tour began in Kuwait, where they met with Emir Jaber Al-Ahmad Al-Sabah and the Crown Prince and Prime Minister Saad Al-Salim Al-Sabah. Diana was presented with gifts, including an elaborate embroidered Bedouin gown. The couple also visited Oman, Saudi Arabia, and United Arab Emirates.
In March 1990, she and the Prince of Wales toured Nigeria and Cameroon. The President of Cameroon hosted an official dinner to welcome them in Yaoundé. In May 1990, they visited Hungary for four days. They attended a dinner hosted by interim President Árpád Göncz and viewed a fashion display at the Museum of Applied Arts in Budapest. In November 1990, the royal couple went to Japan to attend the enthronement of Emperor Akihito. In 1991, the Princess and Prince of Wales visited Queen's University in Kingston, Ontario, where they presented the university with a replica of their royal charter. In September 1991, the Princess visited Pakistan on a solo trip, and went to Brazil with Charles. During their tour in Brazil, Diana visited the orphanage and an Aids Treatment Centre for children and met the Brazilian President Fernando Collor de Mello and First Lady Rosane Collor in Brasília. Her final trips with Charles were to India and South Korea in 1992.
In 1992, the Princess of Wales visited Egypt. She was invited to stay at the British Ambassador's villa. She met with President Hosni Mubarak and toured some of the country's archaeological sites with the Egyptian archaeologist Zahi Hawass.
In February 1995, the Princess visited Japan. She paid formal visits to Emperor Akihito, Empress Michiko, Crown Prince Naruhito, and Crown Princess Masako. She visited a daycare centre for children with learning difficulties, the Yokohama War Cemetery, and the National Children's Hospital, where she gave the opening line of her speech in Japanese. In June 1995, Diana went to Venice to visit the Venice Biennale art festival. In November 1995, the Princess undertook a four-day trip to Argentina and met with President Carlos Menem and his daughter, Zulemita, for lunch. The Princess visited many other countries, including Belgium, Nepal, Switzerland, and Zimbabwe. Her final official engagement was a visit to Northwick Park Hospital, London, on 21 July 1997.
Charity work and patronage.
In 1983 she confided in the then-Premier of Newfoundland, Brian Peckford, "I am finding it very difficult to cope with the pressures of being Princess of Wales, but I am learning to cope with it." As Princess of Wales, she was expected to make regular public appearances at hospitals, schools, and other facilities, in the 20th century model of royal patronage. From the mid-1980s, she became increasingly associated with numerous charities. She carried out 191 official engagements in 1988 and 397 in 1991. The Princess developed an intense interest in serious illnesses and health-related matters outside the purview of traditional royal involvement, including AIDS and leprosy.
In addition to health-related matters, Diana's extensive charity work included campaigning for animal protection and her fight against the use of landmines. She was the patroness of charities and organisations working with the homeless, youth, drug addicts, and the elderly. From 1989, she was president of Great Ormond Street Hospital for Children. From 1991 to 1996, she was a patron of Headway, a brain injury association. She was patron of Natural History Museum and president of Royal Academy of Music. From 1984 to 1996, she was president of Barnardo's, a charity founded by Dr. Thomas John Barnardo in 1866 to care for vulnerable children and young people. In 1988, she became patron of the British Red Cross and supported its organisations in other countries such as Australia and Canada. In 1992, she became the first patron of Chester Childbirth Appeal, a charity that she had supported since 1984. The charity, which is named after one of Diana's royal titles, could raise over £1 million with her help.
Her patronages also included Landmine Survivors Network, Help the Aged, the Trust for Sick Children in Wales, the National Hospital for Neurology and Neurosurgery, the British Lung Foundation, the National AIDS Trust, Eureka!, the National Children's Orchestra, Royal Brompton Hospital, British Red Cross Youth, Relate Marriage Counselors, the Guinness Trust, Meningitis Trust, Dove House, the Malcolm Sargent Cancer Fund for Children, the Royal School for the Blind, Welsh National Opera, the Pre-School Playgroups Association, the Variety Club of New Zealand, Birthright, and the British Deaf Association. She made several lengthy visits each week to Royal Brompton Hospital, where she worked to comfort seriously ill or dying patients. She visited Mother Teresa's hospice in Kolkata, India, in 1992, and the two women developed a personal relationship.
In June 1995, the Princess made a brief trip to Moscow, where she visited a children’s hospital that she had previously supported through her charity work. Diana presented the hospital with medical equipment. During her time in the Russian capital, she was awarded the international Leonardo prize, which is given to the most distinguished patrons and people in the arts, medicine, and sports. In December 1995, Diana received the United Cerebral Palsy Humanitarian of the Year Award in New York City for her philanthropic efforts. In October 1996, for her works on the elderly, the Princess received a gold medal at a health care conference organised by the Pio Manzù Centre in Rimini, Italy.
The day after her divorce, she announced her resignation from over 100 charities to spend more time with only six: Centrepoint, English National Ballet, Great Ormond Street Hospital, The Leprosy Mission, National AIDS Trust, and the Royal Marsden Hospital. She continued her work with the British Red Cross Anti-Personnel Land Mines Campaign, but was no longer listed as patron.
In May 1997, the Princess opened the Richard Attenborough Centre for Disability and the Arts in Leicester, after being asked by her friend Richard Attenborough. In June 1997, her dresses and suits were sold at Christie's auction houses in London and New York, and the proceeds that were earned from these events were donated to charities.
Areas of work.
Leprosy.
In November 1989, the Princess visited a leprosy hospital in Indonesia. She became patron of the Leprosy Mission, an organization dedicated to providing medicine, treatment, and other support services to those who are afflicted with the disease. She remained the patron of this charity until her death in 1997, and visited several of its hospitals around the world. "It has always been my concern to touch people with leprosy, trying to show in a simple action that they are not reviled, nor are we repulsed," she commented. The Diana Princess of Wales Health Education and Media Centre in Noida, India, was opened in her honour in November 1999, funded by the Diana Princess of Wales Memorial Fund.
HIV/AIDS.
The Princess began her work with AIDS victims in the 1980s. In 1989, she opened Landmark Aids Centre in South London. She was not adverse to making physical contact with AIDS patients, though it was still unknown whether the disease could be spread that way. In São Paulo, Brazil, in 1991, she was photographed holding a baby with AIDS. Diana noted: "HIV does not make people dangerous to know. You can shake their hands and give them a hug. Heaven knows they need it." To Diana's disappointment, the Queen did not support this type of charity work, suggesting she get involved in "something more pleasant". In October 1990, Diana opened Grandma's House, a home for young AIDS victims in Washington, D.C. As the patron of Turning Point, a health and social care organization, Diana visited its project in London for people with HIV/AIDS in 1992.
In March 1997, Diana visited South Africa, where she met with President Nelson Mandela. On 2 November 2002, Mandela announced that the Nelson Mandela Children's Fund would be teaming up with the Diana, Princess of Wales Memorial Fund to help victims of AIDS. "When she stroked the limbs of someone with leprosy, or sat on the bed of a man with HIV/AIDS and held his hand, she transformed public attitudes and improved the life chances of such people," Mandela said about the late Princess. "People felt if a British princess can go to a ward with HIV patients, then there's nothing to be superstitious about."
Landmines.
Diana was the patron of HALO Trust. In January 1997, pictures of Diana touring an Angolan minefield in a ballistic helmet and flak jacket were seen worldwide. It was during this campaign that some accused her of meddling in politics and declared her a 'loose cannon'. From 7 to 10 August 1997, just days before her death, she visited Bosnia and Herzegovina with Jerry White and Ken Rutherford of the Landmine Survivors Network.
Her work on the landmines issue has been described as influential in the signing of the Ottawa Treaty, which created an international ban on the use of anti-personnel landmines. Introducing the Second Reading of the Landmines Bill 1998 to the British House of Commons, the Foreign Secretary, Robin Cook, paid tribute to Diana's work on landmines:All Honourable Members will be aware from their postbags of the immense contribution made by Diana, Princess of Wales to bringing home to many of our constituents the human costs of landmines. The best way in which to record our appreciation of her work, and the work of NGOs that have campaigned against landmines, is to pass the Bill, and to pave the way towards a global ban on landmines.
Carol Bellamy, Executive Director of the United Nations Children's Fund (UNICEF), said that landmines remained "a deadly attraction for children, whose innate curiosity and need for play often lure them directly into harm's way". She urged countries which produce and stockpile the largest numbers of landmines (United States, China, India, North Korea, Pakistan, and Russia) to sign the treaty. A few months after Diana's death in 1997, the International Campaign to Ban Landmines won the Nobel Peace Prize.
Homelessness.
Diana was a long-standing and active supporter of Centrepoint, a charity which provides accommodation and support to homeless people, and became patron in 1992. She supported organisations that battle poverty and homelessness. "We, as a part of society, must ensure that young people – who are our future – are given the chance they deserve," she said.
Personal life after divorce.
After the divorce, Diana retained her double apartment on the north side of Kensington Palace which she had shared with the Prince of Wales since the first year of their marriage, and it remained her home until her death. She continued to use two offices at St. James's Palace.
Diana dated the British-Pakistani heart surgeon Hasnat Khan, who was called "the love of her life" after her death by many of her closest friends. In May 1996, Diana visited Lahore upon invitation of Imran Khan, a relative of Hasnat Khan, and visited the latter's family in secret. Khan was intensely private and the relationship was conducted in secrecy, with Diana lying to members of the press who questioned her about it. Their relationship lasted almost two years with differing accounts of who ended it. According to Khan's testimonial at the inquest for her death, it was Diana who ended their relationship in a late-night meeting in Hyde Park, which adjoins the grounds of Kensington Palace, in June 1997.
Within a month Diana had begun seeing Dodi Fayed, son of her host that summer, Mohamed Al-Fayed. Diana had considered taking her sons that summer on a holiday to the Hamptons on Long Island, New York, but security officials had prevented it. After deciding against a trip to Thailand, she accepted Fayed's invitation to join his family in the south of France, where his compound and large security detail would not cause concern to the Royal Protection squad. Mohamed Al-Fayed bought the "Jonikal", a 60-metre multimillion-pound yacht on which to entertain Diana and her sons.
Death.
On 31 August 1997, Diana was fatally injured in a car crash in the Pont de l'Alma road tunnel in Paris, which also caused the deaths of her companion Dodi Fayed and the driver, Henri Paul, acting security manager of the Hôtel Ritz Paris. The funeral saw the British television audience peak at 32.10 million, one of the United Kingdom's highest viewing figures ever, while millions more watched the event around the world.
Conspiracy theories, inquest and verdict.
The initial French judicial investigation concluded the accident was caused by Paul's drunken loss of control. In February 1998, Mohamed Al-Fayed, owner of the Paris Ritz where Paul had worked, publicly maintained that the crash had been planned, accusing MI6 and the Duke of Edinburgh. An inquest in London starting in 2004 and continued in 2007–08 attributed the accident to grossly negligent driving by Paul and to the pursuing paparazzi. On 7 April 2008, the jury returned a verdict of 'unlawful killing'. The day following the final verdict of the inquest, Al-Fayed announced he would end his 10-year campaign to establish that it was murder rather than an accident, stating that he did so for the sake of the princess's children.
Tribute, funeral, and burial.
The sudden and unexpected death of an extraordinarily popular royal figure brought statements from senior figures worldwide and many tributes by members of the public. People left public offerings of flowers, candles, cards, and personal messages outside Kensington Palace for many months. Her coffin, draped with the royal flag, was brought to London from Paris by Prince Charles and Diana's two sisters on 31 August 1997. After being taken to a private mortuary it was placed in the Chapel Royal, St. James's Palace.
Diana's funeral took place in Westminster Abbey on 6 September. The previous day Queen Elizabeth II had paid tribute to her in a live television broadcast. Her sons walked in the funeral procession behind her coffin, along with the Prince of Wales, the Duke of Edinburgh, Diana's brother Charles Spencer, 9th Earl Spencer, and representatives of some of her charities. Lord Spencer said of his sister, "She proved in the last year that she needed no royal title to continue to generate her particular brand of magic." Re-written in tribute to Diana, "Candle in the Wind" was performed by Elton John at the funeral service (the only occasion the song has been performed live). Released as a single in 1997, the global proceeds from the song have gone to Diana's charities.
The burial occurred privately later the same day. Diana's former husband, sons, mother, siblings, a close friend, and a clergyman were present. Diana's body was clothed in a black long-sleeved dress designed by Catherine Walker, which she had chosen some weeks before. A set of rosary beads was placed in her hands, a gift she had received from Mother Teresa, who died the same week as Diana. Her grave is on an island () within the grounds of Althorp Park, the Spencer family home for centuries.
The burial party was provided by the 2nd Battalion The Princess of Wales's Royal Regiment, who were given the honour of carrying the Princess across to the island and laying her to rest. Diana was the Regiment's Colonel-in-Chief from 1992 to 1996. The original plan was for Diana to be buried in the Spencer family vault at the local church in nearby Great Brington, but Lord Spencer said that he was concerned about public safety and security and the onslaught of visitors that might overwhelm Great Brington. He decided that Diana would be buried where her grave could be easily cared for and visited in privacy by William, Harry, and other Spencer relatives.
Later events.
Following Diana's death, the Diana, Princess of Wales Memorial Fund was granted intellectual property rights over her image. In 1998, the fund sued the Franklin Mint, accusing it of illegally selling Diana dolls, plates, and jewellery after having been refused a license to do so. In California, where the initial case was tried, a suit to preserve the right of publicity may be filed on behalf of a dead person, but only if that person is a Californian. The Memorial Fund therefore filed the lawsuit on behalf of the estate and, upon losing the case, was required to pay the Franklin Mint's legal costs of £3 million which, combined with other fees, caused the Memorial Fund to freeze its grants to charities. In 2003, the Franklin Mint counter-sued. In November 2004, the case was settled out of court with the Memorial Fund agreeing to pay £13.5 million (US$21.5 million) to charitable causes on which both sides agreed. In addition to this, the Memorial Fund had spent a total of close to £4 million (US$6.5 million) in costs and fees relating to this litigation, and as a result froze grants allocated to a number of charities.
On 13 July 2006, Italian magazine "Chi" published photographs showing Diana amid the wreckage of the car crash, despite an unofficial blackout on such photographs being published. The editor of "Chi" defended his decision by saying he published the photographs simply because they had not been previously seen, and he felt the images are not disrespectful to the memory of Diana.
The Concert for Diana at Wembley Stadium was held on 1 July 2007. The event, organised by the Princes William and Harry, celebrated the 46th anniversary of their mother's birth and occurred a few weeks before the 10th anniversary of her death on 31 August. The proceeds that were earned from this event were donated to Diana's charities. On 31 August 2007, a memorial service for Diana took place in the Guards Chapel. Guests included members of the royal family and their relatives, members of the Spencer family, members of Diana's wedding party, Diana's close friends and aides, representatives from many of her charities, British politicians Gordon Brown, Tony Blair, and John Major, and friends from the entertainment world such as David Frost, Elton John, and Cliff Richard.
In 2013, a previously unseen photograph of the then already officially engaged Diana was put up for auction. The picture belonged to the "Daily Mirror" newspaper, and has "Not to be published" written on it. In it, a young Diana has her head in the lap of an unidentified man.
On 19 March 2013, ten of Diana's dresses, including a midnight blue velvet gown she wore to a 1985 state dinner at the White House when she famously danced with John Travolta (which became known as the Travolta dress), raised over £800,000 at auction in London.
Legacy.
From her engagement to the Prince of Wales in 1981 until her death in 1997, Diana was a major presence on the world stage, often described as the "world's most photographed woman". She was noted for her compassion, style, charisma, and high-profile charity work, as well as her difficult marriage to the Prince of Wales. Her peak popularity rate in the United Kingdom between 1981 and 2012 was 47%.
She was a fashion icon whose style was emulated by women around the world. Iain Hollingshead of "The Telegraph" writes: " had an ability to sell clothes just by looking at them." An early example of the effect occurred during her courtship with Charles in 1980 when sales of Hunters Wellington boots skyrocketed after she was pictured wearing a pair on the Balmoral estate.
In 1999, "TIME" named Diana one of the . In 2002, Diana was ranked third on the BBC's poll of the 100 Greatest Britons, outranking the Queen and other British monarchs. In 2004, "People" cited her as one of the all-time most beautiful women.
Memorials.
Immediately after her death, many sites around the world became briefly "ad hoc" memorials to Diana where the public left flowers and other tributes. The largest was outside the gates of Kensington Palace, where people continue to leave flowers and tributes. Permanent memorials include:
The Flame of Liberty, erected in 1989 on the Place de l'Alma in Paris above the entrance to the tunnel in which the fatal crash occurred, has become an unofficial memorial to Diana. In addition, there are two memorials inside Harrods department store, commissioned by Dodi Fayed's father, who owned the store from 1985 to 2010. The first memorial is a pyramid-shaped display containing photos of the princess and al-Fayed's son, a wine glass said to be from their last dinner, and a ring purchased by Dodi the day prior to the crash. The second, "Innocent Victims", unveiled in 2005, is a bronze statue of Fayed dancing with Diana on a beach beneath the wings of an albatross.
In 1998, Azermarka issued postage stamps commemorating Diana in Azerbaijan. The English text on souvenir sheets issued reads "DIANA, PRINCESS OF WALES The Princess that captured people's hearts (1961–1997)". Several other countries issued commemorative stamps that year, including Great Britain, Somalia, and Congo. HayPost also issued a postage stamp commemorating Diana in Armenia at the same year.
In February 2013, OCAD University in Toronto, Canada, announced that its new 25,000 square foot arts center would be named the Princess of Wales Visual Arts Centre. Princess Diana Drive was named in her memory in Trenton, New Jersey. Diana's granddaughter, Charlotte Elizabeth Diana, born in 2015, is named after her.
Diana in contemporary art.
Diana has been depicted in contemporary art before and after her death. The first biopics about Diana and Charles were "Charles and Diana: A Royal Love Story" and "The Royal Romance of Charles and Diana" that were broadcast on American TV channels on 17 and 20 September 1981, respectively. In December 1992, ABC aired "Charles and Diana: Unhappily Ever After", a TV movie about marital discord between Diana and Charles. In the 1990s, British magazine "Private Eye" called her "Cheryl" and Prince Charles "Brian". Some of the artworks after her death have referenced the conspiracy theories, as well as paying tribute to Diana's compassion and acknowledging her perceived victimhood.
In July 1999, Tracey Emin created a number of monoprint drawings featuring textual references about Diana's public and private life for "Temple of Diana", a themed exhibition at The Blue Gallery, London. Works such as "They Wanted You To Be Destroyed" (1999) related to Diana's bulimia, while others included affectionate texts such as "Love Was on Your Side" and Diana's "Dress with puffy sleeves". Another text praised her selflessness – "The things you did to help other people", showing Diana in protective clothing walking through a minefield in Angola – while another referenced the conspiracy theories. Of her drawings, Emin maintained "They're quite sentimental ... and there's nothing cynical about it whatsoever."
In 2005, Martín Sastre premiered during the Venice Biennale the film "". This fictional work starts with the world discovering Diana alive and enjoying a happy undercover new life in a dangerous cantegril on the outskirts of Montevideo. Shot at an Uruguayan slum using a Diana impersonator from São Paulo, the film was selected by the Italian Art Critics Association as one of the Venice Biennial's best works.
In 2007, following an earlier series referencing the conspiracy theories, Stella Vine created a series of Diana paintings for her first major solo exhibition at Modern Art Oxford gallery. Vine intended to portray Diana's combined strength and vulnerability as well as her closeness to her two sons. The works, all completed in 2007, included "Diana branches", "Diana family picnic", "Diana veil", "Diana crash" and "Diana pram", which incorporates the quotation "I vow to thee my country". Vine asserted her own abiding attraction to "the beauty and the tragedy of Diana's life".
The 2007 docudrama "" details the final two months of her life. She is portrayed by Irish actress Genevieve O'Reilly. On an October 2007 episode of "The Chaser's War on Everything", Andrew Hansen mocked Diana in his "Eulogy Song", which immediately created considerable controversy in the Australian media.
Titles, styles, honours and arms.
Titles and styles.
Posthumously, as in life, she is most popularly referred to as "Princess Diana", a title not formally correct and one she never held. She is still sometimes referred to in the media as "Lady Diana Spencer" or simply as "Lady Di". In a speech after her death, then-Prime Minister Tony Blair referred to Diana as the "People's Princess".
Honours.
Honorary military appointments.
The Princess of Wales held the following military appointments:
She gave up these appointments following her divorce.
Ancestry.
Diana was born into the British noble Spencer family, different branches of which currently hold the titles of Duke of Marlborough, Earl Spencer, Earls of Sunderland, and Viscount Churchill. The Spencers claimed descent from a cadet branch of the powerful medieval Despenser family, but its validity is still being questioned. Her great-grandmother was Margaret Baring, a member of the German-British Baring family of bankers and the daughter of Edward Baring, 1st Baron Revelstoke. Diana's distant noble ancestors included John Churchill, 1st Duke of Marlborough and Prince of Mindelheim and his wife Sarah, Duchess of Marlborough. Diana and Charles were distantly related, as they were both descended from the House of Tudor through Henry VII of England. She was also descended from the House of Stuart through James II of England.
Diana's American roots came from her great-grandmother Frances Ellen Work, daughter of wealthy American stockbroker Franklin H. Work from Ohio, who was married to her great-grandfather James Roche, 3rd Baron Fermoy. Diana's fourth great-grandmother in her direct maternal line, Eliza Kewark, whose daughter was fathered by Theodore Forbes, is variously described in contemporary documents as "a dark-skinned native woman", "an Armenian woman from Bombay", and "Mrs. Forbesian". Genealogist William Addams Reitwiesner assumed she was Armenian. In June 2013, BritainsDNA announced that genealogical DNA tests on two of Diana's distant cousins in the same direct maternal line confirm that Eliza Kewark was of Indian descent.

</doc>
<doc id="24096" url="https://en.wikipedia.org/wiki?curid=24096" title="Plough">
Plough

A plough (UK) or plow (US; both ) is a tool or Farm implement used in farming for initial cultivation of soil in preparation for sowing seed or planting to loosen or turn the soil. Ploughs are traditionally drawn by working animals such as horses or cattle, but in modern times may be drawn by tractors. A plough may be made of wood, iron, or steel frame with an attached blade or stick used to cut the earth. It has been a basic instrument for most of recorded history, although written references to the plough do not appear in English until 1100 CE at which point it is referenced frequently. The plough represents one of the major advances in agriculture.
The primary purpose of ploughing is to turn over the upper layer of the soil, bringing fresh nutrients to the surface, while burying weeds and the remains of previous crops and allowing them to break down. As the plough is drawn through the soil it creates long trenches of fertile soil called furrows. In modern use, a ploughed field is typically left to dry out, and is then harrowed before planting. Plowing and cultivating a soil homogenizes and modifies the upper 12 to 25 cm of the soil to form a plow layer. In many soils, the majority of fine plant feeder roots can be found in the topsoil or plow layer.
Ploughs were initially human powered, but the process became considerably more efficient once animals were pressed into service. The first animal powered ploughs were undoubtedly pulled by oxen, and later in many areas by horses (generally draft horses) and mules, although various other animals have been used for this purpose. In industrialised countries, the first mechanical means of pulling a plough were steam-powered (ploughing engines or steam tractors), but these were gradually superseded by internal-combustion-powered tractors.
Modern competitions take place for ploughing enthusiasts like the National Ploughing Championships in Ireland. Use of the plough has decreased in some areas, often those significantly threatened by soil damage and erosion, in favour of shallower ploughing and other less invasive conservation tillage techniques.
Natural farming methods are emerging that do not involve any ploughing at all, unless an initial ploughing is necessary to break up hardpan on a new plot to be cultivated, so that the newly introduced soil life can penetrate and develop more quickly and deeply. By not ploughing, beneficial fungi and microbial life can develop that will eventually bring air into the soil, retain water and build up nutrients. A healthy soil full of active fungi and microbial life, combined with a diverse crop (making use of companion planting), suppresses weeds and pests naturally and retains rainwater. Thus the intensive use of water-, oil- and energy hungry irrigation, fertilizers and herbicides are avoided. Cultivated land becomes more fertile and productive over time, while tilled land tends to go down in productivity over time due to erosion and the removal of nutrients with every harvest. Proponents of permaculture claim that it is the only way of farming that can be maintained when fossil fuel runs out. On the other hand, the advantage of agricultural methods that require repeated ploughing are that they allow monocropping on a large scale at remote locations, using industrial machinery rather than human labor.
Etymology.
In older English, as in other Germanic languages, the plough was traditionally known by other names, e.g. Old English "sulh", Old High German "medela", "geiza", "huohilī(n)", Old Norse "arðr" (Swedish "årder"), and Gothic "hōha", all presumably referring to the ard (scratch plough). The term plough or plow, as used today, was not common until 1700 CE.
The modern word "plough" comes from Old Norse "plógr", and therefore Germanic, but it appears relatively late (it is not attested in Gothic), and is thought to be a loanword from one of the north Italic languages. Words with the same root appeared with related meanings: in Raetic "plaumorati" "wheeled heavy plough" (Pliny, "Nat. Hist." 18, 172), and in Latin "plaustrum" "farm cart", "plōstrum, plōstellum" "cart", and "plōxenum, plōximum" "cart box". The word must have originally referred to the wheeled heavy plough, which was common in Roman northwestern Europe by the 5th century.
Orel (2003) tentatively attaches "plough" to a PIE stem *"blōkó-", which gave Armenian "peɫem" "to dig" and Welsh "bwlch" "crack", though the word may not be of Indo-European origin.
Parts.
The diagram ("right") shows the basic parts of the modern plough:
Other parts not shown or labelled include the frog (or frame), runner, landside, shin, trashboard, and stilts (handles).
On modern ploughs and some older ploughs, the mouldboard is separate from the share and runner, so these parts can be replaced without replacing the mouldboard. Abrasion eventually destroys all parts of a plough that come into contact with the soil.
History.
Hoeing.
When agriculture was first developed, simple hand-held digging sticks and hoes were used in highly fertile areas, such as the banks of the Nile where the annual flood rejuvenates the soil, to create drills (furrows) to plant seeds in. Digging sticks, hoes, and mattocks were not invented in any one place, and hoe-cultivation must have been common everywhere agriculture was practiced. Hoe-farming is the traditional tillage method in tropical or sub-tropical regions, which are characterized by stony soils, steep slope gradients, predominant root crops, and coarse grains grown at wide distances apart. While hoe-agriculture is best suited to these regions, it is used in some fashion everywhere. Instead of hoeing, some cultures use pigs to trample the soil and grub the earth.
Ard.
Some ancient hoes, like the Egyptian "mr", were pointed and strong enough to clear rocky soil and make seed drills, which is why they are called "hand-ards". However, the domestication of oxen in Mesopotamia and the Indus valley civilization, perhaps as early as the 6th millennium , provided mankind with the draft power necessary to develop the larger, animal-drawn true ard (or scratch plough). The earliest was the "bow ard", which consists of a "draft-pole" (or "beam") pierced by a thinner vertical pointed stick called the "head" (or "body"), with one end being the "stilt" (handle) and the other a "share" (cutting blade) that was dragged through the topsoil to cut a shallow furrow ideal for most cereal crops. The ard does not clear new land well, so hoes or mattocks must be used to pull up grass and undergrowth, and a hand-held, coulter-like "ristle" could be used to cut deeper furrows ahead of the share. Because the ard leaves a strip of undisturbed earth between the furrows, the fields are often cross-ploughed lengthwise and across, and this tends to form squarish fields (Celtic fields). The ard is best suited to loamy or sandy soils that are naturally fertilized by annual flooding, as in the Nile Delta and Fertile Crescent, and to a lesser extent any other cereal-growing region with light or thin soil. By the late Iron Age, ards in Europe were commonly fitted with coulters.
Mouldboard plough.
To grow crops regularly in less fertile areas, the soil must be turned to bring nutrients to the surface. A major advance for this type of farming was the turnplough, also known as the mouldboard plough (UK), moldboard plow (US), or frame-plough. A "coulter" (or "skeith") could be added to cut vertically into the ground just ahead of the "share" (in front of the "frog"), a wedge-shaped cutting edge at the bottom front of the "mouldboard" with the landside of the frame supporting the undershare (below-ground component).
The upper parts of the frame carry (from the front) the coupling for the motive power (horses), the coulter and the landside frame. Depending on the size of the implement, and the number of furrows it is designed to plough at one time, a forecarriage with a wheel or wheels (known as a furrow wheel and support wheel) may be added to support the frame (wheeled plough). In the case of a single-furrow plough there is only one wheel at the front and handles at the rear for the ploughman to steer and manoeuvre it.
When dragged through a field the coulter cuts down into the soil and the share cuts horizontally from the previous furrow to the vertical cut. This releases a rectangular strip of sod that is then lifted by the share and carried by the mouldboard up and over, so that the strip of sod (slice of the topsoil) that is being cut lifts and rolls over as the plough moves forward, dropping back to the ground upside down into the furrow and onto the turned soil from the previous run down the field. Each gap in the ground where the soil has been lifted and moved across (usually to the right) is called a "furrow". The sod that has been lifted from it rests at about a 45 degree angle in the next-door furrow and lies up the back of the sod from the previous run.
In this way, a series of ploughing runs down a field leaves a row of sods that lie partly in the furrows and partly on the ground lifted earlier. Visually, across the rows, there is the land (unploughed part) on the left, a furrow (half the width of the removed strip of soil) and the removed strip almost upside-down lying on about half of the previous strip of inverted soil, and so on across the field. Each layer of soil and the gutter it came from forms the classic furrow.
The mouldboard plough greatly reduced the amount of time needed to prepare a field, and as a consequence, allowed a farmer to work a larger area of land. In addition, the resulting pattern of low (under the mouldboard) and high (beside it) ridges in the soil forms water channels, allowing the soil to drain. In areas where snow buildup is an issue, this lets farmers plant the soil earlier, as the snow runoff drains away more quickly.
There are five major parts of a mouldboard plough:
A "runner" extending from behind the share to the rear of the plough controls the direction of the plough, because it is held against the bottom land-side corner of the new furrow being formed. The holding force is the weight of the sod, as it is raised and rotated, on the curved surface of the mouldboard. Because of this runner, the mouldboard plough is harder to turn around than the scratch plough, and its introduction brought about a change in the shape of fields — from mostly square fields into longer rectangular "strips" (hence the introduction of the furlong).
An advance on the basic design was the "iron ploughshare", a replaceable horizontal cutting surface mounted on the tip of the share. The earliest ploughs with a detachable and replaceable share date from around 1000 BC in the Ancient Near East, and the earliest iron ploughshares from ca. 500 BC in China. Early mouldboards were basically wedges that sat inside the cut formed by the coulter, turning over the soil to the side. The ploughshare spread the cut horizontally below the surface, so when the mouldboard lifted it, a wider area of soil was turned over. Mouldboards are known in Britain from the late 6th century on.
Loy ploughing.
Loy ploughing was a form of manual ploughing in Ireland, on very small farms — or on very hilly ground, where horses could not work or where farmers could not afford them. It was used up until the 1960s in poorer land. This suited the moist climate of Ireland, as the trenches formed by turning in the sods providing drainage. It also allowed the growing of potatoes in bogs as well as on mountain slopes where no other cultivation could take place.
Heavy ploughs.
In the basic mouldboard plough the depth of the cut is adjusted by lifting against the runner in the furrow, which limited the weight of the plough to what the ploughman could easily lift. This limited the construction to a small amount of wood (although metal edges were possible). These ploughs were fairly fragile, and were not suitable for breaking up the heavier soils of northern Europe. The introduction of wheels to replace the runner allowed the weight of the plough to increase, and in turn allowed the use of a much larger mouldboard faced in metal. These "heavy ploughs" led to greater food production and eventually a significant population increase around 600 AD. 
Before the Han Dynasty (202 BC – 220 AD), Chinese ploughs were made almost entirely of wood, except the iron blade of the ploughshare. By the Han period, the entire ploughshare was made of cast iron; these are the first known heavy mouldboard iron ploughs.
The Romans achieved the heavy wheeled mouldboard plough in the late 3rd and 4th century AD, when archaeological evidence appears, inter alia, in Roman Britain. The first indisputable appearance after the Roman period is from 643, in a northern Italian document. Old words connected with the heavy plough and its use appear in Slavic, suggesting possible early use in this region. The general adoption of the carruca heavy plough in Europe appears to have accompanied the adoption of the three-field system in the later eighth and early ninth centuries, leading to an improvement of the agricultural productivity per unit of land in northern Europe. This was accompanied by larger fields as well, known variously as carucates, ploughlands, and ploughgates.
Improved designs.
The basic plough, with coulter, ploughshare and mouldboard remained in use for a millennium. Major changes in design did not become common until the Age of Enlightenment, when there was rapid progress in design. Joseph Foljambe in Rotherham, England, in 1730 used new shapes as the basis for the Rotherham plough, which also covered the mouldboard with iron. Unlike the heavy plough, the Rotherham (or Rotherham swing) plough consisted entirely of the coulter, mouldboard and handles. It was much lighter than conventional designs and became very popular in England. It may have been the first plough to be widely built in factories and the first to be commercially successful.
In 1789 Robert Ransome, an iron founder in Ipswich started casting ploughshares in a disused malting at St Margaret's Ditches. As a result of a mishap in his foundry, a broken mould caused molten metal to come into contact with cold metal, making the metal surface extremely hard — chilled casting — which he advertised as "self sharpening" ploughs, and received patents for his discovery.
James Small further advanced the design. Using mathematical methods he experimented with various designs until he arrived at a shape cast from a single piece of iron, an improvement on the "Scots plough" of James Anderson of Hermiston. A single-piece cast iron plough was also developed and patented by Charles Newbold in the United States. This was again improved on by Jethro Wood, a blacksmith of Scipio, New York, who made a three-part Scots Plough that allowed a broken piece to be replaced. In 1837 John Deere introduced the first steel plough; it was so much stronger than iron designs that it could work soil in areas of the US that had previously been considered unsuitable for farming.
Improvements on this followed developments in metallurgy: steel coulters and shares with softer iron mouldboards to prevent breakage, the chilled plough (an early example of surface-hardened steel), and eventually the face of the mouldboard grew strong enough to dispense with the coulter.
Single-sided ploughing.
The first mouldboard ploughs could only turn the soil over in one direction (conventionally always to the right), as dictated by the shape of the mouldboard, and so the field had to be ploughed in long strips, or "lands". The plough was usually worked clockwise around each land, ploughing the long sides and being dragged across the short sides without ploughing. The length of the strip was limited by the distance oxen (or later horses) could comfortably work without a rest, and their width by the distance the plough could conveniently be dragged. These distances determined the traditional size of the strips: a furlong, (or "furrow's length", ) by a chain () — an area of one acre (about 0.4 hectares); this is the origin of the acre. The one-sided action gradually moved soil from the sides to the centre line of the strip. If the strip was in the same place each year, the soil built up into a ridge, creating the ridge and furrow topography still seen in some ancient fields.
Turnwrest plough.
The turnwrest plough allows ploughing to be done to either side. The mouldboard is removable, turning to the right for one furrow, then being moved to the other side of the plough to turn to the left (the coulter and ploughshare are fixed). In this way adjacent furrows can be ploughed in opposite directions, allowing ploughing to proceed continuously along the field and thus avoiding the ridge and furrow topography.
Reversible plough.
The reversible plough has two mouldboard ploughs mounted back-to-back, one turning to the right, the other to the left. While one is working the land, the other is carried upside-down in the air. At the end of each row, the paired ploughs are turned over, so the other can be used. This returns along the next furrow, again working the field in a consistent direction.
Riding and multiple-furrow ploughs.
Early steel ploughs, like those for thousands of years prior, were "walking ploughs", directed by the ploughman holding onto handles on either side of the plough. The steel ploughs were so much easier to draw through the soil that the constant adjustments of the blade to react to roots or clods was no longer necessary, as the plough could easily cut through them. Consequently, it was not long after that the first "riding ploughs" appeared. On these, wheels kept the plough at an adjustable level above the ground, while the ploughman sat on a seat ; whereas, with earlier plows the plowman would have had to walk. Direction was now controlled mostly through the draught team, with levers allowing fine adjustments. This led very quickly to riding ploughs with multiple mouldboards, dramatically increasing ploughing performance.
A single draught horse can normally pull a single-furrow plough in clean light soil, but in heavier soils two horses are needed, one walking on the land and one in the furrow. For ploughs with two or more furrows more than two horses are needed and, usually, one or more horses have to walk on the loose ploughed sod—and that makes hard going for them, and the horse treads the newly ploughed land down. It is usual to rest such horses every half-hour for about ten minutes.
Heavy volcanic loam soils, such as are found in New Zealand, require the use of four heavy draught horses to pull a double-furrow plough. Where paddocks are more square than long-rectangular it is more economical to have horses four wide in harness than two-by-two ahead, thus one horse is always on the ploughed land (the sod). The limits of strength and endurance of horses made greater than two-furrow ploughs uneconomic to use on one farm.
Amish farmers tend to use a team of about seven horses or mules when spring ploughing and as Amish farmers often help each other plough, teams are sometimes changed at noon. Using this method about can be ploughed per day in light soils and about in heavy soils.
Improvement in metallurgy and design.
John Deere, a Vermont (U.S.A.) blacksmith, noted that the ploughing of many sticky, non-sandy soils might benefit from modifications in the design of the mouldboard and in the metals used. He noted that a polished needle would enter leather and fabric with greater ease, and a polished pitchfork required less effort as well. In the pursuit of a polished and thus slicker surface for a plough, he experimented with portions of saw blades and by 1837, he was making polished, cast steel ploughs. The energy effort required was lessened, paving the way for larger ploughs as future developments, simultaneous to more effective use of horse power.
Balance plough.
The advent of the mobile steam engine allowed steam power to be applied to ploughing from about 1850. In Europe, soil conditions were often too soft to support the weight of heavy traction engines. Instead, counterbalanced, wheeled ploughs, known as "balance ploughs", were drawn by cables across the fields by pairs of ploughing engines on opposite field edges, or by a single engine drawing directly towards it at one end and drawing away from it via a pulley at the other end. The balance plough had two sets of ploughs facing each other, arranged so when one was in the ground, the other set was lifted into the air. When pulled in one direction, the trailing ploughs were lowered onto the ground by the tension on the cable. When the plough reached the edge of the field, the other engine pulled the opposite cable, and the plough tilted (balanced), putting the other set of shares into the ground, and the plough worked back across the field.
One set of ploughs was right-handed, and the other left-handed, allowing continuous ploughing along the field, as with the turnwrest and reversible ploughs. The man credited with the invention of the ploughing engine and the associated balance plough, in the mid nineteenth century, was John Fowler, an English agricultural engineer and inventor.
In America the firm soil of the Plains allowed direct pulling with steam tractors, such as the big Case, Reeves or Sawyer-Massey breaking engines. Gang ploughs of up to fourteen bottoms were used. Often these big ploughs were used in regiments of engines, so that in a single field there might be ten steam tractors each drawing a plough. In this way hundreds of acres could be turned over in a day. Only steam engines had the power to draw the big units. When internal combustion engines appeared, they had neither the strength nor the ruggedness compared to the big steam tractors. Only by reducing the number of shares could the work be completed.
Stump-jump plough.
The Stump-jump plough was an Australian invention of the 1870s, designed to cope with the breaking up of new farming land, that contains many tree stumps and rocks that would be very expensive to remove. The plough uses a moveable weight to hold the ploughshare in position. When a tree stump or other obstruction such as a rock is encountered, the ploughshare is thrown upwards, clear of the obstacle, to avoid breaking the plough's harness or linkage; ploughing can be continued when the weight is returned to the earth after the obstacle is passed.
A simpler system, developed later, uses a concave disc (or a pair of them) set at a large angle to the direction of progress, that uses the concave shape to hold the disc into the soil — unless something hard strikes the circumference of the disk, causing it to roll up and over the obstruction. As the arrangement is dragged forward, the sharp edge of the disc cuts the soil, and the concave surface of the rotating disc lifts and throws the soil to the side. It doesn't make as good a job as the mouldboard plough (but this is not considered a disadvantage, because it helps fight wind erosion), but it does lift and break up the soil ("see" disc harrow).
Modern ploughs.
Modern ploughs are usually multiple reversible ploughs, mounted on a tractor via a three-point linkage. These commonly have between two and as many as seven mouldboards — and "semi-mounted" ploughs (the lifting of which is supplemented by a wheel about halfway along their length) can have as many as eighteen mouldboards. The hydraulic system of the tractor is used to lift and reverse the implement, as well as to adjust furrow width and depth. The ploughman still has to set the draughting linkage from the tractor so that the plough is carried at the proper angle in the soil. This angle and depth can be controlled automatically by modern tractors. As a complement to the rear plough a two or three mouldboards-plough can be mounted on the front of the tractor if it is equipped with front three-point linkage.
Specialist ploughs.
Chisel plough.
The "chisel plough" is a common tool to get deep tillage (prepared land) with limited soil disruption. The main function of this plough is to loosen and aerate the soils while leaving crop residue at the top of the soil. This plough can be used to reduce the effects of compaction and to help break up ploughpan and hardpan. Unlike many other ploughs the chisel will not invert or turn the soil. This characteristic has made it a useful addition to no-till and low-till farming practices that attempt to maximise the erosion-prevention benefits of keeping organic matter and farming residues present on the soil surface through the year. Because of these attributes, the use of a chisel plough is considered by some to be more sustainable than other types of plough, such as the mouldboard plough.
The chisel plough is typically set to run up to a depth of eight to twelve inches (200 to 300 mm). However some models may run much deeper. Each of the individual ploughs, or shanks, are typically set from nine inches (229 mm) to twelve inches (305 mm) apart. Such a plough can encounter significant soil drag, consequently a tractor of sufficient power and good traction is required. When planning to plough with a chisel plough it is important to bear in mind that 10 to 15 horsepower (7 to 11 kW) per shank will be required.
Cultivators are often similar in form to chisel ploughs, but their goals are different. Cultivator teeth work near the surface, usually for weed control, whereas chisel plough shanks work deep beneath the surface. Consequently, cultivating also takes much less power per shank than does chisel ploughing.
Ridging plough.
A ridging plough is used for crops, such as potatoes or scallions, which are grown buried in ridges of soil using a technique called "ridging" or "hilling". A ridging plough has two mouldboards facing away from each other, cutting a deep furrow on each pass, with high ridges either side. The same plough may be used to split the ridges to harvest the crop.
Scottish hand plough.
This is a variety of ridge plough notable in that the blade points towards the operator. It is used solely by human effort rather than with animal or machine assistance, and is pulled backwards by the operator, requiring great physical effort. It is particularly used for second breaking of ground, and for potato planting. It is found in Shetland, some western crofts and more rarely Central Scotland. The tool is typically found on small holdings too small or poor to merit use of animals.
Mole plough.
The "mole plough" or "subsoiler" allows underdrainage to be installed without trenches, or it breaks up deep impermeable soil layers that impede drainage. It is a very deep plough, with a torpedo-shaped or wedge-shaped tip, and a narrow blade connecting this to the body. When dragged through the ground, it leaves a channel deep under the ground, and this acts as a drain. Modern mole ploughs may also bury a flexible perforated plastic drain pipe as they go, making a more permanent drain — or they may be used to lay pipes for water supply or other purposes. Similar machines, so called pipe-and-cable-laying ploughs, are even used under the sea, for the laying of cables, as well as preparing the earth for side-scan sonar in a process used in oil exploration.
Paraplough.
The paraplough or paraplow is a tool for loosening compacted soil layers 12 to 16 inches deep and still maintain high surface residue levels.
Spade plough.
The spade plough is designed to cut the soil and turn it on its side, minimizing the damage to the earthworms, soil microorganism, and fungi. This helps maximize the sustainability and long term fertility of the soils.
Effects of mouldboard ploughing.
Mouldboard ploughing, in cold and temperate climates, no deeper than 20 cm, aerates the soil by loosening it. It incorporates crop residues, solid manures, limestone and commercial fertilizers along with oxygen. By doing so, it reduces nitrogen losses by denitrification, accelerates mineralization and increases short-term nitrogen availability for transformation of organic matter into humus. It erases wheel tracks and ruts caused by harvesting equipment. It controls many perennial weeds and pushes back the growth of other weeds until the following spring. It accelerates soil warming and water evaporation in spring because of the lesser quantity of residues on the soil surface. It facilitates seeding with a lighter seeder. It controls many enemies of crops (slugs, crane flies, seedcorn maggots-bean seed flies, borers). It increases the number of "soil-eating" earthworms (endogea) but is detrimental to vertical-dwelling earthworms (anecic).
Ploughing leaves very little crop residue on the surface, which otherwise could reduce both wind and water erosion. Over-ploughing can lead to the formation of hardpan. Typically farmers break up hardpan up with a subsoiler, which acts as a long, sharp knife to slice through the hardened layer of soil deep below the surface. Soil erosion due to improper land and plough utilization is possible. Contour ploughing mitigates soil erosion by ploughing across a slope, along elevation lines. Alternatives to ploughing, such as the no till method, have the potential to actually build soil levels and humus. These may be suitable to smaller, more intensively cultivated plots, and to farming on poor, shallow or degraded soils that ploughing would further degrade.

</doc>
<doc id="24097" url="https://en.wikipedia.org/wiki?curid=24097" title="Principle of bivalence">
Principle of bivalence

In logic, the semantic principle (or law) of bivalence states that every declarative sentence expressing a proposition (of a theory under inspection) has exactly one truth value, either true or false. A logic satisfying this principle is called a two-valued logic or bivalent logic.
In formal logic, the principle of bivalence becomes a property that a semantics may or may not possess. It is not the same as the law of excluded middle, however, and a semantics may satisfy that law without being bivalent. It may be written in the second-order sentence as: formula_1, demonstrating similarity yet differing mainly by quantified set elements.
The principle of bivalence is studied in philosophical logic to address the question of which natural-language statements have a well-defined truth value. Sentences which predict events in the future, and sentences which seem open to interpretation, are particularly difficult for philosophers who hold that the principle of bivalence applies to all declarative natural-language statements. Many-valued logics formalize ideas that a realistic characterization of the notion of consequence requires the admissibility of premises which, owing to vagueness, temporal or quantum indeterminacy, or reference-failure, cannot be considered classically bivalent. Reference failures can also be addressed by free logics.
Relationship with the law of the excluded middle.
The principle of bivalence is related to the law of excluded middle though the latter is a syntactic expression of the language of a logic of the form "P ∨ ¬P". The difference between the principle and the law is important because there are logics which validate the law but which do not validate the principle. For example, the three-valued Logic of Paradox (LP) validates the law of excluded middle, but not the law of non-contradiction, ¬(P ∧ ¬P), and its intended semantics is not bivalent. In classical two-valued logic both the law of excluded middle and the law of non-contradiction hold.
Many modern logic programming systems replace the law of the excluded middle with the concept of negation as failure. The programmer may wish to add the law of the excluded middle by explicitly asserting it as true; however, it is not assumed "a priori".
Classical logic.
The intended semantics of classical logic is bivalent, but this is not true of every semantics for classical logic. In Boolean-valued semantics (for classical propositional logic), the truth values are the elements of an arbitrary Boolean algebra, "true" corresponds to the maximal element of the algebra, and "false" corresponds to the minimal element. Intermediate elements of the algebra correspond to truth values other than "true" and "false". The principle of bivalence holds only when the Boolean algebra is taken to be the two-element algebra, which has no intermediate elements.
Assigning Boolean semantics to classical predicate calculus requires that the model be a complete Boolean algebra because the universal quantifier maps to the infimum operation, and the existential quantifier maps to the supremum; this is called a Boolean-valued model. All finite Boolean algebras are complete.
Suszko's thesis.
In order to justify his claim that true and false are the only logical values, Suszko (1977) observes that every structural Tarskian many-valued propositional logic can be provided with a bivalent semantics.
Criticisms.
Future contingents.
A famous example is the "contingent sea battle" case found in Aristotle's work, "De Interpretatione", chapter 9:
The principle of bivalence here asserts:
Aristotle to embrace bivalence for such future contingents; Chrysippus, the Stoic logician, did embrace bivalence for this and all other propositions. The controversy continues to be of central importance in both the philosophy of time and the philosophy of logic.
One of the early motivations for the study of many-valued logics has been precisely this issue. In the early 20th century, the Polish formal logician Jan Łukasiewicz proposed three truth-values: the true, the false and the "as-yet-undetermined". This approach was later developed by Arend Heyting and L. E. J. Brouwer; see Łukasiewicz logic.
Issues such as this have also been addressed in various temporal logics, where one can assert that ""Eventually", either there will be a sea battle tomorrow, or there won't be." (Which is true if "tomorrow" eventually occurs.)
Vagueness.
Such puzzles as the Sorites paradox and the related continuum fallacy have raised doubt as to the applicability of classical logic and the principle of bivalence to concepts that may be vague in their application. Fuzzy logic and some other multi-valued logics have been proposed as alternatives that handle vague concepts better. Truth (and falsity) in fuzzy logic, for example, comes in varying degrees. Consider the following statement in the circumstance of sorting apples on a moving belt:
Upon observation, the apple is an undetermined color between yellow and red, or it is motled both colors. Thus the color falls into neither category " red " nor " yellow ", but these are the only categories available to us as we sort the apples. We might say it is "50% red". This could be rephrased: it is 50% true that the apple is red. Therefore, P is 50% true, and 50% false. Now consider:
In other words, P and not-P. This violates the law of noncontradiction and, by extension, bivalence. However, this is only a partial rejection of these laws because P is only partially true. If P were 100% true, not-P would be 100% false, and there is no contradiction because P and not-P no longer holds.
However, the law of the excluded middle is retained, because P and not-P implies P or not-P, since "or" is inclusive. The only two cases where P and not-P is false (when P is 100% true or false) are the same cases considered by two-valued logic, and the same rules apply.
Example of a 3-valued logic applied to vague (undetermined) cases: Kleene 1952 (§64, pp. 332–340) offers a 3-valued logic for the cases when algorithms involving partial recursive functions may not return values, but rather end up with circumstances "u" = undecided. He lets "t" = "true", "f" = "false", "u" = "undecided" and redesigns all the propositional connectives. He observes that:
The following are his "strong tables":
For example, if a determination cannot be made as to whether an apple is red or not-red, then the truth value of the assertion Q: " This apple is red " is " u ". Likewise, the truth value of the assertion R " This apple is not-red " is " u ". Thus the AND of these into the assertion Q AND R, i.e. " This apple is red AND this apple is not-red " will, per the tables, yield " u ". And, the assertion Q OR R, i.e. " This apple is red OR this apple is not-red " will likewise yield " u ".

</doc>
<doc id="24099" url="https://en.wikipedia.org/wiki?curid=24099" title="Pope Clement II">
Pope Clement II

Pope Clement II (; born Suidger von Morsleben; died 9 October 1047), was Pope from 25 December 1046 until his death in 1047. He was the first in a series of reform-minded popes from Germany.
Life.
Born in Hornburg, Lower Saxony, Germany, he was the son of Count Konrad of Morsleben and Hornburg and his wife Amulrad.
In 1040, he became Bishop of Bamberg. In 1046, he accompanied King Henry III on his campaign to Italy and in December, participated in the Council of Sutri, which deposed former Popes Benedict IX and Sylvester III and persuaded Pope Gregory VI to resign. King Henry nominated Suidger for the papacy and the council elected him. Suidger took the name Clement II. Immediately after his election, King Henry and the new Pope moved to Rome, where Clement crowned Henry III as Holy Roman Emperor.
Clement II's short pontificate, starting with the Roman synod of 1047, initiated an improvement in the state of affairs within the Roman Church, particularly by enacting decrees against simony. A dispute for precedence among the Sees of Ravenna, Milan, and Aquileia was settled in favour of Ravenna.
Clement's election was later criticized by the reform party within the papal curia due to the royal involvement and the fact that the new Pope was already bishop of another diocese. Contrary to later practice, Clement kept his old see, governing both Rome and Bamberg simultaneously.
Clement accompanied the Emperor in a triumphal progress through southern Italy and placed Benevento under an interdict for refusing to open its gates to them. Proceeding with Henry to Germany, he canonized Wiborada, a nun of St. Gall, martyred by the Hungarians in 925. On his way back to Rome, he died near Pesaro on 9 October 1047. His corpse was transferred back to Bamberg, which he had loved dearly, and interred in the western choir of the Bamberg Cathedral. His is the only tomb of a Pope north of the Alps.
A toxicologic examination of his remains in the mid-20th century confirmed centuries-old rumors that the Pope had been poisoned with lead sugar. It is not clear, however, whether he was murdered or whether the lead sugar was used as medicine.

</doc>
<doc id="24100" url="https://en.wikipedia.org/wiki?curid=24100" title="Pope Clement III">
Pope Clement III

Pope Clement III (; 1130 – 20 March 1191), born Paulino (or Paolo) Scolari, reigned from 19 December 1187 to his death in 1191.
Cardinal.
A Roman by birth, Pope Alexander III appointed him in succession Archpriest of the patriarchal Liberian Basilica, Cardinal-deacon of Sergio e Bacco, and finally Cardinal bishop of Palestrina in December 1180. He appears as signatory of the papal bulls issued between 15 October 1179 and 11 December 1187.
Pope.
Shortly after his accession at the conclusion of the papal election of December 1187, Clement succeeded in allaying the conflict which had existed for half a century between the Popes and the citizens of Rome, with an agreement by which the citizens were allowed to elect their magistrates, while the nomination of the governor of the city remained in the hands of the Pope. On 31 May 1188 he concluded a treaty with the Romans which removed long standing difficulties, thus returning the Papacy to Rome.
Clement also inherited a depleted college of cardinals, consisting of no more than twenty cardinals. He orchestrated three series of promotions (March 1188, May 1189 and October 1190) that resulted in over thirty new cardinals.
He pushed King Henry II of England and King Philip II of France to undertake the Third Crusade. In April 1189, Clement made peace with the Emperor Frederick I Barbarossa.
He settled a controversy with King William I of Scotland concerning the choice of the archbishop of St. Andrews, and on 13 March 1188 removed the Scottish church from the legatine jurisdiction of the Archbishop of York, thus making it independent of all save Rome.
In spite of agreeing to crown Holy Roman Emperor Henry VI, Clement III angered him by bestowing Sicily on Tancred, son of Roger III, Duke of Apulia. The crisis was acute when the Pope died in the latter part of March 1191.
References.
Attribution:

</doc>
<doc id="24101" url="https://en.wikipedia.org/wiki?curid=24101" title="Pope Clement IV">
Pope Clement IV

Pope Clement IV (; 23 November 1190  1200 – 29 November 1268), born Gui Foucois (; or ') and also known as Guy le Gros'" (French for "Guy the Fat"; ), was bishop of Le Puy (1257–1260), archbishop of Narbonne (1259–1261), cardinal of Sabina (1261–1265), and Pope from 5 February 1265 until his death. His election as pope occurred at a conclave held at Perugia that lasted four months while cardinals argued over whether to call in Charles of Anjou, the youngest brother of Louis IX of France, to carry on the papal war against the Hohenstaufens. He was a vital patron of Thomas Aquinas and of Roger Bacon, prompting the latter to writer his "Opus Majus", which included important treatises on optics and the scientific method.
Biography.
Early life.
Clement was born in Saint-Gilles-du-Gard in the Languedoc region of France, the son of successful lawyer Pierre Foucois and his wife Marguerite Ruffi. At the age of nineteen, he enrolled as a soldier to fight the Moors in Spain. He then pursued the study of law in in Toulouse, Bourges and Orleans, becoming a noted advocate in Paris. In the latter capacity he acted as secretary to King Louis IX, to whose influence he was chiefly indebted for his elevation to the cardinalate. He married the daughter of Simon de Malbois and had two daughters. Upon the death of his wife, he followed his father's example and gave up secular life for the Church.
His rise was rapid. Ordained in the abbey of Saint-Magloire, Paris, he became pastor of Saint-Gilles in 1255. In 1257, he was appointed Bishop of Le Puy; in 1259, he was appointed Archbishop of Narbonne; and in December 1261, he became the first cardinal created by Pope Urban IV, for the See of Sabina. He was the papal legate in England between 1262 and 1264. He was named grand penitentiary in 1263. 
Pontificate.
In this period, the Holy See was engaged in a conflict with Manfred of Sicily, the illegitimate son and designated heir of Holy Roman Emperor Frederick II of Hohenstaufen, but whom papal loyalists, the Guelfs, called "the usurper of Naples". Clement IV, who was in France at the time of his election, was compelled to enter Italy in disguise. He immediately took steps to ally himself with Charles of Anjou, his erstwhile patron's brother and the impecunious French claimant to the Neapolitan throne. Charles was willing to recognize the Pope as his feudal overlord (a bone of contention with the Hohenstaufens) and was crowned by cardinals in Rome, where Clement IV, permanently established at Viterbo, dared not venture, since the anti-papal Ghibelline party was so firmly in control there.
Then, fortified with papal money and supplies, Charles marched into Naples. Having defeated and slain Manfred in the great Battle of Benevento, Charles established himself firmly in the kingdom of Sicily at the conclusive Battle of Tagliacozzo, in which Conradin, the last of the house of Hohenstaufen, was taken prisoner. Clement IV is said to have disapproved of the cruelties committed by his protégé, but there seems no foundation for the statement by Gregorovius that Clement IV became an accomplice by refusing to intercede for the unfortunate Conradin whom Charles had beheaded in the marketplace of Naples.
Death and Burial.
Within months Clement IV was dead as well, and was buried at the Dominican convent, Santa Maria in Gradi, just outside Viterbo, where he resided throughout his pontificate. In 1885, his remains were transferred to the church, San Francesco alla Rocca, in Viterbo. Owing to irreconcilable divisions among the cardinals, the papal throne remained vacant for nearly three years.
Clement IV's private character was praised by contemporaries for his asceticism, and he is especially commended for his indisposition to promote and enrich his own relatives. He also ordered the Franciscan scholar Roger Bacon to write the "Opus Majus", which is addressed to him.
Acts.
In 1264, Clement IV renewed the prohibition of the Talmud promulgated by Gregory IX, who had it publicly burnt in France and in Italy. Clement, though he did not assign to the stake those who harboured copies of it, and, responding to a denunciation of the Talmud by Pablo Christiani, assigned a Talmud censorship committee and ordered that the Jews of Aragon submit their books to Dominican censors for expurgation.
In February 1265 Clement summoned Thomas Aquinas to Rome to serve as papal theologian. It was during this period that Aquinas also served as regent master for the Dominicans at Rome. With the arrival of Aquinas the existing "studium conventuale" at Santa Sabina, which had been founded in 1222, was transformed into the Order's first "studium provinciale" featuring the study of philosophy ("studia philosophiae") as prescribed by Aquinas and others at the chapter of Valenciennes in 1259, an intermediate school between the "studium conventuale" and the "studium generale". This "studium" was the forerunner of the 16th century College of Saint Thomas at Santa Maria sopra Minerva and the Pontifical University of Saint Thomas Aquinas, "Angelicum". In 1266, after the Battle of Benevento, Pope Clement IV conceded for gratitude his coat of arms to the Guelph Party of Florence as official approval to their supremacy and therefore they could take power in many of the other northern Italian cities. In 1267–68 Clement engaged in correspondence with the Mongol Ilkhanate rule Abaqa. The latter proposed a Franco-Mongol alliance between his forces, those of the West, and the Byzantine emperor Michael VIII Palaeologos (Abaqa's father-in-law). Pope Clement welcomed Abaqa's proposal in a non-committal manner, but did inform him of an upcoming Crusade. In 1267, Pope Clement IV and King James I of Aragon sent an ambassador to the Mongol ruler Abaqa in the person of Jayme Alaric de Perpignan. In his 1267 letter written from Viterbo, the Pope wrote:
Although Clement's successors continued to engage in diplomatic contacts with the Mongols for the rest of the century, they were never able to coordinate an actual alliance.

</doc>
<doc id="24102" url="https://en.wikipedia.org/wiki?curid=24102" title="Pope Clement V">
Pope Clement V

Pope Clement V (; c. 1264 – 20 April 1314), born Raymond Bertrand de Got (also occasionally spelled "de Guoth" and "de Goth"), was Pope from 5 June 1305 to his death in 1314. He is remembered for suppressing the order of the Knights Templar and allowing the execution of many of its members, and as the Pope who moved the Curia from Rome to Avignon, ushering in the period known as the Avignon Papacy.
Biography.
Born in Villandraut, Aquitaine, Bertrand was canon and sacristan of the Cathedral of Saint-André in Bordeaux, then vicar-general to his brother, the Archbishop of Lyon, who in 1294 was created Cardinal-Bishop of Albano. He was then made Bishop of St-Bertrand-de-Comminges, the cathedral church of which he was responsible for greatly enlarging and embellishing, and chaplain to Pope Boniface VIII, who made him Archbishop of Bordeaux in 1297.
Election.
Following the death of Benedict XI in 1304, there was a year's interregnum occasioned by disputes between the French and Italian cardinals, who were nearly equally balanced in the conclave, which had to be held at Perugia. Bertrand was elected Pope Clement V in June 1305 and consecrated on 14 November. Bertrand was neither Italian nor a cardinal, and his election might have been considered a gesture towards neutrality. The contemporary chronicler Giovanni Villani reports gossip that he had bound himself to King Philip IV of France by a formal agreement before his elevation, made at St. Jean d'Angély in Saintonge. Whether this was true or not, it is likely that the future pope had conditions laid down for him by the conclave of cardinals.
At Bordeaux, Bertrand was formally notified of his election and urged to come to Italy, but he selected Lyon for his coronation on 14 November 1305, which was celebrated with magnificence and attended by Philip IV. Among his first acts was the creation of nine French cardinals.
Clement V and the Knights Templar.
Early in 1306, Clement V explained away those features of the Papal bull "Clericis Laicos" that might seem to apply to the king of France and essentially withdrew "Unam Sanctam", the bull of Boniface VIII that asserted papal supremacy over secular rulers and threatened Philip's political plans, a radical change in papal policy.
On Friday, 13 October 1307, hundreds of the Knights Templar were arrested in France, an action apparently motivated financially and undertaken by the efficient royal bureaucracy to increase the prestige of the crown. Philip IV was the force behind this move, but it has also embellished the historical reputation of Clement V. From the very day of Clement V's coronation, the king charged the Templars with usury, credit inflation, fraud, heresy, sodomy, immorality and abuses, and the scruples of the Pope were heightened by a growing sense that the burgeoning French State might not wait for the Church, but would proceed independently.
Meanwhile, Philip IV's lawyers pressed to reopen Guillaume de Nogaret's charges of heresy against the late Boniface VIII that had circulated in the pamphlet war around the bull "Unam sanctam." Clement V had to yield to pressures for this extraordinary trial, begun on 2 February 1309 at Avignon, which dragged on for two years. In the document that called for the witnesses, Clement V expressed both his personal conviction of the innocence of Boniface VIII and his resolution to satisfy the king. Finally, in February 1311, Philip IV wrote to Clement V abandoning the process to the future council of Vienne. For his part, Clement V absolved all the participants in the abduction of Boniface at Anagni.
In pursuance of the king's wishes, Clement V in 1311 summoned the Council of Vienne, which refused to convict the Templars of heresy. The Pope abolished the order anyway, as the Templars seemed to be in bad repute and had outlived their usefulness as papal bankers and protectors of pilgrims in the East. Their French estates were granted to the Knights Hospitallers, but Philip IV held them until his death and expropriated the Templar's bank outright.
False charges of heresy and sodomy set aside, the guilt or innocence of the Templars is one of the more difficult historical problems, partly because of the atmosphere of hysteria that had built up in the preceding generation (marked by habitually intemperate language and extravagant denunciations exchanged between temporal rulers and churchmen), partly because the subject has been embraced by conspiracy theorists and quasi-historians.
Relations with Rome.
In March 1309, the entire papal court moved from Poitiers (where it had remained for 4 years) to the Comtat Venaissin, around the city of Avignon, which was not then part of France, but an imperial fief held by the King of Sicily. This move, actually to Carpentras, the capital of the territory, was justified at the time by French apologists on grounds of security, since Rome, where the dissensions of the Roman aristocrats and their armed militia had reached a nadir and the Basilica di San Giovanni in Laterano had been destroyed in a fire, was unstable and dangerous. But the decision proved the precursor of the long Avignon Papacy, the "Babylonian captivity" (1309–77), in Petrarch's phrase, and marks a point from which the decay of the strictly Catholic conception of the pope as universal bishop may be dated.
Clement V's pontificate was also a disastrous time for Italy. The Papal States were entrusted to a team of three cardinals, but Rome, the battleground of the Colonna and Orsini factions, was ungovernable. In 1310, the Holy Roman Emperor Henry VII entered Italy, established the Visconti as vicars in Milan, and was crowned by Clement V's legates in Rome in 1312 before he died near Siena in 1313.
In Ferrara, which was taken into the Papal states to the exclusion of the Este family, papal armies clashed with Venice and their populace. When excommunication and interdict failed to have their intended effect, Clement V preached a crusade against the Venetians in May 1309, declaring that Venetians captured abroad might be sold into slavery, like non-Christians,
Later career and death.
Other remarkable incidents of Clement V's reign include his violent repression of the Dulcinian movement in Lombardy, which he considered a heresy, and his promulgation of the Clementine Constitutions in 1313. Clement died on 20 April 1314. According to one story, while his body was lying in state, a thunderstorm developed during the night and lightning struck the church where his body lay, igniting the building. The fire was so intense that when it was extinguished, the body of Pope Clement V was almost destroyed. He was buried at the collegiate church in Uzeste close to his birthplace in Villandraut as put down in his will.
Promulgation of a Crusade and relations with the Mongols.
Clement sent John of Montecorvino to Beijing to preach Roman Catholicism in China.
Clement engaged intermittently in communications with the Mongol Empire towards the possibility of creating a Franco-Mongol alliance against the Muslims. In April 1305, the Mongol Ilkhan ruler Oljeitu sent an embassy led by Buscarello de Ghizolfi to Clement, Philip IV of France, and Edward I of England. In 1307, another Mongol embassy led by Tommaso Ugi di Siena reached European monarchs. However, no coordinated military action was forthcoming and hopes of alliance petered out within a few years.
On 4 April 1312, a Crusade was promulgated by Pope Clement V at the Council of Vienne. Another embassy was sent by Oljeitu to the West and to Edward II of England in 1313. The same year, Philip IV "took the cross", making the vow to go on a Crusade in the Levant.

</doc>
<doc id="24103" url="https://en.wikipedia.org/wiki?curid=24103" title="Pope Clement VI">
Pope Clement VI

Clement VI (; 1291 – 6 December 1352), born Pierre Roger, was pope from 7 May 1342 to his death in 1352. He was the fourth Avignon pope. Clement is most notable as the pope who reigned during the time of the Black Death (1348–1350), during which he granted remission of sins to all who died of the plague.
Life.
Clement was born in the château of Maumont, today part of the commune of Rosiers-d'Égletons, Corrèze, in Limousin, the son of the wealthy lord of Rosiers-d'Égletons.
He entered the Benedictine order as a boy, studied at the College de Sorbonne in Paris, and became successively prior of St. Baudil, Abbot of Fécamp, Bishop of Arras, Chancellor of France, Archbishop of Sens and Archbishop of Rouen. As Abbot of Fécamp, he was tasked in 1328 with summoning Edward III of England to pay homage to Philip VI of France for the duchy of Aquitaine. He was made cardinal-priest of Santi Nereo e Achilleo and administrator of the bishopric of Avignon by Benedict XII in 1338 and was chosen to succeed him as pope at the conclave of 1342.
Like his immediate predecessors, he was devoted to France, and he demonstrated his French sympathies by refusing a solemn invitation to return to Rome from the city's people, as well as from the poet Petrarch. He threw a sop to the Romans, however, by reducing the Jubilee term from one hundred years to fifty. He also purchased the sovereignty of Avignon from Queen Joan I of Naples for 80,000 crowns.
Clement VI issued the bull "Unigenitus Dei filius" on 27 January 1343 to justify the power of the pope and the use of indulgences. This document would later be used in the defense of indulgences after Martin Luther pinned his 95 Theses to a church in Wittenberg on 31 October 1517.
Clement VI reigned during the period of the Black Death. This pandemic swept through Europe (as well as Asia and the Middle East) between 1347 and 1350 and is believed to have killed between a third and two-thirds of Europe's population. During the plague, Clement sought the insight of astronomers for explanation. Johannes de Muris was among the team "of three who drew up a treatise explaining the plague of 1348 by the conjunction of Saturn, Jupiter, and Mars in 1341" Clement VI's physicians advised him that surrounding himself with torches would block the plague. However, he soon became skeptical of this recommendation and stayed in Avignon supervising sick care, burials, and the pastoral care of the dying. He never contracted the disease, even though there was so much death around him that the cities ran out of ground for cemeteries, and he had to consecrate the entire Rhone River so bodies could be thrown into it and considered to be buried in holy ground. One of his physicians, Gui de Chauliac, later wrote the "Chirurgia magna".
Popular opinion blamed the Jews for the plague, and pogroms erupted throughout Europe. Clement issued two papal bulls in 1348 (6 July and 26 September), the latter named "Quamvis Perfidiam", which condemned the violence and said those who blamed the plague on the Jews had been "seduced by that liar, the Devil." He urged clergy to take action to protect Jews as he had done.
Clement continued the struggle of his predecessors with Holy Roman Emperor Louis IV. He excommunicated him after protracted negotiations on 13 April 1346 and directed the election of Charles IV, who received general recognition after the death of Louis in October 1347, ending the schism which had long divided Germany. Clement proclaimed a crusade in 1343, but nothing was accomplished beyond a naval attack on Smyrna on 29 October 1344. He also had a role in the Hungarian invasion of the Kingdom of Naples, namely a papal fief; the contest between Louis I of Hungary and Joan I of Naples, accused to have ordered the assassination of the former's brother, was ended in 1352 by a trial held in Avignon, by which she was acquitted from any charge. Among the other benefits, Clement took advantage of the situation to obtain by her the rights over the city of Avignon.
The other chief incidents of his pontificate were his disputes with King Edward III of England as a result of the latter's encroachments on ecclesiastical jurisdiction, as well as with the kings of Castile and Aragon; his fruitless negotiations for reunion with the Armenians and the Byzantine emperor, John VI Kantakouzenos; and the commencement of Cola di Rienzo's agitation in Rome. He had appointed Cola to a civil position at Rome, and, although at first approving the establishment of the tribunate, he later sent a legate who excommunicated him and, with the help of the aristocratic faction, drove him from the city in December 1347. Clement also excommunicated King Casimir III of Poland and made Prague an archbishopric in 1344.
Unlike the Cistercian Benedict XII, Clement VI was devoted to lavish living and the treasury which he inherited made that lifestyle possible. Upon election as pope he exclaimed as he looked forward to a reign of regal self-indulgence: "My predecessors did not know how to be pope." He claimed to have "lived as a sinner among sinners" in his own words. During his pontificate, he added a new chapel to the Papal Palace and dedicated it to St. Peter. He commissioned the artist Matteo Giovanetti of Viterbo to paint common hunting and fishing scenes on the walls of the existing papal chapels, and purchased enormous tapestries to decorate the stone walls. To bring good music to the celebrations, he recruited musicians from northern France, especially from Liège, who cultivated the Ars Nova style. He liked music so much that he kept composers and theorists close to him throughout his entire pontificate, Philippe de Vitry being among the more famous. The first two payments he made after his coronation were to musicians.
Clement VI died in December 1352, leaving the reputation of "a fine gentleman, a prince munificent to profusion, a patron of the arts and learning, but no saint". His body was placed on exhibit in the Notre Dame-des-Doms, then interred at the abbey of La Chaise-Dieu. The funeral procession was accompanied by the five cardinals that were his family members, as well as the Count William Roger of Beaufort, his brother.

</doc>
<doc id="24107" url="https://en.wikipedia.org/wiki?curid=24107" title="Peer-to-peer">
Peer-to-peer

Peer-to-peer (P2P) computing or networking is a distributed application architecture that partitions tasks or work loads between peers. Peers are equally privileged, equipotent participants in the application. They are said to form a peer-to-peer network of nodes.
Peers make a portion of their resources, such as processing power, disk storage or network bandwidth, directly available to other network participants, without the need for central coordination by servers or stable hosts. Peers are both suppliers and consumers of resources, in contrast to the traditional client-server model in which the consumption and supply of resources is divided. Emerging collaborative P2P systems are going beyond the era of peers doing similar things while sharing resources, and are looking for diverse peers that can bring in unique resources and capabilities to a virtual community thereby empowering it to engage in greater tasks beyond those that can be accomplished by individual peers, yet that are beneficial to all the peers.
While P2P systems had previously been used in many application domains, the architecture was popularized by the file sharing system Napster, originally released in 1999. The concept has inspired new structures and philosophies in many areas of human interaction. In such social contexts, peer-to-peer as a meme refers to the egalitarian social networking that has emerged throughout society, enabled by Internet technologies in general.
Historical development.
While P2P systems had previously been used in many application domains, the concept was popularized by file sharing systems such as the music-sharing application Napster (originally released in 1999). The peer-to-peer movement allowed millions of Internet users to connect "directly, forming groups and collaborating to become user-created search engines, virtual supercomputers, and filesystems." The basic concept of peer-to-peer computing was envisioned in earlier software systems and networking discussions, reaching back to principles stated in the first Request for Comments, RFC 1.
Tim Berners-Lee's vision for the World Wide Web was close to a P2P network in that it assumed each user of the web would be an active editor and contributor, creating and linking content to form an interlinked "web" of links. The early Internet was more open than present day, where two machines connected to the Internet could send packets to each other without firewalls and other security measures. This contrasts to the broadcasting-like structure of the web as it has developed over the years. As a precursor to the Internet, ARPANET was a successful client-server network where "every participating node could request and serve content." However, ARPANET was not self-organized, and it lacked the ability to "provide any means for context or content-based routing beyond 'simple' address-based routing."
Therefore, a distributed messaging system that is often likened as an early peer-to-peer architecture was established: USENET. USENET was developed in 1979 and is a system that enforces a decentralized model of control. The basic model is a client-server model from the user or client perspective that offers a self-organizing approach to newsgroup servers.
However, news servers communicate with one another as peers to propagate Usenet news articles over the entire group of network servers. The same consideration applies to SMTP email in the sense that the core email-relaying network of mail transfer agents has a peer-to-peer character, while the periphery of e-mail clients and their direct connections is strictly a client-server relationship.
In May 1999, with millions more people on the Internet, Shawn Fanning introduced the music and file-sharing application called Napster. Napster was the beginning of peer-to-peer networks, as we know them today, where "participating users establish a virtual network, entirely independent from the physical network, without having to obey any administrative authorities or restrictions."
Architecture.
A peer-to-peer network is designed around the notion of equal "peer" nodes simultaneously functioning as both "clients" and "servers" to the other nodes on the network. This model of network arrangement differs from the client–server model where communication is usually to and from a central server. A typical example of a file transfer that uses the client-server model is the File Transfer Protocol (FTP) service in which the client and server programs are distinct: the clients initiate the transfer, and the servers satisfy these requests.
Routing and resource discovery.
Peer-to-peer networks generally implement some form of virtual overlay network on top of the physical network topology, where the nodes in the overlay form a subset of the nodes in the physical network. Data is still exchanged directly over the underlying TCP/IP network, but at the application layer peers are able to communicate with each other directly, via the logical overlay links (each of which corresponds to a path through the underlying physical network). Overlays are used for indexing and peer discovery, and make the P2P system independent from the physical network topology. Based on how the nodes are linked to each other within the overlay network, and how resources are indexed and located, we can classify networks as "unstructured" or "structured" (or as a hybrid between the two).
Unstructured networks.
"Unstructured peer-to-peer networks" do not impose a particular structure on the overlay network by design, but rather are formed by nodes that randomly form connections to each other. (Gnutella, Gossip, and Kazaa are examples of unstructured P2P protocols).
Because there is no structure globally imposed upon them, unstructured networks are easy to build and allow for localized optimizations to different regions of the overlay. Also, because the role of all peers in the network is the same, unstructured networks are highly robust in the face of high rates of "churn"—that is, when large numbers of peers are frequently joining and leaving the network.
However the primary limitations of unstructured networks also arise from this lack of structure. In particular, when a peer wants to find a desired piece of data in the network, the search query must be flooded through the network to find as many peers as possible that share the data. Flooding causes a very high amount of signaling traffic in the network, uses more CPU/memory (by requiring every peer to process all search queries), and does not ensure that search queries will always be resolved. Furthermore, since there is no correlation between a peer and the content managed by it, there is no guarantee that flooding will find a peer that has the desired data. Popular content is likely to be available at several peers and any peer searching for it is likely to find the same thing. But if a peer is looking for rare data shared by only a few other peers, then it is highly unlikely that search will be successful.
Structured networks.
In "structured peer-to-peer networks" the overlay is organized into a specific topology, and the protocol ensures that any node can efficiently search the network for a file/resource, even if the resource is extremely rare.
The most common type of structured P2P networks implement a distributed hash table (DHT), in which a variant of consistent hashing is used to assign ownership of each file to a particular peer. This enables peers to search for resources on the network using a hash table: that is, ("key", "value") pairs are stored in the DHT, and any participating node can efficiently retrieve the value associated with a given key.
However, in order to route traffic efficiently through the network, nodes in a structured overlay must maintain lists of neighbors that satisfy specific criteria. This makes them less robust in networks with a high rate of "churn" (i.e. with large numbers of nodes frequently joining and leaving the network).
More recent evaluation of P2P resource discovery solutions under real workloads have pointed out several issues in DHT-based solutions such as high cost of advertising/discovering resources and static and dynamic load imbalance.
Notable distributed networks that use DHTs include BitTorrent's distributed tracker, the Kad network, the Storm botnet, YaCy, and the Coral Content Distribution Network. Some prominent research projects include the Chord project, Kademlia, PAST storage utility, P-Grid, a self-organized and emerging overlay network, and CoopNet content distribution system. DHT-based networks have also been widely utilized for accomplishing efficient resource discovery for grid computing systems, as it aids in resource management and scheduling of applications.
Hybrid models.
Hybrid models are a combination of peer-to-peer and client-server models. A common hybrid model is to have a central server that helps peers find each other. Spotify is an example of a hybrid model. There are a variety of hybrid models, all of which make trade-offs between the centralized functionality provided by a structured server/client network and the node equality afforded by the pure peer-to-peer unstructured networks. Currently, hybrid models have better performance than either pure unstructured networks or pure structured networks because certain functions, such as searching, do require a centralized functionality but benefit from the decentralized aggregation of nodes provided by unstructured networks.
Security and trust.
Peer-to-peer systems pose unique challenges from a computer security perspective.
Like any other form of software, P2P applications can contain vulnerabilities. What makes this particularly dangerous for P2P software, however, is that peer-to-peer applications act as servers as well as clients, meaning that they can be more vulnerable to remote exploits.
Routing attacks.
Also, since each node plays a role in routing traffic through the network, malicious users can perform a variety of "routing attacks", or denial of service attacks. Examples of common routing attacks include "incorrect lookup routing" whereby malicious nodes deliberately forward requests incorrectly or return false results, "incorrect routing updates" where malicious nodes corrupt the routing tables of neighboring nodes by sending them false information, and "incorrect routing network partition" where when new nodes are joining they bootstrap via a malicious node, which places the new node in a partition of the network that is populated by other malicious nodes.
Corrupted data and malware.
The prevalence of malware varies between different peer-to-peer protocols. Studies analyzing the spread of malware on P2P networks found, for example, that 63% of the answered download requests on the Limewire network contained some form of malware, whereas only 3% of the content on OpenFT contained malware. In both cases, the top three most common types of malware accounted for the large majority of cases (99% in Limewire, and 65% in OpenFT). Another study analyzing traffic on the Kazaa network found that 15% of the 500,000 file sample taken were infected by one or more of the 365 different computer viruses that were tested for.
Corrupted data can also be distributed on P2P networks by modifying files that are already being shared on the network. For example, on the FastTrack network, the RIAA managed to introduce faked chunks into downloads and downloaded files (mostly MP3 files). Files infected with the RIAA virus were unusable afterwards and contained malicious code. The RIAA is also known to have uploaded fake music and movies to P2P networks in order to deter illegal file sharing. Consequently, the P2P networks of today have seen an enormous increase of their security and file verification mechanisms. Modern hashing, chunk verification and different encryption methods have made most networks resistant to almost any type of attack, even when major parts of the respective network have been replaced by faked or nonfunctional hosts.
Resilient and scalable computer networks.
The decentralized nature of P2P networks increases robustness because it removes the single point of failure that can be inherent in a client-server based system. As nodes arrive and demand on the system increases, the total capacity of the system also increases, and the likelihood of failure decreases. If one peer on the network fails to function properly, the whole network is not compromised or damaged. In contrast, in a typical client–server architecture, clients share only their demands with the system, but not their resources. In this case, as more clients join the system, fewer resources are available to serve each client, and if the central server fails, the entire network is taken down.
Distributed storage and search.
There are both advantages and disadvantages in P2P networks related to the topic of data backup, recovery, and availability. In a centralized network, the system administrators are the only forces controlling the availability of files being shared. If the administrators decide to no longer distribute a file, they simply have to remove it from their servers, and it will no longer be available to users. Along with leaving the users powerless in deciding what is distributed throughout the community, this makes the entire system vulnerable to threats and requests from the government and other large forces. For example, YouTube has been pressured by the RIAA, MPAA, and entertainment industry to filter out copyrighted content. Although server-client networks are able to monitor and manage content availability, they can have more stability in the availability of the content they choose to host. A client should not have trouble accessing obscure content that is being shared on a stable centralized network. P2P networks, however, are more unreliable in sharing unpopular files because sharing files in a P2P network requires that at least one node in the network has the requested data, and that node must be able to connect to the node requesting the data. This requirement is occasionally hard to meet because users may delete or stop sharing data at any point.
In this sense, the community of users in a P2P network is completely responsible for deciding what content is available. Unpopular files will eventually disappear and become unavailable as more people stop sharing them. Popular files, however, will be highly and easily distributed. Popular files on a P2P network actually have more stability and availability than files on central networks. In a centralized network a simple loss of connection between the server and clients is enough to cause a failure, but in P2P networks the connections between every node must be lost in order to cause a data sharing failure. In a centralized system, the administrators are responsible for all data recovery and backups, while in P2P systems, each node requires its own backup system. Because of the lack of central authority in P2P networks, forces such as the recording industry, RIAA, MPAA, and the government are unable to delete or stop the sharing of content on P2P systems.
Applications.
Content delivery.
In P2P networks, clients both provide and use resources. This means that unlike client-server systems, the content serving capacity of peer-to-peer networks can actually "increase" as more users begin to access the content (especially with protocols such as Bittorrent that require users to share, refer a performance measurement study). This property is one of the major advantages of using P2P networks because it makes the setup and running costs very small for the original content distributor.
File-sharing networks.
Many file peer-to-peer file sharing networks, such as Gnutella, G2, and the eDonkey network popularized peer-to-peer technologies. 
Copyright infringements.
Peer-to-peer networking involves data transfer from one user to another without using an intermediate server. Companies developing P2P applications have been involved in numerous legal cases, primarily in the United States, over conflicts with copyright law. Two major cases are "Grokster vs RIAA" and "MGM Studios, Inc. v. Grokster, Ltd.". In both of the cases the file sharing technology was ruled to be legal as long as the developers had no ability to prevent the sharing of the copyrighted material.
Social implications.
Incentivizing resource sharing and cooperation.
Cooperation among a community of participants is key to the continued success of P2P systems aimed at casual human users; these reach their full potential only when large numbers of nodes contribute resources. But in current practice P2P networks often contain large numbers of users who utilize resources shared by other nodes, but who do not share anything themselves (often referred to as the "freeloader problem"). Freeloading can have a profound impact on the network and in some cases can cause the community to collapse. In these types of networks "users have natural disincentives to cooperate because cooperation consumes their own resources and may degrade their own performance." Studying the social attributes of P2P networks is challenging due to large populations of turnover, asymmetry of interest and zero-cost identity. A variety of incentive mechanisms have been implemented to encourage or even force nodes to contribute resources.
Some researchers have explored the benefits of enabling virtual communities to self-organize and introduce incentives for resource sharing and cooperation, arguing that the social aspect missing from today's P2P systems should be seen both as a goal and a means for self-organized virtual communities to be built and fostered. Ongoing research efforts for designing effective incentive mechanisms in P2P systems, based on principles from game theory, are beginning to take on a more psychological and information-processing direction.
Privacy and anonymity.
Some peer-to-peer networks (e.g. Freenet) place a heavy emphasis on privacy and anonymity—that is, ensuring that the contents of communications are hidden from eavesdroppers, and that the identities/locations of the participants are concealed. Public key cryptography can be used to provide encryption, data validation, authorization, and authentication for data/messages. Onion routing and other mix network protocols (e.g. Tarzan) can be used to provide anonymity.
Political implications.
Intellectual property law and illegal sharing.
Although peer-to-peer networks can be used for legitimate purposes, rights holders have targeted peer-to-peer over the involvement with sharing copyrighted material. Peer-to-peer networking involves data transfer from one user to another without using an intermediate server. Companies developing P2P applications have been involved in numerous legal cases, primarily in the United States, primarily over issues surrounding copyright law. Two major cases are "Grokster vs RIAA" and "MGM Studios, Inc. v. Grokster, Ltd.". In both of the cases the file sharing technology was ruled to be legal as long as the developers had no ability to prevent the sharing of the copyrighted material. To establish criminal liability for the copyright infringement on peer-to-peer systems, the government must prove that the defendant infringed a copyright willingly for the purpose of personal financial gain or commercial advantage. Fair use exceptions allow limited use of copyrighted material to be downloaded without acquiring permission from the rights holders. These documents are usually news reporting or under the lines of research and scholarly work. Controversies have developed over the concern of illegitimate use of peer-to-peer networks regarding public safety and national security. When a file is downloaded through a peer-to-peer network, it is impossible to know who created the file or what users are connected to the network at a given time. Trustworthiness of sources is a potential security threat that can be seen with peer-to-peer systems.
Network neutrality.
Peer-to-peer applications present one of the core issues in the network neutrality controversy. Internet service providers (ISPs) have been known to throttle P2P file-sharing traffic due to its high-bandwidth usage. Compared to Web browsing, e-mail or many other uses of the internet, where data is only transferred in short intervals and relative small quantities, P2P file-sharing often consists of relatively heavy bandwidth usage due to ongoing file transfers and swarm/network coordination packets. In October 2007, Comcast, one of the largest broadband Internet providers in the USA, started blocking P2P applications such as BitTorrent. Their rationale was that P2P is mostly used to share illegal content, and their infrastructure is not designed for continuous, high-bandwidth traffic. Critics point out that P2P networking has legitimate legal uses, and that this is another way that large providers are trying to control use and content on the Internet, and direct people towards a client-server-based application architecture. The client-server model provides financial barriers-to-entry to small publishers and individuals, and can be less efficient for sharing large files. As a reaction to this bandwidth throttling, several P2P applications started implementing protocol obfuscation, such as the BitTorrent protocol encryption. Techniques for achieving "protocol obfuscation" involves removing otherwise easily identifiable properties of protocols, such as deterministic byte sequences and packet sizes, by making the data look as if it were random. The ISP's solution to the high bandwidth is P2P caching, where an ISP stores the part of files most accessed by P2P clients in order to save access to the Internet.
Current research.
Researchers have used computer simulations to aid in understanding and evaluating the complex behaviors of individuals within the network. "Networking research often relies on simulation in order to test and evaluate new ideas. An important requirement of this process is that results must be reproducible so that other researchers can replicate, validate, and extend existing work." If the research cannot be reproduced, then the opportunity for further research is hindered. "Even though new simulators continue to be released, the research community tends towards only a handful of open-source simulators. The demand for features in simulators, as shown by our criteria and survey, is high. Therefore, the community should work together to get these features in open-source software. This would reduce the need for custom simulators, and hence increase repeatability and reputability of experiments." 
Besides above, there have been work done on ns-2 open source network simulator. One research issue related to free rider detection and punishment has been explored using ns-2 simulator here.

</doc>
<doc id="24109" url="https://en.wikipedia.org/wiki?curid=24109" title="Prime minister">
Prime minister

A prime minister is the most senior minister of cabinet in the executive branch of government, often in a parliamentary or semi-presidential system. In many systems, the prime minister selects and may dismiss other members of the cabinet, and allocates posts to members within the government. In most systems, the prime minister is the presiding member and chairman of the cabinet. In a minority of systems, notably in semi-presidential systems of government, a prime minister is the official who is appointed to manage the civil service and execute the directives of the head of state.
In parliamentary systems fashioned after the Westminster system, the prime minister is the presiding and actual head of government and head of the executive branch. In such systems, the head of state or the head of state's official representative (i.e. the monarch, president, or governor-general) usually holds a largely ceremonial position, although often with reserve powers.
The prime minister is often, but not always, a member of parliament and is expected with other ministers to ensure the passage of bills through the legislature. In some monarchies the monarch may also exercise executive powers (known as the royal prerogative) that are constitutionally vested in the crown and may be exercised without the approval of parliament.
As well as being head of government, a prime minister may have other roles or titles—the Prime Minister of the United Kingdom, for example, is also First Lord of the Treasury and Minister for the Civil Service. Prime ministers may take other ministerial posts—for example, during the Second World War, Winston Churchill was also Minister of Defence (although there was then no Ministry of Defence), and in the current cabinet of Israel, Benjamin Netanyahu also serves as Minister of Communications, Foreign Affairs, Regional Cooperation, Economy and Interior
Etymology.
The first actual usage of the term "prime minister" or "Premier Ministre" was used by Cardinal Richelieu when in 1625 he was named to head the royal council as prime minister of France. Louis XIV and his descendants generally attempted to avoid giving this title to their chief ministers.
The term "prime minister" in the sense that we know it originated in the 18th century in the United Kingdom when members of parliament disparagingly used the title in reference to Sir Robert Walpole. Over time, the title became honorific and remains so in the 21st century.
History.
Origins.
The monarchs of England and the United Kingdom had ministers in whom they placed special trust and who were regarded as the head of the government. Examples were Thomas Cromwell under Henry VIII; William Cecil, Lord Burghley under Elizabeth I; Clarendon under Charles II and Godolphin under Queen Anne. These ministers held a variety of formal posts, but were commonly known as "the minister", the "chief minister", the "first minister" and finally the "prime minister".
The power of these ministers depended entirely on the personal favour of the monarch. Although managing the parliament was among the necessary skills of holding high office, they did not depend on a parliamentary majority for their power. Although there was a cabinet, it was appointed entirely by the monarch, and the monarch usually presided over its meetings.
When the monarch grew tired of a first minister, he or she could be dismissed, or worse: Cromwell was executed and Clarendon driven into exile when they lost favour. Kings sometimes divided power equally between two or more ministers to prevent one minister from becoming too powerful. Late in Anne's reign, for example, the Tory ministers Harley and St John shared power.
Development.
In the mid 17th century, after the English Civil War (1642–1651), Parliament strengthened its position relative to the monarch then gained more power through the Glorious Revolution of 1688 and passage of the Bill of Rights in 1689. The monarch could no longer establish any law or impose any tax without its permission and thus the House of Commons became a part of the government. It is at this point that a modern style of prime minister begins to emerge.
A tipping point in the evolution of the prime ministership came with the death of Anne in 1714 and the accession of George I to the throne. George spoke no English, spent much of his time at his home in Hanover, and had neither knowledge of, nor interest in, the details of English government. In these circumstances it was inevitable that the king's first minister would become the de facto head of the government.
From 1721 this was the Whig politician Robert Walpole, who held office for twenty-one years. Walpole chaired cabinet meetings, appointed all the other ministers, dispensed the royal patronage and packed the House of Commons with his supporters. Under Walpole, the doctrine of cabinet solidarity developed. Walpole required that no minister other than himself have private dealings with the king, and also that when the cabinet had agreed on a policy, all ministers must defend it in public, or resign. As a later prime minister, Lord Melbourne, said, "It matters not what we say, gentlemen, so long as we all say the same thing."
Walpole always denied that he was "prime minister", and throughout the 18th century parliamentarians and legal scholars continued to deny that any such position was known to the Constitution. George II and George III made strenuous efforts to reclaim the personal power of the monarch, but the increasing complexity and expense of government meant that a minister who could command the loyalty of the Commons was increasingly necessary. The long tenure of the wartime prime minister William Pitt the Younger (1783–1801), combined with the mental illness of George III, consolidated the power of the post. The title was first referred to on government documents during the administration of Benjamin Disraeli but did not appear in the formal British Order of precedence until 1905.
The prestige of British institutions in the 19th century and the growth of the British Empire saw the British model of cabinet government, headed by a prime minister, widely copied, both in other European countries and in British colonial territories as they developed self-government. In some places alternative titles such as "premier", "chief minister", "first minister of state", "president of the council" or "chancellor" were adopted, but the essentials of the office were the same.
Modern usage.
By the late 20th century, the majority of the world's countries had a prime minister or equivalent minister, holding office under either a constitutional monarchy or a ceremonial president. The main exceptions to this system have been the United States and the presidential republics in Latin America modelled on the U.S. system, in which the president directly exercises executive authority.
Bahrain's prime minister, Sheikh Khalifah bin Sulman Al Khalifah has been in the post since 1970, making him the longest serving non-elected prime minister.
Prime ministers in republics and in monarchies.
The post of prime minister may be encountered both in constitutional monarchies (such as Belgium, Denmark, Japan, Luxembourg, the Netherlands, Norway, Malaysia, Morocco, Spain, Sweden, Thailand, Canada, Australia, New Zealand, and the United Kingdom), and in parliamentary republics in which the head of state is an elected official (such as Finland ,the Czech Republic, France, Greece, Hungary, India, Indonesia, Ireland, Pakistan, Portugal, Montenegro, Croatia, Bulgaria, Romania, Serbia and Turkey). See also "First Minister", "Premier", "Chief Minister", "Chancellor", "Taoiseach", "Statsminister" and "Secretary of State": alternative titles usually equivalent in meaning to, or translated as, "prime minister".
This contrasts with the presidential system, in which the president (or equivalent) is both the head of state and the head of the government. In some presidential or semi-presidential systems, such as those of France, Russia or South Korea, the prime minister is an official generally appointed by the president but usually approved by the legislature and responsible for carrying out the directives of the president and managing the civil service. The head of government of the People's Republic of China is referred to as the Premier of the State Council and the premier of the Republic of China (Taiwan) is also appointed by the president, but requires no approval by the legislature.
Appointment of the prime minister of France requires no approval by the parliament either, but the parliament may force the resignation of the government. In these systems, it is possible for the president and the prime minister to be from different political parties if the legislature is controlled by a party different from that of the president. When it arises, such a state of affairs is usually referred to as (political) cohabitation.
Entry into office.
In parliamentary systems a prime minister may enter into office by several means.
Prime ministers and constitutions.
The position, power and status of prime ministers differ depending on the age of the constitution.
Australia's constitution makes no mention of a Prime Minister of Australia.
Bangladesh's constitution clearly outlines the functions and powers of the Prime Minister, and also details the process of his/her appointment and dismissal.
The People's Republic of China constitution set a premier just one place below the National People's Congress in China. Premier read as (Simplified Chinese: 总理; pinyin: Zŏnglĭ) in Chinese.
Canada's constitution, being a 'mixed' or hybrid constitution (a constitution that is partly formally codified and partly uncodified) originally did not make any reference whatsoever to a prime minister, with her or his specific duties and method of appointment instead dictated by "convention". In the Constitution Act, 1982, passing reference to a "Prime Minister of Canada" is added, though only regarding the composition of conferences of federal and provincial first ministers.
Czech Republic's constitution clearly outlines the functions and powers of the Prime Minister of the Czech Republic, and also details the process of his/her appointment and dismissal.
Germany's Basic Law (1949) lists the powers, functions and duties of the federal chancellor.
Greece's constitution (1975) lists the powers, functions and duties of the Prime Minister of Greece.
India's constitution (1950) lists the powers, functions and duties of the Prime Minister of India.
Ireland's constitution (1937), provides for the office of Taoiseach in detail, listing powers, functions and duties.
Italy's constitution (1948) lists the powers, functions and duties of the Prime Minister of Italy.
Japan's constitution (1946) lists the powers, functions and duties of the Prime Minister of Japan.
The Republic of Korea's constitution (1987) sections 86-87 list the powers, functions and duties of the Prime Minister of the Republic of Korea.
Malta's constitution (1964) lists the powers, functions and duties of the Prime Minister of Malta.
Malaysia's constitution (1957) lists the powers, functions and duties of the Prime Minister of Malaysia.
Norway's constitution (1814) lists the powers, functions and duties of the Prime Minister of Norway
Pakistan's constitution (1973) lists the powers, functions and duties of the Prime Minister of Pakistan.
Spain's constitution (1978) regulates the appointment, dismissal, powers, functions and duties of the President of the Government.
Thailand's constitution (1932) lists the powers, functions and duties of the Prime Minister of Thailand.
The United Kingdom's constitution, being uncodified and largely unwritten, makes no mention of a prime minister. Though it had de facto existed for centuries, its first mention in official state documents did not occur until the first decade of the twentieth century. Accordingly, it is often said "not to exist", indeed there are several instances of parliament declaring this to be the case. The prime minister sits in the cabinet solely by virtue of occupying another office, either First Lord of the Treasury (office in commission), or more rarely Chancellor of the Exchequer (the last of whom was Balfour in 1905).
Ukraine's constitution (1996) lists the powers, functions and duties of the Prime Minister of Ukraine.
Exit from office.
Most prime ministers in parliamentary systems are not appointed for a specific term in office and in effect may remain in power through a number of elections and parliaments. For example, Margaret Thatcher was only ever appointed prime minister on "one" occasion, in 1979. She remained "continuously" in power until 1990, though she used the assembly of each House of Commons after a general election to reshuffle her cabinet.
Some states, however, do have a term of office of the prime minister linked to the period in office of the parliament. Hence the Irish Taoiseach is formally 'renominated' after every general election. (Some constitutional experts have questioned whether this process is actually in keeping with the provisions of the Irish constitution, which "appear" to suggest that a taoiseach should remain in office, without the requirement of a renomination, unless s/he has clearly lost the general election.) The position of prime minister is normally chosen from the political party that commands majority of seats in the lower house of parliament.
In parliamentary systems, governments are generally required to have the confidence of the lower house of parliament (though a small minority of parliaments, by giving a right to block supply to upper houses, in effect make the cabinet responsible to both houses, though in reality upper houses, even when they have the power, rarely exercise it). Where they lose a "vote of confidence", have a "motion of no confidence" passed against them, or where they lose supply, most constitutional systems require either:
The latter in effect allows the government to appeal the opposition of parliament to the electorate. However, in many jurisdictions a head of state "may" refuse a parliamentary dissolution, requiring the resignation of the prime minister and his or her government. In most modern parliamentary systems, the prime minister is the person who decides when to request a parliamentary dissolution.
Older constitutions often vest this power in the cabinet. In the United Kingdom, for example, the tradition whereby it is the prime minister who requests a dissolution of parliament dates back to 1918. Prior to then, it was the "entire" government that made the request. Similarly, though the modern 1937 Irish constitution grants to the Taoiseach the right to make the request, the earlier 1922 Irish Free State Constitution vested the power in the "Executive Council" (the then name for the Irish cabinet).
In Australia, the Prime Minister is expected to step down if s/he loses the majority support of his/her party under a spill motion as have many such as Tony Abbott, Julia Gillard and Kevin Rudd.
Titles.
In the Russian constitution the prime minister is actually titled "Chairman of the government" while the Irish prime minister is called the (which is rendered into English as "prime minister"), and in Israel he is "Rosh HaMemshalah" meaning "head of the government". In many cases, though commonly used, "prime minister" is not the official title of the office-holder; the Spanish prime minister is the President of the Government ().
Other common forms include president of the council of ministers (for example in Italy, ), President of the Executive Council, or Minister-President. In the Nordic countries the prime minister is called "statsminister" in the native languages (. minister of state). In federations, the head of government of subnational entities such as provinces is most commonly known as the premier, chief minister, governor or minister-president.
The convention in the English language is to call nearly all national heads of government "prime minister" (sometimes modified to the equivalent term of premier), regardless of the correct title of the head of government as applied in his or her respective country. The few exceptions to the rule are Germany and Austria, whose heads of government titles are almost always translated as Chancellor; Monaco, whose head of government is referred to as the Minister of State; and Vatican City, for which the head of government is titled the Secretary of State. In the case of Ireland, the head of government is occasionally referred to as the Taoiseach by English speakers. A stand-out case is the President of Iran, who is not actually a head of state, but the head of the government of Iran. He is referred to as "president" in both the Persian and English languages.
In non-Commonwealth countries the prime minister may be entitled to the style of Excellency like a president. In some Commonwealth countries prime ministers and former prime ministers are styled Right Honourable due to their position, for example in the Prime Minister of Canada. In the United Kingdom the prime minister and former prime ministers may appear to also be styled Right Honourable, however this is not due to their position as head of government but as a privilege of being current members of Her Majesty's Most Honourable Privy Council.
In the UK, where devolved government is in place, the leaders of the Scottish, Northern Irish and Welsh Governments are styled First Minister. In India, The Prime Minister is referred to as ""Pradhan Mantri"", meaning "prime minister". In Pakistan, the prime minister is referred to as ""Wazir-e-Azam"", meaning "Grand Vizier".
Organisational structure.
The Prime Minister's executive office is usually called the Office of the Prime Minister in the case of the Canada and other Commonwealth countries, it is called Cabinet Office in United Kingdom. Some Prime Minister's office do include the role of Cabinet. In other countries, it is called the Prime Minister's Department or the Department of the Prime Minister and Cabinet as for Australia.
Description of the role.
Wilfried Martens, who served as Prime Minister of Belgium, described his role as follows:
Lists of prime ministers.
The following table groups the list of past and present prime ministers and details information available in those lists.

</doc>
<doc id="24110" url="https://en.wikipedia.org/wiki?curid=24110" title="President">
President

A president is the leader of a country or a division or part of a country, typically a republic, a democracy, or a dictatorship. The title "president" is sometimes used by extension for leaders of other groups, including corporate entities.
Etymologically, a "president" is one who (from Latin "prae-" "before" + "sedere" "to sit"; giving the term "praeses"). Originally, the term referred to the presiding officer of a ceremony or meeting (i.e., chairman), but today it most commonly refers to an executive official. Among other things, "President" today is a common title for the heads of state of most republics, whether presidential republics, semi-presidential republics or parliamentary republics.
Title.
The title "President" is derived from the Latin "prae-" "before" + "sedere" "to sit." As such, it originally designated the officer who presides over or "sits before" a gathering and ensures that debate is 
conducted according to the rules of order ("see also" chairman and speaker). Early examples are from the universities of Oxford and Cambridge (from 1464) and the founding President of the Royal Society William Brouncker in 1660. This usage survives today in the title of such offices as "President of the Board of Trade" and "Lord President of the Council" in the United Kingdom, as well as "President of the Senate" (one of the roles constitutionally assigned to the Vice-President of the United States). The officiating priest at certain Anglican religious services, too, is sometimes called the "President" in this sense. However the most common modern usage is as the title of a head of state in a republic.
In pre-revolutionary France, the president of a "Parlement" evolved into a powerful magistrate, a member of the so-called "noblesse de robe" ("nobility of the gown"), with considerable judicial as well as administrative authority. The name referred to her primary role of presiding over trials and other hearings. In the 17th and 18th centuries, seats in the "Parlements," including presidencies, became effectively hereditary, since the holder of the office could ensure that it would pass to an heir by paying the crown a special tax known as the "paulette". The post of "first president" ("premier président"), however, could only be held by the King's nominees. The "Parlements" were abolished by the French Revolution. In modern France the chief judge of a court is known as its president ("président de la cour").
The first usage of the word 'president' to denote the highest official in a government was during the Commonwealth of England. After the abolition of the monarchy the English Council of State, whose members were elected by the House of Commons, became the executive government of the Commonwealth. The Council of State was the successor of the Privy Council, which had previously been headed by the Lord President; its successor the Council of State was also headed by a Lord President, the first of which was John Bradshaw. However, the Lord President alone was not head of state, because that office was vested in the council as a whole.
The modern usage of the term 'president' to designate a single person who is the head of state of a republic can be traced directly to the United States Constitution of 1787, which created the office of President of the United States. Previous American governments had included "presidents" (such as the president of the Continental Congress or the president of the Massachusetts Provincial Congress), but these were presiding officers in the older sense, with no executive authority. It has been suggested that the executive use of the term was borrowed from early American colleges and universities, which were usually headed by a "president." British universities were headed by an official called the "Chancellor" (typically a ceremonial position) while the chief administrator held the title of "Vice-Chancellor". But America's first institutions of higher learning (such as Harvard University and Yale University) didn't resemble a full-sized university so much as one of its constituent colleges. A number of colleges at Cambridge University featured an official called the "President". The head, for instance, of Magdalene College, Cambridge was called the "master" and her second the "president." The first president of Harvard, Henry Dunster, had been educated at Magdalene. Some have speculated that he borrowed the term out of a sense of humility, considering himself only a temporary place-holder. The presiding official of Yale College, originally a "Rector" (after the usage of continental European universities), became "President" in 1745.
A common style of address for presidents, "Mr/Mrs. President," is borrowed from British Parliamentary tradition, in which the presiding Speaker of the House of Commons is referred to as "Mr/Mrs. Speaker." Coincidentally, this usage resembles the older French custom of referring to the president of a "parlement" as ""Monsieur/Madame le Président"", a form of address that in modern France applies to both the President of the Republic and to chief judges. Similarly, the Speaker of the Canadian House of Commons is addressed by francophone parliamentarians as ""Monsieur/Madame Président(e)"". In Pierre Choderlos de Laclos's novel "Les Liaisons Dangereuses" of 1782, the character identified as "Madame la Présidente de Tourvel" ("Madam President of Tourvel") is the wife of a magistrate in a "parlement". The fictional name Tourvel refers not to the "parlement" in which the magistrate sits, but rather, in imitation of an aristocratic title, to his private estate.
Once the United States adopted the title of "President" for its republican Head of State, many other nations followed suit. Haiti became the first presidential republic in Latin America when Henri Christophe assumed the title in 1807. Almost all of the American nations that became independent from Spain in the early 1810s and 1820s chose a US-style president as their chief executive. The first European president was the President of the Italian Republic of 1802, a client state of revolutionary France, in the person of Napoleon Bonaparte. The first African President was the President of Liberia (1848), while the first Asian president was the President of the Republic of China (1912).
In the twentieth and twenty-first centuries, the powers of presidencies have varied from country to country. The spectrum of power has included presidents-for-life and hereditary presidencies to ceremonial heads of state.
Presidents in the countries with a democratic or representative form of government are usually elected for a specified period of time and in some cases may be re-elected by the same process by which they are appointed, i.e. in many nations, periodic popular elections. The powers vested in such presidents vary considerably. Some presidencies, such as that of Ireland, are largely ceremonial, whereas other systems vest the President with substantive powers such as the appointment and dismissal of prime ministers or cabinets, the power to declare war, and powers of veto on legislation. In many nations the President is also the Commander-in-Chief of the nation's armed forces, though once again this can range from a ceremonial role to one with considerable authority.
Presidential systems.
In states with a presidential system of government, the president exercises the functions of head of state and head of government, i.e. the president directs the executive branch of government.
Presidents in this system are either "directly" elected by popular vote or "indirectly" elected by an electoral college or some other democratically elected body.
In the United States, the President is "indirectly" elected by the Electoral College made up of electors chosen by voters in the presidential election. In most U.S. states, each elector is committed to voting for a specified candidate determined by the popular vote in each state, so that the people, in voting for each elector, are in effect voting for the candidate. However, for various reasons the numbers of electors in favour of each candidate are unlikely to be proportional to the popular vote. Thus in four close U.S. elections (1824, 1876, 1888, and 2000), the candidate with the most popular votes still lost the election.
In Mexico, the president is "directly" elected for a six-year term by popular vote. The candidate who wins the most votes is elected president even without an absolute majority. The president may never get another term. The 2006 Mexican elections had a fierce competition, the electoral results showed a minimal difference between the two most voted candidates and such difference was just about the 0.58% of the total vote. The Federal Electoral Tribunal declared an elected President after a controversial post-electoral process.
In Brazil, the president is "directly" elected for a four-year term by popular vote. A candidate has to have more than 50% of the valid votes. If no candidates achieve a majority of the votes, there is a runoff election between the two candidates with most votes. Again, a candidate needs a majority of the vote to be elected. In Brazil, a president cannot be elected to more than two consecutive terms, but there is no limit on the number of terms a president can serve.
Many South American, Central American, and African nations follow the presidential model.
Semi-presidential systems.
A second system is the semi-presidential system, also known as the French system. In this system, as in the parliamentary system, there are both a president and a prime minister; but unlike the parliamentary system, the president may have significant day-to-day power. For example, in France, when his party controls the majority of seats in the National Assembly, the president can operate closely with the parliament and prime minister, and work towards a common agenda. When the National Assembly is controlled by his opponents, however, the president can find himself marginalized with the opposition party prime minister exercising most of the power. Though the prime minister remains an appointee of the president, the president must obey the rules of parliament, and select a leader from the house's majority holding party. Thus, sometimes the president and prime minister can be allies, sometimes rivals; the latter situation is known in France as cohabitation. Variants of the French semi-presidential system, developed at the beginning of the Fifth Republic by Charles de Gaulle, are used in France, Romania, Sri Lanka and several post-colonial countries which have emulated the French model.
Parliamentary systems.
Another system is the parliamentary republic, where the presidency is largely ceremonial with either "de facto" no significant executive authority (such as the President of Austria) or "de jure" no significant executive power (such as the President of Ireland). Countries using this system include Austria, Czech Republic, Germany, Greece, Hungary, Iceland, India, Ireland, Israel, Italy, Malta, Pakistan, Poland, Turkey, Singapore.
Another less common type of parliamentary republic has no separate head of state, the head of state is also the head of government but unlike a presidential system is elected by and accountable to a parliament, and most commonly referred to as a president not a prime minister. Countries using this system include Botswana and South Africa.
Collective presidency.
Only a tiny minority of modern republics do not have a single head of state. Some examples of this are:
Dictatorships.
In dictatorships, the title is frequently taken by self-appointed or military-backed leaders. Such is the case in many states: Idi Amin in Uganda, Mobutu Sese Seko in Zaire, Ferdinand Marcos in Philippines and Saddam Hussein in Iraq are some examples. Other presidents in authoritarian states have wielded only symbolic or no power such as Craveiro Lopes in Portugal and Joaquín Balaguer under the "Trujillo Era" of the Dominican Republic.
President for Life is a title assumed by some dictators to try to ensure that their authority or legitimacy is never questioned. Ironically, most leaders who proclaim themselves President for Life do not in fact successfully serve a life term. On the other hand, presidents like Alexandre Pétion, Rafael Carrera, Josip Broz Tito and François Duvalier died in office. Kim Il-sung was named Eternal President of the Republic after his death.
Lucius Cornelius Sulla appointed himself in 82 BC to an entirely new office, "dictator rei publicae constituendae causa", which was functionally identical to the dictatorate "rei gerendae causa" except that it lacked any set time limit, although Sulla held this office for over two years before he voluntarily abdicated and retired from public life.
The second well-known incident of a leader extending his term indefinitely was Roman dictator Julius Caesar, who made himself "Perpetual Dictator" (commonly mistranslated as 'Dictator-for-life') in 45 BC. His actions would later be mimicked by the French leader Napoleon Bonaparte who was appointed "First Consul for life" in 1802.
Several presidents have ruled until their death, but they have not proclaimed themselves as President for Life. For instance, Nicolae Ceauşescu of Romania, who ruled until his execution (see Romanian Revolution).
Presidential symbols.
As the country's head of state, in most countries the president is entitled to certain perquisites, and may have a prestigious residence; often a lavish mansion or palace, sometimes more than one (e.g. summer and winter residence, country retreat) – for symbols of office, such as an official uniform, decorations, a presidential seal, coat of arms, flag and other visible accessories; military honours such as gun salutes, ruffles and flourishes, and a presidential guard. A common presidential symbol is the presidential sashes worn by mostly Latin American presidents as a symbol of the presidency's continuity, and presenting the sash to the new president.
Presidential chronologies.
United Nations member countries in columns, other entities at the beginning:
Titles for non-heads of state.
As head of government.
Some countries with parliamentary systems use a term meaning/translating as 'president' (in some languages indistinguishable from chairman) for the head of parliamentary government, often as President of the Government, President of the Council of Ministers or President of the Executive Council.
However, such an official is explicitly not the president of the "country". Rather, he/she is called a president in an older sense of the word, to denote the fact that he/she heads the "cabinet". A separate head of state generally exists in their country that instead serves as the president or monarch of the country.
Thus, such officials are really premiers, and to avoid confusion are often described simply as 'prime minister' when being mentioned internationally.
There are several examples for this kind of presidency:
Other executive positions.
Sub-national.
President can also be the title of the chief executive at a lower administrative level, such as the parish presidents of the parishes of the U.S. state of Louisiana, the presiding member of city council for villages in the U.S. state of Illinois, or the municipal presidents of Mexico's municipalities. Perhaps the best known sub-national presidents are the borough presidents of the Five Boroughs of New York City. In the early years of the United States, some states had "Presidents" as well, instead of "Governors".
Poland.
In Poland the "President of the City" () is the executive authority of the municipality elected in direct elections, the equivalent of the mayor. The Office of the President (Mayor) is also found in Germany and Switzerland .
United Kingdom.
The Lord President of the Council is one of the Great Officers of State in England who presides over meetings of British Privy Council; the Cabinet headed by the Prime Minister is technically a committee of the Council, and all decisions of the Cabinet are formally approved through Orders in Council. Although the Lord President is a member of the Cabinet, the position is largely a ceremonial one and is traditionally given to either the Leader of the House of Commons or the Leader of the House of Lords.
Historically the President of the Board of Trade was a cabinet member.
Dependancies.
In Alderney, the elected head of government is called the President of the States of Alderney.
In the Isle of Man, there is a President of Tynwald.
Spain.
In Spain, the executive leaders of the autonomous communities (regions) are called presidents. In each community, they can be called "Presidente de la Comunidad" or "Presidente del Consejo" among others. They are elected by their respective regional assemblies and have similar powers to a state president or governor.
Deputies.
Below a President, there can be a number of or "Vice Presidents" (or occasionally "Deputy Presidents") and sometimes several "Assistant Presidents" or "Assistant Vice Presidents", depending on the organisation and its size. These posts do not hold the same power but more of a subordinate position to the president. However, power can be transferred in special circumstances to the Deputy or Vice President. Normally Vice Presidents hold some power and special responsibilities below that of the President. The difference between Vice/Deputy Presidents and Assistant/Associate Vice Presidents is the former are legally allowed to run an organisation, exercising the same powers (as well as being second in command) whereas the latter are not.
Legislatures.
In some countries the speaker of their unicameral legislatures, or of one or both houses of bicameral legislatures, the speakers have the title of President of "the body".
France.
In French legal terminology, the president of a court consisting of multiple judges is the foremost judge; he chairs the meeting of the court and directs the debates (and this thus addressed as "Mrs President", "Madame la Présidente", Mr President", or "Monsieur le Président". In general, a court comprises several chambers, each with its own president; thus the most senior of these is called the "first president" (as in: "the First President of the Court of Cassation is the most senior judge in France"). Similarly in English legal practice the most senior judge in each division uses this title (e.g. President of the Family Division, President of the Court of Appeal).
United Kingdom.
In the recently established Supreme Court of the United Kingdom, the most senior judge is called the President of the Supreme Court. The Lady/Lord President of the Court of Session is head of the judiciary in Scotland, and presiding judge (and Senator) of the College of Justice and Court of Session, as well as being Lady/Lord Justice General of Scotland and head of the High Court of Justiciary, the offices having been combined in 1784.
See also.
Head of state:
Other head of government:

</doc>
<doc id="24111" url="https://en.wikipedia.org/wiki?curid=24111" title="The Presidents of the United States of America (band)">
The Presidents of the United States of America (band)

The Presidents of the United States of America, sometimes referred to as PUSA, The Presidents or Pot USA, are a twice Grammy-nominated American alternative rock band. The band formed in Seattle, Washington, in 1993. The three-piece group currently comprises vocalist and "basitarist" Chris Ballew, drummer and vocalist Jason Finn with "guitbassist" and vocalist Andrew McKeag. "Guitbassist" and vocalist Dave Dederer was a member of the band for 11 years before leaving in 2004. They have released six studio albums since forming in 1993. On February 14, 2014 they released their latest album, "Kudos to You!"
Biography.
Early years (1993–1994).
The band was formed in late 1993 by Chris Ballew (bass guitar and lead vocals) and Dave Dederer (guitar and backup vocals), who met while attending The Bush School in Seattle. Ballew had previously been in a punk band called Egg, who wrote many songs that would later be turned into PUSA songs. Initially a drummerless duo, Ballew and Dederer performed a half-dozen or so shows in 1993 as "The Lo-Fis", "The Dynamic Duo", and "Pure Frosting." Ballew eventually came upon the name "The Presidents of the United States of America." Shortly after settling on their name, Ballew and Dederer added drummer Jason Finn; the band played their first show as a trio at Seattle's Romper Room in early December 1993. At the time, Finn was also the drummer in the band Love Battery, who had recently changed record labels from Sub Pop to Atlas Records, an A&M subsidiary.
The Presidents recorded a 10-song cassette, "Froggystyle," in early 1994 in one day at Laundry Room Studios. The band sold the cassette at shows in 1994. Finn also sold the cassette from behind the bar of Seattle's Comet Tavern, where he bar tended.
Rise to fame (1994–1998).
In 1994, the Presidents signed with the tiny Seattle label PopLlama Records and released their self-titled debut in the following year. The band also released a limited edition blue vinyl 7" single, "Fuck California", on C/Z Records. Columbia Records signed the band shortly thereafter and re-released the album in late July 1995. Driven by the singles "Lump", "Peaches", and "Kitty", their debut album has been certified triple Platinum by the RIAA.
A follow-up album, "II," received similar praise, but did not match the commercial success that the Presidents' debut album had, though it was still certified gold in the US.
Throughout 1995, 1996 and 1997, the band made worldwide tours to support their first two albums. In 1996, the band performed a live concert at Mount Rushmore on Presidents Day. They were introduced with: "Ladies and gentlemen, the Presidents of the United States." In addition to relentless touring in the U.S. and Canada, PUSA made multiple tours of Europe, Australia, New Zealand and Japan. They also made many appearances in major print media and on radio and TV, including multiple appearances on The Tonight Show with Jay Leno and the Late Show with David Letterman in the U.S. The Presidents turned down an offer to perform on "Saturday Night Live" in the fall of 1995 because the date conflicted with Ballew's wedding. However in 1996 were a Special Appearance on MAD TV's 11th episode. PUSA began the show with a skit called Public Domain and performed "LUMP" later in the show and "When The Saints go Marching In" in the ending credits.
"Pure Frosting", collaborations and break-up (1998–2000).
The band broke up in January 1998 as Ballew quit to spend more time with his young family and explore other musical terrain. "Pure Frosting," a final album composed of new songs, covers, and demos, was released in 1998. The CD also contained videos for "Lump," "Peaches," "Mach 5," and "Dune Buggy."
"Pure Frosting" featured two songs that had previously been used in a movie and as a television show theme. "Video Killed the Radio Star" was included on the soundtrack for "The Wedding Singer", while "Cleveland Rocks," originally recorded by Ian Hunter, was chosen as the theme song for "The Drew Carey Show." Another song on the album, "Man (Opposable Thumb)", appeared in the Nickelodeon-produced motion picture "Good Burger" but was not directly written or performed for the film.
The Presidents also wrote the theme song for the 1998 TV movie "My Date with the President's Daughter". They also performed a cover of the George of the Jungle theme song for the 1997 movie of the same name. This performance is not available on any of their albums.
In 1998, the group appeared on the album "Happy Hour" by Japanese female rockers Shonen Knife (also a three piece); they did backing vocals on the song "Sushi Bar".
The Presidents also collaborated with Sir Mix-A-Lot as Subset, a short-lived rock and hip-hop band. They had a brief tour and recorded several songs, but never released an album. The band broke up because Sir Mix-A-Lot wanted to take the band in a harder, more electronic direction, but Finn and Dederer were not interested.
Brief reformation and break-up (2000–2004).
The Presidents reunited in 2000 to release a new single, "Jupiter", on MUSICBLITZ Records. Because of the single's popularity, the label convinced the band to release a new album. "Freaked Out & Small" was released that year to critical praise. The band did not tour on or promote the album, which quietly sold 25,000 copies as MUSICBLITZ, an early digital music player, quickly went bankrupt.
Afterwards, the band members once again went their own ways. Ballew continued to produce and record his own work and collaborated with Tad Hutchison of The Young Fresh Fellows as The Chris and Tad Show. Also during this time, The Young Fresh Fellows recorded a song, "Good Times Rock 'N' Roll", about The Presidents, which appeared on the 2001 album "Because We Hate You".
Full reformation and new guitbassist (2003–2010).
In 2003, the band once again reformed. In August 2004, the band released "Love Everybody" on their newly formed indie label PUSA Inc. As with their previous albums, it received praise from many critics. Two singles from the album have been released through the Apple iTunes Store. In late 2004, the rights to the debut album were returned to the band, who have since reissued the album through PUSA Inc. twice: once as a Ten Year Anniversary edition with extra tracks, and again in the spring of 2006 in a low-price edition.
Andrew McKeag, Seattle guitarist (formerly of Uncle Joe's Big Ol' Driver, Shuggie, The Black Panties and others), joined the band on guitbass in late 2004, as an occasional live-performance stand-in for Dave Dederer, who had expressed an interest in spending more time with his family. Since late 2007, Andrew started touring full-time with the band, and later replaced Dederer. Dederer has played live with the band in concerts in Seattle on occasion.
In November 2007, it was announced that the band's next album would be entitled "These Are the Good Times People", which was released on March 11, 2008. They did a live webcast celebrating the album's release from Easy Street records: http://app.synclive.com?show/17772 In December 2007 KEXP played the new song "Bad Times." On February 1, 2008, 107.7-The End (a Seattle radio station) played the first single from the Presidents' new album, title "Mixed Up S.O.B." The music video for the song was directed by "Weird Al" Yankovic. On June 15, 2008, they played for Pet-Aid 2008 in Oregon.
In October 2008, "Lump" was released on the video game "Rock Band 2". "Ladybug", "Feather Pluck'n," and "Dune Buggy" were released as downloadable content for the game on November 4, 2008. In the summer of 2009, The Presidents performed in San Diego at the North Park Music Thing Music & Media Festival which only showcases local bands.
Recent years (2010–present).
In September 2010, The Presidents performed during halftime of the UW-Syracuse game at Husky Stadium.
On March 5, 2011, The Presidents performed a new tribute song, "Can't Stop (Catchin' 'Em All)" at the Nintendo World launch event for the video games Pokémon Black and White.
In 2012, Columbia Records re-released "Lump," a discount greatest hits compilation, without the band's approval or collaboration.
On November 12, 2012, The Presidents performed during halftime of the Sounders-LA Galaxy playoff game at CenturyLink Field.
The Presidents appeared on two Australian morning talk shows in March 2013: Sunrise, and The Morning Show.
In November 2013, the band started a PledgeMusic project in order to release a new studio album. The band met their goal in just over a week, and the album, titled "Kudos to You!", was released on February 14, 2014. The band also released their first full live album, "Thanks for the Feedback" at the same time. Since the beginning of the project, fans were able to pledge on various items in addition to the digital and physical copies of the two albums, such as posters, lyric sheets and instruments signed by the band. A limited edition burgundy and yellow vinyl was also available to pledge on.
Politics.
The band performed for President Bill Clinton at a 1994 Democratic Party fundraiser in Seattle. The band also supported John Kerry in the 2004 U.S. presidential election. On January 17, 2009, The Presidents released a single on the National Public Radio show Weekend America called "Moving In," detailing the journey of Barack Obama in celebration of his inauguration as president.
The former Governor of Washington State, Gary Locke, is featured on the backing vocals of "Volcano" (Live) Year Super Bonus Special Anniversary Edition. The band now endorses Bernie Sanders for the 2016 presidential election.
Solo work.
Following the breakup, each band member devoted time to his own solo projects. Ballew was the most prolific of the three, releasing albums with The Giraffes and The Tycoons, two of his side projects. Dederer collaborated with former Guns N' Roses bassist Duff McKagan as The Gentlemen and in McKagan's perennial hard rock band, Loaded, including contributing to the album "Dark Days". Dederer also played bass in the Seattle band Juke and produced songs for singer/songwriter Gerald Collier. Finn played drums for several bands, including Nevada Bachelors, The Fastbacks and Love Battery, his original band.
Around 2006, Chris Ballew began collaborating with Seattle-based rapper Outtasite as The Feelings Hijackers. They have done local shows and have released two albums.
In 2009, in addition to his continued work with The Presidents, Ballew began recording and performing as children's artist Caspar Babypants.
Instruments.
Ballew and Dederer/McKeag play a basitar and guitbass, which are regular, six-string guitars with special modifications: Ballew's instrument has two bass strings (with which he plays bass parts), and Dederer/McKeag's instrument has three guitar strings (used to play guitar parts). The original idea came from Morphine frontman Mark Sandman, with whom Ballew had previously worked.
Guitars modified in this way use heavy-gauge strings for a heavier sound and are normally tuned in Drop D, though the Presidents play half a step lower in C#.
For a basitar, the strings are placed in the D and G positions. Chris uses a .60 gauge string tuned to C# and a .36 tuned to G#.
On a guitbass, the strings are placed in the A, D, and G positions. .54 gauge tuned to C#, .42 to G#, and a .32 gauge tuned to C#.
Finn's drum kit is currently supplied by Slingerland; his cymbals are a variety of "really good" Sabians including two 13" El Sabor splashes as his main "crash" cymbals, 14" Hi hats and a 20" Ride on his left side.

</doc>
<doc id="24113" url="https://en.wikipedia.org/wiki?curid=24113" title="President of the United States">
President of the United States

The President of the United States of America (POTUS) is the elected head of state and head of government of the United States. The president leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces.
The President of the United States is considered one of the world's most powerful people, leading the world's only contemporary superpower. The role includes being the commander-in-chief of the world's most expensive military with the largest nuclear arsenal and leading the largest economy by real and nominal GDP. The office of the president holds significant hard and soft power both in the United States and abroad.
Article II of the U.S. Constitution vests the executive power of the United States in the president. The power includes execution of federal law, alongside the responsibility of appointing federal executive, diplomatic, regulatory and judicial officers, and concluding treaties with foreign powers with the advice and consent of the Senate. The president is further empowered to grant federal pardons and reprieves, and to convene and adjourn either or both houses of Congress under extraordinary circumstances. The president is largely responsible for dictating the legislative agenda of the party to which the president is enrolled. The president also directs the foreign and domestic policy of the United States. Since the founding of the United States, the power of the president and the federal government has grown substantially.
The president is indirectly elected by the people through the Electoral College to a four-year term, and is one of only two nationally elected federal officers, the other being the Vice President of the United States. The Twenty-second Amendment, adopted in 1951, prohibits anyone from ever being elected to the presidency for a third full term. It also prohibits a person from being elected to the presidency more than once if that person previously had served as president, or acting president, for more than two years of another person's term as president. In all, 43 individuals have served 44 presidencies (counting Cleveland's two non-consecutive terms separately) spanning 56 full four-year terms. On January 20, 2009, Barack Obama became the 44th and current president. On November 6, 2012, he was re-elected and is currently serving the 57th term. The next presidential election is scheduled to take place on November 8, 2016; on January 20, 2017, the newly elected president will take office.
Origin.
In 1776, the Thirteen Colonies, acting through the Second Continental Congress, declared political independence from Great Britain during the American Revolution. The new states, though independent of each other as nation states, recognized the necessity of closely coordinating their efforts against the British. Desiring to avoid anything that remotely resembled a monarchy, Congress negotiated the Articles of Confederation to establish a weak alliance between the states. As a central authority, Congress under the Articles was without any legislative power; it could make its own resolutions, determinations, and regulations, but not any laws, nor any taxes or local commercial regulations enforceable upon citizens. This institutional design reflected the conception of how Americans believed the deposed British system of Crown and Parliament ought to have functioned with respect to the royal dominion: a superintending body for matters that concerned the entire empire. Out from under any monarchy, the states assigned some formerly royal prerogatives ("e.g.", making war, receiving ambassadors, etc.) to Congress, while severally lodging the rest within their own respective state governments. Only after all the states agreed to a resolution settling competing western land claims did the Articles take effect on March 1, 1781, when Maryland became the final state to ratify them.
In 1783, the Treaty of Paris secured independence for each of the former colonies. With peace at hand, the states each turned toward their own internal affairs. By 1786, Americans found their continental borders besieged and weak, their respective economies in crises as neighboring states agitated trade rivalries with one another, witnessed their hard currency pouring into foreign markets to pay for imports, their Mediterranean commerce preyed upon by North African pirates, and their foreign-financed Revolutionary War debts unpaid and accruing interest. Civil and political unrest loomed.
Following the successful resolution of commercial and fishing disputes between Virginia and Maryland at the Mount Vernon Conference in 1785, Virginia called for a trade conference between all the states, set for September 1786 in Annapolis, Maryland, with an aim toward resolving further-reaching interstate commercial antagonisms. When the convention failed for lack of attendance due to suspicions among most of the other states, the Annapolis delegates called for a convention to offer revisions to the Articles, to be held the next spring in Philadelphia. Prospects for the next convention appeared bleak until James Madison and Edmund Randolph succeeded in securing George Washington's attendance to Philadelphia as a delegate for Virginia.
When the Constitutional Convention convened in May 1787, the 12 state delegations in attendance (Rhode Island did not send delegates) brought with them an accumulated experience over a diverse set of institutional arrangements between legislative and executive branches from within their respective state governments. Most states maintained a weak executive without veto or appointment powers, elected annually by the legislature to a single term only, sharing power with an executive council, and countered by a strong legislature. New York offered the greatest exception, having a strong, unitary governor with veto and appointment power elected to a three-year term, and eligible for reelection to an indefinite number of terms thereafter. It was through the closed-door negotiations at Philadelphia that the presidency framed in the U.S. Constitution emerged.
Powers and duties.
Article I legislative role.
The first power the Constitution confers upon the president is the veto. The Presentment Clause requires any bill passed by Congress to be presented to the president before it can become law. Once the legislation has been presented, the president has three options:
In 1996, Congress attempted to enhance the president's veto power with the Line Item Veto Act. The legislation empowered the president to sign any spending bill into law while simultaneously striking certain spending items within the bill, particularly any new spending, any amount of discretionary spending, or any new limited tax benefit. Congress could then repass that particular item. If the president then vetoed the new legislation, Congress could override the veto by its ordinary means, a two-thirds vote in both houses. In "Clinton v. City of New York", , the U.S. Supreme Court ruled such a legislative alteration of the veto power to be unconstitutional.
Article II executive powers.
War and foreign affairs powers.
Perhaps the most important of all presidential powers is the command of the United States Armed Forces as its commander-in-chief. While the power to declare war is constitutionally vested in Congress, the president has ultimate responsibility for direction and disposition of the military. The present-day operational command of the Armed Forces (belonging to the Department of Defense) is normally exercised through the Secretary of Defense, with assistance of the Chairman of the Joint Chiefs of Staff, to the Combatant Commands, as outlined in the presidentially approved Unified Command Plan (UCP). The framers of the Constitution took care to limit the president's powers regarding the military; Alexander Hamilton explains this in Federalist No. 69: Congress, pursuant to the War Powers Resolution, must authorize any troop deployments longer than 60 days, although that process relies on triggering mechanisms that have never been employed, rendering it ineffectual. Additionally, Congress provides a check to presidential military power through its control over military spending and regulation. While historically presidents initiated the process for going to war, critics have charged that there have been several conflicts in which presidents did not get official declarations, including Theodore Roosevelt's military move into Panama in 1903, the Korean War, the Vietnam War, and the invasions of Grenada in 1983 and Panama in 1990.
Along with the armed forces, the president also directs U.S. foreign policy. Through the Department of State and the Department of Defense, the president is responsible for the protection of Americans abroad and of foreign nationals in the United States. The president decides whether to recognize new nations and new governments, and negotiates treaties with other nations, which become binding on the United States when approved by two-thirds vote of the Senate.
Although not constitutionally provided, presidents also sometimes employ "executive agreements" in foreign relations. These agreements frequently regard administrative policy choices germane to executive power; for example, the extent to which either country presents an armed presence in a given area, how each country will enforce copyright treaties, or how each country will process foreign mail. However, the 20th century witnessed a vast expansion of the use of executive agreements, and critics have challenged the extent of that use as supplanting the treaty process and removing constitutionally prescribed checks and balances over the executive in foreign relations. Supporters counter that the agreements offer a pragmatic solution when the need for swift, secret, and/or concerted action arises.
Administrative powers.
The president is the head of the executive branch of the federal government and is constitutionally obligated to "take care that the laws be faithfully executed." The executive branch has over four million employees, including members of the military.
Presidents make numerous executive branch appointments: an incoming president may make up to 6,000 before taking office and 8,000 more while serving. Ambassadors, members of the Cabinet, and other federal officers, are all appointed by a president with the "advice and consent" of a majority of the Senate. When the Senate is in recess for at least ten days, the president may make recess appointments. Recess appointments are temporary and expire at the end of the next session of the Senate.
The power of a president to fire executive officials has long been a contentious political issue. Generally, a president may remove purely executive officials at will. However, Congress can curtail and constrain a president's authority to fire commissioners of independent regulatory agencies and certain inferior executive officers by statute.
The president additionally possesses the ability to direct much of the executive branch through executive orders that are grounded in federal law or constitutionally granted executive power. Executive orders are reviewable by federal courts and can be superseded by federal legislation.
To manage the growing federal bureaucracy, Presidents have gradually surrounded themselves with many layers of staff, who were eventually organized into the Executive Office of the President of the United States. Within the Executive Office, the President's innermost layer of aides (and their assistants) are located in the White House Office.
Juridical powers.
The president also has the power to nominate federal judges, including members of the United States courts of appeals and the Supreme Court of the United States. However, these nominations do require Senate confirmation. Securing Senate approval can provide a major obstacle for presidents who wish to orient the federal judiciary toward a particular ideological stance. When nominating judges to U.S. district courts, presidents often respect the long-standing tradition of Senatorial courtesy. Presidents may also grant pardons and reprieves, as is often done just before the end of a presidential term, not without controversy.
Historically, two doctrines concerning executive power have developed that enable the president to exercise executive power with a degree of autonomy. The first is executive privilege, which allows the president to withhold from disclosure any communications made directly to the president in the performance of executive duties. George Washington first claimed privilege when Congress requested to see Chief Justice John Jay's notes from an unpopular treaty negotiation with Great Britain. While not enshrined in the Constitution, or any other law, Washington's action created the precedent for the privilege. When Richard Nixon tried to use executive privilege as a reason for not turning over subpoenaed evidence to Congress during the Watergate scandal, the Supreme Court ruled in "United States v. Nixon", , that executive privilege did not apply in cases where a president was attempting to avoid criminal prosecution. When President Bill Clinton attempted to use executive privilege regarding the Lewinsky scandal, the Supreme Court ruled in "Clinton v. Jones", , that the privilege also could not be used in civil suits. These cases established the legal precedent that executive privilege is valid, although the exact extent of the privilege has yet to be clearly defined. Additionally, federal courts have allowed this privilege to radiate outward and protect other executive branch employees, but have weakened that protection for those executive branch communications that do not involve the president.
The state secrets privilege allows the president and the executive branch to withhold information or documents from discovery in legal proceedings if such release would harm national security. Precedent for the privilege arose early in the 19th century when Thomas Jefferson refused to release military documents in the treason trial of Aaron Burr and again in "Totten v. United States" , when the Supreme Court dismissed a case brought by a former Union spy. However, the privilege was not formally recognized by the U.S. Supreme Court until "United States v. Reynolds" , where it was held to be a common law evidentiary privilege. Before the September 11 attacks, use of the privilege had been rare, but increasing in frequency. Since 2001, the government has asserted the privilege in more cases and at earlier stages of the litigation, thus in some instances causing dismissal of the suits before reaching the merits of the claims, as in the Ninth Circuit's ruling in "Mohamed v. Jeppesen Dataplan, Inc." Critics of the privilege claim its use has become a tool for the government to cover up illegal or embarrassing government actions.
Legislative facilitator.
The Constitution's Ineligibility Clause prevents the President (and all other executive officers) from simultaneously being a member of Congress. Therefore, the president cannot directly introduce legislative proposals for consideration in Congress. However, the president can take an indirect role in shaping legislation, especially if the president's political party has a majority in one or both houses of Congress. For example, the president or other officials of the executive branch may draft legislation and then ask senators or representatives to introduce these drafts into Congress. The president can further influence the legislative branch through constitutionally mandated, periodic reports to Congress. These reports may be either written or oral, but today are given as the State of the Union address, which often outlines the president's legislative proposals for the coming year. Additionally, the president may attempt to have Congress alter proposed legislation by threatening to veto that legislation unless requested changes are made.
In the 20th century critics began charging that too many legislative and budgetary powers have slid into the hands of presidents that should belong to Congress. As the head of the executive branch, presidents control a vast array of agencies that can issue regulations with little oversight from Congress. One critic charged that presidents could appoint a "virtual army of 'czars' – each wholly unaccountable to Congress yet tasked with spearheading major policy efforts for the White House." Presidents have been criticized for making signing statements when signing congressional legislation about how they understand a bill or plan to execute it. This practice has been criticized by the American Bar Association as unconstitutional. Conservative commentator George Will wrote of an "increasingly swollen executive branch" and "the eclipse of Congress."
According to of the Constitution, the president may convene either or both houses of Congress. If both houses cannot agree on a date of adjournment, the president may appoint a date for Congress to adjourn.
Ceremonial roles.
As head of state, the president can fulfill traditions established by previous presidents. William Howard Taft started the tradition of throwing out the ceremonial first pitch in 1910 at Griffith Stadium, Washington, D.C., on the ' Opening Day. Every president since Taft, except for Jimmy Carter, threw out at least one ceremonial first ball or pitch for Opening Day, the All-Star Game, or the World Series, usually with much fanfare.
The President of the United States has served as the honorary president of the Boy Scouts of America since the founding of the organization.
Other presidential traditions are associated with American holidays. Rutherford B. Hayes began in 1878 the first White House egg rolling for local children. Beginning in 1947 during the Harry S. Truman administration, every Thanksgiving the president is presented with a live domestic turkey during the annual national thanksgiving turkey presentation held at the White House. Since 1989, when the custom of "pardoning" the turkey was formalized by George H. W. Bush, the turkey has been taken to a farm where it will live out the rest of its natural life.
Presidential traditions also involve the president's role as head of government. Many outgoing presidents since James Buchanan traditionally give advice to their successor during the presidential transition. Ronald Reagan and his successors have also left a private message on the desk of the Oval Office on Inauguration Day for the incoming president.
During a state visit by a foreign head of state, the president typically hosts a State Arrival Ceremony held on the South Lawn, a custom begun by John F. Kennedy in 1961. This is followed by a state dinner given by the president which is held in the State Dining Room later in the evening.
The modern presidency holds the president as one of the nation's premier celebrities. Some argue that images of the presidency have a tendency to be manipulated by administration public relations officials as well as by presidents themselves. One critic described the presidency as "propagandized leadership" which has a "mesmerizing power surrounding the office." Administration public relations managers staged carefully crafted photo-ops of smiling presidents with smiling crowds for television cameras. One critic wrote the image of John F. Kennedy was described as carefully framed "in rich detail" which "drew on the power of myth" regarding the incident of PT 109 and wrote that Kennedy understood how to use images to further his presidential ambitions. As a result, some political commentators have opined that American voters have unrealistic expectations of presidents: voters expect a president to "drive the economy, vanquish enemies, lead the free world, comfort tornado victims, heal the national soul and protect borrowers from hidden credit-card fees."
Critics of presidency's evolution.
Most of the nation's Founding Fathers expected the Congress, which was the first branch of government described in the Constitution, to be the dominant branch of government; they did not expect a strong executive. However, presidential power has shifted over time, which has resulted in claims that the modern presidency has become too powerful, unchecked, unbalanced, and "monarchist" in nature. Critic Dana D. Nelson believes presidents over the past thirty years have worked towards "undivided presidential control of the executive branch and its agencies." She criticizes proponents of the unitary executive for expanding "the many existing uncheckable executive powers – such as executive orders, decrees, memorandums, proclamations, national security directives and legislative signing statements – that already allow presidents to enact a good deal of foreign and domestic policy without aid, interference or consent from Congress." Activist Bill Wilson opined that the expanded presidency was "the greatest threat ever to individual freedom and democratic rule."
Selection process.
Eligibility.
The Twelfth Amendment precludes anyone ineligible to being the president from becoming the vice president.
A person who meets the above qualifications is still disqualified from holding the office of president under any of the following conditions:
Campaigns and nomination.
The modern presidential campaign begins before the primary elections, which the two major political parties use to clear the field of candidates before their national nominating conventions, where the most successful candidate is made the party's nominee for president. Typically, the party's presidential candidate chooses a vice presidential nominee, and this choice is rubber-stamped by the convention. The most common previous profession by U.S. presidents is lawyer.
Nominees participate in nationally televised debates, and while the debates are usually restricted to the Democratic and Republican nominees, third party candidates may be invited, such as Ross Perot in the 1992 debates. Nominees campaign across the country to explain their views, convince voters and solicit contributions. Much of the modern electoral process is concerned with winning swing states through frequent visits and mass media advertising drives.
Election and oath.
The president is elected indirectly. A number of electors, collectively known as the Electoral College, officially select the president. On Election Day, voters in each of the states and the District of Columbia cast ballots for these electors. Each state is allocated a number of electors, equal to the size of its delegation in both Houses of Congress combined. Generally, the ticket that wins the most votes in a state wins all of that state's electoral votes and thus has its slate of electors chosen to vote in the Electoral College.
The winning slate of electors meet at its state's capital on the first Monday after the second Wednesday in December, about six weeks after the election, to vote. They then send a record of that vote to Congress. The vote of the electors is opened by the sitting vice president—acting in that role's capacity as President of the Senate—and read aloud to a joint session of the incoming Congress, which was elected at the same time as the president.
Pursuant to the Twentieth Amendment, the president's term of office begins at noon on January 20 of the year following the election. This date, known as Inauguration Day, marks the beginning of the four-year terms of both the president and the vice president. Before executing the powers of the office, a president is constitutionally required to take the presidential oath:
Although not required, presidents have traditionally palmed a Bible while swearing the oath and have added, "So help me God!" to the end of the oath. Further, although the oath may be administered by any person authorized by law to administer oaths, presidents are traditionally sworn in by the Chief Justice of the United States.
Tenure and term limits.
The term of office for president and vice president is four years. George Washington, the first president, set an unofficial precedent of serving only two terms, which subsequent presidents followed until 1940. Before Franklin D. Roosevelt, attempts at a third term were encouraged by supporters of Ulysses S. Grant and Theodore Roosevelt; neither of these attempts succeeded. In 1940, Franklin D. Roosevelt declined to seek a third term, but allowed his political party to "draft" him as its presidential candidate and was subsequently elected to a third term. In 1941, the United States entered World War II, leading voters to elect Roosevelt to a fourth term in 1944.
After the war, and in response to Roosevelt being elected to third and fourth terms, the Twenty-second Amendment was adopted. The amendment bars anyone from being elected president more than twice, or once if that person served more than half of another president's term. Harry S. Truman, president when this amendment was adopted, was exempted from its limitations and briefly sought a third (a second full) term before withdrawing from the 1952 election.
Since the amendment's adoption, four presidents have served two full terms: Dwight D. Eisenhower, Ronald Reagan, Bill Clinton, and George W. Bush. Barack Obama has been elected to a second term. Jimmy Carter and George H. W. Bush sought a second term, but were defeated. Richard Nixon was elected to a second term, but resigned before completing it. Lyndon B. Johnson was the only president under the amendment to be eligible to serve more than two terms in total, having served for only fourteen months following John F. Kennedy's assassination. However, Johnson withdrew from the 1968 Democratic Primary, surprising many Americans. Gerald Ford sought a full term, after serving out the last two years and five months of Nixon's second term, but was not elected.
Vacancy or disability.
Vacancies in the office of President may arise under several possible circumstances: death, resignation and removal from office.
Under Section 3 of the Twenty-fifth Amendment, the president may transfer the presidential powers and duties to the vice president, who then becomes acting president, by transmitting a statement to the Speaker of the House and the President "pro tempore" of the Senate stating the reasons for the transfer. The president resumes the discharge of the presidential powers and duties upon transmitting, to those two officials, a written declaration stating that resumption. This transfer of power may occur for any reason the president considers appropriate; in 2002 and again in 2007, President George W. Bush briefly transferred presidential authority to Vice President Dick Cheney. In both cases, this was done to accommodate a medical procedure which required Bush to be sedated; both times, Bush returned to duty later the same day.
Under Section 4 of the Twenty-fifth Amendment, the vice president, in conjunction with a majority of the Cabinet, may transfer the presidential powers and duties from the president to the vice president by transmitting a written declaration to the Speaker of the House and the president "pro tempore" of the Senate that the president is unable to discharge the presidential powers and duties. If this occurs, then the vice president will assume the presidential powers and duties as acting president; however, the president can declare that no such inability exists and resume the discharge of the presidential powers and duties. If the vice president and Cabinet contest this claim, it is up to Congress, which must meet within two days if not already in session, to decide the merit of the claim.
The United States Constitution mentions the resignation of the president, but does not regulate its form or the conditions for its validity. Pursuant to federal law, the only valid evidence of the president's resignation is a written instrument to that effect, signed by the president and delivered to the office of the Secretary of State. This has only occurred once, when Richard Nixon delivered a letter to Henry Kissinger to that effect.
Section 1 of the Twenty-fifth Amendment states that the vice president becomes president upon the removal from office, death or resignation of the preceding president. The Presidential Succession Act of 1947 provides that if the offices of President and Vice President are each either vacant or are held by a disabled person, the next officer in the presidential line of succession, the Speaker of the House, becomes acting president. The line then extends to the President pro tempore of the Senate, followed by every member of the Cabinet. These persons must fulfill all eligibility requirements of the office of President to be eligible to become acting president; ineligible individuals are skipped. There has never been a special election for the office of President.
Compensation.
Since 2001, the president has earned a $400,000 annual salary, along with a $50,000 annual expense account, a $100,000 nontaxable travel account, and $19,000 for entertainment. The most recent raise in salary was approved by Congress and President Bill Clinton in 1999 and went into effect in 2001.
The White House in Washington, D.C., serves as the official place of residence for the president. As well as access to the White House staff, facilities available to the president include medical care, recreation, housekeeping, and security services. The government pays for state dinners and other official functions, but the president pays for personal, family and guest dry cleaning and food; the high food bill often amazes new residents. Naval Support Facility Thurmont, popularly known as Camp David, is a mountain-based military camp in Frederick County, Maryland, used as a country retreat and for high alert protection of the president and guests. Blair House, located next to the Eisenhower Executive Office Building at the White House Complex and Lafayette Park, is a complex of four connected townhouses exceeding of floor space which serves as the president's official guest house and as a secondary residence for the president if needed.
For ground travel, the president uses the presidential state car, which is an armored limousine built on a heavily modified Cadillac-based chassis. One of two identical Boeing VC-25 aircraft, which are extensively modified versions of Boeing 747-200B airliners, serve as long distance travel for the president and are referred to as "Air Force One" while the president is on board (although any U.S. Air Force aircraft the President is aboard is designated as "Air Force One" for the duration of the flight). In-country trips are typically handled with just one of the two planes while overseas trips are handled with both, one primary and one backup. Any civilian aircraft the President is aboard is designated Executive One for the flight. The president also has access to a fleet of thirty-five U.S. Marine Corps helicopters of varying models, designated "Marine One" when the president is aboard any particular one in the fleet. Flights are typically handled with as many as five helicopters all flying together and frequently swapping positions as to disguise which helicopter the President is actually aboard to any would-be threats.
The U.S. Secret Service is charged with protecting the sitting president and the first family. As part of their protection, presidents, first ladies, their children and other immediate family members, and other prominent persons and locations are assigned Secret Service codenames. The use of such names was originally for security purposes and dates to a time when sensitive electronic communications were not routinely encrypted; today, the names simply serve for purposes of brevity, clarity, and tradition.
Post-presidency.
Beginning in 1959, all living former presidents were granted a pension, an office, and a staff. The pension has increased numerous times with Congressional approval. Retired presidents now receive a pension based on the salary of the current administration's cabinet secretaries, which was $199,700 each year in 2012. Former presidents who served in Congress may also collect congressional pensions. The Former Presidents Act, as amended, also provides former presidents with travel funds and franking privileges. Prior to 1997, all former presidents, their spouses, and their children until age 16 were protected by the Secret Service until the president's death. In 1997, Congress passed legislation limiting secret service protection to no more than 10 years from the date a president leaves office. On January 10, 2013, President Obama signed legislation reinstating lifetime secret service protection for him, George W. Bush, and all subsequent presidents. A spouse who remarries is no longer eligible for secret service protection.
Some presidents have had significant careers after leaving office. Prominent examples include William Howard Taft's tenure as Chief Justice of the United States and Herbert Hoover's work on government reorganization after World War II. Grover Cleveland, whose bid for reelection failed in 1888, was elected president again four years later in 1892. Two former presidents served in Congress after leaving the White House: John Quincy Adams was elected to the House of Representatives, serving there for seventeen years, and Andrew Johnson returned to the Senate in 1875. John Tyler served in the provisional Congress of the Confederate States during the Civil War and was elected to the Confederate House of Representatives, but died before that body first met.
Presidents may use their predecessors as emissaries to deliver private messages to other nations or as official representatives of the United States to state funerals and other important foreign events. Richard Nixon made multiple foreign trips to countries including China and Russia and was lauded as an elder statesman. Jimmy Carter has become a global human rights campaigner, international arbiter, and election monitor, as well as a recipient of the Nobel Peace Prize. Bill Clinton has also worked as an informal ambassador, most recently in the negotiations that led to the release of two American journalists, Laura Ling and Euna Lee, from North Korea. Clinton has also been active politically since his presidential term ended, working with his wife Hillary on her 2008 and 2016 presidential bids and President Obama on his reelection campaign.
Presidential libraries.
Since Herbert Hoover, each president has created a repository known as a presidential library for preserving and making available his papers, records and other documents and materials. Completed libraries are deeded to and maintained by the National Archives and Records Administration (NARA); the initial funding for building and equipping each library must come from private, non-federal sources. There are currently thirteen presidential libraries in the NARA system. There are also presidential libraries maintained by state governments and private foundations, such as the Abraham Lincoln Presidential Library and Museum, which is run by the State of Illinois.
As many presidents live for many years after leaving office, several of them have personally overseen the building and opening of their own presidential libraries, some even making arrangements for their own burial at the site. Several presidential libraries therefore contain the graves of the president they document, such as the Richard Nixon Presidential Library and Museum in Yorba Linda, California and the Ronald Reagan Presidential Library in Simi Valley, California. The graves are viewable by the general public visiting these libraries.
See also.
Lists relating to the United States presidency.
List of Presidents of the United States
<categorytree mode="pages" hideroot="on">Lists relating to the United States presidency</categorytree>

</doc>
<doc id="24115" url="https://en.wikipedia.org/wiki?curid=24115" title="Religious affiliations of Presidents of the United States">
Religious affiliations of Presidents of the United States

The religious affiliations of Presidents of the United States can affect their electability, shape their visions of society and also how they want to lead it, and shape their stances on policy matters. Thomas Jefferson,
Abraham Lincoln, William Howard Taft and Barack Obama were accused of being atheists during election campaigns, while others, such as Jimmy Carter, used faith as a defining aspect of their campaigns and tenure to hold the office. Almost all of the presidents can be characterized as Christian, at least by upbringing, though some were unaffiliated with any specific religious body. Protestants predominate, with only one Roman Catholic president - John F. Kennedy. Some are thought to have been deists, or irreligious. No president thus far has been openly an atheist or an adherent of any non-Christian religion.
Formal affiliation.
Most presidents have been formal members of a particular church or religious body, and a specific affiliation can be assigned to every president from Garfield on. For many earlier presidents, however, formal church membership was forestalled until they left office; and in several cases a president never joined any church. Conversely, though every president from Washington to John Quincy Adams can be definitely assigned membership in an Anglican or Unitarian body, the significance of these affiliations is often downplayed as unrepresentative of their true beliefs.
The pattern of religious adherence has changed dramatically over the course of United States history, so that the pattern of presidential affiliations is quite unrepresentative of modern membership numbers. For example, Episcopalians are extraordinarily well represented among the presidents compared to a current membership of about 2% of the population; this is partly because the Church of England, from which the Episcopal Church is derived, was the established church in some states (such as New York and Virginia) before the American Revolution. The Episcopal Church has been much larger previously, with its decline in membership occurring only in more recent decades. The first seven presidents listed as Episcopalians were all from Virginia. Unitarians are also overrepresented, reflecting the importance of those colonial churches. Conversely, Baptists are underrepresented, a reflection of their quite recent expansion in numbers; there has been only one Catholic president, although they are currently the largest single denomination, and there have been no Lutheran, Orthodox, Pentecostal, or Latter Day Saint presidents.
While many presidents did not formally join a church until quite late in life, there is a genre of tales of deathbed conversions. Biographers usually doubt these, though the baptism of Polk is well documented.
Personal beliefs.
The inner beliefs of the presidents are much more difficult to establish than church membership. While some presidents have been relatively voluble about religion, many have been reticent to the point of complete obscurity. Researchers have tried to draw conclusions from patterns of churchgoing or religious references in political speeches. When explicit statements are absent, it is difficult to assess whether the presidents in question were irreligious, were unorthodox in their beliefs, or simply believed that religion was not a matter for public revelation.
On the other hand, there are several presidents who considered themselves aligned with a particular church, but who withheld from formal affiliation for a time. Buchanan, for instance, held himself allied with the Presbyterian church, but refrained from joining it until he left office.
Some presidents changed their beliefs and affiliation at some point in their lives; synthesis of statements and membership from different periods can be misleading.
Deism and the founding fathers.
Deism was a religious philosophy in common currency in colonial times, and some Founding Fathers (most notably Thomas Paine, who was an explicit proponent of it, and Benjamin Franklin, who spoke of it in his Autobiography) are identified more or less with this system. Thomas Jefferson became a deist in later life, and George Washington, Thomas Jefferson, James Madison, James Monroe, and John Tyler are often identified as having some degree of deistic beliefs. Washington in particular maintained a lifelong pattern of church membership and attendance, and there is conflicting testimony from those who knew him.
Unitarianism and non-Trinitarian religion.
Four presidents are affiliated with Unitarian churches, and a fifth (Jefferson) was an exponent of ideas now commonly associated with Unitarianism. Unitarians fall outside of Trinitarian Christianity, and the question arises as to the degree to which the presidents themselves held Christian precepts. The information is generally available in the statements of the presidents themselves; for example, John Quincy Adams left detailed statements of his beliefs. William Howard Taft, a Unitarian, is noted to have said in a letter to a friend, "I am interested in the spread of Christian civilization, but to go into a dogmatic discussion of creed I will not do whether I am defeated or not. . . . If the American electorate is so narrow as not to elect a Unitarian, well and good. I can stand it."
Two presidents were Quakers (Herbert Hoover and Richard Nixon) and information about their religion is harder to come by. Quakerism is, by its nature, not circumscribed by doctrines, but even so it is hard to determine whether either Hoover or Nixon had much adherence even to Quaker practice. For instance, it is common among Quakers to refuse to swear oaths; however, recordings show that Nixon did swear the oath of office in the conventional manner in all cases, and while the matter is clouded for Hoover, there is newspaper and circumstantial evidence that he did likewise.
The only other president with any association with a definitely non-Trinitarian body is Eisenhower, whose parents moved from the River Brethren to the antecedents of the Jehovah's Witnesses. Eisenhower himself was baptized in the Presbyterian church shortly after assuming the presidency, the only president thus far to undergo such a rite while in office; and his attendance at West Point was in sharp opposition to the pacifist tenets of the groups to which his parents belonged.
Non-religious presidents.
There are some presidents for whom there is little evidence as to the importance of religion in their lives. For example, almost no evidence exists for Monroe's personal religious beliefs, though this may be the result of the destruction of most of his personal correspondence, in which religious sentiments may have been recorded. As with claims of deism, these identifications are not without controversy. No president has declared himself to be irreligious, agnostic, or atheist.
Civic religion.
St. John's Episcopal Church, just across Lafayette Square, north of the White House, and built in 1815–1816, is the church nearest to the White House, and its services have been attended at least once by nearly every president since James Madison (1809–1817). Another Episcopal church, Washington National Cathedral, chartered by Congress in 1893, has been the scene of many funeral and memorial services of presidents and other dignitaries, as well as the site of interfaith presidential prayer services after their inaugurations, and the burial place of Woodrow Wilson.
Presidential proclamations, from the earliest days, have often been laden with religious if not explicitly Christian language. In at least two cases, presidents saw fit to issue denials that they were atheists. At the same time, this was tempered, especially in early years, by a strong commitment to disestablishment. Several presidents especially stand out as exponents of this. Consideration of this has become increasingly contentious as topics such as civil rights and human sexuality have increasingly put churches at odds with each other and with the government.
Studies of presidential religion.
Presidential biographers have often been brought to consider the issue of presidential religion. In the case of certain key figures (particularly Washington, Jefferson, and Lincoln), they have devoted considerable attention to the subject.
Some researchers have produced general surveys of presidential religion. A recent example is "The Faiths of the Founding Fathers" by David L. Holmes (New York, Oxford University Press USA, 2006), which examines the views of some early presidents as well as other political figures of the period. The Adherents.com website maintains a list of presidential affiliations, with subpages for each president. Most of these subpages refer to a site by one Peter Roberts, which has links and some more detailed information on the religion of the presidents, vice presidents, and founding fathers.
List of Presidents with details on their religious affiliation.
For each president, the formal affiliation at the time of his presidency is listed first, with other affiliations listed after. Further explanation follows if needed, as well as notable detail.

</doc>
<doc id="24116" url="https://en.wikipedia.org/wiki?curid=24116" title="Peer review">
Peer review

Peer review is the evaluation of work by one or more people of similar competence to the producers of the work (peers). It constitutes a form of self-regulation by qualified members of a profession within the relevant field. Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility. In academia, scholarly peer review is often used to determine an academic paper's suitability for publication. Peer review can be categorized by the type of activity and by the field or profession in which the activity occurs, e.g., medical peer review.
Professional.
Professional peer review focuses on the performance of professionals, with a view to improving quality, upholding standards, or providing certification. In academia, peer review is common in decisions related to faculty advancement and tenure.
A prototype professional peer-review process was recommended in the "Ethics of the Physician" written by Ishāq ibn ʻAlī al-Ruhāwī (854–931). He stated that a visiting physician had to make duplicate notes of a patient's condition on every visit. When the patient was cured or had died, the notes of the physician were examined by a local medical council of other physicians, who would decide whether the treatment had met the required standards of medical care.
Professional peer review is common in the field of health care, where it is usually called "clinical peer review". Further, since peer review activity is commonly segmented by clinical discipline, there is also physician peer review, nursing peer review, dentistry peer review, etc. Many other professional fields have some level of peer review process: accounting, law, engineering (e.g., software peer review, technical peer review), aviation, and even forest fire management.
Peer review is used in education to achieve certain learning objectives, particularly as a tool to reach higher order processes in the affective and cognitive domains as defined by Bloom's taxonomy. This may take a variety of forms, including closely mimicking the scholarly peer review processes used in science and medicine.
Government policy.
The European Union has been using peer review in the 'Open Method of Co-ordination' of policies in the fields of active labour market policy since 1999. In 2004, a program of peer reviews started in social inclusion. Each program sponsors about eight peer review meetings in each year, in which a 'host country' lays a given policy or initiative open to examination by half a dozen other countries and the relevant European-level NGOs. These usually meet over two days and include visits to local sites where the policy can be seen in operation. The meeting is preceded by the compilation of an expert report on which participating 'peer countries' submit comments. The results are published on the web.
The United Nations Economic Commission for Europe, through UNECE Environmental Performance Reviews, uses the technique of peer review to evaluate progress made by its member countries in improving their environmental policies.
The State of California is the only U.S. state to mandate scientific peer review. In 1997, the California Governor signed into law Senate Bill 1320 (Sher), Chapter 295, statutes of 1997, which mandates that, before any CalEPA Board, Department, or Office adopts a final version of a rule-making, the scientific findings, conclusions, and assumptions on which the proposed rule are based must be submitted for independent external scientific peer review. This requirement is incorporated into the California Health and Safety Code Section 57004.
Medical.
Medical peer review may refer to clinical peer review, or the peer evaluation of clinical teaching skills for both physicians and nurses, or scientific peer review of journal articles, or to a secondary round of peer review for the clinical value of articles concurrently published in medical journals.
"Medical peer review" has been used by the American Medical Association to refer not only to the process of improving quality and safety in health care organizations, but also to the process of rating clinical behavior or compliance with professional society membership standards. Thus, the terminology has poor standardization and specificity, particularly as a database search term.

</doc>
<doc id="24117" url="https://en.wikipedia.org/wiki?curid=24117" title="Prime Minister of Australia">
Prime Minister of Australia

The Prime Minister of the Commonwealth of Australia is the head of government in Australia. The individual who holds the office is the most senior Minister of the Crown, the leader of the Cabinet and the chairperson of the National Security Committee. The office is not mentioned in the Constitution of Australia and exists only through an unwritten political convention and tradition. Despite this, in practice it is the most powerful political position in Australia. The individual who holds the office is commissioned by the Governor-General of Australia.
Almost always and according to convention, the Prime Minister is the leader of the majority party or largest party in a coalition of parties in the House of Representatives. However, there is no constitutional requirement that the prime minister sit in the House of Representatives, or even be a member of parliament, though by convention this is always the case. The only case where a member of the Senate was appointed prime minister was John Gorton, who subsequently resigned his Senate position and was elected as a member of the House of Representatives (Senator George Pearce was acting prime minister for seven months in 1916 while Billy Hughes was overseas).
Malcolm Turnbull has held the office of Prime Minister since 15 September 2015. He received his commission after replacing Tony Abbott as the leader of the Liberal Party, the dominant party in the Coalition government, following the outcome of the September 2015 Liberal leadership ballot.
Former Prime Ministers continue to be important national figures, and in some cases go on to significant post-prime ministerial careers. Some notable examples have included: Edmund Barton, who was a justice of the High Court; George Reid, Andrew Fisher, Joseph Cook and Stanley Bruce, who were High Commissioners to the United Kingdom; Arthur Fadden, who was Treasurer under another prime minister, Robert Menzies; and Kevin Rudd, who became Julia Gillard's Foreign Minister.
Appointment.
The Prime Minister of Australia is appointed by the Governor-General of Australia under Section 64 of the Australian Constitution, which empowers the Governor-General to appoint Ministers of the Crown and requires such Ministers to be members of the House of Representatives or the Senate, or become members within three months of the appointment. Before being sworn in as a minister, a person must first be sworn in as a member of the Federal Executive Council if they are not already a member. Membership of the Federal Executive Council entitles the member to the style of "The Honourable" (usually abbreviated to "The Hon") for life, barring exceptional circumstances. The senior members of the Executive Council constitute the Cabinet of Australia.
The Prime Minister is, like other ministers, normally sworn in by the Governor-General and then presented with the commission (Letters patent) of office. When defeated in an election, or on resigning, the Prime Minister is said to "hand in the commission" and actually does so by returning it to the Governor-General. In the event of a Prime Minister dying in office, or becoming incapacitated, the Governor-General can terminate the commission. Ministers hold office "during the pleasure of the Governor-General" (s. 64 of the Constitution of Australia), so theoretically, the Governor-General can dismiss a minister at any time, by notifying them in writing of the termination of their commission; however, his or her power to do so except on the advice of the Prime Minister is heavily circumscribed by convention.
Despite the importance of the office of prime minister, the Constitution does not mention the office by name. The conventions of the Westminster system were thought to be sufficiently entrenched in Australia by the authors of the Constitution that it was deemed unnecessary to detail them. The formal title of the portfolio has always been simply "Prime Minister", except for the period of the Fourth Deakin Ministry (June 1909 to April 1910), when it was known as "Prime Minister (without portfolio)".
If a government cannot get its appropriation (budget) legislation passed by the House of Representatives, or the House passes a vote of "no confidence" in the government, the Prime Minister is bound by convention to immediately advise the Governor-General to dissolve the House of Representatives and hold a fresh election.
Following a resignation in other circumstances, or the death of a prime minister, the governor-general will generally appoint as prime minister the person elected as leader by the governing party or, in the case of a coalition, the senior party in the coalition. There have been four notable exceptions to this:
There were only three other cases where someone other than the leader of the majority party in the House of Representatives was prime minister:
Powers.
Most of the prime minister's powers derive from being head of Government. In practice, the Federal Executive Council will act to ratify all decisions made by the cabinet and, in practice, decisions of the cabinet will always require the support of the prime minister. The powers of the governor-general to grant Royal Assent to legislation, to dissolve and prorogue parliament, to call elections and to make appointments are exercised on the advice of the prime minister.
The formal power to appoint the Governor-General lies with the Queen of Australia, but this appointment is done on the formal advice of the Prime Minister. By convention, this advice is provided by the Prime Minister alone, and thus the appointment is effectively the Prime Minister's personal choice. The Prime Minister may also advise the monarch to dismiss the Governor-General, though it remains unclear how quickly the monarch would act on such advice in a constitutional crisis. This uncertainty, and the possibility of a "race" between the Governor-General and Prime Minister to sack the other, was a key question in the 1975 constitutional crisis.
The power of the prime minister is subject to a number of limitations. Prime ministers removed as leader of his or her party, or whose government loses a vote of no-confidence in the House of Representatives, must advise an election of the lower house or resign the office or be dismissed by the governor-general.
The prime minister's party will normally have a majority in the House of Representatives and party discipline is exceptionally strong in Australian politics, so passage of the government's legislation through the House of Representatives is mostly a formality. Attaining the support of the Senate can be more difficult as government usually lacks an absolute majority because the Senate's representation is based on overall proportion of votes and often includes minor parties.
Salary and benefits.
Allowances.
The Royal Australian Air Force's No. 34 Squadron transports the prime minister within Australia and overseas by specially converted Boeing Business, Jets and smaller Challenger aircraft. The aircraft contain secure communications equipment as well as office, conference room and sleeping compartments. The call-sign for the aircraft is "Envoy".
The prime minister's official residence is The Lodge in Canberra, Australian Capital Territory, but not all prime ministers have chosen to make use of it. Jim Scullin preferred to live at the Hotel Canberra (now the Hyatt Hotel); Ben Chifley lived in the Hotel Kurrajong; and John Howard made Kirribilli House in Sydney his primary residence, using The Lodge when in Canberra on official business. On her appointment on 24 June 2010, Julia Gillard said she would not be living in The Lodge until such time as she was returned to office by popular vote at the next general election. (She became prime minister mid-term after replacing the incumbent, Kevin Rudd, who resigned in the face of an unwinnable party-room ballot.) The official residences are fully staffed and catered for both the prime minister and his or her family. A considerable amount of official entertaining is conducted at these residences.
During his first term, Kevin Rudd had a staff at The Lodge consisting of a senior chef and an assistant chef, a child carer, one senior house attendant, and two junior house attendants. At Kirribilli House in Sydney, there is one full-time chef and one full-time house attendant.
Prime ministers are usually granted certain privileges after leaving office, such as office accommodation, staff assistance, and a Life Gold Pass, which entitles the holder to travel within Australia for "non-commercial" purposes at government expense.
Only one prime minister who had left the Federal Parliament ever returned. Stanley Bruce was defeated in his own seat in 1929 while prime minister, but was re-elected to parliament in 1931. Other prime ministers were elected to parliaments other than the Australian federal parliament: Sir George Reid was elected to the UK House of Commons (after his term as High Commissioner to the UK); and Frank Forde was re-elected to the Queensland Parliament (after his term as High Commissioner to Canada, and a failed attempt to re-enter the Federal Parliament).
Official state car.
Since 2015, the Prime Minister of Australia's official car has been a fleet of heavily armoured BMW 7 Series, which replaced a fleet of Holden Caprices. It is escorted by police vehicles from state and federal authorities. The Prime Minister's car bears the number plate "C1" (meaning "Commonwealth 1").
Acting and interim prime ministers.
From time to time prime ministers are required to leave the country on government business and a deputy acts in their place during that time. In the days before jet aircraft, such absences could be for extended periods. For example, William Watt was acting prime minister for 16 months, from April 1918 until August 1919, when Prime Minister Billy Hughes was away at the Paris Peace Conference, and Senator George Pearce was acting Prime Minister for more than seven months in 1916. An acting Prime Minister is also appointed when the prime minister takes leave. The Deputy Prime Minister most commonly becomes acting Prime Minister in those circumstances.
Three prime ministers have died in office – Joseph Lyons (1939), John Curtin (1945) and Harold Holt (1967) – and Robert Menzies resigned as Prime Minister in 1941. In each of these cases the Deputy Prime Minister (an unofficial office at the time) became an interim Prime Minister, pending an election of a new leader of the government party. In none of these cases was the interim Prime Minister successful at the subsequent election.
The powers and duties of an acting or interim Prime Minister is analogous to that of a caretaker Prime Minister.
Living former prime ministers.
As of , there are six living former Prime Ministers of Australia, the oldest being Bob Hawke (born 1929). The most recent former prime minister to die was Malcolm Fraser (1975–1983), on 20 March 2015.
The greatest number of living former prime ministers at any one time was eight. This has occurred twice:
Convictions.
John Curtin is the only prime minister to serve time in prison (three days for failing to comply with an order for a compulsory medical examination for conscription, during World War I).
Ages.
The three youngest people when they first became prime minister were:
The three oldest people when they first became prime minister were:
The three youngest people to last leave the office of prime minister were:
The three oldest people to last leave the office of prime minister were:
Time in office.
The longest serving prime minister was Sir Robert Menzies, who served in office twice: from 26 April 1939 to 28 August 1941, and again from 19 December 1949 to 26 January 1966. In total Robert Menzies spent 18 years, 5 months and 12 days in office. He served under the United Australia Party and the Liberal Party respectively.
The shortest-serving prime minister was Frank Forde, who was appointed to the position on 6 July 1945 after the death of John Curtin, and served until 13 July 1945 when Ben Chifley was elected leader of the Australian Labor Party.
Post-office longevity.
Six former prime ministers are living: Hawke, Keating, Howard, Rudd, Gillard and Abbott.
Ben Chifley died only one year and six months after leaving the prime ministership. Alfred Deakin lived another nine years and five months.
All the others who have left office at least 10 years ago have lived at least another 10 years. Nine of them (Bruce, Cook, Fadden, Forde, Fraser, Gorton, Hughes, Watson, and Whitlam) lived more than 25 years after leaving the office, and all but one of them have survived longer than 30 years (Hughes lasted 29 years and 8 months).
The longest-surviving was Gough Whitlam, who lived 38 years and 11 months after office, surpassing Stanley Bruce's previous record of 37 years and 10 months after leaving the office.

</doc>
<doc id="24118" url="https://en.wikipedia.org/wiki?curid=24118" title="Passive management">
Passive management

Passive management (also called passive investing) is an investing strategy that tracks a market-weighted index or portfolio. The idea is to minimize investing fees and to avoid the adverse consequences of failing to correctly anticipate the future. The most popular method is to mimic the performance of an externally specified index. investors typically do this by buying one or more index funds. By tracking an index, an investment portfolio typically gets good diversification, low turnover (good for keeping down internal transaction costs), and low management fees. With low fees, an investor in such a fund would have higher returns than a similar fund with similar investments but higher management fees and/or turnover/transaction costs.
Passive management is most common on the equity market, where index funds track a stock market index, but it is becoming more common in other investment types, including bonds, commodities and hedge funds. Today, there is a plethora of market indices in the world, and thousands of different index funds tracking many of them.
One of the largest equity mutual funds, the Vanguard 500, is a passively managed fund. The two firms with the largest amounts of money under management, BlackRock and State Street Corp., primarily engage in passive management strategies. BlackRock acquired Barclays Global Investors in December 2009.
Rationale.
The concept of passive management is counterintuitive to many investors. The rationale behind indexing stems from the following concepts of financial economics:
The bull market of the 1990s helped spur the phenomenal growth in indexing observed over that decade. Investors were able to achieve desired absolute returns simply by investing in portfolios benchmarked to broad-based market indices such as the S&P 500, Russell 3000, and Wilshire 5000.
In the United States, indexed funds have outperformed the majority of active managers, especially as the fees they charge are very much lower than active managers. They are also able to have significantly greater after-tax returns.
Some active managers may beat the index in particular years, or even consistently over a series of years. Nevertheless, the retail investor still has the problem of discerning how much of the outperformance was due to skill rather than luck, and which managers will do well in the future.
Implementation.
At the simplest, an index fund is implemented by purchasing securities in the same proportion as in the stock market index. It can also be achieved by sampling (e.g. buying stocks of each kind and sector in the index but not necessarily some of each individual stock), and there are sophisticated versions of sampling (e.g. those that seek to buy those particular shares that have the best chance of good performance).
Investment funds run by investment managers who closely mirror the index in their managed portfolios and offer little "added value" as managers whilst charging fees for active management are called 'closet trackers'; that is they do not in truth actively manage the fund but furtively mirror the index.
Investment funds that employ passive investment strategies to track the performance of a stock market index are known as index funds. Exchange-traded funds are hardly ever actively managed and often track a specific market or commodity indices. Using a small number of index funds and ETFs, one can construct a portfolio that tracks global equity and bond market at a relatively low cost. Popular examples include two-fund and three-fund lazy portfolios.
Globally diversified portfolios of index funds are used by investment advisors who invest passively for their clients based on the principle that underperforming markets will be balanced by other markets that outperform. A Loring Ward report in Advisor Perspectives showed how international diversification worked over the 10-year period from 2000–2010, with the Morgan Stanley Capital Index for emerging markets generating ten-year returns of 154 percent balancing the blue-chip S&P 500 index, which lost 9.1 percent over the same period – a historically rare event. The report noted that passive portfolios diversified in international asset classes generate more stable returns, particularly if rebalanced regularly.
There is room for dialog about whether index funds are one example of or the only example of passive management.
Pension fund investment in passive strategies.
Research conducted by the World Pensions Council (WPC) suggests that 15% to 20% of overall assets held by large pension funds and national social security funds are invested in various forms of passive funds- as opposed to the more traditional actively managed mandates which still constitute the largest share of institutional investments The proportion invested in passive funds varies widely across jurisdictions and fund type 
The relative appeal of passive funds such as ETFs and other index-replicating investment vehicles has grown rapidly for various reasons ranging from disappointment with underperforming actively managed mandates to the broader tendency towards cost reduction across public services and social benefits that followed the 2008-2012 Great Recession. Public-sector pensions and national reserve funds have been among the early adopters of passive management strategies.

</doc>
