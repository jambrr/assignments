<doc id="22048" url="https://en.wikipedia.org/wiki?curid=22048" title="Cuisine of New England">
Cuisine of New England

New England cuisine is an American cuisine which originated in the northeastern region of the United States known as New England. It is characterized by extensive use of seafood and dairy products, which results from its historical reliance on its seaports and fishing industry, as well as extensive dairy farming in inland regions. Many of New England's earliest Puritan settlers were from eastern England, where baking foods such as pies, beans, and turkey were more common than frying as was the tradition elsewhere. Two prominent characteristic foodstuffs native to New England are maple syrup and cranberries. The traditional standard starch is potato, though rice has a somewhat increased popularity in modern cooking. Although known for limited spices aside from ground black pepper, parsley and sage are common, with a few Caribbean additions like nutmeg. Due to the reliance on dairy, creams are standard. The favored cooking techniques are stewing, steaming, and baking.
History.
Native American foods and cooking methods such as corn meal johnny cakes, oysters, succotash, and New England clam bakes were adopted by early immigrants to New England, as were many staples of their diet such as the nuts of the black walnut tree, the nuts of the shagbark hickory, popcorn, blueberries, blackberries and beach plums. Many of the animals they hunted were avidly adopted by the early settlers of Plymouth Colony and later Massachusetts Bay Colony. In England during this period, carrying weapons (especially guns) was forbidden to any but the upper classes. Upon reaching the New World, these Englishmen found themselves in a land where they could feast on venison from the white tailed deer and the Eastern moose and shoot pigeons for their meat (these were likely featured at the first Thanksgiving feast in 1621.)
Many of New England's earliest Puritan settlers were from eastern England and also brought with them traditions of dairy products and baking pies and other foods. Baked beans, apple pies, baked or roast turkey, pease porridge, and steamed puddings became common Yankee dishes; some are now common nationally during Thanksgiving dinners. Other foods they would have prized would include dishes like roast duck and roast goose, lamb, and hams, and all of the above were brought to the New World as soon as the colonies began to prosper as farmyard stock.
Due to New England's involvement in the Triangle Trade in the 18th century, molasses and rum were common in New England cuisine. Well into the 19th century, molasses from the Caribbean and honey were staple sweeteners for all but the upper class. Prior to Prohibition, some of the finest rum distilleries were located in New England.
Many herbs were uncommon, particularly Mediterranean herbs, which are not hardy in much of New England away from the coast. As a result, most savory New England dishes do not have much strong seasoning aside from salt and ground black pepper, nor are there many particularly spicy staple items. Other dishes meant as desserts often contain ingredients like nutmeg, cinnamon, allspice, cloves, and ground ginger which are a legacy of trade with the Caribbean Sea that began in the 17th Century and lasted well into the 19th.
Even today, traditional cuisine remains a strong part of New England's identity. Some of its plates are now enjoyed by the entire United States, including clam chowder, baked beans, and homemade ice cream. In the past two centuries, New England cooking was strongly influenced and transformed by Irish Americans, the Portuguese fishermen of coastal New England, and Italian Americans.
The oldest operating restaurant in the United States, the Union Oyster House (1826), is located in Boston.
State dishes and staples.
Connecticut is known for its apizza (particularly the white clam pie), shad and shadbakes, grinders (including the state-based Subway chain), and New Haven's claim as the birthplace of the hamburger sandwich at Louis' Lunch in 1900. Italian-inspired cuisine is dominant in the New Haven area, while southeastern Connecticut relies heavily on the fishing industry. Irish American influences are common in the interior portions of the state, including the Hartford area. Hasty pudding is sometimes found in rural communities, particularly around Thanksgiving.
Maine is known for its lobster. Relatively inexpensive lobster rolls (lobster meat mixed with mayonnaise and other ingredients, served in a grilled hot dog roll) are often available in the summer, particularly on the coast. Northern Maine produces potato crops, second only to Idaho in the United States. Moxie, America's first mass-produced soft drink and the official state soft drink, is known for its strong aftertaste and is found throughout New England. Although originally from New Jersey, wax-wrapped salt water taffy is a popular item sold in tourist areas. Wild blueberries are a common ingredient or garnish, and blueberry pie (when made with wild Maine blueberries) is the official state dessert. Red snappers — natural casing frankfurters colored bright red — are considered the most popular type of hot dog in Maine. The whoopie pie is the official state treat. Finally, the Italian sandwich is popular in Portland and southern Maine—Portland restaurant Amato's claims to have invented the Italian sandwich (specifically, a submarine sandwich made with ham, cheese, tomato, raw peppers and pickles, served with or without oil, salt and pepper) in 1902. The city of Portland, Maine, known for its numerous nationally renowned restaurants, was ranked as Bon Appétit magazine's "America's Foodiest Small Town" in 2009.
Coastal Massachusetts is known for its clams, haddock, and cranberries, and previously cod. Boston is known for, among other things, baked beans (hence the nickname "Beantown"), bulkie rolls, and various pastries. Hot roast beef sandwiches served with a sweet barbecue sauce and usually on an onion roll is popular in Boston's surrounding area. The North Shore area is locally known for its roast beef establishments, which slice tender roast beef extremely thin. Apples are grown commercially throughout the Commonwealth. Because of the landlocked, hilly terrain common plant foods in Massachusetts are similar to those of interior northern New England- including potatoes, maple syrup, and wild blueberries. Dairy production is also prominent in this central and western area. Cuisine in western Massachusetts had similar immigrant influences as the coastal regions, though historically strong Eastern European populations instilled kielbasa and pierogi as common dishes.
Southern New Hampshire cuisine is similar to that of the Boston area, featuring fish, shellfish and local apples. As with Maine and Vermont, French-Canadian dishes are popular, including tourtière, which is traditionally served on Christmas Eve, and poutine. Corn chowder, which is similar to clam chowder but with corn and bacon replacing the clams, is also common. Portsmouth is known for its orange cake.
Rhode Island and bordering Bristol County, Massachusetts are known for Rhode Island clam chowder (clear chowder), quahog (hard clams), johnny cakes, coffee milk, celery salt, milkshakes known as "cabinets" (called "frappes" elsewhere in New England), grinders, pizza strips, clam cakes, the chow mein sandwich, and Del's Frozen Lemonade. Another food item popular in Rhode Island and southern Massachusetts is called a "hot wiener" or "New York System wiener," although it is unknown in New York (including Coney Island). Portuguese influences are becoming increasingly popular in the region, with Italian cooking already long established.
Vermont produces Cheddar cheese and other dairy products. It is known in and outside of New England for its maple syrup. Maple syrup is used as an ingredient in some Vermont dishes, including baked beans. Rhubarb pie is a common dessert and has been combined with strawberries in late spring.
Common foods.
New England also has its own food language. In New England, hot and cold sandwiches in elongated rolls are called subs or grinders. This is opposed to the appellations hoagies or heroes in other sections of the country, in particular those closer to the New York City and Philadelphia areas, where the aforementioned names are more common. Sub is short for submarine sandwich, for which Boston, Massachusetts is one of three main claimants for inventing. In Maine, the Italian sandwich—a variation specifically made up of ham or salami, cheese, peppers, pickles, tomatoes and optional oil—is popular, though usually kept distinct from other subs.
New England hot dog rolls are split on top instead of on the side, and have a more rectangular shape. While overall smaller, when separated they have a larger soft surface area because of the way they are baked which allows for buttering and toasting, which are also commonly used for convenient serving of seafood like lobster or fried clams. Regional bread makers often differentiate between these and the more traditional-style American hot dog rolls by referring to the New England variation as "Frankfurt Rolls" on packaging, with both commonly available next to each other on store shelves (though when purchasing a cooked hot dog or seafood "roll" from a restaurant or food stand, the Frankfurt style is almost exclusively used).
Like many of its sister cities of the East Coast, Boston shares a love of a sandwich that is made up of a long soft roll and filled with grilled sweet peppers, sweet onion, a little olive oil, and Italian style pork sausage, called a sausage and pepper sandwich; it is a nod to the Italian immigrants who settled in Boston a century ago, invented it as a quick snack, and now is part of the fabric of local cuisine. It is only served in the spring and summer and is a staple at Fenway Park, home of the Boston Red Sox baseball team.
New England has many local lagers and ales. Notable examples include Samuel Adams of the Boston Beer Company in Boston (even though the recipe for the beer does not come from New England); Sea Dog Brewing Company of Bangor; Shipyard Brewing Company of Portland; and Smuttynose Brewing Company of Portsmouth, New Hampshire. Vermont-based Woodchuck Draft Cider is a popular alcoholic cider.

</doc>
<doc id="22049" url="https://en.wikipedia.org/wiki?curid=22049" title="Neil Simon">
Neil Simon

Marvin Neil Simon (born July 4, 1927) is an American playwright, screenwriter and author. He has written more than thirty plays and nearly the same number of movie screenplays, mostly adaptations of his plays. He has received more combined Oscar and Tony nominations than any other writer.
Simon grew up in New York during the Great Depression, with his parents' financial hardships affecting their marriage, and giving him a mostly unhappy and unstable childhood. He often took refuge in movie theaters where he enjoyed watching the early comedians like Charlie Chaplin. After a few years in the Army Air Force Reserve after graduating from high school, he began writing comedy scripts for radio and some popular early television shows. Among them were "The Phil Silvers Show" and Sid Caesar's "Your Show of Shows" in 1950, where he worked alongside other young writers including Carl Reiner, Mel Brooks and Selma Diamond.
He began writing his own plays beginning with "Come Blow Your Horn" (1961), which took him three years to complete and ran for 678 performances on Broadway. It was followed by two more successful plays, "Barefoot in the Park" (1963) and "The Odd Couple" (1965), for which he won a Tony Award. It made him a national celebrity and "the hottest new playwright on Broadway." During the 1960s to 1980s, he wrote both original screenplays and stage plays, with some films actually based on his plays. His style ranged from romantic comedy to farce to more serious dramatic comedy. Overall, he has garnered seventeen Tony nominations and won three. During one season, he had four successful plays showing on Broadway at the same time, and in 1983 became the only living playwright to have a New York theatre, the Neil Simon Theatre, named in his honor.
After Simon won the Pulitzer Prize for drama in 1991 for "Lost in Yonkers", critics began to take notice of the depths, complexity and issues of universal interest in his stories, which expressed serious concerns of most average people. His comedies centred on subjects such as marital conflict, infidelity, sibling rivalry, adolescence, and fear of aging. Most of his plays were also partly autobiographical, portraying his troubled childhood and different stages of his life, and he created characters who were typically New Yorkers and often Jewish, like himself. Simon's facility with dialogue gives his stories a rare blend of realism, humor and seriousness which audiences find easy to identify with.
Early years.
Neil Simon was born on July 4, 1927, in The Bronx, New York, to Jewish parents. His father, Irving Simon, was a garment salesman, and his mother, Mamie (Levy) Simon, was mostly a homemaker. Simon had one older brother by eight years, Danny Simon. He grew up in Washington Heights, Manhattan during the period of the Great Depression, graduating from DeWitt Clinton High School when he was sixteen, where he was nicknamed "Doc" and described as extremely shy in the school yearbook.
Simon's childhood was difficult and mostly unhappy due to his parents' "tempestuous marriage" and financial hardship caused by the Depression. He would sometimes block out their arguments by putting a pillow over his ears at night. His father often abandoned the family for months at a time, causing them further financial and emotional hardship. As a result, Simon and his brother Danny were sometimes forced to live with different relatives, or else their parents took in boarders for some income.
During an interview with writer Lawrence Grobel, Simon stated: "To this day I never really knew what the reason for all the fights and battles were about between the two of them ... She'd hate him and be very angry, but he would come back and she would take him back. She really loved him." Simon states that among the reasons he became a writer was to fulfill his need to be independent of such emotional family issues, a need he recognized when he was seven or eight: "I'd better start taking care of myself somehow . . . It made me strong as an independent person.
To escape difficulties at home he often took refuge in movie theaters, where he especially enjoyed comedies with silent stars like Charlie Chaplin, Buster Keaton, and Laurel and Hardy. Simon recalls: "I was constantly being dragged out of movies for laughing too loud."
Simon attributes these childhood movies for inspiring him to some day write comedy: "I wanted to make a whole audience fall onto the floor, writhing and laughing so hard that some of them pass out." He appreciated Chaplin's ability to make people laugh and made writing comedy his long-term goal, and also saw it as a way to connect with people. "I was never going to be an athlete or a doctor." He began creating comedy for which he got paid while still in high school, when at the age of fifteen, Simon and his brother created a series of comedy sketches for employees at an annual department store event. And to help develop his writing skill, he often spent three days a week at the library reading books by famous humorists such as Mark Twain, Robert Benchley, George S. Kaufman and S. J. Perelman.
Soon after graduating high school he signed up with the Army Air Force Reserve at New York University, eventually being sent to Colorado as a corporal. It was during those years in the Reserve that Simon began writing, starting as a sports editor. He was assigned to Lowry Air Force Base during 1945 and attended the University of Denver from 1945 to 1946.
Writing career.
Television comedy.
Two years later, he quit his job as a mailroom clerk in the Warner Brothers offices in Manhattan to write radio and television scripts with his brother Danny Simon, including tutelage by radio humourist Goodman Ace when Ace ran a short-lived writing workshop for CBS. They wrote for the radio series "The Robert Q. Lewis Show", which led to other writing jobs, including "The Phil Silvers Show". Sid Caesar hired the duo for his popular television comedy series "Your Show of Shows", for which he earned two Emmy Award nominations.
Simon credits these two latter writing jobs for their importance to his career, stating that "between the two of them, I spent five years and learned more about what I was eventually going to do than in any other previous experience." He adds, "I knew when I walked into "Your Show of Shows", that this was the most talented group of writers that up until that time had ever been assembled together." Simon describes a typical writing session with the show:
Simon incorporated some of their experiences into his play "Laughter on the 23rd Floor" (1993). The play won him two Emmy Award nominations. The first Broadway show Simon wrote was "Catch a Star!" (1955), collaborating on sketches with his brother, Danny.
Playwright.
During 1961, Simon's first Broadway play, "Come Blow Your Horn", ran for 678 performances at the Brooks Atkinson Theatre. Simon took three years to write that first play, partly because he was also working on writing television scripts at the same time. He rewrote the play at least twenty times from beginning to end: "It was the lack of belief in myself. I said, 'This isn't good enough. It's not right. . . It was the equivalent of three years of college." That play, besides being a "monumental effort" for Simon, was a turning point in his career: "The theater and I discovered each other."
After "Barefoot in the Park" (1963) and "The Odd Couple" (1965), for which he won a Tony Award, he became a national celebrity and was considered "the hottest new playwright on Broadway", writes Susan Koprince in her book on Simon. Those successful productions were followed by others, including "The Good Doctor", "God's Favorite", "Chapter Two", "They're Playing Our Song", "I Ought to Be in Pictures", "Brighton Beach Memoirs", "Biloxi Blues", "Broadway Bound", "Jake's Women", "The Goodbye Girl", and "Laughter on the 23rd Floor". His subjects ranged from serious to romantic comedy to more serious drama and less humor. Overall, he has garnered seventeen Tony nominations and won three.
During 1966 Simon had four shows playing at Broadway theaters at the same time: "Sweet Charity", "The Star-Spangled Girl", "The Odd Couple", and "Barefoot in the Park". His professional association with producer Emanuel Azenberg began with "The Sunshine Boys" during 1972 and continued with "The Good Doctor", "God's Favorite", "Chapter Two", "They're Playing Our Song", "I Ought to Be in Pictures", "Brighton Beach Memoirs", "Biloxi Blues", "Broadway Bound", "Jake's Women", "The Goodbye Girl", and "Laughter on the 23rd Floor", among others.
Simon also adapted material written by others for his plays, such as the musical "Little Me" (1962) from the novel by Patrick Dennis, "Sweet Charity" (1966) from a screenplay by Federico Fellini, and "Promises, Promises" (1968) from a film by Billy Wilder, "The Apartment". Simon has occasionally been brought in as an uncredited "script doctor" to help hone the book for Broadway-bound plays or musicals under development such as "A Chorus Line". During the 1970s he wrote a string of successful plays, sometimes having more than one playing at the same time to standing room only audiences. And while he was by then recognized as one of the country's leading playwrights, his inner drive kept him writing:
Simon has also drawn "extensively on his own life and experience" for his stories, with settings typically in working-class New York neighborhoods, similar to ones he grew up in. In 1983 he began writing the first of three autobiographical plays, "Brighton Beach Memoirs" (1983), "Biloxi Blues" (1985), and "Broadway Bound" (1986). With them, he received his greatest critical acclaim. After his follow-up play, "Lost in Yonkers" (1991), Simon was awarded a Pulitzer Prize.
Screenwriter.
Simon has also written screenplays for more than twenty films, and he has received four Academy Award nominations for his screenplays. Some of his screenplays are adaptations of his own plays, along with some original work, including "The Out-of-Towners", "Murder by Death" and "The Goodbye Girl". But although most of his films have been successful, movies were always secondary in importance to his plays:
Simon chose not to write the screenplay for his first film adaptation, "Come Blow Your Horn", preferring to focus on his playwriting. However, he was disappointed with the film, and tried to control his film screenplays thereafter. Many of his earlier screenplays were similar to the play, a characteristic Simon observed in hindsight: "I really didn't have an interest in films then", he explains. "I was mainly interested in continuing writing for the theater ... The plays never became cinematic." "The Odd Couple", however, was a highly successful early adaptation, both faithful to the stage play but also more like a traditional film, having more scenic variety.
Themes and genres.
Theater critic John Lahr describes Simon's primary theme as being about "the silent majority", many of whom are "frustrated, edgy, and insecure". Simon's characters are also portrayed as "likable" and easy for audiences to identify with, often having difficult relationships in marriage, friendship or business, as they "struggle to find a sense of belonging". There is always "an implied seeking for solutions to human problems through relationships with other people Simon is able to deal with serious topics of universal and enduring concern", writes biographer Edythe McGovern, while still making people laugh.
She adds that one of Simon's hallmarks is his "great compassion for his fellow human beings," an opinion similar to that of author Alan Cooper, who states that Simon's plays "are essentially about friendships, even when they are about marriage or siblings or crazy aunts ..."
With regard to places, all of Simon's plays except for two are set in New York, which gives them an urban flavor. Within that setting, Simon's themes, besides marital conflict, sometimes include infidelity, sibling rivalry, adolescences, bereavement, and fear of aging. And despite the serious nature of the themes, Simon has continually managed to tell the stories with humor, developing the theme to include both realism and comedy. Simon said he would tell aspiring comedy playwrights "not to try to make it funny. . . try and make it real and then the comedy will come."
"When I was writing plays," he says, "I was almost always (with some exceptions) writing a drama that was funny ... I wanted to tell a story about real people." Simon explains how he manages this combination:
In marriage relationships, his comedies often portray these struggles with plots of marital difficulties or fading love, sometimes leading to separation, divorce and child custody battles. Their endings would typically conclude, after many twists in the plot, to renewal of the relationships.
Politics seldom have any overt role in Simon's stories, and his characters avoid confronting society despite their personal problems. "Simon is simply interested in showing human beings as they are—with their foibles, eccentricities, and absurdities." Drama critic Richard Eder notes that Simon's popularity relies on his ability to portray a "painful comedy," where characters say and do funny things in extreme contrast to the unhappiness they are feeling.
Simon's plays are generally semi-autobiographical, often portraying aspects of his troubled childhood and first marriages. According to Koprince, Simon's plays also "invariably depict the plight of white middle-class Americans, most of whom are New Yorkers and many of whom are Jewish, like himself." He states, "I suppose you could practically trace my life through my plays." In plays such as "Lost in Yonkers", Simon suggests the necessity of a loving marriage, opposite to that of his parents', and when children are deprived of it in their home, "they end up emotionally damaged and lost".
One of the key influences on Simon is his Jewish heritage, says Koprince, although he is unaware of it when writing. For example, in the "Brighton Beach" trilogy, she explains, the lead character is a "master of self-deprecating humor, cleverly poking fun at himself and at his Jewish culture as a whole." Simon himself has said that his characters are people who "often self-deprecating and usually see life from the grimmest point of view," explaining, "I see humor in even the grimmest of situations. And I think it's possible to write a play so moving it can tear you apart and still have humor in it." This theme in writing, notes Koprince, "belongs to a tradition of Jewish humor ... a tradition which values laughter as a defense mechanism and which sees humor as a healing, life-giving force."
Characters.
Simon's characters are typically portrayed as "imperfect, unheroic figures who are at heart decent human beings", according to Koprince, and she traces Simon's style of comedy to that of Menander, a playwright of ancient Greece. Menander, like Simon, also used average people in domestic life settings, the stories also blending humor and tragedy into his themes. Many of Simon's most memorable plays are built around two-character scenes, as in segments of "California Suite" and "Plaza Suite".
Before writing, Simon tries to create an image of his characters. He says that the play, "Star Spangled Girl" which was a box-office failure, was "the only play I ever wrote where I did not have a clear visual image of the characters in my mind as I sat down at the typewriter." Simon considers "character building" as an obligation, stating that the "trick is to do it skillfully". While other writers have created vivid characters, they have not created nearly as many as Simon: "Simon has no peers among contemporary comedy playwrights," states biographer Robert Johnson.
Simon's characters often amuse the audience with sparkling "zingers," believable due to Simon's skill with writing dialogue. He reproduces speech so "adroitly" that his characters are usually plausible and easy for audiences to identify with and laugh at. His characters may also express "serious and continuing concerns of mankind ... rather than purely topical material". McGovern notes that his characters are always impatient "with phoniness, with shallowness, with amorality", adding that they sometimes express "implicit and explicit criticism of modern urban life with its stress, its vacuity, and its materialism." However, Simon's characters will never be seen thumbing his or her nose at society."
Style and subject matter.
The key aspect most consistent in Simon's writing style is comedy, situational and verbal, and presents serious subjects in a way that makes audiences "laugh to avoid weeping." He achieves this with rapid-fire jokes and wisecracks, in a wide variety of urban settings and stories. This creates a "sophisticated, urban humor", says editor Kimball King, and results in plays that represent "middle America." Simon creates everyday, apparently simple conflicts with his stories, which become comical premises for problems which need be solved.
Another feature of his writing is his adherence to traditional values regarding marriage and family. McGovern states that this thread of the monogamous family runs though most of Simon's work, and is one he feels is necessary to give stability to society. Some critics have therefore described his stories as somewhat old fashioned, although Johnson points out that most members of his audiences "are delighted to find Simon upholding their own beliefs." And where infidelity is the theme in a Simon play, rarely, if ever, do those characters gain happiness: "In Simon's eyes, adds Johnson, "divorce is never a victory."
Another aspect of Simon's style is his ability to combine both comedy and drama. "Barefoot in the Park", for example, was a light romantic comedy, while portions of "Plaza Suite" were written as "farce", and portions of "California Suite" are "high comedy".
Simon was willing to experiment and take risks, often moving his plays in new and unexpected directions. In "The Gingerbread Lady", he combines comedy with tragedy; "Rumors" (1988) was a full-length farce; in "Jake's Women" and "Brighton Beach Memoirs" he uses dramatic narration; in "The Good Doctor", he created a "pastiche of sketches" around various stories by Chekhov; and "Fools" (1981), was written as a fairy-tale romance similar to stories by Sholem Aleichem. Although some of these efforts failed to win approval by many critics, Koprince claims that they nonetheless demonstrate Simon's "seriousness as a playwright and his interest in breaking new ground."
Critical response.
For most of his career Simon's work has received mixed reviews, with many critics admiring his comedy skills, much of it a blend of "humor and pathos". Other critics were less complimentary, noting that much of his dramatic structure was weak and sometimes relied too heavily on gags and one-liners. As a result, notes Kopince, "literary scholars had generally ignored Simon's early work, regarding him as a commercially successful playwright rather than a serious dramatist." Clive Barnes, theater critic for the "New York Times", wrote that like his British counterpart Noël Coward, Simon was "destined to spend most of his career underestimated", but nonetheless very "popular".
This attitude changed after 1991, when he won a Pulitzer Prize for drama with "Lost in Yonkers". McGovern writes that "seldom has even the most astute critic recognized what depths really exist in the plays of Neil Simon." Although, when "Lost in Yonkers" was considered by the Pulitzer Advisory Board, board member Douglas Watt noted that it was the only play nominated by all five jury members, and that they judged it "a mature work by an enduring (and often undervalued) American playwright."
McGovern compares Simon with noted earlier playwrights, including Ben Jonson, Molière, and George Bernard Shaw, pointing out that those playwrights had "successfully raised fundamental and sometimes tragic issues of universal and therefore enduring interest without eschewing the comic mode." She concludes, "It is my firm conviction that Neil Simon should be considered a member of this company ... an invitation long overdue." McGovern attempts to explain the response of many critics:
Similarly, literary critic Robert Johnson explains that Simon's plays have given us a "rich variety of entertaining, memorable characters" who portray the human experience, often with serious themes. Although his characters are "more lifelike, more complicated and more interesting" than most of the characters audiences see on stage, Simon has "not received as much critical attention as he deserves." Lawrence Grobel, in fact, calls him "the Shakespeare of his time", and possibly the "most successful playwright in history." He states:
Broadway critic Walter Kerr tries to rationalize why Simon's work has been underrated:
Personal life.
Simon has been married five times, to dancer Joan Baim (1953–1973), actress Marsha Mason (1973–1981), twice to actress Diane Lander (1987–1988 and 1990–1998), and currently actress Elaine Joyce. He is the father of Nancy and Ellen, from his first marriage, and Bryn, Lander's daughter from a previous relationship whom he adopted. His nephew is U.S. District Judge Michael H. Simon and niece-in-law is U.S. Congresswoman Suzanne Bonamici.
Simon is on the Board of Selectors of Jefferson Awards for Public Service.
Honors and recognition.
Simon has been conferred with three "honoris causa" degrees; a Doctor of Humane Letters from Hofstra University, a Doctor of Letters from Marquette University and a Doctor of Laws from Williams College. In 1983 Simon became the only living playwright to have a New York theatre named after him. The legitimate Broadway theater the Neil Simon Theatre, formerly the Alvin Theatre, was named in his honor, and he is an honorary member of the Walnut Street Theatre's board of trustees. Also in 1983, Simon was inducted into the American Theater Hall of Fame.
In 1965 he won the Tony Award for Best Playwright ("The Odd Couple"), and in 1975, a special Tony Award for his overall contribution to American theater. For "Brighton Beach Memoirs" (1983) he was awarded the New York Drama Critics Circle Award, followed by another Tony Award for Best Play of 1985, "Biloxi Blues". In 1991 he won the Pulitzer Prize along with the Tony Award for "Lost in Yonkers" (1991).

</doc>
<doc id="22050" url="https://en.wikipedia.org/wiki?curid=22050" title="North American Free Trade Agreement">
North American Free Trade Agreement

The North American Free Trade Agreement (NAFTA; Spanish: "Tratado de Libre Comercio de América del Norte", "TLCAN"; French: "Accord de libre-échange nord-américain", "ALÉNA") is an agreement signed by Canada, Mexico, and the United States, creating a trilateral trade bloc in North America. The agreement came into force on January 1, 1994. It superseded the Canada–United States Free Trade Agreement between the U.S. and Canada.
NAFTA has two supplements: the North American Agreement on Environmental Cooperation (NAAEC) and the North American Agreement on Labor Cooperation (NAALC).
Negotiation and U.S. ratification.
Following diplomatic negotiations dating back to 1990 among the three nations, U.S. President George H. W. Bush, Canadian Prime Minister Brian Mulroney and Mexican President Carlos Salinas, each responsible for spearheading and promoting the agreement, ceremonially signed the agreement in their respective capitals on December 17, 1992. The signed agreement then needed to be ratified by each nation's legislative or parliamentary branch.
The Canada–United States Free Trade Agreement had been very controversial and divisive in Canada, and the 1988 Canadian election was fought almost exclusively on that issue. In that election, more Canadians voted for anti-free trade parties (the Liberals and the New Democrats) but the split caused more seats in parliament to be won by the pro-free trade Progressive Conservatives (PCs). Mulroney and the PCs had a parliamentary majority and were easily able to pass the 1987 Canada-U.S. FTA and NAFTA bills. However, he was replaced as Conservative leader and prime minister by Kim Campbell. Campbell led the PC party into the 1993 election where they were decimated by the Liberal Party under Jean Chrétien, who had campaigned on a promise to renegotiate or abrogate NAFTA; however, Chrétien subsequently negotiated two supplemental agreements with the new U.S. president. In the U.S., Bush, who had worked to "fast track" the signing prior to the end of his term, ran out of time and had to pass the required ratification and signing of the implementation law to incoming president Bill Clinton. Prior to sending it to the United States Senate Clinton added two side agreements, The North American Agreement on Labor Cooperation (NAALC) and the North American Agreement on Environmental Cooperation (NAAEC), to protect workers and the environment, plus allay the concerns of many House members. It also required U.S. partners to adhere to environmental practices and regulations similar to its own.
After much consideration and emotional discussion, the House of Representatives passed the North American Free Trade Agreement Implementation Act on November 17, 1993, 234-200. The agreement's supporters included 132 Republicans and 102 Democrats. The bill passed the Senate on November 20, 1993, 61-38. Senate supporters were 34 Republicans and 27 Democrats. Clinton signed it into law on December 8, 1993; the agreement went into effect on January 1, 1994. Clinton, while signing the NAFTA bill, stated that "NAFTA means jobs. American jobs, and good-paying American jobs. If I didn't believe that, I wouldn't support this agreement."
Provisions.
The goal of NAFTA was to eliminate barriers to trade and investment between the U.S., Canada and Mexico. The implementation of NAFTA on January 1, 1994 brought the immediate elimination of tariffs on more than one-half of Mexico's exports to the U.S. and more than one-third of U.S. exports to Mexico. Within 10 years of the implementation of the agreement, all U.S.-Mexico tariffs would be eliminated except for some U.S. agricultural exports to Mexico that were to be phased out within 15 years. Most U.S.-Canada trade was already duty-free. NAFTA also sought to eliminate non-tariff trade barriers and to protect the intellectual property rights on traded products.
Chapter 52 provides a procedure for the international resolution of disputes over the application and interpretation of NAFTA. It was modelled after Chapter 69 of the Canada-United States Free Trade Agreement. The roster of NAFTA adjudicators includes many retired judges, such as Alice Desjardins, John Maxwell Evans, Constance Hunt, John Richard, Arlin M. Adams, Susan Getzendanner, George C. Pratt, Charles B. Renfrew and Sandra Day O'Connor.
Intellectual Property.
The North American Free Trade Agreement Implementation Act made some changes to the Copyright law of the United States, foreshadowing the Uruguay Round Agreements Act of 1994 by restoring copyright (within the NAFTA nations) on certain motion pictures which had entered the public domain.
Environment.
Securing U.S. congressional approval for NAFTA would have been impossible without addressing public concerns about NAFTA’s environmental impact. The Clinton administration negotiated a side agreement on the environment with Canada and Mexico, the North American Agreement on Environmental Cooperation (NAAEC), which led to the creation of the Commission for Environmental Cooperation (CEC) in 1994. To alleviate concerns that NAFTA, the first regional trade agreement between a developing country and two developed countries, would have negative environmental impacts, the CEC was given a mandate to conduct ongoing "ex post" environmental assessment of NAFTA.
In response to this mandate, the CEC created a framework for conducting environmental analysis of NAFTA, one of the first "ex post" frameworks for the environmental assessment of trade liberalization. The framework was designed to produce a focused and systematic body of evidence with respect to the initial hypotheses about NAFTA and the environment, such as the concern that NAFTA would create a "race to the bottom" in environmental regulation among the three countries, or the hope that NAFTA would pressure governments to increase their environmental protection mechanisms. The CEC has held four symposia using this framework to evaluate the environmental impacts of NAFTA and has commissioned 47 papers on this subject. In keeping with the CEC’s overall strategy of transparency and public involvement, the CEC commissioned these papers from leading independent experts.
Agriculture.
From the earliest negotiation, agriculture was (and still remains) a controversial topic within NAFTA, as it has been with almost all free trade agreements that have been signed within the WTO framework. Agriculture is the only section that was not negotiated trilaterally; instead, three separate agreements were signed between each pair of parties. The Canada–U.S. agreement contains significant restrictions and tariff quotas on agricultural products (mainly sugar, dairy, and poultry products), whereas the Mexico–U.S. pact allows for a wider liberalization within a framework of phase-out periods (it was the first North–South FTA on agriculture to be signed).
Transportation infrastructure.
NAFTA established the CANAMEX Corridor for road transport between Canada and Mexico, also proposed for use by rail, pipeline, and fiber optic telecommunications infrastructure. This became a High Priority Corridor under the U.S. Intermodal Surface Transportation Efficiency Act of 1991.
Impact.
NAFTA's effects, both positive and negative, have been quantified by several economists, whose findings have been reported in publications such as the World Bank's "Lessons from NAFTA for Latin America and the Caribbean", "NAFTA's Impact on North America", and "NAFTA Revisited" by the Institute for International Economics.
Canada.
Like Mexico and the U.S., Canada received a modest positive economic benefit as measured by GDP. Many feared declines failed to materialize, and some industries, like the furniture industry, were expected to suffer but grew instead. Canadian manufacturing employment held steady despite an international downward trend in developed countries. One of NAFTA's biggest economic effects on U.S.-Canada trade has been to boost bilateral agricultural flows. In the year 2008 alone, Canada exports to the United States and Mexico were at $381.3 billion, and imports from NAFTA were at $245.1 billion.
A book written by Mel Hurtig published in 2002 called "The Vanishing Country" charged that since NAFTA's ratification more than 10,000 Canadian companies had been taken over by foreigners, and that 98% of all foreign direct investments in Canada were for foreign takeovers.
Mexico.
Maquiladoras (Mexican assembly plants that take in imported components and produce goods for export) have become the landmark of trade in Mexico. These are plants that moved to this region from the United States, hence the debate over the loss of American jobs. Hufbauer's (2005) book shows that income in the maquiladora sector has increased 15.5% since the implementation of NAFTA in 1994. Other sectors now benefit from the free trade agreement, and the share of exports from non-border states has increased in the last five years while the share of exports from maquiladora-border states has decreased. This has allowed for the rapid growth of non-border metropolitan areas, such as Toluca, León and Puebla; all three larger in population than Tijuana, Ciudad Juárez, and Reynosa.
The overall effect of the Mexico–U.S. agricultural agreement is a matter of dispute. Mexico did not invest in the infrastructure necessary for competition, such as efficient rail roads and highways, which resulted in more difficult living conditions for the country's poor. Mexico's agricultural exports increased 9.4 percent annually between 1994 and 2001, while imports increased by only 6.9 percent a year during the same period.
One of the most affected agricultural sectors is the meat industry. Mexico has gone from a small player in the pre-1994 U.S. export market to the second largest importer of U.S. agricultural products in 2004, and NAFTA may be credited as a major catalyst for this change. The allowance of free trade removed the hurdles that impeded business between the two countries. As a result, Mexico has provided a growing market for meat for the U.S., leading to an increase in sales and profits for the U.S. meat industry. This coincides with a noticeable increase in Mexican per capita GDP that has created large changes in meat consumption patterns, implying that Mexicans can now afford to buy more meat and thus per capita meat consumption has grown.
Production of corn in Mexico has increased since NAFTA's implementation. However, internal corn demand has increased beyond Mexico's sufficiency, and imports have become necessary, far beyond the quotas Mexico had originally negotiated. Zahniser & Coyle have also pointed out that corn prices in Mexico, adjusted for international prices, have drastically decreased, yet through a program of subsidies expanded by former president Vicente Fox, production has remained stable since 2000.
A 2001 "Journal of Economic Perspectives" review of the existing literature found that NAFTA was a net benefit to Mexico.
NAFTA has also been credited with the rise of the Mexican middle class. A Tufts University study found that NAFTA lowered the average cost of basic necessities in Mexico by up to 50%. This price reduction has increased cash-on-hand for many Mexican families, allowing Mexico to graduate more engineers than Germany each year.
United States.
In a survey of leading economists, 95% supported the notion that on average, US citizens benefited on NAFTA. A 2001 "Journal of Economic Perspectives" review found that NAFTA was a net benefit to the United States.
The U.S. Chamber of Commerce credits NAFTA with increasing U.S. trade in goods and services with Canada and Mexico from $337 billion in 1993 to $1.2 trillion in 2011, while the AFL-CIO blames the agreement for sending 700,000 American manufacturing jobs to Mexico over that time.
Trade balances.
The U.S. had a services trade surplus of $28.3 billion with NAFTA countries in 2009 (the latest data available).The U.S. goods trade deficit with NAFTA was $94.6 billion in 2010, a 36.4% increase ($25 billion) over 2009. The U.S. goods trade deficit with NAFTA accounted for 26.8% of the overall U.S. goods trade deficit in 2010. 
In a study published in the August 2008 issue of the "American Journal of Agricultural Economics", NAFTA has increased U.S. agricultural exports to Mexico and Canada even though most of this increase occurred a decade after its ratification. The study focused on the effects that gradual "phase-in" periods in regional trade agreements, including NAFTA, have on trade flows. Most of the increase in members’ agricultural trade, which was only recently brought under the purview of the World Trade Organization, was due to very high trade barriers before NAFTA or other regional trade agreements.
Investment.
The U.S. foreign direct investment (FDI) in NAFTA countries (stock) was $327.5 billion in 2009 (latest data available), up 8.8% from 2008. The U.S. direct investment in NAFTA countries is in nonbank holding companies, and in the manufacturing, finance/insurance, and mining sectors. The foreign direct investment of Canada and Mexico in the United States (stock) was $237.2 billion in 2009 (the latest data available), up 16.5% from 2008.[http://www.fas.usda.gov/itp/policy/nafta/nafta.asp]
Jobs.
Many American small businesses depend on exporting their products to Canada or Mexico under NAFTA. According to the U.S. Trade Representative, this trade supports over 140,000 small and medium-sized businesses in the US. [https://ustr.gov/trade-agreements/free-trade-agreements/north-american-free-trade-agreement-nafta]
According to the Economic Policy Institute, California, Texas, Michigan and other states with high concentrations of manufacturing jobs were most affected by job loss due to NAFTA. EPI economist Robert Scott estimates some 682,900 U.S. jobs have been "lost or displaced" as a result of the trade agreement.
Environment.
Overall, none of the initial hypotheses were confirmed. NAFTA did not inherently present a systemic threat to the North American environment, as was originally feared. NAFTA-related environmental threats instead occurred in specific areas where government environmental policy, infrastructure, or mechanisms were unprepared for the increasing scale of production under trade liberalization. In some cases, environmental policy was neglected in the wake of trade liberalization; in other cases, NAFTA's measures for investment protection, such as Chapter 11, and measures against non-tariff trade barriers threatened to discourage more vigorous environmental policy. The most serious overall increases in pollution due to NAFTA were found in the base metals sector, the Mexican petroleum sector, and the transportation equipment sector in the United States and Mexico, but not in Canada.
Mobility of persons.
According to the Department of Homeland Security Yearbook of Immigration Statistics, during fiscal year 2006 (i.e., October 2005 through September 2006), 73,880 foreign professionals (64,633 Canadians and 9,247 Mexicans) were admitted into the United States for temporary employment under NAFTA (i.e., in the TN status). Additionally, 17,321 of their family members (13,136 Canadians, 2,904 Mexicans, as well as a number of third-country nationals married to Canadians and Mexicans) entered the U.S. in the treaty national's dependent (TD) status. Because DHS counts the number of the new I-94 arrival records filled at the border, and the TN-1 admission is valid for three years, the number of non-immigrants in TN status present in the U.S. at the end of the fiscal year is approximately equal to the number of admissions during the year. (A discrepancy may be caused by some TN entrants leaving the country or changing status before their three-year admission period has expired, while other immigrants admitted earlier may change their status "to" TN or TD, or extend TN status granted earlier).
Canadian authorities estimated that, as of December 1, 2006, a total of 24,830 U.S. citizens and 15,219 Mexican citizens were present in Canada as "foreign workers". These numbers include both entrants under the NAFTA agreement and those who have entered under other provisions of the Canadian immigration law. New entries of foreign workers in 2006 were 16,841 (U.S. citizens) and 13,933 (Mexicans).
Disputes and controversies.
Legal disputes.
In 1996, the gasoline additive MMT was brought into Canada by Ethyl Corporation, an American company. At the time, the Canadian federal government banned the importation of the additive. The American company brought a claim under NAFTA Chapter 11 seeking US$201 million, from the Canadian government and the Canadian provinces under the Agreement on Internal Trade ("AIT"). The American company argued that their additive had not been conclusively linked to any health dangers, and that the prohibition was damaging to their company. Following a finding that the ban was a violation of the AIT, the Canadian federal government repealed the ban and settled with the American company for US$13 million. Studies by Health and Welfare Canada (now Health Canada) on the health effects of MMT in fuel found no significant health effects associated with exposure to these exhaust emissions. Other Canadian researchers and the U.S. Environmental Protection Agency disagree with Health Canada, and cite studies that include possible nerve damage.
Canada had filed numerous motions to have the duty eliminated and the collected duties returned to Canada. After the United States lost an appeal from a NAFTA panel, it responded by saying "We are, of course, disappointed with the panel's decision, but it will have no impact on the anti-dumping and countervailing duty orders." (Nick Lifton, spokesman for U.S. Trade Representative Rob Portman) On July 21, 2006, the United States Court of International Trade found that imposition of the duties was contrary to U.S. law.
Change in income trust taxation not expropriation.
On October 30, 2007, American citizens Marvin and Elaine Gottlieb filed a Notice of Intent to Submit a Claim to Arbitration under NAFTA, claiming thousands of U.S. investors lost a total of $5 billion in the fall-out from the Conservative Government's decision the previous year to change the tax rate on income trusts in the energy sector. On April 29, 2009, a determination was made that this change in tax law was not expropriation.
Impact on Mexican farmers.
Several studies have rejected NAFTA as the force responsible for depressing the incomes of poor corn farmers, citing the trend's existence more than a decade before NAFTA's existence, an increase in maize production after NAFTA went into effect in 1994, and the lack of a measurable impact on the price of Mexican corn due to subsidized corn coming into Mexico from the United States, though they agree that the abolition of U.S. agricultural subsidies would benefit Mexican farmers.
Zapatista Uprising in response to NAFTA in Chiapas.
The preparations for NAFTA included cancellation of Article 27 of Mexico's constitution, the cornerstone of Emiliano Zapata's revolution of 1910–1919. Under the historic Article 27, Indian communal landholdings were protected from sale or privatization. However, this barrier to investment was incompatible with NAFTA. With the removal of Article 27, Indian farmers feared the loss of their remaining lands, and also feared cheap imports (substitutes) from the US. Thus, the Zapatistas labelled NAFTA as a "death sentence" to Indian communities all over Mexico. Then EZLN declared war on the Mexican state on January 1, 1994, the day NAFTA came into force.
Chapter 11.
Another contentious issue is the impact of the investor state dispute settlement obligations contained in Chapter 11 of the NAFTA. Chapter 11 allows corporations or individuals to sue Mexico, Canada or the United States for compensation when actions taken by those governments (or by those for whom they are responsible at international law, such as provincial, state, or municipal governments) violate the international law.
This chapter has been criticized by groups in the U.S., Mexico, and Canada for a variety of reasons, including not taking into account important social and environmental considerations. In Canada, several groups, including the Council of Canadians, challenged the constitutionality of Chapter 11. They lost at the trial level and have subsequently appealed.
Methanex Corporation, a Canadian corporation, filed a US$970 million suit against the United States, claiming that a California ban on Methyl tert-butyl ether (MTBE), a substance that had found its way into many wells in the state, was hurtful to the corporation's sales of methanol. However, the claim was rejected, and the company was ordered to pay US$3 million to the U.S. government in costs. The tribunal based its decision namely on following reasoning: But as a matter of general international law, a non-discriminatory regulation for a public purpose, which is enacted in accordance with due process and, which affects, inter alios, a foreign investor or investment is not deemed expropriatory and compensable unless specific commitments had been given by the regulating government to the then putative foreign investor contemplating investment that the government would refrain from such regulation.
In another case, Metalclad, an American corporation, was awarded US$15.6 million from Mexico after a Mexican municipality refused a construction permit for the hazardous waste landfill it intended to construct in Guadalcázar, San Luis Potosí. The construction had already been approved by the federal government with various environmental requirements imposed (see paragraph 48 of the tribunal decision). The NAFTA panel found that the municipality did not have the authority to ban construction on the basis of the environmental concerns.
Eli Lilly and Company v. Government of Canada is a US$500mn claim for faulty drug patent legislation. Apotex is suing the U.S. for US$520 million because of lost opportunity in a FDA generic drug decision.
Lone Pine Resources Inc. v. Government of Canada has filed a US$250mn claim against Canada, whom it accuses of "arbitrary, capricious and illegal" behaviour, because Quebec aims to prevent fracking exploration under the St. Lawrence Seaway. Milos Barutciski, the lawyer who represents Lone Pine, has decried attempts to portray his client as "another rapacious multinational challenging governments’ ability to regulate for health, safety and the environment". Lone Pine Resources is incorporated in Delaware but headquartered in Calgary, and had an initial public offering of stock on the NYSE on May 25, 2011, which offered 15 million shares each for $13 and raised US$195 million. Barutciski acknowledged "that NAFTA and other investor-protection treaties create an anomaly in that Canadian companies that have also seen their permits rescinded by the very same Quebec legislation, which expressly forbids the paying of compensation, do not have the right pursue a NAFTA claim," and that winning "compensation in Canadian courts for domestic companies in this case would be more difficult since the Constitution puts property rights in provincial hands." A treaty with China would extend similar rights to Chinese investors, including SOEs.
Chapter 19.
Also contentious is NAFTA's Chapter 19, which subjects antidumping and countervailing duty (AD/CVD) determinations to binational panel review instead of, or in addition to, conventional judicial review. For example, in the United States, review of agency decisions imposing antidumping and countervailing duties are normally heard before the U.S. Court of International Trade, an Article III court. NAFTA parties, however, have the option of appealing the decisions to binational panels composed of five citizens from the two relevant NAFTA countries. The panelists are generally lawyers experienced in international trade law. Since the NAFTA does not include substantive provisions concerning AD/CVD, the panel is charged with determining whether final agency determinations involving AD/CVD conform with the country's domestic law. Chapter 19 can be considered as somewhat of an anomaly in international dispute settlement since it does not apply international law, but requires a panel composed of individuals from many countries to re-examine the application of one country's domestic law.
A Chapter 19 panel is expected to examine whether the agency's determination is supported by "substantial evidence." This standard assumes significant deference to the domestic agency.
Some of the most controversial trade disputes in recent years, such as the U.S.-Canada softwood lumber dispute, have been litigated before Chapter 19 panels.
Decisions by Chapter 19 panels can be challenged before a NAFTA extraordinary challenge committee. However, an extraordinary challenge committee does not function as an ordinary appeal. Under NAFTA, it will only vacate or remand a decision if the decision involves a significant and material error that threatens the integrity of the NAFTA dispute settlement system. Since January 2006, no NAFTA party has successfully challenged a Chapter 19 panel's decision before an extraordinary challenge committee.
Trans-Pacific Partnership.
If the Trans-Pacific Partnership comes into effect, existing agreements like NAFTA will be reduced to those provisions that do not conflict with the TPP, or that require greater trade liberalization than the TPP.

</doc>
<doc id="22051" url="https://en.wikipedia.org/wiki?curid=22051" title="National Lampoon (magazine)">
National Lampoon (magazine)

National Lampoon was a ground-breaking American humor magazine which ran from 1970 to 1998. The magazine started out as a spinoff from the "Harvard Lampoon". "National Lampoon" magazine reached its height of popularity and critical acclaim during the 1970s, when it had a far-reaching effect on American humor and comedy. The magazine spawned films, radio, live theatre, various kinds of recordings, and print products including books. Many members of the creative staff from the magazine subsequently went on to contribute creatively to successful media of all types.
During the magazine's most successful years, parody of every kind was a mainstay; surrealist content was also central to its appeal. Almost all the issues included long text pieces, shorter written pieces, a section of actual news items (dubbed "True Facts"), cartoons and comic strips. Most issues also included "Foto Funnies" or fumetti, which often featured nudity. The result was an unusual mix of intelligent, cutting-edge wit, combined with some crass, bawdy jesting.
In both cases, "National Lampoon" humor often pushed far beyond the boundaries of what was generally considered appropriate and acceptable. As co-founder Henry Beard described the experience years later: "There was this big door that said, 'Thou shalt not.' We touched it, and it fell off its hinges."
The magazine declined during the late 1980s and never recovered. It was kept alive minimally, but ceased publication altogether in 1998.
About the magazine.
"National Lampoon" was started by Harvard graduates and "Harvard Lampoon" alumni Doug Kenney, Henry Beard and Robert Hoffman in 1969, when they first licensed the "Lampoon" name for a monthly national publication. The magazine's first issue was dated April 1970. The company that owned the magazine was called Twenty First Century Communications.
After a shaky start for a few issues, the magazine rapidly grew in popularity. Like the "Harvard Lampoon", individual issues had themes, including such topics as "The Future", "Back to School", "Death", "Self-Indulgence", and "Blight". The magazine regularly reprinted material in "best-of" omnibus collections. Its writers joyfully targeted every kind of phoniness, and had no specific political stance, even though individual staff members had strong political views.
"National Lampoon" was a monthly magazine for most of its publication history. Numerous "special editions" were also published and sold simultaneously on newsstands. Some of the special editions were anthologies of reprinted material; others were entirely original. Additional projects included a calendar, a songbook, a collection of transfer designs for T-shirts, and a number of books. The magazine sold yellow binders with the Lampoon logo, designed to store a year's worth of issues.
Cover art.
The original art directors were cartoonist Peter Bramley and Bill Skurski, founders of New York's "Cloud Studio", an alternative-culture outfit known at the time for its eclectic style. Bramley created the Lampoon's first cover and induced successful cartoonists Arnold Roth and Gahan Wilson to become regular contributors. 
Beginning with the eighth issue, the art direction of the magazine was taken over by Michael C. Gross, who directed the look of the magazine until 1974. A number of the "National Lampoon"'s most acerbic and humorous covers were designed or overseen by Gross, including:
Michael Gross and Doug Kenney chose a young designer from "Esquire" Magazine named Peter Kleinman to succeed the team of Gross and David Kaestle. During his Lampoon tenure, Kleinman was also the art director of "Heavy Metal" magazine, published by the same company. The best known of Kleinman's Lampoon covers were "Stevie Wonder with 3-D Glasses," painted by Sol Korby; a photographed "Nose to The Grindstone" cover depicting a man's face being pressed against a spinning grinder wheel for the "Work" issue; the "JFK's First 6000 Days Issue," featuring a portrait of an old John F. Kennedy; the "Fat Elvis" Cover which appeared a year before Elvis Presley died, and many of the Mara McAfee covers done in a classic Norman Rockwell style. Kleinman designed the logos for "Animal House" and "Heavy Metal." 
Kleinman left in 1979 to open an ad agency.
He was succeeded by Skip Johnson, the designer responsible for the "Sunday Newspaper Parody" and the "Arab Getting Punched in the Face" cover of the "Revenge" Issue. Johnson went on to "The New York Times." He was followed by Michael Grossman, who changed the logo and style of the magazine.
In 1984, Kleinman returned as Creative Director and went back to the 1970s logo and style, bringing back many of the artists and writers from the magazine's heyday. He left four years later to pursue a career in corporate marketing. At that time, the "National Lampoon" magazine entered a period of precipitous decline.
Editorial.
Every regular monthly issue of the magazine had an editorial at the front of the magazine. This often appeared to be straightforward, but was always a parody. It was written by whoever was the editor of that particular issue, since that role rotated among the staff. A few issues were guest-edited.
Staff.
The magazine was an outlet for some notable writing talents, including Kenney, Beard, George W. S. Trow, Chris Miller, P. J. O'Rourke, Michael O'Donoghue, Chris Rush, Sean Kelly, Tony Hendra, Brian McConnachie, Gerald Sussman, Ellis Weiner, Danny Abelson, Ted Mann, Chris Cluess, Al Jean, Mike Reiss, Jeff Greenfield, and John Hughes.
The work of many important cartoonists, photographers and illustrators appeared in the magazine's pages, including Neal Adams, Gahan Wilson, Michael Sullivan, Ron Barrett, Peter Bramley, Vaughn Bode, Bruce McCall, Rick Meyerowitz, Warren Sattler, M. K. Brown, Shary Flenniken, Bobby London, Edward Gorey, Jeff Jones, Joe Orlando, Arnold Roth, Rich Grote, Ed Subitzky, Mara McAfee, Sam Gross, Charles Rodrigues, Buddy Hickerson, B. K. Taylor, Birney Lettick, Frank Frazetta, Boris Vallejo, Marvin Mattelson, Stan Mack, Chris Callis, John E. Barrett, Raymond Kursar and Andy Lackow.
Comedy stars John Belushi, Chevy Chase, Gilda Radner, Bill Murray, Brian Doyle Murray, Harold Ramis, and Richard Belzer first gained national attention for their performances in the National Lampoon's stage show and radio show. The first three subsequently went on to become part of "Saturday Night Live"'s original wave of Not Ready for Primetime Players, Bill Murray replaced Chase when Chase left "SNL" after the first season, and Brian Doyle Murray later appeared as an "SNL" regular. Harold Ramis went on to be a prolific director and writer working on such films as "Animal House", "Caddyshack", "Ghostbusters", and many more. Brian Doyle Murray has had roles in dozens of films, and Belzer is an Emmy-award-winning TV actor.
Jerry Taylor aka Gerald L. Taylor was the Publisher, followed by William T. Lippe. The business side of the magazine was controlled by Matty Simmons, who was Chairman of the Board and CEO of Twenty First Century Communications, a publishing company.
True Facts.
"True Facts" was a section near the front of the magazine which contained true but ridiculous items from real life. Together with the masthead, it was one of the few parts of the magazine that was factual. "True Facts" included photographs of unintentionally funny signage, extracts from ludicrous newspaper reports, strange headlines, and so on. For many years John Bendel was in charge of the "True Facts" section of the magazine. Steven Brykman edited the "True Facts" section of the National Lampoon website. Several "True Facts" compilation books were published in the 1980s and early 90s, and several all-True-Facts issues of the magazine were published during the 1980s.
Foto Funnies.
Most issues of the magazine featured one or more "Foto Funny" or fumetti, comic strips that use photographs instead of drawings as illustrations. The characters who appeared in the Lampoon's Foto Funnies were usually editors or contributing editors of the magazine, often cast alongside nude or semi-nude models. In 1980, a paperback compilation book, "National Lampoon Foto Funnies", was published.
Funny Pages.
The "Funny Pages" was a large section at the back of the magazine that was composed entirely of comic strips of various kinds. These included work from a number of artists who also had pieces published in the main part of the magazine, including Gahan Wilson, Ed Subitzky and Vaughn Bode, as well as artists whose work was only published in this section. The regular strips included "Dirty Duck" by Bobby London, "Trots and Bonnie" by Shary Flenniken, "The Appletons" by B. K. Taylor, and "Politeness Man" by Ron Barrett, and many other strips. A compilation of Gahan Wilson's "Nuts" strip was published in 2011. The Funny Pages logo header art residing above Gahan Wilson's "Nuts" in each issue, showing a comfortable, old-fashioned family reading newspaper-sized funny papers, was by Michael Wm Kaluta.
Other merchandise.
From time to time the magazine advertised Lampoon-related merchandise for sale, including tee-shirts that had been especially designed.
Chronology.
The magazine existed from 1970 to 1998. Some consider its finest period was from 1971 to 1975, although it continued to be produced on a monthly schedule throughout the 1970s and the early 1980s, and did well during that time.
However, during the late 1980s, a much more serious decline set in. In 1989, the company that controlled the magazine and its related projects (which was part of "Twenty First Century Communications") was the subject of a hostile takeover. In 1991 it was sold outright to another company, "J2 Communications".
At that point "National Lampoon" was considered valuable only as a brand name that could be licensed out to other companies. The magazine was issued erratically and rarely from 1991 onwards. 1998 saw the last issue.
1970.
The first issue was April 1970. By November of that year Michael Gross had become the art director. He achieved a unified, sophisticated and integrated look for the magazine, which enhanced its humorous appeal.
1973–1975.
National Lampoon's most successful sales period was 1973–75. Its national circulation peaked at 1,000,096 copies sold of the October 1974 "Pubescence" issue. The 1974 monthly average was 830,000, which was also a peak. Former "Lampoon" editor Tony Hendra's book "Going Too Far" includes a series of precise circulation figures.
The magazine was considered by many to be at its creative zenith during this time. It should however be noted that the publishing industry's newsstand sales were excellent for many other titles during that time: there were sales peaks for "Mad" (more than 2 million), "Playboy" (more than 7 million), and "TV Guide" (more than 19 million).
1975.
Some fans consider the glory days of National Lampoon to have ended in 1975, although the magazine remained popular and profitable long after that point. During 1975, the three founders (Kenney, Beard and Hoffman) took advantage of a buyout clause in their contracts for $7.5 million. And, at about the same time, writers Michael O'Donoghue and Anne Beatts left to join the NBC comedy show "Saturday Night Live" ("SNL"). At the same time, the National Lampoon Show's John Belushi and Gilda Radner left the troupe to join the original septet of SNL's "Not Ready for Primetime Players."
The magazine was a springboard to Hollywood for a generation of comedy writers, directors, and performers. Various alumni went on to create and write for "Saturday Night Live," "The David Letterman Show," SCTV, "The Simpsons", "Married... with Children", "Night Court", and various films including "National Lampoon's Animal House", "Caddyshack", "National Lampoon's Vacation", and "Ghostbusters".
As some of the original creators departed, the magazine remained popular and profitable as it saw the emergence of John Hughes and editor-in-chief P.J. O'Rourke, along with artists and writers such as Gerry Sussman, Ellis Weiner, Tony Hendra, Ted Mann, Peter Kleinman, Chris Cleuss, Stu Kreisman, John Weidman, Jeff Greenfield, Bruce McCall, and Rick Meyerowitz.
1985.
In 1985, Matty Simmons (who had been working only on the business end of the Lampoon up to that point) took over as Editor-in-Chief. He fired the entire editorial staff, and appointed his two sons, Michael Simmons and Andy Simmons, as editors, Peter Kleinman as Creative Director and Editor, and Larry "Ratso" Sloman as Executive Editor.
The magazine was on an increasingly shaky financial footing, and, beginning in November 1986, the magazine was published six times a year instead of every month.
1989.
In 1989, the magazine was acquired in a hostile takeover by a business partnership of producer Daniel Grodnik and actor Tim Matheson (who played "Otter" in the 1978 film "National Lampoon's Animal House"). Grodnik and Matheson became the co-Chairmen/co CEOS. During their tenure, the stock went up from under $2 to $6 and the magazine doubled the monthly ad pages from 7 to 15. The company moved its headquarters from New York to Los Angeles to focus on film and television. The publishing operation stayed in New York.
1991.
In 1991 the magazine (and more importantly, the rights to the brand name "National Lampoon") were bought by a company called J2 Communications, headed by James P. Jimirro. (J2 was previously known for marketing Tim Conway's "Dorf" videos.)
J2 Communications' focus was to make money by licensing out the brand name "National Lampoon". The company was contractually obliged to publish at least one new issue of the magazine per year in order to retain the rights to the Lampoon name. However, the company had very little interest in the magazine itself; throughout the 1990s the number of issues per year declined precipitously and erratically. In 1991 there was an attempt at monthly publication: nine issues were produced that year. Only two issues were released in 1992. This was followed by one issue in 1993, five in 1994, and three in 1995. For the last three years of its existence, the magazine was published only once a year.
1998, last issue.
The magazine's final print publication was November 1998, after which the contract was renegotiated, and in a sharp reversal, J2 Communications was then "prohibited" from publishing issues of the magazine. J2, however, still owned the rights to the brand name, which it continued to franchise out to other users. In 2002 the use of the brand name and the rights to republish old material were sold to a new, and otherwise unrelated, company which chose to call itself National Lampoon, Incorporated.
Related media.
During its most active period, the magazine spun off numerous productions in a wide variety of media.
"National Lampoon" released books, special issues, anthologies, and other print pieces, including:
Books.
"True Facts" special editions and books
Recordings.
Vinyl.
Vinyl record albums
Vinyl singles
CDs.
Many of the older albums that were originally on vinyl have been re-issued as CDs and a number of tracks from certain albums are available as MP3s.
Films.
There is considerable ambiguity about what actually constitutes a "National Lampoon" film.
During the 1970s and early 1980s, a few films were made as spin-offs from the original "National Lampoon" magazine, using its creative staff. The first theatrical release, and by far the most successful "National Lampoon" film was "National Lampoon's Animal House" (1978). Starring John Belushi and written by Doug Kenney, Harold Ramis and Chris Miller, it became the highest grossing comedy film of that time. Produced on a low budget, it was so enormously profitable that, from that point on for the next two decades, the name "National Lampoon" applied to the title of a movie was considered to be a valuable selling point in and of itself.
Numerous movies were subsequently made that had "National Lampoon" as part of the title. Many of these were unrelated projects, because by that point in time, the name "National Lampoon" could simply be licensed on a one-time basis, by any company, for a fee. Critics such as the "Orlando Sentinel"′s Roger Moore and the "New York Times"′ Andrew Adam Newman have written about the cheapening of the "National Lampoon"′s movie imprimatur; in 2006, an Associated Press review said: "The National Lampoon, once a brand name above nearly all others in comedy, has become shorthand for pathetic frat boy humor."
The first of the "National Lampoon" movies was a not-very-successful made-for-TV movie: 
"National Lampoon's Animal House".
In 1978, "National Lampoon's Animal House" was released. Made on a small budget, it did phenomenally well at the box office. In 2001, the United States Library of Congress considered the film "culturally significant", and preserved it in the National Film Registry.
The script had its origins in a series of short stories that had been previously published in the magazine. These included Chris Miller's "Night of the Seven Fires," which dramatized a frat initiation and included the characters Pinto and Otter, which contained prose versions of the toga party, the "road trip", and the dead horse incident. Another source was Doug Kenney's "First Lay Comics," which included the angel and devil scene and the grocery-cart affair. According to the authors, most of these elements were based on real incidents.
"National Lampoon's Class Reunion".
This 1982 movie was an attempt by John Hughes to make something similar to "Animal House". "National Lampoon's Class Reunion" was not successful however.
"National Lampoon's Vacation".
Released in 1983, the movie "National Lampoon's Vacation" was based upon John Hughes' "National Lampoon" story "Vacation '58". The movie's financial success gave rise to several follow-up films, including "National Lampoon's European Vacation" (1985), "National Lampoon's Christmas Vacation" (1989), based on John Hughes' "Christmas '59", "Vegas Vacation" (1997), and most recently "Vacation" (2015), all featuring Chevy Chase.
Similar films.
The Robert Altman film "O.C. and Stiggs" (1987) was based on two characters who had been featured in several written pieces in "National Lampoon" magazine, including an issue-long story from October 1982 entitled "The Utterly Monstrous, Mind-Roasting Summer of O.C. and Stiggs." Completed in 1984, the film was not released until 1987, when it was shown in a small number of theaters and without the "National Lampoon" name. It was not a success.
Following the success of "Animal House", "MAD" magazine lent its name to a 1980 comedy titled "Up the Academy". But whereas two of "Animal House"′s co-writers were the "Lampoon"′s Doug Kenney and Chris Miller, "Up The Academy" was strictly a licensing maneuver, with no creative input from "MAD"′s staff or contributors. It was a critical and commercial failure.
Film about the magazine.
In 2015, a documentary film was released called "". The film featured a great deal of content from the magazine, as well as interviews with staff members and fans, and it explains how the magazine changed the course of humor.

</doc>
<doc id="22052" url="https://en.wikipedia.org/wiki?curid=22052" title="Non-disclosure agreement">
Non-disclosure agreement

A non-disclosure agreement (NDA), also known as a confidentiality agreement (CA), confidential disclosure agreement (CDA), proprietary information agreement (PIA), or secrecy agreement (SA), is a legal contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes, but wish to restrict access to or by third parties. It is a contract through which the parties agree not to disclose information covered by the agreement. An NDA creates a confidential relationship between the parties to protect any type of confidential and proprietary information or trade secrets. As such, an NDA protects non-public business information.
NDAs are commonly signed when two companies, individuals, or other entities (such as partnerships, societies, etc.) are considering doing business and need to understand the processes used in each other's business for the purpose of evaluating the potential business relationship. NDAs can be "mutual", meaning both parties are restricted in their use of the materials provided, or they can restrict the use of material by a single party.
It is also possible for an employee to sign an NDA or NDA-like agreement with an employer. In fact, some employment agreements will include a clause restricting employees' use and dissemination of company-owned confidential information.
Types.
A non-disclosure agreement may be unilateral or bilateral, that is, it may bind only one party or multiple parties (typically two):
Unilateral NDA.
A unilateral, or a one-way, agreement is where one party wants to disclose certain information to another party but needs the information to remain secret for some reason, perhaps due to secrecy requirements required to satisfy patent laws or to make sure that the other party does not take and use the disclosed information without compensating the discloser.
Bilateral NDA.
A bilateral, or mutual, agreement is where both parties will be supplying information that is intended to remain secret. This type of agreement is common when businesses are considering some kind of joint venture or merger.
Some practitioners insist on a mutual NDA in all cases, to encourage the drafter to make the provisions "fair and balanced" in case the drafter's receiving-party client later ends up as a disclosing party, or vice versa (not an uncommon occurrence).
Content.
A nondisclosure agreement can protect any type of information that is not generally known. However, nondisclosure agreements may also contain clauses that will protect the person receiving the information so that if they lawfully obtained the information through other sources they would not be obligated to keep the information secret. In other words, the nondisclosure agreement typically only requires the receiving party to maintain information in confidence when that information has been directly supplied by the disclosing party. Ironically, however, it is sometimes easier to get a receiving party to sign a simple agreement that is shorter, less complex and does not contain safety provisions protecting the receiver.
Some common issues addressed in an NDA include:
California.
In California (and some other states), there are some special circumstances relating to non-disclosure agreements and non-compete clauses. California's courts and legislature have signaled that they generally value an employee's mobility and entrepreneurship more highly than they do protectionist doctrine.
India.
Use of non-disclosure agreements are on the rise in India and is governed by the Indian Contract Act 1872. Use of an NDA is crucial in many circumstances, such as to tie in employees who are developing patentable technology if the employer intends to apply for a patent. Non-disclosure agreements have become very important in light of India's burgeoning outsourcing industry. In India, an NDA must be stamped to be a valid enforceable document.

</doc>
<doc id="22053" url="https://en.wikipedia.org/wiki?curid=22053" title="Network effect">
Network effect

In economics and business, a network effect (also called network externality or demand-side economies of scale) is the effect that one user of a good or service has on the value of that product to other people. When a network effect is present, the value of a product or service is dependent on the number of others using it.
The classic example is the telephone. The more people who own telephones, the more valuable the telephone is to each owner. This creates a positive externality because a user may purchase a telephone without intending to create value for other users, but does so in any case. Online social networks work in the same way, with sites like Twitter and Facebook becoming more attractive as more users join.
The expression "network effect" is applied most commonly to positive network externalities as in the case of the telephone. Negative network externalities can also occur, where more users make a product less valuable, but are more commonly referred to as "congestion" (as in traffic congestion or network congestion).
Over time, positive network effects can create a bandwagon effect as the network becomes more valuable and more people join, in a positive feedback loop.
Origins.
Network effects were a central theme in the arguments of Theodore Vail, the first post patent president of Bell Telephone, in gaining a monopoly on US telephone services. In 1908, when he presented the concept in Bell's annual report, there were over 4,000 local and regional telephone exchanges, most of which were eventually merged into the Bell System.
The economic theory of the network effect was advanced significantly between 1985 and 1995 by researchers Michael L. Katz, Carl Shapiro, Joseph Farrell and Garth Saloner.
Network effects were popularized by Robert Metcalfe, stated as Metcalfe's law. Metcalfe was one of the co-inventors of Ethernet and a co-founder of the company 3Com. In selling the product, Metcalfe argued that customers needed Ethernet cards to grow above a certain critical mass if they were to reap the benefits of their network.
According to Metcalfe, the rationale behind the sale of networking cards was that (1) the cost of the network was directly proportional to the number of cards installed, but (2) the value of the network was proportional to the square of the number of users. This was expressed algebraically as having a cost of N, and a value of N². While the actual numbers behind this definition were never firm, the concept allowed customers to share access to expensive resources like disk drives and printers, send e-mail, and access the Internet.
Rod Beckstrom presented a mathematical model for describing networks that are in a state of positive network effect at BlackHat and Defcon in 2009 and also presented the "inverse network effect" with an economic model for defining it as well.
Benefits.
Network effects become significant after a certain subscription percentage has been achieved, called critical mass. At the critical mass point, the value obtained from the good or service is greater than or equal to the price paid for the good or service. As the value of the good is determined by the user base, this implies that after a certain number of people have subscribed to the service or purchased the good, additional people will subscribe to the service or purchase the good due to the value exceeding the price.
A key business concern must then be how to attract users prior to reaching critical mass. One way is to rely on extrinsic motivation, such as a payment, a fee waiver, or a request for friends to sign up. A more natural strategy is to build a system that has enough value "without" network effects, at least to early adopters. Then, as the number of users increases, the system becomes even more valuable and is able to attract a wider user base.
Beyond critical mass, the increasing number of subscribers generally cannot continue indefinitely. After a certain point, most networks become either congested or saturated, stopping future uptake. Congestion occurs due to overuse. The applicable analogy is that of a telephone network. While the number of users is below the congestion point, each additional user adds additional value to every other customer. However, at some point the addition of an extra user exceeds the capacity of the existing system. After this point, each additional user decreases the value obtained by every other user. In practical terms, each additional user increases the total system load, leading to busy signals, the inability to get a dial tone, and poor customer support. The next critical point is where the value obtained again equals the price paid. The network will cease to grow at this point, and the system must be enlarged. The congestion point may be larger than the market size. New Peer-to-peer technological models may always defy congestion. Peer-to-peer systems, or "P2P," are networks designed to distribute load among their user pool. This theoretically allows true P2P networks to scale indefinitely. The P2P based telephony service Skype benefits greatly from this effect (though market saturation will still occur).
Network effects are commonly mistaken for economies of scale, which result from business size rather than interoperability. To help clarify the distinction, people speak of demand side vs. supply side economies of scale. Classical economies of scale are on the production side, while network effects arise on the demand side. Network effects are also mistaken for economies of scope.
The network effect has a lot of similarities with the description of phenomenon in reinforcing positive feedback loops described in system dynamics. System dynamics could be used as a modelling method to describe phenomena such as word of mouth and Bass model of marketing.
Network effect is a benefit to society as a whole because it positively relates to and affects the Intellectual Commons, Property Rights, and Cultural Commons of the world. One form of network externality is social media, which is a peer-to-peer network ran by a privately held for profit business. Although the creation of a large network creates a barrier to entry according to Porters five forces and may prevent a few from creating a new form of P2P networking, it largely benefits society as whole and provides a new form of a common-pool resource solargely scalable that the entire world has the ability to use it. Although the barrier to entry may be high, there is no true form of monopoly in the P2P social sharing market. For example, Facebook holds a large stake in the P2P social sharing market, but it is not mutually exclusive, meaning users can have an account on Facebook and also have an account on Twitter. Furthermore, there becomes no true critical mass in this space due to the ability for technology and innovation to constantly adapt to different environments, market for underdeveloped countries to integrate with social sharing is unlimited.
Network effect relates to the intellectual commons in a positive way. Through P2P networks users are able to share their intellectual property in a way that can benefit society as a whole.The sharing of intellectual property ultimately relates to, economic growth due to the ability for creators to share information and still possibly benefit financially from it. Through P2P networks people are able to share types of education like scholarly articles, becoming a new form of public commons. Network externality like Ted.com is an example of how intellectual commons with the use of network externality benefits society as a whole. Those who present intellectual property at Ted conferences are sharing their education on a public forum that benefits whoever will listen. Therefore, the larger Ted.com network becomes positively correlates to those who benefit from its common-pool resources.
P2P networks positively affect property rights. In reference to property rights, it enables those who create the intellectual property: The right to use the good, The right to earn income from the good, The right to transfer the good to others, The right to enforcement of property rights. Through P2P networks those who provide intellectual property not only have these rights, but they also possess the right to claim their information on a public forum. Due to these rights sharing benefits the intellectual property holders and promotes P2P sharing in a positive way. Those who consume the intellectual property also benefit positively from the sharing of it because they are able to use the information freely with respect to the person who created it. An example of this system in effect is a company called Music Vault. Music Vault operates on the P2P network Facebook, enabling users who create music to openly and freely collaborate with other artists content. This is a form of remixing that benefits both parties. This is an example of how a P2P network positively affects the sharing of property rights. In Joseph E. Stiglitz essay "Prizes, Not Patents", he suggests that the creation of intellectual property should be rewarded with by social gratification and rewards instead of patents preventing others from duplicating the creation and sharing it as a common-pool resource. This can be related to P2P networking because it creates a greater incentive for those who create intellectual property to share it is a common-pool resource. As a P2P sharing network becomes larger the gratification of being rewarded on a global public forum would compete with a patent. It is through large P2P networks and network externality that humans can create a reward system large enough to deter seekers of patents to be rewarded in different ways.
Network Externality positively affects the cultural commons in many ways. The reward for being part of a group, society, and even the world through a P2P network is one of the greatest benefits that a modern common-pool resource can provide.The ability to connect and create with people from different cultures, ethnicities, and beliefs is something thought to be impossible 100 years ago. Without network externality this form of communication would have been impossible. Through P2P sharing the world as a culture are able to learn and teach each other through public forums. In Sugata Mitra’s Ted talk, “The child-driven education” he placed a computer in the a third world town and left it there to see what would happen. To his amazement children were able to quickly figure out how to use the computer and educate themselves on its inner workings. This example is a benefit to society for several reasons. The first is the relationship between Sugata Mitra and the P2P network which led him to place the computer in a third world town, along with the ability to present his findings on a public forum. Secondly, it is those who consumed his ted talk and benefited from the knowledge that those in third world countries just need a chance to learn and they will take it. This experiment as a whole brings the culture of the world together and connects us with those we thought impossible due to the P2P network and network externality that led individuals to the Ted talk.
Technology lifecycle.
If some existing technology or company whose benefits are largely based on network effects starts to lose market share against a challenger such as a disruptive technology or open standards based competition, the benefits of network effects will reduce for the incumbent, and increase for the challenger. In this model, a tipping point is eventually reached at which the network effects of the challenger dominate those of the former incumbent, and the incumbent is forced into an accelerating decline, whilst the challenger takes over the incumbent's former position.
Lock-in.
Not surprisingly network economics became a hot topic after the diffusion of the Internet across academia. Most people know only of Metcalfe's law as part of network effects. Network effects are notorious for causing lock-in with the most-cited examples being Microsoft products and the QWERTY keyboard.
Vendor lock-in can be mitigated by opening the standards upon which users depend, allowing competition between implementations. This does not, however, mitigate industry-wide lock-in to the standard itself. Indeed, as there are now multiple vendors driving down the price and increasing the quality, more users are likely to adopt the standard thereby creating greater industry-wide lock-in to the standard.
Types of network effects.
There are many ways to classify networks effects. One popular segmentation views network effects as being of four kinds:
Additionally, there are two sources of economic value that are relevant when analyzing products that display network effects:
Negative network effects.
Negative network effects, in the mathematical sense, are those that have the opposite effect on stability compared to normal (positive) network effects. Just like positive network effects cause positive feedback loops and exponential growth, negative network effects create negative feedback and exponential decay. In nature, negative network effects are the forces that pull towards equilibrium, are responsible for stability, and are the physical limitations preventing states from reaching infinity.
Interoperability.
Interoperability has the effect of making the network bigger and thus increases the external value of the network increasing appear to consumers. Interoperability achieves this primarily by increasing potential connections and secondarily by attracting new participants to the network. Other benefits of interoperability include reduced uncertainty, reduced lock-in, commoditization and competition based on price.
Interoperability can be achieve through standardization or other cooperation. Companies involved in fostering interoperability face a tension between cooperating with their competitors to grow the potential market for products and competing for market share.
Open versus closed standards.
In communication and information technologies, open standards and interfaces are often developed through the participation of multiple companies and are usually perceived to provide mutual benefit. But, in cases in which the relevant communication protocols or interfaces are closed standards the network effect can give the company controlling those standards monopoly power. The Microsoft corporation is widely seen by computer professionals as maintaining its monopoly through these means. One observed method Microsoft uses to put the network effect to its advantage is called Embrace, extend and extinguish.
Mirabilis is an Israeli start-up which pioneered instant messaging (IM) and was bought by America Online. By giving away their ICQ product for free and preventing interoperability between their client software and other products, they were able to temporarily dominate the market for instant messaging. Because of the network effect, new IM users gained much more value by choosing to use the Mirabilis system (and join its large network of users) than they would using a competing system. As was typical for that era, the company never made any attempt to generate profits from their dominant position before selling the company.
Examples.
Financial exchanges.
Stock exchanges and derivatives exchanges feature a network effect. Market liquidity is a major determinant of transaction cost in the sale or purchase of a security, as a bid-ask spread exists between the price at which a purchase can be done versus the price at which the sale of the same security can be done. As the number of buyers and sellers on an exchange increases, liquidity increases, and transaction costs decrease. This then attracts a larger number of buyers and sellers to the exchange.
The network advantage of financial exchanges is apparent in the difficulty that startup exchanges have in dislodging a dominant exchange. For example, the Chicago Board of Trade has retained overwhelming dominance of trading in US Treasury bond futures despite the startup of Eurex US trading of identical futures contracts. Similarly, the Chicago Mercantile Exchange has maintained a dominance in trading of Eurobond interest rate futures despite a challenge from Euronext.Liffe.
Software.
There are very strong network effects operating in the market for widely used computer software.
Take, for example, Microsoft Office. For many people choosing an office suite, prime considerations include how valuable having learned that office suite will prove to potential employers, and how well the software interoperates with other users. That is, since learning to use an office suite takes many hours, they want to invest that time learning the office suite that will make them most attractive to potential employers and clients, and they also want to be able to share documents. (Additionally, an example of an indirect network effect in this case is the notable similarity in user-interfaces and operability menus of most new software – since that similarity directly translates into less time spent learning new environments, therefore potentially greater acceptance and adoption of those products.)
Similarly, finding already-trained employees is a big concern for employers when deciding which office suite to purchase or standardize on. The lack of cross-platform user-interface standards results in a situation in which one firm is in control of almost 100% of the market.
Microsoft Windows is a further example of network effect. The most-vaunted advantage of Windows, and that most publicised by Microsoft, is that Windows is compatible with the widest range of computer hardware and software. Although this claim is justified, it is in reality the result of network effect: hardware and software manufacturers ensure that their products are compatible with Windows in order to have access to the large market of Windows users. Thus, Windows is popular because it is well supported, but is well supported because it is popular.
However, network effects need not lead to market dominance by one firm, when there are standards which allow multiple firms to interoperate, thus allowing the network externalities to benefit the entire market. This is true for the case of x86-based personal computer hardware, in which there are extremely strong market pressures to interoperate with pre-existing standards, but in which no one firm dominates in the market. Also, it is true for the development of enterprise software applications where the Web (HTTP), databases (SQL), and to a moderate degree, service-oriented message buses (SOA) have become common interfaces. Further up the development chain there are network effects as well in language back-end base platforms (JVM, CLR, LLVM), programming models (FP, OOP) and languages themselves.
In 2007 Apple released the iPhone followed by the app store. Most iPhone apps rely heavily on the existence of strong network effects. This enables the software to grow in popularity very quickly and spread to a large userbase with very limited marketing needed. The Free-mium business model has evolved to take advantage of these network effects by releasing a free version that will not limit the adoption or any users and then charge for "premium" features as the primary source of revenue.
Telecommunications.
The same holds true for the market for long-distance telephone service within the United States. In fact, the existence of these types of networks discourages dominance of the market by one company, as it creates pressures which work against one company attempting to establish a proprietary protocol or to even distinguish itself by means of product differentiation.
Web sites.
Many web sites also feature a network effect. One example is web marketplaces and exchanges, in that the value of the marketplace to a new user is proportional to the number of other users in the market. For example, eBay would not be a particularly useful site if auctions were not competitive. However, as the number of users grows on eBay, auctions grow more competitive, pushing up the prices of bids on items. This makes it more worthwhile to sell on eBay and brings more sellers onto eBay, which drives prices down again as this increases supply, while bringing more people onto eBay because there are more things being sold that people want. Essentially, as the number of users of eBay grows, prices fall and supply increases, and more and more people find the site to be useful.
Social networking websites are also good examples. The more people register onto a social networking website, the more useful the website is to its registrants.
By contrast, the value of a news site is primarily proportional to the quality of the articles, not to the number of other people using the site. Similarly, the first generation of search sites experienced little network effect, as the value of the site was based on the value of the search results. This allowed Google to win users away from Yahoo! without much trouble, once users believed that Google's search results were superior. Some commentators mistook the value of the Yahoo! brand (which does increase as more people know of it) for a network effect protecting its advertising business.
Alexa Internet uses a technology that tracks users' surfing patterns; thus Alexa's Related Sites results improve as more users use the technology. Alexa's network relies heavily on a small number of browser software relationships, which makes the network more vulnerable to competition.
Google has also attempted to create a network effect in its advertising business with its Google AdSense service. Google AdSense places ads on many small sites, such as blogs, using Google technology to determine which ads are relevant to which blogs. Thus, the service appears to aim to serve as an exchange (or ad network) for matching many advertisers with many small sites (such as blogs). In general, the more blogs Google AdSense can reach, the more advertisers it will attract, making it the most attractive option for more blogs, and so on, making the network more valuable for all participants.
Network effects were used as justification for some of the dot-com business models in the late 1990s. These firms operated under the belief that when a new market comes into being which contains strong network effects, firms should care more about growing their market share than about becoming profitable. This was believed because market share will determine which firm can set technical and marketing standards and thus determine the basis of future competition.
Rail gauge.
There are strong network effects in the initial choice of rail gauge, and in gauge conversion decisions.
Even when placing isolated rails not connected to any other lines, track layers usually choose a standard rail gauge so they can use off-the-shelf rolling stock.
Although a few manufacturers make rolling stock that can adjust to different rail gauges, most manufacturers make rolling stock that only works with one of the standard rail gauges.

</doc>
<doc id="22054" url="https://en.wikipedia.org/wiki?curid=22054" title="Nuclear fission">
Nuclear fission

In nuclear physics and nuclear chemistry, nuclear fission is either a nuclear reaction or a radioactive decay process in which the nucleus of an atom splits into smaller parts (lighter nuclei). The fission process often produces free neutrons and gamma photons, and releases a very large amount of energy even by the energetic standards of radioactive decay.
Nuclear fission of heavy elements was discovered on December 17, 1938 by German Otto Hahn and his assistant Fritz Strassmann, and explained theoretically in January 1939 by Lise Meitner and her nephew Otto Robert Frisch. Frisch named the process by analogy with biological fission of living cells. It is an exothermic reaction which can release large amounts of energy both as electromagnetic radiation and as kinetic energy of the fragments (heating the bulk material where fission takes place). In order for fission to produce energy, the total binding energy of the resulting elements must be less negative (higher energy) than that of the starting element.
Fission is a form of nuclear transmutation because the resulting fragments are not the same element as the original atom. The two nuclei produced are most often of comparable but slightly different sizes, typically with a mass ratio of products of about 3 to 2, for common fissile isotopes. Most fissions are binary fissions (producing two charged fragments), but occasionally (2 to 4 times per 1000 events), "three" positively charged fragments are produced, in a ternary fission. The smallest of these fragments in ternary processes ranges in size from a proton to an argon nucleus.
Apart from fission induced by a neutron, harnessed and exploited by humans, a natural form of spontaneous radioactive decay (not requiring a neutron) is also referred to as fission, and occurs especially in very high-mass-number isotopes. Spontaneous fission was discovered in 1940 by Flyorov, Petrzhak and Kurchatov in Moscow, when they decided to confirm that, without bombardment by neutrons, the fission rate of uranium was indeed negligible, as predicted by Niels Bohr; it wasn't.
The unpredictable composition of the products (which vary in a broad probabilistic and somewhat chaotic manner) distinguishes fission from purely quantum-tunnelling processes such as proton emission, alpha decay, and cluster decay, which give the same products each time. Nuclear fission produces energy for nuclear power and drives the explosion of nuclear weapons. Both uses are possible because certain substances called nuclear fuels undergo fission when struck by fission neutrons, and in turn emit neutrons when they break apart. This makes possible a self-sustaining nuclear chain reaction that releases energy at a controlled rate in a nuclear reactor or at a very rapid uncontrolled rate in a nuclear weapon.
The amount of free energy contained in nuclear fuel is millions of times the amount of free energy contained in a similar mass of chemical fuel such as gasoline, making nuclear fission a very dense source of energy. The products of nuclear fission, however, are on average far more radioactive than the heavy elements which are normally fissioned as fuel, and remain so for significant amounts of time, giving rise to a nuclear waste problem. Concerns over nuclear waste accumulation and over the destructive potential of nuclear weapons may counterbalance the desirable qualities of fission as an energy source, and give rise to ongoing political debate over nuclear power.
Physical overview.
Mechanism.
Nuclear fission can occur without neutron bombardment as a type of radioactive decay. This type of fission (called spontaneous fission) is rare except in a few heavy isotopes. In engineered nuclear devices, essentially all nuclear fission occurs as a "nuclear reaction" — a bombardment-driven process that results from the collision of two subatomic particles. In nuclear reactions, a subatomic particle collides with an atomic nucleus and causes changes to it. Nuclear reactions are thus driven by the mechanics of bombardment, not by the relatively constant exponential decay and half-life characteristic of spontaneous radioactive processes.
Many types of nuclear reactions are currently known. Nuclear fission differs importantly from other types of nuclear reactions, in that it can be amplified and sometimes controlled via a nuclear chain reaction (one type of general chain reaction). In such a reaction, free neutrons released by each fission event can trigger yet more events, which in turn release more neutrons and cause more fissions.
The chemical element isotopes that can sustain a fission chain reaction are called nuclear fuels, and are said to be "fissile". The most common nuclear fuels are 235U (the isotope of uranium with an atomic mass of 235 and of use in nuclear reactors) and 239Pu (the isotope of plutonium with an atomic mass of 239). These fuels break apart into a bimodal range of chemical elements with atomic masses centering near 95 and 135 u (fission products). Most nuclear fuels undergo spontaneous fission only very slowly, decaying instead mainly via an alpha-beta decay chain over periods of millennia to eons. In a nuclear reactor or nuclear weapon, the overwhelming majority of fission events are induced by bombardment with another particle, a neutron, which is itself produced by prior fission events.
Nuclear fissions in fissile fuels are the result of the nuclear excitation energy produced when a fissile nucleus captures a neutron. This energy, resulting from the neutron capture, is a result of the attractive nuclear force acting between the neutron and nucleus. It is enough to deform the nucleus into a double-lobed "drop," to the point that nuclear fragments exceed the distances at which the nuclear force can hold two groups of charged nucleons together and, when this happens, the two fragments complete their separation and then are driven further apart by their mutually repulsive charges, in a process which becomes irreversible with greater and greater distance. A similar process occurs in fissionable isotopes (such as uranium-238), but in order to fission, these isotopes require additional energy provided by fast neutrons (such as those produced by nuclear fusion in thermonuclear weapons).
The liquid drop model of the atomic nucleus predicts equal-sized fission products as an outcome of nuclear deformation. The more sophisticated nuclear shell model is needed to mechanistically explain the route to the more energetically favorable outcome, in which one fission product is slightly smaller than the other. A theory of the fission based on shell model has been formulated by Maria Goeppert Mayer.
The most common fission process is binary fission, and it produces the fission products noted above, at 95±15 and 135±15 u. However, the binary process happens merely because it is the most probable. In anywhere from 2 to 4 fissions per 1000 in a nuclear reactor, a process called ternary fission produces three positively charged fragments (plus neutrons) and the smallest of these may range from so small a charge and mass as a proton (Z=1), to as large a fragment as argon (Z=18). The most common small fragments, however, are composed of 90% helium-4 nuclei with more energy than alpha particles from alpha decay (so-called "long range alphas" at ~ 16 MeV), plus helium-6 nuclei, and tritons (the nuclei of tritium). The ternary process is less common, but still ends up producing significant helium-4 and tritium gas buildup in the fuel rods of modern nuclear reactors.
Energetics.
Input.
The fission of a heavy nucleus requires a total input energy of about 7 to 8 million electron volts (MeV) to initially overcome the nuclear force which holds the nucleus into a spherical or nearly spherical shape, and from there, deform it into a two-lobed ("peanut") shape in which the lobes are able to continue to separate from each other, pushed by their mutual positive charge, in the most common process of binary fission (two positively charged fission products + neutrons). Once the nuclear lobes have been pushed to a critical distance, beyond which the short range strong force can no longer hold them together, the process of their separation proceeds from the energy of the (longer range) electromagnetic repulsion between the fragments. The result is two fission fragments moving away from each other, at high energy.
About 6 MeV of the fission-input energy is supplied by the simple binding of an extra neutron to the heavy nucleus via the strong force; however, in many fissionable isotopes, this amount of energy is not enough for fission. Uranium-238, for example, has a near-zero fission cross section for neutrons of less than one MeV energy. If no additional energy is supplied by any other mechanism, the nucleus will not fission, but will merely absorb the neutron, as happens when U-238 absorbs slow and even some fraction of fast neutrons, to become U-239. The remaining energy to initiate fission can be supplied by two other mechanisms: one of these is more kinetic energy of the incoming neutron, which is increasingly able to fission a fissionable heavy nucleus as it exceeds a kinetic energy of one MeV or more (so-called fast neutrons). Such high energy neutrons are able to fission U-238 directly (see thermonuclear weapon for application, where the fast neutrons are supplied by nuclear fusion). However, this process cannot happen to a great extent in a nuclear reactor, as too small a fraction of the fission neutrons produced by any type of fission have enough energy to efficiently fission U-238 (fission neutrons have a mode energy of 2 MeV, but a median of only 0.75 MeV, meaning half of them have less than this insufficient energy).
Among the heavy actinide elements, however, those isotopes that have an odd number of neutrons (such as U-235 with 143 neutrons) bind an extra neutron with an additional 1 to 2 MeV of energy over an isotope of the same element with an even number of neutrons (such as U-238 with 146 neutrons). This extra binding energy is made available as a result of the mechanism of neutron pairing effects. This extra energy results from the Pauli exclusion principle allowing an extra neutron to occupy the same nuclear orbital as the last neutron in the nucleus, so that the two form a pair. In such isotopes, therefore, no neutron kinetic energy is needed, for all the necessary energy is supplied by absorption of any neutron, either of the slow or fast variety (the former are used in moderated nuclear reactors, and the latter are used in fast neutron reactors, and in weapons). As noted above, the subgroup of fissionable elements that may be fissioned efficiently with their own fission neutrons (thus potentially causing a nuclear chain reaction in relatively small amounts of the pure material) are termed "fissile." Examples of fissile isotopes are U-235 and plutonium-239.
Output.
Typical fission events release about two hundred million eV (200 MeV) of energy for each fission event. The exact isotope which is fissioned, and whether or not it is fissionable or fissile, has only a small impact on the amount of energy released. This can be easily seen by examining the curve of binding energy (image below), and noting that the average binding energy of the actinide nuclides beginning with uranium is around 7.6 MeV per nucleon. Looking further left on the curve of binding energy, where the fission products cluster, it is easily observed that the binding energy of the fission products tends to center around 8.5 MeV per nucleon. Thus, in any fission event of an isotope in the actinide's range of mass, roughly 0.9 MeV is released per nucleon of the starting element. The fission of U235 by a slow neutron yields nearly identical energy to the fission of U238 by a fast neutron. This energy release profile holds true for thorium and the various minor actinides as well.
By contrast, most chemical oxidation reactions (such as burning coal or TNT) release at most a few eV per event. So, nuclear fuel contains at least ten million times more usable energy per unit mass than does chemical fuel. The energy of nuclear fission is released as kinetic energy of the fission products and fragments, and as electromagnetic radiation in the form of gamma rays; in a nuclear reactor, the energy is converted to heat as the particles and gamma rays collide with the atoms that make up the reactor and its working fluid, usually water or occasionally heavy water or molten salts.
When a uranium nucleus fissions into two daughter nuclei fragments, about 0.1 percent of the mass of the uranium nucleus appears as the fission energy of ~200 MeV. For uranium-235 (total mean fission energy 202.5 MeV), typically ~169 MeV appears as the kinetic energy of the daughter nuclei, which fly apart at about 3% of the speed of light, due to Coulomb repulsion. Also, an average of 2.5 neutrons are emitted, with a mean kinetic energy per neutron of ~2 MeV (total of 4.8 MeV). The fission reaction also releases ~7 MeV in prompt gamma ray photons. The latter figure means that a nuclear fission explosion or criticality accident emits about 3.5% of its energy as gamma rays, less than 2.5% of its energy as fast neutrons (total of both types of radiation ~ 6%), and the rest as kinetic energy of fission fragments (this appears almost immediately when the fragments impact surrounding matter, as simple heat). In an atomic bomb, this heat may serve to raise the temperature of the bomb core to 100 million kelvin and cause secondary emission of soft X-rays, which convert some of this energy to ionizing radiation. However, in nuclear reactors, the fission fragment kinetic energy remains as low-temperature heat, which itself causes little or no ionization.
So-called neutron bombs (enhanced radiation weapons) have been constructed which release a larger fraction of their energy as ionizing radiation (specifically, neutrons), but these are all thermonuclear devices which rely on the nuclear fusion stage to produce the extra radiation. The energy dynamics of pure fission bombs always remain at about 6% yield of the total in radiation, as a prompt result of fission.
The total "prompt fission" energy amounts to about 181 MeV, or ~ 89% of the total energy which is eventually released by fission over time. The remaining ~ 11% is released in beta decays which have various half-lives, but begin as a process in the fission products immediately; and in delayed gamma emissions associated with these beta decays. For example, in uranium-235 this delayed energy is divided into about 6.5 MeV in betas, 8.8 MeV in antineutrinos (released at the same time as the betas), and finally, an additional 6.3 MeV in delayed gamma emission from the excited beta-decay products (for a mean total of ~10 gamma ray emissions per fission, in all). Thus, about 6.5% of the total energy of fission is released some time after the event, as non-prompt or delayed ionizing radiation, and the delayed ionizing energy is about evenly divided between gamma and beta ray energy.
In a reactor that has been operating for some time, the radioactive fission products will have built up to steady state concentrations such that their rate of decay is equal to their rate of formation, so that their fractional total contribution to reactor heat (via beta decay) is the same as these radioisotopic fractional contributions to the energy of fission. Under these conditions, the 6.5% of fission which appears as delayed ionizing radiation (delayed gammas and betas from radioactive fission products) contributes to the steady-state reactor heat production under power. It is this output fraction which remains when the reactor is suddenly shut down (undergoes scram). For this reason, the reactor decay heat output begins at 6.5% of the full reactor steady state fission power, once the reactor is shut down. However, within hours, due to decay of these isotopes, the decay power output is far less. See decay heat for detail.
The remainder of the delayed energy (8.8 MeV/202.5 MeV = 4.3% of total fission energy) is emitted as antineutrinos, which as a practical matter, are not considered "ionizing radiation." The reason is that energy released as antineutrinos is not captured by the reactor material as heat, and escapes directly through all materials (including the Earth) at nearly the speed of light, and into interplanetary space (the amount absorbed is minuscule). Neutrino radiation is ordinarily not classed as ionizing radiation, because it is almost entirely not absorbed and therefore does not produce effects (although the very rare neutrino event is ionizing). Almost all of the rest of the radiation (6.5% delayed beta and gamma radiation) is eventually converted to heat in a reactor core or its shielding.
Some processes involving neutrons are notable for absorbing or finally yielding energy — for example neutron kinetic energy does not yield heat immediately if the neutron is captured by a uranium-238 atom to breed plutonium-239, but this energy is emitted if the plutonium-239 is later fissioned. On the other hand, so-called delayed neutrons emitted as radioactive decay products with half-lives up to several minutes, from fission-daughters, are very important to reactor control, because they give a characteristic "reaction" time for the total nuclear reaction to double in size, if the reaction is run in a "delayed-critical" zone which deliberately relies on these neutrons for a supercritical chain-reaction (one in which each fission cycle yields more neutrons than it absorbs). Without their existence, the nuclear chain-reaction would be prompt critical and increase in size faster than it could be controlled by human intervention. In this case, the first experimental atomic reactors would have run away to a dangerous and messy "prompt critical reaction" before their operators could have manually shut them down (for this reason, designer Enrico Fermi included radiation-counter-triggered control rods, suspended by electromagnets, which could automatically drop into the center of Chicago Pile-1). If these delayed neutrons are captured without producing fissions, they produce heat as well.
Product nuclei and binding energy.
In fission there is a preference to yield fragments with even proton numbers, which is called the odd-even effect on the fragments charge distribution. However, no odd-even effect is observed on fragment mass number distribution. This result is attributed to nucleon pair breaking.
In nuclear fission events the nuclei may break into any combination of lighter nuclei, but the most common event is not fission to equal mass nuclei of about mass 120; the most common event (depending on isotope and process) is a slightly unequal fission in which one daughter nucleus has a mass of about 90 to 100 u and the other the remaining 130 to 140 u. Unequal fissions are energetically more favorable because this allows one product to be closer to the energetic minimum near mass 60 u (only a quarter of the average fissionable mass), while the other nucleus with mass 135 u is still not far out of the range of the most tightly bound nuclei (another statement of this, is that the atomic binding energy curve is slightly steeper to the left of mass 120 u than to the right of it).
Origin of the active energy and the curve of binding energy.
Nuclear fission of heavy elements produces energy because the specific binding energy (binding energy per mass) of intermediate-mass nuclei with atomic numbers and atomic masses close to 62Ni and 56Fe is greater than the nucleon-specific binding energy of very heavy nuclei, so that energy is released when heavy nuclei are broken apart. The total rest masses of the fission products (Mp) from a single reaction is less than the mass of the original fuel nucleus (M). The excess mass Δm = M – Mp is the invariant mass of the energy that is released as photons (gamma rays) and kinetic energy of the fission fragments, according to the mass-energy equivalence formula "E" = "mc"2.
The variation in specific binding energy with atomic number is due to the interplay of the two fundamental forces acting on the component nucleons (protons and neutrons) that make up the nucleus. Nuclei are bound by an attractive nuclear force between nucleons, which overcomes the electrostatic repulsion between protons. However, the nuclear force acts only over relatively short ranges (a few nucleon diameters), since it follows an exponentially decaying Yukawa potential which makes it insignificant at longer distances. The electrostatic repulsion is of longer range, since it decays by an inverse-square rule, so that nuclei larger than about 12 nucleons in diameter reach a point that the total electrostatic repulsion overcomes the nuclear force and causes them to be spontaneously unstable. For the same reason, larger nuclei (more than about eight nucleons in diameter) are less tightly bound per unit mass than are smaller nuclei; breaking a large nucleus into two or more intermediate-sized nuclei releases energy. The origin of this energy is the nuclear force, which intermediate-sized nuclei allows to act more efficiently, because each nucleon has more neighbors which are within the short range attraction of this force. Thus less energy is needed in the smaller nuclei and the difference to the state before is set free.
Also because of the short range of the strong binding force, large stable nuclei must contain proportionally more neutrons than do the lightest elements, which are most stable with a 1 to 1 ratio of protons and neutrons. Nuclei which have more than 20 protons cannot be stable unless they have more than an equal number of neutrons. Extra neutrons stabilize heavy elements because they add to strong-force binding (which acts between all nucleons) without adding to proton–proton repulsion. Fission products have, on average, about the same ratio of neutrons and protons as their parent nucleus, and are therefore usually unstable to beta decay (which changes neutrons to protons) because they have proportionally too many neutrons compared to stable isotopes of similar mass.
This tendency for fission product nuclei to beta-decay is the fundamental cause of the problem of radioactive high level waste from nuclear reactors. Fission products tend to be beta emitters, emitting fast-moving electrons to conserve electric charge, as excess neutrons convert to protons in the fission-product atoms. See Fission products (by element) for a description of fission products sorted by element.
Chain reactions.
Several heavy elements, such as uranium, thorium, and plutonium, undergo both spontaneous fission, a form of radioactive decay and "induced fission", a form of nuclear reaction. Elemental isotopes that undergo induced fission when struck by a free neutron are called fissionable; isotopes that undergo fission when struck by a slow-moving thermal neutron are also called fissile. A few particularly fissile and readily obtainable isotopes (notably 233U, 235U and 239Pu) are called nuclear fuels because they can sustain a chain reaction and can be obtained in large enough quantities to be useful.
All fissionable and fissile isotopes undergo a small amount of spontaneous fission which releases a few free neutrons into any sample of nuclear fuel. Such neutrons would escape rapidly from the fuel and become a free neutron, with a mean lifetime of about 15 minutes before decaying to protons and beta particles. However, neutrons almost invariably impact and are absorbed by other nuclei in the vicinity long before this happens (newly created fission neutrons move at about 7% of the speed of light, and even moderated neutrons move at about 8 times the speed of sound). Some neutrons will impact fuel nuclei and induce further fissions, releasing yet more neutrons. If enough nuclear fuel is assembled in one place, or if the escaping neutrons are sufficiently contained, then these freshly emitted neutrons outnumber the neutrons that escape from the assembly, and a "sustained nuclear chain reaction" will take place.
An assembly that supports a sustained nuclear chain reaction is called a critical assembly or, if the assembly is almost entirely made of a nuclear fuel, a critical mass. The word "critical" refers to a cusp in the behavior of the differential equation that governs the number of free neutrons present in the fuel: if less than a critical mass is present, then the amount of neutrons is determined by radioactive decay, but if a critical mass or more is present, then the amount of neutrons is controlled instead by the physics of the chain reaction. The actual mass of a "critical mass" of nuclear fuel depends strongly on the geometry and surrounding materials.
Not all fissionable isotopes can sustain a chain reaction. For example, 238U, the most abundant form of uranium, is fissionable but not fissile: it undergoes induced fission when impacted by an energetic neutron with over 1 MeV of kinetic energy. However, too few of the neutrons produced by 238U fission are energetic enough to induce further fissions in 238U, so no chain reaction is possible with this isotope. Instead, bombarding 238U with slow neutrons causes it to absorb them (becoming 239U) and decay by beta emission to 239Np which then decays again by the same process to 239Pu; that process is used to manufacture 239Pu in breeder reactors. In-situ plutonium production also contributes to the neutron chain reaction in other types of reactors after sufficient plutonium-239 has been produced, since plutonium-239 is also a fissile element which serves as fuel. It is estimated that up to half of the power produced by a standard "non-breeder" reactor is produced by the fission of plutonium-239 produced in place, over the total life-cycle of a fuel load.
Fissionable, non-fissile isotopes can be used as fission energy source even without a chain reaction. Bombarding 238U with fast neutrons induces fissions, releasing energy as long as the external neutron source is present. This is an important effect in all reactors where fast neutrons from the fissile isotope can cause the fission of nearby 238U nuclei, which means that some small part of the 238U is "burned-up" in all nuclear fuels, especially in fast breeder reactors that operate with higher-energy neutrons. That same fast-fission effect is used to augment the energy released by modern thermonuclear weapons, by jacketing the weapon with 238U to react with neutrons released by nuclear fusion at the center of the device. But the explosive effects of nuclear fission chain reactions can be reduced by using substances like moderators which slow down the speed of secondary neutrons.
Fission reactors.
Critical fission reactors are the most common type of nuclear reactor. In a critical fission reactor, neutrons produced by fission of fuel atoms are used to induce yet more fissions, to sustain a controllable amount of energy release. Devices that produce engineered but non-self-sustaining fission reactions are subcritical fission reactors. Such devices use radioactive decay or particle accelerators to trigger fissions.
Critical fission reactors are built for three primary purposes, which typically involve different engineering trade-offs to take advantage of either the heat or the neutrons produced by the fission chain reaction:
While, in principle, all fission reactors can act in all three capacities, in practice the tasks lead to conflicting engineering goals and most reactors have been built with only one of the above tasks in mind. (There are several early counter-examples, such as the Hanford N reactor, now decommissioned). Power reactors generally convert the kinetic energy of fission products into heat, which is used to heat a working fluid and drive a heat engine that generates mechanical or electrical power. The working fluid is usually water with a steam turbine, but some designs use other materials such as gaseous helium. Research reactors produce neutrons that are used in various ways, with the heat of fission being treated as an unavoidable waste product. Breeder reactors are a specialized form of research reactor, with the caveat that the sample being irradiated is usually the fuel itself, a mixture of 238U and 235U.
For a more detailed description of the physics and operating principles of critical fission reactors, see nuclear reactor physics. For a description of their social, political, and environmental aspects, see nuclear power.
Fission bombs.
One class of nuclear weapon, a "fission bomb" (not to be confused with the "fusion bomb"), otherwise known as an "atomic bomb" or "atom bomb", is a fission reactor designed to liberate as much energy as possible as rapidly as possible, before the released energy causes the reactor to explode (and the chain reaction to stop). Development of nuclear weapons was the motivation behind early research into nuclear fission: the Manhattan Project of the U.S. military during World War II carried out most of the early scientific work on fission chain reactions, culminating in the Trinity test bomb and the Little Boy and Fat Man bombs that were exploded over the cities Hiroshima and Nagasaki, Japan in August 1945.
Even the first fission bombs were thousands of times more explosive than a comparable mass of chemical explosive. For example, Little Boy weighed a total of about four tons (of which 60 kg was nuclear fuel) and was long; it also yielded an explosion equivalent to about 15 kilotons of TNT, destroying a large part of the city of Hiroshima. Modern nuclear weapons (which include a thermonuclear "fusion" as well as one or more fission stages) are hundreds of times more energetic for their weight than the first pure fission atomic bombs (see nuclear weapon yield), so that a modern single missile warhead bomb weighing less than 1/8 as much as Little Boy (see for example W88) has a yield of 475,000 tons of TNT, and could bring destruction to about 10 times the city area.
While the fundamental physics of the fission chain reaction in a nuclear weapon is similar to the physics of a controlled nuclear reactor, the two types of device must be engineered quite differently (see nuclear reactor physics). A nuclear bomb is designed to release all its energy at once, while a reactor is designed to generate a steady supply of useful power. While overheating of a reactor can lead to, and has led to, meltdown and steam explosions, the much lower uranium enrichment makes it impossible for a nuclear reactor to explode with the same destructive power as a nuclear weapon. It is also difficult to extract useful power from a nuclear bomb, although at least one rocket propulsion system, Project Orion, was intended to work by exploding fission bombs behind a massively padded and shielded spacecraft.
The strategic importance of nuclear weapons is a major reason why the technology of nuclear fission is politically sensitive. Viable fission bomb designs are, arguably, within the capabilities of many, being relatively simple from an engineering viewpoint. However, the difficulty of obtaining fissile nuclear material to realize the designs is the key to the relative unavailability of nuclear weapons to all but modern industrialized governments with special programs to produce fissile materials (see uranium enrichment and nuclear fuel cycle).
History.
Discovery of nuclear fission.
The discovery of nuclear fission occurred in 1938 in the buildings of Kaiser Wilhelm Society for Chemistry, today part of the Free University of Berlin, following nearly five decades of work on the science of radioactivity and the elaboration of new nuclear physics that described the components of atoms. In 1911, Ernest Rutherford proposed a model of the atom in which a very small, dense and positively charged nucleus of protons (the neutron had not yet been discovered) was surrounded by orbiting, negatively charged electrons (the Rutherford model). Niels Bohr improved upon this in 1913 by reconciling the quantum behavior of electrons (the Bohr model). Work by Henri Becquerel, Marie Curie, Pierre Curie, and Rutherford further elaborated that the nucleus, though tightly bound, could undergo different forms of radioactive decay, and thereby transmute into other elements. (For example, by alpha decay: the emission of an alpha particle—two protons and two neutrons bound together into a particle identical to a helium nucleus.)
Some work in nuclear transmutation had been done. In 1917, Rutherford was able to accomplish transmutation of nitrogen into oxygen, using alpha particles directed at nitrogen 14N + α → 17O + p.  This was the first observation of a nuclear reaction, that is, a reaction in which particles from one decay are used to transform another atomic nucleus. Eventually, in 1932, a fully artificial nuclear reaction and nuclear transmutation was achieved by Rutherford's colleagues Ernest Walton and John Cockcroft, who used artificially accelerated protons against lithium-7, to split this nucleus into two alpha particles. The feat was popularly known as "splitting the atom", although it was not the modern nuclear fission reaction later discovered in heavy elements, which is discussed below. Meanwhile, the possibility of "combining" nuclei—nuclear fusion—had been studied in connection with understanding the processes which power stars. The first artificial fusion reaction had been achieved by Mark Oliphant in 1932, using two accelerated deuterium nuclei (each consisting of a single proton bound to a single neutron) to create a helium nucleus.
After English physicist James Chadwick discovered the neutron in 1932, Enrico Fermi and his colleagues in Rome studied the results of bombarding uranium with neutrons in 1934. Fermi concluded that his experiments had created new elements with 93 and 94 protons, which the group dubbed ausonium and hesperium. However, not all were convinced by Fermi's analysis of his results. The German chemist Ida Noddack notably suggested in print in 1934 that instead of creating a new, heavier element 93, that "it is conceivable that the nucleus breaks up into several large fragments." However, Noddack's conclusion was not pursued at the time.
After the Fermi publication, Otto Hahn, Lise Meitner, and Fritz Strassmann began performing similar experiments in Berlin. Meitner, an Austrian Jew, lost her citizenship with the "Anschluss", the occupation and annexation of Austria into Nazi Germany in March 1938, but she fled in July 1938 to Sweden and started a correspondence by mail with Hahn in Berlin. By coincidence, her nephew Otto Robert Frisch, also a refugee, was also in Sweden when Meitner received a letter from Hahn dated 19 December describing his chemical proof that some of the product of the bombardment of uranium with neutrons was barium. Hahn suggested a "bursting" of the nucleus, but he was unsure of what the physical basis for the results were. Barium had an atomic mass 40% less than uranium, and no previously known methods of radioactive decay could account for such a large difference in the mass of the nucleus. Frisch was skeptical, but Meitner trusted Hahn's ability as a chemist. Marie Curie had been separating barium from radium for many years, and the techniques were well-known. According to Frisch:
Was it a mistake? No, said Lise Meitner; Hahn was too good a chemist for that. But how could barium be formed from uranium? No larger fragments than protons or helium nuclei (alpha particles) had ever been chipped away from nuclei, and to chip off a large number not nearly enough energy was available. Nor was it possible that the uranium nucleus could have been cleaved right across. A nucleus was not like a brittle solid that can be cleaved or broken; George Gamow had suggested early on, and Bohr had given good arguments that a nucleus was much more like a liquid drop. Perhaps a drop could divide itself into two smaller drops in a more gradual manner, by first becoming elongated, then constricted, and finally being torn rather than broken in two? We knew that there were strong forces that would resist such a process, just as the surface tension of an ordinary liquid drop tends to resist its division into two smaller ones. But nuclei differed from ordinary drops in one important way: they were electrically charged, and that was known to counteract the surface tension.
The charge of a uranium nucleus, we found, was indeed large enough to overcome the effect of the surface tension almost completely; so the uranium nucleus might indeed resemble a very wobbly unstable drop, ready to divide itself at the slightest provocation, such as the impact of a single neutron. But there was another problem. After separation, the two drops would be driven apart by their mutual electric repulsion and would acquire high speed and hence a very large energy, about 200 MeV in all; where could that energy come from? ...Lise Meitner... worked out that the two nuclei formed by the division of a uranium nucleus together would be lighter than the original uranium nucleus by about one-fifth the mass of a proton. Now whenever mass disappears energy is created, according to Einstein's formula "E"= "mc"2, and one-fifth of a proton mass was just equivalent to 200 MeV. So here was the source for that energy; it all fitted!
In short, Meitner and Frisch had correctly interpreted Hahn's results to mean that the nucleus of uranium had split roughly in half. Frisch suggested the process be named "nuclear fission," by analogy to the process of living cell division into two cells, which was then called binary fission. Just as the term nuclear "chain reaction" would later be borrowed from chemistry, so the term "fission" was borrowed from biology.
On 22 December 1938, Hahn and Strassmann sent a manuscript to "Naturwissenschaften" reporting that they had discovered the element barium after bombarding uranium with neutrons. Simultaneously, they communicated these results to Meitner in Sweden. She and Frisch correctly interpreted the results as evidence of nuclear fission. Frisch confirmed this experimentally on 13 January 1939. For proving that the barium resulting from his bombardment of uranium with neutrons was the product of nuclear fission, Hahn was awarded the Nobel Prize for Chemistry in 1944 (the sole recipient) "for his discovery of the fission of heavy nuclei". (The award was actually given to Hahn in 1945, as "the Nobel Committee for Chemistry decided that none of the year's nominations met the criteria as outlined in the will of Alfred Nobel." In such cases, the Nobel Foundation's statutes permit that year's prize be reserved until the following year.)
News spread quickly of the new discovery, which was correctly seen as an entirely novel physical effect with great scientific—and potentially practical—possibilities. Meitner's and Frisch's interpretation of the discovery of Hahn and Strassmann crossed the Atlantic Ocean with Niels Bohr, who was to lecture at Princeton University. I.I. Rabi and Willis Lamb, two Columbia University physicists working at Princeton, heard the news and carried it back to Columbia. Rabi said he told Enrico Fermi; Fermi gave credit to Lamb. Bohr soon thereafter went from Princeton to Columbia to see Fermi. Not finding Fermi in his office, Bohr went down to the cyclotron area and found Herbert L. Anderson. Bohr grabbed him by the shoulder and said: “Young man, let me explain to you about something new and exciting in physics.” It was clear to a number of scientists at Columbia that they should try to detect the energy released in the nuclear fission of uranium from neutron bombardment. On 25 January 1939, a Columbia University team conducted the first nuclear fission experiment in the United States, which was done in the basement of Pupin Hall; the members of the team were Herbert L. Anderson, Eugene T. Booth, John R. Dunning, Enrico Fermi, G. Norris Glasoe, and Francis G. Slack. The experiment involved placing uranium oxide inside of an ionization chamber and irradiating it with neutrons, and measuring the energy thus released. The results confirmed that fission was occurring and hinted strongly that it was the isotope uranium 235 in particular that was fissioning. The next day, the Fifth Washington Conference on Theoretical Physics began in Washington, D.C. under the joint auspices of the George Washington University and the Carnegie Institution of Washington. There, the news on nuclear fission was spread even further, which fostered many more experimental demonstrations.
During this period the Hungarian physicist Leó Szilárd, who was residing in the United States at the time, realized that the neutron-driven fission of heavy atoms could be used to create a nuclear chain reaction. Such a reaction using neutrons was an idea he had first formulated in 1933, upon reading Rutherford's disparaging remarks about generating power from his team's 1932 experiment using protons to split lithium. However, Szilárd had not been able to achieve a neutron-driven chain reaction with neutron-rich light atoms. In theory, if in a neutron-driven chain reaction the number of secondary neutrons produced was greater than one, then each such reaction could trigger multiple additional reactions, producing an exponentially increasing number of reactions. It was thus a possibility that the fission of uranium could yield vast amounts of energy for civilian or military purposes (i.e., electric power generation or atomic bombs).
Szilard now urged Fermi (in New York) and Frédéric Joliot-Curie (in Paris) to refrain from publishing on the possibility of a chain reaction, lest the Nazi government become aware of the possibilities on the eve of what would later be known as World War II. With some hesitation Fermi agreed to self-censor. But Joliot-Curie did not, and in April 1939 his team in Paris, including Hans von Halban and Lew Kowarski, reported in the journal "Nature" that the number of neutrons emitted with nuclear fission of 235U was then reported at 3.5 per fission. (They later corrected this to 2.6 per fission.) Simultaneous work by Szilard and Walter Zinn confirmed these results. The results suggested the possibility of building nuclear reactors (first called "neutronic reactors" by Szilard and Fermi) and even nuclear bombs. However, much was still unknown about fission and chain reaction systems.
Fission chain reaction realized.
"Chain reactions" at that time were a known phenomenon in "chemistry", but the analogous process in nuclear physics, using neutrons, had been foreseen as early as 1933 by Szilárd, although Szilárd at that time had no idea with what materials the process might be initiated. Szilárd considered that neutrons would be ideal for such a situation, since they lacked an electrostatic charge.
With the news of fission neutrons from uranium fission, Szilárd immediately understood the possibility of a nuclear chain reaction using uranium. In the summer, Fermi and Szilard proposed the idea of a nuclear reactor (pile) to mediate this process. The pile would use natural uranium as fuel. Fermi had shown much earlier that neutrons were far more effectively captured by atoms if they were of low energy (so-called "slow" or "thermal" neutrons), because for quantum reasons it made the atoms look like much larger targets to the neutrons. Thus to slow down the secondary neutrons released by the fissioning uranium nuclei, Fermi and Szilard proposed a graphite "moderator," against which the fast, high-energy secondary neutrons would collide, effectively slowing them down. With enough uranium, and with pure-enough graphite, their "pile" could theoretically sustain a slow-neutron chain reaction. This would result in the production of heat, as well as the creation of radioactive fission products.
In August 1939, Szilard and fellow Hungarian refugees physicists Teller and Wigner thought that the Germans might make use of the fission chain reaction and were spurred to attempt to attract the attention of the United States government to the issue. Towards this, they persuaded German-Jewish refugee Albert Einstein to lend his name to a letter directed to President Franklin Roosevelt. The Einstein–Szilárd letter suggested the possibility of a uranium bomb deliverable by ship, which would destroy "an entire harbor and much of the surrounding countryside." The President received the letter on 11 October 1939 — shortly after World War II began in Europe, but two years before U.S. entry into it. Roosevelt ordered that a scientific committee be authorized for overseeing uranium work and allocated a small sum of money for pile research.
In England, James Chadwick proposed an atomic bomb utilizing natural uranium, based on a paper by Rudolf Peierls with the mass needed for critical state being 30–40 tons. In America, J. Robert Oppenheimer thought that a cube of uranium deuteride 10 cm on a side (about 11 kg of uranium) might "blow itself to hell." In this design it was still thought that a moderator would need to be used for nuclear bomb fission (this turned out not to be the case if the fissile isotope was separated). In December, Werner Heisenberg delivered a report to the German Ministry of War on the possibility of a uranium bomb. Most of these models were still under the assumption that the bombs would be powered by slow neutron reactions—and thus be similar to a reactor undergoing a meltdown.
In Birmingham, England, Frisch teamed up with Peierls, a fellow German-Jewish refugee. They had the idea of using a purified mass of the uranium isotope 235U, which had a cross section just determined, and which was much larger than that of 238U or natural uranium (which is 99.3% the latter isotope). Assuming that the cross section for fast-neutron fission of 235U was the same as for slow neutron fission, they determined that a pure 235U bomb could have a critical mass of only 6 kg instead of tons, and that the resulting explosion would be tremendous. (The amount actually turned out to be 15 kg, although several times this amount was used in the actual uranium (Little Boy) bomb). In February 1940 they delivered the Frisch–Peierls memorandum. Ironically, they were still officially considered "enemy aliens" at the time. Glenn Seaborg, Joseph W. Kennedy, Arthur Wahl, and Italian-Jewish refugee Emilio Segrè shortly thereafter discovered 239Pu in the decay products of 239U produced by bombarding 238U with neutrons, and determined it to be a fissile material, like 235U.
The possibility of isolating uranium-235 was technically daunting, because uranium-235 and uranium-238 are chemically identical, and vary in their mass by only the weight of three neutrons. However, if a sufficient quantity of uranium-235 could be isolated, it would allow for a fast neutron fission chain reaction. This would be extremely explosive, a true "atomic bomb." The discovery that plutonium-239 could be produced in a nuclear reactor pointed towards another approach to a fast neutron fission bomb. Both approaches were extremely novel and not yet well understood, and there was considerable scientific skepticism at the idea that they could be developed in a short amount of time.
On June 28, 1941, the Office of Scientific Research and Development was formed in the U.S. to mobilize scientific resources and apply the results of research to national defense. In September, Fermi assembled his first nuclear "pile" or reactor, in an attempt to create a slow neutron-induced chain reaction in uranium, but the experiment failed to achieve criticality, due to lack of proper materials, or not enough of the proper materials which were available.
Producing a fission chain reaction in natural uranium fuel was found to be far from trivial. Early nuclear reactors did not use isotopically enriched uranium, and in consequence they were required to use large quantities of highly purified graphite as neutron moderation materials. Use of ordinary water (as opposed to heavy water) in nuclear reactors requires enriched fuel — the partial separation and relative enrichment of the rare 235U isotope from the far more common 238U isotope. Typically, reactors also require inclusion of extremely chemically pure neutron moderator materials such as deuterium (in heavy water), helium, beryllium, or carbon, the latter usually as graphite. (The high purity for carbon is required because many chemical impurities such as the boron-10 component of natural boron, are very strong neutron absorbers and thus poison the chain reaction and end it prematurely.)
Production of such materials at industrial scale had to be solved for nuclear power generation and weapons production to be accomplished. Up to 1940, the total amount of uranium metal produced in the USA was not more than a few grams, and even this was of doubtful purity; of metallic beryllium not more than a few kilograms; and concentrated deuterium oxide (heavy water) not more than a few kilograms. Finally, carbon had never been produced in quantity with anything like the purity required of a moderator.
The problem of producing large amounts of high purity uranium was solved by Frank Spedding using the thermite or "Ames" process. Ames Laboratory was established in 1942 to produce the large amounts of natural (unenriched) uranium metal that would be necessary for the research to come. The critical nuclear chain-reaction success of the Chicago Pile-1 (December 2, 1942) which used unenriched (natural) uranium, like all of the atomic "piles" which produced the plutonium for the atomic bomb, was also due specifically to Szilard's realization that very pure graphite could be used for the moderator of even natural uranium "piles". In wartime Germany, failure to appreciate the qualities of very pure graphite led to reactor designs dependent on heavy water, which in turn was denied the Germans by Allied attacks in Norway, where heavy water was produced. These difficulties—among many others— prevented the Nazis from building a nuclear reactor capable of criticality during the war, although they never put as much effort as the United States into nuclear research, focusing on other technologies (see German nuclear energy project for more details).
Manhattan Project and beyond.
In the United States, an all-out effort for making atomic weapons was begun in late 1942. This work was taken over by the U.S. Army Corps of Engineers in 1943, and known as the Manhattan Engineer District. The top-secret Manhattan Project, as it was colloquially known, was led by General Leslie R. Groves. Among the project's dozens of sites were: Hanford Site in Washington state, which had the first industrial-scale nuclear reactors; Oak Ridge, Tennessee, which was primarily concerned with uranium enrichment; and Los Alamos, in New Mexico, which was the scientific hub for research on bomb development and design. Other sites, notably the Berkeley Radiation Laboratory and the Metallurgical Laboratory at the University of Chicago, played important contributing roles. Overall scientific direction of the project was managed by the physicist J. Robert Oppenheimer.
In July 1945, the first atomic explosive device, dubbed "Trinity", was detonated in the New Mexico desert. It was fueled by plutonium created at Hanford. In August 1945, two more atomic devices – "Little Boy", a uranium-235 bomb, and "Fat Man", a plutonium bomb – were used against the Japanese cities of Hiroshima and Nagasaki.
In the years after World War II, many countries were involved in the further development of nuclear fission for the purposes of nuclear reactors and nuclear weapons. The UK opened the first commercial nuclear power plant in 1956. In 2013, there are 437 reactors in 31 countries.
Natural fission chain-reactors on Earth.
Criticality in nature is uncommon. At three ore deposits at Oklo in Gabon, sixteen sites (the so-called Oklo Fossil Reactors) have been discovered at which self-sustaining nuclear fission took place approximately 2 billion years ago. Unknown until 1972 (but postulated by Paul Kuroda in 1956), when French physicist Francis Perrin discovered the Oklo Fossil Reactors, it was realized that nature had beaten humans to the punch. Large-scale natural uranium fission chain reactions, moderated by normal water, had occurred far in the past and would not be possible now. This ancient process was able to use normal water as a moderator only because 2 billion years before the present, natural uranium was richer in the shorter-lived fissile isotope 235U (about 3%), than natural uranium available today (which is only 0.7%, and must be enriched to 3% to be usable in light-water reactors).

</doc>
<doc id="22055" url="https://en.wikipedia.org/wiki?curid=22055" title="Neil Gaiman">
Neil Gaiman

Neil Richard MacKinnon Gaiman (; born Neil Richard Gaiman; 10 November 1960) is an English author of short fiction, novels, comic books, graphic novels, audio theatre and films. His notable works include the comic book series "The Sandman" and novels "Stardust", "American Gods", "Coraline", and "The Graveyard Book". He has won numerous awards, including the Hugo, Nebula, and Bram Stoker awards, as well as the Newbery and Carnegie medals. He is the first author to win both the Newbery and the Carnegie medals for the same work, "The Graveyard Book" (2008). In 2013, "The Ocean at the End of the Lane" was voted Book of the Year in the British National Book Awards.
Early life.
Gaiman's family is of Polish-Jewish and other Eastern European-Jewish origins; his great-grandfather emigrated from Antwerp, Belgium to the UK before 1914 and his grandfather eventually settled in the south of England in the Hampshire city of Portsmouth and established a chain of grocery stores. His father, David Bernard Gaiman, worked in the same chain of stores; his mother, Sheila Gaiman ("née" Goldman), was a pharmacist. He has two younger sisters, Claire and Lizzy. After living for a period in the nearby town of Portchester, Hampshire, where Neil was born in 1960, the Gaimans moved in 1965 to the West Sussex town of East Grinstead where his parents studied Dianetics at the Scientology centre in the town; one of Gaiman's sisters works for the Church of Scientology in Los Angeles. His other sister, Lizzy Calcioli, has said, "Most of our social activities were involved with Scientology or our Jewish family. It would get very confusing when people would ask my religion as a kid. I’d say, 'I’m a Jewish Scientologist. Gaiman says that he is not a Scientologist, and that like Judaism, Scientology is his family's religion. About his personal views, Gaiman has stated, "I think we can say that God exists in the DC Universe. I would not stand up and beat the drum for the existence of God in this universe. I don't know, I think there's probably a 50/50 chance. It doesn't really matter to me."
Gaiman was able to read at the age of four. He said, "I was a reader. I loved reading. Reading things gave me pleasure. I was very good at most subjects in school, not because I had any particular aptitude in them, but because normally on the first day of school they'd hand out schoolbooks, and I'd read them—which would mean that I'd know what was coming up, because I'd read it." When he was about ten years old, he read his way through the works of Dennis Wheatley, where especially "The Ka of Gifford Hillary" and "The Haunting of Toby Jugg" made an impact on him. One work that made a particular impression on him was J. R. R. Tolkien's "The Lord of the Rings" from his school library, although it only had the first two volumes of the novel. He consistently took them out and read them. He would later win the school English prize and the school reading prize, enabling him finally to acquire the third volume.
For his seventh birthday, Gaiman received C. S. Lewis's "The Chronicles of Narnia" series. He later recalled that "I admired his use of parenthetical statements to the reader, where he would just talk to you ... I'd think, 'Oh, my gosh, that is so cool! I want to do that! When I become an author, I want to be able to do things in parentheses.' I liked the power of putting things in brackets." "Narnia" also introduced him to literary awards, specifically the 1956 Carnegie Medal won by the concluding volume. When Gaiman won the 2010 Medal himself, the press reported him recalling, "... it had to be the most important literary award there ever was" and observing, "if you can make yourself aged seven happy, you're really doing well – it's like writing a letter to yourself aged seven."
Lewis Carroll's "Alice's Adventures in Wonderland" was another childhood favourite, and "a favourite forever. Alice was default reading to the point where I knew it by heart." He also enjoyed Batman comics as a child.
Gaiman was educated at several Church of England schools, including Fonthill School in East Grinstead, Ardingly College (1970–74), and Whitgift School in Croydon (1974–77). His father's position as a public relations official of the Church of Scientology was the cause of the seven-year-old Gaiman being blocked from entering a boys' school, forcing him to remain at the school that he had previously been attending. He lived in East Grinstead for many years, from 1965 to 1980 and again from 1984 to 1987. He met his first wife, Mary McGrath, while she was studying Scientology and living in a house in East Grinstead that was owned by his father. The couple were married in 1985 after having their first child, Michael.
Career.
Journalism, early writings, and literary influences.
As a child and a teenager, Gaiman read the works of C. S. Lewis, J. R. R. Tolkien, Lewis Carroll, Mary Shelley, Rudyard Kipling, Edgar Allan Poe, Michael Moorcock, Alan Moore, Ursula K. Le Guin, Harlan Ellison, Lord Dunsany and G. K. Chesterton. When he was 19–20 years old, he contacted his favourite science fiction writer, R. A. Lafferty, whom he discovered when he was nine, and asked for advice on becoming an author along with a Lafferty pastiche he had written. The writer sent Gaiman an encouraging and informative letter back, along with literary advice.
In the early 1980s, Gaiman pursued journalism, conducting interviews and writing book reviews, as a means to learn about the world and to make connections that he hoped would later assist him in getting published. He wrote and reviewed extensively for the British Fantasy Society. His first professional short story publication was "Featherquest", a fantasy story, in "Imagine Magazine" in May 1984.
When waiting for a train at London's Victoria Station in 1984, Gaiman noticed a copy of "Swamp Thing" written by Alan Moore, and carefully read it. Moore's fresh and vigorous approach to comics had such an impact on Gaiman that he would later write "that was the final straw, what was left of my resistance crumbled. I proceeded to make regular and frequent visits to London's Forbidden Planet shop to buy comics".
In 1984, he wrote his first book, a biography of the band Duran Duran, as well as "Ghastly Beyond Belief", a book of quotations, with Kim Newman. Even though Gaiman thought he had done a terrible job, the book's first edition sold out very quickly. When he went to relinquish his rights to the book, he discovered the publisher had gone bankrupt. After this, he was offered a job by "Penthouse". He refused the offer.
He also wrote interviews and articles for many British magazines, including "Knave." During this he sometimes wrote under pseudonyms, including Gerry Musgrave, Richard Grey, and "a couple of house names". Gaiman has said he ended his journalism career in 1987 because British newspapers regularly publish untruths as fact.
In the late 1980s, he wrote "" in what he calls a "classic English humour" style. Following this he wrote the opening of what would become his collaboration with fellow English author Terry Pratchett on the comic novel "Good Omens", about the impending apocalypse.
Comics and graphic novels.
After forming a friendship with comic-book writer Alan Moore, Gaiman started writing comic-books, picking up "Marvelman" after Moore finished his run on the series. Gaiman and artist Mark Buckingham collaborated on several issues of the series before its publisher, Eclipse Comics, collapsed, leaving the series unfinished. His first published comic strips were four short "Future Shocks" for "2000 AD" in 1986–7. He wrote three graphic novels with his favourite collaborator and long-time friend Dave McKean: "Violent Cases", "Signal to Noise", and "The Tragical Comedy or Comical Tragedy of Mr. Punch". Impressed with his work, DC Comics hired him in February 1987, and he wrote the limited series "Black Orchid". Karen Berger, who later became head of DC Comics's Vertigo, read "Black Orchid" and offered Gaiman a job: to re-write an old character, The Sandman, but to put his own spin on him.
"The Sandman" tells the tale of the ageless, anthropomorphic personification of Dream that is known by many names, including Morpheus. The series began in January 1989 and concluded in March 1996. In the eighth issue of "The Sandman", Gaiman and artist Mike Dringenberg introduced Death, the older sister of Dream, who would become as popular as the series' title character. The ' limited series launched DC's Vertigo line in 1993. The 75 issues of the regular series, along with an illustrated prose text and a special containing seven short stories, have been collected into 12 volumes that remain in print, 14 of the "Death: The High Cost of Living" and ' spin-offs are included. Artists include Sam Kieth, Mike Dringenberg, Jill Thompson, Shawn McManus, Marc Hempel and Michael Zulli, lettering by Todd Klein, colours by Daniel Vozzo, and covers by Dave McKean. The series became one of DC's top selling titles, eclipsing even "Batman" and "Superman". Comics historian Les Daniels called Gaiman's work "astonishing" and noted that "The Sandman" was "a mixture of fantasy, horror, and ironic humor such as comic books had never seen before". DC Comics writer and executive Paul Levitz observed that ""The Sandman" became the first extraordinary success as a series of graphic novel collections, reaching out and converting new readers to the medium, particularly young women on college campuses, and making Gaiman himself into an iconic cultural figure."
Gaiman and Jamie Delano were to become co-writers of the "Swamp Thing" series following Rick Veitch. An editorial decision by DC to censor Veitch's final storyline caused both Gaiman and Delano to withdraw from the title.
Gaiman produced two stories for DC's "Secret Origins" series in 1989. A Poison Ivy tale drawn by Mark Buckingham and a Riddler story illustrated by Bernie Mireault and Matt Wagner.
In 1990, Gaiman wrote "The Books of Magic", a four-part mini-series that provided a tour of the mythological and magical parts of the DC Universe through a frame story about an English teenager who discovers that he is destined to be the world's greatest wizard. The miniseries was popular, and sired an ongoing series written by John Ney Rieber.
Gaiman's adaptation of "Sweeney Todd", illustrated by Michael Zulli for Stephen R. Bissette's publication "Taboo", was stopped when the anthology itself was discontinued.
In the mid-1990s, he also created a number of new characters and a setting that was to be featured in a title published by Tekno Comix. The concepts were then altered and split between three titles set in the same continuity: "Lady Justice", "Mr. Hero the Newmatic Man", and "Teknophage". They were later featured in "" and "Wheel of Worlds". Although Gaiman's name appeared prominently on all titles, he was not involved in writing any of the above-mentioned books.
Gaiman wrote a semi-autobiographical story about a boy's fascination with Michael Moorcock's anti-hero Elric of Melniboné for Ed Kramer's anthology "Tales of the White Wolf." In 1996, Gaiman and Ed Kramer co-edited "". Nominated for the British Fantasy Award, the original fiction anthology featured stories and contributions by Tori Amos, Clive Barker, Gene Wolfe, Tad Williams, and others.
Asked why he likes comics more than other forms of storytelling, Gaiman said: "One of the joys of comics has always been the knowledge that it was, in many ways, untouched ground. It was virgin territory. When I was working on "Sandman", I felt a lot of the time that I was actually picking up a machete and heading out into the jungle. I got to write in places and do things that nobody had ever done before. When I’m writing novels I’m painfully aware that I’m working in a medium that people have been writing absolutely jaw-droppingly brilliant things for, you know, three-four thousand years now. You know, you can go back. We have things like "The Golden Ass". And you go, well, I don’t know that I’m as good as that and that's two and a half thousand years old. But with comics I felt like – I can do stuff nobody has ever done. I can do stuff nobody has ever thought of. And I could and it was enormously fun."
Gaiman wrote two series for Marvel Comics. "Marvel 1602" was an eight-issue limited series published from November 2003 to June 2004 with art by Andy Kubert and Richard Isanove. "The Eternals" was a seven-issue limited series drawn by John Romita Jr. which was published from August 2006 to March 2007.
In 2009, Gaiman wrote a two-part Batman story for DC Comics to follow "Batman R.I.P." titled "" a play-off of the classic Superman story "" by Alan Moore. He contributed a twelve-part Metamorpho serial drawn by Mike Allred for "Wednesday Comics", a weekly newspaper-style series. Gaiman and Paul Cornell co-wrote "Action Comics" #894 (Dec. 2010) which featured an appearance by Death. In October 2013, DC Comics released"The Sandman: Overture" with art by J. H. Williams III. Gaiman's Angela character was introduced into the Marvel Universe in the last issue of the "Age of Ultron" miniseries in 2013.
Novels.
In a collaboration with author Terry Pratchett best known for his series of "Discworld" novels, Gaiman's first novel "Good Omens" was published in 1990. In recent years Pratchett has said that while the entire novel was a collaborative effort and most of the ideas could be credited to both of them, Pratchett did a larger portion of writing and editing if for no other reason than Gaiman's scheduled involvement with "Sandman".
The 1996 novelisation of Gaiman's teleplay for the BBC mini-series "Neverwhere" was his first solo novel. The novel was released in tandem with the television series though it presents some notable differences from the television series. Gaiman has since revised the novel twice, the first time for an American audience unfamiliar with the London Underground, the second time because he felt unsatisfied with the original.
In 1999 first printings of his fantasy novel "Stardust" were released. The novel has been released both as a standard novel and in an illustrated text edition.
"American Gods" became one of Gaiman's best-selling and multi-award winning novels upon its release in 2001. A special 10th Anniversary edition was released, with the "author's preferred text" 12,000 words longer than the original mass-market editions.
Gaiman has not written a direct sequel to "American Gods" but he has revisited the characters. A glimpse at Shadow's travels in Europe is found in a short story which finds him in Scotland, applying the same concepts developed in "American Gods" to the story of "Beowulf". The 2005 novel "Anansi Boys" deals with Anansi ('Mr. Nancy'), tracing the relationship of his two sons, one semi-divine and the other an unassuming Englishman, as they explore their common heritage. It debuted at number one on "The New York Times" Best Seller list.
In late 2008, Gaiman released a new children's book, "The Graveyard Book". It follows the adventures of a boy named Bod after his family is murdered and he is left to be brought up by a graveyard. It is heavily influenced by Rudyard Kipling's "The Jungle Book". , it had been on "The New York Times" Bestseller children's list for fifteen weeks.
In 2013, "The Ocean at the End of the Lane" was voted Book of the Year in the British National Book Awards. The novel follows an unnamed man who returns to his hometown for a funeral and remembers events that began forty years earlier. Themes include the search for self-identity and the "disconnect between childhood and adulthood".
Film and screenwriting.
Gaiman wrote the 1996 BBC dark fantasy television series "Neverwhere". He cowrote the screenplay for the movie "MirrorMask" with his old friend Dave McKean for McKean to direct. In addition, he wrote the localised English language script to the anime movie "Princess Mononoke", based on a translation of the Japanese script.
He cowrote the script for Robert Zemeckis's "Beowulf" with Roger Avary, a collaboration that has proved productive for both writers. Gaiman has expressed interest in collaborating on a film adaptation of the Epic of Gilgamesh.
He was the only person other than J. Michael Straczynski to write a "Babylon 5" script in the last three seasons, contributing the season five episode "Day of the Dead".
Gaiman has also written at least three drafts of a screenplay adaptation of Nicholson Baker's novel "The Fermata" for director Robert Zemeckis, although the project was stalled while Zemeckis made "The Polar Express" and the Gaiman-Roger Avary written "Beowulf" film.
Neil Gaiman was featured in the "History Channel" documentary "Comic Book Superheroes Unmasked".
Several of Gaiman's original works have been optioned or greenlighted for film adaptation, most notably "Stardust", which premiered in August 2007 and stars Robert De Niro, Michelle Pfeiffer and Claire Danes, directed by Matthew Vaughn. A stop-motion version of "Coraline" was released on 6 February 2009, with Henry Selick directing and Dakota Fanning and Teri Hatcher in the leading voice-actor roles.
In 2007, Gaiman it was announced that after ten years in development, the feature film of "" would finally begin production with a screenplay by Gaiman that he would direct for Warner Independent. Don Murphy and Susan Montford are the producers, and Guillermo del Toro is the film's executive producer. By 2010 it had been reported that it was no longer in production.
Seeing Ear Theatre performed two of Gaiman's audio theatre plays, "Snow, Glass, Apples", Gaiman's retelling of Snow White and "Murder Mysteries", a story of heaven before the Fall in which the first crime is committed. Both audio plays were published in the collection "Smoke and Mirrors" in 1998.
Gaiman's 2009 Newbery Medal winning book "The Graveyard Book" will be made into a movie, with Ron Howard as the director.
Gaiman wrote an episode of the long-running BBC science fiction series "Doctor Who", broadcast in 2011 during Matt Smith's second series as the Doctor. Shooting began in August 2010 for this episode, the original title of which was "The House of Nothing" but which was eventually transmitted as "The Doctor's Wife". The episode won the 2012 Hugo Award for Best Dramatic Presentation (Short Form). Gaiman made his return to "Doctor Who" with an episode titled "Nightmare in Silver", broadcast on 11 May 2013.
In 2011, it was announced that Gaiman would be writing the script to a new film version of "Journey to the West".
Gaiman appeared as himself on "The Simpsons" episode "The Book Job" broadcast on 20 November 2011.
In 2015, Starz greenlighted a series adaptation of Gaiman's novel "American Gods". Bryan Fuller and Michael Green will write and showrun the series.
Radio.
A six part radio play of "Neverwhere" was broadcast in March 2013, adapted by Dirk Maggs for BBC Radio 4 and Radio 4 Extra. Featured stars include James McAvoy as Richard, Natalie Dormer, Benedict Cumberbatch, Christopher Lee, Bernard Cribbens and Johnny Vegas.
In September 2014, Gaiman and Terry Pratchett joined forces with BBC Radio 4 to make the first ever dramatisation of their co-penned novel "Good Omens", which was broadcast in December in five half-hour episodes and culminated in an hour-long final apocalyptic showdown.
Public performances.
Gaiman frequently performs public readings from his stories and poetry, and has toured with his wife, musician Amanda Palmer. In some of these performances he has also sung songs, in "a novelist's version of singing", despite having "no kind of singing voice".
In 2015, Gaiman delivered a 100-minute lecture for the Long Now Foundation entitled "How Stories Last" about the nature of storytelling and how stories persist in human culture.
Blog and Twitter.
In February 2001, when Gaiman had completed writing "American Gods", his publishers set up a promotional website featuring a weblog in which Gaiman described the day-to-day process of revising, publishing, and promoting the novel. After the novel was published, the website evolved into a more general Official Neil Gaiman Website.
Gaiman generally posts to the blog describing the day-to-day process of being Neil Gaiman and writing, revising, publishing, or promoting whatever the current project is. He also posts reader emails and answers questions, which gives him unusually direct and immediate interaction with fans. One of his answers on why he writes the blog is "because writing is, like death, a lonely business."
The original "American Gods" blog was extracted for publication in the NESFA Press collection of Gaiman miscellany, "Adventures in the Dream Trade".
To celebrate the seventh anniversary of the blog, the novel "American Gods" was provided free of charge online for a month.
Gaiman is an active user of the social networking site Twitter with over 2.2 million followers , using the username "@neilhimself". In 2013, Gaiman was named by IGN as one of "The Best Tweeters in Comics", describing his posts as "sublime." Gaiman also runs a Tumblr account on which he primarily answers fan questions.
Personal life.
Home and family.
Gaiman lives near Menomonie, Wisconsin, United States and has lived there since 1992. Gaiman moved there to be close to the family of his then-wife, Mary McGrath, with whom he has three children: Michael, Holly, and Madeleine. , Gaiman also resides in Cambridge, Massachusetts. In 2014, he took up a five-year appointment as professor in the arts at Bard College, in Annandale-on-Hudson, New York.
Gaiman is married to songwriter and performer Amanda Palmer, with whom he has an open marriage. The couple publicly announced that they were dating in June 2009, announced their engagement on Twitter on 1 January 2010. On 16 November 2010, Amanda Palmer hosted a non-legally binding flash mob wedding for Gaiman's birthday in New Orleans. They were legally married on 2 January 2011. The wedding took place in the parlour of writers Ayelet Waldman and Michael Chabon. On marrying Palmer, he took her middle name, MacKinnon, as one of his names. On 18 March 2015, they announced through their Facebook and Twitter accounts that Palmer was pregnant with their first child, due in September. Their son Anthony was born 16 September 2015.
Friendship with Tori Amos.
One of Gaiman's most commented-upon friendships is with the musician Tori Amos, a "Sandman" fan who became friends with Gaiman after making a reference to "Neil and the Dream King" on her 1991 demo tape. He included her in turn as a character (a talking tree) in his novel "Stardust". Amos also mentions Gaiman in her songs, "Tear in Your Hand" ("If you need me, me and Neil'll be hangin' out with the dream king. Neil says hi by the way"), "Space Dog" ("Where's Neil when you need him?"), "Horses" ("But will you find me if Neil makes me a tree?"), "Carbon" ("Get me Neil on the line, no I can't hold. Have him read, 'Snow, Glass, Apples' where nothing is what it seems"), "Sweet Dreams" ("You're forgetting to fly, darling, when you sleep"), and "Not Dying Today" ("Neil is thrilled he can claim he's mammalian, 'but the bad news,' he said, 'girl you're a dandelion'"). He also wrote stories for the tour book of "Boys for Pele" and "Scarlet's Walk", a letter for the tour book of "American Doll Posse", and the stories behind each girl in her album "Strange Little Girls". Amos penned the introduction for his novel "Death: the High Cost of Living", and posed for the cover. She also wrote a song called "Sister Named Desire" based on his "Sandman" character, which was included on his anthology, "Where's Neil When You Need Him?".
Gaiman is godfather to Tori Amos's daughter Tash, and wrote a poem called "Blueberry Girl" for Tori and Tash. The poem has been turned into a book by the illustrator Charles Vess. Gaiman read the poem aloud to an audience at the Sundance Kabuki Theater in San Francisco on 5 October 2008 during his book reading tour for "The Graveyard Book". It was published in March 2009 with the title, "Blueberry Girl".
Litigation.
In 1993, Gaiman was contracted by Todd McFarlane to write a single issue of "Spawn", a popular title at the newly created Image Comics company. McFarlane was promoting his new title by having guest authors Gaiman, Alan Moore, Frank Miller, and Dave Sim each write a single issue.
In issue No. 9 of the series, Gaiman introduced the characters Angela, Cogliostro, and Medieval Spawn. Prior to this issue, Spawn was an assassin who worked for the government and came back as a reluctant agent of Hell but had no direction. In Angela, a cruel and malicious angel, Gaiman introduced a character who threatened Spawn's existence, as well as providing a moral opposite. Cogliostro was introduced as a mentor character for exposition and instruction, providing guidance. Medieval Spawn introduced a history and precedent that not all Spawns were self-serving or evil, giving additional character development to Malebolgia, the demon that creates Hellspawn.
As intended, all three characters were used repeatedly throughout the next decade by Todd McFarlane within the wider Spawn universe. In papers filed by Gaiman in early 2002, however, he claimed that the characters were jointly owned by their scripter (himself) and artist (McFarlane), not merely by McFarlane in his role as the creator of the series. Disagreement over who owned the rights to a character was the primary motivation for McFarlane and other artists to form Image Comics (although that argument related more towards disagreements between writers and artists as character creators). As McFarlane used the characters without Gaiman's permission or royalty payments, Gaiman believed his copyrighted work was being infringed upon, which violated their original, oral, agreement. McFarlane initially agreed that Gaiman had not signed away any rights to the characters, and negotiated with Gaiman to effectively 'swap' McFarlane's interest in the character Marvelman (McFarlane believes he purchased interest in the character when Eclipse Comics was liquidated; Gaiman is interested in being able to continue his aborted run on that title) but later claimed that Gaiman's work had been work-for-hire and that McFarlane owned all of Gaiman's creations entirely. The presiding judge, however, ruled against their agreement being work for hire, based in large part on the legal requirement that "copyright assignments must be in writing."
The Seventh Circuit Court of Appeals upheld the district court ruling in February 2004 granting joint ownership of the characters to Gaiman and McFarlane. On the specific issue of Cogliostro, presiding Judge John C. Shabaz proclaimed, "The expressive work that is the comic-book character Count Nicholas Cogliostro was the joint work of Gaiman and McFarlane—their contributions strike us as quite equal—and both are entitled to ownership of the copyright". Similar analysis led to similar results for the other two characters, Angela and Medieval Spawn.
This legal battle was brought by Gaiman and the specifically formed Marvels and Miracles, LLC, which Gaiman created to help sort out the legal rights surrounding Marvelman. Gaiman wrote "Marvel 1602 "in 2003 to help fund this project. All of Marvel Comics' profits for the original issues of the series went to Marvels and Miracles. In 2009, Marvel Comics purchased Marvelman.
Gaiman returned to court over three more Spawn characters, Dark Ages Spawn, Domina and Tiffany, that are claimed to be "derivative of the three he co-created with McFarlane." The judge ruled that Gaiman was right in his claims and gave McFarlane until the start of September 2010 to settle matters.
Gaiman is a supporter and board member of the Comic Book Legal Defense Fund.
Literary allusions.
Gaiman's work is known for a high degree of allusiveness. Particularly in "The Sandman", literary figures and characters appear often; the character of Fiddler's Green is modelled visually on G. K. Chesterton, both William Shakespeare and Geoffrey Chaucer appear as characters, as do several characters from within "A Midsummer Night's Dream" and "The Tempest". The comic also draws from numerous mythologies and historical periods.
Clay Smith has argued that this sort of allusiveness serves to situate Gaiman as a strong authorial presence in his own works, often to the exclusion of his collaborators. However, Smith's viewpoint is in the minority: to many, if there is a problem with Gaiman scholarship and intertextuality it is that "... his literary merit and vast popularity have propelled him into the nascent comics canon so quickly that there is not yet a basis of critical scholarship about his work."
David Rudd takes a more generous view in his study of the novel "Coraline", where he argues that the work plays and riffs productively on Sigmund Freud's notion of the Uncanny, or the "Unheimlich".
Though Gaiman's work is frequently seen as exemplifying the monomyth structure laid out in Joseph Campbell's "The Hero with a Thousand Faces", Gaiman says that he started reading "The Hero with a Thousand Faces" but refused to finish it: "I think I got about half way through "The Hero with a Thousand Faces" and found myself thinking if this is true – I don’t want to know. I really would rather not know this stuff. I’d rather do it because it’s true and because I accidentally wind up creating something that falls into this pattern than be told what the pattern is."

</doc>
<doc id="22058" url="https://en.wikipedia.org/wiki?curid=22058" title="Nymph">
Nymph

A nymph (, "nymphē" ) in Greek mythology and in Latin mythology is a minor female nature deity typically associated with a particular location or landform. Different from other goddesses, nymphs are generally regarded as divine spirits who animate nature, and are usually depicted as beautiful, young nubile maidens who love to dance and sing; their amorous freedom sets them apart from the restricted and chaste wives and daughters of the Greek "polis". They are beloved by many and dwell in mountainous regions and forests by lakes and streams. Although they would never die of old age nor illness, and could give birth to fully immortal children if mated to a god, they themselves were not necessarily immortal, and could be beholden to death in various forms. Charybdis and Scylla were once nymphs.
Other nymphs, always in the shape of young maidens, were part of the retinue of a god, such as Dionysus, Hermes, or Pan, or a goddess, generally the huntress Artemis. Nymphs were the frequent target of satyrs.
Etymology.
Nymphs are personifications of the creative and fostering activities of nature, most often identified with the life-giving outflow of springs: as Walter Burkert (Burkert 1985:III.3.3) remarks, "The idea that rivers are gods and springs divine nymphs is deeply rooted not only in poetry but in belief and ritual; the worship of these deities is limited only by the fact that they are inseparably identified with a specific locality."
The Greek word has "bride" and "veiled" among its meanings: hence a marriageable young woman. Other readers refer the word (and also Latin "nubere" and German "Knospe") to a root expressing the idea of "swelling" (according to Hesychius, one of the meanings of is "rose-bud").
Adaptations.
The Greek nymphs were spirits invariably bound to places, not unlike the Latin "genius loci", and the difficulty of transferring their cult may be seen in the complicated myth that brought Arethusa to Sicily. In the works of the Greek-educated Latin poets, the nymphs gradually absorbed into their ranks the indigenous Italian divinities of springs and streams (Juturna, Egeria, Carmentis, Fontus), while the Lymphae (originally Lumpae), Italian water-goddesses, owing to the accidental similarity of their names, could be identified with the Greek Nymphae. The mythologies of classicizing Roman poets were unlikely to have affected the rites and cult of individual nymphs venerated by country people in the springs and clefts of Latium. Among the Roman literate class, their sphere of influence was restricted, and they appear almost exclusively as divinities of the watery element.
In modern Greek folklore.
The ancient Greek belief in nymphs survived in many parts of the country into the early years of the twentieth century, when they were usually known as "nereids". At that time, John Cuthbert Lawson wrote: "...there is probably no nook or hamlet in all Greece where the womenfolk at least do not scrupulously take precautions against the thefts and malice of the nereids, while many a man may still be found to recount in all good faith stories of their beauty, passion and caprice.
Nor is it a matter of faith only; more than once I have been in villages where certain Nereids were known by sight to several persons (so at least they averred); and there was a wonderful agreement among the witnesses in the description of their appearance and dress."
Nymphs tended to frequent areas distant from humans but could be encountered by lone travelers outside the village, where their music might be heard, and the traveler could spy on their dancing or bathing in a stream or pool, either during the noon heat or in the middle of the night. They might appear in a whirlwind. Such encounters could be dangerous, bringing dumbness, besotted infatuation, madness or stroke to the unfortunate human. When parents believed their child to be nereid-struck, they would pray to Saint Artemidos.
Modern sexual connotations.
Due to the depiction of the mythological nymphs as females who mate with men or women at their own volition, and are completely outside of male control, the term is often used for women who are perceived as behaving similarly. (For example, the title of the Perry Mason detective novel "The Case of the Negligent Nymph" (1956) by Erle Stanley Gardner is derived from this meaning of the word.)
The term "nymphomania" was created by modern psychology as referring to a "desire to engage in human sexual behavior at a level high enough to be considered clinically significant", "nymphomaniac" being the person suffering from such a disorder. Due to widespread use of the term among lay persons (often shortened to "nympho") and stereotypes attached, professionals nowadays prefer the term "hypersexuality", which can refer to males and females alike.
The word "nymphet" is used to identify a sexually precocious girl. The term was made famous in the novel "Lolita" by Vladimir Nabokov. The main character, Humbert Humbert, uses the term many times, usually in reference to the title character.
Classification.
As H.J. Rose states, all the names for various classes of nymphs are plural feminine adjectives agreeing with the substantive "nymphai", and there was no single classification that could be seen as canonical and exhaustive. Thus the classes of nymphs tend to overlap, which complicates the task of precise classification. Rose mentions dryads and hamadryads as nymphs of trees generally, "meliai" as nymphs of ash trees, and naiads as nymphs of water, but no others specifically.
Classification by type of dwelling.
The following is not the authentic Greek classification, but is intended simply as a guide:
Location-specific groupings of nymphs.
The following is a list of groups of nymphs associated with this or that particular location. Nymphs in such groupings could belong to any of the classes mentioned above (Naiades, Oreades, and so on).
Individual names of some of the nymphs.
The following is a selection of names of the nymphs whose class was not specified in the source texts. For lists of Naiads, Oceanids, Dryades etc. see respective articles.

</doc>
<doc id="22059" url="https://en.wikipedia.org/wiki?curid=22059" title="Norse">
Norse

Norse may refer to:

</doc>
<doc id="22063" url="https://en.wikipedia.org/wiki?curid=22063" title="Natural law">
Natural law

Natural law is a philosophy that certain rights or values are inherent by virtue of human nature and universally cognizable through human reason. Historically, natural law refers to the use of reason to analyze both social and personal human nature to deduce binding rules of moral behavior. The law of nature, being determined by nature, is universal.
In Western culture, the philosophical conception of natural law first appears among ancient Greek thinkers. Although natural law is often conflated with common law, the two are distinct. Common law is not based on inherent rights, but is the legal tradition whereby certain rights or values are legally recognized by virtue of already having judicial recognition or articulation. Natural law is often contrasted with the human-made laws (positive law) of a given political community, society, or state. In legal theory, the interpretation of a human-made law requires some reference to natural law. On this understanding of natural law, natural law can be invoked to criticize judicial decisions about what the law says, but not to criticize the best interpretation of the law itself. Some jurists and scholars use natural law synonymously with natural justice or natural right (Latin "ius naturale"), while others distinguish between natural law and natural right.
Natural law theories have exercised a profound influence on the development of English common law. Declarationism, a legal philosophy, argues that the founding of the United States is based on natural law. Because of the intersection between natural law and natural rights, natural law has been cited as a component in the United States Declaration of Independence and the Constitution of the United States, as well as in the Declaration of the Rights of Man and of the Citizen. (See "Laws of Nature" First Paragraph Declaration of Independence) Within the American Declaration of Independence, building on natural law, philosophies such as Consent of the Governed replaced the Old World Governance Doctrine of the Divine Right of Kings. These philosophies like social contract theory came of age during the age of enlightenment through individuals such as John Locke, but these ideas can be found in Roman law, Greek philosophy and ancient Buddhist texts.
Natural law theories have featured greatly in the philosophies of Thomas Aquinas, Alberico Gentili, Francisco Suárez, Richard Hooker, Thomas Hobbes, Hugo Grotius, Samuel von Pufendorf, Matthew Hale, John Locke, Francis Hutcheson, Jean Jacques Burlamaqui, Emmerich de Vattel, Cesare Beccaria and Francesco Mario Pagano.
History.
The use of natural law, in its various incarnations, has varied widely through its history. There are a number of different theories of natural law, differing from each other with respect to the role that morality plays in determining the authority of legal norms. This article deals with its usages separately rather than attempt to unify them into a single theory.
Plato.
Although Plato does not have an explicit theory of natural law (he rarely used the phrase 'natural law' except in "Gorgias" 484 and "Timaeus" 83e), his concept of nature, according to John Wild, contains some of the elements found in many natural law theories. According to Plato we live in an orderly universe. At the basis of this orderly universe or nature are the forms, most fundamentally the Form of the Good, which Plato describes as "the brightest region of Being". The Form of the Good is the cause of all things and when it is seen it leads a person to act wisely. In the "Symposium", the Good is closely identified with the Beautiful. Also in the "Symposium", Plato describes how the experience of the Beautiful by Socrates enables him to resist the temptations of wealth and sex. In the "Republic", the ideal community is, "...a city which would be established in accordance with nature."
Aristotle.
Greek philosophy emphasized the distinction between "nature" ("physis", "φúσις") on the one hand and "law", "custom", or "convention" ("nomos", "νóμος") on the other. What the law commanded varied from place to place, but what was "by nature" should be the same everywhere. A "law of nature" would therefore have had the flavor more of a paradox than something that obviously existed. Against the conventionalism that the distinction between nature and custom could engender, Socrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right ("dikaion physikon", "δικαιον φυσικον", Latin "ius naturale"). Of these, Aristotle is often said to be the father of natural law.
Aristotle's association with natural law may be due to the interpretation given to his works by Thomas Aquinas. But whether Aquinas correctly read Aristotle is a disputed question. According to some, Aquinas conflates the natural law and natural right, the latter of which Aristotle posits in Book V of the "Nicomachean Ethics" (Book IV of the "Eudemian Ethics"). According to this interpretation, Aquinas's influence was such as to affect a number of early translations of these passages in an unfortunate manner, though more recent translations render them more literally. Aristotle notes that natural justice is a species of political justice, viz. the scheme of distributive and corrective justice that would be established under the best political community; were this to take the form of law, this could be called a natural law, though Aristotle does not discuss this and suggests in the "Politics" that the best regime may not rule by law at all.
The best evidence of Aristotle's having thought there was a natural law comes from the "Rhetoric", where Aristotle notes that, aside from the "particular" laws that each people has set up for itself, there is a "common" law that is according to nature. Specifically, he quotes Sophocles and Empedocles:
Universal law is the law of Nature. For there really is, as every one to some extent divines, a natural justice and injustice that is binding on all men, even on those who have no association or covenant with each other. It is this that Sophocles' Antigone clearly means when she says that the burial of Polyneices was a just act in spite of the prohibition: she means that it was just by nature:
And so Empedocles, when he bids us kill no living creature, says that doing this is not just for some people while unjust for others:
Some critics believe that the context of this remark suggests only that Aristotle advised that it could be rhetorically advantageous to appeal to such a law, especially when the "particular" law of one's own city was averse to the case being made, not that there actually was such a law; Moreover, they claim that Aristotle considered two of the three candidates for a universally valid, natural law provided in this passage to be wrong. Aristotle's theoretical paternity of the natural law tradition is consequently disputed.
Stoic natural law.
The development of this tradition of natural justice into one of natural law is usually attributed to the Stoics. The rise of natural law as a universal system coincided with the rise of large empires and kingdoms in the Greek world. Whereas the "higher" law Aristotle suggested one could appeal to was emphatically natural, in contradistinction to being the result of divine positive legislation, the Stoic natural law was indifferent to the divine or natural source of the law: the Stoics asserted the existence of a rational and purposeful order to the universe (a divine or eternal law), and the means by which a rational being lived in accordance with this order was the natural law, which spelled out action that accorded with virtue.
As the English historian A. J. Carlyle (1861–1943) notes:
There is no change in political theory so startling in its completeness as the change from the theory of Aristotle to the later philosophical view represented by Cicero and Seneca... We think that this cannot be better exemplified than with regard to the theory of the equality of human nature." Charles H. McIlwain likewise observes that "the idea of the equality of men is the profoundest contribution of the Stoics to political thought" and that "its greatest influence is in the changed conception of law that in part resulted from it.
Natural law first appeared among the stoics who believed that God is everywhere and in everyone. Within humans is a "divine spark" which helps them to live in accordance with nature.
The stoics felt that there was a way in which the universe had been designed and natural law helped us to harmonise with this.
Cicero.
Cicero wrote in his De Legibus that both justice and law derive their origin from what nature has given to man, from what the human mind embraces, from the function of man, and from what serves to unite humanity. For Cicero, natural law obliges us to contribute to the general good of the larger society. The purpose of positive laws is to provide for "the safety of citizens, the preservation of states, and the tranquility and happiness of human life." In this view, "wicked and unjust statutes" are "anything but 'laws,'" because "in the very definition of the term 'law' there inheres the idea and principle of choosing what is just and true." Law, for Cicero, "ought to be a reformer of vice and an incentive to virtue." Cicero expressed the view that "the virtues which we ought to cultivate, always tend to our own happiness, and that the best means of promoting them consists in living with men in that perfect union and charity which are cemented by mutual benefits."
Cicero influenced the discussion of natural law for many centuries to come, up through the era of the American Revolution. The jurisprudence of the Roman Empire was rooted in Cicero, who held "an extraordinary grip ... upon the imagination of posterity" as "the medium for the propagation of those ideas which informed the law and institutions of the empire." Cicero's conception of natural law "found its way to later centuries notably through the writings of Saint Isidore of Seville and the Decretum of Gratian." Thomas Aquinas, in his summary of medieval natural law, quoted Cicero's statement that "nature" and "custom" were the sources of a society's laws.
The Renaissance Italian historian Leonardo Bruni praised Cicero as the man "who carried philosophy from Greece to Italy, and nourished it with the golden river of his eloquence." The legal culture of Elizabethan England, exemplified by Sir Edward Coke, was "steeped in Ciceronian rhetoric." The Scottish moral philosopher Francis Hutcheson, as a student at Glasgow, "was attracted most by Cicero, for whom he always professed the greatest admiration." More generally in eighteenth-century Great Britain, Cicero's name was a household word among educated people. Likewise, "in the admiration of early Americans Cicero took pride of place as orator, political theorist, stylist, and moralist."
The British polemicist Thomas Gordon "incorporated Cicero into the radical ideological tradition that travelled from the mother country to the colonies in the course of the eighteenth century and decisively shaped early American political culture." Cicero's description of the immutable, eternal, and universal natural law was quoted by Burlamaqui and later by the American revolutionary legal scholar James Wilson. Cicero became John Adams's "foremost model of public service, republican virtue, and forensic eloquence." Adams wrote of Cicero that "as all the ages of the world have not produced a greater statesman and philosopher united in the same character, his authority should have great weight." Thomas Jefferson "first encountered Cicero as a schoolboy learning Latin, and continued to read his letters and discourses as long as he lived. He admired him as a patriot, valued his opinions as a moral philosopher, and there is little doubt that he looked upon Cicero's life, with his love of study and aristocratic country life, as a model for his own." Jefferson described Cicero as "the father of eloquence and philosophy."
Some early Church Fathers, especially those in the West, sought to incorporate natural law into Christianity. The most notable among these was Augustine of Hippo, who equated natural law with man's prelapsarian state; as such, a life according to nature was no longer possible and men needed instead to seek salvation through the divine law and grace of Jesus Christ.
In the twelfth century, Gratian equated the natural law with divine law. A century later, St. Thomas Aquinas in his "Summa Theologica" I-II qq. 90–106, restored Natural Law to its independent state, asserting natural law as the rational creature's participation in the eternal law. Yet, since human reason could not fully comprehend the Eternal law, it needed to be supplemented by revealed Divine law. (See also Biblical law in Christianity.) Meanwhile, Aquinas taught that all human or positive laws were to be judged by their conformity to the natural law. An unjust law is not a law, in the full sense of the word. It retains merely the 'appearance' of law insofar as it is duly constituted and enforced in the same way a just law is, but is itself a 'perversion of law.' At this point, the natural law was not only used to pass judgment on the moral worth of various laws, but also to determine what the law said in the first place. This principle laid the seed for possible societal tension with reference to tyrants.
The natural law was inherently teleological and deontological in that although it is aimed at goodness, it is entirely focused on the ethicalness of actions, rather than the consequence. The specific content of the natural law was therefore determined by a conception of what things constituted happiness, be they temporal satisfaction or salvation. The state, in being bound by the natural law, was conceived as an institution directed at bringing its subjects to true happiness.
In the 16th century, the School of Salamanca (Francisco Suárez, Francisco de Vitoria, etc.) further developed a philosophy of natural law. After the Church of England broke from Rome, the English theologian Richard Hooker adapted Thomistic notions of natural law to Anglicanism. There are five important principles: to live, to learn, to reproduce, to worship God, and to live in an ordered society.
Those who see biblical support for the doctrine of natural law often point to Paul's Epistle to the Romans: "For when the Gentiles, which have not the law, do by nature the things contained in the law, these, having not the law, are a law unto themselves: Which shew the work of the law written in their hearts, their conscience also bearing witness, and their thoughts the mean while accusing or else excusing one another. (). The intellectual historian A. J. Carlyle has commented on this passage, "There can be little doubt that St Paul's words imply some conception analogous to the 'natural law' in Cicero, a law written in men's hearts, recognized by man's reason, a law distinct from the positive law of any State, or from what St Paul recognized as the revealed law of God. It is in this sense that St Paul's words are taken by the Fathers of the fourth and fifth centuries like St Hilary of Poitiers, St Ambrose, and St Augustine, and there seems no reason to doubt the correctness of their interpretation."
English jurisprudence.
Heinrich A. Rommen remarked upon "the tenacity with which the spirit of the English common law retained the conceptions of natural law and equity which it had assimilated during the Catholic Middle Ages, thanks especially to the influence of Henry de Bracton (d. 1268) and Sir John Fortescue (d. cir. 1476)." Bracton's translator notes that Bracton "was a trained jurist with the principles and distinctions of Roman jurisprudence firmly in mind"; but Bracton adapted such principles to English purposes rather than copying slavishly. In particular, Bracton turned the imperial Roman maxim that "the will of the prince is law" on its head, insisting that the king is "under" the law. The legal historian Charles F. Mullett has noted Bracton's "ethical definition of law, his recognition of justice, and finally his devotion to natural rights." Bracton considered justice to be the "fountain-head" from which "all rights arise." For his definition of justice, Bracton quoted the twelfth-century Italian jurist Azo: "'Justice is the constant and unfailing will to give to each his right.'" Bracton's work was the second legal treatise studied by the young apprentice lawyer Thomas Jefferson.
Fortescue stressed "the supreme importance of the law of God and of nature" in works that "profoundly influenced the course of legal development in the following centuries." The legal scholar Ellis Sandoz has noted that "the historically ancient and the ontologically higher law—eternal, divine, natural—are woven together to compose a single harmonious texture in Fortescue's account of English law." As the legal historian Norman Doe explains: "Fortescue follows the general pattern set by Aquinas. The objective of every legislator is to dispose people to virtue. It is by means of law that this is accomplished. Fortescue's definition of law (also found in Accursius and Bracton), after all, was 'a sacred sanction commanding what is virtuous ["honesta"] and forbidding the contrary.'" Fortescue cited the great Italian Leonardo Bruni for his statement that "virtue alone produces happiness."
Christopher St. Germain's "Doctor and Student" was a classic of English jurisprudence, and it was thoroughly annotated by Thomas Jefferson. St. Germain informs his readers that English lawyers generally don't use the phrase "law of nature," but rather use "reason" as the preferred synonym. Norman Doe notes that St. Germain's view "is essentially Thomist," quoting Thomas Aquinas's definition of law as "an ordinance of reason made for the common good by him who has charge of the community, and promulgated."
Sir Edward Coke was the preeminent jurist of his time. Coke's preeminence extended across the ocean: "For the American revolutionary leaders, 'law' meant Sir Edward Coke's custom and right reason."
After Coke, the most famous common law jurist of the seventeenth century is Sir Matthew Hale. Hale wrote a treatise on natural law that circulated among English lawyers in the eighteenth century and survives in three manuscript copies. This natural-law treatise has been published as "Of the Law of Nature" (2015). Hale's definition of the natural law reads: "It is the Law of Almighty God given by him to Man with his Nature discovering the morall good and moral evill of Moral Actions, commanding the former, and forbidding the latter by the secret voice or dictate of his implanted nature, his reason, and his concience." He viewed natural law as antecedent, preparatory, and subsequent to civil government, and stated that human law "cannot forbid what the Law of Nature injoins, nor Command what the Law of Nature prohibits." He cited as authorities Plato, Aristotle, Cicero, Seneca, Epictetus, and the Apostle Paul. He was critical of Hobbes's reduction of natural law to self-preservation and Hobbes's account of the state of nature, but drew positively on Hugo Grotius's "De jure belli ac pacis", Francisco Suárez's "Tractatus de legibus ac deo legislatore", and John Selden's John Selden's "De jure naturali et gentium juxta disciplinam Ebraeorum".
As early as the thirteenth century, it was held that "the law of nature...is the ground of all laws" and by the Chancellor and Judges that "it is required by the law of nature that every person, before he can be punish'd, ought to be present; and if absent by contumacy, he ought to be summoned and make default.". Further, in 1824, we find it held that "proceedings in our Courts are founded upon the law of England, and that law is again founded upon the law of nature and the revealed law of God. If the right sought to be enforced is inconsistent with either of these, the English municipal courts cannot recognize it."
American jurisprudence.
The U.S. Declaration of Independence states that it has become necessary for the people of the United States to assume "the separate and equal station to which the Laws of Nature and of Nature's God entitle them". Some early American lawyers and judges perceived natural law as too tenuous, amorphous and evanescent a legal basis for grounding concrete rights and governmental limitations. Natural law did, however, serve as authority for legal claims and rights in some judicial decisions, legislative acts, and legal pronouncements. Robert Lowry Clinton argues that the U.S. Constitution rests on a common law foundation and the common law, in turn, rests on a classical natural law foundation.
Islamic natural law.
Abū Rayhān al-Bīrūnī, an Islamic scholar and polymath scientist, understood natural law as the survival of the fittest. He argued that the antagonism between human beings can only be overcome through a divine law, which he believed to have been sent through prophets. This is also the position of the Ashari school, the largest school of Sunni theology. Averroes (Ibn Rushd), in his treatise on "Justice and Jihad" and his commentary on Plato's "Republic", writes that the human mind can know of the unlawfulness of killing and stealing and thus of the five maqasid or higher intents of the Islamic sharia or to protect religion, life, property, offspring, and reason. The concept of natural law entered the mainstream of Western culture through his Aristotelian commentaries, influencing the subsequent Averroist movement and the writings of Thomas Aquinas.
The Maturidi school, the second largest school of Sunni theology, posits the existence of a form of natural law. Abu Mansur al-Maturidi stated that the human mind could know of the existence of God and the major forms of 'good' and 'evil' without the help of revelation. Al-Maturidi gives the example of stealing, which is known to be evil by reason alone due to man's working hard for his property. Killing, fornication, and drinking alcohol were all 'evils' the human mind could know of according to al-Maturidi. The concept of "Istislah" in Islamic law bears some similarities to the natural law tradition in the West, as exemplified by Thomas Aquinas. However, whereas natural law deems good what is self-evidently good, according as it tends towards the fulfilment of the person, "istislah" calls good whatever is connected to one of five "basic goods". Al-Ghazali abstracted these "basic goods" from the legal precepts in the Qur'an and Sunnah: they are religion, life, reason, lineage and property. Some add also "honour". Ibn Qayyim Al-Jawziyya also posited that human reason could discern between 'great sins' and good deeds.
Hobbes.
By the 17th Century, the Medieval teleological view came under intense criticism from some quarters. Thomas Hobbes instead founded a contractualist theory of legal positivism on what all men could agree upon: what they sought (happiness) was subject to contention, but a broad consensus could form around what they feared (violent death at the hands of another). The natural law was how a rational human being, seeking to survive and prosper, would act. Natural law, therefore, was discovered by considering humankind's natural rights, whereas previously it could be said that natural rights were discovered by considering the natural law. In Hobbes' opinion, the only way natural law could prevail was for men to submit to the commands of the sovereign. Because the ultimate source of law now comes from the sovereign, and the sovereign's decisions need not be grounded in morality, legal positivism is born. Jeremy Bentham's modifications on legal positivism further developed the theory.
As used by Thomas Hobbes in his treatises "Leviathan" and "De Cive", natural law is "a precept, or general rule, found out by reason, by which a man is forbidden to do that which is destructive of his life, or takes away the means of preserving the same; and to omit that by which he thinks it may best be preserved."
According to Hobbes, there are nineteen Laws. The first two are expounded in chapter XIV of Leviathan ("of the first and second natural laws; and of contracts"); the others in chapter XV ("of other laws of nature").
Hobbes's philosophy includes a frontal assault on the founding principles of the earlier natural legal tradition, disregarding the traditional association of virtue with happiness, and likewise re-defining "law" to remove any notion of the promotion of the common good. Hobbes has no use for Aristotle's association of nature with human perfection, inverting Aristotle's use of the word "nature." Hobbes posits a primitive, unconnected state of nature in which men, having a "natural proclivity...to hurt each other" also have "a Right to every thing, even to one anothers body"; and "nothing can be Unjust" in this "warre of every man against every man" in which human life is "solitary, poore, nasty, brutish, and short." Rejecting Cicero's view that men join in society primarily through "a certain social spirit which nature has implanted in man," Hobbes declares that men join in society simply for the purpose of "getting themselves out from that miserable condition of Warre, which is necessarily consequent...to the naturall Passions of men, when there is no visible Power to keep them in awe." As part of his campaign against the classical idea of natural human sociability, Hobbes inverts that fundamental natural legal maxim, the Golden Rule. Hobbes's version is ""Do not that to another, which thou wouldst not have done to thy selfe.""
Cumberland's rebuttal of Hobbes.
The English cleric Richard Cumberland wrote a lengthy and influential attack on Hobbes's depiction of individual self-interest as the essential feature of human motivation. Historian Knud Haakonssen has noted that in the eighteenth century, Cumberland was commonly placed alongside Alberico Gentili, Hugo Grotius and Samuel Pufendorf "in the triumvirate of seventeenth-century founders of the 'modern' school of natural law." The eighteenth-century philosophers Shaftesbury and Hutcheson "were obviously inspired in part by Cumberland." Historian Jon Parkin likewise describes Cumberland's work as "one of the most important works of ethical and political theory of the seventeenth century." Parkin observes that much of Cumberland's material "is derived from Roman Stoicism, particularly from the work of Cicero, as "Cumberland deliberately cast his engagement with Hobbes in the mould of Cicero's debate between the Stoics, who believed that nature could provide an objective morality, and Epicureans, who argued that morality was human, conventional and self-interested." In doing so, Cumberland de-emphasized the overlay of Christian dogma (in particular, the doctrine of "original sin" and the corresponding presumption that humans are incapable of "perfecting" themselves without divine intervention) that had accreted to natural law in the Middle Ages.
By way of contrast to Hobbes's multiplicity of laws, Cumberland states in the very first sentence of his "Treatise of the Laws of Nature" that "all the Laws of Nature are reduc'd to that one, of Benevolence toward all Rationals." He later clarifies: "By the name "Rationals" I beg leave to understand, as well "God" as "Man"; and I do it upon the Authority of Cicero." Cumberland argues that the mature development ("perfection") of human nature involves the individual human willing and acting for the common good. For Cumberland, human interdependence precludes Hobbes's natural right of each individual to wage war against all the rest for personal survival. However, Haakonssen warns against reading Cumberland as a proponent of "enlightened self-interest." Rather, the "proper moral love of humanity" is "a disinterested love of God through love of humanity in ourselves as well as others." Cumberland concludes that actions "principally conducive to our Happiness" are those that promote "the Honour and Glory of God" and also "Charity and Justice towards men." Cumberland emphasizes that desiring the well-being of our fellow humans is essential to the "pursuit of our own Happiness." He cites "reason" as the authority for his conclusion that happiness consists in "the most extensive Benevolence," but he also mentions as "Essential Ingredients of Happiness" the "Benevolent Affections," meaning "Love and Benevolence towards others," as well as "that Joy, which arises from their Happiness."
Liberal natural law.
Liberal natural law grew out of the medieval Christian natural law theories and out of Hobbes' revision of natural law, sometimes in an uneasy balance of the two.
Sir Alberico Gentili and Hugo Grotius based their philosophies of international law on natural law. In particular, his writings on freedom of the seas and just war theory directly appealed to natural law. About natural law itself, he wrote that "even the will of an omnipotent being cannot change or abrogate" natural law, which "would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs." ("De iure belli ac pacis", Prolegomeni XI). This is the famous argument "etiamsi daremus" ("non esse Deum"), that made natural law no longer dependent on theology. However, German church-historians Ernst Wolf and M. Elze disagreed and claimed that Grotius' concept of natural law did have a theological basis. In Grotius' view, the Old Testament contained moral precepts (e.g. the Decalogue) which Christ confirmed and therefore were still valid. Moreover, they were useful in explaining the content of natural law. Both biblical revelation and natural law originated in God and could therefore not contradict each other.
In a similar way, Samuel Pufendorf gave natural law a theological foundation and applied it to his concepts of government and international law.
John Locke incorporated natural law into many of his theories and philosophy, especially in "Two Treatises of Government". There is considerable debate about whether his conception of natural law was more akin to that of Aquinas (filtered through Richard Hooker) or Hobbes' radical reinterpretation, though the effect of Locke's understanding is usually phrased in terms of a revision of Hobbes upon Hobbesean contractualist grounds. Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect "life, liberty, and property," people could justifiably overthrow the existing state and create a new one.
While Locke spoke in the language of natural law, the content of this law was by and large protective of natural rights, and it was this language that later liberal thinkers preferred. Political philosopher Jeremy Waldron has pointed out that Locke's political thought was based on "a particular set of Protestant Christian assumptions." To Locke, the content of natural law was identical with biblical ethics as laid down especially in the Decalogue, Christ's teaching and exemplary life, and St. Paul's admonitions. Locke derived the concept of basic human equality, including the equality of the sexes ("Adam and Eve"), from Genesis 1, 26–28, the starting-point of the theological doctrine of Imago Dei. One of the consequences is that as all humans are created equally free, governments need the consent of the governed. Thomas Jefferson, arguably echoing Locke, appealed to unalienable rights in the "Declaration of Independence", "We hold these truths to be self-evident, that all men are "created" equal, that they are endowed by their "Creator" with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness." The Lockean idea that governments need the consent of the governed was also fundamental to the Declaration of Independence, as the American Revolutionaries used it as justification for their separation from the British crown.
The Belgian philosopher of law Frank van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. Libertarian theorist Murray Rothbard argues that "the very existence of a natural law discoverable by reason is a potentially powerful threat to the status quo and a standing reproach to the reign of blindly traditional custom or the arbitrary will of the State apparatus." Ludwig von Mises states that he relaid the general sociological and economic foundations of the liberal doctrine upon utilitarianism, rather than natural law, but R.A. Gonce argues that "the reality of the argument constituting his system overwhelms his denial." David Gordon notes, "When most people speak of natural law, what they have in mind is the contention that morality can be derived from human nature. If human beings are rational animals of such-and-such a sort, then the moral virtues are...(filling in the blanks is the difficult part)."
However, a secular critique of the natural law doctrine was stated by Pierre Charron in his "De la sagesse" (1601): "The sign of a natural law must be the universal respect in which it is held, for if there was anything that nature had truly commanded us to do, we would undoubtedly obey it universally: not only would every nation respect it, but every individual. Instead there is nothing in the world that is not subject to contradiction and dispute, nothing that is not rejected, not just by one nation, but by many; equally, there is nothing that is strange and (in the opinion of many) unnatural that is not approved in many countries, and authorized by their customs."
Catholic natural law jurisprudence.
The Roman Catholic Church holds the view of natural law provided by St. Thomas Aquinas, particularly in his "Summa Theologiae", and often as filtered through the School of Salamanca. This view is also shared by some Protestant churches, and was delineated by C.S. Lewis in his works "Mere Christianity" and "The Abolition of Man.
The Catholic Church understands human beings to consist of body and mind, the physical and the non-physical (or soul perhaps), and that the two are inextricably linked. Humans are capable of discerning the difference between good and evil because they have a conscience. There are many manifestations of the good that we can pursue. Some, like procreation, are common to other animals, while others, like the pursuit of truth, are inclinations peculiar to the capacities of human beings.
To know what is right, one must use one's reason and apply it to Aquinas' precepts. This reason is believed to be embodied, in its most abstract form, in the concept of a primary precept: "Good is to be sought, evil avoided." St. Thomas explains that:
there belongs to the natural law, first, certain most general precepts, that are known to all;
However, while the primary and immediate precepts cannot be "blotted out", the secondary precepts can be. Therefore, for a deontological ethical theory they are open to a surprisingly large amount of interpretation and flexibility. Any rule that helps man to live up to the primary or subsidiary precepts can be a secondary precept, for example:
Natural moral law is concerned with both exterior and interior acts, also known as action and motive. Simply doing the right thing is not enough; to be truly moral one's motive must be right as well. For example, helping an old lady across the road (good exterior act) to impress someone (bad interior act) is wrong. However, good intentions don't always lead to good actions. The motive must coincide with the cardinal or theological virtues. Cardinal virtues are acquired through reason applied to nature; they are:
The theological virtues are:
According to Aquinas, to lack any of these virtues is to lack the ability to make a moral choice. For example, consider a man who possesses the virtues of justice, prudence, and fortitude, yet lacks temperance. Due to his lack of self-control and desire for pleasure, despite his good intentions, he will find himself swaying from the moral path.
In contemporary jurisprudence.
In jurisprudence, "natural law" can refer to the several doctrines:
Whereas legal positivism would say that a law can be unjust without it being any less a law, a natural law jurisprudence would say that there is something legally deficient about an unjust law. Legal interpretivism, famously defended in the English-speaking world by Ronald Dworkin, claims to have a position different from both natural law and positivism.
Besides utilitarianism and Kantianism, natural law jurisprudence has in common with virtue ethics that it is a live option for a first principles ethics theory in analytic philosophy.
The concept of natural law was very important in the development of the English common law. In the struggles between Parliament and the monarch, Parliament often made reference to the Fundamental Laws of England, which were at times said to embody natural law principles since time immemorial and set limits on the power of the monarchy. According to William Blackstone, however, natural law might be useful in determining the content of the common law and in deciding cases of equity, but was not itself identical with the laws of England. Nonetheless, the implication of natural law in the common law tradition has meant that the great opponents of natural law and advocates of legal positivism, like Jeremy Bentham, have also been staunch critics of the common law.
Natural law jurisprudence is currently undergoing a period of reformulation (as is legal positivism). The most prominent contemporary natural law jurist, Australian John Finnis, is based in Oxford, but there are also Americans Germain Grisez, Robert P. George, and Canadian Joseph Boyle and Brazil Emídio Brasileiro. All have tried to construct a new version of natural law. The 19th-century anarchist and legal theorist, Lysander Spooner, was also a figure in the expression of modern natural law.
"New Natural Law" as it is sometimes called, originated with Grisez. It focuses on "basic human goods," such as human life, knowledge, and aesthetic experience, which are self-evidently and intrinsically worthwhile, and states that these goods reveal themselves as being incommensurable with one another.
The tensions between the natural law and the positive law have played, and continue to play a key role in the development of international law.

</doc>
<doc id="22065" url="https://en.wikipedia.org/wiki?curid=22065" title="Nestorianism">
Nestorianism

Nestorianism is a Christological doctrine that emphasizes the disunion between the human and divine natures of Jesus. It was advanced by Nestorius (386–450), Patriarch of Constantinople from 428–431, influenced by Nestorius's studies under Theodore of Mopsuestia at the School of Antioch. Nestorius's teachings brought him into conflict with other prominent church leaders, most notably Cyril of Alexandria, who criticized especially his rejection of the title "Theotokos" ("Bringer forth of God") for the Virgin Mary. Nestorius and his teachings were eventually condemned as heretical at the First Council of Ephesus in 431 and the Council of Chalcedon in 451, leading to the Nestorian Schism, in which churches supporting Nestorius broke with the rest of the Christian Church. Following that, many of Nestorius's supporters relocated to the Sasanian Empire, where they affiliated with the local Christian community, known as the Church of the East. Over the next decades the Church of the East became increasingly Nestorian in doctrine, leading to it becoming known alternately as the Nestorian Church.
Nestorianism is a form of dyophysitism, and can be seen as the antithesis to monophysitism, which emerged in reaction to Nestorianism. Where Nestorianism holds that Christ had two loosely united natures, divine and human, monophysitism holds that he had but a single nature, his human nature being absorbed into his divinity. A brief definition of Nestorianism Christology can be given as: "Jesus Christ, who is not identical with the Son but personally united with the Son, who lives in him, is one hypostasis and one nature: human;" This contrasts with Nestorius' own teaching that the Word, which is eternal, and the Flesh, which is not, came together in a hypostatic union who is called Jesus Christ; Jesus Christ thus being both fully man, and God, of two ousias but of one prosopon. Both Nestorianism and monophysitism were condemned as heretical at the Council of Chalcedon. Monophysitism survived and developed into the Miaphysitism of the modern Oriental Orthodox churches.
Following the exodus to Persia, scholars expanded on the teachings of Nestorius and his mentors, particularly after the relocation of the School of Edessa to the Persian city of Nisibis in 489 (where it became known as the School of Nisibis). Nestorianism never again became prominent in the Roman Empire or later Europe, though the diffusion of the Church of the East in and after the 7th century spread it widely across Asia. But not all churches affiliated with the Church of the East appear to have followed Nestorian Christology; indeed, the modern Assyrian Church of the East, which reveres Nestorius, does not follow all historically Nestorian doctrine.
Despite this initial Eastern expansion, the Nestorians' missionary success was eventually deterred. David J Bosch observes
By the end of the fourteenth century, however, the Nestorian and other churches—which at one time had dotted the landscape of all of Central and even parts of East Asia—were all but wiped out. Isolated pockets of Christianity survived only in India. The religious victors on the vast Central Asian mission field of the Nestorians were Islam and Buddhism...
Nestorian doctrine.
Nestorius developed his Christological views as an attempt rationally to explain and understand the incarnation of the divine Logos, the Second Person of the Holy Trinity as the man Jesus Christ. He had studied at the School of Antioch where his mentor had been Theodore of Mopsuestia; Theodore and other Antioch theologians had long taught a literalist interpretation of the Bible and stressed the distinctiveness of the human and divine natures of Jesus. Nestorius took his Antiochene leanings with him when he was appointed Patriarch of Constantinople by Eastern Roman Emperor Theodosius II in 428.
Nestorius' teachings became the root of controversy when he publicly challenged the long-used title "Theotokos" (Bringer forth of God) for the Virgin Mary. He suggested that the title denied Christ's full humanity, arguing instead that Jesus had two persons, the divine Logos and the human Jesus. As a result of this duality, he proposed "Christotokos" (Bringer forth of Christ) as a more suitable title for Mary.
Nestorius' opponents found his teaching too close to the heresy of adoptionism – the idea that Christ had been born a man who had later been "adopted" as God's son. Nestorius was especially criticized by Cyril, Pope (Patriarch) of Alexandria, who argued that Nestorius' teachings undermined the unity of Christ's divine and human natures at the Incarnation. Some of Nestorius' opponents argued that he put too much emphasis on the human nature of Christ, and others debated that the difference that Nestorius implied between the human nature and the divine nature created a fracture in the singularity of Christ, thus creating two Christ figures. Nestorius himself always insisted that his views were orthodox, though they were deemed heretical at the First Council of Ephesus in 431, leading to the Nestorian Schism, when churches supportive of Nestorius and the rest of the Christian Church separated. A more elaborate Nestorian theology developed from there, which came to see Christ as having two natures united, or hypostases, the divine Logos and the human Christ. However, this formulation was never adopted by all churches termed "Nestorian". Indeed, the modern Assyrian Church of the East, which reveres Nestorius, does not fully subscribe to Nestorian doctrine, though it does not employ the title "Theotokos".
Nestorian Schism and early history.
Nestorianism became a distinct sect following the Nestorian Schism, beginning in the 430s. Nestorius had come under fire from Western theologians, most notably Cyril of Alexandria. Cyril had both theological and political reasons for attacking Nestorius; on top of feeling that Nestorianism was an error against true belief, he also wanted to denigrate the head of a competing patriarchate. Cyril and Nestorius asked Pope Celestine I to weigh in on the matter. Celestine found that the title "Theotokos" was orthodox, and authorized Cyril to ask Nestorius to recant. Cyril, however, used the opportunity to further attack Nestorius, who pleaded with Emperor Theodosius II to call a council so that all grievances could be aired.
In 431 Theodosius called the First Council of Ephesus. However, the council ultimately sided with Cyril, holding that Christ is one subsistence and nature, and that the Virgin Mary is the mother of God. The council accused Nestorius of heresy, and deposed him as patriarch. Nestorianism was officially anathematized, a ruling reiterated at the Council of Chalcedon in 451. However, a number of churches, particularly those associated with the School of Edessa, supported Nestorius – though not necessarily his doctrine – and broke with the churches of the West. Many of Nestorius' supporters relocated to Sassanid Persia, home to a vibrant but persecuted Christian minority.
Nestorianism and the Persian Church.
Persia had long been home to a Christian community that had been persecuted by the Zoroastrian majority, which had accused it of Roman leanings. In 424, the Persian Church declared itself independent of the Byzantine and all other churches, in order to ward off allegations of foreign allegiance. Following the Nestorian Schism, the Persian Church increasingly aligned itself with the Nestorians, a measure encouraged by the Zoroastrian ruling class. The Persian Church became increasingly Nestorian in doctrine over the next decades, furthering the divide between Chalcedonian Christianity and the Nestorians. In 486 the Metropolitan of Nisibis, Barsauma, publicly accepted Nestorius' mentor, Theodore of Mopsuestia, as a spiritual authority. In 489 when the School of Edessa in Mesopotamia was closed by Byzantine Emperor Zeno for its Nestorian teachings, the school relocated to its original home of Nisibis, becoming again the School of Nisibis, leading to a wave of Nestorian immigration into Persia. The Persian patriarch Mar Babai I (497–502) reiterated and expanded upon the church's esteem for Theodore, solidifying the church's adoption of Nestorianism.
Now firmly established in Persia, with centers in Nisibis, Ctesiphon, and Gundeshapur, and several metropolitan sees, the Nestorian Persian Church began to branch out beyond the Persian Sassanid Empire. However, through the 6th century the church was frequently beset with internal strife and persecution from the Zoroastrians. The infighting led to a schism, which lasted from 521 until around 539, when the issues were resolved. However, immediately afterward Roman-Persian conflict led to the persecution of the church by the Sassanid King Khosrau I; this ended in 545. The church survived these trials under the guidance of Patriarch Mar Abba I, who had converted to Christianity from Zoroastrianism.
The church emerged stronger after this period of ordeal, and increased missionary efforts farther afield. Missionaries established dioceses in the Arabian Peninsula and India (the Saint Thomas Christians). They made some advances in Egypt, despite the strong Miaphysite (Oriental Orthodox) presence there. Missionaries entered Central Asia and had significant success converting local Turkic tribes. Nestorian missionaries were firmly established in China during the early part of the Tang Dynasty (618–907); the Chinese source known as the Nestorian Stele records a mission under a Persian proselyte named Alopen as introducing Nestorian Christianity to China in 635. Following the Muslim conquest of Persia, completed in 644, the Persian Church became a "dhimmi" community under the Rashidun Caliphate. The church and its communities abroad grew larger under the Caliphate; by the 10th century it had fifteen metropolitan sees within the Caliphate's territories, and another five elsewhere, including in China and India.

</doc>
<doc id="22066" url="https://en.wikipedia.org/wiki?curid=22066" title="NCR">
NCR

NCR may refer to:

</doc>
<doc id="22068" url="https://en.wikipedia.org/wiki?curid=22068" title="Naomi Klein">
Naomi Klein

Naomi Klein (born May 8, 1970) is a Canadian author, social activist, and filmmaker known for her political analyses and criticism of corporate globalization and of corporate capitalism. She first became known internationally for "No Logo" (1999); "The Take", a documentary film about Argentina’s occupied factories that was written by Klein and directed by her husband Avi Lewis; and "The Shock Doctrine" (2007), a critical analysis of the history of neoliberal economics that was adapted into a six-minute companion film by Alfonso and Jonás Cuarón, as well as a feature-length documentary by Michael Winterbottom. "This Changes Everything: Capitalism vs. the Climate" (2014) was a "New York Times" non-fiction bestseller and the winner of the Hilary Weston Writers' Trust Prize for Nonfiction in its year. Klein frequently appears on global and national lists of top influential thinkers, including the 2014 Thought Leaders ranking compiled by the Gottlieb Duttweiler Institute, "Prospect" magazine's world thinkers 2014 poll, and Maclean's 2014 Power List. She is a member of the board of directors of the climate activist group 350.org.
Family.
Naomi Klein was born in Montreal, Quebec, and brought up in a Jewish family with a history of peace activism. Her parents were self-described "hippies" who moved to Montreal from the U.S. in 1967 as war resisters to the Vietnam War. Her mother, documentary film-maker Bonnie Sherr Klein, is best known for her anti-pornography film "Not a Love Story". Her father, Michael Klein, is a physician and a member of Physicians for Social Responsibility. Her brother, Seth Klein, is director of the British Columbia office of the Canadian Centre for Policy Alternatives.
Her paternal grandparents were communists who began to turn against the Soviet Union after the Molotov-Ribbentrop Pact and had abandoned communism by 1956. In 1942, her grandfather Phil Klein, an animator at Disney, was fired after the Disney animators' strike, and went to work at a shipyard instead. Klein's father grew up surrounded by ideas of social justice and racial equality, but found it "difficult and frightening to be the child of Communists", a so-called red diaper baby.
Klein's husband, Avi Lewis, works as a TV journalist and documentary filmmaker. The couple's first child, son Toma, was born on June 13, 2012.
Early life.
Klein spent much of her teenage years in shopping malls, obsessed with designer labels. As a child and teenager, she found it "very oppressive to have a very public feminist mother" and she rejected politics, instead embracing "full-on consumerism".
She has attributed her change in worldview to two events. One was when she was 17 and preparing for the University of Toronto, her mother had a stroke and became severely disabled. Naomi, her father, and her brother took care of Bonnie through the period in hospital and at home, making educational sacrifices to do so. That year off prevented her "from being such a brat". The next year, after beginning her studies at the University of Toronto, the second event occurred: the 1989 École Polytechnique massacre of female engineering students, which proved to be a wake-up call to feminism.
Klein's writing career began with contributions to "The Varsity", a student newspaper, where she served as editor-in-chief. After her third year at the University of Toronto, she dropped out of university to take a job at "The Globe and Mail", followed by an editorship at "This Magazine". In 1995, she returned to the University of Toronto with the intention of finishing her degree but left academia for a journalism internship before acquiring the final credits required to complete her degree.
Works.
"No Logo".
In 2000, Klein published the book "No Logo", which for many became a manifesto of the anti-corporate globalization movement. In it, she attacks brand-oriented consumer culture and the operations of large corporations. She also accuses several such corporations of unethically exploiting workers in the world's poorest countries in pursuit of greater profits. In this book, Klein criticized Nike so severely that Nike published a point-by-point response. "No Logo" became an international bestseller, selling over one million copies in over 28 languages.
"Fences and Windows".
Klein's "Fences and Windows" (2002) is a collection of her articles and speeches written on behalf of the anti-globalization movement (all proceeds from the book go to benefit activist organizations through The Fences and Windows Fund).
"The Take".
Klein and her husband, Avi Lewis made a documentary film called "The Take" (2004) about factory workers in Argentina who took over a closed plant and resumed production, operating as a collective. The first African screening was in the Kennedy Road shack settlement in the South African city of Durban, where the Abahlali baseMjondolo movement began.
An article in "Z Communications" criticized "The Take" for its portrayal of the Argentine general and politician Juan Domingo Perón arguing that he was falsely portrayed as a social democrat.
"The Shock Doctrine".
Klein's third book, "The Shock Doctrine: The Rise of Disaster Capitalism", was published on September 4, 2007. The book argues that the free market policies of Nobel Laureate Milton Friedman and the Chicago School of Economics have risen to prominence in countries such as Chile, under Pinochet, Poland, Russia, under Yeltsin, and the United States (for example, the privatization of the New Orleans Public Schools after Hurricane Katrina). The book also argues that policy initiatives (for instance, the privatization of Iraq's economy under the Coalition Provisional Authority) were rushed through while the citizens of these countries were in shock from disasters, upheavals, or invasion. The book became an international and New York Times bestseller translated into 28 languages.
Central to the book's thesis is the contention that those who wish to implement unpopular free market policies now routinely do so by taking advantage of certain features of the aftermath of major disasters, be they economic, political, military or natural. The suggestion is that when a society experiences a major 'shock' there is a widespread desire for a rapid and decisive response to correct the situation; this desire for bold and immediate action provides an opportunity for unscrupulous actors to implement policies which go far beyond a legitimate response to disaster. The book suggests that when the rush to act means the specifics of a response will go unscrutinized, that is the moment when unpopular and unrelated policies will intentionally be rushed into effect. The book appears to claim that these shocks are in some cases intentionally encouraged or even manufactured.
Klein identifies the "shock doctrine", elaborating on Joseph Schumpeter, as the latest in capitalism's phases of "creative destruction".
"The Shock Doctrine" was adapted into a short film of the same name, released onto YouTube. The film was directed by Jonás Cuarón, produced and co-written by his father Alfonso Cuarón. The video has been viewed over one million times.
The publication of "The Shock Doctrine" increased Klein's prominence, with the "New Yorker" judging her "the most visible and influential figure on the American left—what Howard Zinn and Noam Chomsky were thirty years ago." On February 24, 2009, the book was awarded the inaugural Warwick Prize for Writing from the University of Warwick in England. The prize carried a cash award of £50,000.
"This Changes Everything: Capitalism vs. the Climate".
Klein's fourth book, "This Changes Everything: Capitalism vs. the Climate" was published in September 2014. The book puts forth the argument that the hegemony of neoliberal market fundamentalism is blocking any serious reforms to halt climate change and protect the environment. Questioned about Klein's claim that capitalism and controlling climate change were incompatible, Benoit Blarel, manager of the Environment and Natural Resources global practice at the World Bank, said that the write-off of fossil fuels necessary to control climate change "will have a huge impact all over" and that the World Bank was "starting work on this". The book won the 2014 Hilary Weston Writers' Trust Prize for Nonfiction, and was a shortlisted nominee for the 2015 Shaughnessy Cohen Prize for Political Writing.
Iraq War criticism.
Klein has written on various current issues, such as the Iraq War. In a September 2004 article for "Harper's Magazine", she argues that, contrary to popular belief, the Bush administration did have a clear plan for post-invasion Iraq, which was to build a completely unconstrained free market economy. She describes plans to allow foreigners to extract wealth from Iraq, and the methods used to achieve those goals. The film "War, Inc." (2008) was partially inspired by her article, "Baghdad Year Zero".
Klein's August 2004 "Bring Najaf to New York", published in "The Nation", argued that Muqtada Al Sadr's Mahdi Army "represents the overwhelmingly mainstream sentiment in Iraq." She went on to say "Yes, if elected Sadr would try to turn Iraq into a theocracy like Iran, but for now his demands are for direct elections and an end to foreign occupation". Marc Cooper, a former "Nation" columnist, attacked the assertion that Al Sadr represented mainstream Iraqi sentiment and that American forces had brought the fight to the holy city of Najaf. Cooper wrote that "Klein should know better. All enemies of the U.S. occupation she opposes are not her friends. Or ours. Or those of the Iraqi people. I don’t think that Mullah Al Sadr, in any case, is much desirous of support issuing from secular Jewish feminist-socialists."
Criticism of Israeli policies.
In March 2008, Klein was the keynote speaker at the first national conference of the Alliance of Concerned Jewish Canadians. In January 2009, during the Gaza War, Klein supported the Boycott, Divestment and Sanctions (BDS) campaign against Israel, arguing that "the best strategy to end the increasingly bloody occupation is for Israel to become the target of the kind of global movement that put an end to apartheid in South Africa."
In summer 2009, on the occasion of the publication of the Hebrew translation of her book "The Shock Doctrine", Klein visited Israel, the West Bank, and Gaza, combining the promotion of her book and the BDS campaign. In an interview to the Israeli newspaper "Haaretz" she emphasized that it is important to her "not to boycott Israelis but rather to boycott the normalization of Israel and the conflict." In a speech in Ramallah on June 27, she apologized to the Palestinians for not joining the BDS campaign earlier. Her remarks, particularly that "Jews even think we get one get-away-with-genocide-free-card" were characterized by an op-ed columnist in "The Jerusalem Post" as "violent" and "unethical", and as the "most perverse of aspersions on Jews, an age-old stereotype of Jews as intrinsically evil and malicious."
Klein was also a spokesperson for the protest against the spotlight on Tel Aviv at the 2009 Toronto International Film Festival, a spotlight that Klein said was a very selective and misleading portrait of Israel.
Environmentalism.
Since 2009, Klein’s attention has turned to environmentalism, with particular focus on climate change, the subject of her book "This Changes Everything" (2014). According to her website, the book and its accompanying film (released in 2015) will be about "how the climate crisis can spur economic and political transformation." She sits on the board of directors of campaign group 350.org and took part in their "Do the Math" tour in 2013, encouraging a divestment movement.
She has encouraged the Occupy movement to join forces with the environmental movement, saying the financial crisis and the climate crisis have the same root—unrestrained corporate greed. She gave a speech at Occupy Wall Street where she described the world as "upside down", where we act as if "there is no end to what is actually finite—fossil fuels and the atmospheric space to absorb their emissions," and as if there are "limits to what is actually bountiful—the financial resources to build the kind of society we need."
She has been a particularly vocal critic of the Athabasca oil sands in Alberta, describing it in a TED talk as a form of "terrestrial skinning." On September 2, 2011, she attended the demonstration against the Keystone XL pipeline outside the White House and was arrested. Klein celebrated Obama’s decision to postpone a decision on the Keystone pipeline until 2013 pending an environmental review as a victory for the environmental movement.
She attended the Copenhagen Climate Summit of 2009. She put the blame for the failure of Copenhagen on Barack Obama, and described her own country, Canada, as a "climate criminal." She presented the Angry Mermaid Award (a satirical award designed to recognise the corporations who have best sabotaged the climate negotiations) to Monsanto.
Writing in the wake of Hurricane Sandy she warned that the climate crisis constitutes a massive opportunity for disaster capitalists and corporations seeking to profit from crisis. But equally, the climate crisis "can be a historic moment to usher in the next great wave of progressive change," or a so-called "People's Shock."
Other activities.
Klein contributes to "The Nation", "In These Times", "The Globe and Mail", "This Magazine", "Harper's Magazine", and "The Guardian". She is a former Miliband Fellow and lectured at the London School of Economics on the anti-globalisation movement.
Klein ranked 11th in an internet poll of the top global intellectuals of 2005, a list of the world's top 100 public intellectuals compiled by the "Prospect" magazine in conjunction with "Foreign Policy" magazine. She was involved in 2010 G-20 Toronto summit protests, condemning police force and brutality. She spoke to a rally seeking the release of protesters in front of police headquarters on June 28, 2010.
In May 2011, Klein received an honorary degree from Saint Thomas University. On October 6, 2011, she visited Occupy Wall Street and gave a speech declaring the protest movement "the most important thing in the world". On November 10, 2011, she participated in a panel discussion about the future of Occupy Wall Street with four other panelists, including Michael Moore, William Greider, and Rinku Sen, in which she stressed the crucial nature of the evolving movement.

</doc>
<doc id="22071" url="https://en.wikipedia.org/wiki?curid=22071" title="Nonsteroidal anti-inflammatory drug">
Nonsteroidal anti-inflammatory drug

Nonsteroidal anti-inflammatory drugs (usually abbreviated to NSAIDs ), also called nonsteroidal anti-inflammatory agents/analgesics (NSAIAs) or nonsteroidal anti-inflammatory medicines (NSAIMs), are a drug class that groups together drugs that provide analgesic (pain-killing) and antipyretic (fever-reducing) effects, and, in higher doses, anti-inflammatory effects.
The term "nonsteroidal" distinguishes these drugs from steroids, which, among a broad range of other effects, have a similar eicosanoid-depressing, anti-inflammatory action. First used in 1960, the term served to distance new drugs from steroid related iatrogenic tragedies.
As analgesics, NSAIDs are unusual in that they are non-narcotic and thus are used as a non-addictive alternative to narcotics.
The most prominent members of this group of drugs, aspirin, ibuprofen and naproxen, are all available over the counter in most countries. Paracetamol (acetaminophen) is generally not considered an NSAID because it has only little anti-inflammatory activity. It treats pain mainly by blocking COX-2 mostly in the central nervous system, but not much in the rest of the body.
Most NSAIDs inhibit the activity of cyclooxygenase-1 (COX-1) and cyclooxygenase-2 (COX-2), and thereby, the synthesis of prostaglandins and thromboxanes. It is thought that inhibiting COX-2 leads to the anti-inflammatory, analgesic and antipyretic effects and that those NSAIDs also inhibiting COX-1, particularly aspirin, may cause gastrointestinal bleeding and ulcers.
Medical uses.
NSAIDs are usually used for the treatment of acute or chronic conditions where pain and inflammation are present.
NSAIDs are generally used for the symptomatic relief of the following conditions:
Aspirin, the only NSAID able to irreversibly inhibit COX-1, is also indicated for inhibition of platelet aggregation. This is useful in the management of arterial thrombosis and prevention of adverse cardiovascular events. Aspirin inhibits platelet aggregation by inhibiting the action of thromboxane A2.
Contraindications.
NSAIDs may be used with caution by people with the following conditions:
NSAIDs should usually be avoided by people with the following conditions:
Adverse effects.
The widespread use of NSAIDs has meant that the adverse effects of these drugs have become increasingly common. Use of NSAIDs increases risk of having a range of gastrointestinal (GI) problems. When NSAIDs are used for pain management after surgery they cause increased risk of kidney problems.
An estimated 10–20% of NSAID patients experience dyspepsia. In the 1990s high doses of prescription NSAIDs were associated with serious upper gastrointestinal adverse events, including bleeding. Over the past decade, deaths associated with gastric bleeding have declined.
NSAIDs, like all drugs, may interact with other medications. For example, concurrent use of NSAIDs and quinolones may increase the risk of quinolones' adverse central nervous system effects, including seizure.
Combinational risk.
If a COX-2 inhibitor is taken, a traditional NSAID (prescription or over-the-counter) should not be taken at the same time. In addition, people on daily aspirin therapy (e.g., for reducing cardiovascular risk) must be careful if they also use other NSAIDs, as these may inhibit the cardioprotective effects of aspirin.
Rofecoxib (Vioxx) was shown to produce significantly fewer gastrointestinal adverse drug reactions (ADRs) compared with naproxen. This study, the VIGOR trial, raised the issue of the cardiovascular safety of the coxibs. A statistically significant increase in the incidence of myocardial infarctions was observed in patients on rofecoxib. Further data, from the APPROVe trial, showed a statistically significant relative risk of cardiovascular events of 1.97 versus placebo—which caused a worldwide withdrawal of rofecoxib in October 2004.
Use of methotrexate together with NSAIDS in rheumatoid arthritis is safe, if adequate monitoring is done.
Cardiovascular.
NSAIDs aside from aspirin, both newer selective COX-2 inhibitors and traditional anti-inflammatories, increase the risk of myocardial infarction and stroke. They are not recommended in those who have had a previous heart attack as they increase the risk of death and/or recurrent MI. Evidence indicates that naproxen may be the least harmful out of these.
NSAIDs aside from (low-dose) aspirin are associated with a doubled risk of heart failure in people without a history of cardiac disease. In people with such a history, use of NSAIDs (aside from low-dose aspirin) was associated with a more than 10-fold increase in heart failure. If this link is proven causal, researchers estimate that NSAIDs would be responsible for up to 20 percent of hospital admissions for congestive heart failure. In people with heart failure, NSAIDs increase mortality risk (hazard ratio) by approximately 1.2–1.3 for naproxen and ibuprofen, 1.7 for rofecoxib and celecoxib, and 2.1 for diclofenac.
On 9 July 2015, the FDA toughened warnings of increased heart attack and stroke risk associated with nonsteroidal anti-inflammatory drugs (NSAID). Aspirin is an NSAID but is not affected by the new warnings.
Possible erectile dysfunction risk.
A 2005 Finnish study linked long term (over 3 months) use of NSAIDs with an increased risk of erectile dysfunction. This study was correlational only, and depended solely on self-reports (questionnaires).
A 2011 publication in the Journal of Urology received widespread publicity. According to this study, men who used NSAIDs regularly were at significantly increased risk of erectile dysfunction. A link between NSAID use and erectile dysfunction still existed after controlling for several conditions. However, the study was observational and not controlled, with low original participation rate, potential participation bias, and other uncontrolled factors. The authors warned against drawing any conclusion regarding cause.
Gastrointestinal.
The main adverse drug reactions (ADRs) associated with NSAID use relate to direct and indirect irritation of the gastrointestinal (GI) tract. NSAIDs cause a dual assault on the GI tract: the acidic molecules directly irritate the gastric mucosa, and inhibition of COX-1 and COX-2 reduces the levels of protective prostaglandins. Inhibition of prostaglandin synthesis in the GI tract causes increased gastric acid secretion, diminished bicarbonate secretion, diminished mucus secretion and diminished trophic effects on epithelial mucosa.
Common gastrointestinal ADRs include:
Clinical NSAID ulcers are related to the systemic effects of NSAID administration. Such damage occurs irrespective of the route of administration of the NSAID (e.g., oral, rectal, or parenteral) and can occur even in patients with achlorhydria.
Ulceration risk increases with therapy duration, and with higher doses. To minimise GI ADRs, it is prudent to use the lowest effective dose for the shortest period of time—a practice that studies show is often not followed. Recent studies show that over 50% of patients who take NSAIDs have sustained some mucosal damage to their small intestine.
There are also some differences in the propensity of individual agents to cause gastrointestinal ADRs. Indomethacin, ketoprofen and piroxicam appear to have the highest prevalence of gastric ADRs, while ibuprofen (lower doses) and diclofenac appear to have lower rates.
Certain NSAIDs, such as aspirin, have been marketed in enteric-coated formulations that manufacturers claim reduce the incidence of gastrointestinal ADRs. Similarly, some believe that rectal formulations may reduce gastrointestinal ADRs. However, consistent with the systemic mechanism of such ADRs, and in clinical practice, these formulations have not demonstrated a reduced risk of GI ulceration.
Commonly, gastric (but not necessarily intestinal) adverse effects can be reduced through suppressing acid production, by concomitant use of a proton pump inhibitor, e.g., omeprazole, esomeprazole; or the prostaglandin analogue misoprostol. Misoprostol is itself associated with a high incidence of gastrointestinal ADRs (diarrhea). While these techniques may be effective, they are expensive for maintenance therapy.
Inflammatory bowel disease.
NSAIDs should be used with caution in individuals with inflammatory bowel disease (e.g., Crohn's disease or ulcerative colitis) due to their tendency to cause gastric bleeding and form ulceration in the gastric lining. Pain relievers such as paracetamol (also known as acetaminophen) or drugs containing codeine (which slows down bowel activity) are safer medications for pain relief in IBD.
Renal.
NSAIDs are also associated with a fairly high incidence of renal adverse drug reactions (ADRs). The mechanism of these renal ADRs is due to changes in renal haemodynamics (kidney blood flow), ordinarily mediated by prostaglandins, which are affected by NSAIDs. Prostaglandins normally cause vasodilation of the afferent arterioles of the glomeruli. This helps maintain normal glomerular perfusion and glomerular filtration rate (GFR), an indicator of renal function. This is particularly important in renal failure where the kidney is trying to maintain renal perfusion pressure by elevated angiotensin II levels. At these elevated levels, angiotensin II also constricts the afferent arteriole into the glomerulus in addition to the efferent arteriole it normally constricts. Prostaglandins serve to dilate the afferent arteriole; by blocking this prostaglandin-mediated effect, particularly in renal failure, NSAIDs cause unopposed constriction of the afferent arteriole and decreased RPF (renal perfusion pressure).
Common ADRs associated with altered renal function include:
These agents may also cause renal impairment, especially in combination with other nephrotoxic agents. Renal failure is especially a risk if the patient is also concomitantly taking an ACE inhibitor (which removes angiotensin II's vasoconstriction of the efferent arteriole) and a diuretic (which drops plasma volume, and thereby RPF)—the so-called "triple whammy" effect.
In rarer instances NSAIDs may also cause more severe renal conditions:
NSAIDs in combination with excessive use of phenacetin and/or paracetamol (acetaminophen) may lead to analgesic nephropathy.
Photosensitivity.
Photosensitivity is a commonly overlooked adverse effect of many of the NSAIDs. The 2-arylpropionic acids are the most likely to produce photosensitivity reactions, but other NSAIDs have also been implicated including piroxicam, diclofenac and benzydamine.
Benoxaprofen, since withdrawn due to its hepatotoxicity, was the most photoactive NSAID observed. The mechanism of photosensitivity, responsible for the high photoactivity of the 2-arylpropionic acids, is the ready decarboxylation of the carboxylic acid moiety. The specific absorbance characteristics of the different chromophoric 2-aryl substituents, affects the decarboxylation mechanism. While ibuprofen has weak absorption, it has been reported as a weak photosensitising agent.
During pregnancy.
NSAIDs are not recommended during pregnancy, particularly during the third trimester. While NSAIDs as a class are not direct teratogens, they may cause premature closure of the fetal ductus arteriosus and renal ADRs in the fetus. Additionally, they are linked with premature birth and miscarriage. Aspirin, however, is used together with heparin in pregnant women with antiphospholipid antibodies. Additionally, Indomethacin is used in pregnancy to treat polyhydramnios by reducing fetal urine production via inhibiting fetal renal blood flow.
In contrast, paracetamol (acetaminophen) is regarded as being safe and well-tolerated during pregnancy, but Leffers et al. released a study in 2010 indicating that there may be associated male infertility in the unborn. Doses should be taken as prescribed, due to risk of hepatotoxicity with overdoses.
In France, the country's health agency contraindicates the use of NSAIDs, including aspirin, after the sixth month of pregnancy.
Allergy/allergy-like hypersensitivity reactions.
A variety of allergic or allergic-like NSAID hypersensitivity reactions follow the ingestion of NSAIDs. These hypersensitivity reactions differ from the other adverse reactions listed here which are toxicity reactions, i.e. unwanted reactions that result from the pharmacological action of a drug, are dose-related, and can occur in any treated individual; hypersensitivity reactions are idiosyncratic reactions to a drug. Some NSAID hypersensitivity reactions are truly allergic in origin: 1) repetitive IgE-mediated urticarial skin eruptions, angioedema, and anaphylaxis following immediately to hours after ingesting one structural type of NSAID but not after ingesting structurally unrelated NSAIDs; and 2) Comparatively mild to moderately severe T cell-mediated delayed onset (usually more than 24 hour), skin reactions such as maculopapular rash, fixed drug eruptions, photosensitivity reactions, delayed urticaria, and contact dermatitis; or 3) far more severe and potentially life-threatening t-cell mediated delayed systemic reactions such as the DRESS syndrome, acute generalized exanthematous pustulosis, the Stevens–Johnson syndrome, and toxic epidermal necrolysis. Other NSAID hypersensitivity reactions are allergy-like symptoms but do not involve true allergic mechanisms; rather, they appear due to the ability of NSAIDs to alter the metabolism of arachidonic acid in favor of forming metabolites that promote allergic symptoms. Afflicted individuals may be abnormally sensitive to these provocative metabolites and/or overproduce them and typically are susceptible to a wide range of structurally dissimilar NSAIDs, particularly those that inhibit COX1. Symptoms, which develop immediately to hours after ingesting any of various NSAIDs that inhibit COX-1, are: 1) exacerbations of asthmatic and rhinitis (see aspirin-induced asthma) symptoms in individuals with a history of asthma or rhinitis and 2) exacerbation or first-time development of wheals and/or angioedema in individuals with or without a history of chronic urticarial lesions or angioedema.
Other.
Common adverse drug reactions (ADR), other than listed above, include: raised liver enzymes, headache, dizziness. Uncommon ADRs include: hyperkalaemia, confusion, bronchospasm, rash. Rapid and severe swelling of the face and/or body. Ibuprofen may also rarely cause irritable bowel syndrome symptoms. NSAIDs are also implicated in some cases of Stevens–Johnson syndrome.
Most NSAIDs penetrate poorly into the central nervous system (CNS). However, the COX enzymes are expressed constitutively in some areas of the CNS, meaning that even limited penetration may cause adverse effects such as somnolence and dizziness.
In very rare cases, ibuprofen can cause aseptic meningitis.
As with other drugs, allergies to NSAIDs might exist. While many allergies are specific to one NSAID, up to 1 in 5 people may have unpredictable cross-reactive allergic responses to other NSAIDs as well.
Drug interactions.
NSAIDs reduce renal blood flow and thereby decrease the efficacy of diuretics, and inhibit the elimination of lithium and methotrexate.
NSAIDs cause hypocoagulability, which may be serious when combined with other drugs that also decrease blood clotting, such as warfarin.
NSAIDs may aggravate hypertension (high blood pressure) and thereby antagonize the effect of antihypertensives, such as ACE Inhibitors.
NSAIDs may interfere and reduce efficiency of SSRI antidepressants.
Various widely used nonsteroidal anti-inflammatory drugs (NSAIDs) enhance endocannabinoid signaling by blocking the anandamide-degrading membrane enzyme fatty acid amide hydrolase (FAAH).
Mechanism of action.
Most NSAIDs act as nonselective inhibitors of the enzyme cyclooxygenase (COX), inhibiting both the cyclooxygenase-1 (COX-1) and cyclooxygenase-2 (COX-2) isoenzymes. This inhibition is competitively reversible (albeit at varying degrees of reversibility), as opposed to the mechanism of aspirin, which is irreversible inhibition. COX catalyzes the formation of prostaglandins and thromboxane from arachidonic acid (itself derived from the cellular phospholipid bilayer by phospholipase A2). Prostaglandins act (among other things) as messenger molecules in the process of inflammation. This mechanism of action was elucidated by John Vane (1927–2004), who received a Nobel Prize for his work (see Mechanism of action of aspirin).
COX-1 is a constitutively expressed enzyme with a "house-keeping" role in regulating many normal physiological processes. One of these is in the stomach lining, where prostaglandins serve a protective role, preventing the stomach mucosa from being eroded by its own acid. COX-2 is an enzyme facultatively expressed in inflammation, and it is inhibition of COX-2 that produces the desirable effects of NSAIDs.
When nonselective COX-1/COX-2 inhibitors (such as aspirin, ibuprofen, and naproxen) lower stomach prostaglandin levels, ulcers of the stomach or duodenum internal bleeding can result.
NSAIDs have been studied in various assays to understand how they affect each of these enzymes. While the assays reveal differences, unfortunately different assays provide differing ratios.
The discovery of COX-2 led to research to development of selective COX-2 inhibiting drugs that do not cause gastric problems characteristic of older NSAIDs.
Paracetamol (acetaminophen) is not considered an NSAID because it has little anti-inflammatory activity. It treats pain mainly by blocking COX-2 mostly in the central nervous system, but not much in the rest of the body.
However, many aspects of the mechanism of action of NSAIDs remain unexplained, and for this reason further COX pathways are hypothesized. The COX-3 pathway was believed to fill some of this gap but recent findings make it appear unlikely that it plays any significant role in humans and alternative explanation models are proposed.
NSAIDs are also used in the acute pain caused by gout because they inhibit urate crystal phagocytosis besides inhibition of prostaglandin synthase.
Antipyretic activity.
NSAIDS have antipyretic activity and can be used to treat fever. Fever is caused by elevated levels of prostaglandin E2, which alters the firing rate of neurons within the hypothalamus that control thermoregulation. Antipyretics work by inhibiting the enzyme COX, which causes the general inhibition of prostanoid biosynthesis (PGE2) within the hypothalamus. PGE2 signals to the hypothalamus to increase the body's thermal set point. Ibuprofen has been shown more effective as an antipyretic than paracetamol (acetaminophen).
Arachidonic acid is the precursor substrate for cyclooxygenase leading to the production of prostaglandins F, D & E.
Classification.
NSAIDs can be classified based on their chemical structure or mechanism of action. Older NSAIDs were known long before their mechanism of action was elucidated and were for this reason classified by chemical structure or origin. Newer substances are more often classified by mechanism of action.
Anthranilic acid derivatives (Fenamates).
The following NSAIDs are derived from fenamic acid. which is a derivative of anthranilic acid, which in turn is a nitrogen isostere of salicylic acid, which is the active metabolite of aspirin.
Chirality.
Most NSAIDs are chiral molecules (diclofenac is a notable exception). However, the majority are prepared in a racemic mixture. Typically, only a single enantiomer is pharmacologically active. For some drugs (typically profens), an isomerase enzyme "in vivo" converts the inactive enantiomer into the active form, although its activity varies widely in individuals. This phenomenon is likely responsible for the poor correlation between NSAID efficacy and plasma concentration observed in older studies, when specific analysis of the active enantiomer was not performed.
Ibuprofen and ketoprofen are now available in single, active enantiomer preparations (dexibuprofen and dexketoprofen), which purport to offer quicker onset and an improved side-effect profile. Naproxen has always been marketed as the single active enantiomer.
Main practical differences.
NSAIDs within a group tend to have similar characteristics and tolerability. There is little difference in clinical efficacy among the NSAIDs when used at equivalent doses. Rather, differences among compounds usually relate to dosing regimens (related to the compound's elimination half-life), route of administration, and tolerability profile.
Regarding adverse effects, selective COX-2 inhibitors have lower risk of gastrointestinal bleeding, but a substantially more increased risk of myocardial infarction than the increased risk from nonselective inhibitors. Some data also supports that the partially selective nabumetone is less likely to cause gastrointestinal events. The nonselective naproxen appears risk-neutral with regard to cardiovascular events.
A consumer report noted that ibuprofen, naproxen, and salsalate are less expensive than other NSAIDs, and essentially as effective and safe when used appropriately to treat osteoarthritis and pain.
Pharmacokinetics.
Most nonsteroidal anti-inflammatory drugs are weak acids, with a pKa of 3–5. They are absorbed well from the stomach and intestinal mucosa. They are highly protein-bound in plasma (typically >95%), usually to albumin, so that their volume of distribution typically approximates to plasma volume. Most NSAIDs are metabolised in the liver by oxidation and conjugation to inactive metabolites that typically are excreted in the urine, though some drugs are partially excreted in bile. Metabolism may be abnormal in certain disease states, and accumulation may occur even with normal dosage.
Ibuprofen and diclofenac have short half-lives (2–3 hours). Some NSAIDs (typically oxicams) have very long half-lives (e.g. 20–60 hours).
History.
From the era of Greek medicine to the mid-19th century, the discovery of medicinal agents was classed as an empirical art; folklore and mythological guidance were combined in deploying the vegetable and mineral products that made up the expansive pharmacopoeia of the time. Myrtle leaves were in use by 1500 BCE. Hippocrates (460–377 BCE) first reported using willow bark and in 30 BCE Celsus described the signs of inflammation and also used willow bark to mitigate them. On 25 April 1763, Edward Stone wrote to the Royal Society describing his observations on the use of willow bark-based medicines in febrile patients. The active ingredient of willow bark, a glycoside called salicin, was first isolated by Johann Andreas Buchner in 1827. By 1829, French chemist Henri Leroux had improved the extraction process to obtain about 30g of purified salicin from 1.5 kg of bark.
By hydrolysis, salicin releases glucose and salicylic alcohol which can be converted into salicylic acid, both in vivo and through chemical methods. The acid is more effective than salicin and, in addition to its fever-reducing properties, is anti-inflammatory and analgesic. In 1869, Hermann Kolbe synthesised salicylate, although it was too acidic for the gastric mucosa. The reaction used to synthesise aromatic acid from a phenol in the presence of CO2 is known as the Kolbe-Schmitt reaction.
By 1897 the German chemist Felix Hoffmann and the Bayer company prompted a new age of pharmacology by converting salicylic acid into acetylsalicylic acid—named aspirin by Heinrich Dreser. Other NSAIDs were developed from the 1950s forward.
In 2001, NSAIDs accounted for 70,000,000 prescriptions and 30 billion over-the-counter doses sold annually in the United States.
Veterinary use.
Research supports the use of NSAIDs for the control of pain associated with veterinary procedures such as dehorning and castration of calves. The best effect is obtained by combining a short-term local anesthetic such as lidocaine with an NSAID acting as a longer term analgesic. However, as different species have varying reactions to different medications in the NSAID family, little of the existing research data can be extrapolated to animal species other than those specifically studied, and the relevant government agency in one area sometimes prohibits uses approved in other jurisdictions.
For example, ketoprofen's effects have been studied in horses more than in ruminants but, due to controversy over its use in racehorses, veterinarians who treat livestock in the United States more commonly prescribe flunixin meglumine, which, while labeled for use in such animals, is not indicated for post-operative pain.
In the United States, meloxicam is approved for use only in canines, whereas (due to concerns about liver damage) it carries warnings against its use in cats except for one-time use during surgery. In spite of these warnings, meloxicam is frequently prescribed "off-label" for non-canine animals including cats and livestock species. In other countries, for example The European Union (EU), there is a label claim for use in cats.

</doc>
<doc id="22073" url="https://en.wikipedia.org/wiki?curid=22073" title="NC (complexity)">
NC (complexity)

In complexity theory, the class NC (for "Nick's Class") is the set of decision problems decidable in polylogarithmic time on a parallel computer with a polynomial number of processors. In other words, a problem is in NC if there exist constants "c" and "k" such that it can be solved in time "O"(log"c" "n") using "O"("n""k") parallel processors. Stephen Cook coined the name "Nick's class" after Nick Pippenger, who had done extensive research on circuits with polylogarithmic depth and polynomial size.
Just as the class P can be thought of as the tractable problems (Cobham's thesis), so NC can be thought of as the problems that can be efficiently solved on a parallel computer. NC is a subset of P because polylogarithmic parallel computations can be simulated by polynomial-time sequential ones. It is unknown whether NC = P, but most researchers suspect this to be false, meaning that there are probably some tractable problems that are "inherently sequential" and cannot significantly be sped up by using parallelism. Just as the class NP-complete can be thought of as "probably intractable", so the class P-complete, when using NC reductions, can be thought of as "probably not parallelizable" or "probably inherently sequential".
The parallel computer in the definition can be assumed to be a "parallel, random-access machine" (PRAM). That is a parallel computer with a central pool of memory, and any processor can access any bit of memory in constant time. The definition of NC is not affected by the choice of how the PRAM handles simultaneous access to a single bit by more than one processor. It can be CRCW, CREW, or EREW. See PRAM for descriptions of those models.
Equivalently, NC can be defined as those decision problems decidable by a uniform Boolean circuit (which can be calculated from the length of the input) with polylogarithmic depth and a polynomial number of gates.
RNC is a class extending NC with access to randomness.
Problems in NC.
As with P, by a slight abuse of language, one might classify function problems and search problems as being in NC. NC is known to include many problems, including
Often algorithms for those problems had to be separately invented and could not be naïvely adapted from well-known algorithms – Gaussian elimination and Euclidean algorithm rely on operations performed in sequence. One might contrast ripple carry adder with a carry-lookahead adder.
The NC hierarchy.
NC"i" is the class of decision problems decidable by uniform boolean circuits with a polynomial number of gates of at most two inputs and depth "O"(log"i" "n"), or the class of decision problems solvable in time "O"(log"i" "n") on a parallel computer with a polynomial number of processors. Clearly, we have
which forms the NC-hierarchy.
We can relate the NC classes to the space classes L and NL and AC.
The NC classes are related to the AC classes, which are defined similarly, but with gates having unbounded fan-in. For each "i", we have
As an immediate consequence of this, we have that NC = AC.
It is known that both inclusions are strict for "i" = 0.
Similarly, we have that NC is equivalent to the problems solvable on an alternating Turing machine restricted to at most two options at each step with "O"(log "n") space and formula_4 alternations.
Open problem: Is NC proper?
One major open question in complexity theory is whether or not every containment in the NC hierarchy is proper. It was observed by Papadimitriou that, if NC"i" = NC"i"+1 for some "i", then NC"i" = NC"j" for all "j" ≥ "i", and as a result, NC"i" = NC. This observation is known as NC-hierarchy collapse because even a single equality in the chain of containments
implies that the entire NC hierarchy "collapses" down to some level "i". Thus, there are 2 possibilities:
It is widely believed that (1) is the case, although no proof as to the truth of either statement has yet been discovered.
Barrington's theorem.
A branching program with "n" variables of width "k" and length "m" consists of a sequence of "m" instructions. Each of the instructions is a tuple ("i", "p", "q") where "i" is the index of variable to check (1 ≤ "i" ≤ "n"), and "p" and "q" are functions from {1, 2, ..., "k"} to {1, 2, ..., "k"}. Numbers 1, 2, ..., "k" are called states of the branching program. The program initially starts in state 1, and each instruction ("i", "p", "q") changes the state from "x" to "p"("x") or "q"("x"), depending on whether the "i"th variable is 0 or 1.
A family of branching programs consists of a branching program with "n" variables for each "n".
It is easy to show that every language "L" on {0,1} can be recognized by a family of branching programs of width 4 and exponential length, or by a family of exponential width and linear length.
Every regular language on {0,1} can be recognized by a family of branching programs of constant width and linear number of instructions (since a DFA can be converted to a branching program). BWBP denotes the class of languages recognizable by a family of branching programs of bounded width and polynomial length.
Barrington's theorem says that is exactly nonuniform NC1. The proof uses the nonsolvability of the symmetric group S5.
The theorem is rather surprising. For instance, it implies that the majority function can be computed by a family of branching programs of constant width and polynomial size, while intuition might suggest that to achieve polynomial size, one needs a linear number of states. 
Proof of Barrington's theorem.
A branching program of constant width and polynomial size can be easily converted (via divide-and-conquer) to a circuit in NC1.
Conversely, suppose a circuit in NC1 is given. Without loss of generality, assume it uses only AND and NOT gates.
Lemma 1: If there exists a branching program that sometimes works as a permutation "P" and sometimes as a permutation "Q", by right-multiplying permutations in the first instruction by α, and in the last instruction left-multiplying by β, we can make a circuit of the same length that behaves as β"P"α or β"Q"α, respectively.
Call a branching program α-computing a circuit "C" if it works as identity when C's output is 0, and as α when C's output is 1.
As a consequence of Lemma 1 and the fact that all cycles of length 5 are conjugate, for any two 5-cycles α, β, if there exists a branching program α-computing a circuit "C", then there exists a branching program β-computing the circuit "C", of the same length.
Lemma 2: There exist 5-cycles γ, δ such that their commutator ε=γδγ-1δ-1 is a 5-cycle. For example, γ = (1 2 3 4 5), δ = (1 3 5 4 2) giving ε = (1 3 2 5 4).
We will now prove Barrington's theorem by induction: 
Suppose we have a circuit "C" which takes inputs "x"1...,"x"n and assume that for all subcircuits "D" of "C" and 5-cycles α, there exists a branching program α-computing "D". We will show that for all 5-cycles α, there exists a branching program α-computing "C".
By assuming the subcircuits have branching programs so that they are α-computing for all 5-cycles α∈"S"5, we have shown "C" also has this property, as required.
The size of the branching program is at most 4d, where "d" is the depth of the circuit. If the circuit has logarithmic depth, the branching program has polynomial length.

</doc>
<doc id="22076" url="https://en.wikipedia.org/wiki?curid=22076" title="Nori">
Nori

Pyropia is also called "laver" in Wales and other English-speaking countries.
History.
Originally, the term "nori" was generic and referred to seaweeds including "hijiki". One of the oldest descriptions of nori is dated to around the 8th century. In the Taihō Code enacted in 701, "nori" was already included in the form of taxation. Local people have been described as drying nori in Hitachi Province Fudoki (721–721), and nori was harvested in Izumo Province Fudoki (713–733), showing that nori was used as food from ancient times. In "Utsubo Monogatari", written around 987, "nori" was recognized as a common food. Nori had been consumed as paste form until the sheet form was invented in Asakusa, Edo (contemporary Tokyo), around 1750 in the Edo period through the method of Japanese paper-making.
The word ""nori"" first appeared in an English-language publication in "C. P. Thunberg's Trav.", published in 1796. It was used in conjugation as "Awa nori", probably referring to what is now called aonori.
The Japanese nori industry was in decline after WWII, when Japan was in need of all food which could be produced. The decline was due to a lack of understanding of the plant's three stage life cycle so that local people did not understand why traditional cultivation methods were not effective. The industry was rescued by knowledge deriving from the work of British phycologist, Kathleen Mary Drew-Baker who had been researching the organism porphyria umbilicalis, which grew in the seas around Wales and was harvested for food, as in Japan. Her work was discovered by Japanese scientists who applied it to artificial methods of seeding and growing the plants, rescuing the industry. Kathleen Baker was hailed as the 'Mother of the Sea' in Japan and a statue erected in her memory; she is still revered as the savior of the Japanese nori industry.
In the 21st century, the Japanese nori industry faces a new decline due to increased competition from seaweed producers in China and Korea and domestic sales tax hikes
The word "nori" started to be used widely in the United States, and the product (imported in dry form from Japan) became widely available at natural food stores and Asian-American grocery stores in the 1960s due to the macrobiotic movement, and in the 1970s with the increase of sushi bars and Japanese restaurants.
In one study by Jan-Hendrik Hehemann, subjects of Japanese descent have been shown to be able to digest the polysaccharide of the seaweed, after gut microbes developed the enzyme from marine bacteria. Gut microbes from the North American subjects lacked these enzymes.
Production.
Production and processing of "nori" is an advanced form of agriculture. The biology of "Pyropia", although complicated, is well understood, and this knowledge is used to control the production process. Farming takes place in the sea where the "Pyropia" plants grow attached to nets suspended at the sea surface and where the farmers operate from boats. The plants grow rapidly, requiring about 45 days from "seeding" until the first harvest. Multiple harvests can be taken from a single seeding, typically at about ten-day intervals. Harvesting is accomplished using mechanical harvesters of a variety of configurations. Processing of raw product is mostly accomplished by highly automated machines that accurately duplicate traditional manual processing steps, but with much improved efficiency and consistency. The final product is a paper-thin, black, dried sheet of approximately and in weight.
Several grades of "nori" are available in the United States. The most common, and least expensive, grades are imported from China, costing about six cents per sheet. At the high end, ranging up to 90 cents per sheet, are "delicate "shin-nori"" ("nori" from the first of the year's several harvests) cultivated in Ariake Sea, off the island of Kyushu in Japan".
In Japan, over of Japanese coastal waters are given to producing of "nori", worth over a billion dollars. China produces about a third of this amount.
Use.
"Nori" is commonly used as a wrap for sushi and "onigiri". It is also a garnish or flavoring in noodle preparations and soups. It is most typically toasted prior to consumption ("yaki-nori"). A common secondary product is toasted and flavored "nori" ("ajitsuke-nori"), in which a flavoring mixture (variable, but typically soy sauce, sugar, sake, mirin, and seasonings) is applied in combination with the toasting process. It is also eaten by making it into a soy sauce-flavored paste, "nori no tsukudani" ().
"Nori" is sometimes used as a form of food decoration.
A related product, prepared from the unrelated green algae "Monostroma" and "Enteromorpha", is called "aonori" ( literally blue/green "nori") and is used like herbs on everyday meals, such as "okonomiyaki" and "yakisoba".
Since "nori" sheets easily absorb water from the air and degrade, a desiccant is indispensable when storing it for any significant time.
Nutrition.
While seaweed has by far the highest proportion of iodine by weight of any food,
It has also been found to contain sufficient vitamin B to prevent vitamin B deficiency in rats. Though Nori has long been considered to be an important source of vitamin B for vegans, its vitamin B may actually not be biologically available to humans. It may contain cobalamin analogues which block absorption of B. However, recent studies have shown otherwise, that Nori ("Pyropia yezoensis") contains a significant amount of bioactive vitamin B12, not the inactive analogues.

</doc>
<doc id="22080" url="https://en.wikipedia.org/wiki?curid=22080" title="Netwar">
Netwar

Netwar is a form of low intensity conflict, crime, and activism waged by networked actors. Typical netwar actors might include transnational terrorists, criminal organizations, activist groups, and social movements that employ decentralized, flexible network structures.
The term "netwar" was developed by RAND researchers John Arquilla and David Ronfeldt.
Terminology.
The term is proposed in order to focus specifically on the spread of network based organizational structures throughout the low intensity spectrum of societal conflict. It is argued that other terms applied to information age conflict, such as ‘information warfare’, are inadequate, focusing too narrowly on technological issues while missing the broader social transformation enabled by technological advances.
‘Cyberwar’ is a corresponding term which Arquilla and Ronfeldt propose to describe high-intensity information age conflicts.
Network structures.
Arquilla and Ronfeldt point to three basic types of networks that may be used by netwar actors:
Netwar actors may also take on hybrid forms as well, blending different types of networks and hierarchies. For instance, a node in the network may be hierarchical, an organization may shift between hierarchy and networked autonomy depending on operational demands, or various members of the same group may be networked to each other through different types of network structures.
All-channel networks.
Arquilla and Ronfeldt argue that it is the all-channel model that is becoming increasingly significant as a source of organizational collaborative power. The all-channel network has no central leadership and no key node whose removal might disrupt the entire organization. Instead, the network is completely decentralized, “allowing for local initiative and autonomy” in an organization that may at times appear “acephalous (headless), and at other times polycephalous (hydra-headed).”
The all-channel network is one of the most difficult to maintain because it requires a strong communications capacity to maintain ties between nodes. Moreover, nodal autonomy results in a distributed, consensus style of decision making which is necessarily dependent on back-and-forth communication. As such, this form of organization has only recently become feasible on a greater scale with the dawn of the information age.
Historical context.
The theory of netwar rests on the prediction that networks, enabled by information technology, will become the dominant form of organization following past eras of tribal, institutional/hierarchical, and market-based societies.
Proponents of netwar argue that globalization has set the stage for the rise of networks. National borders in the 21st century have become more permeable to flows of people, capital, and information; non-state actors have gained power vis-à-vis states; and the information revolution has empowered both individuals and dispersed groups. States have begun experimenting with networking and cooperation to tackle transnational issues, non-governmental organizations have formed transnational advocacy networks around shared goals, multinational corporations have distributed and networked their operations around the globe, and criminal and terrorist organizations have shifted to more agile and resilient network forms.
Advances in communications technologies have played a large part in enabling globalization, and likewise play a crucial role in enabling netwar. Networks, especially global or transnational networks, require "rapid, dense, multidirectional communications to function well and endure". This level of communication has only become easily attainable and affordable with the spread of the Internet, satellite communications, cellular phones, digitization, wireless communications, fax, email, etc., all of which allow "diverse, dispersed, autonomous actors […] to consult, coordinate, and act jointly across great distances on the basis of more, better, and faster information than ever before".
Netwar and network dynamics.
The high flexibility and reconfigurability inherent in the network structure creates a challenge in maintaining its effectiveness. Arquilla and Ronfeldt identify four areas that affect the strength of a network:
With this rubric, the strength of a netwar actor corresponds to how highly networked it is, whether its doctrine sustains the network and guides its members, how effectively technology is used to maintain the network, and how much interpersonal trust there is between nodes in the network.
Networks with many leaders, or no leader, may maintain coordination through a combination of powerful doctrine, ideology, shared beliefs, and/or common interests. This allows all the members of the network to maintain a common objective despite great personal or group autonomy. In other words, this provides an “ideational, strategic, and operational centrality that allows for tactical decentralization.”
Examples.
The following are several examples used to support the argument that there is in fact an emergent netwar.
Terrorism.
Terrorist groups, in the Middle East especially, seem to be adopting flexible, decentralized network structures as part of a shift away from “formally organized, state-sponsored groups to privately financed, loose networks of individuals and subgroups that may have strategic guidance but that, nonetheless, enjoy tactical independence”.
Past terrorist groups did incorporate autonomous cells, but they were largely coordinated in a non-networked manner. Newer terrorist movements, such as al-Qaeda, employ less hierarchical, loosely interlinked organizational models. Rather than the rigid bureaucratic structures and nationalist agendas of old terror groups, these new operatives are networked, relying on decentralized decision making with flexible ties between other individuals and radical groups sharing common values.
Zapatistas.
The Zapatista movement began as a seemingly traditional, hierarchical insurgency, but was transformed into an information-age conflict. It has benefited from a diverse network of actors, made up of indigenous communities, non-indigenous middle-class guerilla leaders, and a range of local and transnational NGOs sympathetic to the Zapatista cause. Numerous transnational NGOs networked with local Mexican NGOs that were involved with the marginalized indigenous community and the Zapatista guerillas.
Following setbacks in battle, the guerillas switched tactics and began to exploit the network form, taking advantage of the NGOs connections to mobilize global awareness and support for their reform movement, while putting pressure on the Mexican government. These diverse groups of activists and issue organizations were united by common values and shared goals. The internet, which was in its infancy at the time, also became a key space for networking various groups from around the globe with the Zapatista movement.
Transnational Criminal Organizations.
Transnational Criminal organizations (TCOs), such as Extremist and Terrorist Groups, Italian, Russian, and Jewish Mafias, Mexican and Colombian Drug Cartels, Japanese Yakuza and Chinese Triad Crime syndicates or some Street Gangs, Outlaw Motorcycle Gangs and Cyber-criminals are empowered by the network form in the sense that it heightens their mobility, adaptability, and their ability to operate transnationally. These transnational networks pose a problem for states operating in a conventional, inwardly focused manner. For instance, cartels in Colombia draw power from their extended transnational network resources, making it difficult for the Colombian government to fight the cartels within the confines of its national boundaries. Thus, networking allows TCOs to easily operate across jurisdictions, evading national law enforcement agencies. Networks also make it more difficult to dismantle a criminal operation, given that there is less emphasis on rigid, central leadership.

</doc>
<doc id="22081" url="https://en.wikipedia.org/wiki?curid=22081" title="Normative ethics">
Normative ethics

Normative ethics is the study of ethical action. It is the branch of philosophical ethics that investigates the set of questions that arise when considering how one ought to act, morally speaking. Normative ethics is distinct from meta-ethics because it examines standards for the rightness and wrongness of actions, while meta-ethics studies the meaning of moral language and the metaphysics of moral facts. Normative ethics is also distinct from descriptive ethics, as the latter is an empirical investigation of people’s moral beliefs. To put it another way, descriptive ethics would be concerned with determining what proportion of people believe that killing is always wrong, while normative ethics is concerned with whether it is correct to hold such a belief. Hence, normative ethics is sometimes called prescriptive, rather than descriptive. However, on certain versions of the meta-ethical view called moral realism, moral facts are both descriptive and prescriptive at the same time.
Most traditional moral theories rest on principles that determine whether an action is right or wrong. Classical theories in this vein include utilitarianism, Kantianism, and some forms of contractarianism. These theories mainly offered overarching moral principles to use to resolve difficult moral decisions.
Normative ethical theories.
There are disagreements about what precisely gives an action, rule, or disposition its ethical force. Broadly speaking, there are three competing views on how moral questions should be answered, along with hybrid positions that combine some elements of each. Virtue ethics focuses on the character of those who are acting, while both deontological ethics and consequentialism focus on the status of the action, rule, or disposition itself. The latter two conceptions of ethics themselves come in various forms.
Binding force.
It can be unclear what it means to say that a person "ought to do X because it is moral, whether they like it or not". Morality is sometimes presumed to have some kind of special binding force on behaviour, but some philosophers think that, used this way, the word "ought" seems to wrongly attribute magic powers to morality. For instance, G. E. M. Anscombe worries that "ought" has become "a word of mere mesmeric force". British ethicist Philippa Foot elaborates that morality does not seem to have any special binding force, and she clarifies that people only behave morally when motivated by other factors.
Foot says "People talk, for instance, about the 'binding force' of morality, but it is not clear what this means if not that we feel ourselves unable to escape." The idea is that, faced with an opportunity to steal a book because we can get away with it, moral obligation itself has no power to stop us unless we "feel" an obligation. Morality may therefore have no binding force beyond regular human motivations, and people must be motivated to behave morally. The question then arises: what role does reason play in motivating moral behaviour?
Motivating morality.
The categorical imperative perspective suggests that proper reason always leads to particular moral behaviour. As mentioned above, Foot instead believes that humans are actually motivated by desires. Proper reason, on this view, allows humans to discover actions that get them what they want (i.e., hypothetical imperatives)—not necessarily actions that are moral.
Social structure and motivation can make morality binding in a sense, but only because it makes moral norms feel inescapable, according to Foot.
John Stuart Mill adds that external pressures, to please others for instance, also influence this felt binding force, which he calls human "conscience". Mill says that humans must first reason about what is moral, then try to bring the feelings of our conscience in line with our reason. At the same time, Mill says that a good moral system (in his case, utilitarianism) ultimately appeals to aspects of human nature — which, must themselves be nurtured during upbringing. Mill explains:
This firm foundation is that of the social feelings of mankind; the desire to be in unity with our fellow creatures, which is already a powerful principle in human nature, and happily one of those which tend to become stronger, even without express inculcation, from the influences of advancing civilisation.
Mill thus believes that it is important to appreciate that it is feelings that drive moral behavior, but also that they may not be present in some people (e.g. psychopaths). Mill goes on to describe factors that help ensure people develop a conscience and behave morally, and thinkers like Joseph Daleiden describe how societies can use science to figure out how to make people more likely to be good.

</doc>
<doc id="22083" url="https://en.wikipedia.org/wiki?curid=22083" title="Negotiation">
Negotiation

Negotiation is a dialogue between two or more people or parties intended to reach a beneficial outcome.
This beneficial outcome can be for all of the parties involved, or just for one or some of them, in situations in which a good outcome for one/some, excludes the possibility of a desired result for the other/others.
It is aimed to resolve points of difference, to gain advantage for an individual or collective, or to craft outcomes to satisfy various interests. It is often conducted by putting forward a position and making small concessions to achieve an agreement. The degree to which the negotiating parties trust each other to implement the negotiated solution is a major factor in determining whether negotiations are successful. Negotiation is not a zero-sum game; if there is no compromise, the negotiations have failed. When negotiations are at an impasse it is essential that both the parties acknowledge the difficulties, and agree to work towards a solution at a later date.
Negotiation occurs in business, non-profit organizations, government branches, legal proceedings, among nations, and in personal situations such as marriage, divorce, parenting, and everyday life. The study of the subject is called "negotiation theory". Professional negotiators are often specialized, such as "union negotiators", "leverage buyout negotiators", "peace negotiators", "hostage negotiators", or may work under other titles, such as diplomats, legislators or brokers.
Strategies.
Negotiation can take a wide variety of forms, from a trained negotiator acting on behalf of a particular organization or position in a formal setting, to an informal negotiation between friends. Negotiation can be contrasted with mediation, where a neutral third party listens to each side's arguments and attempts to help craft an agreement between the parties. It can also be compared with arbitration, which resembles a legal proceeding. In arbitration, both sides make an argument as to the merits of their case and the arbitrator decides the outcome. This negotiation is also sometimes called positional or hard-bargaining negotiation.
Negotiation theorists generally distinguish between two types of negotiation. Different theorists use different labels for the two general types and distinguish them in different ways.
One very common distinction concerns the distribution of gains (distributive versus integrative models):
Distributive negotiation.
Distributive negotiation is also sometimes called positional or hard-bargaining negotiation. It tends to approach negotiation on the model of haggling in a market. In a distributive negotiation, each side often adopts an extreme position, knowing that it will not be accepted, and then employs a combination of guile, bluffing, and brinkmanship in order to cede as little as possible before reaching a deal. Distributive bargainers conceive of negotiation as a process of distributing a fixed amount of value.
The term distributive implies that there is a finite amount of the thing being distributed or divided among the people involved. Sometimes this type of negotiation is referred to as the distribution of a "fixed pie." There is only so much to go around, but the proportion to be distributed is variable. Distributive negotiation is also sometimes called "win-lose" because of the assumption that one person's gain results in another person's loss. A distributive negotiation often involves people who have never had a previous interactive relationship, nor are they likely to do so again in the near future. Simple everyday examples would be buying a car or a house.
Integrative negotiation is also sometimes called interest-based or principled negotiation. It is a set of techniques that attempts to improve the quality and likelihood of negotiated agreement by providing an alternative to traditional distributive negotiation techniques. While distributive negotiation assumes there is a fixed amount of value (a "fixed pie") to be divided between the parties, integrative negotiation often attempts to create value in the course of the negotiation ("expand the pie"). It focuses on the underlying interests of the parties rather than their arbitrary starting positions, approaches negotiation as a shared problem rather than a personalized battle, and insists upon adherence to objective, principled criteria as the basis for agreement.
Integrative negotiation often involves a higher degree of trust and the forming of a relationship. It can also involve creative problem-solving that aims to achieve mutual gains. It is also sometimes called "win-win" negotiation.
Elements of negotiation.
There are many different ways to categorize the essential elements of negotiation.
One view of negotiation involves three basic elements: "process", "behavior" and "substance". The process refers to how the parties negotiate: the context of the negotiations, the parties to the negotiations, the tactics used by the parties, and the sequence and stages in which all of these play out. Behavior refers to the relationships among these parties, the communication between them and the styles they adopt. The substance refers to what the parties negotiate over: the agenda, the issues (positions and - more helpfully - interests), the options, and the agreement(s) reached at the end.
Another view of negotiation comprises four elements: "strategy", "process", "tools", and "tactics". Strategy comprises the top level goals - typically including relationship and the final outcome. Processes and tools include the steps that will be followed and the roles taken in both preparing for and negotiating with the other parties. Tactics include more detailed statements and actions and responses to others' statements and actions. Some add to this "persuasion and influence", asserting that these have become integral to modern day negotiation success, and so should not be omitted.
Adversary or partner?
The two basically different approaches to negotiating will require different tactics. In the distributive approach each negotiator is battling for the largest possible piece of the pie, so it may be quite appropriate - within certain limits - to regard the other side more as an adversary than a partner and to take a somewhat harder line. This would however be less appropriate if the idea were to hammer out an arrangement that is in the best interest of both sides. A good agreement is not one with maximum gain, but optimum gain. This does not by any means suggest that we should give up our own advantage for nothing. But a cooperative attitude will regularly pay dividends. What is gained is not at the expense of the other, but with him.
Employing an advocate.
A skilled negotiator may serve as an advocate for one party to the negotiation. The advocate attempts to obtain the most favorable outcomes possible for that party. In this process the negotiator attempts to determine the minimum outcome(s) the other party is (or parties are) willing to accept, then adjusts their demands accordingly. A "successful" negotiation in the advocacy approach is when the negotiator is able to obtain all or most of the outcomes their party desires, but without driving the other party to permanently break off negotiations, unless the best alternative to a negotiated agreement (BATNA) is acceptable.
Skilled negotiators may use a variety of tactics ranging from negotiation hypnosis, to a straightforward presentation of demands or setting of preconditions, to more deceptive approaches such as cherry picking. Intimidation and salami tactics may also play a part in swaying the outcome of negotiations.
Another negotiation tactic is bad guy/good guy. Bad guy/good guy is when one negotiator acts as a bad guy by using anger and threats. The other negotiator acts as a good guy by being considerate and understanding. The good guy blames the bad guy for all the difficulties while trying to get concessions and agreement from the opponent.
Perspective taking for integrative negotiation.
Perspective taking can be helpful for two reasons: that it can help self-centered negotiators to seek mutually beneficial solutions, and it increases the likelihood of logrolling (when a favor is traded for another i.e. quid pro quo). Social motivation can increase the chances of a party conceding to a negotiation. While concession is mandatory for negotiations, research shows that people who concede more quickly, are less likely to explore all integrative and mutually beneficial solutions. Therefore, conceding reduces the chance of an integrative negotiation.
Negotiation styles.
Kenneth W. Thomas identified 5 styles/responses to negotiation. These ﬁve strategies have been frequently described in the literature and are based on the dual-concern model. The dual concern model of conflict resolution is a perspective that assumes individuals' preferred method of dealing with conflict is based on two themes or dimensions 
Based on this model, individuals balance the concern for personal needs and interests with the needs and interests of others. The following five styles can be used based on individuals’ preferences depending on their pro-self or pro-social goals. These styles can change over time, and individuals can have strong dispositions towards numerous styles.
1. Accommodating: Individuals who enjoy solving the other party's problems and preserving personal relationships. Accommodators are sensitive to the emotional states, body language, and verbal signals of the other parties. They can, however, feel taken advantage of in situations when the other party places little emphasis on the relationship.
2. Avoiding: Individuals who do not like to negotiate and don't do it unless warranted. When negotiating, avoiders tend to defer and dodge the confrontational aspects of negotiating; however, they may be perceived as tactful and diplomatic.
3. Collaborating: Individuals who enjoy negotiations that involve solving tough problems in creative ways. Collaborators are good at using negotiations to understand the concerns and interests of the other parties. They can, however, create problems by transforming simple situations into more complex ones.
4. Competing: Individuals who enjoy negotiations because they present an opportunity to win something. Competitive negotiators have strong instincts for all aspects of negotiating and are often strategic. Because their style can dominate the bargaining process, competitive negotiators often neglect the importance of relationships.
5. Compromising: Individuals who are eager to close the deal by doing what is fair and equal for all parties involved in the negotiation. Compromisers can be useful when there is limited time to complete the deal; however, compromisers often unnecessarily rush the negotiation process and make concessions too quickly.
Types of negotiators.
Three basic kinds of negotiators have been identified by researchers involved in The Harvard Negotiation Project. These types of negotiators are: Soft bargainers, hard bargainers, and principled bargainers.
Researchers from The Harvard Negotiation Project recommend that negotiators explore a number of alternatives to the problems they are facing in order to come to the best overall conclusion/solution, but this is often not the case (as when you may be dealing with an individual utilizing soft or hard bargaining tactics) (Forsyth, 2010).
Bad faith negotiation.
When a party pretends to negotiate, but secretly has no intention of compromising, the party is considered to be negotiating in bad faith. Bad faith is a concept in negotiation theory whereby parties pretend to reason to reach settlement, but have no intention to do so, for example, one political party may pretend to negotiate, with no intention to compromise, for political effect.
In international relations and political psychology.
Bad faith in political science and political psychology refers to negotiating strategies in which there is no real intention to reach compromise, or a model of information processing. It is the most widely studied model of one's opponent. A state is presumed to be implacably hostile, and contra-indicators of this are ignored. They are dismissed as propaganda ploys or signs of weakness. Examples are John Foster Dulles' position regarding the Soviet Union, or Hamas's position on the state of Israel.
Emotion.
Emotions play an important part in the negotiation process, although it is only in recent years that their effect is being studied. Emotions have the potential to play either a positive or negative role in negotiation. During negotiations, the decision as to whether or not to settle rests in part on emotional factors. Negative emotions can cause intense and even irrational behavior, and can cause conflicts to escalate and negotiations to break down, but may be instrumental in attaining concessions. On the other hand, positive emotions often facilitate reaching an agreement and help to maximize joint gains, but can also be instrumental in attaining concessions. Positive and negative discrete emotions can be strategically displayed to influence task and relational outcomes and may play out differently across cultural boundaries.
Affect effect.
Dispositional affects affect the various stages of the negotiation process: which strategies are planned to be used, which strategies are actually chosen, the way the other party and his or her intentions are perceived, their willingness to reach an agreement and the final negotiated outcomes. Positive affectivity (PA) and negative affectivity (NA) of one or more of the negotiating sides can lead to very different outcomes.
Positive affect.
Even before the negotiation process starts, people in a positive mood have more confidence, and higher tendencies to plan to use a cooperative strategy. During the negotiation, negotiators who are in a positive mood tend to enjoy the interaction more, show less contentious behavior, use less aggressive tactics and more cooperative strategies. This in turn increases the likelihood that parties will reach their instrumental goals, and enhance the ability to find integrative gains. Indeed, compared with negotiators with negative or natural affectivity, negotiators with positive affectivity reached more agreements and tended to honor those agreements more.
Those favorable outcomes are due to better decision making processes, such as flexible thinking, creative problem solving, respect for others' perspectives, willingness to take risks and higher confidence.
Post negotiation positive affect has beneficial consequences as well. It increases satisfaction with achieved outcome and influences one's desire for future interactions. The PA aroused by reaching an agreement facilitates the dyadic relationship, which result in affective commitment that sets the stage for subsequent interactions.
PA also has its drawbacks: it distorts perception of self performance, such that performance is judged to be relatively better than it actually is. Thus, studies involving self reports on achieved outcomes might be biased.
Negative affect.
Negative affect has detrimental effects on various stages in the negotiation process. Although various negative emotions affect negotiation outcomes, by far the most researched is anger. Angry negotiators plan to use more competitive strategies and to cooperate less, even before the negotiation starts. These competitive strategies are related to reduced joint outcomes.
During negotiations, anger disrupts the process by reducing the level of trust, clouding parties' judgment, narrowing parties' focus of attention and changing their central goal from reaching agreement to retaliating against the other side. Angry negotiators pay less attention to opponent's interests and are less accurate in judging their interests, thus achieve lower joint gains. Moreover, because anger makes negotiators more self-centered in their preferences, it increases the likelihood that they will reject profitable offers. Opponents who get really angry (or cry, or otherwise lose control) are more likely to make errors: make sure they are in your favor.
Anger does not help in achieving negotiation goals either: it reduces joint gains and does not help to boost personal gains, as angry negotiators do not succeed in claiming more for themselves. Moreover, negative emotions lead to acceptance of settlements that are not in the positive utility function but rather have a negative utility. However, expression of negative emotions during negotiation can sometimes be beneficial: legitimately expressed anger can be an effective way to show one's commitment, sincerity, and needs. Moreover, although NA reduces gains in integrative tasks, it is a better strategy than PA in distributive tasks (such as zero-sum). In his work on negative affect arousal and white noise, Seidner found support for the existence of a negative affect arousal mechanism through observations regarding the devaluation of speakers from other ethnic origins." Negotiation may be negatively affected, in turn, by submerged hostility toward an ethnic or gender group.
Conditions for emotion affect.
Research indicates that negotiator's emotions do not necessarily affect the negotiation process.
Albarracın et al. (2003) suggested that there are two conditions for emotional affect, both related to the ability (presence of environmental or cognitive disturbances) and the motivation:
According to this model, emotions are expected to affect negotiations only when one is high and the other is low. When both ability and motivation are low the affect will not be identified, and when both are high the affect will be identify but discounted as irrelevant for judgment.
A possible implication of this model is, for example, that the positive effects PA has on negotiations (as described above) will be seen only when either motivation or ability are low.
Effect of partner's emotions.
Most studies on emotion in negotiations focus on the effect of the negotiator's own emotions on the process. However, what the other party feels might be just as important, as group emotions are known to affect processes both at the group and the personal levels.
When it comes to negotiations, trust in the other party is a necessary condition for its emotion to affect, and visibility enhances the effect.
Emotions contribute to negotiation processes by signaling what one feels and thinks and can thus prevent the other party from engaging in destructive behaviors and to indicate what steps should be taken next: PA signals to keep in the same way, while NA points that mental or behavioral adjustments are needed.
Partner's emotions can have two basic effects on negotiator's emotions and behavior: mimetic/ reciprocal or complementary. For example, disappointment or sadness might lead to compassion and more cooperation. In a study by Butt et al. (2005) which simulated real multi-phase negotiation, most people reacted to the partner's emotions in reciprocal, rather than complementary, manner.
Specific emotions were found to have different effects on the opponent's feelings and strategies chosen:
Problems with laboratory studies.
Negotiation is a rather complex interaction. Capturing all its complexity is a very difficult task, let alone isolating and controlling only certain aspects of it. For this reason most negotiation studies are done under laboratory conditions, and focus only on some aspects. Although lab studies have their advantages, they do have major drawbacks when studying emotions:
Team negotiations.
Due to globalization and growing business trends, negotiation in the form of teams is becoming widely adopted. Teams can effectively collaborate to break down a complex negotiation. There is more knowledge and wisdom dispersed in a team than in a single mind. Writing, listening, and talking, are specific roles team members must satisfy. The capacity base of a team reduces the amount of blunder, and increases familiarity in a negotiation.
Etymology.
The word "negotiation" originated in the early 15th century from the Old French and Latin expressions “negociacion” and “negotiationem.” These terms mean “business, trade and traffic.” By the late 1590s negotiation had the definition, "to communicate in search of mutual agreement." With this new introduction and this meaning, it showed a shift in “doing business” to “bargaining about” business.
Barriers.
Tactics are always an important part of the negotiating process. More often than not they are subtle, difficult to identify and used for multiple purposes. Tactics are more frequently used in distributive negotiations and when the focus in on taking as much value off the table as possible. Many negotiation tactics exist. Below are a few commonly used tactics.
Auction:
The bidding process is designed to create competition. When multiple parties want the same thing, pit them against one another. When people know that they may lose out on something, they will want it even more. Not only do they want the thing that is being bid on, they also want to win, just to win. Taking advantage of someone's competitive nature can drive up the price.
Brinksmanship:
One party aggressively pursues a set of terms to the point at which the other negotiating party must either agree or walk away. Brinkmanship is a type of "hard nut" approach to bargaining in which one party pushes the other party to the "brink" or edge of what that party is willing to accommodate. Successful brinksmanship convinces the other party they have no choice but to accept the offer and there is no acceptable alternative to the proposed agreement.
Bogey:
Negotiators use the bogey tactic to pretend that an issue of little or no importance to him or her is very important. Then, later in the negotiation, the issue can be traded for a major concession of actual importance.
Chicken:
Negotiators propose extreme measures, often bluffs, to force the other party to chicken out and give them what they want. This tactic can be dangerous when parties are unwilling to back down and go through with the extreme measure.
Defence in Depth:
Several layers of decision-making authority is used to allow further concessions each time the agreement goes through a different level of authority. In other words, each time the offer goes to a decision maker, that decision maker asks to add another concession in order to close the deal.
Deadlines:
Give the other party a deadline forcing them to make a decision. This method uses time to apply pressure to the other party. Deadlines given can be actual or artificial.
Flinch:
Flinching is showing a strong negative physical reaction to a proposal. Common examples of flinching are gasping for air, or a visible expression of surprise or shock. The flinch can be done consciously or unconsciously. The flinch signals to the opposite party that you think the offer or proposal is absurd in hopes the other party will lower their aspirations. Seeing a physical reaction is more believable than hearing someone saying, "I'm shocked."
Good Guy/Bad Guy:
The good guy/bad guy approach is typically used in team negotiations where one member of the team makes extreme or unreasonable demands, and the other offers a more rational approach. This tactic is named after a police interrogation technique often portrayed in the media. The "good guy" will appear more reasonable and understanding, and therefore, easier to work with. In essence, it is using the law of relativity to attract cooperation. The good guy will appear more agreeable relative to the "bad guy." This tactic is easy to spot because of its frequent use.
Highball/Lowball:
Depending on whether selling or buying, sellers or buyers use a ridiculously high, or ridiculously low opening offer that will never be achieved. The theory is that the extreme offer will cause the other party to reevaluate his or her own opening offer and move close to the resistance point (as far as you are willing to go to reach an agreement). Another advantage is that the person giving the extreme demand appears more flexible he or she makes concessions toward a more reasonable outcome. A danger of this tactic is that the opposite party may think negotiating is a waste of time.
The Nibble:
Nibbling is asking for proportionally small concessions that haven't been discussed previously just before closing the deal. This method takes advantage of the other party's desire to close by adding "just one more thing."
Snow Job:
Negotiators overwhelm the other party with so much information that he or she has difficulty determining which facts are important, and which facts are diversions. Negotiators may also use technical language or jargon to mask a simple answer to a question asked by a non-expert.
Nonverbal communication.
Communication is a key element of negotiation. Effective negotiation requires that participants effectively convey and interpret information. Participants in a negotiation will communicate information not only verbally but non-verbally through body language and gestures. By understanding how nonverbal communication works, a negotiator is better equipped to interpret the information other participants are leaking non-verbally while keeping secret those things that would inhibit his/her ability to negotiate.
Examples in negotiation.
Non-verbal "anchoring"
In a negotiation, a person can gain the advantage by verbally expressing his or her position first. By anchoring your position, one establishes the position from which the negotiation will proceed. In a like manner, one can "anchor" and gain advantage with nonverbal (body language) cues.
Reading non-verbal communication
Being able to read the non-verbal communication of another person can significantly aid in the communication process. By being aware of inconsistencies between a person's verbal and non-verbal communication and reconciling them, negotiators will be able to come to better resolutions. Examples of incongruity in body language include:
Conveying receptivity
The way negotiation partners position their bodies relative to each other may influence how receptive each is to the other person's message and ideas.
Receptive negotiators tend to appear relaxed with their hands open and palms visibly displayed.

</doc>
<doc id="22085" url="https://en.wikipedia.org/wiki?curid=22085" title="Fertility awareness">
Fertility awareness

Fertility awareness (FA) refers to a set of practices used to determine the fertile and infertile phases of a woman's menstrual cycle. Fertility awareness methods may be used to avoid pregnancy, to achieve pregnancy, or as a way to monitor gynecological health.
Methods of identifying infertile days have been known since antiquity, but scientific knowledge gained during the past century has increased the number and variety of methods.
Systems of fertility awareness rely on observation of changes in one or more of the primary fertility signs (basal body temperature, cervical mucus, and cervical position), tracking menstrual cycle length and identifying the fertile window based on this information, or both. Other signs may also be observed: these include breast tenderness and mittelschmerz (ovulation pains), urine analysis strips known as ovulation predictor kits (OPKs), and microscopic examination of saliva or cervical fluid. Also available are computerized fertility monitors.
Terminology.
Symptoms-based methods involve tracking one or more of the three primary fertility signs: basal body temperature, cervical mucus, and cervical position. Systems relying exclusively on cervical mucus include the Billings Ovulation Method, the Ovulation Method, the Creighton Model, and the Two-Day Method. Symptothermal methods combine observations of basal body temperature (BBT), cervical mucus, and sometimes cervical position. Calendar-based methods rely on tracking a woman's cycle and identifying her fertile window based on the lengths of her cycles. The best known of these methods is the Standard Days Method. The Calendar-Rhythm method is also considered a calendar-based method, though it is not well defined and has many different meanings to different people.
Systems of fertility awareness may be referred to as fertility awareness–based methods (FAB methods); the term Fertility Awareness Method (FAM) refers specifically to the system taught by Toni Weschler. The term natural family planning (NFP) is sometimes used to refer to any use of FA methods, the Lactational amenorrhea method and periodic abstinence during fertile times. A method of FA may be used by NFP users to identify these fertile times.
Women who are breastfeeding a child and wish to avoid pregnancy may be able to practice the lactational amenorrhea method (LAM). LAM is distinct from fertility awareness, but because it also does not involve devices or chemicals, it is often presented alongside FA as a method of "natural" birth control.
History.
Development of calendar-based methods.
It is not known exactly when it was first discovered that women have predictable periods of fertility and infertility. St. Augustine wrote about periodic abstinence to avoid pregnancy in the year 388 (the Manichaeans attempted to use this method to remain childfree, and Augustine condemned their use of periodic abstinence). One book states that periodic abstinence was recommended ""by a few secular thinkers since the mid-nineteenth century,"" but the dominant force in the twentieth century popularization of fertility awareness-based methods was the Roman Catholic Church.
In 1905 Theodoor Hendrik van de Velde, a Dutch gynecologist, showed that women only ovulate once per menstrual cycle. In the 1920s, Kyusaku Ogino, a Japanese gynecologist, and Hermann Knaus, from Austria, independently discovered that ovulation occurs about fourteen days before the next menstrual period. Ogino used his discovery to develop a formula for use in aiding infertile women to time intercourse to achieve pregnancy. In 1930, John Smulders, Roman Catholic physician from the Netherlands, used this discovery to create a method for "avoiding" pregnancy. Smulders published his work with the Dutch Roman Catholic medical association, and this was the first formalized system for periodic abstinence: the rhythm method.
Introduction of temperature and cervical mucus signs.
In the 1930s, Reverend Wilhelm Hillebrand, a Catholic priest in Germany, developed a system for avoiding pregnancy based on basal body temperature. This temperature method was found to be more effective at helping women avoid pregnancy than were calendar-based methods. Over the next few decades, both systems became widely used among Catholic women. Two speeches delivered by Pope Pius XII in 1951 gave the highest form of recognition to the Catholic Church's approval—for couples who needed to avoid pregnancy—of these systems. In the early 1950s, Dr. John Billings discovered the relationship between cervical mucus and fertility while working for the Melbourne Catholic Family Welfare Bureau. Billings and several other physicians, including his wife, Dr. Evelyn Billings, studied this sign for a number of years, and by the late 1960s had performed clinical trials and begun to set up teaching centers around the world.
First symptoms-based teaching organizations.
While Dr. Billings initially taught both the temperature and mucus signs, they encountered problems in teaching the temperature sign to largely illiterate populations in developing countries. In the 1970s they modified the method to rely on only mucus. The international organization founded by Dr. Billings is now known as the World Organization Ovulation Method Billings (WOOMB).
The first organization to teach a symptothermal method was founded in 1971. John and Sheila Kippley, lay Catholics, joined with Dr. Konald Prem in teaching an observational method that relied on all three signs: temperature, mucus, and cervical position. Their organization is now called Couple to Couple League International. The next decade saw the founding of other now-large Catholic organizations, Family of the Americas (1977), teaching the Billings method, and the Pope Paul VI Institute (1985), teaching a new mucus-only system called the Creighton Model.
Up until the 1980s, information about fertility awareness was only available from Catholic sources. The first secular teaching organization was the Fertility Awareness Center in New York, founded in 1981. Toni Weschler started teaching in 1982 and published the bestselling book "Taking Charge of Your Fertility" in 1995. Justisse was founded in 1987 in Edmonton, Canada. These secular organizations all teach symptothermal methods. Although the Catholic organizations are significantly larger than the secular fertility awareness movement, independent secular teachers have become increasingly common since the 1990s.
Ongoing development.
Development of fertility awareness methods is ongoing. In the late 1990s, the Institute for Reproductive Health at Georgetown University introduced two new methods. The Two-Day Method, a mucus-only system, and CycleBeads and iCycleBeads (the digital version), based on the Standard Days Method, are designed to be both effective and simple to teach, learn, and use.
Fertility signs.
Most menstrual cycles have several days at the beginning that are infertile (pre-ovulatory infertility), a period of fertility, and then several days just before the next menstruation that are infertile (post-ovulatory infertility). The first day of red bleeding is considered day one of the menstrual cycle. Different systems of fertility awareness calculate the fertile period in slightly different ways, using primary fertility signs, cycle history, or both.
Primary fertility signs.
The three primary signs of fertility are "basal body temperature" (BBT), "cervical mucus", and "cervical position". A woman practicing symptoms-based fertility awareness may choose to observe one sign, two signs, or all three. Many women experience secondary fertility signs that correlate with certain phases of the menstrual cycle, such as abdominal pain and heaviness, back pain, breast tenderness, and mittelschmerz (ovulation pains).
Basal body temperature.
This usually refers to a temperature reading collected when a person first wakes up in the morning (or after their longest sleep period of the day). The true BBT can only be obtained by continuous temperature monitoring through internally worn temperature sensors. In women, ovulation will trigger a rise in BBT between 0.2º and 0.5ºC. (0.5 and 1.ºF) that lasts approximately until the next menstruation. This temperature shift may be used to determine the onset of post-ovulatory infertility. (See ref. 30)
Cervical mucus.
The appearance of cervical mucus and vulvar sensation are generally described together as two ways of observing the same sign. Cervical mucus is produced by the cervix, which connects the uterus to the vaginal canal. Fertile cervical mucus promotes sperm life by decreasing the acidity of the vagina, and also it helps guide sperm through the cervix and into the uterus. The production of fertile cervical mucus is caused by estrogen, the same hormone that prepares a woman's body for ovulation. By observing her cervical mucus and paying attention to the sensation as it passes the vulva, a woman can detect when her body is gearing up for ovulation, and also when ovulation has passed. When ovulation occurs, estrogen production drops slightly and progesterone starts to rise. The rise in progesterone causes a distinct change in the quantity and quality of mucus observed at the vulva.
Cervical position.
The cervix changes position in response to the same hormones that cause cervical mucus to be produced and to dry up. When a woman is in an infertile phase of her cycle, the cervix will be low in the vaginal canal; it will feel firm to the touch (like the tip of a person's nose); and the os—the opening in the cervix—will be relatively small, or "closed". As a woman becomes more fertile, the cervix will rise higher in the vaginal canal, it will become softer to the touch (more like a person's lips), and the os will become more open. After ovulation has occurred, the cervix will revert to its infertile position.
Cycle history.
Calendar-based systems determine both pre-ovulatory and post-ovulatory infertility based on cycle history. When used to avoid pregnancy, these systems have higher perfect-use failure rates than symptoms-based systems, but are still comparable with barrier methods, such as diaphragms and cervical caps.
Mucus- and temperature-based methods used to determine post-ovulatory infertility, when used to avoid conception, result in very low perfect-use pregnancy rates. However, mucus and temperature systems have certain limitations in determining pre-ovulatory infertility. A temperature record alone provides no guide to fertility or infertility before ovulation occurs. Determination of pre-ovulatory infertility may be done by observing the absence of fertile cervical mucus; however, this results in a higher failure rate than that seen in the period of post-ovulatory infertility. Relying only on mucus observation also means that unprotected sexual intercourse is not allowed during menstruation, since any mucus would be obscured.
Use of certain calendar rules to determine the length of the pre-ovulatory infertile phase allows unprotected intercourse during the first few days of the menstrual cycle while maintaining a very low risk of pregnancy. With mucus-only methods, there is a possibility of incorrectly identifying mid-cycle or anovulatory bleeding as menstruation. Keeping a BBT chart enables accurate identification of menstruation, when pre-ovulatory calendar rules may be reliably applied. In temperature-only systems, a calendar rule may be relied on alone to determine pre-ovulatory infertility. In symptothermal systems, the calendar rule is cross-checked by mucus records: observation of fertile cervical mucus overrides any calendar-determined infertility.
Calendar rules may set a standard number of days, specifying that (depending on a woman's past cycle lengths) the first three to six days of each menstrual cycle are considered infertile. Or, a calendar rule may require calculation, for example holding that the length of the pre-ovulatory infertile phase is equal to the length of a woman's shortest cycle minus 21 days. Rather than being tied to cycle length, a calendar rule may be determined from the cycle day on which a woman observes a thermal shift. One system has the length of the pre-ovulatory infertile phase equal to a woman's earliest historical day of temperature rise minus seven days.
Other techniques.
Ovulation predictor kits (OPKs) can detect imminent ovulation from the concentration of lutenizing hormone (LH) in a woman's urine. A positive OPK is usually followed by ovulation within 12–36 hours.
Saliva microscopes, when correctly used, can detect ferning structures in the saliva that precede ovulation. Ferning is usually detected beginning three days before ovulation, and continuing until ovulation has occurred. During this window, ferning structures occur in cervical mucus as well as saliva.
Computerized fertility monitors, such as Lady-Comp, are available under various brand names. These monitors may use BBT-only systems, they may analyze urine test strips, they may use symptothermal observations, they may monitor the electrical resistance of saliva and vaginal fluids, or a combination of any of these factors.
Benefits and drawbacks.
Fertility awareness has a number of unique characteristics:
As birth control.
By restricting unprotected sexual intercourse to the infertile portion of the menstrual cycle, a woman and her partner can prevent pregnancy. During the fertile portion of the menstrual cycle, the couple may use barrier contraception or abstain from sexual intercourse. Or the couple may attempt to control birth in the opposite sense by timing intercourse to achieve pregnancy.
Effectiveness.
The effectiveness of fertility awareness, as of most forms of contraception, can be assessed two ways. "Perfect use" or "method" effectiveness rates only include people who follow all observational rules, correctly identify the fertile phase, and refrain from unprotected intercourse on days identified as fertile. "Actual use" or "typical use" effectiveness rates include all women relying on fertility awareness to avoid pregnancy, including those who fail to meet the "perfect use" criteria. Rates are generally presented for the first year of use. Most commonly, the Pearl Index is used to calculate effectiveness rates, but some studies use decrement tables.
The failure rate of fertility awareness varies widely depending on the system used to identify fertile days, the instructional method, and the population being studied. Some studies have found actual failure rates of 25% per year or higher. At least one study has found a failure rate of less than 1% per year with continuous intensive coaching and monthly review, and several studies have found actual failure rates of 2%–3% per year.
When used correctly and consistently (i.e., with perfect use) with ongoing coaching, under study conditions some studies have found some forms of FA to be 99% effective.
From "Contraceptive Technology":
Reasons for lower typical-use effectiveness.
Several factors account for typical-use effectiveness being lower than perfect-use effectiveness:
The most common reason for the lower actual effectiveness is not mistakes on the part of instructors or users, but conscious user non-compliance—that is, the couple knowing that the woman is likely to be fertile at the time but engaging in sexual intercourse nonetheless. This is similar to failures of barrier methods, which are primarily caused by non-use of the method.
To achieve pregnancy.
Intercourse timing.
A review showed no evidence of a benefit in effect of timing intercourse on live births or pregnancies, compared to regular intercourse.
A study by Barrett and Marshall has shown that random acts of intercourse achieve a 24% pregnancy rate per cycle. That study also found that timed intercourse based on information from a BBT-only method of FA increased pregnancy rates to 31%–68%.
Studies of cervical-mucus methods of fertility awareness have found pregnancy rates of 67%-81% in the first cycle if intercourse occurred on the Peak Day of the mucus sign.
Because of high rates of very early miscarriage (25% of pregnancies are lost within the first six weeks since the woman's last menstrual period, or LMP), the methods used to detect pregnancy may lead to bias in conception rates. Less-sensitive methods will detect lower conception rates, because they miss the conceptions that resulted in early pregnancy loss. A Chinese study of couples practicing random intercourse to achieve pregnancy used very sensitive pregnancy tests to detect pregnancy. It found a 40% conception rate per cycle over the 12-month study period.
Problem diagnosis.
Regular menstrual cycles are sometimes taken as evidence that a woman is ovulating normally, and irregular cycles as evidence she is not. However, many women with irregular cycles do ovulate normally, and some with regular cycles are actually annovulatory or have a luteal phase defect. Records of basal body temperatures, especially, but also of cervical mucus and position, can be used to accurately determine if a woman is ovulating, and if the length of the post-ovulatory (luteal) phase of her menstrual cycle is sufficient to sustain a pregnancy.
Fertile cervical mucus is important in creating an environment that allows sperm to pass through the cervix and into the fallopian tubes where they wait for ovulation. Fertility charts can help diagnose hostile cervical mucus, a common cause of infertility. If this condition is diagnosed, some sources suggest taking guaifenesin in the few days before ovulation to thin out the mucus.
Pregnancy testing and gestational age.
Pregnancy tests are not accurate until 1–2 weeks after ovulation. Knowing an estimated date of ovulation can prevent a woman from getting false negative results due to testing too early. Also, 18 consecutive days of elevated temperatures means a woman is almost certainly pregnant.
Estimated ovulation dates from fertility charts are a more accurate method of estimating gestational age than the traditional pregnancy wheel or last menstrual period (LMP) method of tracking menstrual periods.

</doc>
<doc id="22087" url="https://en.wikipedia.org/wiki?curid=22087" title="Nicaragua Canal">
Nicaragua Canal

The Nicaraguan Canal (), formally the Nicaraguan Canal and Development Project (also referred to as the Nicaragua Grand Canal, or the Nicaragua Interoceanic Grand Canal) is a planned shipping route through Nicaragua to connect the Caribbean Sea (and therefore the Atlantic Ocean) with the Pacific Ocean. Its viability has been questioned by shipping experts and engineers. , no significant construction has taken place. No "major works" such as dredging will take place until after a Pacific Ocean wharf is finished and the wharf's construction will not start until sometime after August 2016.
In June 2013, Nicaragua's National Assembly approved a bill to grant a 50-year concession to finance and manage the project to the private Hong Kong Nicaragua Canal Development Investment Company (HKND Group) headed by Wang Jing, a Chinese billionaire. The concession can be extended for another 50 years once the waterway is operational.
Media reports have suggested the project would now be delayed or even possibly canceled because Wang Jing's personal wealth declined greatly as a result of the 2015–16 Chinese stock market crash. The Nicaraguan government has failed to present reliable information about whether or not the project can be financed, thus casting doubt over whether or not it can be completed. The HKND Group says that financing will come from debt and equity sales and a potential initial public offering (IPO).
Scientists are concerned about the project's environmental impact, as Lake Nicaragua is Central America's key freshwater reservoir.
Construction of a canal using the San Juan River as an access route to Lake Nicaragua was first proposed in the early colonial era. The United States abandoned plans to construct a waterway in Nicaragua in the early 20th century after it purchased the French interests in the Panama Canal.
Status.
, no significant construction has taken place. No "major works" such as dredging will take place until after a Pacific Ocean wharf is finished and the wharf's construction will not start until sometime after August 2016.
On 3 April 2016, Suzanne Daley, writing in the "New York Times", reported that progress on the project seemed stalled. Daley reported that Nicauraguan President Daniel Ortega hadn't mentioned the Canal in months. She reported that cows were still browsing for grass in the field where Wang held his ground-breaking. She reported that Wang had financial setbacks unrelated to the Nicauragua project, and that he had lost eighty percent of his net worth.
History.
The idea of constructing a man-made waterway through Central America is old. The colonial administration of New Spain conducted preliminary surveys. The routes suggested usually ran across Nicaragua, Panama, or the Isthmus of Tehuantepec in Mexico.
The history of attempts to build a Nicaragua canal connecting the Caribbean Sea and thus the Atlantic Ocean and the Pacific Ocean goes back at least to 1825 when the Federal Republic of Central America hired surveyors to study a route via Lake Nicaragua. Many other proposals have followed. Despite the operation of the Panama Canal, which opened in 1914, interest in a Nicaragua canal has continued. With emergence of globalization, an increase in commerce and the cost of fuel, and the limitations of the Panama Canal, the concept of a second canal across the American land bridge became more attractive, and in 2006 the president of Nicaragua, Enrique Bolaños, announced an intention to proceed with such a project. Even with the Panama Canal expansion project, expected at that time to be completed in 2016, some ships would be too big for the Panama Canal.
On 26 September 2012, the Nicaraguan Government and the newly formed Hong Kong Nicaragua Canal Development Group (HKND) signed a memorandum of understanding that committed HKND to financing and building the "Nicaraguan Canal and Development Project".
HKND Group is a private enterprise.
The Nicaraguan Government subsequently approved the "Master Concession Agreement" with HKND on 13 June 2013 thereby granting the company "the sole rights to the HKND Group to plan, design, construct and thereafter to operate and manage the Nicaragua Grand Canal and other related projects, including ports, a free trade zone, an international airport and other infrastructure development projects".
The agreement will last for 50 years and is renewable for another 50 years.
HKND will pay the Government of Nicaragua 10M USD annually for 10 years, and thereafter a portion of the revenue starting at 1% and increasing later.
Stratfor indicated that after 10 years, ownership shares will periodically be handed over to Nicaragua, so that after 50 years Nicaragua would be the majority shareholder.
HKND Group has begun the study phase of development, to assess the technological and economic feasibility of constructing a canal in Nicaragua, as well as the potential environmental, social, and regional implications of various routes. The canal and other associated projects would be financed by investors throughout the world and would generate jobs for Nicaragua and other Central American countries.
Initial findings of the commercial analysis conducted by HKND Group indicate that the combined impact of growth in east–west trade and in ship sizes could provide a compelling argument for the construction of a second canal, substantially larger than the expanded Panama Canal, across Central America. Within 10 to 15 years, growth in global maritime trade is expected to cause congestion and delays in transit through the Panama Canal without a complementary route through the isthmus. Additionally, by 2030, the volume of trade that a Nicaragua Canal could serve will have grown by 240%.
On 10 June 2013, The Associated Press reported that the National Assembly's Infrastructure Committee unanimously voted in favor of the project, with four members abstaining.
On 13 June 2013, Nicaragua's legislature passed the legislation granting the concession.
On 15 June 2013, Nicaraguan President Daniel Ortega and the chairman of HKND Group, Wang Jing, signed the concession agreement giving HKND Group the rights to construct and manage the canal and associated projects for 50 years.
An HKND Group press release read, "HKND Group Successfully Obtains Exclusive Right to Develop and Manage Nicaragua Grand Canal for 100 Years".
Under the exclusive contract, Wang can skip building the canal (and making any payments to Nicaragua) and instead simply operate lucrative tax-free side projects.
Wang Jing, a Chinese billionaire who leads and wholly owns HKND Group, announced at a press briefing in June 2013 that he had successfully attracted global investors to the 40 billion USD project.
In January 2014, Wang Jing and President Ortega issued a statement that the project's construction would begin in December 2014, and that it would be completed in 2019.
On 7 July 2014, a route for the Nicaragua Canal was approved.
The route starts from the mouth of the Brito River on the Pacific side, passes through Lake Nicaragua, and ends in the Punta Gorda River on the Caribbean. The proposed canal would be between 230 meters and 520 meters (754.6 feet and 1,706 feet) wide and deep. The "Toronto Star" noted that Chinese engineer Dong Yung Song said the canal's design called for the creation of a artificial lake. The water to fill the canal's giant locks would come from the artificial lake, not from Lake Nicaragua.
Daniel Ortega whose government approved the agreement within one week in June 2013 sees the canal as the second phase of the Nicaraguan Revolution, predicting that it will pull Nicaragua out of poverty and lead to the creation of 250,000 jobs, but HKND says the project will create 50,000 jobs, though about half will come from abroad, mainly China.
The Moscow Times has reported that Russia will help build the Nicaragua Canal, viewing the project in part as an opportunity to pursue strategic interests in the region.
Construction was to begin on 29 December 2014,
and officially started a week earlier. However, due to Nicaragua's volatile climate and seismic activity, feasibility concerns have emerged over the project's future. In November, 2015 HKND announced that there would be a delay in the construction of locks and excavations until late 2016 in order to fine-tune the design.
The Nicaragua canal project saw business rivalry greatly intensify in late 2014. China Harbor Engineering Company, an experienced construction company, offered to design, construct, and finance a fourth set of locks in Panama, where it opened a regional headquarters. If built to the width of the proposed Nicaragua Canal, it would cut across far fewer kilometers, and still cost only $10 billion USD, according to the firm. Panama is in a much better financial situation than Nicaragua to afford taking on such debt, and already has a stream of income from its existing canals.
Furthermore, the Suez Canal, with financing already complete, has put competitive pressure on Panama, by initiating an expansion, in August 2014, to double transit capacity, and finishing before the third set of locks in Panama is complete.
Alternative motives have been explored and other projects have taken priority against the water transportation venture. Bloomberg reports that "conspiracy theories abound" including the project is a land grab by Ortega, an attempt by Ortega to "whip up" support in elections, and part of a Chinese plan to gain influence in the region.
Opposition.
Protests against the canal's construction occurred shortly after the official ceremony marking its beginning. Farmers feared it could cause their eviction.
Opposition leader Eliseo Nuñez has called the deal “part of one of the biggest international scams in the world.” Legal challenges that the deal violates constitutional rights were rejected by the Supreme Court of Nicaragua and a retrospective rewriting of the Constitution of Nicaragua placed HKND beyond legal challenge.
HKND has been granted the right to expropriate land within on each side of the canal and pay only cadastral value, not market value, for property. Wang Jing, however, promised to pay fair market value. The estimates of the number of people who will be displaced range from 29,000
to more than 100,000. There are indications of local opposition to intended expropriations. Thus, according to an activist leader, an unrest in Rivas in December 2014 in opposition to the canal, left two protesters dead, although no evidence was ever produced to justify his claim.
The CIDH, Nicaragua’s Human Rights Commission, has strongly criticized the government for not looking into the project’s impact on citizens, not to mention the fact that citizens were not involved in decision-making.
Description.
The construction company has provided a project description for review on open source, [http://hknd-group.com/upload/pdf/20150105/Nicaragua_Canal_Project_Description_EN.pdf] dated December 2014. The canal as planned will be and will have three sections. The West Canal runs from Brito on the Pacific Ocean up the Rio Brito valley, crosses the continental divide, and after passing through the Rio Las Lajas valley enters Lake Nicaragua; its length is 25.9 km. The Nicaragua Lake section measures 106.8 km and runs from 4 km south of San Jorge to 8 km south of San Miguelito. The Eastern Canal is the longest section at 126.7 km and will be built along the Rio Tule valley through the Caribbean highland to the Rio Punta Gorda valley to meet the Caribbean Sea. A channel will have to be dug in the lake bottom, as it is not deep enough for the large vessels that can transit the canal.
Both the West Canal and the East Canal will each have one lock with 3 consecutive chambers to raise ships to the level of Lake Nicaragua that has an average water elevation of 31.3 m, range 30.2-33.0 m. The western Brito Lock is 14.5 km inland from the Pacific, and the eastern Camilo Lock is 13.7 km inland from the Caribbean Sea. The dimensions of each of the locks' chambers are long, wide, and threshold depth. As locks generally define the limit on the size of ships that can be handled, the Nicaragua Canal is being designed to allow passage for larger ships than those that pass through the Panama Canal. For comparison, the new third set of locks in the Panama expansion will only be long, wide, and deep.
No water from Lake Nicaragua is planned to be used to flood the locks; water will come from local rivers and recycling using water saving basins. The Camilo lock will be built adjacent to a new dam of the upper Punta Gorda River that creates a reservoir. This Atlanta Reservoir (or Lake Atlanta) will have a surface area of 395 km2. West of the Atlanta reservoir, the Rio Agua Zarca will be dammed to create a second reservoir. This reservoir would have a surface area of 48.5 km2 and hold 1,100 gigalitres. A hydropower facility will be built at the dam and is expected to generate over 10 megawatts of power to be used for Camilo Lock operations. Both locks would also be connected to the country’s power grid and have back-up generator facilities. It is estimated that each lock will use about 9 megawatts of power.
At each oceanic canal entrance, breakwaters and port facilities will be constructed. The Pacific port will be named Brito Port and the Caribbean one Aguila Port. Initially these two ports will help during construction and later become international ports. Their design capacity is 1.68 million TEU/year and 2.5 million TEU/year, respectively. Existing port facilities at Corinto and Bluefields will be improved to allow for shipment of material to the entry ports under construction. Fuel storage sites will be placed at the two port sites. Four lighthouses will be constructed at the entrances to the East and West Canals. In addition, the channel entrance on sea will be marked on both sides with a large sailing buoy about offshore and 2 light buoys will mark the passage through Lake Nicaragua. Navigation and lock control centers will be established.
A free trade zone with commercial facilities as well as tourist hotels and an international airport at Rivas are planned to be built when canal construction is advanced.
Appropriate road improvements are planned. The Pan-American Highway would cross the canal via a bridge. Nicaragua Route 25 (Acoyapa-San Carlos) on the eastern side of Lake Nicaragua would get a ferry service. Both ports would get public road connections. HKND plans to construct a private gravel maintenance road on both sides of the canal.
The estimate for the workforce in 2020 when the project is completed is 3,700 people, and 12,700 in 2050 when traffic has increased.
Transit time will be about 30 hours. It is projected that by 2020 3,576 ships will pass the canal annually. The transit rate is expected to increase to 4,138 by 2030, and to 5,097 by 2050. For comparison, the Panama Canal handled 12,855 transits in 2009.
Construction.
, no significant construction has taken place. No "major works" such as dredging will take place until after a Pacific Ocean wharf is finished and the wharf's construction will not start until sometime after August 2016.
The apparent lack of experience of Wang Jing and his HKND Group in large-scale engineering has been cited as a risk. Due to Nicaragua's volatile climate and seismic activity, it has also been questioned whether or not the canal is feasible.
On December 22, 2014, the China-backed canal announced construction started in Rivas, Nicaragua. HKND Group Chairman Wang Jing spoke during the starting ceremony of the first works of the Interoceanic Grand Canal in Brito town. Construction of the new waterway will by HKND Group—Hong Kong-based HK Nicaragua Canal Development Investment Co Ltd., which is controlled by Wang Jing. According to HKND's announced plans, , the project entails the canal's development and building, and a supporting infrastructure. There will be four general phases. The pre-construction phase included getting permits, acquiring land and machinery and finalizing designs and plans. The early construction phase, started in December 2014, will last through September 2015: it secures access to construction sites, provides the critical infrastructure and mobilizes the workforce. During the construction phase from September 2015 to March 2020, the canal will be dug and the locks built along with accompanying infrastructure. The commissioning phase from April 2020 to June 2020 includes lock testing and lock and tug boat operator training.
HKND describes the project as the largest civil earthmoving operation in history. Most of this will consist of dry excavation to form the canal with an estimate of 4,019 MCM (million cubic metres) of rock and soil. There will be 739 MCM of freshwater dredging (Lake Nicaragua) and 241 MCM of marine dredging. Marine dredging of the oceanic access canal will be required on the Pacific side for 1.7 km and on the Caribbean Sea for 14.4 km. Disposal of excavation material will be done usually along the canal in designated disposal areas typically within 3 km of the canal.
Two concrete plants and a steel plant are planned to support the project. While cement will probably be imported, construction aggregate will come from local quarries near the two locks.
HKND estimates that about 50,000 people will be employed during the 5-year construction, about half of them from Nicaragua, 25% from China, and the remainder from various countries. 1,400 workers will be in office or administrative positions and the rest in the field. The management offices will be rented or purchased near Rivas. Workers will live in one of nine camps, which besides food and shelter would also provide health care and security. These are “closed” camps, that is workers cannot leave the camp unless part of an organized activity. The work schedule calls for 12-hour shifts for seven days a week. Domestic workers work two weeks and get one week off, while foreign workers are 6 weeks on and get 2 weeks off (management) or 22 weeks on, 4 weeks off (blue collar workers).
On 2 September 2015, Pang Wai Kwok (Executive VP of HKND Group) was interviewed by Nicaraguan journalist Carlos Solis and said up to 3,000 people might be employed on the canal project within the year. However, the labor force depends on the contract bid's winner and Mr. Kwok said anyone in the world is eligible to work on the canal.
Financing.
Project costs are estimated in the region of 40 to 50 billion US dollars
Beside private money provided by Wang Jing at the start-up, further influx of financial support is expected from investors. An IPO was reported to be in preparation by the end on 2014.XCMG, a state-owned Chinese construction company will provide machinery and take 1.5 to 3% of HKND shares in return.
As of the end of 2014, no major investors had been named. There had been speculation that the Chinese government would provide financial backing for the project, but China as well as Wang Jing denied this. Wang Jing lost nearly 85% of his wealth during the 2015 Chinese stock market crash, according to the Bloomberg Billionaires Index.
The economic development potential for the canal project is relatively measurable with Panama, however the World Bank describes the country of Nicaragua as the second poorest in Latin America and the Caribbean. The World Bank has compiled a data list of projects that the impoverished nation has on record and the majority of the efforts are geared towards infrastructure and agricultural needs, but there is no explicit title project that will support the canal line of effort.
Wang Jing admitted that the project has financial, political and engineering risks. With the high cost of the project that independently has been estimated to be about 100 billion US dollars, it remains to be seen if it will be fully funded.
The project is supposed to be completed in 2020, but Stratfor, an analyst agency, believes this target to be an “unrealistic goal”. As the Panama Canal still has capacity and is undergoing a renovation, projections for the Nicaragua canal's traffic may be optimistic. Further, a coast-to-coast railway line may be built by China in Honduras and could affect utilization of the canal.
Also, North American land bridges in Mexico and the United States will compete in the traffic between Asia and the United States' east coast. Thus, competition may undermine the canal's economic viability.
While the Nicaraguan National Bank reserves serve as collateral on the part of Nicaragua, HKND has no such potential liability.
Environmental impact.
A major environmental concern is the project's impact on Lake Nicaragua, the largest source of freshwater in Nicaragua. An oil spill would have serious and lasting consequences. Other problems include the possibility of dredging bringing up toxic sediments, the disruption of migration patterns of animal species, and the potential to introduce invasive species to the Lake. Environmental studies had not been released by HKND when the project officially started in December 2014. Claims by the Nicaraguan Academy of Sciences that hundreds of thousands of hectares of pristine forests and wetlands would be destroyed and that the environmental study performed for the canal was not independent were refuted by several scientists who participated in the environmental impact study performed by ERM.
The protesters also fear that the canal will bring massive environmental destruction to Lake Nicaragua and the Atlantic Autonomous Regions.
Safety.
Richard Condit, from the Smithsonian Tropical Research Institute, believes that the project will develop environmental protection in a country that currently lacks "institutional capacity" to meet ecological demand. A Canadian pilot was the first fatality during the Hong Kong-led Nicaragua Canal project as of October 2, 2015. Historically, the construction phase has caused the highest amount of casualties as noted during the French effort on the Panama Canal. Mr. Atkinson was flying alone on the western side of Lake Nicaragua during an aerial survey.
Sustainability.
The survey site was on the same side as NicarAgua-Dulce which is the only ecotourism group in Nicaragua that is affiliated with The International Ecotourism Society and it is located north of the proposed canal site. Falling in line with ecotourism, Nicaragua's Ministry of Environment and Natural Resources has promoted formal workshops at each level of education (primary, secondary and post-secondary), however there is no curriculum relevant to the pending canal project. The American-led Foundation for Sustainable Development (FSD) is another partner that provides training initiatives to Nicaraguans that cannot access formal education. One of FSD's support sites is located at Tola which is within close proximity of the proposed Brito-Pacific canal opening.
The willingness to accept pollution and the Nicaraguan government's ability to declare property rights in favor of an "environmental permit" for HKND is a signal towards measurable and strong sustainability.
Economic impact.
The canal will have an impact on neighboring economies, like Honduras and El Salvador, as they are part of the Mexico-Northern Triangle Free Trade Agreement through the Declaration of Tuxtla Gutiérrez. The GDP of each nation will be influenced by expanded export/import operations and trade cooperation through agencies like the promotion authority in El Salvador.

</doc>
<doc id="22090" url="https://en.wikipedia.org/wiki?curid=22090" title="Nu metal">
Nu metal

Nu metal (also known as nü-metal and ) is a form of that combines elements of with elements of other music genres such as hip hop, alternative rock, funk and grunge. Nu metal bands have drawn elements and influences from a variety of musical styles, including multiple genres of heavy metal. rarely features guitar solos; it is heavily syncopated and based on guitar riffs. Many nu metal guitarists use that are down-tuned to play a heavier sound. DJs occasionally are featured in nu metal to provide instrumentation such as sampling, turntable scratching and electronic backgrounds. Vocal styles in include singing, rapping, screaming and growling. Nu metal is one of the key genres of the New Wave of American Heavy Metal.
At the time of the release of Korn's 1996 album "Life is Peachy", the popularity of nu metal was beginning to grow, and broke into the mainstream in 1998. In the late 1990s, some bands were blending nu metal with other music genres. For example, industrial metal elements were incorporated into the music of Static-X and Dope. In 2003, MTV wrote that popularity was declining, but still had mainstream success. During the mid-2000s, lost popularity and metalcore became one of the most popular genres within the New Wave of American Heavy Metal. During this period, classic rock-inspired bands and emo bands grew in popularity and exceeded the declining popularity of nu metal. Also, during this period, many nu metal bands experimented with other styles of music, or in some cases, changed their style altogether.
Characteristics and fashion.
Nu metal is also known as nü-metal and aggro-metal. Considered a form of alternative metal, nu metal merges elements of heavy metal music with elements of other music genres such as grunge, hip hop, funk and alternative rock.
Nu metal bands have been influenced by and have used elements of a variety of musical genres, including electronic music, funk, grunge, gothic rock, hardcore punk, death metal, hip hop, punk rock, dance music, new wave music, industrial metal, jazz, post-punk, symphonic rock and synthpop. Nu metal bands also are influenced by and use elements of genres of heavy metal music such as death metal, rap metal, groove metal, funk metal, alternative metal and thrash metal. Some nu metal bands such as Static-X and Dope made nu metal music with elements of industrial metal.
Nu metal music is heavily syncopated and is based on guitar riffs. Mid-song bridges and a general lack of guitar solos contrasts it with other genres of heavy metal. Kory Grow of "Revolver" wrote, " ... n its efforts to tune down and simplify riffs, effectively drove a stake through the heart of the guitar solo". Another contrast with other heavy metal genres is nu metal's emphasis on rhythm, rather than on complexity or mood, often its rhythm sounds like that of groove metal. The wah pedal is occasionally featured in nu metal music. Nu metal guitar riffs occasionally are similar to death metal guitar riffs. Nu metal bassists and drummers are often influenced by funk and hip hop, respectively, adding to nu metal's rhythmic nature. Blast beats, which are common in heavy metal subgenres such as black metal and death metal, are extremely rare in nu metal. Nu metal's similarities with many heavy metal subgenres include its use of common time, distorted guitars, power chords and note structures primarily revolving around Dorian, Aeolian or Phrygian modes.
Some nu metal bands use seven-string guitars that are generally down-tuned, rather than traditional six-string guitars. This results in bass guitarists using five-string and six-string instruments. Bass guitar-playing in nu metal often features an emphasis on funk elements. In nu metal music, DJs are sometimes featured to provide instrumentation such as sampling, turntable scratching and electronic backgrounds. Nu metal tends to have hip hop grooves and rhythms.
Nu metal has a participation of female musicians, in contrast with many other heavy metal subgenres; Kittie is an all-female band and there is at least one female member in nu metal bands such as Coal Chamber and Otep.
Vocal styles used in nu metal music include singing, rapping, screaming and growling. Vocals in nu metal are often rhythmic and influenced by hip hop. Lyrics in nu metal songs are often angry or nihilistic; many of the genre's lyrics focus on topics such as pain, angst, bullying, emotional torture, abandonment, betrayal, and personal alienation, in a way similar to those of grunge. Many nu metal lyrics about these topics tend to be in a very direct tone. However, some nu-metal songs have lyrics that are about other topics. P.O.D. have used positive lyrics about promise and hope. The nu metal song "Bodies" by Drowning Pool is about moshing. Wayne Swinny of the nu metal band Saliva said that the band's song "Badass" was "meant to be one of those 'sports anthem kind of songs'". "The Michigan Daily" wrote about Limp Bizkit's lyrics, writing that the band "used the nu-metal sound as a way to spin testosterone fueled fantasies into snarky white-boy rap. Oddly, audiences took frontman Fred Durst more seriously than he wanted, failing to see the intentional silliness in many of his songs". Limp Bizkit's lyrics also have been described as "misogynistic". Dope's lyrics are usually about sex, drugs, parties, women, violence and relationships. In contrast with other heavy metal subgenres, Nu metal tends to use the same structure of verses, choruses and bridges as those in pop music.
Nu metal bands occasionally feature hip hop musicians as guests in their songs; Korn's song "Children of the Korn" features the rapper Ice Cube, who performed on the band's 1998 Family Values Tour. The hip hop musician Nas was featured on Korn's song "Play Me", which is on the band's album "Take a Look in the Mirror". Limp Bizkit has recorded with multiple hip hop musicians including Method Man, Lil Wayne, Xzibit, Redman, DMX and Snoop Dogg. Linkin Park collaborated with hip hop musician Jay Z on their 2004 extended play "Collision Course". Kid Rock has recorded with hip hop musicians Eminem and Snoop Dogg. Trevor Baker of "The Guardian" wrote, "Bands such as Linkin Park, Korn and even the much reviled Limp Bizkit ... did far more to break down the artificial barriers between 'urban music' and rock than any of their more critically acceptable counterparts. Their concerts also drew huge numbers of women, which is much more than you could say for any old-metal band."
Nu metal fashion consists of baggy pants, shirts, and shorts, JNCO jeans, Adidas tracksuits, sports jerseys, baseball caps, baggy hoodies, cargo pants, sweatpants, dreadlocks, wallet chains, spiky hair, chin beards, tattoos, bald heads, goatees, bleached or dyed hair, and piercings, especially facial piercings. Nu metal fashion has been compared to hip hop fashion. Some nu metal bands such as Hollywood Undead, Motograter, Mushroomhead, Mudvayne, and Slipknot wear masks, jumpsuits, costumes, face paint, corpse paint or body paint.
Predecessors and influences.
Many heavy metal, alternative metal, industrial, funk metal, alternative rock, experimental metal, rap metal, grunge and industrial metal artists and bands of the 1980s and 1990s have been credited with laying groundwork for the development of nu metal by combining heavy guitar riffs with pop music structures, and drawing influences from subgenres of heavy metal and other music genres. Faith No More, White Zombie, Mr. Bungle, Red Hot Chili Peppers, Jane's Addiction, Primus, Rage Against the Machine, Helmet, Soundgarden, Prong, Alice in Chains, Godflesh, Nine Inch Nails and Ministry all have been highlighted as examples of this.
Groove metal and thrash metal bands of the same era such as Pantera, Slayer, Sepultura, Metallica and Anthrax have also been cited as influential to nu metal. For example, Anthrax pioneered the rap metal genre by combining hip hop and rap with heavy metal on their 1987 EP "I'm the Man", which laid groundwork for development. Korn's lead vocalist Jonathan Davis said about Pantera guitarist Dimebag Darrell, "if there was no Dimebag Darrell, there would be no Korn". Tool, a band cited as influential to nu metal, influenced the bands Mudvayne, Limp Bizkit, and Otep.
In the 1990s, bands described as "neo-metal" by the author Garry Sharpe-Young emerged; these bands include Pantera, Strapping Young Lad, Machine Head, Biohazard and Fear Factory. Sharpe-Young wrote that these bands "had chosen to strip metal down to its raw, primal element" and that "neo-metal paved the way for nu-metal".
Nu metal is often influenced by hip hop; The hip hop group Beastie Boys are very influential on nu metal. Hip hop musicians Dr. Dre and Ice Cube have been a big influence on nu metal pioneers Korn; guitarist Munky said the band were trying to emulate the samples of Dr. Dre's 1992 album "The Chronic". Munky and fellow Korn guitarist Head also said they tried to emulate samples by the hip hop group Cypress Hill. Both the Geto Boys and N.W.A. also have been a major influence on Korn. Fred Durst of Limp Bizkit has cited the hip hop group The Fat Boys as a major influence on him. The nu metal band Papa Roach cited rapper Nas and hip hop groups and Fugees as influences. Shifty Shellshock of the nu metal band Crazy Town cited Run–D.M.C. and Beastie Boys as influences. Josey Scott of the nu metal band Saliva cited Run–D.M.C., LL Cool J, Beastie Boys, Public Enemy, N.W.A., Chuck D, Doug E. Fresh, and Whodini as influences. Sonny Sandoval of the nu metal band P.O.D. cited hip hop groups Boogie Down Productions and Run–D.M.C. as influences. Linkin Park member Mike Shinoda's hip hop influences include Boogie Down Productions, Public Enemy, N.W.A., and the Juice Crew. Chester Bennington, another member of Linkin Park, cited A Tribe Called Quest, KRS-One, Run–D.M.C., Public Enemy, N.W.A., Beastie Boys, and Rob Base as influences.
History.
Early development and rise (early–mid 1990s).
Joel McIver acknowledged Korn as the band that pioneered the nu metal genre with its demo "Neidermayer's Mind", which was released in 1993. McIver also acknowledged Korn as the band that started the New Wave of American Heavy Metal, which is a heavy metal music movement that started in the 1990s. The aggressive riffs of Korn, the rapping of Limp Bizkit, and the acoustic ballads of Staind created the sonic template for nu metal. The origins of the term nu metal are often attributed to the work of producer Ross Robinson, who has been called "The Godfather of Nu Metal". Robinson has produced for nu metal bands such as Korn, Limp Bizkit and Slipknot. Many of the first nu metal bands, such as Korn and Deftones, came from California. Other notable nu metal bands are Staind from Massachusetts, Limp Bizkit from Florida and Slipknot from Iowa. In the book "Brave Nu World", Tommy Udo wrote about the nu metal band Coal Chamber, "There's some evidence to suggest that Coal Chamber were the first band to whom the tag 'nu metal' was actually applied, in a live review in Spin magazine."
In 1994, Korn released their self-titled debut album, which is widely considered the first nu metal album. Korn had experienced underground popularity at this time; their debut album peaked at number 72 on the "Billboard" 200. The nu metal band P.O.D.'s album "Snuff the Punk" also is considered one of the first nu metal albums. Like Korn's self-titled debut album, "Snuff the Punk" also was released in 1994. Nu metal achieved recognition through MTV and Ozzy Osbourne's 1995 introduction of Ozzfest, which led the media to talk of a resurgence of heavy metal. Ozzfest was integral to the launching of the careers of many nu metal bands, including Limp Bizkit in 1998. Sepultura incorporated elements of nu metal into their 1996 album "Roots", which was inspired by Korn's self-titled debut album. "Roots" paved the way for the nu metal scene that followed in its wake. Few bands were playing nu metal until 1997 when bands such as Snot, Coal Chamber, Limp Bizkit, Papa Roach and Sevendust all released their debut albums.
Nu metal began to rise in popularity when Korn's 1996 album "Life Is Peachy" peaked at number 3 on the "Billboard" 200 and sold 106,000 copies in its first week of being released. Korn's albums "Life is Peachy" and "Korn" both were certified 2x platinum by the Recording Industry Association of America (RIAA) on November 10, 1999. In 1997, Deftones released their album "Around the Fur", which peaked at number 29 on the "Billboard" 200 chart, remained on that chart for at least 17 weeks and sold 43,000 copies in its first week of release. Deftones' albums "Around the Fur" and "Adrenaline" both were certified gold in 1999. In 1997, Sugar Ray broke into the mainstream; their album "Floored" was released in 1997 and went double-platinum in less than one year. Coal Chamber's self-titled album peaked at number 10 on the Top Heatseekers chart in 1998 and was certified gold by the RIAA in December 1999.
Mainstream popularity (late 1990s and early 2000s).
1998 is generally recognized as the year when nu metal broke into the mainstream when Korn's third album, "Follow the Leader", which peaked at number 1 on the "Billboard" 200, became a multi-platinum hit, and paved the way for other nu metal bands. At this point, many nu metal bands were signed to major record labels, and were playing combinations of heavy metal, hip hop, industrial, grunge and hardcore punk styles. Musical artists and groups such as Cypress Hill, Sepultura, Vanilla Ice, Primus, Fear Factory, Machine Head, and Slayer released albums that draw from the nu metal genre. In "Sound of the Beast: The Complete Headbanging History of Heavy Metal", Ian Christie wrote that the nu metal genre demonstrated that "pancultural metal could pay off".
In 1999, Korn's fourth studio album "Issues" peaked at number 1 on the "Billboard" 200. The album was certified 3x platinum in one month. The album sold at least 573,000 copies in its first week of release and its first single "Falling Away From Me" peaked at number 99 on the "Billboard" Hot 100. A little before the album was released, Korn appeared on an episode of "South Park" titled "Korn's Groovy Pirate Ghost Mystery", in which "Falling Away from Me" was premiered. During the late 1990s and early 2000s, multiple nu metal bands such as Korn, Limp Bizkit and P.O.D. appeared constantly on MTV's "Total Request Live".
Woodstock 1999 festival featured multiple nu metal artists and bands such as Korn, Kid Rock, Godsmack, Limp Bizkit and Sevendust. During and after Limp Bizkit's performance at the festival, violence occurred and people tore plywood from the walls during the performance of the band's song "Break Stuff". Several sexual assaults were reported to have happened during the festival; a rape that was said to have occurred during Limp Bizkit's performance and gang rape was reported to have occurred during Korn's set at the festival. Limp Bizkit's vocalist Fred Durst said during his band's Woodstock 1999 concert, "People are getting hurt. Don't let anybody get hurt. But I don't think you should mellow out. That's what Alanis Morissette had you motherfuckers do. If someone falls, pick 'em up. We already let the negative energy out. Now we wanna let out the positive energy." Durst was accused of inciting violence at the festival. In an interview about the Woodstock 1999 incident, Durst said, "I didn't see anybody getting hurt. You don't see that. When you're looking out on a sea of people and the stage is twenty feet in the air and you're performing, and you're feeling your music, how do they expect us to see something bad going on?" Les Claypool, a member of the band Primus, said, "Woodstock was just Durst being Durst. His attitude is 'no press is bad press', so he brings it on himself. He wallows in it. Still, he's a great guy." Tom Morello of Rage Against the Machine referred to Woodstock 1999 as "the low point of nu metal". Despite the incident at the festival, Limp Bizkit's popularity and the sales of their then-recent album "Significant Other" were not affected.
The nu metal band Orgy became popular in the late 1990s with their album "Candyass", which was certified platinum by the RIAA. The band's cover of "Blue Monday" by New Order peaked at number 56 on the "Billboard" Hot 100. Godsmack's was released in 1998 and was certified 4x platinum. In April 1999, Kid Rock's album "Devil Without a Cause" was certified by gold by the RIAA. The following month, "Devil Without a Cause", as Kid Rock predicted, went platinum. The album sold at least 9,300,000 copies in the United States and was certified 11x platinum. In 1999, Slipknot emerged with an extremely heavy nu metal sound, releasing their self-titled album, which was certified 2x platinum. In a review of the band's self-titled album, Rick Anderson of AllMusic wrote about Slipknot, "You thought Limp Bizkit was hard? They're the Osmonds. These guys are something else entirely." Limp Bizkit's second album "Significant Other", released in 1999, peaked at number 1 on the "Billboard" 200, selling 643,874 copies in its first week of release. In its second week, the album sold 335,000 copies. "Significant Other" by Limp Bizkit sold at least 7,237,123 copies in the United States and was certified 7x platinum.
In 1999, Staind's second album "Dysfunction" was released; the track "Mudshovel" peaked at number 10 on the Mainstream Rock chart. "Dysfunction" was certified 2x platinum by the RIAA. In 2000, Limp Bizkit's third studio album "Chocolate Starfish and the Hot Dog Flavored Water" set a record for highest week-one sales of a rock album, selling over one million copies in the United States in its first week of release—400,000 of which sold on its first day of release, making it the fastest-selling rock album ever and breaking the world record held for seven years by Pearl Jam's "Vs." "Chocolate Starfish and the Hot Dog Flavored Water" by Limp Bizkit sold at least 8,000,000 copies in the United States. That same year, both Papa Roach's second studio album "Infest" and Disturbed's debut studio album "The Sickness" were certified at least platinum. The RIAA certified "The Sickness" 4x platinum and "Infest" 3x platinum. Disturbed's song "Down with the Sickness" has been used as entrance music by the National Football League team the Dallas Cowboys. Papa Roach's song "Last Resort" peaked at number 57 on the "Billboard" Hot 100 and at number 1 on the Modern Rock Tracks chart. In 2000, P.O.D.'s album "The Fundamental Elements of Southtown" went platinum in the United States and was the 143rd best-selling album of 2000. The album's song "Rock the Party (Off the Hook)" peaked at number 1 on MTV's "Total Request Live". In 2000, the hip hop group Cypress Hill released their fifth studio album "Skull & Bones", which features a and rap metal style. The album went platinum in the United States in two months. During the early 2000s, the nu metal band Incubus was very popular and made the albums "Make Yourself" and "Morning View", which both were certified 2x platinum by the RIAA.
Late in 2000, Linkin Park released their debut album "Hybrid Theory", which is both the best-selling debut album by any artist in the 21st century and the best-selling nu metal album of all time. The album was also the best-selling album of 2001, selling more than albums "Celebrity" by NSYNC and "Hot Shot" by Shaggy. Linkin Park earned a Grammy Award for their second single "Crawling". Their fourth single, "In the End", was released late in 2001 and peaked at number 2 on the "Billboard" Hot 100 in March 2002. In 2001, the band's album "Hybrid Theory" sold 4,800,000 copies in the United States, making it the highest-selling album of the year. Linkin Park's album "Hybrid Theory" was certified diamond by the RIAA and sold at least 10,222,000 copies in the United States. In 2000, Snot released the album "Strait Up", which is a tribute to Snot's former vocalist James Lynn Strait, who died in a car accident in December 1998. The album features multiple nu metal musicians including Jonathan Davis, Fred Durst, Corey Taylor, Mark McGrath, Max Cavalera, Brandon Boyd, DJ Lethal and Dez Fafara. The album peaked at number 56 on the "Billboard" 200. In 2000, Godsmack released their second studio album "Awake", which was certified 2x platinum. The album's title track peaked at number 1 on the Mainstream Rock chart. Both the album's title track and the song "Sick of Life" have been featured on the United States Navy's television commercials.
The nu metal band Crazy Town broke into the mainstream with their hit song, "Butterfly", which peaked at number 1 on many charts, including the "Billboard" Hot 100 during March 2001, remaining on the chart for 23 weeks. It also peaked at number 1 on the Modern Rock Tracks chart and the Hot Dance Single Sales chart, number 6 on the Rhythmic Top 40, number 2 on the Mainstream Top 40 chart and number 4 on the Top 40 Tracks chart. The band's album "The Gift of Game" peaked at number 9 on the "Billboard" 200, went platinum and sold at least 1,500,000 copies in the United States. Worldwide, the album sold at least 2,500,000 copies. Staind's 2001 album "Break the Cycle" debuted at number 1 on the Billboard 200 with at least 716,000 copies sold in its first week of release, selling more than albums such as "Survivor" by Destiny's Child, "Lateralus" by Tool and "Miss E… So Addictive" by Missy Elliot. "Break the Cycle" by Staind was certified 5x platinum by the RIAA. In March 2001, the nu metal band Saliva released their second album "Every Six Seconds" and the album was certified platinum. The album's song "Click Click Boom" was used as the theme song for WWE's No Mercy event of 2001. "Click Click Boom" also has been played during football games. Saliva's song "Your Disease" peaked at number 7 on "Billboard" Modern Rock Tracks chart and peaked at number 3 on "Billboard" Mainstream Rock chart.
In 2001, Slipknot released their album "Iowa", which peaked at number 3 on the "Billboard" 200 and went platinum. Critic John Mulvey called the album the "absolute triumph of nu metal". At the 2001 MTV Video Music Awards, Mudvayne's nu metal song "Dig" won the MTV2 Award, beating the commercially successful song "Fallin'" by Alicia Keys. The song "Dig" by Mudvayne received a lot of on-air rotation. P.O.D.'s 2001 album "Satellite" went triple-platinum and peaked at number 6 on the "Billboard" 200. P.O.D.'s popularity continued in the year 2002. On June 5, 2001, Drowning Pool released a nu metal album titled "Sinner", which features the song "Bodies". The album went platinum on August 23, 2001 and its song "Bodies" became one of the most frequently played videos on MTV for new bands. "Bodies" peaked at number 6 on the Mainstream Rock chart and was used by Boston Red Sox closer Jonathan Papelbon as his theme song.
Alien Ant Farm's 2001 album "Anthology", which has been described as nu metal, peaked at number 1 on the Top Heatseekers chart and includes a cover of Michael Jackson's song "Smooth Criminal". Alien Ant Farm's cover of "Smooth Criminal" peaked at number 23 on the "Billboard" Hot 100. The album "Anthology" by Alien Ant Farm sold at least 1,900,000 copies in the United States and was certified platinum by the RIAA in the year it was released in. In 2002, the soundtrack album for the film "The Scorpion King" was released and peaked at number 1 on the Top Soundtracks chart; it features multiple nu metal bands such as Drowning Pool, Coal Chamber, Lifer, Sevendust, Flaw and Godsmack. Godsmack's track "I Stand Alone" was the most played active rock song in 2002 for fourteen consecutive weeks. "I Stand Alone" also peaked at number 1 on the Mainstream Rock chart. In March 2002, the compilation album "Now That's What I Call Music! 9" was released. It included the song "Giving In" by the nu metal band Adema; the album peaked at number 1 on the "Billboard" 200 and was certified double platinum by the RIAA.
In 2003, MTV wrote that nu metal's mainstream popularity was declining, citing that Korn's long-awaited fifth album "Untouchables" and Papa Roach's third album "Lovehatetragedy" both sold less than the bands' previous releases. Korn's lead vocalist Jonathan Davis blamed music piracy for the amount of sales of "Untouchables" because the album had been leaked to the Internet more than four months before its official release date. MTV also wrote that nu metal bands were played less frequently on radio stations and MTV began focusing other musical genres. MTV wrote that Papa Roach's third album "Lovehatetragedy" has less hip hop elements than the band's previous album "Infest" and also said that Saliva's 2002 album "Back into Your System" has less elements than the band's 2001 album "Every Six Seconds". MTV also wrote that Crazy Town's second album "Darkhorse" had no hit singles and sold less than the band's previous album "The Gift of Game". MTV wrote that although Kid Rock's album "Cocky" had characteristics of the musician's 1998 album "Devil Without a Cause", "Cocky" song "Forever", which featured the style of Kid Rock's song "Bawitdaba", was not as popular as "Cocky" country song "Picture". MTV also wrote, "Another cause for nü-metal and rap-rock's slip from the spotlight could be a diluted talent pool caused by so many similar-sounding bands. American Head Charge, Primer 55, Adema, Cold, the Union Underground, Dope, Apartment 26, Hed (Planet Earth) and Skrape—all of whom released albums between 2000-2001—left more of a collective impression than individual ones". Despite what MTV wrote, the RIAA certified Korn's album "Untouchables" platinum, and one of the album's singles, "Here to Stay", peaked at number 72 on the "Billboard" Hot 100, had a lot of radio play, and peaked at number one on MTV's "Total Request Live" twice. "Untouchables" sold at least 434,000 copies in first week of release and peaked at number 2 on the Billboard 200. "Thoughtless", another single from the album, also proved to be very successful. The song reached number 11 on the "Billboard" Modern Rock Tracks chart and number 6 on the "Billboard" Mainstream Rock chart. However, "Untouchables" still did not sell as many copies as Korn's most commercially successful album, "Follow the Leader". Papa Roach's song "She Loves Me Not" from the band's 2002 album "Lovehatetragedy" peaked at number 76 on the "Billboard" Hot 100.
Despite the decline in sales of bands such as Korn and Papa Roach, nu metal remained extremely popular with bands such as Linkin Park, Taproot, Godsmack, Trapt and Evanescence. Taproot's song "Poem" was popular in 2002 and peaked at number 5 on the "Billboard" Mainstream Rock chart. Linkin Park's remix album "Reanimation" was released in July 2002 and sold more than a million copies that year, which MTV described as "impressive for a remix album". Trapt's 2002 song "Headstrong" launched the band into the mainstream; the song peaked at number 16 on the "Billboard" Hot 100, number 4 on the "Billboard" Pop Songs chart and number 1 on the "Billboard" Mainstream Rock Tracks chart. Trapt's song "Still Frame" peaked at number 69 on the "Billboard" Hot 100. The band's self-titled album was certified platinum in 2003 by the RIAA. Evanescence's debut album "Fallen" was released in March 2003. Johnny Loftus of AllMusic noted the nu metal sound of the album. "Fallen" Grammy Award-winning lead single "Bring Me to Life" peaked at number 5 on the "Billboard" Hot 100. In 2003, Linkin Park's album "Meteora" peaked at number 1 on the "Billboard" 200 and sold at least 810,000 copies in its first week of being released. "Meteora" by Linkin Park and "Fallen" by Evanescence ranked third and fourth respectively on the best-selling albums of 2003. Both Linkin Park and Evanescence released high-charting singles throughout 2003 to "Fallen" by Evanescence sold at least 7,600,000 copies in the United States and "Meteora" by Linkin Park sold at least 6,100,000 copies in the United States. In 2003, Korn released a song called "Did My Time", which peaked at number 38 on the "Billboard" Hot 100. That same year, Godsmack released their third studio album "Faceless", which peaked at number 1 on the "Billboard" 200 and was certified platinum by the RIAA in its first five weeks of being released.
Decline (mid–late 2000s).
After a period of mainstream success of bands such as Trapt, Linkin Park and Evanescence, nu metal declined in popularity. Limp Bizkit's 2003 album "Results May Vary", which features elements of alternative rock and , peaked at number 3 on the "Billboard" 200. Limp Bizkit's cover of The Who's song "Behind Blue Eyes" peaked at number 71 on the "Billboard" Hot 100 and number 25 on the Mainstream Top 40 chart. However, "Results May Vary" sold less than previous Limp Bizkit albums such as "Significant Other" and "Chocolate Starfish and the Hot Dog Flavored Water". Although album's song "Did My Time" peaking at number 38 on the "Billboard" Hot 100, Korn's 2003 album "Take a Look in the Mirror" sold less than their previous albums "Issues" and "Untouchables". Korn struggled to prevent their album "Take a Look in the Mirror" being leaked to the Internet; the band's bassist Reginald Arvizu said, "As soon as we were done listening to the CD, we destroyed it. We didn't go online with it. I think that's how leak happened the last time." Korn released "Take a Look in the Mirror" earlier than planned because some songs from the album, including "Right Now" and "Break Some Off", had already been leaked to the Internet. In 2004, classic rock-inspired bands such as Jet and The Darkness were achieving mainstream success as the popularity of nu metal declined. The popularity of emo exceeded the declining popularity of nu metal. During the mid-2000s, metalcore, a fusion of extreme metal and hardcore punk, became one of the most popular genres in the New Wave of American Heavy Metal.
In the mid-to-late 2000s, many nu metal bands experimented with other genres and sounds. Linkin Park's third studio album "Minutes to Midnight", released in 2007, was noted for its complete departure from the band's nu metal sound. Nu metal bands such as Disturbed and Drowning Pool moved to a hard rock or standard heavy metal sound. Slipknot also departed from their nu metal sound and included elements of groove metal, death metal and thrash metal into their music. Staind and Papa Roach moved to lighter sounds. Staind's 2003 album "14 Shades Of Grey" does not express as much anger as the band's previous albums and shows the band's departure from heavy metal elements and a movement towards a lighter sound. Papa Roach abandoned the nu metal genre with their 2004 album "Getting Away with Murder", moving to a hard rock style.
Soulfly moved away from the nu metal style and moved to styles such as death metal and thrash metal. Kittie abandoned the nu metal style and started making music with elements of genres such as black metal and death metal. Korn and Mudvayne maintained their popularity during the mid-2000s. Korn's songs "Coming Undone" and "Twisted Transistor", which both are on their 2005 album "See You on the Other Side", reached the "Billboard" Hot 100; although they did not abandon the nu metal style, Korn added industrial elements and moved onto a different sound. Pop music producers The Matrix helped produce the band's album "See You on the Other Side". Mudvayne's 2005 album "Lost and Found" showed a change in the band's musical style. The album's song "Happy?" peaked at number 89 on the "Billboard" Hot 100 and at number 91 on "Billboard" Pop 100 chart. In 2005, Limp Bizkit released a record called "The Unquestionable Truth (Part 1)" without promoting and advertising the record. The album was not very popular; its sales fell 67% during its second week of release. In 2006, Limp Bizkit went on hiatus.
Fusion with other genres and revival (2010s).
During the 2010s, there was a discussion within media of a possible nu metal revival because of bands fusing nu metal with other genres, the return of nu metal bands, extant bands going back to the nu metal genre and nu metal bands forming. Despite the lack of radio play and popularity, some nu metal bands recaptured some of their former popularity as they released albums in a nu metal style. Korn's 2010 studio album "" sold 63,000 copies during its first week of release and peaked at number 2 on the "Billboard" 200. As of December 6, 2011, the album had sold at least 185,000 units in the United States. Korn's vocalist Jonathan Davis said with their new album the band "want to go back to that old-school vibe". He also said "It's gonna be very raw, it's gonna be old school like the first Korn records".
In 2011, Limp Bizkit's long-awaited sixth studio album "Gold Cobra" was released; it sold 27,000 copies during its first week in the United States and peaked at number 16 on the "Billboard" 200. That same year, Staind's self-titled album was released; it shows the band returning to their heavier nu metal style. The album debuted at number 5 on the "Billboard" 200, selling 47,000 copies in its first week of release, making it the band's fifth consecutive top-five album. In October 2011, Evanescence's self-titled album debuted at number 1 on the "Billboard" 200 and other United States charts and sold over 127,000 copies in the first week. In December that year, Korn released their album "The Path of Totality", which sold 55,000 copies in its first week. The album combines nu metal with dubstep. Both the "Phoenix New Times" and the "LA Weekly" cited "The Path of Totality" as a new direction for nu metal. The album won a Revolver Golden God award for "Album of the Year". In 2012, Papa Roach released their album "The Connection". While mostly featuring elements of hard rock, the album also shows the band returning to the nu metal and rap rock style.
Nu metal-influenced metalcore and deathcore bands such as Emmure, Here Comes the Kraken, Suicide Silence, Of Mice & Men and Issues all either gained moderate popularity or an underground following in the 2010s. Suicide Silence's 2011 album "The Black Crown", which features elements of nu metal and deathcore, peaked at number 28 on the "Billboard" 200. In 2014, Issues' self-titled debut album peaked at number 9 on the same chart. The album features elements of metalcore, nu metal, pop and R&B. In September 2013, My Ticket Home released an album called "Strangers Only", which features elements of nu metal and shows the band moving away from their former metalcore sound. Of Mice & Men's 2014 album "Restoring Force", which features elements of nu metal, peaked at number 4 on the "Billboard" 200.
In 2014, Linkin Park released their sixth studio album "The Hunting Party". The album shows the band returning to the genre. The album peaked at number three on the "Billboard" 200 behind Lana Del Rey's album "Ultraviolence" and Sam Smith's album "In the Lonely Hour", with first-week sales of 110,000 copies in the United States. Linkin Park's song "Until It's Gone" was nominated for the Best Rock Video category on the 2014 MTV Video Music Awards, but lost to Lorde's song "Royals". Also, MTV offered fans a chance to meet Linkin Park. In 2014, Islander released their debut album "Violence & Destruction". Critics noted the nu metal sound of the album and compared it to the bands P.O.D. and Deftones. In 2015, Papa Roach released their album "F.E.A.R.", which features rapping. That same year, Coal Chamber released "Rivals", their first studio album since 2002's "Dark Days". Many critics noted the nu metal sound of the album. In one review of "Rivals", "100% Rock" wrote that Coal Chamber have taken early 2000's style nu metal and "modernized the sound for the current day." Bring Me the Horizon, previously known for a much heavier style of music, released their fifth album "That's the Spirit", which peaked at number 2 on the "Billboard" 200, in 2015. The album draws from multiple genres, including nu metal, and shows the band completely abandoning their metalcore style.
Criticism and controversy.
In spite of both its popularity and the fact that it is a genre of heavy metal music, nu metal has often been criticized by a lot of fans of heavy metal music, often being labelled with derogatory terms such as "mallcore" and "whinecore". Gregory Heaney of AllMusic called nu metal "one of metal's more unfortunate pushes into the mainstream." Lucy Jones of "NME" called nu metal "the worst genre of all time". In "Metal: The Definitive Guide : Heavy, NWOBH, Progressive, Thrash, Death ...", Garry Sharpe-Young described as "a dumbed-down and—thankfully shortlived exercise". When Machine Head moved to nu metal with their album "The Burning Red" and their vocalist Robb Flynn spiked his hair in the fashion of many nu metal musicians, the band were accused of selling out and many fans criticized their change of appearance and musical style. Machine Head's drummer Dave McClain said, "Pissing people off isn't a bad thing, you know? For people to be narrow-minded is bad ... doesn't bother us at all, we know we're going to piss people off with this record, but some people hopefully will actually sit down and listen to the whole record". Robb Flynn, Machine Head's vocalist, said "There's a minute and a half of rapping on that album. The other 53 minutes of the record are like a giant scar being ripped open while I projectile-vomit through it. If all that people got out of ["The Burning Red" was rap-metal, then they didn't fucking listen to it."
Jonathan Davis, the vocalist of Korn, spoke about the criticism of nu metal from heavy metal fans, saying "There's a lot of closed-minded metal purists that would hate something because it's not true to metal or whatever, but Korn has never been a metal band, dude. We're not a metal band. We've always been looked at as what they called the nu-metal thing. But we've always been the black sheep and we never fitted into that kind of thing so ... We're always ever evolving, and we always piss fans off and we're gaining other fans and it is how it is." Lamb of God's vocalist Randy Blythe criticized the nu metal genre and spoke about its loss of popularity in 2004, saying, "Nu-metal sucks, so that's why that's dying off. And I think ... ... people are ready for angrier music. I think people are ready for something that's real, not, you know, 'I did it all for the Nookie.'" Dave Mustaine of the heavy metal band Megadeth said he would "rather have his eyelids pulled out" than listen to nu metal. Gary Holt, a member of the thrash metal band Exodus, said that he "was so glad about" the decline of . Despite the large amount of criticism that the genre received, Jack Porter of "The Michigan Daily" defended , writing "Unfortunately, some barriers prevent listeners from understanding nu-metal bands apart from the identity that genre label has given them—picture a bone-headed suburban white kid sporting a backwards baseball cap. What used to be a descriptor for a specific strain of alternative metal turned into a ghetto for every band that a) plays extremely heavy yet radio-friendly music and b) sucks. Because the genre came to be defined by its lack of quality, many 'serious' music fans have missed out on what it has to offer." Additionally, FasterLouder called nu metal "music's most hated genre" and said that nu metal's "not as bad as people think".
Some musicians who influenced nu metal have tried to distance themselves from the subgenre and its bands. Mike Patton, the vocalist of Faith No More and Mr. Bungle, tried to distance himself from the subgenre and criticized it, even though he is featured on the song "Lookaway" on heavy metal band Sepultura's album "Roots", which also features Jonathan Davis. Patton said of his music's influence on nu metal, "I feel no responsibility for that, it's their mothers' fault, not mine". Helmet member Page Hamilton said, "It's frustrating that people write off because we're affiliated with or credited with or discredited with creating and rap metal ... which we sound nothing like". However, Page Hamilton appeared on the song "All for Nothing" on Linkin Park's album "The Hunting Party".
While Trent Reznor of Nine Inch Nails has said he knows some Korn members and that he thinks they are "cool guys", he also criticized nu metal, saying:
In response to reports that Fred Durst, lead singer of Limp Bizkit, is a big fan of Tool, the latter's vocalist Maynard James Keenan said, "If the lunch-lady in high school hits on you, you appreciate the compliment, but you're not really gonna start dating the lunch-lady, are ya?"
While Durst has cited Rage Against the Machine as a major influence, Tim Commerford of Rage Against the Machine is open about hating Limp Bizkit's music. At the 2000 MTV Video Music Awards, Limp Bizkit won the Best Rock Video category for their song "Break Stuff", beating Rage Against the Machine's "Sleep Now in the Fire". When Limp Bizkit accepted their award, Commerford went on stage and climbed up a backdrop, rocking back and forth. After the incident, Commerford was arrested and spent a night in jail. Tim Commerford called Limp Bizkit "one of the dumbest bands in the history of music". Commerford said, "I do apologize for Limp Bizkit. I really do. I feel really bad that we inspired such bullshit ... They're gone, though. That's the beautiful thing."
Rejection of nu metal label.
Some nu metal musicians have rejected the label nu metal and have tried to distance themselves from it. Slipknot prefer to distance themselves from other nu metal groups, describing their own music as "metal metal" and equate their link to nu metal as a coincidence of their time of emergence.
Jonathan Davis has rejected the nu metal label, saying "We're not 'rap rock,' we're not 'nu-metal ... We might have invented a new genre of heavy music or rock, but I believe the term 'nu-metal' was made up for all the bands that followed us. Those guys to me are nu-metal. And we're just Korn." In 2014, Davis spoke about the nu metal label, saying:
Staind's vocalist Aaron Lewis rejected the nu metal label, saying, "if we get called a 'nu metal' band one more time, I don't even know what I'm going to do! ... We've never been a nu metal band. We never had a DJ. We never had any sort of rap element mixed in. We never fit that bill. I don't want to say it was guilt by association because we were very happy to be associated with some of the bands in that genre."
Chino Moreno, vocalist of Deftones, rejected the nu metal label saying "We told motherfuckers not to lump us in with nu metal because when those bands go down we aren't going to be with them". As Deftones abandoned the nu metal sound of their early work, Moreno tried to distance himself from nu metal bands and began to criticize the bands and their albums, including Korn's 2002 album "Untouchables"; he said, "As Korn go on, it's the same things—bad childhoods and mean moms. It gets too old after a while. How old is Jonathan ? Thirty? How long has it been since he lived with his parents?" Davis responded saying, "Obviously, Chino hasn't listened to the words on the rest of my albums because they're nothing about my parents or my childhood." Moreno also said, "A big problem for me was opening for Limp Bizkit and Linkin Park, two bands that wouldn't exist if it weren't for me, straight up!".
Mike Shinoda of Linkin Park spoke about the nu metal label in an interview with "NME", saying "We never held the flag for nu-metal—it was associated with frat rock. Arrogant, misogynistic, and full of testosterone; we were reacting against that."
Wes Borland of Limp Bizkit said that he "never liked or condoned" the term "nu metal" in any way, and said he does not understand "how so many bands that sound nothing alike can be put into" the nu metal genre.
Despite the fact that multiple nu metal musicians rejected the nu metal label, Limp Bizkit's vocalist Fred Durst defended it, saying "Nu metal let people open up and it meant something to people. It really did." Coal Chamber's vocalist Dez Fafara also defended nu metal. He said he is proud to be associated with the subgenre and that nu metal bands "broke new musical ground" saying, "I think 'hair metal' was cheesy. I think 'nu metal' was different. I think what's beautiful about 'nu metal' is it's different. And you've got so many different influences."
Chester Bennington of Linkin Park said he accepts the nu metal label, saying "I think for the first time in our history, we're actually OK with being recognized as a nu metal band, especially for what we did early in our careers, because the truth is that when we were first doing it, nobody else really was, especially in terms of the hip-hop thing."
Rejection of heavy metal label.
In addition to criticizing nu metal, many heavy metal musicians and fans of heavy metal music have rejected nu metal as a legitimate subgenre of heavy metal, saying it is not "true heavy metal". In a Metal Underground article, writer Mike Smith wrote, "After Korn's 'Follow the Leader' blew the whole movement into orbit in 1998, nu-metal produced some ridiculous bands, to be sure. And to be fair, plenty of them dwelled in the realms of corny rap-rock and dull alternative radio rock with the occasional heavy riff or tendency to scream, making their designation as 'metal' quite dubious indeed ... ut the movement also produced plenty of heavier bands with primarily metal influences". Sepultura's vocalist Derrick Green said, "I don't know if I would say Korn is metal".
Some nu metal musicians have tried to distance themselves from the "heavy metal" label. For example, Korn's Jonathan Davis rejected the "heavy metal" label. When talking with "Vice", Davis spoke about Korn being called a heavy metal band, saying, "I never thought of us to be metal to begin with. Yeah, we're heavy and downtuned, but metal, to me, is like Judas Priest and Iron Maiden. That's metal, man. I always thought of us as a funk band. That funky, groovy shit."
Godsmack's vocalist Sully Erna also rejected the "heavy metal" label and said he views Godsmack as a hard rock band. In an interview, Linkin Park's vocalist Chester Bennington said "I don't think we're a metal band" and also said:
However, some nu metal bands do consider their music "heavy metal". Shortly after releasing their debut album "Spit", Kittie's drummer Mercedes Lander said her band wanted to be recognized as simply a "metal band" rather than as a "girl metal band". Before 2004, Slipknot described their sound as "metal metal". John Connolly, a member of the nu metal band Sevendust, described their music as "some kind of heavy, some kind of rock and some kind of metal".

</doc>
<doc id="22091" url="https://en.wikipedia.org/wiki?curid=22091" title="Ncurses">
Ncurses

ncurses (new curses) is a programming library providing an API that allows the programmer to write text-based user interfaces in a terminal-independent manner. It is a toolkit for developing "GUI-like" application software that runs under a terminal emulator. It also optimizes screen changes, in order to reduce the latency experienced when using remote shells.
History.
The "N" in ncurses comes from the word "new". This is because ncurses is a free-software emulation (clone) of the System V Release 4.0 (SVr4) curses, which was itself an enhancement over the discontinued classic 4.4 BSD curses. The XSI Curses standard issued by X/Open is explicitly and closely modeled on System V.
curses.
The first curses library was developed at the University of California at Berkeley, for a BSD operating system, around 1980 to support a screen-oriented game. It originally used the termcap library, which was used in other programs, such as the vi editor.
The success of the BSD curses library prompted Bell Labs to release an enhanced curses library in their System V Release 2 Unix systems. This library was more powerful and instead of using termcap, it used terminfo. However, due to AT&T policy regarding source-code distribution, this improved curses library did not have much acceptance in the BSD community.
pcurses.
Around 1982, Pavel Curtis started work on a freeware clone of the Bell Labs curses, named pcurses, which was maintained by various people through 1986.
ncurses.
The pcurses library was further improved when Zeyd Ben-Halim took over the development effort in late 1991. The new library was released as ncurses in November 1993, with version 1.8.1 as the first major release. Subsequent work, through version 1.8.8 (1995), was driven by Eric S. Raymond, who added the form and menu libraries written by Juergen Pfeifer. Since 1996, it has been maintained by Thomas E. Dickey.
Most ncurses calls can be easily ported to the old curses. System V curses implementations can support BSD curses programs with just a recompilation. However, a few areas are problematic, such as handling terminal resizing, since no counterpart exists in the old curses.
Terminal database.
Ncurses can use either terminfo (with extensible data) or termcap. Other implementations of curses generally use terminfo; a minority use termcap. Few (mytinfo was an older exception) use both.
License.
Ncurses is a part of the GNU Project. It is one of the few GNU files not distributed under the GNU GPL or LGPL; it is distributed under a permissive free software licence, similar to the MIT License. This is due to the agreement made with the Free Software Foundation at the time the developers assigned their copyright.
When the agreement was made to pass on the rights to the FSF, there was a clause that stated:
The Foundation promises that all distribution of the Package, or of any work "based on the Package", that takes place under the control of the Foundation or its agents or assignees, shall be on terms that explicitly and perpetually permit anyone possessing a copy of the work to which the terms apply, and possessing accurate notice of these terms, to redistribute copies of the work to anyone on the same terms.
According to the maintainer Thomas E. Dickey, this precludes relicensing to the GPL in any version, since it would place restrictions on the programs that will be able to link to the libraries.
Programs using ncurses.
There are hundreds of programs which use ncurses. Some, such as GNU Screen and w3m, use only the termcap interface, performing screen management within the application. Others, such as GNU Midnight Commander and YaST, use the curses programming interface.

</doc>
<doc id="22092" url="https://en.wikipedia.org/wiki?curid=22092" title="NBA (disambiguation)">
NBA (disambiguation)

The NBA is the National Basketball Association, a men's professional basketball league in North America.
NBA may also refer to:

</doc>
<doc id="22093" url="https://en.wikipedia.org/wiki?curid=22093" title="National Basketball Association">
National Basketball Association

The National Basketball Association (NBA) is the pre-eminent men's professional basketball league in North America, and is widely considered to be the premier men's professional basketball league in the world. It has 30 teams (29 in the United States and 1 in Canada), and is an active member of USA Basketball (USAB), which is recognized by FIBA (also known as the International Basketball Federation) as the national governing body for basketball in the United States. The NBA is one of the four major North American professional sports leagues. NBA players are the world's best paid sportsmen, by average annual salary per player.
The league was founded in New York City on June 6, 1946, as the Basketball Association of America (BAA). The league adopted the name National Basketball Association on August 3, 1949, after merging with its rival National Basketball League (NBL). The league's several international as well as individual team offices are directed out of its head offices located in the Olympic Tower at 645 Fifth Avenue in New York City. NBA Entertainment and NBA TV studios are directed out of offices located in Secaucus, New Jersey.
History.
Creation and merger.
The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada. On November 1, 1946, in Toronto, Ontario, Canada, the Toronto Huskies hosted the New York Knickerbockers at Maple Leaf Gardens, in a game the NBA now regards as the first played in its history. The first basket was made by Ossie Schectman of the Knickerbockers. Although there had been earlier attempts at professional basketball leagues, including the American Basketball League and the NBL, the BAA was the first league to attempt to play primarily in large arenas in major cities. During its early years, the quality of play in the BAA was not significantly better than in competing leagues or among leading independent clubs such as the Harlem Globetrotters. For instance, the 1948 ABL finalist Baltimore Bullets moved to the BAA and won that league's 1948 title, and the 1948 NBL champion Minneapolis Lakers won the 1949 BAA title. Prior to the 1948–49 season, however, NBL teams from Fort Wayne, Indianapolis, Minneapolis, and Rochester jumped to the BAA, which established the BAA as the league of choice for collegians looking to turn professional.
Following the 1948–49 season, the BAA took in the remainder of the NBL: Syracuse, Anderson, Tri-Cities, Sheboygan, Denver, and Waterloo. In deference to the merger and to avoid possible legal complications, the league name was changed from the BAA to the National Basketball Association in spite of having the same BAA governing body including Podoloff. The new league had seventeen franchises located in a mix of large and small cities, as well as large arenas and smaller gymnasiums and armories. In 1950, the NBA consolidated to eleven franchises, a process that continued until 1953–54, when the league reached its smallest size of eight franchises: the New York Knicks, Boston Celtics, Philadelphia Warriors, Minneapolis Lakers, Rochester Royals, Fort Wayne Pistons, Tri-Cities Blackhawks, and Syracuse Nationals, all of which remain in the league today. The process of contraction saw the league's smaller-city franchises move to larger cities. The Hawks shifted from the Tri-Cities to Milwaukee in 1951, and then to St. Louis in 1955. The Rochester Royals moved from Rochester, New York, to Cincinnati in 1957 and the Pistons relocated from Fort Wayne, Indiana, to Detroit in 1957.
Japanese-American Wataru Misaka broke the NBA color barrier in the 1947–48 season when he played for the New York Knicks. He remained the only non-white player in league history prior to the first African-American, Harold Hunter, signing with the Washington Capitols in 1950. Hunter was cut from the team during training camp, but several African-American players did play in the league later that year, including Chuck Cooper with the Celtics, Nathaniel "Sweetwater" Clifton with the Knicks, and Earl Lloyd with the Washington Capitols. During this period, the Minneapolis Lakers, led by center George Mikan, won five NBA Championships and established themselves as the league's first dynasty. To encourage shooting and discourage stalling, the league introduced the 24-second shot clock in 1954. If a team does not attempt to score a field goal (or the ball fails to make contact with the rim) within 24 seconds of obtaining the ball, play is stopped and the ball given to its opponent.
Celtics' dominance, league expansion and competition.
In 1957, rookie center Bill Russell joined the Boston Celtics, who already featured guard Bob Cousy and coach Red Auerbach, and went on to lead the club to eleven NBA titles in thirteen seasons. Center Wilt Chamberlain entered the league with the Warriors in 1959 and became a dominant individual star of the 1960s, setting new single game records in scoring (100) and rebounding (55). Russell's rivalry with Chamberlain became one of the greatest rivalries in the history of American team sports.
The 1960s were dominated by the Celtics. Led by Russell, Bob Cousy and coach Red Auerbach, Boston won eight straight championships in the NBA from 1959 to 1966. This championship streak is the longest in NBA history. They did not win the title in 1966–67, but regained it in the 1967–68 season and repeated in 1969. The domination totaled nine of the ten championship banners of the 1960s.
Through this period, the NBA continued to strengthen with the shift of the Minneapolis Lakers to Los Angeles, the Philadelphia Warriors to San Francisco, the Syracuse Nationals to Philadelphia to become the Philadelphia 76ers, and the St. Louis Hawks moving to Atlanta, as well as the addition of its first expansion franchises. The Chicago Packers (now Washington Wizards) became the ninth NBA team in 1961. From 1966 to 1968, the league expanded from 9 to 14 teams, introducing the Chicago Bulls, Seattle SuperSonics (now Oklahoma City Thunder), San Diego Rockets (who relocated to Houston four years later), Milwaukee Bucks, and Phoenix Suns.
In 1967, the league faced a new external threat with the formation of the American Basketball Association (ABA). The leagues engaged in a bidding war. The NBA landed the most important college star of the era, Kareem Abdul-Jabbar (then known as Lew Alcindor). However, the NBA's leading scorer, Rick Barry, jumped to the ABA, as did four veteran referees—Norm Drucker, Earl Strom, John Vanak, and Joe Gushue.
In 1969, Alan Siegel, who oversaw the design of Jerry Dior's Major League Baseball logo a year prior, created the modern NBA logo inspired by the MLB's. It incorporates the silhouette of the legendary Jerry West based on a photo by Wen Roberts, although NBA officials denied a particular player as being its influence because, according to Siegel, "They want to institutionalize it rather than individualize it. It's become such a ubiquitous, classic symbol and focal point of their identity and their licensing program that they don't necessarily want to identify it with one player." The iconic logo debuted in 1971 and would remain a fixture of the NBA brand.
The ABA succeeded in signing a number of major stars in the 1970s, including Julius Erving of the Virginia Squires, in part because it allowed teams to sign college undergraduates. The NBA expanded rapidly during this period, one purpose being to tie up the most viable cities. From 1966 to 1974, the NBA grew from nine franchises to 18. In 1970, the Portland Trail Blazers, Cleveland Cavaliers, and Buffalo Braves (now the Los Angeles Clippers) all made their debuts expanding the league to 17. The New Orleans Jazz (now in Utah) came aboard in 1974 bringing the total to 18. Following the 1976 season, the leagues reached a settlement that provided for the addition of four ABA franchises to the NBA, raising the number of franchises in the league at that time to 22. The franchises added were the San Antonio Spurs, Denver Nuggets, Indiana Pacers, and New York Nets (now the Brooklyn Nets). Some of the biggest stars of this era were Kareem Abdul-Jabbar, Rick Barry, Dave Cowens, Julius Erving, Elvin Hayes, Walt Frazier, Moses Malone, Artis Gilmore, George Gervin, Dan Issel, and Pete Maravich. The end of the decade, however, saw declining TV ratings, low attendance and drug-related player issues – both perceived and real – that threatened to derail the NBA.
Surging popularity.
The league added the ABA's innovative three-point field goal beginning in 1979 to open up the game. That same year, rookies Larry Bird and Magic Johnson joined the Boston Celtics and Los Angeles Lakers respectively, initiating a period of significant growth in fan interest in the NBA throughout the country and the world. In 1984 they played against each other for the first time in the NBA Finals. Johnson went on to lead the Lakers to five titles, and Bird went on to lead the Celtics to three. Also in the early 1980s, the NBA added one more expansion franchise, the Dallas Mavericks, bringing the total to 23 teams. Later on, Larry Bird won the first three three-point shooting contests. Former league commissioner David Stern who took office on February 1, 1984 before retiring February 1, 2014, oversaw the expansion and growth of the NBA to a global commodity.
Michael Jordan entered the league in 1984 with the Chicago Bulls, providing an even more popular star to support growing interest in the league. This resulted in more cities demanding teams of their own. In 1988 and 1989, four cities got their wishes as the Charlotte Hornets, Miami Heat, Orlando Magic, and Minnesota Timberwolves made their NBA debuts, bringing the total to 27 teams. In the first year of the 1990s, the Detroit Pistons would win the second of their back-to-back titles, led by coach Chuck Daly and guard Isiah Thomas. Jordan and Scottie Pippen would lead the Bulls to two three-peats in eight years during the 1991–98 seasons. Hakeem Olajuwon won back-to-back titles with the Houston Rockets in 1994 and 1995.
The 1992 Olympic basketball Dream Team, the first to use current NBA stars, featured Michael Jordan as the anchor, along with Bird, Johnson, David Robinson, Patrick Ewing, Scottie Pippen, Clyde Drexler, Karl Malone, John Stockton, Chris Mullin, Charles Barkley, and Christian Laettner. Eleven players on the Dream Team have been inducted individually into the Basketball Hall of Fame.
In 1995, the NBA expanded to Canada with the addition of the Vancouver Grizzlies and the Toronto Raptors. In 2001, the Vancouver Grizzlies relocated to Memphis, which left the Raptors as the only Canadian team in the NBA.
In 1996, the NBA created a women's league, the Women's National Basketball Association (WNBA).
In 1998, the NBA owners began a lockout which lasted 191 days and was settled on January 18, 1999. As a result of this lockout the 1998–99 NBA season was reduced from 82 to 50 games (61% of a normal season), and the All-Star Game was cancelled. The San Antonio Spurs won their first championship, and first by a former ABA team, by beating the New York Knicks, who were the first, and to this date, the only, eighth seed to ever make it to the NBA Finals.
Modern era.
Since the breakup of the Chicago Bulls championship roster in the summer of 1998, the Western Conference has dominated, with the Los Angeles Lakers and San Antonio Spurs combining to win the title nine out of fourteen seasons. Tim Duncan and David Robinson won the 1999 championship with the Spurs, and Shaquille O'Neal and Kobe Bryant started the 2000s with three consecutive championships for the Lakers. The Spurs reclaimed the title in 2003 against the Nets. In 2004, the Lakers returned to the Finals, only to fall in five games to the Detroit Pistons.
After the Spurs took home the Larry O'Brien Championship Trophy in 2005, the 2006 Finals featured two franchises making their inaugural Finals appearances. The Miami Heat, led by their star shooting guard, Dwyane Wade, and Shaquille O'Neal, who had been traded from the Lakers during the 2004 summer, won the series over the Dallas Mavericks in six after losing the first two games. The Lakers/Spurs dominance continued in 2007 with a four-game sweep by the Spurs over the Cleveland Cavaliers, who were led by LeBron James. The 2008 Finals saw a rematch of the league's highest profile rivalry, the Boston Celtics and Los Angeles Lakers, with the Celtics winning, for their 17th championship, thanks to their new big three of Paul Pierce, Ray Allen, and Kevin Garnett.
In 2009, Kobe Bryant and the Lakers returned to the Finals, this time defeating the Dwight Howard-led Orlando Magic. Bryant won his first Bill Russell NBA Finals Most Valuable Player Award in his 13th season after leading the Lakers to their first NBA championship since the departure of Shaquille O'Neal.
The 2010 NBA All-Star Game was held at Cowboys Stadium in front of the largest crowd ever, 108,713. At the end of that season, the Celtics and the Lakers renewed their rivalry from 2008 when they met again in the NBA Finals for a record 12th time. The Lakers won the title by winning Game 7, 83–79. Before the start of the 2010–11 season the NBA had an exciting summer with one of the most anticipated free agent classes of all time. Two of which signed, and one resigned, with the Miami Heat, leading to a season that was heavily centered on their eventual success or failure at taking home the championship. The Heat, led by LeBron James, Dwyane Wade, and Chris Bosh, did in fact make the Finals against the Dallas Mavericks, in a rematch for the franchises of the 2006 Finals. The Mavericks, led by Dirk Nowitzki (the eventual NBA Finals MVP), took the series in six games. This was the Mavericks' first title. Veterans Shawn Marion, Jason Kidd, Jason Terry, and Peja Stojaković celebrated their first NBA championship.
On July 1, 2011, at 12:01 am, the NBA announced another lockout. After the first few weeks of the season were canceled, the players and owners ratified a new collective bargaining agreement on December 8, 2011, setting up a shortened 66-game season. Following the shortened season, the Miami Heat made a return to the Finals with the trio of Dwyane Wade, LeBron James and Chris Bosh against Oklahoma City's Kevin Durant, Russell Westbrook and James Harden. The Heat went on to defeat the Thunder in five games, capturing their second NBA title in six years. Their success would continue into the following season, which concluded with their victory over the San Antonio Spurs in the 2013 NBA Finals. The two teams would meet for a rematch in the following year's Finals, in which the Spurs defeated the Heat in five games. Following that series, LeBron James announced that he would return to the Cleveland Cavaliers. Most recently, the 2015 NBA Finals concluded with the Golden State Warriors defeating the Cavaliers in six games to win their first NBA Championship since 1975.
International influence.
Following pioneers like Vlade Divac (Serbia) and Dražen Petrović (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Since 2006, the NBA has faced Euroleague teams in exhibition matches in the NBA Europe Live Tour and since 2009 in the Euroleague American Tour. The 2013–14 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20% of the league 
Other developments.
In 2001, an affiliated minor league, the National Basketball Development League, now called the NBA Development League (or D-League) was created. Before the league was started, there were strong rumors that the NBA would purchase the Continental Basketball Association, and call it its developmental league.
Two years after the Hornets' relocation to New Orleans, the NBA returned to North Carolina as the Charlotte Bobcats were formed as an expansion team in 2004.
The Hornets temporarily relocated to Oklahoma City in 2005 for two seasons because of damage caused by Hurricane Katrina. The team returned to New Orleans in 2007.
A new official game ball was introduced on June 28, 2006, for the 2006–07 season, marking the first change to the ball in over 35 years and only the second ball in 60 seasons. Manufactured by Spalding, the new ball featured a new design and new synthetic material that Spalding claimed offered a better grip, feel, and consistency than the original ball. However, many players were vocal in their disdain for the new ball, saying that it was too sticky when dry, and too slippery when wet.
Commissioner Stern announced on December 11, 2006, that beginning January 1, 2007, the NBA would return to the traditional leather basketball in use prior to the 2006–07 season. The change was influenced by frequent player complaints and confirmed hand injuries (cuts) caused by the microfiber ball. The Players' Association had filed a suit in behalf of the players against the NBA over the new ball. As of 2006, the NBA team jerseys are manufactured by Adidas, which purchased the previous supplier, Reebok.
The Federal Bureau of Investigation (FBI) began an investigation on July 19, 2007, over allegations that veteran NBA referee Tim Donaghy bet on basketball games he officiated over the past two seasons and that he made calls affecting the point spread in those games. On August 15, 2007, Donaghy pleaded guilty to two federal charges related to the investigation. However, he could face additional charges if it is determined that he deliberately miscalled individual games. Donaghy claimed in 2008 that certain refs were friendly with players and "company men" for the NBA. Donaghy alleged that refs influenced the outcome of certain playoff and finals games in 2002 and 2005. NBA commissioner David Stern denied the allegations and said Donaghy was a convicted felon and a "singing, cooperating witness". Donaghy served 15 months in prison and was released in November 2009. According to an independent study by Ronald Beech of Game 6 of the 2002 Western Conference Finals between the Los Angeles Lakers and Sacramento Kings, although the refs increased the Lakers' chances of winning through foul calls during the game, there was no collusion to fix the game. On alleged "star treatment" during Game 6 by the refs toward certain players, Beech claimed, "there does seem to be issues with different standards and allowances for different players." 
The NBA Board of Governors approved the request of the Seattle SuperSonics to relocate to Oklahoma City on April 18, 2008. The team, however, could not move until it had settled a lawsuit filed by the city of Seattle, Washington, which was intended to keep the SuperSonics in Seattle for the remaining two seasons of the team's lease at KeyArena. Following a court case, the city of Seattle settled with the ownership group of the SuperSonics on July 2, 2008, allowing the team to move to Oklahoma City immediately in exchange for terminating the final two seasons of the team's lease at KeyArena. The Oklahoma City Thunder began playing in the 2008–09 season.
The first outdoor game in the modern era of the league was played at the Indian Wells Tennis Garden on October 11, 2008, between the Phoenix Suns and the Denver Nuggets.
A referee lockout began on September 1, 2009, when the contract between the NBA and its referees expired. The first preseason games were played on October 1, 2009, and replacement referees from the WNBA and NBA Development League were used, the first time replacement referees had been used since the beginning of the 1995–96 season. The NBA and the regular referees reached a deal on October 23, 2009.
The first official NBA league games on European ground took place in 2011. In two matchups, the New Jersey Nets faced the Toronto Raptors at the O2 Arena in London in front of over 20,000 fans.
The NBA laid off around 114 league employees—about 11 percent of all the league office workforce—in July 2011 to save money.
The 2011–12 NBA season, scheduled to begin November 1, 2011, with a matchup between the defending champion Dallas Mavericks and the Chicago Bulls, was postponed due to a labor dispute. The lockout officially ended on December 8, 2011, when players and owners ratified a new collective bargaining agreement, and the season began on Christmas Day.
The New Jersey Nets officially changed their name to the Brooklyn Nets on April 30, 2012. They began playing in the New York City borough of Brooklyn in the 2012–13 season.
The NBA announced in October 2012 that it would begin fining players for flopping.
After the 2012–13 season, the New Orleans Hornets renamed themselves the Pelicans. During the 2013–14 season, Stern retired as commissioner after 30 years, and deputy commissioner Adam Silver ascended to the position of commissioner. During that season's playoffs, the Bobcats officially reclaimed the Hornets name, and by agreement with the league and the Pelicans, also received sole ownership of all history, records, and statistics from the Pelicans' time in Charlotte. As a result, the Hornets are now officially considered to have been founded in 1988, suspended operations in 2002, and resumed in 2004 as the Bobcats, while the Pelicans are officially treated as a 2002 expansion team. (This is somewhat similar to the relationship between the Cleveland Browns and Baltimore Ravens in the NFL.)
Donald Sterling, who was then-owner of the Los Angeles Clippers, received a lifetime ban from the NBA on April 29, 2014, after racist remarks he made became public. Sterling was also fined $2.5 million, the maximum allowed under the NBA Constitution.
Becky Hammon was hired by the San Antonio Spurs on August 5, 2014, as an assistant coach, becoming the second female coach in NBA history but the first full-time coach. This also makes her the first full-time female coach in any of the four major professional sports in North America.
The NBA announced on April 15, 2016, that it would allow all 30 of its member clubs to sell corporate sponsor advertisement patches on official game uniforms, beginning with the 2017–18 season. The sponsorship advertisement patches would appear on the left front of jerseys, opposite Nike's logo, and would measure approximately 2.5 by 2.5 inches. The NBA will become the first major North American professional sports league to allow corporate sponsorship logos on official team uniforms.
Teams.
The NBA originated in 1946 with 11 teams, and through a sequence of team expansions, reductions, and relocations currently consists of 30 teams. The United States is home to 29 teams and one is located in Canada.
The current league organization divides thirty teams into two conferences of three divisions with five teams each. The current divisional alignment was introduced in the 2004–05 season. Reflecting the population distribution of the United States and Canada as a whole, most teams are in the eastern half of the country: thirteen teams are in the Eastern Time Zone, nine in the Central, three in the Mountain, and five in the Pacific.
Regular season.
Following the summer break, teams begin training camps in late September. Training camps allow the coaching staff to evaluate players (especially rookies), scout the team's strengths and weaknesses, prepare the players for the rigorous regular season, and determine the 12-man active roster (and a 3-man inactive list) with which they will begin the regular season. Teams have the ability to assign players with less than two years of experience to the NBA development league. After training camp, a series of preseason exhibition games are held. Preseason matches are sometimes held in non-NBA cities, both in the United States and overseas. The NBA regular season begins in the last week of October.
During the regular season, each team plays 82 games, 41 each home and away. A team faces opponents in its own division four times a year (16 games). Each team plays six of the teams from the other two divisions in its conference four times (24 games), and the remaining four teams three times (12 games). Finally, each team plays all the teams in the other conference twice apiece (30 games). This asymmetrical structure means the strength of schedule will vary between teams (but not as significantly as the NFL or MLB). Over five seasons, each team will have played 80 games against their division (20 games against each opponent, 10 at home, 10 on the road), 180 games against the rest of their conference (18 games against each opponent, 9 at home, 9 on the road), and 150 games against the other conference (10 games against each team, 5 at home, 5 on the road).
The NBA is one of only two of the four major professional sports leagues in the United States and Canada in which teams play every other team during the regular season (the other being the National Hockey League). Each team hosts and visits every other team at least once every season. From 2005 to 2008, the NBA had the distinction of being the only one of the four major leagues in which all teams play every other team.
The NBA is also the only league that regularly schedules games on Christmas Day. The league has been playing games regularly on the holiday since 1947, though the first Christmas Day games weren't televised until . Games played on this day have featured some of the best teams and players. Christmas is also notable for NBA on television, as the holiday is when the first NBA games air on network television each season. Games played on this day have been some of the highest-rated games during a particular season.
In February, the regular season pauses to celebrate the annual NBA All-Star Game. Fans vote throughout the United States, Canada, and on the Internet, and the top vote-getters at each position in each conference are given a starting spot on their conference's All-Star team. Coaches vote to choose the remaining 14 All-Stars. Then, Eastern conference players face the Western conference players in the All-Star game. The player with the best performance during the game is rewarded with a Game MVP award. Other attractions of the All-Star break include the Rising Stars Challenge (originally Rookie Challenge), where the top rookies and second-year players in the NBA play in a 5-on-5 basketball game, with the current format pitting U.S. players against those from the rest of the world; the Skills Challenge, where players compete to finish an obstacle course consisting of shooting, passing, and dribbling in the fastest time; the Three Point Contest, where players compete to score the most amount of three-point field goals in a given time; and the NBA Slam Dunk Contest, where players compete to dunk the ball in the most entertaining way according to the judges. These other attractions have varying names which include the names of the various sponsors who have paid for naming rights.
Shortly after the All-Star break is the trade deadline, which is set to fall on the 16th Thursday of the season (usually in February) at 3pm Eastern Time. After this date, teams are not allowed to exchange players with each other for the remainder of the season, although they may still sign and release players. Major trades are often completed right before the trading deadline, making that day a hectic time for general managers.
Around the middle of April, the regular season ends. It is during this time that voting begins for individual awards, as well as the selection of the honorary, league-wide, post-season teams. The Sixth Man of the Year Award is given to the best player coming off the bench (must have more games coming off the bench than actual games started). The Rookie of the Year Award is awarded to the most outstanding first-year player. The Most Improved Player Award is awarded to the player who is deemed to have shown the most improvement from the previous season. The Defensive Player of the Year Award is awarded to the league's best defender. The Coach of the Year Award is awarded to the coach that has made the most positive difference to a team. The Most Valuable Player Award is given to the player deemed the most valuable for (his team) that season. Additionally, "Sporting News" awards an unofficial (but widely recognized) Executive of the Year Award to the general manager who is adjudged to have performed the best job for the benefit of his franchise.
The post-season teams are the All-NBA Team, the All-Defensive Team, and the All-Rookie Team; each consists of five players. There are three All-NBA teams, consisting of the top players at each position, with first-team status being the most desirable. There are two All-Defensive teams, consisting of the top defenders at each position. There are also two All-Rookie teams, consisting of the top first-year players regardless of position.
Playoffs.
NBA Playoffs begin in late April, with eight teams in each conference competing for the Championship. The three division winners, along with the team with the next best record from the conference are given the top four seeds. The next four teams in terms of record are given the lower four seeds.
Having a higher seed offers several advantages. Since the first seed begins the playoffs playing against the eighth seed, the second seed plays the seventh seed, the third seed plays the sixth seed, and the fourth seed plays the fifth seed, having a higher seed means a team faces a weaker team in the first round. The team in each series with the better record has home court advantage, including the First Round. This means that, for example, if the team who receives the 6 seed has a better record than the team with the 3 seed (by virtue of a divisional championship), the 6 seed would have home court advantage, even though the other team has a higher seed. Therefore, the team with the best regular season record in the league is guaranteed home court advantage in every series it plays. For example, in 2006, the Denver Nuggets won 44 games and captured the Northwest Division and the #3 seed. Their opponent was the #6 seed Los Angeles Clippers, who won 47 games and finished second in the Pacific Division. Although Denver won its much weaker division, the Clippers had home-court advantage and won the series in 5.
The playoffs follow a tournament format. Each team plays an opponent in a best-of-seven series, with the first team to win four games advancing into the next round, while the other team is eliminated from the playoffs. In the next round, the successful team plays against another advancing team of the same conference. All but one team in each conference are eliminated from the playoffs. Since the NBA does not re-seed teams, the playoff bracket in each conference uses a traditional design, with the winner of the series matching the 1st and 8th seeded teams playing the winner of the series matching the 4th and 5th seeded teams, and the winner of the series matching the 2nd and 7th seeded teams playing the winner of the series matching the 3rd and 6th seeded teams. In every round, the best-of-7 series follows a 2–2–1–1–1 home-court pattern, meaning that one team will have home court in games 1, 2, 5, and 7, while the other plays at home in games 3, 4, and 6. From 1985 to 2013, the NBA Finals followed a 2–3–2 pattern, meaning that one team had home court in games 1, 2, 6, and 7, while the other played at home in games 3, 4, and 5.
The final playoff round, a best-of-seven series between the victors of both conferences, is known as the NBA Finals, and is held annually in June. The victor in the NBA Finals wins the Larry O'Brien Championship Trophy. Each player and major contributor—including coaches and the general manager—on the winning team receive a championship ring. In addition, the league awards the Bill Russell NBA Finals Most Valuable Player Award to the best performing player of the series.
On August 2, 2006, the NBA announced the new playoff format. The new format takes the three division winners and the second-place team with the best record and rank them 1–4 by record. The other 4 slots are filled by best record other than those other 4 teams. Previously, the top three seeds went to the division winners.
League championships.
The Boston Celtics have won the most championships with 17 NBA Finals wins. The second most successful franchise is the Los Angeles Lakers, who have 16 overall championships (11 in Los Angeles, 5 in Minneapolis). Following the Lakers, are the Chicago Bulls with six championships, all won over an 8-year span during the 1990s, and the San Antonio Spurs with five championships, all since 1999.
Current teams that have no NBA Finals appearances:
International competitions.
The National Basketball Association has sporadically participated in international club competitions. From 1987 to 1999 the NBA champions played against the continental champions of the Fédération Internationale de Basketball (FIBA) in the McDonald's Championship. This tournament was won by the NBA invitee every year it was held.
Ticket prices.
In 2012, a ticket cost from $10 to $3,000 apiece, depending on the location of the seat and the success of the teams that were playing.
Notable people.
Foreign players.
International influence.
Following pioneers like Vlade Divac (Serbia) and Dražen Petrović (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Below is a short list of foreign players who have won NBA awards or have been otherwise recognized for their contributions to basketball, either currently or formerly active in the league:
On some occasions, young players, most but not all from the English-speaking world, have attended U.S. colleges before playing in the NBA. Notable examples are:
Since 2006, the NBA has faced Euroleague teams in exhibition matches in the NBA Europe Live Tour and since 2009 in the Euroleague American Tour.
The 2013–14 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20% of the league The NBA defines "international" players as those born outside the 50 United States and Washington, D.C. This means that:

</doc>
<doc id="22094" url="https://en.wikipedia.org/wiki?curid=22094" title="Nutation">
Nutation

Nutation (from Latin "nūtātiō", "nodding, swaying") is a rocking, swaying, or nodding motion in the axis of rotation of a largely axially symmetric object, such as a gyroscope, planet, or bullet in flight, or as an intended behavior of a mechanism. In an appropriate reference frame it can be defined as a change in the second Euler angle. If it is not caused by forces external to the body, it is called "free nutation" or "Euler nutation". A "pure nutation" is a movement of a rotational axis such that the first Euler angle is constant. In spacecraft dynamics, precession (a change in the first Euler angle) is sometimes referred to as nutation.
Rigid body.
If a top is set at a tilt on a horizontal surface and spun rapidly, its rotational axis starts precessing about the vertical. After a short interval, the top settles into a motion in which each point on its rotation axis follows a circular path. The vertical force of gravity produces a horizontal torque about the point of contact with the surface; the top rotates in the direction of this torque with an angular velocity such that at any moment
where is the instantaneous angular momentum of the top.
Initially, however, there is no precession, and the top falls straight downward. This gives rise to an imbalance in torques that starts the precession. In falling, the top overshoots the level at which it would precess steadily and then oscillates about this level. This oscillation is called "nutation". If the motion is damped, the oscillations will die down until the motion is a steady precession.
The physics of nutation in tops and gyroscopes can be explored using the model of a "heavy symmetrical top" with its tip fixed. Initially, the effect of friction is ignored. The motion of the top can be described by three Euler angles: the tilt angle between the symmetry axis of the top and the vertical; the azimuth of the top about the vertical; and the rotation angle of the top about its own axis. Thus, precession is the change in and nutation is the change in .
If the top has mass and its center of mass is at a distance from the pivot point, its gravitational potential relative to the plane of the support is
In a coordinate system where the axis is the axis of symmetry, the top has angular velocities and moments of inertia about the , and axes. The kinetic energy is
In terms of the Euler angles, this is
If the Euler–Lagrange equations are solved for this system, it is found that the motion depends on two constants and (each related to a constant of motion). The rate of precession is related to the tilt by
The tilt is determined by a differential equation for of the form
where is a cubic polynomial that depends on parameters and as well as constants that are related to the energy and the gravitational torque. The roots of are cosines of the angles at which the rate of change of is zero. One of these is not related to a physical angle; the other two determine the upper and lower bounds on the tilt angle, between which the gyroscope oscillates.
Astronomy.
The nutation of a planet happens because of gravitational attraction of other bodies that cause the precession of the equinoxes to vary over time so that the speed of precession is not constant. The nutation of the axis of the Earth was discovered in 1728 by the British astronomer James Bradley, but this nutation was not explained in detail until 20 years later by the Swiss mathematician Leonhard Euler.
Because the dynamic motions of the planets are so well known, their nutations can be calculated to within arcseconds over periods of many decades. There is another disturbance of the Earth's rotation called polar motion that can be estimated for only a few months into the future because it is influenced by rapidly and unpredictably varying things such as ocean currents, wind systems, and hypothesised motions in the liquid nickel-iron outer core of the Earth.
Values of nutations are usually divided into components parallel and perpendicular to the ecliptic. The component that works along the ecliptic is known as the "nutation in longitude". The component perpendicular to the ecliptic is known as the "nutation in obliquity". Celestial coordinate systems are based on an "equator" and "equinox", which means a great circle in the sky that is the projection of the Earth's equator outwards, and a line, the vernal equinox intersecting that circle, which determines the starting point for measurement of right ascension. These items are affected both by precession of the equinoxes and nutation, and thus depend on the theories applied to precession and nutation, and on the date used as a reference date for the coordinate system. In simpler terms, nutation (and precession) values are important in observation from Earth for calculating the apparent positions of astronomical objects.
Earth.
Nutation makes a small change to the angle at which the Earth tilts with respect to the Sun, changing the location of the major circles of latitude that are defined by the Earth's tilt (the tropical circles and the polar circles).
In the case of the Earth, the principal sources of tidal force are the Sun and Moon, which continuously change location relative to each other and thus cause nutation in Earth's axis. The largest component of Earth's nutation has a period of 18.6 years, the same as that of the precession of the Moon's orbital nodes. However, there are other significant periodic terms that must be accounted for depending upon the desired accuracy of the result. A mathematical description (set of equations) that represents nutation is called a "theory of nutation". In the theory, parameters are adjusted in a more or less "ad hoc" method to obtain the best fit to data. Simple rigid body dynamics do not give the best theory; one has to account for deformations of the Earth, including mantle inelasticity and changes in the core–mantle boundary.
The principal term of nutation is due to the regression of the Moon's nodal line and has the same period of 6798 days (18.61 years). It reaches plus or minus 17″ in longitude and 9.2″ in obliquity. All other terms are much smaller; the next-largest, with a period of 183 days (0.5 year), has amplitudes 1.3″ and 0.6″ respectively. The periods of all terms larger than 0.0001″ (about as accurately as one can measure) lie between 5.5 and 6798 days; for some reason (as with ocean tidal periods) they seem to avoid the range from 34.8 to 91 days, so it is customary to split the nutation into long-period and short-period terms. The long-period terms are calculated and mentioned in the almanacs, while the additional correction due to the short-period terms is usually taken from a table.
In popular culture.
In the 1961 movie "The Day the Earth Caught Fire", the near-simultaneous detonation of two super-hydrogen bombs near the poles causes a change in the Earth's nutation, as well as an 11 degree shift in the axis of rotation and a change in the Earth's orbit around the Sun.
The verb "to nutate" was used by MIT physicist Peter Fisher on the television show Late Night with Conan O'Brien on February 8, 2008. Fisher used the term to describe the motion of a spinning ring as it began to slow down and wobble.

</doc>
<doc id="22096" url="https://en.wikipedia.org/wiki?curid=22096" title="NASCO">
NASCO

NASCO or Nasco may refer to:

</doc>
<doc id="22097" url="https://en.wikipedia.org/wiki?curid=22097" title="North Atlantic Salmon Conservation Organization">
North Atlantic Salmon Conservation Organization

The North Atlantic Salmon Conservation Organization (NASCO) is an international organization established under the Convention for the Conservation of Salmon in the North Atlantic Ocean from October 1 1983. 
The organization's mission is to contribute through consultation and cooperation to the conservation, restoration, enhancement and rational management of salmon stocks.
Its headquarters are in Edinburgh, United Kingdom.
Membership.
Current participants (since 1984): Canada, Denmark (in respect of the Faroe Islands and Greenland), the European Union, Norway, Russian Federation, and the United States of America.
Former participants:

</doc>
<doc id="22099" url="https://en.wikipedia.org/wiki?curid=22099" title="Narcissus (mythology)">
Narcissus (mythology)

In Greek mythology, Narcissus (; , "Narkissos") was a hunter from Thespiae in Boeotia who was known for his beauty. He was the son of the river god Cephissus and nymph Liriope. He was proud, in that he disdained those who loved him. Nemesis noticed this behavior and attracted Narcissus to a pool, where he saw his own reflection in the water and fell in love with it, not realizing it was merely an image. Unable to leave the beauty of his reflection, Narcissus lost his will to live. He stared at his reflection until he died. Narcissus is the origin of the term "narcissism", a fixation with oneself and one's physical appearance.
Etymology.
The name is of uncertain etymology. According to R. S. P. Beekes, "suffix [-ισσος clearly points to a Pre-Greek word." further ( pre era)
Ancient sources.
Several versions of the myth have survived from ancient sources. The classic version is by Ovid, found in book 3 of his "Metamorphoses" (completed 8 AD); this is the story of Echo and Narcissus. One day Narcissus was walking in the woods when Echo, an Oread (mountain nymph) saw him, fell deeply in love, and followed him. Narcissus sensed he was being followed and shouted "Who's there?". Echo repeated "Who's there?". She eventually revealed her identity and attempted to embrace him. He stepped away and told her to leave him alone. She was heartbroken and spent the rest of her life in lonely glens until nothing but an echo sound remained of her. Nemesis, the goddess of revenge, learned of this story and decided to punish Narcissus. She lured him to a pool where he saw his own reflection. He didn't realize it was only an image and fell in love with it. He eventually recognized that his love could not be reciprocated and committed suicide.
An earlier version ascribed to the poet Parthenius of Nicaea, composed around 50 BC, was recently rediscovered among the Oxyrhynchus papyri at Oxford. Like Ovid's version, it ends with Narcissus committing suicide. A version by Conon, a contemporary of Ovid, also ends in suicide ("Narrations," 24). In it, a young man named Aminias fell in love with Narcissus, who had already spurned his male suitors. Narcissus also spurned him and gave him a sword. Aminias committed suicide at Narcissus's doorstep. He had prayed to the gods to give Narcissus a lesson for all the pain he provoked. Narcissus walked by a pool of water and decided to drink some. He saw his reflection, became entranced by it, and killed himself because he could not have his object of desire. A century later the travel writer Pausanias recorded a novel variant of the story, in which Narcissus falls in love with his twin sister rather than himself ("Guide to Greece", 9.31.7).
Influence on culture.
Тhe myth of Narcissus has inspired artists for at least two thousand years, even before the Roman poet Ovid featured a version in book III of his "Metamorphoses". This was followed in more recent centuries by other poets (e.g. Keats and Alfred Edward Housman) and painters (Caravaggio, Poussin, Turner, Dalí (see "Metamorphosis of Narcissus"), and Waterhouse).
Narcissus in literature.
In Stendhal's novel "Le Rouge et le Noir" (1830), there is a classic narcissist in the character of Mathilde. Says Prince Korasoff to Julien Sorel, the protagonist, with respect to his beloved girl:
She looks at herself instead of looking at you, and so doesn't know you.
During the two or three little outbursts of passion she has allowed herself in your favor, she has, by a great effort of imagination, seen in you the hero of her dreams, and not yourself as you really are.<br>
(Page 401, 1953 Penguin Edition, trans. Margaret R.B. Shaw).
The myth had a decided influence on English Victorian homoerotic culture, via André Gide's study of the myth, "Le Traité du Narcisse" ('The Treatise of the Narcissus', 1891), and the only novel by Oscar Wilde, "The Picture of Dorian Gray".
Paulo Coelho's "The Alchemist" also starts with a story about Narcissus, found (we are told) by the alchemist in a book brought by someone in the caravan. The alchemist's (and Coelho's) source was very probably Hesketh Pearson's "The Life of Oscar Wilde" (1946) in which this story is recorded (Penguin edition, p. 217) as one of Wilde's inspired inventions. This version of the Narcissus story is based on Wilde's "The Disciple" from his "Poems in Prose (Wilde) ".
Author and poet Rainer Maria Rilke visits the character and symbolism of Narcissus in several of his poems.
Seamus Heaney references Narcissus in his poem "Personal Helicon" from his first collection "Death of a Naturalist":"To stare, big-eyed Narcissus, into some spring<br>
Is beneath all adult dignity."
In Rick Riordan's "Heroes of Olympus series," Narcissus appears as a minor antagonist in the third book "The Mark of Athena".
In the fantasy series "Harry Potter", Narcissa Malfoy, a minor antagonist, is named for Narcissus.
William Faulkner's character "Narcissa" in "Sanctuary", sister of Horace Benbow, was also named after Narcissus. Throughout the novel, she allows the arrogant, pompous pressures of high-class society to overrule the unconditional love that she should have for her brother.
Hermann Hesse's character "Narcissus" in "Narcissus and Goldmund" shares several of mythical Narcissus' traits, although his narcissism is based on his intellect rather than his physical beauty.
A. E. Housman refers to the 'Greek Lad', Narcissus, in his poem "Look not in my Eyes" from "A Shropshire Lad" set to music by several English composers including George Butterworth. At the end of the poem stands a jonquil, a variety of daffodil, Narcissus Jonquilla, which like Narcissus looks sadly down into the water.
Herman Melville references the myth of Narcissus in his novel Moby-Dick, in which Ishmael explains the myth as "the key to it all," referring to the greater theme of finding the essence of Truth through the physical world.
On Sophia de Mello Breyner Andresen's A Fada Oriana, the eponymous protagonist is punished with mortality for abandoning her duties in order to stare at herself in the surface of a river.
Narcissus on film.
In the TV series Boardwalk Empire, a Dr. Narcisse (Valentin Narcisse) is introduced as a condescending intellectual.
Scottish-Canadian animator Norman McLaren finished his career with a short film named "Narcissus", re-telling the Greek legend through ballet.
Narcissus appears in the Disney adaptation of "Hercules". In the film, he is portrayed as an Olympian god with purple skin.
In the film Bab'Aziz, directed by Nacer Khemir, a Narcissus like character was portrayed by an ancient prince who sat by a pond for days after days and looked at the reflection of his own soul. He was referred to as 'The prince who contemplated his soul'.
"Pink Narcissus" is an artistic film by James Bidgood about the fantasies of a hustler.
The escape craft Ripley boards in the 1979 Ridley Scott film Alien is called the Narcissus.
In the 2011 film "Seeing Heaven", Narcissus is depicted in a painting - the character of the film also replicates the myth of Narcissus gazing at his own reflection. The film delves deeply into the main character (Paul) and the theme is loosely based on the myth of Narcissus, as all who look at Paul are transfixed by his beauty - just as all those who gazed upon Narcissus were transifixed with his beauty.
In music.
National Medal Of Arts recipient Morten Lauridsen wrote a choral work entitled "Dirait-on" based on the poem by Rainer Maria Rilke.
"Supper's Ready" by Genesis (ca. 1972), a near-23-minute epic song laden with religious and mythological imagery, refers to the myth of Narcissus as follows: "A young figure sits still by the pool / He's been stamped "Human Bacon" by some butchery tool / (He is you) / Social Security took care of this lad. / We watch in reverence, as Narcissus is turned to a flower. / A flower?". The movement is titled "How Dare I Be So Beautiful?".
American rock band Tool made a subtle reference in their song "Reflection" from their third studio album Lateralus. Not only is the whole song a metaphor of the myth, but it also makes an explicit reference: "And as I pull my head out I am without one doubt/ Don't want to be down here feeding my narcissism/ I must crucify the ego before it's far too late/ I pray the light lifts me out".
The song combines elements of self-analysis and finding the right path, versus self-infatuation and absorption.
Progressive metal band Threshold referenced the myth with an 11-minute epic titled "Narcissus", the closing track on their album "Hypothetical". Greek metal band Septic Flesh recorded a song about Narcissus (called "Narcissus") on their album "Communion".
"Narcissus in a Red Dress" by The Like was released on "The Like EP" and their album "Release Me". The Canadian band Hedley has written a song about Narcissus (called "Narcissist"). One line goes "He falls in love with his reflection in the glass / He can't resist who's staring back"
Composer Nikolai Tcherepnin wrote his ballet "Narcisse et Echo, Op. 40 in 1911 for Sergei Diaghilev's Ballets Russes and was danced by Nijinski. Uruguayan band El Cuarteto de Nos wrote the song "Me Amo" (I Love Myself) in which the chorus sings "como Narciso soy" (I am like Narcissus). In 2010, Swedish electronic artist pacific! released "Narcissus" an album and ballet staged in Gothenburg. In 1994, composer Mark Applebaum composed Narcissus: Strata/Panacea for marimba solo. This work comprised one movement of the larger Janus Cycle, for mixed instrumentation. In 1987, Thea Musgrave was commissioned by a consortium of four flutists for a solo work. She composed Narcissus for flute and digital delay.

</doc>
