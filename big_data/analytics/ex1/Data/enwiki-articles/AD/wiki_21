<doc id="19734" url="https://en.wikipedia.org/wiki?curid=19734" title="Malcolm Fraser">
Malcolm Fraser

John Malcolm Fraser (; 21 May 1930 – 20 March 2015) was an Australian politician who was the 22nd Prime Minister of Australia and the Leader of the Liberal Party from 1975 to 1983.
Elected to the Australian Parliament seat of Wannon in 1955 at the age of 25, Fraser was appointed to the Cabinet in 1966. After rising to become Minister for Defence in 1969, he was regarded as a contender for the leadership of the Liberal Party following their defeat in 1972, but he lost that contest to Billy Snedden. Fraser challenged Snedden in 1975 and was elected Leader of the Liberal Party, becoming the Leader of the Opposition.
Fraser was appointed as caretaker prime minister on 11 November 1975 by the Governor-General of Australia, Sir John Kerr, following the controversial dismissal of the Whitlam Government in which he played a key role. He went on to win the largest parliamentary majority as a proportion of seats in Australian political history at the subsequent election. After two further election victories in 1977 and 1980, he was defeated by the Bob Hawke-led Australian Labor Party in 1983 and left parliament shortly after.
Fraser was the last Liberal Party Prime Minister to practise Keynesian economics. In retirement, Fraser became involved in international relief and humanitarian aid issues and, domestically, as a forthright liberal voice for human rights. Shortly after Tony Abbott won the 2009 Liberal Party leadership spill, Fraser ended his Liberal Party membership, stating the party was "no longer a liberal party but a conservative party".
On 20 March 2015, Fraser died at the age of 84 after a brief illness.
Early life and education.
John Malcolm Fraser was born on 21 May 1930 in Toorak, Victoria, to a family with a history of involvement in politics and the pastoral industry. His grandfather, Simon Fraser, Sr., emigrated from Nova Scotia in 1853, becoming a successful pastoralist and speculator, and later a member of the Victorian Parliament, the Federation Conventions and the Australian Senate. Fraser's uncle, Simon Fraser, Jr., was a noted sportsman who rowed for Australia at the 1912 Olympics in Stockholm, and also played Australian rules football for Essendon and University in the Victorian Football League.
Fraser's father, John Neville Fraser, had been educated at the University of Melbourne, and was a pastoralist at Moulamein in the western Riverina region of New South Wales, and later at a property called "Nareen Station" in Nareen, near Hamilton in the Western District of Victoria. Fraser's mother, Una Woolf, was of Jewish descent on her father's side, which Fraser did not discover until he was an adult.
Fraser grew up on the family's pastoral properties and was educated at Tudor House School, near Moss Vale in New South Wales, Glamorgan, now part of Geelong Grammar School, and Melbourne Grammar School, before completing a degree in Philosophy, Politics and Economics at Magdalen College, Oxford in 1952. While at Oxford, Fraser was a classmate and friend of future Canadian Prime Minister John Turner.
Early political career, 1955–75.
Upon returning to Australia from Oxford, Fraser contested the seat of Wannon in 1954 for the Liberal Party, losing to Labor incumbent Don McLeod by just 17 votes. However, a redistribution made Wannon a notionally Liberal seat, and McLeod announced his retirement shortly before the election in 1955. Fraser subsequently won the seat with a majority of more than 5,000 on a swing of 8.5 per cent. Aged just 25, he was the youngest Member of Parliament; he would continue to represent Wannon until his retirement in 1983.
Cabinet minister.
After more than a decade on the backbench, Fraser was appointed to the Cabinet by the prime minister, Harold Holt, in 1966. As Minister for the Army he presided over the controversial Vietnam War conscription program. Under the new prime minister, John Gorton, he became Minister for Education and Science and in 1969 was promoted to Minister for Defence, a particularly challenging post at the time, given the height of Australia's involvement in the Vietnam War and the protests against it.
In March 1971, Fraser abruptly resigned from the Cabinet in protest at what he called Gorton's "interference in (his) ministerial responsibilities". This precipitated a series of events which eventually led to the downfall of Gorton and his replacement as prime minister by William McMahon. Gorton never forgave Fraser for the role he played in his downfall and to the day he died in 2002 could not bear to be in the same room with him. McMahon immediately reappointed Fraser to the Cabinet, returning him to his old position of Minister for Education and Science. When the Liberals were defeated at the 1972 election by the Labor Party under Gough Whitlam, McMahon resigned and Fraser became Shadow Minister for Labour under Billy Snedden.
Role in the dismissal.
After Snedden was defeated in 1974, Fraser unsuccessfully challenged him for the leadership of the Liberal Party in November. Despite surviving the challenge, Snedden's position in opinion polls continued to decline and he was unable to get the better of Whitlam in the Parliament. Fraser again challenged Snedden on 21 March 1975, this time succeeding and becoming Leader of the Liberal Party and Leader of the Opposition.
Following a series of ministerial scandals engulfing the Whitlam Government later that year, Fraser began to instruct Coalition senators to delay the government's budget bills, with the objective of forcing an early election that he believed he would win. After several months of political deadlock, during which time the government secretly explored methods of obtaining supply funding outside the Parliament, the governor-general, Sir John Kerr, controversially dismissed Whitlam as prime minister on 11 November 1975. Fraser was immediately sworn in as caretaker prime minister on the condition that he end the political deadlock and call an immediate election.
On 19 November 1975, shortly after the election had been called, a letter bomb was sent to Fraser, but it was intercepted and defused before it reached him. Similar devices were sent to the governor-general and the Premier of Queensland, Joh Bjelke-Petersen.
Prime Minister (1975–83).
At the 1975 election, Fraser led the Liberal-Country Party Coalition to a landslide victory. The Coalition won 30 seats from Labor to gain a 55-seat majority, which remains to date the largest in Australian history. Fraser subsequently led the Coalition to a second victory in 1977, with only a very small decrease in their vote. The Liberals actually won a majority in their own right, something that even Robert Menzies had not been able to achieve. Although Fraser thus had no need for the support of the (National) Country Party to govern, he retained the formal Coalition between the two parties.
Fraser quickly dismantled some of the programs of the Whitlam Government, such as the Ministry of the Media, and made major changes to the universal health insurance system Medibank. He initially maintained Whitlam's levels of tax and spending, but real per-person tax and spending soon began to increase. He did manage to rein in inflation, which had soared under Whitlam. His so-called "Razor Gang" implemented stringent budget cuts across many areas of the Commonwealth Public Sector, including the Australian Broadcasting Corporation (ABC).
Fraser practised Keynesian economics during his time as Prime Minister, in part demonstrated by running budget deficits throughout his term as Prime Minister. He was the Liberal Party's last Keynesian Prime Minister. Though he had long been identified with the Liberal Party's right wing, he did not carry out the radically conservative program that his political enemies had predicted, and that some of his followers wanted. Fraser's relatively moderate policies particularly disappointed the treasurer, John Howard, as well as other ministers who were strong adherents of emerging free market neo-liberal economics, and therefore detractors of Keynesian economics. The government's economic record was marred by rising double-digit unemployment and double-digit inflation, creating "stagflation", caused in part by the ongoing effects of the 1973 oil crisis.
Fraser was particularly active in foreign policy as prime minister. He supported the Commonwealth in campaigning to abolish apartheid in South Africa and refused permission for the aircraft carrying the Springbok rugby team to refuel on Australian territory en route to their controversial 1981 tour of New Zealand. However, an earlier tour by the South African ski boat angling team was allowed to pass through Australia on the way to New Zealand in 1977 and the transit records were suppressed by Cabinet order.
Fraser also strongly opposed white minority rule in Rhodesia. During the 1979 Commonwealth Conference, Fraser, together with his Nigerian counterpart, convinced the newly elected British prime minister, Margaret Thatcher, to withhold recognition of the internal settlement Zimbabwe Rhodesia government; Thatcher had earlier promised to recognise it. Subsequently, the Lancaster House Agreement was signed and Robert Mugabe was elected leader of an independent Zimbabwe at the inaugural 1980 election. Duncan Campbell, a former deputy secretary of the Department of Foreign Affairs and Trade has stated that Fraser was "the principal architect" in the ending of white minority rule. The President of Tanzania, Julius Nyerere, said that he considered Fraser's role "crucial in many parts" and the President of Zambia, Kenneth Kaunda, called his contribution "vital".
Under Fraser, Australia recognised Indonesia's annexation of East Timor, although many East Timorese refugees were granted asylum in Australia. Fraser was also a strong supporter of the United States and supported the boycott of the 1980 Summer Olympics in Moscow. However, although he persuaded some sporting bodies not to compete, Fraser did not try to prevent the Australian Olympic Committee sending a team to the Moscow Games.
Fraser also surprised his critics over immigration policy; according to 1977 Cabinet documents, the Fraser Government adopted a formal policy for "a humanitarian commitment to admit refugees for resettlement". Fraser's aim was to expand immigration from Asian countries and allow more refugees to enter Australia. He was a firm supporter of multiculturalism and established a government-funded multilingual radio and television network, the Special Broadcasting Service (SBS), building on their first radio stations which had been established under the Whitlam Government.
Despite Fraser's support for SBS, his government imposed stringent budget cuts on the national broadcaster, the ABC, which came under repeated attack from the Coalition for alleged "left-wing bias" and "unfair" coverage on their TV programs, including "This Day Tonight" and "Four Corners", and on the ABC's new youth-oriented radio station Double Jay. One result of the cuts was a plan to establish a national youth radio network, of which Double Jay was the first station. The network was delayed for many years and did not come to fruition until the 1990s. Fraser also legislated to give Indigenous Australians control of their traditional lands in the Northern Territory, but resisted imposing land rights laws on conservative state governments.
At the 1980 election, Fraser saw his majority more than halved, from 48 seats to 21. The Coalition also lost control of the Senate. Despite this, Fraser remained ahead of Labor leader Bill Hayden in opinion polls. However, the economy was hit by the early 1980s recession, and a protracted scandal over tax-avoidance schemes run by some high-profile Liberals also began to hurt the Government.
In April 1981, the Minister for Industrial Relations, Andrew Peacock, resigned from the Cabinet, accusing Fraser of "constant interference in his portfolio". Fraser, however, had accused former prime minister John Gorton of the same thing a decade earlier. Peacock subsequently challenged Fraser for the leadership; although Fraser defeated Peacock, these events left him politically weakened.
By early 1982, the popular former ACTU President, Bob Hawke, who had entered Parliament in 1980, was polling well ahead of both Fraser and the Labor Leader, Bill Hayden, on the question of who voters would rather see as prime minister. Fraser was well aware of the infighting this caused between Hayden and Hawke and had planned to call a snap election in autumn 1982, preventing the Labor Party changing leaders. These plans were derailed when Fraser suffered a severe back injury. Shortly after recovering from his injury, the Liberal Party narrowly won a by-election in the marginal seat of Flinders in January 1983. The failure of the Labor Party to win the seat convinced Fraser that he would be able to win an election against Hayden. As leadership tensions began to grow in the Labor Party throughout January, Fraser subsequently resolved to call a double dissolution election at the earliest opportunity, hoping to capitalise on Labor's disunity and prevent them from replacing Hayden.
On 3 February 1983, Fraser arranged to visit the Governor-General of Australia, Ninian Stephen, intending to call a surprise election. By coincidence and without any knowledge of Fraser's plans, Hayden resigned as Labor Leader just two hours before Fraser travelled to Government House. This meant that the considerably more popular Bob Hawke was able to replace him at almost exactly the same time that the writs were issued for the election. Although Fraser reacted to the move by saying he looked forward to "knock two Labor Leaders off in one go" at the forthcoming election, Labor immediately surged in the opinion polls.
At the election on 5 March the Coalition was heavily defeated, suffering a 24-seat swing, the worst defeat of a non-Labor government since Federation. Fraser immediately announced his resignation as Liberal leader and formally resigned as prime minister on 11 March 1983; he retired from Parliament two months later. To date, he is the last non-interim prime minister from a rural seat.
Retirement (1983–2015).
In retirement Fraser served as Chairman of the UN Panel of Eminent Persons on the Role of Transnational Corporations in South Africa 1985, as Co-Chairman of the Commonwealth Group of Eminent Persons on South Africa in 1985–86, and as Chairman of the UN Secretary-General's Expert Group on African Commodity Issues in 1989–90. He was a distinguished international fellow at the American Enterprise Institute from 1984 to 1986. Fraser helped to establish the foreign aid group CARE organisation in Australia and became the agency's international president in 1991, and worked with a number of other charitable organisations. In 2006, he was appointed Professorial Fellow at the Asia Pacific Centre for Military Law, and in October 2007 he presented his inaugural professorial lecture, "Finding Security in Terrorism's Shadow: The importance of the rule of law".
Memphis trousers affair.
On 14 October 1986, Fraser, then the Chairman of the Commonwealth Eminent Persons Group, was found in the foyer of the Admiral Benbow Inn, a seedy Memphis hotel, wearing only a pair of underpants and confused as to where his trousers were. The hotel was an establishment popular with prostitutes and drug dealers. Though it was rumoured at the time that the former Prime Minister had been with a prostitute, his wife stated that Fraser had no recollection of the events and that she believes it more likely that he was the victim of a practical joke by his fellow delegates.
Estrangement from the Liberal Party.
In 1993, Fraser made a bid for the Liberal Party presidency but withdrew at the last minute following opposition to his bid, which was raised due to Fraser being critical of then Liberal leader John Hewson for losing the election earlier that year.
After 1996, Fraser was critical of the Howard Coalition government over foreign policy issues, particularly John Howard's alignment with the foreign policy of the Bush administration, which Fraser saw as damaging Australian relationships in Asia. He opposed Howard's policy on asylum-seekers, campaigned in support of an Australian Republic and attacked what he perceived as a lack of integrity in Australian politics, together with former Labor prime minister Gough Whitlam, finding much common ground with his predecessor and his successor Bob Hawke, another republican.
The 2001 election continued his estrangement from the Liberal Party. Many Liberals criticised the Fraser years as "a decade of lost opportunity" on deregulation of the Australian economy and other issues. In early 2004, a Young Liberal convention in Hobart called for Fraser's life membership of the Liberal Party to be ended.
In 2006, Fraser criticised Howard Liberal government policies on areas such as refugees, terrorism and civil liberties, and that "if Australia continues to follow United States policies, it runs the risk of being embroiled in the conflict in Iraq for decades, and a fear of Islam in the Australian community will take years to eradicate". Fraser claimed that the way the Howard government handled the David Hicks, Cornelia Rau and Vivian Solon cases was questionable.
On 20 July 2007, Fraser sent an open letter to members of the large activist group GetUp!, encouraging members to support GetUp's campaign for a change in policy on Iraq including a clearly defined exit strategy. Fraser stated: "One of the things we should say to the Americans, quite simply, is that if the United States is not prepared to involve itself in high-level diplomacy concerning Iraq and other Middle East questions, our forces will be withdrawn before Christmas."
After the defeat of the Howard government at the 2007 federal election, Fraser claimed Howard approached him in a corridor, following a cabinet meeting in May 1977 regarding Vietnamese refugees, and said: "We don't want too many of these people. We're doing this just for show, aren't we?" The claims were made by Fraser in an interview to mark the release of the 1977 cabinet papers. Howard, through a spokesman, denied making the comment.
In October 2007 Fraser gave a speech to Melbourne Law School on terrorism and "the importance of the rule of law," which Liberal MP Sophie Mirabella
condemned in January 2008, claiming errors and "either intellectual sloppiness or deliberate dishonesty", and claimed that he tacitly supported Islamic fundamentalism, that he should have no influence on foreign policy, and claimed his stance on the war on terror had left him open to caricature as a "frothing-at-the-mouth leftie".
Shortly after Tony Abbott won the 2009 Liberal Party leadership spill, Fraser ended his Liberal Party membership, stating the party was "no longer a liberal party but a conservative party".
Later political activity.
In December 2011, Fraser was highly critical of the Australian government's decision (also supported by the Liberal Party Opposition) to permit the export of uranium to India, relaxing the Fraser government's policy of banning sales of uranium to countries that are not signatories of the Nuclear Non-Proliferation Treaty.
In 2012, Fraser criticised the basing of US military forces in Australia. In 2014, speaking on the Russian RT television network, he criticised the concept of American exceptionalism and US foreign policy.
In late 2012, Fraser wrote a foreword for the journal "Jurisprudence" where he openly criticised the current state of human rights in Australia and the Western World. "It is a sobering thought that in recent times, freedoms hard won through centuries of struggle, in the United Kingdom and elsewhere have been whittled away. In Australia alone we have laws that allow the secret detention of the innocent. We have had a vast expansion of the power of intelligence agencies. In many cases the onus of proof has been reversed and the justice that once prevailed has been gravely diminished."
In July 2013, Fraser endorsed Australian Greens Senator Sarah Hanson-Young for re-election in a television advertisement, stating she had been a "reasonable and fair-minded voice".
Fraser's books include "Malcolm Fraser: The Political Memoirs" (with Margaret Simons – The Miegunyah Press, 2010) and "Dangerous Allies" (Melbourne University Press, 2014), which warns of "strategic dependence" on the United States.
Death.
On 20 March 2015, his office announced that Fraser had died in the early hours of the morning, noting that he had suffered a brief illness. An obituary noted that there had been "greater appreciation of the constructive and positive nature of his post-prime ministerial contribution" as his retirement years progressed. He was survived by his wife Tamara "Tamie" Beggs, whom he had married in 1956, and their four children, Mark, Angela, Hugh and Phoebe.
Fraser was given a state funeral at Scots' Church in Melbourne on 27 March 2015.
Legacy.
In 2004, Fraser designated the University of Melbourne the official custodian of his personal papers and library to create the Malcolm Fraser Collection at the university.

</doc>
<doc id="19735" url="https://en.wikipedia.org/wiki?curid=19735" title="Macquarie University">
Macquarie University

Macquarie University is a public research university based in Sydney, Australia, in the suburb of Macquarie Park. Founded in 1964 by the New South Wales Government, it was the third university to be established in the metropolitan area of Sydney.
Established as a verdant university, Macquarie has five faculties as well as the Macquarie University Hospital and the Macquarie Graduate School of Management which are located on the university's main campus in suburban Sydney. 
The university is the first in Australia to fully align its degree system with the Bologna Accord.
History.
20th century.
The idea of founding a third university in Sydney was flagged in the early 1960s when the New South Wales Government formed a committee of enquiry into higher education to deal with a perceived emergency in university enrollments in New South Wales. During this enquiry, the Senate of the University of Sydney put in a submission which highlighted 'the immediate need to establish a third university in the metropolitan area'. After much debate a future campus location was selected in what was then a semi-rural part of North Ryde, and it was decided that the future university be named after Lachlan Macquarie, an important early governor of the colony of New South Wales.
Macquarie University was formally established in 1964 with the passage of the Macquarie University Act 1964 by the New South Wales parliament. The university was designed in the Brutalist style and developed by the renowned town planner Walter Abraham who also oversaw the next 20 years of planning and development for the university. A committee appointed to advise the state government on the establishment of the new university at North Ryde nominated Abraham as the architect-planner. The fledgling Macquarie University Council decided that planning for the campus would be done within the university, rather than by consultants, and this led to the establishment of the architect-planners office.
The first Vice-Chancellor of Macquarie University, Alexander George Mitchell, was selected by the University Council which met for the first time on 17 June 1964. Members of the first university council included: Colonel Sir Edward Ford OBE, David Paver Mellor, Rae Else-Mitchell QC and Sir Walter Scott.
The university first opened to students on 6 March 1967 with more students than anticipated. The Australian Universities Commission had allowed for 510 effective full-time students (EFTS) but Macquarie had 956 enrolments and 622 EFTS. Between 1968 and 1969, enrolment at Macquarie increased dramatically with an extra 1200 EFTS, with 100 new academic staff employed. 1969 also saw the establishment of the Macquarie Graduate School of Management (MGSM).
Macquarie grew during the seventies and eighties with rapid expansion in courses offered, student numbers and development of the site. In 1972, the university established the Macquarie Law School, the third law school in Sydney. In their book "Liberality of Opportunity", Bruce Mansfield and Mark Hutchinson describe the founding of Macquarie University as 'an act of faith and a great experiment'. An additional topic considered in this book is the science reform movement of the late 1970s that resulted in the introduction of a named science degree, thus facilitating the subsequent inclusion of other named degrees in addition to the traditional BA. Alternative views on this topic are given by famous British-Australian physicist John Ward and laser physicist Frank Duarte.
The first Vice-Chancellor of Macquarie University was Alexander George Mitchell, who held the position until December 1975, when he was replaced by Edwin Webb, who served until 1986.
In 1990 the university absorbed the Institute of Early Childhood Studies of the Sydney College of Advanced Education, under the terms of the Higher Education (Amalgamation) Act 1989.
Di Yerbury was appointed Vice-Chancellor in 1986, and was the first female Vice-Chancellor in Australia. Professor Yerbury held the position of Vice-Chancellor for just under 20 years.
21st century.
Professor Steven Schwartz replaced Di Yerbury at the beginning of 2006. Yerbury's departure was attended with much controversy, including a "bitter dispute" with Schwartz, disputed ownership of university artworks worth $13 million and Yerbury's salary package. In August 2006, Professor Schwartz expressed concern about the actions of Yerbury in a letter to university auditors. Yerbury strongly denied any wrongdoing and claimed the artworks were hers.
During 2007, Macquarie University restructured its student organisation after an audit raised questions about management of hundreds of thousands of dollars in funds by student organisations At the centre of the investigation was Victor Ma, president of the Macquarie University Students' Council, who was previously involved in a high-profile case of student election fixing at the University of Sydney.
The university Council resolved to immediately remove Ma from his position. Vice-Chancellor Schwartz cited an urgent need to reform Macquarie's main student bodies.
However, Ma strongly denied any wrongdoing and labelled the controversy a case of 'character assassination'.
The Federal Court ordered on 23 May 2007 that Macquarie University Union Ltd be wound up.
Following the dissolution of Macquarie University Union Ltd, the outgoing student organisation was replaced with a new wholly owned subsidiary company of the university, known as U@MQ Ltd. The new student organisation originally lacked a true student representative union; however, following a complete review and authorisation from the university Council, a new student union known as Macquarie University Students Association (MUSRA) was established in 2009.
Within the first few hundred days of Schwartz's instatement as Vice-Chancellor, the 'Macquarie@50' strategic plan was launched, which positioned the university to enhance research, teaching, infrastructure and academic rankings by the university's 50th anniversary in 2014. Included in the university's plans for the future was the establishment of a sustainability office in order to more effectively manage environmental and social development at Macquarie. As part of this campaign, in 2009 Macquarie became the first Fair Trade accredited university in Australia. The beginning of 2009 also saw the introduction of a new logo for the university which retained the Sirius Star, present on both the old logo and the university crest, but now 'embedded in a stylised lotus flower'. In accordance with the university by-law, the crest continues to be used for formal purposes and is displayed on university testamurs. The by-law also prescribes the university's motto, taken from Chaucer: 'And gladly teche'.
In 2013, the university became the first in Australia to fully align its degree system with the Bologna Accord.
Governance.
The university is governed by a 17-member Council.
The University Council is the governing authority of the university under the "Macquarie University Act 1989". The Council takes primary responsibility for the control and management of the affairs of the University, and is empowered to make by-laws and rules relating to how the University is managed. Members of the Council include the University Vice-Chancellor, Academic and non-academic staff, the Vice President of the Academic Senate and a student representative. The Council is chaired by The Chancellor of the University.
The Academic Senate is the primary academic body of the university. It has certain powers delegated to it by Council, such as the approving of examination results and the completion of requirements for the award of degrees. At the same time, it makes recommendations to the Council concerning all changes to degree rules, and all proposals for new awards. While the Academic Senate is an independent body, it is required to make recommendations to the university Council in relation to matters outside its delegated authority.
Macquarie's current Vice-Chancellor, Dr Bruce Dowton, took over from Professor Schwartz in September 2012. Prior to his appointment Professor Dowton served as a senior medical executive having held a range of positions in university, healthcare and consulting organisations. He also served as a pediatrician at the Massachusetts General Hospital for Children, and as Clinical Professor of Pediatrics at Harvard Medical School. There have been five Vice-Chancellors in the university's history.
Campus.
Main campus.
Macquarie University's main campus is located about north-west of the Sydney CBD and is set on 126 hectares of rolling lawns and natural bushland. Located within the high-technology corridor of Sydney's north-west and in close proximity to Macquarie Park and its surrounding industries, Macquarie's location has been crucial in its development as a relatively research intensive university. The university is straddled between the suburbs of North Ryde and the later developed technology and industry focused Macquarie Park; however, the campus has its own postcode, 2109. The M2 Motorway runs parallel to the northern boundary of the campus and is accessible to traffic from the university.
Prior to the development of the campus, most of the site was cultivated with peach orchards, market gardens and poultry farms. The university's first architect-planner was Walter Abraham, one of the first six administrators appointed to Macquarie University.
Apart from its centres of learning, the campus features the Macquarie University Research Park, museums, art galleries, a sculpture park, an observatory, a sport and aquatic centre and also the private Macquarie University Hospital.
Macquarie became the first university in Australia to own and operate a private medical facility in 2010 when it opened a $300 million hospital on its North Ryde campus. The hospital is first and only private not-for-profit teaching hospital on an Australian university campus. The Macquarie University Hospital is located to the north of the main campus area are the university sports grounds. It comprises 183 beds, 12 operating theatres, 2 cardiac and vascular angiography suites. The hospital is co-located with the university's Australian School of Advanced Medicine.
The Macquarie University Research Park is a privately funded Research and Development Park located on campus and is home to companies including Dow Corning, Goodman Fielder, Nortel Networks, OPSM and Siemens.
Cochlear Headquarters, located on the southern edge of the campus, is the global headquarters for Cochlear Limited, manufacturers of cochlear implants.
Located on the western side of the campus is the Macquarie University Sport and Aquatic Centre. Previously a sports hall facility, the complex was renovated and reopened in 2007 with the addition of the new gym and aquatic centre. It houses a 50 metre FINA-compliant outdoor pool and a 25 metre indoor pool. The complex also contains a gymnasium and squash, badminton, basketball, volleyball and netball courts.
The Macquarie University Observatory was originally constructed in 1978 as a research facility but, since 1997, has been accessible to the public through its Public Observing Program.
Library.
The library houses over 1.8 million items and uses the Library of Congress Classification System. The library features several collections including a Rare Book Collection, a Palaeontology Collection and the Brunner Collection of Egyptological materials. Macquarie University operated two libraries during the transition. The old library in building C7A closed at the end of July 2011, and the new library in building C3C became fully operational on 1 August 2011. The new library was the first university library in Australia to possess an Automated Storage and Retrieval System (ASRS). The ASRS consists of an environmentally controlled vault with metal bins storing the items; robotic cranes retrieve an item on request and deliver it to the service desk for collection.
Residential colleges.
Macquarie University has two residential colleges on its campus, Dunmore Lang College and Robert Menzies College, both founded in 1972. In addition to these residential colleges is the Macquarie University Village which contains over 890 rooms inside multiple two-storey townhouses and apartment block.
Macquarie University railway station.
Macquarie University is served by the Macquarie University railway station, which opened in 2009. The underground station is on the Sydney Trains network. The station is served by eight trains per hour for most of the day. There is also a bus interchange within the campus that provides close to 800 bus services daily.
Academics.
The university currently comprises 35 departments within five faculties:
Research centres, schools and institutes that are affiliated with the university:
Macquarie University's Australian Hearing Hub is partnered with Cochlear. Cochlear Headquarters are on campus. The Australian Hearing Hub includes the head office of Australian Hearing.
The Australian Research Institute for Environment and Sustainability is a research centre that promotes change for environmental sustainability, is affiliated with the University and is located on its campus.
Access Macquarie Limited was established in 1989 as the commercial arm of the university. It facilitates and supports the commercial needs of industry, business and government organisations seeking to utilise the academic expertise of the broader University community.
Admissions.
The Sydney Institute of Business and Technology operates on the Macquarie University campus, offering Foundation Studies (Pre-University) and University-level Diplomas. Upon successful completion of a SIBT Diploma, students enter the appropriate bachelor's degree as a second year student.
The Centre for Macquarie English is the English-language centre that offers a range of specialised, direct entry English programmes that are approved by Macquarie University.
Research.
The university positions itself as being research intensive. In 2012, 85% of Macquarie's broad fields of research was rated 'at or above world standard' in the Excellence in Research for Australia 2012 National report. The university is within the top 3 universities in Australia for the number of peer reviewed publications produced per academic staff member.
Researchers at Macquarie University, David Skellern and Neil Weste, and the Commonwealth Scientific and Industrial Research Organisation helped develop Wi-Fi. David Skellern has been a major donor to the University through the Skellern Family Trust. Macquarie University's linguistics department developed the Macquarie Dictionary. The dictionary is regarded as the standard reference on Australian English.
Macquarie University has a research partnership with the University of Hamburg in Germany and Fudan University in China. They offer dual and joint degree programs and engage in joint research.
University rankings.
Macquarie is ranked in the top 40 universities in the Asia-Pacific region and within Australia's top nine universities according to the Academic Ranking of World Universities, the U.S. News & World Report Rankings and the QS World University Rankings. Macquarie is ranked just outside the top eight in Australia (Group of Eight universities) in most international rankings, or has ranked within the top eight in Australia in international rankings. In 2011–2012 CWTS Leiden Ranking Macquarie was ranked 4th in Australia. Macquarie University was ranked in 2014: 239th in the world (9th in Australia) in the Academic Ranking of World Universities, 254th in the world (9th in Australia) in the QS World University Rankings, and 301–350 in the world in the Times Higher Education World University Rankings.
Macquarie was the highest ranked university in Australia under the age of 50 and was ranked 18th in the world (prior to its golden jubilee in 2014), according to the QS World University Rankings.
Macquarie University was ranked among the top 50 universities in the world for linguistics (43rd), psychology (48th) and earth and marine sciences (48th), and was ranked in the top 5 nationally for philosophy and earth and marine sciences, according to the 2014 QS World University Rankings.
Macquarie ranked 67th in the world for Arts and Humanities (equal 5th in Australia), according to the 2015 Times Higher Education rankings by subject. Arts and Humanities is Macquarie's best discipline area in rankings. Macquarie was one of four non-Group of Eight universities ranked in the top 100 universities in the world in particular discipline areas.
The Macquarie Graduate School of Management is one of the oldest business schools in Australia. In 2011, "The Economist" ranked MGSM 73rd in the world, 7th in Asia Pacific and 1st in Sydney/New South Wales. It was ranked 13th in the Asia-Pacific, according to QS Global 200 Business Schools Report for 2013–14. In 2014, "The Economist" ranked MGSM 5th in the Asia-Pacific, 3rd in Australia, 1st in Sydney/New South Wales and 49th in the world. It was the highest ranked business school in Australia and was ranked 68th in the world in the 2015 "Financial Times" MBA ranking.
Macquarie University is ranked first in environmental sciences and ecology research within Australia and New Zealand, and is ranked 14th in the world, according to Times Higher Education.
Students.
Macquarie is the fourth largest university in Sydney (38,753 students in 2013). The university has the largest student exchange programme in Australia.
In 2012, 9,802 students from Asia were enrolled at Macquarie University (Sydney campuses and offshore programs in China, Hong Kong, Korea and Singapore).
Campus Life manages the university's non-academic services: food and retail, sport and recreation, student groups, child care, and entertainment.
The Global Leadership Program (GLP) is a student organisation and program that is undertaken by a large proportion of Macquarie Students. All students at the university are encouraged to undertake the program to enhance leadership skills, cross cultural understanding and international awareness. Upon completion of the GLP, students receive a formal notation on their academic transcript.
Macquarie University has its own community radio station on campus, 2SER FM. The station is jointly owned by Macquarie University and University of Technology, Sydney.
Macquarie University students celebrate Conception Day each year since 1969 to – according to legend – commemorate the date of conception of Lachlan Macquarie, as his birthday fell at the wrong time of year for a celebration. Conception Day is traditionally held on the last day of classes before the September mid-semester break.
Conception Day has since been cancelled and replaced with the less popular FAME festival in 2015. However, there are ongoing social media protests on behalf of students to reinstate the tradition of Conception Day.
Notable alumni and staff.
Alumni include Rhodes and John Monash Scholars and several Fulbright Scholars.
Notable alumni include: Australian politician and former Lord Mayor of Brisbane, Jim Soorley; Australian basketball player, Lauren Jackson; Australian swimmer, Ian Thorpe; Australian water polo player, Holly Lincoln-Smith; three founding members of the Australian children's musical group The Wiggles (Murray Cook, Anthony Field, Greg Page); New Zealand conservationist, Pete Bethune.
Notable alumni in science include: Australian scientist Barry Brook, American physicist Frank Duarte, and Australian scientist Cathy Foley. Alumni notable in the business world include: Australian hedge fund manager Greg Coffey, Australian businesswoman Catherine Livingstone and Australian venture capitalist Larry R. Marshall.
Notable faculty members include: Australian writer and four time Miles Franklin Award winner, Thea Astley; Hungarian Australian mathematician, Esther Szekeres; Australian mathematician, Neil Trudinger; Australian environmentalist and activist, Tim Flannery; British physicist, Paul Davies; British-Australian physicist, John Clive Ward; Israeli-Australian physicist, José Enrique Moyal; Australian linguist, Geoffrey Hull.
Four Macquarie University academics were included in The World's Most Influential Minds 2014 report by Thomson Reuters, which identified the most highly cited researchers of the last 11 years.

</doc>
<doc id="19736" url="https://en.wikipedia.org/wiki?curid=19736" title="Muspelheim">
Muspelheim

In Norse mythology, Muspelheim (), also called Muspell (), is a realm of fire. This realm is one of the Nine Worlds, ruled by Surt with his consort Sinmara in some accounts. The denizens of Muspelheim were usually referred to as the Eldjötnar ("fire giants") in Norse tradition, though they were also identified by other epithets in Eddic poetry, such as the Múspellssynir (or Múspellsmegir — "sons of Muspell") and the Rjúfendr (from "rjúfa" — "to break, tear asunder", "Destroyers of Doomsday"). Both of these terms sometimes described an entirely separate mythological species that dwelled alongside or in place of the eldjötnar within this fiery realm. Muspelheim is fire; and the land to the North, Niflheim, is ice. The two mixed and created water from the melting ice in Ginnungagap. The sun and the stars originate from Muspelheim.
According to the Ragnarök prophecies in Snorri Sturluson's Gylfaginning, the first part of his Prose Edda, the sons of Muspell will break the Bifröst bridge, signaling the end of times:
The etymology of "Muspelheim" is uncertain, but may come from "Mund-spilli", "world-destroyers", "wreck of the world".
In popular culture.
The realm of Muspelheim appears as 'Muspel' in Gene Wolfe's book series, "The Wizard Knight". It is inhabited by the dragon 'Setr', as a close parallel to Surtr.
"Muspel" is the name of a German colony in Africa in the alternate-reality novel "The Afrika Reich" by Guy Saville.
Muspelheim is the name of a reoccurring boss ship in the "" series.

</doc>
<doc id="19737" url="https://en.wikipedia.org/wiki?curid=19737" title="Maxwell's equations">
Maxwell's equations

Maxwell's equations are a set of partial differential equations that, together with the Lorentz force law, form the foundation of classical electrodynamics, classical optics, and electric circuits. These fields in turn underlie modern electrical and communications technologies. Maxwell's equations describe how electric and magnetic fields are generated and altered by each other and by charges and currents. They are named after the physicist and mathematician James Clerk Maxwell, who published an early form of those equations between 1861 and 1862.
The equations have two major variants. The "microscopic" set of Maxwell's equations uses total charge and total current, including the complicated charges and currents in materials at the atomic scale; it has universal applicability but may be infeasible to calculate. The "macroscopic" set of Maxwell's equations defines two new auxiliary fields that describe large-scale behaviour without having to consider these atomic scale details, but it requires the use of parameters characterizing the electromagnetic properties of the relevant materials.
The term "Maxwell's equations" is often used for other forms of Maxwell's equations. For example, space-time formulations are commonly used in high energy and gravitational physics. These formulations, defined on space-time rather than space and time separately, are manifestly compatible with special and general relativity. In quantum mechanics and analytical mechanics, versions of Maxwell's equations based on the electric and magnetic potentials are preferred.
Since the mid-20th century, it has been understood that Maxwell's equations are not exact but are a classical field theory approximation to the more accurate and fundamental theory of quantum electrodynamics. In many situations, though, deviations from Maxwell's equations are immeasurably small. Exceptions include nonclassical light, photon-photon scattering, quantum optics, and many other phenomena related to photons or virtual photons.
Formulation in terms of electric and magnetic fields.
As a major contributor to the mathematics of vector calculus, Oliver Heaviside was able to rewrite Maxwell's original 20 equations into a mathematically equivalent four equation form. For Maxwell's equations, vector calculus formulations are much more mathematically convenient, and have become the standard formulation to use.
In the electric and magnetic field formulation there are four equations. Two of them describe how the fields vary in space due to sources, if any; electric fields emanating from electric charges in Gauss's law, and magnetic fields as closed field lines "not due to magnetic monopoles" in Gauss's law for magnetism. The other two describe how the fields "circulate" around their respective sources; the magnetic field "circulates" around electric currents and time varying electric fields in Ampère's law with Maxwell's addition, while the electric field "circulates" around time varying magnetic fields in Faraday's law. A separate law of nature, the Lorentz force law, describes how the electric and magnetic field act on charged particles and currents. A version of this law was included in the original equations by Maxwell but, by convention, is no longer.
The precise formulation of Maxwell's equations depends on the precise definition of the quantities involved. Conventions differ with the unit systems, because various definitions and dimensions are changed by absorbing dimensionful factors like the speed of light . This makes constants come out differently. The most common form is based on quantities measured using SI units, but other commonly used units include Gaussian units based on the cgs system, Lorentz–Heaviside units (used mainly in particle physics), and Planck units (used in theoretical physics).
Formulation in Gaussian units.
Gaussian units are a popular system of units, that are part of the centimetre–gram–second system of units (cgs). When using cgs units it is conventional to use a slightly different definition of electric field . This implies that the modified electric and magnetic field have the same units (in the SI convention this is not the case: e.g. for EM waves in vacuum, , making dimensional analysis of the equations different). Then it uses a unit of charge defined in such a way that the permittivity of the vacuum , hence . These units are sometimes preferred over SI units in the context of special relativity, since when using them, the components of the electromagnetic tensor, the Lorentz covariant object describing the electromagnetic field, have the same unit without constant factors.
Using these different conventions, the Maxwell equations become:
Key for mathematical notation.
Symbols in bold represent vector quantities, and symbols in "italics" represent scalar quantities, unless otherwise indicated.
The equations introduce the electric field, , a vector field, and the magnetic field, , a pseudovector field, where each generally have time-dependence.
The universal constants appearing in the equations are
In the differential equations, a "local" description of the fields,
The sources are taken to be
In the integral equations, a description of the fields within a region of space,
Here "fixed" means the volume or surface do not change in time. Although it is possible to formulate Maxwell's equations with time-dependent surfaces and volumes, this is not actually necessary: the equations are correct and complete with time-independent surfaces. The sources are correspondingly the total amounts of charge and current within these volumes and surfaces, found by integration.
The "total charge or current" refers to including free and bound charges, or free and bound currents. These are used in the macroscopic formulation.
Relationship between differential and integral formulations.
The differential and integral formulations of the equations are mathematically equivalent, by the divergence theorem in the case of Gauss's law and Gauss's law for magnetism, and by the Kelvin–Stokes theorem in the case of Faraday's law and Ampère's law. Both the differential and integral formulations are useful. The integral formulation can often be used to simplify and directly calculate fields from symmetric distributions of charges and currents. On the other hand, the differential formulation is a more natural starting point for calculating the fields in more complicated (less symmetric) situations, for example using finite element analysis.
Flux and divergence.
The "fields emanating from the sources" can be inferred from the surface integrals of the fields through the closed surface , defined as the electric flux and magnetic flux , as well as their respective divergences and . These surface integrals and divergences are connected by the divergence theorem.
Circulation and curl.
The "circulation of the fields" can be interpreted from the line integrals of the fields around the closed curve :
where is the differential vector element of "path length" tangential to the path/curve, as well as their curls:
These line integrals and curls are connected by Stokes' theorem, and are analogous to quantities in classical fluid dynamics: the circulation of a fluid is the line integral of the fluid's flow velocity field around a closed loop, and the vorticity of the fluid is the curl of the velocity field.
Time evolution.
The "dynamics" or "time evolution of the fields" is due to the partial derivatives of the fields with respect to time:
These derivatives are crucial for the prediction of field propagation in the form of electromagnetic waves. Since the surface is taken to be time-independent, we can make the following transition in Faraday's law:
see differentiation under the integral sign for more on this result.
Conceptual descriptions.
Gauss's law.
Gauss's law describes the relationship between a static electric field and the electric charges that cause it: The static electric field points away from positive charges and towards negative charges. In the field line description, electric field lines begin only at positive electric charges and end only at negative electric charges. 'Counting' the number of field lines passing through a closed surface, therefore, yields the total charge (including bound charge due to polarization of material) enclosed by that surface divided by dielectricity of free space (the vacuum permittivity). More technically, it relates the electric flux through any hypothetical closed "Gaussian surface" to the enclosed electric charge.
Gauss's law for magnetism.
Gauss's law for magnetism states that there are no "magnetic charges" (also called magnetic monopoles), analogous to electric charges. Instead, the magnetic field due to materials is generated by a configuration called a dipole. Magnetic dipoles are best represented as loops of current but resemble positive and negative 'magnetic charges', inseparably bound together, having no net 'magnetic charge'. In terms of field lines, this equation states that magnetic field lines neither begin nor end but make loops or extend to infinity and back. In other words, any magnetic field line that enters a given volume must somewhere exit that volume. Equivalent technical statements are that the sum total magnetic flux through any Gaussian surface is zero, or that the magnetic field is a solenoidal vector field.
Faraday's law.
The Maxwell-Faraday's equation version of Faraday's law describes how a time varying magnetic field creates ("induces") an electric field. This dynamically induced electric field has closed field lines just as the magnetic field, if not superposed by a static (charge induced) electric field. This aspect of electromagnetic induction is the operating principle behind many electric generators: for example, a rotating bar magnet creates a changing magnetic field, which in turn generates an electric field in a nearby wire.
Ampère's law with Maxwell's addition.
Ampère's law with Maxwell's addition states that magnetic fields can be generated in two ways: by electric current (this was the original "Ampère's law") and by changing electric fields (this was "Maxwell's addition").
Maxwell's addition to Ampère's law is particularly important: it shows that not only does a changing magnetic field induce an electric field, but also a changing electric field induces a magnetic field. Therefore, these equations allow self-sustaining "electromagnetic waves" to travel through empty space (see electromagnetic wave equation).
The speed calculated for electromagnetic waves, which could be predicted from experiments on charges and currents, exactly matches the speed of light; indeed, light "is" one form of electromagnetic radiation (as are X-rays, radio waves, and others). Maxwell understood the connection between electromagnetic waves and light in 1861, thereby unifying the theories of electromagnetism and optics.
Vacuum equations, electromagnetic waves and speed of light.
In a region with no charges () and no currents (), such as in a vacuum, Maxwell's equations reduce to:
Taking the curl of the curl equations, and using the curl of the curl identity we obtain the wave equations
which identify
with the speed of light in free space. In materials with relative permittivity, , and relative permeability, , the phase velocity of light becomes
which is usually less than .
In addition, and are mutually perpendicular to each other and the direction of wave propagation, and are in phase with each other. A sinusoidal plane wave is one special solution of these equations. Maxwell's equations explain how these waves can physically propagate through space. The changing magnetic field creates a changing electric field through Faraday's law. In turn, that electric field creates a changing magnetic field through Maxwell's addition to Ampère's law. This perpetual cycle allows these waves, now known as electromagnetic radiation, to move through space at velocity, .
Macroscopic formulation.
The "microscopic" variant of Maxwell's equation is the version given above. It expresses the electric field and the magnetic field in terms of the "total charge" and "total current" present, including the charges and currents at the atomic level. The "microscopic" form is sometimes called the "general" form of Maxwell's equations. The macroscopic variant of Maxwell's equation is equally general, however, with the difference being one of bookkeeping.
The "microscopic" variant is sometimes called "Maxwell's equations in a vacuum". This refers to the fact that the material medium is not built into the structure of the equation; it does not mean that space is empty of charge or current.
"Maxwell's macroscopic equations", also known as Maxwell's equations in matter, are more similar to those that Maxwell introduced himself.
Unlike the "microscopic" equations, the "macroscopic" equations separate out the bound charge and bound current to obtain equations that depend only on the free charges and currents . This factorization can be made by splitting the total electric charge and current as follows:
Correspondingly, the total current density splits into free and bound components, and similarly the total charge density splits into free and bound parts.
The cost of this factorization is that additional fields, the displacement field and the magnetizing field , are defined and need to be determined. Phenomenological constituent equations relate the additional fields to the electric field and the magnetic -field, often through a simple linear relation.
For a detailed description of the differences between the microscopic ("total" charge and current including material contributes or in air/vacuum)
and macroscopic ("free" charge and current; practical to use on materials) variants of Maxwell's equations, see below.
Bound charge and current.
When an electric field is applied to a dielectric material its molecules respond by forming microscopic electric dipoles – their atomic nuclei move a tiny distance in the direction of the field, while their electrons move a tiny distance in the opposite direction. This produces a "macroscopic" "bound charge" in the material even though all of the charges involved are bound to individual molecules. For example, if every molecule responds the same, similar to that shown in the figure, these tiny movements of charge combine to produce a layer of positive bound charge on one side of the material and a layer of negative charge on the other side. The bound charge is most conveniently described in terms of the polarization of the material, its dipole moment per unit volume. If is uniform, a macroscopic separation of charge is produced only at the surfaces where enters and leaves the material. For non-uniform , a charge is also produced in the bulk.
Somewhat similarly, in all materials the constituent atoms exhibit magnetic moments that are intrinsically linked to the angular momentum of the components of the atoms, most notably their electrons. The connection to angular momentum suggests the picture of an assembly of microscopic current loops. Outside the material, an assembly of such microscopic current loops is not different from a macroscopic current circulating around the material's surface, despite the fact that no individual charge is traveling a large distance. These "bound currents" can be described using the magnetization .
The very complicated and granular bound charges and bound currents, therefore, can be represented on the macroscopic scale in terms of and which average these charges and currents on a sufficiently large scale so as not to see the granularity of individual atoms, but also sufficiently small that they vary with location in the material. As such, "Maxwell's macroscopic equations" ignore many details on a fine scale that can be unimportant to understanding matters on a gross scale by calculating fields that are averaged over some suitable volume.
Auxiliary fields, polarization and magnetization.
The "definitions" (not constitutive relations) of the auxiliary fields are:
where is the polarization field and is the magnetization field which are defined in terms of microscopic bound charges and bound currents respectively. The macroscopic bound charge density and bound current density in terms of polarization and magnetization are then defined as
If we define the total, bound, and free charge and current density by
and use the defining relations above to eliminate , and , the "macroscopic" Maxwell's equations reproduce the "microscopic" equations.
Constitutive relations.
In order to apply 'Maxwell's macroscopic equations', it is necessary to specify the relations between displacement field and the electric field , as well as the magnetizing field and the magnetic field . Equivalently, we have to specify the dependence of the polarisation (hence the bound charge) and the magnetisation (hence the bound current) on the applied electric and magnetic field. The equations specifying this response are called constitutive relations. For real-world materials, the constitutive relations are rarely simple, except approximately, and usually determined by experiment. See the main article on constitutive relations for a fuller description.
For materials without polarisation and magnetisation ("vacuum"), the constitutive relations are
where is the permittivity of free space and the permeability of free space. Since there is no bound charge, the total and the free charge and current are equal.
More generally, for linear materials the constitutive relations are
where is the permittivity and the permeability of the material. Even the linear case can have various complications, however.
Even more generally, in the case of non-linear materials (see for example nonlinear optics), and are not necessarily proportional to , similarly is not necessarily proportional to or . In general and depend on both and , on location and time, and possibly other physical quantities.
In applications one also has to describe how the free currents and charge density behave in terms of and possibly coupled to other physical quantities like pressure, and the mass, number density, and velocity of charge-carrying particles. E.g., the original equations given by Maxwell (see History of Maxwell's equations) included Ohms law in the form
Alternative formulations.
Following is a summary of some of the numerous other ways to write the microscopic Maxwell's equations, showing they can be formulated using different points of view and mathematical formalisms that describe the same physics. Often, they are also called the Maxwell equations. The direct space–time formulations make manifest that the Maxwell equations are relativistically invariant (in fact studying the hidden symmetry of the vector calculus formulation was a major source of inspiration for relativity theory). In addition, the formulation using potentials was originally introduced as a convenient way to solve the equations but with all the observable physics contained in the fields. The potentials play a central role in quantum mechanics, however, and act quantum mechanically with observable consequences even when the fields vanish (Aharonov–Bohm effect). See the main articles for the details of each formulation. SI units are used throughout.
where
Other formulations include the geometric algebra formulation and a matrix representation of Maxwell's equations. Historically, a quaternionic formulation was used.
Solutions.
Maxwell's equations are partial differential equations that relate the electric and magnetic fields to each other and to the electric charges and currents. Often, the charges and currents are themselves dependent on the electric and magnetic fields via the Lorentz force equation and the constitutive relations. These all form a set of coupled partial differential equations, which are often very difficult to solve. In fact, the solutions of these equations encompass all the diverse phenomena in the entire field of classical electromagnetism. A thorough discussion is far beyond the scope of the article, but some general notes follow.
Like any differential equation, boundary conditions and initial conditions are necessary for a unique solution. For example, even with no charges and no currents anywhere in spacetime, many solutions to Maxwell's equations are possible, not just the obvious solution . Another solution is , , while yet other solutions have electromagnetic waves filling spacetime. In some cases, Maxwell's equations are solved through infinite space, and boundary conditions are given as asymptotic limits at infinity. In other cases, Maxwell's equations are solved in just a finite region of space, with appropriate boundary conditions on that region: For example, the boundary could be an artificial absorbing boundary representing the rest of the universe, or periodic boundary conditions, or (as with a waveguide or cavity resonator) the boundary conditions may describe the walls that isolate a small region from the outside world.
Jefimenko's equations (or the closely related Liénard–Wiechert potentials) are the explicit solution to Maxwell's equations for the electric and magnetic fields created by any given distribution of charges and currents. It assumes specific initial conditions to obtain the so-called "retarded solution", where the only fields present are the ones created by the charges. Jefimenko's equations are not so helpful in situations when the charges and currents are themselves affected by the fields they create.
Numerical methods for differential equations can be used to approximately solve Maxwell's equations when an exact solution is impossible. These methods usually require a computer, and include the finite element method and finite-difference time-domain method. For more details, see Computational electromagnetics.
Maxwell's equations "seem" overdetermined, in that they involve six unknowns (the three components of and ) but eight equations (one for each of the two Gauss's laws, three vector components each for Faraday's and Ampere's laws). (The currents and charges are not unknowns, being freely specifiable subject to charge conservation.) This is related to a certain limited kind of redundancy in Maxwell's equations: It can be proven that any system satisfying Faraday's law and Ampere's law "automatically" also satisfies the two Gauss's laws, as long as the system's initial condition does. This explanation was first introduced by Julius Adams Stratton in 1941. Although it is possible to simply ignore the two Gauss's laws in a numerical algorithm (apart from the initial conditions), the imperfect precision of the calculations can lead to ever-increasing violations of those laws. By introducing dummy variables characterizing these violations, the four equations become not overdetermined after all. The resulting formulation can lead to more accurate algorithms that take all four laws into account.
Limitations of the Maxwell equations as a theory of electromagnetism.
While Maxwell's equations (along with the rest of classical electromagnetism) are extraordinarily successful at explaining and predicting a variety of phenomena, they are not exact, but approximations. In some special situations, they can be noticeably inaccurate. Examples include extremely strong fields (see Euler–Heisenberg Lagrangian) and extremely short distances (see vacuum polarization). Moreover, various phenomena occur in the world even though Maxwell's equations predict them to be impossible, such as "nonclassical light" and quantum entanglement of electromagnetic fields (see quantum optics). Finally, any phenomenon involving individual photons, such as the photoelectric effect, Planck's law, the Duane–Hunt law, single-photon light detectors, etc., would be difficult or impossible to explain if Maxwell's equations were exactly true, as Maxwell's equations do not involve photons. For the most accurate predictions in all situations, Maxwell's equations have been superseded by quantum electrodynamics.
Variations.
Popular variations on the Maxwell equations as a classical theory of electromagnetic fields are relatively scarce because the standard equations have stood the test of time remarkably well.
Magnetic monopoles.
Maxwell's equations posit that there is electric charge, but no magnetic charge (also called magnetic monopoles), in the universe. Indeed, magnetic charge has never been observed (despite extensive searches) and may not exist. If they did exist, both Gauss's law for magnetism and Faraday's law would need to be modified, and the resulting four equations would be fully symmetric under the interchange of electric and magnetic fields.
Historical publications.
The developments before relativity:

</doc>
<doc id="19738" url="https://en.wikipedia.org/wiki?curid=19738" title="Metrization theorem">
Metrization theorem

In topology and related areas of mathematics, a metrizable space is a topological space that is homeomorphic to a metric space. That is, a topological space formula_1 is said to be metrizable if there is a metric 
such that the topology induced by "d" is formula_3. Metrization theorems are theorems that give sufficient conditions for a topological space to be metrizable.
Properties.
Metrizable spaces inherit all topological properties from metric spaces. For example, they are Hausdorff paracompact spaces (and hence normal and Tychonoff) and first-countable. However, some properties of the metric, such as completeness, cannot be said to be inherited. This is also true of other structures linked to the metric. A metrizable uniform space, for example, may have a different set of contraction maps than a metric space to which it is homeomorphic.
Metrization theorems.
One of the first widely recognized metrization theorems was Urysohn's metrization theorem. This states that every Hausdorff second-countable regular space is metrizable. So, for example, every second-countable manifold is metrizable. (Historical note: The form of the theorem shown here was in fact proved by Tychonoff in 1926. What Urysohn had shown, in a paper published posthumously in 1925, was that every second-countable "normal" Hausdorff space is metrizable). The converse does not hold: there exist metric spaces that are not second countable, for example, an uncountable set endowed with the discrete metric. The Nagata–Smirnov metrization theorem, described below, provides a more specific theorem where the converse does hold.
Several other metrization theorems follow as simple corollaries to Urysohn's Theorem. For example, a compact Hausdorff space is metrizable if and only if it is second-countable.
Urysohn's Theorem can be restated as: A topological space is separable and metrizable if and only if it is regular, Hausdorff and second-countable. The Nagata–Smirnov metrization theorem extends this to the non-separable case. It states that a topological space is metrizable if and only if it is regular, Hausdorff and has a σ-locally finite base. A σ-locally finite base is a base which is a union of countably many locally finite collections of open sets. For a closely related theorem see the Bing metrization theorem.
Separable metrizable spaces can also be characterized as those spaces which are homeomorphic to a subspace of the Hilbert cube formula_4, i.e. the countably infinite product of the unit interval (with its natural subspace topology from the reals) with itself, endowed with the product topology.
A space is said to be locally metrizable if every point has a metrizable neighbourhood. Smirnov proved that a locally metrizable space is metrizable if and only if it is Hausdorff and paracompact. In particular, a manifold is metrizable if and only if it is paracompact.
Examples.
The group of unitary operators formula_5 on a separable Hilbert space formula_6 endowed
with the strong operator topology is metrizable (see Proposition II.1 in ).
Examples of non-metrizable spaces.
Non-normal spaces cannot be metrizable; important examples include
The real line with the lower limit topology is not metrizable. The usual distance function is not a metric on this space because the topology it determines is the usual topology, not the lower limit topology. This space is Hausdorff, paracompact and first countable.
The long line is locally metrizable but not metrizable; in a sense it is "too long".

</doc>
<doc id="19739" url="https://en.wikipedia.org/wiki?curid=19739" title="Martin Agricola">
Martin Agricola

Martin Agricola (6 January 1486 – 10 June 1556) was a German composer of Renaissance music and a music theorist.
Biography.
Agricola was born in Schwiebus in Lebusz.
From 1524 until his death he lived at Magdeburg, where he occupied the post of teacher or cantor in the Protestant school. The senator and music-printer Georg Rhau, of Wittenberg, was a close friend of Agricola, whose theoretical works, providing valuable material concerning the change from the old to the new system of notation, he published.
Among Agricola's other theoretical works is "Musica instrumentalis deudsch" (1528 and 1545), a study of musical instruments, and one of the most important works in early organology; and one of the earliest books on the Rudiments of music.
Agricola was also the first to harmonize in four parts Martin Luther's chorale, "Ein feste Burg".

</doc>
<doc id="19740" url="https://en.wikipedia.org/wiki?curid=19740" title="Max August Zorn">
Max August Zorn

Max August Zorn (; June 6, 1906 – March 9, 1993) was a German mathematician. He was an algebraist, group theorist, and numerical analyst. He is best known for Zorn's lemma, a powerful tool in set theory that is applicable to a wide range of mathematical constructs such as vector spaces, ordered sets, etc. Zorn's lemma was first postulated by Kazimierz Kuratowski in 1922, and then independently by Zorn in 1935.
Life and career.
Zorn was born in Krefeld, Germany. He attended the University of Hamburg. He received his Ph.D. in April 1930 for a thesis on alternative algebras. He married Alice Schlottau and they had one son, Jens, and one daughter, Liz. Jens (born June 19, 1931) is an emeritus professor of physics at the University of Michigan and an accomplished sculptor. Max Zorn's grandson Eric Zorn is a columnist for the "Chicago Tribune".
Max Zorn was appointed as an assistant at the University of Halle. However, he did not have the opportunity to work there for long since he was forced to leave Germany in 1933 because of the Nazi policies. He emigrated to the U.S. and was appointed a Sterling Fellow at Yale University. After that, he moved to UCLA and remained until 1946. He left UCLA to become a professor at Indiana University. He held this position from 1946 until he retired in 1971. He was thesis advisor for Israel Nathan Herstein.
Zorn died in Bloomington, Indiana, United States, in March 1993, of congestive heart failure, according to his obituary in "The New York Times".

</doc>
<doc id="19745" url="https://en.wikipedia.org/wiki?curid=19745" title="Main (river)">
Main (river)

The Main () is a river in Germany. With a length of (including the White Main: ), it is the longest right tributary of the Rhine, and the longest river lying entirely in Germany (if we consider the Weser and the Werra as two separate rivers; together they are longer). The largest cities along the Main are Frankfurt am Main and Würzburg.
Geography.
The Main River flows through the German states of Bavaria, Baden-Württemberg (forming the border with Bavaria for some distance) and Hesse. Its basin competes with the Danube for water; as a result, many of its boundaries are identical with those of the European Watershed.
The Main begins near Kulmbach in Franconia at the joining of its two headstreams, the Red Main ("Roter Main") and the White Main ("Weißer Main"). The Red Main originates in the Franconian Jura mountain range, in length, and runs through Creussen and Bayreuth. The White Main originates in the mountains of the Fichtelgebirge; it is long. In its upper and middle section it runs through the valleys of the German Highlands. Its lower section crosses the Lower Main Lowlands (Hanau-Seligenstadt Basin and northern Upper Rhine Plain) to Wiesbaden, where it discharges into the Rhine. Major tributaries of the Main are the Regnitz, the Franconian Saale, the Tauber, and the Nidda.
The name derives from the Latin "Moenus" or "Menus", and is not related to the name of the city Mainz (Latin: "Moguntiacum").
Navigation.
The Main is navigable for shipping from its mouth at the Rhine close to Mainz for to Bamberg. Since 1992, the Main has been connected to the Danube via the Rhine-Main-Danube Canal and the highly regulated Altmühl river. The Main has been canalized with 34 large locks () to allow CEMT class V () vessels to navigate the total length of the river. The 16 locks in the adjacent Rhine-Main-Danube Canal and the Danube itself are of the same dimensions.
Dams and locks.
There are 34 dams and locks along the 380 km navigable portion of the Main, from the confluence with the Regnitz near Bamberg, to the Rhine.
Hydroelectric power generation.
Most of the dams along the Main also have turbines for power generation.
Tributaries.
Tributaries from source to mouth:
Left
Right
Ports and municipalities.
Around Frankfurt are several large inland ports. Because the river is rather narrow on many of the upper reaches, navigation with larger vessels and push convoys requires great skill.
The largest cities along the Main are Frankfurt am Main and Würzburg. The Main also passes the following towns and cities: Burgkunstadt, Lichtenfels, Bad Staffelstein, Eltmann, Haßfurt, Schweinfurt, Volkach, Kitzingen, Marktbreit, Ochsenfurt, Karlstadt, Gemünden, Lohr, Marktheidenfeld, Wertheim, Miltenberg, Obernburg, Erlenbach/Main, Aschaffenburg, Seligenstadt, Hainburg, Hanau, Offenbach, Hattersheim, Flörsheim, and Rüsselsheim.
The river has gained enormous importance as a vital part of European "Corridor VII", the inland waterway link from the North Sea to the Black Sea.
Main line.
In a historical and political sense, the Main line is referred to as the northern border of Southern Germany, with its predominantly Catholic population. The river roughly marked the southern border of the North German Federation, established in 1867 under Prussian leadership as the predecessor of the German Empire.
The river course also corresponds with the Speyer line isogloss between Central and Upper German dialects, sometimes mocked as "Weißwurstäquator".
Recreation.
The Main-Radweg is a major German bicycle path running along the Main River. It is approximately long and was the first long-distance bicycle path to be awarded 5 stars by the General German Bicycle Club ADFC in 2008. It starts from either Creußen or Bischofsgrün and ends in Mainz.

</doc>
<doc id="19747" url="https://en.wikipedia.org/wiki?curid=19747" title="Marcus Vipsanius Agrippa">
Marcus Vipsanius Agrippa

Marcus Vipsanius Agrippa (; 64/62 BC – 12 BC) was a Roman statesman, general and architect. He was a close friend, son-in-law, and lieutenant to Octavian and was responsible for the construction of some of the most notable buildings in the history of Rome and for important military victories, most notably at the Battle of Actium in 31 BC against the forces of Mark Antony and Cleopatra. As a result of these victories Octavian became the first Roman Emperor, adopting the name of Augustus. Agrippa assisted Augustus in making Rome a city of marble and renovating aqueducts to give all Romans, from every social class, access to the highest quality public services. He was responsible for the creation of many baths, porticoes and gardens and was once thought to have commissioned the construction of the Pantheon. Agrippa was also father-in-law to the second Emperor Tiberius, maternal grandfather to Caligula, and maternal great-grandfather to the Emperor Nero.
Early life.
Agrippa was born between 64–62 BC, in an uncertain location. His father was perhaps called Lucius Vipsanius Agrippa. However, Agrippa was about the same age as Octavian (the future emperor Augustus), and the two were educated together and became close friends. Despite Agrippa's association with the family of Julius Caesar, his elder brother chose another side in the civil wars of the 40s BC, fighting under Cato against Caesar in Africa. When Cato's forces were defeated, Agrippa's brother was taken prisoner but freed after Octavian interceded on his behalf.
It is not known whether Agrippa fought against his brother in Africa, but he probably served in Caesar's campaign of 46–45 BC against Gnaeus Pompeius, which culminated in the Battle of Munda. Caesar regarded him highly enough to send him with Octavius in 45 BC to study in Apollonia (on the Illyrian coast) with the Macedonian legions, while Caesar consolidated his power in Rome. In the fourth month of their stay in Apollonia the news of Julius Caesar's assassination in March 44 BC reached them. Agrippa and another friend, Quintus Salvidienus Rufus, advised Octavius to march on Rome with the troops from Macedonia, but Octavius decided to sail to Italy with a small retinue. After his arrival, he learned that Caesar had adopted him as his legal heir. Octavius at this time took Caesar's name, but modern historians refer to him as "Octavian" during this period.
Rise to power.
After Octavian's return to Rome, he and his supporters realised they needed the support of legions. Agrippa helped Octavian to levy troops in Campania. Once Octavian had his legions, he made a pact with Mark Antony and Lepidus, legally established in 43 BC as the Second Triumvirate. Octavian and his consular colleague Quintus Pedius arranged for Caesar's assassins to be prosecuted in their absence, and Agrippa was entrusted with the case against Gaius Cassius Longinus. It may have been in the same year that Agrippa began his political career, holding the position of Tribune of the Plebs, which granted him entry to the Senate.
In 42 BC, Agrippa probably fought alongside Octavian and Antony in the Battle of Philippi. After their return to Rome, he played a major role in Octavian's war against Lucius Antonius and Fulvia Antonia, respectively the brother and wife of Mark Antony, which began in 41 BC and ended in the capture of Perusia in 40 BC. However, Salvidienus remained Octavian's main general at this time. After the Perusine war, Octavian departed for Gaul, leaving Agrippa as urban praetor in Rome with instructions to defend Italy against Sextus Pompeius, an opponent of the Triumvirate who was now occupying Sicily. In July 40, while Agrippa was occupied with the Ludi Apollinares that were the praetor's responsibility, Sextus began a raid in southern Italy. Agrippa advanced on him, forcing him to withdraw. However, the Triumvirate proved unstable, and in August 40 both Sextus and Antony invaded Italy (but not in an organized alliance). Agrippa's success in retaking Sipontum from Antony helped bring an end to the conflict. Agrippa was among the intermediaries through whom Antony and Octavian agreed once more upon peace. During the discussions Octavian learned that Salvidienus had offered to betray him to Antony, with the result that Salvidienus was prosecuted and either executed or committed suicide. Agrippa was now Octavian's leading general.
In 39 or 38 BC, Octavian appointed Agrippa governor of Transalpine Gaul, where in 38 he put down a rising of the Aquitanians. He also fought the Germanic tribes, becoming the next Roman general to cross the Rhine after Julius Caesar. He was summoned back to Rome by Octavian to assume the consulship for 37 BC. He was well below the usual minimum age of 43, but Octavian had suffered a humiliating naval defeat against Sextus Pompey and needed his friend to oversee the preparations for further warfare. Agrippa refused the offer of a triumph for his exploits in Gaul – on the grounds, says Dio, that he thought it improper to celebrate during a time of trouble for Octavian. Since Sextus Pompeius had command of the sea on the coasts of Italy, Agrippa's first care was to provide a safe harbour for his ships. He accomplished this by cutting through the strips of land which separated the Lacus Lucrinus from the sea, thus forming an outer harbour, while joining the lake Avernus to the Lucrinus to serve as an inner harbor. The new harbor-complex was named Portus Julius in Octavian's honour. Agrippa was also responsible for technological improvements, including larger ships and an improved form of grappling hook. About this time, he married Caecilia Pomponia Attica, daughter of Cicero's friend Titus Pomponius Atticus.
In 36 BC, Octavian and Agrippa set sail against Sextus. The fleet was badly damaged by storms and had to withdraw; Agrippa was left in charge of the second attempt. Thanks to superior technology and training, Agrippa and his men won decisive victories at Mylae and Naulochus, destroying all but seventeen of Sextus' ships and compelling most of his forces to surrender. Octavian, with his power increased, forced the triumvir Lepidus into retirement and entered Rome in triumph. Agrippa received the unprecedented honour of a naval crown decorated with the beaks of ships; as Dio remarks, this was "a decoration given to nobody before or since".
Life in public service.
Agrippa participated in smaller military campaigns in 35 and 34 BC, but by the autumn of 34 he had returned to Rome. He rapidly set out on a campaign of public repairs and improvements, including renovation of the aqueduct known as the Aqua Marcia and an extension of its pipes to cover more of the city. Through his actions after being elected in 33 BC as one of the aediles (officials responsible for Rome's buildings and festivals), the streets were repaired and the sewers were cleaned out, while lavish public spectacles were put on. Agrippa signalled his tenure of office by effecting great improvements in the city of Rome, restoring and building aqueducts, enlarging and cleansing the Cloaca Maxima, constructing baths and porticos, and laying out gardens. He also gave a stimulus to the public exhibition of works of art. It was unusual for an ex-consul to hold the lower-ranking position of aedile, but Agrippa's success bore out this break with tradition. As emperor, Augustus would later boast that "he had found the city of brick but left it of marble", thanks in part to the great services provided by Agrippa under his reign.
Antony and Cleopatra.
Agrippa was again called away to take command of the fleet when the war with Antony and Cleopatra broke out. He captured the strategically important city of Methone at the southwest of the Peloponnese, then sailed north, raiding the Greek coast and capturing Corcyra (modern Corfu). Octavian then brought his forces to Corcyra, occupying it as a naval base. Antony drew up his ships and troops at Actium, where Octavian moved to meet him. Agrippa meanwhile defeated Antony's supporter Quintus Nasidius in a naval battle at Patrae. Dio relates that as Agrippa moved to join Octavian near Actium, he encountered Gaius Sosius, one of Antony's lieutenants, who was making a surprise attack on the squadron of Lucius Tarius, a supporter of Octavian. Agrippa's unexpected arrival turned the battle around.
As the decisive battle approached, according to Dio, Octavian received intelligence that Antony and Cleopatra planned to break past his naval blockade and escape. At first he wished to allow the flagships past, arguing that he could overtake them with his lighter vessels and that the other opposing ships would surrender when they saw their leaders' cowardice. Agrippa objected that Antony's ships, although larger, could outrun Octavian's if they hoisted sails, and that Octavian ought to fight now because Antony's fleet had just been struck by storms. Octavian followed his friend's advice.
On September 2, 31 BC, the Battle of Actium was fought. Octavian's victory, which gave him the mastery of Rome and the empire, was mainly due to Agrippa. As a token of signal regard, Octavian bestowed upon him the hand of his niece Claudia Marcella Major in 28 BC. He also served a second consulship with Octavian the same year. In 27 BC, Agrippa held a third consulship with Octavian, and in that year, the senate also bestowed upon Octavian the imperial title of Augustus.
In commemoration of the Battle of Actium, Agrippa built and dedicated the building that served as the Roman Pantheon before its destruction in 80AD. Emperor Hadrian used Agrippa's design to build his own Pantheon, which survives in Rome. The inscription of the later building, which was built around 125, preserves the text of the inscription from Agrippa's building during his third consulship. The years following his third consulship, Agrippa spent in Gaul, reforming the provincial administration and taxation system, along with building an effective road system and aqueducts.
Late life.
Agrippa's friendship with Augustus seems to have been clouded by the jealousy of Augustus' nephew Marcus Claudius Marcellus, which was probably fomented by the intrigues of Livia, the third wife of Augustus, who feared his influence over her husband. Traditionally it is said the result of such jealousy was that Agrippa left Rome, ostensibly to take over the governorship of eastern provinces – a sort of honourable exile, but he only sent his legate to Syria, while he himself remained at Lesbos and governed by proxy, though he may have been on a secret mission to negotiate with the Parthians about the return of the Roman legions standards which they held. On the death of Marcellus, which took place within a year of his exile, he was recalled to Rome by Augustus, who found he could not dispense with his services. However, if one places the events in the context of the crisis in 23 BC it seems unlikely that, when facing significant opposition and about to make a major political climb down, the emperor Augustus would place a man in exile in charge of the largest body of Roman troops. What is far more likely is that Agrippa's 'exile' was actually the careful political positioning of a loyal lieutenant in command of a significant army as a backup plan in case the settlement plans of 23 BC failed and Augustus needed military support. Moreover, after 23 BC as part of what became known as Augustus' "Second Constitutional Settlement", Agrippa's constitutional powers were greatly increased to provide the Principate of Augustus with greater constitutional stability by providing for a political heir or replacement for Augustus if he were to succumb to his habitual ill health or was assassinated. In the course of the year proconsular imperium, similar to Augustus' power, was conferred upon Agrippa for five years. The exact nature of the grant is uncertain but it probably covered Augustus' imperial provinces, east and west, perhaps lacking authority over the provinces of the Senate. That was to come later, as was the jealously guarded tribunicia potestas, or powers of a tribune of the plebeians. These great powers of state are not usually heaped upon a former exile.
It is said that Maecenas advised Augustus to attach Agrippa still more closely to him by making him his son-in-law. He accordingly induced him to divorce Marcella and marry his daughter Julia the Elder by 21 BC, the widow of Marcellus, equally celebrated for her beauty, abilities, and her shameless profligacy. In 19 BC, Agrippa was employed in putting down a rising of the Cantabrians in Hispania (Cantabrian Wars).
In 18 BC, Agrippa's powers were even further increased to almost match those of Augustus. That year his proconsular imperium was augmented to cover the provinces of the Senate. More than that, he was finally granted tribunicia potestas, or powers of a tribune of the plebeians. As was the case with Augustus, Agrippa’s grant of tribunician powers was conferred without his having to actually hold that office. These powers were considerable, giving him veto power over the acts of the Senate or other magistracies, including those of other tribunes, and the power to present laws for approval by the People. Just as important, a tribune’s person was sacrosanct, or sacred, meaning that any person who harmfully touched them or impeded their actions, including political acts, could lawfully be killed. After the grant of these powers Agrippa was, on paper, almost as powerful as Augustus was. However, there was no doubt that Augustus was the man in charge.
Agrippa was appointed governor of the eastern provinces a second time in 17 BC, where his just and prudent administration won him the respect and good-will of the provincials, especially from the Jewish population. Agrippa also restored effective Roman control over the Cimmerian Chersonnese (Crimean Peninsula) during his governorship.
Agrippa’s last public service was his beginning of the conquest of the upper Danube River region, which would become the Roman province of Pannonia in 13 BC. He died at Campania in 12 BC at the age of 51. His posthumous son, Marcus Vipsanius Agrippa Postumus, was named in his honor. Augustus honoured his memory by a magnificent funeral and spent over a month in mourning. Augustus personally oversaw all of Agrippa's children’s educations. Although Agrippa had built a tomb for himself, Augustus had Agrippa's remains placed in Augustus' own mausoleum.
Legacy.
Agrippa was also known as a writer, especially on the subject of geography. Under his supervision, Julius Caesar's dream of having a complete survey of the Empire made was carried out. Agrippa constructed a circular chart, which was later engraved on marble by Augustus, and afterwards placed in the colonnade built by his sister Polla. Amongst his writings, an autobiography, now lost, is referenced.
The term Via Agrippa is used for any part of the network of roadways in Gaul built by Agrippa. Some of these still exist as paths or even as highways.
Marriages and issue.
Agrippa had several children through his three marriages:
Descendants.
Through his numerous children, Agrippa would become ancestor to many subsequent members of the Julio-Claudian dynasty, whose position he helped to attain, as well as many other reputed Romans.
There have been some attempts to assign further descendants to a number of the aforementioned figures, including two lines of Asinii descended from Gaius Asinius Pollio and Marcus Asinius Agrippa respectively. A daughter (and further descendants) named Rubellia Bassa to Julia, who may have been a daughter of Gaius Rubellius Blandus by an earlier marriage. And, finally, a series of descendants from Junia Lepida and her husband, Gaius Cassius Longinus. However, all of these lines of descent are extremely hypothetical and lack any evidence to support a connection to the descendants of Agrippa.
Agrippa in popular culture.
Drama.
Agrippa is a character in William Shakespeare's play "Antony and Cleopatra".
A fictional version of Agrippa in his later life played a prominent role in the 1976 BBC Television series "I, Claudius". Agrippa was portrayed as a much older man, though he would have only been 39 years old at the time of the first episode (24/23 BC). He was played by John Paul.
Agrippa is the main character in Paul Naschy's 1980 film "Los cántabros", played by Naschy himself. It is a highly fictionalized version of the Cantabrian Wars in which Agrippa is depicted as the lover of the sister of Cantabrian leader Corocotta.
Agrippa appears in several film versions of the life of Cleopatra. He is normally portrayed as an old man rather than a young one. Among the people to portray him are Philip Locke, Alan Rowe and Andrew Keir.
Agrippa is also one of the principal characters in the British/Italian joint project "" (2003) featuring flashbacks between Augustus and Julia about Agrippa, which shows him in his youth on serving in Caesar's army up until his victory at Actium and the defeat of Cleopatra. He is portrayed by Ken Duken. In the 2005 series "Empire" the young Agrippa (played by Christopher Egan) becomes Octavian's sidekick after saving him from an attempted poisoning.
Marcus Agrippa, a highly fictional character based on Marcus Vipsanius Agrippa's early life, is part of the BBC-HBO-RAI television series "Rome". He is played by Allen Leech. He describes himself as the grandson of a slave. The series creates a romantic relationship between Agrippa and Octavian's sister Octavia Minor, for which there is no historical evidence.
Literature.
Agrippa is a main character in the early part of Robert Graves novel "I, Claudius". He is a main character in the later two novels of Colleen McCullough's Masters of Rome series. He is a featured character of prominence and importance in the historical fiction novel "Cleopatra's Daughter" by Michelle Moran. He also features prominently in John Edward Williams' historical novel "Augustus". In the backstory of "Gunpowder Empire", the first volume in Harry Turtledove's Crosstime Traffic series, Agrippa lived until AD 26, conquering all of Germania for the Empire and becoming the second Emperor when Augustus died in AD 14.
Video games.
A heavily fictionalized version of Agrippa is one of the playable characters (the other being an equally fictionalized Augustus) in the video game "Shadow of Rome". There, Agrippa is sentenced to become a gladiator after his father was wrongly sentenced for assassinating Caesar. Agrippa's goal is to stay alive as a gladiator for as long as possible, while Augustus acts as an infiltrator who slowly exposes the conspiracy against Caesar. Eventually, Augustus is able to prove Vipsanius' innocence and both of them are pardoned. Then a civil war breaks out, because the direct successor was outraged by exposure of the conspiracy. Agrippa and Augustus fight against Antonius. Agrippa also appears as a Great Admiral in the computer game Sid Meier's Civilization V.

</doc>
<doc id="19757" url="https://en.wikipedia.org/wiki?curid=19757" title="Mariotto Albertinelli">
Mariotto Albertinelli

Mariotto di Bigio di Bindo Albertinelli (October 13, 1474 – November 5, 1515) was a High Renaissance Italian painter of the Florentine school, closely involved with Fra Bartolomeo and influenced by Raphael.
Biography.
Mariotto Albertinelli was born in Florence. As a 12-year-old boy, he became a pupil of Cosimo Rosselli, and a fellow-pupil with Fra Bartolomeo with whom he formed such an intimate brotherly rapport that in 1494 the two started their own studio in Florence. Vasari's opinion was that Mariotto was not so well grounded in drawing as Bartolomeo, and he tells that, to improve his hand he had taken to drawing the antiquities in the Medici garden. He was sponsored by Alfonsina Orsini, the mother of Lorenzo II de' Medici.
When the Medici were temporarily banished in 1494, he returned to his friend, whose manner he copied so assiduously, according to Vasari, that his works were taken for Baccio's. When, in the wake of Savonarola's morality campaign, Baccio joined the Dominican order as Fra Bartolomeo in 1500 and gave up painting, Albertinelli, beside himself with the loss, would have joined him; but, spurred by his success in completing an unfinished "Last Judgment" of Bartolomeo's, he resolved to carry on alone. Among his many students were Jacopo da Pontormo, Innocenzo di Pietro Francucci da Imola and Giuliano Bugiardini.
Mariotto was a most restless person and carnal in the affairs of love and apt to the art of living, and, taking a dislike to the studies and brain-wracking necessary to painting, being also often stung by the tongues of other painters, as is their way, he resolved to give himself to a less laborious and more jovial profession, and so opened the most lovely hostelry outside the Porta San Gallo, and at the sign of the Dragon at the Ponte Vecchio a tavern and inn. This life he led for many months, saying that he had taken up an art that was without muscles, foreshortening or perspective and, better still, without faultfinding, and that the art that he had given up imitated flesh and blood, but this one created flesh and blood; in this if you had good wine you heard yourself praised, but in that every day you were blamed. But at last the low life became an annoyance to him, and, filled with remorse, he returned to painting.
Albertinelli's paintings bear the imprint of Perugino's sense of volumes in space and perspective, Fra Bartolomeo's coloring, the landscape portrayal of Flemish masters like Memling, and Leonardo's Sfumato technique. His chief paintings are in Florence, notably his masterpiece, the "Visitation" (1503) at the Uffizi ("illustrated right").

</doc>
<doc id="19758" url="https://en.wikipedia.org/wiki?curid=19758" title="Beijing cuisine">
Beijing cuisine

Beijing cuisine (), also known as Jing cuisine () or Mandarin cuisine and Peiping cuisine (北平菜) in Taiwan, because that was the city's name during the Republican era of China, is the cuisine of Beijing.
Background.
As Beijing has been the capital of China for centuries, its cuisine is influenced by culinary traditions from all over China, but the style that has the greatest influence on Beijing cuisine is that of the eastern coastal province of Shandong. Beijing cuisine has itself, in turn, also greatly influenced other Chinese cuisines, particularly the cuisine of Liaoning, the Chinese imperial cuisine, and the Chinese aristocrat cuisine.
Another tradition that influenced Beijing cuisine (as well as influenced by the latter itself) is the Chinese imperial cuisine that originated from the "Emperor's Kitchen" (), which referred to the cooking facilities inside the Forbidden City, where thousands of cooks from different parts of China showed their best culinary skills to please the imperial family and officials. Therefore, it is sometimes difficult to determine the actual origin of a dish as the term "Mandarin" is generalised and refers not only to Beijing, but other provinces as well. However, some generalisation of Beijing cuisine can be characterised as follows: Foods that originated in Beijing are often snacks rather than main courses, and they are typically sold by small shops or street vendors. There is emphasis on dark soy paste, sesame paste, sesame oil, and scallions, and fermented tofu is often served as a condiment. In terms of cooking techniques, methods relating to different ways of frying are often used. There is less emphasis on rice as an accompaniment as compared to many other regions in China, as local rice production in Beijing is limited by the relatively dry climate.
Dishes in Beijing cuisine that are served as main courses are mostly from other Chinese cuisines, and some of the following in particular have been central to the formation of Beijing cuisine.
Huaiyang cuisine has been praised since ancient times in China, and it was a general practice for an official travelling to Beijing to take up a new post to bring along with him a chef specialising in Huaiyang cuisine. When these officials had completed their terms in the capital and returned to their native provinces, most of the chefs they brought along often remained in Beijing. They opened their own restaurants or were hired by wealthy locals. The imperial clan of the Ming Dynasty, the House of Zhu, who had ancestry from Jiangsu, also contributed greatly in introducing Huaiyang cuisine to Beijing when the capital was moved from Nanjing to Beijing in the 15th century, because the imperial kitchen was mainly Huaiyang style. The element of traditional Beijing culinary and gastronomical cultures of enjoying artistic performances such as Beijing opera while dining directly developed from the similar practice in the culture of Jiangsu and Huaiyang cuisines. 
Chinese Islamic cuisine is another important component of Beijing cuisine, and was first prominently introduced when Beijing became the capital of the Yuan Dynasty. However, the most significant contribution to the formation of Beijing cuisine came from Shandong cuisine, as most chefs from Shandong came to Beijing en masse during the Qing Dynasty. Unlike the earlier two cuisines, which were brought by the ruling class such as nobles, aristocrats and bureaucrats, and then spread to the general populace, the introduction of Shandong cuisine begun with serving the general populace, with much wider market segment, from wealthy merchants to the working class.
History.
The Qing Dynasty was a major period in the formation of Beijing cuisine. Before the Boxer Rebellion, the foodservice establishments in Beijing were strictly stratified by the foodservice guild. Each category of the establishment was specifically based on its ability to provide for a particular segment of the market. The top ranking foodservice establishments served nobles, aristocrats, and wealthy merchants and landlords, while lower ranking foodservice establishments served the populace of lower financial and social status. It was during this period when Beijing cuisine gained fame and became recognised by the Chinese culinary society, and the stratification of the foodservice was one of its most obvious characteristics as part of its culinary and gastronomic cultures during this first peak of its formation.
The official stratification was an integral part of the local culture of Beijing and it was not finally abolished officially after the end of the Qing Dynasty, which resulted in the second peak in the formation of Beijing cuisine. Meals previously offered to nobles and aristocrats was made available to anyone who can afford them instead of being restricted only to the upper class. As chefs freely switched between jobs offered by different foodservice establishments, they brought their skills that further enriched and developed Beijing cuisine. Though the stratification of food services in Beijing was no longer effected by imperial laws, the structure more or less remained despite continuous weakening due to the financial background of the local clientele. The different classes are listed in the following subsections.
Zhuang.
Foodservice establishments with names ending with the Chinese character "zhuang" (), or "zhuang zihao" (), were the top-ranking foodservice establishments, not only in providing foods, but entertainment as well. The form of entertainment provided was usually Beijing opera, and foodservice establishments of this class always had long-term contracts with a Beijing opera troupe to perform onsite. Moreover, foodservice establishments of this class would always have long-term contracts with famous performers (such as national-treasure-class performers) to perform onsite, though not on a daily basis. Foodservice establishments of this category did not accept any different customers on a walk-in basis, but instead, only accepted customers who came as a group and ordered banquets by appointment, and the banquets provided by foodservice establishments of this category often included most, if not all tables, at the site. The bulk of the business of foodservice of this category, however, was catering at customers’ homes or other locations, and such catering was often for birthdays, marriages, funerals, promotions and other important celebrations and festivals. When catering, these foodservice establishments not only provided what was on the menu, but fulfilled customers’ requests.
Foodservice establishments categorised as "leng zhuangzi" () lacked any rooms to host banquets, and thus their business was purely catering.
Tang.
Foodservice establishments with names ending with the Chinese character "tang" (), or "tang zihao" (), are similar to foodservice establishments with names ending with the Chinese character "zhuang", but the business of these second-class foodservice establishments were generally evenly divided among onsite banquet hosting and catering (at customers’ homes). Foodservice establishments of this class would also have long-term contracts with Beijing opera troupes to perform onsite, but they did not have long-term contracts with famous performers (such as national-treasure-class performers) to perform onsite on regular basis; however these top performers would still perform at foodservice establishments of this category occasionally. In terms of catering at the customers’ sites, foodservice establishments of this category often only provided dishes strictly according to their menu, and would not provide any dishes that were not on the menu.
Ting.
Foodservice establishments with names ending with the Chinese character "ting" (), or "ting zihao" () are foodservice establishments which had more business in onsite banquet hosting than catering at customers’ homes. For onsite banquet hosting, entertainment was still provided, but foodservice establishments of this category did not have long-term contracts with Beijing opera troupes, so that performers varied from time to time, and top performers usually did not perform here or at any lower-ranking foodservice establishments. For catering, different foodservice establishments of this category were incapable of handling significant catering on their own, but generally had to combine resources with other foodservice establishments of the same ranking (or lower) to do the job.
Yuan.
Foodservice establishments with names ending with the Chinese character "yuan" (), or "yuan zihao" () did nearly all their business in hosting banquets onsite. Entertainment was not provided on a regular basis, but there were stages built onsite for Beijing opera performers. Instead of being hired by the foodservice establishments like in the previous three categories, performers at foodservice establishments of this category were usually contractors who paid the foodservice establishment to perform and split the earnings according to a certain percentage. Occasionally, foodservice establishments of this category would be called upon to help cater at customers’ homes, and like foodservice establishments with names ending with the Chinese character "ting", they could not do the job on their own but had to work with others, never taking the lead as foodservice establishments with names ending with the Chinese character "ting" could.
Lou.
Foodservice establishments with names ending with the Chinese character "lou" (), or "lou zihao" () did the bulk of their business hosting banquets onsite by appointment. In addition, a smaller portion of the business was in serving different customers onsite on a walk-in basis. Occasionally, when catering at customers’ homes, foodservice establishments of this category would only provide the few specialty dishes they were famous for.
Ju.
Foodservice establishments with names ending with the Chinese character "ju" (), or "ju zihao" () generally divided their business evenly into two areas: serving different customers onsite on a walk-in basis, and hosting banquets by appointment for customers who came as one group. Occasionally, when catering at the customers’ homes, foodservice establishments of this category would only provide the few specialty dishes they were famous for, just like foodservice establishments with names ending with the Chinese character "lou". However, unlike those establishments, which always cooked their specialty dishes on location, foodservice establishment of this category would either cook on location or simply bring the already-cooked food to the location.
Zhai.
Foodservice establishments with names ending with the Chinese character "zhai" (), or "zhai zihao" () were mainly in the business of serving different customers onsite on a walk-in basis, but a small portion of their income did come from hosting banquets by appointment for customers who came as one group. Just like foodservice establishments with names ending with the Chinese character "ju", when catering at customers’ homes, foodservice establishments of this category would also only provide the few specialty dishes they are famous for, but they would mostly bring the already-cooked dishes to the location, and would only cook on location occasionally.
Fang.
Foodservice establishments with names ending with the Chinese character "fang" (), or "fang zihao" (). Foodservice establishments of this category generally did not offer the service of hosting banquets made by appointment for customers who came as one group, but instead, often only offered to serve different customers onsite on a walk-in basis. Foodservice establishments of this category or lower would not be called upon to perform catering at the customers’ homes for special events.
Guan.
Foodservice establishments with names ending with the Chinese character "guan" (), or "guan zihao" (). Foodservice establishments of this category mainly served different customers onsite on a walk-in basis, and in addition, a portion of the income would be earned from selling to-goes.
Dian.
Foodservice establishments with names ending with the Chinese character "dian" (), or "dian zihao" (). Foodservice establishments of this category had their own place, like all previous categories, but serving different customers to dine onsite on a walk-in basis only provided half of the overall income, while the other half came from selling to-goes.
Pu.
Foodservice establishments with name ending with the Chinese character "pu" (), or "pu zihao" (). Foodservice establishments of this category ranked next to the last, and they were often named after the owners' last names. Foodservice establishments of this category had fixed spots of business for having their own places, but not as large as those belonging to the category of "dian", and thus did not have tables, but only seats for customers. As a result, the bulk of the income of foodservice establishments of this category was from selling to-goes, while income earned from customers dining onsite only provided a small portion of the overall income.
Tan.
Foodservice establishments with names ending with the Chinese character "tan" (), or "tan zihao" (). The lowest ranking foodservice establishments without any tables, and selling to-goes was the only form of business. In addition to name the food stand after the owners’ last name or the food sold, these food stands were also often named after the owners’ nicknames.
Restaurants known for Beijing cuisine.
Numerous traditional restaurants in Beijing are credited with great contributions in the formation of Beijing cuisine, but many of them have gone out of business as time went by. However, some of them managed to survive until today, and some of them are:

</doc>
<doc id="19760" url="https://en.wikipedia.org/wiki?curid=19760" title="Manichaeism">
Manichaeism

Manichaeism (;
in Modern Persian "Āyin e Māni"; ) was a major religion that was founded by the Iranian prophet Mani (in Persian: مانی, Syriac: ܡܐܢܝ
, Latin: Manichaeus or Manes; 216–276 AD) in the Sasanian Empire.
Manichaeism taught an elaborate dualistic cosmology describing the struggle between a good, spiritual world of light, and an evil, material world of darkness. Through an ongoing process which takes place in human history, light is gradually removed from the world of matter and returned to the world of light whence it came. Its beliefs were based on local Mesopotamian gnostic and religious movements.
Manichaeism was quickly successful and spread far through the Aramaic-Syriac speaking regions. It thrived between the third and seventh centuries, and at its height was one of the most widespread religions in the world. Manichaean churches and scriptures existed as far east as China and as far west as the Roman Empire. It was briefly the main rival to Christianity in the competition to replace classical paganism. Manichaeism survived longer in the east than in the west, and it appears to have finally faded away after the 14th century in southern China contemporary to the decline in China of the Church of the East during the Ming Dynasty. While most of Manichaeism's original writings have been lost, numerous translations and fragmentary texts have survived.
An adherent of Manichaeism is called, especially in older sources, a "Manichee, "or more recently "Manichaean." By extension, the term "manichean" is widely applied (often used as a derogatory term) as an adjective to a philosophy of moral dualism, according to which a moral course of action involves a clear (or simplistic) choice between good and evil, or as a noun to people who hold such a view.
History.
Life of Mani.
Mani, an Arsacid Persian by birth, was born 216 AD in Mesopotamia (Iraq), which was ruled by Persia, then within the Sassanid Empire province of Asuristan. According to the Cologne Mani-Codex, Mani's parents were members of the religious sect of Elcesaites.
Mani composed seven writings, six of which were written in Syriac Aramaic. The seventh, the Shabuhragan, was written by Mani in Middle Persian and presented by him to the contemporary King of Sassanid Persia, Shapur I, in the Persian capital of Ctesiphon. Although there is no proof Shapur I was a Manichaean, he tolerated the spread of Manichaeism and refrained from persecuting it in his empire's boundaries. According to one tradition it was Mani himself who invented the unique version of the Syriac script called Manichaean script, which was used in all of the Manichaean works written within the Persian Empire, whether they were in Syriac or Middle Persian, and also for most of the works written within the Uyghur Empire. The primary language of Babylon (and the administrative and cultural language of the Sassanid Empire) at that time was Eastern Middle Aramaic, which included three main dialects: Judeo-Aramaic (the language of the Talmud), Mandaean Aramaic (the language of the Mandaean religion), and Syriac Aramaic, which was the language of Mani, as well as of the Syriac Christians.
While Manichaeism was spreading, existing religions such as Zoroastrianism were still popular and Christianity was gaining social and political influence. Although having fewer adherents, Manichaeism won the support of many high-ranking political figures. With the assistance of the Persian Empire, Mani began missionary expeditions. After failing to win the favour of the next generation of Persian royalty, and incurring the disapproval of the Zoroastrian clergy, Mani is reported to have died in prison awaiting execution by the Persian Emperor Bahram I. The date of his death is estimated at AD 276–277.
Influences.
Mani believed that the teachings of Buddha, Zoroaster, and Jesus were incomplete, and that his revelations were for the entire world, calling his teachings the "Religion of Light." Manichaean writings indicate that Mani received revelations when he was 12 and again when he was 24, and over this time period he grew dissatisfied with the Elcesaite sect he was born into. Mani began preaching at an early age and was possibly influenced by contemporary Babylonian-Aramaic movements such as Mandaeanism, and Aramaic translations of Jewish apocalyptic writings similar to those found at Qumran (such as the book of Enoch literature), and by the Syriac dualist-gnostic writer Bardaisan (who lived a generation before Mani). With the discovery of the Mani-Codex, it also became clear that he was raised in a Jewish-Christian baptism sect, the Elcesaites, and was influenced by their writings as well. According to biographies preserved by Ibn al-Nadim and the Persian polymath al-Biruni, he allegedly received a revelation as a youth from a spirit, whom he would later call his "Twin" (Aramaic "Tauma" (תאומא), from which is also derived the name of the apostle Thomas, the "twin"), his "Syzygos" (Greek for "partner", in the Cologne Mani-Codex), his Double, his Protective Angel or "Divine Self". It taught him truths which he developed into a religion. His "divine" Twin or true Self brought Mani to self-realization. He claimed to be the "Paraclete of the Truth", as promised in the New Testament.
Manichaeism's views on Jesus are described by historians:
Historians also note that Mani declared himself to be an "apostle of Jesus Christ" Manichaean tradition is also noted to have claimed that Mani was the reincarnation of different religious figures from Buddha, Krishna, Zoroaster, and Jesus.
Academics also note that since much of what is known about Manichaeism comes from later 10th and 11th Century AD Islamic historians like Al-Biruni and especially the Shia Muslim Persian historian Ibn al-Nadim (and his work Fihrist), "Islamic authors ascribed to Mani the claim to be the Seal of the Prophets." This topic is discussed by an Israeli academic, Guy G. Stroumsa.
Another source of Mani's scriptures was original Aramaic writings relating to the book of Enoch literature (see the Book of Enoch and the Second Book of Enoch), as well as an otherwise unknown section of the book of Enoch called the "Book of Giants". This book was quoted directly, and expanded on by Mani, becoming one of the original six Syriac writings of the Manichaean Church. Besides brief references by non-Manichaean authors through the centuries, no original sources of "The Book of Giants" (which is actually part six of the "Book of Enoch") were available until the 20th century.
Scattered fragments of both the original Aramaic "Book of Giants" (which were analyzed and published by Józef Milik in 1976) and of the Manichaean version of the same name (analyzed and published by W.B. Henning in 1943) were found with the discovery in the twentieth century of the Dead Sea Scrolls in the Judaean Desert and the Manichaean writings of the Uyghur Manichaean kingdom in Turpan. Henning wrote in his analysis of them:
From a careful reading of the Enoch literature and the Book of Giants, alongside the description of the Manichaean myth, it becomes clear that the "Great King of Honor" of this myth (a being that sits as a guard to the world of light at the seventh of ten heavens in the Manichaean myth,) is identical with the King of Honor sitting on the heavenly throne in the Enoch literature. In the Aramaic book of Enoch, in the Qumran writings in general, and in the original Syriac section of Manichaean scriptures quoted by Theodore bar Konai, he is called "malka raba de-ikara" (the great king of honor).
Mani was also influenced by writings of the Assyrian gnostic Bardaisan (154–222), who like Mani, wrote in Syriac, and presented a dualistic interpretation of the world in terms of light and darkness, in combination with elements from Christianity.
Noting Mani's travels to the Kushan Empire (several religious paintings in Bamiyan are attributed to him) at the beginning of his proselytizing career, Richard Foltz postulates Buddhist influences in Manichaeism:
The Kushan monk Lokakṣema began translating Pure Land Buddhist texts into Chinese in the century prior to Mani arriving there, and the Chinese texts of Manichaeism are full of uniquely Buddhist terms taken directly from these Chinese Pure Land scriptures, including the term "Pure land" (淨土 Jìngtǔ) itself. However, the central object of veneration in Pure Land Buddhism, Amitābha, the Buddha of Infinite Light, does not appear in Chinese Manichaeism, and seems to have been replaced by another deity.
Spread.
Manichaeism spread with extraordinary speed through both the east and west. It reached Rome through the apostle Psattiq by 280, who was also in Egypt in 244 and 251. It was flourishing in the Fayum area of Egypt in 290. Manichaean monasteries existed in Rome in 312 during the time of the Christian Pope Miltiades.
In 291, persecution arose in the Persian empire with the murder of the apostle Sisin by Bahram II, and the slaughter of many Manichaeans. In 296, Diocletian decreed against the Manichaeans: "We order that their organizers and leaders be subject to the final penalties and condemned to the fire with their abominable scriptures", resulting in martyrdom for many in Egypt and North Africa (see "Diocletian Persecution"). By 354, Hilary of Poitiers wrote that the Manichaean faith was a significant force in southern Gaul. In 381 Christians requested Theodosius I to strip Manichaeans of their civil rights. He issued a decree of death for Manichaean monks in 382.
Augustine of Hippo (354–430) converted to Christianity from Manichaeism, in the year 387. This was shortly after the Roman Emperor Theodosius I had issued a decree of death for all Manichaean monks in 382 and shortly before he declared Christianity to be the only legitimate religion for the Roman Empire in 391. Due to the heavy persecution, the religion almost disappeared from western Europe in the 5th century and from the eastern portion of the empire in the 6th century. According to his "Confessions," after nine or ten years of adhering to the Manichaean faith as a member of the group of "hearers", Augustine became a Christian and a potent adversary of Manichaeism (which he expressed in writing against his Manichaean opponent Faustus of Mileve), seeing their beliefs that knowledge was the key to salvation as too passive and not able to effect any change in one's life.
I still thought that it is not we who sin but some other nature that sins within us. It flattered my pride to think that I incurred no guilt and, when I did wrong, not to confess it... I preferred to excuse myself and blame this unknown thing which was in me but was not part of me. The truth, of course, was that it was all my own self, and my own impiety had divided me against myself. My sin was all the more incurable because I did not think myself a sinner. ("Confessions, Book V, Section 10")
Some modern scholars have suggested that Manichaean ways of thinking influenced the development of some of Augustine's ideas, such as the nature of good and evil, the idea of hell, the separation of groups into elect, hearers, and sinners, and the hostility to the flesh and sexual activity.
How Manichaeism may have influenced Christianity continues to be debated. Manichaeism may have influenced the Bogomils, Paulicians, and Cathars. However, these groups left few records, and the link between them and Manichaeans is tenuous. Regardless of its accuracy the charge of Manichaeism was levelled at them by contemporary orthodox opponents, who often tried to make contemporary heresies conform to those combatted by the church fathers. Whether the dualism of the Paulicians, Bogomils, and Cathars and their belief that the world was created by a Satanic demiurge were due to influence from Manichaeism is impossible to determine. The Cathars apparently adopted the Manichaean principles of church organization. Priscillian and his followers may also have been influenced by Manichaeism. The Manichaeans preserved many apocryphal Christian works, such as the Acts of Thomas, that would otherwise have been lost.
Manichaeism maintained a sporadic and intermittent existence in the west (Mesopotamia, Africa, Spain, France, North Italy, the Balkans) for a thousand years, and flourished for a time in Persia and even further east in Northern India, Western China, and Tibet. While it had long been thought that Manichaeism arrived in China only at the end of the seventh century, a recent archaeological discovery demonstrated that it was already known there in the second half of the 6th century.
Some Sogdians in Central Asia believed in the religion. Uyghur ruler Khagan Boku Tekin (759–780) converted to the religion in 763 after a 3 days discussion with its preachers, the Babylonian headquarters sent high rank clerics to Uyghur, and Manichaeism remained the state religion for about a century before the collapse of the Uyghur empire in 840. In the east it spread along trade routes as far as Chang'an, the capital of the Tang dynasty in China. After the Tang Dynasty, some Manichaens groups participated in peasant movements. The religion was used by many rebel leaders to mobilise followers. In the Song and Yuan dynasties of China remnants of Manichaeism continued to leave a legacy contributing to sects such as the Red Turbans. During the Song Dynasty, the Manichaeans were derogatorily referred by the Chinese as "chicai simo" (meaning that they "abstain from meat and worship demons"). An account in "Fozu Tongji", an important historiography of Buddhism in China compiled by Buddhist scholars during 1258-1269, says that the Manichaens worshipped the "white Buddha" and their leader wore a violet headgear, while the followers wore white costumes. Many Manichaeans took part in rebellions against the Song government and were eventually quelled. After that, all governments were suppressive against Manichaeism and its followers and the religion was banned by the Ming Dynasty in 1370.
The Manichaeans tried to assimilate their religion along with Islam in the Arab Islamic empires. Relatively little is known about the religion during the first century of Islamic rule. During the early period of the Arab Islamic empire, Manichaeism attracted many followers. It had a significant appeal among the Muslim society especially among the elites. Due to the appeal of its teachings, many Muslims adopted the ideas of its theology and some even became dualists. Ibn al-Muqaffa' wrote an apologia for Manichaeism, defending its phantasmagorical cosmogony and attacking the fideism of Islam and other monotheistic religions. According to some accounts, even the Umayyad caliph Al-Walid II was a follower of Mani. The Manichaeans had sufficient structure to have a head of their community. Under the 8th-century Abbasids, Arabic "zindiq" and the adjectival "zandaqa" could denote many different things, though it seems primarily (or at least initially) to have signified a follower of Manichaeism however its true meaning is not known. In the ninth century, it is reported that the Muslim Caliph Al-Ma'mun tolerated a community of Manichaeans. During the early period of Abbasids, the Manichaeans underwent persecution. The third Abbasid caliph al-Mahdi persecuted the Manichaeans, establishing an inquisition against dualists who if being found guilty of heresy refused to renounce their beliefs, were executed. Their persecution was finally ended in 780s by Harun al-Rashid. During the reign of the Caliph Al-Muqtadir, many Manichaeans fled from Mesopotamia to Khorasan from fear of persecution and the base of the religion was later shifted to Samarkand.
Manichaeism claimed to present the complete version of teachings that were corrupted and misinterpreted by the followers of its predecessors Adam, Zoroaster, Buddha and Jesus. Accordingly, as it spread, it adapted new deities from other religions into forms it could use for its scriptures. Its original Aramaic texts already contained stories of Jesus. When they moved eastward and were translated into Iranian languages, the names of the Manichaean deities (or angels) were often transformed into the names of Zoroastrian yazatas. Thus "Abbā dəRabbūṯā " ("The Father of Greatness", the highest Manichaean deity of Light), in Middle Persian texts might either be translated literally as "pīd ī wuzurgīh", or substituted with the name of the deity "Zurwān". Similarly, the Manichaean primal figure "Nāšā Qaḏmāyā " "The Original Man" was rendered "Ohrmazd Bay", after the Zoroastrian god Ohrmazd. This process continued in Manichaeism's meeting with Chinese Buddhism, where, for example, the original Aramaic "karia" (the "call" from the world of Light to those seeking rescue from the world of Darkness), becomes identified in the Chinese scriptures with Guan Yin ( or Avalokitesvara in Sanskrit, literally, "watching/perceiving sounds the world", the Chinese Bodhisattva of Compassion).
Persecution and extinction.
Manichaeism was repressed in Persia by the Sassanids. In 291, persecution arose in the Persian empire with the murder of the apostle Sisin by Bahram II, and the slaughter of many Manichaeans. In AD 296, the Roman emperor Diocletian decreed all the Manichaean leaders to be burnt alive along with the Manichaean scriptures and many Manichaeans in Europe and North Africa were killed. This policy of persecution was also followed by his successors. Theodosius I issued a decree of death for all Manichaean monks in 382 AD. The religion was vigorously attacked and persecuted by both the Christian Church and the Roman state. Due to the heavy persecution upon its followers in the Roman Empire, the religion almost disappeared from western Europe in the 5th century and from the eastern portion of the empire in the 6th century.
In 732, Emperor Xuanzong of Tang banned any Chinese from converting to the religion saying it was a heretic religion that was confusing people by claiming to be Buddhism. However the foreigners who followed the religion were allowed to practice it without punishment. After the fall of the Uyghur Khaganate in 840 which was the chief patron of Manichaeism (which was also the state religion of the Khaganate) in China, all Manichaean temples in China except in the two capitals and Taiyuan were closed down and never reopened since these temples were viewed as a symbol of foreign arrogance by the Chinese. Even those that were allowed to remain open did not for long. The Manichaean temples were attacked by Chinese people who burned the images and idols of these temples. The Manichaean priests were ordered to wear Chinese dress. In 843, Emperor Wuzong of Tang gave the order to kill all Manichaean clerics as part of his campaign against Buddhism and other religions, and over half died. They were made to look like Buddhists by the authorities, their heads were shaved, they were made to dress like Buddhist monks and then killed. Although the religion was mostly forbidden and its followers persecuted thereafter in China, it survived till the 14th century in the country. Under the Song dynasty, its followers were derogatorily called by the Chinese people and the authorities as "chicai simo" (meaning that they "abstain from meat and worship demons"). Many of the followers of the religion took part in rebellions against the Song dynasty. They were quelled by the Songs and were suppressed and persecuted by all successive governments before the Mongol Yuan dynasty. In 1370, the religion was banned through an edict of the Ming dynasty, whose founding emperor had a personal dislike for the religion. The religion survived in East Turkestan (a region controlled by Uyghur Khaganate before its fall in 840) until the Mongol invasion in the 13th century.
The Manicheans also suffered persecution for some time under the Abbasids. In 780, the third Abbasid Caliph, Al-Mahdi started a campaign of inquisition against those who were "dualist heretics" or "Manichaeans" called the "Zindīq". He appointed a "master of the heretics" (Sahib-az-Zanadiqa), an official whose task was to pursue and investigate suspected dualists, who were then examined by the caliph. Those found guilty who refused to abjure their beliefs were executed. This persecution continued under his successor Caliph al-Hadi as well. It continued for some time during reign of Harun al-Rashid who abolished it and ended it. During the reign of the 18th Abbassid Caliph Al-Muqtadir, many Manichaeans fled from Mesopotamia to Khorasan from fear of persecution by him and about 500 of them assembled in Samarkand. The base of the religion was later shifted to this city.
Later movements accused of "Neo-Manichaeism".
During the Middle Ages, several movements emerged which were collectively described as "Manichaean" by the Catholic Church, and persecuted as Christian heresies through the establishment, in 1184, of the Inquisition. They included the Cathar churches of Western Europe. Other groups sometimes referred to as "neo-Manichaean" were the Paulician movement, which arose in Armenia, and the Bogomils in Bulgaria. An example of this usage can be found in the published edition of the Latin Cathar text, the "Liber de duobus principiis" ("Book of the Two Principles"), which was described as "Neo-Manichaean" by its publishers. As there is no presence of Manichaean mythology or church terminology in the writings of these groups, there has been some dispute among historians as to whether these groups were descendants of Manichaeism.
Present day.
Some sites are preserved in Xinjiang and Fujian in China. The Cao'an temple is the only fully intact Manichaean building, though it later became associated with Buddhism. Several small groups claim to continue to practice this faith.
Teachings and beliefs.
General.
Mani's teaching dealt with the origin of evil, by addressing a theoretical part of the problem of evil by denying the omnipotence of God and postulating two opposite powers. Manichaean theology taught a dualistic view of good and evil. A key belief in Manichaeism is that the powerful, though not omnipotent good power (God) was opposed by the semi-eternal evil power (Satan). Humanity, the world and the soul are seen as the byproduct of the battle between God's proxy, Primal Man, and Satan. The human person is seen as a battleground for these powers: the soul defines the person, but it is under the influence of both light and dark. This contention plays out over the world as well as the human body—neither the Earth nor the flesh were seen as intrinsically evil, but rather possessed portions of both light and dark. Natural phenomena (such as rain) were seen as the physical manifestation of this spiritual contention. Therefore, the Manichaean worldview explained the existence of evil with a flawed creation which God took no role in forming but rather was the result of Satan striking out against God.
Cosmogony.
Manichaeism presented an elaborate description of the conflict between the spiritual world of light and the material world of darkness. The beings of both the world of darkness and the world of light have names. There are numerous sources for the details of the Manichaean belief. There are two portions of Manichaean scriptures that are probably the closest thing to the original Manichaean writings in their original languages that will ever be available. These are the Syriac-Aramaic quotation by the Nestorian Christian Theodore bar Konai, in his Syriac "Book of Scholia" (""Ketba de-Skolion"", eighth century), and the Middle Persian sections of Mani's Shabuhragan discovered at Turpan (a summary of Mani's teachings prepared for Shapur I). These two sections are probably the original Syriac and Middle Persian written by Mani.
From these and other sources, it is possible to derive an almost complete description of the detailed Manichaean vision (a complete list of Manichaean deities is outlined below). According to Mani, the unfolding of the universe takes place with three "creations":
The First Creation: Originally, good and evil existed in two completely separate realms, one the "World of Light", ruled by the "Father of Greatness" together with his five "Shekhinas" (divine attributes of light), and the other the "World of Darkness", ruled by the "King of Darkness". At a certain point, the "Kingdom of Darkness" notices the "World of Light", becomes greedy for it and attacks it. The "Father of Greatness", in the first of three "creations" (or "calls"), calls to the "Mother of Life", who sends her son "Original Man" ("Nāšā Qaḏmāyā" in Aramaic), to battle with the attacking powers of Darkness, which include the "Demon of Greed". The "Original Man" is armed with five different shields of light (reflections of the five "Shekhinas"), which he loses to the forces of darkness in the ensuing battle, described as a kind of "bait" to trick the forces of darkness, as the forces of darkness greedily consume as much light as they can. When the "Original Man" comes to, he is trapped among the forces of darkness.
The Second Creation: Then the "Father of Greatness" begins the "Second Creation", calling to the "Living Spirit", who calls to his five sons, and sends a call to the "Original Man" ("Call" then becomes a Manichaean deity). An answer ("Answer" becomes another Manichaean deity) then returns from the "Original Man" to the "World of Light". The "Mother of Life", the "Living Spirit", and his five sons begin to create the universe from the bodies of the evil beings of the "World of Darkness", together with the light that they have swallowed. Ten heavens and eight earths are created, all consisting of various mixtures of the evil material beings from the "World of Darkness" and the swallowed light. The sun, moon, and stars are all created from light recovered from the "World of Darkness". The waxing and waning of the moon is described as the moon filling with light, which passes to the sun, then through the Milky Way, and eventually back to the "World of Light".
The Third Creation: Great demons (called "archons" in bar-Khonai's account) are hung out over the heavens, and then the "Father of Greatness" begins the "Third Creation". Light is recovered from out of the material bodies of the male and female evil beings and demons, by causing them to become sexually aroused in greed, towards beautiful images of the beings of light, such as the "Third Messenger" and the "Virgins of Light". However, as soon as the light is expelled from their bodies and falls to the earth (some in the form of abortions – the source of fallen angels in the Manichaean myth), the evil beings continue to swallow up as much of it as they can to keep the light inside of them. This results eventually in the evil beings swallowing huge quantities of light, copulating, and producing Adam and Eve. The "Father of Greatness" then sends the "Radiant Jesus" to awaken Adam, and to enlighten him to the true source of the light that is trapped in his material body. Adam and Eve, however, eventually copulate, and produce more human beings, trapping the light in bodies of mankind throughout human history. The appearance of the Prophet Mani was another attempt by the "World of Light" to reveal to mankind the true source of the spiritual light imprisoned within their material bodies.
Outline of the beings and events in the Manichaean mythos.
Beginning with the time of its creation by Mani, the Manichaean religion had a detailed description of deities and events that took place within the Manichaean scheme of the universe. In every language and region that Manichaeism spread to, these same deities reappear, whether it is in the original Syriac quoted by Theodore bar Konai, or the Latin terminology given by Saint Augustine from Mani's "Epistola Fundamenti", or the Persian and Chinese translations found as Manichaeism spread eastward. While the original Syriac retained the original description which Mani created, the transformation of the deities through other languages and cultures produced incarnations of the deities not implied in the original Syriac writings. This process began in Mani's lifetime, with "The Father of Greatness", for example, being translated into Middle Persian as Zurvan, a Zoroastrian supreme being.
Organization and religious practices.
Organization of the Manichaean Church.
The Manichaean Church was divided into "Elect" – those who had taken upon themselves the vows of Manicheaism, and "Hearers" – those who had not, but still participated in the Church. The terms for these divisions were already common since the days of early Christianity. In the Chinese writings, the Middle Persian and Parthian terms are transcribed phonetically (instead of being translated into Chinese).
The Bema Fest.
The most important religious observance of the Manichaeans was the Bema Fest, observed annually:
The Bema was originally, in the Syriac Christian churches, a seat placed in the middle of the nave on which the bishop would preside and from which the Gospel would be read. In the Manichaean places of worship, the throne was a five-stepped altar, covered by precious cloths, symbolizing the five classes of the hierarchy. The top of the Bema was always empty, as it was the seat of Mani. The Bema was celebrated at the vernal equinox, was preceded by fasts, and symbolized the passion of Mani, thus it was strictly parallel to the Christian Easter.
While it is often presumed that the Bema seat was empty, there is some evidence from the Coptic Manichaean "Bema Psalms", that the Bema seat may have actually contained a copy of Mani's picture book, the Arzhang.
Primary sources.
Mani wrote either seven or eight books, which contained the teachings of the religion. Only scattered fragments and translations of the originals remain.
The original six Syriac writings are not preserved, although their Syriac names have been. There are also fragments and quotations from them. A long quotation, preserved by the eighth-century Nestorian Christian author Theodore bar Konai, shows that in the original Syriac Aramaic writings of Mani there was no influence of Iranian or Zoroastrian terms. The terms for the Manichaean deities in the original Syriac writings are in Aramaic. The adaptation of Manichaeism to the Zoroastrian religion appears to have begun in Mani's lifetime however, with his writing of the Middle Persian Shabuhragan, his book dedicated to the King Shapuhr. In it, there are mentions of Zoroastrian deities such as Ohrmazd, Ahriman, and Az. Manichaeism is often presented as a Persian religion, mostly due to the vast number of Middle Persian, Parthian, and Soghdian (as well as Turkish) texts discovered by German researchers near Turpan, in the Xinjiang (Chinese Turkestan) province of China, during the early 1900s. However, from the vantage point of its original Syriac descriptions (as quoted by Theodore bar Khonai and outlined above), Manichaeism may be better described as a unique phenomenon of Aramaic Babylonia, occurring in proximity to two other new Aramaic religious phenomena, Talmudic Judaism and Babylonian Mandaeism, which were also appearing in Babylonia in roughly the third century AD.
The original, but now lost, six sacred books of Manichaeism were composed in Syriac Aramaic, and translated into other languages to help spread the religion. As they spread to the east, the Manichaean writings passed through Middle Persian, Parthian, Sogdian, Tocharian and ultimately Uyghur and Chinese translations. As they spread to the west, they were translated into Greek, Coptic, and Latin.
Henning describes how this translation process evolved and influenced the Manichaeans of Central Asia:
Beyond doubt, Sogdian was the national language of the Majority of clerics and propagandists of the Manichaean faith in Central Asia. Middle Persian (= Pārsīg), and to a lesser degree, Parthian (= Pahlavānīg), occupied the position held by Latin in the medieval church. The founder of Manichaeism had employed Syriac (his own language) as his medium, but conveniently he had written at least one book in Middle Persian, and it is likely that he himself had arranged for the translation of some or all of his numerous writings from Syriac into Middle Persian. Thus the Eastern Manichaeans found themselves entitled to dispense with the study of Mani’s original writings, and to continue themselves to reading the Middle Persian edition; it presented small difficulty to them to acquire a good knowledge of the Middle Persian language, owing to its affinity with Sogdian.
Later works.
In later centuries, as Manichaeism passed through eastern Persian speaking lands and arrived at the Uyghur Empire (回鹘帝国), and eventually the Uyghur kingdom of Turpan (destroyed around 1335), Middle Persian and Parthian prayers ("āfrīwan" or "āfurišn") and the Parthian hymn-cycles (the "Huwīdagmān" and "Angad Rōšnan" created by Mar Ammo) were added to the Manichaean writings. A translation of a collection of these produced the Manichaean Chinese Hymnscroll (the 摩尼教下部贊, which Lieu translates as "Hymns for the Lower Section the Hearers of the Manichaean Religion"). In addition to containing hymns attributed to Mani, it contains prayers attributed to Mani's earliest disciples, including Mār Zaku, Mār Ammo and Mār Sīsin. Another Chinese work is a complete translation of the "Sermon of the Light Nous", presented as a discussion between Mani and his disciple Adda.
Critical and polemic sources.
Until discoveries in the 1900s of original sources, the only sources for Manichaeism were descriptions and quotations from non-Manichaean authors, either Christian, Muslim, Buddhist or Zoroastrian. While often criticizing Manichaeism, they also quoted directly from Manichaean scriptures. This enabled Isaac de Beausobre, writing in the 18th century, to create a comprehensive work on Manichaeism, relying solely on anti-Manichaean sources. Thus quotations and descriptions in Greek and Arabic have long been known to scholars, as have the long quotations in Latin by Saint Augustine, and the extremely important quotation in Syriac by Theodore bar Khonai.
Patristic depictions of Mani and Manchæeism.
Eusebius commented as follows:
Acta Archelai.
An example of how inaccurate some of these accounts could be is seen in the account of the origins of Manichaeism contained in the "Acta Archelai". This was a Greek anti-manichaean work written before 348, most well known in its Latin version, which was regarded as an accurate account of Manichaeism until the end of the 19th century:
In the time of the Apostles there lived a man named Scythianus, who is described as coming 'from Scythia,' and also as being 'a Saracen by race' ('ex genere Saracenorum'). He settled in Egypt, where he became acquainted with 'the wisdom of the Egyptians,' and invented the religious system which was afterwards known as Manichaeism. Finally he emigrated to Palestine, and, when he died, his writings passed into the hands of his sole disciple, a certain Terebinthus. The latter betook himself to Babylonia, assumed the name of Budda, and endeavoured to propagate his master's teaching. But he, like Scythianus, gained only one disciple, who was an old woman. After a while he died, in consequence of a fall from the roof of a house, and the books which he had inherited from Scythianus became the property of the old woman, who, on her death, bequeathed them to a young man named Corbicius, who had been her slave. Corbicius thereupon changed his name to Manes, studied the writings of Scythianus, and began to teach the doctrines which they contained, with many additions of his own. He gained three disciples, named Thomas, Addas, and Hermas. About this time the son of the Persian king fell ill, and Manes undertook to cure him; the prince, however, died, whereupon Manes was thrown into prison. He succeeded in escaping, but eventually fell into the hands of the king, by whose order he was flayed, and his corpse was hung up at the city gate.
A. A. Bevan, who quoted this story, commented that it 'has no claim to be considered historical.'
View of Judaism in the "Acta Archelai".
According to Hegemonius' portrayal of Mani, the devil god which created the world was the Jewish Jehovah. Hegemonius reports that Mani said, "It is the Prince of Darkness who spoke with Moses, the Jews and their priests. Thus the Christians, the Jews, and the Pagans are involved in the same error when they worship this God. For he leads them astray in the lusts he taught them." He goes on to state: "Now, he who spoke with Moses, the Jews, and the priests he says is the archont of Darkness, and the Christians, Jews, and pagans (ethnic) are one and the same, as they revere the same god. For in his aspirations he seduces them, as he is not the god of truth. And so therefore all those who put their hope in the god who spoke with Moses and the prophets have (this in store for themselves, namely) to be bound with him, because they did not put their hope in the god of truth. For that one spoke with them (only) according to their own aspirations."
Central Asian and Iranian primary sources.
In the early 1900s, original Manichaean writings started to come to light when German scholars led by Albert Grünwedel, and then by Albert von Le Coq, began excavating at Gaochang, the ancient site of the Manichaean Uyghur Kingdom near Turpan, in Chinese Turkestan (destroyed around AD 1300). While most of the writings they uncovered were in very poor condition, there were still hundreds of pages of Manichaean scriptures, written in three Iranian languages (Middle Persian, Parthian, and Sogdian) and old Turkish. These writings were taken back to Germany, and were analyzed and published at the Preußische Akademie der Wissenschaften in Berlin, by Le Coq and others, such as Friedrich W. K. Müller and Walter Bruno Henning. While the vast majority of these writings were written in a version of the Syriac script known as Manichaean script, the German researchers, perhaps for lack of suitable fonts, published most of them using the Hebrew alphabet (which could easily be substituted for the 22 Syriac letters).
Perhaps the most comprehensive of these publications was "Manichaeische Dogmatik aus chinesischen und iranischen Texten" ("Manichaean Dogma from Chinese and Iranian texts"), by Ernst Waldschmidt and Wolfgang Lentz, published in Berlin in 1933. More than any other research work published before or since, this work printed, and then discussed, the original key Manichaean texts in the original scripts, and consists chiefly of sections from Chinese texts, and Middle Persian and Parthian texts transcribed with the Hebrew alphabet. (After the Nazi party gained power in Germany, the Manichaean writings continued to be published during the 1930s, but the publishers no longer used Hebrew letters, instead transliterating the texts into Latin letters.)
Coptic primary sources.
Additionally, in 1930, German researchers in Egypt found a large body of Manichaean works in Coptic. Though these were also damaged, hundreds of complete pages survived and, beginning in 1933, were analyzed and published in Berlin before World War II, by German scholars such as Hans Jakob Polotsky. Some of these Coptic Manichaean writings were lost during the war.
Chinese primary sources.
After the success of the German researchers, French scholars visited China and discovered what is perhaps the most complete set of Manichaean writings, written in Chinese. These three Chinese writings, all found at the Caves of the Thousand Buddhas among the Dunhuang manuscripts, and all written before the 9th century, are today kept in London, Paris, and Beijing. Some of the scholars involved with their initial discovery and publication were Édouard Chavannes, Paul Pelliot, and Aurel Stein. The original studies and analyses of these writings, along with their translations, first appeared in French, English, and German, before and after World War II. The complete Chinese texts themselves were first published in Tokyo, Japan in 1927, in the Taisho Tripitaka, volume 54. While in the last thirty years or so they have been republished in both Germany (with a complete translation into German, alongside the 1927 Japanese edition), and China, the Japanese publication remains the standard reference for the Chinese texts.
Greek life of Mani, Cologne codex.
In Egypt a small codex was found and became known through antique dealers in Cairo. It was purchased by the University of Cologne in 1969. Two of its scientists, Henrichs and Koenen, produced the first edition known since as the Cologne Mani-Codex, which was published in four articles in the "Zeitschrift für Papyrologie und Epigraphik". The ancient papyrus manuscript contained a Greek text describing the life of Mani. Thanks to this discovery, much more is known about the man who founded one of the most influential world religions of the past.
Figurative use.
The terms "Manichaean" and "Manichaeism" are sometimes used figuratively as a synonym of the more general term "dualist" with respect to a philosophy or outlook. They are often used to suggest that the world view in question simplistically reduces the world to a struggle between good and evil. For example, Zbigniew Brzezinski used the phrase "Manichaean paranoia" in reference to U.S. President George W. Bush's world view (in "The Daily Show with Jon Stewart", March 14, 2007); Brzezinski elaborated that he meant "the notion that he (Bush) is leading the forces of good against the empire of evil".
Author and journalist Glenn Greenwald followed up on the theme in describing Bush in his 2007 book, "A Tragic Legacy".
In "The Man Who Shot Snapping Turtles," ("Memoirs of Hecate County"), Edmund Wilson's narrator refers to Asa Stryker's argument as "the Manichaean heresy."

</doc>
<doc id="19761" url="https://en.wikipedia.org/wiki?curid=19761" title="Moroccan cuisine">
Moroccan cuisine

Moroccan cuisine is influenced by Morocco's interactions and exchanges with other cultures and nations over the centuries. Moroccan cuisine is typically a mix of Mediterranean, Arabic, Andalusian and Berber cuisine.
Ingredients.
Morocco produces a large range of Mediterranean fruits and vegetables and even some tropical ones. Common meats include beef, goat, mutton and lamb, camel, chicken and seafood, which serve as a base for the cuisine. Characteristic flavorings include lemon pickle, cold-pressed, unrefined olive oil and dried fruits.
Spices and other flavorings.
Spices.
Spices are used extensively in Moroccan food. Although spices have been imported to Morocco through the Arabs for thousands of years, many ingredients — like saffron from Talaouine, mint and olives from Meknes, and oranges and lemons from Fes — are home-grown. Common spices include:
Herbs.
Common herbs include:
Structure of meals.
A typical lunch meal begins with a series of hot and cold salads, followed by a tagine or Dwaz. Bread is eaten with every meal. Often, for a formal meal, a lamb or chicken dish is next, followed by couscous topped with meat and vegetables. A cup of sweet mint tea usually ends the meal. Moroccans either eat with fork, knife and spoon or with their hands using bread as a utensil depending on the dish served. The consumption of pork and alcohol is not common due to religious restrictions.
Main dishes.
The main Moroccan dish most people are familiar with is couscous, the old national delicacy. Beef is the most commonly eaten red meat in Morocco, usually eaten in a Tagine with a wide selection of vegetables. Chicken is also very commonly used in Tagines, or roasted. One of the most appreciated local dishes is the Tagine of Chicken, fries and olives. 
Lamb is also heavily consumed, and since Moroccan sheep breeds store most of their fat in their tails, Moroccan lamb does not have the pungent flavour that Western lamb and mutton have.
Since Morocco lies on two coasts the Atlantic and the Mediterranean, Moroccan cuisine has ample seafood dishes. European pilchard is widely and heavily consumed due to its abundance and quality, hence Morocco is the first producer of this kind of species globally.
Among the most famous Moroccan dishes are Couscous, Pastilla (also spelled Basteeya or Bestilla), Tajine, Tanjia and Harira, a typical heavy soup, eaten during winter to warm up and is usually served for dinner, it is typical eaten with plain bread or with dates. The latter is especially used during the month of Ramadan. 
A big part of the daily meal is bread. Bread in Morocco is principally made from durum wheat semolina known as khobz. Bakeries are very common throughout Morocco and fresh bread is a staple in every city, town and village. The most common is whole grain coarse ground or white flour bread or baguettes. There are also a number of flat breads and pulled unleavened pan-fried breads.
In addition, there are dried salted meats and salted preserved meats such as kliia/khlia and g'did, which are used to flavor tagines or used in "el ghraif", a folded savory Moroccan pancake.
Salads.
Salads include both raw and cooked vegetables, served either hot or cold. Cold salads include "zaalouk," an aubergine and tomato mixture, and taktouka (a mixture of tomatoes, green peppers, garlic and spices) characteristic of the cities of Taza and Fes, in the Atlas.
Desserts.
Usually, seasonal fruits rather than cooked desserts are served at the close of a meal. A common dessert is "kaab el ghzal" ("gazelle's horns"), a pastry stuffed with almond paste and topped with sugar. Another is "Halwa chebakia", pretzel-shaped dough deep-fried, soaked in honey and sprinkled with sesame seeds. Halwa Shebakia are cookies eaten during the month of Ramadan. Coconut fudge cakes, 'Zucre Coco', are popular also.
Beverages.
The most popular drink is green tea with mint. Traditionally, making good mint tea in Morocco is considered an art form and the drinking of it with friends and family is often a daily tradition. The pouring technique is as crucial as the quality of the tea itself. Moroccan tea pots have long, curved pouring spouts and this allows the tea to be poured evenly into tiny glasses from a height. For the best taste, glasses are filled in two stages. The Moroccans traditionally like tea with bubbles, so while pouring they hold the teapot high above the glasses. Finally, the tea is accompanied with hard sugar cones or lumps.
Snacks and fast food.
Selling fast food in the street has long been a tradition, and the best example is Djemaa el Fna square in Marrakech. Starting in the 1980s, new snack restaurants started serving "Bocadillo" (a Spanish word for a sandwich). Though the composition of a bocadillo varies by region, it is usually a baguette filled with salad and a choice of meats, Mozarella, fish (usually tuna), or omelette.
Dairy product shops locally called Mhlaba, are very prevalent all around the country. Those dairy stores generally offer all types of dairy products, juices, and local delicacies such as (Bocadillos, Msemen and Harcha).
In the late 1990s, several multinational fast-food franchises opened restaurants in major cities.
Moroccan food abroad.
Couscous is one of the most popular North African dishes globally. Markets, stores and restaurants in Europe, especially in France and lately the United Kingdom, feature lamb tajines, bastilla, and couscous.
Paula Wolfert, prolific American author of nine cookbooks (two on Moroccan cuisine), helped enable Moroccan-Americans to enjoy their native cuisine with ease. "Couscous and Other Good Food from Morocco" was published in 1973 and is still in print; it was added to the James Beard Hall of Fame in 2008. Her "Food of Morocco" came out in 2011 and won the 2012 James Beard Award for Best International Cookbook. Wolfert appeared on the "Martha Stewart Show" to demonstrate cooking in clay.
Raised between Fez and San Sebastian, chef Najat Kaanache has served as an unofficial culinary ambassador of Morocco, sharing Moroccan flavors and cooking techniques with many of the world's top chefs during her pilgrimage through the best restaurant kitchens of Spain, Denmark, the Netherlands and the US.
External links.
Moroccan cuisine recipes

</doc>
<doc id="19763" url="https://en.wikipedia.org/wiki?curid=19763" title="Martin Van Buren">
Martin Van Buren

Martin Van Buren (; December 5, 1782 – July 24, 1862) was an American politician who served as the eighth President of the United States (1837–41). A member of the Democratic Party, he served in a number of senior roles, including eighth Vice President (1833–37) and tenth Secretary of State (1829–31), both under Andrew Jackson. Van Buren's inability as president to deal with the economic chaos of the Panic of 1837 and with the surging Whig Party led to his defeat in the 1840 election.
Of Dutch ancestry, Van Buren learned early to interact with people from multiple ethnic, income, and societal groups, which he used to his advantage as a political organizer. A meticulous dresser, he could mingle in upper class society as well as in saloon environments like the tavern his father ran. A delegate to a political convention at age 18, he quickly moved from local to state politics, gaining fame both as a political organizer and an accomplished lawyer. Elected to the Senate by the state legislature in 1821, Van Buren supported William H. Crawford for president in 1824, but by 1828 had come to support General Andrew Jackson. Van Buren was a major supporter and organizer for Jackson in the 1828 election. Jackson was elected, and made Van Buren Secretary of State.
During Jackson's eight years as president, Van Buren was a key advisor, and built the organizational structure for the coalescing Democratic Party, particularly in New York. In 1831, following his resignation as Secretary of State, Jackson gave Van Buren a recess appointment as American minister to Britain, but Van Buren's nomination was rejected by the Senate, cutting short his service in London. He was successful in the jockeying to become Jackson's picked successor, and was elected vice president in 1832. Van Buren defeated several Whig opponents in 1836, and was elected president. He was the third sitting Vice President to be elected directly to the presidency, following John Adams in 1796 and Thomas Jefferson in 1800, and the last for 152 years, until George H. W. Bush was elected in 1988.
As president, Van Buren was blamed for the depression of 1837; hostile newspapers called him "Martin Van Ruin". He attempted to cure the economic problems by keeping control of federal funds in an independent treasury—rather than in state banks—but Congress would not approve of this until 1840. In foreign affairs, he denied the application of Texas for admission to the Union, unwilling to upset the balance of free and slave states in the Missouri Compromise, and hoping to avoid war with Mexico over Texas annexation by purchasing the territory from Mexico's government. Additionally, relations with Britain and its colonies in Canada proved to be strained from the bloodless Aroostook War and the "Caroline" Affair.
In 1840, Van Buren was voted out of office, losing to Whig candidate William Henry Harrison. Van Buren was the leading candidate for the Democratic nomination in 1844, but lost to James K. Polk, who went on to win the election. In the 1848 election Van Buren ran unsuccessfully as the candidate of the Free Soil Party. He also supported fellow Democrats Franklin Pierce (1852), James Buchanan (1856), and Stephen A. Douglas (1860) for the presidency, but his increasingly abolitionist views and support for the Union led him to support Abraham Lincoln's policies after the start of the American Civil War.
Van Buren's health began to fail in 1861, and he died in July 1862 at the age of seventy-nine. Although he served in many high offices, his most lasting achievement was as a political organizer who built the modern Democratic Party and guided it to dominance in the new Second Party System.
Early life and education.
Martin Van Buren was born on December 5, 1782, in the village of Kinderhook, New York about south of Albany on the Hudson River. He was the first president to be born after the United States declared independence. He was baptized on December 15 of that year as "Maarten van Buren", the original Dutch spelling of his name. In the era before the steamboat, Kinderhook was an isolated village, and most of the townsfolk, including the Van Burens, spoke Dutch at home. Martin Van Buren is the only president who spoke English as a second language. Van Buren descended from Cornelis Maessen of the town of Buren in the Netherlands, who had come to America in 1631 and purchased a plot of land on Manhattan Island; his son Martin Cornelisen took the surname Van Buren.
The future president's father, Abraham Van Buren (1737–1817), was a farmer who owned a Kinderhook inn as well as six slaves. Abraham Van Buren supported the Patriot cause during the American Revolution as a captain in the Albany County Militia's 7th Regiment, and later joined the Jeffersonian Republicans. He was active in local politics and government, and served as Kinderhook's town clerk from 1787 to 1797. Martin Van Buren's mother was Maria Hoes Van Alen Van Buren (1747–1818). She had been married to Johannes Van Alen. After Johannes' death, she married Abraham Van Buren in 1776. By his mother's first marriage, Van Buren had one half-sister and two half-brothers, including: Marytje (or Maria) Van Alen (1768-1829), the wife of John L. Hoes; John I. Van Alen (1770–1805); and James I. Van Alen, who practiced law with Van Buren for a time and served as a member of Congress (1807–1809). Van Buren had four full siblings:
Van Buren received a basic education at the village schoolhouse and briefly studied Latin at the Kinderhook Academy and at Washington Seminary in Claverack. His formal education ended before he reached 14, when he began reading law in 1796 at the office of Peter Silvester and his son Francis, prominent Federalist attorneys in Kinderhook.
Van Buren was small in stature; as an adult he was 5 feet 6 inches tall, and often referred to as "Little Van." When he first began his legal studies, he often presented an unkempt appearance in rough, homespun clothing. It was the Silvesters who suggested that Van Buren could improve his professional prospects by dressing fashionably and taking care in how he appeared in public; he heeded the advice and patterned his clothing, appearance, bearing and conduct after theirs. After six years under the Silvesters, the elder Silvester and Democratic-Republican political figure John Peter Van Ness suggested that Van Buren's political leanings made it a good idea for him to complete his education with a Democratic-Republican attorney. Accepting this advice, he spent a final year of apprenticeship in the New York City office of John Van Ness's brother William P. Van Ness, a political lieutenant of Aaron Burr. Van Buren was admitted to the bar in 1803.
Van Buren married Hannah Hoes, his childhood sweetheart and first cousin once removed, on February 21, 1807, in Catskill, New York. Like Van Buren, she was raised in a Dutch home; she spoke primarily Dutch, and spoke English with a distinct accent. The couple had five sons and one daughter: Abraham (1807–1873) a graduate of West Point and career military officer; John (1810–1866), graduate of Yale and Attorney General of New York; Martin, Jr. (1812–1855), secretary to his father and editor of his father's papers until a premature death from tuberculosis; Winfield Scott (born and died in 1814); and Smith Thompson (1817–1876), an editor and special assistant to his father while president. Their daughter was stillborn. After 12 years of marriage, Hannah Van Buren contracted tuberculosis and died on February 5, 1819, at the age of 35. Martin Van Buren never remarried.
Early political career.
Van Buren had been active in politics from at least the age of 17, when he attended a party convention in Troy, New York, where he worked successfully to secure for John Peter Van Ness the Democratic-Republican Party nomination in a special election for the 6th Congressional District seat. He formed a law partnership with his half-brother James I. Van Alen, and once established in his practice, he became financially secure enough to increase his focus on politics. He was a supporter of Aaron Burr, and allied himself with the George Clinton faction of the Democratic-Republican Party. Van Buren supported Daniel D. Tompkins for Governor over incumbent Morgan Lewis in 1807. Tompkins won, and his allies were a majority in the state legislature. As a result, Van Buren was appointed Surrogate of Columbia County, New York, replacing Van Alen, who had supported Lewis. Van Buren served as Surrogate from 1808 until 1813, when the Federalist Party obtained a majority in the state legislature and replaced him.
Van Buren was a member of the New York State Senate from 1812 to 1820, and joined the opposition party in 1813. (The opposition party were Democratic-Republicans who fought DeWitt Clinton for control of the Democratic-Republican Party in New York.) Van Buren served as New York Attorney General from 1815 to 1819. He replaced William Floyd as a presidential elector in 1820, and voted for James Monroe and Daniel D. Tompkins.
Though he never served in the military, during the War of 1812 Van Buren worked in the State Senate to pass war measures, including bills to expand the New York Militia and increase soldier pay. In addition, he was a special judge advocate appointed to serve as one of the prosecutors of William Hull during Hull's court-martial following the surrender of Detroit. In the winter of 1814–15 he exchanged ideas with Winfield Scott on ways to reorganize the New York Militia in anticipation of another military campaign in 1815. The reorganization would have included a position for Van Buren at a rank to be determined, but the conclusion of the war in February 1815 ended Scott and Van Buren's work on the project.
At first he opposed DeWitt Clinton's plan for the Erie Canal, but he supported it when the Bucktails (the name given to the anti-DeWitt Clinton Democratic-Republicans) were able to gain a majority on the Erie Canal Commission, and he supported a bill that raised money for the canal through the sale of state bonds.
In 1817, Van Buren's connection with so-called "machine politics" started when he created the first political organization encompassing all of New York, the Bucktails. The Bucktails became a successful movement that emphasized party loyalty and used it to capture and control many patronage posts throughout New York. Van Buren gained the nickname of "Little Magician" for the skill with which he exploited what came to be called the "spoils system". Van Buren served as a member of the 1820 state constitutional convention, where he favored expanded voting rights, but opposed universal suffrage and tried to maintain property requirements for voting.
He was the leading figure in the Albany Regency, a group of Bucktail leaders who for more than a generation dominated the politics of New York and influenced national politics. The Regency, together with other political organizations such as Tammany Hall, played a major role in expanding the spoils system and making it a recognized and accepted procedure. He was the prime architect of the first nationwide political party: the Jacksonian Democrats or Democratic Party, which evolved from the Democratic-Republicans and relied on party loyalty and patronage to prevent contentious sectional issues, including tariffs and slavery, from becoming national crises. In Van Buren's words, "Without strong national political organizations, there would be nothing to moderate the prejudices between free and slaveholding states." As had James Madison and other Democratic Party organizers who favored states' rights and local control, Van Buren was struggling to find an institutional solution to the Constitution's seeming inability to prevent concentration of power in an administrative republic.
Early in his life Van Buren owned a slave, a man named Tom who served as his personal valet. Tom ran away in 1814 and eventually settled in Canada, with Van Buren making no effort to locate him. In 1824 Tom was found to be living in Worcester, Massachusetts. Since he still legally owned Tom (under New York's gradual emancipation law, slavery was scheduled to be completely abolished in the state in 1827), Van Buren privately agreed to sell Tom to the finder for $50, provided the finder, a resident of Rensselaer County, could guarantee that Tom would be captured without violence. He could not make such a guarantee, and his willingness to pay was lessened by the knowledge that Tom would be emancipated in fewer than three years even if he was re-enslaved, so Tom remained free, as Van Buren probably intended. (Allowing Tom to remain in Massachusetts unmolested without notice enabled Van Buren to avoid offending southern slave owners, as he would do if he publicly allowed a former slave to remain free. At the same time, he avoided offending northern abolitionists, which he would do if he captured and re-enslaved a former slave.)
U.S. Senate and national politics.
In February 1821, Martin Van Buren was elected a U.S. Senator from New York, defeating the incumbent Nathan Sanford who ran as the Clintonian candidate. Van Buren at first favored internal improvements, such as road repairs and canal construction, proposing a constitutional amendment in 1824 to authorize such undertakings, but changed his position the following year. He voted for the tariffs of 1824 and 1828, and then gradually abandoned this protectionist position, later coming out for tariffs "for revenue only."
In the presidential election of 1824, Van Buren supported William H. Crawford and received the electoral vote of Georgia for Vice President. None of the presidential candidates—Crawford, John Quincy Adams, Andrew Jackson, or Henry Clay—had received a majority of the electoral college votes, so the choice fell to the United States House of Representatives. The House had to choose from among the top three candidates, so Clay was eliminated. Van Buren had originally hoped to block John Quincy Adams by denying him the state of New York, which was divided between supporters of Crawford and Adams. However, Representative Stephen Van Rensselaer swung New York to Adams. Adams won, and appointed Clay as Secretary of State. Because Clay had supported Adams in the House election, Jackson and Crawford supporters alleged corruption. After the House contest, Van Buren shrewdly kept out of the controversy which followed, and began looking forward to 1828. He switched his support early from Crawford, whose ill health after a stroke had made him a less than viable candidate, to Andrew Jackson, who had won the popular vote in 1824. Jackson was angered to see the presidency go to Adams after he received fewer popular votes, and eagerly looked forward to a rematch.
Always notably courteous in his treatment of opponents, Van Buren showed no bitterness toward either Adams or Henry Clay, and he voted for Clay's confirmation as Secretary of State, notwithstanding Jackson's "corrupt bargain" charge. At the same time, he opposed the Adams-Clay plans for internal infrastructure improvements (roads, canals, bridges etc.) and declined to support U.S. participation in the Congress of Panama. As chair of the Judiciary Committee, he brought forward a number of measures for the improvement of judicial procedure, including one (not adopted), which would have required a super-majority vote by the United States Supreme Court to declare a law unconstitutional. in May 1826, Van Buren joined with Senator Thomas Hart Benton in reporting on patronage in the executive branch, going against his own use of the spoils system to propose unsuccessfully that Presidents not be able to remove officeholders at will, and that Presidents report to Congress on the reasons why dismissed holders of federal positions had been removed. The 1828 "Tariff of Abominations" was recognized as his work. Since Democrats, especially Southerners, were generally opposed to tariffs that increased the price of manufactured goods from the North but did not benefit the raw materials produced in the South, Van Buren could normally have been expected to oppose tariffs. Political observers of the time viewed Van Buren's efforts to pass the 1828 tariff as part of the campaign to elect Jackson as President. Anticipating that most Southerners would vote for Andrew Jackson no matter who else was running, Van Buren intended the tariff proposed by Jackson's Northern Democratic supporters in Congress to attract to Jackson's candidacy Northern voters, who generally favored high tariffs to protect the manufactured goods they produced. Van Buren voted in favor, later adopting the cover story that he had done so only in response to instructions from the New York State Legislature. Most Democrats, especially Southerners, continued to oppose tariffs after 1828. Van Buren's political opponents in the Democratic Party used his 1828 vote against him for years afterwards to prevent him from obtaining Southern support for his candidacies.
Van Buren was not considered to be an orator like Henry Clay or Daniel Webster, but his more important speeches show careful preparation and his opinions carried weight; the oft-repeated charge that he refrained from declaring himself on crucial questions is hardly borne out by an examination of his senatorial career. In February 1827, he was re-elected to the Senate by a large majority. He became one of the recognized managers of the Jackson campaign, and his tour of Virginia, the Carolinas, and Georgia in the spring of 1827 won support for Jackson from Crawford. Martin Van Buren sought to reorganize and unify "the old Republican party" behind Jackson. At the state level, Jackson's committee chairs would split up the responsibilities around the state and organize volunteers at the local level. "Hurra Boys" would plant hickory trees (in honor of Jackson's nickname, "Old Hickory") or hand out hickory sticks at rallies. In 1828 Van Buren ran for Governor of New York in an effort to use his personal popularity to bolster Jackson's chances of carrying New York in the presidential election. Jackson defeated Adams handily, leading the pro-Adams "New York American" to editorialize "Organization is the secret of victory. By the want of it we have been overthrown." Van Buren won his election, and resigned from the Senate to start the gubernatorial term, which began on January 1, 1829.
Martin Van Buren's tenure as New York governor is the second shortest on record. While his term was short, he did manage to pass the Bank Safety Fund Law (an early form of deposit insurance) through the Legislature.
Jackson Cabinet.
On March 5, 1829, President Jackson appointed Van Buren Secretary of State, an office which probably had been assured to him before the 1828 elections, and Van Buren resigned the governorship on March 12. He was succeeded by his Lieutenant Governor, Enos T. Throop, a member of the Regency.
Secretary of State.
As Secretary of State, Van Buren took care to keep on good terms with the Kitchen Cabinet, Jackson's informal advisers. He sometimes opposed Jackson in the matter of removing political appointees from office to replace them with Jackson loyalists, but also saw to the replacement of postmasters in New York with Van Buren loyalists.
No serious diplomatic crises arose during Van Buren's tenure, but he achieved several notable successes, including the settlement of long-standing claims against France, winning reparations for property that had been seized during the Napoleonic Wars. He reached an agreement with the British to open trade with the British West Indies colonies. In addition, Van Buren completed a treaty with the Ottoman Empire that gained American merchants access to the Black Sea. Items on which he did not achieve success included settling the Maine-New Brunswick boundary dispute with Great Britain, gaining settlement of the U.S. claim to the Oregon Country, concluding a commercial treaty with Russia, and persuading Mexico to sell Texas.
Van Buren also advised Jackson informally on matters of domestic policy. In the controversy over the Bank of the United States, he sided with Jackson. He also sided with Jackson on the Indian Removal Act. After the breach between Jackson and Calhoun, which culminated with the Nullification Crisis, Van Buren's position as one of Jackson's primary political supporters and policy advisors clearly marked him as the most prominent candidate for the vice presidency in 1832, and Jackson's most likely successor in 1836.
Petticoat affair.
Van Buren won Jackson's lasting regard by his courtesies to Peggy Eaton, wife of Secretary of War John H. Eaton, with whom the wives of the cabinet members had refused to associate.
As a widower, Van Buren was unaffected by the position of the Cabinet wives, and he supported Jackson's position that criticism of the Eatons would not be tolerated. The anti-Eaton effort was led by Calhoun's wife, Floride, and Jackson's opponents, including Calhoun, hoped to use it to gain political leverage. By siding with Jackson, Van Buren helped create a counter-coalition that weakened Calhoun.
The dispute was finally resolved when Van Buren offered to resign; Jackson eventually accepted, which gave him the opportunity to reorganize his cabinet by asking for the resignations of Cabinet members whose wives were part of the anti-Eaton coalition. Postmaster General William T. Barry, who had sided with Jackson and Van Buren, was the lone cabinet member to stay, and Eaton eventually received appointments that took him away from Washington, first as governor of Florida Territory, and then as minister to Spain.
Vice-Presidency.
In December 1829, Jackson had already made known his wish that Van Buren receive the 1832 vice presidential nomination. After resigning as Secretary of State in April 1831 as part of resolving the Petticoat affair, Van Buren remained in office until June, and afterwards continued to play a part in Jackson's Kitchen Cabinet. In August 1831 Jackson gave Van Buren a recess appointment as Minister to the Court of St. James (Britain) and he arrived in London in September. He was cordially received, but in February, he learned that his nomination had been rejected by the Senate on January 25, 1832. The rejection was attributed by the Senate to Van Buren's instructions while Secretary of State to Louis McLane, the American minister to Britain. Van Buren's instructions, which concerned the opening of the West Indies trade, supposedly repudiated the foreign policy of Jackson's predecessors, which the Senate claimed was a breach of decorum. In fact, the rejection of Van Buren was the work of Calhoun. Calhoun opposed Van Buren's confirmation, believing that Van Buren had attempted to keep him from becoming vice president. Calhoun also opposed Van Buren for his role in the Petticoat Affair and his work on the 1828 tariff. When the vote on Van Buren's nomination was taken, enough pro-Calhoun Democrats refrained from voting to produce a tie, thus giving Calhoun, in his role as presiding officer, the ability to cast a vote. He voted no, and so achieved "vengeance" on Van Buren.
Calhoun was elated, convinced that he had ended Van Buren's career. "It will kill him dead, sir, kill him dead. He will never kick, sir, never kick," Calhoun exclaimed to a friend within earshot of Thomas Hart Benton. In fact, Calhoun's move backfired by making Van Buren seem the victim of petty politics, thus raising him in both Jackson's regard and the esteem of others in the Democratic Party. Far from ending Van Buren's career, Calhoun's action gave greater impetus to Van Buren's candidacy for vice president.
After a brief tour of Europe, Van Buren reached New York on July 5, 1832. The May 1832 Democratic National Convention, the party's first, had nominated him for vice president on the Jackson ticket. Van Buren's nomination was not as strongly supported as Jackson's, particularly among southerners who recalled his work on the tariff in 1828, but he somewhat placated southerners by denying the right of Congress to abolish slavery in the District of Columbia without the consent of the slave states.
The Jackson-Van Buren ticket won the 1832 election, and Van Buren took office as Vice President in March 1833. During his time in office Van Buren continued to be one of Jackson's primary advisors and confidants, and accompanied Jackson on his tour of the northeastern United States in 1833. Jackson's confidence in Van Buren was further demonstrated after Jackson named Benjamin F. Butler, Van Buren's political ally and former law partner, to serve as Attorney General, and John Forsyth, another Van Buren ally, to serve as Secretary of State.
Van Buren's support of Jackson in the Nullification Crisis and the decision not to recharter the Second Bank of the United States made him a target of Jackson's most vocal opponents. Van Buren was threatened with violence, including explicit comments from Senator George Poindexter of Mississippi, which caused Van Buren to carry pistols for self-defense. However he also demonstrated both the willingness and the ability to work with his opponents, cooperating with Clay and Calhoun (now a Senator) to pass the compromise Tariff of 1833, which helped end the Nullification Crisis.
During one contentious debate on the bank issue, Van Buren presided over the Senate as Clay spoke passionately about the harm he believed Jackson's bank policy would cause. Directing his remarks to Van Buren, Clay asked rhetorically whether Van Buren would approach Jackson and persuade him to change his mind. After Clay concluded, observers wondered how Van Buren would react. Van Buren's response was to descend from the rostrum and ask Clay if he could borrow a pinch of snuff. Caught off guard, Clay reflexively handed over his snuff box. Van Buren took a pinch, bowed to Clay, and left the chamber, both deflating the effect of Clay's remarks and preventing tension from escalating, as would have happened if Van Buren had attempted to reply directly.
Election of 1836.
In the election of 1832, the Jackson-Van Buren ticket won by a landslide. Jackson, not running in 1836, was determined to make Van Buren his successor in order to continue the Jackson administration's policies.
Van Buren was unanimously nominated by the 1835 Democratic National Convention at Baltimore, Maryland. On the issue of slavery, Van Buren moved to obtain the support of southerners by assuring them that he opposed abolitionism and supported the maintaining of slavery in states where it had already existed. Regarding the national bank, Van Buren made clear that he opposed rechartering a national bank. To demonstrate consistency regarding his opinions on slavery, Van Buren cast the tie-breaking Senate vote in favor of engrossing a bill to subject abolitionist mail to state laws, thus ensuring that its circulation would be prohibited in the South.
Martin Van Buren's competitors in the 1836 election were the Whigs; they ran several regional candidates in hopes of sending the election to the House of Representatives, where each state delegation would have one vote and the Whigs would stand a better chance of winning. William Henry Harrison hoped to receive the support of the Western voters, Daniel Webster had strength in New England, and Hugh Lawson White and Willie Person Mangum had support in the South. Van Buren won the election easily, with 170 electoral votes to 73 for Harrison, 26 for White, 14 for Webster and 11 for Mangum.
Twentieth-century etymologist Allen Walker Read published research asserting the wide usage of the phrase "O.K." (okay) -- "Old Kinderhook"—started during the presidential campaign and subsequent presidency of Martin Van Buren.
Presidency 1837–1841.
Policies.
Martin Van Buren announced his intention "to follow in the footsteps of his illustrious predecessor", and retained all but one of Jackson's cabinet. Van Buren had few economic tools to deal with the Panic of 1837. The Panic was followed by a five-year depression in which banks failed and unemployment reached record highs. Some modern economists have argued that the Panic was caused by the Jackson administration's bank policies, with the power to create money being distributed into decentralized banks (most of which would then continue to cause a massive inflationary bubble).
Van Buren advocated lower tariffs and free trade, and by doing so maintained support of the South for the Democratic Party. He succeeded in setting up a system of bonds for the national debt. His party was so split that his 1837 proposal for an "Independent Treasury" system did not pass until 1840. It gave the Treasury control of all federal funds and had a legal tender clause that required, by 1843, all payments to be made in specie, but further inflamed public opinion on both sides. In the field of labor conditions, an Executive Order issued by Van Buren in 1840 established the 10-hour day for laborers on all federal public works.
In a bold step, Van Buren reversed Andrew Jackson's policies and sought peace at home, as well as abroad. Instead of settling a financial dispute between American citizens and the Mexican government by force, Van Buren wanted to seek a diplomatic solution. In an action that upset political leaders of the pro-slavery states, in August 1837, Van Buren denied Texas' formal request to join the United States, partly to prevent the upset of the slave state/free state balance in the Missouri Compromise, and partly because he hoped to avoid the possibility of war with Mexico over Texas annexation by purchasing the territory from the Mexican government.
In the case of the ship "Amistad", Van Buren sided with the Spanish government to return the kidnapped slaves. Regarding Indian removal, Van Buren oversaw the movement of Cherokee, Choctaw, Creek, Chickasaw and Seminole tribes from Georgia, Tennessee, Alabama, and South Carolina to the Oklahoma territory, executing the orders passed under Jackson. To help secure Florida, Van Buren also continued the Second Seminole War, which had begun during Jackson's presidency. Fighting was not resolved until 1842, after Van Buren had left office.
In 1839, Joseph Smith, Jr., the founder of the Latter Day Saint movement, visited Van Buren to plead for the U.S. to help roughly 20,000 Mormon settlers of Independence, Missouri (who were forced from the state during the 1838 Mormon War) there. The Governor of Missouri, Lilburn Boggs, had issued an executive order on October 27, 1838, known as the "Extermination Order". It authorized troops to use force against Mormons to "exterminate or drive from the state". In 1839, after moving to Illinois, Smith and his party appealed to members of Congress and to President Van Buren to intercede for the Mormons. According to Smith's grandnephew, Van Buren said to Smith, "Your cause is just, but I can do nothing for you; if I take up for you I shall lose the vote of Missouri".
Slavery.
While in the state Senate Van Buren voted for a resolution instructing New York's members of Congress to vote against the admission of Missouri as a slave state. In 1848 he would be the nominated for president by the Free Soil Party (an anti-slavery political party). Despite these antislavery views, during his term of office there was no ambiguity about his position on the abolition of slavery. Van Buren actually considered slavery immoral, but sanctioned by the Constitution. He was against its abolition both in D.C. and in the United States altogether, and said so in his Inaugural Address in 1837: "I believed it a solemn duty fully to make known my sentiments in regard to it , and now, when every motive for misrepresentation has passed away, I trust that they will be candidly weighed and understood."
"I must go into the Presidential chair the inflexible and uncompromising opponent of every attempt on the part of Congress to abolish slavery in the District of Columbia against the wishes of the slaveholding States, and also with a determination equally decided to resist the slightest interference with it in the States where it exists." Slavery would be abolished in the District of Columbia on April 18, 1862.
Judicial appointments.
Supreme Court.
Van Buren appointed two Justices to the Supreme Court of the United States:
Van Buren appointed eight other federal judges, all to United States district courts.
Some sources incorrectly state that Van Buren appointed John Catron to the Supreme Court. Catron was appointed by Jackson on Jackson's last day in office, and confirmed a few days later, after Van Buren's term had begun.
Election of 1840.
Van Buren took the blame for hard times, as Whigs ridiculed him as "Martin Van Ruin". Van Buren's rather elegant personal style was also an easy target for Whig attacks, such as the Gold Spoon Oration. State elections of 1837 and 1838 were disastrous for the Democrats, and the partial economic recovery in 1838 was offset by a second commercial crisis in that year. Nevertheless, Van Buren controlled his party and was unanimously renominated by the Democrats in 1840. The revolt against Democratic rule led to the election of William Henry Harrison, the Whig candidate. Van Buren once mentioned his relief upon leaving office: "As to the presidency, the two happiest days of my life were those of my entrance upon the office and my surrender of it."
Later life.
On the expiration of his term, Van Buren returned to his estate, Lindenwald in Kinderhook, where he planned his return to the White House. He seemed likely to be nominated by the Democrats in 1844, but in April of that year a Van Buren letter to William H. Hammett was made public. In it, Van Buren opposed the immediate annexation of Texas, but said that he would support annexation once the state of war between Texas and Mexico was resolved. Van Buren's opposition to immediate annexation cost him the support of pro-slavery Democrats; he began the Democratic National Convention with a majority of the delegates, but with no southern support he could not reach the two-thirds threshold required for nomination. His name was withdrawn after eight ballots, and a dark horse, James K. Polk, received the nomination and went on to win the presidency.
Van Buren was increasingly opposed to slavery, and his original attempts to accommodate pro-slavery southerners gave way over time to acceptance of anti-slavery positions including opposing slavery's expansion into newly organized western states. In 1848, he was nominated for President by two minor parties, first by the "Barnburner" faction of the Democratic Party in New York, then by the Free Soil Party, with whom the "Barnburners" coalesced. The Barnburners and Free Soilers opposed Democratic nominee Lewis Cass, who opposed the Wilmot Proviso and was otherwise seen as friendly to slavery. In addition, Van Buren, who had been denied the 1844 nomination by Cass supporters despite having begun the convention with a majority of delegates, may have run in order to exact a measure of revenge by denying Cass the presidency. Van Buren won no electoral votes, but finished second to Whig nominee Zachary Taylor in New York, taking enough votes from Cass to give the state—and perhaps the election—to Taylor.
Unlike many anti-slavery Democrats of the 1840s and 1850s, who later joined the Republican Party, Van Buren and most of his followers remained in the Democratic fold, including his son John Van Buren and Samuel J. Tilden, who later served as Governor of New York and was the Democratic nominee for President in 1876. Van Buren supported Franklin Pierce for President in 1852, and James Buchanan in 1856, though he later opposed the Buchanan administration's efforts to accommodate the southern states when they threatened secession.
In the election of 1860, he supported Stephen A. Douglas, the candidate of northern Democrats, and helped create a fusion ticket in New York of Democratic electors pledged to both Douglas and John C. Breckinridge, but Abraham Lincoln carried New York and every northern state except New Jersey. Once the American Civil War began, Van Buren made public his support for the Union, and supported Abraham Lincoln's efforts to prevent the southern states from seceding. In April, 1861 former President Pierce wrote to the other living former Presidents and asked them to consider meeting in order to use their stature and influence to propose a negotiated end to the war. Pierce asked Van Buren to use his role as the senior living ex-President to issue a formal call. Van Buren's reply suggested that Buchanan should be the one to call the meeting, since he was the former President who had served most recently, and nothing more resulted from Pierce's proposal.
Van Buren's health began to fail later in 1861, and he was bedridden with pneumonia during the fall and winter of 1861–62. He did not recover, and died of bronchial asthma and heart failure at his Lindenwald estate in Kinderhook at 2:00 a.m. on July 24, 1862, at the age of 79. He is buried in the Kinderhook Reformed Dutch Church Cemetery, as are his wife Hannah, his parents, and his son Martin Van Buren, Jr.
Memorials.
Counties.
Counties are named for Martin Van Buren in Michigan, Iowa, Arkansas, and Tennessee. Cass County, Missouri was originally named for Van Buren, and was renamed in 1849 to honor Lewis Cass.
Cities and towns.
Cities and towns named for Van Buren include:
Arkansas: Van Buren, Arkansas.
Indiana:Van Buren, IndianaVan Buren Township, Clay County, IndianaVan Buren Township, Brown County, IndianaVan Buren Township, Monroe County, IndianaVan Buren Township, Grant County, IndianaVan Buren Township, Pulaski County, IndianaVan Buren Township, Fountain County, IndianaVan Buren Township, LaGrange County, IndianaVan Buren Township, Madison County, IndianaVan Buren Township, Kosciusko County, IndianaVan Buren Township, Daviess County, IndianaVan Buren Township, Shelby County, Indiana.
In addition, Van Buren Township in LaPorte County, Indiana was later merged with Noble Township.
Iowa: Van Buren Township, Jackson County, Iowa; Van Buren Township, Lee County, Iowa.
Kentucky: Van Buren, Anderson County. The small community was abandoned due to the construction and flooding of Taylorsville Lake from 1974 to 1983.
Louisiana: Van Buren, Livingston Parish. The original parish seat, it is now abandoned.
Maine: Van Buren, Maine.
Michigan: Van Buren Charter Township, Michigan and Martin, Michigan. In addition, the now-defunct village of Martinsville in Sumpter Township was named for him.
Missouri: Van Buren, Missouri.
Minnesota: Van Buren Township, St. Louis County, Minnesota.
Mississippi: Van Buren, Mississippi (defunct).
New York: Van Buren, New York.
Ohio:Van Buren (a village in Hancock County)Van Buren Township, Shelby County, Ohio. This township started to be populated by white settlers in the early 1830s. It was incorporated in 1835, and its government organized in 1841.Van Buren Township, Putnam County, Ohio. Originally part of Blanchard Township, it was surveyed in 1821, became home to its first white settlers in 1835, and was organized in 1843.Van Buren Township, Darke County, OhioVan Buren Township, Hancock County, Ohio.
Tennessee: Van Buren, Hardeman County (unincorporated). Established in 1831, this unincorporated populated area is located at the intersection of Van Buren and Lake Hardeman Roads, and shares a ZIP code with Hickory Valley.
Wisconsin: Van Buren, Grant County. In 1841 this unincorporated area was combined with unincorporated areas named for Lafayette and Osceola to form the incorporated town of Potosi.
State parks.
Van Buren State Park and Van Buren Trail State Park in Michigan, and Ohio's Van Buren State Park and its Van Buren Lake are named for him.
Mountains.
Mount Van Buren on the Palmer Land portion of Antarctica was named for Martin Van Buren.
Islands.
Van Buren Island in the St. Lawrence River, part of the Thousand Islands, sits at latitude 44.404339N, 75.892119W. Though named for the US President, this island has always been in Canadian waters. 
Ships.
The "USS Van Buren", a United States Navy schooner in service from 1839 to 1847 was also named for Martin Van Buren.
In popular culture.
During the 1988 campaign for President, George H. W. Bush, a Yale University graduate and member of the Skull and Bones secret society, was attempting to become the first sitting Vice President to win election to the Presidency since Van Buren. In the comic strip "Doonesbury" artist Garry Trudeau depicted members of Skull and Bones as attempting to rob Van Buren's grave, apparently intending to use the relics in a ritual that would aid Bush in the election.
On the television show "Seinfeld", the episode "The Van Buren Boys" is about a fictional street gang that admires Van Buren and bases its rituals and symbols on him, including the hand sign of eight fingers pointing up. Eight fingers signifies Van Buren, the eighth President.
Martin Van Buren was portrayed by Nigel Hawthorne in the 1997 historical drama film "Amistad".
In an early scene of the film "Two Faces of January", the main characters – American expatriates in Athens – encounter an American tourist and discover that she is a Van Buren descendant. They then argue over whether Martin Van Buren was the seventh or eighth President.
The "USS Van Buren" is a fictional Navy aircraft carrier named for President Van Buren which has appeared in the television show "".
During the 2016 presidential campaign, a #FeeltheBuren hashtag was created as a parody of Bernie Sanders' #FeeltheBern campaign slogan.
References.
Sources

</doc>
<doc id="19765" url="https://en.wikipedia.org/wiki?curid=19765" title="Melbourne Cricket Ground">
Melbourne Cricket Ground

The Melbourne Cricket Ground (MCG), also known simply as "The G", is an Australian sports stadium located in Yarra Park, Melbourne, Victoria, and is home to the Melbourne Cricket Club. It is the 10th-largest stadium in the world, the largest in Australia, the largest in the Southern Hemisphere, the largest cricket ground by capacity, and has the tallest light towers of any sporting venue. The MCG is within walking distance of the city centre and is served by the Richmond railway station, Richmond, and the Jolimont railway station, East Melbourne. It is part of the Melbourne Sports and Entertainment Precinct.
Since it was built in 1853, the MCG has been in a state of almost constant renewal. It served as the centrepiece stadium of the 1956 Summer Olympics, the 2006 Commonwealth Games and two Cricket World Cups: 1992 and 2015. It is also famous for its role in the development of international cricket; it was the venue for both the first Test match and the first One Day International, played between Australia and England in 1877 and 1971 respectively. The annual Boxing Day Test is one of the MCG's most popular events. Referred to as "the spiritual home of Australian rules football", it hosts AFL matches in the winter, with at least one game (though usually more) held there each round. The stadium fills to capacity for the AFL Grand Final.
Home to the National Sports Museum, the MCG has hosted other major sporting events, including International rules football matches between Australia and Ireland, international rugby union matches, State of Origin series (rugby league), FIFA World Cup qualifiers and international friendly matches. Concerts and other cultural events are also held at the venue.
Until the 1970s, more than 120,000 people sometimes crammed into the MCG—the record crowd standing at around 130,000 for a Billy Graham evangelistic crusade in 1959, followed by 121,696 for the 1970 VFL Grand Final. Grandstand redevelopments and occupational health and safety legislation have now limited the maximum seating capacity to approximately 95,000 with an additional 5000 standing room capacity, bringing the total capacity to 100,024.
The MCG is listed on the Victorian Heritage Register and was included on the Australian National Heritage List in 2005. Journalist Greg Baum called it "a shrine, a citadel, a landmark, a totem" that "symbolises Melbourne to the world".
Early history.
Founded in November 1838 the Melbourne Cricket Club (MCC) selected the current MCG site in 1853 after previously playing at several grounds around Melbourne. The club’s first game was against a military team at the Old Mint site, at the corner of William and Latrobe Streets. Burial Hill (now Flagstaff railway station) became its home ground in January 1839, but the area was already set aside for Botanical Gardens and the club was moved on in October 1846, to an area on the south bank of the Yarra about where the Herald and Weekly Times building is today. The area was subject to flooding, forcing the club to move again, this time to a ground in South Melbourne.
It was not long before the club was forced out again, this time because of the expansion of the railway. The South Melbourne ground was in the path of Victoria’s first steam railway line from Melbourne to Sandridge (now Port Melbourne). Governor La Trobe offered the MCC a choice of three sites; an area adjacent to the existing ground, a site at the junction of Flinders and Spring Streets or a ten-acre (about 4 hectares) section of the Government Paddock at Richmond next to Richmond Park.
This last option, which is now Yarra Park, had been used by Aborigines until 1835. Between 1835 and 1853 it was an agistment area for colonial troopers’ horses. In 1850 it was part of a stretch set aside for public recreation extending from Governor La Trobe’s Jolimont Estate to the Yarra River. By 1853 it had become a busy promenade for Melbourne residents.
An MCC sub-committee chose the Richmond Park option because it was level enough for cricket but sloped enough to prevent inundation. That ground was located where the Richmond, or outer, end of the current MCG is now.
At the same time the Richmond Cricket Club was given occupancy rights to six acres (2.4 hectares) for another cricket ground on the eastern side of the Government Paddock.
At the time of the land grant the Government stipulated that the ground was to be used for cricket and cricket only. This condition remained until 1933 when the State Government allowed the MCG’s uses to be broadened to include other purposes when not being used for cricket.
In 1863 a corridor of land running diagonally across Yarra Park was granted to the Hobson’s Bay Railway and divided Yarra Park from the river. The area closest to the river was also developed for sporting purposes in later years including Olympic venues in 1956.
Stadium development.
The first grandstand at the MCG was the original wooden members’ stand built in 1854, while the first public grandstand was a 200-metre long 6000-seat temporary structure built in 1861. Another grandstand seating 2000, facing one way to the cricket ground and the other way to the park where football was played, was built in 1876 for the 1877 visit of James Lillywhite's English cricket team. It was during this tour that the MCG hosted the world's first Test match.
In 1881 the original members' stand was sold to the Richmond Cricket Club for £55. A new brick stand, considered at the time to be the world’s finest cricket facility, was built in its place. The foundation stone was laid by Prince George of Wales and Prince Albert Victor on 4 July and the stand opened in December that year. It was also in 1881 that a telephone was installed at the ground, and the wickets and goal posts were changed from an east-west orientation to north-south. In 1882 a scoreboard was built which showed details of the batsman's name and how he was dismissed.
When the Lillywhite tour stand burnt down in 1884 it was replaced by a new stand which seated 450 members and 4500 public. In 1897, second-storey wings were added to ‘The Grandstand’, as it was known, increasing capacity to 9,000. In 1900 it was lit with electric light.
More stands were built in the early 20th century. An open wooden stand was on the south side of the ground in 1904 and the 2084-seat Grey Smith Stand (known as the New Stand until 1912) was erected for members in 1906. The 4000-seat Harrison Stand on the ground’s southern side was built in 1908 followed by the 8000-seat Wardill Stand in 1912. In the 15 years after 1897 the stand capacity at the ground increased to nearly 20,000.
In 1927 the second brick members’ stand was replaced at a cost of £60,000. The Harrison and Wardill Stands were demolished in 1936 to make way for the Southern Stand which was completed in 1937. The Southern Stand seated 18,200 under cover and 13,000 in the open and was the main public area of the MCG. The maximum capacity of the ground under this configuration, as advised by the Health Department, was 84,000 seated and 94,000 standing.
The Northern Stand, also known as the Olympic Stand, was built to replace the old Grandstand for the 1956 Olympic Games. By Health Department regulations, this was to increase the stadium's capacity to 120,000; although this was revised down after the 1956 VFL Grand Final, which could not comfortably accommodate its crowd of 115,802. Ten years later, the Grey Smith Stand and the open concrete stand next to it were replaced by the Western Stand; the Duke of Edinburgh laid a foundation stone for the Western Stand on 3 March 1967, and it was completed in 1968; in 1986, it was renamed the Ponsford Stand in honour of Victorian batsman Bill Ponsford. This was the stadium's highest capacity configuration, and the all-time record crowd for a sporting event at the venue of 121,696 was set under this configuration in the 1970 VFL Grand Final.
The MCG was the home of Australia’s first full colour video scoreboard, which replaced the old scoreboard in 1982, located on Level 4 of the Western Stand. A second video screen added in 1994 almost directly opposite, on Level 4 of the Olympic stand. In 1985, light towers were installed at the ground, allowing for night football and day-night cricket games.
In 1988 inspections of the old Southern Stand found concrete cancer and provided the opportunity to replace the increasingly run-down 50-year-old facility. The projected cost of $100 million was outside what the Melbourne Cricket Club could afford so the Victorian Football League took the opportunity to part fund the project in return for a 30-year deal to share the ground. The new Great Southern Stand was completed in 1992, in time for the 1992 Cricket World Cup, at a final cost of $150 million.
The 1928 Members' stand, the 1956 Olympic stand and the 1968 Ponsford stand were demolished one by one between late 2003 to 2005 and replaced with a new structure in time for the 2006 Commonwealth Games. Despite now standing as a single unbroken stand, the individual sections retain the names of Ponsford, Olympic and Members Stands. The redevelopment cost exceeded 400 million and pushed the ground's capacity to just above 100,000. Since redevelopment, the highest attendance was the 2010 Grand Final of the AFL with 100,016.
From 2011 until 2013, the Victorian Government and the Melbourne Cricket Club funded a $55 million refurbishment of the facilities of Great Southern Stand, including renovations to entrance gates and ticket outlets, food and beverage outlets, "etc.", without significantly modifying the stand. New scoreboards, more than twice the size of the original ones, were installed in the same positions in late 2013.
Cricket.
Early years.
The first cricket match was played on 30 September 1854.
The first inter-colonial cricket match to be played at the MCG was between Victoria and New South Wales in March 1856. Victoria had played Tasmania (then known as Van Diemen's Land) as early as 1851 but the Victorians had included two professionals in the 1853 team upsetting the Tasmanians and causing a cooling of relations between the two colonies. To replace the disgruntled Tasmanians the Melbourne Cricket Club issued a challenge to play any team in the colonies for £1000. Sydney publican William Tunks accepted the challenge on behalf of New South Wales although the Victorians were criticised for playing for money. Ethics aside, New South Wales could not afford the £1000 and only managed to travel to Melbourne after half the team’s travel cost of £181 was put up by Sydney barrister Richard Driver.
The game eventually got under way on 26 March 1856. The Victorians, stung by criticism over the £1000 stake, argued over just about everything; the toss, who should bat first, whether different pitches should be used for the different innings and even what the umpires should wear.
Victoria won the toss but New South Wales captain George Gilbert successfully argued that the visiting team should decide who bats first. The MCG was a grassless desert and Gilbert, considering players fielded without boots, promptly sent Victoria into bat. Needing only 16 to win in the final innings, New South Wales collapsed to be 5 for 5 before Gilbert’s batting saved the game and the visitors won by three wickets.
In subsequent years conditions at the MCG improved but the ever-ambitious Melburnians were always on the lookout for more than the usual diet of club and inter-colonial games. In 1861, Felix William Spiers and Christopher Pond, the proprietors of the Cafe de Paris in Bourke Street and caterers to the MCC, sent their agent, W.B. Mallam, to England to arrange for a cricket team to visit Australia.
Mallam found a team and, captained by Heathfield Stephenson, it arrived in Australia on Christmas Eve 1861 to be met by a crowd of more than 3000 people. The team was taken on a parade through the streets wearing white-trimmed hats with blue ribbons given to them for the occasion. Wherever they went they were mobbed and cheered by crowds to the point where the tour sponsors had to take them out of Melbourne so that they could train undisturbed.
Their first game was at the MCG on New Year’s Day 1862, against a Victorian XVIII. The Englishmen also wore coloured sashes around their waists to identify each player and were presented with hats to shade them from the sun. Some estimates put the crowd at the MCG that day at 25,000. It must have been quite a picture with a new 6000 seat grandstand, coloured marquees ringing the ground and a carnival outside. Stephenson said that the ground was better than any in England. The Victorians however, were no match for the English at cricket and the visitors won by an innings and 96 runs.
Over the four days of the ‘test’ more than 45,000 people attended and the profits for Speirs and Pond from this game alone was enough to fund the whole tour. At that time it was the largest number of people to ever watch a cricket match anywhere in the world. Local cricket authorities went out of their way to cater for the needs of the team and the sponsors. They provided grounds and sponsors booths without charge and let the sponsors keep the gate takings. The sponsors however, were not so generous in return. They quibbled with the Melbourne Cricket Club about paying £175 for damages to the MCG despite a prior arrangement to do so.
The last match of the tour was against a Victorian XXII at the MCG after which the English team planted an elm tree outside the ground.
Following the success of this tour, a number of other English teams also visited in subsequent years. George Parr’s side came out in 1863–64 and there were two tours by sides led by W.G. Grace. The fourth tour was led by James Lillywhite.
On Boxing Day 1866 an Indigenous Australian cricket team played at the MCG with 11,000 spectators against an MCC team. A few players in that match were in a later team that toured England in 1868. Some also played in three other matches at the ground before 1869.
First Test match.
Up until the fourth tour in 1877, led by Lillywhite, touring teams had played first-class games against the individual colonial sides, but Lillywhite felt that his side had done well enough against New South Wales to warrant a game against an All Australian team.
When Lillywhite headed off to New Zealand he left Melbourne cricketer John Conway to arrange the match for their return. Conway ignored the cricket associations in each colony and selected his own Australian team, negotiating directly with the players. Not only was the team he selected of doubtful representation but it was also probably not the strongest available as some players had declined to take part for various reasons. Demon bowler Fred Spofforth refused to play because wicket-keeper Billy Murdoch was not selected. Paceman Frank Allan was at Warnambool Agricultural Show and Australia’s best all-rounder Edwin Evans could not get away from work. In the end only five Australian-born players were selected.
The same could be said for Lillywhite’s team which, being selected from only four counties, meant that some of England’s best players did not take part. In addition, the team had a rough voyage back across the Tasman Sea and many members had been seasick. The game was due to be played on 15 March, the day after their arrival, but most had not yet fully recovered. On top of that, wicket-keeper Ted Pooley was still in a New Zealand prison after a brawl in a Christchurch pub.
England was nonetheless favourite to win the game and the first ever Test match began with a crowd of only 1000 watching. The Australians elected Dave Gregory from New South Wales as Australia’s first ever captain and on winning the toss he decided to bat.
Charles Bannerman scored an unbeaten 165 before retiring hurt. Sydney Cricket Ground curator, Ned Gregory, playing in his one and only Test for Australia, scored Test cricket’s first duck. Australia racked up 245 and 104 while England scored 196 and 108 giving Australia victory by 45 runs. The win hinged on Bannerman’s century and a superb bowling performance by Tom Kendall who took of 7 for 55 in England’s second innings.
A fortnight later there was a return game, although it was really more of a benefit for the English team. Australia included Spofforth, Murdoch and T.J.D. Cooper in the side but this time the honours went to England who won by four wickets.
Two years later Lord Harris brought another England team out and during England’s first innings in the Test at the MCG, Fred Spofforth took the first hat-trick in Test cricket. He bagged two hauls of 6 for 48 and 7 for 62 in Australia’s ten wicket win.
Cricket uses.
Through most of the 20th century, the Melbourne Cricket Ground was one of the two major Test venues in Australia (along with the Sydney Cricket Ground), and it would host one or two Tests in each summer in which Tests were played; since 1982, the Melbourne Cricket Ground has hosted one Test match each summer. Until 1979, the ground almost always hosted its match or one of its matches over the New Year, with the first day's play falling somewhere between 29 December and 1 January; in most years since 1980 and every year since 1995, its test has begun on Boxing Day, and it is now a standard fixture in the Australian cricket calendar and is known as the Boxing Day Test. The venue also hosts one-day international matches each year, and Twenty20 international matches most years. No other venue in Melbourne has hosted a Test, and Docklands Stadium is the only other venue to have hosted a limited-overs international.
The Victorian first-class team plays Sheffield Shield cricket at the venue during the season. Prior to Test cricket being played on Boxing Day, it was a long-standing tradition for Victoria to host New South Wales in a first-class match on Boxing Day. Victoria also played its limited overs matches at the ground. Since the introduction of the domestic Twenty20 Big Bash League (BBL) in 2011, the Melbourne Stars club has played its home matches at the ground. It is also the home ground of the Melbourne Stars Women team, which plays in the Women's Big Bash League (WBBL).
By the 1980s, the integral MCG pitch – grown from Merri Creek black soil – was considered the worst in Australia, in some matches exhibiting wildly inconsistent bounce which could see balls pass through as grubbers or rear dangerously high – a phenomenon which was put down to damage caused by footballers in winter and increased use for cricket during the summers of the 1970s. The integral pitch has since been removed and drop-in pitches have been used since 1996, generally offering consistent bounce and a fair balance between bat and ball.
Highlights and lowlights.
The highest first class team score in history was posted at the MCG in the Boxing Day match against New South Wales in 1926–27. Victoria scored 1107 in two days, with Bill Ponsford scoring 352 and Jack Ryder scoring 295.
One of the most sensational incidents in Test cricket occurred at the MCG during the Melbourne test of the 1954–55 England tour of Australia. Big cracks had appeared in the pitch during a very hot Saturday’s play and on the rest day Sunday, groundsman Jack House watered the pitch to close them up. This was illegal and the story was leaked by The Age newspaper. The teams agreed to finish the match and England won by 128 runs after Frank Tyson took 7 for 27 in the final innings.
An incident in the second Test of the 1960–61 series involved the West Indies player Joe Solomon being given out after his hat fell on the stumps after being bowled at by Richie Benaud. The crowd sided with the West Indies over the Australians.
Not only was the first Test match played at the MCG, the first One Day International match was also played there, on 5 January 1971, between Australia and England. The match was played on what was originally scheduled to have been the fifth day of a Test match, but the Test was abandoned after the first three days were washed out. Australia won the 40-over match by 5 wickets. The next ODI was played on August 1972, some 19 months later.
In March 1977, the Australian Cricket Board assembled 218 of the surviving 224 Australia-England players for a Test match to celebrate 100 years of Test cricket between the two nations. The match was the idea of former Australian bowler and MCC committee member Hans Ebeling who had been responsible for developing the cricket museum at the MCG. The match had everything. England’s Derek Randall scored 174, Australia’s Rod Marsh also got a century, Lillee took 11 wickets, and David Hookes, in his first test, smacked five fours in a row off England captain Tony Greig’s bowling. Rick McCosker who opened for Australia suffered a fractured jaw after being hit by a sharply rising delivery. He left the field but came back in the second innings with his head swathed in bandages. Australia won the match by 45 runs, exactly the same margin as the first Test in 1877.
Another incident occurred on 1 February 1981 at the end of a one-day match between Australia and New Zealand. New Zealand, batting second, needed six runs off the last ball of the day to tie the game. Australian captain, Greg Chappell instructed his brother Trevor, who was bowling the last over, to send the last ball down underarm to prevent the New Zealand batsman, Brian McKechnie, from hitting the ball for six. Although not entirely in the spirit of the game, an underarm delivery was quite legal, so long as the arm was kept straight. The Laws of cricket have since been changed to prevent such a thing happening again. The incident has long been a sore point between Australia and New Zealand.
In February and March 1985 the Benson & Hedges World Championship of Cricket was played at the MCG, a One Day International tournament involving all of the then Test match playing countries to celebrate 150 years of the Australian state of Victoria. Some matches were also played at Sydney Cricket Ground.
The MCG hosted the 1992 Cricket World Cup final between Pakistan and England with a crowd of more than 87,000. Pakistan won the match after an all-round performance by Wasim Akram who scored 33 runs and picked up 3 crucial wickets to make Pakistan cricket world champions for the first and as yet only time.
During the 1995 Boxing Day Test at the MCG, Australian umpire Darrell Hair called Sri Lankan spin bowler Muttiah Muralitharan for throwing the ball, rather than bowling it, seven times during the match. The other umpires did not call him once and this caused a controversy, although he was later called for throwing by other umpires seven other times in different matches.
The MCG is known for its great atmosphere, much of which is generated in the infamous Bay 13, situated almost directly opposite to the members stand. In the late 1980s, the crowd at Bay 13 would often mimic the warm up stretches performed by Merv Hughes. In a 1999 One-Day International, the behaviour of Bay 13 was so bad that Shane Warne, donning a helmet for protection, had to enter the ground from his dressing rooms and tell the crowd to settle down at the request of opposing England captain Alec Stewart.
The MCG hosted three pool games as part of the 2015 ICC Cricket World Cup as well as a quarter-final, and then the final on 29 March. Australia comfortably defeated New Zealand by seven wickets in front of an Australian record cricket crowd of 93,013.
Australian rules football.
Origins.
Despite being called the Melbourne Cricket Ground, the stadium has been and continues to be used much more often for Australian rules football. Spectator numbers for football are larger than for any other sport in Australia, and it makes more money for the MCG than any of the other sports played there.
Although the Melbourne Cricket Club members were instrumental in founding Australian Rules Football, there were understandable concerns in the early days about the damage that might be done to the playing surface if football was allowed to be played at the MCG. Therefore, football games were often played in the parklands next to the cricket ground, and this was the case for the first documented football match to be played at the ground. The match which today is considered to be the first Australian rules football, played between Scotch College and Melbourne Grammar over three Saturdays beginning 7 August 1858 was played in this area.
It wasn’t until 1869 that football was played on the MCG proper, a trial game involving a police team. It was not for another ten years, in 1879, after the formation of the Victorian Football Association, that the first official match was played on the MCG and the cricket ground itself became a regular venue for football. Two night matches were played on the ground during the year under the newly invented electric light.
In the early years, the MCG was the home ground of Melbourne Football Club, Australia’s oldest club, established in 1858 by the founder of the game itself, Thomas Wills. Melbourne won five premierships during the 1870s using the MCG as its home ground.
The first of nearly 2500 Victorian Football League/Australian Football League games to be played at the MCG was on 15 May 1897, with beating 64 to 19.
Several Australian Football League (AFL) clubs later joined Melbourne in using the MCG as their home ground for matches: (1965), (1985), (1992), (started moving in 1994, became a full-time tenant in 2000) and (2000). Melbourne used the venue as its training base until 1984, before being required to move to preserve the venue's surface when North Melbourne began playing there. Geelong also call the MCG home for some of their Melbourne home games as well as all of their finals matches unless if the MCG is unavailable.
Finals and Grand Finals.
The VFL/AFL Grand Final has been played at the MCG every season since 1902, except in 1924, when no Grand Final was held because of the season's round-robin finals format (it hosted three of the six games in the Finals Series), 1942–1945, when the ground was used by the military during World War II; and in 1991, as the construction of the Great Southern Stand had temporarily reduced the ground’s capacity below that of Waverley Park. All three Grand Final Replays have been played at the MCG.
Before the ground was fully seated, the Grand Final could draw attendances above 110,000. The record for the highest attendance in the history of the sport was set in the 1970 VFL Grand Final, with 121,696 in attendance.
Since being fully seated, Grand Final attendances are typically between 95,000 and 100,000, with the record of 100,016 attending the first 2010 AFL Grand Final (which ended in a draw, requiring a replay).
In the modern era, most finals games held in Melbourne have been played at the MCG. Under the current contract, ten finals (excluding the Grand Final) must be played at the MCG over a five-year period. Under previous contracts, the MCG was entitled to host at least one match in each week of the finals, which on two occasions required a non-Victorian club to play a "home" final in Victoria.
The MCG and the VFL/AFL.
For many years the VFL had an uneasy relationship with the MCG trustees and the Melbourne Cricket Club. Both needed the other, but resented the dependence. The VFL made the first move which brought things to a head by beginning the development of VFL Park at Mulgrave in the 1960s as its own home ground and as a potential venue for future grand finals. Then in 1983, president of the VFL, Alan Aylett started to pressure the MCG Trust to give the VFL a greater share of the money it made from using the ground for football.
In March 1983 the MCG trustees met to consider a submission from Aylett. Aylett said he wanted the Melbourne Cricket Club’s share of revenue cut from 15 per cent to 10 per cent. He threatened to take the following day’s opening game of the season, Collingwood vs Melbourne, away from the MCG. The money was held aside until an agreement could be reached.
Different deals, half deals and possible deals were done over the years, with the Premier of Victoria, John Cain, Jr., even becoming involved. Cain was said to have promised the VFL it could use the MCG for six months of the year and then hand it back to the MCC, but this never eventuated, as the MCG Trust did not approve it. In the mid-1980s, a deal was done where the VFL was given its own members area in the Southern Stand.
Against this background of political manoeuvring, in 1985 became the third club to make the MCG its home ground. In the same year, North played in the first night football match at the MCG for almost 110 years, against Collingwood on 29 March 1985.
In 1986, only a month after Ross Oakley had taken over as VFL Commissioner, VFL executives met with the MCC and took a big step towards resolving their differences. Changes in the personnel at the MCC also helped. In 1983 John Lill was appointed secretary and Don Cordner its president.
Shortly after the Southern Stand opened in 1992, the Australian Football League moved its headquarters into the complex. The AFL assisted with financing the new stand and came to an agreement that ensures at least 45 AFL games are played at the MCG each year, including the Grand Final in September. Another 45 days of cricket are also played there each year and more than 3.5 million spectators come to watch every year.
As of the end of 2011, Matthew Richardson holds the records for having scored the most goals on the MCG, and Kevin Bartlett holds the record for playing the most matches at the MCG. Two players have scored 14 goals for an AFL or VFL game in one match at the MCG: Gary Ablett, Sr. in 1989 and 1993, and John Longmire in 1990.
Before an AFL match between and on 27 August 1999, the city end scoreboard caught on fire due to an electrical fault, causing the start of play to be delayed by half an hour.
World War II.
During World War II, the government requisitioned the MCG for military use. From 1942 until 1945 it was occupied by (in order): the United States Army Air Forces, the Royal Australian Air Force, the United States Marine Corps and again the RAAF. Over the course of the war, more than 200,000 personnel were barracked at the MCG. From April to October 1942, the US Army’s Fifth Air Force occupied the ground, naming it "Camp Murphy", in honor of officer Colonel William Murphy, a senior USAAF officer killed in Java. In 1943 the MCG was home to the legendary First Regiment of the First Division of the United States Marine Corps. The First Marine Division were the heroes of the Guadalcanal campaign and used the "cricket grounds", as the marines referred to it, to rest and recuperate. On 14 March 1943 the marines hosted a giant "get together" of American and Australian troops on the arena.
In 1977, Melbourne Cricket Club president Sir Albert Chadwick and Medal of Honor recipient, Colonel Mitchell Paige, unveiled a commemorative plaque recognizing the Americans' time at the ground.
In episode 3 of the 2010 TV miniseries, "The Pacific", members of the US Marines are shown to be camped in the war-era MCG.
Olympic Games.
The MCG’s most famous moment in history was as the main stadium for the 1956 Olympic Games. The MCG was only one of seven possible venues, including the Melbourne Showgrounds, for the Games’ main arena. The MCG was the Federal Government’s preferred venue but there was resistance from the MCC. The inability to decide on the central venue nearly caused the Games to be moved from Melbourne. Prime Minister Robert Menzies recognised the potential embarrassment to Australia if this happened and organised a three-day summit meeting to thrash things out. Attending was Victorian Premier John Cain, Sr., the Prime Minister, deputy opposition leader Arthur Calwell, all State political leaders, civic leaders, Olympic officials and trustees and officials of the MCC. Convening the meeting was no small effort considering the calibre of those attending and that many of the sports officials were only part-time amateurs.
As 22 November, the date of the opening ceremony, drew closer, Melbourne was gripped ever more tightly by Olympic fever. At 3 pm the day before the opening ceremony, people began to line up outside the MCG gates. That night the city was paralysed by a quarter of a million people who had come to celebrate.
The MCG's capacity was increased by the new Olympic (or Northern) Stand, and on the day itself 103,000 people filled the stadium to capacity. A young up and coming distance runner was chosen to carry the Olympic torch into the stadium for the opening ceremony.
Although Ron Clarke had a number of junior world records for distances of 1500 m, one mile (1.6 km) and two miles (3 km), he was relatively unknown in 1956. Perhaps the opportunity to carry the torch inspired him because he went on to have a career of exceptional brilliance and was without doubt the most outstanding runner of his day. At one stage he held the world record for every distance from two miles (3 km) to 20 km. His few failures came in Olympic and Commonwealth Games competition. Although favourite for the gold at Tokyo in 1964 he was placed ninth in the 5,000 metres race and the marathon and third in the 10,000 metres. He lost again in the 1966 Commonwealth Games and in 1968 at altitude in Mexico he collapsed at the end of the 10 km race.
On that famous day in Melbourne in 1956 the torch spluttered and sparked, showering Clarke with hot magnesium, burning holes in his shirt. When he dipped the torch into the cauldron it burst into flame singeing him further. In the centre of the ground, John Landy, the fastest miler in the world, took the Olympic oath and sculler Merv Wood carried the Australian flag.
The Melbourne Games also saw the high point of Australian female sprinting with Betty Cuthbert winning three gold medals at the MCG. She won the 100 m and 200 m and anchored the winning 4 x 100 m team. Born in Merrylands in Sydney’s west she was a champion schoolgirl athlete and had already broken the world record for the 200 m just before the 1956 Games. She was to be overshadowed by her Western Suburbs club member, the Marlene Matthews. When they got to the Games, Matthews was the overwhelming favourite especially for the 100 m a distance over which Cuthbert had beaten her just once.
Both Matthews and Cuthbert won their heats with Matthews setting an Olympic record of 11.5 seconds in hers. Cuthbert broke that record in the following heat with a time of 11.4 seconds. The world record of 11.3 was held by another Australian, Shirley Strickland who was eliminated in her heat. In the final Matthews felt she got a bad start and was last at the 50 metre mark. Cuthbert sensed Isabella Daniels from the USA close behind her and pulled out a little extra to win Australia’s first gold at the Games in a time of 11.5 seconds, Matthews was third. The result was repeated in the 200 m final. Cuthbert won her second gold breaking Marjorie Jackson’s Olympic record. Mathews was third again.
By the time the 1956 Olympics came around, Shirley Strickland was a mother of 31 years of age but managed to defend her 80 m title, which she had won in Helsinki four years before, winning gold and setting a new Olympic record.
The sensational incident of the track events was the non-selection of Marlene Matthews in the 4 x 100 m relay. Matthews trained with the relay team up until the selection was made but Cuthbert, Strickland, Fleur Mellor and Norma Croker were picked for the team. There was outrage at the selection which increased when Matthews went on to run third in both the 100 m and 200 m finals. Personally she was devastated and felt that she had been overlooked for her poor baton change. Strickland was disappointed with the way Matthews was treated and maintained it was an opinion held in New South Wales that she had baton problems. One of the selectors, Doris Magee from NSW, said that selecting Matthews increased the risk of disqualification at the change. But Cuthbert maintained that the selectors made the right choice saying that Fleur Mellor was fresh, a specialist relay runner and was better around the curves than Matthews.
The men did not fare so well. The 4 x 400 m relay team, including later IOC Committee member Kevan Gosper, won silver. Charles Porter also won silver in the high jump. Hec Hogan won bronze in the 100 m to become the first Australian man to win a medal in a sprint since the turn of the century and despite injury John Landy won bronze in the 1500 m. Allan Lawrence won bronze in the 10,000 m event.
Apart from athletics, the stadium was also used for the soccer finals, the hockey finals, the Opening and Closing Ceremonies, and an exhibition game of baseball between the Australian National Team and a US armed services team at which an estimated crowd of 114,000 attended. This was the Guinness World Record for the largest attendance for any baseball game, which stood until a 29 March 2008 exhibition game between the Boston Red Sox and Los Angeles Dodgers at the Los Angeles Coliseum (also a former Olympic venue) drawing 115,300.
The MCG was also used for another demonstration sport, Australian Rules. The Olympics being an amateur competition meant that only amateurs could play in the demonstration game. A combined team of amateurs from the VFL and VFA were selected to play a state team from the Victorian Amateur Football Association (VAFA). The game was played 7 December 1956 with the VAFA side, wearing white jumpers, green collars and the Olympic rings on their chests, winning easily 81 to 55.
The MCG’s link with its Olympic past continues to this day. Within its walls is the IOC-endorsed Australian Gallery of Sport and Olympic Museum.
Forty-four years later at the 2000 Summer Olympics in Sydney, the Grounds served as host to several football preliminaries, making it one of a few venues ever used for more than one Olympics. It is quite possible the ground may be one of the first to be used in three Olympic games, as Melbourne's Lord Mayor Robert Doyle, and Premier Ted Ballieu are considering bidding for either the 2028 or 2032 Olympic games, using the MCG as a selling point.
Commonwealth Games.
The Opening and Closing Ceremonies of the 2006 Commonwealth Games were held at the MCG, as well as athletics events during the games. The games began on 15 March and ended on 26 March.
Rugby union.
The first game of Rugby Union to be played on the ground was on Saturday, 29 June 1878, when the Waratah Club of Sydney played Carlton Football Club in a return of the previous year’s contests in Sydney where the clubs had competed in both codes of football. The match, watched by a crowd of between 6,000 and 7,000 resulted in a draw; one goal and one try being awarded to each team.
The next Rugby match was held on Wednesday 29 June 1881, when the Wanderers, a team organised under the auspices of the Melbourne Cricket Club, played a team representing a detached Royal Navy squadron then visiting Melbourne. The squadron team won by one goal and one try to nil.
It was not until 19 August 1899 that the MCG was again the venue for a Union match, this time Victoria v the British Lions (as they were later to be called). During the preceding week the Victorians had held several trial and practice matches there, as well as several training sessions, despite which they were defeated
30-0 on the day before a crowd of some 7,000.
Nine years later, on Monday, 10 August 1908, Victoria was again the host, this time to the Australian team en route to Great Britain and soon to be dubbed the First Wallabies. Despite being held on a working day some 1,500 spectators attended to see the visitors win by 26-6.
On Saturday, 6 July 1912 the MCG was the venue, for the only time ever, of a match between two Victorian Rugby Union clubs, Melbourne and East Melbourne, the former winning 9-5 in what was reported to be ‘... one of the finest exhibitions of the Rugby game ever seen in Victoria.’ It was played before a large crowd as a curtain raiser to a State Rules match against South Australia.
On Saturday 18 June 1921, in another curtain raiser, this time to a Melbourne-Fitzroy League game, a team representing Victoria was soundly beaten 51-0 by the South African Springboks in front of a crowd of 11,214 
It was nine years later, on Saturday 13 September 1930, that the British Lions returned to play Victoria, again before a crowd of 7,000, this time defeating the home side 41-36, a surprisingly narrow winning margin. 
The first post war match at the MCG was on 21 May 1949 when the NZ Maoris outclassed a Southern States side 35-8 before a crowd of close to 10,000. A year later, on 29 July 1950, for the first and only time, Queensland travelled to Victoria to play an interstate match, defeating their hosts 31-12 before a crowd of 7,479. 
In the following year the MCG was the venue for a contest between the New Zealand All Blacks and an Australian XV . This was on 30 June 1951 before some 9,000 spectators and resulted in a convincing 56-11 win for the visitors.
Union did not return the MCG until the late 1990, for several night time Test matches, both Australia v New Zealand All Blacks as part of the Tri Nations Series. The first, on Saturday 26 July 1997, being notable for an attendance of 90,119, the visitors winning 33-18 and the second, on Saturday 11 July 1998, for a decisive victory to Australia of 24-16. Australia and New Zealand met again at the MCG during the 2007 Tri Nations Series on 30 June, the hosts again winning, this time by 20 points to 15 in from of a crowd of 79,322. 
Rugby league.
Rugby league was first played at the ground on 15 August 1914, with the New South Wales team losing to England 15–21.
The first ever State of Origin match at the MCG (and second in Melbourne) was Game II of the 1994 series, and the attendance of 87,161 set a new record rugby league crowd in Australia. The MCG was also the venue for Game II of the 1995 State of Origin series and drew 52,994, the most of any game that series. The second game of the 1997 State of Origin series, which, due to the Super League war only featured Australian Rugby League-signed players, was played there too, but only attracted 25,105, the lowest in a series that failed to attract over 35,000 to any game.
The Melbourne Storm played two marquee games at the MCG in 2000. This was the first time that they had played outside of their normal home ground of Olympic Park Stadium which holds 18,500 people.
Their first game was held on 3 March 2000 against the St. George Illawarra Dragons in a rematch of the infamous 1999 Grand Final. Anthony Mundine said they were 'not worthy premiers' and the Storm responded by running in 12 tries to two and winning 70–10 in front of 23,239 fans. This was their biggest crowd they had played against until 33,427 turned up to the 2007 Preliminary Final at Docklands Stadium. The record home and away crowd record has also been overhauled, when a match at Docklands in 2010 against St George attracted 25,480 spectators.
Their second game attracted only 15,535 spectators and was up against the Cronulla Sharks on 24 June 2000. Once again, the Storm won 22–16.
It was announced in June 2014 that the ground will host its first State of Origin match since 1997. Game II of the 2015 series was played at the venue, with an all-time record State of Origin crowd of 91,513 attending the match.
Soccer.
On 9 February 2006, the then Victorian premier Steve Bracks and Football Federation Australia chairman Frank Lowy announced that the MCG would host a world class football event each year from 2006 until 2009 inclusive. The announcement came as the game gained further popularity in the country following the qualification for the 2006 FIFA World Cup in Germany.
The agreement sees an annual fixture at the MCG, beginning with a clash between Australia and European champions Greece on 25 May 2006 in front of a sell-out crowd of 95,103, before Australia left to contest in the World Cup finals. Australia beat Greece 1–0. The Socceroos also hosted a match in 2007 against Argentina, losing 1–0, as well as 2010 FIFA World Cup qualification matches in 2009 against Asian Football heavyweights (Japan) which attracted 81,872 fans as Australia beat Japan 2–1 via 2 Tim Cahill trademark headers after falling behind 1–0 late in the 1st half.
In 2010 it was announced that as a warm up to the 2010 FIFA World Cup which the Australians had qualified for, they would play fellow qualified nation New Zealand on 24 May at the MCG.
Other matches played at the MCG include the following:
Tennis.
In 1878 the Melbourne Cricket Club’s Lawn Tennis Committee laid an asphalt court at the MCG and Victoria’s first game of tennis was played there. A second court of grass was laid in 1879 and the first Victorian Championship played on it in 1880. The first inter-colonial championship was played in 1883 and the first formal inter-state match between NSW and Victoria played in 1884 with Victoria winning.
In 1889 the MCC arranged for tennis to be played at the Warehousemen’s Cricket Ground (now known as the Albert Cricket Ground), at Albert Park, rather than at the MCG.
Cycling.
It was at the MCG in 1869 that Australia’s first bicycle race was held. The event was for velocipedes, crude wooden machines with pedals on the front wheels. In 1898 the Austral Wheel Race was held at the MCG attracting a crowd of 30,000 to see cyclists race for a total of £200 in prize money.
Records.
VFL/AFL Records.
"Last updated: 21 July 2015"
Statues.
Outside of the MCG are statues of famous Australian athletes donated by Tattersalls and known as the "Parade of Champions", including many Australian rules football and cricket legends.
They include:
The MCC, in association with Australia Post, commissioned five statues for the "Australia Post Avenue of Legends". Three have been erected so far:
A statue is also planned for cricket player Neil Harvey.

</doc>
<doc id="19766" url="https://en.wikipedia.org/wiki?curid=19766" title="Marshall Plan">
Marshall Plan

The Marshall Plan (officially the European Recovery Program, ERP) was an American initiative to aid Western Europe, in which the United States gave $13 billion (approximately $130 billion in current dollar value as of March 2016) in economic support to help rebuild Western European economies after the end of World War II. The plan was in operation for four years beginning April 8th 1948. The goals of the United States were to rebuild war-devastated regions, remove trade barriers, modernize industry, make Europe prosperous again, and prevent the spread of communism. The Marshall Plan required a lessening of interstate barriers, a dropping of many regulations, and encouraged an increase in productivity, labour union membership, as well as the adoption of modern business procedures.
The Marshall Plan aid was divided amongst the participant states roughly on a per capita basis. A larger amount was given to the major industrial powers, as the prevailing opinion was that their resuscitation was essential for general European revival. Somewhat more aid per capita was also directed towards the Allied nations, with less for those that had been part of the Axis or remained neutral. The largest recipient of Marshall Plan money was the United Kingdom (receiving about 26% of the total), followed by France (18%) and West Germany (11%). Some 18 European countries received Plan benefits. Although offered participation, the Soviet Union refused Plan benefits, and also blocked benefits to Eastern Bloc countries, such as East Germany and Poland. The United States provided similar aid programs in Asia, but they were not called "Marshall Plan".
The initiative is named after Secretary of State George Marshall. The plan had bipartisan support in Washington, where the Republicans controlled Congress and the Democrats controlled the White House with Harry S. Truman as president. The Plan was largely the creation of State Department officials, especially William L. Clayton and George F. Kennan, with help from the Brookings Institution, as requested by Senator Arthur H. Vandenberg, chairman of the Senate Foreign Relations Committee. Marshall spoke of an urgent need to help the European recovery in his address at Harvard University in June 1947. The purpose of the Marshall Plan was to aid in the economic recovery of nations after WWII as well as to antagonize the Soviet Union. In order to combat the effects of the Marshall Plan, the USSR developed its own economic plan, known as the Molotov Plan.
The phrase "equivalent of the Marshall Plan" is often used to describe a proposed large-scale economic rescue program.
Development and deployment.
The reconstruction plan, developed at a meeting of the participating European states, was drafted on June 5, 1947. It offered the same aid to the Soviet Union and its allies, but they refused to accept it, as to do so would be to allow a degree of US control over the Communist economies. In fact, the Soviet Union even prevented its satellite states (i.e. East Germany, Poland, etc.) from accepting. Secretary Marshall became convinced that Stalin had absolutely no interest in helping restore economic health in Western Europe. President Harry Truman signed the Marshall Plan on April 3, 1948, granting $5 billion in aid to 16 European nations. During the four years that the plan was operational, US donated $13 billion in economic and technical assistance to help the recovery of the European countries that had joined in the Organization for European Economic Co-operation. In 2013, the equivalent sum reflecting currency inflation since 1948 totalled roughly $148 billion. The $13 billion was in the context of a US GDP of $258 billion in 1948, and was on top of $13 billion in American aid to Europe between the end of the war and the start of the Plan that is counted separately from the Marshall Plan. The Marshall Plan was replaced by the Mutual Security Plan at the end of 1951; that new plan gave away about $7 billion annually until 1961 when it in turn was replaced by a new program.
The ERP addressed each of the obstacles to postwar recovery. The plan looked to the future, and did not focus on the destruction caused by the war. Much more important were efforts to modernize European industrial and business practices using high-efficiency American models, reducing artificial trade barriers, and instilling a sense of hope and self-reliance.
By 1952, as the funding ended, the economy of every participant state had surpassed pre-war levels; for all Marshall Plan recipients, output in 1951 was at least 35% higher than in 1938. Over the next two decades, Western Europe enjoyed unprecedented growth and prosperity, but economists are not sure what proportion was due directly to the ERP, what proportion indirectly, and how much would have happened without it. A common American interpretation of the program's role in European recovery is the one expressed by Paul Hoffman, head of the Economic Cooperation Administration, in 1949, when he told Congress that Marshall aid had provided the "critical margin" on which other investment needed for European recovery depended. The Marshall Plan was one of the first elements of European integration, as it erased trade barriers and set up institutions to coordinate the economy on a continental level—that is, it stimulated the total political reconstruction of western Europe.
Belgian economic historian Herman Van der Wee concludes the Marshall Plan was a "great success":
Wartime destruction.
By the end of World War II, much of Europe was devastated. Sustained aerial bombardment during the war had badly damaged most major cities, and industrial facilities were especially hard-hit. The region's trade flows had been thoroughly disrupted; millions were in refugee camps living on aid from United Nations Relief and Rehabilitation Administration and other agencies. Food shortages were severe, especially in the harsh winter of 1946–1947. From July 1945 through June 1946, the United States shipped 16.5 million tons of food, primarily wheat, to Europe and Japan. It amounted to 1/6 of the American food supply, and provided 35 trillion calories, enough to provide 400 calories a day for one year to 300 million people.
Especially damaged was transportation infrastructure, as railways, bridges, and docks had been specifically targeted by air strikes, while much merchant shipping had been sunk. Although most small towns and villages had not suffered as much damage, the destruction of transportation left them economically isolated. None of these problems could be easily remedied, as most nations engaged in the war had exhausted their treasuries in the process.
The only major powers whose infrastructure had not been significantly harmed in World War II were the United States and Canada. They were much more prosperous than before the war but exports were a small factor in their economy. Much of the Marshall Plan aid would be used by the Europeans to buy manufactured goods and raw materials from the United States and Canada.
Initial post-war events.
Slow recovery.
Europe's economies were recovering slowly, as unemployment and food shortages led to strikes and unrest in several nations. In 1947 the European economies were still well below their pre-war levels and were showing few signs of growth. Agricultural production was 83% of 1938 levels, industrial production was 88%, and exports only 59%. In Britain the situation was not as severe.
In Germany in 1945–46 housing and food conditions were bad, as the disruption of transport, markets and finances slowed a return to normality. In the West, bombing had destroyed 5,000,000 houses and apartments, and 12,000,000 refugees from the east had crowded in. Food production was only two-thirds of the pre-war level in 1946–48, while normal grain and meat shipments no longer arrived from the East. The drop in food production can be attributed to a drought that killed a major portion of the wheat crop while a severe winter destroyed the majority of the wheat crop the following year. This caused most Europeans to rely on a 1,500 calorie per day diet. Furthermore, the large shipments of food stolen from occupied nations during the war no longer reached Germany. Industrial production fell more than half and reached pre-war levels only at the end of 1949.
While Germany struggled to recover from the destruction of the War, the recovery effort began in June 1948, moving on from emergency relief. The currency reform in 1948 was headed by the military government and helped Germany to restore stability by encouraging production. The reform revalued old currency and deposits and introduced new currency. Taxes were also reduced and Germany prepared to remove economic barriers.
During the first three years of occupation of Germany the UK and US vigorously pursued a military disarmament program in Germany, partly by removal of equipment but mainly through an import embargo on raw materials, part of the Morgenthau Plan approved by President Franklin D. Roosevelt.
Nicholas Balabkins concludes that "as long as German industrial capacity was kept idle the economic recovery of Europe was delayed." By July 1947 Washington realized that economic recovery in Europe could not go forward without the reconstruction of the German industrial base, deciding that an "orderly, prosperous Europe requires the economic contributions of a stable and productive Germany." In addition, the strength of Moscow-controlled communist parties in France and Italy worried Washington.
In the view of the State Department under President Harry S Truman, the United States needed to adopt a definite position on the world scene or fear losing credibility. The emerging doctrine of containment (as opposed to rollback) argued that the United States needed to substantially aid non-communist countries to stop the spread of Soviet influence. There was also some hope that the Eastern Bloc nations would join the plan, and thus be pulled out of the emerging Soviet bloc, but that did not happen.
In January 1947, Truman appointed retired General George Marshall as Secretary of State. In July 1947 Marshall scrapped Joint Chiefs of Staff Directive 1067 implemented as part of the Morgenthau Plan under the personal supervision of Roosevelt's treasury secretary Henry Morgenthau, Jr., which had decreed "take no steps looking toward the economic rehabilitation of Germany designed to maintain or strengthen the German economy." Thereafter, JCS 1067 was supplanted by JCS 1779, stating that "an orderly and prosperous Europe requires the economic contributions of a stable and productive Germany." The restrictions placed on German heavy industry production were partly ameliorated; permitted steel production levels were raised from 25% of pre-war capacity to a new limit placed at 50% of pre-war capacity.
With a Communist insurgency threatening Greece, and Britain financially unable to continue its aid, the President announced his Truman Doctrine on 12 March 1947, "to support free peoples who are resisting attempted subjugation by armed minorities or by outside pressures", with an aid request for consideration and decision, concerning Greece and Turkey. Also in March 1947, former US President Herbert Hoover, in one of his reports from Germany, argued for a change in US occupation policy, amongst other things stating:
There is the illusion that the New Germany left after the annexations can be reduced to a 'pastoral state' (Morgenthau's vision). It cannot be done unless we exterminate or move 25,000,000 people out of it.
Hoover further noted that, "The whole economy of Europe is interlinked with German economy through the exchange of raw materials and manufactured goods. The productivity of Europe cannot be restored without the restoration of Germany as a contributor to that productivity." Hoover's report led to a realization in Washington that a new policy was needed; "almost any action would be an improvement on current policy." In Washington, the Joint Chiefs declared that the "complete revival of German industry, particularly coal mining" was now of "primary importance" to American security.
The United States was already spending a great deal to help Europe recover. Over $14 billion was spent or loaned during the postwar period through the end of 1947, and is not counted as part of the Marshall Plan. Much of this aid was designed to restore infrastructure and help refugees. Britain, for example, received an emergency loan of $3.75 billion.
The United Nations also launched a series of humanitarian and relief efforts almost wholly funded by the United States. These efforts had important effects, but they lacked any central organization and planning, and failed to meet many of Europe's more fundamental needs. Already in 1943, the United Nations Relief and Rehabilitation Administration (UNRRA) was founded to provide relief to areas liberated from Germany. UNRRA provided billions of dollars of rehabilitation aid, and helped about 8 million refugees. It ceased operation of displaced persons camps in Europe in 1947; many of its functions were transferred to several UN agencies.
Soviet negotiations.
After Marshall's appointment in January 1947, administration officials met with Soviet Foreign Minister Vyacheslav Molotov and others to press for an economically self-sufficient Germany, including a detailed accounting of the industrial plants, goods and infrastructure already removed by the Soviets in their occupied zone. Molotov refrained from supplying accounts of Soviet assets. The Soviets took a punitive approach, pressing for a delay rather than an acceleration in economic rehabilitation, demanding unconditional fulfillment of all prior reparation claims, and pressing for progress toward nationwide socioeconomic transformation.
After six weeks of negotiations, Molotov rejected all of the American and British proposals. Molotov also rejected the counter-offer to scrap the British-American "Bizonia" and to include the Soviet zone within the newly constructed Germany. Marshall was particularly discouraged after personally meeting with Stalin to explain that the United States could not possibly abandon its position on Germany, while Stalin expressed little interest in a solution to German economic problems.
Marshall's speech.
After the adjournment of the Moscow conference following six weeks of failed discussions with the Soviets regarding a potential German reconstruction, the United States concluded that a solution could not wait any longer.
To clarify the US's position, a major address by Secretary of State George Marshall was planned. Marshall gave the address to the graduating class of Harvard University on June 5, 1947. Standing on the steps of Memorial Church in Harvard Yard, he offered American aid to promote European recovery and reconstruction. The speech described the dysfunction of the European economy and presented a rationale for US aid.
The modern system of the division of labor upon which the exchange of products is based is in danger of breaking down. ... Aside from the demoralizing effect on the world at large and the possibilities of disturbances arising as a result of the desperation of the people concerned, the consequences to the economy of the United States should be apparent to all. It is logical that the United States should do whatever it is able to do to assist in the return of normal economic health to the world, without which there can be no political stability and no assured peace. Our policy is not directed against any country, but against hunger, poverty, desperation and chaos. Any government that is willing to assist in recovery will find full co-operation on the part of the USA.
Its purpose should be the revival of a working economy in the world so as to permit the emergence of political and social conditions in which free institutions can exist.
Marshall was convinced that economic stability would provide political stability in Europe. He offered aid, but the European countries had to organize the program themselves.
The speech, written by Charles Bohlen, contained virtually no details and no numbers. More a proposal than a plan, it was a challenge to European leaders to cooperate and coordinate. It asked Europeans to create their own plan for rebuilding Europe, indicating the United States would then fund this plan. The administration felt that the plan would likely be unpopular among many Americans, and the speech was mainly directed at a European audience. In an attempt to keep the speech out of American papers journalists were not contacted, and on the same day Truman called a press conference to take away headlines. In contrast, Dean Acheson, an Under Secretary of State, was dispatched to contact the European media, especially the British media, and the speech was read in its entirety on the BBC.
Rejection by the Soviets.
British Foreign Secretary Ernest Bevin heard Marshall's radio broadcast speech and immediately contacted French Foreign Minister Georges Bidault to begin preparing a quick European response to (and acceptance of) the offer, which led to the creation of the Committee of European Economic Co-operation. The two agreed that it would be necessary to invite the Soviets as the other major allied power. Marshall's speech had explicitly included an invitation to the Soviets, feeling that excluding them would have been a sign of distrust. State Department officials, however, knew that Stalin would almost certainly not participate, and that any plan that would send large amounts of aid to the Soviets was unlikely to be approved by Congress.
Initial reactions.
While the Soviet ambassador in Washington suspected that the Marshall Plan could lead to the creation of an anti-Soviet bloc, Stalin was open to the offer. He directed that—in negotiations to be held in Paris regarding the aid—countries in the Eastern Bloc should not reject economic conditions being placed upon them. Stalin only changed his outlook when he learned that (a) credit would only be extended under conditions of economic cooperation and, (b) aid would also be extended to Germany in total, an eventuality which Stalin thought would hamper the Soviets' ability to exercise influence in western Germany.
Initially, Stalin maneuvered to kill the Plan, or at least hamper it by means of destructive participation in the Paris talks regarding conditions. He quickly realized, however, that this would be impossible after Molotov reported—following his arrival in Paris in July 1947—that conditions for the credit were non-negotiable. Looming as just as large a concern was the Czechoslovak eagerness to accept the aid, as well as indications of a similar Polish attitude.
Stalin suspected a possibility that these Eastern Bloc countries might defy Soviet directives not to accept the aid, potentially causing a loss of control of the Eastern Bloc. In addition, the most important condition was that every country choosing to take advantage of the plan would need to have its economic situation independently assessed—a level of scrutiny to which the Soviets could not agree. Bevin and Bidault also insisted that any aid be accompanied by the creation of a unified European economy, something incompatible with the strict Soviet command economy.
Compulsory Eastern Bloc rejection.
Soviet Foreign Minister Vyacheslav Molotov left Paris, rejecting the plan. Thereafter, statements were made suggesting a future confrontation with the West, calling the United States both a "fascizing" power and the "center of worldwide reaction and anti-Soviet activity," with all U.S.-aligned countries branded as enemies. The Soviets also then blamed the United States for communist losses in elections in Belgium, France and Italy months earlier, in the spring of 1947. It claimed that "marshallization" must be resisted and prevented by any means, and that French and Italian communist parties were to take maximum efforts to sabotage the implementation of the Plan. In addition, Western embassies in Moscow were isolated, with their personnel being denied contact with Soviet officials.
On July 12, a larger meeting was convened in Paris. Every country of Europe was invited, with the exceptions of Spain (a World War II neutral that had sympathized with Axis powers) and the small states of Andorra, San Marino, Monaco, and Liechtenstein. The Soviet Union was invited with the understanding that it would likely refuse. The states of the future Eastern Bloc were also approached, and Czechoslovakia and Poland agreed to attend. In one of the clearest signs of Soviet control over the region, the Czechoslovakian foreign minister, Jan Masaryk, was summoned to Moscow and berated by Stalin for thinking of joining the Marshall Plan. Polish Prime minister Józef Cyrankiewicz was rewarded by Stalin for the Polish rejection of the Plan. Russia rewarded Poland with a lucrative five-year trade agreement, the equivalent of 450 million 1948 dollars ($4.4 billion in 2014 dollars) in credit, 200,000 tons of grain, heavy machinery, and factories.
The Marshall Plan participants were not surprised when the Czechoslovakian and Polish delegations were prevented from attending the Paris meeting. The other Eastern Bloc states immediately rejected the offer. Finland also declined in order to avoid antagonizing the Soviets (see also Finlandization). The Soviet Union's "alternative" to the Marshall plan, which was purported to involve Soviet subsidies and trade with western Europe, became known as the Molotov Plan, and later, the COMECON. In a 1947 speech to the United Nations, Soviet deputy foreign minister Andrei Vyshinsky said that the Marshall Plan violated the principles of the United Nations. He accused the United States of attempting to impose its will on other independent states, while at the same time using economic resources distributed as relief to needy nations as an instrument of political pressure.
Yugoslavia.
Although all other Communist European Countries had deferred to Stalin and rejected the aid, the Yugoslavs, led by Josip Tito, at first went along and rejected the Marshall plan. However, in 1948 Tito broke decisively with Stalin on other issues, making Yugoslavia an independent communist state. Yugoslavia requested American aid. American leaders were internally divided, but finally agreed and began sending money on a small scale in 1949, and on a much larger scale in 1950-53. The American aid was not part of the Marshall plan.
Szklarska Poręba meeting.
In late September, the Soviet Union called a meeting of nine European Communist parties in southwest Poland. A Communist Party of the Soviet Union (CPSU) report was read at the outset to set the heavily anti-Western tone, stating now that "international politics is dominated by the ruling clique of the American imperialists" which have embarked upon the "enslavement of the weakened capitalist countries of Europe". Communist parties were to struggle against the U.S. presence in Europe by any means necessary, including sabotage. The report further claimed that "reactionary imperialist elements throughout the world, particularly in the U.S.A., in Britain and France, had put particular hope on Germany and Japan, primarily on Hitlerite Germany—first as a force most capable of striking a blow at the Soviet Union".
Referring to the Eastern Bloc, the report stated that "the Red Army's liberating role was complemented by an upsurge of the freedom-loving peoples' liberation struggle against the fascist predators and their hirelings." It argued that "the bosses of Wall Street" were "tak the place of Germany, Japan and Italy". The Marshall Plan was described as "the American plan for the enslavement of Europe". It described the world now breaking down "into basically two camps—the imperialist and antidemocratic camp on the one hand, and the antiimperialist and democratic camp on the other".
Although the Eastern Bloc countries except Czechoslovakia had immediately rejected Marshall Plan aid, Eastern Bloc communist parties were blamed for permitting even minor influence by non-communists in their respective countries during the run up to the Marshall Plan. The meeting's chair, Andrei Zhdanov, who was in permanent radio contact with the Kremlin from whom he received instructions, also castigated communist parties in France and Italy for collaboration with those countries' domestic agendas. Zhdanov warned that if they continued to fail to maintain international contact with Moscow to consult on all matters, "extremely harmful consequences for the development of the brother parties' work" would result.
Italian and French communist leaders were prevented by party rules from pointing out that it was actually Stalin who had directed them not to take opposition stances in 1944. The French communist party, as others, was then to redirect its mission to "destroy capitalist economy" and that the Soviet Communist Information Bureau (Cominform) would take control of the French Communist Party's activities to oppose the Marshall Plan. When they asked Zhdanov if they should prepare for armed revolt when they returned home, he did not answer. In a follow-up conversation with Stalin, he explained that an armed struggle would be impossible and that the struggle against the Marshall Plan was to be waged under the slogan of national independence.
Negotiations.
Turning the plan into reality required negotiations among the participating nations, and to get the plan through the United States Congress. Sixteen nations met in Paris to determine what form the American aid would take, and how it would be divided. The negotiations were long and complex, with each nation having its own interests. France's major concern was that Germany not be rebuilt to its previous threatening power. The Benelux countries (Belgium, Netherlands and Luxemburg), despite also suffering under the Nazis, had long been closely linked to the German economy and felt their prosperity depended on its revival. The Scandinavian nations, especially Sweden, insisted that their long-standing trading relationships with the Eastern bloc nations not be disrupted and that their neutrality not be infringed.
The United Kingdom insisted on special status as a longstanding belligerent during the war, concerned that if it were treated equally with the devastated continental powers it would receive virtually no aid. The Americans were pushing the importance of free trade and European unity to form a bulwark against communism. The Truman administration, represented by William L. Clayton, promised the Europeans that they would be free to structure the plan themselves, but the administration also reminded the Europeans that implementation depended on the plan's passage through Congress. A majority of Congress members were committed to free trade and European integration, and were hesitant to spend too much of the money on Germany. However, before the Marshall Plan was in effect, France, Austria, and Italy needed immediate aid. On December 17, 1947, the United States agreed to give $40 million to France, Austria, China, and Italy.
Agreement was eventually reached and the Europeans sent a reconstruction plan to Washington, which was formulated and agree upon by the Committee of European Economic Co-operation in 1947. In the document the Europeans asked for $22 billion in aid. Truman cut this to $17 billion in the bill he put to Congress. The plan encountered sharp opposition in Congress, mostly from the portion of the Republican Party led by Robert A. Taft that advocated a more isolationist policy and was weary of massive government spending. The plan also had opponents on the left, Henry A. Wallace notably among them. Wallace saw the plan as a subsidy for American exporters and sure to polarize the world between East and West.
Wallace, the former vice president and secretary of agriculture, mockingly called this the "Martial Plan", arguing that it was just another step towards war. However, opposition against the Marshall Plan was greatly reduced by the shock of the Communist coup in Czechoslovakia in February 1948. Soon after, a bill granting an initial $5 billion passed Congress with strong bipartisan support. Congress would eventually allocate $12.4 billion in aid over the four years of the plan.
On March 17, 1948, President Harry S. Truman addressed European security and condemned the Soviet Union before a hastily convened Joint Session of Congress. Attempting to contain spreading Soviet influence in Eastern Bloc, Truman asked Congress to restore a peacetime military draft and to swiftly pass the Economic Cooperation Act, the name given to the Marshall Plan. Of the Soviet Union Truman said, "The situation in the world today is not primarily the result of the natural difficulties which follow a great war. It is chiefly due to the fact that one nation has not only refused to cooperate in the establishment of a just and honorable peace but—even worse—has actively sought to prevent it."
Members of the Republican-controlled 80th Congress (1947–1949) were skeptical. "In effect, he told the Nation that we have lost the peace, that our whole war effort was in vain.", noted Representative Frederick Smith of Ohio. Others thought he had not been forceful enough to contain the USSR. "What said fell short of being tough", noted Representative Eugene Cox, a Democrat from Georgia, "there is no prospect of ever winning Russian cooperation." Despite its reservations, the 80th Congress implemented Truman's requests, further escalating the Cold War with the USSR.
Truman signed the Economic Cooperation Act into law on April 3, 1948; the Act established the Economic Cooperation Administration (ECA) to administer the program. ECA was headed by economic cooperation administrator Paul G. Hoffman. In the same year, the participating countries (Austria, Belgium, Denmark, France, West Germany, the United Kingdom, Greece, Iceland, Ireland, Italy, Luxembourg, the Netherlands, Norway, Sweden, Switzerland, Turkey, and the United States) signed an accord establishing a master financial-aid-coordinating agency, the Organization for European Economic Cooperation (later called the Organization for Economic Cooperation and Development or OECD), which was headed by Frenchman Robert Marjolin.
Implementation.
The first substantial aid went to Greece and Turkey in January 1947, which were seen as the front line of the battle against communist expansion, and were already receiving aid under the Truman Doctrine. Initially, Britain had supported the anti-communist factions in those countries, but due to its dire economic condition it decided to pull out and in February 1947 requested the U.S. to continue its efforts. The ECA formally began operation in July 1948.
The ECA's official mission statement was to give a boost to the European economy: to promote European production, to bolster European currency, and to facilitate international trade, especially with the United States, whose economic interest required Europe to become wealthy enough to import U.S. goods. Another unofficial goal of ECA (and of the Marshall Plan) was the containment of growing Soviet influence in Europe, evident especially in the growing strength of communist parties in Czechoslovakia, France, and Italy.
The Marshall Plan money was transferred to the governments of the European nations. The funds were jointly administered by the local governments and the ECA. Each European capital had an ECA envoy, generally a prominent American businessman, who would advise on the process. The cooperative allocation of funds was encouraged, and panels of government, business, and labor leaders were convened to examine the economy and see where aid was needed.
The Marshall Plan aid was mostly used for the purchase of goods from the United States. The European nations had all but exhausted their foreign exchange reserves during the war, and the Marshall Plan aid represented almost their sole means of importing goods from abroad. At the start of the plan these imports were mainly much-needed staples such as food and fuel, but later the purchases turned towards reconstruction needs as was originally intended. In the latter years, under pressure from the United States Congress and with the outbreak of the Korean War, an increasing amount of the aid was spent on rebuilding the militaries of Western Europe. Of the some $13 billion allotted by mid-1951, $3.4 billion had been spent on imports of raw materials and semi-manufactured products; $3.2 billion on food, feed, and fertilizer; $1.9 billion on machines, vehicles, and equipment; and $1.6 billion on fuel.
Also established were counterpart funds, which used Marshall Plan aid to establish funds in the local currency. According to ECA rules 60% of these funds had to be invested in industry. This was prominent in Germany, where these government-administered funds played a crucial role in lending money to private enterprises which would spend the money rebuilding. These funds played a central role in the reindustrialization of Germany. In 1949–50, for instance, 40% of the investment in the German coal industry was by these funds.
The companies were obligated to repay the loans to the government, and the money would then be lent out to another group of businesses. This process has continued to this day in the guise of the state owned KfW bank, (Kreditanstalt für Wiederaufbau, meaning Reconstruction Credit Institute). The Special Fund, then supervised by the Federal Economics Ministry, was worth over DM 10 billion in 1971. In 1997 it was worth DM 23 billion. Through the revolving loan system, the Fund had by the end of 1995 made low-interest loans to German citizens amounting to around DM 140 billion. The other 40% of the counterpart funds were used to pay down the debt, stabilize the currency, or invest in non-industrial projects. France made the most extensive use of counterpart funds, using them to reduce the budget deficit. In France, and most other countries, the counterpart fund money was absorbed into general government revenues, and not recycled as in Germany.
Technical Assistance Program.
The US Bureau of Labor Statistics (BLS) contributed heavily to the success of the Technical Assistance Program. The United States Congress passed a law on June 7, 1940 that allowed the BLS to "make continuing studies of labor productivity" and appropriated funds for the creation of a Productivity and Technological Development Division. The BLS could then use its expertise in the field of productive efficiency to implement a productivity drive in each Western European country receiving Marshall Plan aid.
By implementing technological literature surveys and organized plant visits, American economists, statisticians, and engineers were able to educate European manufacturers in statistical measurement. The goal of the statistical and technical assistance from the Americans was to increase productive efficiency of European manufacturers in all industries.
In order to perform this analysis, the BLS performed two types of productivity calculations. First, they used existing data to calculate how much a worker produces per hour of work—the average output rate. Second, they compared the existing output rates in a particular country to output rates in other nations. By performing these calculations across all industries, the BLS was able to identify the strengths and weaknesses of each country's manufacturing and industrial production. From that, the BLS could recommend technologies (especially statistical) that each individual nation could implement. Often, these technologies came from the United States; by the time the Technical Assistance Program began, the United States used statistical technologies "more than a generation ahead of what Europeans were using".
The BLS used these statistical technologies to create Factory Performance Reports for Western European nations. The American government sent hundreds of technical advisors to Europe in order to observe workers in the field; this on-site analysis made the Factory Performance Reports especially helpful to the manufacturers. In addition, the Technical Assistance Program funded 24,000 European engineers, leaders, and industrialists to visit America and tour America's factories, mines, and manufacturing plants. This way, the European visitors would be able to return to their home countries and implement the technologies used in the United States. The analyses in the Factory Performance Reports and the "hands-on" experience had by the European productivity teams effectively identified productivity deficiencies in European industries; from there, it became clearer how to make European production more effective.
Before the Technical Assistance Program even went into effect, Maurice Tobin (the United States Secretary of Labor) expressed his confidence in American productivity and technology to both American and European economic leaders. He urged that the United States play a large role in improving European productive efficiency by providing four recommendations for the program's administrators: 
The effects of the Technical Assistance Program were not limited to improvements in productive efficiency. While the thousands of European leaders took their work/study trips to the United States, they were able to observe a number of aspects of American society as well. The Europeans could watch local, state, and federal governments work together with citizens in a pluralist society. They observed a democratic society with open universities and civic societies in addition to more advanced factories and manufacturing plants. The Technical Assistance Program allowed Europeans to bring home many types of American ideas.
Another important aspect of the Technical Assistance Program was its low cost. While $19.4 billion was allocated for capital costs in the Marshall Plan, the Technical Assistance Program only required $300 million. Only one-third of that $300 million cost was paid by the United States.
German level of industry restrictions.
Even while the Marshall Plan was being implemented, the dismantling of German industry continued; and in 1949 Konrad Adenauer wrote to the Allies requesting the end of industrial dismantling, citing the inherent contradiction between encouraging industrial growth and removing factories, and also the unpopularity of the policy. Support for dismantling was by this time coming predominantly from the French, and the Petersberg Agreement of November 1949 greatly reduced the levels of deindustrialization, though dismantling of minor factories continued until 1951. The first "level of industry" plan, signed by the Allies on March 29, 1946, had stated that German heavy industry was to be lowered to 50% of its 1938 levels by the destruction of 1,500 listed manufacturing plants.
In January 1946 the Allied Control Council set the foundation of the future German economy by putting a cap on German steel production. The maximum allowed was set at about 5,800,000 tons of steel a year, equivalent to 25% of the pre-war production level. The UK, in whose occupation zone most of the steel production was located, had argued for a more limited capacity reduction by placing the production ceiling at 12 million tons of steel per year, but had to submit to the will of the U.S., France and the Soviet Union (which had argued for a 3 million ton limit). Steel plants thus made redundant were to be dismantled. Germany was to be reduced to the standard of life it had known at the height of the Great Depression (1932). Consequently, car production was set to 10% of pre-war levels, and the manufacture of other commodities was reduced as well.
The first "German level of industry" plan was subsequently followed by a number of new ones, the last signed in 1949. By 1950, after the virtual completion of the by then much watered-down "level of industry" plans, equipment had been removed from 706 manufacturing plants in western Germany and steel production capacity had been reduced by 6,700,000 tons. Vladimir Petrov concludes that the Allies "delayed by several years the economic reconstruction of the war-torn continent, a reconstruction which subsequently cost the United States billions of dollars." In 1951 West Germany agreed to join the European Coal and Steel Community (ECSC) the following year. This meant that some of the economic restrictions on production capacity and on actual production that were imposed by the International Authority for the Ruhr were lifted, and that its role was taken over by the ECSC.
Expenditures.
The Marshall Plan aid was divided amongst the participant states on a roughly per capita basis. A larger amount was given to the major industrial powers, as the prevailing opinion was that their resuscitation was essential for general European revival. Somewhat more aid per capita was also directed towards the Allied nations, with less for those that had been part of the Axis or remained neutral. The exception was Iceland, which had been neutral during the war, but received far more on a per capita basis than the second highest recipient. The table below shows Marshall Plan aid by country and year (in millions of dollars) from "The Marshall Plan Fifty Years Later." There is no clear consensus on exact amounts, as different scholars differ on exactly what elements of American aid during this period were part of the Marshall Plan.
Loans and grants.
The Marshall plan, just as GARIOA, consisted of aid both in the form of grants and in the form of loans. Out of the total, 1.2 billion USD were loan-aid.
Ireland which received 146.2 million USD through the Marshall plan, received 128.2 million USD as loans, and the remaining 18 million USD as grants. By 1969 the Irish Marshall plan debt, which was still being repaid, amounted to 31 million pounds, out of a total Irish foreign debt of 50 million pounds.
The UK received 385 million USD of its Marshall plan aid in the form of loans. Unconnected to the Marshall plan the UK also received direct loans from the US amounting to 4.6 billion USD. The proportion of Marshall plan loans versus Marshall plan grants was roughly 15% to 85% for both the UK and France.
Germany, which up until the 1953 Debt agreement had to work on the assumption that all the Marshall plan aid was to be repaid, spent its funds very carefully. Payment for Marshall plan goods, "counterpart funds", were administered by the Reconstruction Credit Institute, which used the funds for loans inside Germany. In the 1953 Debt agreement the amount of Marshall plan aid that Germany was to repay was reduced to less than 1 billion USD. This made the proportion of loans versus grants to Germany similar to that of France and the UK.
The final German loan repayment was made in 1971. Since Germany chose to repay the aid debt out of the German Federal budget, leaving the German ERP fund intact, the fund was able to continue its reconstruction work. By 1996 it had accumulated a value of 23 billion Deutsche Mark.
Effects and legacy.
The Marshall Plan was originally scheduled to end in 1953. Any effort to extend it was halted by the growing cost of the Korean War and rearmament. American Republicans hostile to the plan had also gained seats in the 1950 Congressional elections, and conservative opposition to the plan was revived. Thus the plan ended in 1951, though various other forms of American aid to Europe continued afterwards.
The years 1948 to 1952 saw the fastest period of growth in European history. Industrial production increased by 35%. Agricultural production substantially surpassed pre-war levels. The poverty and starvation of the immediate postwar years disappeared, and Western Europe embarked upon an unprecedented two decades of growth that saw standards of living increase dramatically. There is some debate among historians over how much this should be credited to the Marshall Plan. Most reject the idea that it alone miraculously revived Europe, as evidence shows that a general recovery was already underway. Most believe that the Marshall Plan sped this recovery, but did not initiate it. Many argue that the structural adjustments that it forced were of great importance. Economic historians J. Bradford DeLong and Barry Eichengreen call it "history's most successful structural adjustment program." One effect of the plan was that it subtly "Americanized" countries, especially Austria, who embraced United States' assistance, through popular culture, such as Hollywood movies and rock n' roll.
The political effects of the Marshall Plan may have been just as important as the economic ones. Marshall Plan aid allowed the nations of Western Europe to relax austerity measures and rationing, reducing discontent and bringing political stability. The communist influence on Western Europe was greatly reduced, and throughout the region communist parties faded in popularity in the years after the Marshall Plan. The trade relations fostered by the Marshall Plan helped forge the North Atlantic alliance that would persist throughout the Cold War. At the same time, the nonparticipation of the states of Eastern Bloc was one of the first clear signs that the continent was now divided.
The Marshall Plan also played an important role in European integration. Both the Americans and many of the European leaders felt that European integration was necessary to secure the peace and prosperity of Europe, and thus used Marshall Plan guidelines to foster integration. In some ways this effort failed, as the OEEC never grew to be more than an agent of economic cooperation. Rather it was the separate European Coal and Steel Community, which notably excluded Britain, that would eventually grow into the European Union. However, the OEEC served as both a testing and training ground for the structures that would later be used by the European Economic Community. The Marshall Plan, linked into the Bretton Woods system, also mandated free trade throughout the region.
While some historians today feel some of the praise for the Marshall Plan is exaggerated, it is still viewed favorably and many thus feel that a similar project would help other areas of the world. After the fall of communism several proposed a "Marshall Plan for Eastern Europe" that would help revive that region. Others have proposed a Marshall Plan for Africa to help that continent, and U.S. vice president Al Gore suggested a Global Marshall Plan. "Marshall Plan" has become a metaphor for any very large scale government program that is designed to solve a specific social problem. It is usually used when calling for federal spending to correct a perceived failure of the private sector.
Repayment.
The Organization for European Economic Cooperation took the leading role in allocating funds, and the OEEC arranged for the transfer of the goods. The American supplier was paid in dollars, which were credited against the appropriate European Recovery Program funds. The European recipient, however, was not given the goods as a gift, but had to pay for them (usually on credit) in local currency. These payments were kept by the European government involved in a special counterpart fund. This counterpart money, in turn, could be used by the government for further investment projects. 5% of the counterpart money was paid to the U.S. to cover the administrative costs of the ERP.
The Marshall Plan money was in the form of grants that did not have to be repaid. In addition to ERP grants, the Export-Import Bank (an agency of the U.S. government) at the same time made long-term loans at low interest rates to finance major purchases in the US, all of which were repaid.
In the case of Germany there also were 16 billion marks of debts from the 1920s which had defaulted in the 1930s, but which Germany decided to repay to restore its reputation. This money was owed to government and private banks in the U.S., France and Britain. Another 16 billion marks represented postwar loans by the U.S. Under the London Debts Agreement of 1953, the repayable amount was reduced by 50% to about 15 billion marks and stretched out over 30 years, and compared to the fast-growing German economy were of minor impact.
Areas without the Plan.
Large parts of the world devastated by World War II did not benefit from the Marshall Plan. The only major Western European nation excluded was Francisco Franco's Spain, which did not overtly participate in World War II. After the war, it pursued a policy of self-sufficiency, currency controls, and quotas, with little success. With the escalation of the Cold War, the United States reconsidered its position, and in 1951 embraced Spain as an ally, encouraged by Franco's aggressive anti-communist policies. Over the next decade, a considerable amount of American aid would go to Spain, but less than its neighbors had received under the Marshall Plan.
While the western portion of the Soviet Union had been as badly affected as any part of the world by the war, the eastern portion of the country was largely untouched and had seen a rapid industrialization during the war. The Soviets also imposed large reparations payments on the Axis allies that were in its sphere of influence. Austria, Finland, Hungary, Romania, and especially East Germany were forced to pay vast sums and ship large amounts of supplies to the USSR. These reparation payments meant the Soviet Union itself received about the same as 16 European countries received in total from Marshall Plan aid.
In accordance with the agreements with the USSR shipment of dismantled German industrial installations from the west began on March 31, 1946. Under the terms of the agreement the Soviet Union would in return ship raw materials such as food and timber to the western zones. In view of the Soviet failure to do so, the western zones halted the shipments east, ostensibly on a temporary basis, although they were never resumed. It was later shown that the main reason for halting shipments east was not the behavior of the USSR but rather the recalcitrant behavior of France. Examples of material received by the USSR were
equipment from the Kugel-Fischer ballbearing plant at Schweinfurt, the Daimler-Benz underground aircraft-engine plant at Obrigheim, the Deschimag shipyards at Bremen-Weser, and the Gendorf powerplant.
The USSR did establish COMECON as a riposte to the Marshall Plan to deliver aid for Eastern Bloc countries, but this was complicated by the Soviet efforts to manage their own recovery from the war. The members of Comecon looked to the Soviet Union for oil; in turn, they provided machinery, equipment, agricultural goods, industrial goods, and consumer goods to the Soviet Union. Economic recovery in the east was much slower than in the west, and the economies never fully recovered in the communist period, resulting in the formation of the shortage economies and a gap in wealth between East and West. Finland, which USSR forbade to join the Marshall Plan and which was required to give large reparations to the USSR, saw its economy recover to pre-war levels in 1947. France, which received billions of dollars through the Marshall Plan, similarly saw its average income per person return to almost pre-war level by 1949. By mid-1948 industrial production in Poland, Hungary, Bulgaria, and Czechoslovakia had recovered to a level somewhat above pre-war level.
Aid to Asia.
From the end of the war to the end of 1953, the U.S. provided grants and credits amounting to $5.9 billion to Asian countries, especially China/Taiwan ($1.051 billion), India ($255 million), Indonesia ($215 million), Japan ($2.44 billion), South Korea ($894 million), Pakistan ($98 million) and the Philippines ($803 million). In addition, another $282 million went to Israel and $196 million to the rest of the Middle East. All this aid was separate from the Marshall Plan.
Canada.
Canada, like the United States, was little damaged by the war and in 1945 was one of the world's largest economies. It operated its own aid program. In 1948, the U.S. allowed ERP aid to be used in purchasing goods from Canada. Canada made over a billion dollars in sales in the first two years of operation.
World total.
The total of American grants and loans to the world from 1945 to 1953 came to $44.3 billion.
Criticism.
Laissez-faire criticism.
Initial criticism of the Marshall Plan came from a number of economists. Wilhelm Röpke, who influenced German Minister for Economy Ludwig Erhard in his economic recovery program, believed recovery would be found in eliminating central planning and restoring a market economy in Europe, especially in those countries which had adopted more fascist and corporatist economic policies. Röpke criticized the Marshall Plan for forestalling the transition to the free market by subsidizing the current, failing systems. Erhard put Röpke's theory into practice and would later credit Röpke's influence for West Germany's preeminent success.
Henry Hazlitt criticized the Marshall Plan in his 1947 book "Will Dollars Save the World?", arguing that economic recovery comes through savings, capital accumulation and private enterprise, and not through large cash subsidies. Ludwig von Mises criticized the Marshall Plan in 1951, believing that "the American subsidies make it possible for [Europe's] governments to conceal partially the disastrous effects of the various socialist measures they have adopted".
Some critics and Congressmen at the time believed that America was giving too much aid to Europe. America had already given Europe $9 billion in other forms of help in previous years. The Marshall Plan gave another $13 billion, equivalent to about $100 billion in 2010 value.
Modern criticism.
Criticism of the Marshall Plan became prominent among historians of the revisionist school, such as Walter LaFeber, during the 1960s and 1970s. They argued that the plan was American economic imperialism, and that it was an attempt to gain control over Western Europe just as the Soviets controlled Eastern Bloc. In a review of West Germany's economy from 1945 to 1951, German analyst Werner Abelshauser concluded that "foreign aid was not crucial in starting the recovery or in keeping it going". The economic recoveries of France, Italy, and Belgium, Cowen found, also predated the flow of U.S. aid. Belgium, the country that relied earliest and most heavily on free market economic policies after its liberation in 1944, experienced swift recovery and avoided the severe housing and food shortages seen in the rest of continental Europe.
Former US Chairman of the Federal Reserve Bank Alan Greenspan gives most credit to Ludwig Erhard for Europe's economic recovery. Greenspan writes in his memoir "The Age of Turbulence" that Erhard's economic policies were the most important aspect of postwar Western Europe recovery, even outweighing the contributions of the Marshall Plan. He states that it was Erhard's reductions in economic regulations that permitted Germany's miraculous recovery, and that these policies also contributed to the recoveries of many other European countries. Its recovery is attributed to traditional economic stimuli, such as increases in investment, fueled by a high savings rate and low taxes. Japan saw a large infusion of US investment during the Korean War. 
Noam Chomsky wrote that the amount of American dollars given to France and the Netherlands equaled the funds these countries used to finance their military actions against their colonial subjects in East Asia, in French Indochina and the Netherlands East Indies respectively. The Marshall Plan was said to have "set the stage for large amounts of private U.S. investment in Europe, establishing the basis for modern transnational corporations". The Netherlands received U.S. aid for economic recovery in the Netherlands Indies. However, in January 1949, the American government suspended this aid in response to the Dutch efforts to restore colonial rule in Indonesia during the Indonesian National Revolution, and it implicitly threatened to suspend Marshall aid to the Netherlands if the Dutch government continued to oppose the independence of Indonesia.
In popular culture.
Alfred Friendly, press aide to the US Secretary of Commerce W. Averell Harriman, wrote a humorous operetta about the Marshall Plan during its first year; one of the lines in the operetta was: "Wines for Sale; will you swap / A little bit of steel for Chateau Neuf du Pape?"
The Spanish comedy film" Welcome Mr. Marshall! "tells the story of a small Spanish town, Villar del Río, which hears of the visit of American diplomats and begins preparations to impress the American visitors in the hopes of benefitting under the Marshall Plan.

</doc>
<doc id="19769" url="https://en.wikipedia.org/wiki?curid=19769" title="Mariculture">
Mariculture

Mariculture is a specialized branch of aquaculture involving the cultivation of marine organisms for food and other products in the open ocean, an enclosed section of the ocean, or in tanks, ponds or raceways which are filled with seawater. An example of the latter is the farming of marine fish, including finfish and shellfish like prawns, or oysters and seaweed in saltwater ponds. Non-food products produced by mariculture include: fish meal, nutrient agar, jewellery (e.g. cultured pearls), and cosmetics.
Methods.
Shellfish.
Similar to algae cultivation, shellfish can be farmed in multiple ways: on ropes, in bags or cages, or directly on (or within) the intertidal substrate. Shellfish mariculture does not require feed or fertilizer inputs, nor insecticides or antibiotics, making shellfish aquaculture (or 'mariculture') a self-supporting system. Shellfish can also be used in multi-species cultivation techniques, where shellfish can utilize waste generated by higher trophic level organisms.
Artifical reefs.
After trials in 2012, a commercial "sea ranch" was set up in Flinders Bay, Western Australia to raise abalone. The ranch is based on an artificial reef made up of 5000 () separate concrete units called "abitats" (abalone habitats). The abitats can host 400 abalone each. The reef is seeded with young abalone from an onshore hatchery.
The abalone feed on seaweed that has grown naturally on the abitats; with the ecosystem enrichment of the bay also resulting in growing numbers of dhufish, pink snapper, wrasse, Samson fish among other species.
Brad Adams, from the company, has emphasised the similarity to wild abalone and the difference from shore based aquaculture. "We're not aquaculture, we're ranching, because once they're in the water they look after themselves."
Open ocean.
Raising marine organisms under controlled conditions in exposed, high-energy ocean environments beyond significant coastal influence, is a relatively new approach to mariculture. Open ocean aquaculture (OOA) uses cages, nets, or long-line arrays that are moored, towed or float freely. Research and commercial open ocean aquaculture facilities are in operation or under development in Panama, Australia, Chile, China, France, Ireland, Italy, Japan, Mexico, and Norway. As of 2004, two commercial open ocean facilities were operating in U.S. waters, raising Threadfin near Hawaii and cobia near Puerto Rico. An operation targeting bigeye tuna recently received final approval. All U.S. commercial facilities are currently sited in waters under state or territorial jurisdiction. The largest deep water open ocean farm in the world is raising cobia 12 km off the northern coast of Panama in highly exposed sites.
Enhanced stocking.
Enchanced Stocking (also known as sea ranching) is a Japanese principle based on operant conditioning and the migratory nature of certain species. The fishermen raise hatchlings in a closely knitted net in a harbor, sounding an underwater horn before each feeding. When the fish are old enough they are freed from the net to mature in the open sea. During spawning season, about 80% of these fish return to their birthplace. The fishermen sound the horn and then net those fish that respond.
Seawater ponds.
In seawater pond mariculture, fish are raised in ponds which receive water from the sea. This has the benefit that the nutrition (e.g. microorganisms) present in the seawater can be used. This is a great advantage over traditional fish farms (e.g. sweet water farms) for which the farmers buy feed (which is expensive). Other advantages are that water purification plants may be planted in the ponds to eliminate the buildup of nitrogen, from fecal and other contamination. Also, the ponds can be left unprotected from natural predators, providing another kind of filtering.
Environmental effects.
Mariculture has rapidly expanded over the last two decades due to new technology, improvements in formulated feeds, greater biological understanding of farmed species, increased water quality within closed farm systems, greater demand for seafood products, site expansion and government interest. As a consequence, mariculture has been subject to some controversy regarding its social and environmental impacts. Commonly identified environmental impacts from marine farms are:
As with most farming practices, the degree of environmental impact depends on the size of the farm, the cultured species, stock density, type of feed, hydrography of the site, and husbandry methods. The adjacent diagram connects these causes and effects.
Wastes from cage cultures.
Mariculture of finfish can require a significant amount of fishmeal or other high protein food sources. Originally, a lot of fishmeal went to waste due to inefficient feeding regimes and poor digestibility of formulated feeds which resulted in poor feed conversion ratios.
In cage culture, several different methods are used for feeding farmed fish – from simple hand feeding to sophisticated computer-controlled systems with automated food dispensers coupled with "in situ" uptake sensors that detect consumption rates. In coastal fish farms, overfeeding primarily leads to increased disposition of detritus on the seafloor (potentially smothering seafloor dwelling invertebrates and altering the physical environment), while in hatcheries and land-based farms, excess food goes to waste and can potentially impact the surrounding catchment and local coastal environment. This impact is usually highly local, and depends significantly on the settling velocity of waste feed and the current velocity (which varies both spatially and temporally) and depth.
Farm escapees and invasives.
The impact of escapees from aquaculture operations depends on whether or not there are wild conspecifics or close relatives in the receiving environment, and whether or not the escapee is reproductively capable. Several different mitigation/prevention strategies are currently employed, from the development of infertile triploids to land-based farms which are completely isolated from any marine environment. Escapees can adversely impact local ecosystems through hybridization and loss of genetic diversity in native stocks, increase negative interactions within an ecosystem (such as predation and competition), disease transmission and habitat changes (from trophic cascades and ecosystem shifts to varying sediment regimes and thus turbidity).
The accidental introduction of invasive species is also of concern. Aquaculture is one of the main vectors for invasives following accidental releases of farmed stocks into the wild. One example is the Siberian sturgeon ("Acipenser baerii") which accidentally escaped from a fish farm into the Gironde Estuary (Southwest France) following a severe storm in December 1999 (5,000 individual fish escaped into the estuary which had never hosted this species before). Molluscan farming is another example whereby species can be introduced to new environments by ‘hitchhiking’ on farmed molluscs. Also, farmed molluscs themselves can become dominate predators and/or competitors, as well as potentially spread pathogens and parasites.
Genetic pollution and disease and parasite transfer.
One of the primary concerns with mariculture is the potential for disease and parasite transfer. Farmed stocks are often selectively bred to increase disease and parasite resistance, as well as improving growth rates and quality of products. As a consequence, the genetic diversity within reared stocks decreases with every generation – meaning they can potentially reduce the genetic diversity within wild populations if they escape into those wild populations. Such genetic pollution from escaped aquaculture stock can reduce the wild population’s ability to adjust to the changing natural environment. Also, maricultured species can harbour diseases and parasites (e.g., lice) which can be introduced to wild populations upon their escape. An example of this is the parasitic sea lice on wild and farmed Atlantic salmon in Canada. Also, non-indigenous species which are farmed may have resistance to, or carry, particular diseases (which they picked up in their native habitats) which could be spread through wild populations if they escape into those wild populations. Such ‘new’ diseases would be devastating for those wild populations because they would have no immunity to them.
Habitat modification.
With the exception of benthic habitats directly beneath marine farms, most mariculture causes minimal destruction to habitats. However, the destruction of mangrove forests from the farming of shrimps is of concern. Globally, shrimp farming activity is a small contributor to the destruction of mangrove forests; however, locally it can be devastating. Mangrove forests provide rich matrices which support a great deal of biodiversity – predominately juvenile fish and crustaceans. Furthermore, they act as buffering systems whereby they reduce coastal erosion, and improve water quality for in situ animals by processing material and ‘filtering’ sediments.
Others.
In addition, nitrogen and phosphorus compounds from food and waste may lead to blooms of phytoplankton, whose subsequent degradation can drastically reduce oxygen levels. If the algae are toxic, fish are killed and shellfish contaminated.
Sustainability.
Mariculture development must be sustained by basic and applied research and development in major fields such as nutrition, genetics, system management, product handling, and socioeconomics. One approach is closed systems that have no direct interaction with the local environment. However, investment and operational cost are currently significantly higher than open cages, limiting them to their current role as hatcheries.
Benefits.
Sustainable mariculture promises economic and environmental benefits. Economies of scale imply that ranching can produce fish at lower cost than industrial fishing, leading to better human diets and the gradual elimination of unsustainable fisheries. Maricultured fish are also perceived to be of higher quality than fish raised in ponds or tanks, and offer more diverse choice of species. Consistent supply and quality control has enabled integration in food market channels.
Scientific literature.
Scientific literature on mariculture can be found in the following journals:

</doc>
<doc id="19770" url="https://en.wikipedia.org/wiki?curid=19770" title="Memetics">
Memetics

Memetics is the theory of mental content based on an analogy with Darwinian evolution, originating from the popularization of Richard Dawkins' 1976 book "The Selfish Gene." Proponents describe memetics as an approach to evolutionary models of cultural information transfer.
The meme, analogous to a gene, was conceived as a "unit of culture" (an idea, belief, pattern of behaviour, etc.) which is "hosted" in the minds of one or more individuals, and which can reproduce itself, thereby jumping from mind to mind. Thus what would otherwise be regarded as one individual influencing another to adopt a belief is seen as an idea-replicator reproducing itself in a new host. As with genetics, particularly under a Dawkinsian interpretation, a meme's success may be due to its contribution to the effectiveness of its host.
Memetics is also notable for sidestepping the traditional concern with the "truth" of ideas and beliefs. Instead, it is interested in their success.
The Usenet newsgroup alt.memetics started in 1993 with peak posting years in the mid to late 1990s. The "Journal of Memetics" was published electronically from 1997 to 2005.
History.
In his book "The Selfish Gene" (1976), the evolutionary biologist Richard Dawkins used the term "meme" to describe a unit of human cultural transmission analogous to the gene, arguing that replication also happens in culture, albeit in a different sense. Ted Cloak had briefly outlined a similar hypothesis in 1975, which Dawkins referenced. Cultural evolution itself is a much older topic, with a history that dates back to Darwin's era.
Dawkins (1976) contended that the meme is a unit of information residing in the brain and is the mutating replicator in human cultural evolution. It is a pattern that can influence its surroundings – that is, it has causal agency – and can propagate. This created great debate among sociologists, biologists, and scientists of other disciplines, because Dawkins himself did not provide a sufficient explanation of how the replication of units of information in the brain controls human behaviour and ultimately culture, since the principal topic of the book was genetics. Dawkins apparently did not intend to present a comprehensive theory of "memetics" in "The Selfish Gene", but rather coined the term "meme" in a speculative spirit. Accordingly, the term "unit of information" came to be defined in different ways by many scientists.
The modern memetics movement dates from the mid-1980s. A January 1983 Metamagical Themas column by Douglas Hofstadter, in "Scientific American", was influential as was his 1985 book of the same name. "Memeticist" was coined as analogous to "geneticist" originally in "The Selfish Gene." Later Arel Lucas suggested that the discipline that studies memes and their connections to human and other carriers of them be known as memetics by analogy with 'genetics.'" Dawkins' "The Selfish Gene" has been a factor in drawing in people of disparate intellectual backgrounds. Another stimulus was the publication in 1991 of "Consciousness Explained" by Tufts University philosopher Daniel Dennett, which incorporated the meme concept into a theory of the mind. In his 1991 essay "Viruses of the Mind", Richard Dawkins used memetics to explain the phenomenon of religious belief and the various characteristics of organised religions. By then, memetics had also become a theme appearing in fiction (e.g. Neal Stephenson's Snow Crash).
The idea of "language as a virus" had already been introduced by William S. Burroughs as early as 1962 in his book "The Ticket That Exploded", and later in "The Electronic Revolution", published in 1970 in "" and is also explored in Media Virus by Douglas Rushkoff in 1995.
However, the foundation of memetics in full modern incarnation originates in the publication in 1996 of two books by authors outside the academic mainstream: "Virus of the Mind: The New Science of the Meme" by former Microsoft executive turned motivational speaker and professional poker player, Richard Brodie, and "Thought Contagion: How Belief Spreads Through Society" by Aaron Lynch, a mathematician and philosopher who worked for many years as an engineer at Fermilab. Lynch claimed to have conceived his theory totally independently of any contact with academics in the cultural evolutionary sphere, and apparently was not even aware of Dawkins' "The Selfish Gene" until his book was very close to publication.
Around the same time as the publication of the books by Lynch and Brodie the e-journal Journal of Memetics – "Evolutionary Models of Information Transmission" appeared on the web. It was first hosted by the Centre for Policy Modelling at Manchester Metropolitan University but later taken over by Francis Heylighen of the CLEA research institute at the Vrije Universiteit Brussel. The e-journal soon became the central point for publication and debate within the nascent memeticist community. (There had been a short-lived paper memetics publication starting in 1990, the "Journal of Ideas" edited by Elan Moritz.) In 1999, Susan Blackmore, a psychologist at the University of the West of England, published "The Meme Machine", which more fully worked out the ideas of Dennett, Lynch, and Brodie and attempted to compare and contrast them with various approaches from the cultural evolutionary mainstream, as well as providing novel, and controversial, memetics-based theories for the evolution of language and the human sense of individual selfhood.
The term "meme".
The term "meme" derives from the Ancient Greek μιμητής ("mimētḗs"), meaning "imitator, pretender". The similar term "mneme" was used in 1904, by the German evolutionary biologist Richard Semon, best known for his development of the engram theory of memory, in his work "Die mnemischen Empfindungen in ihren Beziehungen zu den Originalempfindungen", translated into English in 1921 as "The Mneme". Until Daniel Schacter published "Forgotten Ideas, Neglected Pioneers: Richard Semon and the Story of Memory" in 2000, Semon's work had little influence, though it was quoted extensively in Erwin Schrödinger’s prescient 1956 Tarner Lecture “Mind and Matter”. Richard Dawkins (1976) apparently coined the word "meme" independently of Semon, writing this:
“Mimeme” comes from a suitable Greek root, but I want a monosyllable that sounds a bit like “gene”. I hope my classicist friends will forgive me if I abbreviate mimeme to meme. If it is any consolation, it could alternatively be thought of as being related to “memory”, or to the French word même.
Maturity.
In 2005, the "Journal of Memetics – Evolutionary Models of Information Transmission" ceased publication and published a set of articles on the future of memetics. The website states that although "there was to be a relaunch...after several years nothing has happened". Susan Blackmore has left the University of the West of England to become a freelance science writer and now concentrates more on the field of consciousness and cognitive science. Derek Gatherer moved to work as a computer programmer in the pharmaceutical industry, although he still occasionally publishes on memetics-related matters. Richard Brodie is now climbing the world professional poker rankings. Aaron Lynch disowned the memetics community and the words "meme" and "memetics" (without disowning the ideas in his book), adopting the self-description "thought contagionist". He died in 2005.
Susan Blackmore (2002) re-stated the definition of meme as: whatever is copied from one person to another person, whether habits, skills, songs, stories, or any other kind of information. Further she said that memes, like genes, are replicators in the sense as defined by Dawkins. That is, they are information that is copied. Memes are copied by imitation, teaching and other methods. The copies are not perfect: memes are copied with variation; moreover, they compete for space in our memories and for the chance to be copied again. Only some of the variants can survive. The combination of these three elements (copies; variation; competition for survival) forms precisely the condition for Darwinian evolution, and so memes (and hence human cultures) evolve. Large groups of memes that are copied and passed on together are called co-adapted meme complexes, or "memeplexes". In her definition, the way that a meme replicates is through imitation. This requires brain capacity to generally imitate a model or selectively imitate the model. Since the process of social learning varies from one person to another, the imitation process cannot be said to be completely imitated. The sameness of an idea may be expressed with different memes supporting it. This is to say that the mutation rate in memetic evolution is extremely high, and mutations are even possible within each and every interaction of the imitation process. It becomes very interesting when we see that a social system composed of a complex network of microinteractions exists, but at the macro level an order emerges to create culture.
Internalists and externalists.
The memetics movement split almost immediately into two. The first group were those who wanted to stick to Dawkins' definition of a meme as "a unit of cultural transmission". Gibran Burchett, another memeticist responsible for helping to research and co-coin the term memetic engineering, along with Leveious Rolando and Larry Lottman, has stated that a meme can be defined, more precisely, as "a unit of cultural information that can be copied, located in the brain". This thinking is more in line with Dawkins' second definition of the meme in his book "The Extended Phenotype". The second group wants to redefine memes as observable cultural artifacts and behaviors. However, in contrast to those two positions, Blackmore does not reject either concept of external or internal memes.
These two schools became known as the "internalists" and the "externalists." Prominent internalists included both Lynch and Brodie; the most vocal externalists included Derek Gatherer, a geneticist from Liverpool John Moores University, and William Benzon, a writer on cultural evolution and music. The main rationale for externalism was that internal brain entities are not observable, and memetics cannot advance as a science, especially a quantitative science, unless it moves its emphasis onto the directly quantifiable aspects of culture. Internalists countered with various arguments: that brain states will eventually be directly observable with advanced technology, that most cultural anthropologists agree that culture is about beliefs and not artifacts, or that artifacts cannot be replicators in the same sense as mental entities (or DNA) are replicators. The debate became so heated that a 1998 Symposium on Memetics, organised as part of the 15th International Conference on Cybernetics, passed a motion calling for an end to definitional debates. McNamara demonstrated in 2011 that functional connectivity profiling using neuroimaging tools enables the observation of the processing of internal memes, "i-memes", in response to external "e-memes".
An advanced statement of the internalist school came in 2002 with the publication of "The Electric Meme", by Robert Aunger, an anthropologist from the University of Cambridge. Aunger also organised a conference in Cambridge in 1999, at which prominent sociologists and anthropologists were able to give their assessment of the progress made in memetics to that date. This resulted in the publication of "Darwinizing Culture: The Status of Memetics as a Science", edited by Aunger and with a foreword by Dennett, in 2000.
Criticism.
This evolutionary model of cultural information transfer is based on the concept that units of information, or "memes", have an independent existence, are self-replicating, and are subject to selective evolution through environmental forces. Starting from a proposition put forward in the writings of Richard Dawkins, it has since turned into a new area of study, one that looks at the self-replicating units of culture. It has been proposed that just as memes are analogous to genes, memetics is analogous to genetics.
Critics contend that some proponents' assertions are "untested, unsupported or incorrect." Luis Benitez-Bribiesca, a critic of memetics, calls it "a pseudoscientific dogma" and "a dangerous idea that poses a threat to the serious study of consciousness and cultural evolution" among other things. As factual criticism, he refers to the lack of a "code script" for memes, as the DNA is for genes, and to the fact that the meme mutation mechanism (i.e., an idea going from one brain to another) is too unstable (low replication accuracy and high mutation rate), which would render the evolutionary process chaotic.
Another criticism comes from semiotics, (e.g., Deacon, Kull) stating that the concept of meme is a primitivized concept of Sign. Meme is thus described in memetics as a sign without its triadic nature. In other words, meme is a degenerate sign, which includes only its ability of being copied. Accordingly, in the broadest sense, the objects of copying are memes, whereas the objects of translation and interpretation are signs.
Mary Midgley criticises memetics for at least two reasons: One, culture is not best understood by examining its smallest parts, as culture is pattern-like, comparable to an ocean current. Many more factors, historical and others, should be taken into account than only whatever particle culture is built from. Two, if memes are not thoughts (and thus not cognitive phenomena), as Daniel C. Dennett insists in "Darwin's Dangerous Idea", then their ontological status is open to question, and memeticists (who are also reductionists) may be challenged whether memes even exist. Questions can extend to whether the idea of "meme" is itself a meme, or is a true concept. Fundamentally, memetics is an attempt to produce knowledge through organic metaphors, which as such is a questionable research approach, as the application of metaphors has the effect of hiding that which does not fit within the realm of the metaphor. Rather than study actual reality, without preconceptions, memetics, as so many of the socio-biological explanations of society, believe that saying that the apple is like an orange is a valid analysis of the apple.
Like other critics, Maria Kronfeldner has criticized memetics for being based on an allegedly inaccurate analogy with the gene; alternately, she claims it is "heuristically trivial", being a mere redescription of what is already known without offering any useful novelty.
New developments.
Dawkins in "A Devil's Chaplain" responded that there are actually two different types of memetic processes (controversial and informative). The first is a type of cultural idea, action, or expression, which does have high variance; for instance, a student of his who had inherited some of the mannerisms of Wittgenstein. However, he also describes a self-correcting meme, highly resistant to mutation. As an example of this, he gives origami patterns in elementary schools – except in rare cases, the meme is either passed on in the exact sequence of instructions, or (in the case of a forgetful child) terminates. This type of meme tends not to evolve, and to experience profound mutations in the rare event that it does.
Another definition, given by Hokky Situngkir, tried to offer a more rigorous formalism for the meme, "memeplexes", and the "deme", seeing the meme as a cultural unit in a cultural complex system. It is based on the Darwinian genetic algorithm with some modifications to account for the different patterns of evolution seen in genes and memes. In the method of memetics as the way to see culture as a complex adaptive system, he describes a way to see memetics as an alternative methodology of cultural evolution. However, there are as many possible definitions that are credited to the word "meme". For example, in the sense of computer simulation the term "memetic algorithm" is used to define a particular computational viewpoint.
The possibility of quantitative analysis of memes using neuroimaging tools and the suggestion that such studies have already been done was given by McNamara (2011). This author proposes hyperscanning (concurrent scanning of two communicating individuals in two separate MRI machines) as a key tool in the future for investigating memetics.
Velikovsky (2013) proposed the "holon" as the structure of the meme, synthesizing the major theories on memes of Richard Dawkins, Mihaly Csikszentmihalyi, E. O. Wilson, Frederick Turner (poet) and Arthur Koestler.
Proponents of memetics as described in the Journal of Memetics (out of print since 2005 ) – "Evolutionary Models of Information Transmission" believe that 'memetics' has the potential to be an important and promising analysis of culture using the framework of evolutionary concepts. 
Keith Henson in "Memetics and the Modular-Mind" (Analog Aug. 1987) makes the case that memetics needs to incorporate evolutionary psychology to understand the psychological traits of a meme's host. This is especially true of time-varying, meme-amplification host-traits, such as those leading to wars.
DiCarlo () has developed the idea of 'memetic equilibrium' to describe a cultural compatible state with biological equilibrium. In "Problem Solving and Neurotransmission in the Upper Paleolithic" (in press), diCarlo argues that as human consciousness evolved and developed, so too did our ancestors' capacity to consider and attempt to solve environmental problems in more conceptually sophisticated ways. Understood in this way, problem solving amongst a particular group, when considered satisfactory, often produces a feeling of environmental control, stability, in short—memetic equilibrium. 
But the pay-off is not merely practical, providing purely functional utility—it is biochemical and it comes in the form of neurotransmitters. The relationship between a gradually emerging conscious awareness and sophisticated languages in which to formulate representations combined with the desire to maintain biological equilibrium, generated the necessity for memetic equilibrium to fill in conceptual gaps in terms of understanding three very important aspects in the Upper Paleolithic: causality, morality, and mortality. The desire to explain phenomena in relation to maintaining survival and reproductive stasis, generated a normative stance in the minds of our ancestors—Survival/Reproductive Value (or S-R Value).
Houben (2014) has argued on several occasions that the exceptional resilience of Vedic ritual and its interaction with a changing ecological and economic environment over several millennia can be profitably dealt with in a ‘cultural evolution’ perspective in which the Vedic mantra is the ‘meme’ or unit of cultural replication.
This renders superfluous attempts to explain the phenomenon of Vedic tradition in genetic terms. The domain of Vedic ritual should be able to fulfil to a large extent the three challenges posed to memetics by B. Edmonds (2002 and 2005).
Applications.
Research methodologies that apply memetics go by many names: Viral marketing, cultural evolution, the history of ideas, social analytics, and more. Many of these applications do not make reference to the literature on memes directly but are built upon the evolutionary lens of idea propagation that treats semantic units of culture as self-replicating and mutating patterns of information that are assumed to be relevant for scientific study. For example, the field of public relations is filled with attempts to introduce new ideas and alter social discourse. One means of doing this is to design a meme and deploy it through various media channels. One historic example of applied memetics is the PR campaign conducted in 1991 as part of the build-up to the first Gulf War in the United States.
The application of memetics to a difficult complex social system problem, environmental sustainability, has recently been attempted at thwink.org. Using meme types and memetic infection in several stock and flow simulation models, Jack Harich has demonstrated several interesting phenomena that are best, and perhaps only, explained by memes. One model, The Dueling Loops of the Political Powerplace, argues that the fundamental reason corruption is the norm in politics is due to an inherent structural advantage of one feedback loop pitted against another. Another model, The Memetic Evolution of Solutions to Difficult Problems, uses memes, the evolutionary algorithm, and the scientific method to show how complex solutions evolve over time and how that process can be improved. The insights gained from these models are being used to engineer memetic solution elements to the sustainability problem.
Another application of memetics in the sustainability space is the crowdfunded Climate Meme Project conducted by Joe Brewer and Balasz Laszlo Karafiath in the spring of 2013. This study was based on a collection of 1000 unique text-based expressions gathered from Twitter, Facebook, and structured interviews with climate activists. The major finding was that the global warming meme is not effective at spreading because it causes emotional duress in the minds of people who learn about it. Five central tensions were revealed in the discourse about change, each of which represents a resonance point through which dialogue can be engaged. The tensions were Harmony/Disharmony (whether or not humans are part of the natural world), Survival/Extinction (envisioning the future as either apocalyptic collapse of civilization or total extinction of the human race), Cooperation/Conflict (regarding whether or not humanity can come together to solve global problems), Momentum/Hesitation (about whether or not we are making progress at the collective scale to address climate change), and Elitism/Heretic (a general sentiment that each side of the debate considers the experts of its opposition to be untrustworthy.
Ben Cullen, in his book "Contagious Ideas", brought the idea of the meme into the discipline of archaeology. He coined the term "Cultural Virus Theory", and used it to try to anchor archaeological theory in a neo-Darwinian paradigm. Archaeological memetics could assist the application of the meme concept to material culture in particular.
Francis Heylighen of the Center Leo Apostel for Interdisciplinary Studies has postulated what he calls "memetic selection criteria". These criteria opened the way to a specialized field of "applied memetics" to find out if these selection criteria could stand the test of quantitative analyses. In 2003 Klaas Chielens carried out these tests in a Masters thesis project on the testability of the selection criteria.
In "Selfish Sounds and Linguistic Evolution", Austrian linguist Nikolaus Ritt has attempted to operationalise memetic concepts and use them for the explanation of long term sound changes and change conspiracies in early English. It is argued that a generalised Darwinian framework for handling cultural change can provide explanations where established, speaker centred approaches fail to do so. The book makes comparatively concrete suggestions about the possible material structure of memes, and provides two empirically rich case studies.
Australian academic S.J. Whitty has argued that project management is a memeplex with the language and stories of its practitioners at its core. This radical approach sees a project and its management as an illusion; a human construct about a collection of feelings, expectations, and sensations, which are created, fashioned, and labeled by the human brain. Whitty's approach requires project managers to consider that the reasons for using project management are not consciously driven to maximize profit, and are encouraged to consider project management as naturally occurring, self-serving, evolving process which shapes organizations for its own purpose.
Swedish political scientist Mikael Sandberg argues against "Lamarckian" interpretations of institutional and technological evolution and studies creative innovation of information technologies in governmental and private organizations in Sweden in the 1990s from a memetic perspective. Comparing the effects of active ("Lamarckian") IT strategy versus user–producer interactivity (Darwinian co-evolution), evidence from Swedish organizations shows that co-evolutionary interactivity is almost four times as strong a factor behind IT creativity as the "Lamarckian" IT strategy.

</doc>
<doc id="19773" url="https://en.wikipedia.org/wiki?curid=19773" title="March 25">
March 25


</doc>
<doc id="19780" url="https://en.wikipedia.org/wiki?curid=19780" title="List of islands of Michigan">
List of islands of Michigan

The following is a list of islands of Michigan. Michigan has the second longest coastline of any state after Alaska. Being bordered by four of the five Great Lakes—Erie, Huron, Michigan, and Superior—Michigan also has 64,980 inland lakes and ponds, as well as innumerable rivers, that may contain their own islands included in this list. The majority of the islands are within the Great Lakes. Other islands can also be found within other waterways of the Great Lake system, including Lake St. Clair, St. Clair River, Detroit River, and St. Marys River.
The largest of all the islands is Isle Royale in Lake Superior, which, in addition to its waters and other surrounding islands, is organized as Isle Royale National Park. Isle Royale itself is . The most populated island is Grosse Ile with approximately 10,000 residents, located in the Detroit River about 10 miles (16 km) south of Detroit. The majority of Michigan's islands are uninhabited and very small. Some of these otherwise unusable islands have been used for the large number of Michigan's lighthouses to aid in shipping throughout the Great Lakes, while others have been set aside as nature reserves. Many islands in Michigan have the same name, even some that are in the same municipality and body of water, such as Gull, Long, or Round islands.
Lake Erie.
Only Monroe County has territory in the westernmost portion of Lake Erie, which has a surface elevation of 571 ft (174 m). The islands in the southern portion of the county are part of the North Maumee Bay Archeological District of the Detroit River International Wildlife Refuge, in which Turtle Island is the only island in the state of Michigan that is shared by another state. This remote and tiny island is cut in half and shared with Ohio. While not distinct named islands in their own right, Sterling State Park and Pointe Mouillee are situated on several islands.
Lake Huron.
Lake Huron is the second largest of the Great Lakes (after Lake Superior) with a surface area of . Michigan is the only U.S. state to border Lake Huron, while the portion of the lake on the other side of the international border belongs to the Canadian province of Ontario. The vast majority of Michigan's islands in Lake Huron are centered around Drummond Island in the northernmost portion of the state's lake territory. Drummond Island is the largest of Michigan's islands in Lake Huron and is the second largest Michigan island after Lake Superior's Isle Royale. Another large group of islands is the Les Cheneaux Islands archipelago, which itself contains dozens of small islands. Many of the lake's islands are very small and uninhabited.
As the most popular tourist destination in the state, Mackinac Island is the most well known of Lake Huron's islands. Drummond Island is the most populous of Michigan's islands in Lake Huron, with a population of 992 at the 2000 census. While Mackinac Island had a population of only 553, there are thousands more seasonal workers and tourists during the summer months.
Lake Michigan.
Michigan only has islands in Lake Michigan in the northern portion of the lake. There are no islands in the southern half of Lake Michigan. The largest and most populated of Michigan's islands in Lake Michigan is Beaver Island at and 551 residents. Some of the smaller islands surrounding Beaver Island are part of the larger Michigan Islands National Wildlife Refuge.
Lake Superior.
Lake Superior is the largest of the Great Lakes, and the coastline is sparsely populated. At , Isle Royale is the largest Michigan island and is the center of Isle Royale National Park, which itself contains over 450 islands. The following is a list of islands in Lake Superior that are "not" part of Isle Royale National Park. For those islands, see the list of islands in Isle Royale National Park.
Lake St. Clair.
Lake St. Clair connects Lake Huron and Lake Erie through the St. Clair River in the north and the Detroit River in the south. At , it is one of the largest non-Great Lakes in the United States, but it only contains a small number of islands near the mouth of the St. Clair River, where all of the following islands are located. The largest of these islands is Harsens Island, and all the islands are in Clay Township in St. Clair County.
Detroit River.
The Detroit River runs for 32 miles (51 km) and connects Lake St. Clair to Lake Erie. For its entire length, it carries the international border between the United States and Canada. Some islands belong to Ontario in Canada and are not included in the list below. All islands on the American side belong to Wayne County. Portions of the southern portion of the river serve as wildlife refuges as part of the Detroit River International Wildlife Refuge. The largest and most populous island is Grosse Ile at and a population of around 10,000. Most of the islands are around and closely connected to Grosse Ile.
St. Marys River.
The St. Marys River connects Lake Superior and Lake Huron at the easternmost point of the Upper Peninsula. It carries the international border throughout its length, and some of the islands belong to neighboring Ontario. The largest of Michigan's islands in the river are Sugar Island and Neebish Island. Wider portions of the river are designated as Lake George, Lake Nicolet, and the Munuscong Lake. The whole length of the Michigan portion of the river is part of Chippewa County.
Inland islands.
Michigan has numerous inland lakes and rivers that also contain their own islands. The following also lists the body of water in which these islands are located. Five islands below (* and highlighted in green) are actually islands within an island; they are contained within inland lakes in Isle Royale.
Grand Lake.
Grand Lake is a large lake in Presque Isle County. While it is not the largest inland lake in Michigan, it does contain the most inland islands. At its shortest distance, it is located less than one mile (0.6 km) from Lake Huron, but the two are not connected. Grand Lake contains 14 islands, of which Grand Island is by far the largest.

</doc>
<doc id="19808" url="https://en.wikipedia.org/wiki?curid=19808" title="List of Governors of Michigan">
List of Governors of Michigan

The governor of Michigan is the head of the executive branch of Michigan's state government and serves as the commander-in-chief of the state's military forces. The governor has a duty to enforce state laws; the power to either approve or veto appropriation bills passed by the Michigan Legislature; the power to convene the legislature; and the power to grant pardons, except in cases of impeachment. He or she is also empowered to reorganize the executive branch of the state government.
Michigan was originally part of French and British holdings, and administered by their colonial governors. After becoming part of the United States, numerous areas of what is today Michigan were originally part of the Northwest Territory, Indiana Territory and Illinois Territory, and administered by territorial governors. In 1805, the Michigan Territory was created, and five men served as territorial governors, until Michigan was granted statehood in 1837. Forty-eight individuals have held the position of state governor. The first female governor, Jennifer Granholm, was elected in 2003.
After Michigan gained statehood, governors held the office for a two-year term, until the 1963 Michigan Constitution changed the term to four years. The number of times an individual could hold the office was unlimited until a 1992 constitutional amendment imposed a lifetime term limit of two four-year governorships. The longest serving governor in Michigan's history was William Milliken, who was promoted from lieutenant governor after Governor George W. Romney resigned, then was elected to three further successive terms.
Governors.
Michigan was part of colonial New France until the Treaty of 1763 transferred ownership to the Kingdom of Great Britain. During this time, it was governed by the Lieutenants General of New France until 1627, the Governors of New France from 1627 to 1663, and the Governors General of New France until the transfer to Great Britain. The 1783 Treaty of Paris ceded the territory that is now Michigan to the United States as part of the end of the Revolutionary War, but British troops were not removed from the area until 1796. During the British ownership, their governors administrated the area as part of the Canadian territorial holdings.
Prior to becoming its own territory, parts of Michigan were administered by the governors of the Northwest Territory, the governors of the Indiana Territory and the governors of the Illinois Territory. On June 30, 1805, the Territory of Michigan was created, with General William Hull as the first territorial governor.
Governors of the State of Michigan.
Michigan was admitted to the Union on January 26, 1837. The original 1835 Constitution of Michigan provided for the election of a governor and a lieutenant governor every 2 years. The fourth and current constitution of 1963 increased this term to four years. There was no term limit on governors until a constitutional amendment effective in 1993 limited governors to two terms.
Should the office of governor become vacant, the lieutenant governor becomes governor, followed in order of succession by the Secretary of State and the Attorney General. Prior to the current constitution, the duties of the office would devolve upon the lieutenant governor, without that person actually becoming governor. The term begins at noon on January 1 of the year following the election. Prior to the 1963 constitution, the governor and lieutenant governor were elected through separate votes, allowing them to be from different parties. In 1963, this was changed, so that votes are cast jointly for a governor and lieutenant governor of the same party.
Other high offices held.
Several governors also held other high positions within the state and federal governments. Eight governors served as U.S. House of Representatives members, while seven held positions in the U.S. Senate, all representing Michigan. Others have served as ambassadors, U.S. Cabinet members and state and federal Supreme Court justices.
Living former U.S. governors of Michigan.
, there are four former U.S. governors of Michigan who are currently living at this time. The most recent U.S. governor of Michigan to die, and also the most recently serving U.S. governor of Michigan to have died, was George W. Romney who served from January 1, 1963 until he left office on January 22, 1969 and died on July 26, 1995 eighteen days after his eighty-eighth birthday.

</doc>
<doc id="19809" url="https://en.wikipedia.org/wiki?curid=19809" title="Moses Amyraut">
Moses Amyraut

Moïse Amyraut, Latin Moyses Amyraldus (Bourgueil, September 1596 – January 8, 1664), in English texts often Moses Amyraut, was a French Protestant theologian and metaphysician. He is perhaps most noted for his modifications to Calvinist theology regarding the nature of Christ's atonement, which is referred to as Amyraldism or Amyraldianism.
Life.
Born at Bourgueil, in the valley of the Changeon in the province of Anjou, his father was a lawyer, and, preparing Moses for his own profession, sent him, on the completion of his study of the humanities at Orléans to the university of Poitiers.
At the university he took the degree of licentiate (BA) of laws. On his way home from the university he passed through Saumur, and, having visited the pastor of the Protestant church there, was introduced by him to Philippe de Mornay, governor of the city. Struck with young Amyraut's ability and culture, they both urged him to change from law to theology. His father advised him to revise his philological and philosophical studies, and read over Calvin's "Institutions," before finally determining a course. He did so, and decided for theology.
He moved to the Academy of Saumur and studied under John Cameron, who ultimately regarded him as his greatest scholar. He had a brilliant course, and was in due time licensed as a minister of the French Protestant Church. The contemporary civil wars and excitements hindered his advancement. His first church was in Saint-Aignan, in the province of Maine. There he remained two years. Jean Daillé, who moved to Paris, advised the church at Saumur to secure Amyraut as his successor, praising him "as above himself." The university of Saumur at the same time had fixed its eyes on him as professor of theology. The great churches of Paris and Rouen also contended for him, and to win him sent their deputies to the provincial synod of Anjou.
Amyraut had left the choice to the synod. He was appointed to Saumur in 1633, and to the professor's chair along with the pastorate. On the occasion of his inauguration he maintained for thesis "De Sacerdotio Christi". His co-professors were Louis Cappel and Josué de la Place, who also were Cameron's pupils and lifelong friends, who collaborated in the "Theses Salmurienses", a collection of theses propounded by candidates in theology prefaced by the inaugural addresses of the three professors. Amyraut soon gave to French Protestantism a new direction.
In 1631 he published his "Traité des religions"; and from this year onward he was a foremost man in the church. Chosen to represent the provincial synod of Anjou, Touraine and Maine at the 1631 , he was appointed as orator to present to the king "The Copy of their Complaints and Grievances for the Infractions and Violations of the Edict of Nantes".
Previous deputies had addressed the king on their bent knees, whereas the representatives of the Catholics had been permitted to stand. Amyraut consented to be orator only if the assembly authorized him to stand. There was intense resistance. Cardinal Richelieu himself, preceded by lesser dignitaries, condescended to visit Amyraut privately, to persuade him to kneel; but Amyraut held resolutely to his point and carried it. His "oration" on this occasion, which was immediately published in the French "Mercure", remains a striking landmark in the history of French Protestantism. During his absence on this matter the assembly debated "whether the Lutherans who desired it, might be admitted into communion with the Reformed Churches of France at the Lord's Table." It was decided in the affirmative previous to his return; but he approved with astonishing eloquence, and thereafter was ever in the front rank in maintaining intercommunion between all churches holding the main doctrines of the Reformation.
Pierre Bayle recounts the title-pages of no fewer than thirty-two books of which Amyraut was the author. These show that he took part in all the great controversies on predestination and Arminianism which then so agitated and harassed all Europe. Substantially he held fast the Calvinism of his preceptor Cameron; but, like Richard Baxter in England, by his breadth and charity he exposed himself to all manner of misconstruction. In 1634 he published his "Traité de la predestination", in which he tried to mitigate the harsh features of predestination by his "Universalismus hypotheticus". God, he taught, predestines all men to happiness on condition of their having faith. This gave rise to a charge of heresy, of which he was acquitted at the national synod held at Alençon in 1637, and presided over by Benjamin Basnage (1580–1652). The charge was brought up again at the national synod of Charenton in 1644, when he was again acquitted. A third attack at the synod of Loudun in 1659 met with no better success. The university of Saumur became the university of French Protestantism.
Amyraut had as many as a hundred students in attendance upon his lectures. One of these was William Penn, who would later go on to found the Pennsylvania Colony in America based in part on Amyraut's notions of religious freedom [http://www.quaker.org/wmpenn.html]. Another historic part filled by Amyraut was in the negotiations originated by Pierre le Gouz de la Berchère (1600–1653), first president of the "parlement" of Grenoble, when exiled to Saumur, for a reconciliation and reunion of the Catholics of France with the French Protestants. Very large were the concessions made by Richelieu in his personal interviews with Amyraut; but, as with the Worcester House negotiations in England between the Church of England and nonconformists, they inevitably fell through. On all sides the statesmanship and eloquence of Amyraut were conceded. His "De l'elevation de la foy et de l'abaissement de la raison en la creance des mysteres de la religion" (1641) gave him early a high place as a metaphysician. Exclusive of his controversial writings, he left behind him a very voluminous series of practical evangelical books, which have long remained the "fireside" favourites of the peasantry of French Protestantism. Amongst these are "Estat des fideles apres la mort"; "Sur l'oraison dominicale"; "Du merite des oeuvres"; "Traité de la justification"; and paraphrases of books of the Old and New Testament. His closing years were weakened by a severe fall he met with in 1657. He died on 18 January 1664.
Seventeenth century opponents.
There were a number of theologians who defended Calvinistic orthodoxy against Amyraut and Saumur, including Friedrich Spanheim (1600–1649) and Francis Turretin (1623–1687). Ultimately, the Helvetic Consensus was drafted to counteract the theology of Saumur and Amyraldism.

</doc>
<doc id="19811" url="https://en.wikipedia.org/wiki?curid=19811" title="Murray River">
Murray River

The Murray River (or River Murray) is Australia's longest river, at in length. The Murray rises in the Australian Alps, draining the western side of Australia's highest mountains, and then meanders across Australia's inland plains, forming the border between the states of New South Wales and Victoria as it flows to the northwest into South Australia. It turns south at Morgan for its final , reaching the ocean at Lake Alexandrina.
The water of the Murray flows through several terminal lakes that fluctuate in salinity (and were often fresh until recent decades) including Lake Alexandrina and The Coorong before emptying through the Murray Mouth into the southeastern portion of the Indian Ocean, often referenced on Australian maps as the Southern Ocean, near Goolwa. Despite discharging considerable volumes of water at times, particularly before the advent of largescale river regulation, the mouth has always been comparatively small and shallow.
As of 2010, the Murray River system receives 58 percent of its natural flow. It is perhaps Australia's most important irrigated region, and it is widely known as the food bowl of the nation.
Geography.
The Murray River forms part of the long combined Murray–Darling river system which drains most of inland Victoria, New South Wales, and southern Queensland. Overall the catchment area is one seventh of Australia's total land mass. The Murray carries only a small fraction of the water of comparably-sized rivers in other parts of the world, and with a great annual variability of its flow. In its natural state it has even been known to dry up completely during extreme droughts, although that is extremely rare, with only two or three instances of this occurring since official record keeping began.
The Murray River makes up much of the border between the Australian states of Victoria and New South Wales. Where it does, the border is the top of the bank of the southern side of the river (i.e., none of the river itself is actually in Victoria). This was determined in a 1980 ruling by Justice Ninian Stephen of the High Court of Australia, which settled the question as to which state had jurisdiction in the unlawful death of a man on an island in the middle of the river. This boundary definition can be ambiguous, since the river changes its course over time, and some of the river banks have been modified.
West of the line of longitude 141°E, the river continues as the border between Victoria and South Australia for approximately , where this is the only stretch where a state border runs down the middle of the river. This was due to a miscalculation during the 1840s, when the border was originally surveyed. Past this point, the Murray River is entirely within the state of South Australia.
Major settlements along.
The following major settlements are located along the course of the river, with population figures from the 2011 Census:
River life.
The Murray River (and associated tributaries) support a variety of unique river life adapted to its vagaries. This includes a variety of native fish such as the famous Murray cod, trout cod, golden perch, Macquarie perch, silver perch, eel-tailed catfish, Australian smelt, and western carp gudgeon, and other aquatic species like the Murray short-necked turtle, Murray River crayfish, broad-clawed yabbies, and the large clawed "Macrobrachium" shrimp, as well as aquatic species more widely distributed through southeastern Australia such as common longnecked turtles, common yabbies, the small claw-less "paratya" shrimp, water rats, and platypus. The Murray River also supports fringing corridors and forests of the river red gum.
The health of the Murray River has declined significantly since European settlement, particularly due to river regulation, and much of its aquatic life including native fish are now declining, rare or endangered. Recent extreme droughts (2000–07) have put significant stress on river red gum forests, with mounting concern over their long-term survival. The Murray has also flooded on occasion, the most significant of which was the flood of 1956, which inundated many towns on the lower Murray and which lasted for up to six months.
Introduced fish species such as carp, "gambusia", weather loach, redfin perch, brown trout, and rainbow trout have also had serious negative effects on native fish, while carp have contributed to environmental degradation of the Murray River and tributaries by destroying aquatic plants and permanently raising turbidity. In some segments of the Murray River, carp have become the only species found.
Ancient history.
Lake Bungunnia.
Between 2.5 and 0.5 million years ago the Murray River terminated in a vast freshwater lake called Lake Bungunnia. Lake Bungunnia was formed by earth movements that blocked the Murray River near Swan Reach during this period of time. At its maximum extent Lake Bungunnia covered , extending to near the Menindee Lakes in the north and to near Boundary Bend on the Murray in the south. The draining of Lake Bungunnia occurred approximately 0.6 million years ago.
Deep clays deposited by the lake are evident in cliffs around Chowilla in South Australia. Considerably higher rainfall would have been required to keep such a lake full; the draining of Lake Bungunnia appears to mark the end of a wet phase in the history of the Murray-Darling Basin and the onset of widespread arid conditions similar to today. A species of "Neoceratodus" lungfish existed in Lake Bungunnia (McKay & Eastburn, 1990); today "Neoceratodus" lungfish are only found in several Queensland rivers.
Cadell Fault and formation of the Barmah Red Gum Forests.
The noted Barmah Red Gum Forests owe their existence to the Cadell Fault. About 25,000 years ago, displacement occurred along the Cadell fault, raising the eastern edge of the fault, which runs north-south, above the floodplain. This created a complex series of events. A section of the original Murray River channel immediately behind the fault was abandoned, and it exists today as an empty channel known as Green Gully. The Goulburn River was dammed by the southern end of the fault to create a natural lake.
The Murray River flowed to the north around the Cadell Fault, creating the channel of the Edward River which exists today and through which much of the Murray River's waters still flow. Then the natural dam on the Goulburn River failed, the lake drained, and the Murray River avulsed to the south and started to flow through the smaller Goulburn River channel, creating "The Barmah Choke" and "The Narrows" (where the river channel is unusually narrow), before entering into the proper Murray River channel again.
This complex series of events, however, diverts attention from the primary result of the Cadell Fault — that the west-flowing water of the Murray River strikes the north-south fault and diverts both north and south around the fault in the two main channels (Edward and ancestral Goulburn) as well as a fan of small streams, and regularly floods a large amount of low-lying country in the area. These conditions are perfect for River Red Gums, which rapidly formed forests in the area. Thus the displacement of the Cadell Fault 25,000 BP led directly to the formation of the famous Barmah River Red Gum Forests.
The Barmah Choke and The Narrows mean the amount of water that can travel down this part of the Murray River is restricted. In times of flood and high irrigation flows the majority of the water, in addition to flooding the Red Gum forests, actually travels through the Edward River channel. The Murray River has not had enough flow power to naturally enlarge The Barmah Choke and The Narrows to increase the amount of water they can carry.
The Cadell Fault is quite noticeable as a continuous, low, earthen embankment as one drives into Barmah from the west, although to the untrained eye it may appear man-made.
Burra Creek.
The Burra Creek (also known as the Worlds End Creek), which flows through Burra township, was once part of the ancient Murray River system. The system used to cross the Northern Mount Lofty Ranges through the Burra creek gorge, and then flow out to Spencer Gulf near Port Pirie. The Murray River was diverted south at Morgan during Eocene times, about 50 million years ago by fault movements and uplifting of the fold belt.
Murray mouth.
The Murray Mouth is the point at which the Murray River empties into the sea, and the interaction between its shallow, shifting and variable currents and the open sea can be complex and unpredictable. During the peak period of Murray River commerce (roughly 1855 to 1920), it presented a major impediment to the passage of goods and produce between Adelaide and the Murray settlements, and many vessels foundered or were wrecked there.
Since the early 2000s, dredging machines have operated at the Murray Mouth, moving sand from the channel to maintain a minimal flow from the sea and into the Coorong's lagoon system. Without the 24-hour dredging, the Mouth would silt up and close, cutting the supply of fresh sea-water into the Coorong, which would then warm up, stagnate and die.
Mythology.
Being one of the major river systems in one of the driest continents of Earth, the Murray has significant cultural relevance to Indigenous Australians. According to the peoples of Lake Alexandrina, the Murray was created by the tracks of the Great Ancestor, Ngurunderi, as he pursued Pondi, the Murray Cod. The chase originated in the interior of New South Wales. Ngurunderi pursued the fish (who, like many totem animals in Aboriginal myths, is often portrayed as a man) on rafts (or "lala") made from red gums and continually launched spears at his target. But Pondi was a wily prey and carved a weaving path, carving out the river's various tributaries. Ngurunderi was forced to beach his rafts, and often create new ones as he changed from reach to reach of the river.
At Kobathatang, Ngurunderi finally got lucky, and struck Pondi in the tail with a spear. However, the shock to the fish was so great it launched him forward in a straight line to a place called Peindjalang, near Tailem Bend. Eager to rectify his failure to catch his prey, the hunter and his two wives (sometimes the escaped sibling wives of Waku and Kanu) hurried on, and took positions high on the cliff on which Tailem Bend now stands. They sprung an ambush on Pondi only to fail again. Ngurunderi set off in pursuit again, but lost his prey as Pondi dived into Lake Alexandrina. Ngurunderi and his women settled on the shore, only to suffer bad luck with fishing, being plagued by a water fiend known as Muldjewangk. They later moved to a more suitable spot at the site of present-day Ashville. The twin summits of Mount Misery are supposed to be the remnants of his rafts, they are known as "Lalangengall" or "the two watercraft".
Remarkably, this story of a hunter pursuing a Murray cod that carved out the Murray persists in numerous forms in various language groups that inhabit the enormous area spanned by the Murray system. The Wotojobaluk people of Victoria tell of Totyerguil from the area now known as Swan Hill who ran out of spears while chasing Otchtout the cod.
European exploration.
The first Europeans to encounter the river were Hamilton Hume and William Hovell, who crossed the river where Albury now stands in 1824: Hume named it the "Hume River" after his father. In 1830 Captain Charles Sturt reached the river after travelling down its tributary the Murrumbidgee River and named it the "Murray River" in honour of the then British Secretary of State for War and the Colonies, Sir George Murray, not realising it was the same river that Hume and Hovell had encountered further upstream.
Sturt continued down the remaining length of the Murray to finally reach Lake Alexandrina and the river's mouth. The area of the Murray Mouth was explored more thoroughly by Captain Collet Barker in 1831.
In 1852 Francis Cadell, in preparation for the launch of his steamer service, explored the river in a canvas boat, travelling downstream from Swan Hill.
In 1858 the Government Zoologist, William Blandowski, along with Gerard Krefft, explored the lower reaches of the Murray and Darling rivers, compiling a list of birds and mammals.
River transport.
The lack of an estuary means that shipping cannot enter the Murray from the sea. However, in the 19th century the river supported a substantial commercial trade using shallow-draft paddle steamers, the first trips being made by two boats from South Australia on the spring flood of 1853. The "Lady Augusta", captained by Francis Cadell, reached Swan Hill while another, "Mary Ann", captained by William Randell, made it as far as Moama (near Echuca). In 1855 a steamer carrying gold-mining supplies reached Albury but Echuca was the usual turn-around point though small boats continued to link with up-river ports such as Tocumwal, Wahgunya and Albury.
The arrival of steamboat transport was welcomed by pastoralists who had been suffering from a shortage of transport due to the demands of the gold fields. By 1860 a dozen steamers were operating in the high water season along the Murray and its tributaries. Once the railway reached Echuca in 1864, the bulk of the woolclip from the Riverina was transported via river to Echuca and then south to Melbourne.
The Murray was plagued by "snags", fallen trees submerged in the water, and considerable efforts were made to clear the river of these threats to shipping by using barges equipped with steam-driven winches. In recent times, efforts have been made to restore many of these "snags" by placing dead gum trees back into the river. The primary purpose of this is to provide habitat for fish species whose breeding grounds and shelter were eradicated by the removal of "snags".
The volume and value of river trade made Echuca Victoria's second port and in the decade from 1874 it underwent considerable expansion. By this time up to thirty steamers and a similar number of barges were working the river in season. River transport began to decline once the railways touched the Murray at numerous points. The unreliable levels made it impossible for boats to compete with the rail and later road transport. However, the river still carries pleasure boats along its entire length.
Today, most traffic on the river is recreational. Small private boats are used for water skiing and fishing. Houseboats are common, both commercial for hire and privately owned. There are a number of both historic paddle steamers and newer boats offering cruises ranging from half an hour to 5 days. In 2009, British Adventurer David Cornthwaite walked and kayaked 2476 km along the Murray River from source to sea.
River crossings.
The Murray River has been a significant barrier to land-based travel and trade. Many of the Ports for transport of goods along the Murray have also developed as places to cross the river, either by bridge or ferry. The first bridge to cross the Murray, which was built in 1869, is in the town of Murray Bridge, formerly called Edwards Crossing.
Water storage and irrigation.
Small-scale pumping plants began drawing water from the Murray in the 1850s and the first high-volume plant was constructed at Mildura in 1887. The introduction of pumping stations along the river promoted an expansion of farming and led ultimately to the development of irrigation areas (including the Murrumbidgee Irrigation Area).
In 1915, the three Murray states – New South Wales, Victoria, and South Australia – signed the River Murray Agreement which proposed the construction of storage reservoirs in the river's headwaters as well as at Lake Victoria near the South Australian border. Along the intervening stretch of the river a series of locks and weirs were built. These were originally proposed to support navigation even in times of low water, but riverborne transport was already declining due to improved highway and railway systems.
Four large reservoirs were built along the Murray. In addition to Lake Victoria (completed late 1920s). These are Lake Hume near Albury–Wodonga (completed 1936), Lake Mulwala at Yarrawonga (completed 1939), and Lake Dartmouth, which is actually on the Mitta Mitta River upstream of Lake Hume (completed 1979). The Murray also receives water from the complex dam and pipeline system of the Snowy Mountains Scheme. An additional reservoir was proposed in the 1960s at Chowilla Dam which was to have been built in South Australia and would have flooded land mostly in Victoria and New South Wales. This reservoir was cancelled in favour of building Dartmouth Dam due to costs and concerns relating to increased salinity.
From 1935 to 1940 a series of barrages was built near the Murray Mouth to stop seawater egress into the lower part of the river during low flow periods. They are the Goolwa Barrage, located at , Mundoo Channel Barrage at , Boundary Creek Barrage at , Ewe Island Barrage at , and Tauwitchere Barrage at .
These dams inverted the patterns of the river's natural flow from the original winter-spring flood and summer-autumn dry to the present low level through winter and higher during summer. These changes ensured the availability of water for irrigation and made the Murray Valley Australia's most productive agricultural region, but have seriously disrupted the life cycles of many ecosystems both inside and outside the river, and the irrigation has led to dryland salinity that now threatens the agricultural industries.
The disruption of the river's natural flow, runoff from agriculture, and the introduction of pest species like the European carp has led to serious environmental damage along the river's length and to concerns that the river will be unusably salty in the medium to long term – a serious problem given that the Murray supplies 40 percent of the water supply for Adelaide. Efforts to alleviate the problems proceed but disagreement between various groups stalls progress.
In 2006, the state government of South Australia revealed its plan to investigate the construction of the controversial Wellington Weir.
Locks.
Lock 1 was completed near Blanchetown in 1922. Torrumbarry weir downstream of Echuca began operating in December 1923. Of the numerous locks that were proposed, only thirteen were completed; Locks 1 to 11 on the stretch downstream of Mildura, Lock 15 at Euston and Lock 26 at Torrumbarry. Construction of the remaining weirs purely for navigation purposes was abandoned in 1934. The last lock to be completed was Lock 15, in 1937.
Lock 11, just downstream of Mildura, creates a long lock pool which aided irrigation pumping from Mildura and Red Cliffs.
Each lock has a navigable passage next to it through the weir, which is opened during periods of high river flow, when there is too much water for the lock. The weirs can be completely removed, and the locks completely covered by water during flood conditions. Lock 11 is unique in that the lock was built inside a bend of the river, with the weir in the bend itself. A channel was dug to the lock, creating an island between it and the weir. The weir is also of a different design, being dragged out of the river during high flow, rather than lifted out.
See also.
Major tributaries
Population centres

</doc>
<doc id="19812" url="https://en.wikipedia.org/wiki?curid=19812" title="Project Mercury">
Project Mercury

Project Mercury was the first human spaceflight program of the United States, running from 1958 through 1963. An early highlight of the Space Race, its goal was to put a man into Earth orbit and return him safely, ideally before the Soviet Union. Taken over from the U.S. Air Force by the newly created civilian space agency NASA, it conducted twenty unmanned developmental flights (some using animals), and six successful flights by astronauts.
The Space Race began with the 1957 launch of the Soviet satellite Sputnik 1. This came as a shock to the American public, and led to the creation of NASA to expedite existing U.S. space exploration efforts, and place most of them under civilian control. After the successful launch of the Explorer 1 satellite in 1958, manned spaceflight became the next goal. The Soviet Union put the first human, cosmonaut Yuri Gagarin, into a single orbit aboard Vostok 1 on April 12, 1961. Shortly after this, on May 5, the U.S. launched its first astronaut, Alan Shepard, on a suborbital flight. Soviet Gherman Titov followed with a day-long orbital flight in August, 1961. The U.S. reached its orbital goal on February 20, 1962, when John Glenn made three orbits around the Earth. When Mercury ended in May 1963, both nations had sent six people into space, but the Soviets led the U.S. in total time spent in space.
The program took its name from the wing-footed, fleet god of travel in Roman mythology, cost $277 million in 1965 US dollars, and involved the work of 2 million people. The astronauts were collectively known as the "Mercury Seven", and each spacecraft was given a name ending with a "7" by its pilot.
The Mercury space capsule was produced by McDonnell Aircraft, and carried supplies of water, food and oxygen for about one day in a pressurized cabin. Mercury flights were launched from Cape Canaveral Air Force Station in Florida, on launch vehicles modified from the Redstone and Atlas D missiles. The capsule was fitted with a launch escape rocket to carry it safely away from the launch vehicle in case of a failure. The flight was designed to be controlled from the ground via the Manned Space Flight Network, a system of tracking and communications stations; back-up controls were outfitted on board. Small retrorockets were used to bring the spacecraft out of its orbit, after which an ablative heat shield protected it from the heat of atmospheric reentry. Finally, a parachute slowed the craft for a water landing. Both astronaut and capsule were recovered by helicopters deployed from a U.S. Navy ship.
After a slow start riddled with humiliating mistakes, the Mercury project gained popularity, its missions followed by millions on radio and TV around the world. Its success laid the groundwork for Project Gemini, which carried two astronauts in each capsule and perfected space docking maneuvers essential for manned lunar landings in the subsequent Apollo program announced a few weeks after the first manned Mercury flight.
Creation.
Project Mercury was officially approved on October 7, 1958 and publicly announced on December 17. Originally called Project Astronaut, President Dwight Eisenhower felt that gave too much attention to the pilot. Instead, the name "Mercury" was chosen from classical mythology, which had already lent names to rockets like the Greek "Atlas" and Roman "Jupiter" for the SM-65 and PGM-19 missiles. It absorbed military projects with the same aim, such as the Air Force Man In Space Soonest.
Background.
Following the end of World War II, a nuclear arms race evolved between the U.S. and the Soviet Union (USSR). Since the USSR did not have a large fleet of bomber planes to deliver such weapons to the U.S., or bases in the western hemisphere from which to deploy them, Joseph Stalin decided to develop intercontinental ballistic missiles, which drove a missile race. The rocket technology in turn enabled both sides to develop Earth-orbiting satellites for communications, and gathering weather data and intelligence. Americans were shocked when the Soviet Union placed the first satellite into orbit in October 1957, leading to a growing fear that the U.S. was falling into a "missile gap". A month later, the Soviets launched Sputnik 2, carrying a dog into orbit. Though the animal was not recovered alive, it was obvious their goal was manned spaceflight. Unable to disclose details of military space projects, President Eisenhower ordered the creation of a civilian space agency in charge of civilian and scientific space exploration. Based on the federal research agency National Advisory Committee for Aeronautics (NACA), it was named the National Aeronautics and Space Administration. It achieved its first goal, an American satellite in space, in 1958. The next goal was to put a man there.
The limit of space was defined at the time as a minimum altitude of , and the only way to reach it was by using rocket powered boosters. This created risks for the pilot, including explosion, high g-forces and vibrations during lift off through a dense atmosphere, and temperatures of more than from air compression during reentry.
In space, pilots would require pressurized chambers or space suits to supply fresh air. While there, they would experience weightlessness, which could potentially cause disorientation. Further potential risks included radiation and micrometeoroid strikes, both of which would normally be absorbed in the atmosphere. All seemed possible to overcome: experience from satellites suggested micrometeoroid risk was negligible, and experiments in the early 1950s with simulated weightlessness, high g-forces on humans, and sending animals to the limit of space, all suggested potential problems could be overcome by known technologies. Finally, reentry was studied using the nuclear warheads of ballistic missiles, which demonstrated a blunt, forward-facing heat shield could solve the problem of heating.
Organization and facilities.
T. Keith Glennan had been appointed the first Administrator of NASA, with Hugh L. Dryden (last Director of NACA) as his Deputy, at the creation of the agency on October 1, 1958. Glennan would report to the president through the National Aeronautics and Space Council. The group responsible for Project Mercury was NASA's Space Task Group, and the goals of the program were to orbit a manned spacecraft around Earth, investigate the pilot's ability to function in space, and to recover both pilot and spacecraft safely. Existing technology and off-the-shelf equipment would be used wherever practical, the simplest and most reliable approach to system design would be followed, and an existing launch vehicle would be employed, together with a progressive test program. Spacecraft requirements included: a launch escape system to separate the spacecraft and its occupant from the launch vehicle in case of impending failure; attitude control for orientation of the spacecraft in orbit; a retrorocket system to bring the spacecraft out of orbit; drag braking blunt body for atmospheric reentry; and landing on water. To communicate with the spacecraft during an orbital mission, an extensive communications network had to be built. In keeping with his desire to keep from giving the U.S. space program an overly military flavor, President Eisenhower at first hesitated to give the project top national priority (DX rating under the Defense Production Act), which meant that Mercury had to wait in line behind military projects for materials; however, this rating was granted in May 1959.
Twelve companies bid to build the Mercury spacecraft on a $20 million ($) contract. In January 1959, McDonnell Aircraft Corporation was chosen to be prime contractor for the spacecraft. Two weeks earlier, North American Aviation, based in Los Angeles, was awarded a contract for Little Joe, a small rocket to be used for development of the launch escape system. The World Wide Tracking Network for communication between the ground and spacecraft during a flight was awarded to the Western Electric Company. Redstone rockets for suborbital launches were manufactured in Huntsville, Alabama by the Chrysler Corporation and Atlas rockets by Convair in San Diego, California. For manned launches, the Atlantic Missile Range at Cape Canaveral Air Force Station in Florida was made available by the USAF. This was also the site of the Mercury Control Center while the computing center of the communication network was in Goddard Space Center, Maryland. Little Joe rockets were launched from Wallops Island, Virginia. Astronaut training took place at Langley Research Center in Virginia, Lewis Flight Propulsion Laboratory in Cleveland, Ohio, and Naval Air Development Center Johnsville in Warminster, PA. Langley wind tunnels together with a rocket sled track at Holloman Air Force Base at Alamogordo, New Mexico were used for aerodynamic studies. Both Navy and Air Force aircraft were made available for the development of the spacecraft's landing system, and Navy ships and Navy and Marine Corps helicopters were made available for recovery. South of Cape Canaveral the town of Cocoa Beach boomed. From here, 75,000 people watched the first American orbital flight being launched in 1962.
Spacecraft.
The Mercury spacecraft's principal designer was Maxime Faget, who started research for manned spaceflight during the time of the NACA. It was long and wide; with the launch escape system added, the overall length was . With of habitable volume, the capsule was just large enough for a single crew member. Inside were 120 controls: 55 electrical switches, 30 fuses and 35 mechanical levers. The heaviest spacecraft, Mercury-Atlas 9, weighed fully loaded. Its outer skin was made of René 41, a nickel alloy able to withstand high temperatures.
The spacecraft was cone shaped, with a neck at the narrow end. It had a convex base, which carried a heat shield (Item 2 in the diagram below) consisting of an aluminum honeycomb covered with multiple layers of fiberglass. Strapped to it was a retropack (1) consisting of three rockets deployed to brake the spacecraft during reentry. Between these were three minor rockets for separating the spacecraft from the launch vehicle at orbital insertion. The straps that held the package could be severed when it was no longer needed. Next to the heat shield was the pressurized crew compartment (3). Inside an astronaut would be strapped to a form-fitting seat, with instruments in front and his back to the heat shield. Underneath the seat was the environmental control system supplying oxygen and heat, scrubbing the air of CO2, vapor and odors, and (on orbital flights) collecting urine. The recovery compartment (4) at the narrow end of the spacecraft contained three parachutes: a drogue to stabilize free fall and two main chutes, a primary and reserve. Between the heat shield and inner wall of the crew compartment was a landing skirt, deployed by letting down the heat shield before landing. On top of the recovery compartment was the antenna section (5) containing both antennas for communication and scanners for guiding spacecraft orientation. Attached was a flap used to ensure the spacecraft was faced heat shield first during reentry. A launch escape system (6) was mounted to the narrow end of the spacecraft containing three small solid-fueled rockets which could be fired briefly in a launch failure to separate the capsule safely from its booster. It would deploy the capsule's parachute for a landing nearby at sea. (See also Mission profile for details.)
Pilot accommodations.
The astronaut lay in a sitting position with his back to the heat shield, which was found to be the position that best enabled a human to withstand the high g-forces of launch and re-entry. A form-fitted fiberglass seat was custom-molded from each astronaut's space-suited body for maximum support. Near his left hand was a manual abort handle to activate the launch escape system if necessary prior to or during liftoff, in case the automatic trigger failed.
To supplement the onboard environmental control system, he wore a pressure suit with its own oxygen supply, which would also cool him. A cabin atmosphere of pure oxygen at a low pressure of 5.5 psi (equivalent to an altitude of ) was chosen, rather than one with the same composition as air (nitrogen/oxygen) at sea level. This was easier to control, avoided the risk of decompression sickness (known as "the bends"), and also saved on spacecraft weight. Fires (which never occurred) would have to be extinguished by emptying the cabin of oxygen. In such case, or failure of the cabin pressure for any reason, the astronaut could make an emergency return to Earth, relying on his suit for survival. The astronauts normally flew with their visor up, which meant that the suit was not inflated. With the visor down and the suit inflated, the astronaut could only reach the side and bottom panels, where vital buttons and handles were placed.
The astronaut also wore electrodes on his chest to record his heart rhythm, a cuff that could take his blood pressure, and a rectal thermometer to record his temperature (this was replaced by an oral thermometer on the last flight). Data from these was sent to the ground during the flight. The astronaut normally drank water and ate food pellets.
Once in orbit, the spacecraft could be rotated in three directions: along its longitudinal axis (roll), left to right from the astronaut's point of view (yaw), and up or down (pitch). Movement was created by rocket-propelled thrusters which used hydrogen peroxide as a fuel. For orientation, the pilot could look through the window in front of him or from a screen connected to a periscope which could be turned 360°.
The Mercury astronauts had taken part in the development of their spacecraft, and insisted that manual control, and a window, be elements of its design. As a result, spacecraft movement and other functions could be controlled three ways: remotely from the ground when passing over a ground station, automatically guided by onboard instruments, or manually by the astronaut, who could replace or override the two other methods. Experience validated the astronauts' insistence on manual controls. Without them, Gordon Cooper's manual reentry during the last flight would not have been possible.
Development and production.
The Mercury spacecraft design was modified three times by NASA between 1958 and 1959. After bidding by potential contractors had been completed, NASA selected the design submitted as "C" in November 1958. After it failed a test flight in July 1959, a final configuration, "D", emerged. The heat shield shape had been developed earlier in the 1950s through experiments with ballistic missiles, which had shown a blunt profile would create a shock wave that would lead most of the heat around the spacecraft. To further protect against heat, either a heat sink, or an ablative material, could be added to the shield. The heat sink would remove heat by the flow of the air inside the shock wave, whereas the ablative heat shield would remove heat by a controlled evaporation of the ablative material. After unmanned tests, the latter was chosen for manned flights. Apart from the capsule design, a rocket plane similar to the existing X-15 was considered. This approach was still too far from being able to make a spaceflight, and was consequently dropped. The heat shield and the stability of the spacecraft were tested in wind tunnels, and later in flight. The launch escape system was developed through unmanned flights. During a period of problems with development of the landing parachutes, alternative landing systems such as the Rogallo glider wing were considered, but ultimately scrapped.
The spacecraft were produced at McDonnell Aircraft, St. Louis, Missouri in clean rooms and tested in vacuum chambers at the McDonnell plant. The spacecraft had close to 600 subcontractors, such as Garrett AiResearch which built the spacecraft's environmental control system. Final quality control and preparations of the spacecraft were made at Hangar S at Cape Canaveral. NASA ordered 20 production spacecraft, numbered 1 through 20. Five of the 20, Nos. 10, 12, 15, 17, and 19, were not flown. Spacecraft No. 3 and No. 4 were destroyed during unmanned test flights. Spacecraft No. 11 sank and was recovered from the bottom of the Atlantic Ocean after 38 years. Some spacecraft were modified after initial production (refurbished after launch abort, modified for longer missions, etc.) A number of Mercury boilerplate spacecraft (made from non-flight materials or lacking production spacecraft systems) were also made by NASA and McDonnell. They were designed and used to test spacecraft recovery systems and the escape tower. McDonnell also built the spacecraft simulators used by the astronauts during training.
Launch vehicles.
The Mercury program used two launch vehicles for manned missions. The most important was the Atlas LV-3B or Atlas D, a two-stage liquid fueled rocket used for orbital flight. It was developed by Convair for the Air Force during the mid-1950s and was fueled with liquid oxygen (LOX) and kerosene. It was by itself and with the spacecraft and the launch escape system (including the adapter that held both to the launch vehicle), its total height was . The first stage was a booster skirt with two engines using liquid fuel from the sustainer stage. This together with the larger sustainer stage gave it sufficient power to launch a Mercury spacecraft into orbit. Both stages fired from lift-off until staging of the booster; the sustainer through an opening in the booster. After staging, the sustainer stage continued alone. The sustainer also steered the rocket by thrusters guided by gyroscopes. Smaller vernier rockets were added on its sides for precise control of maneuvers. The Atlas was made of paper-thin stainless steel and had to be kept under constant internal pressure by fuel or helium in order to prevent the rocket from collapsing. This meant that the airframe of the launch vehicle could be reduced to 2% of the weight of the fuel. The Atlas D rocket also required extra strengthening in order to handle the increased weight of the Mercury spacecraft beyond that of the nuclear warheads it was designed for. Its internal guidance system also had to be moved accordingly to its greater length. The Titan missile was also considered for later Mercury missions but was not ready in time. The Atlas was flown to Cape Canaveral and transported to the launch pad on a dolly. At the launch pad, the rocket and dolly were lifted to a vertical position by the service tower and the Atlas was then held by clamps to the launch pad. Later the spacecraft was mounted.
The other manned launch vehicle was the Mercury-Redstone Launch Vehicle which was an (spacecraft and escape system included) tall single-stage launch vehicle used for suborbital (ballistic) flights. It had a liquid-fueled engine that burned alcohol and liquid oxygen producing about 75,000 pounds of thrust, which was not enough for orbital missions. It was a descendant of the German V-2, and developed for the U.S. Army during the early 1950s. It was modified for Project Mercury by removing the warhead and adding a collar for supporting the spacecraft together with material for damping vibrations during launch. Its rocket motor was produced by North American Aviation and its direction could be altered during flight by its fins. They worked in two ways: by directing the air around them or by directing the thrust by their inner parts (or both at the same time). Both the Atlas-D and Redstone launch vehicles contained an automatic abort sensing system which allowed them to abort a launch by firing the launch escape system if something went wrong. The Jupiter rocket, a relative of the Redstone, was originally considered for the suborbital launch vehicle, but was replaced by the Redstone in July 1959 due to budget constraints.
A smaller launch vehicle ( long) called Little Joe which carried a Mercury spacecraft with an escape tower mounted on it, was used for unmanned tests of the launch escape system. Its main purpose was to test the system at a point called max-q, at which air pressure against the spacecraft peaked, making separation of the launch vehicle and spacecraft most difficult. It was also the point at which the astronaut was subjected to the heaviest vibrations. The Little Joe rocket used solid-fuel propellant and was originally designed in 1958 by the NACA for suborbital manned flights, but was redesigned for Project Mercury to simulate an Atlas-D launch. It was produced by North American Aviation. It was not able to change direction, instead its flight depended on the angle from which it was launched. Its maximum altitude was fully loaded. A Scout launch vehicle was used for a single flight intended to evaluate the tracking network; however, it failed and was destroyed from the ground shortly after launch.
Astronauts.
NASA announced the selected seven astronauts – known as the Mercury Seven – on April 9, 1959, they were:
Shepard became the first American in space by making a suborbital flight in May 1961. He went on to fly in the Apollo program and became the only Mercury astronaut to walk on the Moon. Gus Grissom, who became the second American in space, also participated in the Gemini and Apollo programs, but died in January 1967 during a pre-launch test for Apollo 1. Glenn became the first American to orbit the Earth in February 1962, then quit NASA and went into politics, but returned to space aboard STS-95. Deke Slayton was grounded in 1962, but remained with NASA and flew on the Apollo-Soyuz Test Project in 1975. Gordon Cooper became the last to fly in Mercury and made its longest flight, and also flew a Gemini mission. Carpenter's Mercury flight was his only trip into space. Schirra flew the third orbital Mercury mission, and then flew a Gemini mission. Three years later, he commanded the first manned Apollo mission, becoming the only person to fly in all three of those programs.
One of the astronauts' tasks was publicity; they gave interviews to the press and visited project manufacturing facilities to speak with those who worked on Project Mercury. To make their travels easier, they requested and got jet fighters for personal use. The press was especially fond of John Glenn, who was considered the best speaker of the seven. They sold their personal stories to Life magazine which portrayed them as patriotic, God-fearing family men. Life was also allowed to be at home with the families while the astronauts were in space. During the project, Grissom, Carpenter, Cooper, Schirra and Slayton stayed with their families at or near Langley Air Force Base; Glenn lived at the base and visited his family in Washington DC on weekends. Shepard lived with his family at Naval Air Station Oceana in Virginia. As of January 2016, only one of them, John Glenn is still alive. He became the last surviving member with the death of Carpenter on October 10, 2013. He went on to become a US senator. Other than Grissom, the other five survived past retirement and died in between 1993 and 2013.
Selection and training.
It was first envisaged that the pilot could be any man or woman willing to take a personal risk. However, the first Americans to venture into space were drawn, on President Eisenhower's insistence, from a group of 508 active duty military test pilots, who were either USN or USMC naval aviation pilots (NAPs), or USAF pilots of Senior or Command rating. This excluded women, since there were no female military test pilots at the time. It also excluded civilian NASA X-15 pilot Neil Armstrong, though he had been selected by the U.S. Air Force in 1958 for its Man In Space Soonest program, which was replaced by Mercury. Although Armstrong had been a combat-experienced NAP during the Korean War, he left active duty in 1952. Armstrong became NASA's first civilian astronaut in 1962 when he was selected for NASA's second group, and became the first man on the Moon in 1969.
It was further stipulated that candidates should be between 25 and 40 years old, no taller than , and hold a college degree in science or engineering. The college degree requirement excluded the USAF's X-1 pilot, then-Lt Col (later Brig Gen) Chuck Yeager, the first person to exceed the speed of sound. He later became a critic of the project, ridiculing especially the use of monkeys as test subjects. USAF Capt (later Col) Joseph Kittinger, a USAF fighter pilot and stratosphere balloonist, met all the requirements but preferred to stay in his contemporary project. Other potential candidates declined because they did not believe that manned spaceflight had a future beyond Project Mercury. From the original 508, 110 candidates were selected for an interview, and from the interviews, 32 were selected for further physical and mental testing. Their health, vision, and hearing were examined, together with their tolerance to noise, vibrations, g-forces, personal isolation, and heat. In a special chamber, they were tested to see if they could perform their tasks under confusing conditions. The candidates had to answer more than 500 questions about themselves and describe what they saw in different images. Navy LT (later CAPT) Jim Lovell, a NAP who was later an astronaut in the Gemini and Apollo programs, did not pass the physical tests. After these tests it was intended to narrow the group down to six astronauts, but in the end it was decided to keep seven.
The astronauts went through a training program covering some of the same exercises that were used in their selection. They simulated the g-force profiles of launch and reentry in a centrifuge at the Naval Air Development Center, and were taught special breathing techniques necessary when subjected to more than 6 g. Weightlessness training took place in aircraft, first on the rear seat of a two-seater fighter and later inside converted and padded cargo aircraft. They practiced gaining control of a spinning spacecraft in a machine at the Lewis Flight Propulsion Laboratory called the Multi-Axis Spin-Test Inertia Facility (MASTIF), by using an attitude controller handle simulating the one in the spacecraft. A further measure for finding the right attitude in orbit was star and Earth recognition training in planetaria and simulators. Communication and flight procedures were practiced in flight simulators, first together with a single person assisting them and later with the Mission Control Center. Recovery was practiced in pools at Langley, and later at sea with frogmen and helicopter crews.
Mission profile.
Project Mercury had two kinds of missions: suborbital, and orbital. In the suborbital mission, a Redstone rocket lifted the spacecraft for 2 minutes and 30 seconds to an altitude of , separated from it and let it continue on a ballistic curve. Though not necessary for re-entry because orbital speed had not been attained, the spacecraft's retrorockets were fired, and the spacecraft landed in the Atlantic Ocean. Orbital missions with three orbits also landed in the Atlantic. The suborbital mission took 15 minutes, had an apogee altitude of , and a downrange distance of .
Preparations for a mission started a month in advance with the selection of the primary and back-up astronaut; they would practice together for the mission. For three days prior to launch, the astronaut went through a special diet to minimize his need for defecating during the flight. On the morning of the trip he typically ate a steak breakfast. After having sensors applied to his body and being dressed in the pressure suit, he started breathing pure oxygen to prepare him for the atmosphere of the spacecraft. He arrived at the launch pad, took the elevator up the launch tower and entered the spacecraft two hours before launch. Once the astronaut was secured inside, the hatch was bolted, the launch area evacuated and the mobile tower rolled back. After this, the launch vehicle was filled with liquid oxygen. The entire procedure of preparing for launch and launching the spacecraft followed a time table called the countdown. It started a day in advance with a pre-count, in which all systems of the launch vehicle and spacecraft were checked. After that followed a 15-hour hold, during which pyrotechnics were installed. Then came the main countdown which for orbital flights started 6½ hours before launch (T – 390 min), counted backwards to launch (T = 0) and then forward until orbital insertion (T + 5 min).
On an orbital mission, the Atlas' rocket engines were ignited 4 seconds before lift-off. The launch vehicle was held to the ground by clamps and then released when sufficient thrust was built up at lift-off (A). After 30 seconds of flight, the point of maximum dynamic pressure against the vehicle was reached, at which the astronaut felt heavy vibrations. After 2 minutes and 10 seconds, the two outboard booster engines shut down and were released with the aft skirt, leaving the center sustainer engine running (B). At this point, the launch escape system was no longer needed, and was separated from the spacecraft by its jettison rocket (C). The space vehicle moved gradually to a horizontal attitude until, at an altitude of , the sustainer engine shut down and the spacecraft was inserted into orbit (D). This happened after 5 minutes and 10 seconds in a direction pointing east, whereby the spacecraft would gain speed from the rotation of the Earth. Here the spacecraft fired the three posigrade rockets for a second to separate it from the launch vehicle. Just before orbital insertion and sustainer engine cutoff, g-loads peaked at 8 g (6 g for a suborbital flight). In orbit, the spacecraft automatically turned 180°, pointed the retropackage forward and its nose 14.5° downward and kept this attitude for the rest of the orbital phase of the mission, as it was necessary for communication with the ground.
Once in orbit, it was not possible for the spacecraft to change its trajectory except by initiating reentry. Each orbit would typically take 88 minutes to complete. The lowest point of the orbit called perigee was at the point where the spacecraft entered orbit and was about , the highest called apogee was on the opposite side of Earth and was about . When leaving orbit (E) the angle downward was increased to 34°, which was the angle of retrofire. Retrorockets fired for 10 seconds each (F) in a sequence where one started 5 seconds after the other. During reentry (G), the astronaut would experience about 8 g (11–12 g on a suborbital mission). The temperature around the heat shield rose to and at the same time, there was a two-minute radio blackout due to ionization of the air around the spacecraft. After re-entry, a small, drogue parachute (H) was deployed at for stabilizing the spacecraft's descent. The main parachute (I) was deployed at starting with a narrow opening that opened fully in a few seconds to lessen the strain on the lines. Just before hitting the water, the landing bag inflated from behind the heat shield to reduce the force of impact (J). Upon landing the parachutes were released. An antenna (K) was raised and sent out signals that could be traced by ships and helicopters. Further, a green marker dye was spread around the spacecraft to make its location more visible from the air. Frogmen brought in by helicopters inflated a collar around the craft to keep it upright in the water. The recovery helicopter hooked onto the spacecraft and the astronaut blew the escape hatch to exit the capsule. He was then hoisted aboard the helicopter that finally brought both him and the spacecraft to the ship.
Ground control.
The number of personnel supporting a Mercury mission was typically around 18,000, with about 15,000 people associated with recovery. Most of the others followed the spacecraft from the World Wide Tracking Network, a chain of 18 stations placed around the equator, which was based on a network used for satellites and made ready in 1960. It collected data from the spacecraft and provided two-way communication between the astronaut and the ground. Each station had a range of and a pass typically lasted 7 minutes. Mercury astronauts on the ground would take part of the Capsule Communicator or CAPCOM who communicated with the astronaut in orbit. Data from the spacecraft was sent to the ground, processed at the Goddard Space Center and relayed to the Mercury Control Center at Cape Canaveral. In the Control Center, the data was displayed on boards on each side of a world map, which showed the position of the spacecraft, its ground track and the place it could land in an emergency within the next 30 minutes.
The World Wide Tracking Network went on to serve subsequent space programs, until it was replaced by a satellite relay system in the 1980s Mission Control Center was moved from Cape Canaveral to Houston in 1965.
Flights.
On April 12, 1961 the Soviet cosmonaut Yuri Gagarin became the first person in space on an orbital flight. Alan Shepard became the first American in space on a suborbital flight three weeks later, on May 5, 1961. John Glenn, the third Mercury astronaut to fly, became the first American to reach orbit on February 20, 1962, but only after the Soviets had launched a second cosmonaut, Gherman Titov, into a day-long flight in August 1961. Three more Mercury orbital flights were made, ending on May 16, 1963 with a day-long, 22 orbit flight. However, the Soviet Union ended its Vostok program the next month, with the human spaceflight endurance record set by the 82-orbit, almost 5-day Vostok 5 flight.
Manned.
All of the manned Mercury flights were successful. The main medical problems encountered were simple personal hygiene, and post-flight symptoms of low blood pressure. The launch vehicles had been tested through unmanned flights, therefore the numbering of manned missions did not start with 1. Also, since two different launch vehicles were used, there were two separate numbered series: MR for "Mercury-Redstone" (suborbital flights), and MA for "Mercury-Atlas" (orbital flights). These names were not popularly used, since the astronauts followed a pilot tradition, each giving their spacecraft a name. They selected names ending with a "7" to commemorate the seven astronauts. Mercury-Redstone flights were launched from Launch Complex-5 while the Mercury-Atlas flights were launched from Launch Complex-14. Times given are Universal Coordinated Time, local time + 5 hours.
Unmanned.
The unmanned flights used Little Joe, Redstone, and Atlas launch vehicles. They were used to develop the launch vehicles, launch escape system, spacecraft and tracking network. One flight of a Scout rocket attempted to launch an unmanned satellite for testing the ground tracking network, but failed to reach orbit. The Little Joe program used seven airframes for eight flights, of which three were successful. The second Little Joe flight was named Little Joe 6, because it was inserted into the program after the first 5 airframes had been allocated.
Impact and legacy.
The project was delayed by 22 months, counting from the beginning until the first orbital mission. It had a dozen prime contractors, 75 major subcontractors, and about 7200 third-tier subcontractors, who together employed two million persons. An estimate of its cost made by NASA in 1969 gave $392.6 million ($ adjusted for inflation), broken down as follows: Spacecraft: $135.3 million, launch vehicles: $82.9 million, operations: $49.3 million, tracking operations and equipment: $71.9 million and facilities: $53.2 million.
Today the Mercury program is commemorated as the first manned American space program. It did not win the race against the Soviet Union, but gave back national prestige and was scientifically a successful precursor of later programs such as Gemini, Apollo and Skylab. During the 1950s, some experts doubted that manned spaceflight was possible. Still when John F. Kennedy was elected president, many including he had doubts about the project. As president he chose to support the programs a few months before the launch of "Freedom 7", which became a great public success. Afterwards, a majority of the American public supported manned spaceflight, and within a few weeks, Kennedy announced a plan for a manned mission to land on the Moon and return safely to Earth before the end of the 1960s. The six astronauts who flew were awarded medals, driven in parades and two of them were invited to address a joint session of the U.S. Congress. As a response to the selection criteria, which ruled out women, a private project was founded in which 13 women pilots successfully underwent the same tests as the men in Project Mercury. It was named Mercury 13 by the media Despite this effort, NASA did not select female astronauts until 1978 for the Space Shuttle.
In 1964, a monument commemorating Project Mercury was unveiled near Launch Complex 14 at Cape Canaveral, featuring a metal logo combining the symbol of Mercury with the number 7. In 1962, the United States Postal Service honored the Mercury-Atlas 6 flight with a Project Mercury commemorative stamp, the first U.S. postal issue to depict a manned spacecraft. The stamp first went on sale in Cape Canaveral, Florida on February 20, 1962, the same day as the first manned orbital flight. On May 4, 2011, the Postal Service released a stamp commemorating the 50th anniversary of "Freedom 7", the first manned flight of the project. On film, the program was portrayed in "The Right Stuff" a 1983 adaptation of Tom Wolfe's 1979 book of the same name. On February 25, 2011, the Institute of Electrical and Electronic Engineers, the world's largest technical professional society, awarded Boeing (the successor company to McDonnell Aircraft) a Milestone Award for important inventions which debuted on the Mercury spacecraft.
Patches.
Commemorative patches were designed by entrepreneurs after the Mercury program to satisfy collectors.
Videos.
Additional videos can be found on NASA's multimedia website.

</doc>
<doc id="19813" url="https://en.wikipedia.org/wiki?curid=19813" title="Gaius Maecenas">
Gaius Maecenas

Gaius Cilnius Maecenas (; 15 April 68 BC – 8 BC) was an ally, friend and political advisor to Octavian (who was to become the first Emperor of Rome as Caesar Augustus) as well as an important patron for the new generation of Augustan poets, including both Horace and Virgil. During the reign of Augustus, Maecenas served as a quasi-culture minister to the Emperor.
His name has become a byword for a wealthy, generous and enlightened patron of the arts.
Biography.
Expressions in Propertius seem to imply that Maecenas had taken some part in the campaigns of Mutina, Philippi and Perugia. He prided himself on his ancient Etruscan lineage, and claimed descent from the princely house of the Cilnii, who excited the jealousy of their townsmen by their preponderant wealth and influence at Arretium in the 4th century BC. Horace makes reference to this in his address to Maecenas at the opening of his first books of "Odes" with the expression "atavis edite regibus" (descendant of kings). Tacitus refers to him as "Cilnius Maecenas"; it is possible that "Cilnius" was his mother's nomen - or that Maecenas was in fact a cognomen.
The Gaius Maecenas mentioned in Cicero as an influential member of the equestrian order in 91 BC may have been his grandfather, or even his father. The testimony of Horace and Maecenas's own literary tastes imply that he had profited from the highest education of his time.
His great wealth may have been in part hereditary, but he owed his position and influence to his close connection with the Emperor Augustus. He first appears in history in 40 BC, when he was employed by Octavian in arranging his marriage with Scribonia, and afterwards in assisting to negotiate the Treaty of Brundisium and the reconciliation with Mark Antony. As a close friend and advisor he acted even as deputy for Augustus when he was abroad.
It was in 39 BC that Horace was introduced to Maecenas, who had before this received Lucius Varius Rufus and Virgil into his intimacy. In the "Journey to Brundisium," in 37, Maecenas and Marcus Cocceius Nerva - great-grandfather of the future emperor Nerva - are described as having been sent on an important mission, and they were successful in patching up, by the Treaty of Tarentum, a reconciliation between the two claimants for supreme power. During the Sicilian war against Sextus Pompeius in 36, Maecenas was sent back to Rome, and was entrusted with supreme administrative control in the city and in Italy. He was vicegerent of Octavian during the campaign that led to the Battle of Actium, when, with great promptness and secrecy, he crushed the conspiracy of Lepidus the Younger; during the subsequent absences of his chief in the provinces he again held the same position.
During the latter years of his life he fell somewhat out of favour with his master. Suetonius attributes the loss of the imperial favour to Maecenas' having indiscreetly revealed to Terentia, his beautiful but difficult wife, the discovery of the conspiracy in which her brother Lucius Licinius Varro Murena was implicated, but according to Cassius Dio (writing in the early 3rd century AD) it was due to the emperor's relations with Terentia. Maecenas died in 8 BC, leaving the emperor sole heir to his wealth.
Reputation.
Opinions were much divided in ancient times as to his personal character; but the testimony as to his administrative and diplomatic ability was unanimous. He enjoyed the credit of sharing largely in the establishment of the new order of things, of reconciling parties, and of carrying the new empire safely through many dangers. To his influence especially was attributed the more humane policy of Octavian after his first alliance with Antony and Lepidus. The best summary of his character as a man and a statesman, by Marcus Velleius Paterculus, describes him as "of sleepless vigilance in critical emergencies, far-seeing and knowing how to act, but in his relaxation from business more luxurious and effeminate than a woman." Expressions in the "Odes of Horace" seem to imply that Maecenas was deficient in the robustness of fibre which Romans liked to imagine was characteristic of their city.
"Maecenate" (patronage).
Maecenas is most famous for his support of young poets, hence his name has become the eponym for a ""patron of arts"". He supported Virgil who wrote the "Georgics" in his honour. It was Virgil, impressed with examples of Horace's poetry, who introduced Horace to Maecenas. Indeed, Horace begins the first poem of his "Odes" ("Odes" I.i) by addressing his new patron. Maecenas gave him full financial support as well as an estate in the Sabine mountains. Propertius and the minor poets Varius Rufus, Plotius Tucca, Valgius Rufus and Domitius Marsus also were his protégés.
His character as a munificent patron of literature - which has made his name a household word - is gratefully acknowledged by the recipients of it and attested by the regrets of the men of letters of a later age, expressed by Martial and Juvenal. His patronage was exercised, not from vanity or a mere dilettante love of letters, but with a view to the higher interest of the state. He recognized in the genius of the poets of that time, not only the truest ornament of the court, but a power of reconciling men's minds to the new order of things, and of investing the actual state of affairs with an ideal glory and majesty. The change in seriousness of purpose between the "Eclogues" and the "Georgics" of Virgil was in a great measure the result of the direction given by the statesman to the poet's genius. A similar change between the earlier odes of Horace, in which he declares his epicurean indifference to affairs of state, and the great national odes of the third book has been ascribed by some to the same guidance.
Maecenas endeavoured also to divert the less masculine genius of Propertius from harping continually on his love to themes of public interest. But if the motive of his patronage had been merely politic it never could have inspired the affection which it did in its recipients. The great charm of Maecenas in his relation to the men of genius who formed his circle was his simplicity, cordiality and sincerity. Although not particular in the choice of some of the associates of his pleasures, he admitted none but men of worth to his intimacy, and when once admitted they were treated like equals. Much of the wisdom of Maecenas probably lives in the "Satires" and "Epistles" of Horace. It has fallen to the lot of no other patron of literature to have his name associated with works of such lasting interest as the "Georgics" of Virgil, the first three books of Horace's "Odes," and the first book of his "Epistles."
Works.
Maecenas also wrote literature himself in both prose and verse. The some twenty fragments that remain show that he was less successful as an author than as a judge and patron of literature.
His prose works on various subjects – "Prometheus," dialogues like "Symposium" (a banquet at which Virgil, Horace and Messalla were present), "De cultu suo " (on his manner of life) and a poem "In Octaviam" ("Against Octavia") of which the content is unclear - were ridiculed by Augustus, Seneca and Quintilian for their strange style, the use of rare words and awkward transpositions.
According to Dio Cassius, Maecenas was also the inventor of a system of shorthand.
Gardens of Maecenas.
Maecenas sited his famous gardens, the first gardens in the Hellenistic-Persian garden style in Rome, on the Esquiline Hill, atop the Servian Wall and its adjoining necropolis, near the gardens of Lamia. It contained terraces, libraries and other aspects of Roman culture. Maecenas is said to have been the first to construct a swimming bath of hot water in Rome, which may have been in the gardens. The luxury of his gardens and villas incurred the displeasure of Seneca the Younger.
Though the approximate site is known, it is not easy to reconcile literary indications to determine the gardens' exact location, whether or not they lay on both sides of the Servian "ager" and both north and south of the porta Esquilina. Common graves of the archaic Esquiline necropolis have been found near the north-west corner of the modern Piazza Vittorio Emanuele, that is, outside the Esquiline gate of antiquity and north of the "via Tiburtina vetus"; most probably the "horti Maecenatiani" extended north from this gate and road on both sides of the "ager". The "Auditorium of Maecenas", a probable venue for dining and entertainment, may still be visited (upon reservation) on Largo Leopardi near Via Merulana.
The gardens became imperial property after Maecenas's death, and Tiberius lived there after his return to Rome in 2 AD. Nero connected them with the Palatine Hill via his Domus Transitoria, and viewed the burning of that from the turris Maecenatiana. This turris was probably the "molem propinquam nubibus arduis" ("the pile, among the clouds") mentioned by Horace.
Whether the "horti Maecenatiani" bought by Fronto actually were the former gardens of Maecenas is unknown, and the "domus Frontoniana" mentioned in the twelfth century by Magister Gregorius may also refer to the gardens of Maecenas.
Legacy.
His name has become a byword in many languages for a well-connected and wealthy patron, a role which he is celebrated for in the two poems, the "Elegiae in Maecenatem", which were written after his death and collected in the "Appendix Vergiliana". In various languages, it has even been coined into a word for (private) patronage (mainly cultural, but sometimes wider, usually perceived as more altruistic than sponsorship). A verse of the student song "Gaudeamus igitur" wishes longevity upon the charity of the students' benefactors ("Maecenatum", genitive plural of "Maecenas").
The word "Maecenas", in the sense of cultural benefactor, was the penultimate word used in the 2009 Scripps National Spelling Bee, on May 28, 2009. It was spelled incorrectly.
Film and television portrayals.
Maecenas was portrayed by Alex Wyndham in the second season of the 2005 HBO television series "Rome". He was portrayed by Russell Barr in the made-for-TV movie . He is also featured in one episode of the second series of Plebs on ITV.

</doc>
<doc id="19814" url="https://en.wikipedia.org/wiki?curid=19814" title="Meander (disambiguation)">
Meander (disambiguation)

A meander is a bend in a river.
Meander may also refer to:
In geography:
In other fields:

</doc>
<doc id="19818" url="https://en.wikipedia.org/wiki?curid=19818" title="March 16">
March 16


</doc>
<doc id="19820" url="https://en.wikipedia.org/wiki?curid=19820" title="Magick (Thelema)">
Magick (Thelema)

Magick, in the context of Aleister Crowley's Thelema, is a term used to differentiate the occult from stage magic and is defined as "the Science and Art of causing Change to occur in conformity with Will", including both "mundane" acts of will as well as ritual magic. Crowley wrote that "it is theoretically possible to cause in any object any change of which that object is capable by nature". John Symonds and Kenneth Grant attach a deeper occult significance to this preference.
Crowley saw Magick as the essential method for a person to reach true understanding of the self and to act according to one's true will, which he saw as the reconciliation "between freewill and destiny." Crowley describes this process in his "Magick, Book 4":
Definitions and general purpose of Magick.
The term itself is an Early Modern English spelling for "magic", used in works such as the 1651 translation of Heinrich Cornelius Agrippa's "De Occulta Philosophia", "Three Books of Occult Philosophy, or Of Magick". Aleister Crowley chose the spelling to differentiate his practices and rituals from stage magic and the term has since been re-popularised by those who have adopted elements of his teachings.
Crowley defined Magick as "the science and art of causing change to occur in conformity with will." He goes on to elaborate on this, in one postulate, and twenty eight theorems. His first clarification on the matter is that of a postulate, in which he states "ANY required change may be effected by the application of the proper kind and degree of Force in the proper manner, through the proper medium to the proper object." He goes on further to state:
Paranormal effects.
Crowley made many theories for the paranormal effects of Magick; however, as magicians and mystics had done before him and continue to do after him, Crowley dismissed such effects as useless:
Even so, Crowley recognized that paranormal effects and magical powers have some level of value for the individual:
Techniques of Magick.
There are several ways to view what Magick is. Again, at its most broad, it can be defined as any willed action leading to intended change. It can also be seen as the general set of methods used to accomplish the Great Work of mystical attainment. At the practical level, Magick most often takes several practices and forms of ritual, including banishing, invocation and evocation, eucharistic ritual, consecration and purification, astral travel, yoga, sex magic, and divination.
Banishing.
The professed purpose of banishing rituals is to eliminate forces that might interfere with a magical operation, and they are often performed at the beginning of an important event or ceremony (although they can be performed for their own sake as well). The area of effect can be a magick circle, a room, or the magician himself. The general theory of Magick proposes that there are various forces which are represented by the classical elements (air, earth, fire, and water), the planets, the signs of the Zodiac, and adjacent spaces in the astral world. Magick also proposes that various spirits and non-corporeal intelligences can be present. Banishings are performed in order to "clean out" these forces and presences. It is not uncommon to believe that banishings are more psychological than anything else, used to calm and balance the mind, but that the effect is ultimately the same—a sense of cleanliness within the self and the environment. There are many banishing rituals, but most are some variation on two of the most common—"The Star Ruby" and the Lesser Banishing Ritual of the Pentagram.
Crowley describes banishing in his "Magick, Book 4" (ch.13):
However, he further asserts:
Purification.
Purification is similar in theme to banishing, but is a more rigorous process of preparing the self and her temple for serious spiritual work. Crowley mentions that ancient magicians would purify themselves through arduous programs, such as through special diets, fasting, sexual abstinence, keeping the body meticulously tidy, and undergoing a complicated series of prayers. He goes on to say that purification no longer requires such activity, since the magician can purify the self via willed intention. Specifically, the magician labors to purify the mind and body of all influences which may interfere with the Great Work:
Crowley recommended symbolically ritual practices, such as bathing and robing before a main ceremony: "The bath signifies the removal of all things extraneous or antagonistic to the one thought. The putting on of the robe is the positive side of the same operation. It is the assumption of the frame of mind suitable to that one thought."
Consecration.
Consecration is an equally important magical operation. It is essentially the dedication, usually of a ritual instrument or space, to a specific purpose. In "Magick, Book 4" (ch.13), Crowley writes:
Invocation.
Invocation is the bringing in or identifying with a particular deity or spirit. Crowley wrote of two keys to success in this arena: to "inflame thyself in praying" and to "invoke often". For Crowley, the single most important invocation, or any act of Magick for that matter, was the invocation of one's Holy Guardian Angel, or "secret self", which allows the adept to know his or her True Will.
Crowley describes the experience of invocation:
Crowley ("Magick, Book 4") discusses three main categories of invocation, although "in the great essentials these three methods are one. In each case the magician identifies himself with the Deity invoked."
Another invocatory technique that the magician can employ is called the "assumption of godforms"—where with "concentrated imagination of oneself in the symbolic shape of any God, one should be able to identify oneself with the idea which god represents." A general method involves positioning the body in a position that is typical for a given god, imagining that the image of the god is coinciding with or enveloping the body, accompanied by the practice of "vibration" of the appropriate god-name(s).
Evocation.
There is a distinct difference between invocation and evocation, as Crowley explains:
Generally, evocation is used for two main purposes: to gather information and to obtain the services or obedience of a spirit or demon. Crowley believed that the most effective form of evocation was found in the grimoire on Goetia (see below), which instructs the magician in how to safely summon forth and command 72 infernal spirits. However, it is equally possible to evoke angelic beings, gods, and other intelligences related to planets, elements, and the Zodiac.
Unlike with invocation, which involves a calling in, evocation involves a calling forth, most commonly into what is called the "triangle of art."
Eucharist.
The word "eucharist" originally comes from the Greek word for thanksgiving. However, within Magick, it takes on a special meaning—the transmutation of ordinary things (usually food and drink) into divine sacraments, which are then consumed. The object is to infuse the food and drink with certain properties, usually embodied by various deities, so that the adept takes in those properties upon consumption. Crowley describes the process of the regular practice of eucharistic ritual:
There are several eucharistic rituals within the magical canon. Two of the most well known are The Mass of the Phoenix and The Gnostic Mass. The first is a ritual designed for the individual, which involves sacrificing a "Cake of Light" (a type of bread that serves as the host) to Ra (i.e. the Sun) and infusing a second Cake with the adept's own blood (either real or symbolic, in a gesture reflecting the myth of the Pelican cutting its own breast to feed its young) and then consuming it with the words, "There is no grace: there is no guilt: This is the Law: Do what thou wilt!" The other ritual, The Gnostic Mass, is a very popular public ritual (although it can be practiced privately) that involves a team of participants, including a Priest and Priestess. This ritual is an enactment of the mystical journey that culminates with the Mystic Marriage and the consumption of a Cake of Light and a goblet of wine (a process termed "communication"). Afterwards, each Communicant declares, "There is no part of me that is not of the gods!"
Yoga.
Generally speaking, Yoga is not considered to be Magick "per se.", by those who are really familiar with it. But in verity, it is the necessary training of the body and the mind to allow for certain types of illumination of the soul and the person himself to take place. Simply put, the goal is the control of the mind—to increase concentration and to be able to enter different states of consciousness. When developing his basic yogic program, Crowley borrowed heavily from many other yogis, such as Patanjali and Yajnavalkya.
Yoga, as Crowley interprets it, involves several key components. The first is Asana, which is the assumption (after eventual success) of any easy, steady and comfortable posture so as to maintain a good physique which complements the high level of enlightenment that meditation is accompanied with. Next is Pranayama, which is the control of breath, yogi's believe that the number of breaths a human takes are counted before one is even born and thus, by controlling the intake one may also be able to control the life. Mantram, the use of mantras enables the subject to use the knowledge of the Vedas "Atharva Veda" in this context adequately. Yama and Niyama are the adopted moral or behavioral codes (of the adept's choosing) that will be least likely to excite the mind. Pratyahara is the stilling of the thoughts so that the mind becomes quiet. Dharana is the beginning of concentration, usually on a single shape, like a triangle, which eventually leads to Dhyana, the loss of distinction between object and subject, which can be described as the annihilation of the ego (or sense of a separate self). The final stage is Samādhi—Union with the All, it is considered to be the utmost level of awareness that one could possibly achieve, according to Hindu mythology, one of their main three deities, Shiva, had mastered this and thus was bestowed upon with stupendous power and control.
Divination.
The art of divination is generally employed for the purpose of obtaining information that can guide the adept in his Great Work. The underlying theory states that there exists intelligences (either outside of or inside the mind of the diviner) that can offer accurate information within certain limits using a language of symbols. Normally, divination within Magick is not the same as fortune telling, which is more interested in predicting future events. Rather, divination tends to be more about discovering information about the nature and condition of things that can help the magician gain insight and to make better decisions.
There are literally hundreds of different divinatory techniques in the world. However, Western occult practice mostly includes the use of astrology (calculating the influence of heavenly bodies), bibliomancy (reading random passages from a book, such as Liber Legis or the I Ching), tarot (a deck of 78 cards, each with symbolic meaning, usually laid out in a meaningful pattern), and geomancy (a method of making random marks on paper or in earth that results in a combination of sixteen patterns).
It is an accepted truism within Magick that divination is imperfect. As Crowley writes, "In estimating the ultimate value of a divinatory judgment, one must allow for more than the numerous sources of error inherent in the process itself. The judgment can do no more than the facts presented to it warrant. It is naturally impossible in most cases to make sure that some important factor has not been omitted [...] One must not assume that the oracle is omniscient."
Other magical practices.
Qabalah and the Tree of Life.
The Tree of Life is a tool used to categorize and organize various mystical concepts. At its most simple level, it is composed of ten spheres, or emanations, called sephiroth (sing. "sephira") which are connected by twenty two paths. The sephiroth are represented by the planets and the paths by the characters of the Hebrew alphabet, which are subdivided by the four classical elements, the seven classical planets, and the twelve signs of the Zodiac. Within the western magical tradition, the Tree is used as a kind of conceptual filing cabinet. Each sephira and path is assigned various ideas, such as gods, cards of the Tarot, astrological planets and signs, elements, etc.
Crowley considered a deep understanding of the Tree of Life to be essential to the magician:
Similar to yoga, learning the Tree of Life is not so much Magick as it is a way to map out one's spiritual universe. As such, the adept may use the Tree to determine a destination for astral travel, to choose which gods to invoke for what purposes, et cetera. It also plays an important role in modeling the spiritual journey, where the adept begins in Malkuth, which is the every-day material world of phenomena, with the ultimate goal being at Kether, the sphere of Unity with the All.
Magical record.
A magical record is a journal or other source of documentation containing magical events, experiences, ideas, and any other information that the magician may see fit to add. There can be many purposes for such a record, such as recording evidence to verify the effectiveness of specific procedures (per the scientific method that Aleister Crowley claimed should be applied to the practice of Magick) or to ensure that data may propagate beyond the lifetime of the magician. Benefits of this process vary, but usually include future analysis and further education by the individual and/or associates with whom the magician feels comfortable in revealing such intrinsically private information.
Crowley was highly insistent upon the importance of this practice. As he writes in Liber E, "It is absolutely necessary that all experiments should be recorded in detail during, or immediately after, their performance ... The more scientific the record is, the better. Yet the emotions should be noted, as being some of the conditions. Let then the record be written with sincerity and care; thus with practice it will be found more and more to approximate to the ideal." Other items he suggests for inclusion include the physical and mental condition of the experimenter, the time and place, and environmental conditions, including the weather.
Components of ritual magic.
Magical weapons.
As with Magick itself, a "magical weapon" is any instrument used to bring about intentional change. As Crowley writes, "Illustration: It is my Will to inform the World of certain facts within my knowledge. I therefore take "magical weapons", pen, ink, and paper ... The composition and distribution of this book is thus an act of Magick by which I cause Changes to take place in conformity with my Will." With that said, in practice, magical weapons are usually specific, consecrated items used within ceremonial magic. There is no hard and fast rule for what is or isn't a magical weapon—if a magician considers it such a weapon, then it is. However, there does exist a set of magical weapons that have particular uses and symbolic meanings. Common weapons include the dagger (or athame in neopagan parlance), sword, wand, holy oil, cup (or graal), disk (or pentacle), oil lamp, bell, and thurible (or censer).
Magical formulae.
A magical formula is generally a name, word, or series of letters whose meaning illustrates principles and degrees of understanding that are often difficult to relay using other forms of speech or writing. It is a concise means to communicate very abstract information through the medium of a word or phrase, usually regarding a process of spiritual or mystical change. Common formulae include INRI, IAO, ShT, AUMGN, NOX, and LVX.
These words often have no intrinsic meaning in and of themselves. However, when deconstructed, each individual letter may refer to some universal concept found in the system that the formula appears. Additionally, in grouping certain letters together one is able to display meaningful sequences that are considered to be of value to the spiritual system that utilizes them (e.g. spiritual hierarchies, historiographic data, psychological stages, etc.)
Vibration of god-names.
In magical rituals involving the invocation of deities, a vocal technique called "vibration" is commonly used. This was a basic aspect of magical training for Crowley, who described it in "Liber O." According to that text, vibration involves a physical set of steps, starting in a standing position, breathing in through the nose while imagining the name of the god entering with the breath, imagining that breath travelling through the entire body, stepping forward with the left foot while throwing the body forward with arms outstretched, visualizing the name rushing out when spoken, ending in an upright stance, with the right forefinger placed upon the lips. According to Crowley in "Liber O", success in this technique is signaled by physical exhaustion and "though only by the student himself is it perceived, when he hears the name of the God vehemently roared forth, as if by the concourse of ten thousand thunders; and it should appear to him as if that Great Voice proceeded from the Universe, and not from himself."
In general ritual practice, "vibration" can also refer to a technique of saying a god-name or a magical formula in a long, drawn-out fashion (i.e. with a full, deep breath) that employs the nasal passages, such that the sound feels and sounds "vibrated'. This is known as Galdering.

</doc>
<doc id="19821" url="https://en.wikipedia.org/wiki?curid=19821" title="Tacitus (emperor)">
Tacitus (emperor)

Tacitus (; ; c. 200 – June 276), was Roman Emperor from 275 to 276. During his short reign he campaigned against the Goths and the Heruli, for which he received the title "Gothicus Maximus".
Early life.
Tacitus was born in Interamna (Terni), in Italia. He circulated copies of the historian Gaius Cornelius Tacitus' work, which was barely read at the time, and so we perhaps have him to thank for the partial survival of Tacitus' work; however, modern historiography rejects his claimed descent from the historian as forgery. In the course of his long life he discharged the duties of various civil offices, including that of consul in 273, with universal respect.
Emperor.
After the assassination of Aurelian, Tacitus was chosen by the Senate to succeed him, and the choice was cordially ratified by the army. This was the last time the Senate elected a Roman Emperor. There was an interregnum between Aurelian and Tacitus, and there is substantial evidence that Aurelian's wife, Ulpia Severina, ruled in her own right before the election of Tacitus. At any rate, Tacitus was situated at Campania when he heard the news of his election, and he quickly rushed to Rome. He decided to re-involve the Senate in some consultative manner in the mechanisms of government and asked the Senate to deify Aurelian, before arresting and executing Aurelian's murderers.
Fighting barbarians.
Next he moved against the barbarian mercenaries that had been gathered by Aurelian to supplement Roman forces for his Eastern campaign. These mercenaries had plundered several towns in the Eastern Roman provinces after Aurelian had been murdered and the campaign cancelled. His half-brother, the Praetorian Prefect Florianus, and Tacitus himself won a victory against these tribes, among which were the Heruli, gaining the emperor the title "Gothicus Maximus".
Death.
On his way back to the west to deal with a Frankish and Alamannic invasion of Gaul, according to Aurelius Victor, Eutropius and the Historia Augusta, Tacitus died of fever at Tyana in Cappadocia in June 276. It was reported that he began acting strangely, declaring that he would alter the names of the months to honor himself, before succumbing to a fever. In a contrary account, Zosimus claims he was assassinated, after appointing one of his relatives to an important command in Syria.
In popular culture.
He appears in Harry Sidebottom's historical fiction novel series "Warrior Of Rome".

</doc>
<doc id="19822" url="https://en.wikipedia.org/wiki?curid=19822" title="MV Tampa">
MV Tampa

MV "Tampa" is a roll-on/roll-off container ship completed in 1984 by Hyundai Heavy Industries Co., Ltd. in South Korea for the Norway-based firm, Wilhelmsen Lines Shipowning.
Tampa affair.
In August 2001, under Captain Arne Rinnan, a diplomatic dispute brewed between Australia, Norway, and Indonesia after "Tampa" rescued 438 Afghans from a distressed fishing vessel in international waters. The Afghans wanted passage to nearby Christmas Island. The Australian government sought to prevent this by refusing "Tampa" entry into Australian waters, insisting on their disembarkment elsewhere, and deploying the Special Air Service Regiment to board the ship. At the time of the incident, "Tampa" carried cargo worth , and 27 crew.
The crew of "Tampa" received the Nansen Refugee Award for 2002 from the United Nations High Commissioner for Refugees (UNHCR) for their efforts to follow international principles of saving people in distress at sea.
Cocaine smuggling bust.
In October 2006, MV "Tampa" was one of two Wilhelmsen ships involved in a cocaine-smuggling operation intercepted by the New Zealand Customs Service and the Australian Federal Police. Twenty-seven kilograms of cocaine was allegedly attached to the side of the two cargo ships bound for Australia in purpose-built metal pods, although New Zealand authorities stated they did not believe the ship's crew or owners were involved.
MythBusters test model.
In the 2006 episode of the TV show "MythBusters", a 1:550 scale model of MV "Tampa" was assembled, weighted with lead shot to simulate a full load of cargo, and used as a scale scientific test bed vehicle for determining whether ocean whirlpools are capable of sinking a large container ship.

</doc>
<doc id="19823" url="https://en.wikipedia.org/wiki?curid=19823" title="Maya numerals">
Maya numerals

The Maya numeral system is a vigesimal (base-twenty) positional numeral system used by the Pre-Columbian Maya civilization.
The numerals are made up of three symbols; zero (shell shape, with the plastron uppermost), one (a dot) and five (a bar). For example, thirteen is written as three dots in a horizontal row above two horizontal lines stacked above each other.
Numbers above 19.
<br>
Numbers after 19 were written vertically in powers of twenty. For example, thirty-three would be written as one dot above three dots, which are in turn atop two lines. The first dot represents "one twenty" or "1×20", which is added to three dots and two bars, or thirteen. Therefore, (1×20) + 13 = 33. Upon reaching 202 or 400, another row is started (203 or 8000, then 204 or 160,000, and so on). The number 429 would be written as one dot above one dot above four dots and a bar, or (1×202) + (1×201) + 9 = 429. The powers of twenty are numerals, just as the Hindu-Arabic numeral system uses powers of tens.
Other than the bar and dot notation, Maya numerals can be illustrated by face type glyphs or pictures. The face glyph for a number represents the deity associated with the number. These face number glyphs were rarely used, and are mostly seen on some of the most elaborate monumental carving.
Addition and subtraction:
Adding and subtracting numbers below 20 using Maya numerals is very simple.
Addition is performed by combining the numeric symbols at each level:<br>
If five or more dots result from the combination, five dots are removed and replaced by a bar. If four or more bars result, four bars are removed and a dot is added to the next higher row.
Similarly with subtraction, remove the elements of the subtrahend symbol from the minuend symbol:<br>
If there are not enough dots in a minuend position, a bar is replaced by five dots. If there are not enough bars, a dot is removed from the next higher minuend symbol in the column and four bars are added to the minuend symbol which is being worked on.
Zero.
The Maya/Mesoamerican Long Count calendar required the use of zero as a place-holder within its vigesimal positional numeral system. A shell glyph – – was used as a zero symbol for these Long Count dates, the earliest of which (on Stela 2 at Chiapa de Corzo, Chiapas) has a date of 36 BC.
However, since the eight earliest Long Count dates appear outside the Maya homeland, it is assumed that the use of zero predated the Maya, and was possibly the invention of the Olmec. Indeed, many of the earliest Long Count dates were found within the Olmec heartland. However, the Olmec civilization had come to an end by the 4th century BC, several centuries before the earliest known Long Count dates—which suggests that zero was "not" an Olmec discovery.
In the calendar.
In the "Long Count" portion of the Maya calendar, a variation on the strictly vigesimal numbering is used. The Long Count changes in the third place value; it is not 20×20 = 400, as would otherwise be expected, but 18×20, so that one dot over two zeros signifies 360. This is supposed to be because 360 is roughly the number of days in a year. (Some hypothesize that this was an early approximation to the number of days in the solar year, although the Maya had a quite accurate calculation of 365.2422 days for the solar year at least since the early Classic era.) Subsequent place values return to base-twenty.
In fact, every known example of large numbers uses this 'modified vigesimal' system, with the third position representing multiples of 18×20. It is reasonable to assume, but not proven by any evidence, that the normal system in use was a pure base-20 system.
Notes.
500

</doc>
<doc id="19826" url="https://en.wikipedia.org/wiki?curid=19826" title="Michael Foot">
Michael Foot

Michael Mackintosh Foot (23 July 1913 – 3 March 2010) was a British Labour Party politician and man of letters. Foot began his career as a journalist, becoming editor of "Tribune" on several occasions, and the "Evening Standard" newspaper at the age of just 28. He co-wrote the classic polemic against appeasement of Hitler, "Guilty Men", under a pseudonym.
Foot became a Member of Parliament (MP) from 1945 to 1955 and served again from 1960 until 1992. He was Deputy Leader of the Labour Party from 1976 to 1980, and later the Leader of the Labour Party and Leader of the Opposition from 1980 to 1983.
Associated with the left of the Labour Party for most of his career, Foot was an ardent supporter of the Campaign for Nuclear Disarmament and British withdrawal from the European Economic Community. He was appointed to the Cabinet as Secretary of State for Employment under Harold Wilson in 1974, and he later served as Leader of the House of Commons under James Callaghan. A passionate orator, he became party leader after its defeat in 1979. 
Foot's strongly left-wing political positions and criticisms of vacillating leadership made him an unpopular leader. Not particularly telegenic, he was also nicknamed "Worzel Gummidge" for his rumpled appearance. A right-wing faction of the party broke away to form the Social Democratic Party. Foot led Labour into the 1983 general election, when the party obtained its lowest share of the vote at a general election since 1918 and the fewest parliamentary seats it had had at any time since before 1945. He resigned after the election.
Among the books he authored are "Guilty Men", a biography of Jonathan Swift ("The Pen and the Sword", 1957) and a biography of Aneurin Bevan.
Family.
Foot was born in Lipson Terrace, Plymouth, Devon, the fifth of seven children of Isaac Foot (1880–1960) and Eva (née Mackintosh, died 17 May 1946), a Scotswoman. 
Isaac Foot was a solicitor and founder of the Plymouth law firm Foot and Bowden (which merged with another firm to become Foot Anstey). Isaac Foot was an active member of the Liberal Party and was Liberal Member of Parliament for Bodmin in Cornwall 1922–24 and 1929–35 and a Lord Mayor of Plymouth.
Michael Foot was the brother of Sir Dingle Foot MP (1905–78), a Liberal and subsequently Labour MP; Hugh Foot, Baron Caradon (1907–90), Governor of Cyprus (1957–60) and representative of the United Kingdom at the United Nations from 1964 to 1970; Liberal politician John Foot, Baron Foot (1909–99); Margaret Elizabeth Foot (1911–65), Jennifer Mackintosh Highet (born 1916) and Christopher Isaac Foot (born 1917). He was the uncle of campaigning journalist Paul Foot (1937–2004) and charity worker Oliver Foot (1946–2008).
Early life.
Foot was educated at Plymouth College Preparatory School, Forres School in Swanage, and Leighton Park School in Reading. When he left Forres School, the headmaster sent a letter to his father in which he said “he has been the leading boy in the school in every way”. He then went on to read Philosophy, Politics and Economics at Wadham College, Oxford. Foot was the President of the Oxford Union. He also took part in the ESU USA Tour (the debating tour of the USA run by the English-Speaking Union). On graduating with a second-class degree in 1934, he took a job as a shipping clerk in Birkenhead. Foot was profoundly influenced by the poverty and unemployment that he witnessed in Liverpool, which was on a different scale from anything he had seen in Plymouth. A Liberal up to this time, Foot was converted to socialism by Oxford University Labour Club president David Lewis, a Canadian Rhodes scholar, and others: "... I knew him Oxford when I was a Liberal Lewis played a part in converting me to socialism." Foot joined the Labour Party and first stood for parliament at the age of 22 in the 1935 general election, when he contested Monmouth. During this election Foot criticised the Prime Minister, Stanley Baldwin, for seeking rearmament. In his election address Foot contended that "the armaments race in Europe must be stopped now". Foot also supported unilateral disarmament, after multilateral disarmament talks at Geneva had broken down in 1933.
Foot became a journalist, working briefly on the "New Statesman", before joining the left-wing weekly "Tribune" when it was set up in early 1937 to support the Unity Campaign, an attempt to secure an anti-fascist United Front between Labour and the parties to its left. The campaign's members were Stafford Cripps's (Labour-affiliated) Socialist League, the Independent Labour Party and the Communist Party of Great Britain (CP). Foot resigned in 1938 after the paper's first editor, William Mellor, was fired for refusing to adopt a new CP policy of backing a Popular Front, including non-socialist parties, against fascism and appeasement. In a 1955 interview, Foot ideologically identified as a libertarian socialist.
Journalism.
On the recommendation of Aneurin Bevan, Foot was soon hired by Lord Beaverbrook to work as a writer on his "Evening Standard". (Bevan is supposed to have told Beaverbrook on the phone: "I've got a young bloody knight-errant here. They sacked his boss, so he resigned. Have a look at him.") At the outbreak of the Second World War, Foot volunteered for military service, but was rejected because of his chronic asthma. It was suggested in 2011 that he became a member of the secret Auxiliary Units.
In 1940, under the pen-name "Cato" he and two other Beaverbrook journalists (Frank Owen, editor of the "Standard", and Peter Howard of the "Daily Express") published "Guilty Men", a Left Book Club book attacking the appeasement policy of the Chamberlain government (thus Mr Foot reversed his position of the 1935 election - when he had attacked the Conservatives as militaristic and demanded disarmament in the face of Nazi Germany), which became a run-away best-seller. Beaverbrook made Foot editor of the "Evening Standard" in 1942 at the age of 28. During the war Foot made a speech that was later featured in the documentary TV series "The World at War" broadcast in February 1974. Foot was speaking in defence of the "Daily Mirror", which had criticised the conduct of the war by the Churchill Government. He mocked the notion that the Government would make no more territorial demands of other newspapers if they allowed the "Mirror" to be censored.
Foot left the "Standard" in 1945 to join the "Daily Herald" as a columnist. The "Daily Herald" was jointly owned by the TUC and Odhams Press, and was effectively an official Labour Party paper. He rejoined "Tribune" as editor from 1948 to 1952, and was again the paper's editor from 1955 to 1960. Throughout his political career he railed against the increasing corporate domination of the press, entertaining a special loathing for Rupert Murdoch.
Member of Parliament.
Foot fought the Plymouth Devonport constituency in the 1945 general election. His election agent was Labour activist and lifelong friend Ron Lemin. He won the seat for Labour for the first time, holding it until his surprise defeat by Dame Joan Vickers at the 1955 general election. Until 1957, he was the most prominent ally of Aneurin Bevan, who had taken Cripps's place as leader of the Labour left, though Foot and Bevan fell out after Bevan renounced unilateral nuclear disarmament at the 1957 Labour Party conference.
Before the Cold War began in the late 1940s, Foot favoured a 'third way' foreign policy for Europe (he was joint author with Richard Crossman and Ian Mikardo of the pamphlet "Keep Left" in 1947), but in the wake of the communist seizure of power in Hungary and Czechoslovakia he and "Tribune" took a strongly anti-communist position, eventually embracing NATO.
Foot was however a critic of the West's handling of the Korean War, an opponent of West German rearmament in the early 1950s and a founder member of the Campaign for Nuclear Disarmament. Under his editorship, "Tribune" opposed both the British government's Suez adventure and the Soviet crushing of the Hungarian Revolution in 1956. In this period he made regular television appearances on the current affairs programmes "In The News" (BBC) and subsequently "Free Speech" (ITV). "There was certainly nothing wrong with his television technique in those days", reflected Anthony Howard shortly after Foot's death.
Foot returned to parliament in 1960 at a by-election in Ebbw Vale in Monmouthshire, left vacant by Bevan's death. He had the Labour whip withdrawn in March 1961 after rebelling against the Labour leadership over air force estimates. He only returned to the Parliamentary Labour Group in 1963 when Harold Wilson became Labour leader after the sudden death of Hugh Gaitskell.
Harold Wilson – the subject of an enthusiastic campaign biography by Foot published by Robert Maxwell's Pergamon Press in 1964 – offered Foot a place in his first government, but Foot turned it down. Instead he became the leader of Labour's left opposition from the back benches, dazzling the Commons with his command of rhetoric. He opposed the government's moves to restrict immigration, join the Common Market and reform the trade unions, was against the Vietnam War and Rhodesia's unilateral declaration of independence, and denounced the Soviet suppression of "socialism with a human face" in Czechoslovakia in 1968. He also famously allied with the Tory right-winger Enoch Powell to scupper the government's plan to abolish the voting rights of hereditary peers and create a House of Lords comprising only life peers – a "seraglio of eunuchs" as Foot put it.
In 1967, Foot challenged James Callaghan but failed to win the post of Treasurer of the Labour Party.
In government.
After 1970, Labour moved to the left and Wilson came to an accommodation with Foot. Foot served in the Second Shadow Cabinet of Harold Wilson in various roles during 1970–74. In April 1972, he stood for the Deputy Leadership of the party, along with Edward Short and Anthony Crosland. Short defeated Foot in the second ballot after Crosland had been eliminated in the first.
When, in 1974, Labour returned to office under Harold Wilson, Foot became Secretary of State for Employment. According to Ben Pimlott, his appointment was intended to please the left of the party and the Trade Unions. In this role, he played the major part in the government's efforts to maintain the trade unions' support. He was also responsible for the Health and Safety at Work Act. Foot was one of the mainstays of the "no" campaign in the 1975 referendum on British membership of the European Economic Community. When Wilson retired in 1976, Foot contested the party leadership and led in the first ballot, but was ultimately defeated by James Callaghan. Later that year, Foot was elected Deputy Leader and served as Leader of the House of Commons, which gave him the unenviable task of trying to maintain the survival of the Callaghan government as its majority evaporated.
In 1975, Foot, along with Jennie Lee and others, courted controversy when they supported Indira Gandhi, the Prime Minister of India, after she prompted the declaration of a state of emergency. In December 1975, "The Times" ran an editorial titled 'Is Mr Foot a Fascist?' – their answer was that he was – after Norman Tebbit accused him of 'undiluted fascism' once Foot said that the Ferrybridge Six deserved dismissal for defying a closed shop.
Labour leadership.
Following Labour's 1979 general election defeat by Margaret Thatcher, James Callaghan remained party leader for the next 18 months before he resigned. Foot was elected Labour leader on 10 November 1980, beating Denis Healey in the second round of the leadership election (the last leadership contest to involve only Labour MPs). Foot presented himself as a compromise candidate capable, unlike Healey, of uniting the party, which at the time was riven by the grassroots left-wing insurgency centred around Tony Benn.
The Bennites were demanding revenge for what they considered to be the betrayals of the Callaghan government. They called for replacement of MPs who had acquiesced to Callaghan's policies by left-wingers who would support unilateral nuclear disarmament, withdrawal from the Common Market, and widespread nationalisation. (Benn did not stand for the leadership: apart from Foot and Healey, the other candidates – both eliminated in the first round – were John Silkin, a Tribunite like Foot, and the anti-European Peter Shore.)
When he became leader, Foot was already 67 and frail. After the 1979 energy crisis, Britain went into recession in 1980, which was blamed on the Tory government's controversial monetarist policy against inflation, which had the effect of increasing unemployment. As a result, Labour had moved ahead of the Tories in the opinion polls. After Foot's election as leader, opinion polls showed a double-digit lead for Labour, boosting his hopes of becoming prime minister in the next general election, which had to be held by May 1984.
When Foot became leader, the Conservative politician Kenneth Baker commented: "Labour was led by Dixon of Dock Green under Jim Callaghan. Now it is led by Worzel Gummidge." Foot's nickname in the press gradually became "Worzel Gummidge", or "Worzel". This became particularly common after Remembrance Day 1981. Foot was "depicted as as a scarecrow on ITV’s satirical puppet show Spitting Image."
Almost immediately after his election as leader he was faced with a serious crisis. In early 1981, four senior politicians from the right-wing of the Labour party (Roy Jenkins, Shirley Williams, David Owen and William Rodgers, the so-called "Gang of Four") left Labour to form the Social Democratic Party. This was largely seen as the consequence of the Labour Party's swing to the left, polarising divisions in an already divided party.
The SDP won the support of large sections of the media. For most of 1981 and early 1982 its opinion poll ratings suggested that it could at least overtake Labour and possibly win a general election. The Tories were then unpopular because of the economic policies of Margaret Thatcher, which had seen unemployment reach a postwar high.
The Labour left was still strong – in 1981 Benn decided to challenge Healey for the deputy leadership of the party, a contest Healey won narrowly. Foot struggled to make an impact and was widely criticised for his ineffectiveness, though his performances in the Commons, most notably on the Falklands war of 1982, won him widespread respect from other parliamentarians. He was criticised by some on the left for supporting Thatcher's immediate resort to military action. The right-wing newspapers nevertheless lambasted him consistently for what they saw as his bohemian eccentricity, attacking him for wearing what they described as a "donkey jacket" (actually he wore a type of duffel coat) at the wreath-laying ceremony at the Cenotaph on Remembrance Day in November 1981, for which he was likened to an "out-of-work navvy" by a fellow Labour MP. Foot did not make it generally known that the Queen Mother had described it as a "sensible coat for a day like this", which could be considered a slight or a compliment depending on whether irony was intended. He later donated the garment to the People's History Museum in Manchester.
The formation of the SDP – who formed an alliance with the Liberal Party in June 1981 – contributed to a fall in Labour support. The double-digit lead which had still been intact in opinion polls at the start of 1981 was swiftly wiped out, and by the end of October the opinion polls were showing the Alliance ahead of Labour. Labour briefly regained their lead of most opinion polls in early 1982, but when the Falklands conflict ended on 14 June 1982 with a British victory over Argentina, opinion polls showed the Tories firmly in the lead. Their position at the top of the polls was strengthened by the return to economic growth later in the year. It was looking certain that the Tories would be re-elected, and the only key issue that the media were still speculating by the end of 1982 was whether it would be Labour or the Alliance who formed the next opposition.
Through late 1982 and early 1983, there was constant speculation that Labour MPs would replace Foot with Healey as leader. Such speculation increased after Labour lost the 1983 Bermondsey by-election, in which Peter Tatchell was Labour candidate, standing against a Tory, a Liberal (eventual winner Simon Hughes) and John O'Grady, who had declared himself the Real Bermondsey Labour candidate. Critically, Labour held on in a subsequent by-election in Darlington and Foot remained leader for the 1983 general election.
1983 election.
The 1983 Labour manifesto, strongly socialist in tone, advocated unilateral nuclear disarmament, higher personal taxation and a return to a more interventionist industrial policy. The manifesto also pledged that a Labour government would abolish the House of Lords, nationalise banks and leave the then-European Economic Community. Gerald Kaufman, once Harold Wilson's press officer and during the 1980s prominent on the Labour right, described the 1983 Labour manifesto as "the longest suicide note in history."
The "Daily Mirror" was the only major newspaper to back Foot and Labour at the 1983 general election, urging its readers to vote Labour and "Stop the waste of our nation, for your job your children and your future" in response to the mass unemployment which followed Conservative prime minister Margaret Thatcher's monetarist economic policies to reduce inflation. Most other newspapers had urged their readers to vote Tory.
Foot's Labour Party lost to the Conservatives in a landslide – a result which had been widely predicted by the opinion polls since the previous summer. The only consolation for Foot and Labour was that they did not lose their place in opposition to the SDP-Liberal Alliance, who came close to them in terms of votes but were still a long way behind in terms of seats. Despite this, Foot was very critical of the Alliance, accusing them of "siphoning" Labour support and enabling the Tories to win more seats.
Resignation.
Foot resigned days after the election and was succeeded as leader on 2 October by Neil Kinnock, who had been tipped from the outset to be Labour's choice of new leader.
As a statement on internal democracy, Foot passed the edict that the manifesto would consist of all resolutions arrived at conference. The party also failed to master the medium of television, while Foot addressed public meetings around the country, and made some radio broadcasts, in the same manner as Clement Attlee in 1945. Members joked that they had not expected Foot to allow the slogan "Think positive, Act positive, Vote Labour" on grammatical grounds.
Foot's involvement in the nuclear disarmament movement gave rise to the beloved, if apocryphal, story that "The Times" ran the headline "Foot Heads Arms Body" over an article about his leadership of a nuclear-disarmament committee. Some decades later, Martyn Cornell recalled the story as true, saying he had written the headline himself as a "Times" subeditor around 1986. The headline does not, however, appear in The Times Digital Archive, which includes every day's newspaper for the years 1785–2007.
The Labour History Archive and Study Centre at the People's History Museum in Manchester holds a collection that spans Foot's entire political career from 1938 to 1990, and his personal papers dating back to 1926.
Backbenches and retirement.
Foot took a back seat in Labour politics after 1983 and retired from the House of Commons at the 1992 general election, when Labour lost to the Tories (led by John Major) for the fourth election in succession, but remained politically active. From 1987 to 1992, he was the oldest sitting British MP (preceding former Prime Minister Sir Edward Heath). He defended Salman Rushdie, the novelist who was subject to a fatwā requiring Rushdie's execution by Ayatollah Khomeini, and took a strongly pro-interventionist position against Serbia during its conflict with Croatia and Bosnia, supporting NATO forces whilst citing defence of civilian populations in the latter countries. In addition he was among the Patrons of the British-Croatian Society. "The Guardian"'s political editor Michael White criticised Foot's "overgenerous" support for Croatian leader Franjo Tuđman.
Foot remained a high-profile member of the Campaign for Nuclear Disarmament. He wrote several books, including highly regarded biographies of Aneurin Bevan and H. G. Wells. Indeed, he was a distinguished Vice-president of the H. G. Wells Society. Many of his friends have said publicly that they regret that he ever gave up literature for politics.
Foot was an Honorary Associate of the National Secular Society and a Distinguished Supporter of the British Humanist Association. He was elected in 1988 a Fellow of the Royal Society of Literature. 
In a poll of Labour party activists he was voted the worst post-war Labour party leader. Though Foot is considered by many a failure as Labour leader, his biographer Mervyn Jones strongly makes the case that no one else could have held Labour together at the time, particularly in the face of the controversy over the infiltration of the party by Militant. Foot is remembered with affection in Westminster as a great parliamentarian. He was widely liked, and admired for his integrity, habitual courtesy, and generosity of spirit, by both his colleagues and opponents.
A portrait of Foot by the artist Robert Lenkiewicz now permanently hangs in Portcullis House, Westminster.
Gordievsky allegations.
Oleg Gordievsky, a high-ranking KGB officer who defected from the Soviet Union to Britain in 1985, made allegations against Foot in his 1995 memoirs. "The Sunday Times", which serialised Gordievsky's book under the headline "KGB: Michael Foot was our agent", claimed in an article of 19 February that the Soviet intelligence services regarded Foot as an "agent of influence", codenamed "Agent BOOT", and in the pay of the KGB for many years. Crucially, the newspaper used material from the original manuscript of the book which had not been included in the published version. At the time a leading article in "The Independent" newspaper asserted: "It seems extraordinary that such an unreliable figure should now be allowed, given the lack of supporting evidence, to damage the reputation of figures such as Mr Foot." In a February 1992 interview, Gordievsky had claimed that he had no further Labour Party revelations to make. Foot successfully sued the "Sunday Times", winning "substantial" damages.
However, in the "Daily Telegraph" in 2010, Charles Moore gave a "full account", which he claimed had been provided to him by Gordievsky shortly after Foot's death, of the extent of Foot's alleged KGB involvement. The account provides additional information concerning the allegations, but no new evidence. The evidence against Foot consists solely of Gordievsky's testimony. Moore wrote that, although the claims are difficult to corroborate without MI6 and KGB files, Gordievsky's past record in revealing KGB contacts in Britain had been shown to be reliable. However Moore did not think that Foot would have known that he was considered an agent, and he probably considered that he was simply keeping the Soviet Union well informed in the interests of peace. There is no evidence Foot gave away secrets.
Plymouth Argyle.
Foot was a passionate supporter of Plymouth Argyle Football Club from his childhood and once remarked that he wasn't going to die until he had seen them play in the Premier League.
He served for several years as a director of the club, seeing two promotions under his tenure.
For his 90th birthday, Foot was registered with the Football League as an honorary player and given the shirt number 90. This made him the oldest registered professional player in the history of football.
Personal life.
Foot had no children. He was married to the film-maker, author and feminist historian Jill Craigie (1911–99) from 1949 until her death.
In February 2007, it was revealed that Foot had an extramarital affair with a woman around 35 years his junior in the early 1970s. The affair, which lasted nearly a year, put a considerable strain on his marriage. The affair is detailed in Foot's official biography, published in March 2007.
On 23 July 2006, his 93rd birthday, Michael Foot became the longest-lived leader of a major British political party, passing Lord Callaghan's record of 92 years, 364 days.
A staunch republican (though well liked by the Royal Family on a personal level), Foot rejected honours from the Queen and the government, including a knighthood and a peerage, on more than one occasion.
Health.
Foot suffered from asthma until 1963 (which disqualified him from service in World War II) and eczema until middle age.
In October 1963 he was involved in a car crash, suffering pierced lungs, broken ribs, and a broken left leg. Foot used a walking stick for the rest of his life. According to former MP Tam Dalyell, Foot had up to the accident been a chain-smoker, but gave up the habit thereafter.
In 1976, Foot became blind in one eye following an attack of shingles.
Death.
Foot died at his Hampstead, north London home in the morning of 3 March 2010. The House of Commons was informed of the news later that day by Justice Secretary Jack Straw, who told the House: "I am sure that this news will be received with great sadness not only in my own party but across the country as a whole." Foot's funeral was a non-religious service, held on 15 March 2010 at Golders Green Crematorium in north west London.
Fictional portrayals.
Foot was portrayed by Patrick Godfrey in the 2002 BBC production of Ian Curteis's long unproduced "The Falklands Play" and by Michael Pennington in the film "The Iron Lady".
Foot was likened to the scarecrow Worzel Gummidge in "Dear Bill", a long-running series of fictional letters which appeared in the British satirical magazine "Private Eye", purportedly written by Denis Thatcher, husband of Margaret Thatcher, to his fictional friend Bill.

</doc>
<doc id="19828" url="https://en.wikipedia.org/wiki?curid=19828" title="Max and Moritz">
Max and Moritz

Max and Moritz (A Story of Seven Boyish Pranks) (original: "Max und Moritz - Eine Bubengeschichte in sieben Streichen") is a German language illustrated story in verse. This highly inventive, blackly humorous tale, told entirely in rhymed couplets, was written and illustrated by Wilhelm Busch and published in 1865. It is among the early works of Busch, nevertheless it already features many substantial, effectually aesthetic and formal regularities, procedures and basic patterns of Busch's later works. Many familiar with comic strip history consider it to have been the direct inspiration for the "Katzenjammer Kids" and "Quick & Flupke". The German title satirizes the German custom of giving a subtitle to the name of dramas in the form of "Ein Drama in ... Akten" ("A Drama in ... Acts"), which became dictum in colloquial usage for any event with an unpleasant or dramatic course, e.g. "Bundespräsidentenwahl - Drama in drei Akten" ("Federal Presidential Elections - Drama in Three Acts").
Cultural significance.
Busch's classic tale of the terrible duo (now in the public domain) has since become a proud part of the culture in German-speaking countries. Even today, parents usually read these tales to their not-yet-literate children. To this day in Germany, Austria, and Switzerland, a certain familiarity with the story and its rhymes is still presumed, as it is often referenced in mass communication. The two leering faces are synonymous with mischief, and appear almost logo-like in advertising and even graffiti.
During World War 1, the Red Baron, Manfred von Richthofen, named his dog Moritz, giving the name Max to another animal given to his friend.
It even occurs that young German couples name their boy twins Max and Moritz respectively, depending on their individual sense of humour and the intended parenting.
"Max and Moritz" is the first published original foreign children’s book in Japan which was translated into rōmaji by Shinjirō Shibutani and Kaname Oyaizu in 1887 as "" ("Naughty stories").
Max and Moritz became the forerunners to the comic strip. The story inspired Rudolph Dirks to create The Katzenjammer Kids.
The influence of these characters in German culture is also evident in their names being applied to two British armoured command vehicles that were captured by the German army during World War 2 in North Africa. Their new German owners named the vehicles Max and Moritz, as can be seen in numerous photographs of the vehicles online and in books.
Max and Moritz also made an appearance on the Eastern Front during World War 2, as the nicknames of a pair of prototype self-propelled guns based on the Henschel 30.01 chassis; one of the two was destroyed, the other captured at Stalingrad. It is currently on display at the Kubinka Tank Museum.
After World War 2, German-U.S. composer Richard Mohaupt created together with choreographer Alfredo Bortoluzzi the dance burlesque ("Tanzburleske") "Max und Moritz", which premiered at Badisches Staatstheater Karlsruhe on December 18, 1949.
The pranks.
There have been several English translations of the original German verses over the years, but all have maintained the original trochaic tetrameter:
Preface.
Ah, how oft we read or hear of <br>
Boys we almost stand in fear of!<br>
For example, take these stories<br>
Of two youths, named Max and Moritz,<br>
Who, instead of early turning<br>
Their young minds to useful learning,<br>
Often leered with horrid features<br>
At their lessons and their teachers.
Look now at the empty head: he<br>
Is for mischief always ready.<br>
Teasing creatures - climbing fences,<br>
Stealing apples, pears, and quinces,<br>
Is, of course, a deal more pleasant,<br>
And far easier for the present,<br>
Than to sit in schools or churches,<br>
Fixed like roosters on their perches
But O dear, O dear, O deary,<br>
When the end comes sad and dreary!<br>
'Tis a dreadful thing to tell<br>
That on Max and Moritz fell!<br>
All they did this book rehearses,<br>
Both in pictures and in verses.
First Trick: The Widow.
The boys tie several crusts of bread together with thread, and lay this trap in the chicken yard of Bolte, an old widow, causing all the chickens to become fatally entangled.
This prank is remarkably similar to the eighth history of the classic German prankster tales of Till Eulenspiegel.
Second Trick: The Widow II.
As the widow cooks her chickens, the boys sneak onto her roof. When she leaves her kitchen momentarily, the boys steal the chickens using a fishing pole down the chimney. The widow hears her dog barking and hurries upstairs, finds the hearth empty and beats the dog.
Third Trick: The Tailor.
The boys torment Böck, a well-liked tailor who has a fast stream flowing in front of his house. They saw through the planks of his wooden bridge, making a precarious gap, then taunt him by making goat noises, until he runs outside. The bridge breaks; the tailor is swept away and nearly drowns (but for two geese, which he grabs a hold of and which fly high to safety).
Although Till removes the planks of the bridge instead of sawing them there are some similarities to Till Eulenspiegel (32nd History).
Fourth Trick: The Teacher.
While their devout teacher, Lämpel, is busy at church, the boys invade his home and fill his favorite pipe with gunpowder. When he lights the pipe, the blast knocks him unconscious, blackens his skin and burns away all his hair. But: "Time that comes will quick repair; yet the pipe retains its share."
Fifth Trick: The Uncle.
The boys collect bags full of May bugs, which they promptly deposit in their Uncle Fritz's bed. Uncle is nearly asleep when he feels the bugs walking on his nose. Horrified, he goes into a frenzy, killing them with a shoe.
Sixth Trick: The Baker.
The boys invade a bakery which they believe is closed. Attempting to steal pretzels, they fall into a vat of dough. The baker returns, catches the breaded pair, and bakes them. But they survive, and escape by gnawing through their crusts.
Final Trick: The Farmer.
Hiding out in the grain storage area of a farmer, Mecke, the boys slit some grain sacks. Carrying away one of the sacks, farmer Mecke immediately notices the problem. He puts the boys in the sack instead, then takes it to the mill. The boys are ground to bits and devoured by the miller’s ducks. Later, no one expresses regret.

</doc>
