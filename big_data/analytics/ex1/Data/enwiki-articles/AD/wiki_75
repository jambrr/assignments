<doc id="23053" url="https://en.wikipedia.org/wiki?curid=23053" title="Periodic table">
Periodic table

The periodic table is a tabular arrangement of the chemical elements, ordered by their atomic number (number of protons), electron configurations, and recurring chemical properties. This ordering shows "periodic trends", such as elements with similar behavior in the same column. It also shows four rectangular blocks with some approximately similar chemical properties. In general, within one row (period) the elements are metals on the lefthand side, and non-metals on the righthand side.
The rows of the table are called periods; the columns are called groups. Six groups (columns) have names as well as numbers: for example, group 17 elements are the halogens; and group 18, the noble gases. The periodic table can be used to derive relationships between the properties of the elements, and predict the properties of new elements yet to be discovered or synthesized. The periodic table provides a useful framework for analyzing chemical behavior, and is widely used in chemistry and other sciences.
Dmitri Mendeleev published in 1869 the first widely recognized periodic table. He developed his table to illustrate periodic trends in the properties of the then-known elements. Mendeleev also predicted some properties of then-unknown elements that would be expected to fill gaps in this table. Most of his predictions were proved correct when the elements in question were subsequently discovered. Mendeleev's periodic table has since been expanded and refined with the discovery or synthesis of further new elements and the development of new theoretical models to explain chemical behavior.
All elements from atomic numbers 1 (hydrogen) to 118 (ununoctium) have been discovered or synthesized, with the most recent additions (elements 113, 115, 117, and 118) being confirmed by the IUPAC on December 30, 2015. The first 94 elements exist naturally, although some are found only in trace amounts and were synthesized in laboratories before being found in nature. Elements with atomic numbers from 95 to 118 have only been synthesized in laboratories. It has been shown that elements 95 to 100 once occurred in nature but currently do not. Synthesis of elements having higher atomic numbers is being pursued. Numerous synthetic radionuclides of naturally occurring elements have also been produced in laboratories.
Overview.
Each chemical element has a unique atomic number representing the number of protons in its nucleus. Most elements have differing numbers of neutrons among different atoms, with these variants being referred to as isotopes. For example, carbon has three naturally occurring isotopes: all of its atoms have six protons and most have six neutrons as well, but about one per cent have seven neutrons, and a very small fraction have eight neutrons. Isotopes are never separated in the periodic table; they are always grouped together under a single element. Elements with no stable isotopes have the atomic masses of their most stable isotopes, where such masses are shown, listed in parentheses.
In the standard periodic table, the elements are listed in order of increasing atomic number (the number of protons in the nucleus of an atom). A new row ("period") is started when a new electron shell has its first electron. Columns ("groups") are determined by the electron configuration of the atom; elements with the same number of electrons in a particular subshell fall into the same columns (e.g. oxygen and selenium are in the same column because they both have four electrons in the outermost p-subshell). Elements with similar chemical properties generally fall into the same group in the periodic table, although in the f-block, and to some respect in the d-block, the elements in the same period tend to have similar properties, as well. Thus, it is relatively easy to predict the chemical properties of an element if one knows the properties of the elements around it.
As of 2016, the periodic table has 118 confirmed elements, comprising elements 1 (hydrogen) to 118 (ununoctium). Elements 113, 115, 117 and 118 have been officially confirmed by the International Union of Pure and Applied Chemistry (IUPAC) in December 2015, though their official names are yet undecided. As such these elements are currently identified by their atomic number (e.g., "element 113"), or by their provisional systematic name ("ununtrium", symbol "Uut").
A total of 94 elements occur naturally; the remaining 20 elements, from americium to copernicium, and flerovium and livermorium, occur only when synthesised in laboratories. Of the 94 elements that occur naturally, 84 are primordial. The other 10 naturally occurring elements occur only in decay chains of primordial elements. No element heavier than einsteinium (element 99) has ever been observed in macroscopic quantities in its pure form, nor has astatine (element 85); francium (element 87) has been only photographed in the form of light emitted from microscopic quantities (300,000 atoms).
Grouping methods.
Groups.
A "group" or "family" is a vertical column in the periodic table. Groups usually have more significant periodic trends than periods and blocks, explained below. Modern quantum mechanical theories of atomic structure explain group trends by proposing that elements within the same group generally have the same electron configurations in their valence shell. Consequently, elements in the same group tend to have a shared chemistry and exhibit a clear trend in properties with increasing atomic number. However, in some parts of the periodic table, such as the d-block and the f-block, horizontal similarities can be as important as, or more pronounced than, vertical similarities.
Under an international naming convention, the groups are numbered numerically from 1 to 18 from the leftmost column (the alkali metals) to the rightmost column (the noble gases). Previously, they were known by roman numerals. In America, the roman numerals were followed by either an "A" if the group was in the s- or p-block, or a "B" if the group was in the d-block. The roman numerals used correspond to the last digit of today's naming convention (e.g. the group 4 elements were group IVB, and the group 14 elements were group IVA). In Europe, the lettering was similar, except that "A" was used if the group was before group 10, and "B" was used for groups including and after group 10. In addition, groups 8, 9 and 10 used to be treated as one triple-sized group, known collectively in both notations as group VIII. In 1988, the new IUPAC naming system was put into use, and the old group names were deprecated.
Some of these groups have been given trivial (unsystematic) names, as seen in the table below, although some are rarely used. Groups 3–10 have no trivial names and are referred to simply by their group numbers or by the name of the first member of their group (such as "the scandium group" for Group 3), since they display fewer similarities and/or vertical trends.
Elements in the same group tend to show patterns in atomic radius, ionization energy, and electronegativity. From top to bottom in a group, the atomic radii of the elements increase. Since there are more filled energy levels, valence electrons are found farther from the nucleus. From the top, each successive element has a lower ionization energy because it is easier to remove an electron since the atoms are less tightly bound. Similarly, a group has a top to bottom decrease in electronegativity due to an increasing distance between valence electrons and the nucleus. There are exceptions to these trends, however, an example of which occurs in group 11 where electronegativity increases farther down the group.
Periods.
A "period" is a horizontal row in the periodic table. Although groups generally have more significant periodic trends, there are regions where horizontal trends are more significant than vertical group trends, such as the f-block, where the lanthanides and actinides form two substantial horizontal series of elements.
Elements in the same period show trends in atomic radius, ionization energy, electron affinity, and electronegativity. Moving left to right across a period, atomic radius usually decreases. This occurs because each successive element has an added proton and electron, which causes the electron to be drawn closer to the nucleus. This decrease in atomic radius also causes the ionization energy to increase when moving from left to right across a period. The more tightly bound an element is, the more energy is required to remove an electron. Electronegativity increases in the same manner as ionization energy because of the pull exerted on the electrons by the nucleus. Electron affinity also shows a slight trend across a period. Metals (left side of a period) generally have a lower electron affinity than nonmetals (right side of a period), with the exception of the noble gases.
Blocks.
Specific regions of the periodic table can be referred to as "blocks" in recognition of the sequence in which the electron shells of the elements are filled. Each block is named according to the subshell in which the "last" electron notionally resides. The s-block comprises the first two groups (alkali metals and alkaline earth metals) as well as hydrogen and helium. The p-block comprises the last six groups, which are groups 13 to 18 in IUPAC group numbering (3A to 8A in American group numbering) and contains, among other elements, all of the metalloids. The d-block comprises groups 3 to 12 (or 3B to 2B in American group numbering) and contains all of the transition metals. The f-block, often offset below the rest of the periodic table, has no group numbers and comprises lanthanides and actinides.
Metals, metalloids and nonmetals.
According to their shared physical and chemical properties, the elements can be classified into the major categories of metals, metalloids and nonmetals. Metals are generally shiny, highly conducting solids that form alloys with one another and salt-like ionic compounds with nonmetals (other than the noble gases). The majority of nonmetals are coloured or colourless insulating gases; nonmetals that form compounds with other nonmetals feature covalent bonding. In between metals and nonmetals are metalloids, which have intermediate or mixed properties.
Metal and nonmetals can be further classified into subcategories that show a gradation from metallic to non-metallic properties, when going left to right in the rows. The metals are subdivided into the highly reactive alkali metals, through the less reactive alkaline earth metals, lanthanides and actinides, via the archetypal transition metals, and ending in the physically and chemically weak post-transition metals. The nonmetals are simply subdivided into the polyatomic nonmetals, which, being nearest to the metalloids, show some incipient metallic character; the diatomic nonmetals, which are essentially nonmetallic; and the monatomic noble gases, which are nonmetallic and almost completely inert. Specialized groupings such as the refractory metals and the noble metals, which are subsets (in this example) of the transition metals, are also known and occasionally denoted.
Placing the elements into categories and subcategories based on shared properties is imperfect. There is a spectrum of properties within each category and it is not hard to find overlaps at the boundaries, as is the case with most classification schemes. Beryllium, for example, is classified as an alkaline earth metal although its amphoteric chemistry and tendency to mostly form covalent compounds are both attributes of a chemically weak or post transition metal. Radon is classified as a nonmetal and a noble gas yet has some cationic chemistry that is more characteristic of a metal. Other classification schemes are possible such as the division of the elements into mineralogical occurrence categories, or crystalline structures. Categorising the elements in this fashion dates back to at least 1869 when Hinrichs wrote that simple boundary lines could be drawn on the periodic table to show elements having like properties, such as the metals and the nonmetals, or the gaseous elements.
Periodic trends.
Electron configuration.
The electron configuration or organisation of electrons orbiting neutral atoms shows a recurring pattern or periodicity. The electrons occupy a series of electron shells (numbered shell 1, shell 2, and so on). Each shell consists of one or more subshells (named s, p, d, f and g). As atomic number increases, electrons progressively fill these shells and subshells more or less according to the Madelung rule or energy ordering rule, as shown in the diagram. The electron configuration for neon, for example, is 1s2 2s2 2p6. With an atomic number of ten, neon has two electrons in the first shell, and eight electrons in the second shell—two in the s subshell and six in the p subshell. In periodic table terms, the first time an electron occupies a new shell corresponds to the start of each new period, these positions being occupied by hydrogen and the alkali metals.
Since the properties of an element are mostly determined by its electron configuration, the properties of the elements likewise show recurring patterns or periodic behaviour, some examples of which are shown in the diagrams below for atomic radii, ionization energy and electron affinity. It is this periodicity of properties, manifestations of which were noticed well before the underlying theory was developed, that led to the establishment of the periodic law (the properties of the elements recur at varying intervals) and the formulation of the first periodic tables.
Atomic radii.
Atomic radii vary in a predictable and explainable manner across the periodic table. For instance, the radii generally decrease along each period of the table, from the alkali metals to the noble gases; and increase down each group. The radius increases sharply between the noble gas at the end of each period and the alkali metal at the beginning of the next period. These trends of the atomic radii (and of various other chemical and physical properties of the elements) can be explained by the electron shell theory of the atom; they provided important evidence for the development and confirmation of quantum theory.
The electrons in the 4f-subshell, which is progressively filled from cerium (element 58) to ytterbium (element 70), are not particularly effective at shielding the increasing nuclear charge from the sub-shells further out. The elements immediately following the lanthanides have atomic radii that are smaller than would be expected and that are almost identical to the atomic radii of the elements immediately above them. Hence hafnium has virtually the same atomic radius (and chemistry) as zirconium, and tantalum has an atomic radius similar to niobium, and so forth. This is known as the lanthanide contraction. The effect of the lanthanide contraction is noticeable up to platinum (element 78), after which it is masked by a relativistic effect known as the inert pair effect. The d-block contraction, which is a similar effect between the d-block and p-block, is less pronounced than the lanthanide contraction but arises from a similar cause.
Ionization energy.
The first ionization energy is the energy it takes to remove one electron from an atom, the second ionization energy is the energy it takes to remove a second electron from the atom, and so on. For a given atom, successive ionization energies increase with the degree of ionization. For magnesium as an example, the first ionization energy is 738 kJ/mol and the second is 1450 kJ/mol. Electrons in the closer orbitals experience greater forces of electrostatic attraction; thus, their removal requires increasingly more energy. Ionization energy becomes greater up and to the right of the periodic table.
Large jumps in the successive molar ionization energies occur when removing an electron from a noble gas (complete electron shell) configuration. For magnesium again, the first two molar ionization energies of magnesium given above correspond to removing the two 3s electrons, and the third ionization energy is a much larger 7730 kJ/mol, for the removal of a 2p electron from the very stable neon-like configuration of Mg2+. Similar jumps occur in the ionization energies of other third-row atoms.
Electronegativity.
Electronegativity is the tendency of an atom to attract electrons. An atom's electronegativity is affected by both its atomic number and the distance between the valence electrons and the nucleus. The higher its electronegativity, the more an element attracts electrons. It was first proposed by Linus Pauling in 1932. In general, electronegativity increases on passing from left to right along a period, and decreases on descending a group. Hence, fluorine is the most electronegative of the elements, while caesium is the least, at least of those elements for which substantial data is available.
There are some exceptions to this general rule. Gallium and germanium have higher electronegativities than aluminium and silicon respectively because of the d-block contraction. Elements of the fourth period immediately after the first row of the transition metals have unusually small atomic radii because the 3d-electrons are not effective at shielding the increased nuclear charge, and smaller atomic size correlates with higher electronegativity. The anomalously high electronegativity of lead, particularly when compared to thallium and bismuth, appears to be an artifact of data selection (and data availability)—methods of calculation other than the Pauling method show the normal periodic trends for these elements.
Electron affinity.
The electron affinity of an atom is the amount of energy released when an electron is added to a neutral atom to form a negative ion. Although electron affinity varies greatly, some patterns emerge. Generally, nonmetals have more positive electron affinity values than metals. Chlorine most strongly attracts an extra electron. The electron affinities of the noble gases have not been measured conclusively, so they may or may not have slightly negative values.
Electron affinity generally increases across a period. This is caused by the filling of the valence shell of the atom; a group 17 atom releases more energy than a group 1 atom on gaining an electron because it obtains a filled valence shell and is therefore more stable.
A trend of decreasing electron affinity going down groups would be expected. The additional electron will be entering an orbital farther away from the nucleus. As such this electron would be less attracted to the nucleus and would release less energy when added. However, in going down a group, around one-third of elements are anomalous, with heavier elements having higher electron affinities than their next lighter congenors. Largely, this is due to the poor shielding by d and f electrons. A uniform decrease in electron affinity only applies to group 1 atoms.
Metallic character.
The lower the values of ionization energy, electronegativity and electron affinity, the more metallic character the element has. Conversely, nonmetallic character increases with higher values of these properties. Given the periodic trends of these three properties, metallic character tends to decrease going across a period (or row) and, with some irregularities (mostly) due to poor screening of the nucleus by d and f electrons, and relativistic effects, tends to increase going down a group (or column or family). Thus, the most metallic elements (such as caesium and francium) are found at the bottom left of traditional periodic tables and the most nonmetallic elements (oxygen, fluorine, chlorine) at the top right. The combination of horizontal and vertical trends in metallic character explains the stair-shaped dividing line between metals and nonmetals found on some periodic tables, and the practice of sometimes categorizing several elements adjacent to that line, or elements adjacent to those elements, as metalloids.
History.
First systemization attempts.
In 1789, Antoine Lavoisier published a list of 33 chemical elements, grouping them into gases, metals, nonmetals, and earths. Chemists spent the following century searching for a more precise classification scheme. In 1829, Johann Wolfgang Döbereiner observed that many of the elements could be grouped into triads based on their chemical properties. Lithium, sodium, and potassium, for example, were grouped together in a triad as soft, reactive metals. Döbereiner also observed that, when arranged by atomic weight, the second member of each triad was roughly the average of the first and the third; this became known as the Law of Triads. German chemist Leopold Gmelin worked with this system, and by 1843 he had identified ten triads, three groups of four, and one group of five. Jean-Baptiste Dumas published work in 1857 describing relationships between various groups of metals. Although various chemists were able to identify relationships between small groups of elements, they had yet to build one scheme that encompassed them all.
In 1857, German chemist August Kekulé observed that carbon often has four other atoms bonded to it. Methane, for example, has one carbon atom and four hydrogen atoms. This concept eventually became known as valency; different elements bond with different numbers of atoms.
In 1862, Alexandre-Emile Béguyer de Chancourtois, a French geologist, published an early form of periodic table, which he called the telluric helix or screw. He was the first person to notice the periodicity of the elements. With the elements arranged in a spiral on a cylinder by order of increasing atomic weight, de Chancourtois showed that elements with similar properties seemed to occur at regular intervals. His chart included some ions and compounds in addition to elements. His paper also used geological rather than chemical terms and did not include a diagram; as a result, it received little attention until the work of Dmitri Mendeleev.
In 1864, Julius Lothar Meyer, a German chemist, published a table with 44 elements arranged by valency. The table showed that elements with similar properties often shared the same valency. Concurrently, William Odling (an English chemist) published an arrangement of 57 elements, ordered on the basis of their atomic weights. With some irregularities and gaps, he noticed what appeared to be a periodicity of atomic weights among the elements and that this accorded with "their usually received groupings". Odling alluded to the idea of a periodic law but did not pursue it. He subsequently proposed (in 1870) a valence-based classification of the elements.
English chemist John Newlands produced a series of papers from 1863 to 1866 noting that when the elements were listed in order of increasing atomic weight, similar physical and chemical properties recurred at intervals of eight; he likened such periodicity to the octaves of music. This so termed Law of Octaves, however, was ridiculed by Newlands' contemporaries, and the Chemical Society refused to publish his work. Newlands was nonetheless able to draft a table of the elements and used it to predict the existence of missing elements, such as germanium. The Chemical Society only acknowledged the significance of his discoveries five years after they credited Mendeleev.
In 1867, Gustavus Hinrichs, a Danish born academic chemist based in America, published a spiral periodic system based on atomic spectra and weights, and chemical similarities. His work was regarded as idiosyncratic, ostentatious and labyrinthine and this may have militated against its recognition and acceptance.
Mendeleev's table.
Russian chemistry professor Dmitri Mendeleev and German chemist Julius Lothar Meyer independently published their periodic tables in 1869 and 1870, respectively. Mendeleev's table was his first published version; that of Meyer was an expanded version of his (Meyer's) table of 1864. They both constructed their tables by listing the elements in rows or columns in order of atomic weight and starting a new row or column when the characteristics of the elements began to repeat.
The recognition and acceptance afforded to Mendeleev's table came from two decisions he made. The first was to leave gaps in the table when it seemed that the corresponding element had not yet been discovered. Mendeleev was not the first chemist to do so, but he was the first to be recognized as using the trends in his periodic table to predict the properties of those missing elements, such as gallium and germanium. The second decision was to occasionally ignore the order suggested by the atomic weights and switch adjacent elements, such as tellurium and iodine, to better classify them into chemical families. Later in 1913, Henry Moseley determined experimental values of the nuclear charge or atomic number of each element, and showed that Mendeleev's ordering actually corresponds to the order of increasing atomic number.
The significance of atomic numbers to the organization of the periodic table was not appreciated until the existence and properties of protons and neutrons became understood. Mendeleev's periodic tables used atomic weight instead of atomic number to organize the elements, information determinable to fair precision in his time. Atomic weight worked well enough in most cases to (as noted) give a presentation that was able to predict the properties of missing elements more accurately than any other method then known. Substitution of atomic numbers, once understood, gave a definitive, integer-based sequence for the elements, and Moseley predicted (in 1913) that the only missing elements between aluminum (Z=13) and gold (Z=79) were Z = 43, 61, 72 and 75, which were all later discovered. The sequence of atomic numbers is still used today even as new synthetic elements are being produced and studied.
Second version and further development.
In 1871, Mendeleev published his periodic table in a new form, with groups of similar elements arranged in columns rather than in rows, and those columns numbered I to VIII corresponding with the element's oxidation state. He also gave detailed predictions for the properties of elements he had earlier noted were missing, but should exist. These gaps were subsequently filled as chemists discovered additional naturally occurring elements. It is often stated that the last naturally occurring element to be discovered was francium (referred to by Mendeleev as "eka-caesium") in 1939. However, plutonium, produced synthetically in 1940, was identified in trace quantities as a naturally occurring primordial element in 1971.
The popular periodic table layout, also known as the common or standard form (as shown at various other points in this article), is attributable to Horace Groves Deming. In 1923, Deming, an American chemist, published short (Mendeleev style) and medium (18-column) form periodic tables. Merck and Company prepared a handout form of Deming's 18-column medium table, in 1928, which was widely circulated in American schools. By the 1930s Deming's table was appearing in handbooks and encyclopaedias of chemistry. It was also distributed for many years by the Sargent-Welch Scientific Company.
With the development of modern quantum mechanical theories of electron configurations within atoms, it became apparent that each period (row) in the table corresponded to the filling of a quantum shell of electrons. Larger atoms have more electron sub-shells, so later tables have required progressively longer periods.
In 1945, Glenn Seaborg, an American scientist, made the suggestion that the actinide elements, like the lanthanides, were filling an f sub-level. Before this time the actinides were thought to be forming a fourth d-block row. Seaborg's colleagues advised him not to publish such a radical suggestion as it would most likely ruin his career. As Seaborg considered he did not then have a career to bring into disrepute, he published anyway. Seaborg's suggestion was found to be correct and he subsequently went on to win the 1951 Nobel Prize in chemistry for his work in synthesizing actinide elements.
Although minute quantities of some transuranic elements occur naturally, they were all first discovered in laboratories. Their production has expanded the periodic table significantly, the first of these being neptunium, synthesized in 1939. Because many of the transuranic elements are highly unstable and decay quickly, they are challenging to detect and characterize when produced. There have been controversies concerning the acceptance of competing discovery claims for some elements, requiring independent review to determine which party has priority, and hence naming rights. The most recently accepted and named elements are flerovium (element 114) and livermorium (element 116), both named on 31 May 2012. In 2010, a joint Russia–US collaboration at Dubna, Moscow Oblast, Russia, claimed to have synthesized six atoms of ununseptium (element 117), making it the most recently claimed discovery.
On December 30, 2015, elements 113, 115, 117, and 118 were formally recognized by IUPAC, completing the seventh row of the periodic table. Official names and symbols for each of these elements, which will replace temporary designations such as ununpentium (Uup) in the case of element 115, are expected to be announced later in 2016.
Different periodic tables.
Group 3 constitution variants.
There are three main variants of periodic table, each differing as to the constitution of group 3. Scandium and yttrium are uniformly shown as the first two members of this group; the differences hinge on the identity of the remaining members.
. Lanthanum (La) and actinium (Ac) occupy the two positions below yttrium. This variant is the most common. It emphasizes similarities in periodic trends going down groups 1, 2 and 3, at the expense of discontinuities in periodic trends between groups 3 and 4 and fragmenting the lanthanides and actinides.
. Lutetium (Lu) and lawrencium (Lr) occupy the two positions below yttrium. This variant retains a 14-column wide f-block while fragmenting the lanthanides and actinides. It emphasizes similarities in periodic trends between group 3 and the following groups at the expense of discontinuities in periodic trends between groups 2 and 3.
. The two positions below yttrium contain the lanthanides and the actinides (possibly by footnote markers). This variant emphasizes similarities in the chemistry of the 15 lanthanide elements (La–Lu), at the expense of ambiguity as to which elements occupy the two group 3 positions below yttrium, and seemingly a 15-column wide "f" block (there can only be 14 elements in any row of the "f" block).
The three variants originate from historical difficulties in placing the lanthanides in the periodic table, and arguments as to where the "f" block elements start and end. It has been claimed that such arguments are proof that, "it is a mistake to break the system into sharply delimited blocks". Equally, some versions of the two markers table have been criticized for implying that all 15 lanthanides occupy the single box or place below yttrium, in breach of the basic principle of one place, one element. The controversy over which two elements occupy the Group 3 positions below scandium and yttrium is further discussed in the Open questions and controversies section of this article.
The Lu and Lr table is shown in the lead and overview section of this article. When compared to the La and Ac variant, there are fewer apparent exceptions to the regular filling of the 4f orbitals among the subsequent members of the series. Unlike the two markers variant, there is no ambiguity on the composition of group 3.
Periodic tables by different structure.
Within 100 years of the appearance of Mendeleev's table in 1869 it has been estimated that around 700 different periodic table versions were published. As well as numerous rectangular variations, other periodic table formats have been shaped, for example, like a circle, cube, cylinder, building, spiral, lemniscate, octagonal prism, pyramid, sphere, or triangle. Such alternatives are often developed to highlight or emphasize chemical or physical properties of the elements that are not as apparent in traditional periodic tables.
The modern periodic table is sometimes expanded into its long or 32-column form by reinstating the footnoted f-block elements into their natural position between the s- and d-blocks. Unlike the 18-column form this arrangement results in "no interruptions to the sequence increasing atomic numbers". The relationship of the f-block to the other blocks of the periodic table also becomes easier to see. Jensen advocates a form of table with 32 columns on the grounds that the lanthanides and actinides are otherwise relegated in the minds of students as dull, unimportant elements that can be quarantined and ignored. Despite these advantages the 32-column form is generally avoided by editors on account of its undue rectangular ratio (compared to a book page ratio).
A popular alternative structure is that of Theodor Benfey (1960). The elements are arranged in a continuous spiral, with hydrogen at the center and the transition metals, lanthanides, and actinides occupying peninsulas.
Most periodic tables are two-dimensional; however, three-dimensional tables are known to as far back as at least 1862 (pre-dating Mendeleev's two-dimensional table of 1869). More recent examples include Courtines' Periodic Classification (1925), Wringley's Lamina System (1949),
Giguère's Periodic helix (1965) and Dufour's Periodic Tree (1996). Going one further, Stowe's Physicist's Periodic Table (1989) has been described as being four-dimensional (having three spatial dimensions and one colour dimension).
The various forms of periodic tables can be thought of as lying on a chemistry–physics continuum. Towards the chemistry end of the continuum can be found, as an example, Rayner-Canham's "unruly" Inorganic Chemist's Periodic Table (2002), which emphasizes trends and patterns, and unusual chemical relationships and properties. Near the physics end of the continuum is Janet's Left-Step Periodic Table (1928). This has a structure that shows a closer connection to the order of electron-shell filling and, by association, quantum mechanics. A somewhat similar approach has been taken by Alper, albeit criticized by Scerri as disregarding the need to display chemical and physical periodicity. Somewhere in the middle of the continuum is the ubiquitous common or standard form of periodic table. This is regarded as better expressing empirical trends in physical state, electrical and thermal conductivity, and oxidation numbers, and other properties easily inferred from traditional techniques of the chemical laboratory.
Open questions and controversies.
Elements with unknown chemical properties.
Although all elements up to ununoctium have been discovered, of the elements above hassium (element 108), only copernicium (element 112) and flerovium (element 114) have known chemical properties. The other elements may behave differently from what would be predicted by extrapolation, due to relativistic effects; for example, flerovium has been predicted to possibly exhibit some noble-gas-like properties, even though it is currently placed in the carbon group. More recent experiments have suggested, however, that flerovium behaves chemically like lead, as expected from its periodic table position.
Further periodic table extensions.
It is unclear whether new elements will continue the pattern of the current periodic table as period 8, or require further adaptations or adjustments. Seaborg expected the eighth period to follow the previously established pattern exactly, so that it would include a two-element s-block for elements 119 and 120, a new g-block for the next 18 elements, and 30 additional elements continuing the current f-, d-, and p-blocks. More recently, physicists such as Pekka Pyykkö have theorized that these additional elements do not follow the Madelung rule, which predicts how electron shells are filled and thus affects the appearance of the present periodic table.
Element with the highest possible atomic number.
The number of possible elements is not known. A very early suggestion made by Elliot Adams in 1911, and based on the arrangement of elements in each horizontal periodic table row, was that elements of atomic weight greater than 256± (which would equate to between elements 99 and 100 in modern-day terms) did not exist. A higher—more recent—estimate is that the periodic table may end soon after the island of stability, which is expected to center around element 126, as the extension of the periodic and nuclides tables is restricted by proton and neutron drip lines. Other predictions of an end to the periodic table include at element 128 by John Emsley, at element 137 by Richard Feynman, and at element 155 by Albert Khazan.
The Bohr model exhibits difficulty for atoms with atomic number greater than 137, as any element with an atomic number greater than 137 would require 1s electrons to be traveling faster than "c", the speed of light. Hence the non-relativistic Bohr model is inaccurate when applied to such an element.
The relativistic Dirac equation has problems for elements with more than 137 protons. For such elements, the wave function of the Dirac ground state is oscillatory rather than bound, and there is no gap between the positive and negative energy spectra, as in the Klein paradox. More accurate calculations taking into account the effects of the finite size of the nucleus indicate that the binding energy first exceeds the limit for elements with more than 173 protons. For heavier elements, if the innermost orbital (1s) is not filled, the electric field of the nucleus will pull an electron out of the vacuum, resulting in the spontaneous emission of a positron; however, this does not happen if the innermost orbital is filled, so that element 173 is not necessarily the end of the periodic table.
Placement of hydrogen and helium.
Simply following electron configurations, hydrogen (electronic configuration 1s1) and helium (1s2) should be placed in groups 1 and 2, above lithium (and beryllium ([He2s2). However, such placing is rarely used outside of the context of electron configurations: When the noble gases (then called "inert gases") were first discovered around 1900, they were known as "group 0", reflecting no chemical reactivity of these elements known at that point, and helium was placed on the top that group, as it did share the extreme chemical inertness seen throughout the group. As the group changed its formal number, many authors continued to assign helium directly above neon, in group 18; one of the examples of such placing is the current IUPAC table.
Hydrogen's chemical properties are not very close to those of the alkali metals, which occupy group 1, and on that basis hydrogen is sometimes placed elsewhere: one of the most common alternatives is in group 17; one of the factors behind it is the strictly univalent predominantly non-metallic chemistry of hydrogen, and that of fluorine (the element placed on the top of group 17) is strictly univalent and non-metallic. Sometimes, to show how hydrogen has properties both corresponding to those of the alkali metals and the halogens, it may be shown in two columns simultaneously. Another suggestion is above carbon in group 14: placed that way, it fits well into the trend of increasing trends of ionization potential values and electron affinity values, and is not too stray from the electronegativity trend. Finally, hydrogen is sometimes placed separately from any group; this is based on how general properties of hydrogen differ from that of any group: unlike hydrogen, the other group 1 elements show extremely metallic behavior; the group 17 elements commonly form salts (hence the term "halogen"); elements of any other group show some multivalent chemistry. The other period 1 element, helium, is sometimes placed separately from any group as well. The property that distinguishes helium from the rest of the noble gases (even though the extraordinary inertness of helium is extremely close to that of neon and argon) is that in its closed electron shell, helium has only two electrons in the outermost electron orbital, while the rest of the noble gases have eight.23p6, and so on.)-->
Groups included in the transition metals.
The definition of a transition metal, as given by IUPAC, is an element whose atom has an incomplete d sub-shell, or which can give rise to cations with an incomplete d sub-shell. By this definition all of the elements in groups 3–11 are transition metals. The IUPAC definition therefore excludes group 12, comprising zinc, cadmium and mercury, from the transition metals category.
Some chemists treat the categories "d-block elements" and "transition metals" interchangeably, thereby including groups 3–12 among the transition metals. In this instance the group 12 elements are treated as a special case of transition metal in which the d electrons are not ordinarily involved in chemical bonding. The recent discovery that mercury can use its d electrons in the formation of mercury(IV) fluoride (HgF4) has prompted some commentators to suggest that mercury can be regarded as a transition metal. Other commentators, such as Jensen, have argued that the formation of a compound like HgF4 can occur only under highly abnormal conditions. As such, mercury could not be regarded as a transition metal by any reasonable interpretation of the ordinary meaning of the term.
Still other chemists further exclude the group 3 elements from the definition of a transition metal. They do so on the basis that the group 3 elements do not form any ions having a partially occupied d shell and do not therefore exhibit any properties characteristic of transition metal chemistry. In this case, only groups 4–11 are regarded as transition metals.
Period 6 and 7 elements in group 3.
Although scandium and yttrium are always the first two elements in group 3 the identity of the next two elements is not settled. They are either lanthanum and actinium; or lutetium and lawrencium. Physical and chemical arguments have been made in support of the latter arrangement but not all authors have been convinced. Most working chemists are not aware there is any controversy. In December 2015 an IUPAC project was established to make a recommendation on the matter.
Lanthanum and actinium are traditionally depicted as the remaining group 3 members. It has been suggested that this layout originated in the 1940s, with the appearance of periodic tables relying on the electron configurations of the elements and the notion of the differentiating electron. The configurations of caesium, barium and lanthanum are [Xe6s2 and Lanthanum thus has a 5"d" differentiating electron and this establishes "it in group 3 as the first member of the "d"-block for period 6". A consistent set of electron configurations is then seen in group 3: scandium [Ar3d14s2, yttrium and lanthanum [Xe5d16s2. Still in period 6, ytterbium was assigned an electron configuration of and lutetium [Xe4f145d16s2, "resulting in a 4"f" differentiating electron for lutetium and firmly establishing it as the last member of the "f"-block for period 6". Matthias described the placement of lanthanum under yttrium as, "a mistake in the periodic system—unfortunately mostly propagated by the Welsh [Sargent-Welch] Company…and…everybody copied it". Lavelle further argued for the retention of lanthanum under yttrium given several well-known reference books featured periodic tables with such an arrangement.
In other tables, lutetium and lawrencium are the remaining group 3 members. Early techniques for chemically separating scandium, yttrium and lutetium relied on the fact that these elements occurred together in the so-called "yttrium group" whereas La and Ac occurred together in the "cerium group". Accordingly, lutetium rather than lanthanum was assigned to group 3 by some chemists in the 1920s and 30s. Later spectroscopic work found that the electron configuration of ytterbium was in fact This meant that ytterbium and lutetium—the latter with [Xe4f145d16s2—both had 14 "f" electrons, "resulting in a "d" rather than an "f" differentiating electron" for lutetium and making it an "equally valid candidate" with lanthanum, for the group 3 periodic table position below yttrium. Several physicists in the 1950s and 60s opted for lutetium, in light of a comparison of several of its physical properties with those of lanthanum. This arrangement, in which lanthanum is the first member of the f-block, is disputed by some authors since lanthanum lacks any "f" electrons. However, it has been argued that this is not valid concern given other periodic table anomalies—thorium, for example, has no "f" electrons yet is part of the f-block. As for lawrencium, its electron configuration was confirmed in 2015 as [Rn5f147s27p1. Such a configuration represents another periodic table anomaly, regardless of whether lawrencium is located in the f-block or the d-block, as the only potentially applicable p-block position has been reserved for ununtrium with its predicted electron configuration of 5f146d107s27p1.
Optimal form.
The many different forms of periodic table have prompted the question of whether there is an optimal or definitive form of periodic table. The answer to this question is thought to depend on whether the chemical periodicity seen to occur among the elements has an underlying truth, effectively hard-wired into the universe, or if any such periodicity is instead the product of subjective human interpretation, contingent upon the circumstances, beliefs and predilections of human observers. An objective basis for chemical periodicity would settle the questions about the location of hydrogen and helium, and the composition of group 3. Such an underlying truth, if it exists, is thought to have not yet been discovered. In its absence, the many different forms of periodic table can be regarded as variations on the theme of chemical periodicity, each of which explores and emphasizes different aspects, properties, perspectives and relationships of and among the elements. The ubiquity of the standard or medium-long periodic table is thought to be a result of this layout having a good balance of features in terms of ease of construction and size, and its depiction of atomic order and periodic trends.

</doc>
<doc id="23055" url="https://en.wikipedia.org/wiki?curid=23055" title="Potassium">
Potassium

Potassium is a chemical element with symbol K (derived from Neo-Latin, "kalium") and atomic number 19. It was first isolated from potash, the ashes of plants, from which its name is derived. In the Periodic table, potassium is one of seven elements in column (group) 1 (alkali metals): they all have a single valence electron in their outer electron shell, which they readily give up to create an atom with a positive charge - a cation, and combine with anions to form salts. Potassium in nature occurs only in ionic salts. Elemental potassium is a soft silvery-white alkali metal that oxidizes rapidly in air and reacts vigorously with water, generating sufficient heat to ignite hydrogen emitted in the reaction and burning with a lilac-colored flame. It is found dissolved in sea water (which is 0.04% potassium by weight), and is part of many minerals. Naturally occurring potassium is composed of three isotopes, one of which, , is radioactive. Traces of are found in all potassium, and it is the most common radioisotope in the human body.
Potassium is chemically very similar to sodium, the previous element in group 1 of the periodic table. They have a similar ionization energy, which allows for each atom to give up its sole outer electron. The fact that they are different elements, each combining with the same anions to make similar salts, was suspected in 1702, and was proven in 1807 using electrolysis.
Most industrial applications of potassium exploit the high solubility in water of potassium compounds, such as potassium soaps. Heavy crop production rapidly depletes soils of potassium, and this depletion is prevented and remedied with agricultural fertilizers containing potassium, which account for 95% of global potassium chemical production.
Potassium ions are necessary for the function of all living cells. Potassium ion shifts across nerve cell membranes are necessary for normal nerve transmission; potassium depletion or excess can result in numerous abnormalities, including an abnormal heart rhythm and various electrocardiographic (ECG) abnormalities. Fresh fruits and vegetables are good dietary sources of potassium. The body responds to the influx of dietary potassium, which raises serum potassium levels, with a shift of potassium from outside to inside cells, and an increase in potassium excretion by the kidney.
Properties.
Physical.
Potassium is the second least dense metal after lithium. It is a soft solid that has a low melting point and can easily be cut with a knife. Freshly cut potassium is silvery in appearance, but it begins to tarnish toward gray immediately after being exposed to air. In a flame test, potassium and its compounds emit a lilac color with a peak emission wavelength of 766.5 nanometers
Chemical.
Potassium atoms have 19 electrons, which is one more than the extremely stable configuration of the noble gas argon. Because of this and its low first ionization energy of 418.8 kJ/mol, the potassium atom is thus much more likely to lose the "extra" electron, acquiring a positive charge, than to gain one and acquire a negative charge; (however, such negatively charged alkalide ions () are known.) This process requires so little energy that potassium is readily oxidized by atmospheric oxygen. In contrast, the second ionization energy is very high (3052 kJ/mol), because removal of two electrons breaks the stable noble gas electronic configuration (the configuration of the inert argon). Potassium therefore does not readily form compounds with the oxidation state of +2 or higher.
Potassium is an extremely active metal, which reacts violently with oxygen and water in air. With oxygen it forms potassium peroxide, and with water potassium forms potassium hydroxide. The reaction of potassium with water is dangerous because of its violent exothermic character and the production of hydrogen gas. Hydrogen reacts again with atmospheric oxygen, producing water, which reacts with the remaining potassium. This reaction requires only traces of water; because of this, potassium and its liquid alloy with sodium — NaK — are potent desiccants that can be used to dry solvents prior to distillation.
Because of the sensitivity of potassium to water and air, reactions with other elements are possible only in inert atmosphere, such as argon gas using air-free techniques. Potassium does not react with most hydrocarbons such as mineral oil or kerosene. It readily dissolves in liquid ammonia, up to 480 g per 1000 g of ammonia at 0 °C. Depending on the concentration, the ammonia solutions are blue to yellow, and their electrical conductivity is similar to that of liquid metals. In a pure solution, potassium slowly reacts with ammonia to form , but this reaction is accelerated by minute amounts of transition metal salts. Because it can reduce the salts to the metal, potassium is often used as the reductant in the preparation of finely divided metals from their salts by the Rieke method. For example, the preparation of Rieke magnesium employs potassium as the reductant:
Compounds.
The only common oxidation state for potassium is +1. Potassium metal is a powerful reducing agent that is easily oxidized to the monopositive cation, . Once oxidized, it is very stable and difficult to reduce back to the metal.
Potassium hydroxide reacts readily with carbon dioxide to produce potassium carbonate, and is used to remove traces of the gas from air. In general, potassium compounds have excellent water solubility, owing to the high hydration energy of the ion. The potassium ion is colorless in water and is very difficult to precipitate; possible precipitation methods include reactions with sodium tetraphenylborate, hexachloroplatinic acid, and sodium cobaltinitrite.
Potassium oxidizes faster than most metals and forms oxides with oxygen-oxygen bonds, as do all alkali metals except lithium. Three species are formed during the reaction: potassium oxide, potassium peroxide, and potassium superoxide, which contain three different oxygen-based ions: oxide (), peroxide (), and superoxide (). The last two species, especially the superoxide, are rare and are formed only in reaction with very electropositive metals; these species contain oxygen-oxygen bonds. All potassium-oxygen binary compounds are known to react with water violently, forming potassium hydroxide. This compound is a very strong alkali, and 1.21 kg of it can dissolve in as little as a liter of water.
Potassium compounds are typically highly ionic and thus most of them are soluble in water. The main species in water are the aquated complexes where n = 6 and 7. Some of the few poorly soluble potassium salts include potassium tetraphenylborate, potassium hexachloroplatinate, and potassium cobaltinitrite.
Isotopes.
There are 24 known isotopes of potassium, three of which occur naturally: (93.3%), (0.0117%), and (6.7%). Naturally occurring has a half-life of 1.250×109 years. It decays to stable by electron capture or positron emission (11.2%) or to stable by beta decay (88.8%).
The decay of to enables a commonly used method for dating rocks. The conventional K-Ar dating method depends on the assumption that the rocks contained no argon at the time of formation and that all the subsequent radiogenic argon (i.e., ) was quantitatively retained. Minerals are dated by measurement of the concentration of potassium and the amount of radiogenic that has accumulated. The minerals that are best suited for dating include biotite, muscovite, metamorphic hornblende, and volcanic feldspar; whole rock samples from volcanic flows and shallow instrusives can also be dated if they are unaltered. Outside of dating, potassium isotopes have been used as tracers in studies of weathering and for nutrient cycling studies because potassium is a macronutrient required for life.
Cosmic formation and distribution.
Potassium is formed in supernovas by nucleosynthesis from lighter atoms. Potassium is principally created in Type II supernovas via the explosive oxygen-burning process. is also formed in s-process nucleosynthesis and the neon burning process.
Potassium makes up about 2.6% of the weight of the earth's crust and is the seventh most abundant element in the crust. It is the 17th most abundant element by weight in the earth, and 20th most abundant element in the solar system. The potassium concentration in seawater is 0.39 g/L (0.039 wt/v%), about one-quarter the concentration of sodium.
Etymology.
Neither elemental potassium nor potassium salts (as separate entities from other salts) were known in Roman times, and the Latin name of the element, "kalium", is not Classical Latin but rather neo-Latin. Kalium was taken from the word "alkali", which in turn came from "" "al-qalyah" "plant ashes." The similar-sounding English term alkali is from this same root, whereas the word for potassium in Modern Standard Arabic is بوتاسيوم "būtāsyūm". The English name for the element "potassium" comes from the word "potash", and refers to the method by which potassium was obtained – placing in a "pot" the "ash" of burnt wood or tree leaves, adding water, heating, and evaporating the solution.
Potash.
Potash is primarily a mixture of potassium salts because plants have little or no sodium content, and the rest of a plant's major mineral content consists of calcium salts of relatively low solubility in water. While potash has been used since ancient times, it was not understood for most of its history to be a fundamentally different substance from sodium mineral salts. Georg Ernst Stahl obtained experimental evidence that led him to suggest the fundamental difference of sodium and potassium salts in 1702, and Henri Louis Duhamel du Monceau was able to prove this difference in 1736. The exact chemical composition of potassium and sodium compounds, and the status as chemical element of potassium and sodium, was not known then, and thus Antoine Lavoisier did not include the alkali in his list of chemical elements in 1789. For a long time the only significant applications for potash were the production of glass, bleach, soap and gunpowder as potassium nitrate. Potassium soaps from animal fats and vegetable oils were especially prized, as they tended to be more water-soluble and of softer texture, and were known as soft soaps. The discovery by Justus Liebig in 1840 that potassium is a necessary element for plants and that most types of soil lack potassium caused a steep rise in demand for potassium salts. Wood-ash from fir trees was initially used as a potassium salt source for fertilizer, but, with the discovery in 1868 of mineral deposits containing potassium chloride near Staßfurt, Germany, the production of potassium-containing fertilizers began at an industrial scale. Other potash deposits were discovered, and by the 1960s Canada became the dominant producer.
The metal.
Potassium "metal" was first isolated in 1807 in England by Sir Humphry Davy, who derived it from caustic potash (KOH, potassium hydroxide) by the use of electrolysis of the molten KOH with the newly discovered voltaic pile. Potassium was the first metal that was isolated by electrolysis. Later in the same year, Davy reported extraction of the metal sodium from a mineral derivative (caustic soda, NaOH, or lye) rather than a plant salt, by a similar technique, demonstrating that the elements, and thus the salts, are different. Although the production of potassium and sodium metal should have shown that both are elements, it took some time before this view was universally accepted.
Geology.
Elemental potassium does not occur in nature because of its high reactivity. It reacts violently with water (see section Precautions below) and also reacts with oxygen. Orthoclase (potassium feldspar) is a common rock-forming mineral. Granite for example contains 5% potassium, which is well above the average in the Earth's crust. Sylvite (KCl), carnallite , kainite and langbeinite are the minerals found in large evaporite deposits worldwide. The deposits often show layers starting with the least soluble at the bottom and the most soluble on top. Deposits of niter (potassium nitrate) are formed by decomposition of organic material in contact with atmosphere, mostly in caves; because of the good water solubility of niter the formation of larger deposits requires special environmental conditions.
Commercial production.
Potassium salts such as carnallite, langbeinite, polyhalite, and sylvite form extensive deposits in ancient lake bottoms and seabeds, making extraction of potassium salts in these environments commercially viable. The principal source of potassium – potash – is mined in Canada, Russia, Belarus, Germany, Israel, United States, Jordan, and other places around the world. The first mined deposits were located near Staßfurt, Germany, but the deposits span from Great Britain over Germany into Poland. They are located in the Zechstein and were deposited in the Middle to Late Permian. The largest deposits ever found lie below the surface of the Canadian province of Saskatchewan. The deposits are located in the Elk Point Group produced in the Middle Devonian. Saskatchewan, where several large mines have operated since the 1960s, pioneered the use of freezing of wet sands (the Blairmore formation) in order to drive mine shafts through them. The main potash mining company in Saskatchewan is the Potash Corporation of Saskatchewan. The water of the Dead Sea is used by Israel and Jordan as a source for potash, while the concentration in normal oceans is too low for commercial production at current prices.
Several methods are applied to separate the potassium salts from the present sodium and magnesium compounds. The most-used method is to precipitate some compounds relying on the solubility difference of the salts at different temperatures. Electrostatic separation of the ground salt mixture is also used in some mines. The resulting sodium and magnesium waste is either stored underground or piled up in slag heaps. Most of the mined potassium minerals end up as potassium chloride after processing. The mineral industry refers to potassium chloride either as potash, muriate of potash, or simply MOP.
Pure potassium metal can be isolated by electrolysis of its hydroxide in a process that has changed little since Davy. Although the electrolysis process was developed and used in industrial scale in the 1920s the thermal method by reacting sodium with potassium chloride in a chemical equilibrium reaction became the dominant method in the 1950s. The production of sodium potassium alloys is possible by changing the reaction time and the amount of sodium used in the reaction. The Griesheimer process employing the reaction of potassium fluoride with calcium carbide was also used to produce potassium.
Reagent-grade potassium metal cost about $10.00/pound ($22/kg) in 2010 when purchased in tonne quantities. Lower purity metal is considerably cheaper. The market is volatile due to the difficulty of the long-term storage of the metal. It must be stored under a dry inert gas atmosphere or anhydrous mineral oil to prevent the formation of a surface layer of potassium superoxide. This superoxide is a pressure-sensitive explosive that will detonate when scratched. The resulting explosion will usually start a fire that is difficult to extinguish.
Biological role.
Potassium is the eighth or ninth most common element by mass (0.2%) in the human body, so that a 60 kg adult contains a total of about 120 g of potassium. The body has about as much potassium as sulfur and chlorine, and only calcium and phosphorus are more abundant.
Biochemical function.
Potassium levels influence multiple physiological processes, including
Homeostasis.
Potassium homeostasis denotes the maintenance of the total body potassium content, plasma potassium level, and the ratio of the intracellular to extracellular potassium concentrations within narrow limits, in the face of pulsatile intake (meals), obligatory renal excretion, and shifts between intracellular and extracellular compartments.
Plasma levels.
The plasma potassium is normally kept at 3.5 to 5.0 millimoles (mmol), milliequivalents (mEq) per liter by multiple mechanisms. Levels outside this range are associated with an increased rate of death of any cause; and some cardiac, kidney, and lung diseases progress more rapidly if serum potassium levels are not maintained with the normal range.
An average meal of 40-50 mmol presents the body with more potassium than is present in all plasma (20-25 mmol). However, this surge causes the plasma potassium to rise at most only 10% because of prompt and efficient clearance by both renal and extra-renal mechanisms.
Hypokalemia, a deficiency of potassium in the plasma, can be fatal if severe. Common causes are increased gastrintestinal loss (vomiting, diarrhea), and increased renal loss (diuresis). Deficiency symptoms include muscle weakness, paralytic ileus, ECG abnormalities, decreased reflex response; and in severe cases, respiratory paralysis, alkalosis and cardiac arrhythmia.
Control mechanisms.
There are four basic mechanisms which maintain tight control of the plasma potassium: they have various names and various classifications. The four are 1) a reactive negative-feedback system, 2) a reactive feed-forward system, 3) a predictive or circadian system, and 4) an internal or cell membrane transport system. The first three are sometimes referred to collectively as the "external potassium homeostasis system"; the first two as the "reactive potassium homeostasis system".
Renal filtration, reabsorption, and excretion.
Renal handling of potassium is closely connected to sodium handling. Potassium is the major cation (positive ion) inside animal cells (4.8 g), while sodium is the major cation of extracellular fluid (3.345 g). In the kidneys, plasma is filtered through the glomeruli and into the renal tubules in enormous amounts, about 180 liters per day. Thus about 600 g of sodium and 33 g of potassium are filtered each day. All but the 1–10 g of sodium and the 1–4 g of potassium likely to be in the diet must be reabsorbed.
Sodium is reabsorbed to maintain extracellular volume, osmotic pressure, and serum sodium concentration within narrow limits; potassium is reabsorbed to maintain serum potassium concentration within narrow limits. Sodium pumps in the renal tubules operate to reabsorb sodium. Potassium must sometimes be conserved also, but, as the amount of potassium in the blood plasma is very small and the pool of potassium in the cells is about thirty times as large, the situation is not so critical for potassium. Since potassium is moved passively in counter flow to sodium in response to an apparent (but not actual) Donnan equilibrium, the urine can never sink below the concentration of potassium in serum except sometimes by actively excreting water at the end of the processing. Potassium is secreted twice and reabsorbed three times before the urine reaches the collecting tubules. At that point, it usually has about the same potassium concentration as plasma. At the end of the processing, potassium is secreted one more time if the serum levels are too high.
With no potassium intake, there is an obligatory excretion of about 200 mg per day, until in about a week the serum potassium declines to a mildly deficient level of 3.0–3.5 mmol/L. It continues to fall to create a severe deficiency in the plasma and eventually death.
The potassium moves passively through pores in the cell membrane. When ions move through pumps there is a gate in the pumps on either side of the cell membrane and only one gate can be open at once. As a result, approximately 100 ions are forced through per second. Pores have only one gate, and there only one kind of ion can stream through, at 10 million to 100 million ions per second. The pores require calcium in order to open although it is thought that the calcium works in reverse by blocking at least one of the pores. Carbonyl groups inside the pore on the amino acids mimic the water hydration that takes place in water solution by the nature of the electrostatic charges on four carbonyl groups inside the pore.
In diet.
Detection by taste buds.
Potassium can be detected by taste because it triggers three of the five types of taste sensations, according to concentration. Dilute solutions of potassium ions taste sweet, allowing moderate concentrations in milk and juices, while higher concentrations become increasingly bitter/alkaline, and finally also salty to the taste. The combined bitterness and saltiness of high-potassium solutions makes high-dose potassium supplementation by liquid drinks a palatability challenge.
Adequate intake.
Adequate potassium intake is achieved by eating a variety of foods. Potassium is present in all fruits, vegetables, meat and fish. Foods with high potassium concentrations include yam, parsley, dried apricots, dried milk, chocolate, all nuts (especially almonds and pistachios), potatoes, bamboo shoots, bananas, avocados, coconut water, soybeans, and bran. Dried apricots have the highest concentration of potassium by weight of any food. Many processed foods contain no potassium.
Optimal intake.
Epidemiological studies indicate that diets high in potassium can reduce the risk of hypertension and possibly stroke (by a mechanism independent of blood pressure). The 2004 guidelines of the Institute of Medicine specify a Dietary Reference Intake (DRI]) of 4,700 mg of potassium (100 mEq); most Americans consume only half that amount per day. Likewise, in the European Union, in particular in Germany and Italy, insufficient potassium intake is somewhat common. A meta-analysis concluded that a 1640 mg increase in the daily intake of potassium was associated with a 21% lower risk of stroke.
Deficient intake.
Diets low in potassium can lead to hypertension and hypokalemia.
Supplementation.
Supplements of potassium are most widely used in conjunction with diuretics that block reabsorption of sodium and water upstream from the distal tubule (thiazides and loop diuretics), because this promotes increased distal tubular potassium secretion, with resultant increased potassium excretion. A variety of prescription and over-the counter supplements are available. Potassium chloride may be dissolved in water, but the salty/bitter taste make liquid supplements unpalatable. Typical doses range from 10 mmol (400 mg), to 20 mmol (800 mg). Potassium is also available in tablets or capsules, which are formulated to allow potassium to leach slowly out of a matrix, since very high concentrations of potassium ion which occur adjacent to a solid tablet cause injury to the gastric or intestinal mucosa. For this reason, non-prescription potassium pills are limited by law in the US to a maximum of 99 mg of potassium.
Since the kidneys are the site of potassium excretion, individuals with impaired kidney function are at risk for hyperkalemia if dietary potassium and supplements are not restricted. The more severe the impairment, the more severe is the restriction necessary to avoid hyperkalemia.
Applications.
Fertilizer.
Potassium ions are an essential component of plant nutrition and are found in most soil types. They are used as a fertilizer in agriculture, horticulture, and hydroponic culture in the form of chloride (KCl), sulfate (), or nitrate (). Agricultural fertilizers consume 95% of global potassium chemical production, and about 90% of this potassium is supplied as KCl. The potassium content of most plants range from 0.5% to 2% of the harvested weight of crops, conventionally expressed as amount of . Modern high-yield agriculture depends upon fertilizers to replace the potassium lost at harvest. Most agricultural fertilizers contain potassium chloride, while potassium sulfate is used for chloride-sensitive crops or crops needing higher sulfur content. The sulfate is produced mostly by decomposition of the complex minerals kainite () and langbeinite (). Only a very few fertilizers contain potassium nitrate. In 2005, about 93% of world potassium production was consumed by the fertilizer industry.
Food.
The potassium cation is a nutrient necessary for human life and health. Potassium chloride and bicarbonate are used by those seeking to control hypertension. The USDA lists tomato paste, orange juice, beet greens, white beans, potatoes, bananas and many other dietary sources of potassium, ranked in descending order according to potassium content.
Potassium sodium tartrate (, Rochelle salt) is the main constituent of baking powder; it is also used in the silvering of mirrors. Potassium bromate () is a strong oxidizer (E924), used to improve dough strength and rise height. Potassium bisulfite () is used as a food preservative, for example in wine and beer-making (but not in meats). It is also used to bleach textiles and straw, and in the tanning of leathers.
Industrial.
Major potassium chemicals are potassium hydroxide, potassium carbonate, potassium sulfate, and potassium chloride. Megatons of these compounds are produced annually.
Potassium hydroxide is a strong base, which is used in industry to neutralize strong and weak acids, to control pH and to manufacture potassium salts. It is also used to saponify fats and oils, in industrial cleaners, and in hydrolysis reactions, for example of esters.
Potassium nitrate () or saltpeter is obtained from natural sources such as guano and evaporites or manufactured via the Haber process; it is the oxidant in gunpowder (black powder) and an important agricultural fertilizer. Potassium cyanide (KCN) is used industrially to dissolve copper and precious metals, in particular silver and gold, by forming complexes. Its applications include gold mining, electroplating, and electroforming of these metals; it is also used in organic synthesis to make nitriles. Potassium carbonate ( or potash) is used in the manufacture of glass, soap, color TV tubes, fluorescent lamps, textile dyes and pigments. Potassium permanganate () is an oxidizing, bleaching and purification substance and is used for production of saccharin. Potassium chlorate () is added to matches and explosives. Potassium bromide (KBr) was formerly used as a sedative and in photography.
Potassium chromate () is used in inks, dyes, stains (bright yellowish-red color); in explosives and fireworks; in the tanning of leather, in fly paper and safety matches, but all these uses are due to the properties of chromate ion containment rather than potassium ions.
Niche uses.
There are thousands of uses of various potassium compounds. One example is potassium superoxide, , an orange solid that acts as a portable source of oxygen and a carbon dioxide absorber. It is widely used in respiration systems in mines, submarines and spacecraft as it takes less volume than the gaseous oxygen.
Another example is potassium cobaltinitrite, which is used as artist's pigment under the name of Aureolin or Cobalt Yellow.
Laboratory uses.
An alloy of sodium and potassium, NaK is a liquid used as a heat-transfer medium and a desiccant for producing dry and air-free solvents. It can also be used in reactive distillation. The ternary alloy of 12% Na, 47% K and 41% Cs has the lowest melting point of −78 °C of any metallic compound.
Metallic potassium is used in several types of magnetometers.
Precautions.
Potassium metal reacts very violently with water producing potassium hydroxide (KOH) and hydrogen gas.
This reaction is exothermic and releases enough heat to ignite the resulting hydrogen. It in turn may explode in the presence of oxygen. Potassium hydroxide is a strong alkali that causes skin burns. Finely divided potassium will ignite in air at room temperature. The bulk metal will ignite in air if heated. Because its density is 0.89 g/cm3, burning potassium floats in water that exposes it to atmospheric oxygen. Many common fire extinguishing agents, including water, either are ineffective or make a potassium fire worse. Nitrogen, argon, sodium chloride (table salt), sodium carbonate (soda ash), and silicon dioxide (sand) are effective if they are dry. Some Class D dry powder extinguishers designed for metal fires are also effective. These agents deprive the fire of oxygen and cool the potassium metal.
Potassium reacts violently with halogens and will detonate in the presence of bromine. It also reacts explosively with sulfuric acid. During combustion potassium forms peroxides and superoxides. These peroxides may react violently with organic compounds such as oils. Both peroxides and superoxides may react explosively with metallic potassium.
Because potassium reacts with water vapor present in the air, it is usually stored under anhydrous mineral oil or kerosene. Unlike lithium and sodium, however, potassium should not be stored under oil for longer than 6 months, unless in an inert (oxygen free) atmosphere, or under vacuum. After prolonged storage in air dangerous shock-sensitive peroxides can form on the metal and under the lid of the container, and can detonate upon opening.
Because of the highly reactive nature of potassium metal, it must be handled with great care, with full skin and eye protection and preferably an explosion-resistant barrier between the user and the metal. Ingestion of large amounts of potassium compounds can lead to hyperkalemia strongly influencing the cardiovascular system. Potassium chloride is used in the United States for executions via lethal injection.

</doc>
<doc id="23056" url="https://en.wikipedia.org/wiki?curid=23056" title="Pope">
Pope

The Pope ( from "pappas", a child's word for "father") is the Bishop of Rome and the leader of the worldwide Catholic Church. The primacy of the Roman bishop is largely derived from his role as the traditional successor to Saint Peter, to whom Jesus is supposed to have given the keys of Heaven and the powers of "binding and loosing", naming him as the "rock" upon which the church would be built. The current pope is Francis, who was elected on 13 March 2013, succeeding Benedict XVI.
The office of the Pope is the papacy. His ecclesiastical jurisdiction, the Diocese of Rome, is often called "the Holy See" or "the Apostolic See", the latter name being based upon the belief that the Bishop of Rome is the successor of Peter the Apostle. The Pope is considered one of the world's most powerful people because of his diplomatic and cultural influence. He is also head of state of Vatican City, a sovereign city-state entirely enclaved within the Italian capital city of Rome.
The papacy is one of the most enduring institutions in the world and has had a prominent part in world history. The popes in ancient times helped in the spread of Christianity and the resolution of various doctrinal disputes. In the Middle Ages, they played a role of secular importance in Western Europe, often acting as arbitrators between Christian monarchs. Currently, in addition to the expansion of the Christian faith and doctrine, the popes are involved in ecumenism and interfaith dialog, charitable work, and the defense of human rights.
Popes, who originally had no temporal powers, in some periods of history accrued wide powers similar to those of temporal rulers. In recent centuries, popes were gradually forced to give up temporal power, and papal authority is now once again almost exclusively restricted to matters of religion. Over the centuries, papal claims of spiritual authority have been ever more firmly expressed, culminating in 1870 with the proclamation of the dogma of papal infallibility for rare occasions when the pope speaks "ex cathedra"—literally "from the chair (of Saint Peter)"—to issue a formal definition of faith or morals.
History.
Title and etymology.
The word "pope" derives from Greek πάππας meaning "father". In the early centuries of Christianity, this title was applied, especially in the east, to all bishops and other senior clergy, and later became reserved in the west to the Bishop of Rome, a reservation made official only in the 11th century. The earliest record of the use of this title was in regard to the by then deceased Patriarch of Alexandria, Pope Heraclas of Alexandria (232–248). The earliest recorded use of the title "pope" in English dates to the mid-10th century, when it was used in reference to Pope Vitalian in an Old English translation of Bede's "Historia ecclesiastica gentis Anglorum".
Position within the Church.
The Catholic Church teaches that the pastoral office, the office of shepherding the Church, that was held by the apostles, as a group or "college" with Saint Peter at their head, is now held by their successors, the bishops, with the bishop of Rome (the pope) at their head.
The Catholic Church teaches that Jesus personally appointed Peter as leader of the Church and in its dogmatic constitution "Lumen gentium" makes a clear distinction between apostles and bishops, presenting the latter as the successors of the former, with the pope as successor of Peter in that he is head of the bishops as Peter was head of the apostles. Some historians have argued that the notion that Peter was the first bishop of Rome and founded the episcopal see there can be traced back no earlier than the 3rd century. The writings of the Church Father Irenaeus who wrote around AD 180 reflect a belief that Peter "founded and organised" the Church at Rome. Moreover, Irenaeus was not the first to write of Peter's presence in the early Roman Church. Clement of Rome wrote in a letter to the Corinthians, "c." 96, about the persecution of Christians in Rome as the "struggles in our time" and presented to the Corinthians its heroes, "first, the greatest and most just columns", the "good apostles" Peter and Paul. St. Ignatius of Antioch wrote shortly after Clement and in his letter from the city of Smyrna to the Romans he said he would not command them as Peter and Paul did. Given this and other evidence, many scholars agree that Peter was martyred in Rome under Nero, although some scholars argue that he may have been martyred in Palestine.
Protestants contend that the New Testament offers no proof that Jesus established the papacy nor even that he established Peter as the first bishop of Rome. Others, using Peter's own words, argue that Christ intended himself as the foundation of the church and not Peter. Others have argued that the church is indeed built upon Jesus and faith, but also on the disciples as the roots and foundations of the church on the basis of Paul's teaching in Romans and Ephesians, though not primarily Peter.
First-century Christian communities would have had a group of presbyter-bishops functioning as leaders of their local churches. Gradually, episcopacies were established in metropolitan areas. Antioch may have developed such a structure before Rome. In Rome there were many who claimed to be the rightful bishop though again Irenaeus stressed the validity of one line of bishops from the time of St. Peter up to his contemporary Pope Victor I and listed them. Some writers claim that the emergence of a single bishop in Rome probably did not occur until the middle of the 2nd century. In their view, Linus, Cletus and Clement were possibly prominent presbyter-bishops but not necessarily monarchical bishops.
Documents of the 1st century and early 2nd century indicate that the Holy See had some kind of pre-eminence and prominence in the Church as a whole, though the detail of what this meant is very unclear at this period.
Early Christianity ("c." 30–325).
It seems that at first the terms "episcopos" and "presbyter" were used interchangeably. The consensus among scholars has been that, at the turn of the 1st and 2nd centuries, local congregations were led by bishops and presbyters whose offices were overlapping or indistinguishable. Some say that there was probably "no single 'monarchical' bishop in Rome before the middle of the 2nd century ... and likely later." Other scholars and historians disagree, citing the historical records of St. Ignatius of Antioch (d 107) and St. Irenaeus who recorded the linear succession of Bishops of Rome (the popes) up until their own times. They also cite the importance accorded to the Bishops of Rome in the ecumenical councils, including the early ones.
In the early Christian era, Rome and a few other cities had claims on the leadership of worldwide Church. James the Just, known as "the brother of the Lord", served as head of the Jerusalem church, which is still honored as the "Mother Church" in Orthodox tradition. Alexandria had been a center of Jewish learning and became a center of Christian learning. Rome had a large congregation early in the apostolic period whom Paul the Apostle addressed in his Epistle to the Romans, and according to tradition Paul was martyred there. 
During the 1st century of the Church (c. 30–130), the Roman capital became recognized as a Christian center of exceptional importance. Clement I, at the end of the 1st century, wrote an epistle to the Church in Corinth intervening in a major dispute, and apologizing for not having taken action earlier. However, there are only a few other references of that time to recognition of the authoritative primacy of the Roman See outside of Rome. In the Ravenna Document of 13 October 2007, theologians chosen by the Roman Catholic and the Eastern Orthodox Churches stated: "41. Both sides agree ... that Rome, as the Church that 'presides in love' according to the phrase of St Ignatius of Antioch, occupied the first place in the "taxis", and that the bishop of Rome was therefore the "protos" among the patriarchs. They disagree, however, on the interpretation of the historical evidence from this era regarding the prerogatives of the Bishop of Rome as "protos", a matter that was already understood in different ways in the first millennium." 
In the late 2nd century AD, there were more manifestations of Roman authority over other churches. In 189, assertion of the primacy of the Church of Rome may be indicated in Irenaeus's "Against Heresies" (3:3:2): "With Church of Rome, because of its superior origin, all the churches must agree ... and it is in her that the faithful everywhere have maintained the apostolic tradition." In AD 195, Pope Victor I, in what is seen as an exercise of Roman authority over other churches, excommunicated the Quartodecimans for observing Easter on the 14th of Nisan, the date of the Jewish Passover, a tradition handed down by John the Evangelist (see Easter controversy). Celebration of Easter on a Sunday, as insisted on by the pope, is the system that has prevailed (see computus). 
Nicaea to East-West Schism (325–1054).
The Edict of Milan in 313 granted freedom to all religions in the Roman Empire, beginning the Peace of the Church. In 325, the First Council of Nicaea condemned Arianism, declaring trinitarianism dogmatic, and in its sixth canon recognized the special role of the sees of Rome, Alexandria, and Antioch. Great defenders of Trinitarian faith included the popes, especially Pope Liberius, who was exiled to Berea by Constantius II for his Trinitarian faith, Damasus I, and several other bishops.
In 380, the Edict of Thessalonica declared Nicene Christianity to be the state religion of the empire, with the name "Catholic Christians" reserved for those who accepted that faith. While the civil power in the Eastern Roman Empire controlled the church, and the Ecumenical Patriarch of Constantinople, the capital, wielded much power, in the Western Roman Empire, the Bishops of Rome were able to consolidate the influence and power they already possessed. After the Fall of the Western Roman Empire, barbarian tribes were converted to Arian Christianity or Catholicism; Clovis I, king of the Franks, was the first important barbarian ruler to convert to Catholicism rather than Arianism, allying himself with the papacy. Other tribes, such as the Visigoths, later abandoned Arianism in favour of Catholicism.
Middle Ages.
After the Fall of the Western Roman Empire, the pope served as a source of authority and continuity. Pope Gregory I ("c" 540–604) administered the church with strict reform. From an ancient senatorial family, Gregory worked with the stern judgement and discipline typical of ancient Roman rule. Theologically, he represents the shift from the classical to the medieval outlook; his popular writings are full of dramatic miracles, potent relics, demons, angels, ghosts, and the approaching end of the world.
Gregory's successors were largely dominated by the Exarch of Ravenna, the Byzantine emperor's representative in the Italian Peninsula. These humiliations, the weakening of the Byzantine Empire in the face of the Muslim conquests, and the inability of the emperor to protect the papal estates against the Lombards, made Pope Stephen II turn from Emperor Constantine V. He appealed to the Franks to protect his lands. Pepin the Short subdued the Lombards and donated Italian land to the papacy. When Pope Leo III crowned Charlemagne (800) as Roman Emperor, he established the precedent that, in Western Europe, no man would be emperor without being crowned by a pope.
The low point of the papacy was 867–1049. This period includes the Saeculum obscurum, the Crescentii era, and the Tusculan Papacy. The papacy came under the control of vying political factions. Popes were variously imprisoned, starved, killed, and deposed by force. The family of a certain papal official made and unmade popes for fifty years. The official's great-grandson, Pope John XII, held orgies of debauchery in the Lateran Palace. Otto I, Holy Roman Emperor had John accused in an ecclesiastical court, which deposed him and elected a layman as Pope Leo VIII. John mutilated the Imperial representatives in Rome and had himself reinstated as pope. Conflict between the Emperor and the papacy continued, and eventually dukes in league with the emperor were buying bishops and popes almost openly.
In 1049, Leo IX became pope, at last a pope with the character to face the papacy's problems. He traveled to the major cities of Europe to deal with the church's moral problems firsthand, notably simony and clerical marriage and concubinage. With his long journey, he restored the prestige of the papacy in Northern Europe.
From the 7th century it became common for European monarchies and nobility to found churches and perform investiture or deposition of clergy in their states and fiefdoms, their personal interests causing corruption among the clergy. This practice had become common because often the prelates and secular rulers were also participants in public life. To combat this and other practices that had corrupted the Church between the years 900 and 1050, centres emerged promoting ecclesiastical reform, the most important being the Abbey of Cluny, which spread its ideals throughout Europe. This reform movement gained strength with the election of Pope Gregory VII in 1073, who adopted a series of measures in the movement known as the Gregorian Reform, in order to fight strongly against simony and the abuse of civil power and try to restore ecclesiastical discipline, including clerical celibacy. The conflict between popes and secular autocratic rulers such as the Holy Roman Emperor Henry IV and Henry I of England, known as the Investiture Controversy, was only resolved in 1122, by the Concordat of Worms, in which Pope Callixtus II decreed that clerics were to be invested by clerical leaders, and temporal rulers by lay investiture. Soon after, Pope Alexander III began reforms that would lead to the establishment of canon law.
Since the beginning of the 7th century, the Caliphate had conquered much of the southern Mediterranean, and represented a threat to Christianity. In 1095, the Byzantine emperor, Alexios I Komnenos, asked for military aid from Pope Urban II in the ongoing Byzantine–Seljuq wars. Urban, at the council of Clermont, called the First Crusade to assist the Byzantine Empire to regain the old Christian territories, especially Jerusalem.
East–West Schism to Reformation (1054–1517).
With the East–West Schism, the Eastern Orthodox Church and the Roman Catholic Church split definitively in 1054. This fracture was caused more by political events than by slight divergences of creed. Popes had galled the Byzantine emperors by siding with the king of the Franks, crowning a rival Roman emperor, appropriating the Exarchate of Ravenna, and driving into Greek Italy.
In the Middle Ages, popes struggled with monarchs over power.
From 1309 to 1377, the pope resided not in Rome but in Avignon. The Avignon Papacy was notorious for greed and corruption. During this period, the pope was effectively an ally of the Kingdom of France, alienating France's enemies, such as the Kingdom of England.
The pope was understood to have the power to draw on the Treasury of Merit built up by the saints and by Christ, so that he could grant indulgences, reducing one's time in purgatory. The concept that a monetary fine or donation accompanied contrition, confession, and prayer eventually gave way to the common assumption that indulgences depended on a simple monetary contribution. The popes condemned misunderstandings and abuses, but were too pressed for income to exercise effective control over indulgences.
Popes also contended with the cardinals, who sometimes attempted to assert the authority of Catholic Ecumenical Councils over the pope's. Conciliarism holds that the supreme authority of the church lies with a General Council, not with the pope. Its foundations were laid early in the 13th century, and it culminated in the 15th century. The failure of Conciliarism to gain broad acceptance after the 15th century is taken as a factor in the Protestant Reformation.
Various Antipopes challenged papal authority, especially during the Western Schism (1378–1417). In this schism, the papacy had returned to Rome from Avignon, but an antipope was installed in Avignon, as if to extend the papacy there.
The Eastern Church continued to decline with the Eastern Roman (Byzantine) Empire, undercutting Constantinople's claim to equality with Rome. Twice an Eastern Emperor tried to force the Eastern Church to reunify with the West. First in the Second Council of Lyon (1272-1274) and secondly in the Council of Florence (1431-1449). Papal claims of superiority were a sticking point in reunification, which failed in any event. In the 15th century, the Ottoman Empire captured Constantinople.
Reformation to present (1517 to today).
Protestant Reformers criticized the papacy as corrupt and characterized the pope as the antichrist.
Popes instituted a Catholic Reformation (1560–1648), which addressed the challenges of the Protestant Reformation and instituted internal reforms. Pope Paul III initiated the Council of Trent (1545-1563), whose definitions of doctrine and whose reforms sealed the triumph of the papacy over elements in the church that sought conciliation with Protestants and opposed papal claims.
Gradually forced to give up secular power, the popes focused on spiritual issues.
In 1870, the First Vatican Council proclaimed the dogma of papal infallibility for those rare occasions the pope speaks "ex cathedra" when issuing a solemn definition of faith or morals.
Later the same year, Victor Emmanuel II of Italy seized Rome from the pope's control and substantially completed the Italian unification.
In 1929, the Lateran Treaty between the Kingdom of Italy and the Holy See established Vatican City as an independent city-state, guaranteeing papal independence from secular rule.
In 1950, Pope Pius XII defined the Assumption of Mary as dogma, the only time that a pope has spoken "ex cathedra" since papal infallibility was explicitly declared. 
The Petrine Doctrine is still controversial as an issue of doctrine that continues to divide the eastern and western churches and separate Protestants from Rome. 
Saint Peter and the origin of the papal office.
The Catholic Church teaches that, within the Christian community, the bishops as a body have succeeded to the body of the apostles ("apostolic succession") and the Bishop of Rome has succeeded to Saint Peter.
Scriptural texts proposed in support of Peter's special position in relation to the church include:
The symbolic keys in the Papal coats of arms are a reference to the phrase "the keys of the kingdom of heaven" in the first of these texts. Some Protestant writers have maintained that the "rock" that Jesus speaks of in this text is Jesus himself or the faith expressed by Peter. This idea is undermined by the Biblical usage of "Cephas," which is the masculine form of "rock" in Aramaic, to describe Peter. The "Encyclopaedia Britannica" comments that "the consensus of the great majority of scholars today is that the most obvious and traditional understanding should be construed, namely, that rock refers to the person of Peter".
Election, death and resignation.
Election.
The pope was originally chosen by those senior clergymen resident in and near Rome. In 1059 the electorate was restricted to the Cardinals of the Holy Roman Church, and the individual votes of all Cardinal Electors were made equal in 1179. The electors are now limited to those who have not reached 80 on the day before the death or resignation of a pope. Since the pope is Bishop of Rome, only those who can be ordained a bishop can be elected, which means that any male baptized Catholic is eligible. The last to be elected when not yet a bishop was Pope Gregory XVI in 1831, and the last to be elected when not even a priest was Pope Leo X in 1513, and the last to be elected when not a cardinal was Pope Urban VI in 1378. If someone who is not a bishop is elected, he must be given episcopal ordination before the election is announced to the people.
The Second Council of Lyon was convened on 7 May 1274, to regulate the election of the pope. This Council decreed that the cardinal electors must meet within ten days of the pope's death, and that they must remain in seclusion until a pope has been elected; this was prompted by the three-year "sede vacante" following the death of Pope Clement IV in 1268. By the mid-16th century, the electoral process had evolved into its present form, allowing for variation in the time between the death of the pope and the meeting of the cardinal electors. 
Traditionally, the vote was conducted by Acclamation, by selection (by committee), or by plenary vote. Acclamation was the simplest procedure, consisting entirely of a voice vote.
The election of the pope almost always takes place in the Sistine Chapel, in a sequestered meeting called a "conclave" (so called because the cardinal electors are theoretically locked in, "cum clave", i.e., with key, until they elect a new pope). Three cardinals are chosen by lot to collect the votes of absent cardinal electors (by reason of illness), three are chosen by lot to count the votes, and three are chosen by lot to review the count of the votes. The ballots are distributed and each cardinal elector writes the name of his choice on it and pledges aloud that he is voting for "one whom under God I think ought to be elected" before folding and depositing his vote on a plate atop a large chalice placed on the altar. in the Papal conclave, 2005, a special urn was used for this purpose instead of a chalice and plate. The plate is then used to drop the ballot into the chalice, making it difficult for electors to insert multiple ballots. Before being read, the ballots are counted while still folded; if the number of ballots does not match the number of electors, the ballots are burned unopened and a new vote is held. Otherwise, each ballot is read aloud by the presiding Cardinal, who pierces the ballot with a needle and thread, stringing all the ballots together and tying the ends of the thread to ensure accuracy and honesty. Balloting continues until someone is elected by a two-thirds majority. 
One of the most prominent aspects of the papal election process is the means by which the results of a ballot are announced to the world. Once the ballots are counted and bound together, they are burned in a special stove erected in the Sistine Chapel, with the smoke escaping through a small chimney visible from Saint Peter's Square. The ballots from an unsuccessful vote are burned along with a chemical compound to create black smoke, or "fumata nera". (Traditionally, wet straw was used to produce the black smoke, but this was not completely reliable. The chemical compound is more reliable than the straw.) When a vote is successful, the ballots are burned alone, sending white smoke ("fumata bianca") through the chimney and announcing to the world the election of a new pope. Starting with the Papal conclave, 2005, church bells are also rung as a signal that a new pope has been chosen. 
The Dean of the College of Cardinals then asks two solemn questions of the cardinal who has been elected. First he asks, "Do you freely accept your election as Supreme Pontiff?" If he replies with the word ""Accepto"", his reign begins at that instant. If he replies "not", his reign begins at the inauguration ceremony several days afterward. The Dean asks next, "By what name shall you be called?" The new pope announces the regnal name he has chosen. If the Dean himself is elected pope, the Vice Dean performs this task. 
The new pope is led through the "Door of Tears" to a dressing room where three sets of white papal vestments ("immantatio") await: small, medium, and large. Donning the appropriate vestments and reemerging into the Sistine Chapel, the new pope is given the "Fisherman's Ring" by the Camerlengo of the Holy Roman Church, whom he first either reconfirms or reappoints. The pope assumes a place of honor as the rest of the cardinals wait in turn to offer their first "obedience" ("adoratio") and to receive his blessing. 
The Senior Cardinal Deacon announces from a balcony over St. Peter's Square the following proclamation: "Annuntio vobis gaudium magnum! Habemus Papam!" ("I announce to you a great joy! We have a pope!"). He announces the new pope's Christian name along with his newly chosen regnal name. 
Until 1978 the pope's election was followed in a few days by the Papal coronation, which started with a procession with great pomp and circumstance from the Sistine Chapel to St. Peter's Basilica, with the newly elected pope borne in the "sedia gestatoria". After a solemn Papal Mass, the new pope was crowned with the "triregnum" (papal tiara) and he gave for the first time as pope the famous blessing "Urbi et Orbi" ("to the City and to the World"). Another renowned part of the coronation was the lighting of a bundle of flax at the top of a gilded pole, which would flare brightly for a moment and then promptly extinguish, as he said, "Sic transit gloria mundi" ("Thus passes worldly glory"). A similar warning against papal hubris made on this occasion was the traditional exclamation, ""Annos Petri non videbis"", reminding the newly crowned pope that he would not live to see his rule lasting as long as that of St. Peter. According to tradition, he headed the church for 35 years and has thus far been the longest-reigning pope in the history of the Catholic Church. 
A traditionalist Catholic belief that lacks reliable authority claims that a Papal Oath was sworn, at their coronation, by all popes from Pope Agatho to Pope Paul VI and that it was omitted with the abolition of the coronation ceremony.
The Latin term, "sede vacante" ("while the see is vacant"), refers to a papal interregnum, the period between the death or resignation of a pope and the election of his successor. From this term is derived the term sedevacantism, which designates a category of dissident Catholics who maintain that there is no canonically and legitimately elected pope, and that there is therefore a "sede vacante". One of the most common reasons for holding this belief is the idea that the reforms of the Second Vatican Council, and especially the reform of the Tridentine Mass with the Mass of Paul VI, are heretical and that those responsible for initiating and maintaining these changes are heretics and not true popes.
For centuries, from 1378 on, those elected to the papacy were predominantly Italians. Prior to the election of the Polish cardinal Karol Wojtyla as Pope John Paul II in 1978, the last non-Italian was Pope Adrian VI of the Netherlands, elected in 1522. John Paul II was followed by election of the German-born Pope Benedict XVI, who was in turn followed by Argentine-born Pope Francis. 
Death.
The current regulations regarding a papal interregnum—that is, a "sede vacante" ("vacant seat")—were promulgated by Pope John Paul II in his 1996 document "Universi Dominici Gregis". During the "sede vacante" period, the College of Cardinals is collectively responsible for the government of the Church and of the Vatican itself, under the direction of the Camerlengo of the Holy Roman Church; however, canon law specifically forbids the cardinals from introducing any innovation in the government of the Church during the vacancy of the Holy See. Any decision that requires the assent of the pope has to wait until the new pope has been elected and accepts office. 
In recent centuries, when a pope was judged to have died, it was reportedly traditional for the Cardinal Camerlengo to confirm the death ceremonially by gently tapping the pope's head thrice with a silver hammer, calling his birth name each time. This was not done on the deaths of popes John Paul I and John Paul II. The Cardinal Camerlengo retrieves the Ring of the Fisherman and cuts it in two in the presence of the Cardinals. The pope's seals are defaced, to keep them from ever being used again, and his personal apartment is sealed. 
The body lies in state for several days before being interred in the crypt of a leading church or cathedral; all popes who have died in the 20th and 21st centuries have been interred in St. Peter's Basilica. A nine-day period of mourning ("novendialis") follows the interment.
Resignation.
It is highly unusual for a pope to resign. The 1983 Code of Canon Law states, "If it happens that the Roman Pontiff resigns his office, it is required for validity that the resignation is made freely and properly manifested but not that it is accepted by anyone." Benedict XVI, who vacated the Holy See on 28 February 2013, was the most recent to do so since Gregory XII's resignation in 1415.
Titles.
Official list of titles.
The official list of titles of the Pope, in the order in which they are given in the "Annuario Pontificio", is:
The best-known title, that of "Pope", does not appear in the official list, but is commonly used in the titles of documents, and appears, in abbreviated form, in their signatures. Thus Pope Paul VI signed as "Paulus PP. VI", the "PP." standing for ""Papa"" ("Pope").
The title "Pope" was from the early 3rd century an honorific designation used for "any" bishop in the West. In the East, it was used only for the Bishop of Alexandria. Pope Marcellinus (d. 304) is the first Bishop of Rome shown in sources to have had the title "Pope" used of him. From the 6th century, the imperial chancery of Constantinople normally reserved this designation for the Bishop of Rome. From the early 6th century, it began to be confined in the West to the Bishop of Rome, a practice that was firmly in place by the 11th century, when Pope Gregory VII declared it reserved for the Bishop of Rome. 
In Eastern Christianity, where the title "Pope" is used also of the Bishop of Alexandria, the Bishop of Rome is often referred to as the "Pope of Rome", regardless of whether the speaker or writer is in communion with Rome or not. 
Vicar of Jesus Christ.
The first record of the application of this title to a Bishop of Rome appears in a synod of 495 with reference to Pope Gelasius I. But at that time, and down to the 9th century, other bishops too referred to themselves as vicars of Christ, and for another four centuries this description was sometimes used of kings and even judges, as it had been used in the 5th and 6th centuries to refer to the Byzantine emperor. Earlier still, in the 3rd century, Tertullian used "vicar of Christ" to refer to the Holy Spirit sent by Jesus. Its use specifically for the Pope appears in the 13th century in connection with the reforms of Pope Innocent III, as can be observed already in his 1199 letter to Leo I, King of Armenia. Other historians suggest that this title was already used in this way in association with the pontificate of Pope Eugene III (1145–1153).
This title "Vicar of Christ" is thus not used of the Pope alone and has been used of all bishops since the early centuries. The Second Vatican Council referred to all bishops as "vicars and ambassadors of Christ", and this description of the bishops was repeated by Pope John Paul II in his encyclical "Ut unum sint," 95. The difference is that the other bishops are vicars of Christ for their own local churches, the Pope is vicar of Christ for the whole Church.
On at least one occasion the title "Vicar of God" (a reference to Christ as God) was used of the pope.
The title "Vicar of Peter" ("Vicarius Petri") is used only of the Pope, not of other bishops. Variations of it include: "Vicar of the Prince of the Apostles" ("Vicarius Principis Apostolorum") and "Vicar of the Apostolic See" ("Vicarius Sedis Apostolicae"). Saint Boniface described Pope Gregory II as vicar of Peter in the oath of fealty that he took in 722. In today's Roman Missal, the description "vicar of Peter" is found also in the collect of the Mass for a saint who was a pope.
Supreme Pontiff.
The term "pontiff" is derived from the , which literally means "bridge builder" ("pons" + "facere") and which designated a member of the principal college of priests in ancient Rome. The Latin word was translated into ancient Greek variously: as , , , (hierophant), or (archiereus, high priest) The head of the college was known as the Pontifex Maximus (the greatest pontiff).
In Christian use, "pontifex" appears in the Vulgate translation of the New Testament to indicate the High Priest of Israel (in the original Koine Greek, ἀρχιερεύς). The term came to be applied to any Christian bishop, but since the 11th century commonly refers specifically to the Bishop of Rome, who is more strictly called the "Roman Pontiff". The use of the term to refer to bishops in general is reflected in the terms "Roman Pontifical" (a book containing rites reserved for bishops, such as confirmation and ordination), and "pontificals" (the insignia of bishops).
The "Annuario Pontificio" lists as one of the official titles of the pope that of "Supreme Pontiff of the Universal Church" (). He is also commonly called the Supreme Pontiff or the Sovereign Pontiff (). 
"Pontifex Maximus", similar in meaning to "Summus Pontifex", is a title commonly found in inscriptions on papal buildings, paintings, statues and coins, usually abbreviated as "Pont. Max" or "P.M." The office of Pontifex Maximus, or head of the College of Pontiffs, was held by Julius Caesar and thereafter, by the Roman emperors, until Gratian (375-383) relinquished it. Tertullian, when he had become a Montanist, used the title derisively of either the Pope or the Bishop of Carthage. The Popes began to use this title regularly only in the 15th century.
Servant of the servants of God.
Although the description "servant of the servants of God" () was also used by other Church leaders, including Augustine of Hippo and Benedict of Nursia, it was first used extensively as a papal title by Pope Gregory I, reportedly as a lesson in humility for the Patriarch of Constantinople, John the Faster, who had assumed the title "Ecumenical Patriarch". It became reserved for the pope in the 12th century and is used in papal bulls and similar important papal documents.
Patriarch of the West.
From 1863 until 2005, the "Annuario Pontificio" also included the title "Patriarch of the West". This title was first used by Pope Theodore I in 642, and was only used occasionally. Indeed, it did not begin to appear in the pontifical yearbook until 1863. On 22 March 2006, the Vatican released a statement explaining this omission on the grounds of expressing a "historical and theological reality" and of "being useful to ecumenical dialogue". The title Patriarch of the West symbolized the pope's special relationship with, and jurisdiction over, the Latin Church—and the omission of the title neither symbolizes in any way a change in this relationship, nor distorts the relationship between the Holy See and the Eastern Churches, as solemnly proclaimed by the Second Vatican Council.
Other titles.
Other titles commonly used are "His Holiness" (either used alone or as an honorific prefix "His Holiness Pope Francis"; and as "Your Holiness" as a form of address), "Holy Father". In Spanish and Italian, ""Beatísimo/Beatissimo Padre"" (Most Blessed Father) is often used in preference to ""Santísimo/Santissimo Padre"" (Most Holy Father). In the medieval period, ""Dominus Apostolicus"" ("the Apostolic Lord") was also used. 
Signature.
Pope Francis signs some documents with his name alone, either in Latin ("Franciscus", as in an encyclical dated 29 June 2013) or in another language. Other documents he signs in accordance with the tradition of using Latin only and including, in the abbreviated form "PP.", the description "Papa". Popes who have an ordinal numeral in their name traditionally place the abbreviation "PP." before the ordinal numeral, as in "Benedictus PP. XVI" (Pope Benedict XVI), except in bulls of canonization and decrees of ecumenical councils, which a Pope signs with the formula, "Ego N. Episcopus Ecclesiae catholicae", without the numeral, as in "Ego Benedictus Episcopus Ecclesiae catholicae" (I, Benedict, Bishop of the Catholic Church). The Pope's signature is followed, in bulls of canonization, by those of all the cardinals resident in Rome, and in decrees of ecumenical councils, by the signatures of the other bishops participating in the council, each signing as Bishop of a particular see.
Papal bulls are headed "N. Episcopus Servus Servorum Dei" ("Name, Bishop, Servant of the Servants of God"). In general, they are not signed by the Pope, but Pope John Paul II introduced in the mid-1980s the custom by which the Pope signs not only bulls of canonization but also, using his normal signature, such as "Benedictus PP. XVI", bulls of nomination of bishops. 
Regalia and insignia.
In heraldry, each pope has his own personal coat of arms. Though unique for each pope, the arms have for several centuries been traditionally accompanied by two keys in saltire (i.e., crossed over one another so as to form an "X") behind the escutcheon (shield) (one silver key and one gold key, tied with a red cord), and above them a silver "triregnum" with three gold crowns and red "infulae" (lappets—two strips of fabric hanging from the back of the triregnum which fall over the neck and shoulders when worn). This is blazoned: "two keys in saltire or and argent, interlacing in the rings or, beneath a tiara argent, crowned or"). The 21st century has seen departures from this tradition. In 2005, Pope Benedict XVI, while maintaining the crossed keys behind the shield, omitted the papal tiara from his personal coat of arms, replacing it with a mitre with three horizontal lines. Beneath the shield he added the pallium, a papal symbol of authority more ancient than the tiara, the use of which is also granted to metropolitan archbishops as a sign of communion with the See of Rome. Though the tiara was omitted in the Pope's personal coat of arms, the coat of arms of the Holy See, which includes the tiara, remained unaltered. In 2013, Pope Francis maintained the mitre that replaced the tiara, but omitted the pallium. He also departed from papal tradition by adding beneath the shield his personal pastoral motto: "Miserando atque eligendo". 
The flag most frequently associated with the pope is the yellow and white flag of Vatican City, with the arms of the Holy See (blazoned: "Gules, two keys in saltire or and argent, interlacing in the rings or, beneath a tiara argent, crowned or") on the right-hand side (the "fly") in the white half of the flag (the left-hand side—the "hoist"—is yellow). The pope's escucheon does not appear on the flag. This flag was first adopted in 1808, whereas the previous flag had been red and gold. Although Pope Benedict XVI replaced the triregnum with a mitre on his personal coat of arms, it has been retained on the flag. 
Papal garments.
Pope Pius V (reigned 1566-1572), is often credited with having originated the custom whereby the Pope wears white, by continuing after his election to wear the white habit of the Dominican order. In reality, the basic papal attire was white long before. The earliest document that describes it as such is the "Ordo XIII", a book of ceremonies compiled in about 1274. Later books of ceremonies describe the Pope as wearing a red mantle, mozzetta, camauro and shoes, and a white cassock and stockings. Many contemporary portraits of 15th and 16th-century predecessors of Pius V show them wearing a white cassock similar to his.
Status and authority.
First Vatican Council.
The status and authority of the Pope in the Catholic Church was dogmatically defined by the First Vatican Council on 18 July 1870. In its Dogmatic Constitution of the Church of Christ, the Council established the following canons:
"If anyone says that the blessed Apostle Peter was not established by the Lord Christ as the chief of all the apostles, and the visible head of the whole militant Church, or, that the same received great honour but did not receive from the same our Lord Jesus Christ directly and immediately the primacy in true and proper jurisdiction: let him be anathema.
If anyone says that it is not from the institution of Christ the Lord Himself, or by divine right that the blessed Peter has perpetual successors in the primacy over the universal Church, or that the Roman Pontiff is not the successor of blessed Peter in the same primacy, let him be anathema.
If anyone thus speaks, that the Roman Pontiff has only the office of inspection or direction, but not the full and supreme power of jurisdiction over the universal Church, not only in things which pertain to faith and morals, but also in those which pertain to the discipline and government of the Church spread over the whole world; or, that he possesses only the more important parts, but not the whole plenitude of this supreme power; or that this power of his is not ordinary and immediate, or over the churches altogether and individually, and over the pastors and the faithful altogether and individually: let him be anathema.
We, adhering faithfully to the tradition received from the beginning of the Christian faith, to the glory of God, our Saviour, the elevation of the Catholic religion and the salvation of Christian peoples, with the approbation of the sacred Council, teach and explain that the dogma has been divinely revealed: that the Roman Pontiff, when he speaks ex cathedra, that is, when carrying out the duty of the pastor and teacher of all Christians by his supreme apostolic authority he defines a doctrine of faith or morals to be held by the universal Church, through the divine assistance promised him in blessed Peter, operates with that infallibility with which the divine Redeemer wished that His church be instructed in defining doctrine on faith and morals; and so such definitions of the Roman Pontiff from himself, but not from the consensus of the Church, are unalterable. But if anyone presumes to contradict this definition of Ours, which may God forbid: let him be anathema."
Second Vatican Council.
In its Dogmatic Constitution on the Church (1964), the Second Vatican Council declared:
On 11 October 2012, on the occasion of the 50th anniversary of the opening of the Second Vatican Council 60 prominent theologians, (including Hans Küng), put out a Declaration, stating that the intention of Vatican II to balance authority in the Church has not been realised. "Many of the key insights of Vatican II have not at all, or only partially, been implemented . . . A principal source of present-day stagnation lies in misunderstanding and abuse affecting the exercise of authority in our Church."
Politics of the Holy See.
Residence and jurisdiction.
The pope's official seat or cathedral is the Archbasilica of St. John Lateran, and his official residence is the Apostolic Palace. He also possesses a summer residence at Castel Gandolfo, situated on the site of the ancient city of Alba Longa. Until the time of the Avignon Papacy, the residence of the Pope was the Lateran Palace, donated by the Roman emperor Constantine the Great. 
The Pope's ecclesiastical jurisdiction (the Holy See) is distinct from his secular jurisdiction (Vatican City). It is the Holy See that conducts international relations; for hundreds of years, the papal court (the Roman Curia) has functioned as the government of the Catholic Church. 
The names "Holy See" and "Apostolic see" are ecclesiastical terminology for the ordinary jurisdiction of the Bishop of Rome (including the Roman Curia); the pope's various honors, powers, and privileges within the Catholic Church and the international community derive from his Episcopate of Rome in lineal succession from the Apostle Saint Peter (see Apostolic succession). Consequently, Rome has traditionally occupied a central position in the Catholic Church, although this is not necessarily so. The Pope derives his pontificate from being Bishop of Rome but is not required to live there; according to the Latin formula "ubi Papa, ibi Curia", wherever the Pope resides is the central government of the Church, provided that the pope is Bishop of Rome. As such, between 1309 and 1378, the popes lived in Avignon, France (see Avignon Papacy), a period often called the Babylonian captivity in allusion to the Biblical narrative of Jews of the ancient Kingdom of Judah living as captives in Babylonia. 
Though the Pope is the diocesan Bishop of the Diocese of Rome, he delegates most of the day-to-day work of leading the diocese to the Cardinal Vicar, who assures direct episcopal oversight of the diocese's pastoral needs, not in his own name but in that of the Pope. The current Cardinal Vicar is Agostino Vallini, who was appointed to the office in June 2008. 
Political role.
Though the progressive Christianisation of the Roman Empire in the 4th century did not confer upon bishops civil authority within the state, the gradual withdrawal of imperial authority during the 5th century left the pope the senior imperial civilian official in Rome, as bishops were increasingly directing civil affairs in other cities of the Western Empire. This status as a secular and civil ruler was vividly displayed by Pope Leo I's confrontation with Attila in 452. The first expansion of papal rule outside of Rome came in 728 with the Donation of Sutri, which in turn was substantially increased in 754, when the Frankish ruler Pippin the Younger gave to the pope the land from his conquest of the Lombards. The pope may have utilized the forged Donation of Constantine to gain this land, which formed the core of the Papal States. This document, accepted as genuine until the 15th century, states that Constantine the Great placed the entire Western Empire of Rome under papal rule. In 800, Pope Leo III crowned the Frankish ruler Charlemagne as Roman Emperor, a major step toward establishing what later became known as the Holy Roman Empire; from that date onward the popes claimed the prerogative to crown the Emperor, though the right fell into disuse after the coronation of Charles V in 1530. Pope Pius VII was present at the coronation of Napoleon I in 1804 but did not actually perform the crowning. As mentioned above, the pope's sovereignty over the Papal States ended in 1870 with their annexation by Italy.
Popes like Alexander VI, an ambitious if spectacularly corrupt politician, and Pope Julius II, a formidable general and statesman, were not afraid to use power to achieve their own ends, which included increasing the power of the papacy. This political and temporal authority was demonstrated through the papal role in the Holy Roman Empire (especially prominent during periods of contention with the Emperors, such as during the Pontificates of Pope Gregory VII and Pope Alexander III). Papal bulls, interdict, and excommunication (or the threat thereof) have been used many times to increase papal power. The Bull "Laudabiliter" in 1155 authorized Henry II of England to invade Ireland. In 1207, Innocent III placed England under interdict until King John made his kingdom a fiefdom to the Pope, complete with yearly tribute, saying, "we offer and freely yield...to our lord Pope Innocent III and his catholic successors, the whole kingdom of England and the whole kingdom of Ireland with all their rights and appurtenences for the remission of our sins". The Bull "Inter caetera" in 1493 led to the Treaty of Tordesillas in 1494, which divided the world into areas of Spanish and Portuguese rule. The Bull "Regnans in Excelsis" in 1570 excommunicated Elizabeth I of England and declared that all her subjects were released from all allegiance to her. The Bull, "Inter gravissimas", in 1582 established the Gregorian calendar.
International position.
Under international law, a serving head of state has sovereign immunity from the jurisdiction of the courts of other countries, though not from that of international tribunals. This immunity is sometimes loosely referred to as "diplomatic immunity", which is, strictly speaking, the immunity enjoyed by the "diplomatic representatives" of a head of state.
International law treats the Holy See, essentially the central government of the Roman Catholic Church, as the juridical equal of a state. It is distinct from the state of Vatican City, existing for many centuries before the foundation of the latter. (It is common, however, for publications to use "Holy See", "Vatican/Vatican City", and even "Rome" interchangeably, and incorrectly.) Most countries of the world maintain the same form of diplomatic relations with the Holy See that they entertain with other states. Even countries without those diplomatic relations participate in international organizations of which the Holy See is a full member.
It is as head of the Holy See, not of Vatican City, that the U.S. Justice Department ruled that the Pope enjoys head-of-state immunity. This head-of-state immunity, recognized by the United States, must be distinguished from that envisaged under the United States' Foreign Sovereign Immunities Act of 1976, which, while recognizing the basic immunity of foreign governments from being sued in American courts, lays down nine exceptions, including commercial activity and actions in the United States by agents or employees of the foreign governments. It was in relation to the latter that, in November 2008, the United States Court of Appeals in Cincinnati decided that a case over sexual abuse by Catholic priests could proceed, provided the plaintiffs could prove that the bishops accused of negligent supervision were acting as employees or agents of the Holy See and were following official Holy See policy.
In April 2010, there was press coverage in Britain concerning a proposed plan by atheist campaigners and a prominent barrister to have Pope Benedict XVI arrested and prosecuted in the UK for alleged offences, dating from several decades before, in failing to take appropriate action regarding Catholic sex abuse cases and concerning their disputing his immunity from prosecution in that country. This was generally dismissed as "unrealistic and spurious". Another barrister said that it was a "matter of embarrassment that a senior British lawyer would want to allow himself to be associated with such a silly idea".
Objections to the papacy.
The Pope's claim to authority is either disputed or not recognised at all by other churches. The reasons for these objections differ from denomination to denomination.
Orthodox, Anglican and Old Catholic churches.
Other traditional Christian churches (Assyrian Church of the East, the Oriental Orthodox Church, the Eastern Orthodox Church, the Old Catholic Church, the Anglican Communion, the Independent Catholic churches, etc.) accept the doctrine of Apostolic succession and, to varying extents, papal claims to a primacy of honour while generally rejecting that the pope is the successor to Peter in any unique sense not true of any other bishop. Primacy is regarded as a consequence of the pope's position as bishop of the original capital city of the Roman Empire, a definition explicitly spelled out in the 28th canon of the Council of Chalcedon. These churches see no foundation to papal claims of "universal immediate jurisdiction", or to claims of papal infallibility. Several of these churches refer to such claims as "ultramontanism".
Protestant denominations.
Protestant denominations of Christianity reject the claims of Petrine primacy of honor, Petrine primacy of jurisdiction, and papal infallibility. These denominations vary from simply not accepting the Pope's claim to authority as legitimate and valid, to believing that the Pope is the Antichrist from 1 John 2:18, the Man of Sin from 2 Thessalonians 2:3-12, and the Beast out of the Earth from Revelation 13:11-18.
This sweeping rejection is held by, among others, some denominations of Lutherans: Confessional Lutherans hold that the pope is the Antichrist, stating that this article of faith is part of a "quia" rather than "quatenus" subscription to the Book of Concord. In 1932, one of these Confessional churches, the Lutheran Church–Missouri Synod (LCMS), adopted "A Brief Statement of the Doctrinal Position of the Missouri Synod", which a small number of Lutheran church bodies now hold. The Lutheran Churches of the Reformationthe Concordia Lutheran Conference[http://www.concordialutheranconf.com/doctrine/1932-2.cfm, the Church of the Lutheran Confessionand the Illinois Lutheran Conference [http://www.illinoislutheranconference.org/our-solid-foundation/doctrinal-position-of-the-ilc.lwp/odyframe.htm all hold to the "Brief Statement", which the LCMS places on its website.
Historically, Protestants objected to the papacy's claim of temporal power over all secular governments, including territorial claims in Italy, the papacy's complex relationship with secular states such as the Roman and Byzantine Empires, and the autocratic character of the papal office. In Western Christianity these objections both contributed to and are products of the Protestant Reformation.
Antipopes.
Groups sometimes form around antipopes, who claim the Pontificate without being canonically and properly elected to it.
Traditionally, this term was reserved for claimants with a significant following of cardinals or other clergy. The existence of an antipope is usually due either to doctrinal controversy within the Church (heresy) or to confusion as to who is the legitimate pope at the time (schism). Briefly in the 15th century, three separate lines of popes claimed authenticity (see Papal Schism). Even Catholics do not all agree whether certain historical figures were popes or antipopes. Though antipope movements were significant at one time, they are now overwhelmingly minor fringe causes.
Other uses of the title "pope".
In the earlier centuries of Christianity, the title "Pope", meaning "father", had been used by all bishops. Some popes used the term and others did not. Eventually, the title became associated especially with the Bishop of Rome. In a few cases, the term is used for other Christian clerical authorities.
In the Roman Catholic Church.
"Black Pope" is a name that was popularly, but unofficially, given to the Superior General of the Society of Jesus due to the Jesuits' importance within the Church. This name, based on the black colour of his cassock, was used to suggest a parallel between him and the "White Pope" (since the time of Pope Pius V the Popes dress in white) and the Cardinal Prefect of the Congregation for the Evangelization of Peoples (formerly called the Sacred Congregation for the Propagation of the Faith), whose red cardinal's cassock gave him the name of the "Red Pope" in view of the authority over all territories that were not considered in some way Catholic. In the present time this cardinal has power over mission territories for Catholicism, essentially the Churches of Africa and Asia, but in the past his competence extended also to all lands where Protestants or Eastern Christianity was dominant. Some remnants of this situation remain, with the result that, for instance, New Zealand is still in the care of this Congregation.
In the Eastern Churches.
Since the papacy of Heraclas in the 3rd century, the Bishop of the Alexandria in both the Coptic Orthodox Church of Alexandria and the Greek Orthodox Church of Alexandria continue to be called "Pope", the former being called "Coptic Pope" or, more properly, "Pope and Patriarch of All Africa on the Holy Orthodox and Apostolic Throne of Saint Mark the Evangelist and Holy Apostle" and the latter called "Pope and Patriarch of Alexandria and All Africa".
In the Bulgarian Orthodox Church, Russian Orthodox Church and Serbian Orthodox Church, it is not unusual for a village priest to be called a "pope" ("поп" "pop"). However, this should be differentiated from the words used for the head of the Catholic Church (Bulgarian "папа" "papa", Russian "папа римский" "papa rimskiy").
In new religious movements.
Some new religious movements, especially those that have disassociated themselves from the Catholic Church yet retain a Catholic hierarchical framework, have used the designation "pope" for a movement's founder or current leader. One example in Africa is the Legio Maria Church of Africa. Another example is Cao Dai, a Vietnamese faith that duplicates the Catholic hierarchy, which is declared legitimate by religious authorities in Cao Dai due to the fact that, according to them, God created both Catholicism and Cao Dai.
Lengths of papal reign.
Longest-reigning popes.
Although the average reign of the pope from the Middle Ages was a decade, a number of those whose reign lengths can be determined from contemporary historical data are the following:
During the Western Schism, Avignon Pope Benedict XIII (1394–1423) ruled for 28 years, seven months and 12 days. However, since he is regarded as an anti-pope, he is not mentioned in the list above.
Shortest-reigning popes.
There have been a number of popes whose reign lasted about a month or less. In the following list the number of calendar days includes partial days. Thus, for example, if a pope's reign commenced on 1 August and he died on 2 August, this would count as having reigned for two calendar days.
Stephen (23–26 March 752), died of stroke three days after his election, and before his consecration as a bishop. He is not recognized as a valid pope, but was added to the lists of popes in the 15th century as "Stephen II", causing difficulties in enumerating later popes named Stephen. The Holy See's "Annuario Pontificio", in its list of popes and antipopes, attaches a footnote to its mention of Stephen II (III):
Published every year by the Roman Curia, the "Annuario Pontificio" attaches no consecutive numbers to the popes, stating that it is impossible to decide which side represented at various times the legitimate succession, in particular regarding Pope Leo VIII, Pope Benedict V and some mid-11th-century popes.

</doc>
<doc id="23059" url="https://en.wikipedia.org/wiki?curid=23059" title="Passover">
Passover

Passover or Pesach (; from Hebrew "Pesah, Pesakh", Assyrian; ܦܸܨܚܵܐ"piskha"), is an important, biblically derived Jewish festival. The Jewish people celebrate Passover as a commemoration of their liberation by God from slavery in Egypt and their freedom as a nation under the leadership of Moses. It commemorates the story of the Exodus as described in the Hebrew Bible especially in the Book of Exodus, in which the Israelites were freed from slavery in Egypt. According to standard biblical chronology, this event would have taken place at about 1300 BCE (AM 2450).
Passover is a spring festival which during the existence of the Jerusalem Temple was connected to the offering of the "first-fruits of the barley", barley being the first grain to ripen and to be harvested in the Land of Israel.
Passover commences on the 15th of the Hebrew month of Nisan and lasts for either seven days (in Israel and for Reform Jews and other progressive Jews around the world who adhere to the Biblical commandment) or eight days for Orthodox, Hasidic, and most Conservative Jews (in the diaspora). In Judaism, a day commences at dusk and lasts until the following dusk, thus the first day of Passover only begins "after" dusk of the 14th of Nisan and ends at dusk of the 15th day of the month of Nisan. The rituals unique to the Passover celebrations commence with the Passover Seder when the 15th of Nisan has begun. In the Northern Hemisphere Passover takes place in spring as the Torah prescribes it: "in the month of spring" (בחדש האביב ). It is one of the most widely observed Jewish holidays.
In the narrative of the Exodus, the Bible tells that God helped the Children of Israel escape from their slavery in Egypt by inflicting ten plagues upon the ancient Egyptians before the Pharaoh would release his Israelite slaves; the tenth and worst of the plagues was the .
The Israelites were instructed to mark the doorposts of their homes with the blood of a slaughtered spring lamb and, upon seeing this, the spirit of the Lord knew to "pass over" the first-born in these homes, hence the English name of the holiday.
When the Pharaoh freed the Israelites, it is said that they left in such a hurry that they could not wait for bread dough to rise (leaven). In commemoration, for the duration of Passover no leavened bread is eaten, for which reason Passover was called the feast of unleavened bread in the Torah or Old Testament. Thus "Matzo" (flat unleavened bread) is eaten during Passover and it is a tradition of the holiday.
Historically, together with Shavuot ("Pentecost") and Sukkot ("Tabernacles"), Passover is one of the three pilgrimage festivals ("Shalosh Regalim") during which the entire population of the kingdom of Judah made a pilgrimage to the Temple in Jerusalem. Samaritans still make this pilgrimage to Mount Gerizim, but only men participate in public worship.
Date and duration.
The Passover begins on the 15th day of the month of Nisan, which typically falls in March or April of the Gregorian calendar. Passover is a spring festival, so the 15th day of Nisan typically begins on the night of a full moon after the northern vernal equinox. However, due to intercalary months or leap months falling after the vernal equinox, Passover sometimes starts on the second full moon after vernal equinox, as in 2016.
To ensure that Passover did not start before spring, the tradition in ancient Israel held that the first day of Nisan would not start until the barley was ripe, being the test for the onset of spring. If the barley was not ripe, or various other phenomena indicated that spring was not yet imminent, an intercalary month (Adar II) would be added. However, since at least the 4th century, the date has been fixed mathematically.
In Israel, Passover is the seven-day holiday of the Feast of Unleavened Bread, with the first and last days observed as legal holidays and as holy days involving abstention from work, special prayer services, and holiday meals; the intervening days are known as Chol HaMoed ("Weekdays the Festival"). Diaspora Jews historically observed the festival for eight days, and most still do. Reform and Reconstructionist Jews and Israeli Jews, wherever they are, usually observe the holiday over seven days. The reason for this extra day is due to enactment of the ancient Jewish sages. It is thought by many scholars that Jews outside of Israel could not be certain if their local calendars fully conformed to practice of the Temple at Jerusalem, so they added an extra day. But as this practice only attaches to certain (major) sacred days, others posit the extra day may have been added to accommodate people who had to travel long distances to participate in communal worship and ritual practices; or the practice may have evolved as a compromise between conflicting interpretations of Jewish Law regarding the calendar; or it may have evolved as a safety measure in areas where Jews were commonly in danger, so that their enemies would not be certain on which day to attack.
Karaites and Samaritans use different versions of the Jewish calendar, which are often out of sync with the modern Jewish calendar by one or two days. In "2009", for example, Nisan 15 on the Jewish calendar used by Rabbinic Judaism corresponds to April 9. On the calendars used by Karaites and Samaritans, "Abib" or "Aviv" 15 (as opposed to 'Nisan') corresponds to April 11 in "2009". The Karaite and Samaritan Passovers are each one day long, followed by the six day Festival of Unleavened Bread – for a total of seven days.
Origins and Biblical development.
Scholarly consensus dates the origin of the festival to a period earlier than the Exodus. The Passover ritual, prior to Deuteronomy, is widely thought to have its origins in an apotropaic rite, unrelated to the Exodus, to ensure the protection of a family home, a rite conducted wholly within a clan. Hyssop was employed to daub the blood of a slaughtered sheep on the lintels and door posts to ensure that demonic forces could not enter the home. A further hypothesis maintains that, once the Priestly Code was promulgated, the exodus narrative took on a central function, as the apotropaic rite was, arguably, amalgamated with the Canaanite agricultural festival of spring which was a ceremony of Unleavened Bread, connected with the barley harvest. As the Exodus motif grew, the original function and symbolism of these double origins was lost. Several motifs replicate the features associated with the Mesopotamian Akitu festival. Other scholars, John van Seters, J.B.Segal and Tamara Prosic disagree with the merged two-festivals hypothesis.
Called the "festival the matzot" (Hebrew: חג המצות "hag hamatzot") in the Hebrew Bible, the commandment to keep Passover is recorded in the Book of Leviticus:
In the first month, on the fourteenth day of the month at dusk is the LORD's Passover. And on the fifteenth day of the same month is the feast of unleavened bread unto the LORD; seven days ye shall eat unleavened bread. In the first day ye shall have a holy convocation; ye shall do no manner of servile work. And ye shall bring an offering made by fire unto the LORD seven days; in the seventh day is a holy convocation; ye shall do no manner of servile work. ()
The biblical regulations for the observance of the festival require that all leavening be disposed of before the beginning of the 15th of Nisan An unblemished lamb or goat, known as the Korban Pesach or "Paschal Lamb", is to be set apart on Nisan 10, and slaughtered at dusk as Nisan 14 ends in preparation for the 15th of Nisan when it will be eaten after being roasted. The literal meaning of the Hebrew is "between the two evenings". It is then to be eaten "that night", Nisan 15, roasted, without the removal of its internal organs with unleavened bread, known as matzo, and bitter herbs known as maror. Nothing of the sacrifice on which the sun rises by the morning of the 15th of Nisan may be eaten, but must be burned. The sacrifices may only be performed in a specific place prescribed by God (for Judaism, Jerusalem, and for Samaritans, Mount Gerizim).
The biblical regulations pertaining to the original Passover, at the time of the Exodus only, also include how the meal was to be eaten: "with your loins girded, your shoes on your feet, and your staff in your hand; and ye shall eat it in haste: it is the LORD's passover" .
The biblical requirements of slaying the Paschal lamb in the individual homes of the Hebrews and smearing the blood of the lamb on their doorways were observed in Egypt. However, once Israel was in the wilderness and the tabernacle was in operation, a change was made in those two original requirements (). Passover lambs were to be sacrificed at the door of the tabernacle and no longer in the homes of the Jews. No longer, therefore, could blood be smeared on doorways.
The biblical commandments concerning the Passover (and the Feast of Unleavened Bread) stress the importance of remembering:
In extra-biblical sources.
Some of these details can be corroborated, and to some extent amplified, in extrabiblical sources. The removal (or "sealing up") of the leaven is referred to in the Elephantine papyri, an Aramaic papyrus from 5th century BCE Elephantine in Egypt. The slaughter of the lambs on the 14th is mentioned in "The Book of Jubilees", a Jewish work of the Ptolemaic period, and by the Herodian-era writers Josephus and Philo. These sources also indicate that "between the two evenings" was taken to mean the afternoon. "Jubilees" states the sacrifice was eaten that night, and together with Josephus states that nothing of the sacrifice was allowed to remain until morning. Philo states that the banquet included hymns and prayers.
Etymology.
The English term "Passover" is first known to be recorded in the English language in William Tyndale's translation of the Bible, later appearing in the King James Version as well. It is a literal translation of the Hebrew term.
The Hebrew is rendered as Tiberian , and Modern Hebrew: "Pesah, Pesakh;" The Yiddish word is Latinized variously as "Peysekh, Paysakh, Paysokh". The etymology is disputed, and hypotheses are divided whether to connect it to "psh" (to protect, save) or to a word meaning 'limp, dance with limping motions.' Cognate languages yield similar terms with distinct meanings, such as 'make soft, soothe, placate' (Akkadian "passahu"), 'harvest, commemoration, blow' (Egyptian), or 'separate' (Arabic "fsh"")".
The verb ""pasàch"" () is first mentioned in the Torah's account of the Exodus from Egypt (), and there is some debate about its exact meaning: the commonly held assumption that it means "He passed over" (פסח), in reference to God "passing over" (or "skipping") the houses of the Hebrews during the final of the Ten Plagues of Egypt, stems from the translation provided in the Septuagint (παρελευσεται in , and εσκεπασεν in ). 
Targum Onkelos translates "pesach" as "he had pity".
Judging from other instances of the verb, and instances of parallelism, a more faithful translation may be "he hovered over, guarding." Indeed, this is the image invoked by the verb in Isaiah 31:5: "As birds hovering, so will the Lord of hosts protect Jerusalem; He will deliver it as He protecteth it, He will rescue it as He "passeth over"" (כְּצִפֳּרִים עָפוֹת—כֵּן יָגֵן יְהוָה צְבָאוֹת, עַל-יְרוּשָׁלִָם; גָּנוֹן וְהִצִּיל, פָּסֹחַ וְהִמְלִיט.) () Both meanings become apparent in Exodus 12:23 when parsed as: the Lord will pass (hover, guard) over the door, and will not suffer the destroyer (destroying angel is commanded to pass by the children of Israel) to come in unto your houses to smite.
The term "Pesach" () may also refer to the lamb or goat which was designated as the Passover sacrifice (called the "Korban Pesach" in Hebrew). Four days before the Exodus, the Hebrews were commanded to set aside a lamb.() and inspect it daily for blemishes. During the day on the 14th of Nisan, they were to slaughter the animal and use its blood to mark their lintels and door posts. Up until midnight on the 15th of Nisan, they were to consume the lamb. On the night of the first Passover at the start of the original Exodus, each family (or group of families) gathered together to eat a meal that included the meat of the "Korban Pesach" while the Tenth Plague ravaged Egypt.
During the existence of the Tabernacle and later the Temple in Jerusalem, the Passover offering (Hebrew "Korban Pesach") was eaten during the Passover Seder on the 15th of Nisan. However, following the destruction of the Temple, no sacrifices may be offered or eaten.
The "Seder Korban Pesach", a set of scriptural and Rabbinic passages dealing with the Passover sacrifice, is customarily recited during or after the "Mincha" (afternoon prayer) service on the 14th on Nisan. The story of the "Korban Pesach" is also retold at the Passover Seder, the word "seder" (סדר) meaning "order" or "arrangement", and one of the symbolic food items displayed (but not eaten) which represents it on the Seder Plate is the "zeroa" (shankbone) or a chicken wing or neck.
Passover offering, "korban Pesach".
When the Temple in Jerusalem was standing, the focus of the Passover festival was the Passover sacrifice (Hebrew "korban Pesach") also known as the "Paschal Lamb". Every family large enough to completely consume a young lamb or wild goat was required to offer one for sacrifice at the Jewish Temple on the afternoon of the 14th day of Nisan,() and eat it that night, which was the 15th of Nisan (). If the family was too small to finish eating the entire offering in one sitting, an offering was made for a group of families. The sacrifice could not be offered with anything leavened, () and had to be roasted, without its head, feet, or inner organs being removed () and eaten together with unleavened bread ("matzo") and bitter herbs ("maror"). One had to be careful not to break any bones from the offering, () and none of the meat could be left over by morning ().
Because of the Passover sacrifice's status as a sacred offering, the only people allowed to eat it were those who had the obligation to bring the offering. Among those who could not offer or eat the Passover lamb were an apostate (), a servant (), an uncircumcised man (), a person in a state of ritual impurity, except when a majority of Jews are in such a state ("Pesahim" 66b), and a non-Jew. The offering had to be made before a quorum of 30 ("Pesahim" 64b). In the Temple, the Levites sang Hallel while the priests performed the sacrificial service. Men and women were equally obligated regarding the offering ("Pesahim" 91b).
Women were obligated, as men, to perform the Korban Pesach and to participate in a Seder.
Today.
Today, in the absence of the Temple, the mitzvah of the "Korban Pesach" is memorialized in the "Seder Korban Pesach", recited in the afternoon of Nisan 14, and in the form of symbolic food placed on the Passover Seder Plate, which is usually a roasted shankbone. The eating of the afikoman substitutes for the eating of the "Korban Pesach" at the end of the Seder meal (Mishnah Pesachim 119a). Many Sephardi Jews have the custom of eating lamb or goat meat during the Seder in memory of the "Korban Pesach".
Removing all chametz.
Chametz (חמץ, "leavening") is made from one of five types of grains combined with water and left to stand for more than eighteen minutes. The consumption, keeping, and owning of "chametz" is forbidden during Passover. Yeast and fermentation are not themselves forbidden as seen for example by wine, which is required, rather than merely permitted. According to Halakha, the ownership of such "chametz" is also proscribed.
"Chametz" does not include baking soda, baking powder or like products. Although these are defined in English as leavening agents, they leaven by chemical reaction, not by biological fermentation. Thus, bagels, waffles and pancakes made with baking soda and matzo meal are considered permissible, while bagels made with sourdough and pancakes and waffles made with yeast are prohibited.
The Torah commandments regarding "chametz" are:
Observant Jews spend the weeks before Passover in a flurry of thorough housecleaning, to remove every morsel of "chametz" from every part of the home. Jewish law requires the elimination of olive-sized or larger quantities of leavening from one's possession, but most housekeeping goes beyond this. Even the cracks of kitchen counters are thoroughly scrubbed, for example, to remove any traces of flour and yeast, however small. Any item or implement that has handled "chametz" is generally put away and not used during Passover.
Some hotels, resorts, and even cruise ships across America, Europe and Israel also undergo a thorough housecleaning to make their premises "kosher for Pesach" to cater to observant Jews.
Interpretations for abstinence from leaven or yeast.
Some Scholars suggest that the command to abstain from leavened food or yeast suggests that sacrifices offered to God involve the offering of objects in "their least altered state", that would be nearest to the way in which they were initially made by God. According to other scholars the absence of leaven or yeast means that leaven or yeast symbolizes corruption and spoiling. In any case the main entity in Passover according to Judaism is the sacrificial lamb.
Additionally, there is a tradition of not eating matzoh (flat unleavened bread) in the 30 days before Passover begins so that there will be an increased appetite for it during Passover itself.
Sale of chametz.
"Chametz" may be sold rather than discarded, especially in the case of relatively valuable forms such as liquor distilled from wheat, with the products being repurchased afterward. In some cases, they may never leave the house, instead being formally sold while remaining in the original owner's possession in a locked cabinet until they can be repurchased after the holiday. Modern observance may also include sealing cabinets and drawers which contain "Chametz" shut by using adhesive tape, which serves a similar purpose to a lock but also shows evidence of tampering. Although the practice of selling "Chametz" dates back many years, some contemporary rabbinical authorities have come to regard it with disdain – since the supposed "new owner" never takes actual possession of the goods.
The sale of "chametz" may also be conducted communally via a rabbi, who becomes the "agent" for all the community's Jews through a halakhic procedure called a "kinyan" (acquisition). Each householder must put aside all the "chametz" he is selling into a box or cupboard, and the rabbi enters into a contract to sell all the "chametz" to a non-Jew (who is not obligated to observe the commandments) in exchange for a small down payment ("e.g." $1.00), with the remainder due after Passover. This sale is considered completely binding according to Halakha, and at any time during the holiday, the buyer may come to take or partake of his property. The rabbi then re-purchases the goods for less than they were sold at the end of the holiday.
Search for leaven.
On the night of the fourteenth of Nisan, the night before the Passover Seder (after nightfall on the evening before Passover eve), Jews do a formal search in their homes known as "bedikat chametz" for any possible remaining leaven ("chametz"). The Talmudic sages instructed that a search for "chametz" be made in every home, place of work, or any place where "chametz" may have been brought during the year. When the first Seder is on a Saturday night, the search is conducted on the preceding Thursday night (thirteenth of Nisan).
The Talmud in Pesahim (p. 2a) derives from the Torah that the search for "chametz" be conducted by the light of a candle and therefore is done at night, and although the final destruction of the "chametz" (usually by burning it in a small bonfire) is done on the next morning, the blessing is made at night because the search is both in preparation for and part of the commandments to remove and destroy all "chametz" from one's possession.
Blessing for search of chametz and nullification of chametz.
Before the search is begun there is a special blessing. If several people or family members assist in the search then only one person, usually the head of that family recites the blessing having in mind to include everyone present:
In Hebrew:
The search is then usually conducted by the head of the household joined by his family including children under the supervision of their parents.
It is customary to turn off the lights and conduct the search by candlelight, using a feather and a wooden spoon: candlelight effectively illuminates corners without casting shadows; the feather can dust crumbs out of their hiding places; and the wooden spoon which collects the crumbs can be burned the next day with the "chametz". However, most contemporary Jewish-Orthodox authorities permit using a flashlight, while some strongly encourage it due to the danger coupled with using a candle.
Because the house is assumed to have been thoroughly cleaned by the night before Passover, there is some concern that making a blessing over the search for "chametz" will be in vain ("bracha l'vatala") if nothing is found. Thus, 10 morsels of bread or cereal smaller than the size of an olive are traditionally hidden throughout the house in order to ensure that some "chametz" will be found.
Upon conclusion of the search, with all the small pieces safely wrapped up and put in one bag or place, to be burned the next morning, the following is said:
Original declaration as recited in Aramaic:
Morning of 14th of Nissan.
Fast of the Firstborn.
On the morning of the Passover seder, firstborn sons are commanded to observe the Fast of the Firstborn which commemorates the salvation of the Hebrew firstborns. According to , God struck down all Egyptian firstborns while the Israelites were not affected. However, it is customary for synagogues to conduct a "siyum" (ceremony marking the completion of a section of Torah learning) right after morning prayers, and the celebratory meal that follows cancels the firstborn's obligation to fast.
Burning and nullification of chametz.
On the morning of the 14th of Nisan, any leavened products that remain in the householder's possession, along with the 10 morsels of bread from the previous night's search, are burned ("s'rayfat chametz"). The head of the household repeats the declaration of "biyur chametz", declaring any "chametz" that may not have been found to be null and void "as the dust of the earth":
Original declaration as recited in Aramaic:
Should more "chametz" actually be found in the house during the Passover holiday, it must be burnt as soon as possible.
Unlike "chametz", which can be eaten any day of the year except during Passover, kosher for Passover foods can be eaten year-round. They need not be burnt or otherwise discarded after the holiday ends.
The historic "Paschal lamb" Passover sacrifice ("korban Pesach") has not been brought following the Romans' destruction of the Second Jewish temple approximately two thousand years ago, and it is therefore still not part of the modern Jewish holiday.
However, the Paschal lamb is still a principal feature of Falashah, Karaite and Samaritan observance.
In the times when the Jewish Temples stood, the lamb was slaughtered and cooked on the evening of Passover and was completely consumed before the morning as described in .
Separate kosher for Passover utensils and dishes.
Due to the Torah injunction not to eat "chametz" during Passover, () observant families typically own complete sets of serving dishes, glassware and silverware (and in some cases, even separate dishwashers and sinks) which have never come into contact with "chametz", for use only during Passover. Under certain circumstances, some "chametz" utensils can be immersed in boiling water ("hagalat keilim") to purge them of any traces of "chametz" that may have accumulated during the year. Many Sephardic families thoroughly wash their year-round glassware and then use it for Passover, as the Sephardic position is that glass does not absorb enough traces of food to present a problem. Similarly, ovens may be used for Passover either by setting the self-cleaning function to the highest degree for a certain period of time, or by applying a blow torch to the interior until the oven glows red hot (a process called "libun gamur").
Matzah.
A symbol of the Passover holiday is matzo, an unleavened flatbread made solely from flour and water which is continually worked from mixing through baking, so that it is not allowed to rise. Matzo may be made by machine or by hand; the latter type of matzo, called "shmura matzo" ("watched" or "guarded" matzo), is the bread of preference for the Passover Seder in Orthodox Jewish communities. The Torah contains a Divine commandment to eat matzo, specifically, on the first night of Passover and to eat only unleavened bread (in practice, matzo) during the entire week of Passover. Consequently, the eating of matzo figures prominently in the Passover Seder. There are several explanations for this.
The Torah says that it is because the Hebrews left Egypt with such haste that there was no time to allow baked bread to rise; thus flat, unleavened bread, matzo, is a reminder of the rapid departure of the Exodus. Other scholars teach that in the time of the Exodus, matzo was commonly baked for the purpose of traveling because it preserved well and was light to carry (making it similar to hardtack), suggesting that matzo was baked intentionally for the long journey ahead.
Matzo has also been called "Lechem Oni" (Hebrew: "bread of poverty"). There is an attendant explanation that matzo serves as a symbol to remind Jews what it is like to be a poor slave and to promote humility, appreciate freedom, and avoid the inflated ego symbolized by more luxurious leavened bread.
In the weeks before Passover, matzos are prepared for holiday consumption. In Orthodox Jewish communities, men traditionally gather in groups (""chaburas"") to bake a special version of handmade matzo called ""shmura matzo"", or "guarded matzo", for use at the Seder. These are made from wheat that is guarded from contamination by chametz from the time of summer harvest to its baking into matzos five to ten months later. "Shmura matzo" dough is rolled by hand, resulting in a large and round matzo. "Chaburas" also work together in machine-made matzo factories, which produce the typically square-shaped matzo sold in stores.
The baking of "shmura matzo" is labor-intensive, as only 18–22 minutes is permitted between the mixing of flour and water to the conclusion of baking and removal from the oven; however, most are completed within 5 minutes of being kneaded. Consequently, only a small number of matzos can be baked at one time, and the "chabura" members are enjoined to work the dough constantly so that it is not allowed to ferment and rise. A special cutting tool is run over the dough just before baking to prick any bubbles which might make the matza puff up; this creates the familiar dotted holes in the matzo.
After the matzos come out of the oven, the entire work area is scrubbed down and swept to make sure that no pieces of old, potentially leavened dough remain, as any stray pieces are now "chametz", and can contaminate the next batch of matzo.
Passover seder.
It is traditional for Jewish families to gather on the first night of Passover (first two nights in communities outside the land of Israel) for a special dinner called a seder (סדר—derived from the Hebrew word for "order", referring to the very specific order of the ritual). The table is set with the finest china and silverware to reflect the importance of the meal. During this meal, the story of the Exodus from Egypt is retold using a special text called the Haggadah. Four cups of wine are consumed at various stages in the narrative. The Haggadah divides the night's procedure into 15 parts:
These 15 parts parallel the 15 steps in the Temple in Jerusalem on which the Levites stood during Temple services, and which were memorialized in the 15 Psalms (#120-134) known as "Shir HaMa'alot" (, "Songs of Ascent").
The seder is replete with questions, answers, and unusual practices (e.g. the recital of Kiddush which is not immediately followed by the blessing over bread, which is the traditional procedure for all other holiday meals) to arouse the interest and curiosity of the children at the table. The children are also rewarded with nuts and candies when they ask questions and participate in the discussion of the Exodus and its aftermath. Likewise, they are encouraged to search for the "afikoman", the piece of matzo which is the last thing eaten at the seder. Audience participation and interaction is the rule, and many families' seders last long into the night with animated discussions and much singing. The seder concludes with additional songs of praise and faith printed in the Haggadah, including "Chad Gadya" ("One Little Kid" or "One Little Goat").
Maror.
Maror symbolizes the bitterness of slavery in Egypt. The following verse from the Torah underscores that symbolism: "And they embittered ("ve-yimareru" וימררו) their lives with hard labor, with mortar and with bricks and with all manner of labor in the field; any labor that they made them do was with hard labor" (Exodus 1:14).
Four cups of wine.
There is a Rabbinic requirement that four cups of wine are to be drunk during the seder meal. This applies to both men and women. The Mishnah says (Pes. 10:1) that even the poorest man in Israel has an obligation to drink. Each cup is connected to a different part of the seder: the first cup is for Kiddush, the second cup is connected with the recounting of the Exodus, the drinking of the third cup concludes Birkat Hamazon and the fourth cup is associated with Hallel.
The four questions and participation of children.
Children have a very important role in the Passover seder. Traditionally the youngest child is prompted to ask questions about the Passover seder, beginning with the words, "Mah Nishtana HaLeila HaZeh" (Why is this night different from all other nights?). The questions encourage the gathering to discuss the significance of the symbols in the meal. The questions asked by the child are:
Often the leader of the seder and the other adults at the meal will use prompted responses from the Haggadah, which states, "The more one talks about the Exodus from Egypt, the more praiseworthy he is." Many readings, prayers, and stories are used to recount the story of the Exodus. Many households add their own commentary and interpretation and often the story of the Jews is related to the theme of liberation and its implications worldwide.
Afikoman.
The "afikoman" — an integral part of the Seder itself — is used to engage the interest and excitement of the children at the table. During the fourth part of the Seder, called "Yachatz", the leader breaks the middle piece of matzo into two. He sets aside the larger portion as the "afikoman". Many families use the "afikoman" as a device for keeping the children awake and alert throughout the Seder proceedings by hiding the "afikoman" and offering a prize for its return. Alternatively, the children are allowed to "steal" the "afikoman" and demand a reward for its return. In either case, the "afikoman" must be consumed during the twelfth part of the Seder, "Tzafun".
Concluding songs.
After the Hallel, the fourth glass of wine is drunk, and participants recite a prayer that ends in "Next year in Jerusalem!". This is followed by several lyric prayers that expound upon God's mercy and kindness, and give thanks for the survival of the Jewish people through a history of exile and hardship. "Echad Mi Yodea" ("Who Knows One?") is a playful song, testing the general knowledge of the children (and the adults). Some of these songs, such as "Chad Gadiyah" are allegorical.
Counting of the Omer.
Beginning on the second night of Passover, the 16th day of Nisan, Jews begin the practice of the Counting of the Omer, a nightly reminder of the approach of the holiday of Shavuot 50 days hence. Each night after the evening prayer service, men and women recite a special blessing and then enumerate the day of the Omer. On the first night, for example, they say, "Today is the first day in (or, to) the Omer"; on the second night, "Today is the second day in the Omer." The counting also involves weeks; thus, the seventh day is commemorated, "Today is the seventh day, which is one week in the Omer." The eighth day is marked, "Today is the eighth day, which is one week and one day in the Omer," etc.
When the Temple stood in Jerusalem, a sheaf of new-cut barley was presented before the altar on the second day of Unleavened Bread. Josephus writes
On the second day of unleavened bread, that is to say the sixteenth, our people partake of the crops which they have reaped and which have not been touched till then, and esteeming it right first to do homage to God, to whom they owe the abundance of these gifts, they offer to him the first-fruits of the barley in the following way. After parching and crushing the little sheaf of ears and purifying the barley for grinding, they bring to the altar an "assaron" for God, and, having flung a handful thereof on the altar, they leave the rest for the use of the priests. Thereafter all are permitted, publicly or individually, to begin harvest. Since the destruction of the Temple, this offering is brought in word rather than deed.
One explanation for the Counting of the Omer is that it shows the connection between Passover and Shavuot. The physical freedom that the Hebrews achieved at the Exodus from Egypt was only the beginning of a process that climaxed with the spiritual freedom they gained at the giving of the Torah at Mount Sinai. Another explanation is that the newborn nation which emerged after the Exodus needed time to learn their new responsibilities vis-a-vis Torah and mitzvot before accepting God's law. The distinction between the Omer offering—a measure of barley, typically animal fodder—and the Shavuot offering—two loaves of wheat bread, human food—symbolizes the transition process.
Hol Hamoed: The intermediate days of Passover.
In Israel, Passover lasts for seven days with the first and last days being major Jewish holidays. In Orthodox and Conservative communities, no work is performed on those days, with most of the rules relating to the observances of Shabbat being applied. A seder is held on the first day.
Outside Israel, in Orthodox and Conservative communities, the holiday lasts for eight days with the first two days and last two days being major holidays. A seder is conducted twice, on both the first and second days. In the intermediate days necessary work can be performed. Reform Judaism observes Passover over seven days, with the first and last days being a major holidays. The Seder is held on the first day.
Like the holiday of Sukkot, the intermediary days of Passover are known as Chol HaMoed (festival weekdays) and are imbued with a semi-festive status. It is a time for family outings and picnic lunches of matzo, hardboiled eggs, fruits and vegetables, and Passover treats such as macaroons and homemade candies.
Passover cake recipes call for potato starch or Passover cake flour made from finely granulated matzo instead of regular flour, and a large amount of eggs to achieve fluffiness. Cookie recipes use matzo farfel (broken bits of matzo) or ground nuts as the base. For families with Eastern European backgrounds, borsht, a soup made with beets, is a Passover tradition.
While kosher for Passover packaged goods are available in stores, some families opt to cook everything from scratch during Passover week. In Israel, families that do not kasher their ovens can bake cakes, casseroles, and even meat on the stovetop in a Wonder Pot, an Israeli invention consisting of three parts: an aluminium pot shaped like a Bundt pan, a hooded cover perforated with venting holes, and a thick, round, metal disc with a center hole which is placed between the Wonder Pot and the flame to disperse heat.
Seventh day of Passover.
"Shvi'i shel Pesach" (שביעי של פסח) ("seventh of Passover") is another full Jewish holiday, with special prayer services and festive meals. Outside the Land of Israel, in the Jewish diaspora, "Shvi'i shel Pesach" is celebrated on both the seventh and eighth days of Passover. This holiday commemorates the day the Children of Israel reached the Red Sea and witnessed both the miraculous "Splitting of the Sea", the drowning of all the Egyptian chariots, horses and soldiers that pursued them, and the Passage of the Red Sea. According to the Midrash, only the Pharaoh was spared to give testimony to the miracle that occurred.
Hasidic Rebbes traditionally hold a "tish" on the night of "Shvi'i shel Pesach" and place a cup or bowl of water on the table before them. They use this opportunity to speak about the Splitting of the Sea to their disciples, and sing songs of praise to God.
Second Passover.
The "Second Passover" (Pesach Sheni) on the 14th of Iyar in the Hebrew Calendar is mentioned in the Hebrew Bible (Numbers 9:6–13) as a make-up day for people who were unable to offer the pesach sacrifice at the appropriate time due to ritual impurity or distance from Jerusalem. Just as on the first Pesach night, breaking bones from the second Paschal offering (Numbers 9:12) or leaving meat over until morning (Numbers 9:12) is prohibited.
Today, Pesach Sheni on the 14th of Iyar has the status of a very minor holiday (so much so that many of the Jewish people have never even heard of it, and it essentially does not exist outside of Orthodox and traditional Conservative Judaism). There are not really any special prayers or observances that are considered Jewish law. The only change in the liturgy is that in some communities "Tachanun", a penitential prayer omitted on holidays, is not said. There is a custom, though not Jewish law, to eat just one piece of matzo on that night.
Traditional foods.
Because the house is free of chametz for eight days, the Jewish household typically eats different foods during the week of Passover. Some include:
Ashkenazi foods
Sephardi foods
Sermons, liturgy, and song.
The story of Passover, with its message that slaves can go free, and that the future can be better than the present, has inspired a number of religious sermons, prayers, and songs—including spirituals (what used to be called "Negro Spirituals"), within the African-American community.
Rabbi Philip R. Alstat, an early leader of Conservative Judaism, known for his fiery rhetoric and powerful oratory skills, wrote and spoke in 1939 about the power of the Passover story during the rise of Nazi persecution and terror:
Perhaps in our generation the counsel of our Talmudic sages may seem superfluous, for today the story of our enslavement in Egypt is kept alive not only by ritualistic symbolism, but even more so by tragic realism. We are the contemporaries and witnesses of its daily re-enactment. Are not our hapless brethren in the German Reich eating "the bread of affliction"? Are not their lives embittered by complete disenfranchisement and forced labor? Are they not lashed mercilessly by brutal taskmasters behind the walls of concentration camps? Are not many of their men-folk being murdered in cold blood? Is not the ruthlessness of the Egyptian Pharaoh surpassed by the sadism of the Nazi dictators?And yet, even in this hour of disaster and degradation, it is still helpful to "visualize oneself among those who had gone forth out of Egypt." It gives stability and equilibrium to the spirit. Only our estranged kinsmen, the assimilated, and the de-Judaized, go to pieces under the impact of the blow...But those who visualize themselves among the groups who have gone forth from the successive Egypts in our history never lose their sense of perspective, nor are they overwhelmed by confusion and despair... It is this faith, born of racial experience and wisdom, which gives the oppressed the strength to outlive the oppressors and to endure until the day of ultimate triumph when we shall "be brought forth from bondage unto freedom, from sorrow unto joy, from mourning unto festivity, from darkness unto great light, and from servitude unto redemption.
Influence on other religions.
Christianity.
The Christian feast of Maundy Thursday finds its roots in the Jewish feast of Passover, the night on which the Last Supper is generally thought to have occurred.
Islam.
In Islam, Sunni Muslims fast on the day of Ashura (the 10th day of Muharram) based on narrations attributed to Muhammad. The fasting is to commemorate the day when Moses and his followers were saved from Pharaoh by Allah by creating a path in the Red Sea (i.e. The Exodus). According to Muslim tradition, the Jews of Madinah used to fast on the tenth day in observance of passover. As Muslims revere the Israelites, Muhammad recommended to fast this day but be different from the Jews and recommended fasting two days instead of one. 9th and 10th or the 10th and 11th day of Muharram.

</doc>
<doc id="23062" url="https://en.wikipedia.org/wiki?curid=23062" title="Post Office Protocol">
Post Office Protocol

In computing, the Post Office Protocol (POP) is an application-layer Internet standard protocol used by local e-mail clients to retrieve e-mail from a remote server over a TCP/IP connection. POP has been developed through several versions, with version 3 (POP3) being the last standard in common use before largely being made obsolete by the more advanced IMAP.
Overview.
POP supports simple download-and-delete requirements for access to remote mailboxes (termed maildrop in the POP RFC's). Although most POP clients have an option to leave mail on server after download, e-mail clients using POP generally connect, retrieve all messages, store them on the user's PC as new messages, delete them from the server, and then disconnect. Other protocols, notably IMAP, (Internet Message Access Protocol) provide more complete and complex remote access to typical mailbox operations. In the late 1990s and early 2000s, fewer Internet Service Providers (ISPs) supported IMAP due to the storage space that was required on the ISP's hardware. Contemporary e-mail clients supported POP, then over time popular mail client software added IMAP support.
A POP3 server listens on well-known port 110. Encrypted communication for POP3 is either requested after protocol initiation, using the STLS command, if supported, or by POP3S, which connects to the server using Transport Layer Security (TLS) or Secure Sockets Layer (SSL) on well-known TCP port 995.
Available messages to the client are fixed when a POP session opens the maildrop, and are identified by message-number local to that session or, optionally, by a unique identifier assigned to the message by the POP server. This unique identifier is permanent and unique to the maildrop and allows a client to access the same message in different POP sessions. Mail is retrieved and marked for deletion by message-number. When the client exits the session, the mail marked for deletion is removed from the maildrop.
History.
POP1 was specified in RFC 918 (1984), POP2 by RFC 937 (1985).
POP3 originated with RFC 1081 (1988). Its current specification is RFC 1939, updated with an extension mechanism, RFC 2449 and an authentication mechanism in RFC 1734.
The original POP3 specification supported only an unencrypted USER/PASS login mechanism or Berkeley .rhosts access control. POP3 currently supports several authentication methods to provide varying levels of protection against illegitimate access to a user's e-mail. Most are provided by the POP3 extension mechanisms. POP3 clients support SASL authentication methods via the AUTH extension. MIT Project Athena also produced a Kerberized version. RFC 1460 introduced APOP into the core protocol. APOP is a challenge/response protocol which uses the MD5 hash function in an attempt to avoid replay attacks and disclosure of the shared secret. Clients implementing APOP include Mozilla Thunderbird, Opera Mail, Eudora, KMail, Novell Evolution, RimArts' Becky!, Windows Live Mail, PowerMail, Apple Mail, and Mutt. RFC 1460 was obsoleted by RFC 1725, which was in turn obsoleted by RFC 1939.
""POP4"" exists only as an informal proposal adding basic folder management, multipart message support, as well as message flag management to compete with IMAP; but has not progressed since 2003.
Extensions.
An extension mechanism was proposed in RFC 2449 to accommodate general extensions as well as announce in an organized manner support for optional commands, such as TOP and UIDL. The RFC did not intend to encourage extensions, and reaffirmed that the role of POP3 is to provide simple support for mainly download-and-delete requirements of mailbox handling.
The extensions are termed capabilities and are listed by the CAPA command. Except for APOP, the optional commands were included in the initial set of capabilities. Following the lead of ESMTP (RFC 5321), capabilities beginning with an X signify local capabilities.
STARTTLS.
The STARTTLS extension allows the use of Transport Layer Security (TLS) or Secure Sockets Layer (SSL) to be negotiated using the "STLS" command, on the standard POP3 port, rather than an alternate. Some clients and servers instead use the alternate-port method, which uses TCP port 995 (POP3S).
SDPS.
Demon Internet introduced extensions to POP3 that allow multiple accounts per domain, and has become known as "Standard Dial-up POP3 Service" (SDPS). To access each account, the username includes the hostname, as "john@hostname" or "john+hostname".
Google Apps uses the same method.
Dialog example.
The APOP usage is a direct example from [//tools.ietf.org/html/rfc1939#page-19 RFC 1939 page 18].
RFC 1939 APOP support indicated by <1896.697170952@dbc.mtview.ca.us> here:
POP3 servers without the optional APOP command expect the client to log in with the USER and PASS commands:

</doc>
<doc id="23069" url="https://en.wikipedia.org/wiki?curid=23069" title="Punch (magazine)">
Punch (magazine)

Punch, or The London Charivari was a British weekly magazine of humour and satire established in 1841 by Henry Mayhew and engraver Ebenezer Landells. Historically, it was most influential in the 1840s and 1850s, when it helped to coin the term "cartoon" in its modern sense as a humorous illustration. 
After the 1940s, when its circulation peaked, it went into a long decline, closing in 1992. It was revived in 1996, but closed again in 2002.
History.
"Punch" was founded on 17 July 1841 by Henry Mayhew and engraver Ebenezer Landells, on an initial investment of £25. It was jointly edited by Mayhew and Mark Lemon. It was subtitled "The London Charivari" in homage to Charles Philipon's French satirical humour magazine "Le Charivari". Reflecting their satiric and humorous intent, the two editors took for their name and masthead the anarchic glove puppet, Mr. Punch, of Punch and Judy; the name also referred to a joke made early on about one of the magazine's first editors, Lemon, that "punch is nothing without lemon". Mayhew ceased to be joint editor in 1842 and became "suggestor in chief" until he severed his connection in 1845. The magazine initially struggled for readers, except for an 1842 "Almanack" issue which shocked its creators by selling 90,000 copies. In December 1842 due to financial difficulties the magazine was sold to Bradbury and Evans, both printers and publishers. Bradbury and Evans capitalised on newly evolving mass printing technologies and also were the publishers for Charles Dickens and William Makepeace Thackeray.
The term "cartoon" to refer to comic drawings was first used in "Punch" in 1843, when the Houses of Parliament were to be decorated with murals, and "cartoons" for the mural were displayed for the public; the term "cartoon" then meant a finished preliminary sketch on a large piece of cardboard, or in Italian. "Punch" humorously appropriated the term to refer to its political cartoons, and the popularity of the "Punch" cartoons led to the term's widespread use.
The illustrator Archibald Henning designed the cover of the magazine's first issues. The cover design varied in the early years, though Richard Doyle designed what became the magazine's masthead in 1849. Artists who published in "Punch" during the 1840s and 50s included John Leech, Richard Doyle, John Tenniel and Charles Keene. This group became known as "The "Punch" Brotherhood", which also included Charles Dickens who joined Bradbury and Evans after leaving Chapman and Hall in 1843. "Punch" authors and artists also contributed to another Bradbury and Evans literary magazine called "Once A Week" (est.1859), created in response to Dickens' departure from "Household Words".
In the 1860s and 1870s, conservative "Punch" faced competition from upstart liberal journal "Fun", but after about 1874, "Fun"&apos;s fortunes faded. At Evans's café in London, the two journals had "Round tables" in competition with each other.
After months of financial difficulty and lack of market success, "Punch" became a staple for British drawing rooms because of its sophisticated humour and absence of offensive material, especially when viewed against the satirical press of the time. "The Times" and the Sunday paper "News of the World" used small pieces from "Punch" as column fillers, giving the magazine free publicity and indirectly granting a degree of respectability, a privilege not enjoyed by any other comic publication. "Punch" would share a friendly relationship with not only "The Times" but journals aimed at intellectual audiences such as the "Westminster Review", which published a fifty-three page illustrated article on "Punch's" first two volumes. Historian Richard Altick writes that "To judge from the number of references to it in the private letters and memoirs of the 1840s..."Punch" had become a household word within a year or two of its founding, beginning in the middle class and soon reaching the pinnacle of society, royalty itself".
Increasing in readership and popularity throughout the remainder of the 1840s and 1850s, "Punch" was the success story of a threepenny weekly paper that had become one of the most talked-about and enjoyed periodicals. "Punch" enjoyed an audience including Elizabeth Barrett, Robert Browning, Thomas Carlyle, Edward FitzGerald, Charlotte Brontë, Queen Victoria, Prince Albert, Ralph Waldo Emerson, Emily Dickinson, Herman Melville, Henry Wadsworth Longfellow, and James Russell Lowell. "Punch" gave several phrases to the English language, including The Crystal Palace, and the "Curate's egg" (first seen in an 1895 cartoon). Several British humour classics were first serialised in "Punch", such as the "Diary of a Nobody" and "1066 and All That". Towards the end of the nineteenth century, the artistic roster included Harry Furniss, Linley Sambourne, Francis Carruthers Gould, and Phil May. Among the outstanding cartoonists of the following century were Bernard Partridge, H. M. Bateman, Bernard Hollowood who also edited the magazine from 1957 to 1968, Kenneth Mahood and Norman Thelwell.
Circulation broke the 100,000 mark around 1910, and peaked in 1947–1948 at 175,000 to 184,000. Sales declined steadily thereafter; ultimately, the magazine was forced to close in 1992 after 150 years of publication.
"Punch" was widely emulated worldwide and popular in the colonies. However, the colonial experience, especially in India, also had an impact on Punch and its iconography. Tenniels' "Punch" cartoons of the 1857 Sepoy Mutiny led to a surge in the magazine's popularity. Colonial India was time and again caricatured in "Punch" and can be seen as a significant source for producing knowledge about India (Khanduri 2014).
Later years.
"Punch" material was collected in book formats from the late nineteenth century, which included "Pick of the Punch" annuals with cartoons and text features, "Punch and the War" (a 1941 collection of WWII-related cartoons), and "A Big Bowl of Punch" – which was republished a number of times. Many Punch cartoonists of the late 20th century published collections of their own, partly based on "Punch" contributions.
"Punch" magazine ceased publishing in 1992.
In early 1996, the Egyptian businessman Mohamed Al-Fayed bought the rights to the name, and "Punch" was re-launched later that year. It was reported that the magazine was intended to be a spoiler aimed at "Private Eye", which had published many items critical of Fayed. The magazine never became profitable in its new incarnation, and at the end of May 2002 it was announced that "Punch" would once more cease publication. Press reports quoted a loss of £16 million over the six years of publication, with only 6,000 subscribers at the end.
Whereas the earlier version of "Punch" prominently featured the clownish character Punchinello (Punch of Punch and Judy) performing antics on front covers, the resurrected "Punch" magazine did not use this character, but featured on its weekly covers a photograph of a boxing glove, thus informing its readers that the new magazine intended its name to mean "punch" in the sense of a punch in the eye.
Punch table.
In 2004, much of the archive was acquired by the British Library, including the famous "Punch" table. The long oval Victorian table was used for staff meetings and other occasions, and was brought into the offices sometime around 1855. The wooden surface is scarred with the carved initials of the magazine's longtime writers, artists and editors, as well as six invited "strangers" including James Thurber and Prince Charles. Mark Twain declined the offer, saying that the already-carved initials of William Makepeace Thackeray included his own.

</doc>
<doc id="23070" url="https://en.wikipedia.org/wiki?curid=23070" title="Pacific Ocean">
Pacific Ocean

The Pacific Ocean is the largest of the Earth's oceanic divisions. It extends from the Arctic Ocean in the north to the Southern Ocean (or, depending on definition, to Antarctica) in the south and is bounded by Asia and Australia in the west and the Americas in the east.
At 165.25 million square kilometers (63.8 million square miles) in area, this largest division of the World Ocean—and, in turn, the hydrosphere—covers about 46% of the Earth's water surface and about one-third of its total surface area, making it larger than all of the Earth's land area combined.
The equator subdivides it into the North Pacific Ocean and South Pacific Ocean, with two exceptions: the Galápagos and Gilbert Islands, while straddling the equator, are deemed wholly within the South Pacific. The Mariana Trench in the western North Pacific is the deepest point in the world, reaching a depth of .
Though the peoples of Asia and Oceania have travelled the Pacific Ocean since prehistoric times, the eastern Pacific was first sighted by Europeans in the early 16th century when Spanish explorer Vasco Núñez de Balboa crossed the Isthmus of Panama in 1513 and discovered the great "southern sea" which he named "Mar del Sur". The ocean's current name was coined by Portuguese explorer Ferdinand Magellan during the Spanish circumnavigation of the world in 1521, as he encountered favourable winds on reaching the ocean. He called it "Mar Pacifico", which in both Portuguese and Spanish means "peaceful sea".
History.
Early migrations.
Important human migrations occurred in the Pacific in prehistoric times. About 3000 BC, the Austronesian peoples on the island of Taiwan mastered the art of long-distance canoe travel and spread themselves and their languages south to the Philippines, Indonesia, and maritime Southeast Asia; west towards Madagascar; southeast towards New Guinea and Melanesia (intermarrying with native Papuans); and east to the islands of Micronesia, Oceania and Polynesia.
Long-distance trade developed all along the coast from Mozambique to Japan. Trade, and therefore knowledge, extended to the Indonesian islands but apparently not Australia. By at least 878 when there was a significant Islamic settlement in Canton much of this trade was controlled by Arabs or Muslims. In 219 BC Xu Fu sailed out into the Pacific searching for the elixir of immortality. From 1404 to 1433 Zheng He led expeditions into the Indian Ocean.
European exploration.
The first contact of European navigators with the western edge of the Pacific Ocean was made by the Portuguese expeditions of António de Abreu and Francisco Serrão to the Maluku Islands in 1512, and with Jorge Álvares's expedition to southern China in 1513, both ordered by Afonso de Albuquerque.
The east side of the ocean was discovered by Spanish explorer Vasco Núñez de Balboa in 1513 after his expedition crossed the Isthmus of Panama and reached a new ocean. He named it "Mar del Sur" (literally, "Sea of the South" or "South Sea") because the ocean was to the south of the coast of the isthmus where he first observed the Pacific.
Later, Portuguese explorer Ferdinand Magellan sailed the Pacific on a Castilian ("Spanish") expedition of world circumnavigation starting in 1519. Magellan called the ocean "Pacífico" (or "Pacific" meaning, "peaceful") because, after sailing through the stormy seas off Cape Horn, the expedition found calm waters. The ocean was often called the "Sea of Magellan" in his honor until the eighteenth century. Although Magellan himself died in the Philippines in 1521, Spanish Basque navigator Juan Sebastián Elcano led the expedition back to Spain across the Indian Ocean and round the Cape of Good Hope, completing the first world circumnavigation in 1522. Sailing around and east of the Moluccas, between 1525 and 1527, Portuguese expeditions discovered the Caroline Islands and Papua New Guinea. In 1542–43 the Portuguese also reached Japan.
In 1564, five Spanish ships consisting of 379 explorers crossed the ocean from Mexico led by Miguel López de Legazpi and sailed to the Philippines and Mariana Islands. For the remainder of the 16th century, Spanish influence was paramount, with ships sailing from Mexico and Peru across the Pacific Ocean to the Philippines, via Guam, and establishing the Spanish East Indies. The Manila galleons operated for two and a half centuries linking Manila and Acapulco, in one of the longest trade routes in history. Spanish expeditions also discovered Tuvalu, the Marquesas, the Cook Islands, the Solomon Islands, and the Admiralty Islands in the South Pacific.
Later, in the quest for Terra Australis (i.e., "the Southern Land"), Spanish explorers in the 17th century discovered the Pitcairn and Vanuatu archipelagos, and sailed the Torres Strait between Australia and New Guinea, named after navigator Luís Vaz de Torres. Dutch explorers, sailing around southern Africa, also engaged in discovery and trade; Abel Janszoon Tasman discovered Tasmania and New Zealand in 1642.
In the 16th and 17th century Spain considered the Pacific Ocean a "Mare clausum"—a sea closed to other naval powers. As the only known entrance from the Atlantic the Strait of Magellan was at times patrolled by fleets sent to prevent entrance of non-Spanish ships. On the western end of the Pacific Ocean the Dutch threatened the Spanish Philippines.
The 18th century marked the beginning of major exploration by the Russians in Alaska and the Aleutian Islands. Spain also sent expeditions to the Pacific Northwest reaching Vancouver Island in southern Canada, and Alaska. The French explored and settled Polynesia, and the British made three voyages with James Cook to the South Pacific and Australia, Hawaii, and the North American Pacific Northwest. In 1768, Pierre-Antoine Véron, a young astronomer accompanying Louis Antoine de Bougainville on his voyage of exploration, established the width of the Pacific with precision for the first time in history. One of the earliest voyages of scientific exploration was organized by Spain in the Malaspina Expedition of 1789–1794. It sailed vast areas of the Pacific, from Cape Horn to Alaska, Guam and the Philippines, New Zealand, Australia, and the South Pacific.
New Imperialism.
Growing imperialism during the 19th century resulted in the occupation of much of Oceania by other European powers, and later, Japan and the United States. Significant contributions to oceanographic knowledge were made by the voyages of HMS "Beagle" in the 1830s, with Charles Darwin aboard; HMS "Challenger" during the 1870s; the USS "Tuscarora" (1873–76); and the German "Gazelle" (1874–76).
In Oceania, France got a leading position as imperial power after making Tahiti and New Caledonia protectorates in 1842 and 1853 respectively. After navy visits to Easter Island in 1875 and 1887, Chilean navy officer Policarpo Toro managed to negotiate an incorporation of the island into Chile with native Rapanui in 1888. By occupying Easter Island, Chile joined the imperial nations. By 1900 nearly all Pacific islands were in control of Britain, France, United States, Germany, Japan, and Chile.
Although the United States gained control of Guam and the Philippines from Spain in 1898, Japan controlled most of the western Pacific by 1914 and occupied many other islands during World War II. However, by the end of that war, Japan was defeated and the U.S. Pacific Fleet was the virtual master of the ocean. Since the end of World War II, many former colonies in the Pacific have become independent states.
Geography.
The Pacific separates Asia and Australia from the Americas. It may be further subdivided by the equator into northern (North Pacific) and southern (South Pacific) portions. It extends from the Antarctic region in the South to the Arctic in the north. The Pacific Ocean encompasses approximately one-third of the Earth's surface, having an area of 165.2 million square kilometers (63.8 million square miles)—significantly larger than Earth's entire landmass of some 150 million square kilometers (58 million square miles).
Extending approximately from the Bering Sea in the Arctic to the northern extent of the circumpolar Southern Ocean at 60°S (older definitions extend it to Antarctica's Ross Sea), the Pacific reaches its greatest east-west width at about 5°N latitude, where it stretches approximately from Indonesia to the coast of Colombia—halfway around the world, and more than five times the diameter of the Moon. The lowest known point on Earth—the Mariana Trench—lies below sea level. Its average depth is , putting the total water volume at 710,000,000 cubic kilometers.
Due to the effects of plate tectonics, the Pacific Ocean is currently shrinking by roughly per year on three sides, roughly averaging a year. By contrast, the Atlantic Ocean is increasing in size.
Along the Pacific Ocean's irregular western margins lie many seas, the largest of which are the Celebes Sea, Coral Sea, East China Sea, Philippine Sea, Sea of Japan, South China Sea, Sulu Sea, Tasman Sea, and Yellow Sea. The Strait of Malacca joins the Pacific and the Indian Oceans on the west, and Drake Passage and the Strait of Magellan link the Pacific with the Atlantic Ocean on the east. To the north, the Bering Strait connects the Pacific with the Arctic Ocean.
As the Pacific straddles the 180th meridian, the "West Pacific" (or "western Pacific", near Asia) is in the Eastern Hemisphere, while the "East Pacific" (or "eastern Pacific", near the Americas) is in the Western Hemisphere.
The Southern Pacific Ocean harbors the Southeast Indian Ridge crossing from south of Australia turning into the Pacific-Antarctic Ridge (north of the South Pole) and merges with another ridge (south of South American) to form the East Pacific Rise which also connects with another ridge (south of North America) which overlooks the Juan de Fuca Ridge.
For most of Magellan's voyage from the Strait of Magellan to the Philippines, the explorer indeed found the ocean peaceful. However, the Pacific is not always peaceful. Many tropical storms batter the islands of the Pacific. The lands around the Pacific Rim are full of volcanoes and often affected by earthquakes. Tsunamis, caused by underwater earthquakes, have devastated many islands and in some cases destroyed entire towns.
The Martin Waldseemüller map of 1507 was the first to show the Americas separating two distinct oceans. Later, the Diogo Ribeiro map of 1529 was the first to show the Pacific at about its proper size.
Bordering countries and territories.
Sovereign nations.
"1 The status of Taiwan and China is disputed. For more information, see political status of Taiwan."
Landmasses and islands.
The islands entirely within the Pacific Ocean can be divided into three main groups known as Micronesia, Melanesia and Polynesia. Micronesia, which lies north of the equator and west of the International Date Line, includes the Mariana Islands in the northwest, the Caroline Islands in the center, the Marshall Islands to the west and the islands of Kiribati in the southwest.
Melanesia, to the southwest, includes New Guinea, the world's second largest island after Greenland and by far the largest of the Pacific islands. The other main Melanesian groups from north to south are the Bismarck Archipelago, the Solomon Islands, Santa Cruz, Vanuatu, Fiji and New Caledonia.
The largest area, Polynesia, stretching from Hawaii in the north to New Zealand in the south, also encompasses Tuvalu, Tokelau, Samoa, Tonga and the Kermadec Islands to the west, the Cook Islands, Society Islands and Austral Islands in the center, and the Marquesas Islands, Tuamotu, Mangareva Islands and Easter Island to the east.
Islands in the Pacific Ocean are of four basic types: continental islands, high islands, coral reefs and uplifted coral platforms. Continental islands lie outside the andesite line and include New Guinea, the islands of New Zealand, and the Philippines. Some of these islands are structurally associated with nearby continents. High islands are of volcanic origin, and many contain active volcanoes. Among these are Bougainville, Hawaii, and the Solomon Islands.
The coral reefs of the South Pacific are low-lying structures that have built up on basaltic lava flows under the ocean's surface. One of the most dramatic is the Great Barrier Reef off northeastern Australia with chains of reef patches. A second island type formed of coral is the uplifted coral platform, which is usually slightly larger than the low coral islands. Examples include Banaba (formerly Ocean Island) and Makatea in the Tuamotu group of French Polynesia.
Water characteristics.
The volume of the Pacific Ocean, representing about 50.1 percent of the world's oceanic water, has been estimated at some 714 million cubic kilometers. Surface water temperatures in the Pacific can vary from , the freezing point of sea water, in the poleward areas to about near the equator. Salinity also varies latitudinally, reaching a maximum of 37 parts per thousand in the southeastern area. The water near the equator, which can have a salinity as low as 34 parts per thousand, is less salty than that found in the mid-latitudes because of abundant equatorial precipitation throughout the year. The lowest counts of less than 32 parts per thousand are found in the far north as less evaporation of seawater takes place in these frigid areas. The motion of Pacific waters is generally clockwise in the Northern Hemisphere (the North Pacific gyre) and counter-clockwise in the Southern Hemisphere. The North Equatorial Current, driven westward along latitude 15°N by the trade winds, turns north near the Philippines to become the warm Japan or Kuroshio Current.
Turning eastward at about 45°N, the Kuroshio forks and some water moves northward as the Aleutian Current, while the rest turns southward to rejoin the North Equatorial Current. The Aleutian Current branches as it approaches North America and forms the base of a counter-clockwise circulation in the Bering Sea. Its southern arm becomes the chilled slow, south-flowing California Current. The South Equatorial Current, flowing west along the equator, swings southward east of New Guinea, turns east at about 50°S, and joins the main westerly circulation of the South Pacific, which includes the Earth-circling Antarctic Circumpolar Current. As it approaches the Chilean coast, the South Equatorial Current divides; one branch flows around Cape Horn and the other turns north to form the Peru or Humboldt Current.
Climate.
The climate patterns of the Northern and Southern Hemispheres generally mirror each other. The trade winds in the southern and eastern Pacific are remarkably steady while conditions in the North Pacific are far more varied with, for example, cold winter temperatures on the east coast of Russia contrasting with the milder weather off British Columbia during the winter months due to the preferred flow of ocean currents.
In the tropical and subtropical Pacific, the El Niño Southern Oscillation (ENSO) affects weather conditions. To determine the phase of ENSO, the most recent three-month sea surface temperature average for the area approximately to the southeast of Hawaii is computed, and if the region is more than above or below normal for that period, then an El Niño or La Niña is considered in progress. 
In the tropical western Pacific, the monsoon and the related wet season during the summer months contrast with dry winds in the winter which blow over the ocean from the Asian landmass. Worldwide, tropical cyclone activity peaks in late summer, when the difference between temperatures aloft and sea surface temperatures is the greatest. However, each particular basin has its own seasonal patterns. On a worldwide scale, May is the least active month, while September is the most active month. November is the only month in which all the tropical cyclone basins are active. Cyclones are liable to form south of Mexico, striking the western Mexican coast and occasionally the southwestern United States between June and October, with those forming in the western Pacific moving into southeast and east Asia from May to December.
In the arctic, icing from October to May can present a hazard for shipping while persistent fog occurs from June to December. A climatological low in the Gulf of Alaska keeps the southern coast wet and mild during the winter months. The Westerlies and associated jet stream within the Mid-Latitudes can be particularly strong, especially in the Southern Hemisphere, due to the temperature difference between the tropics and Antarctica, which records the coldest temperature readings on the planet. In the Southern hemisphere, because of the stormy and cloudy conditions associated with extratropical cyclones riding the jet stream, it is usual to refer to the Westerlies as the Roaring Forties, Furious Fifties and Shrieking Sixties according to the varying degrees of latitude.
Geology.
The ocean was first mapped by Abraham Ortelius; he called it Maris Pacifici following Ferdinand Magellan's description of it as "a pacific sea" during his circumnavigation from 1519 to 1522. To Magellan, it seemed much more calm (pacific) than the Atlantic.
The andesite line is the most significant regional distinction in the Pacific. A petrologic boundary, it separates the deeper, mafic igneous rock of the Central Pacific Basin from the partially submerged continental areas of felsic igneous rock on its margins. The andesite line follows the western edge of the islands off California and passes south of the Aleutian arc, along the eastern edge of the Kamchatka Peninsula, the Kuril Islands, Japan, the Mariana Islands, the Solomon Islands, and New Zealand's North Island.
The dissimilarity continues northeastward along the western edge of the Andes Cordillera along South America to Mexico, returning then to the islands off California. Indonesia, the Philippines, Japan, New Guinea, and New Zealand lie outside the andesite line.
Within the closed loop of the andesite line are most of the deep troughs, submerged volcanic mountains, and oceanic volcanic islands that characterize the Pacific basin. Here basaltic lavas gently flow out of rifts to build huge dome-shaped volcanic mountains whose eroded summits form island arcs, chains, and clusters. Outside the andesite line, volcanism is of the explosive type, and the Pacific Ring of Fire is the world's foremost belt of explosive volcanism. The Ring of Fire is named after the several hundred active volcanoes that sit above the various subduction zones.
The Pacific Ocean is the only ocean which is almost totally bounded by subduction zones. Only the Antarctic and Australian coasts have no nearby subduction zones.
Geological history.
The Pacific Ocean was born 750 million years ago at the breakup of Rodinia, although it is generally called the Panthalassic Ocean until the breakup of Pangea, about 200 million years ago. The oldest Pacific Ocean floor is only around 180 Ma old, with older crust subducted by now.
Seamount chains.
The Pacific Ocean contains several long seamount chains, formed by hotspot volcanism. These include the Hawaiian–Emperor seamount chain and the Louisville seamount chain.
Economy.
The exploitation of the Pacific's mineral wealth is hampered by the ocean's great depths. In shallow waters of the continental shelves off the coasts of Australia and New Zealand, petroleum and natural gas are extracted, and pearls are harvested along the coasts of Australia, Japan, Papua New Guinea, Nicaragua, Panama, and the Philippines, although in sharply declining volume in some cases.
Fishing.
Fish are an important economic asset in the Pacific. The shallower shoreline waters of the continents and the more temperate islands yield herring, salmon, sardines, snapper, swordfish, and tuna, as well as shellfish. Overfishing has become a serious problem in some areas. For example, catches in the rich fishing grounds of the Okhotsk Sea off the Russian coast have been reduced by at least half since the 1990s as a result of overfishing.
Environmental issues.
The quantity of small plastic fragments floating in the north-east Pacific Ocean increased a hundredfold between 1972 and 2012.
Marine pollution is a generic term for the harmful entry into the ocean of chemicals or particles. The main culprits are those using the rivers for disposing of their waste. The rivers then empty into the ocean, often also bringing chemicals used as fertilizers in agriculture. The excess of oxygen-depleting chemicals in the water leads to hypoxia and the creation of a dead zone.
Marine debris, also known as marine litter, is human-created waste that has ended up floating in a lake, sea, ocean, or waterway. Oceanic debris tends to accumulate at the center of gyres and coastlines, frequently washing aground where it is known as beach litter.
In addition, the Pacific Ocean has served as the crash site of satellites, including Mars 96, Fobos-Grunt, and Upper Atmosphere Research Satellite.

</doc>
<doc id="23071" url="https://en.wikipedia.org/wiki?curid=23071" title="Prince Edward Island">
Prince Edward Island

Prince Edward Island (PEI or P.E.I.; ) is a province of Canada consisting of the island of the same name, as well as several much smaller islands.
It is one of the three Maritime Provinces and is the smallest province in both land area and population. It is the only province of Canada to have no land boundary. The island has several informal names: "Garden of the Gulf," referring to the pastoral scenery and lush agricultural lands throughout the province; and "Birthplace of Confederation" or "Cradle of Confederation", referring to the Charlottetown Conference in 1864, although PEI did not join Confederation until 1873, when it became the seventh Canadian province. The backbone of the economy is farming; it produces 25% of Canada's potatoes. Historically, PEI is one of Canada's older settlements and demographically still reflects older immigration to the country, with Celtic, Anglo-Saxon and French surnames being overwhelmingly dominant to this day.
According to the 2011 census, the province of Prince Edward Island has 140,204 residents. It is located about 200 km north of Halifax, Nova Scotia and 600 km east of Quebec City. It consists of the main island and 231 minor islands. Altogether, the entire province has a land area of . Its capital is Charlottetown.
The main island is in size, slightly larger than the U.S. state of Delaware. It is the 104th-largest island in the world and Canada's 23rd-largest island.
Etymology.
The island is named for Prince Edward, Duke of Kent and Strathearn (1767–1820), the fourth son of King George III and the father of Queen Victoria. Prince Edward has been called "Father of the Canadian Crown." The following island landmarks are also named after the Duke of Kent:
The island is known in Scottish Gaelic as "Eilean a' Phrionnsa" (lit. "the Island of the Prince", the local form of the longer 'Eilean a' Phrionnsa Iomhair/Eideard') or "Eilean Eòin" for some Gaelic speakers in Nova Scotia though not on PEI (lit. "John's Island" in reference to the island's former name of St. John's Island: the English translation of Île Saint-Jean); in Míkmaq as "Abegweit" or "Epekwitk" roughly translated "land cradled in the waves".
Geography.
Prince Edward Island is located in the Gulf of St. Lawrence, west of Cape Breton Island, north of the Nova Scotia peninsula, and east of New Brunswick. Its southern shore bounds the Northumberland Strait. The island has two urban areas. The largest surrounds Charlottetown Harbour, situated centrally on the island's southern shore, and consists of the capital city Charlottetown, and suburban towns Cornwall and Stratford and a developing urban fringe. A much smaller urban area surrounds Summerside Harbour, situated on the southern shore west of Charlottetown Harbour, and consists primarily of the city of Summerside. As with all natural harbours on the island, Charlottetown and Summerside harbours are created by rias.
The island's landscape is pastoral. Rolling hills, woods, reddish white sand beaches, ocean coves and the famous red soil have given Prince Edward Island a reputation as a province of outstanding natural beauty. The provincial government has enacted laws to preserve the landscape through regulation, although there is a lack of consistent enforcement, and an absence of province-wide zoning and land-use planning. Under the Planning Act of the province, municipalities have the option to assume responsibility for land-use planning through the development and adoption of official plans and land use bylaws. Thirty-one municipalities have taken responsibility for planning. In areas where municipalities have not assumed responsibility for planning, the Province remains responsible for development control.
The island's lush landscape has a strong bearing on its economy and culture. The author Lucy Maud Montgomery drew inspiration from the land during the late Victorian Era for the setting of her classic novel "Anne of Green Gables" (1908). Today, many of the same qualities that Montgomery and others found in the island are enjoyed by tourists who visit year-round. They enjoy a variety of leisure activities, including beaches, various golf courses, eco-tourism adventures, touring the countryside, and enjoying cultural events in local communities around the island.
The smaller, rural communities as well as the towns and villages throughout the province, retain a slower-paced, old-world flavour. Prince Edward Island has become popular as a tourist destination for relaxation. The economy of most rural communities on the island is based on small-scale agriculture. Industrial farming has increased as businesses buy and consolidate older farm properties.
The coastline has a combination of long beaches, dunes, red sandstone cliffs, salt water marshes, and numerous bays and harbours. The beaches, dunes and sandstone cliffs consist of sedimentary rock and other material with a high iron concentration, which oxidises upon exposure to the air. The geological properties of a white silica sand found at Basin Head are unique in the province; the sand grains cause a scrubbing noise as they rub against each other when walked on, and have been called the "singing sands".
Large dune fields on the north shore can be found on barrier islands at the entrances to various bays and harbours. The magnificent sand dunes at Greenwich are of particular significance. The shifting, parabolic dune system is home to a variety of birds and rare plants; it is also a site of significant archeological interest.
Despite Prince Edward Island's small size and reputation as a largely rural province, it is the most densely populated province in Canada.
Climate.
The climate of the island is considered to be moderate and strongly influenced by the surrounding seas. As such, it is milder than inland locations owing to the warm waters from the Gulf of St. Lawrence. The climate is characterized by changeable weather throughout the year; it has some of the most variable day to day weather in Canada in which specific weather conditions seldom last for long.
During July and August, the average daytime high in PEI is ; however, the temperature can sometimes exceed during these months. In the winter months of January and February, the average daytime high is . The Island receives an average yearly rainfall of 855 mm and an average yearly snowfall of 285 cm.
Winters are moderately cold and long but are milder than inland locations, with clashes of cold Arctic air and milder Atlantic air causing frequent temperature swings. The climate is considered to be more continental than oceanic since the Gulf of St. Lawrence freezes over, thus eliminating any moderation. The mean temperature is in January. During the winter months, the island usually has many storms (which may produce rain as well as snow) and blizzards since during this time, storms originating from the North Pacific or the Gulf of Mexico frequently pass through. Springtime temperatures typically remain cool until the sea ice has melted, usually in late April or early May. Summers are moderately warm, but rarely uncomfortable, with the daily maximum temperature only occasionally reaching as high as . Autumn is a pleasant season, as the moderating Gulf waters delay the onset of frost, although storm activity increases compared to the summer. There is ample precipitation throughout the year, although it is heaviest in the late autumn, early winter and mid spring.
Geology.
Between 250 and 300 million years ago, freshwater streams flowing from ancient mountains brought silt, sand and gravel into what is now the Gulf of St. Lawrence. These sediments accumulated to form a sedimentary basin, and make up the island's bedrock. When Pleistocene glaciers receded about 15,000 years ago, glacial debris such as till was left behind to cover most of the area that would become the island. This area was connected to the mainland by a strip of land, but when ocean levels rose as the glaciers melted this land strip was flooded, forming the island. As the land rebounded from the weight of the ice, the island rose up to elevate it further from the surrounding water.
Most of the bedrock in Prince Edward Island is composed of red sandstone, part of the Permian aged Pictou Group.
Although commercial deposits of minerals have not been found, exploration in the 1940s for natural gas beneath the northeastern end of the province resulted in the discovery of an undisclosed quantity of gas. The Island was reported by government to have only 0.08tcf of "technically recoverable" natural gas. Twenty exploration wells for hydrocarbon resources have been drilled on Prince Edward Island and offshore. The first reported well was Hillsborough No.#1, drilled in Charlottetown Harbour in 1944 (the world’s first offshore well), and the most recent was New Harmony No.#1 in 2007. Since the resurgence of exploration in the mid-1990s, all wells that have shown promising gas deposits have been stimulated through hydraulic fracture or “fracking”. All oil and natural gas exploration and exploitation activities on the Island are governed by the "Oil and Natural Gas Act" R.S.P.E.I. 1988, Cap. 0-5 and its associated regulations and orders.
Water supply.
The Province of Prince Edward Island is totally dependent on groundwater for its source of drinking water. As groundwater flows through an aquifer it is naturally filtered. The water for City of Charlottetown is extracted from thirteen wells in three wellfields and distributed to customers. The water removed is replenished by precipitation.
Infrastructure in Charlottetown that was installed in 1888 is still in existence. With the age of the system in the older part of Charlottetown, concern has been raised regarding lead pipes. The Utility has been working with its residents on a lead replacement program. A plebiscite in 1967 was held in Charlottetown over fluoridation, and residents voted in favour. Under provincial legislation, the Utility is required to report to its residents on an annual basis. It is also required to do regular sampling of the water and an overview is included in each annual report. The Winter River watershed provides about 92 per cent of the 18 million litre water supply for the city of Charlottetown, which had difficulty in each of 2011, 2012 and 2013 with its supply, until water meters were installed.
Minister of Communities, Land and Environment Robert Mitchell tabled a discussion paper on the proposed "Water Act" for the province on 8 July 2015. The use of groundwater came under scrutiny as the potato industry, which accounts for $1 billion every year and 50% of farm receipts, has pressed the government to lift a moratorium on high-capacity water wells for irrigation. The release of the discussion paper was to set off a consultation process in the autumn of 2015.
Detailed information about the quality of drinking water in PEI communities and watersheds can be found at the Department of Environment, Labour and Justice. It provides a summary of the ongoing testing of drinking water done by the Prince Edward Island Analytical Laboratories. Average drinking water quality results are available, and information on the following parameters are provided: alkalinity, cadmium, calcium, chloride, chromium, iron, magnesium, manganese, nickel, nitrate, pH, phosphorus, potassium, sodium, and sulfate, as well as the presence of pesticides. Water testing services are provided for a variety of clients through the PEI Analytical Laboratories, which assesses according to the recommendations of the Guidelines for Canadian Drinking Water Quality published by Health Canada.
Unique flora and fauna.
In 2008, a new ascomycete species, "Jahnula apiospora" (Jahnulales, Dothideomycetes), was collected from submerged wood in a freshwater creek on Prince Edward Island, Canada. North Atlantic right whales, one of the rarest whale species, were once thought to be rare visitors into St. Lawrence regions until 1994, have been showing dramatic increases (annual concentrations were discovered off Percé in 1995 and gradual increases across the regions since in 1998), and since in 2014, notable numbers of whales have been recorded around Cape Breton to Prince Edward Island as 35 to 40 whales were seen in these areas in 2015.
History.
Before the influx of Europeans, the Mi'kmaq First Nations inhabited Prince Edward Island. They named the Island "Epekwitk", meaning "cradled on the waves"; Europeans represented the pronunciation as "Abegweit". The natives believed that the island was formed by the Great Spirit placing on the Blue Waters some dark red crescent-shaped clay.
French colony.
In 1534, Jacques Cartier was the first European to see the island. As part of the French colony of Acadia, the island was called "Île Saint-Jean".
Battle at Port-la-Joye (1745).
After the Siege of Louisbourg (1745) during the War of the Austrian Succession, the New Englanders also captured Île Saint-Jean (Prince Edward Island). An English detachment landed at Port-la-Joye. Under the command of Joseph de Pont Duvivier, the French had a garrison of 20 French troops at Port-la-Joye. The troops fled and New Englanders burned the capital to the ground. Duvivier and the twenty men retreated up the Northeast River (Hillsborough River), pursued by the New Englanders until the French troops received reinforcements from the Acadian militia and the Mi'kmaq. The French troops and their allies were able to drive the New Englanders to their boats, nine New Englanders killed, wounded or made prisoner. The New Englanders took six Acadian hostages, who would be executed if the Acadians or Mi'kmaq rebelled against New England control. The New England troops left for Louisbourg. Duvivier and his 20 troops left for Quebec. After the fall of Louisbourg, the resident French population of Ile Royal were deported to France. The Acadians of Ile Saint-Jean lived under the threat of deportation for the remainder of the war. 
Battle at Port-la-Joye (1746).
The New Englanders had a force of two war ships and 200 soldiers stationed at Port-La-Joye. To regain Acadia, Ramezay was sent from Quebec to the region to join forces with the Duc d'Anville Expedition. Upon arriving at Chignecto, he sent Boishebert to Ile Saint-Jean on a reconnaissance to assess the size of the New England force. After Boishebert returned, Ramezay sent Joseph-Michel Legardeur de Croisille et de Montesson along with over 500 men, 200 of whom were Mi'kmaq, to Port-La-Joye. In July 1746, the battle happened near York River. Montesson and his troops killed forty New Englanders and captured the rest. Montesson was commended for having distinguished himself in his first independent command.
Expulsion of the Acadians.
Roughly one thousand Acadians lived on the island, many of whom had fled to the island from mainland Nova Scotia during the first wave of the British-ordered expulsion in 1755, reaching a population of 5,000. However, many more were forcibly deported during the second wave of the expulsion after the Siege of Louisbourg (1758). In the Ile Saint-Jean Campaign (1758) General Jeffery Amherst ordered Colonel Andrew Rollo to capture the island. Many Acadians died in the expulsion en route to France; on December 13, 1758, the transport ship "Duke William" sank and 364 died. A day earlier the "Violet" sank and 280 died; several days later the "Ruby" sank with 213 on board.
British colony.
Great Britain obtained the island from France under the terms of the "Treaty of Paris" in 1763 which settled the Seven Years' War. The British called their new colony St. John's Island (also the Island of St. John's).
The first British governor of St. John's Island, Walter Patterson, was appointed in 1769. Assuming office in 1770, he had a controversial career during which land title disputes and factional conflict slowed the initial attempts to populate and develop the island under a feudal system. In an attempt to attract settlers from Ireland, in one of his first acts (1770) Patterson led the island's colonial assembly to rename the island "New Ireland", but the British Government promptly vetoed this as exceeding the authority vested in the colonial government; only the Privy Council in London could change the name of a colony.
Land distribution.
In the mid-1760s, a survey team divided the Island into 67 lots. On July 1, 1767, these properties were allocated to supporters of King George III by means of a lottery. Ownership of the land remained in the hands of landlords in England, angering Island settlers who were unable to gain title to land on which they worked and lived. Significant rent charges (to absentee landlords) created further anger. The land had been given to the absentee landlords with a number of conditions attached regarding upkeep and settlement terms; many of these conditions were not satisfied. Islanders spent decades trying to convince the Crown to confiscate the lots, however the descendants of the original owners were generally well connected to the British government and refused to give up the land.
In 1853, the Island government passed the Land Purchase Act which empowered them to purchase lands from those owners who were willing to sell, and then resell the land to settlers for low prices. This scheme collapsed when the Island ran short of money to continue with the purchases. Many of these lands also were fertile, and were some of the key factors to sustaining Prince Edward Island's economy.
Raid on Charlottetown (1775).
During the American Revolutionary War Charlottetown was raided in 1775 by a pair of American-employed privateers. Two armed schooners, "Franklin" and "Hancock", from Beverly, Massachusetts, made prisoner of the attorney-general at Charlottetown, on advice given them by some Pictou residents after they had taken eight fishing vessels in the Gut of Canso.
During and after the American Revolutionary War, from 1776 to 1783, the colony's efforts to attract exiled Loyalist refugees from the rebellious American colonies met with some success. Walter Patterson's brother, John Patterson, one of the original grantees of land on the island, was a temporarily exiled Loyalist and led efforts to persuade others to come.
The 1787 dismissal of Governor Patterson and his recall to London in 1789 dampened his brother's efforts, leading John to focus on his interests in the United States (one of John's sons, Commodore Daniel Patterson, became a noted United States Navy hero, and John's grandsons, Rear Admiral Thomas H. Patterson and Lt. Carlile Pioou). Edmund Fanning, also a Loyalist exiled by the Revolution, took over as the second governor, serving until 1804. His tenure was more successful than Patterson's.
On November 29, 1798, during Fanning's administration, Great Britain granted approval to change the colony's name from St. John's Island to Prince Edward Island to distinguish it from similar names in the Atlantic, such as the cities of Saint John, New Brunswick and St. John's in Newfoundland. The colony's new name honoured the fourth son of King George III, Prince Edward Augustus, the Duke of Kent (1767–1820), who subsequently led the British military forces on the continent as Commander-in-Chief, North America (1799–1800), with his headquarters in Halifax. (Prince Edward later became the father of the future Queen Victoria.)
During the 19th century the colony of Prince Edward Island began to attract "adventurous Victorian families looking for elegance on the sea. Prince Edward Island became a fashionable retreat in the nineteenth century for British nobility."
Confederation.
In September 1864, Prince Edward Island hosted the Charlottetown Conference, which was the first meeting in the process leading to the Quebec Resolutions and the creation of Canada in 1867. Prince Edward Island did not find the terms of union favourable and balked at joining in 1867, choosing to remain a colony of the United Kingdom. In the late 1860s, the colony examined various options, including the possibility of becoming a discrete dominion unto itself, as well as entertaining delegations from the United States, who were interested in Prince Edward Island joining the United States of America.
In 1871, the colony began construction of a railway and, frustrated by Great Britain's Colonial Office, began negotiations with the United States. In 1873, Canadian Prime Minister Sir John A. Macdonald, anxious to thwart American expansionism and facing the distraction of the Pacific Scandal, negotiated for Prince Edward Island to join Canada. The Dominion Government of Canada assumed the colony's extensive railway debts and agreed to finance a buy-out of the last of the colony's absentee landlords to free the island of leasehold tenure and from any new immigrants entering the island (accomplished through the passage of the "Land Purchase Act, 1875"). Prince Edward Island entered Confederation on July 1, 1873.
As a result of having hosted the inaugural meeting of Confederation, the Charlottetown Conference, Prince Edward Island presents itself as the "Birthplace of Confederation" and this is commemorated through several buildings, a ferry vessel, and the Confederation Bridge (constructed 1993 to 1997). The most prominent building in the province honouring this event is the Confederation Centre of the Arts, presented as a gift to Prince Edward Islanders by the 10 provincial governments and the Federal Government upon the centenary of the Charlottetown Conference, where it stands in Charlottetown as a national monument to the "Fathers of Confederation". The Centre is one of the 22 National Historic Sites of Canada located in Prince Edward Island.
Demographics.
According to the 2011 National Household Survey, the largest ethnic group consists of people of Scottish descent (39.2%), followed by English (31.1%), Irish (30.4%), French (21.1%), German (5.2%), and Dutch (3.1%) descent. Prince Edward Island's population is largely white; there are few visible minorities. Chinese Canadians are the largest visible minority group of Prince Edward Island, comprising 1.3% of the province's population. Almost half of respondents identified their ethnicity as "Canadian."
"Source: Statistics Canada"
Language.
The Canada 2006 Census showed a population of 135,851. Of the 133,570 singular responses to the census question concerning mother tongue, the most commonly reported languages were as follows:
In addition, there were also 105 responses of both English and a 'non-official language'; 25 of both French and a 'non-official language'; 495 of both English and French; 10 of English, French, and a 'non-official language'; and about 1,640 people who either did not respond to the question, or reported multiple non-official languages, or else gave another unenumerated response. (Figures shown are for the number of single language responses and the percentage of total single-language responses.)
Religion.
Traditionally the population has been evenly divided between Catholic and Protestant affiliations. The 2001 census indicated number of adherents for the Roman Catholic Church with 63,240 (47%) and various Protestant churches with 57,805 (43%). This included the United Church of Canada with 26,570 (20%); the Presbyterian Church with 7,885 (6%) and the Anglican Church of Canada with 6,525 (5%); those with no religion were among the lowest of the provinces with 8,705 (6.5%). If one considers that the founders of the United Church of Canada were largely Presbyterians in Prince Edward Island, the Island has one of the highest percentages of Presbyterians in the Province. The Island also has one of the largest number of Free Church of Scotland buildings in Canada, though attendance at many of these churches is very low today.
Economy.
The provincial economy is dominated by the seasonal industries of agriculture, tourism, and the fishery. The province is limited in terms of heavy industry and manufacturing, though the McCain's food conglomerate runs expansion operations from PEI.
Agriculture remains the dominant industry in the provincial economy, as it has since colonial times. The Island has a total land area of 1.4 million acres with approximately cleared for agricultural use. In 2006, the Census of Agriculture counted 1700 farms on the Island. During the 20th century, potatoes replaced mixed farming as the leading cash crop, accounting for one-third of provincial farm income. The number of acres under potato production in 2010 was 88,000, while soy accounted for 55,000. There are approximately 330 potato growers on PEI, with the grand majority of these being family farms, often with multiple generations working together. The province currently accounts for a third of Canada's total potato production, producing approximately 1.3 billion kilograms annually. Comparatively, the state of Idaho produces approximately 6.2 billion kilograms annually, with a population approximately 9.5 times greater. The province is a major producer of seed potatoes, exporting to more than twenty countries around the world. An estimated total of 70% of the land is cultivated and 25% of all potatoes grown in Canada originate from P.E.I. The processing of frozen fried potatoes, green vegetables, and berries is a leading business activity.
As a legacy of the island's colonial history, the provincial government enforces extremely strict rules for non-resident land ownership, especially since the PEI "Lands Protection Act" of 1982. Residents and corporations are limited to maximum holdings of 400 and 1,200 hectares respectively. There are also restrictions on non-resident ownership of shorelines.
The island's economy has grown significantly over the last decade in key areas of innovation. Aerospace, Bioscience, ICT and Renewable energy have been a focus for growth and diversification. Aerospace alone now accounts for over 25% of the province's international exports and is the island's fourth largest industry at $355 million in annual sales.
Many of the province's coastal communities rely upon shellfish harvesting, particularly lobster fishing as well as oyster fishing and mussel farming.
The sale of carbonated beverages such as beer and soft drinks in non-refillable containers, such as aluminum cans or plastic bottles, was banned in 1976 as an environmental measure in response to public concerns over litter. Beer and soft drink companies opted to use refillable glass bottles for their products which were redeemable at stores and bottle depots.
Though often environmental and economic agendas may be at odds, the ‘ban the can’ legislation along with being environmentally driven, was also economically motivated as it protected jobs. Seamans Beverages, a bottling company and carbonated beverage manufacturer, was established in 1939 and a major employer in Charlottetown, Prince Edward Island. Making it illegal to retail cans led to a bigger share of the carbonated beverage market for Seamans. Seamans Beverages was eventually acquired by Pepsi Bottling Group Inc in 2002 prior to the lifting of the legislation.
The introduction of recycling programs for cans and plastic bottles in neighbouring provinces in recent years (also using a redemption system) has seen the provincial government introduce legislation to reverse this ban with the restriction lifted on May 3, 2008.
Prince Edward Island has Canada's highest provincial retail sales tax rate, currently (2008) established at 10%. The tax is applied to almost all goods and services except some clothing, food and home heating fuel. The tax is also applied to the Federal Goods and Services Tax.
The provincial government provides consumer protection in the form of regulation for certain items, ranging from apartment rent increases to petroleum products including gas, diesel, propane and heating oil. These are regulated through the Prince Edward Island Regulatory and Appeals Commission (IRAC). IRAC is authorised to limit the number of companies who are permitted to sell petroleum products.
At present, approximately fifteen percent of electricity consumed on the island is generated from renewable energy (largely wind turbines); the provincial government has set renewable energy targets as high as 30-50% for electricity consumed by 2015. Until wind generation, the province relied entirely on electricity imports on a submarine cable from New Brunswick. A thermal oil-fired generating station in Charlottetown is also available. Electricity rates in the province were in 2011 the highest in Canada, at a domestic rate of 0.161 $/kWh. The province imports about 85 per cent of its power through New Brunswick. The maintenance shutdown of Point Lepreau nuclear plant forced the province to acquire most of its electrons on the expensive open market. The result was a steep price hikes of about 25 per cent in the three years to 2011 but the province later subsidised rates. Residents were to pay 11.2 per cent more for electricity when the harmonized sales tax was adopted in April 2013, according to the P.E.I. Energy Accord that was tabled in the legislature on 7 December 2012. and passed as the "Electric Power (Energy Accord Continuation) Amendment Act", which establishes electric pricing from 1 April 2013 to 1 March 2016. Regulatory powers are derived for IRAC from the "Electric Power Act". Since 1918 Maritime Electric has delivered electricity to customers on the Island. The utility is currently owned and operated by Fortis Inc.
The average family income on Prince Edward Island is $62,110/year, and the minimum wage of $10.50/hour as of July 1, 2015.
Government and politics.
The provincial government is responsible for such areas as health and social services, education, economic development, labour legislation and civil law. These matters of government are carried out in the provincial capital, Charlottetown.
Prince Edward Island is governed by a parliamentary government within the construct of constitutional monarchy; the monarchy in Prince Edward Island is the foundation of the executive, legislative, and judicial branches. The sovereign is Queen Elizabeth II, who also serves as head of state of 15 other Commonwealth countries, each of Canada's nine other provinces, and the Canadian federal realm, and resides predominantly in the United Kingdom. As such, the Queen's representative, the Lieutenant Governor of Prince Edward Island (presently Harry Frank Lewis), carries out most of the royal duties in Prince Edward Island.
The direct participation of the royal and viceroyal figures in any of these areas of governance is limited; in practice, their use of the executive powers is directed by the Executive Council, a committee of ministers of the Crown responsible to the unicameral, elected Legislative Assembly and chosen and headed by the Premier of Prince Edward Island (presently Wade MacLauchlan), the head of government. To ensure the stability of government, the lieutenant governor will usually appoint as premier the person who is usually the current leader of the political party that can obtain the confidence of a plurality in the Legislative Assembly. The leader of the party with the second-most seats usually becomes the Leader of Her Majesty's Loyal Opposition (presently Steven Myers) and is part of an adversarial parliamentary system intended to keep the government in check.
Each of the 27 Members of the Legislative Assembly (MLA) is elected by simple plurality in an electoral district. General elections are called by the lieutenant governor on the first Monday in October four years after the previous election, or may be called, on the advice of the premier, should the government lose a confidence vote in the legislature. Traditionally, politics in the province have been dominated by both the Liberal Party and the Progressive Conservative Party.
The Mi'kmaq Confederacy of PEI is the tribal council and provincial territorial organization in the province that represents both the Lennox Island and Abegweit First Nations.
Transportation.
Prince Edward Island's transportation network has traditionally revolved around its seaports of Charlottetown, Summerside, Borden, Georgetown, and Souris —linked to its railway system, and the two main airports in Charlottetown and Summerside, for communication with mainland North America. The railway system was abandoned by CN in 1989 in favour of an agreement with the federal government to improve major highways.
Until 1997, the province was linked by two passenger-vehicle ferry services to the mainland: one, provided by Marine Atlantic, operated year-round between Borden and Cape Tormentine, New Brunswick; the other, provided by Northumberland Ferries Limited, operates seasonally between Wood Islands and Caribou, Nova Scotia. A third ferry service provided by CTMA operates all year round with seasonal times between Souris and Cap-aux-Meules, Quebec, in the Magdalen Islands.
On June 1, 1997, the Confederation Bridge opened, connecting Borden-Carleton to Cape Jourimain, New Brunswick. The world's longest bridge over ice-covered waters, it replaced the Marine Atlantic ferry service. Since then, the Confederation Bridge's assured transportation link to the mainland has altered the province's tourism and agricultural and fisheries export economies.
Several airlines service the Charlottetown Airport (CYYG); the Summerside Airport (CYSU) is an additional option for general aviation.
The Island has the highest concentration of roadways in Canada. The provincially managed portion of the network consists of of paved roadways and of non-paved or clay roads.
The province has very strict laws regarding use of road-side signs. Billboards and the use of portable signs are banned. There are standard direction information signs on roads in the province for various businesses and attractions in the immediate area. Some municipalities' by-laws also restrict the types of permanent signs that may be installed on private property.
There is an extensive bicycling / hiking trail that spans the island. The Confederation Trail is a recreational trail system. The land was once owned and used by Canadian National Railway (CN) as a rail line on the island.
Education.
Prince Edward Island is home to one university, the University of Prince Edward Island (UPEI), located in the city of Charlottetown.
The university was created by the Island legislature to replace Prince of Wales College and St. Dunstan's University. UPEI is also home to the Atlantic Veterinary College, which offers the region's only veterinary medicine program.
Holland College is the provincial community college, with campuses across the province, including specialised facilities such as the Atlantic Police Academy, Marine Training Centre, and the Culinary Institute of Canada.
Prince Edward Island is also home to Maritime Christian College. It is also home to Immanuel Christian School, a private Christian School in Charlottetown.
Prince Edward Island's public school system has an English school district named the English Language School Board, as well as a Francophone district, the Commission scolaire de langue française. The English language districts have a total of 10 secondary schools and 54 intermediate and elementary schools while the Francophone district has 6 schools covering all grades. 22 per cent of the student population is enrolled in French immersion. This is one of the highest levels in the country.
Today 23.5 per cent of residents aged 15 to 19 have bilingual skills, an increase of 100 per cent in a decade.
Prince Edward Island, along with most rural regions in North America, is experiencing an accelerated rate of youth emigration. The provincial government has projected that public school enrollment will decline by 40% during the 2010s.
Health care.
The province has a single health administrative region (or district health authority) called Health PEI. Health PEI receives funding for its operations and is regulated by the Department of Health and Wellness.
Many PEI homes and businesses are serviced by central sewage collection and/or treatment systems. These are operated either by a municipality or a private utility. Many industrial operations have their own wastewater treatment facilities. Staff members with the Department of Environment, Labour and Justice provide advice to operators, as needed, on proper system maintenance. The IRAC regulates municipal water and sewer in the province, now under the "Environmental Protection Act". Since around 1900, the residents of the City of Charlottetown have benefited from a central sanitary sewer service. Early disposal practices, while advanced for their time, eventually were found to compromise the ecological integrity of the nearby Hillsborough River and the Charlottetown Harbour. By 1974, the Commission had spearheaded the development of a primary wastewater treatment plant, known as the Charlottetown Pollution Control Plant, together with the construction of several pumping stations along the City’s waterfront, and outfall piping deep into the Hillsborough River.
There are eight hospitals in the province.
Prince Edward Island offers programs and services in areas such as acute care, primary care, home care, palliative care, public health, chronic disease prevention, and mental health and addictions, to name a few. The provincial government has opened several family health centres in recent years in various rural and urban communities. A provincial cancer treatment centre at the Queen Elizabeth Hospital provides support to those dealing with various types of cancer-related illnesses. A family medicine residency program was established in 2009 with the Dalhousie University Faculty of Medicine as a means to encourage new physicians to work in Prince Edward Island.
Long-term-care services are also available with several programs in place to support seniors wishing to remain independent in their communities. Many medications for seniors are subsidized through a provincial pharmaceutical plan, however, Prince Edward Island remains one of the only provinces lacking a catastrophic drug coverage program for its residents.
The provincial government has several programs for early illness detection, including mammography and pap screening clinics. There are also asthma education and diabetes education programs, as well as prenatal programs, immunization programs and dental health risk prevention programs for children. The government is also attempting to implement a comprehensive integrated Electronic Health Record system.
The provincial government has recently committed to enhancing primary care and home care services and has invested in health care facilities in recent capital budgets; mostly replacements and upgrades to provincial government operated nursing homes and hospitals.
Some specialist services require patients to be referred to clinics and specialists in neighbouring provinces. Specialist operations and treatments are also provided at larger tertiary referral hospitals in neighbouring provinces such as the IWK Health Centre and Queen Elizabeth II Health Sciences Centre in Nova Scotia or the Saint John Regional Hospital, Moncton Hospital, and Dr. Georges-L.-Dumont University Hospital Centre in New Brunswick.
Ground ambulance service in Prince Edward Island is provided under contract by Island EMS. Air ambulance service is provided under contract by LifeFlight.
In recent decades, Prince Edward Island's population has shown statistically significant and abnormally high rates of diagnosed rare cancers, particularly in rural areas. Health officials, ecologists and environmental activists point to the use of pesticides for industrial potato farming as a primary contaminant.
Prince Edward Island is the only province in Canada that does not provide abortion services through its hospitals. The last abortion was performed in the province in 1982 prior to the opening of the Queen Elizabeth Hospital which saw the closure of the Roman Catholic-affiliated Charlottetown Hospital and the non-denominational Prince Edward Island Hospital; a condition of the "merger" being that abortions not be performed in the province. In 1988, following the court decision "R. v. Morgentaler", the then-opposition Progressive Conservative Party of Prince Edward Island tabled a motion demanding that the ban on abortions be upheld at the province's hospitals; the then-governing Prince Edward Island Liberal Party under Premier Joe Ghiz acquiesced and the ban was upheld. The Government of Prince Edward Island will fund abortions for women who travel to another province. Women from Prince Edward Island may also travel to the nearest private user-pay, Morgentaler Clinic in Fredericton, New Brunswick, where they must pay for the procedure using their own funds. (See also abortion in Canada)
Culture and sports.
Arts.
The island's cultural traditions of art, music and creative writing are supported through the public education system. There is an annual arts festival, the Charlottetown Festival, hosted at the Confederation Centre of the Arts.
Lucy Maud Montgomery, who was born in Clifton (now New London) in 1874, wrote some 20 novels and numerous short stories that have been collected into anthologies. Her first "Anne" book "Anne of Green Gables" was published in 1908. The musical play "Anne of Green Gables" has run every year at the Charlottetown festival for more than four decades. The sequel, "Anne & Gilbert", premiered in the Playhouse in Victoria in 2005. The actual location of Green Gables, the house featured in Montgomery's "Anne" books, is in Cavendish, on the north shore of PEI.
Elmer Blaney Harris founded an artists colony at Fortune Bridge and set his famous play "Johnny Belinda" on the island. Robert Harris was a well-known artist.
Prince Edward Island's documented music history begins in the 19th century with religious music, some written by the local pump and block maker and organ-importer, Watson Duchemin. Several big bands including the Sons of Temperance Band and the Charlottetown Brass Band were active. Today, Acadian, Celtic, folk, and rock music prevail, with exponents including Gene MacLellan, his daughter Catherine MacLellan, Al Tuck, Lennie Gallant, Two Hours Traffic and Paper Lions. The celebrated singer-songwriter Stompin' Tom Connors spent his formative years in Skinners Pond. Celtic music is certainly the most common traditional music on the island, with fiddling and step dancing being very common. This tradition, largely Scottish, Irish and Acadian in origin is very similar to the music of Cape Breton and to a lesser extent, Newfoundland and is unique to the region. A March 4/4 for bagpipes was composed in honour of Prince Edward Island.
There is also an annual jazz festival, the P.E.I. Jazz and Blues Festival. The one-week-long series of concerts takes place at a multitude of venues including Murphy's Community Center, outdoor stages and churches in Charlottetown. The moving of its date to mid August caused in 2011 a serious loss in funding from Ottawa's regional development agency ACOA. The musician's line up in 2011 included Oliver Jones, Sophie Milman, Matt Dusk, Jack de Keyzer, Jack Semple, Meaghan Smith, Meaghan Blanchard, Hupman Brothers, Alex Dean, Charlie A'Court, Sean Ferris, Jimmy Bowskill, West End Blues Band, Bad Habits, Brian McConnell and Mellotones.
Sister province.
Hainan Province, China, has been the sister province of Prince Edward Island since 2001. This came about after Vice-Governor Lin Fanglue stayed for two days to hold discussions about partnership opportunities and trade.

</doc>
<doc id="23080" url="https://en.wikipedia.org/wiki?curid=23080" title="Pretty Good Privacy">
Pretty Good Privacy

Pretty Good Privacy (PGP) is a data encryption and decryption computer program that provides cryptographic privacy and authentication for data communication. PGP is often used for signing, encrypting, and decrypting texts, e-mails, files, directories, and whole disk partitions and to increase the security of e-mail communications. It was created by Phil Zimmermann in 1991.
PGP and similar software follow the OpenPGP standard (RFC 4880) for encrypting and decrypting data.
Design.
PGP encryption uses a serial combination of hashing, data compression, symmetric-key cryptography, and finally public-key cryptography; each step uses one of several supported algorithms. Each public key is bound to a user name and/or an e-mail address. The first version of this system was generally known as a web of trust to contrast with the X.509 system, which uses a hierarchical approach based on certificate authority and which was added to PGP implementations later. Current versions of PGP encryption include both options through an automated key management server.
Compatibility.
As PGP evolves, versions that support newer features and algorithms are able to create encrypted messages that older PGP systems cannot decrypt, even with a valid private key. Therefore, it is essential that partners in PGP communication understand each other's capabilities or at least agree on PGP settings.
Confidentiality.
PGP can be used to send messages confidentially. For this, PGP combines symmetric-key encryption and public-key encryption. The message is encrypted using a symmetric encryption algorithm, which requires a symmetric key. Each symmetric key is used only once and is also called a session key. The message and its session key are sent to the receiver. The session key must be sent to the receiver so they know how to decrypt the message, but to protect it during transmission, it is encrypted with the receiver's public key. Only the private key belonging to the receiver can decrypt the session key.
Digital signatures.
PGP supports message authentication and integrity checking. The latter is used to detect whether a message has been altered since it was completed (the "message integrity" property) and the former to determine whether it was actually sent by the person or entity claimed to be the sender (a "digital signature"). Because the content is encrypted, any changes in the message will result in failure of the decryption with the appropriate key. The sender uses PGP to create a digital signature for the message with either the RSA or DSA algorithms. To do so, PGP computes a hash (also called a message digest) from the plaintext and then creates the digital signature from that hash using the sender's private key.
Web of trust.
Both when encrypting messages and when verifying signatures, it is critical that the public key used to send messages to someone or some entity actually does 'belong' to the intended recipient. Simply downloading a public key from somewhere is not an overwhelming assurance of that association; deliberate (or accidental) impersonation is possible. From its first version, PGP has always included provisions for distributing user's public keys in an 'identity certificate', which is also constructed cryptographically so that any tampering (or accidental garble) is readily detectable. However, merely making a certificate which is impossible to modify without being detected is insufficient; this can prevent corruption only after the certificate has been created, not before. Users must also ensure by some means that the public key in a certificate actually does belong to the person or entity claiming it. From its first release, PGP products have included an internal certificate 'vetting scheme' to assist with this, a trust model which has been called a web of trust. A given public key (or more specifically, information binding a user name to a key) may be digitally signed by a third party user to attest to the association between someone (actually a user name) and the key. There are several levels of confidence which can be included in such signatures. Although many programs read and write this information, few (if any) include this level of certification when calculating whether to trust a key.
The web of trust protocol was first described by Zimmermann in 1992, in the manual for PGP version 2.0:
The web of trust mechanism has advantages over a centrally managed public key infrastructure scheme such as that used by S/MIME but has not been universally used. Users have been willing to accept certificates and check their validity manually or to simply accept them. No satisfactory solution has been found for the underlying problem.
Certificates.
In the (more recent) OpenPGP specification, "trust signatures" can be used to support creation of certificate authorities. A trust signature indicates both that the key belongs to its claimed owner and that the owner of the key is trustworthy to sign other keys at one level below their own. A level 0 signature is comparable to a web of trust signature since only the validity of the key is certified. A level 1 signature is similar to the trust one has in a certificate authority because a key signed to level 1 is able to issue an unlimited number of level 0 signatures. A level 2 signature is highly analogous to the trust assumption users must rely on whenever they use the default certificate authority list (like those included in web browsers); it allows the owner of the key to make other keys certificate authorities.
PGP versions have always included a way to cancel ('revoke') identity certificates. A lost or compromised private key will require this if communication security is to be retained by that user. This is, more or less, equivalent to the certificate revocation lists of centralised PKI schemes. Recent PGP versions have also supported certificate expiration dates.
The problem of correctly identifying a public key as belonging to a particular user is not unique to PGP. All public key/private key cryptosystems have the same problem, even if in slightly different guises, and no fully satisfactory solution is known. PGP's original scheme at least leaves the decision as to whether or not to use its endorsement/vetting system to the user, while most other PKI schemes do not, requiring instead that every certificate attested to by a central certificate authority be accepted as correct.
Security quality.
To the best of publicly available information, there is no known method which will allow a person or group to break PGP encryption by cryptographic or computational means. Indeed, in 1995, cryptographer Bruce Schneier characterized an early version as being "the closest you're likely to get to military-grade encryption." Early versions of PGP have been found to have theoretical vulnerabilities and so current versions are recommended. In addition to protecting data in transit over a network, PGP encryption can also be used to protect data in long-term data storage such as disk files. These long-term storage options are also known as data at rest, i.e. data stored, not in transit.
The cryptographic security of PGP encryption depends on the assumption that the algorithms used are unbreakable by direct cryptanalysis with current equipment and techniques.
In the original version, the RSA algorithm was used to encrypt session keys. RSA's security depends upon the one-way function nature of mathematical integer factoring. Similarly, the symmetric key algorithm used in PGP version 2 was IDEA, which might at some point in the future be found to have previously undetected cryptanalytic flaws. Specific instances of current PGP or IDEA insecurities (if they exist) are not publicly known. As current versions of PGP have added additional encryption algorithms, the degree of their cryptographic vulnerability varies with the algorithm used. In practice, each of the algorithms in current use are not publicly known to have cryptanalytic weaknesses.
New versions of PGP are released periodically and vulnerabilities are fixed by developers as they come to light. Any agency wanting to read PGP messages would probably use easier means than standard cryptanalysis, e.g. rubber-hose cryptanalysis or black-bag cryptanalysis i.e. installing some form of trojan horse or keystroke logging software/hardware on the target computer to capture encrypted keyrings and their passwords. The FBI has already used this attack against PGP in its investigations. However, any such vulnerabilities apply not just to PGP but to any conventional encryption software.
In 2003, an incident involving seized Psion PDAs belonging to members of the Red Brigade indicated that neither the Italian police nor the FBI were able to decrypt PGP-encrypted files stored on them.
A more recent incident in December 2006, (see "In re Boucher"), involving US customs agents who seized a laptop PC that allegedly contained child pornography, indicates that US government agencies find it "nearly impossible" to access PGP-encrypted files. Additionally, a magistrate judge ruling on the case in November 2007 has stated that forcing the suspect to reveal his PGP passphrase would violate his Fifth Amendment rights i.e. a suspect's constitutional right not to incriminate himself. The Fifth Amendment issue was opened again as the government appealed the case and a federal district judge ordered the defendant to provide the key.
Evidence suggests that as of 2007, British police investigators are unable to break PGP, so instead have resorted to using RIPA legislation to demand the passwords/keys. In November 2009 a British citizen was convicted under RIPA legislation and jailed for nine months for refusing to provide police investigators with encryption keys to PGP-encrypted files.
History.
Early history.
Phil Zimmermann created the first version of PGP encryption in 1991. The name, "Pretty Good Privacy" was inspired by the name of a grocery store, "Ralph's Pretty Good Grocery", featured in radio host Garrison Keillor's fictional town, Lake Wobegon. This first version included a symmetric-key algorithm that Zimmermann had designed himself, named BassOmatic after a "Saturday Night Live" sketch. Zimmermann had been a long-time anti-nuclear activist, and created PGP encryption so that similarly inclined people might securely use BBSs and securely store messages and files. No license was required for its non-commercial use. There was not even a nominal charge, and the complete source code was included with all copies.
In a posting of June 5, 2001, entitled "PGP Marks 10th Anniversary", Zimmermann describes the circumstances surrounding his release of PGP:
PGP found its way onto the Internet, and it very rapidly acquired a considerable following around the world. Users and supporters included dissidents in totalitarian countries (some affecting letters to Zimmermann have been published, some of which have been included in testimony before the US Congress), civil libertarians in other parts of the world (see Zimmermann's published testimony in various hearings), and the 'free communications' activists who called themselves cypherpunks (who provided both publicity and distribution) and decades later, CryptoParty, who did much the same via Twitter.
Criminal investigation.
Shortly after its release, PGP encryption found its way outside the United States, and in February 1993 Zimmermann became the formal target of a criminal investigation by the US Government for "munitions export without a license". Cryptosystems using keys larger than 40 bits were then considered munitions within the definition of the US export regulations; PGP has never used keys smaller than 128 bits, so it qualified at that time. Penalties for violation, if found guilty, were substantial. After several years, the investigation of Zimmermann was closed without filing criminal charges against him or anyone else.
Zimmermann challenged these regulations in an imaginative way. He published the entire source code of PGP in a hardback book, via MIT Press, which was distributed and sold widely. Anybody wishing to build their own copy of PGP could cut off the covers, separate the pages, and scan them using an OCR program (or conceivably enter it as a type-in program if OCR software was not available), creating a set of source code text files. One could then build the application using the freely available GNU Compiler Collection. PGP would thus be available anywhere in the world. The claimed principle was simple: export of "munitions"—guns, bombs, planes, and software—was (and remains) restricted; but the export of "books" is protected by the First Amendment. The question was never tested in court with respect to PGP. In cases addressing other encryption software, however, two federal appeals courts have established the rule that cryptographic software source code is speech protected by the First Amendment (the Ninth Circuit Court of Appeals in the Bernstein case and the Sixth Circuit Court of Appeals in the Junger case).
US export regulations regarding cryptography remain in force, but were liberalized substantially throughout the late 1990s. Since 2000, compliance with the regulations is also much easier. PGP encryption no longer meets the definition of a non-exportable weapon, and can be exported internationally except to seven specific countries and a list of named groups and individuals (with whom substantially all US trade is prohibited under various US export controls).
PGP 3 and founding of PGP Inc..
During this turmoil, Zimmermann's team worked on a new version of PGP encryption called PGP 3. This new version was to have considerable security improvements, including a new certificate structure which fixed small security flaws in the PGP 2.x certificates as well as permitting a certificate to include separate keys for signing and encryption. Furthermore, the experience with patent and export problems led them to eschew patents entirely. PGP 3 introduced use of the CAST-128 (a.k.a. CAST5) symmetric key algorithm, and the DSA and ElGamal asymmetric key algorithms, all of which were unencumbered by patents.
After the Federal criminal investigation ended in 1996, Zimmermann and his team started a company to produce new versions of PGP encryption. They merged with Viacrypt (to whom Zimmermann had sold commercial rights and who had licensed RSA directly from RSADSI), which then changed its name to PGP Incorporated. The newly combined Viacrypt/PGP team started work on new versions of PGP encryption based on the PGP 3 system. Unlike PGP 2, which was an exclusively command line program, PGP 3 was designed from the start as a software library allowing users to work from a command line or inside a GUI environment. The original agreement between Viacrypt and the Zimmermann team had been that Viacrypt would have even-numbered versions and Zimmermann odd-numbered versions. Viacrypt, thus, created a new version (based on PGP 2) that they called PGP 4. To remove confusion about how it could be that PGP 3 was the successor to PGP 4, PGP 3 was renamed and released as PGP 5 in May 1997.
Network Associates acquisition.
In December 1997, PGP Inc. was acquired by Network Associates, Inc. ("NAI"). Zimmermann and the PGP team became NAI employees. NAI was the first company to have a legal export strategy by publishing source code. Under NAI, the PGP team added disk encryption, desktop firewalls, intrusion detection, and IPsec VPNs to the PGP family. After the export regulation liberalizations of 2000 which no longer required publishing of source, NAI stopped releasing source code.
In early 2001, Zimmermann left NAI. He served as Chief Cryptographer for Hush Communications, who provide an OpenPGP-based e-mail service, Hushmail. He has also worked with Veridis and other companies. In October 2001, NAI announced that its PGP assets were for sale and that it was suspending further development of PGP encryption. The only remaining asset kept was the PGP E-Business Server (the original PGP Commandline version). In February 2002, NAI canceled all support for PGP products, with the exception of the renamed commandline product. NAI (now McAfee) continued to sell and support the product under the name McAfee E-Business Server until 2013.
Current situation.
In August 2002, several ex-PGP team members formed a new company, PGP Corporation, and bought the PGP assets (except for the command line version) from NAI. The new company was funded by Rob Theis of Doll Capital Management (DCM) and Terry Garnett of Venrock Associates. PGP Corporation supports existing PGP users and honors NAI's support contracts. Zimmermann now serves as a special advisor and consultant to PGP Corporation, as well as continuing to run his own consulting company. In 2003, PGP Corporation created a new server-based product called PGP Universal. In mid-2004, PGP Corporation shipped its own command line version called PGP Command Line, which integrates with the other PGP Encryption Platform applications. In 2005, PGP Corporation made its first acquisition—the German software company Glück & Kanja Technology AG, which is now PGP Deutschland AG. In 2010, PGP Corporation acquired Hamburg-based certificate authority TC TrustCenter and its parent company, ChosenSecurity, to form its PGP TrustCenter division.
Since the 2002 purchase of NAI's PGP assets, PGP Corporation has offered worldwide PGP technical support from its offices in Draper, Utah; Offenbach, Germany; and Tokyo, Japan.
On April 29, 2010, Symantec Corp. announced that it would acquire PGP for $300 million with the intent of integrating it into its Enterprise Security Group. This acquisition was finalized and announced to the public on June 7, 2010. The source code of PGP Desktop 10 is available for peer review.
Also in 2010, Intel Corporation acquired McAfee. In 2013, the McAfee E-Business Server was transferred to Software Diversified Services, which now sells, supports, and develops it under the name SDS E-Business Server.
PGP Corporation encryption applications.
While originally used primarily for encrypting the contents of e-mail messages and attachments from a desktop client, PGP products have been diversified since 2002 into a set of encryption applications which can be managed by an optional central policy server. PGP encryption applications include e-mail and attachments, digital signatures, laptop full disk encryption, file and folder security, protection for IM sessions, batch file transfer encryption, and protection for files and folders stored on network servers and, more recently, encrypted and/or signed HTTP request/responses by means of a client side (Enigform) and a server side (mod openpgp) module. There is also a Wordpress plugin available, called wp-enigform-authentication, that takes advantage of the session management features of Enigform with mod_openpgp.
The PGP Desktop 9.x family includes PGP Desktop Email, PGP Whole Disk Encryption, and PGP NetShare. Additionally, a number of Desktop bundles are also available. Depending on application, the products feature desktop e-mail, digital signatures, IM security, whole disk encryption, file and folder security, encrypted self-extracting archives, and secure shredding of deleted files. Capabilities are licensed in different ways depending on features required.
The PGP Universal Server 2.x management console handles centralized deployment, security policy, policy enforcement, key management, and reporting. It is used for automated e-mail encryption in the gateway and manages PGP Desktop 9.x clients. In addition to its local keyserver, PGP Universal Server works with the PGP public keyserver—called the PGP Global Directory—to find recipient keys. It has the capability of delivering e-mail securely when no recipient key is found via a secure HTTPS browser session.
With PGP Desktop 9.x managed by PGP Universal Server 2.x, first released in 2005, all PGP encryption applications are based on a new proxy-based architecture. These newer versions of PGP software eliminate the use of e-mail plug-ins and insulate the user from changes to other desktop applications. All desktop and server operations are now based on security policies and operate in an automated fashion. The PGP Universal server automates the creation, management, and expiration of keys, sharing these keys among all PGP encryption applications.
The Symantec PGP platform has now undergone a rename. PGP Desktop is now known as Symantec Encryption Desktop, and the PGP Universal Server is now known as Symantec Encryption Management Server. The current shipping versions are Symantec Encryption Desktop 10.3.0 (Windows and Mac OS platforms) and Symantec Encryption Server 3.3.2.
Also available are PGP Command Line, which enables command line-based encryption and signing of information for storage, transfer, and backup, as well as the PGP Support Package for BlackBerry which enables RIM BlackBerry devices to enjoy sender-to-recipient messaging encryption.
New versions of PGP applications use both OpenPGP and the S/MIME, allowing communications with any user of a NIST specified standard.
OpenPGP.
Inside PGP Inc., there was still concern about patent issues. RSADSI was challenging the continuation of the Viacrypt RSA license to the newly merged firm. The company adopted an informal internal standard called "Unencumbered PGP": "use no algorithm with licensing difficulties". Because of PGP encryption's importance worldwide (it is thought to be the most widely chosen quality cryptographic system), many wanted to write their own software that would interoperate with PGP 5. Zimmermann became convinced that an open standard for PGP encryption was critical for them and for the cryptographic community as a whole. In July 1997, PGP Inc. proposed to the IETF that there be a standard called OpenPGP. They gave the IETF permission to use the name OpenPGP to describe this new standard as well as any program that supported the standard. The IETF accepted the proposal and started the OpenPGP Working Group.
OpenPGP is on the Internet Standards Track and is under active development. Many e-mail clients provide OpenPGP-compliant email security as described in RFC 3156. The current specification is RFC 4880 (November 2007), the successor to RFC 2440. RFC 4880 specifies a suite of required algorithms consisting of ElGamal encryption, DSA, Triple DES and SHA-1. In addition to these algorithms, the standard recommends RSA as described in PKCS #1 v1.5 for encryption and signing, as well as AES-128, CAST-128 and IDEA. Beyond these, many other algorithms are supported. The standard was extended to support Camellia cipher by RFC 5581 in 2009, and encryption based on elliptic curve cryptography (ECDSA, ECDH) by RFC 6637 in 2012. Support of EdDSA will be added by draft-koch-eddsa-for-openpgp-00 proposed in 2014.
The Free Software Foundation has developed its own OpenPGP-compliant program called GNU Privacy Guard (abbreviated GnuPG or GPG). GnuPG is freely available together with all source code under the GNU General Public License (GPL) and is maintained separately from several Graphical User Interfaces (GUIs) that interact with the GnuPG library for encryption, decryption and signing functions (see KGPG, Seahorse, MacGPG). Several other vendors have also developed OpenPGP-compliant software.
There are several iOS and Android OpenPGP-compliant applications such as iPGMail for iOS; and OpenKeychain for Android which enable key generation and encryption/decryption of email and files on Apple's iOS and Android.
OpenPGP's encryption can ensure secure delivery of files and messages, as well as provide verification of who created or sent the message using a process called digital signing. Using OpenPGP for communication requires participation by both the sender and recipient. OpenPGP can also be used to secure sensitive files when they're stored in vulnerable places like mobile devices or in the cloud.

</doc>
<doc id="23083" url="https://en.wikipedia.org/wiki?curid=23083" title="Playing card">
Playing card

A playing card is a piece of specially prepared heavy paper, thin cardboard, plastic-coated paper, cotton-paper blend, or thin plastic, marked with distinguishing motifs and used as one of a set for playing card games. Playing cards are typically palm-sized for convenient handling.
A complete set of cards is called a pack (UK English), deck (US English), or set (Universal), and the subset of cards held at one time by a player during a game is commonly called a hand. A pack of cards may be used for playing a variety of card games, with varying elements of skill and chance, some of which are played for money (e.g., poker and blackjack games at a casino). Playing cards are also used for illusions, cardistry, building card structures, cartomancy and memory sport.
The front (or "face") of each card carries markings that distinguish it from the other cards in the pack and determine its use under the rules of the game being played. The back of each card is identical for all cards in any particular pack to create an imperfect information scenario. Usually every card will be smooth; however, some packs have braille to allow blind people to read the card number and suit.
Dedicated deck card games have sets that are used only for a specific game. The cards described in this article are used for many games and share a common origin stemming from the standards set in Mamluk Egypt. These sets divide their cards into four suits each consisting of three face cards and numbered or "pip" cards.
History.
Early history.
The scholarly consensus is that playing cards were invented in Imperial China. They first appeared as early as 9th century Tang China (618–907). The first reference to card games also dates from the 9th century, when the "Collection of Miscellanea at Duyang", written by Tang dynasty writer Su E, described Princess Tongchang, daughter of Emperor Yizong of Tang, playing the "leaf game" in 868 with members of the Wei clan, the family of the princess' husband. The first known book on the "leaf" game was called the "Yezi Gexi" and was allegedly written by a Tang woman, and was commented on by Chinese writers of subsequent dynasties. The Song dynasty (960–1279) scholar Ouyang Xiu (1007–1072) asserted that the "leaf" game existed at least since the mid-Tang dynasty and associated their invention with the simultaneous development of using sheets or pages instead of paper rolls as a writing medium. However, Ouyang claimed the "leaves" were pages of a book for a board game played with dice. In any case, Ouyang asserted that the rules for the game were lost by 1067.
It may be that the first pack of cards ever printed was a 32-card Chinese domino pack, in whose cards all 21 combinations of a pair of dice are depicted. According to the "Gui Tian Lu" (歸田錄), an 11th-century Chinese text redacted, domino cards were printed during the Tang dynasty, contemporary to the first printed books. There is difficulty distinguishing paper cards and gaming tiles in many early sources as the Chinese word "pái" (牌) is used to describe both. Playing cards are paper "pái" while tiles are called bone "pái". Paper playing cards and the woodblocks to print them are unambiguously attested in 1294.
William Henry Wilkinson suggests that the first cards may have been actual paper currency which were both the tools of gaming and the stakes being played for, as in trading card games. As using paper money was inconvenient and risky, they were substituted by play money known as "money-suited cards". One of the earliest games in which we know the rules is Madiao, a trick-taking game, which dates to the Ming Dynasty (1368–1644). 15th century scholar Lu Rong described it is as being played with 38 "money-suited cards" divided into four suits: 9 in coins, 9 in strings of coins (which may have been misinterpreted as sticks from crude drawings), 9 in myriads (of coins or of strings), and 11 in tens of myriads (a myriad is 10,000). The two latter suits had "Water Margin" characters instead of pips on them with Chinese ideograms to mark their rank and suit. The pips were copied directly from Chinese banknotes such as the Song's Jiaozi or the Yuan's Chao currencies. The suit of coins is in reverse order with 9 of coins being the lowest going up to 1 of coins as the high card. Inverted ranking is also found in the Vietnamese game of Tổ tôm and other games below.
The money-suited system is based on denominations of currency and not on the pips or pictures. This is why there is no tenth rank as that would create a new suit. A simplified deck is still in use by Hakka players, where every suit has just nine cards in progressive ranking, replacing pips and pictures with labels. Another type of modern deck keeps the traditional images but drops the highest suit (tens of myriads) and quadruplicate the rest. The designs on modern Mahjong tiles likely evolved from this pack.
Persia and India.
It is not known when playing cards arrived in Persia. They may have been acquired through trade in the Silk Road or brought by the Mongol conquerors in the 13th century. Persian cards, known as Ganjifeh or Ganjafa, have eight suits. Mughal conquerors brought these cards to India in the early 16th century where they are called Ganjifa. In India, current packs used for play have eight, ten, or twelve suits though as many as 32 suits once existed. The Indians also converted the original rectangular cards to circular ones. In Iran, the cards were superseded by As-Nas decks during the 19th century.
Despite the wide variety of Ganjifa patterns, the suits show a uniformity of structure. Every suit contains twelve cards with the top two usually being the court cards of king and vizier and the bottom ten being pip cards. Half the suits use reverse ranking for their pip cards. There many different motifs for the suit pips but some include coins, clubs, jugs, and swords which resemble later Mamluk and Latin suits. Michael Dummett speculated that Ganjifa and Mamluk cards may have descended from an earlier deck which consisted of 48 cards divided into four suits each with ten pip cards and two court cards.
Egypt.
By the 11th century, playing cards were spreading throughout the Asian continent and later came into Egypt. The oldest surviving cards in the world are four fragments found in the Keir Collection and one in the Benaki Museum. They are dated to the 12th and 13th centuries (late Fatimid, Ayyubid, and early Mamluk periods).
A near complete pack of Mamluk playing cards dating to the 15th century and of similar appearance to the fragments above was discovered by Leo Aryeh Mayer in the Topkapı Palace, Istanbul, in 1939. It is not a complete set and is actually composed of three different packs, probably to replace missing cards. The Topkapı pack originally contained 52 cards comprising four suits: polo-sticks, coins, swords, and cups. Each suit contained ten pip cards and three court cards, called "malik" (king), "nā'ib malik" (viceroy or deputy king), and "thānī nā'ib" (second or under-deputy). The "thānī nā'ib" is a non-existent title so it may not have been in the earliest versions; without this rank, the Mamluk suits would structurally be the same as a Ganjifa suit. In fact, the word "Kanjifah" appears in Arabic on the king of swords and is still used in parts of the Middle East to describe modern playing cards. Influence from further east can explain why the Mamluks, most of whom were Central Asian Turkic Kipchaks, called their cups "tuman" which means myriad in Turkic, Mongolian and Jurchen languages. Wilkinson postulated that the cups may have been derived from inverting the Chinese and Jurchen ideogram for myriad ().
The Mamluk court cards showed abstract designs or calligraphy not depicting persons possibly due to religious proscription in Sunni Islam, though they did bear the names of military officers. "Nā'ib" would be corrupted into "naibi" (Italian) and "naipes" (Spanish), the latter still in common usage. Panels on the pip cards in two suits show they had a reverse ranking, a feature found in Madiao, Ganjifa, and old European card games like Ombre, Tarot, and Maw.
A fragment of two uncut sheets of Moorish-styled cards of a similar but plainer style were found in Spain and dated to the early 15th century.
Production of these cards did not outlive the fall of the Mamluks in the sixteenth century. The rules to play these games are lost but they are believed to be plain trick games without trumps.
Spread across Europe and early design changes.
Playing cards first entered Southern Europe in the 14th century, probably from Mamluk Egypt, using the Mamluk suits of cups, coins, swords, and polo-sticks, which are still used in traditional Latin decks. As polo was an obscure sport to Europeans then, the polo-sticks became batons or cudgels. Their presence is attested in Catalonia in 1371, 1377 in Switzerland, and 1380 in many locations including Florence and Paris. Wide use of playing cards in Europe can, with some certainty, be traced from 1377 onwards.
A 1369 Paris ordinance does not mention cards, but its 1377 update does. In the account books of Johanna, Duchess of Brabant and Wenceslaus I, Duke of Luxemburg, an entry dated May 14, 1379 reads: "Given to Monsieur and Madame four peters, two forms, value eight and a half moutons, wherewith to buy a pack of cards". In his book of accounts for 1392 or 1393, Charles or Charbot Poupart, treasurer of the household of Charles VI of France, records payment for the painting of three sets of cards.
The earliest cards were made by hand, like those designed for Charles VI; this was expensive. Printed woodcut decks appeared in the 15th century. The technique of printing woodcuts to decorate fabric was transferred to printing on paper around 1400 in Christian Europe, very shortly after the first recorded manufacture of paper there, while in Islamic Spain it was much older. The earliest dated European woodcut is 1418.
From about 1418 to 1450 professional card makers in Ulm, Nuremberg, and Augsburg created printed decks. Playing cards even competed with devotional images as the most common uses for woodcuts in this period. Most early woodcuts of all types were coloured after printing, either by hand or, from about 1450 onwards, stencils. These 15th-century playing cards were probably painted. The Flemish Hunting Deck, held by the Metropolitan Museum of Art is the oldest complete set of ordinary playing cards made in Europe from the fifteenth century. Hunting themed decks like the Stuttgart playing cards and the Ambraser Hofjagdspiel were produced in the Rhine basin during the 15th and 16th centuries. Producers of hunting decks include the Master of the Playing Cards who worked in Germany from the 1430s with the newly invented printmaking technique of engraving. Several other important engravers also made cards, including Master ES and Martin Schongauer. Engraving was much more expensive than woodcut, and engraved cards must have been relatively unusual.
Karnöffel is the oldest card game with which the rules are recorded. It has a complicated "elected suit" that sometimes beat the other suits in certain circumstances. This may have preceded or inspired the creation of the tarot deck. The origins of the tarot pack are thought to be Italian, with the oldest surviving examples dating from the mid-15th century in Milan. It is generally thought that the tarot was invented between 1411 and 1425 by adding a fifth suit of cards known as "trionfi" (triumphs) to the Italian deck. These "trionfi" can beat any of the other four suits and is the origin of the word "trump". The tarot deck was never as popular as the standard decks, as it was more expensive, so lower classes preferred smaller decks. In many countries or regions, the regular 52 or 56 card deck shrank to 48, 40, 36, 32, or 24 cards. Instead of having a permanent trump suit like tarot, many trick-taking games starting with Triomphe simply use one or more of the four suits as trumps.
As cards spread from Italy to Germanic countries, the Latin suits were replaced with the suits of Leaves (or Shields), Hearts (or Roses), Bells, and Acorns, and a combination of Latin and Germanic suit pictures and names resulted in the French suits of "trèfles" (clovers), "carreaux" (tiles), "cœurs" (hearts), and "piques" (pikes) around 1480. The "trèfle" (clover) was probably derived from the acorn and the "pique" (pike) from the leaf of the German suits. The names "pique" and "spade", however, may have derived from the sword ("spade") of the Italian suits. In England, the French suits were eventually used, although the earliest packs circulating may have had Latin suits. This may account to why the English called the clovers "clubs" and the pikes "spades".
In the late 14th century, Europeans changed the Mamluk court cards to represent European royalty and attendants. In a description from 1377, the earliest courts were originally a seated "King", an upper marshal that held his suit symbol up, and a lower marshal that held it down. The latter two correspond with the "Ober" and "Unter" cards found in German and Swiss playing cards. The Italians and Iberians replaced the "Ober"/"Unter" system with the "Knight" and ""Fante"" or ""Sota"" before 1390, perhaps to make the cards more visually distinguishable. In England, the lowest court card was called the "Knave" which originally meant "male child" (cf German "Knabe"), so in this context the character could represent the "prince", son to the King and Queen; the meaning "servant" developed later. Queens appeared sporadically in packs as early as 1377, especially in Germany. Although the Germans abandoned the Queen before the 1500s, the French permanently picked it up and placed it under the King. Packs of 56 cards containing in each suit a King, Queen, Knight, and Knave (as in tarot) were once common in the 15th century.
Court cards designed in the 16th century in the manufacturing centre of Rouen became the standard pattern in England, while the Parisian pattern became standard in France. Both the Parisian and Rouennais court cards were named after historical and mythological heroes and heroines. The Parisian names are still printed on cards in France while the Rouennais names were never used in England.
During the mid 16th century, Portuguese traders introduced playing cards to Japan. The first indigenous Japanese deck was the Tenshō karuta named after the Tenshō period. It was a 48 card deck with the 10s missing like Iberian decks from that period. The Tokugawa shogunate banned these cards in the early 17th century forcing Japanese manufacturers to radically redesign their cards. As a result of Japan's isolationist Sakoku policy, karuta would develop separately from the rest of the world. Modern decks like hanafuda bear no resemblance to their Portuguese ancestor.
Later design changes.
In early games the kings were "always" the highest card in their suit. However, as early as the late 15th century special significance began to be placed on the nominally lowest card, now called the Ace, so that it sometimes became the highest card and the Two, or Deuce, the lowest. The term "Ace" itself comes from a dicing term in Anglo-Norman language, which is itself derived from the Latin "as" (the smallest unit of coinage). Another dicing term, "trey" (3), sometimes shows up in playing card games. Many governments used to raise revenue by imposing a stamp duty on playing cards. As the Ace card has the most blank space, it was usually chosen as the place to bear the stamp which proved the tax was paid. This led to elaborate designs of certain ace cards: the ace of spades in England, the ace of clubs in France, and the ace of diamonds in Russia.
Packs with corner and edge indices (i.e. the value of the card printed at the corner(s) of the card) enabled players to hold their cards close together in a fan with one hand (instead of the two hands previously used). The first such pack known with Latin suits was printed by Infirerra and dated 1693, but this feature was commonly used only from the end of the 18th century. The first Anglo-American deck with this innovation was the Saladee's Patent, printed by Samuel Hart in 1864. In 1870, he and his cousins at Lawrence & Cohen followed up with the Squeezers, the first cards with indices that had a large diffusion.
Before this time, the lowest court card in an English pack was officially termed the "Knave", but its abbreviation ("Kn") was too similar to the King ("K") and thus this term did not adapt well to indices. However, from the 17th century the Knave had often been termed the "Jack", a term borrowed from the English Renaissance card game All Fours where the Knave of trumps has this name. All Fours was considered a game of the lower classes, so the use of the term Jack at one time was considered vulgar. The use of indices, however, encouraged a formal change from Knave to Jack in English language packs. Other languages faced similar problems when adding corner indices. In Latin languages both the King and Queen begin with the letter "R" while in Germanic and Slavic languages they begin with the letter "K". Like the equivalent chess piece, the Queen was called "Dame", "Dama" or other variations which mean "lady". Scandinavian cards have kept the "Kn" for knaves.
This was followed by the innovation of reversible court cards. This invention is attributed to a French card maker of Agen in 1745. But the French government, which controlled the design of playing cards, prohibited the printing of cards with this innovation. In central Europe (Trappola cards) and Italy (Tarocco Bolognese) the innovation was adopted during the second half of the 18th century. In Great Britain the pack with reversible court cards was patented in 1799 by Edmund Ludlow and Ann Wilcox. The Anglo-American pack with this design was printed around 1802 by Thomas Wheeler. Reversible court cards meant that players had no need to turn upside-down court cards right side up. Before this, other players could often get a hint of what other players' hands contained by watching them reverse their cards. This innovation required abandoning some of the design elements of the earlier full-length courts.
Sharp corners wear out more quickly, and could possibly reveal the card's value, so they were replaced with rounded corners. Before the mid-19th century, British, American, and French players preferred blank backs. The need to hide wear and tear and to discourage writing on the back led cards to have designs, pictures, photos, or advertising on the reverse.
During the nineteenth century, the evolution of Tarot packs for cartomancy and for gaming diverged after Etteilla created the first tarot deck dedicated to divination in 1791. The "reading tarots" based on the symbolic designs of the Tarot de Marseille (which were extensively modified to produce the widely known Rider-Waite deck) kept the older style of full-length character art, specific character meanings for the 21 trumps, and the use of the Latin suits (although most of the reading tarots in use today derive from the French Tarot de Marseille). On the other hand, "playing tarots", especially those of France and the Germanic regions, had by the end of the 19th century evolved into a form more resembling the modern playing card pack, with corner indices and easily identifiable number and court cards. The use of the traditional characters for the trumps was largely discarded in favor of more whimsical scenes. The Tarot Nouveau and Industrie und Glück are the most common examples of the current patterns of playing tarot. The Italian Tarocchi packs, however, have largely kept the traditional character identifications of each trump, as well as the Latin suits, though these packs are used almost exclusively for gaming. Tarocco Bolognese and Tarocco Piemontese are examples of Italian-suited playing tarot packs while the Tarocco Siciliano is the only one that uses Spanish pips.
The United States introduced the Joker into the deck. It was devised for the game of Euchre, which spread from Europe to America beginning shortly after the American Revolutionary War. In Euchre, the highest trump card is the Jack of the trump suit, called the "right bower" (from the German "Bauer"); the second-highest trump, the "left bower", is the Jack of the suit of the same color as trumps. The joker was invented c. 1860 as a third trump, the "imperial" or "best bower", which ranked higher than the other two "bowers". The name of the card is believed to derive from "juker", a variant name for Euchre. The earliest reference to a Joker functioning as a wild card dates to 1875 with a variation of poker.
Modern manufacturing.
Most playing cards sold today are either made of card stock or plastic. Commercial grade polyvinyl chloride (PVC) was not available until the late 1920s and the first all PVC cards appeared in 1935. Contemporary plastic cards are increasingly made of polyvinyl chloride acetate (PVCA) or cellulose acetate. Plastic cards last longer and are more durable than paper cards but are more expensive. After World War II, paper cards were given a plastic coating to extend their lifetime.
Cards are printed on unique sheets that undergo a varnishing procedure in order to enhance the brightness and glow of the colours printed on the cards, as well as to increase their durability. Most printing today is done by offset printing or digital printing.
In today’s market, some high-quality products are available. There are some specific treatments on card surfaces, such as calender and linen finishing, that improve shuffling for either professional or domestic use.
The cards are printed on sheets, which are cut and arranged in bands (vertical stripes) before undergoing a cutting operation that cuts out the individual cards. After assembling the new decks, they pass through the corner-rounding process that will confer the final outline: the typical rectangular playing-card shape.
For most decks, the cards are assembled mechanically in an unvarying sequence, so their order must be randomized when play begins. Exceptions are decks destined for casinos which use pre-shuffled cards. Finally, each pack is wrapped in cellophane and inserted in its case, which may also be wrapped and sealed.
Modern deck formats.
Contemporary playing cards are grouped into three broad categories based on the suits they use: French, Latin, and German. Latin suits are used in the closely related Spanish and Italian formats. The Swiss German suits are distinct enough to merit their subcategory. Excluding Jokers and Tarot trumps, the French 52-card deck preserves the number of cards in the original Mamluk deck, while Latin and German decks average fewer. Latin decks usually drop the higher-valued pip cards, while German decks drop the lower-valued ones.
Within suits, there are regional or national variations called "standard patterns" because they are in the public domain, allowing multiple card manufacturers to copy them. Pattern differences are most easily found in the face cards but the number of cards per deck, the use of numeric indices, or even minor shape and arrangement differences of the pips can be used to distinguish them. Some patterns have been around for hundreds of years. Jokers are not part of any pattern as they are a relatively recent invention and lack any standardized appearance so each publisher usually puts their own trademarked illustration into their decks. The wide variation of jokers has turned them into collectible items. Any card that bore the stamp duty like the ace of spades in England or the ace of clubs in France are also collectible as that is where the manufacturer's logo is usually placed.
French suits.
French decks come in a variety of patterns and deck sizes. The 52-card deck is the most popular deck and includes 13 ranks of each suit with reversible "court" or face cards. Each suit includes an Ace, depicting a single symbol of its suit, a King, Queen, and Jack, each depicted with a symbol of their suit; and ranks two through ten, with each card depicting that number of pips of its suit. As well as these 52 cards, commercial packs often include between one and four jokers, most often two.
The piquet pack has all values from 2 through 6 in each suit removed for a total of 32 cards. It is popular in France, the Low Countries, Central Europe and Russia and is used to play Piquet, Belote, Bezique and Skat. 40 card French suited packs are common in northwest Italy; these remove the 8s through 10s like Latin suited decks. 24 card decks, removing 2s through 8s are also sold in Austria and Bavaria to play Schnapsen.
The 78 card Tarot Nouveau adds the Knight card between Queens and Jacks along with 21 numbered trumps and the unnumbered Fool.
German suits.
In the German pack, there are four colors, namely Acorns ("Eichel"), Leaves ("Grün" or "Blatt"), Hearts ("Herz") and Bells ("Schelle"). In northern decks, the card ranks are Deuce ("Daus" or "Ass"), King ("König"), Over Knave ("Ober"), Under Knave ("Unter"), 10, 9, 8, and 7. Southern decks include the 6 for a total of 36 cards. 24 card "Short" Schafkopf and Schnapsen decks have no 6s, 7s, or 8s. 40-card decks with the 5s can be found in South Tyrol, Italy.
Swiss German suits.
Eastern parts of German-speaking Switzerland (east of the Brünig-Napf-Reuss line) use a variation of the German deck. It uses Roses ("Rosen") instead of Hearts and Shields ("Schilten") in place of Leaves. Also unlike the German deck, the 10 has been replaced by a "Banner" card which depicts a flag defaced by its suit symbol. Thus the only true pip cards are 6, 7, 8, and 9. The German "Unter" card is spelled "Under" to reflect the local Swiss dialect. They come in 36-card packs and are used to play the national game of Jass.
A less common deck of 48 cards containing the 3s, 4s, and 5s is used to play Kaiserspiel, a variant of Karnöffel.
Latin suits.
Latin decks consist of four suits: Swords, Clubs, Cups, and Coins. Spanish style clubs are knobbly cudgels while Italian style clubs are smooth batons. Italian style swords are curved while Spanish style swords are straight. The Portuguese pattern used Spanish pips but intersected their clubs and swords like in Italian suits. The only decks that use the Portuguese pattern in the present is the Sicilian Tarot and some Karuta packs.
Most Italian and Spanish decks consist of 40 cards with each suit numbering 1 (or Ace) to 7 with three face cards of King, Knight, and Knave/Jack.
Italian suits.
Despite the name, Italian suits normally refer to only suits found in northeastern Italy (essentially around the former Republic of Venice) while the rest of the country uses Spanish (Sardinia and the south), French (northwest), or German (South Tyrol) suits. They are most commonly found in packs of 40 cards but 52 card sets are also available. The Tarocco Piemontese and Tarocco Bolognese have 78 and 62 cards respectively. Unlike the French deck, some Italian cards do not have any numbers (or letters) identifying their value. The cards' value is determined by identifying the face card or counting the number of suit characters.
Spanish suits.
The cards ("cartas" or "naipes" in Spanish) are all numbered, but unlike in the standard French pack, the card numbered 10 is the first of the court cards (instead of a card depicting ten pips); so each suit has only twelve cards. Most Spanish games involve forty-card packs, with the 8s and 9s removed, similar to the standard Italian pack. Many Spanish decks have reintroduced cards representing 8 and 9 for a total of 48 cards though 40 card decks are still common. Certain packs include two "comodines" (jokers) as well. The box ("la pinta") that goes around the edges of the card is used to distinguish the suit without showing all of your cards: The cups have one interruption, the swords two, the clubs three, and the coins none.
Accessible playing cards.
Playing cards have been adapted for use by the visually impaired by the inclusion of large-print and/or braille characters as part of the card. In addition to increasing the size of the suit symbol and the denomination text, large-print cards commonly reduce the visual complexity of the images for simpler identification. They may also omit the patterns of pips in favor of one large pip to identify suit. Some decks have larger indices, often for use in stud poker games, where being able to read cards from a distance is a benefit and hand sizes are small.
Oversize cards are also produced. These can assist with ease of handling and to allow for larger text. Some decks use four colors for the suits in order to make it easier to tell them apart: The most common set of four colors for poker is black spades, red hearts, blue diamonds and green clubs (♠♥♦♣). Another common color set is borrowed from the German suits and uses green spades (leaves) and yellow diamonds (bells) with red hearts and black clubs (♣♠♥♦).
No universal standards for braille playing cards exist. There are many national and producer variations. In most cases each card is marked with two braille characters in the same location as the normal corner markings. The two characters can appear in either vertical (one character below another) or horizontal (two characters side by side). In either case one character identifies the card "suit" and the other the card "denomination". 1 for "ace", 2 through 9 for the numbered cards, X (from Roman numerals) or the letter O for ten, J for "jack", Q for "queen", K for "king". The suits are variously marked using D for "diamond", S for "spade", C or X for "club" and H or K for "heart".
Symbols in Unicode.
The Unicode standard for text encoding on computers defines 8 characters for card suits in the Miscellaneous Symbols block, at U+2660–2667. Unicode 7.0 added a unified pack for French-suited Tarot Nouveau's trump cards and the 52 cards of the modern French pack, with 4 Knights, together with a character for "Playing Card Back" and black, red, and white jokers in the block U+1F0A0–1F0FF.
See also.
Geographic origin:
Types of decks:
Specific decks:
Uses:
Terminology:
Sources for further information:

</doc>
<doc id="23084" url="https://en.wikipedia.org/wiki?curid=23084" title="Paleontology">
Paleontology

Paleontology or palaeontology (, or , ) is the scientific study of life existent prior to, and sometimes including, the start of the Holocene Epoch roughly 11,700 years before present. It includes the study of fossils to determine organisms' evolution and interactions with each other and their environments (their paleoecology). Paleontological observations have been documented as far back as the 5th century BC. The science became established in the 18th century as a result of Georges Cuvier's work on comparative anatomy, and developed rapidly in the 19th century. The term itself originates from Greek παλαιός, "palaios", i.e. "old, ancient", ὄν, "on" (gen. "ontos"), i.e. "being, creature" and λόγος, "logos", i.e. "speech, thought, study".
Paleontology lies on the border between biology and geology, but differs from archaeology in that it excludes the study of anatomically modern humans. It now uses techniques drawn from a wide range of sciences, including biochemistry, mathematics and engineering. Use of all these techniques has enabled paleontologists to discover much of the evolutionary history of life, almost all the way back to when Earth became capable of supporting life, about . As knowledge has increased, paleontology has developed specialised sub-divisions, some of which focus on different types of fossil organisms while others study ecology and environmental history, such as ancient climates.
Body fossils and trace fossils are the principal types of evidence about ancient life, and geochemical evidence has helped to decipher the evolution of life before there were organisms large enough to leave body fossils. Estimating the dates of these remains is essential but difficult: sometimes adjacent rock layers allow radiometric dating, which provides absolute dates that are accurate to within 0.5%, but more often paleontologists have to rely on relative dating by solving the "jigsaw puzzles" of biostratigraphy. Classifying ancient organisms is also difficult, as many do not fit well into the Linnean taxonomy that is commonly used for classifying living organisms, and paleontologists more often use cladistics to draw up evolutionary "family trees". The final quarter of the 20th century saw the development of molecular phylogenetics, which investigates how closely organisms are related by measuring how similar the DNA is in their genomes. Molecular phylogenetics has also been used to estimate the dates when species diverged, but there is controversy about the reliability of the molecular clock on which such estimates depend.
Overview.
The simplest definition is "the study of ancient life". Paleontology seeks information about several aspects of past organisms: "their identity and origin, their environment and evolution, and what they can tell us about the Earth's organic and inorganic past".
A historical science.
Paleontology is one of the historical sciences, along with archaeology, geology, astronomy, cosmology, philology and history itself. This means that it aims to describe phenomena of the past and reconstruct their causes. Hence it has three main elements: description of the phenomena; developing a general theory about the causes of various types of change; and applying those theories to specific facts.
When trying to explain past phenomena, paleontologists and other historical scientists often construct a set of hypotheses about the causes and then look for a "smoking gun", a piece of evidence that indicates that one hypothesis is a better explanation than others. Sometimes the smoking gun is discovered by a fortunate accident during other research. For example, the discovery by Luis Alvarez and Walter Alvarez of an iridium-rich layer at the Cretaceous–Tertiary boundary made asteroid impact and volcanism the most favored explanations for the Cretaceous–Paleogene extinction event.
The other main type of science is experimental science, which is often said to work by conducting experiments to "disprove" hypotheses about the workings and causes of natural phenomena – note that this approach cannot confirm a hypothesis is correct, since some later experiment may disprove it. However, when confronted with totally unexpected phenomena, such as the first evidence for invisible radiation, experimental scientists often use the same approach as historical scientists: construct a set of hypotheses about the causes and then look for a "smoking gun".
Related sciences.
Paleontology lies on the boundary between biology and geology since paleontology focuses on the record of past life but its main source of evidence is fossils, which are found in rocks. For historical reasons paleontology is part of the geology departments of many universities, because in the 19th century and early 20th century geology departments found paleontological evidence important for estimating the ages of rocks while biology departments showed little interest.
Paleontology also has some overlap with archaeology, which primarily works with objects made by humans and with human remains, while paleontologists are interested in the characteristics and evolution of humans as organisms. When dealing with evidence about humans, archaeologists and paleontologists may work together – for example paleontologists might identify animal or plant fossils around an archaeological site, to discover what the people who lived there ate; or they might analyze the climate at the time when the site was inhabited by humans.
In addition paleontology often uses techniques derived from other sciences, including biology, osteology, ecology, chemistry, physics and mathematics. For example, geochemical signatures from rocks may help to discover when life first arose on Earth, and analyses of carbon isotope ratios may help to identify climate changes and even to explain major transitions such as the Permian–Triassic extinction event. A relatively recent discipline, molecular phylogenetics, often helps by using comparisons of different modern organisms' DNA and RNA to re-construct evolutionary "family trees"; it has also been used to estimate the dates of important evolutionary developments, although this approach is controversial because of doubts about the reliability of the "molecular clock". Techniques developed in engineering have been used to analyse how ancient organisms might have worked, for example how fast "Tyrannosaurus" could move and how powerful its bite was. It is relatively commonplace to study fossils using X-ray microtomography A combination of paleontology, biology, and archaeology, paleoneurology is the study of endocranial casts (or endocasts) of species related to humans to learn about the evolution of human brains.
Paleontology even contributes to astrobiology, the investigation of possible life on other planets, by developing models of how life may have arisen and by providing techniques for detecting evidence of life.
Subdivisions.
As knowledge has increased, paleontology has developed specialised subdivisions. Vertebrate paleontology concentrates on fossils of vertebrates, from the earliest fish to the immediate ancestors of modern mammals. Invertebrate paleontology deals with fossils of invertebrates such as molluscs, arthropods, annelid worms and echinoderms. Paleobotany focuses on the study of fossil plants, but traditionally includes the study of fossil algae and fungi. Palynology, the study of pollen and spores produced by land plants and protists, straddles the border between paleontology and botany, as it deals with both living and fossil organisms. Micropaleontology deals with all microscopic fossil organisms, regardless of the group to which they belong.
Instead of focusing on individual organisms, paleoecology examines the interactions between different organisms, such as their places in food chains, and the two-way interaction between organisms and their environment.  One example is the development of oxygenic photosynthesis by bacteria, which hugely increased the productivity and diversity of ecosystems. This also caused the oxygenation of the atmosphere. Together, these were a prerequisite for the evolution of the most complex eukaryotic cells, from which all multicellular organisms are built.
Paleoclimatology, although sometimes treated as part of paleoecology, focuses more on the history of Earth's climate and the mechanisms that have changed it – which have sometimes included evolutionary developments, for example the rapid expansion of land plants in the Devonian period removed more carbon dioxide from the atmosphere, reducing the greenhouse effect and thus helping to cause an ice age in the Carboniferous period.
Biostratigraphy, the use of fossils to work out the chronological order in which rocks were formed, is useful to both paleontologists and geologists. Biogeography studies the spatial distribution of organisms, and is also linked to geology, which explains how Earth's geography has changed over time.
Sources of evidence.
Body fossils.
Fossils of organisms' bodies are usually the most informative type of evidence. The most common types are wood, bones, and shells. Fossilisation is a rare event, and most fossils are destroyed by erosion or metamorphism before they can be observed. Hence the fossil record is very incomplete, increasingly so further back in time. Despite this, it is often adequate to illustrate the broader patterns of life's history. There are also biases in the fossil record: different environments are more favorable to the preservation of different types of organism or parts of organisms. Further, only the parts of organisms that were already mineralised are usually preserved, such as the shells of molluscs. Since most animal species are soft-bodied, they decay before they can become fossilised. As a result, although there are 30-plus phyla of living animals, two-thirds have never been found as fossils.
Occasionally, unusual environments may preserve soft tissues. These lagerstätten allow paleontologists to examine the internal anatomy of animals that in other sediments are represented only by shells, spines, claws, etc. – if they are preserved at all. However, even lagerstätten present an incomplete picture of life at the time. The majority of organisms living at the time are probably not represented because lagerstätten are restricted to a narrow range of environments, e.g. where soft-bodied organisms can be preserved very quickly by events such as mudslides; and the exceptional events that cause quick burial make it difficult to study the normal environments of the animals. The sparseness of the fossil record means that organisms are expected to exist long before and after they are found in the fossil record – this is known as the Signor-Lipps effect.
Trace fossils.
Trace fossils consist mainly of tracks and burrows, but also include coprolites (fossil feces) and marks left by feeding. Trace fossils are particularly significant because they represent a data source that is not limited to animals with easily fossilised hard parts, and they reflect organisms' behaviours. Also many traces date from significantly earlier than the body fossils of animals that are thought to have been capable of making them. Whilst exact assignment of trace fossils to their makers is generally impossible, traces may for example provide the earliest physical evidence of the appearance of moderately complex animals (comparable to earthworms).
Geochemical observations.
Geochemical observations may help to deduce the global level of biological activity, or the affinity of certain fossils. For example, geochemical features of rocks may reveal when life first arose on Earth, and may provide evidence of the presence of eukaryotic cells, the type from which all multicellular organisms are built. Analyses of carbon isotope ratios may help to explain major transitions such as the Permian–Triassic extinction event.
Classifying ancient organisms.
Simple example cladogram Warm-bloodedness evolved somewhere in thesynapsid–mammal transition. Warm-bloodedness must also have evolved at one of these points – an example of convergent evolution.
Naming groups of organisms in a way that is clear and widely agreed is important, as some disputes in paleontology have been based just on misunderstandings over names. Linnean taxonomy is commonly used for classifying living organisms, but runs into difficulties when dealing with newly discovered organisms that are significantly different from known ones. For example: it is hard to decide at what level to place a new higher-level grouping, e.g. genus or family or order; this is important since the Linnean rules for naming groups are tied to their levels, and hence if a group is moved to a different level it must be renamed.
Paleontologists generally use approaches based on cladistics, a technique for working out the evolutionary "family tree" of a set of organisms. It works by the logic that, if groups B and C have more similarities to each other than either has to group A, then B and C are more closely related to each other than either is to A. Characters that are compared may be anatomical, such as the presence of a notochord, or molecular, by comparing sequences of DNA or proteins. The result of a successful analysis is a hierarchy of clades – groups that share a common ancestor. Ideally the "family tree" has only two branches leading from each node ("junction"), but sometimes there is too little information to achieve this and paleontologists have to make do with junctions that have several branches. The cladistic technique is sometimes fallible, as some features, such as wings or camera eyes, evolved more than once, convergently – this must be taken into account in analyses.
Evolutionary developmental biology, commonly abbreviated to "Evo Devo", also helps paleontologists to produce "family trees", and understand fossils. For example, the embryological development of some modern brachiopods suggests that brachiopods may be descendants of the halkieriids, which became extinct in the Cambrian period.
Estimating the dates of organisms.
Paleontology seeks to map out how living things have changed through time. A substantial hurdle to this aim is the difficulty of working out how old fossils are. Beds that preserve fossils typically lack the radioactive elements needed for radiometric dating. This technique is our only means of giving rocks greater than about 50 million years old an absolute age, and can be accurate to within 0.5% or better. Although radiometric dating requires very careful laboratory work, its basic principle is simple: the rates at which various radioactive elements decay are known, and so the ratio of the radioactive element to the element into which it decays shows how long ago the radioactive element was incorporated into the rock. Radioactive elements are common only in rocks with a volcanic origin, and so the only fossil-bearing rocks that can be dated radiometrically are a few volcanic ash layers.
Consequently, paleontologists must usually rely on stratigraphy to date fossils. Stratigraphy is the science of deciphering the "layer-cake" that is the sedimentary record, and has been compared to a jigsaw puzzle. Rocks normally form relatively horizontal layers, with each layer younger than the one underneath it. If a fossil is found between two layers whose ages are known, the fossil's age must lie between the two known ages. Because rock sequences are not continuous, but may be broken up by faults or periods of erosion, it is very difficult to match up rock beds that are not directly next to one another. However, fossils of species that survived for a relatively short time can be used to link up isolated rocks: this technique is called "biostratigraphy". For instance, the conodont "Eoplacognathus pseudoplanus" has a short range in the Middle Ordovician period. If rocks of unknown age are found to have traces of "E. pseudoplanus", they must have a mid-Ordovician age. Such index fossils must be distinctive, be globally distributed and have a short time range to be useful. However, misleading results are produced if the index fossils turn out to have longer fossil ranges than first thought. Stratigraphy and biostratigraphy can in general provide only relative dating ("A" was before "B"), which is often sufficient for studying evolution. However, this is difficult for some time periods, because of the problems involved in matching up rocks of the same age across different continents.
Family-tree relationships may also help to narrow down the date when lineages first appeared. For instance, if fossils of B or C date to X million years ago and the calculated "family tree" says A was an ancestor of B and C, then A must have evolved more than X million years ago.
It is also possible to estimate how long ago two living clades diverged – i.e. approximately how long ago their last common ancestor must have lived – by assuming that DNA mutations accumulate at a constant rate. These "molecular clocks", however, are fallible, and provide only a very approximate timing: for example, they are not sufficiently precise and reliable for estimating when the groups that feature in the Cambrian explosion first evolved, and estimates produced by different techniques may vary by a factor of two.
Overview of the history of life.
The evolutionary history of life stretches back to over , possibly as far as . Earth formed about and, after a collision that formed the Moon about 40 million years later, may have cooled quickly enough to have oceans and an atmosphere about .* </ref> However, there is evidence on the Moon of a Late Heavy Bombardment from . If, as seems likely, such a bombardment struck Earth at the same time, the first atmosphere and oceans may have been stripped away. The oldest clear evidence of life on Earth dates to , although there have been reports, often disputed, of fossil bacteria from and of geochemical evidence for the presence of life . Some scientists have proposed that life on Earth was "seeded" from elsewhere,* * </ref> but most research concentrates on various explanations of how life could have arisen independently on Earth.
[[File:Runzelmarken.jpg|thumb|250px|This wrinkled "elephant skin" texture is a trace fossil of a non-stromatolite microbial mat. The image shows the location, in the Burgsvik beds of Sweden, where the texture was first identified as evidence of a microbial mat.]]For about 2,000 million years microbial mats, multi-layered colonies of different types of bacteria, were the dominant life on Earth. The evolution of oxygenic photosynthesis enabled them to play the major role in the oxygenation of the atmosphere from about . This change in the atmosphere increased their effectiveness as nurseries of evolution. While eukaryotes, cells with complex internal structures, may have been present earlier, their evolution speeded up when they acquired the ability to transform oxygen from a poison to a powerful source of energy in their metabolism. This innovation may have come from primitive eukaryotes capturing oxygen-powered bacteria as endosymbionts and transforming them into organelles called mitochondria. The earliest evidence of complex eukaryotes with organelles such as mitochondria, dates from .
Multicellular life is composed only of eukaryotic cells, and the earliest evidence for it is the Francevillian Group Fossils from , although specialisation of cells for different functions first appears between (a possible fungus) and (a probable red alga). Sexual reproduction may be a prerequisite for specialisation of cells, as an asexual multicellular organism might be at risk of being taken over by rogue cells that retain the ability to reproduce.
The earliest known animals are cnidarians from about , but these are so modern-looking that the earliest animals must have appeared before then. Early fossils of animals are rare because they did not develop mineralised hard parts that fossilise easily until about . The earliest modern-looking bilaterian animals appear in the Early Cambrian, along with several "weird wonders" that bear little obvious resemblance to any modern animals. There is a long-running debate about whether this Cambrian explosion was truly a very rapid period of evolutionary experimentation; alternative views are that modern-looking animals began evolving earlier but fossils of their precursors have not yet been found, or that the "weird wonders" are evolutionary "aunts" and "cousins" of modern groups. Vertebrates remained an obscure group until the first fish with jaws appeared in the Late Ordovician.
The spread of life from water to land required organisms to solve several problems, including protection against drying out and supporting themselves against gravity. The earliest evidence of land plants and land invertebrates date back to about and respectively. The lineage that produced land vertebrates evolved later but very rapidly between and ; recent discoveries have overturned earlier ideas about the history and driving forces behind their evolution. Land plants were so successful that they caused an ecological crisis in the Late Devonian, until the evolution and spread of fungi that could digest dead wood.
During the Permian period synapsids, including the ancestors of mammals, may have dominated land environments, but the Permian–Triassic extinction event came very close to wiping out complex life. The extinctions were apparently fairly sudden, at least among vertebrates. During the slow recovery from this catastrophe a previously obscure group, archosaurs, became the most abundant and diverse terrestrial vertebrates. One archosaur group, the dinosaurs, were the dominant land vertebrates for the rest of the Mesozoic, and birds evolved from one group of dinosaurs. During this time mammals' ancestors survived only as small, mainly nocturnal insectivores, but this apparent set-back may have accelerated the development of mammalian traits such as endothermy and hair. After the Cretaceous–Paleogene extinction event killed off the non-avian dinosaurs – birds are the only surviving dinosaurs – mammals increased rapidly in size and diversity, and some took to the air and the sea.
Fossil evidence indicates that flowering plants appeared and rapidly diversified in the Early Cretaceous, between and . Their rapid rise to dominance of terrestrial ecosystems is thought to have been propelled by coevolution with pollinating insects. Social insects appeared around the same time and, although they account for only small parts of the insect "family tree", now form over 50% of the total mass of all insects.
Humans evolved from a lineage of upright-walking apes whose earliest fossils date from over . Although early members of this lineage had chimp-sized brains, about 25% as big as modern humans', there are signs of a steady increase in brain size after about . There is a long-running debate about whether "modern" humans are descendants of a single small population in Africa, which then migrated all over the world less than 200,000 years ago and replaced previous hominine species, or arose worldwide at the same time as a result of interbreeding.
Mass extinctions.
Life on earth has suffered occasional mass extinctions at least since . Although they are disasters at the time, mass extinctions have sometimes accelerated the evolution of life on earth. When dominance of particular ecological niches passes from one group of organisms to another, it is rarely because the new dominant group is "superior" to the old and usually because an extinction event eliminates the old dominant group and makes way for the new one.
The fossil record appears to show that the rate of extinction is slowing down, with both the gaps between mass extinctions becoming longer and the average and background rates of extinction decreasing. However, it is not certain whether the actual rate of extinction has altered, since both of these observations could be explained in several ways:
Biodiversity in the fossil record, which is
shows a different trend: a fairly swift rise from , a slight decline from , in which the devastating Permian–Triassic extinction event is an important factor, and a swift rise from to the present.
History of paleontology.
Although paleontology became established around 1800, earlier thinkers had noticed aspects of the fossil record. The ancient Greek philosopher Xenophanes (570–480 BC) concluded from fossil sea shells that some areas of land were once under water. During the Middle Ages the Persian naturalist Ibn Sina, known as "Avicenna" in Europe, discussed fossils and proposed a theory of petrifying fluids on which Albert of Saxony elaborated in the 14th century. The Chinese naturalist Shen Kuo (1031–1095) proposed a theory of climate change based on the presence of petrified bamboo in regions that in his time were too dry for bamboo.
In early modern Europe, the systematic study of fossils emerged as an integral part of the changes in natural philosophy that occurred during the Age of Reason. In the Italian Renaissance, Leonardo Da Vinci made various significant contributions to the field as well designed numerous fossils. At the end of the 18th century Georges Cuvier's work established comparative anatomy as a scientific discipline and, by proving that some fossil animals resembled no living ones, demonstrated that animals could become extinct, leading to the emergence of paleontology. The expanding knowledge of the fossil record also played an increasing role in the development of geology, particularly stratigraphy.
The first half of the 19th century saw geological and paleontological activity become increasingly well organised with the growth of geologic societies and museums and an increasing number of professional geologists and fossil specialists. Interest increased for reasons that were not purely scientific, as geology and paleontology helped industrialists to find and exploit natural resources such as coal.
This contributed to a rapid increase in knowledge about the history of life on Earth and to progress in the definition of the geologic time scale, largely based on fossil evidence. In 1822 Henri Marie Ducrotay de Blanville, editor of "Journal de Physique", coined the word "palaeontology" to refer to the study of ancient living organisms through fossils. As knowledge of life's history continued to improve, it became increasingly obvious that there had been some kind of successive order to the development of life. This encouraged early evolutionary theories on the transmutation of species.
After Charles Darwin published "Origin of Species" in 1859, much of the focus of paleontology shifted to understanding evolutionary paths, including human evolution, and evolutionary theory.
The last half of the 19th century saw a tremendous expansion in paleontological activity, especially in North America. The trend continued in the 20th century with additional regions of the Earth being opened to systematic fossil collection. Fossils found in China near the end of the 20th century have been particularly important as they have provided new information about the earliest evolution of animals, early fish, dinosaurs and the evolution of birds. The last few decades of the 20th century saw a renewed interest in mass extinctions and their role in the evolution of life on Earth. There was also a renewed interest in the Cambrian explosion that apparently saw the development of the body plans of most animal phyla. The discovery of fossils of the Ediacaran biota and developments in paleobiology extended knowledge about the history of life back far before the Cambrian.
Increasing awareness of Gregor Mendel's pioneering work in genetics led first to the development of population genetics and then in the mid-20th century to the modern evolutionary synthesis, which explains evolution as the outcome of events such as mutations and horizontal gene transfer, which provide genetic variation, with genetic drift and natural selection driving changes in this variation over time. Within the next few years the role and operation of DNA in genetic inheritance were discovered, leading to what is now known as the "Central Dogma" of molecular biology. In the 1960s molecular phylogenetics, the investigation of evolutionary "family trees" by techniques derived from biochemistry, began to make an impact, particularly when it was proposed that the human lineage had diverged from apes much more recently than was generally thought at the time. Although this early study compared proteins from apes and humans, most molecular phylogenetics research is now based on comparisons of RNA and DNA.

</doc>
<doc id="23085" url="https://en.wikipedia.org/wiki?curid=23085" title="Plotter">
Plotter

The plotter is a computer printer for printing vector graphics. In the past, plotters were used in applications such as computer-aided design, though they have generally been replaced with wide-format conventional printers. A plotter gives a hard copy of the output. It draws pictures on a paper using a pen. Plotters are used to print designs of ships and machines, plans for buildings and so on.
Overview.
Pen plotters print by moving a pen or other instrument across the surface of a piece of paper. This means that plotters are vector graphics devices, rather than raster graphics as with other printers. Pen plotters can draw complex line art, including text, but do so slowly because of the mechanical movement of the pens. They are often incapable of efficiently creating a solid region of color, but can hatch an area by drawing a number of close, regular lines.
Plotters offered the fastest way to efficiently produce very large drawings or color high-resolution vector-based artwork when computer memory was very expensive and processor power was very limited, and other types of printers had limited graphic output capabilities.
Pen plotters have essentially become obsolete, and have been replaced by large-format inkjet printers and LED toner based printers. Such devices may still understand vector languages originally designed for plotter use, because in many uses, they offer a more efficient alternative to raster data.
The Z64, the image seen to the right, is a "flatbed drawing machine" of high precision.
Electrostatic plotters.
Electrostatic plotters used a dry toner transfer process similar to that in many photocopiers. They were faster than pen plotters and were available in large formats, suitable for reproducing engineering drawings. The quality of image was often not as good as contemporary pen plotters. Electrostatic plotters were made in both flat-bed and drum types.
Cutting plotters.
Cutting plotters use knives to cut into a piece of material (such as paper, mylar or vinyl) that is lying on the flat surface area of the plotter. It is achieved because the cutting plotter is connected to a computer, which is equipped with specialized cutting design or drawing computer software programs. Those computer software programs are responsible for sending the necessary cutting dimensions or designs in order to command the cutting knife to produce the correct project cutting needs.
In recent years the use of cutting plotters (generally called die-cut machines) has become popular with home enthusiasts of paper crafts such as cardmaking and scrapbooking. Such tools allow desired card shapes to be cut out very precisely, and repeated perfectly identically.
History.
A number of printer control languages were created to operate pen plotters, and transmit commands like "lift pen from paper", "place pen on paper", or "draw a line from here to here". Three common ASCII-based plotter control languages are Hewlett-Packard's HP-GL, its successor HP-GL/2 and Houston Instruments DMPL. Here is a simple HP-GL script drawing a line :
This program instructs the plotter, in order, to take the first pen (SP1 = Select Pen 1), to go to coordinates X=500, Y=500 on the paper sheet (PA = Plot Absolute), to lower the pen against the paper (PD = Pen Down), to move 1000 units in the Y direction (thus drawing a vertical line - PR = Plot Relative), to lift the pen (PU = Pen Up) and finally to put it back in its stall.
Programmers using FORTRAN or BASIC generally did not program these directly, but used software packages, such as the Calcomp library, or device independent graphics packages, such as Hewlett-Packard's AGL libraries or BASIC extensions or high end packages such as DISSPLA. These would establish scaling factors from world coordinates to device coordinates, and translate to the low level device commands. For example, to plot X*X in HP 9830 BASIC, the program would be 
Early pen plotters, e.g., the Calcomp 565 of 1959, worked by placing the paper over a roller that moved the paper back and forth for X motion, while the pen moved back and forth on a track for Y motion. The paper was supplied in roll form and had perforations along both edges that were engaged by sprockets on the rollers.
Another approach, e.g. Computervision's Interact I, involved attaching ball-point pens to drafting pantographs and driving the machines with stepper motors controlled by the computer. This had the disadvantage of being somewhat slow to move, as well as requiring floor space equal to the size of the paper, but could double as a digitizer. A later change was the addition of an electrically controlled clamp to hold the pens, which allowed them to be changed, and thus create multi-colored output.
Hewlett Packard and Tektronix produced small, desktop-sized flatbed plotters in the late 1960s and 1970s. The pens were mounted on a traveling bar, whereby the y-axis was represented by motion up and down the length of the bar and the x-axis was represented by motion of the bar back and forth across the plotting table. Due to the mass of the bar, these plotters operated relatively slowly.
In the 1980s, the small and lightweight HP 7470 introduced the "grit wheel" mechanism, eliminating the need for perforations along the edges, unlike the Calcomp plotters two decades earlier. The grit wheels at opposite edges of the sheet press against resilient polyurethane-coated rollers and form tiny indentations in the sheet. As the sheet is moved back and forth, the grit wheels keep the sheet in proper registration due to the grit particles falling into the earlier indentations, much like the teeth of two gears meshing. The pen is mounted on a carriage that moves back and forth in a line between the grit wheels, representing the orthogonal axis. These smaller "home-use" plotters became popular for desktop business graphics and in engineering laboratories, but their low speed meant they were not useful for general printing purposes, and different conventional printer would be required for those jobs. One category, introduced by Hewlett Packard's MultiPlot for the HP 2647, was the "word chart", which used the plotter to draw large letters on a transparency. This was the forerunner of the modern Powerpoint chart. With the widespread availability of high-resolution inkjet and laser printers, inexpensive memory and computers fast enough to rasterize color images, pen plotters have all but disappeared. However, the grit wheel mechanism is still found in inkjet-based, large format engineering plotters.
Plotters were also used in the Create-A-Card kiosks that were available for a while in the greeting card area of supermarkets that used the HP 7475 six-pen plotter.
Plotters are used primarily in technical drawing and CAD applications, where they have the advantage of working on very large paper sizes while maintaining high resolution. Another use has been found by replacing the pen with a cutter, and in this form plotters can be found in many garment and sign shops.
If a plotter was commanded to use different colors it had to replace the pen and select the wanted color and/or width.
A niche application of plotters is in creating tactile images for visually handicapped people on special thermal cell paper.
Unlike other printer types, pen plotter speed is measured by pen speed and acceleration rate, instead of by page printing speed. A pen plotter's speed is primarily limited by the type of pen used, so the choice of pen is a key factor in pen plotter output speed. Indeed, most modern pen plotters have commands to control slewing speed, depending on the type of pen currently in use.
There are many types of plotter pen, some of which are no longer mass-produced. Technical pen tips are often used, many of which can be renewed using parts and supplies for manual drafting pens. Early HP flatbed and grit wheel plotters used small, proprietary fiber-tipped or plastic nib disposable pens.
One type of plotter pen uses a cellulose fiber rod inserted through a circular foam tube saturated with ink, with the end of the rod sharpened into a conical tip. As the pen moves across the paper surface, capillary wicking draws the ink from the foam, down the rod, and onto the paper. As the ink supply in the foam is depleted, the migration of ink to the tip begins to slow down, resulting in faint lines. Slowing the plotting speed will allow the lines drawn by a worn-out pen to remain dark, but the fading will continue until the foam is completely depleted. Also, as the fiber tip pen is used, the tip slowly wears away on the plotting medium, producing a progressively wider, smudged line.
Ball-point plotter pens with refillable clear plastic ink reservoirs are available. They do not have the fading or wear effects of fiber pens, but are generally more expensive and uncommon. Also, conventional ball-point pens can be modified to work in most pen plotters.
Vinyl cutter.
A vinyl cutter (sometimes known as a cutting plotter) is used to create posters, billboards, signs, t-shirt logos, and other weather-resistant graphical designs. The vinyl can also be applied to car bodies and windows for large, bright company advertising and to sailboat transoms. A similar process is used to cut tinted vinyl for automotive windows.
Colors are limited by the collection of vinyl on hand. To prevent creasing of the material, it is stored in rolls. Typical vinyl roll sizes are 15-inch, 24-inch, 36-inch and 48-inch widths, and have a backing material for maintaining the relative placement of all design elements.
Vinyl cutter hardware is similar to a traditional plotter except that the ink pen is replaced by a very sharp knife to outline each shape, and may have a pressure control to adjust how hard the knife presses down into the vinyl film, preventing the cuts from also penetrating the backing material. Besides losing relative placement of separate design elements, loose pieces cut out of the backing material may fall out and jam the plotter roll feed or the cutter head. After cutting, the vinyl material outside of the design is peeled away, leaving the design on the backing material which can be applied using self-adhesion, glue, lamination, or a heat press.
The vinyl knife is usually shaped like a plotter pen and is also mounted on a swivel head so that the knife edge self-rotates to face the correct direction as the plotter head moves.
Vinyl cutters are primarily used to produce single-color line art and lettering. Multiple color designs require cutting separate sheets of vinyl, then overlaying them during application; but this process quickly becomes cumbersome for more than a couple of hues.
Sign cutting plotters are in decline in applications such as general billboard design, where wide-format inkjet printers that use solvent-based inks are employed to print directly onto a variety of materials. Cutting plotters are still relied upon for precision contour-cutting of graphics produced by wide-format inkjet printers – for example to produce window or car graphics, or shaped stickers.
Large-format inkjet printers are increasingly used to print onto heat-shrink plastic sheeting, which is then applied to cover a vehicle surface and shrunk to fit using a heat gun, known as a vehicle wrap.
Static cutting table.
A static cutting table is a type of cutting plotter used a large flat vacuum table. It is used for cutting non-rigid and porous material such as textiles, foam, or leather, that may be too difficult or impossible to cut with roll-fed plotters. Static cutters can also cut much thicker and heavier materials than a typical roll-fed or sheet-fed plotter is capable of handling.
The surface of the table has a series of small pinholes drilled in it. Material is placed on the table, and a coversheet of plastic or paper is overlaid onto the material to be cut. A vacuum pump is turned on, and air pressure pushes down on the coversheet to hold the material in place. The table then operates like a normal vector plotter, using various cutting tools to cut holes or slits into the fabric. The coversheet is also cut, which may lead to a slight loss of vacuum around the edges of the coversheet, but this loss is not significant.
Contemporary uses of pen plotters.
In the mid-to-late 2000s artists and hackers began to rediscover pen plotters as quirky, customizable output devices. The quality of the lines produced by pens on paper is quite different from other digital output techniques. Even 30-year-old pen plotters typically still function reliably, and many were available for less than $100 on auction and resale websites. While support for driving pen plotters directly or saving files as HPGL has disappeared from most commercial graphics applications, several contemporary software packages make working with HPGL on modern operating systems possible.
As use of plotters has waned, the large-format printers that have largely replaced them have come to be called plotters as well.

</doc>
<doc id="23086" url="https://en.wikipedia.org/wiki?curid=23086" title="Poker equipment">
Poker equipment

The following is a list of equipment used for a game of poker:

</doc>
<doc id="23090" url="https://en.wikipedia.org/wiki?curid=23090" title="Ante">
Ante

Ante or Antes may refer to:

</doc>
<doc id="23093" url="https://en.wikipedia.org/wiki?curid=23093" title="Bug (poker)">
Bug (poker)

A bug in poker is a limited form of wild card. One or both jokers are often added to the deck and played as bugs.
In draw poker played for high and pai gow poker, the bug is considered to be an ace, unless it can be used as a missing card to complete a straight or a flush, in which case it becomes the highest card which can complete the hand.
In California lowball, the bug is the lowest unpaired card in a hand. For example in 8-6-4-3 plus the bug, the bug becomes an ace; in A-2-3-5 plus the bug, the bug becomes a four.
Holding the bug greatly increases the power of certain drawing hands. For example, playing for high, a natural four-straight such as Q-J-10-9 drawing one has nine outs to complete the hand, any king or eight or the bug. By contrast a four-straight including the bug can have as many as sixteen outs to complete the straight - Q-J-10-Joker can catch any ace, king, nine, or eight.

</doc>
<doc id="23094" url="https://en.wikipedia.org/wiki?curid=23094" title="Wild card (card games)">
Wild card (card games)

Card games, particularly poker games, may contain one or more cards designated as wild. These may be jokers, or they may be normal ranked and suited cards pressed into wild card duty ("deuces wild" is a common variant). In most cases, the wild card or cards must be agreed upon by all players before the cards are dealt and play commences. There are two common rules regarding wild cards: "fully wild" cards and the "bug".
A card that is fully wild can be designated by its holder as any card they choose with no restrictions. Under this rule, for example, a hand with any natural pair and a wild card becomes three of a kind. With wild cards in play, the best possible hand is a natural royal flush. The common rule in casinos is that a wild card plays as a bug, which is given the rank of ace unless designating it as a different card would complete a straight, flush, or royal flush. Under this rule, a hand such as K-K-Joker-5-2 is just a pair of kings (with an ace kicker), but any four same-suit cards with a bug make a flush, and a hand such as 7-Joker-5-4-3 makes a straight.
There is also a variation of the "Fully Wild" rule in which the wild card (in this instance they are usually jokers as there are traditionally only two and there is only one black and one red) can be any card of the suits matching the cards colour or current suit. For example in a jokers wild game with these rules, the red joker could be used as any card of hearts or diamonds. Inversely, the black joker would be any card of clubs or spades.
Two exceptions to standard poker practice sometimes seen in home games are the double-ace flush rule, and the natural wins rule. The latter rule states that between hands that would otherwise tie, the hand with fewer wild cards wins. This is not common in casinos and should be treated as an exception to standard practice (as is the double-ace flush).
There is a tendency among some players to regard wild cards as "impure" or treat wild card games as silly or amateurish. While it is certainly true that a game with too many wild cards can become so random that all skill is lost, the occasional use of wild cards is a good way to add variation to a game and add opportunities for skillful play. In particular, five-card draw is traditionally played with a joker in California (which plays as a bug), and also plays well with deuces fully wild. Seven-card stud plays well with one or two bugs, especially when played high-low split. Other games such as Texas hold 'em and Omaha hold'em do not play well with wild cards. For some players, the problem with wild card games is that the winner is almost always the hand with the most wild cards, making the other cards irrelevant, and making skill less important.
Another issue with wild cards is that they distort the hand frequencies. In 5-card stud, the stronger hands are less frequent than the weaker hands; i.e., no pair is most common, followed by one pair, two pair, three of a kind, etc. When wild cards are added, the stronger hands gain frequency while the weaker hands lose frequency. For example, if a player holds a pair and a wild card, they will always choose three of a kind rather than two pair. This causes three of a kind to be more common than two pair. But if two pair ranks above three of a kind, the two pair will become more common.

</doc>
<doc id="23101" url="https://en.wikipedia.org/wiki?curid=23101" title="High-low split">
High-low split

In traditional poker games, the player with the best traditional hand wins the whole pot. Lowball variations award the pot to the lowest hand, by any of several methods (see Low hand (poker)). High-low split games are those in which the pot is divided between the player with the best traditional hand (called the high hand) and the player with the low hand.
There are two common methods for playing high-low split games, called declaration and cards speak. In a declaration game, each player declares (either verbally or using markers such as chips) whether he wishes to contest for the high hand or the low hand. The lowest hand among those who declared low wins that half of the pot, and the highest hand among those who declared high wins that half (for further details, see declaration). In a cards speak game, all players simply reveal their cards at showdown and the hands are evaluated by all players; high hand wins half of the pot and low hand wins the other half.
Especially when using the ace-to-five low method, it is possible for one player to have both the low hand and the high hand, and therefore win all of the pot (called "scooping," "hogging" the pot, or "going pig"). In the event more than one player ties for either high or low, the pot can be further split into quarters or smaller fractions. For example, if one player has the high hand on showdown, and two other players tie for the best low hand, the high hand wins half of the pot and each low hand wins only a quarter of the pot.
It is common, especially in cards speak games, to require a certain hand value or better to win the low half of the pot, called a qualifier. For example in an "eight or better to qualify low" game, a player with an eight-high hand (or better low such as seven-high) is entitled to win the low half of the pot (assuming his hand defeats all other low hands), but a player with a 10-high or 9-high hand cannot win, even if his hand is the lowest. In this case, the high hand wins the entire pot. There is generally no qualifier to win high, although one common variant is any pair/no pair, where a hand of at least a pair is required to win high and any hand with no pair is required to win low.
In high-low split games where each player is dealt more than five cards, each player chooses five of his cards to play as his high hand, and/or five of his cards to play as his low hand. The sets may overlap: for example, in seven-card stud played high-low split, a player dealt 7-7-6-4-4-3-2 can play a high hand of 7-7-4-4-6 (two pair, sevens and fours) and a low hand of 7-6-4-3-2 (seven-high).
Note that bluffs can be especially powerful in high-low split games, because a player making a successful bluff wins the whole pot rather than having to share it. This fact also makes bluffs less likely to succeed.

</doc>
<doc id="23106" url="https://en.wikipedia.org/wiki?curid=23106" title="Kicker (poker)">
Kicker (poker)

A kicker, also called a side card, is a card in a poker hand that does not itself take part in determining the rank of the hand, but that may be used to break ties between hands of the same rank. For example, the hand Q-Q-10-5-2 is ranked as a pair of queens. The 10, 5, and 2 are kickers. This hand would defeat any hand with no pair, or with a lower-ranking pair, and lose to any higher-ranking hand. But the kickers can be used to break ties between other hands that also have a pair of queens. For example, Q-Q-K-3-2 would win (because its K kicker outranks the 10), but Q-Q-10-4-3 would lose (because its 4 is outranked by the 5).
Kickers in draw poker.
The term is also used in draw poker to denote an unmatched card (often an ace) retained by a player during the draw in the hope that either it will be paired on the draw, or else play as a kicker (in the first sense) on the showdown. A kicker may also be retained in order to deceive an opponent, for example, to represent a three-of-a-kind when the player has only a pair.
Kickers in Texas hold 'em.
Kickers take on special importance in Texas hold 'em, because a common winning hand is one card in a player's hand matched with a card on the board, while the player's second card acts as a kicker. For example, if one player holds A-8, a second player holds A-7, and the board is
A-K-6-5-4, the player with the A-8 will outkick the player with the A-7, since A-8's best hand is A-A-K-8-6, while the A-7's hand is A-A-K-7-6.
However, if the board held A-K-Q-J-3, the players would tie, because both would play the hand A-A-K-Q-J; in this case it is said that the players' kickers "don't play", or that the "kicker on the board plays". In this case, there would be a split pot.

</doc>
<doc id="23118" url="https://en.wikipedia.org/wiki?curid=23118" title="Four of a kind">
Four of a kind

Four of a kind may refer to:

</doc>
<doc id="23124" url="https://en.wikipedia.org/wiki?curid=23124" title="Blind (poker)">
Blind (poker)

The blinds are forced bets posted by players to the left of the dealer button in flop-style poker games. The number of blinds is usually two, but it can range from none to three.
The small blind is placed by the player to the left of the dealer button and the big blind is then posted by the next player to the left. The one exception is when there are only two players (a "heads-up" game), when the player on the button is the small blind, and the other player is the big blind. (Both the player and the bet may be referred to as big or small blind.)
After the cards are dealt, the player to the left of the big blind is the first to act during the first betting round. If any players call the big blind, the big blind is then given an extra opportunity to raise. This is known as a "live blind". If the live blind checks, the betting round then ends.
Generally, the "big blind" is equal to the minimum bet. The "small blind" is normally half the big blind. In cases where posting exactly half the big blind is impractical due to the big blind being some odd-valued denomination, the small blind is rounded (usually down) to the nearest practical value. For example, if the big blind in a live table game is $3 then the small blind will usually be $1 or $2 since most casinos do not distribute large quantities of $0.50 poker chips.
The blinds exist because Omaha and Texas hold 'em are frequently played without antes, allowing a player to fold his hand without placing a bet. The blind bets introduce a regular cost to take part in the game, thus inducing a player to enter pots in an attempt to compensate for that expense.
It is possible to play without blinds. The minimum bet is then the lowest denomination chip in play, and tossing only one chip is considered as a call. Anything higher than that is considered a raise. Poker without blinds is usually played with everyone posting an ante to receive cards.
Blinds in cash games.
In cash games, otherwise known as ring games, blinds primarily serve to ensure all players are subject to some minimum, ongoing cost for participating in the game. This encourages players to play hands they otherwise might not, thereby increasing the average size of the pots and, by extension, increasing the amount of rake earned by the cardroom hosting the game.
In cash games, the amount of the blinds are normally fixed for each particular table and will not change for the duration of the game. However, many cardrooms will allow blind levels to change in cases where all players unanimously agree to a change. Larger cardrooms will often include tables with different blind levels to give players the option of playing at whatever stakes they are most comfortable with. In online poker, blinds range from as little as one U.S. cent to USD1,000 or more.
The minimum and maximum buy-in at a table is usually set in relation to the big blind. At live games, the minimum buy-in is usually between 20 and 50 big blinds, while the maximum buy-in is usually between 100 and 250 big blinds. Some online cardrooms offer "short stack" tables where the maximum buy-in is 50 big blinds or less and/or "deep stack" tables where the minimum buy-in is 100 big blinds or more.
Missed blinds.
In cash games that do not deal cards to players who are absent from the table at the start of the hand (or, in online games, are designated as "sitting out"), special rules are necessary to deal with players who miss their blinds.
In such a situation, if a player misses his or her big blind, he or she will not be dealt in again until the button has passed. At that point, if the player wishes to rejoin the game, he or she must "super-post" - meaning he or she must post both the big and small blinds in order to be dealt cards. Of these, only the big blind is considered "live" while the small blind is "dead" - it is placed in the center of the pot apart from the big blind and will not count towards calling any additional bets or raises by other players. If the player has only missed the small blind, then the same procedure applies except that the player only has to post the "dead" small blind to rejoin the game. Most cardrooms allow players to relieve themselves of these obligations if they wait until they are again due to post the big blind before rejoining the game.
Some cardrooms hosting live cash games do not allow players to miss and/or avoid paying blinds in this manner. In these games, all players with chips on the table are dealt in whether or not they are present at the table. Any blinds due will be posted from the player's stack - depending on the cardroom's rules this will be done either by the dealer, another cardroom employee or a nearby player under staff supervision. Whenever a player has not returned to the table by the time it is his turn to act, his or her hand is automatically folded. Under such rules, if a player wishes to be absent from the table then the only way he or she can avoid paying blinds is to cash out and leave the game altogether.
Blinds in tournament play.
In poker tournament play, blinds serve a dual purpose. In addition to the purpose explained above, blinds are also used to control how long the tournament will last. Before the tournament begins, the players will agree to a blinds structure, usually set by the tournament organizer. This structure defines how long each round is and how much the blinds increase per round. Typically, they are increased at a smooth rate of between 25% and 50% per round over the previous round. As the blinds increase, players need to increase their chip counts (or "stacks") to stay in the game. The blinds will eventually consume all of a player's stack if he or she does not play to win more.
Unlike many cash games, it is not possible for a player to "miss" blinds in a tournament. If a player is absent from the table, he will continue to have his or her cards dealt and mucked and will have blinds and, if applicable, antes taken from his stack as they are due, either until he or she returns or until his or her stack is completely consumed by blinds and antes. A player who loses his or her chips in this manner is said to have been "blinded off."
Goals.
There are two main goals for the blinds structure:
If desired, antes can be added to further increase the pressure to win more chips.
Example.
If each player in a tournament starts with 5,000 in chips and after four hours, the big blind is 10,000 (with a small blind of 5,000), it will be very difficult for a player with only 15,000 in chips to stay in the game.

</doc>
<doc id="23128" url="https://en.wikipedia.org/wiki?curid=23128" title="Showdown (poker)">
Showdown (poker)

In poker, the showdown is a situation when, if more than one player remains after the last betting round, remaining players expose and compare their hands to determine the winner or winners.
To win any part of a pot if more than one player has a hand, a player must show all of his cards faceup on the table, whether they were used in the final hand played or not. Cards speak for themselves: the actual value of a player's hand prevails in the event a player mis-states the value of his hand. Because exposing a losing hand gives information to an opponent, players may be reluctant to expose their hands until after their opponents have done so and will muck their losing hands without exposing them. "Robert's Rules of Poker" state that the last player to take aggressive action by a bet or raise is the first to show the hand—unless everyone checks (or is all-in) on the last round of betting, then the first player to the left of the dealer button is the first to show the hand.
If there is a side pot, players involved in the side pot should show their hands before anyone who is all-in for only the main pot. To speed up the game, a player holding a probable winner is encouraged to show the hand without delay. Any player who has been dealt in may request to see any hand that is eligible to participate in the showdown, even if the hand has been mucked. This option is generally only used when a player suspects collusion or some other sort of cheating by other players. When the privilege is abused by a player (i.e. the player does not suspect cheating, but asks to see the cards just to get insight on another player's style or betting patterns), he may be warned by the dealer, or even removed from the table.
There has been a recent trend in public cardroom rules to limit the ability of players to request to see mucked losing hands at the showdown. Specifically, some cardrooms only grant the right to view a mucked losing hand if the requesting player articulates a concern about possible collusion. Under such rules, players do not have an inherent right to view mucked hands. Because the act of folding a losing hand rather than showing it down is so common, some players can take advantage of others who do this with a rare play called a "call-bluff". For example, if you know that a player always folds rather than showing his hand if he was bluffing, you might call his last bet even with a hand inferior to the one you suspect him of bluffing with, expecting that he will simply fold before he sees that you don't actually have him beat.

</doc>
<doc id="23134" url="https://en.wikipedia.org/wiki?curid=23134" title="Check-raise">
Check-raise

A check-raise in poker is a common deceptive play in which a player checks early in a betting round, hoping someone else will open. The player who checked then raises in the same round.
This might be done, for example, when the first player believes that an opponent has an inferior hand and will not call a direct bet, but that they may attempt to bluff, allowing the first player to win more money than they would by betting straightforwardly. The key point is that if no one else is keen to bet, then the most a player can raise by (in a limit game) is one single bet. If someone else bets first, they can raise, thus increasing the value of the pot by two bets. In a no-limit game, there is no restriction on the size of one's bet, and a raise is likely to be much larger than the second player's bet. Of course, if no other player chooses to open, the betting will be "checked around" and the play will fail.
While it can be an important part of one's poker strategy, this play is not allowed by a house rule in some home games and certain small-stakes casino games. It is also frequently not allowed in the game of California lowball. In older poker material and among stud and draw poker players, it is sometimes referred to as "sandbagging".
Check-raises can also be used as an intimidation technique over the course of a game; a player who has frequently been check-raised may be less likely to attempt to steal the pot.
In online poker games special tracking software can be used to determine the exact percentage of times a player check-raised when they had the opportunity. This information helps to determine if a player who check-raised has a monster hand or is bluffing as part of their routine poker play.
Not all players agree that a check-raise is an especially effective play, however. In "Super/System", poker legend Doyle Brunson claims to check-raise very rarely in no-limit hold 'em; he contends that it is more profitable to simply bet a quality hand, regardless of whether his opponent will try to bluff. His reasoning for this is twofold: First, a failed check-raise gives other players the chance to see free cards that may improve their hand; second, it makes it obvious to other players that you potentially have a very strong hand. The latter, however, may be used as a strong bluff technique, although the opponent could put in a re-raise to scare off a bluff.

</doc>
<doc id="23144" url="https://en.wikipedia.org/wiki?curid=23144" title="Twist (poker)">
Twist (poker)

Twist is poker jargon for a round with specific rules which is sometimes used in the poker variant stud poker. 
One can replace any round of (or add a round to) a stud poker game with a twist round, in which each player is offered the option to replace exactly one card in his hand with a new one from the remaining deck stub.
This is similar to the draw phase of draw poker, differing in the following way: if the player chooses to replace a downcard, he discards it and is dealt a replacement card also face down; if he wishes to replace an upcard, he discards it and receives the replacement face up.
On a twist round, players make the decision of which card to replace in turn starting with the player who bet first on the preceding round (usually the player whose upcards make the best hand), discarding the card they choose to replace, if any.
After everyone has made their decision, the replacement cards are dealt starting at the dealer's left as usual.
Sometimes replacement cards are "bought" by requiring a player to add a fixed amount to the pot to be able to get a replacement.

</doc>
<doc id="23145" url="https://en.wikipedia.org/wiki?curid=23145" title="Stripped deck">
Stripped deck

A stripped deck (US) or shortened pack (UK) is a set of playing cards from which some cards have been removed. The removed cards are usually the pip cards. Many card games use stripped decks, and stripped decks for popular games are commercially available.
History.
When playing cards first arrived in Europe during the 1370s, they had the same format as the modern standard 52-card deck, consisting of four suits each with ten pip cards and three face cards. During the late 14th and 15th centuries, the Spanish and Portuguese decks dropped the 10s while the German and Swiss packs removed the Aces to create 48-card decks. It is far easier to print 48 cards using two woodblocks than 52 cards. While the removal of the above cards was motivated by manufacturing considerations, later expulsions are the result of trying to speed up card games to make them more exciting. Trappola is the first known card game to be played with a deck that was stripped for game play. It removed all the cards from 6 to 3 to create a 36-card deck. 
The most popular card game in 16th-century Europe was Piquet, played with a 36-card deck that dropped ranks from 5 to 2. Around 1700, it dropped the 6s as well to create the 32-card deck which is now the most popular format in France. 32 and 36-card decks are the most widespread in countries that were once part of the Holy Roman (the Low Countries, Germany, and Switzerland), Austro-Hungarian, and Russian empires. 24-card decks to play Schnapsen are widely available in central Europe although it may be shortened to 20 in the future as that is how the modern variant is now commonly played.
The Spanish, Portuguese, Italians, and Latin Americans use mostly 40-card decks. Unlike the countries above, they drop the higher ranking numerals so that the 7 is located immediately under the face cards. This was due to the popularity of Ombre, the game that introduced the concept of bidding.
The British and the Scandinavians are the most resistant against stripped decks, having maintained the 52-card format since receiving them in the 15th century. The British have also propagated that deck size through Whist, the most popular card game of the 19th-century. In the 20th-century, this has been followed by Contract Bridge, Gin Rummy, Canasta, and Poker which all require that deck size.
Asian countries also created stripped decks using their traditional playing cards. In contrast to the Western practice of removing "ranks", Asians remove "suits". During the Qing dynasty, the Chinese money-suited cards dropped one suit as shedding-type games became more popular. In India, the gambling game of Naqsha overtook the Ganjifa trick-taking game and many decks were made with only half of the traditional suits.
The opposite of a stripped deck is an expanded deck. Many commercial attempts have tried and failed to increase the standard deck above 52 cards. The most successful addition to the standard deck is the Joker which first appeared during the American Civil War as a Euchre trump card. The Joker has since been adopted as a wild card in a few other standard playing card games with different values and quantities depending on which game is being played. 500 is a Euchre offshoot invented by the United States Playing Card Company (USPCC) during the early 20th-century. To play the six-handed version, USPCC created a deck with ranks 11, 12, and 13. 500 decks are now produced by other manufacturers and are sold primarily in English speaking countries where the game is played. A much older expanded deck is tarot, invented in 15th-century Italy, with an extra suit of trumps. Tarot card games were the most popular card games of the 18th-century but have since declined. They are still played in various continental European countries with France having the largest community. Tarot decks are not immune to stripping either. The Tarocco Bolognese, Tarocco Siciliano, Industrie und Glück, and Cego decks have excised some pip cards.
Piquet deck.
A French-suited deck of 32 cards, consisting of 7, 8, 9, 10, Jack, Queen, King and Ace in four suits each, is used in the two-player game Piquet, which dates back to the 16th century. 
Games played with a piquet deck (or the equivalent German- or Swiss-suited decks) are still among the most popular in some parts of Europe. This includes belote and klaverjas (the national games of France and the Netherlands, respectively) and skat (the German national game, which is also played with the equivalent German-suited decks in some regions). Bezique is played with two piquet decks.
Stripped decks in poker variants.
Stripped decks are used in certain poker variants. The earliest form of poker was played with only 20 cards. The Australian game of Manila uses a piquet deck, and Mexican stud is played with the 8s, 9s, and 10s removed from the deck (and a joker added). This may require adjusting hand values: in both of these games, a flush ranks above a full house, because having fewer cards of each suit available makes flushes rarer.
A hand such as 6-7-J-Q-K plays as a straight in Mexican stud, skipping over the removed ranks. Some places may allow a hand such as 10-9-8-7-A to play as a straight (by analogy to a wheel) in the 32-card game, the A playing low and skipping over the removed ranks (although this is not the case in Manila). Finally, the relative frequency of straights versus three of a kind is also sensitive to the deck composition (and to the number of cards dealt), so some places may consider three of a kind to be superior to a straight, but the difference is small enough that this complication is not necessary for most games. Similarly, a full house tends to occur more often than a flush in a piquet deck, due to the increased frequency of each playing card rank, creating a change in poker combination ranking.
Five-card stud is also often played with a piquet deck. In lively home games it might work better to only strip three ranks (2s through 4s) with seven or eight players; with only two or three players 7s and 8s could be stripped as well, leaving the same 24-card deck used in euchre. In any of these cases, a flush should rank above a full house (in a 24-card deck it is actually rarer than four of a kind, but is rarely played that flushes are superior to four of a kind). Stripped deck five-card stud is a game particularly well-suited to cheating by collusion, because it is easy for partners to signal a single hole card and the relative value of knowing the location of a single card is higher than with a full deck.
Other games.
The game of euchre is also played with a 24-card stripped deck, consisting of only 9-10-J-Q-K-A of each suit, the 2-8 being stripped from the deck. The game of pinochle is played with 48 cards, consisting of a doubled euchre deck (that is, two copies of 9-A of each suit). 

</doc>
<doc id="23146" url="https://en.wikipedia.org/wiki?curid=23146" title="Roll-your-own cigarette">
Roll-your-own cigarette

Roll-your-own cigarettes (also called RYO, MYO, rollies, roll-ups, burns, hand-rolled cigarettes, or simply rolls) refer to cigarettes made from loose tobacco and rolling paper. Roll-your-own products are sold in pouches or as tins of tobacco, sometimes including the rolling papers or cigarette tubes. Loose filters are available for purchase and can be added to the rolled cigarettes. Some people use a machine to assist them and some people use pre-rolled cones or cigarette tubes.
Hand-rolled cigarettes give smokers the ability to roll cigarettes of any diameter, thereby varying the strength of the cigarette. Technological aids—from hand injectors to large in-store machines—aid in the process.
In the United States, the Internal Revenue section of the tax code includes a personal exemption for people who make their own cigarettes and tobacco (done by shredding blended strips of tobacco leaves).
An amendment to the 2012 federal transportation bill caused roll-your-own cigarette shops to struggle and consider closing. In order for shops to continue using machines, owners must obtain a manufacturer's permit, file a bond, pay the applicable federal cigarette tax rate, keep records, print required markings on packages used for manufactured cigarettes, affix the U.S. Surgeon General's warning labels to packages and comply with the U.S. Food and Drug Administration's minimum cigarette package size.
In Europe, EU regulations for tar and nicotine levels in cigarettes do not apply to rolling tobacco. Hand-rolling tobacco is taxed and priced at a lower level – about half that of packaged cigarettes. In countries where cigarettes are cheap or rolling tobacco is expensive, very few people use RYO cigarettes. By contrast, in the Netherlands more than half of all tobacco smoked in the country is RYO because of price differences.
Equipment.
The least amount of supplies needed to roll one's own cigarettes includes tobacco and rolling papers. However, some prefer to use equipment to aid them in rolling. These can include mechanical rolling machines and cigarette injectors (both mechanical and electric). Filters can also be added when using a rolling machine, and filter tubes are used when making cigarettes with an injector.
Rolling tobacco.
Rolling tobacco, or cigarette tobacco, is the primary tobacco used for R-Y-O cigarettes. It is generally packaged in pouches. After 2009, the (United States) federal tax rate on R-Y-O tobacco was raised from $1.0969 per pound to $24.78 per pound. This increase has caused many people to switch to using pipe tobacco to make cigarettes, since the pipe tobacco tax rate was also increased, but only to $2.83 per pound.
Techniques.
Backroll.
Backroll is a widely used method for hand-rolling a cigarette. The method involves inversion of the rolling paper, so that the gum strip faces the inside. Once rolled, the gum can then be licked through the paper and torn off, thus removing any excess paper. This technique was developed due to the alleged increased heat (possibly caused by additives) generated by smoking tobacco wrapped in multiple layers of paper.
Prevalence.
R-Y-O has become more popular in the United States in recent years, but relatively few smokers, only 6.7%, actually roll their own cigarettes. In contrast, this rate was 15% in Canada, 22% in Australia, and 30% in the UK. Reasons for this difference include the generally lower price of traditional cigarettes in most states in the US compared to Canada and Europe.

</doc>
<doc id="23147" url="https://en.wikipedia.org/wiki?curid=23147" title="Rollout (poker)">
Rollout (poker)

Rollout or roll 'em out is poker jargon used for a game phase in certain poker variants. It is often incorrectly called "roll your own", to which it has similarities but from which it is fundamentally different.
Poker games with a rollout phase resemble stud poker but have significantly different strategies, because players generally receive all of their cards up front (sometimes with a draw phase), and know the final value of their hand in early betting rounds. They resemble stud poker only in that cards are revealed to other players one at a time for each betting round.
There are the same three variations on the idea as with roll your own, depending on when players are allowed to choose which card to reveal. They can either be forced to arrange the order of their cards before any betting begins ("choose before"), or they can also be allowed to choose cards in later rounds based on information found in earlier rounds ("choose after"). In the latter case, the revealing can be made simultaneously or in turn.
In the game of show five, for example, each player is dealt seven cards before any betting begins, and each of the game's five betting rounds begins with the players simultaneously revealing one of their cards ("simultaneous choose-after rollout"). Rollout games are frequently played high-low split, and players choose which cards to reveal in order to delay as long as possible revealing which half of the pot they intend to win.

</doc>
<doc id="23149" url="https://en.wikipedia.org/wiki?curid=23149" title="One player to a hand">
One player to a hand

One player to a hand is an important poker rule designed to promote fair play that is universally applied in casino play. It states that all game decisions about the play of each hand must be made by one player without any assistance. This means, for example, that a player may not ask for advice from any other player or non-player during the play of the hand, nor should anyone offer such advice. The phrase is often used as a warning to players making what might be perceived as minor violations, such as commenting upon other players' possible hands.
Note that any player correcting an error on a declared holding once the hands are exposed is not a violation of this rule, since no further decisions can be made. Some rulebooks declare it an ethical obligation of a player to point out any error in the awarding of a pot or the reading of hands shown down. See Cards speak.

</doc>
<doc id="23150" url="https://en.wikipedia.org/wiki?curid=23150" title="Cards speak">
Cards speak

Cards speak ("for themselves"), also known as "cards read" is used in two poker contexts:
First, it is used to describe a high-low split game without a declaration. That is, in a cards speak game, players all reveal their hands at the showdown, and whoever has the highest hand wins the high half of the pot and whoever has the lowest hand wins the low half.
The other context is as a house rule in casino cardrooms. "Cards speak" means that any verbal declaration as to the content of a player’s hand is not binding. If Mary says she has no pair, but in fact she has a flush, her cards speak and her hand is viewed for its genuine value, that of a flush. Likewise if John says he has a flush, but in fact he does not, his hand is judged on its actual merits, not his verbal declaration. At the discretion of management, a player deemed to be deliberately miscalling his hand may incur a penalty.
The "cards speak" rule does not address the awarding of a pot, player responsibilities, or the similar one player to a hand rule. It merely means that verbal statements do not make a hand value, but the cards do.

</doc>
<doc id="23151" url="https://en.wikipedia.org/wiki?curid=23151" title="Declaration (poker)">
Declaration (poker)

There are several actions in poker called declaration, in which a player formally expresses his intent to take some action (which he may perform at a later point).
For example, one may verbally declare an action (fold, call, raise) while in turn, which obligates the player to complete that action.
One may declare a number of cards to draw in a draw poker game (which is typically not binding), or one may declare some other choice specific to the variant being played.
But most commonly, the term refers to the declaration in the final phase of a high-low split game, in which players indicate whether their hands are to be evaluated as high hands, low hands, or both at showdown. This is only one option for high-low split games; the other is known as "cards speak", in which players simply reveal their hands at showdown and award the pot to the highest and lowest hands shown (possibly subject to qualifications). Cards speak is used commonly in casinos because it is the much simpler method. High-low with declaration is common in home games.
Methods of declaration.
First, declarations can be made either in turn or simultaneously.
Games with verbal in-turn declarations are uncommon, because the positional value of declaring last is so great that it makes the game unfair.
Simultaneous declarations are commonly done by the "chips in hand" method.
Each player remaining in the game takes two chips or coins below the table, then brings up a closed hand containing zero, one, or two of the chips.
After all players have brought their closed hands above the table, they all then open their hands to reveal their choices: for example, no chips in the hand means the player is declaring "low", one chip "high", and two chips "swing" (both ways).
Awarding the pot.
After declaration and showdown, half of the pot is awarded to the highest hand among those players who declared high, and half to the lowest hand among those who declared low. If no one declared in one direction, the whole pot is awarded to the other (for example, if all players declared low, the lowest hand is awarded the whole pot).
If any player declared "swing", then that player must have both the high and low hands to take any part of the pot, though there are several rule variations covering the specifics. First, if the rules specify that ties are acceptable, then a player declaring swing must win or tie both directions to win anything, but if he does, he is entitled to his appropriate share. For example, if the swing player has the clearly highest hand but shares the lowest hand with another player, he wins three-fourths of the pot and the other low hand wins one-fourth. If the rules specify that ties are not acceptable, then a swing player must clearly win both directions: even a tie in one direction means he wins nothing.
Finally, if a swing player fails for half the pot, the half that he would have otherwise won can be awarded either to the second-best hand in that direction, or to the player who defeated him in the other. The latter rule affords more strategic possibilities in declaration. For example, if a player declaring swing has the best high hand but loses for low (or ties for low with a no-ties rule), the whole pot is awarded to the low hand that defeated him.

</doc>
<doc id="23153" url="https://en.wikipedia.org/wiki?curid=23153" title="Closed (poker)">
Closed (poker)

In the game of poker, a betting round is said to be closed if no player will have the right to raise in the round. Normally this occurs when a player calls, and the next player whose turn it is to act is the one who made the last raise, so he cannot raise further (this ends the betting round). The round can also said to be closed before it has actually ended if there are still players remaining to act, but they will not be entitled to raise either because the last raise was a sub-minimum all-in raise (see poker table stakes rules) or because the limit ("cap") on allowed raises has been reached.
The term is also used to describe a category of poker game in which no cards held by individual players are visible to any other player before the showdown. Most forms of draw poker are closed games (draw games with a rollout are an exception). Most forms of stud poker, in contrast, are open games, because some players' cards are dealt face up or are exposed during play (blind stud games are an exception). Most community card poker games like Texas hold 'em are considered closed as well, because the only cards exposed before showdown belong to everyone; the individual players' cards are never seen until showdown.
Strategic implications.
A player who closes the betting round by calling or overcalling is entitled to greater freedom by doing so, since he does not face the threat of subsequent raises. This is especially true when comparing limit hold'em games with a standard cap (3 raises) to an elevated cap (4 raises) or capless game. A player can cap with as much as 80% of his flat calling range when he knows he cannot be forced out of the pot and no opponent can make his hand appear much stronger by raising. This is particularly correct when closing the action on the river in Texas hold'em or on the 7th street in stud poker, where a player can make calldowns with hands that are unlikely to win simply because of the pot odds he is getting and the fact he cannot be bluffed out of the pot.

</doc>
<doc id="23157" url="https://en.wikipedia.org/wiki?curid=23157" title="Value (poker)">
Value (poker)

In poker, the strength of a hand (how likely it is to be the best according to the rules of the game being played) is often called its value; however, in the context of poker strategy the term is more often used to describe a betting tactic, a bet for value. This bet (or raise) is intended to increase the size of the pot, by inducing opponents to call. A bet for value is in contrast to a "bluff" or a "protection bet" (though some bets may have a combination of these motives).
For a bet for value to be correct, a player must have a positive expectation, that is, he will win more than one bet for every bet he puts in the pot. Note that pot odds do not matter in this situation, because the factor here is whether it is more profitable to "raise" or "call", rather than to "call" or "fold". Betting for value can apply to both made hand and drawing hand situations, although in the latter situation it is less often correct, as the drawing hand's chances of winning are generally lower. Many made hands will win the pot more than 50% of the time, therefore a value bet is usually correct, even heads up.
For example, in a game of Texas hold 'em, a player has 8♣ 6♠ with a flop of 9♥ 7♦ 2♣, The player has an open-ended straight draw and so has eight outs (four 10s and four 5s). With 47 unknown cards, the player will make the straight approximately one time for every five times he doesn't, thus a bet is profitable if six or more of his opponents will call the bet (he will win once (+6 bets) and lose five times (-5 bets) out of every six hands like this, resulting in an expectation of +1 bet). If he thinks that fewer than six opponents will call the bet, he would lose money and must simply call.

</doc>
<doc id="23158" url="https://en.wikipedia.org/wiki?curid=23158" title="Nut hand">
Nut hand

In poker, the nut hand is the strongest possible hand in a given situation. The second-nut hand or third-nut hand (and so on) may refer to the second and third best possible hands. The term applies mostly to community card poker games where the individual holding the strongest possible hand, with the given board of community cards, is capable of knowing that they have the nut hand.
Usage in context.
In Texas hold 'em, if the board is 5♠ 6♠ A♣ 9♠ 5♥, a player holding 7♠ 8♠ has the nut hand, a 9-high straight flush of spades, and cannot lose. On the same board, the hand 5♣ 5♦ would be the second-nut hand, four of a kind fives; the third-nut hand would be any pair of the remaining three aces, making a full house, aces full of fives.
It is important to note that the "actual" nut hand may not be the same as the "absolute" nut hand; for example, if the board is 7♥ 2♣ K♠ K♥ 3♦ a player with K♣ K♦ has the absolute nut hand. However, any player with K-7 knows that he has the nut hand as it is impossible for another player to have two kings. The phrase may also refer to a hand in progress with cards yet to be dealt, as the player can be said to have the nuts at that time. For example if a player holds 7♠ 8♠ on a board of 5♣ 6♠ 9♥ he can be said to have the nuts, however if the next card comes 7♥ then 8-10 becomes the nuts. This makes some nut hands very vulnerable in nine-card games, such as Omaha hold 'em.
In high-low split games one often speaks of "nut-low" and "nut-high" hands separately. In Omaha hold 'em, if the board is, 5♠ 6♠ A♣ 9♠ 5♥, any player with 2-3 makes the nut-low hand, 6-5-3-2-A, while a player with 2-4 makes the second-nut-low hand, 6-5-4-2-A (the nut-high hands remain the same as in Texas hold 'em, in this case 7♠ 8♠ to make a straight flush, although one can go as low as aces full by introducing quads and straight flush blockers). Similarly, one can sometimes hear the term "nut-nut", which refers to a hand that makes both the best possible high and low. In Omaha, with the same board as above, a player holding 7♠ 8♠ plus 2-3 of any suit has the nut-nut and is guaranteed no worse than a split of the low pot plus a win of the high pot.
Origins.
A common and certainly apocryphal folk etymology is that the term originated from the historical poker games in the colonial west of America, where if a player bet everything he possessed, he would place the nuts of his wagon wheels on the table to ensure that, should he lose, he would be unable to flee and would have to make good on the bet. Since it would be expected that a player would only make such a bet when he had the best possible hand, the folk lore says that this is how the best possible hand came to be known as the nuts. It is also rumored that these historical games were played only in the winter, and therefore, the nuts that were placed on the table were "stone cold", hence coining the term "stone-cold-nuts".
A far more likely explanation is that "the nuts" originated from the old English usage of "nuts", meaning "any source of pleasure".
Another seemingly fitting explanation is that the term was derived from the UK English slang "the dog's bollocks" or "the mutt's nuts", meaning "the absolute best". However, this phrase originated around 1949, and the term "the nuts" pre-dates it.

</doc>
<doc id="23159" url="https://en.wikipedia.org/wiki?curid=23159" title="Protection (poker)">
Protection (poker)

Protection in poker is a bet made with a strong but vulnerable hand, such as top pair when straight or flush draws are possible. The bet forces opponents with draws to either call with insufficient pot odds, or to fold, both of which are profitable for the betting player. By contrast, if he failed to protect his hand, another player could draw out on him at no cost, meaning he gets no value from his made hand.
A protection play differs from a bluff in that the bluff can win "only" when the opponent folds, while protection bet is made with a hand that is likely to win a showdown, but isn't strong enough for slow playing.
The importance of protection increases when there are multiple opponents. For example, if a hand is currently the best, but each of four opponents has a 1-in-6 chance of drawing an out, the four opponents "combined" become the favorite to win, even though each one is individually an underdog. With a protection bet, some or all of them may fold, leaving fewer opponents and a better chance of winning.
The term "protection" is also often heard in the context of an "all-in" player (see poker table stakes rules). A bet by an opponent serves to protect the all-in player by reducing the number of opponents the all-in player must beat. To deliberately make such a bet solely to protect another player's hand constitutes collusion.
A player may also be said to "protect" his or her cards by placing an object like a specialty chip or miniature figure upon them. This prevents the player from having his cards accidentally collected by the dealer or being fouled by other players' discards.

</doc>
<doc id="23160" url="https://en.wikipedia.org/wiki?curid=23160" title="Draw (poker)">
Draw (poker)

A poker player is drawing if they have a hand that is incomplete and needs further cards to become valuable. The hand itself is called a draw or drawing hand. For example, in seven-card stud, if four of a player's first five cards are all spades, but the hand is otherwise weak, they are "drawing to" a flush. In contrast, a made hand already has value and does not necessarily need to draw to win. A made starting hand with no help can lose to an inferior starting hand with a favorable draw. If an opponent has a made hand that will beat the player's draw, then the player is "drawing dead"; even if they make their desired hand, they will lose. Not only draws benefit from additional cards; many made hands can be improved by catching an out — and may have to in order to win.
Outs.
An unseen card that would improve a drawing hand to a likely winner is an out. "Playing a drawing hand has a positive expectation if the probability of catching an out is greater than the pot odds offered by the pot."
The probability formula_1 of catching an out with one card to come is:
The probability formula_3 of catching at least one out with two cards to come is:
A dead out is a card that would normally be considered an out for a particular drawing hand, but should be excluded when calculating the probability of catching an out. Outs can be dead for two reasons:
Types of draws.
Flush draw.
A flush draw, or four flush, is a hand with four cards of the same suit that may improve to a flush. For example, K♣ 9♣ 8♣ 5♣ x. A flush draw has nine outs (thirteen cards of the suit less the four already in the hand). If you have a flush draw in Hold'em, the probability to flush the hand in the end is 34.97 percent if there are two more cards to come, and 19.56 percent (9 live cards divided by 46 unseen cards) if there is only one more card to come.
Outside straight draw.
An outside straight draw, also called up and down, double-ended straight draw or open-end(ed) straight draw, is a hand with four of the five needed cards in sequence (and could be completed on either end) that may improve to a straight. For example, x-9-8-7-6-x. An outside straight draw has eight outs (four cards to complete the top of the straight and four cards to complete the bottom of the straight). Straight draws including an ace are not outside straight draws, because the straight can only be completed on one end (has four outs).
Inside straight draw.
An inside straight draw, or gutshot draw or belly buster draw, is a hand with four of the five cards needed for a straight, but missing one in the middle. For example, 9-x-7-6-5. An inside straight draw has four outs (four cards to fill the missing internal rank). Because straight draws including an ace only have four outs, they are also considered inside straight draws. For example, A-K-Q-J-x or A-2-3-4-x. The probability of catching an out for an inside straight draw is half that of catching an out for an outside straight draw.
Double inside straight draw.
A double inside straight draw, or double gutshot draw or double belly buster draw can occur when either of two ranks will make a straight, but both are "inside" draws. For example in 11-card games, 9-x-7-6-5-x-3, or 9-8-x-6-5-x-3-2, or in Texas Hold'em when holding 9-J hole cards on a 7-10-K flop. The probability of catching an out for a double inside straight draw is the same as for an outside straight draw.
Other draws.
Sometimes a made hand needs to draw to a better hand. For example, if a player has two pair or three of a kind, but an opponent has a straight or flush, to win the player must draw an out to improve to a full house (or four of a kind). There are a multitude of potential situations where one hand needs to improve to beat another, but the expected value of most drawing plays can be calculated by counting outs, computing the probability of winning, and comparing the probability of winning to the pot odds.
Backdoor draw.
A backdoor draw, or runner-runner draw, is a drawing hand that needs to catch two outs to win. For example, a hand with three cards of the same suit has a "backdoor flush draw" because it needs two more cards of the suit. The probability formula_6 of catching two outs with two cards to come is:
For example, if after the flop in Texas hold 'em, a player has a backdoor flush draw (e.g., three spades), the probability of catching two outs on the turn and river is (10 ÷ 47) × (9 ÷ 46) = 4.16 percent. Backdoor draws are generally unlikely; with 43 unseen cards, it is equally likely to catch two out of seven outs as to catch one out of one. A backdoor outside straight draw (such as J-10-9) is equally likely as a backdoor flush, but any other 3-card straight combination isn't worth even one out.
Drawing dead.
A player is said to be "drawing dead" when the hand he hopes to complete will nonetheless lose to a player who already has a better one. For example, drawing to a straight or flush when the opponent already has a full house. In games with community cards, the term can also refer to a situation where no possible additional community card draws results in a win for a player. (This may be because another player has folded the cards that would complete his hand, his opponent's hand is already stronger than any hand he can possibly draw to or that the card that completes his hand also augments his opponent's, as with the second community 9 in the initial scene of the movie Rounders)
References.
How to Play Texas Hold'em

</doc>
<doc id="23162" url="https://en.wikipedia.org/wiki?curid=23162" title="Out (poker)">
Out (poker)

In a poker game with more than one betting round, an out is any unseen card that, if drawn, will improve a player's hand to one that is likely to win. Knowing the number of outs a player has is an important part of poker strategy. For example in draw poker, a hand with four diamonds has nine outs to make a flush: there are 13 diamonds in the deck, and four of them have been seen. If a player has two small pairs, and he believes that it will be necessary for him to make a full house to win, then he has four outs: the two remaining cards of each rank that he holds.
One's number of outs is often used to describe a drawing hand: "I had a two-outer" meaning you had a hand that only two cards in the deck could improve to a winner, for example. In draw poker, one also hears the terms "12-way" or "16-way" straight draw for hands such as 6♥ 7♥ 8♠ (Joker), in which any of sixteen cards (4 fours, 4 fives, 4 nines, 4 tens) can fill a straight.
The number of outs can be converted to the probability of making the hand on the next card by dividing the number of outs by the number of unseen cards. For example, say a Texas Holdem player holds two spades, and two more appear in the flop. He has seen five cards (regardless of the number of players, as there are no upcards in Holdem except the board), of which four are spades. He thus has 9 outs for a flush out of 47 cards yet to be drawn, giving him a 9/47 chance to fill his flush on the turn. If he fails on the turn, he then has a 9/46 chance to fill on the river. Calculating the combined odds of filling on "either" the turn or river is more complicated: it is (1 - ((38/47) * (37/46))), or about 35%. A common approximation used is to double the number of outs and add one for the percentage to hit on the next card, or to multiply outs by four for the either-of-two case. This approximation works out to within a 1% error margin for up to 14 outs.
Note that the hidden cards of a player's opponents may affect the calculation of outs. For example, assume that a Texas hold 'em board looks like this after the third round: 5♠ K♦ 7♦ J♠, and that a player is holding A♦ 10♦. The player's current hand is just a high ace, which is not likely to win unimproved, so the player has a drawing hand. He has a minimum of nine outs for certain, called "nut outs", because they will make his hand the best possible: those are the 2♦, 3♦, 4♦, 6♦, 8♦, 9♦, and Q♦ (which will give him an ace-high flush with no possible better hand on the board) and the Q♣ and Q♥, which will give him an ace-high straight with no higher hand possible. The 5♦ and J♦ will also make him an ace-high flush, so those are "possible outs" since they give him a hand that is likely to win, but they also make it possible for an opponent to have a full house (if the opponent has something like K♠ K♣, for example). Likewise, the Q♠ will fill his ace-high straight, but will also make it possible for an opponent to have a spade flush. It is possible that an opponent could have as little as something like 7♣ 9♣ (making a pair of sevens); in this case even catching any of the three remaining aces or tens will give the player a pair to beat the opponent's, so those are even more "potential outs". In sum, the player has 9 guaranteed outs, and possibly as many as 18, depending on what cards he expects his opponents to have.

</doc>
<doc id="23163" url="https://en.wikipedia.org/wiki?curid=23163" title="Pot odds">
Pot odds

In poker, pot odds are the ratio of the current size of the pot to the cost of a contemplated call. Pot odds are often compared to the probability of winning a hand with a future card in order to estimate the call's expected value.
Converting odds ratios to and from percentages.
Odds are most commonly expressed as ratios, but converting them to percentages will often make them easier to work with. The ratio has two numbers: the size of the pot and the cost of the call. To convert this ratio to the equivalent percentage, we add these two numbers together and then divide the cost of the call by this sum. For example, the pot is $30, and the cost of the call is $10. The pot odds in this situation are 30:10, or 3:1 when simplified. To get the percentage, we add 30 and 10 to get a sum of 40 and then divide 10 by 40, giving us 0.25, or 25%.
To convert any percentage or fraction to the equivalent odds, we subtract the numerator from the denominator and then divide this difference by the numerator. For example, to convert 25%, or 1/4, we subtract 1 from 4 to get 3 (or 25 from 100 to get 75) and then divide 3 by 1 (or 75 by 25), giving us 3, or 3:1.
Using pot odds to determine expected value.
When a player holds a drawing hand, or a hand that is behind now but is likely to win if a certain card is drawn, pot odds are used to determine the expected value of that hand when the player is faced with a bet.
The expected value of a call is determined by comparing the pot odds to the odds of drawing a card that wins the pot. When the odds of drawing a card that wins the pot are numerically higher than the pot odds, the call has a positive expectation; on average, you win a portion of the pot that is greater than the cost of the call. Conversely, if the odds of drawing a winning card are numerically lower than the pot odds, the call has a negative expectation, and you can expect to win less money on average than it costs to call the bet.
Implied pot odds.
Implied pot odds, or simply implied odds, are calculated the same way as pot odds, but take into consideration estimated future betting. Implied odds are calculated in situations where the player expects to fold in the following round if the draw is missed, thereby losing no additional bets, but expects to gain additional bets when the draw is made. Since the player expects to always gain additional bets in later rounds when the draw is made, and never lose any additional bets when the draw is missed, the extra bets that the player expects to gain, excluding his own, can fairly be added to the current size of the pot. This adjusted pot value is known as the implied pot.
Example (Texas Hold'em).
On the turn, Alice's hand is certainly behind, and she faces a $1 call to win a $10 pot against a single opponent. There are four cards remaining in the deck that make her hand a certain winner. Her probability of drawing one of those cards is therefore 4/46 (8.7%), which when converted to odds is 10.5:1. Since the pot lays 10:1 (9.1%), Alice will on average lose money by calling if there is no future betting. However, Alice expects her opponent to call her additional $1 bet on the final betting round if she makes her draw. Alice will fold if she misses her draw and thus lose no additional bets. Alice's implied pot is therefore $11 ($10 plus the expected $1 call to her additional $1 bet), so her implied pot odds are 11:1 (8.3%). Her call now has a positive expectation.
Reverse implied pot odds.
Reverse implied pot odds, or simply reverse implied odds, apply to situations where a player will win the minimum if holding the best hand but lose the maximum if not having the best hand. Aggressive actions (bets and raises) are subject to reverse implied odds, because they win the minimum if they win immediately (the current pot), but may lose the maximum if called (the current pot plus the called bet or raise). These situations may also occur when a player has a made hand with little chance of improving what is believed to be currently the best hand, but an opponent continues to bet. An opponent with a weak hand will be likely to give up after the player calls and not call any bets the player makes. An opponent with a superior hand, will, on the other hand, continue, (extracting additional bets or calls from the player).
Limit Texas hold'em example.
With one card to come, Alice holds a made hand with little chance of improving and faces a $10 call to win a $30 pot. If her opponent has a weak hand or is bluffing, Alice expects no further bets or calls from her opponent. If her opponent has a superior hand, Alice expects the opponent to bet another $10 on the end. Therefore, if Alice wins, she only expects to win the $30 currently in the pot, but if she loses, she expects to lose $20 ($10 call on the turn plus $10 call on the river). Because she is risking $20 to win $30, Alice's "reverse implied pot odds" are 1.5-to-1 ($30/$20) or 40 percent (1/(1.5+1)). For calling to have a positive expectation, Alice must believe the probability of her opponent having a weak hand is over 40 percent.
Manipulating pot odds.
Often a player will bet to manipulate the pot odds offered to other players. A common example of manipulating pot odds is make a bet to protect a made hand that discourages opponents from chasing a drawing hand.
No-limit Texas hold 'em example.
With one card to come, Bob has a made hand, but the board shows a potential flush draw. Bob wants to bet enough to make it wrong for an opponent with a flush draw to call, but Bob does not want to bet more than he has to in the event the opponent already has him beat. How much should Bob bet?
Assume a $20 pot and one opponent. If Bob bets $10 (half the pot), when his opponent acts, the pot will be $30 and it will cost $10 to call. The opponent's pot odds will be 3-to-1, or 25 percent. If the opponent is on a flush draw (9/46, approximately 19.565 percent or 4.11-to-1 odds against with one card to come), the pot is not offering adequate pot odds for the opponent to call unless the opponent thinks he can induce additional final round betting from Bob if the opponent completes his flush draw (see implied pot odds).
A bet of $6.43, resulting in pot odds of 4.11-to-1, would make his opponent mathematically indifferent to calling if implied odds are disregarded.
Bluffing frequency.
According to David Sklansky, game theory shows that a player should bluff a percentage of the time equal to his opponent's pot odds to call the bluff. For example, in the final betting round, if the pot is $30 and a player is contemplating a $30 bet (which will give his opponent 2-to-1 pot odds for the call), the player should bluff half as often as he would bet for value (one out of three times). 
However, this conclusion does not take into account some of the context of specific situations. A player's bluffing frequency often accounts for many different factors, particularly the tightness or looseness of their opponents. Bluffing against a tight player is more likely to induce a fold than bluffing against a loose player, who is more likely to call the bluff. Sklansky's strategy is an equilibrium strategy in the sense that it is optimal against someone playing an optimal strategy against it.

</doc>
<doc id="23165" url="https://en.wikipedia.org/wiki?curid=23165" title="Position (poker)">
Position (poker)

Position in poker refers to the order in which players are seated around the table and the related poker strategy implications. Players who act first are in "early position"; players who act later are in "late position"; players who act in between are in "middle position". A player "has position" on opponents acting before him and is "out of position" to opponents acting after him. Because players act in clockwise order, a player "has position" on opponents seated to his right, except when the opponent has the button and certain cases in the first betting round of games with blinds.
Position in Texas hold 'em.
The primary advantage held by a player in late position is that he will have more information with which to make better decisions than players in early position, who will have to act first, without the benefit of this extra information. This advantage has led to many players in heads-up play raising on the button with an extremely wide range of hands because of this positional advantage. Also, as earlier opponents fold, the probability of a hand being the best goes up as the number of opponents goes down. 
The blinds are the least desirable position because a player is forced to contribute to the pot and they must act first on all betting rounds after the flop. Although the big blind has a big advantage on the first round of betting, it is on average the biggest money losing position.
Texas hold 'em example.
There are 10 players playing $4/$8 fixed limit. Alice pays the $2 small blind. Bob pays the $4 big blind. Carol is under the gun (first to act). If Carol has a hand like K♥ J♠, she may choose to fold. With 9 opponents remaining to act, there is approximately a 40% chance that at least one of them will have a better hand than Carol's like A-A, K-K, Q-Q, J-J, A-K, A-Q, A-J or K-Q. And even if no one does, seven of them (all but the two players in the blind) will have position on Carol in the next three betting rounds.
Now instead, suppose David in the cut-off position (to the right of the button) has the same K♥ J♠ and all players fold to him. In this situation, there are only three opponents left to act, so the odds that one of them has a better hand are considerably less (only around 16%). Secondly, two of those three (Alice and Bob) will be out of position to David on later betting rounds. A common play would be for David to raise and hope that the button (the only player who has position on David) folds. David's raise might simply steal the blinds if they don't have playable hands, but if they do play, David will be in good shape to take advantage of his position in later betting rounds.

</doc>
<doc id="23166" url="https://en.wikipedia.org/wiki?curid=23166" title="Steal (poker)">
Steal (poker)

In poker, a steal is a type of a bluff, a raise during the first betting round made with an inferior hand and meant to make other players fold superior hands because of shown strength. A steal is normally either an "ante steal" or "blind steal" (depending on whether the game being played uses antes or blinds).
Steals are done with hands less valuable than what might normally be considered a raising hand, normally a below average one, with the hope that the few players remaining will not have a hand worth calling the raise, thereby winning the antes or blinds without further action. This play is used either in late position after several people have folded, or when the game is short-handed. Steals happen more often in tournament situations due to the escalating ante/blind structure making the starting pot quite valuable.
While steals don't win much money per hand, they can accumulate to considerable profit if the players to the left of the stealer are tight enough not to contest enough steals. Of course, skilled players will recognize repeated steal plays and frequently reraise for defense.
Steals being made in late position when everyone folds to the stealer, or when the game is short-handed, are the most common steals, but a raise under other conditions can also act as a steal. An aggressive player, especially one with a large stack of chips, might reraise, also known as re-steal, someone he knows might be trying to steal. The objective here is twofold: the re-raiser hopes to pick up both the blinds and antes and the original raiser's chips when the raiser folds, and he also hopes to keep that player from constantly raising before she or he can act because that cuts down on the reraiser's own stealing opportunities.
If one or more players have called a raise pre-flop, a player can re-raise as a bluff in what is called a squeeze play. The original raiser will need to have a premium holding to continue in the hand as several other players have shown signs of strength, and he may well be playing out of position. The players that have just called the original raise are unlikely to have very strong hands as they have not re-raised. 

</doc>
<doc id="23169" url="https://en.wikipedia.org/wiki?curid=23169" title="Dead money (poker)">
Dead money (poker)

In poker, dead money is the amount of money in the pot other than the equal amounts bet by active remaining players in that pot. Examples of dead money include money contributed to the pot by players who have folded, a dead blind posted by a player returning to a game after missing blinds, or an odd chip left in the pot from a previous deal. For example, eight players each ante $1, one player opens for $2, and gets two callers, making the pot total $14. Three players are now in the pot having contributed $3 each, for $9 "live" money; the remaining $5 (representing the antes of the players who folded) is dead money. The amount of dead money in a pot affects the pot odds of plays or rules of thumb that are based on the number of players.
The term "dead money" is also used in a derogatory sense to refer to money put in the pot by players who are still legally eligible to win it, but who are unlikely to do so because they are unskilled, increasing the expected return of other players. This can also be applied to the player himself: "Let's invite John every week; he's dead money". The term "dead money" also applies in tournaments, when many casual players enter events with virtually no chance of winning.

</doc>
<doc id="23170" url="https://en.wikipedia.org/wiki?curid=23170" title="Isolation (poker)">
Isolation (poker)

In poker, an isolation play is usually a raise designed to encourage one or more players to fold, specifically for the purpose of making the hand a one-on-one contest with a specific opponent. For example, if an opponent raises and a player suspects he is holding a weak, but playable hand, they may reraise to pressure other opponents to fold, with the aim of getting heads up with the opening raiser.
Isolation plays are most common against overly-aggressive players ("maniacs") who frequently play inferior hands, or with players who may have a drawing hand. Isolation plays are also common in tournaments to isolate a player who is "short stacked", that is, one who is in imminent danger of elimination, and so is likely to be playing aggressively out of desperation. However, when a player is extremely short stacked compared to the rest of the field in a tournament, making him bust will sometimes be more profitable than winning his chips, so inducing overcalls from other players trumps isolation play.
Isolating is encouraged when holding a hand that fares better heads up than in a multi-way pot. For instance, when a player has a small pocket pair he may raise a large amount simply to knock out other players because typically a small pocket pair is about 50–60% likely to win an all-in pot in a heads up situation, but less likely when facing multiple opponents.

</doc>
<doc id="23172" url="https://en.wikipedia.org/wiki?curid=23172" title="Freeroll">
Freeroll

In poker, a freeroll has two distinct meanings. One applies to the play of a single hand, and the other describes an entire poker tournament.
Freeroll hand.
In playing a particular hand of poker, a freeroll is a situation that arises (usually when only two players remain) before the last card has been dealt, in which one player is guaranteed to at least split the pot with his opponent no matter what the final cards are, but where there is some chance he can win the whole pot if certain final cards are dealt. This most commonly occurs in a high-low split game where one player knows that he has a guaranteed low hand made, his opponent cannot make a better low no matter what the last card is, but the player who is low might possibly catch a lucky card that gives him a straight or flush, winning high as well.
Here's an example from Texas hold'em: Angie holds , and Burt holds . After the fourth card is dealt, the board is . Both players have an ace-high straight, the current nut hand, and so they will most likely split the pot. But if the final card happens to be a club, Burt's straight will lose to Angie's flush. There is no other possible final card that will give Burt more than a split; only Angie can improve, so she is "freerolling" Burt.
If a player knows he has a freeroll, he can raise the pot with impunity, and often a less-skilled opponent with a good hand who does not realize that he is on the wrong end of the freeroll will continue to put in raises with no possible hope of gain.
Freeroll tournament.
A freeroll tournament is a tournament with no entry fee, although some freerolls require a payment at some point to gain entry to the tournament.
In a typical pay-to-play tournament, the prize pool consists of an accumulation of the entry fees minus a "fee" which is retained by the house. In a freeroll (at least from the players' perspective) the prize pool is essentially a "donation" provided by the house. Of course, in most freerolls the house is able defray a significant portion of the prize pool (or even turn a profit) by charging for food and beverages, sponsorship fees, admission to spectators, broadcast rights fees, or any combination of these. Sometimes a particular cardroom or casino (either traditional or online) will offer a freeroll tournament to frequent players. Invitation-only tournaments are frequently freerolls.
Freerolls at Internet poker sites should not be confused with their close counterpart -- play money tournaments. Freerolls are different from play-money tournaments in two respects. Play money tournaments usually require the 'payment' of play money and the tournament winnings are play money. Freeroll tournaments can be genuinely free, may require a payment of points (from a point system developed by the site), or on some occasions require a deposit of funds into the player's account. The winnings are either real money, points, merchandise or entry tickets (invitations) to other tournaments.
Most if not all Internet poker sites have freeroll tournaments although in many cases require a payment of points to play. These points typically can only be earned by paying and playing real money hands which in essence is a payment required to play their 'freerolls' and therefore a loose use of the term 'freeroll'. There are Internet sites that allow playing in freerolls without payment of any kind and with the chance to win real money.
It is not unusual to pay to play in a feeder tournament that gives the winner(s) a free entry to another tournament but it is debatable whether these second level tournaments can be called 'freerolls', since they require a buy-in, albeit smaller than the major tournament one. More often, such tournaments are called 'satellites'. This format is typical of freeroll tournaments both on the Internet and in the 'brick and mortar' sites. 
The Professional Poker Tour is one such 'freeroll', with entrants being required to qualify through their results in previous tournaments. Sponsorship and broadcast-rights fees fund the prize pools.
Freeroll tournaments are not exclusive to poker. Casinos frequently offer them to frequent and/or high-value players in games such as craps, blackjack, video poker and slot machines.
Origin of the term.
Many believe the term comes from early 1950s Las Vegas, when guests would often be given a "free roll" of nickels to play at the slot machines upon check-in. Guests would often ask for their "free rolls" and the words became fused together and expanded to mean any complimentary gaming bonus.

</doc>
<doc id="23173" url="https://en.wikipedia.org/wiki?curid=23173" title="Starting hand">
Starting hand

In poker, the starting hand is the initial set of cards dealt to each player before any voluntary betting takes place. For example, in seven-card stud this is two downcards and one upcard; in Texas hold 'em it is two downcards; in five-card draw it is five cards.
The one decision made by every poker player on every deal of every game is whether to continue playing that hand after seeing that first set of cards. Since making this decision correctly will lead to the most long-run profit for a skilled player, players often put considerable study into what the appropriate starting hand "standards" are for the game being played.
Optimal starting hand standards can be very sensitive to factors such as the betting structure of a game, position, and the character of the other players, as well as the rules of the game being played.

</doc>
<doc id="23174" url="https://en.wikipedia.org/wiki?curid=23174" title="Omaha hold 'em">
Omaha hold 'em

Omaha hold 'em (also known as Omaha holdem or simply Omaha) is a community card poker game similar to Texas hold 'em, where each player is dealt four cards and must make his or her best hand using exactly two of them, plus exactly three of the five community cards. The exact origin of the game is unknown, but casino executive Robert Turner first brought Omaha into a casino setting when he introduced the game to Bill Boyd, who offered it as a game at the Las Vegas Golden Nugget Casino (calling it "Nugget Hold'em"). Omaha uses a 52-card French deck. Limit Omaha hold 'em 8-or-better is the "O" game featured in H.O.R.S.E. Both limit Omaha/8 and pot limit Omaha high are featured in the 8-Game.
History.
Omaha Hold'em gets its name from two types of games.
In the original Omaha poker game, players were only dealt two hole cards and had to use both to make a hand combined with community cards. This version of Omaha is defined in the glossary of "Super/System" (under Omaha) as being interchangeable with "Tight Holdem". Across all the variations of the game, the requirement of using exactly two hole cards is the only consistent rule. The "Omaha" part of the name represents this aspect of the game.
"Hold'em" refers to a game using community cards that are shared by all players. This is opposed to Draw games where each player's hand is composed only by hole cards and Stud games where each player hand contains both non-community cards that are visible to the other players and concealed hole cards.
Explanation.
In North American casinos, the term "Omaha" can refer to several poker games. The original game is also commonly known as "Omaha high". A high-low split version called "Omaha Hi-Lo", or sometimes "Omaha eight-or-better" or "Omaha/8", is also played. In Europe, "Omaha" still typically refers to the high version of the game, usually played pot-limit. Pot-limit Omaha is often abbreviated as "PLO." Pot-limit and no-limit Omaha eight-or-better can be found in some casinos and online, though no-limit is rarer.
It is often said that Omaha is a game of "the nuts", i.e. the best possible high or low hand, because it frequently takes "the nuts" to win a showdown. It is also a game where between the cards in his hand and the community cards a player may have drawing possibilities to multiple different types of holdings. For example, a player may have both a draw to a flush and a full house using different combinations of cards. At times, even seasoned players may need additional time to figure what draws are possible for their hand.
The basic differences between Omaha and Texas hold 'em are these: first, each player is dealt four hole cards instead of two. The betting rounds and layout of community cards are identical. At showdown, each player's hand is the best five-card hand made from "exactly three" of the five cards on the board, plus "exactly two" of the player's own cards. Unlike Texas hold 'em, a player cannot play four or five of the cards on the board with fewer than two of his own, nor can a player use three or four hole cards to disguise a strong hand.
Some specific things to notice about Omaha hands are:
Omaha hi-low split-8 or better.
In Omaha hi-low split-8 or better (simply Omaha/8), each player makes a separate five-card high hand and five-card ace-to-five low hand (eight-high or lower to qualify), and the pot is split between the high and low (which may be the same player). To qualify for low, a player must be able to play an 8-7-6-5-4 or lower (this is why it is called "eight or better"). A few casinos play with a 9-low qualifier instead, but this is rare. Each player can play any two of his four hole cards to make his high hand, and any two of his four hole cards to make his low hand. If there is no qualifying low hand, the high hand wins ("scoops") the whole pot. This game is usually played in the fixed limit version, although pot limit Omaha/8 is becoming more popular. A few low-stakes online tournaments feature no limit Omaha/8.
The brief explanation above belies the complexity of the game, so a number of examples will be useful here to clarify it. The table below shows a five-card board of community cards at the end of play, and then lists for each player the initial private four-card hand dealt to him or her, and the best five-card high hand and low hand each player can play on showdown:
In the deal above, Chris wins the high-hand half of the pot with his J-high straight, and Bryan and Eve split the low half (getting a quarter of the pot each) with 7-5-3-2-A.
Some specific things to notice about Omaha/8 hands are:
Pot-limit Omaha.
Pot-limit Omaha (shortened to PLO) is popular in Europe, online, and in high-stakes "mixed games" played in some American casinos. It is more often played high only, but can also be played high-low. Even more so than Limit Omaha Hi-Lo, PLO is a game of drawing, if you are drawing, to the nut hand. Second best flushes and straights can be, and frequently are, beaten. Furthermore, because of the exponential growth of the pot size in pot-limit play, seeing one of these hands to the end can be very expensive and carry immense reverse implied odds.
Wraps.
In poker, an out is any unseen card in the deck that will give a player the best hand. A wrap is a straight draw with 9 or more outs. It’s called a wrap because the player’s hole cards are said to wrap-around the board cards. In hold-em, where players have 2 hole cards, the most straight outs possible is 8. But in Omaha, there are 4 hole cards and this results in straight draws that can have up to 20 outs. An example of a twenty out wrap is on a flop of . To hit a straight one of the following cards is needed: .
Redraws.
A desirable hand to have in PLO is the current best hand with a redraw. For example, if the board is , and the player has , then not only do they have the current best hand possible (their ace-king makes the ace-high straight), but they also have a redraw with the two queens in their hand because if the board pairs, they will make a full house, or four queens. would be an even better hand because it has flush and royal flush redraws as well. In fact, with the board, is approximately an 80-20 money favorite over a random hand containing ace-king (see freerolling). Even a pair of queens with any two spades is better than 55-45 against a random ace-king hand.
Omaha Variations.
The most common variations of Pot Limit Omaha high are Five-card Omaha, commonly referred as "Big O" very popular in Southeastern United States as a home game and Six-card Omaha or 6-O which can be found in many casinos across the UK. Some online poker rooms support Five-card Omaha, Six-card Omaha and Courchevel.
"Big O" (occasionally called Five-card Omaha or 5-O) began appearing in Southern California in 2008, and had spread to most of the card rooms in the area by the end of the year.
Sometimes the high-low split game is played with a 9 or a 7-high qualifier instead of 8-high. It can also be played with five cards dealt to each player instead of four. In that case, the same rules for making a hand apply: exactly two from the player's hand, and exactly three from the board.
Courchevel.
In the game of Courchevel, players are dealt five hole cards rather than four. Simultaneously, the first community card is dealt. Following an opening round of betting, two additional community cards are dealt, creating a 3-card flop, where the structure of the game is then identical to standard Omaha. Still, exactly two of the five hole cards must be used. Courchevel is popular in France but its popularity has expanded in other parts of Europe, particularly the United Kingdom.

</doc>
<doc id="23184" url="https://en.wikipedia.org/wiki?curid=23184" title="Aggression (poker)">
Aggression (poker)

In the game of poker, opens and raises are considered aggressive plays, while calls and checks are considered passive (though a check-raise would be considered a very aggressive play). It is said that "aggression has its own value", meaning that often aggressive plays can make money with weak hands because of bluff value. In general, opponents must respond to aggressive play by playing more loosely, which offers more opportunities to make mistakes.
While it is true that aggressive play is generally superior to passive play, using any play exclusively can lead to predictability. A player who is constantly aggressive and plays many inferior hands is called a "maniac", and skilled players will take advantage of him by calling him more often, using isolation plays, and by other means.
If a player is not aggressive with his weaker hands, the opponents can safely fold whenever the player does bet or raise. The appropriate amount of aggression can be computed using game theory, and depends on the game being played and the tendencies of the opponents.
Most theorists, like David Sklansky and Doyle Brunson, suggest aggression as an important tool. Aggressive play should not be confused with loose play. Loose players may play passively, resulting in a calling station, while tight players may play aggressively, referred to as a TAG. Aggression is called for in particular circumstances. Very strong starting hands should be played very aggressively most of the time. A very strong propositional hand – one that is more likely to win with a straight or a flush – is one of the hands that can be played for effect with an aggressive style. Such aggression is deceptive, as the low and unpaired ranks of the starting hand require much improvement to win. This is beneficial for two reasons:
The second reasoning is what is known as "advertising" in poker. It can be very profitable for a player to convince the other players at the table that he is willing to gamble with less than premium cards. The result is larger pots when the aggressive player has tremendously strong hands.

</doc>
<doc id="23189" url="https://en.wikipedia.org/wiki?curid=23189" title="Shuffling">
Shuffling

Shuffling is a procedure used to randomize a deck of playing cards to provide an element of chance in card games. Shuffling is often followed by a cut, to help ensure that the shuffler has not manipulated the outcome.
__TOC__
Shuffling techniques.
Overhand shuffle.
One of the easiest shuffles to accomplish, the overhand or stripping shuffle is essentially a series of cuts. A group of cards on the bottom (or top) of the deck grasped between the thumb on one side and fingers on the other, lifted sideways out of the deck, and then placed on the top (or bottom). This process is repeated multiple times with random selections of cards in order to randomize them.
The overhand shuffle offers sufficient opportunity for sleight of hand techniques to be used to affect the ordering of cards, creating a stacked deck. The most common way that players cheat with the overhand shuffle is by having a card at the top or bottom of the pack that they require, and then slipping it to the bottom at the start of a shuffle (if it was on top to start), or leaving it as the last card in a shuffle and just dropping it on top (if it was originally on the bottom of the deck).
Riffle.
A common shuffling technique is called the "riffle" or "dovetail" shuffle, in which half of the deck is held in each hand with the thumbs inward, then cards are released by the thumbs so that they fall to the table interleaved. Many also lift the cards up after a riffle, forming what is called a bridge which puts the cards back into place. This can also be done by placing the halves flat on the table with their rear corners touching, then lifting the back edges with the thumbs while pushing the halves together. While this method is more difficult, it is often used in casinos because it minimizes the risk of exposing cards during the shuffle. There are two types of perfect riffle shuffles: if the top card moves to be second from the top then it is an in shuffle, otherwise it is known as an out shuffle (which preserves both the top and bottom cards).
Riffle shuffling does, however, carry a risk of damaging cards from excessive bending. Casinos replace their playing cards often to prevent players from gaining an advantage by detecting deformations in the cards. However, collectible card game cards are considerably less replaceable than playing cards, and CCG cards can be damaged from riffle shuffling, even when protected with card sleeves.
The Gilbert–Shannon–Reeds model provides a mathematical model of the random outcomes of riffling, that has been shown experimentally to be a good fit to human shuffling and that forms the basis for a recommendation that card decks be riffled seven times in order to thoroughly randomize them.
Hindu shuffle.
Also known as the "Indian", "Kattar", "Kenchi" or "Kutti Shuffle" (Hindi for scissor). The deck is held face down, with the middle finger on one long edge and the thumb on the other on the bottom half of the deck. The other hand draws off a packet from the top of the deck. This packet is allowed to drop into the palm. The maneuver is repeated over and over, with newly drawn packets dropping onto previous ones, until the deck is all in the second hand. Indian shuffle differs from stripping in that all the action is in the hand "taking" the cards, whereas in stripping, the action is performed by the hand with the original deck, "giving" the cards to the resulting pile. This is the most common shuffling technique in Asia and other parts of the world, while the overhand shuffle is primarily used in Western countries.
Pile shuffle.
Cards are simply dealt out into a number of piles, then the piles are stacked on top of each other. Though this is deterministic and does not randomize the cards at all, this ensures that cards that were next to each other are now separated. For any number of piles, the right number of repetitions will bring the deck back to its original state. Some variations on the pile shuffle attempt to make it slightly random by dealing to the piles in a random order each circuit.
Corgi shuffle.
Also known as the Chemmy, Irish, scramble, beginner shuffle, or washing the cards, this involves simply spreading the cards out face down, and sliding them around and over each other with one's hands. Then the cards are moved into one pile so that they begin to intertwine and are then arranged back into a stack. This method is useful for beginners and small children or if one is inept at shuffling cards. However, the beginner shuffle requires a large surface for spreading out the cards and takes longer than the other methods.
Mongean shuffle.
The Mongean shuffle, or Monge's shuffle, is performed as follows (by a right-handed person): Start with the unshuffled deck in the left hand and transfer the top card to the right. Then repeatedly take the top card from the left hand and transfer it to the right, putting the second card at the top of the new deck, the third at the bottom, the fourth at the top, the fifth at the bottom, etc. The result, if one started with cards numbered consecutively formula_1, would be a deck with the cards in the following order: formula_2.
For a deck of given size, the number of Mongean shuffles that it takes to return a deck to starting position, is known . Twelve perfect Mongean shuffles restore a 52-card deck.
Weave and Faro shuffles.
"Weaving" is the procedure of pushing the ends of two halves of a deck against each other in such a way that they naturally intertwine. Sometimes the deck is split into equal halves of 26 cards which are then pushed together in a certain way so as to make them perfectly interweave. This is known as a "Faro Shuffle".
The faro shuffle is performed by cutting the deck into two, preferably equal, packs in both hands as follows (right-handed):
The cards are held from above in the right and from below in the left hand. Separation of the deck is done simply lifting up half the cards with the right hand thumb slightly and pushing the left hand's packet forward away from the right hand. The two packets are often crossed and slammed into each other as to align them. They are then pushed together by the short sides and bent (either up or down). The cards then alternately fall into each other, much like a zipper. A flourish can be added by springing the packets together by applying pressure and bending them from above. The faro is a controlled shuffle which does not randomize a deck when performed properly.
A perfect faro shuffle, where the cards are perfectly alternated, is considered one of the most difficult sleights by card magicians, simply because it requires the shuffler to be able to cut the deck into two equal packets and apply just the right amount of pressure when pushing the cards into each other. Performing eight perfect faro shuffles in a row restores the order of the deck to the original order only if there are 52 cards in the deck and if the original top and bottom cards remain in their positions (1st and 52nd) during the eight shuffles. If the top and bottom cards are weaved in during each shuffle, it takes 52 shuffles to return the deck back into original order (or 26 shuffles to reverse the order).
Mexican spiral shuffle.
The Mexican spiral shuffle is performed by cyclic actions of moving the top card onto the table, then the new top card under the deck, the next onto the table, next under the deck, and so on until the last card is dealt onto the table. It takes quite a long time, compared with riffle or overhand shuffles, but allows other players to fully control cards which are on the table. The Mexican spiral shuffle was popular at the end of the 19th century in some areas of Mexico as a protection from gamblers and con men arriving from the United States.
False shuffles.
Magicians, sleight-of-hand artists, and card cheats employ various methods of shuffling whereby the deck appears to have been shuffled fairly, when in reality one or more cards (up to and including the entire deck) stays in the same position. It is also possible, though generally considered very difficult, to "stack the deck" (place cards into a desirable order) by means of one or more riffle shuffles; this is called "riffle stacking".
Both performance magicians and card sharps regard the Zarrow shuffle as a particularly effective example of the false shuffle. In this shuffle, the entire deck remains in its original order, although spectators think they see an honest riffle shuffle.
Shuffling machines.
Casinos often equip their tables with shuffling machines instead of having croupiers shuffle the cards, as it gives the casino a few advantages, including an increased complexity to the shuffle and therefore an increased difficulty for players to make predictions, even if they're collaborating with croupiers. The shuffling machines are carefully designed to avoid biasing the shuffle and are typically computer-controlled. Shuffling machines also save time that would otherwise be wasted on manual shuffling, thereby increasing the profitability of the table. These machines are also used to lessen repetitive-motion-stress injuries to a dealer.
Players with superstitions often regard with suspicion any electronic equipment, so casinos sometimes still have the croupiers perform the shuffling at tables that typically attract those crowds (Baccarat tables).
Randomization.
There are exactly 52 factorial (expressed in shorthand as 52!) possible orderings of the cards in a 52-card deck. In other words, there are 52 × 51 × 50 × 49 × ··· × 4 × 3 × 2 × 1 possible combinations of card sequence. This is approximately 8 possible orderings or specifically 80,658,175,170,943,878,571,660,636,856,403,766,975,289,505,440,883,277,824,000,000,000,000. The magnitude of this number means that it is exceedingly improbable that two randomly selected, truly randomized decks will be the same. However, while the exact sequence of all cards in a randomized deck is unpredictable, it may be possible to make some probabilistic predictions about a deck that is not sufficiently randomized.
Sufficient number of shuffles.
The number of shuffles which are sufficient for a "good" level of randomness is a fundamental question, and the answer depends on the type of shuffle and the measure of "good enough randomness", which in turn depends on the game in question. Broadly, for most games, four to seven good riffle shuffles (GRS) are both necessary and sufficient: for unsuited games such as blackjack, four GRSs are sufficient, while for suited games with strict conditions on randomness, seven GRSs are necessary. There are some games, however, for which even seven GRSs are insufficient.
In practice the number of shuffles required depends both on the quality of the shuffle and how significant non-randomness is, particularly how good the people playing are at noticing and using non-randomness. Two to four shuffles is good enough for casual play. But in club play, good bridge players take advantage of non-randomness after four shuffles, and top blackjack players supposedly track aces through the deck; this is known as "ace tracking", or more generally, as "shuffle tracking".
Research.
Following early research at Bell Labs, which was abandoned in 1955, the question of how many shuffles was required remained open until 1990, when it was convincingly solved as "seven shuffles," as elaborated below. Some results preceded this, and refinements have continued since.
A leading figure in the mathematics of shuffling is mathematician and magician Persi Diaconis, who began studying the question around 1970, and has authored many papers in the 1980s, 1990s, and 2000s on the subject with numerous co-authors. Most famous is , co-authored with mathematician Dave Bayer, which analyzed the Gilbert–Shannon–Reeds model of random riffle shuffling and concluded that the deck did not start to become random until five good riffle shuffles, and was truly random after seven, in the precise sense of variation distance described in Markov chain mixing time; of course, you would need more shuffles if your shuffling technique is poor. Recently, the work of Trefethen et al. has questioned some of Diaconis' results, concluding that six shuffles are enough. The difference hinges on how each measured the randomness of the deck. Diaconis used a very sensitive test of randomness, and therefore needed to shuffle more. Even more sensitive measures exist, and the question of what measure is best for specific card games is still open. Diaconis released a response indicating that you only need four shuffles for un-suited games such as blackjack.
On the other hand, variation distance may be too forgiving a measure and seven riffle shuffles may be many too few. For example, seven shuffles of a new deck leaves an 81% probability of winning New Age Solitaire where the probability is 50% with a uniform random deck. One sensitive test for randomness uses a standard deck without the jokers divided into suits with two suits in ascending order from ace to king, and the other two suits in reverse. (Many decks already come ordered this way when new.) After shuffling, the measure of randomness is the number of rising sequences that are left in each suit.
Shuffling algorithms.
If a computer has access to purely random numbers, it is capable of generating a "perfect shuffle", a random permutation of the cards; beware that this terminology (an algorithm that perfectly randomizes the deck) differs from "a perfectly executed single shuffle", notably a perfectly interleaving faro shuffle. The Fisher–Yates shuffle, popularized by Donald Knuth, is simple (a few lines of code) and efficient (O("n") on an "n"-card deck, assuming constant time for fundamental steps) algorithm for doing this. Shuffling can be seen as the opposite of sorting.
There are other, less-desirable algorithms in common use. For example, one can assign a random number to each card, and then sort the cards in order of their random numbers. This will generate a random permutation, unless any of the random numbers generated are the same as any others (i.e. pairs, triplets etc.). This can be eliminated either by adjusting one of the pair's values randomly up or down by a small amount, or reduced to an arbitrarily low probability by choosing a sufficiently wide range of random number choices. If using efficient sorting such as mergesort or heapsort this is an O("n" log "n") average and worst-case algorithm.
In online gambling.
These issues are of considerable commercial importance in online gambling, where the randomness of the shuffling of packs of simulated cards for online card games is crucial. For this reason, many online gambling sites provide descriptions of their shuffling algorithms and the sources of randomness used to drive these algorithms, with some gambling sites also providing auditors' reports of the performance of their systems.
External links.
Physical card shuffling:
Mathematics of shuffling:
Real world (historical) application:

</doc>
<doc id="23190" url="https://en.wikipedia.org/wiki?curid=23190" title="Cut (cards)">
Cut (cards)

After a deck of playing cards is shuffled by the dealer, it is often given to a player other than the one who performed the shuffle for a procedure called a cut. This is not to be confused with cut cards which are used in casino poker games.
Procedure.
The dealer completes the shuffle, and then sets the cards face-down on the table near the designated player, typically the player to the dealer's right. The player cuts the deck by removing a contiguous range of cards from the deck, and places them toward himself so that the stack of cards to be dealt is closest to the dealer. The simplest form of the cut is done by taking, roughly, the top one-half of the cards, and placing them on the table or a cut card. Either the player cutting or the dealer then completes the cut by placing the remaining bottom portion on top of the cards that have been cut off. 
Once the cut is complete, the dealer then picks up the deck, straightens or "squares" it, then deals the cards.
Etiquette.
The contiguous section may also be taken from the middle of the deck. This is called "Scarne's cut", though in some settings this is considered poor etiquette or against the rules. A cut involving a very small number of cards, such as taking only the top card (or some cards from the bottom) as a cut, is often acceptable according to rules. The same is true when a player takes every top card save for one on the cut.
During informal card games, the dealer is typically not required to offer the cut, and even if offered, the designated player can decline the request. On the other hand, any player may specifically request to cut the cards before they are dealt. If a cut is requested by a player, it must be granted by the dealer.
In formal player dealt settings, such as in a casino or during a tournament, an offer to cut the deck is mandatory and the designated player must perform the cut, generally by inserting a cut card (a plastic card about the size of a playing card, usually solid-colored) into the deck; the dealer then makes the actual cut at that point in the deck. When the dealer is not a player (i.e. a casino employee), the cut is mandatory and is usually performed by the dealer. In this instance, the deck is cut onto the aforementioned cut card, and the cut completed; this prevents players from seeing the bottom card of the deck.
A cut should always be completed with one hand to limit possibility of a false cut.
Scarne's cut.
Scarne's cut was developed by John Scarne during WWII to help protect servicemen against cheating by unscrupulous dealers. First one pulls out a portion of the middle of the stack and places it back on top of the deck; one then performs a regular cut described earlier.
Reasons.
The practice of cutting is primarily a method of reducing the likelihood of someone cheating by manipulating the order of cards to gain advantage. Even if the dealer does not plan on cheating, cutting will prevent suspicions, thus many rules require it. Some players also consider the cut to be lucky.
Multiple cuts.
It can be demonstrated that multiple top-to-bottom (non-Scarne's) cuts are equivalent to some single cut. In fact, knowing the size of the deck and the size of the cuts, the formula for the composite single cut is given as the sum of the sizes of the cuts modulo the size of the deck. For example, in a 10 card deck, if a 7 card cut and a 4 card cut are made, that is, 7 cards are moved from the top of the deck to the bottom and then the resulting top 4 cards are also moved to the bottom, then those two consecutive cuts are equivalent to a cut the size of (7 + 4 = 11 (mod 10)) = 1. The deck will be in the order (2,3...,10,1).
False cut.
A false cut is a move used either in magic, or for cheating when playing card games. It appears to be a real cut, but leaves the deck in the same order as when it began. More sophisticated versions may make specific desired changes to the deck's order, while still appearing to be an innocuous normal cut.
There are many ways to accomplish a false cut, involving misdirection or using complex moves to conceal the real result.
As a game.
Cutting cards is usually a prelude to a game, but it can be a game unto itself. Each player, in turn, removes a selection of cards from the top and reveals the bottom card to all the players, and then replaces the cards in the original position. Whoever has revealed the highest (or sometimes lowest) card is the winner. This is often used in an informal setting, much like flipping coins; it is also sometimes used to determine who will play first in a card game.
As a joke.
The command to "cut the cards", following by someone literally chopping the deck in half with an axe, is a none-too-subtle gag that has been used many times in popular media, going back to at least the vaudeville days. Examples include Harpo Marx in "Horse Feathers", Curly Howard in "Ants in the Pantry", and Bugs Bunny in "Bugs Bunny Rides Again".

</doc>
<doc id="23193" url="https://en.wikipedia.org/wiki?curid=23193" title="Philology">
Philology

Philology is the study of language in written historical sources; it is a combination of literary criticism, history, and linguistics. It is more commonly defined as the study of literary texts and written records, the establishment of their authenticity and their original form, and the determination of their meaning. A person who pursues this kind of study is known as a philologist.
Classical philology is the philology of classical languages. Historically Classical philology originated principally from the Library of Pergamum and the Library of Alexandria around the 4th century BCE, continued by Greeks and Romans throughout the Roman and Byzantine Empires, preserved and promoted during the Islamic Golden Age and eventually again taken up by European scholars of the Renaissance, where it was soon joined by philologies of other non-Asian (European) (Germanic, Celtic), Eurasian (Slavistics, etc.) and Asian (Sanskrit, Persian, Arabic, Chinese, etc.) languages. Indo-European studies involves the comparative philology of all Indo-European languages.
Any classical language can be studied philologically, and indeed describing a language as "classical" is to imply the existence of a philological tradition associated with it.
Philology, with its focus on historical development (diachronic analysis), became contrasted with linguistics due to Ferdinand de Saussure's insistence on the importance of synchronic analysis. The contrast continued with the later emergence of structuralism and Chomskyan linguistics alongside its emphasis on syntax.
Etymology.
The term "philology" is derived from the Greek ("philologia"), from the terms ("philos"), meaning "love, affection, loved, beloved, dear, friend" and ("logos"), meaning "word, articulation, reason", describing a love of learning, of literature as well as of argument and reasoning, reflecting the range of activities included under the notion of . The term changed little with the Latin "philologia", and later entered the English language in the 16th century, from the Middle French "philologie", in the sense of "love of literature".
The adjective ("philologos") meant "fond of discussion or argument, talkative", in Hellenistic Greek also implying an excessive ("sophistic") preference of argument over the love of true wisdom, ("philosophos").
As an allegory of literary erudition, "Philologia" appears in 5th-century post-classical literature (Martianus Capella, "De nuptiis Philologiae et Mercurii"), an idea revived in Late Medieval literature (Chaucer, Lydgate).
The meaning of "love of learning and literature" was narrowed to "the study of the historical development of languages" (historical linguistics) in 19th-century usage of the term. Due to the rapid progress made in understanding sound laws and language change, the "golden age of philology" lasted throughout the 19th century, or "from Giacomo Leopardi and Friedrich Schlegel to Nietzsche". In the Anglo-Saxon world, the term philology to describe work on languages and literatures, which had become synonymous with the practices of German scholars, was abandoned as a consequence of anti-German feeling following World War I. Most continental European countries still maintain the term to designate departments, colleges, position titles, and journals. J. R. R. Tolkien opposed the nationalist reaction against philological practices, claiming that "the philological instinct" was "universal as is the use of language". In British English usage, and in British academia, "philology" remains largely synonymous with "historical linguistics", while in US English, and US academia, the wider meaning of "study of a language's grammar, history and literary tradition" remains more widespread. Based on the harsh critique of Friedrich Nietzsche, US scholars since the 1980s have viewed philology as responsible for a narrowly scientistic study of language and literature.
Branches.
Comparative.
The comparative linguistics branch of philology studies the relationship between languages. Similarities between Sanskrit and European languages were first noted in the early 16th century and led to speculation of a common ancestor language from which all these descended. It is now named Proto-Indo-European. Philology's interest in ancient languages led to the study of what were, in the 18th century, "exotic" languages, for the light they could cast on problems in understanding and deciphering the origins of older texts.
Textual.
Philology also includes the study of texts and their history. It includes elements of textual criticism, trying to reconstruct an author's original text based on variant copies of manuscripts. This branch of research arose among Ancient scholars in the 4th century BC Greek-speaking world, who desired to establish a standard text of popular authors for the purposes of both sound interpretation and secure transmission. Since that time, the original principles of textual criticism have been improved and applied to other widely distributed texts such as the Bible. Scholars have tried to reconstruct the original readings of the Bible from the manuscript variants. This method was applied to Classical Studies and to medieval texts as a way to reconstruct the author's original work. The method produced so-called "critical editions", which provided a reconstructed text accompanied by a "critical apparatus", i.e., footnotes that listed the various manuscript variants available, enabling scholars to gain insight into the entire manuscript tradition and argue about the variants.
A related study method known as higher criticism studies the authorship, date, and provenance of text to place such text in historical context. As these philological issues are often inseparable from issues of interpretation, there is no clear-cut boundary between philology and hermeneutics. When text has a significant political or religious influence (such as the reconstruction of Biblical texts), scholars have difficulty reaching objective conclusions.
Some scholars avoid all critical methods of textual philology, especially in historical linguistics, where it is important to study the actual recorded materials. The movement known as New Philology has rejected textual criticism because it injects editorial interpretations into the text and destroys the integrity of the individual manuscript, hence damaging the reliability of the data. Supporters of New Philology insist on a strict "diplomatic" approach: a faithful rendering of the text exactly as found in the manuscript, without emendations.
Cognitive.
Another branch of philology, cognitive philology, studies written and oral texts, considering them as results of human mental processes. This science compares the results of textual science with the results of experimental research of both psychology and artificial intelligence production systems.
Decipherment.
In the case of Bronze Age literature, philology includes the prior decipherment of the language under study.
This has notably been the case with the Egyptian, Sumerian, Assyrian, Hittite, Ugaritic and Luwian languages. Beginning with the famous decipherment and translation of the Rosetta Stone by Jean-François Champollion in 1822, a number of individuals attempted to decipher the writing systems of the Ancient Near East and Aegean. In the case of Old Persian and Mycenaean Greek, decipherment yielded older records of languages already known from slightly more recent traditions (Middle Persian and Alphabetic Greek).
Work on the ancient languages of the Near East progressed rapidly. In the mid-19th century, Henry Rawlinson and others deciphered the Behistun Inscription, which records the same text in Old Persian, Elamite, and Akkadian, using a variation of cuneiform for each language. The elucidation of cuneiform led to the decipherment of Sumerian. Hittite was deciphered in 1915 by Bedřich Hrozný.
Linear B, a script used in the ancient Aegean, was deciphered in 1952 by Michael Ventris, who demonstrated that it recorded an early form of Greek, now known as Mycenaean Greek. Linear A, the writing system that records the still-unknown language of the Minoans, resists deciphering, despite many attempts.
Work continues on scripts such as the Maya, with great progress since the initial breakthroughs of the phonetic approach championed by Yuri Knorozov and others in the 1950s. Since the late 20th century, the Maya code has been almost completely deciphered, and the Mayan languages are among the most documented and studied in Mesoamerica. The code is described as a logosyllabic style of writing, which could be used to fully express any spoken thought.
In popular culture.
The main character in the Academy Award Nominee for Best Foreign Language film in 2012, "Footnote", is a Hebrew philologist, and a significant part of the film deals with his work.
Moritz-Maria von Igelfeld, the main character in Alexander McCall Smith's 1997 comic novel "Portuguese Irregular Verbs" is a philologist, educated at Cambridge.
In the Space Trilogy by C.S. Lewis, the main character, Elwin Ransom, is a philologist.

</doc>
<doc id="23194" url="https://en.wikipedia.org/wiki?curid=23194" title="Phonetics">
Phonetics

Phonetics (pronounced , from the , "phōnē", 'sound, voice') is a branch of linguistics that comprises the study of the sounds of human speech, or—in the case of sign languages—the equivalent aspects of sign. It is concerned with the physical properties of speech sounds or signs (phones): their physiological production, acoustic properties, auditory perception, and neurophysiological status. Phonology, on the other hand, is concerned with the abstract, grammatical characterization of systems of sounds or signs.
The field of phonetics is a multilayered subject of linguistics that focuses on speech. In the case of oral languages there are three basic areas of study:
These areas are inter-connected through the common mechanism of sound, such as wavelength (pitch), amplitude, and harmonics.
History.
Phonetics was studied by 4th century BCE, and possibly as early as the 6th century BCE, in the Indian subcontinent, with Pāṇini's account of the place and manner of articulation of consonants in his treatise on Sanskrit. The major Indic alphabets today order their consonants according to Pāṇini's classification.
Modern phonetics begins with attempts—such as those of Joshua Steele (in "Prosodia Rationalis", 1779) and Alexander Melville Bell (in "Visible Speech", 1867)—to introduce systems of precise notation for speech sounds.
The study of phonetics grew quickly in the late 19th century partly due to the invention of the phonograph, which allowed the speech signal to be recorded. Phoneticians were able to replay the speech signal several times and apply acoustic filters to the signal. By doing so, they were able to more carefully deduce the acoustic nature of the speech signal.
Using an Edison phonograph, Ludimar Hermann investigated the spectral properties of vowels and consonants. It was in these papers that the term "formant" was first introduced. Hermann also played vowel recordings made with the Edison phonograph at different speeds in order to test Willis', and Wheatstone's theories of vowel production.
Relation to phonology.
In contrast to phonetics, phonology is the study of how sounds and gestures pattern in and across languages, relating such concerns with other levels and aspects of language. Phonetics deals with the articulatory and acoustic properties of speech sounds, how they are produced, and how they are perceived. As part of this investigation, phoneticians may concern themselves with the physical properties of meaningful sound contrasts or the social meaning encoded in the speech signal (socio-phonetics) (e.g. gender, sexuality, ethnicity, etc.). However, a substantial portion of research in phonetics is not concerned with the meaningful elements in the speech signal.
While it is widely agreed that phonology is grounded in phonetics, phonology is a distinct branch of linguistics, concerned with sounds and gestures as abstract units (e.g., distinctive features, phonemes, morae, syllables, etc.) and their conditioned variation (via, e.g., allophonic rules, constraints, or derivational rules). Phonology relates to phonetics via the set of distinctive features, which map the abstract representations of speech units to articulatory gestures, acoustic signals, and/or perceptual representations.
Subfields.
Phonetics as a research discipline has three main branches:
Transcription.
Phonetic transcription is a system for transcribing sounds that occur in a language, whether oral or sign. The most widely known system of phonetic transcription, the International Phonetic Alphabet (IPA), provides a standardized set of symbols for oral phones. The standardized nature of the IPA enables its users to transcribe accurately and consistently the phones of different languages, dialects, and idiolects. The IPA is a useful tool not only for the study of phonetics, but also for language teaching, professional acting, and speech pathology.
Applications.
Applications of phonetics include:
Practical phonetic training.
Studying phonetics involves not only learning theoretical material but also undergoing training in the production and perception of speech sounds. The latter is often known as "ear-training". Students must learn control of articulatory variables and develop their ability to recognize fine differences between different vowels and consonants. As part of the training, they must become expert in using phonetic symbols, usually those of the International Phonetic Alphabet.

</doc>
