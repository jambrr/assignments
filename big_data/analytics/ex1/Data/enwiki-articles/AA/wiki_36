<doc id="2736" url="https://en.wikipedia.org/wiki?curid=2736" title="Andalusia">
Andalusia

Andalusia (; ) is a south-western European region established as an autonomous community of the Kingdom of Spain. It is the most populated and the second largest in area of the autonomous communities in Spain. The Andalusian autonomous community is officially recognised as a nationality of Spain. The territory is divided into eight provinces: Almería, Cádiz, Córdoba, Granada, Huelva, Jaén, Málaga and Seville. Its capital is the city of Seville (Spanish: "Sevilla").
Andalusia is in the south of the Iberian peninsula, immediately south of the autonomous communities of Extremadura and Castile–La Mancha; west of the autonomous community of Murcia and the Mediterranean Sea; east of Portugal and the Atlantic Ocean; and north of the Mediterranean Sea and the Strait of Gibraltar. Andalusia is the only European region with both Mediterranean and Atlantic coastlines. The small British overseas territory of Gibraltar shares a three-quarter-mile land border with the Andalusian province of Cádiz at the eastern end of the Strait of Gibraltar.
The main mountain ranges of Andalusia are the Sierra Morena and the Baetic System, consisting of the Subbaetic and Penibaetic Mountains, separated by the Intrabaetic Basin. In the north, the Sierra Morena separates Andalusia from the plains of Extremadura and Castile–La Mancha on Spain's Meseta Central. To the south the geographic subregion of Upper Andalusia lies mostly within the Baetic System, while Lower Andalusia is in the Baetic Depression of the valley of the Guadalquivir.
The name "Andalusia" is derived from the Arabic word "Al-Andalus" (الأندلس) and this term derives in turn from an older word: Vandalusia or land of the Vandals. As well as Muslim and Romani influences, the region's history and culture have been influenced by the earlier Iberians, Carthaginians/Phoenicians, Greeks, Romans, Vandals, Visigoths, Byzantines, as well as the later Castilian and other Christian North Iberian nationalities who conquered and repopulated the area in the latter phases of the "Reconquista". 
Andalusia has been a traditionally agricultural region, compared to the rest of Spain and the rest of Europe. However, the growth of the community especially in the sectors of industry and services was above average in Spain and higher than many communities in the eurozone. The region has, however, a rich culture and a strong cultural identity. Many cultural phenomena that are seen internationally as distinctively Spanish are largely or entirely Andalusian in origin. These include flamenco, bullfighting, and certain Moorish-influenced architectural styles.
Andalusia's interior is the hottest area of Europe, with cities like Córdoba and Seville averaging above 36 °C (97 °F) in summer high temperatures. Late evening temperatures can sometimes stay around 35 °C (95 °F) up close to midnight, with daytime highs of over 40 °C (104 °F) common. Seville also has the highest average annual temperature in mainland Spain (19.2 °C).[http://es.climate-data.org/location/2933/]
Name.
Although its present form is certainly derived from the Arabic translation of Vandalusia or "Land of the Vandals"., the etymology of the name "Andalusia" is disputed, and the extent of Iberian territory encompassed by the name has changed over the centuries.
In the form of "Vandalusia", it was traditionally believed to be derived from the name of the Germanic tribe, the Vandals, that briefly colonized parts of Iberia from AD 409 to AD 429. This proposal is sometimes associated with the 19th-century historian Reinhart Dozy, but it predates him and he recognized some of its shortcomings. Although he accepted that "Al-Andalus" derived from "Vandal", he believed that geographically it referred only to the harbor from which the Vandals departed Iberia for (North) Africa—the location of which harbour was unknown.
The Spanish toponym (place name) "Andalucía" (immediate source of the English "Andalusia") was introduced into the Spanish languages in the 13th century AD under the form "el Andalucía". The name was adopted to refer those territories still under the Moorish rule until then, and generally south of Castilla Nueva and Valencia, and corresponding with the former Roman province hitherto called Baetica in Latin sources. This was a Castilianization of "Al-Andalusiya", the adjectival form of the Arabic language "al-Andalus", the name given by the Arabs to all of the Iberian territories under Muslim rule from 711 to 1492. The etymology of "al-Andalus" is itself somewhat debated (see al-Andalus), but it entered the Arabic language even before such time as this area came under Muslim rule.
Like the Arabic term "al-Andalus", in historical contexts the Spanish term "Andalucía" or the English term "Andalusia" do not necessarily refer to the exact territory designated by these terms today. Initially, the term referred exclusively to territories under Muslim control; later, it was applied to some of the last Iberian territories to be regained from the Muslims, though not always to exactly the same ones. In the "Estoria de España" (also known as the "Primera Crónica General") of Alfonso X of Castile, written in the second half of the 13th century, the term "Andalucía" is used with three different meanings:
From an administrative point of view, Granada remained separate for many years even after the completion of the "Reconquista" due, above all, to its emblematic character as the last territory regained, and as the seat of the important Real Chancillería de Granada, a court of last resort. Still, the reconquest and repopulation of Granada was accomplished largely by people from the three preexisting Christian kingdoms of Andalusia, and Granada came to be considered a fourth kingdom of Andalusia. The often-used expression "Four Kingdoms of Andalusia" dates back in Spanish at least to the mid-18th century.
Symbols.
The Andalusian coat of arms shows the figure of Hercules and two lions between the two pillars of Hercules that tradition situates on either side of the Strait of Gibraltar. An inscription below, superimposed on an image of the flag of Andalusia reads "Andalucía por sí, para España y la Humanidad" ("Andalusia by herself, for Spain and Humanity"). Over the two columns is a semicircular arch in the colors of the flag of Andalusia, with the Latin words "Dominator Hercules Fundator" superimposed.
The official flag of Andalusia consists of three equal horizontal stripes, colored green, white, and green respectively; the Andalusian coat of arms is superimposed on the central stripe. Its design was overseen by Blas Infante and approved in the Assembly of Ronda (a 1918 gathering of Andalusian nationalists at Ronda). The green symbolizes hope and union, and the white symbolizes peace and dialogue. Blas Infante considered these to have been the colors most used in regional symbols throughout the region's history. According to him, the green came in particular from the standard of the Umayyad Caliphate and represented the call for a gathering of the populace. The white symbolized pardon in the Almohad dynasty, interpreted in European heraldry as parliament or peace. Other writers have justified the colors differently, with some Andalusian nationalists referring to them as the "Arbonaida", meaning white-and-green in Mozarabic, a Romance language that was spoken in the region in Muslim times.
The anthem of Andalusia was composed by José del Castillo Díaz (director of the Municipal Band of Seville, commonly known as Maestro Castillo) with lyrics by Blas Infante. The music was inspired by "Santo Dios", a popular religious song sung at harvest time by peasants and day laborers in the provinces of Málaga, Seville, and Huelva. Blas Infante brought the song to Maestro Castillo's attention; Maestro Castillo adapted and harmonized the traditional melody. The lyrics appeal to the Andalusians to mobilize and demand "tierra y libertad" ("land and liberty") by way of agrarian reform and a statute of autonomy within Spain.
The Parliament of Andalusia voted unanimously in 1983 that the preamble to the Statute of Autonomy recognize Blas Infante as the Father of the Andalusian Nation ("Padre de la Patria Andaluza"), which was reaffirmed in the reformed Statute of Autonomy submitted to popular referendum 18 February 2007. The preamble of the present 2007 Statute of Autonomy says that Article 2 of the present Spanish Constitution of 1978 recognizes Andalusia as a nationality. Later, in its articulation, it speaks of Andalusia as a "historic nationality" (Spanish: "nacionalidad histórica"). It also cites the 1919 Andalusianist Manifesto of Córdoba describing Andalusia as a "national reality" ("realidad nacional"), but does not endorse that formulation. Article 1 of the earlier 1981 Statute of Autonomy defined it simply as a "nationality" ("nacionalidad").
The national holiday, the Día de Andalucía, is celebrated on 28 February, commemorating the 1980 autonomy referendum. In spite of this, nationalist groups celebrate the holiday on 4 December, commemorating the 1977 demonstrations to demand autonomy.
The honorific title of "Hijo Predilecto de Andalucía" ("Favorite Son of Andalucia") is granted by the Regional Government of Andalusia to those whose exceptional merits benefited Andalusia, for work or achievements in natural, social, or political science. It is the highest distinction given by the Autonomous Community of Andalusia.
Geography.
The Sevillian historian Antonio Domínguez Ortiz wrote that:
Location.
Andalusia has a surface area of , 17.3 percent of the territory of Spain. Andalusia alone is comparable in extent and in the variety of its terrain to any of several of the smaller European countries. To the east is the Mediterranean Sea; to the west the Atlantic Ocean; to the north the Sierra Morena constitutes the border with the Meseta Central; to the south, the self-governing British overseas territory of Gibraltar and the Strait of Gibraltar separate it from Africa.
Climate.
Andalusia sits at a latitude between 36° and 38° 44' N, in the warm-temperate region. In general, it experiences a Mediterranean climate, with dry summers influenced by the Azores High, but subject to occasional torrential rains and extremely hot temperatures. In the winter, the tropical anticyclones move south, allowing cold polar fronts to penetrate the region. Still, within Andalusia there is considerable climatic variety. From the extensive coastal plains one may pass to the valley of the Guadalquivir, barely above sea level, then to the highest altitudes in the Iberian peninsula in the peaks of the Sierra Nevada. In a mere one can pass from the subtropical coast of the province of Granada to the snowy peaks of Mulhacén. Andalusia also includes both the dry Tabernas Desert in the province of Almería and the Sierra de Grazalema Natural Park in the province of Cádiz, which experiences Spain's greatest rainfall.
Annual rainfall in the Sierra de Grazalema has been measured as high as in 1963, the highest ever recorded for any location in Iberia. Andalusia is also home to the driest place in continental Europe, the Cabo de Gata, with only of rain per year.
In general, as one goes from west to east, away from the Atlantic, there is less precipitation. "Wet Andalusia" includes most of the highest points in the region, above all the Sierra de Grazalema but also the Serranía de Ronda in western Málaga. The valley of the Guadalquivir has moderate rainfall. The Tabernas Desert in Almería, Europe's only true desert, has less than 75 days with any measurable precipitation, and some particular places in the desert have as few as 50 such days. Much of "dry Andalusia" has more than 300 "sunny" days a year.
The average temperature in Andalusia throughout the year is over . Averages in the cities range from in Baeza to in Almería. Much of the Guadalquivir valley and the Mediterranean coast has an average of about . The coldest month is January when Granada at the foot of the Sierra Nevada experiences an average temperature of . The hottest are July and August, with an average temperature of for Andalusia as a whole. Córdoba is the hottest provincial capital, followed by Seville.
The Guadalquivir valley has experienced the highest temperatures recorded in Europe, with a maximum of recorded at Córdoba and Seville. The mountains of Granada and Jaén have the coldest temperatures in southern Iberia, but do not reach continental extremes (and, indeed are surpassed by some mountains in northern Spain). In the cold snap of January 2005, Santiago de la Espada (Jaén) experienced a temperature of and the ski resort at Sierra Nevada National Park—the southernmost ski resort in Europe—dropped to . Sierra Nevada Natural Park has Iberia's lowest average annual temperature, ( at Pradollano) and its peaks remain snowy practically year-round.
Terrain.
Mountain ranges affect climate, the network of rivers, soils and their erosion, bioregions, and even human economies insofar as they rely on natural resources. The Andalusian terrain offers a range of altitudes and slopes. Andalusia has the Iberian peninsula's highest mountains and nearly 15 percent of its terrain over . The picture is similar for areas under (with the Baetic Depression), and for the variety of slopes.
The Atlantic coast is overwhelmingly beach and gradually sloping coasts; the Mediterranean coast has many cliffs, above all in the Malagan Axarquía and in Granada and Almería. This asymmetry divides the region naturally into Upper Andalusia (two mountainous areas) and Lower Andalusia (the broad basin of the Guadalquivir).
The Sierra Morena separates Andalusia from the plains of Extremadura and Castile–La Mancha on Spain's Meseta Central. Although sparsely populated, this is not a particularly high range, and its highest point, the peak of La Bañuela in the Sierra Madrona, lies outside of Andalusia. Within the Sierra Morena, the gorge of Despeñaperros forms a natural frontier between Castile and Andalusia.
The Baetic Cordillera consists of the parallel mountain ranges of the Cordillera Penibética near the Mediterranean coast and the Cordillera Subbética inland, separated by the Surco Intrabético. The Cordillera Subbética is quite discontinuous, offering many passes that facilitate transportation, but the Penibético forms a strong barrier between the Mediterranean coast and the interior. The Sierra Nevada, part of the Cordillera Penibética in the Province of Granada, has the highest peaks in Iberia: El Mulhacén at and El Veleta at .
Lower Andalusia, the Baetic Depression, the basin of the Guadalquivir, lies between these two mountainous areas. It is a nearly flat territory, open to the Gulf of Cádiz in the southeast. Throughout history, this has been the most populous part of Andalusia.
Hydrography.
Andalusia has rivers that flow into both the Atlantic and the Mediterranean. Flowing to the Atlantic are the Guadiana, Odiel-Tinto, Guadalquivir, Guadalete, and Barbate. Flowing to the Mediterranean are the Guadiaro, Guadalhorce, Guadalmedina, Guadalfeo, Andarax (also known as the Almería) and Almanzora. Of these, the Guadalquivir is the longest in Andalusia and fifth longest on the Iberian peninsula, at .
The rivers of the Atlantic basin are characteristically long, run through mostly flat terrain, and have broad river valleys. As a result, at their mouths are estuaries and wetlands, such as the marshes of Doñana in the delta of the Guadalquivir, and wetlands of the Odiel. In contrast, the rivers of the Mediterranean Basin are shorter, more seasonal, and make a precipitous descent from the mountains of the Baetic Cordillera. Their estuaries are small, and their valleys are less suitable for agriculture. Also, being in the rain shadow of the Baetic Cordillera means that they receive a lesser volume of water.
The following hydrographic basins can be distinguished in Andalusia. On the Atlantic side are the Guadalquivir basin; the Andalusian Atlantic Basin with the sub-basins Guadalete-Barbate and Tinto-Odiel; and the Guadiana basin. On the Mediterranean side is the Andalusian Mediterranean Basin and the very upper portion of the basin of the Segura.
Soils.
The soils of Andalusia can be divided into three large areas: the Sierra Morena, Cordillera Subbética, and the Baetic Depression and the Surco Intrabético.
The Sierra Morena, due to its morphology and the acidic content of its rocks, developed principally relatively poor, shallow soils, suitable only for forests. In the valleys and in some areas where limestone is present, deeper soils allowed farming of cereals suitable for livestock. The more complicated morphology of the Baetic Cordillera makes it more heterogeneous, with the most heterogeneous soils in Andalusia. Very roughly, in contrast to the Sierra Morena, a predominance of basic (alkaline) materials in the Cordillera Subbética, combined with a hilly landscape, generates deeper soils with greater agricultural capacity, suitable to the cultivation of olives.
Finally, the Baetic Depression and the Surco Intrabético have deep, rich soils, with great agricultural capacity. In particular, the alluvial soils of the Guadalquivir valley and plain of Granada have a loamy texture and are particularly suitable for intensive irrigated crops. In the hilly areas of the countryside, there is a double dynamic: the depressions have filled with older lime-rich material, developing the deep, rich, dark clay soils the Spanish call "bujeo", or "tierras negras andaluzas", excellent for dryland farming. In other zones, the whiter "albariza" provides an excellent soil for vineyards.
Despite their marginal quality, the poorly consolidated soils of the sandy coastline of Huelva and Almería
have been successfully used in recent decades for hothouse cultivation under clear plastic of strawberries, raspberries, blueberries, and other fruits.
Flora.
Biogeographically, Andalusia forms part of the Western Mediterranean subregion of the Mediterranean Basin, which falls within the Boreal Kingdom. Five floristic provinces lie, in whole or in part, within Andalusia: along much of the Atlantic coast, the Lusitanian-Andalusian littoral or Andalusian Atlantic littoral; in the north, the southern portion of the Luso-Extremaduran floristic province; covering roughly half of the region, the Baetic floristic province; and in the extreme east, the Almerian portion of the Almerian-Murcian floristic province and (coinciding roughly with the upper Segura basin) a small portion of the Castilian-Maestrazgan-Manchegan floristic province. These names derive primarily from past or present political geography: "Luso" and "Lusitanian" from Lusitania, one of three Roman provinces in Iberia, most of the others from present-day Spanish provinces, and Maestrazgo being a historical region of northern Valencia.
In broad terms, the typical vegetation of Andalusia is Mediterranean woodland, characterized by leafy xerophilic perennials, adapted to the long, dry summers. The dominant species of the climax community is the holly oak ("Quercus ilex"). Also abundant are cork oak ("Quercus suber"), various pines, and Spanish fir ("Abies pinsapo"). Due to cultivation, olive ("Olea europaea") and almond ("Prunus dulcis") trees also abound. The dominant understory is composed of thorny and aromatic woody species, such as rosemary ("Rosmarinus officinalis"), thyme ("Thymus"), and "Cistus". In the wettest areas with acidic soils, the most abundant species are the oak and cork oak, and the cultivated "Eucalyptus". In the woodlands, leafy hardwoods of genus "Populus" (poplars, aspens, cottonwoods) and "Ulmus" (elms) are also abundant; poplars are cultivated in the plains of Granada.
The Andalusian woodlands have been much altered by human settlement, the use of nearly all of the best land for farming, and frequent wildfires. The degraded forests become shrubby and combustible garrigue. Extensive areas have been planted with non-climax trees such as pines. There is now a clear conservation policy for the remaining forests, which survive almost exclusively in the mountains.
Fauna.
The biodiversity of Andalusia extends to its fauna as well. More than 400 of the 630 vertebrate species extant in Spain can be found in Andalusia. Spanning the Mediterranean and Atlantic basins, and adjacent to the Strait of Gibraltar, Andalusia is on the migratory route of many of the numerous flocks of birds that travel annually from Europe to Africa and back.
The Andalusian wetlands host a rich variety of birds. Some are of African origin, such as the red-knobbed coot ("Fulica cristata"), the purple swamphen ("Porphyrio porphyrio"), and the greater flamingo ("Phoenicopterus roseus"). Others originate in Northern Europe, such as the greylag goose ("Anser anser"). Birds of prey (raptors) include the Spanish imperial eagle ("Aquila adalberti"), the griffon vulture ("Gyps fulvus"), and both the black and red kite ("Milvus migrans" and "Milvus milvus").
Among the herbivores, are several deer (Cervidae) species, notably the fallow deer ("Dama dama") and roe deer ("Capreolus capreolus"); the European mouflon ("Ovis orientalis musimon"), a type of sheep; and the Spanish ibex ("Capra pyrenaica", which despite its scientific name is no longer found in the Pyrenees). The Spanish ibex has recently been losing ground to the Barbary sheep ("Ammotragus lervia"), an invasive species from Africa, introduced for hunting in the 1970s. Among the small herbivores are rabbits—especially the European rabbit ("Oryctolagus cuniculus")—which form the most important part of the diet of the carnivorous species of the Mediterranean woodlands.
The large carnivores such as the Iberian wolf ("Canis lupus signatus") and the Iberian lynx ("Lynx pardinus") are quite threatened, and are limited to the Sierra de Andújar, inside of Sierra Morena, Doñana and Despeñaperros. Stocks of the wild boar ("Sus scrofa"), on the other hand, have been well preserved because they are popular with hunters. More abundant and in varied situations of conservation are such smaller carnivores as otters, dogs, foxes, the European badger ("Meles meles"), the European polecat ("Mustela putorius"), the least weasel ("Mustela nivalis"), the wildcat ("Felis silvestris"), the common genet ("Genetta genetta"), and the Egyptian mongoose ("Herpestes ichneumon)".
Other notable species are "Acherontia atropos" (a variety of death's-head hawkmoth), "Vipera latasti" (a venomous snake), and the endemic (and endangered) fish "Aphanius baeticus".
Protected areas.
Andalusia has many unique ecosystems. In order to preserve these areas in a manner compatible with both conservation and economic exploitation, many of the most representative ecosystems have been given protected status.
The various levels of protection are encompassed within the Network of Protected Natural Spaces of Andalusia (Red de Espacios Naturales Protegidos de Andalucía, RENPA) which integrates all protected natural spaces located in Andalusia, whether they are protected at the level of the local community, the autonomous community of Andalusia, the Spanish state, or by international conventions. RENPA consists of 150 protected spaces, consisting of two national parks, 24 natural parks, 21 periurban parks (on the fringes of cities or towns), 32 natural sites, two protected countrysides, 37 natural monuments, 28 nature reserves, and four concerted nature reserves (in which a government agency coordinates with the owner of the property for its management), all part of the European Union's Natura 2000 network. Under the international ambit are the nine Biosphere Reserves, 20 Ramsar wetland sites, four Specially Protected Areas of Mediterranean Importance and two UNESCO Geoparks.
In total, nearly 20 percent of the territory of Andalusia lies in one of these protected areas, which constitute roughly 30 percent of the protected territory of Spain. Among these many spaces, some of the most notable are the Sierras de Cazorla, Segura y Las Villas Natural Park, Spain's largest natural park and the second largest in Europe, the Sierra Nevada National Park, Doñana National Park and Natural Park, the Tabernas Desert, and the Cabo de Gata-Níjar Natural Park, the largest terrestrial-maritime reserve in the European Western Mediterranean Sea.
History.
The geostrategic position of Andalusia in the extreme south of Europe, providing (along with Morocco) a gateway between Europe and Africa, added to its position between the Atlantic Ocean and the Mediterranean Sea, as well as its rich deposits of minerals and its agricultural wealth, have made Andalusia a tempting prize for civilizations since prehistoric times. Add to this its area of (larger than many European countries), and it can be no surprise that Andalusia has figured prominently in the history of Europe and the Mediterranean.
Several theories postulate that the first hominids in Europe were in Andalusia, having passed across the Strait of Gibraltar; the earliest known paintings of humanity have been found in the Caves of Nerja, Málaga. The first settlers, based on artifacts from the archaeological sites at Los Millares, El Argar, and Tartessos, were clearly influenced by cultures of the Eastern Mediterranean who arrived on the Andalusian coast. Andalusia then went through a period of protohistory, when the region did not have a written language of its own, but its existence was known to and documented by literate cultures, principally the Phoenicians (Gadir, Malaka) and Ancient Greeks. During the second millennium BCE, the kingdom of Tartessos developed in Andalusia.
Carthaginians and Romans.
With the fall of the Phoenician cities, Carthage became the dominant sea power of the western Mediterranean and the most important trading partner for the Phoenician towns along the Andalusian coast. Between the First and Second Punic Wars, Carthage extended its control beyond Andalucia to include all of Iberia except the Basque Country. Andalusia was the major staging ground for the war with Rome led by the Hannibal Barca. The Romans defeated the Carthaginians and conquered Andalusia, the region being renamed Baetica. It was fully incorporated into the Roman Empire, and from this region came many Roman magistrates and senators, as well as the emperors Trajan and (most likely) Hadrian.
Vandals, Visigoths and the Byzantine Empire.
The Vandals moved briefly through the region during the 5th century AD before settling in North Africa, after which the region fell into the hands of the Visigothic Kingdom. The Visigoths in this region were practically independent of the Visigothic Catholic Kingdom of Toledo. This is the era of Saints Isidore of Seville and Hermenegild. During this period, around 555 AD, the Eastern Roman Empire conquered Andalusia under Justinian I, the Eastern Roman Emperor. They established Spania, a province of the Byzantine Empire from 552 until 624. Though their holdings were quickly reduced, they continued to have interests in the region until it was lost altogether in 624.
Al-Andalus.
The Visigothic era came to an abrupt end in 711 with the Umayyad conquest of Hispania by the Umayyad general Tariq ibn Ziyad, an Islamic Berber. Tariq is known in Spanish history and legend as a formidable conqueror who dared and bore the nerve to burn his fleet of ships, when he landed with his troops on the coast of Gibraltar - an acronym of "Jabel alTariq" meaning "the mountain of Tariq". The —by the Umayyad Caliphate—of the Iberian Peninsula in 711–718 marked the collapse of Visigothic rule and the establishment of the Islamic Empire era. Andalusian culture was fundamentally influenced by over half a millennium of rule by many Muslim caliphates and emirates. In this period, the name "Al-Andalus" was applied to a much larger area than the present Andalusia, and in some periods it referred to nearly the entire Iberian peninsula.
Nevertheless, the Guadalquivir River valley in present-day Andalusia was the hub of Muslim power in the peninsula, with the Caliphate of Córdoba making Córdoba its capital. The Umayyad Caliphate produced such illustrious leaders as Caliph Abd-ar-Rahman III (ruled 912–961) and his son, Caliph Al-Hakam II (ruled 961–976); and built the magnificent Great Mosque of Córdoba. Under these rulers, Moorish Islam in Spain reached its zenith, and Córdoba was a centre of global economic and cultural significance.
Already in the 10th century, the Christians of northern Spain had begun what would eventually become the Reconquista: the reconquest of Spain for Christendom. Caliph Abd-ar-Rahman suffered some minor military defeats, but often managed to play off the Christian kingdoms. Al-Hakam's death achieved military successes, but at the expense of uniting the Christian kings of the north against him.
Internal divisions after the death of Almanzor (1002) led to the first of several decompositions of the Caliphate (1031). New centers of power arose, each ruling a "taifa" (and often with multiple levels of nominal fealty and relative independence, according to the patterns of feudalism). The "taifa" of Seville was especially influential, but the Emirate of Granada was the last to survive, lasting from 1228 until 1492.
After the conquest of Toledo in 1086 by Alfonso VI, Christian rule dominated the peninsula. The main "Taifas" therefore had to resort to assistance from various Muslim powers across the Mediterranean. A number of different Muslim dynasties of North African origin—notably Almoravid dynasty and Almohad dynasty—dominated a slowly diminishing Al-Andalus over the next several centuries.
After the Muslim victory at the Battle of Sagrajas (1086) put a temporary stop to Christian expansion, the Almoravid dynasty constructed a unified Al-Andalus with its capital in Granada, ruling until the mid-12th century. The various "Taifa" kingdoms were assimilated. the Almohad dynasty expansion in North Africa weakened Al-Andalus, and in 1170 the Almohads transferred their capital from Marrakesh to Seville. The Christian victory at the Battle of Las Navas de Tolosa (1212) marked the beginning of the end of the Almohad dynasty.
Kingdom of Castile.
The weakness caused by the collapse of Almohad power and the subsequent creation of new "Taifas", each with its own ruler, led to the rapid Christian reconquest of the valley of the Guadalquivir. Córdoba was regained in 1236 and Seville in 1248. The fall of Granada in 1492 put an end to Muslim rule in the Iberian peninsula.
On 3 August 1492 Christopher Columbus left the town of Palos de la Frontera, with the first expedition that resulted in the Europeans learning of the existence of America. Many Andalusians participated in the expedition that would end the Middle Ages and signal the beginning of modernity. Contacts between Spain and the Americas, including royal administration and the shipping trade of Spanish colonies for over three hundred years, came almost exclusively through Andalusia. As a result, the region became the wealthiest and most influential in Spain and one of the most influential in Europe. However, Habsburg ambitions elsewhere in Europe diverted much of the colonial wealth to war. Discontent with this situation culminated in 1641, when the Andalusian nobility staged an unsuccessful conspiracy to gain independence in 1641 from the provincial government of the Gaspar de Guzmán, Count-Duke of Olivares.
Modern era.
In the first half of the 16th century plague was still prevalent in Spain. According to George C. Kohn, "One of the worst epidemics of the century, whose miseries were accompanied by severe drought and food shortage, started in 1505; by 1507, about 100,000 people had died in Andalusia alone... Andalusia was struck once again in 1646. For three years, plague haunted the entire region, causing perhaps as many as 200,000 deaths, especially in Málaga and Seville."
Following the Second Rebellion of the Alpujarras in 1568-1571, the Moorish population—that is, unconverted Moriscos—were expelled from Kingdom of Castile (and Aragon). However, by order of the Spanish crown, two Moorish families were required to remain in each village in order to demonstrate to the new inhabitants, introduced from northern Spain, the workings of the terracing and irrigation systems on which the district's agriculture depends.
In 1810-12 the people strongly resisted the French occupation during the Peninsular War (part of the Napoleonic Wars).
Andalusia profited from the Spanish overseas empire, although much trade and finance eventually came to be controlled by other parts of Europe to where it was ultimately destined. In the 18th century, commerce from other parts of Spain began to displace Andalusian commerce when the Spanish government ended Andalusia's trading monopoly with the American colonies. The loss of the empire in the 1820s hurt the economy of the region, particularly the cities that had benefited from the trade and ship building. The construction of railways in the latter part of the 19th century enabled Andalusia to better develop its agricultural potential and it became an exporter of food. While industrialisation was taking off in the northern Spanish regions of Catalonia and the Basque country, Andalusia remained traditional and displayed a deep social division between a small class of wealthy landowners and a population made up largely of poor agricultural labourers and tradesmen.
Government and politics.
Andalusia is one of the 17 autonomous communities of Spain. The Regional Government of Andalusia (Spanish: "Junta de Andalucía") includes the Parliament of Andalusia, its chosen president, a Consultative Council, and other bodies.
The Autonomous Community of Andalusia was formed in accord with a referendum of 28 February 1980 and became an autonomous community under the 1981 Statute of Automony known as the "Estatuto de Carmona". The process followed the Spanish Constitution of 1978, still current as of 2009, which recognizes and guarantees the right of automony for the various regions and nationalities of Spain. The process to establish Andalusia as an autonomous region followed Article 151 of the Constitution, making Andalusia the only autonomous community to take that particular course. That article was set out for regions like Andalusia that had been prevented by the outbreak of the Spanish Civil War from adopting a statute of autonomy during the period of the Second Spanish Republic.
Article 1 of the 1981 Statute of Autonomy justifies autonomy based on the region's "historical identity, on the self-government that the Constitution permits every nationality, on outright equality to the rest of the nationalities and regions that compose Spain, and with a power that emanates from the Andalusian Constitution and people, reflected in its Statute of Autonomy".
In October 2006 the constitutional commission of the Cortes Generales (the national legislature of Spain), with favorable votes from the left-of-center Spanish Socialist Workers' Party (PSOE), the leftist United Left (IU) and the right-of-center People`s Party (PP), approved a new Statute of Autonomy for Andalusia, whose preamble refers to the community as a "national reality" ("realidad nacional"):
On 2 November 2006 the Spanish Chamber Deputies ratified the text of the Constitutional Commission with 306 votes in favor, none opposed, and 2 abstentions. This was the first time a Spanish Organic Law adopting a Statute of Autonomy was approved with no opposing votes. The Senate, in a plenary session of 20 December 2006, ratified the referendum to be voted upon by the Andalusian public 18 February 2007.
The Statute of Autonomy spells out Andalusia's distinct institutions of government and administration. Chief among these is the Andalusian Autonomous Government ("Junta de Andalucía"). Other institutions specified in the Statute are the Defensor del Pueblo Andaluz (literally "Defender of the Andalusian People", basically an ombudsperson), the Consultative Council, the Chamber of Accounts, the Audiovisual Council of Andalusia, and the Economic and Social Council.
The Andalusian Statute of Autonomy recognizes Seville as the region's capital. The Andalusian Autonomous Government is located there. However, the region's highest court, the High Court of Andalusia ("Tribunal Superior de Justicia de Andalucía") is not part of the Autonomous Government, and has its seat in Granada.
Andalusian Autonomous Government.
The Andalusian Autonomous Government ("Junta de Andalucía") is the institution of self-government of the Autonomous Community of Andalusia. Within the government, the President of the Regional Government of Andalusia is the supreme representative of the autonomous community, and the ordinary representative of the Spanish state in the autonomous community. The president is formally named to the position by the Monarch of Spain and then confirmed by a majority vote of the Parliament of Andalusia. In practice, the monarch always names a person acceptable to the ruling party or coalition of parties in the autonomous region. In theory, were the candidate to fail to gain the needed majority, the monarch could propose a succession of candidates. After two months, if no proposed candidate could gain the parliament's approval, the parliament would automatically be dissolved and the acting president would call new elections. On September 5, 2013 Susana Díaz was elected president.
The Council of Government, the highest political and administrative organ of the Community, exercises regulatory and executive power. The President presides over the council, which also includes the heads of various departments ("Consejerías"). In the current legislature (2008–2012), there are 15 of these departments. In order of precedence, they are Presidency, Governance, Economy and Treasury, Education, Justice and Public Administration, Innovation, Science and Business, Public Works and Transportation, Employment, Health, Agriculture and Fishing, Housing and Territorial Planning, Tourism, Commerce and Sports, Equality and Social Welfare, Culture, and Environment.
The Parliament of Andalusia, its Autonomic Legislative Assembly, develops and approves laws and elects and removes the President. Elections to the Andalusian Parliament follow a democratic formula through which the citizens elect 109 representatives. After the approval of the Statute of Autonomy through Organic Law 6/1981 on 20 December 1981, the first elections to the autonomic parliament took place 23 May 1982. Further elections have occurred in 1986, 1990, 1994, 1996, 2000, 2004, and 2008.
The current (2008–2012) legislature includes representatives of the PSOE-A (Andalusian branch of the left-of-center PSOE), PP-A (Andalusian branch of the right-of-center PP) and IULV-CA (Andalusian branch of the leftist IU).
Judicial power.
The High Court of Andalusia ("Tribunal Superior de Justicia de Andalucía") in Granada is subject only to the higher jurisdiction of Supreme Court of Spain. The High Court is not an organ of the Autonomous Community, but rather of the Judiciary of Spain, which is unitary throughout the kingdom and whose powers are not transferred to the autonomous communities. The Andalusian territory is divided into 88 legal/judicial districts ("partidos judiciales").
Administrative divisions.
Provinces.
Andalusia consists of eight provinces. The latter were established by Javier de Burgos in the 1833 territorial division of Spain. Each of the Andalusian provinces bears the same name as its capital:
Andalusia is traditionally divided into two historical subregions: "Upper Andalusia" or "Eastern Andalusia" ("Andalucía Oriental"), consisting of the provinces of Almería, Granada, Jaén, and Málaga, and "Lower Andalusia" or "Western Andalusia" ("Andalucía Occidental"), consisting of the provinces of Cádiz, Córdoba, Huelva and Seville.
Municipalities and local entities.
Beyond the level of provinces, Andalusia is further divided into 774 municipalities ("municipios"). The municipalities of Andalusia are regulated by Title III of the Statute of Autonomy, Articles 91–95, which establishes the municipality as the basic territorial entity of Andalusia, each of which has legal personhood and autonomy in many aspects of its internal affairs. At the municipal level, representation, government and administration is performed by the "ayuntamiento" (municipal government), which has competency for urban planning, community social services, supply and treatment of water, collection and treatment of waste, and promotion of tourism, culture, and sports, among other matters established by law.
Among the more important Andalusian cities besides the provincial capitals are:
In conformity with the intent to devolve control as locally as possible, in many cases, separate nuclei of population within municipal borders each administer their own interests. These are variously known as "pedanías" ("hamlets"), "villas" ("villages"), "aldeas" (also usually rendered as "villages"), or other similar names.
Comarcas and mancomunidades.
Within the various autonomous communities of Spain, "comarcas" are comparable to shires (or, in some countries, counties) in the English-speaking world. Unlike in some of Spain's other autonomous communities, under the original 1981 Statute of Autonomy, the "comarcas" of Andalusia had no formal recognition, but, in practice, they still had informal recognition as geographic, cultural, historical, or in some cases administrative entities. The 2007 Statute of Autonomy echoes this practice, and mentions "comarcas" in Article 97 of Title III, which defines the significance of "comarcas" and establishes a basis for formal recognition in future legislation.
The current statutory entity that most closely resembles a "comarca" is the "mancomunidad", a freely chosen, bottom-up association of municipalities intended as an instrument of socioeconomic development and coordination between municipal governments in specific areas.
Demographics.
Andalusia ranks first by population among the 17 autonomous communities of Spain. The estimated population at the beginning of 2009 was 8,285,692. The population is concentrated, above all, in the provincial capitals and along the coasts, so that the level of urbanization is quite high; half the population is concentrated in the 28 cities of more than 50,000 inhabitants. The population is aging, although the process of immigration is countering the inversion of the population pyramid.
Population change.
At the end of the 20th century, Andalusia was in the last phase of demographic transition. The death rate stagnated at around 8–9 per thousand, and the population came to be influenced mainly by birth and migration.
In 1950, Andalusia had 20.04 percent of the national population of Spain. By 1981, this had declined to 17.09 percent. Although the Andalusian population was not declining in absolute terms, these relative losses were due to emigration great enough to nearly counterbalance having the highest birth rate in Spain. Since the 1980s, this process has reversed on all counts, and as of 2009, Andalusia has 17.82 percent of the Spanish population.
The birth rate is sharply down, as is typical in developed economies, although it has lagged behind much of the rest of the world in this respect. Furthermore, prior emigrants have been returning to Andalusia. Beginning in the 1990s, others have been immigrating in large numbers as well, as Spain has become a country of net immigration.
At the beginning of the 21st century, statistics show a slight increase in the birth rate, due in large part to the higher birth rate among immigrants. The result is that as of 2009, the trend toward rejuvenation of the population is among the strongest of any autonomous community of Spain, or of any comparable region in Europe.
Structure.
At the beginning of the 21st century, the population structure of Andalusia shows a clear inversion of the population pyramid, with the largest cohorts falling between ages 25 and 50. Comparison of the population pyramid in 2008 to that in 1986 shows:
As far as composition by sex, two aspects stand out: the higher percentage of women in the elderly population, owing to women's longer life expectancy, and, on the other hand, the higher percentage of men of working age, due in large part to a predominantly male immigrant population.
Immigration.
In 2005, 5.35 percent of the population of Andalusia were born outside of Spain. This is a relatively low number for a Spanish region, the national average being three percentage points higher. The immigrants are not evenly distributed among the Andalusian provinces: Almería, with a 15.20 percent immigrant population, is third among all provinces in Spain, while at the other extreme Jaén is only 2.07 percent immigrants and Córdoba 1.77 percent. The predominant nationalities among the immigrant populations are Moroccan (92,500, constituting 17.79 percent of the foreigners living in Andalusia) and British (15.25 percent across the region). When comparing regions rather than individual countries, the single largest immigrant block is from Latin America, outnumbering either North Africans or non-Spanish Western Europeans. Demographically, this group has provided an important addition to the Andalusian labor force.
Economy.
Andalusia is traditionally an agricultural area, but the service sector (particularly tourism, retail sales, and transportation) now predominates. The once booming construction sector, hit hard by the 2009 recession, was also important to the region's economy. The industrial sector is less developed than most other regions in Spain.
Between 2000–2006 economic growth per annum was 3.72%, one of the highest in the country. Still, according to the Spanish Instituto Nacional de Estadística (INE), the GDP per capita of Andalusia (€17,401; 2006) remains the second lowest in Spain, with only Extremadura lagging behind.
Primary sector.
The primary sector, despite adding the least of the three sectors to the regional GDP remains important, especially when compared to typical developed economies. The primary sector produces 8.26 percent of regional GDP and employs 8.19 percent of the workforce. In monetary terms it could be considered a rather uncompetitive sector, given its level of productivity compared to other Spanish regions. In addition to its numeric importance relative to other regions, agriculture and other primary sector activities have strong roots in local culture and identity.
The primary sector is divided into a number of subsectors: agriculture, commercial fishing, animal husbandry, hunting, forestry, mining, and energy.
Agriculture, husbandry, hunting, and forestry.
For many centuries, Andalusian society was mainly agricultural. Even today, 45.74 percent of the Andalusian territory is cultivated. The primary cultivation is dryland farming of cereals and sunflowers without artificial irrigation, especially in the vast countryside of the Guadalquivir valley and the high plains of Granada and Almería-with a considerably lesser and more geographically focused cultivation of barley and oats. Using irrigation, maize, cotton and rice are also grown on the banks of the Guadalquivir and Genil.
The most important tree crops are olives, especially in the Subbetic regions of the provinces of Córdoba and Jáen, where irrigated olive orchards constitute a large component of agricultural output. There are extensive vineyards in various zones such as Jerez de la Frontera (sherry), Condado de Huelva, Montilla-Moriles and Málaga. Fruits—mainly citrus fruits—are grown near the banks of the Guadalquivir; almonds, which require far less water, are grown on the high plains of Granada and Almería.
In monetary terms, by far the most productive and competitive agriculture in Andalusia is the intensive forced cultivation of strawberries, raspberries, blueberries, and other fruits grown under hothouse conditions under clear plastic, often in sandy zones, on the coasts, in Almería and Huelva.
Organic farming has recently undergone rapid expansion in Andalusia, mainly for export to European markets but with increasing demand developing in Spain.
Andalusia has a long tradition of animal husbandry and livestock farming, but it is now restricted mainly to mountain meadows, where there is less pressure from other potential uses. Andalusians have a long and colourful history of dog breeding that can be observed throughout the region today. The raising of livestock now plays a semi-marginal role in the Andalusian economy, constituting only 15 percent of the primary sector, half the number for Spain taken as a whole.
"Extensive" raising of livestock grazes the animals on natural or cultivated pastures, whereas "intensive" raising of livestock is based in fodder rather than pasture. Although the productivity is higher than with extensive techniques, the economics are quite different. While intensive techniques now dominate in Europe and even in other regions of Spain, most of Andalusia's cattle, virtually all of its sheep and goats, and a good portion of its pigs are raised by extensive farming in mountain pastures. This includes the Black Iberian pigs that are the source of "Jamón ibérico". Andalusia's native sheep and goats present a great economic opportunity in a Europe where animal products are generally in strong supply, but the sheep and goat meat, milk, and leather (and the products derived from these) are relatively scarce. Dogs are bred not just as companion animals, but also as herding animals used by goat and sheep herders.
Hunting remains relatively important in Andalusia, but has largely lost its character as a means of obtaining food.
It is now more of a leisure activity linked to the mountain areas and complementary to forestry and the raising of livestock. Dogs are frequently used as hunting companions to retrieve killed game.
The Andalusian forests are important for their extent—50 percent of the territory of Andalusia—and for other less quantifiable environmental reasons, such as their value in preventing erosion, regulating the flow of water necessary for other flora and fauna. For these reasons, there is legislation in place to protect the Andalusian forests. The value of forest products as such constitutes only 2 percent of agricultural production. This comes mostly from cultivated species—eucalyptus in Huelva and poplar in Granada—as well as naturally occurring cork oak in the Sierra Morena.
Fishing.
Fishing is a longstanding tradition on the Andalusian coasts. Fish and other seafood have long figured prominently in the local diet and in the local gastronomic culture: fried fish ("pescaito frito" in local dialect), white prawns, "almadraba" tuna, among others. The Andalusian fishing fleet is Spain's second largest, after Galicia, and Andalusia's 38 fishing ports are the most of any Spanish autonomous community. Commercial fishing produces only 0.5 percent of the product of the regional primary sector by value, but there are areas where it has far greater importance. In the province of Huelva it constitutes 20 percent of the primary sector, and locally in Punta Umbría 70 percent of the work force is involved in commercial fishing.
Failure to comply with fisheries laws regarding the use of trawling, urban pollution of the seacoast, destruction of habitats by coastal construction (for example, alteration of the mouths of rivers, construction of ports), and diminution of fisheries by overexploitation
have created a permanent crisis in the Andalusian fisheries, justifying attempts to convert the fishing fleet. The decrease in fish stocks has led to the rise of aquaculture, including fish farming both on the coasts and in the interior.
Mining.
Despite the general poor returns in recent years, mining retains a certain importance in Andalusia. Andalusia produces half of Spain's mining product by value. Of Andalusia's production, roughly half comes from the province of Huelva. Mining for precious metals at Minas de Riotinto in Huelva ("see Rio Tinto Group") dates back to pre-Roman times; the mines were abandoned in the Middle Ages and rediscovered in 1556. Other mining activity is coal mining in the Guadiato valley in the province of Córdoba; various metals at Aznalcóllar in the province of Seville, and iron at Alquife in the province of Granada. In addition, limestone, clay, and other materials used in construction are well distributed throughout Andalusia.
Secondary sector: industry.
The Andalusian industrial sector has always been relatively small. Nevertheless, in 2007, Andalusian industry earned 11.979 million euros and employed more than 290,000 workers. This represented 9.15 percent of regional GDP, far below the 15.08 the secondary sector represents in the economy of Spain as a whole. By analyzing the different subsectors of the food industry Andalusian industry accounts for more than 16% of total production. In a comparison with the Spanish economy, this subsector is virtually the only food that has some weight in the national economy with 16.16%. Lies far behind the manufacturing sector of shipping materials just over 10% of the Spanish economy. Companies like Cruzcampo (Heineken Group), Puleva, Domecq, Santana Motors or Renault-Andalusia, are exponents of these two subsectors. Of note is the Andalusian aeronautical sector, which is second nationally only behind Madrid and represents approximately 21% of total turnover in terms of employment, highlighting companies like Airbus, Airbus Military, or the newly formed Aerospace Alestis. On the contrary it is symptomatic of how little weight the regional economy in such important sectors such as textiles or electronics at the national level.
Andalusian industry is also characterized by a specialization in industrial activities of transforming raw agricultural and mineral materials. This is largely done by small enterprises without the public or foreign investment more typical of a high level of industrialization.
Tertiary sector: services.
In recent decades the Andalusian tertiary (service) sector has grown greatly, and has come to constitute the majority of the regional economy, as is typical of contemporary economies in developed nations. In 1975 the service sector produced 51.1 percent of local GDP and employed 40.8 percent of the work force. In 2007, this had risen to 67.9 percent of GDP and 66.42 percent of jobs. This process of "tertiarization" of the economy has followed a somewhat unusual course in Andalusia. This growth occurred somewhat earlier than in most developed economies and occurred independently of the local industrial sector. There were two principal reasons that "tertiarization" followed a different course in Andalusia than elsewhere:
1. Andalusian capital found it impossible to compete in the industrial sector against more developed regions, and was obligated to invest in sectors that were easier to enter.
2. The absence of an industrial sector that could absorb displaced agricultural workers and artisans led to the proliferation of services with rather low productivity. This unequal development compared to other regions led to a hypertrophied and unproductive service sector, which has tended to reinforce underdevelopment, because it has not led to large accumulations of capital.
Tourism in Andalusia.
Due in part to the relatively mild winter and spring climate, the south of Spain is attractive to overseas visitors–especially tourists from Northern Europe. While inland areas such as Jaén, Córdoba and the hill villages and towns remain relatively untouched by tourism, the coastal areas of Andalusia have heavy visitor traffic for much of the year.
Among the autonomous communities, Andalusia is second only to Catalonia in tourism, with nearly 30 million visitors every year. The principal tourist destinations in Andalusia are the Costa del Sol and (secondarily) the Sierra Nevada. As discussed above, Andalusia is one of the sunniest and warmest places in Europe, making it a center of "sun and sand" tourism. 70 percent of the lodging capacity and 75 percent of the nights booked in Andalusian hotels are in coastal municipalities. The largest number of tourists come in August—13.26 percent of the nights booked throughout the year—and the smallest number in December—5.36 percent.
On the west (Atlantic) coast are the Costa de la Luz (provinces of Huelva and Cádiz), and on the east (Mediterranean) coast, the Costa del Sol (provinces of Cádiz y Málaga), Costa Tropical (Granada and part of Almería) and the Costa de Almería. In 2004, the Blue Flag beach program of the non-profit Foundation for Environmental Education recognized 66 Andalusian beaches and 18 pleasure craft ports as being in a good state of conservation in terms of sustainability, accessibility, and quality. Nonetheless, the level of tourism on the Andalusian coasts has been high enough to have a significant environmental impact, and other organizations—such as the Spanish Ecologists in Action ("Ecologistas en Acción") with their description of "Black Flag beaches" or Greenpeace—have expressed the opposite sentiment. However, Hotel chains such as Fuerte Hotels have ensured that sustainability within the tourism industry is one of their highest priorities.
Together with "sand and sun" tourism, there has also been a strong increase in nature tourism in the interior, as well as cultural tourism, sport tourism, and conventions. One example of sport and nature tourism is the ski resort at Sierra Nevada National Park.
As for cultural tourism, Andalusia has some notable monuments dating back to the Muslim era: the Great Mosque of Córdoba, the Alhambra in Granada, the Giralda and Alcazar in Seville, and the Alcazaba in Málaga. There are hundreds of cultural tourist destinations: cathedrals, castles, forts, monasteries, and historic city centers; the city centers of Úbeda and Baeza in the province of Jaén are UNESCO World Heritage Sites.
Each of the provinces shows a great variety of architectural styles: Islamic architecture, Renaissance architecture, Baroque architecture and more modern styles. Further, there are the "Lugares colombinos", significant places in the life of Christopher Columbus: Palos de la Frontera, La Rábida Monastery, and Moguer) in the province of Huelva. There are also archeological sites of great interest: the Roman city of Italica, birthplace of Emperor Trajan and (most likely) Hadrian; Baelo Claudia near the Straits of Gibraltar; Medina Azahara, the city-palace of the Cordoban caliph Abd-ar-Rahman III, where major excavations still continue.
Andalusia was the birthplace of such great painters as Velázquez and Murillo (Seville) and, more recently, Picasso (Málaga); Picasso is memorialized by his native city at the Museo Picasso Málaga and Natal House Foundation; the Casa de Murillo was a house museum 1982–1998, but is now mostly offices for the Andalusian Council of Culture. The CAC Málaga (Museum of Modern Art) is the most visited museum of Andalusia and has offered exhibitions of artists such as Louise Bourgeois, Jake and Dinos Chapman, Gerhard Richter, Anish Kapoor, Ron Mueck or Rodney Graham. Malaga is also located part of the private Carmen Thyssen-Bornemisza Collection at Carmen Thyssen Museum.
There are numerous other significant museums around the region, both of paintings and of archeological artifacts such as gold jewelry, pottery and other ceramics, and other works that demonstrate the region's artisanal traditions.
The Council of Government has designated the following "Municipios Turísticos": in Almería, Roquetas de Mar; in Cádiz, Chiclana de la Frontera, Chipiona, Conil de la Frontera, Grazalema, Rota, and Tarifa; in Granada, Almuñécar; in Huelva, Aracena; in Jaén, Cazorla; in Málaga, Benalmádena, Fuengirola, Nerja, Rincón de la Victoria, Ronda, and Torremolinos; in Seville, Santiponce.
Infrastructure.
Transport.
As in any modern society, transport systems are an essential structural element of the functioning of Andalusia. The transportation network facilitates territorial coordination, economic development and distribution, and intercity transportation.
In urban transport, underdeveloped public transport systems put pedestrian traffic and other non-motorized traffic are at a disadvantage compared to the use of private vehicles. Several Andalusian capitals—Córdoba, Granada and Seville—have recently been trying to remedy this by strengthening their public transport systems and providing a better infrastructure for the use of bicycles.
For over a century, the conventional rail network has been centralized on the regional capital, Seville, and the national capital, Madrid; in general, there are no direct connections between provincial capitals. High-speed AVE trains run from Madrid via Córdoba to Seville and Málaga. Further AVE routes are under construction. The Madrid-Córdoba-Seville route was the first high-velocity route in Spain (operating since 1992). Other principal routes are the one from Algeciras to Seville and from Almería via Granada to Madrid.
Most of the principal roads have been converted into limited access highways known as "autovías". The Autovía del Este (Autovía A-4) runs from Madrid through the Despeñaperros Natural Park, then via Bailén, Córdoba, and Seville to Cádiz, and is part of European route E05 in the International E-road network. The other main road in the region is the portion of European route E15, which runs as the Autovia del Mediterráneo along the Spanish Mediterranean coast. Parts of this constitute the superhighway Autopista AP-7, while in other areas it is Autovía A-7. Both of these roads run generally east-west, although the Autovía A-4 turns to the south in western Andalusia.
Other first-order roads include the Autovía A-48 roughly along the Atlantic coast from Cádiz to Algeciras, continuing European route E05 to meet up with European route E15; the Autovía del Quinto Centenario (Autovía A-49), which continues west from Seville (where the Autovía A-4 turns toward the south) and goes on to Huelva and into Portugal as European route E01; the Autovía Ruta de la Plata (Autovía A-66), European route E803, which roughly corresponds to the ancient Roman 'Silver Route' from the mines of northern Spain, and runs north from Seville; the Autovía de Málaga (Autovía A-45), which runs south from Córdoba to Málaga; and the Autovía de Sierra Nevada (Autovía A-44), part of European route E902, which runs south from Jaén to the Mediterranean coast at Motril.
As of 2008 Andalusia has six public airports, all of which can legally handle international flights; however the Málaga Airport is dominant, handling 60.67 percent of passengers and 85 percent of its international traffic. The Seville Airport handles another 20.12 percent of traffic, and the Jerez Airport 7.17 percent, so that these three airports account for 87.96 percent of traffic.
Málaga Airport is the international airport that offers a wide variety of international destinations. It has a daily link with twenty cities in Spain and over a hundred cities in Europe (mainly in Great Britain, Central Europe and the Nordic countries but also the main cities of Eastern Europe: Moscow, Saint Petersburg, Sofia, Riga or Bucharest), North Africa, Middle East (Riyadh, Jeddah and Kuwait) and North America (New York, Toronto and Montreal).
The main ports are Algeciras (for freight and container traffic) and Málaga for cruise ships. Algeciras is Spain's leading commercial port, with of cargo in 2004. Seville has Spain's only commercial river port. Other significant commercial ports in Andalusia are the ports of the Bay of Cádiz, Almería and Huelva.
The Council of Government has approved a Plan of Infrastructures for the Sustainability of Transport in Andalusia (PISTA) 2007–2013, which plans an investment of 30 billion euros during that period.
Energy infrastructure.
The lack of high-quality fossil fuels in Andalusia has led to a strong dependency on petroleum imports. Still, Andalusia has a strong potential for the development of renewable energy, above all wind energy. The Andalusian Energy Agency established in 2005 by the autonomous government, is a new governmental organ charged with the development of energy policy and provision of a sufficient supply of energy for the community.
The infrastructure for production of electricity consists of eight large thermal power stations, more than 70 hydroelectric power plants, two wind farms, and 14 major cogeneration facilities. Historically, the largest Andalusian business in this sector was the Compañía Sevillana de Electricidad, founded in 1894, absorbed into Endesa in 1996.
The Solar power tower PS10 was built by the Andalusian firm Abengoa in Sanlúcar la Mayor in the province of Seville, and began operating in March 2007. It is the largest existing solar power facility in Europe. Smaller solar power stations, also recent, exist at Cúllar and Galera, Granada, inaugurated by Geosol and Caja Granada. Two more large thermosolar facilities, Andasol I y II, planned at Hoya de Guadix in the province of Granada are expected to supply electricity to half a million households. The Plataforma Solar de Almería (PSA) in the Tabernas Desert is an important center for the exploration of the solar energy.
The largest wind power firm in the region is the Sociedad Eólica de Andalucía, formed by the merger of Planta Eólica del Sur S.A. and Energía Eólica del Estrecho S.A.
Education.
As throughout Spain, basic education in Andalusia is free and compulsory. Students are required to complete ten years of schooling, and may not leave school before the age of 16, after which students may continue on to a baccalaureate, to intermediate vocational education, to intermediate-level schooling in arts and design, to intermediate sports studies, or to the working world.
Andalusia has a tradition of higher education dating back to the Middle Ages and the Madrasah of Granada, University of Baeza, and University of Osuna.
As of 2009, there are ten private or public universities in Andalucia. University studies are structured in cycles, awarding degrees based on ECTS credits in accord with the Bologna process, which the Andalusian universities are adopting in accord with the other universities of the European Higher Education Area.
Healthcare.
Responsibility for healthcare jurisdictions devolved from the Spanish government to Andalusia with the enactment of the Statute of Autonomy. Thus, the Andalusian Health Service ("Servicio Andaluz de Salud") currently manages almost all public health resources of the Community, with such exceptions as health resources for prisoners and members of the military, which remain under central administration.
Science and technology.
According to the Outreach Program for Science in Andalusia, Andalusia contributes 14 percent of Spain's scientific production behind only Madrid and Catalonia among the autonomous communities, even though regional investment in research and development (R&D) as a proportion of GDP is below the national average. The lack of research capacity in business and the low participation of the private sector in research has resulted in R&D taking place largely in the public sector.
The Council of Innovation, Science and Business is the organ of the autonomous government responsible for universities, research, technological development, industry, and energy. The council coordinates and initiates scientific and technical innovation through specialized centers an initiatives such as the Andalusian Center for Marine Science and Technology ("Centro Andaluz de Ciencia y Tecnología Marina") and Technological Corporation of Andalusia ("Corporación Tecnológica de Andalucía").
Within the private sphere, although also promoted by public administration, technology parks have been established throughout the Community, such as the Technological Park of Andalucia ("Parque Tecnológico de Andalucía") in Campanillas on the outskirts of Málaga, and Cartuja 93 in Seville. Some of these parks specialize in specific sector, such as Aerópolis in aerospace or Geolit in food technology. The Andalusian government deployed 600,000 Ubuntu desktop computers in their schools.
Media.
Andalusia has international, national, regional, and local media organizations, which are active gathering and disseminating information (as well as creating and disseminating entertainment).
The most notable is the public Radio y Televisión de Andalucía (RTVA), broadcasting on two regional television channels, Canal Sur and Canal Sur 2, four regional radio stations, Canal Sur Radio, Canal Fiesta Radio, Radio Andalucía Información and Canal Flamenco Radio, as well as various digital signals, most notably Canal Sur Andalucía available on cable TV throughout Spain.
Newspapers.
Different newspapers are published for each Andalusian provincial capital, comarca, or important city. Often, the same newspaper organization publishes different local editions with much shared content, with different mastheads and different local coverage. There are also popular papers distributed without charge, again typically with local editions that share much of their content.
No single Andalusian newspaper is distributed throughout the region, not even with local editions. In eastern Andalusia the "Diario Ideal" has editions tailored for the provinces if Almería, Granada, and Jaén. Grupo Joly is based in Andalucia, backed by Andalusian capital, and publishes eight daily newspapers there. Efforts to create a newspaper for the entire autonomous region have not succeeded (the most recent as of 2009 was the "Diario de Andalucía"). The national press ("El País", "El Mundo", "ABC", etc.) include sections or editions specific to Andalusia.
Public television.
Andalusia has two public television stations, both operated by Radio y Televisión de Andalucía (RTVA):
In addition, RTVA also operates the national and international cable channel Canal Sur Andalucía, which first broadcast in 1996 as Andalucía Televisión.
Radio.
There are four public radio stations in the region, all operated by RTVA:
Art and culture.
The culture of Andalusia has been shaped by its particular history and geography, as well as its complex flows of population. Andalusia has been home to a succession of peoples and civilizations, many very different from one another, each impacting the settled inhabitants. The ancient Iberians were followed by Celts, Phoenicians and other Eastern Mediterranean traders, Romans, migrating Germanic tribes, North African Muslims, and the Castilians and other Spanish of the "Reconquista". All have affected Andalusian identity and culture, which was already delineated in the 19th century and diffused widely in the literary and pictorial genre of the "costumbrismo andaluz".
In the 19th century, Andalusian culture came to be widely viewed as the Spanish culture "par excellence", in part thanks to the perceptions of romantic travellers. In the words of Ortega y Gasset:
Arts.
Andalusia has been the birthplace of many great artists: the classic painters Velázquez, Murillo, and Juan de Valdés Leal; the sculptors Juan Martínez Montañés, Alonso Cano and Pedro de Mena; and such modern painters as Daniel Vázquez Díaz and Pablo Picasso.
The composer Manuel de Falla was from Cádiz and incorporated typical Andalusian melodies in his works, as did Joaquín Turina, from Seville. The great singer Camarón de la Isla was born in San Fernando, Cádiz, and Andrés Segovia who helped shape the romantic-modernist approach to classical guitar, was born in Linares, Jaén.
Architecture.
Since the Neolithic era, Andalusia has preserved important megaliths, such as the dolmens at the Cueva de Menga and the Dolmen de Viera, both at Antequera. Archeologists have found Bronze Age cities at Los Millares and El Argar. Archeological digs at Doña Blanca in El Puerto de Santa María have revealed the oldest Phoenicians city in the Iberian peninsula; major ruins have also been revealed at Roman Italica near Seville.
Some of the greatest architecture in Andalusia dates from the Muslim era: the Alhambra and the Great Mosque of Córdoba.
The traditional architecture of Andalusia retains its Roman and Arab roots, with a marked Mediterranean character strongly conditioned by the climate. Traditional urban houses are constructed with shared walls to minimize exposure to high exterior temperatures. Solid exterior walls are painted with lime to minimize the heating effects of the sun. In accord with the climate and tradition of each area, the roofs may be terraces or tiled in the Roman imbrex and tegula style. One of the most characteristic elements (and one of the most obviously influenced by Roman and North African architecture) is the interior patio or courtyard; the patios of Córdoba are particularly famous. Other characteristic elements are decorative (and functional) wrought iron gratings, and the tiles known as "azulejos". Landscaping—both for common private homes and homes on a more lavish scale—also carries on older traditions, with plants, flowers, and fountains, pools, and streams of water. Beyond these general elements, there are also specific local architectural styles, such as the flat roofs, roofed chimneys, and radically extended balconies of the Alpujarra, the cave dwellings of Guadix and of Granada's Sacromonte, or the traditional architecture of the Marquisate of Zenete.
The monumental architecture of the centuries immediately after the Reconquista often displayed an assertion of Christian hegemony through architecture that referenced non-Arab influences. Some of the greatest Renaissance buildings in Andalusia are from the then-kingdom of Jaén: the Jaén Cathedral, designed in part by Andrés de Vandelvira, served as a model for the Cathedral of Malaga and Guadix; the centers of Úbeda and Baeza, dating largely from this era, are UNESCO World Heritage Sites. Seville and its kingdom also figured prominently in this era, as is shown by the Casa consistorial de Sevilla, the Hospital de las Cinco Llagas or the Charterhouse of Jerez de la Frontera. The Palace of Charles V in Granada is uniquely important for its Italianate purism. Andalusia also has such Baroque-era buildings as the Palace of San Telmo in Seville (seat of the current autonomic presidency), the Church of Our Lady of Reposo in Campillos, and the Granada Charterhouse. Academicism gave the region the Royal Tobacco Factory in Seville and Neoclassicism the nucleus of Cádiz, such as its city hall, Royal Prison and the Oratorio de la Santa Cueva.
Revivalist architecture in the 19th and 20th centuries contributed the buildings of the Ibero-American Exposition of 1929 in Seville, including the Neo-Mudéjar Plaza de España. Andalusia also preserves an important industrial patrimony related to various economic activities.
Besides the architecture of the cities, there is also much outstanding rural architecture: houses, as well as ranch and farm buildings and dog houses.
Sculpture.
The Iberian reliefs of Osuna, Lady of Baza, and León de Bujalance, the Phoenician sarcophagi of Cádiz, and the Roman sculptures of the Baetic cities such as Italica give evidence of traditions of sculpture in Andalusia dating back to antiquity. There are few significant surviving sculptures from the time of al-Andalus; two notable exceptions are the lions of the Alhambra and of the Maristán of Granada (the Muslim-era hospital in the Albaicín).
The Sevillian school of sculpture dating from the 13th century onward and the Granadan school beginning toward the end of the 16th century both focused primarily on Christian religious subject matter, including many wooden altarpieces. Notable sculptors in these traditions include Lorenzo Mercadante de Bretaña, Pedro Millán, Juan Martínez Montañés, Pedro Roldán, José de Arce, Jerónimo Balbás, Alonso Cano, and Pedro de Mena.
Non-religious sculpture has also existed in Andalusia since antiquity. A fine example from the Renaissance era is the decoration of the Casa de Pilatos in Seville. Nonetheless, non-religious sculpture played a relatively minor role until such 19th-century sculptors as Antonio Susillo.
Painting.
As in sculpture, there were Sevillian and the Granadan schools of painting. The latter has figured prominently in the history of Spanish art since the 15th century and includes such important artists as Zurbarán, Velázquez and Murillo, as well as theoreticians of art such as Francisco Pacheco. The Museum of Fine Arts of Seville and the The Prado contain numerous representative works of the Sevillian school of painting.
A specific romantic genre known as "costumbrismo andaluz" depicts traditional and folkloric Andalusian subjects, such as bullfighting scenes, dogs, and scenes from Andalusia's history. Important artists in this genre include Manuel Barrón, José García Ramos, Gonzalo Bilbao and Julio Romero de Torres. The genre is well represented in the private Carmen Thyssen-Bornemisza Collection, part of which is on display at Madrid's Thyssen-Bornemisza Museum and Carmen Thyssen Museum in Málaga.
Málaga also has been and is an important artistic center. Its most illustrious representative was Pablo Picasso, one of the most influential artists of the 20th century. The city has a Museum and Natal House Foundation, dedicated to the painter.
Literature and philosophy.
Andalusia plays a significant role in the history of Spanish language literature, however not all of the important literature associated with Andalusia was written in Spanish. Before 1492, there was the literature written in Andalusian Arabic. Hispano-Arabic authors native to the region include
Ibn Hazm, Ibn Zaydun, Ibn Tufail, Al-Mu'tamid, Ibn al-Khatib, Ibn al-Yayyab, and Ibn Zamrak or Andalusian Hebrew poets as Solomon Ibn Gabirol. Ibn Quzman, of the 12th century, crafted poems in the colloquial Andalusian language.
In 1492 Antonio de Nebrija published his celebrated "Gramática de la lengua castellana" ("Grammar of the Castilian language"), the first such work for a modern European language. In 1528 Francisco Delicado wrote "", a novel in the orbit of "La Celestina", and in 1599 the Sevillian Mateo Alemán wrote the first part of "Guzmán de Alfarache", the first picaresque novel with a known author.
The prominent humanist literary school of Seville included such writers as Juan de Mal Lara, Fernando de Herrera, Gutierre de Cetina, Luis Barahona de Soto, Juan de la Cueva, Gonzalo Argote de Molina, and Rodrigo Caro. The Cordoban Luis de Góngora was the greatest exponent of the "culteranismo" of Baroque poetry in the Siglo de Oro; indeed, the style is often referred to as "Góngorismo".
Literary Romanticism in Spain had one of its great centers in Andalusia, with such authors as Ángel de Saavedra, Duke of Rivas, José Cadalso and Gustavo Adolfo Bécquer. "Costumbrismo andaluz" existed in literature as much as in visual art, with notable examples being the "Escenas andaluzas" of Serafín Estébanez Calderón and the works of Pedro Antonio de Alarcón.
Andalusian authors Ángel Ganivet, Manuel Gómez-Moreno, Manuel and Antonio Machado, and Francisco Villaespesa are all generally counted in the Generation of '98. Also of this generation were the Hermanos Álvarez Quintero, dramatists who faithfully captured Andalusian dialects and idiosyncrasies. Also of note, 1956 Nobel Prize-winning poet Juan Ramón Jiménez was a native of Moguer, near Huelva.
A large portion of the "avant garde" Generation of '27 who gathered at the Ateneo de Sevilla on the 300th anniversary of Góngora's death were Andalusians: Federico García Lorca, Luis Cernuda, Rafael Alberti, Manuel Altolaguirre, Emilio Prados, and 1977 Nobel laureate Vicente Aleixandre.
Certain Andalusian fictional characters have become universal archetypes: Prosper Merimée's gypsy "Carmen", P. D. Eastman's "Perro", Pierre Beaumarchais's "Fígaro", and Tirso de Molina's "Don Juan".
As in most regions of Spain, the principal form of popular verse is the romance, although there are also strophes specific to Andalusia, such as the "soleá" or the "soleariya". Ballads, lullabies, street vendor's cries, nursery rhymes, and work songs are plentiful.
Among the philosophers native to the region can be counted Seneca, Avicebron, Maimonides, Averroes, Fernán Pérez de Oliva, Sebastián Fox Morcillo, Ángel Ganivet, Francisco Giner de los Ríos and María Zambrano.
Music of Andalusia.
The music of Andalusia includes traditional and contemporary music, folk and composed music, and ranges from flamenco to rock. Conversely, certain metric, melodic and harmonic characteristics are considered Andalusian even when written or performed by musicians from elsewhere.
Flamenco, perhaps the most characteristically Andalusian genre of music and dance, originated in the 18th century, but is based in earlier forms from the region. The influence of the traditional music and dance of the Romani people or Gypsies is particularly clear. The genre embraces distinct vocal ("cante flamenco"), guitar ("toque flamenco"), and dance ("baile flamenco") styles.
The Andalusian Statute of Autonomy reflects the cultural importance of flamenco in its Articles 37.1.18 and 68:
Fundamental in the history of Andalusian music are the composers Cristóbal de Morales, Francisco Guerrero, Francisco Correa de Arauxo, Manuel García, Manuel de Falla, Joaquín Turina, and Manuel Castillo, as well as the father of modern classical guitar, the guitarist Andrés Segovia. Mention should also be made of the great folk artists of the "copla (music)" and the "cante hondo", such as Rocío Jurado, Lola Flores ("La Faraona", "the pharaoh"), Juanito Valderrama and the revolutionary Camarón de la Isla.
Prominent Andalusian rock groups include Triana and Medina Azahara. The duo Los del Río from Dos Hermanas had international success with their "Macarena", including playing at a Super Bowl half-time show in the United States, where their song has also been used as campaign music by the Democratic Party. Other notables include the singer, songwriter, and poet Joaquín Sabina, Isabel Pantoja, Rosa López, who represented Spain at Eurovision in 2002, and David Bisbal.
Film.
The portrayal of Andalusia in film is often reduced to archetypes: flamenco, bullfighting, Catholic pageantry, brigands, the property-rich and cash-poor "señorito andaluz" and emigrants. These images particularly predominated from the 1920s through the 1960s, and helped to consolidate a cliched image of the region. In a very different vein, the province of Almería was the filming location for many Westerns, especially (but by no means exclusively) the Italian-directed Spaghetti Westerns. During the dictatorship of Francisco Franco, this was the extent of the film industry in Andalusia.
Nonetheless, Andalusian film has roots as far back as José Val del Omar in the pre-Franco years, and since the Spanish transition to democracy has brought forth numerous nationally and internationally respected directors: Antonio Cuadri ("Heart of the Earth"), Chus Gutiérrez ("Poniente"), Chiqui Carabante ("Carlos Against the World"), Alberto Rodríguez ("7 Virgins"), Benito Zambrano ("Solas"), and Antonio Banderas ("Summer Rain").
Counting together feature films, documentaries, television programs, music videos etc., Andalusia has boomed from 37 projects shooting in 1999 to 1,054 in 2007, with the figure for 2007 including 19 feature films. Although feature films are the most prestigious, commercials and television are currently more economically important to the region.
The Filmoteca de Andalucía, headquartered in Córdoba, is a government-run entity in charge of the investigation, collection and diffusion of Andalusian cinematic heritage. Other important contributors to this last activity are such annual film festivals as the Málaga Film Festival ("Festival de Málaga Cine Español (FMCE)"), the most important festival dedicated exclusively to cinema made in Spain, the Seville Festival of European Film (SFCE), the International Festival of Short Films - Almería in Short, the Huelva Festival of Latin American Film, the Atlantic Film Show in Cádiz, the Islantilla Festival of Film and Television and the African Film Festival of Tarifa.
Culture.
Customs and society.
Andalusia has a wide array of social customs, many of which have their roots in the Islamic traditions integrated into the culture of the area under Muslim rule. Each sub-region in Andalusia has its own unique customs that represent a fusion of Catholicism and local folklore. Traditional dress in all areas of Andalusia tends to be colorful and involve various head coverings reminiscent of a Muslim past. Cities like Almería have been influenced historically by both Granada and Murcia in the use of traditional head coverings. The "sombrero de Labrador", a worker's hat made of black velvet, is a signature style of the region.
In Cádiz, traditional costumes with rural origins are worn at bullfights and at parties on the large estates. The "tablao flamenco" dance and the accompanying "cante jondo" vocal style originated in Granada. They are believed to have their roots in oriental, Gregorian, Moorish, and Jewish music. This music is most often performed by the gypsy Romani, who are more numerous in Granada than anywhere else in Spain. One of the most distinctive cultural events in Andalusia is the Romeria de El Rocio in May. It consists of a pilgrimage to the Hermitage of El Rocío in the countryside near Almonte, in honor of the Virgin of El Rocío, an image of the Virgin and Child, which was supposedly hidden from the Muslims during Moorish rule. In recent times the "Romería" has attracted roughly a million pilgrims each year.
In Jaen, the saeta is a revered form of Spanish religious song, whose form and style has evolved over many centuries. Saetas evoke strong emotion and are sung most often during public processions. "Verdiales", based upon the fandango, are a flamenco music style and song form originating in Almogia, near Málaga. For this reason, the Verdiales are sometimes known as "Fandangos de Málaga." The region also has a rich musical tradition of flamenco songs, or palos called cartageneras. Seville celebrates "Semana Santa", one of the better known religious events within Spain. During the festival, religious fraternities dress as penitents and carry large floats of lifelike wooden sculptures representing scenes of the Passion, and images of the Virgin Mary. Sevillanas, a type of old folk music sung and written in Seville and still very popular, are performed in fairs and festivals, along with an associated dance for the music, the "Baile por sevillanas". All the different regions of Andalusia have developed their own distinctive customs, but all share a connectedness to Catholicism and the region’s Muslim cultural past.
Andalusian Spanish.
Andalusian Spanish is one of the most widely spoken forms of Spanish in Spain, and because of emigration patterns was very influential on American Spanish. Rather than a single dialect, it is really a range of dialects sharing some common features; among these is the retention of more Arabic words than elsewhere in Spain, as well as some phonological differences compared with Standard Spanish. The isoglosses that mark the borders of Andalusian Spanish overlap to form a network of divergent boundaries, so there is no clear border for the linguistic region.
Religion.
The territory now known as Andalusia fell within the sphere of influence of ancient Mediterranean mythological beliefs. Phoenician colonization brought the cults of Baal and Melqart; the latter lasted into Roman times as Hercules, mythical founder of both Cádiz and Seville. The Islote de Sancti Petri held the supposed tomb of Hercules, with representations of his Twelve labors; the region was the traditional site of the tenth labor, obtaining the cattle of the monster Geryon. Traditionally, the Pillars of Hercules flank the Strait of Gibraltar. Clearly, the European pillar is the Rock of Gibraltar; the African pillar was presumably either Monte Hacho in Ceuta or Jebel Musa in Morocco. The Roman road that led from Cádiz to Rome was known by several names, one of them being "Via Herculea", Hercules route returning from his tenth labor. The present coat of arms of Andalusia shows Hercules between two lions, with two pillars behind these figures.
The principal characteristic of the local popular form of Catholicism is devotion to the Virgin Mary; Andalusia is sometimes known as "la tierra de María Santísima" ("the land of Most Holy Mary"). Also characteristic are the processions during Holy Week, in which thousands of penitents (known as "nazarenos") sing saetas. Andalusia is the site of such pilgrim destinations as the Santuario de Nuestra Señora de la Cabeza in Andújar and the Hermitage of El Rocío in Almonte.
Bullfighting.
While some trace the lineage of the Spanish Fighting Bull back to Roman times, today's fighting bulls in the Iberian peninsula and in the former Spanish Empire trace back to Andalusia in the 15th and 16th centuries. Andalusia remains a center of bull-rearing and bullfighting: its 227 "fincas de ganado" where fighting bulls are raised cover . In the year 2000, Andalusia's roughly 100 bullrings hosted 1,139 "corridas".
The oldest bullring still in use in Spain is the neoclassical "Plaza de toros" in Ronda, built in 1784. The Andalusian Autonomous Government sponsors the "Rutas de Andalucía taurina", a touristic route through the region centered on bullfighting.
Festivals.
The Andalusian festivals provide a showcase for popular arts and traditional costume. Among the most famous of these are the Seville Fair or "Feria de Abril" in Seville, now echoed by smaller fairs in Madrid and Barcelona, both of which have many Andalusian immigrants; the "Feria de Agosto" in Málaga; the Feria de Jerez or "Feria del Caballo" in Jerez; the Festival of Corpus Christi in Granada; the Feria de Nuestra Señora de la Salud in Córdoba; the Columbian Festivals ("Fiestas Colombinas") in Huelva; the Feria de la Virgen del Mar in Almería; and the Feria de San Lucas in Jaén, among many others.
Festivals of a religious nature are a deep Andalusian tradition and are met with great popular fervor. There are numerous major festivals during Holy Week. An annual pilgrimage brings a million visitors to the Hermitage of El Rocío in Almonte (population 16,914 in 2008); similarly large crowds visit the Santuario de Nuestra Señora de la Cabeza in Andújar every April.
Other important festivals are the Carnival of Cádiz and the Fiesta de las Cruces or Cruz de mayo in Granada and Córdoba; in Córdoba this is combined with a competition for among the "patios" (courtyards) of the city.
Andalusia hosts an annual festival for the dance of flamenco in the summer-time.
Cuisine.
The Andalusian diet varies, especially between the coast and the interior, but in general is a Mediterranean diet based on olive oil, cereals, legumes, vegetables, fish, dried fruits and nuts, and meat; there is also a great tradition of drinking wine.
Fried fish—"pescaíto frito"—and seafood are common on the coast and also eaten well into the interior under coastal influence. Atlantic bluefin tuna ("Thunnus thynnus") from the Almadraba areas of the Gulf of Cádiz, prawns from Sanlúcar de Barrameda (known as "langostino de Sanlúcar"), and deepwater rose shrimp ("Parapenaeus longirostris") from Huelva are all highly prized. Fishing for the transparent goby or "chanquete" ("Aphia minuta"), a once-popular small fish from Málaga, is now banned because the techniques used to catch them trap too many immature fish of other species.
The mountainous regions of the Sierra Morena and Sierra Nevada produce cured hams, notably including "jamón serrano" and "jamón ibérico". These come from two different types of pig, ("jamón serrano" from white pigs, the more expensive "jamón ibérico" from the Black Iberian pig). There are several Denominaciones de Origen, each with its own specifications including in just which microclimate region ham of a particular denomination must be cured. "Plato alpujarreño" is another mountain specialty, a dish combining ham, sausage, sometimes other pork, egg, potatoes, and olive oil.
Confectionery is popular in Andalusia. Almonds and honey are common ingredients. Many enclosed convents of nuns make and sell pastries, especially Christmas pastries: "mantecados", "polvorones", "pestiños", "alfajores", "yemas de San Leandro", as well as "churros" or "tejeringos", meringue cookies ("merengadas"), and "amarguillos".
Cereal-based dishes include "migas de harina" in eastern Andalusia (a similar dish to couscous rather than the fried breadcrumb based "migas" elsewhere in Spain) and a sweeter, more aromatic porridge called "poleá" in western Andalusia.
Vegetables form the basis of such dishes as "alboronía" (similar to "ratatouille") and the chopped salad known as "pipirrana" or "piriñaca". Hot and cold soups based in olive oil, garlic, bread, tomato and peppers include "gazpacho", "salmorejo", "porra antequerana", "ajo caliente", "sopa campera", or—using almonds instead of tomato—"ajoblanco".
Wine has a privileged place at the Andalusian table. Andalusian wines are known worldwide, especially fortified wines such as sherry ("jerez"), aged in soleras. These are enormously varied; for example, dry sherry may be the very distinct "fino", "manzanilla", "amontillado", "oloroso", or "Palo Cortado" and each of these varieties can each be sweetened with Pedro Ximénez or Moscatel to produce a different variety of sweet sherry. Besides sherry, Andalucía has five other Denominaciones de Origen for wine: D.O. Condado de Huelva, D.O. Manzanilla-Sanlúcar de Barrameda, D.O. Málaga, D.O. Montilla-Moriles, and D.O. Sierras de Málaga. Most Andalusian wine comes from one of these regions, but there are other historic wines without a Protected Geographical Status, for example Tintilla de Rota, Pajarete, Moscatel de Chipiona and Mosto de Umbrete.
Andalusia also produces D.O. vinegar and brandy: D.O. Vinagre de Jerez and D.O. Brandy de Jerez.
Other traditions.
The traditional dress of 18th-century Andalusia was strongly influenced by "majismo" within the context of "casticismo" (purism, traditionalism, authenticity). The archetype of the "majo" and "maja" was that of a bold, pure Spaniard from a lower-class background, somewhat flamboyant in his or her style of dress. This emulation of lower-class dress also extended to imitating the clothes of brigands and Romani ("Gypsy") women.
The Museum of Arts and Traditions of Sevilla has collected representative samples of a great deal of the history of Andalusian dress, including examples of such notable types of hat as the "sombrero cordobés, "sombrero calañés, "sombrero de catite" and the "pavero", as well as the "traje corto" and "traje de flamenca".
Andalusia has a great artisan tradition in tile, leather ("see Shell cordovan"), weaving (especially of the heavy "jarapa" cloth), marquetry, and ceramics (especially in Jaén, Granada, and Almería), lace (especially Granada and Huelva), embroidery (in Andévalo), ironwork, woodworking, and basketry in wicker, many of these traditions a heritage of the long period of Muslim rule.
Andalusia is also known for its dogs, particularly the Andalusian Hound, which was originally bred in the region. Dogs, not just andalusian hounds, are very popular in the region.
Andalusian equestrianism, institutionalized in the Royal Andalusian School of Equestrian Art is known well beyond the borders of Spain. The Andalusian horse is strongly built, compact yet elegant, distinguished in the area of dressage and show jumping, and is also an excellent horse for driving. They are known for their elegant "dancing" gait.
Sports.
Team sports.
In Andalusia, as throughout Spain, football is the predominant sport. Introduced to Spain by British men who worked in mining for Rio Tinto in the province of Huelva, the sport soon became popular with the local population. As Spain's oldest existing football club, Recreativo de Huelva, founded 1889, is known as "El Decano" ("the Dean").
For the 2015/16 season, four Andalusian clubs will compete in Spain's First Division "La Liga": Granada CF, Málaga CF, Real Betis and Sevilla FC. Betis won La Liga in 1934–35 and Sevilla in the 1945–46 season. The four other Andalusian teams, Córdoba CF and UD Almería, play in the Segunda División, whilst Recreativo de Huelva, Spain's oldest club, and Real Jaén participate in the Segunda División B.
The Andalusia autonomous football team is not in any league, and plays only friendly matches. In recent years, they have played mostly during the Christmas break of the football leagues. They play mostly against national teams from other countries, but would not be eligible for international league play, where Spain is represented by a single national team.
In recent decades, basketball has become increasingly popular, with CB Málaga, also known as Unicaja Málaga who have won the Liga ACB in 2007 and the Korać Cup in 2001 and usually play the Euroleague, CB Sevilla (Banca Cívica) and CB Granada competing at the top level in the Liga ACB.
Unlike basketball, handball has never really taken off in Andalusia. There is one Andalusian team in the Liga Asobal, Spain's premier handball league: BM Puente Genil, playing in the provincia of Córdoba.
Andalusia's strongest showing in sports has been in table tennis. There are two professional teams: Cajasur Priego TM and Caja Granada TM, the latter being Spain's leading table tennis team, with more than 20 league championships in nearly consecutive years and 14 consecutive Copas del Rey, dominating the Liga ENEBÉ. Cajasur is also one of the league's leading teams. 
Olympics.
220 Andalusian athletes have competed in a total of 16 summer or winter Olympic Games. The first was Leopoldo Sáinz de la Maza, part of the silver-medal-winning polo team at the 1920 Summer Olympics in Antwerp, Belgium.
In all, Andalusians have won 6 gold medals, 11 silver, and 2 bronze. Winners of multiple medals include the Cordoban boxer Rafael Lozano (bronze in the 1996 Summer Olympics at Atlanta, Georgia, US, and silver in the 2000 Summer Olympics in Sydney, Australia); sailor Theresa Zabell, Malagueña by adoption (gold medals at Barcelona in 1992 and Atlanta in 1996). Other notable winners have been Granadan tennis player Manuel Orantes (silver in the men's singles of the demonstration tournament in Mexico City in 1968), Jerezano riders Ignacio Rambla and Rafael Soto (silver in dressage in Athens in 2004) and the racewalker Paquillo Fernández from Guadix (silver in Athens in 2004).
The largest number of Olympic appearances were by the Malagueña swimmer María Peláez (five appearances), the Granadan skier María José Rienda (four), the Sevillian rider Luis Astolfi (four), and the Sevillian rower Fernando Climent Huerta (four, including a silver at Los Angeles, California, US, in 1984.
Seville has been a pre-candidate to host the Summer Olympics in two occasions, 2004 and 2008, and Granada has been a pre-candidate to host the winter Olympics; neither has ever succeeded in its candidature. The ski resort of Sierra Nevada, near Granada, has however hosted the 1996 Alpine World Ski Championships, and Granada will host the 2015 Winter Universiade.
Other sports.
Other sporting events in Andalusia include surfing, kitesurfing and windsurfing competitions at Tarifa, various golf tournaments at courses along the coast, and horse racing and polo at several locations in the interior. Andalusia hosted the 1999 World Championships in Athletics (Seville), the 2005 Mediterranean Games (Almería) and the FIS Alpine World Ski Championships 1996 (Granada), among other major events. There is also the annual Vuelta a Andalucía bicycle road race and the Linares chess tournament.
Sister region.
Andalusia has a sister region relationship with Buenos Aires, Argentina since 2001.

</doc>
<doc id="2739" url="https://en.wikipedia.org/wiki?curid=2739" title="Abhorrers">
Abhorrers

Abhorrers, the name given in 1679 to the persons who expressed their abhorrence at the action of those who had signed petitions urging King Charles II of England to assemble Parliament.
Feeling against Catholics, and especially against James, Duke of York, was running strongly; the Exclusion Bill had been passed by the House of Commons, and the popularity of James Scott, 1st Duke of Monmouth, was very great.
To prevent this bill from passing into law, Charles had dissolved parliament in July 1679, and in the following October had prorogued its successor, which became known as the Exclusion Bill Parliament, without allowing it to meet. He was then deluged with petitions urging him to call it together, and this agitation was opposed by Sir George Jeffreys and Francis Wythens, who presented addresses expressing "abhorrence" of the "Petitioners," and thus initiated the movement of the abhorrers, who supported the action of the king. "The frolic went all over England," says Roger North; and the addresses of the Abhorrers which reached the king from all parts of the country formed a counterblast to those of the Petitioners. It is said that the terms Whig and Tory were first applied to English political parties in consequence of this dispute.

</doc>
<doc id="2740" url="https://en.wikipedia.org/wiki?curid=2740" title="Abiathar">
Abiathar

Abiathar (אביתר, "Ebyathar", "Evyatar", "the father is pre-eminent" or "father of plenty"), in the Hebrew Bible, son of Ahimelech or Ahijah, High Priest at Nob, the fourth in descent from Eli (1 Sam. 23:6) and the last of Eli's House. The only one of the priests to escape from Saul's massacre, he fled to David at Keilah, taking with him the ephod and other priestly regalies (1 Sam. 22:20 f., 23:6, 9). He was of great service to David, especially at the time of the rebellion of Absalom (2 Sam. 15:24, 29, 35, 20:25). In 1 Kings 4:4 Zadok and Abiathar are found acting together as priests under Solomon. In 1 Kings 1:7, 19, 25, however, Abiathar appears as a supporter of Adonijah, and in 2:22 and 26 it is said that he was deposed by Solomon and banished to Anathoth. In 2 Sam. 8:17 "Abiathar, the son of Achimelech" should be read, with the Syriac, for "Achimelech, the son of Abiathar."
A similar confusion occurs in Gospel of Mark 2:26: in reporting Jesus' words, the evangelist used the name Abiathar when we might expect to see Jesus mention his father Ahimelech. Suggestions made to resolve the difficulty — e.g. that father and son each bore the same double name, or that Abiathar officiated during his father's lifetime and in his father's stead—have been supported by great names, but have not been fully accepted.
When his father and the priests of Nob were slain on the command of Saul, Abiathar escaped, bearing with him the ephod. Rabbinical literature that linked the later extermination of the male descendants of David with the priests of Nob, also link the survival of David's descendant Joash with that of Abiathar. (Sanh. 95b)
Abiathar joined David, who was then in the cave of Adullam (1 Sam. 22:20-23; 23:6). He remained with David, and became priest of the party of which he was the leader (1 Sam. 30:7). When David ascended the throne of Judah, Abiathar was appointed High Priest (1 Chr. 15:11; 1 Kings 2:26) and the "king's counselor" (1 Chr. 27:33-34). Meanwhile, Zadok, of the house of Eleazar, had been made High Priest. According to the Jewish Encyclopedia Abiathar was deposed from office when he was deserted by the Holy Spirit without which the Urim and Thummin could not be consulted. Another version says he was Co-Pontiff with Zadok during King David. He supported Prince Adonijah over Prince Solomon, and was deposed by him and exiled in Anathoth.
These appointments continued in force till the end of David's reign (1 Kings 4:4). Abiathar was deposed (the sole historical instance of the deposition of a high priest) and banished to his home at Anathoth by Solomon, because he took part in the attempt to raise Adonijah to the throne. The priesthood thus passed from the house of Ithamar (1 Sam. 2:30-36; 1 Kings 1:19; 2:26, 27). Zadok now became sole high priest. Abiathar's removal from the Priesthood fulfilled that other part of the curse on the House of Eli—that the Priesthood would pass out of the House of Eli.
Later use of the name.
In Georgian traditions, Abiathar and Sidonia were a legendary Jewish priest of Mtskheta and his daughter. Abiathar is said to have been the first person Saint Nino converted to Christianity.
"Abiathar" (pronounced "Abiathar" (A·bi′a·thar) in Modern Hebrew) is sometimes used a male given name in contemporary Israel (see Eviatar Banai, Eviatar Zerubavel, Eviatar Manor).

</doc>
<doc id="2741" url="https://en.wikipedia.org/wiki?curid=2741" title="Abigail">
Abigail

Abigail (, spelled "Abigal" in in the American Standard Version but not in the King James Version) was the wife of Nabal; she became a wife of David after Nabal's death (1 Samuel ). Abigail is David's third wife, after Saul's daughter, Michal, whom Saul later married to Palti, son of Laish when David went into hiding and Ahinoam.
She became the mother of one of David's sons, who is listed in the Book of Chronicles under the name "Daniel", in the Masoretic Text of the Books of Samuel as "Chileab," and in the Septuagint text of 2 Samuel 3:3 as Δαλουια, "Dalouia".
Biblical history.
In the passage from 1 Samuel, Nabal demonstrates ingratitude towards David, and Abigail attempts to placate David in order to stop him taking revenge. She gives him food, and speaks to him, urging him not to "have on his conscience the staggering burden of needless bloodshed" (verse 31, NIV) and reminding him that God will make him a "lasting dynasty" (verse 28). Jon Levenson calls this an "undeniable adumbration" of Nathan's prophecy in 2 Samuel 7. Alice Bach notes that Abigail pronounces a "crucial prophecy," and the Talmud regards her as one of the Tanakh's seven female prophets. Levenson, however, suggests that she "senses the drift of history" from intelligence rather than from special revelation.
After Abigail reveals to Nabal what she has done, "Yahweh struck Nabal and he died," (v.38), after which David married her. Abigail is described as intelligent and beautiful. The Talmud amplifies this idea, mentioning her as being one of the "four women of surpassing beauty in the world," (the other three being Rahab, Sarah, and Esther). As the wife of the wealthy Nabal, she is also a woman of high socioeconomic status. Whether David married her because he was attracted to her, or as an astute political move, or both is unclear.
Abigail and David's third wife, Ahinoam the Jezreelite, accompany David and his war band when they seek refuge in Philistine territory. While David and his men were encamped near Jezreel, and when they are captured by Amalekites raided the town of Ziglak and carried off the women and children. David led the pursuit and they were subsequently rescued. Both wives then settle with David in Hebron, where Abigail gives birth to David’s second son, Chileab (also called Daniel).
Abigail is also listed as one of the seven Jewish women prophets, the other six being Miriam, Deborah, Hannah, Sarah, Huldah,and Esther. In terms of her moral character, Abraham Kuyper argues that Abigail's conduct indicates "a most appealing character and unwavering faith," but Alice Bach regards her as subversive.
Adele Berlin contrasts the story of Abigail with that of Bathsheba. In one, the wife prevents David from murdering her foolish and greedy husband. In the second, David orders the murder of a good man because he desires his wife. "In the Abigail story, David, the potential king, is seen as increasingly strong and virtuous, whereas in the Bathsheba story, the reigning monarch shows his flaws ever more overtly and begins to lose control of his family."
Levenson and Halpern suggest that Abigail may, in fact, also be the same person as Abigail, mother of Amasa. Richard M. Davidson, however, points out that "on the basis of the final form of Old Testament canon, references to Abigail in the biblical accounts indicate two different individuals."
Generic use.
Abigail's self-styling as a "handmaid" led to "Abigail" being the traditional term for a waiting-woman, for example as the "waiting gentlewoman" in Beaumont and Fletcher's "The Scornful Lady", published in 1616. Jonathan Swift and Henry Fielding use "Abigail" in this generic sense, as does Charlotte Brontë. Anthony Trollope makes two references to "the abigail" (all lower case) in "The Eustace Diamonds", at the beginning of Chapter 42, whilst Thomas Mann makes the same reference at the start of the second chapter of Part 2 in Buddenbrooks (published in 1901). William Rose Benet notes the notoriety of Abigail Hill, better known as "Mrs Masham", a lady-in-waiting to Queen Anne. George MacDonald Fraser makes mention of "an "abigail" fussing about the room" in his novel "Flashman" from "The Flashman Papers" series.
In art.
Abigail is a featured figure on Judy Chicago's installation piece "The Dinner Party", being represented in one of the 999 tiles of the "Heritage Floor."

</doc>
<doc id="2742" url="https://en.wikipedia.org/wiki?curid=2742" title="Abila">
Abila

Abila is the name of several places:

</doc>
<doc id="2745" url="https://en.wikipedia.org/wiki?curid=2745" title="Azad Kashmir">
Azad Kashmir

Azad Jammu and Kashmir ( "Azad Jammu o Kashmir"), abbreviated as AJK and commonly known as Azad Kashmir, AJK translated into English means The Free State Jammu and Kashmir, is a self-governing administrative division of Pakistan. The territory lies west of the Indian-administered state of Jammu and Kashmir, and was previously part of the former princely state of Jammu and Kashmir, which ceased to exist as a result of the first Kashmir war fought between India and Pakistan in 1947.
Azad Kashmir is part of the greater Kashmir region, which is the subject of a long-running conflict between India and Pakistan. The territory shares a border with Gilgit–Baltistan, together with which it is referred to by the United Nations and other international organisations as "Pakistan-administered Kashmir".
The territory also borders Pakistan's Punjab province to the south and Khyber Pakhtunkhwa province to the west. To the east, Azad Kashmir is separated from the Indian-administered state of Jammu and Kashmir by the Line of Control, the "de facto" border between India and Pakistan. Azad Kashmir has a total area of , with an estimated population of around 4.6 million people.
The territory has a parliamentary form of government, with its capital located at Muzaffarabad. The President of Azad Jammu and Kashmir is the constitutional head of the state, while the prime minister, supported by a Council of Ministers, is the chief executive. The unicameral Azad Jammu & Kashmir Legislative Assembly elects both the prime minister and president. The state has its own Supreme Court and a High Court, while the Government of Pakistan's Ministry of Kashmir Affairs serves as a link between it and Azad Kashmir's government. Neither Azad Kashmir nor Gilgit-Baltistan elect members to Pakistan's National Assembly.
A 2005 earthquake killed 100,000 people and left another three million people displaced, with widespread devastation. Since then, with help from the Government of Pakistan and foreign donors, reconstruction of infrastructure is underway. Azad Kashmir's economy largely depends on agriculture, services, tourism, and remittances sent by members of the British Mirpuri community. The territory's official language is Urdu, although Pahari, Hindko, Gojri, Punjabi, and Pashto are also spoken. It has a literacy rate of approximately 64%.
History.
At the time of the Partition of India in 1947, the British abandoned their suzerainty over the princely states, which were left with the options of joining India or Pakistan or remaining independent. Hari Singh, the maharaja of Jammu and Kashmir, Wanted his state to remain independent.
In Spring 1947, an uprising against the Maharaja broke out in Poonch, an area bordering the Rawalpindi division of West Punjab. Maharaja's administration is said to have started levying punitive taxes on the peasantry which provoked a local revolt and the administration resorted to brutal suppression. The area's population, swelled by recently demobilised soldiers following World War II, rebelled against the Maharaja's forces and gained control of almost the entire district. Following this victory, the pro-Pakistan chieftains of the western Jammu districts of Muzaffarabad, Poonch and Mirpur proclaimed a provisional Azad Jammu and Kashmir government in Rawalpindi on 3October 1947.
On 21October, several thousand Pashtun tribesmen from North-West Frontier Province poured into Jammu and Kashmir to liberate it from the Maharaja's rule. They were led by experienced military leaders and were equipped with modern arms. The Maharaja's crumbling forces were unable to withstand the onslaught. The raiders captured the towns of Muzaffarabad and Baramulla, the latter northwest of the state capital Srinagar. On 24October, the Maharaja requested military assistance from India, which responded that it was unable to help him unless he acceded to India. Accordingly, on 26October 1947, Maharaja Hari Singh signed an Instrument of Accession, handing over control of defence, external affairs and communications to the Government of India in return for military aid. Indian troops were immediately airlifted into Srinagar. Pakistan intervened subsequently. Fighting ensued between the Indian and Pakistani armies, with the two areas of control more or less stabilised around what is now known as the "Line of Control".
India later approached the United Nations, asking it to resolve the dispute, and resolutions were passed in favour of the holding of a plebiscite with regard to Kashmir's future. However, no such plebiscite has ever been held on either side, since there was a precondition which required the withdrawal of the Pakistani Army along with the non-state elements and the subsequent partial withdrawal of the Indian Army. from the parts of Kashmir under their respective control – a withdrawal that never took place. In 1949, a formal cease-fire line separating the Indian- and Pakistani-controlled parts of Kashmir came into effect.
Following the 1949 cease-fire agreement with India, the government of Pakistan divided the northern and western parts of Kashmir that it occupied at the time of cease-fire into the following two separately-controlled political entities:
At one time under Pakistani control, Kashmir's Shaksgam tract, a small region along the northeastern border of Gilgit–Baltistan, was provisionally ceded by Pakistan to the People's Republic of China in 1963 and now forms part of China's Xinjiang Uygur Autonomous Region.
In 1972, the then current border between the Indian and Pakistani controlled parts of Kashmir was designated as the "Line of Control". This line has remained unchanged since the 1972 Simla Agreement, which bound the two countries "to settle their differences by peaceful means through bilateral negotiations". Some political experts claim that, in view of that pact, the only solution to the issue is mutual negotiation between the two countries without involving a third party such as the United Nations. The 1974 Interim Constitution Act was passed by the 48-member Azad Jammu and Kashmir unicameral assembly.
Government.
Azad Jammu and Kashmir (AJK) is a self-governing state under Pakistani control, but under Pakistan's constitution the state is not formally a part of the country as the dispute on Azad Kashmir has not yet been resolved. Pakistan is administering the region as a self-governing territory rather than incorporating it in the federation since the UN mandated ceasefire. Azad Kashmir has its own elected President, Prime Minister, Legislative Assembly, High Court, with Azam khan as its present chief justice, and official flag. The government of Pakistan has not yet allowed Azad Kashmir to issue its own postage stamps, meaning that those of Pakistan are used instead. Brad Adams the Asia director at the U.S. based NGO Human Rights Watch has said in 2006 Although ‘azad’ means ‘free,’ the residents of Azad Kashmir are anything but, The Pakistani authorities govern Azad Kashmir with strict controls on basic freedoms. The Government of Azad Kashmir has very little control over its territory, with its politicians mainly spending their time in Islamabad.
Azad Kashmir's financial matters, i.e., budget and tax affairs, are dealt with by the Azad Jammu and Kashmir Council rather than by Pakistan's Central Board of Revenue. The Azad Jammu and Kashmir Council is a supreme body consisting of 14 members, 8 from the government of Azad Jammu and Kashmir and 6 from the government of Pakistan. Its chairman/chief executive is the prime minister of Pakistan. Other members of the council are the president and the prime minister of Azad Kashmir(or and individual nominated by her/him) and 6 members of the AJK Legislative Assembly. Azad Kashmir Day is celebrated in Azad Jammu and Kashmir on October 24, which is the day that the Azad Jammu and Kashmir government was created in 1947. Pakistan has celebrated Kashmir Solidarity Day on February 5 of each year since 1990 as a day of protest against India's "de facto" sovereignty over its State of Jammu and Kashmir. That day is a national holiday in Pakistan. Kashmiris in Azad Kashmir observe the Kashmir Black Day on October 27 of each year since 1947 as day of protest against military occupation in Indian controlled Jammu and Kashmir.
Administrative divisions.
The state is administratively divided into three divisions which, in turn, are divided into ten districts.
Geography and climate.
The northern part of Azad Jammu and Kashmir encompasses the lower part of the Himalayas, including Jamgarh Peak (15,531 feet meters). However, Sarwali peak in the Neelum Valley is the highest peak in the state. Fertile, green, mountainous valleys are characteristic of Azad Kashmir's geography, making it one of the most beautiful regions on the subcontinent.
The southern parts of Azad Kashmir including Bhimber, Mirpur and Kotli districts has extremely hot weather in summers and moderate cold weather in winters. It receives rains mostly in monsoon weather.
In the central and northern parts of state weather remains moderate hot in summers and very cold and chilly in winter. Snow fall also occurs there in December and January.
This region receives rainfall in both winters and summers. Muzaffarabad and Pattan are among the wettest areas of the state. Throughout most of the region, the average rainfall exceeds 1400 mm, with the highest average rainfall occurring near Muzaffarabad (around 1800 mm). During summer, monsoon floods of the Jhelum and Leepa rivers are common, due to high rainfall and melting snow.
Culture.
The culture of Azad Kashmir has many similarities to that of northern Punjabi (Potohar) culture in Punjab province. The natives of Azad Kashmir speak Urdu, Potwari, and the Pahari languages. The traditional dress of the women is the shalwar kameez in Pahari style. The shalwar kameez is commonly worn by both men and women. Women use shawl to cover their head and upper body.
The popular and traditional cuisines of Azad Kashmir are Raan (Fried leg of Lamb), Rogan Josh, Balti Gosht, Dal Chawal (A mixture of split peas, split red lentils, and boiled rice), and Dam Aloo (Fried Potatoes). The traditional drink of the region is tea.
Ethnic groups.
Azad Jammu and Kashmir is almost entirely Muslim. This inhabitants of this region are of many communities and tribes who share ethnic and linguistic similarities with the people of Northern Punjab. While Urdu is the official language of the region, other languages commonly spoken are Pahari, Gojri and Potohari. The main communities living in this region are as follows:
Gurjar-They are an agricultural tribe and are estimated to be the largest community living in Azad Jammu and Kashmir.
Jat- They are one of the larger community of AJK and primarily inhabit the Districts of Mirpur, Bhimber and Kotli. A large Mirpuri population lives in the UK and it is estimated that more people of Mirpuri origins are now residing in the UK than in Mirpur district. The district Mirpur retains strong ties with the UK.
Pahari Rajputs- They are a community of Pahari speaking Rajputs like Jarral Rajputs, Thakial Rajputs, etc. They primarily inhabit the Districts of Muzaffarabad, Bagh, Mirpur, Bhimber and Kotli
Sudhan- They are a large clan living in Poonch, Sudhanoti, Bagh and Kolti districts.
Abbasi- They are a large clan in Azad Jammu and Kashmir and mostly live in Bhag, Hattian Bala and Muzaffarabad districts. Besides Azad Kashmir, they also inhabit, Abbottabad and upper Potohar Punjab in large numbers.
Awan - A clan with significant numbers found in Azad Jammu and Kashmir, living mainly in the Poonch, Hattian Bala and Muzaffarabad districts. Besides Azad Kashmir they also reside in Punjab and Khyber Pakhtunkhwa in large numbers.
Economy.
Historically the economy of these areas now called ‘Azad’ Kashmir has been agricultural which meant that land was the main source or mean of production. This means that all food for immediate and long term consumption was produced from land. The produce included various crops, fruits, vegetables etc. Land was also the source of other livelihood necessities such as wood, fuel, grazing for animals which then turned into dairy products. Because of this land was also the main source of revenue for the governments whose primary purpose for centuries was to accumulate revenue.
Agriculture is a major part of Azad Kashmir's economy. Low-lying areas that have high populations grow crops like barley, mangoes, millet, corn (maize), and wheat, and also raise cattle. In the elevated areas that are less populated and more spread-out, forestry, corn, and livestock are the main sources of income. There are mineral and marble resources in Azad Kashmir close to Mirpur and Muzaffarabad. There are also graphite deposits at Mohriwali. There are also reservoirs of low-grade coal, chalk, bauxite, and zircon. Local household industries produce carved wooden objects, textiles, and dhurrie carpets. There is also an arts and crafts industry that produces such cultural goods as namdas, shawls, pashmina, pherans, Papier-mâché, basketry copper, rugs, wood carving, silk and woolen clothing, patto, carpets, namda gubba, and silverware. Agricultural goods produced in the region include mushrooms, honey, walnuts, apples, cherries, medicinal herbs and plants, resin, deodar, kail, chir, fir, maple, and ash timber.
The migration to UK was accelerated and by the completion of Mangla Dam in 1967 the process of ‘chain migration’ became in full flow. Today, remittances from British Mirpuri community make a critical role in AJK's economy. In the mid-1950s various economic and social development processes were launched in Azad Kashmir. In the 1960s, with the construction of the Mangla Dam in Mirpur District, the Azad Jammu and Kashmir Government began to receive royalties from the Pakistani government for the electricity that the dam provided to Pakistan. During the mid-2000s, a multibillion-dollar reconstruction began in the aftermath of the 2005 Kashmir earthquake.
In addition to agriculture, textiles, and arts and crafts, remittances have played a major role in the economy of Azad Kashmir. One analyst estimated that the figure for Azad Kashmir was 25.1% in 2001. With regard to annual household income, people living in the higher areas are more dependent on remittances than are those living in the lower areas. In the latter part of 2006, billions of dollars for development were mooted by international aid agencies for the reconstruction and rehabilitation of earthquake-hit zones in Azad Kashmir, though much of that amount was subsequently lost in bureaucratic channels, leading to considerable delays in help getting to the most needy. Hundreds of people continued to live in tents long after the earthquake. A land-use plan for the city of Muzaffarabad was prepared by the Japan International Cooperation Agency.
Kashmir as a whole is the one of the most beautiful regions in the world. Some well-known and popular tourist destinations are the following:
Education.
The literacy rate in Azad Kashmir was 62% in 2004, higher than in any region in Pakistan. However, only 2.2% were graduates, compared to the average of 2.9% for Pakistan.
Universities.
The following is a list of universities recognised by Higher Education Commission of Pakistan (HEC):
Medical colleges.
The following is a list of undergraduate medical institutions recognised by Pakistan Medical and Dental Council (PMDC) as of 2013.
Sports.
In terms of sports, football, cricket and volleyball are very popular in Azad Kashmir. Many tournaments are also held throughout the year and in the holy month of Ramazan night time floodlit tournaments are also organised.
Mirpur has a cricket stadium (Quaid-e-Azam Stadium) which has been taken over by the Pakistan Cricket Board for renovation to bring it up to International standards. There is also a cricket stadium in Muzaffarabad with the capacity of 8,000 people. This stadium has hosted 8 matches of Inter-District Under 19 Tournament 2013.
There are also registered football clubs namely, Pilot Football Club,Youth Football Club and Kashmir National FC. Pilot FC is the current champion of the District Football Association Cup (DFA Cup). Mirpur also takes part in the All AJK Football Championship, last year Mirpur was the winner after beating Rawalakot in the final.

</doc>
<doc id="2747" url="https://en.wikipedia.org/wiki?curid=2747" title="Arabian Sea">
Arabian Sea

The Arabian Sea (Also Persian Sea) is a region of the northern Indian Ocean bounded on the north by Pakistan and Iran, on the west by northeastern Somalia and the Arabian Peninsula, and on the east by India. Historically the sea has been known by other names including the Erythraean Sea and the Persian Sea. Its total area is and its maximum depth is . The Gulf of Aden is in the southwest, connecting the Arabian Sea to the Red Sea through the strait of Bab-el-Mandeb, and the Gulf of Oman is in the northwest, connecting it to the Persian Gulf.
The Arabian Sea has been crossed by important marine trade routes since the third or second millennium BCE. Major seaports include Jawaharlal Nehru Port in Mumbai, the Port of Karachi and the Gwadar Port in Pakistan and the Port of Salalah in Oman. Other important ports include in India, Kandla Port, Jawaharlal Nehru Port, Vizhinjam Port, Trivandrum, Mumbai Port, and Mormugao in Goa. The largest islands in the Arabian Sea include Socotra (Yemen), Masirah Island (Oman), Astola Island (Pakistan) and Andrott (India).
Geography.
The Arabian Sea's surface area is about . The maximum width of the Sea is approximately , and its maximum depth is . The biggest river flowing into the Sea is the Indus River.
The Arabian Sea has two important branches — the Gulf of Aden in the southwest, connecting with the Red Sea through the strait of Bab-el-Mandeb; and the Gulf of Oman to the northwest, connecting with the Persian Gulf. There are also the gulfs of Khambhat and Kutch on the Indian coast.
The countries with coastlines on the Arabian Sea are Somalia, Djibouti, Yemen, Oman, Iran, Pakistan, India and the Maldives. There are several large cities on the sea's coast including Karachi, Gwadar, Pasni, Ormara, Aden, Muscat, Mumbai, Keti Bandar, Salalah, Duqm and Trivandrum.
Limits.
The International Hydrographic Organization defines the limits of the Arabian Sea as follows:
"On the West." The Eastern limit of the Gulf of Aden meridian of Cape Guardafui (Ras Asir, 51°16'E).
"On the North." A line joining Ràs al Hadd, East point of Arabia (22°32'N) and Ràs Jiyùni (61°43'E) on the coast of Pakistan.
"On the South." A line running from the South extremity of Addu Atoll (Maldives), to the Eastern extreme of Ràs Hafun (Africa, 10°26'N).
"On the East." The Western limit of the Laccadive Sea line running from Sadashivgad Lt. on West Coast of India () to Corah Divh () and thence down the West side of the Laccadive and Maldive Archipelagos to the most Southerly point of Addu Atoll in the Maldives.
Alternative names.
The Arabian Sea historically and geographically has been referred to by many different names by Arab travellers and European geographers, that include Indian Sea, Persian Sea, Sindhu Sagar, Erythraean Sea, Sindh Sea, and Akhzar Sea.
Trade routes.
The Arabian Sea has been an important marine trade route since the era of the "coastal sailing vessels" from possibly as early as the 3rd millennium BCE, certainly the late 2nd millennium BCE through the later days known as the Age of Sail. By the time of Julius Caesar, several well-established combined land-sea trade routes depended upon water transport through the Sea around the rough inland terrain features to its north.
These routes usually began in the Far East or down river from Madhya Pradesh with transshipment via historic Bharuch (Bharakuccha), traversed past the inhospitable coast of today's Iran then split around Hadhramaut into two streams north into the Gulf of Aden and thence into the Levant, or south into Alexandria via Red Sea ports such as Axum. Each major route involved transhipping to pack animal caravan, travel through desert country and risk of bandits and extortionate tolls by local potentiates.
This southern coastal route past the rough country in the southern Arabian peninsula (Yemen and Oman today) was significant, and the Egyptian Pharaohs built several shallow canals to service the trade, one more or less along the route of today's Suez canal, and another from the Red Sea to the Nile River, both shallow works that were swallowed up by huge sand storms in antiquity. Later the kingdom of Axum arose in Ethiopia to rule a mercantile empire rooted in the trade with Europe via Alexandria.
Major ports.
Jawaharlal Nehru Port in Mumbai is the largest port in Arabian sea, and the largest container port in India.
The Port of Karachi (Urdu: بندر گاہ كراچى, "") is Pakistan's largest and busiest seaport, handling about 60% of the nation's cargo (25 million tons per annum). It is located between the Karachi towns of Kiamari and Saddar, close to the main business district and several industrial areas. The geographic position of the port places it in close proximity to major shipping routes such as the Strait of Hormuz. The history of the port is intertwined with that of the city of Karachi. Several ancient ports have been attributed in the area including "Krokola", "Morontobara" (Woman's Harbour) (mentioned by Nearchus), Barbarikon (the Periplus of the Erythraean Sea, and Debal (a city invaded and captured by the Muslim general Muhammad bin Qasim in 712 AD). There is a reference to the early existence of the port of Karachi in the "Umdah", by the Arab navigator Sulaiman al Mahri (AD 1511), who mentions "Ras al Karazi" and "Ras Karashi" while describing a route along the coast from Pasni to Ras Karashi.
Karachi is also mentioned in the sixteenth century Turkish treatise Mirat ul Memalik (Mirror of Countries, 1557) by the Ottoman captain Seydi Ali Reis, which is a compilation of sailing directions from the Portuguese island of Diu to Hormuz in the Persian Gulf. It warns sailors about whirlpools and advises them to seek safety in "Kaurashi" harbour if they found themselves drifting dangerously.
The gate facing the sea was called "Kharadar" (salt gate), and the gate facing the Lyari River was called "Mithadar" (sweet gate). The modern neighbourhoods around the location of the gates are called Mithadar and Kharadar. Surrounded by mangrove swamps to the east, the sea to the southwest, and the Lyari River to the north, the town was well defended and engaged in a profitable trade with Muscat and Bahrain.
The Gwadar Port is a warm-water, deep-sea port situated at Gwadar in Balochistan, Pakistan at the apex of the Arabian Sea and at the entrance of the Persian Gulf, about 460 km west of Karachi and approximately 75 km (47 mi) east of Pakistan's border with Iran. The port is located on the eastern bay of a natural hammerhead-shaped peninsula jutting out into the Arabian Sea from the coastline.
Port of Salalah in Salalah, Oman is also a major port in the area. From a modest start in 1997, the Omani container transhipment port has achieved consistent growth. For a growing number of ships’ crew, the port of Salalah is a welcome sight after an unpleasant and often prolonged encounter with pirates.
The Port of Salalah is a key container transhipment hub on the Arabian Sea and is often used as the first port of call for vessels whose crew have just been released from the clutches of Somali pirates following ransom payments for withheld vessels and crew.
The port also plays host as a supply base for the visiting warships that provide protective escorts for merchant shipping in the sea lanes.
From that dual role has emerged another, one as an intelligence network — both military and civilian — to exchange information on possible pirate sightings and near misses. Also, the International Task Force often uses the port as a base. There is a significant number of warships of all nations coming in and out of the port, which makes it a very safe bubble. The port handled just under 3.5m teu in 2009
Major Indian ports in the Arabian Sea are Kandla Port, Nava Sheva, Trivandrum, Mumbai Port, and Mormugão.
Islands.
There are several islands in the Arabian Sea, with the largest being Socotra (Yemen), Masirah (Oman), Astola Island (Pakistan) and Andrott (India).
Astola Island, also known as "Jezira Haft Talar" () or 'Island of the Seven Hills', is a small, uninhabited island in the northern tip of the Arabian Sea in Pakistan's territorial waters. It is a popular eco-tourism destination in the region. Overnight tourists camp on the island and bring their own provisions. Camping, fishing and scuba-diving expeditions are popular. It is also a site for observing turtle breeding. Endangered animals such as the green turtle ("Chelonia mydas") and the Hawksbill turtle ("Eretmochelys imbracata") nest on the beach at the foot of the cliffs. The island is also a very important area for endemic reptiles such as the Astola Viper ("Echis carinatus astolae").
Socotra ( '), also spelled Soqotra, is the largest island, being part of a small archipelago of four islands. It lies some east of the Horn of Africa and south of the Arabian Peninsula. The island is very isolated and through the process of speciation, a third of its plant life is found nowhere else on the planet. It has been described as the most alien-looking place on Earth.
Masirah () is an island off the East coast of Oman. The main industries here are fishing and traditional textile manufacturing. Formerly, traditional ship building was important. The rugged terrain of the island and surrounding rough coastline has led to the appearance of many wrecked dhows on the beaches of the island, most of them well preserved by the salt water and intense heat. The ocean bottom environment surrounding Masirah is hostile as the majority of the area is covered in either sand or hard rock. Despite the poor quality ocean bottom, the area is very productive with marine fisheries, and any hard objects (barrels, engines) are immediately colonized by local fauna.

</doc>
<doc id="2752" url="https://en.wikipedia.org/wiki?curid=2752" title="Aspartame">
Aspartame

Aspartame (APM; or ) is an artificial, non-saccharide sweetener used as a sugar substitute in some foods and beverages. In the European Union, it is codified as E951. Aspartame is a methyl ester of the aspartic acid/phenylalanine dipeptide. It was first sold under the brand name NutraSweet. It was first synthesized in 1965, and the patent expired in 1992.
The safety of aspartame has been the subject of several political and medical controversies, United States congressional hearings and Internet hoaxes since its initial approval for use in food products by the U.S. Food and Drug Administration (FDA) in 1981. The European Food Safety Authority concluded in its 2013 re-evaluation that aspartame and its breakdown products are safe for human consumption at current levels of exposure, corroborating other medical reviews. However, because its breakdown products include phenylalanine, aspartame must be avoided by people with the genetic condition phenylketonuria (PKU).
Chemistry.
Aspartame is a methyl ester of the dipeptide of the natural amino acids L-aspartic acid and L-phenylalanine. Under strongly acidic or alkaline conditions, aspartame may generate methanol by hydrolysis. Under more severe conditions, the peptide bonds are also hydrolyzed, resulting in free amino acids.
While known aspects of synthesis are covered by patents, many details are proprietary. Two approaches to synthesis are used commercially. In the chemical synthesis, the two carboxyl groups of aspartic acid are joined into an anhydride, and the amino group is protected by a compound that will prevent further reactions of that group. Phenylalanine is methylated and combined with the "N"-protected aspartic anhydride; then the blocking group is removed from aspartic acid by acid hydrolysis. The drawback of this technique is that a byproduct, the bitter-tasting β-form, is produced when the wrong carboxyl group from aspartic acid links to phenylalanine. A process using an enzyme from "Bacillus thermoproteolyticus" to catalyze the condensation of the chemically altered amino acids will produce high yields without the β-form byproduct. A variant of this method, which has not been used commercially, uses unmodified aspartic acid, but produces low yields. Methods for directly producing aspartyl-phenylalanine by enzymatic means, followed by chemical methylation, have also been tried, but not scaled for industrial production.
Properties and use.
Aspartame is approximately 200 times sweeter than sucrose (table sugar). Due to this property, even though aspartame produces four kilocalories of energy per gram (/g) when metabolized, the quantity of aspartame needed to produce a sweet taste is so small that its caloric contribution is negligible. The taste of aspartame and other artificial sweeteners differs from that of table sugar in the times of onset and how long the sweetness lasts, though aspartame comes closest to sugar's taste profile among approved artificial sweeteners. The sweetness of aspartame lasts longer than that of sucrose, so it is often blended with other artificial sweeteners such as acesulfame potassium to produce an overall taste more like sugar. Aspartame can be synthesized from its constituent amino acids, L-phenylalanine and L-aspartate.
Like many other peptides, aspartame may hydrolyze (break down) into its constituent amino acids under conditions of elevated temperature or high pH. This makes aspartame undesirable as a baking sweetener, and prone to degradation in products hosting a high pH, as required for a long shelf life. The stability of aspartame under heating can be improved to some extent by encasing it in fats or in maltodextrin. The stability when dissolved in water depends markedly on pH. At room temperature, it is most stable at pH 4.3, where its half-life is nearly 300 days. At pH 7, however, its half-life is only a few days. Most soft-drinks have a pH between 3 and 5, where aspartame is reasonably stable. In products that may require a longer shelf life, such as syrups for fountain beverages, aspartame is sometimes blended with a more stable sweetener, such as saccharin.
Aspartame's major decomposition products are its cyclic dipeptide (in a 2,5-diketopiperazine, or DKP, form), the de-esterified dipeptide (aspartyl-phenylalanine), and its constituent components, phenylalanine, aspartic acid, and methanol. At 180 °C, aspartame undergoes decomposition to form a diketopiperazine derivative.
In products such as powdered beverages, the amine in aspartame can undergo a Maillard reaction with the aldehyde groups present in certain aroma compounds. The ensuing loss of both flavor and sweetness can be prevented by protecting the aldehyde as an acetal.
Descriptive analyses of solutions containing aspartame report a sweet aftertaste as well as bitter and off-flavor aftertastes.
Discovery and approval.
Aspartame was discovered in 1965 by James M. Schlatter, a chemist working for G.D. Searle & Company. Schlatter had synthesized aspartame as an intermediate step in generating a tetrapeptide of the hormone gastrin, for use in assessing an anti-ulcer drug candidate. He accidentally discovered its sweet taste when he licked his finger, which had become contaminated with aspartame, to lift up a piece of paper.
In 1975, prompted by issues regarding Flagyl and Aldactone, a U.S. FDA task force team reviewed 25 studies submitted by the manufacturer, including 11 on aspartame. The team reported "serious deficiencies in Searle's operations and practices". The FDA sought to authenticate 15 of the submitted studies against the supporting data. In 1979, the Center for Food Safety and Applied Nutrition (CFSAN) concluded, since many problems with the aspartame studies were minor and did not affect the conclusions, the studies could be used to assess aspartame's safety.
In 1980, the FDA convened a Public Board of Inquiry (PBOI) consisting of independent advisors charged with examining the purported relationship between aspartame and brain cancer. The PBOI concluded aspartame does not cause brain damage, but it recommended against approving aspartame at that time, citing unanswered questions about cancer in laboratory rats.
Citing data from a Japanese study that had not been available to the members of the PBOI, and after seeking advice from an expert panel that found fault with statistical analyses underlying the PBOI's hesitation, yet argued against approval, FDA commissioner Hayes approved aspartame for use in dry goods. In 1983, the FDA further approved aspartame for use in carbonated beverages, and for use in other beverages, baked goods, and confections in 1993. In 1996, the FDA removed all restrictions from aspartame, allowing it to be used in all foods.
Several European Union countries approved aspartame in the 1980s, with EU-wide approval in 1994. The European Commission Scientific Committee on Food reviewed subsequent safety studies and reaffirmed the approval in 2002. The European Food Safety Authority reported in 2006 that the previously established Acceptable daily intake was appropriate, after reviewing yet another set of studies.
Safety and approval controversies.
Aspartame has been found to be safe for human consumption by more than ninety countries worldwide, with FDA officials describing aspartame as "one of the most thoroughly tested and studied food additives the agency has ever approved" and its safety as "clear cut", but has been the subject of several controversies, hoaxes and health scares.
Initially aspartame was approved by the U.S. Food and Drug Administration (FDA) in 1974; however, problems with Searle's safety testing program, including testing of aspartame, were discovered subsequently. The approval was rescinded the following year, but after outside reviews of the problematic tests and additional testing, final approval was granted in 1981. Because allegations of conflicts of interest marred the FDA's approval of aspartame, the U.S. Government Accountability Office reviewed the actions of involved officials in 1986 and the approval process in 1987; neither the allegations of conflict of interest nor problems in the final approval process were substantiated.
In addition, the Centers for Disease Control investigated in 1984 and was unable to find any significant epidemiological associations to serious risk or harm.
Since December 1998, a widely circulated email hoax cited aspartame as the cause of numerous diseases.
The weight of existing scientific evidence indicates that aspartame is safe at current levels of consumption as a non-nutritive sweetener. Reviews conducted by regulatory agencies decades after aspartame was first approved have supported its continued availability.
Safety and health effects.
The safety of aspartame has been studied extensively since its discovery with research that includes animal studies, clinical and epidemiological research, and postmarketing surveillance. Aspartame is one of the most rigorously tested food ingredients. Peer-reviewed comprehensive review articles and independent reviews by governmental regulatory bodies have analyzed the published research on the safety of aspartame and have found aspartame is safe for consumption at current levels. Aspartame has been deemed safe for human consumption by over 100 regulatory agencies in their respective countries, including the UK Food Standards Agency, the European Food Safety Authority (EFSA) and Health Canada.
Intake.
The acceptable daily intake (ADI) value for aspartame, as well as other food additives studied, is defined as the "amount of a food additive, expressed on a body weight basis, that can be ingested daily over a lifetime without appreciable health risk." The Joint FAO/WHO Expert Committee on Food Additives (JECFA) and the European Commission's Scientific Committee on Food has determined this value is 40 mg/kg of body weight for aspartame, while FDA has set its ADI for aspartame at 50 mg/kg.
The primary source for exposure to aspartame in the United States is diet soft drinks, though it can be consumed in other products, such as pharmaceutical preparations, fruit drinks, and chewing gum among others in smaller quantities. A 12 US fluid ounce (355 ml) can of diet soda contains of aspartame, and for a adult, it takes approximately 21 cans of diet soda daily to consume the of aspartame that would surpass the FDA's 50 milligrams per kilogram of body weight ADI of aspartame from diet soda alone.
Reviews have analyzed studies which have looked at the consumption of aspartame in countries worldwide, including the United States, countries in Europe and Australia, among others. These reviews have found that even the high levels of intake of aspartame, studied across multiple countries and different methods of measuring aspartame consumption, are well below the ADI for safe consumption of aspartame. Reviews have also found that populations that are believed to be especially high consumers of aspartame such as children and diabetics are below the ADI for safe consumption, even considering extreme worst-case scenario calculations of consumption.
In a report released on 10 December 2013, the EFSA said that, after an extensive examination of evidence, it ruled out the "potential risk of aspartame causing damage to genes and inducing cancer," and deemed the amount found in diet sodas an amount safe to consume.
Metabolites.
Aspartame is rapidly hydrolyzed in the small intestines. Even with ingestion of very high doses of aspartame (over 200 mg/kg), no aspartame is found in the blood due to the rapid breakdown. These metabolites have been studied in a wide range of populations including infants, children, adolescents, and healthy adults. In healthy adults and children, even enormous doses of aspartame do not lead to plasma levels of metabolites that are a concern for safety.
Upon ingestion, aspartame breaks down into residual components, including aspartic acid, phenylalanine, methanol, in ratio of 4:5:1 by mass and further breakdown products including formaldehyde and formic acid, accumulation of the latter being suspected as the major cause of injury in methanol poisoning. Human studies show that formic acid is excreted faster than it is formed after ingestion of aspartame. In some fruit juices, "higher" concentrations of methanol can be found than the amount produced from aspartame in beverages.
Aspartate.
Aspartic acid (aspartate) is one of the most common amino acids in the typical diet. As with methanol and phenylalanine, intake of aspartic acid from aspartame is less than would be expected from other dietary sources. At the 90th percentile of intake, aspartame provides only between 1% and 2% of the daily intake of aspartic acid. There has been some speculation that aspartame, in conjunction with other amino acids like glutamate, may lead to excitotoxicity, inflicting damage on brain and nerve cells. However, clinical studies have shown no signs of neurotoxic effects, and studies of metabolism suggest it is not possible to ingest enough aspartic acid and glutamate through food and drink to levels that would be expected to be toxic.
Methanol.
The methanol produced by the metabolism of aspartame is absorbed and quickly converted into formaldehyde and then completely oxidized to formic acid, which, due to its long half life, is considered the primary mechanism of toxicity in methanol poisoning. The methanol from aspartame is unlikely to be a safety concern for several reasons. The amount of methanol in aspartame is less than that found in fruit juices and citrus fruits, and there are other dietary sources for methanol such as fermented beverages. Therefore, the amount of methanol produced from aspartame is likely to be less than that from natural sources. With regard to formaldehyde, it is rapidly converted in the body, and the amounts of formaldehyde from the metabolism of aspartame are trivial when compared to the amounts produced routinely by the human body and from other foods and drugs. At the highest expected human doses of consumption of aspartame, there are no increased blood levels of methanol or formic acid, and ingesting aspartame at the 90th percentile of intake would produce 25 times less methanol than what would be considered toxic.
Phenylalanine and phenylketonuria.
High levels of the naturally-occurring essential amino acid phenylalanine are a health hazard to those born with phenylketonuria (PKU), a rare inherited disease that prevents phenylalanine from being properly metabolized. Since individuals with PKU must consider aspartame as an additional source of phenylalanine, foods containing aspartame sold in the United States must state "Phenylketonurics: Contains Phenylalanine" on their product labels.
In the UK, foods that contain aspartame are legally required by the country's Food Standards Agency to list the substance among the product's ingredients and carry the warning "Contains a source of phenylalanine" – this is usually at the foot of the list of ingredients. Manufacturers are also required to print '"with sweetener(s)" on the label close to the main product name on foods that contain "sweeteners such as aspartame" or "with sugar and sweetener(s)" on "foods that contain both sugar and sweetener".
In Canada, foods that contain aspartame are legally required by the country to list the substance among the product's ingredients and include a measure of the amount of aspartame per serving. As well, labels must state that the product contains phenylalanine – this is usually in the order of ingredients, contained in brackets.
Phenylalanine is one of the essential amino acids and is required for normal growth and maintenance of life. Concerns about the safety of phenylalanine from aspartame center largely on hypothetical changes in neurotransmitter levels as well as ratios of neurotransmitters to each other in the blood and brain that could lead to neurological symptoms. Reviews of the literature have found no consistent findings to support such concerns, and while high doses of aspartame consumption may have some biochemical effects, these effects are not seen in toxicity studies to suggest aspartame can adversely affect neuronal function. Like methanol, the typical diet will lead to ingestion of significantly higher amounts of phenylalanine than would be expected from aspartame consumption.
People with the genetic disorder phenylketonuria are advised to avoid aspartame as they have a decreased ability to metabolize phenylalanine. Common foods such as milk, meat, and fruits provide far greater amounts of these metabolites in a diet than does aspartame.
Lactation.
In a study done in 1979, the effect of aspartame ingestion on blood and milk amino acid levels in lactating women was tested. In this study, six women from the ages of 20 to 29 with established lactation were studied after oral administration of aspartame or lactose (50 mg/kg body weight) in a random order, with the intent to study the differences in breast milk between the two. The study resulted with the conclusion that aspartame administration at 50 mg/kg body weight has a small effect upon the milk aspartate levels and although a small increase in aspartate time-effect scores was noted over the four-hour postabsorptive period, no significant difference was noted over the entire 24-hour watching period.
Cancer.
Reviews have found no association between aspartame and cancer. These reviews have looked at numerous carcinogenicity studies in animals, epidemiologic studies in humans, as well as "in vitro" genotoxicity studies. These studies have found no significant evidence that aspartame causes cancer in animals, damages the genome, or causes cancer in humans at doses currently used. This position is supported by multiple regulatory agencies like the FDA and EFSA as well as scientific bodies such as the National Cancer Institute. Aspartame did not show any DNA-damaging properties either.
Concern about possible carcinogenic properties of aspartame was originally raised and popularized in the mainstream media by John Olney in the 1970s and again in 1996 by suggesting that aspartame may be related to brain tumors. Reviews have found that these concerns were flawed, due to reliance on the ecological fallacy and the purported mechanism of causing tumors being unlikely to actually cause cancer. Independent agencies such as the FDA and National Cancer Institute have reanalyzed multiple studies based on these worries and found no association between aspartame and brain cancer.
As discussed in the article on controversies around aspartame, the Cesare Maltoni Cancer Research Center of the European Ramazzini Foundation of Oncology and Environmental Sciences released several studies which claimed that aspartame can increase several malignancies in rodents, concluding that aspartame is a potential carcinogen at normal dietary doses. The EFSA and the FDA discounted the study results due to lack of transparency and numerous flaws in the study, finding no reason to revise their previously established acceptable daily intake levels for aspartame.
Neurological and psychiatric symptoms.
Numerous allegations have been made via the Internet and in consumer magazines purporting neurotoxic effects of aspartame leading to neurological or psychiatric symptoms such as seizures, headaches, and mood changes. Review of the biochemistry of aspartame has found no evidence that the doses consumed would plausibly lead to neurotoxic effects.
Comprehensive reviews have not found any evidence for aspartame as a cause for these symptoms.
One review did provide a theoretical biochemical background of neurotoxicity and suggested further testing.
However, a panel of EFSA experts noted that this review's conclusions were partially based on Internet sources and therefore were not scientifically robust. These experts also concurred with a critique that significant scientific errors were made in the critical review that led to unsubstantiated and misleading interpretations. A review of the pediatric literature did not show any significant findings for safety concerns with regard to neuropsychiatric conditions such as panic attacks, mood changes, hallucinations or with ADHD or seizures.
Headaches.
Headaches are the most common symptom reported by consumers. While one small review noted aspartame is likely one of many dietary triggers of migraines, in a list that includes "cheese, chocolate, citrus fruits, hot dogs, monosodium glutamate, aspartame, fatty foods, ice cream, caffeine withdrawal, and alcoholic drinks, especially red wine and beer,"
other reviews have noted conflicting studies about headaches
and still more reviews lack any evidence and references to support this claim.
Weight change and hunger.
Since the caloric contribution of aspartame is negligible, it has been used as a means for weight loss through its role as a sugar substitute, with reviews finding that aspartame may aid in weight loss as part of a multidisciplinary weight loss program. On its own, aspartame is not known by medical literature to cause weight gain or weight loss. Although some researchers have stated that aspartame contributes to weight gain, hunger and increase in appetite, broad reviews and regulators conclude that aspartame has no appreciable effect on appetite.
Commercial uses.
Under the trade names Equal, NutraSweet, and Canderel, aspartame is an ingredient in approximately 6,000 consumer foods and beverages sold worldwide, including (but not limited to) diet sodas and other soft drinks, instant breakfasts, breath mints, cereals, sugar-free chewing gum, cocoa mixes, frozen desserts, gelatin desserts, juices, laxatives, chewable vitamin supplements, milk drinks, pharmaceutical drugs and supplements, shake mixes, tabletop sweeteners, teas, instant coffees, topping mixes, wine coolers and yogurt. It is provided as a table condiment in some countries. Aspartame is less suitable for baking than other sweeteners, because it breaks down when heated and loses much of its sweetness.
NutraSweet Company.
In 1985, Monsanto Company bought G.D.Searle, and the aspartame business became a separate Monsanto subsidiary, the NutraSweet Company. In March 2000, Monsanto sold it to J.W. Childs Equity Partners II L.P. European use patents on aspartame expired starting in 1987, and the U.S. patent expired in 1992. Since then, the company has competed for market share with other manufacturers, including Ajinomoto, Merisant and the Holland Sweetener Company.
Ajinomoto.
Many aspects of industrial synthesis of aspartame were established by Ajinomoto. In 2004, the market for aspartame, in which Ajinomoto, the world's largest aspartame manufacturer, had a 40 percent share, was 14,000 metric tons a year, and consumption of the product was rising by 2 percent a year. Ajinomoto acquired its aspartame business in 2000 from Monsanto for $67M.
In 2008, Ajinomoto sued British supermarket chain Asda, part of Wal-Mart, for a malicious falsehood action concerning its aspartame product when the substance was listed as excluded from the chain's product line, along with other "nasties". In July 2009, a British court found in favour of Asda. In June 2010, an appeals court reversed the decision, allowing Ajinomoto to pursue a case against Asda to protect aspartame's reputation. Asda said that it would continue to use the term "no nasties" on its own-label products, but the suit was settled in 2011 with Asda choosing to remove references to aspartame from its packaging.
In November 2009, Ajinomoto announced a new brand name for its aspartame sweetener – AminoSweet.
Holland Sweetener Company.
A joint venture of DSM and Tosoh, the Holland Sweetener Company manufactured aspartame using the enzymatic process developed by Toyo Soda (Tosoh) and sold as the brand Sanecta. Additionally, they developed a combination aspartame-acesulfame salt under the brand name Twinsweet. They left the sweetener industry in late 2006, because "global aspartame markets are facing structural oversupply, which has caused worldwide strong price erosion over the last five years", making the business "persistently unprofitable".
Competing products.
Because sucralose, unlike aspartame, retains its sweetness after being heated, and has at least twice the shelf life of aspartame, it has become more popular as an ingredient. This, along with differences in marketing and changing consumer preferences, caused aspartame to lose market share to sucralose. In 2004, aspartame traded at about $30/kg and sucralose, which is roughly three times sweeter by weight, at around $300/kg.
Ant-killer hoax.
Aspartame has been falsely claimed to have been originally developed as ant poison. The source for this was a satirical article posted on "thespoof" website. Further claims that the substance actually is poisonous to ants were inferred from that online article being quoted as fact by various anti-aspartame websites, and videos of numerous trials of this rumor have been shown on YouTube, or posted on social networks, some even claiming success in eradicating ants with Aspartame or with other sweeteners.

</doc>
<doc id="2753" url="https://en.wikipedia.org/wiki?curid=2753" title="AutoCAD">
AutoCAD

AutoCAD is a commercial software application for 2D and 3D computer-aided design (CAD) and drafting — available since 1982 as a desktop application and since 2010 as a mobile, web- and cloud-based app marketed as AutoCAD 360.
Developed and marketed by Autodesk, AutoCAD was first released in December 1982, running on microcomputers with internal graphics controllers. Prior to the introduction of AutoCAD, most commercial CAD programs ran on mainframe computers or minicomputers, with each CAD operator (user) working at a separate graphics terminal.
AutoCAD is used across a wide range of industries, by architects, project managers, engineers, graphic designers, and other professionals. It is supported by 750 training centers worldwide as of 1994.
As Autodesk's flagship product, by March 1986 AutoCAD had become the most ubiquitous CAD program worldwide.
History.
AutoCAD was derived from a program begun in 1977 and released in 1979 called Interact CAD, also referred to in early Autodesk documents as MicroCAD, which was written prior to Autodesk's (then Marinchip Software Partners) formation by Autodesk cofounder Mike Riddle.
The first version by Autodesk was demonstrated at the 1982 Comdex and released that December. The 2016 release marked the 30th major release of AutoCAD for Windows. The 2014 release marked the fourth consecutive year of AutoCAD for Mac.
Design.
File formats and versions.
The native file format of AutoCAD is ".dwg". This and, to a lesser extent, its interchange file format "DXF", have become de facto, if proprietary, standards for CAD data interoperability, particularly for 2D drawing exchange. AutoCAD has included support for .dwf, a format developed and promoted by Autodesk, for publishing CAD data.
Autodesk's logo and, respectively, AutoCAD icons have changed for several versions through the years. 
Compatibility with other software.
ESRI ArcMap 10 permits export as AutoCAD drawing files. Civil 3D permits export as AutoCAD objects and as LandXML. Third-party file converters exist for specific formats such as Bentley MX GENIO Extension, PISTE Extension (France), 
ISYBAU (Germany), OKSTRA and Microdrainage (UK);
also, conversion of .pdf files is feasible, however, the accuracy of the results may be unpredictable or distorted, as that of jagged edges.
Languages.
AutoCAD 2014 and AutoCAD LT 2014 are available for English, German, French, Italian, Spanish, Japanese, Korean, Chinese Simplified, Chinese Traditional and Brazilian Portuguese. Russian, Czech, Polish, Hungarian will be available later on. The extent of localization varies from full translation of the product to documentation only. The AutoCAD command set is localized as a part of the software localization.
Extensions.
AutoCAD supports a number of APIs for customization and automation. These include AutoLISP, Visual LISP, VBA, .NET and ObjectARX. ObjectARX is a C++ class library, which was also the base for:
There are a large number of AutoCAD plugins (add-on applications) available on the application store Autodesk Exchange Apps
AutoCAD's DXF, drawing exchange format, allows importing and exporting drawing information.
Vertical integration.
Autodesk has also developed a few vertical programs (AutoCAD Architecture, AutoCAD Civil 3D, AutoCAD Electrical, AutoCAD ecscad, AutoCAD Map 3D, AutoCAD Mechanical, AutoCAD MEP, AutoCAD Structural Detailing, AutoCAD Utility Design, AutoCAD P&ID and AutoCAD Plant 3D) for discipline-specific enhancements. For example, AutoCAD Architecture (formerly Architectural Desktop) permits architectural designers to draw 3D objects, such as walls, doors and windows, with more intelligent data associated with them rather than simple objects, such as lines and circles. The data can be programmed to represent specific architectural products sold in the construction industry, or extracted into a data file for pricing, materials estimation, and other values related to the objects represented. Additional tools generate standard 2D drawings, such as elevations and sections, from a 3D architectural model. Similarly, Civil Design, Civil Design 3D, and Civil Design Professional support data-specific objects, facilitating easy standard civil engineering calculations and representations. Civil 3D was originally developed as an AutoCAD add-on by a company in New Hampshire called Softdesk (originally DCA). Softdesk was acquired by Autodesk, and Civil 3D was further evolved.
Variants.
AutoCAD LT.
AutoCAD LT is the lower cost version of AutoCAD, with reduced capabilities, first released in November 1993. Autodesk developed AutoCAD LT to have an entry-level CAD package to compete in the lower price level. AutoCAD LT, priced at $495, became the first AutoCAD product priced below $1000. It is sold directly by Autodesk and can also be purchased at computer stores (unlike the full version of AutoCAD, which must be purchased from official Autodesk dealers).
As of the 2011 release the AutoCAD LT MSRP has risen to $1200. While there are hundreds of small differences between the full AutoCAD package and AutoCAD LT, there are a few recognized major differences in the software's features:
AutoCAD LT 2015 introduced Desktop Subscription from $360 per year
AutoCAD 360.
Formerly marketed as AutoCAD WS, AutoCAD 360 is an account-based mobile and web application enabling registered users to view, edit, and share AutoCAD files via mobile device and web using a limited AutoCAD feature set — and using cloud-stored drawing files. The program, which is an evolution and combination of previous products, uses a freemium business model with a free plan and two paid levels — marketed as Pro ($4.99 monthly or $49.99 yearly) and Pro Plus ($99.99 yearly) — including various amounts of storage, tools, and online access to drawings. 360 includes new features such as a "Smart Pen" mode and linking to third-party cloud-based storage such as Dropbox. Having evolved from Flash-based software, AutoCAD 360 uses HTML5 browser technology available in newer browsers including Firefox and Google Chrome.
AutoCAD WS began with a version for the iPhone and subsequently expanded to include versions for the iPod Touch, iPad, Android phones, and Android tablets. Autodesk released the iOS version in September 2010, following with the Android version on April 20, 2011. The program is available via download at no cost from the App Store (iOS), Google Play (Android) and Amazon Appstore (Android).
In its initial iOS version, AutoCAD WS supported drawing of lines, circles, and other shapes; creation of text and comment boxes; and management of color, layer, and measurements — in both landscape and portrait modes. Version 1.3, released August 17, 2011, added support of unit typing, layer visibility, area measurement and file management. The Android variant includes the iOS feature set along with such unique features as the ability to insert text or captions by voice command as well as manually. Both Android and iOS versions allow the user to save files on-line — or off-line in the absence of an Internet connection.
In 2011, Autodesk announced plans to migrate the majority of its software to "the cloud", starting with the AutoCAD WS mobile application.
According to a 2013 interview with Ilai Rotbaein, an AutoCAD WS Product Manager for Autodesk, the name AutoCAD WS had no definitive meaning, and was interpreted variously as "Autodesk Web Service", "White Sheet" or "Work Space."
Student versions.
AutoCAD is licensed, for free, to qualifying students and teachers, with a 18-month renewable license available. The student version of AutoCAD is functionally identical to the full commercial version, with one exception: DWG files created or edited by a student version have an internal bit-flag set (the "educational flag"). When such a DWG file is printed by any version of AutoCAD (commercial or student) older than AutoCAD 2014 SP1, the output includes a plot stamp / banner on all four sides. Objects created in the Student Version cannot be used for commercial use. Student Version objects "infect" a commercial version DWG file if it is imported in older versions than AutoCAD 2015.
The Autodesk Education Community provides registered students and faculty with free access to different Autodesk applications.
Ports.
Android.
Autodesk AutoCAD 360 is the official AutoCAD mobile app for Android.
Microsoft Windows.
AutoCAD is a software package created for Windows and usually any new AutoCAD version supports the current Windows version and some older ones. AutoCAD 2016 supports Windows 7 up to Windows 10.
Mac OS.
Autodesk stopped supporting Apple's computers in 1994. Over the next several years, no compatible versions for Macintosh computers were released. In 2010 Autodesk announced that it would once again support Apple's Mac OS X software in the future. Most of the features found in the 2012 Windows version can be found in the 2012 Mac version. The main difference is the user interface and layout of the program. The interface is designed so that users who are already familiar with Apple's OS X software will find it similar to other Mac applications. Autodesk has also built in various features in order to take full advantage of Apple's Trackpad capabilities as well as the full-screen mode in Apple's OS X Lion. AutoCAD 2012 for Mac supports both the editing and saving of files in DWG formatting that will allow the file to be compatible with other platforms besides the OS X. AutoCAD 2014 for Mac supports Apple Mac OS X v10.9.0 or later (Mavericks), OS X v10.8.0 or later (Mountain Lion) with 64-bit Intel processor.
AutoCAD LT 2013 is now available through the Mac App Store for $899.99. The full featured version of AutoCAD 2013 for Mac, however, is not available through the Mac App Store due to the price limit of $999 set by Apple. AutoCAD 2014 for Mac is available for purchase from Autodesk's Web site for $4,195 and AutoCAD LT 2014 for Mac for $1,200, or from an Autodesk Authorized Reseller.
External links.
"on Michael Riddle and Interact:"

</doc>
<doc id="2754" url="https://en.wikipedia.org/wiki?curid=2754" title="AutoCAD DXF">
AutoCAD DXF

AutoCAD DXF (Drawing Interchange Format, or Drawing Exchange Format) is a CAD data file format developed by Autodesk for enabling data interoperability between AutoCAD and other programs.
DXF was originally introduced in December 1982 as part of AutoCAD 1.0, and was intended to provide an exact representation of the data in the AutoCAD native file format, DWG (Drawing), for which Autodesk for many years did not publish specifications. Because of this, correct imports of DXF files have been difficult. Autodesk now publishes the DXF specifications as a PDF on its website.
Versions of AutoCAD from Release 10 (October 1988) and up support both ASCII and binary forms of DXF. Earlier versions support only ASCII.
As AutoCAD has become more powerful, supporting more complex object types, DXF has become less useful. Certain object types, including ACIS solids and regions, are not documented. Other object types, including AutoCAD 2006's dynamic blocks, and all of the objects specific to the vertical market versions of AutoCAD, are partially documented, but not well enough to allow other developers to support them. For these reasons many CAD applications use the DWG format which can be licensed from Autodesk or non-natively from the Open Design Alliance.
DXF coordinates are always without dimensions so that the reader or user needs to know the drawing unit or has to extract it from the textual comments in the sheets.
File structure.
ASCII versions of DXF can be read with any text editor. The basic organization of a DXF file is as follows:
The data format of a DXF is called a "tagged data" format which "means that each data element in the file is preceded by an integer number that is called a group code. A group code's value indicates what type of data element follows. This value also indicates the meaning of a data element for a given object (or record) type. Virtually all user-specified information in a drawing file can be represented in DXF format."

</doc>
<doc id="2756" url="https://en.wikipedia.org/wiki?curid=2756" title="Asexual reproduction">
Asexual reproduction

Asexual reproduction is a type of reproduction by which offspring arise from a single organism, and inherit the genes of that parent only; it does not involve the fusion of gametes and almost never changes the number of chromosomes. Asexual reproduction is the primary form of reproduction for single-celled organisms such as the archaebacteria, eubacteria, and protists. Many plants and fungi reproduce asexually as well.
While all prokaryotes reproduce asexually (without the formation and fusion of gametes), mechanisms for lateral gene transfer such as conjugation, transformation and transduction are sometimes likened to sexual reproduction (or at least with sex, in the sense of genetic recombination). A complete lack of sexual reproduction is relatively rare among multicellular organisms, particularly animals. It is not entirely understood why the ability to reproduce sexually is so common among them. Current hypotheses suggest that asexual reproduction may have short term benefits when rapid population growth is important or in stable environments, while sexual reproduction offers a net advantage by allowing more rapid generation of genetic diversity, allowing adaptation to changing environments. Developmental constraints may underlie why few animals have relinquished sexual reproduction completely in their life-cycles. Another constraint on switching from sexual to asexual reproduction would be the concomitant loss of meiosis and the protective recombinational repair of DNA damage afforded as one function of meiosis. (Also see Meiosis section: Origin and function of meiosis)
Types of asexual reproduction.
Binary fission.
An important form of fission is binary fission.
In binary fission, the parent organism is replaced by two daughter organisms, because it literally divides in two. Only prokaryotes (the archaea and the bacteria) reproduce asexually through binary fission. Eukaryotes (such as protists and unicellular fungi) reproduce by mitosis; most of these are also capable of sexual reproduction.
Another type of fission is multiple fission that is advantageous to the plant life cycle. Multiple fission at the cellular level occurs in many protists, e.g. sporozoans and algae. The nucleus of the parent cell divides several times by mitosis, producing several nuclei. The cytoplasm then separates, creating multiple daughter cells.
In apicomplexans, multiple fission, or schizogony, is manifested either as merogony, sporogony or gametogony. Merogony results in merozoites, which are multiple daughter cells, that originate within the same cell membrane, sporogony results in sporozoites, and gametogony results in microgametes.
Budding.
Some cells split via budding (for example baker's yeast), resulting in a 'mother' and 'daughter' cell. The offspring organism is smaller than the parent. Budding is also known on a multicellular level; an animal example is the hydra, which reproduces by budding. The buds grow into fully matured individuals which eventually break away from the parent organism.
Internal budding or Endodyogeny is a process of asexual reproduction, favoured by parasites such as "Toxoplasma gondii". It involves an unusual process in which two daughter cells are produced inside a mother cell, which is then consumed by the offspring prior to their separation.
Endopolygeny is the division into several organisms at once by internal budding. also budding (external or internal) is present in some worm like Taenia or Echinococci; these worm produce cyst and then produce (invaginated or evaginated) protoscolex with budding.
Vegetative reproduction.
Vegetative reproduction is a type of asexual reproduction found in plants where new individuals are formed without the production of seeds or spores by meiosis or syngamy. Examples of vegetative reproduction include the formation of miniaturized plants called plantlets on specialized leaves (for example in kalanchoe) and some produce new plants out of rhizomes or stolon (for example in strawberry). Other plants reproduce by forming bulbs or tubers (for example tulip bulbs and dahlia tubers). Some plants produce adventitious shoots and suckers that form along their lateral roots. Plants that reproduce vegetatively may form a clonal colony, where all the individuals are clones, and the clones may cover a large area.
Spore.
Many multicellular organisms form spores during their biological life cycle in a process called sporogenesis. Exceptions are animals and some protists, who undergo "meiosis" immediately followed by fertilization. Plants and many algae on the other hand undergo "sporic meiosis" where meiosis leads to the formation of haploid spores rather than gametes. These spores grow into multicellular individuals (called gametophytes in the case of plants) without a fertilization event. Then in the plant life cycle.
Fungi and some algae can also utilize true asexual spore formation, which involves mitosis giving rise to reproductive cells called mitospores that develop into a new organism after dispersal. This method of reproduction is found for example in conidial fungi and the red alga "Polysiphonia", and involves sporogenesis without meiosis. Thus the chromosome number of the spore cell is the same as that of the parent producing the spores. However, mitotic sporogenesis is an exception and most spores, such as those of plants, most Basidiomycota, and many algae, are produced by meiosis.
A mode of reproduction resembling multiple fission, common among Protozoa, in which the organism breaks up into a number of pieces, or spores, each of which eventually develops into an organism like the parent form.
The formation of reproductive cells or spores, as in the growth of bacilli. Even if the plants are healthy the outcome of the seed will always be high
Fragmentation.
Fragmentation is a form of asexual reproduction where a new organism grows from a fragment of the parent. Each fragment develops into a mature, fully grown individual. Fragmentation is seen in many organisms such as animals (some annelid worms, turbellarians and sea stars), fungi, and plants. Some plants have specialized structures for reproduction via fragmentation, such as "gemma" in liverworts. Most lichens, which are a symbiotic union of a fungus and photosynthetic algae or bacteria, reproduce through fragmentation to ensure that new individuals contain both symbiont. These fragments can take the form of "soredia", dust-like particles consisting of fungal hyphen wrapped around photobiont cells.
Clonal Fragmentation in multicellular or colonial organisms is a form of asexual reproduction or cloning where an organism is split into fragments. Each of these fragments develop into mature, fully grown individuals that are clones of the original organism. In echinoderms, this method of reproduction is usually known as fissiparity.
Agamogenesis.
Agamogenesis is any form of reproduction that does not involve a male gamete. Examples are parthenogenesis and apomixis.
Parthenogenesis.
Parthenogenesis is a form of agamogenesis in which an unfertilized egg develops into a new individual. Parthenogenesis occurs naturally in many plants, invertebrates (e.g. water fleas, rotifers, aphids, stick insects, some ants, bees and parasitic wasps), and vertebrates (e.g. some reptiles, amphibians, rarely birds). In plants, apomixis may or may not involve parthenogenesis.
Apomixis and nucellar embryony.
Apomixis in plants is the formation of a new sporophyte without fertilization. It is important in ferns and in flowering plants, but is very rare in other seed plants. In flowering plants, the term "apomixis" is now most often used for agamospermy, the formation of seeds without fertilization, but was once used to include vegetative reproduction. An example of an apomictic plant would be the triploid European dandelion. Apomixis mainly occurs in two forms: In gametophytic apomixis, the embryo arises from an unfertilized egg within a diploid embryo sac that was formed without completing meiosis. In nucellar embryony, the embryo is formed from the diploid nucellus tissue surrounding the embryo sac. Nucellar embryony occurs in some citrus seeds. Male apomixis can occur in rare cases, such as the Saharan Cypress "Cupressus dupreziana", where the genetic material of the embryo are derived entirely from pollen.
The term "apomixis" is also used for asexual reproduction in some animals, notably water-fleas, "Daphnia".
Alternation between sexual and asexual reproduction.
Some species alternate between the sexual and asexual strategies, an ability known as heterogamy, depending on conditions. Alternation is observed in several rotifer species (cyclical parthenogenesis e.g. in Brachionus species) and a few types of insects, such as aphids which will, under certain conditions, produce eggs that have not gone through meiosis, thus cloning themselves. The cape bee "Apis mellifera" subsp. "capensis" can reproduce asexually through a process called thelytoky. A few species of amphibians, reptiles, and birds have a similar ability (see parthenogenesis for examples).
For example, the freshwater crustacean "Daphnia" reproduces by parthenogenesis in the spring to rapidly populate ponds, then switches to sexual reproduction as the intensity of competition and predation increases. Another example are monogonont rotifers of the genus Brachionus, which reproduce via cyclical parthenogenesis: at low population densities females produce asexually and at higher densities a chemical cue accumulates and induces the transition to sexual reproduction. Many protists and fungi alternate between sexual and asexual reproduction.
For example, the slime mold "Dictyostelium" undergoes binary fission (mitosis) as single-celled amoebae under favorable conditions. However, when conditions turn unfavorable, the cells aggregate and follow one of two different developmental pathways, depending on conditions. In the social pathway, they form a multicellular slug which then forms a fruiting body with asexually generated spores. In the sexual pathway, two cells fuse to form a giant cell that develops into a large cyst. When this macrocyst germinates, it releases hundreds of amoebic cells that are the product of meiotic recombination between the original two cells.
The hyphae of the common mold ("Rhizopus") are capable of producing both mitotic as well as meiotic spores. Many algae similarly switch between sexual and asexual reproduction. A number of plants use both sexual and asexual means to produce new plants, some species alter their primary modes of reproduction from sexual to asexual under varying environmental conditions.
Inheritance of asexual reproduction in sexual species.
For example, in the rotifer "Brachionus calyciflorus" asexual reproduction (obligate parthenogenesis) can be inherited by a recessive allele, which leads to loss of sexual reproduction in homozygous offspring.
Inheritance of asexual reproduction by a single recessive locus has also been found in the parasitoid wasp "Lysiphlebus fabarum".
Examples in animals.
There are examples of parthenogenesis in the hammerhead shark and the blacktip shark. In both cases, the sharks had reached sexual maturity in captivity in the absence of males, and in both cases the offspring were shown to be genetically identical to the mothers.
Reptiles use the ZW sex-determination system, which produces either males (with ZZ sex chromosomes) or females (with ZW or WW sex chromosomes). Until 2010, it was thought that the ZW chromosome system used by reptiles was incapable of producing viable WW offspring, but a (ZW) female boa constrictor was discovered to have produced viable female offspring with WW chromosomes. The female boa could have chosen any number of male partners (and had successfully in the past) but on these occasions she reproduced asexually, creating 22 female babies with WW sex-chromosomes.
Polyembryony is a widespread form of asexual reproduction in animals, whereby the fertilized egg or a later stage of embryonic development splits to form genetically identical clones. Within animals, this phenomenon has been best studied in the parasitic Hymenoptera. In the 9-banded armadillos, this process is obligatory and usually gives rise to genetically identical quadruplets. In other mammals, monozygotic twinning has no apparent genetic basis, though its occurrence is common. There are at least 10 million identical human twins and triplets in the world today.
Bdelloid rotifers reproduce exclusively asexually, and all individuals in the class Bdelloidea are females. Asexuality evolved in these animals millions of years ago and has persisted since. There is evidence to suggest that asexual reproduction has allowed the animals to evolve new proteins through the Meselson effect that have allowed them to survive better in periods of dehydration.
Molecular evidence strongly suggest that several species of the stick insect genus "Timema" have used only asexual (parthenogenetic) reproduction for millions of years, the longest period known for any insect.
In the grass thrips genus "Aptinothrips" there have been several transitions to asexuality, likely due to different causes.

</doc>
<doc id="2758" url="https://en.wikipedia.org/wiki?curid=2758" title="Aelbert Cuyp">
Aelbert Cuyp

Aelbert Jacobsz Cuyp (October 20, 1620 – November 15, 1691) was one of the leading Dutch landscape painters of the Dutch Golden Age in the 17th century. The most famous of a family of painters, the pupil of his father Jacob Gerritsz Cuyp (1594–1651/52), he is especially known for his large views of the Dutch countryside in early morning or late afternoon light.
Biography.
Aelbert Cuyp was born in Dordrecht on October 20, 1620, and also died there on November 15, 1691. Known as the Dutch equivalent of Claude Lorrain, this landscape artist went on to inherit a considerable fortune. His family were all artists, with his uncle Benjamin and grandfather Gerrit being stained glass cartoon designers. Jacob Gerritsz Cuyp, his father, was a portraitist.
The amount of biographical information regarding Aelbert Cuyp is tremendously limited. Even Arnold Houbraken, a noted historian of Dutch Golden Age paintings and the sole authority on Cuyp for the hundred years following his death, paints a very thin biographical picture. His period of activity as a painter is traditionally limited to the two decades between 1639 and 1660, fitting directly within the generally accepted limits of the Dutch Golden Age's most significant period, 1640-1665. He is known to have been married to Cornelia Bosman in 1658, a date coinciding so directly with the end of his productivity as a painter that it has been accepted that his marriage played some sort of role in the end of his artistic career. The year after his marriage Cuyp became the deacon of the reformed church. Even Houbraken recalled that Cuyp was a devout Calvinist and the fact that when he died, there were no paintings of other artists found in his home.
Style.
The development of Aelbert Cuyp, who was trained as a landscape painter, may be roughly sketched in three phases based on the painters who most influenced him during that time and the subsequent artistic characteristics that are apparent in his paintings. Generally, Cuyp learned tone from the exceptionally prolific Jan van Goyen, light from Jan Both and form from his father, Jacob Gerritsz Cuyp.
Cuyp's "van Goyen phase" can be placed approximately in the early 1640s.
Cuyp probably first encountered a painting by van Goyen in 1640 when van Goyen was, as Stephen Reiss points out "at the height of powers." This is noticeable in the comparison between two of Cuyp's landscape paintings inscribed 1639 where no properly formed style is apparent and the landscape backgrounds he painted two years later for two of his father's group portraits that are distinctly van Goyenesque. 
Cuyp took from van Goyen the straw yellow and light brown tones that are so apparent in his Dunes (1629) and the broken brush technique also very noticeable in that same work. 
This technique, a precursor to impressionism, is noted for the short brush strokes where the colors are not necessarily blended smoothly. In Cuyp's River Scene, Two Men Conversing (1641) both of these van Goyen-influenced stylistic elements are noticeable
The next phase in the development of Cuyp's increasingly amalgamated style is due to the influence of Jan Both. In the mid-1640s Both, a native and resident of Utrecht, had just returned to his hometown from a trip to Rome. It is around this same time that Cuyp's style changed fundamentally. In Rome, Both had developed a new style of composition due, at least in part, to his interaction with Claude Lorrain. This new style was focused on changing the direction of light in the painting. Instead of the light being placed at right angles in relation to the line of vision, Both started moving it to a diagonal position from the back of the picture. In this new form of lighting, the artist (and viewer of the painting) faced the sun more or less contre-jour. Both, and subsequently Cuyp, used the advantages of this new lighting style to alter the sense of depth and luminosity possible in a painting. To make notice of these new capabilities, much use was made of elongated shadows. Cuyp was one of the first Dutch painters to appreciate this new leap forward in style and while his own Both-inspired phase was quite short (limited to the mid-1640s) he did, more than any other contemporary Dutch artist, maximize the full chromatic scale for sunsets and sunrises.
Cuyp's third stylistic phase (which occurred throughout his career) is based on the influence of his father. While it is assumed that the younger Cuyp did work with his father initially to develop rudimentary talents, Aelbert became more focused on landscape paintings while Jacob was a portrait painter by profession. As has been mentioned and as will be explained in depth below, there are pieces where Aelbert provided the landscape background for his father's portraits. What is meant by stating that Aelbert learned form from his father is that his eventual transition from a specifically landscape painter to the involvement of foreground figures is attributed to his interaction with his father Jacob. The evidence for Aelbert's evolution to foreground figure painter is in the production of some paintings from 1645-50 featuring foreground animals that do not fit with Jacob's style. Adding to the confusion that is, Aelbert's stylistic development and the problem of attribution is of course the fact that Jacob's style was not stagnant either. Their converging styles make it difficult to exactly understand the influences each had on the other, although it is clear enough to say that Aelbert started representing large scale forms (something he had not done previously) and placing animals as the focus of his paintings (something that was specific to him).
Paintings.
Sunlight in his paintings rakes across the panel, accentuating small bits of detail in the golden light. In large, atmospheric panoramas of the countryside, the highlights on a blade of meadow grass, the mane of a tranquil horse, the horn of a dairy cow reclining by a stream, or the tip of a peasant's hat are all caught in a bath of yellow ocher light. The richly varnished medium refracts the rays of light like a jewel as it dissolves into numerous glazed layers. Cuyp's landscapes were based on reality and on his own invention of what an enchanting landscape should be.
Cuyp's drawings reveal him to be a draftsman of superior quality. Light-drenched washes of golden brown ink depict a distant view of the city of Dordrecht or Utrecht.
A Cuyp drawing may look like he intended it to be a finished work of art, but it was most likely taken back to the studio and used as a reference for his paintings. Often the same section of a sketch can be found in several different pictures.
Cuyp signed many of his works but rarely dated them, so that a chronology of his career has not been satisfactorily reassembled. A phenomenal number of paintings are ascribed to him, some of which are likely to be by other masters of the golden landscape, such as Abraham Calraet (1642–1722), whose initials "A.C." may be mistaken for Cuyp's.
However, not everyone appreciates his work and "River Landscape" (1660), despite being widely regarded as amongst his best work, has been described as having "chocolate box blandness".
Misattribution of paintings.
In addition to the scarcely documented and confirmed biography of Cuyp's life, and even more so than his amalgamated style from his three main influences, there are yet other factors that have led to the misattribution and confusion over Aelbert Cuyp's works for hundreds of years. His highly influenced style which incorporated Italianate lighting from Jan Both, broken brush technique and atonality from Jan van Goyen, and his ever-developing style from his father Jacob Gerritsz Cuyp was studied acutely by his most prominent follower, Abraham van Calraet. Calraet mimicked Cuyp's style, incorporating the same aspects, and produced similar landscapes to that of the latter. This made it quite difficult to tell whose paintings where whose. Adding to the confusion is the similar initials between the two and the inconsistent signing of paintings which were produced by Cuyp's studio.
Although Aelbert Cuyp signed many of his paintings with a script "A. Cuyp" insignia, many paintings were left unsigned (not to mention undated) after being painted, and so a similar signature was added later on, presumably by collectors who inherited or discovered the works. Furthermore, many possible Cuyp paintings were not signed but rather initialed "A. C." referring to his name. However, Abraham van Calraet could also have used the same initials to denote a painting. Although this is unlikely (as Calraet would likely have signed his paintings "A. v.C."), this brings up the question of how paintings were signed to show ownership. Most original Cuyp paintings were signed by him, and in the script manner in which his name was inscribed. This would denote that the painting was done almost entirely by him. Conversely, paintings which came out of his workshop that were not necessarily physically worked on by Cuyp but merely overseen by him technically, were marked with A.C. to show that it was his instruction which saw the paintings' completion. Cuyp's pupils and assistants often worked on paintings in his studio, and so most of the work of a painting could be done without Cuyp ever touching the canvas, but merely approving its finality. Hence, the initialed inscription rather than a signature.
Common among the mislabeled works are all of the reasons identified for misattributing Cuyp's works: the lack of biography and chronology of his works made it difficult to discern when paintings were created (making it difficult to pinpoint an artist); contentious signatures added to historians' confusion as to who actually painted the works; and the collaborations and influences by different painters makes it hard to justify that a painting is genuinely that of Aelbert Cuyp; and finally, accurate identification is made extremely difficult by the fact that this same style was copied (rather accurately) by his predecessor. As it turns out, even the historians and expert researchers have been fooled and forced to reassess their conclusions over "Cuyp's" paintings over the years.
Later life.
After he married Cornelia Boschman in 1658, the number of works produced by him declined almost to nothing. This may have been because his wife was a very religious woman and a not very big patron of the arts. It could also be that he became more active in the church under his wife's guidance. He was also active as deacon and elder of the Reformed Church.
Conclusions.
Upon close examination of the works attributed to Aelbert Cuyp it is easily understood why his unique style developed the way it did, and how his works have been misinterpreted over the years. A lacking biography and weak chronology of works as well as his style which emerged from various influences makes his works distinctive, yet often questionable in determination. Furthermore, his evolving technique and collaborations with his father add to the puzzle over which works should be attributed to Cuyp. Lastly and most importantly, the precision in mimicking Cuyp's style by his follower Abraham van Calraet and their contentious signatures makes it all the more difficult to determine which paintings are genuinely that of Cuyp and which ones are actually accurate reproductions in his style.
Such a thin chronology and little background knowledge has led to gross misinterpretations of his works, and thus further investigation must always be done to conclude with confidence that Aelbert Cuyp is the genuine source of such great paintings. It is this felt reluctance which led the Rijksmuseum to reattribute works to other painters (Abraham van Calraet does not even appear in a Museum catalogue until 1926, and even then he is not given his own entry) which shows how important it is to art historians that painters are accurately connected to their works—and this is continuously necessary for those of Aelbert Cuyp, as Dordrecht's most famous painter may not in fact be Dordrecht's most famous painter.

</doc>
<doc id="2761" url="https://en.wikipedia.org/wiki?curid=2761" title="Alkene">
Alkene

In organic chemistry, an alkene is an unsaturated hydrocarbon that contains at least one carbon–carbon double bond. The words alkene, olefin, and olefine are used often interchangeably (see nomenclature section below). Acyclic alkenes, with only one double bond and no other functional groups, known as mono-enes, form a homologous series of hydrocarbons with the general formula "n"2"n". Alkenes have two hydrogen atoms less than the corresponding alkane (with the same number of carbon atoms). The simplest alkene, ethylene (C2H4), with the International Union of Pure and Applied Chemistry (IUPAC) name "ethene", is the organic compound produced on the largest scale industrially. Aromatic compounds are often drawn as cyclic alkenes, but their structure and properties are different and they are not considered to be alkenes.
Structure.
Bonding.
Like a single covalent bond, double bonds can be described in terms of overlapping atomic orbitals, except that, unlike a single bond (which consists of a single sigma bond), a carbon–carbon double bond consists of one sigma bond and one pi bond. This double bond is stronger than a single covalent bond (611 kJ/mol for C=C vs. 347 kJ/mol for C–C) and also shorter, with an average bond length of 1.33 ångströms (133 pm).
Each carbon of the double bond uses its three sp2 hybrid orbitals to form sigma bonds to three atoms (the other carbon and two hydrogen atoms). The unhybridized 2p atomic orbitals, which lie perpendicular to the plane created by the axes of the three sp² hybrid orbitals, combine to form the pi bond. This bond lies outside the main C–C axis, with half of the bond on one side of the molecule and half on the other.
Rotation about the carbon–carbon double bond is restricted because it incurs an energetic cost to break the alignment of the p orbitals on the two carbon atoms. As a consequence, substituted alkenes may exist as one of two isomers, called "cis" or "trans" isomers. More complex alkenes may be named with the "E"–"Z" notation for molecules with three or four different substituents (side groups). For example, of the isomers of butene, the two methyl groups of ("Z")-but-2-ene (a.k.a. "cis"-2-butene) appear on the same side of the double bond, and in ("E")-but-2-ene (a.k.a. "trans"-2-butene) the methyl groups appear on opposite sides. These two isomers of butene are slightly different in their chemical and physical properties.
A 90° twist of the C=C bond (which may be determined by the positions of the groups attached to the carbons) requires less energy than the strength of a pi bond, and the bond still holds. This contradicts a common textbook assertion that the p orbitals would be unable sustain such a bond. In truth, the misalignment of the p orbitals is less than expected because pyramidalization takes place (See: pyramidal alkene). "trans"-Cyclooctene is a stable strained alkene and the orbital misalignment is only 19° with a dihedral angle of 137° (normal 120°) and a degree of pyramidalization of 18°. The "trans" isomer of cycloheptene is stable only at low temperatures.
Shape.
As predicted by the VSEPR model of electron pair repulsion, the molecular geometry of alkenes includes bond angles about each carbon in a double bond of about 120°. The angle may vary because of steric strain introduced by nonbonded interactions between functional groups attached to the carbons of the double bond. For example, the C–C–C bond angle in propylene is 123.9°.
For bridged alkenes, Bredt's rule states that a double bond cannot occur at the bridgehead of a bridged ring system unless the rings are large enough (8 or more atoms).
Physical properties.
The physical properties of alkenes and alkanes are similar. They are colourless, nonpolar, combustable, and almost odorless. The physical state depends on molecular mass: like the corresponding saturated hydrocarbons, the simplest alkenes, ethene, propene, and butene are gases at room temperature. Linear alkenes of approximately five to sixteen carbons are liquids, and higher alkenes are waxy solids.
Reactions.
Alkenes are relatively stable compounds, but are more reactive than alkanes, either because of the reactivity of the carbon–carbon pi-bond or the presence of allylic CH centers. Most reactions of alkenes involve additions to this pi bond, forming new single bonds. Alkenes serve as a feedstock for the petrochemical industry because they can participate in a wide variety of reactions, prominently polymerization and alkylation.
Addition reactions.
Alkenes react in many addition reactions, which occur by opening up the double-bond. Most of these addition reactions follow the mechanism of electrophilic addition. Examples are hydrohalogenation, halogenation, halohydrin formation, oxymercuration, hydroboration, dichlorocarbene addition, Simmons–Smith reaction, catalytic hydrogenation, epoxidation, radical polymerization and hydroxylation.
Hydrogenation.
Hydrogenation of alkenes produces the corresponding alkanes. The reaction is carried out under pressure at a temperature of 200 °C in the presence of a metallic catalyst. Common industrial catalysts are based on platinum, nickel or palladium. For laboratory syntheses, Raney nickel (an alloy of nickel and aluminium) is often employed. The simplest example of this reaction is the catalytic hydrogenation of ethylene to yield ethane:
Hydration.
Hydration, the addition of water across the double bond of alkenes, yields alcohols. The reaction is catalyzed by strong acids such as sulfuric acid. This reaction is carried out on an industrial scale to produce ethanol.
Alkenes can also be converted into alcohols via the oxymercuration–demercuration reaction or hydroboration–oxidation reaction.
Halogenation.
In electrophilic halogenation the addition of elemental bromine or chlorine to alkenes yields vicinal dibromo- and dichloroalkanes (1,2-dihalides or ethylene dihalides), respectively. The decoloration of a solution of bromine in water is an analytical test for the presence of alkenes:
Related reactions are also used as quantitative measures of unsaturation, expressed as the bromine number and iodine number of a compound or mixture.
Hydrohalogenation.
Hydrohalogenation is the addition of hydrogen halides such as HCl or HI to alkenes to yield the corresponding haloalkanes:
If the two carbon atoms at the double bond are linked to a different number of hydrogen atoms, the halogen is found preferentially at the carbon with fewer hydrogen substituents. This patterns is known as Markovnikov's rule. The use of radical initiators or other compounds can lead to the opposite product result. Hydrobromic acid in particular is prone to forming radicals in the presence of various impurities or even atmospheric oxygen, leading to the reversal of the Markovnikov result:
Halohydrin formation.
Alkenes react with water and halogens to form halohydrins by an addition reaction. Markovnikov regiochemistry and anti stereochemistry occur.
Oxidation.
Alkenes are oxidized with a large number of oxidizing agents. In the presence of oxygen, alkenes burn with a bright flame to produce carbon dioxide and water. Catalytic oxidation with oxygen or the reaction with percarboxylic acids yields epoxides. Reaction with ozone in ozonolysis leads to the breaking of the double bond, yielding two aldehydes or ketones. Reaction with concentrated, hot KMnO4 (or other oxidizing salts) in an acidic solution will yield ketones or carboxylic acids.
This reaction can be used to determine the position of a double bond in an unknown alkene.
The oxidation can be stopped at the vicinal diol rather than full cleavage of the alkene by using milder (dilute,lower temperature) KMnO4 or with osmium tetroxide or other oxidants.
Photooxygenation.
In the presence of an appropriate photosensitiser, such as methylene blue and light, alkenes can undergo reactions with reactive oxygen species generated by the photosensitiser, such as hydroxyl radicals, singlet oxygen or superoxide ion. These reactive photochemical intermediates are generated in what are known as Type I, Type II, and Type III processes, respectively. These various alternative processes and reactions can be controlled by choice of specific reaction conditions, leading to a wide range of different products. A common example is the [4+2]-cycloaddition of singlet oxygen with a diene such as cyclopentadiene to yield an endoperoxide:
Another example is the Schenck ene reaction, in which singlet oxygen reacts with an allylic structure to give a transposed allyl peroxide:
Polymerization.
Polymerization of alkenes is a reaction that yields polymers of high industrial value at great economy, such as the plastics polyethylene and polypropylene. Polymers from alkene monomers are referred to in a general way as "polyolefins" or in rare instances as "polyalkenes". A polymer from alpha-olefins is called a polyalphaolefin (PAO). Polymerization can proceed via either a free-radical or an ionic mechanism, converting the double to a single bond and forming single bonds to join the other monomers. Polymerization of conjugated dienes such as buta-1,3-diene or isoprene (2-methylbuta-1,3-diene) results in largely 1,4-addition with possibly some 1,2-addition of the diene monomer to a growing polymer chain.
Metal complexation.
Alkenes are ligands in transition metal alkene complexes. The two carbon centres bond to the metal using the C–C pi- and pi*-orbitals. Mono- and diolefins are often used as ligands in stable complexes. Cyclooctadiene and norbornadiene are popular chelating agents, and even ethylene itself is sometimes used as a ligand, for example, in Zeise's salt. In addition, metal–alkene complexes are intermediates in many metal-catalyzed reactions including hydrogenation, hydroformylation, and polymerization.
Synthesis.
Industrial methods.
Alkenes are produced by hydrocarbon cracking. Raw materials are mostly natural gas condensate components (principally ethane and propane) in the US and Mideast and naphtha in Europe and Asia. Alkanes are broken apart at high temperatures, often in the presence of a zeolite catalyst, to produce a mixture of primarily aliphatic alkenes and lower molecular weight alkanes. The mixture is feedstock and temperature dependent, and separated by fractional distillation. This is mainly used for the manufacture of small alkenes (up to six carbons).
Related to this is catalytic dehydrogenation, where an alkane loses hydrogen at high temperatures to produce a corresponding alkene. This is the reverse of the catalytic hydrogenation of alkenes.
This process is also known as reforming. Both processes are endothermic and are driven towards the alkene at high temperatures by entropy.
Catalytic synthesis of higher α-alkenes (of the type RCH=CH2) can also be achieved by a reaction of ethylene with the organometallic compound triethylaluminium in the presence of nickel, cobalt, or platinum.
Elimination reactions.
One of the principal methods for alkene synthesis in the laboratory is the elimination of alkyl halides, alcohols, and similar compounds. Most common is the β-elimination via the E2 or E1 mechanism, but α-eliminations are also known.
The E2 mechanism provides a more reliable β-elimination method than E1 for most alkene syntheses. Most E2 eliminations start with an alkyl halide or alkyl sulfonate ester (such as a tosylate or triflate). When an alkyl halide is used, the reaction is called a dehydrohalogenation. For unsymmetrical products, the more substituted alkenes (those with fewer hydrogens attached to the C=C) tend to predominate (see Zaitsev's rule). Two common methods of elimination reactions are dehydrohalogenation of alkyl halides and dehydration of alcohols. A typical example is shown below; note that if possible, the H is "anti" to the leaving group, even though this leads to the less stable "Z"-isomer.
Alkenes can be synthesized from alcohols via dehydration, in which case water is lost via the E1 mechanism. For example, the dehydration of ethanol produces ethene:
An alcohol may also be converted to a better leaving group (e.g., xanthate), so as to allow a milder "syn"-elimination such as the Chugaev elimination and the Grieco elimination. Related reactions include eliminations by β-haloethers (the Boord olefin synthesis) and esters (ester pyrolysis).
Alkenes can be prepared indirectly from alkyl amines. The amine or ammonia is not a suitable leaving group, so the amine is first either alkylated (as in the Hofmann elimination) or oxidized to an amine oxide (the Cope reaction) to render a smooth elimination possible. The Cope reaction is a "syn"-elimination that occurs at or below 150 °C, for example:
The Hofmann elimination is unusual in that the "less" substituted (non-Saytseff) alkene is usually the major product.
Alkenes are generated from α-halosulfones in the Ramberg–Bäcklund reaction, via a three-membered ring sulfone intermediate.
Synthesis from carbonyl compounds.
Another important method for alkene synthesis involves construction of a new carbon–carbon double bond by coupling of a carbonyl compound (such as an aldehyde or ketone) to a carbanion equivalent. Such reactions are sometimes called "olefinations". The most well-known of these methods is the Wittig reaction, but other related methods are known.
The Wittig reaction involves reaction of an aldehyde or ketone with a Wittig reagent (or phosphorane) of the type Ph3P=CHR to produce an alkene and Ph3P=O. The Wittig reagent is itself prepared easily from triphenylphosphine and an alkyl halide. The reaction is quite general and many functional groups are tolerated, even esters, as in this example:
Related to the Wittig reaction is the Peterson olefination. This uses a less accessible silicon-based reagent in place of the phosphorane, but it allows for the selection of "E"- or "Z"-products. If an "E"-product is desired, another alternative is the Julia olefination, which uses the carbanion generated from a phenyl sulfone. The Takai olefination based on an organochromium intermediate also delivers E-products. A titanium compound, Tebbe's reagent, is useful for the synthesis of methylene compounds; in this case, even esters and amides react.
A pair of carbonyl compounds can also be reductively coupled together (with reduction) to generate an alkene. Symmetrical alkenes can be prepared from a single aldehyde or ketone coupling with itself, using titanium metal reduction (the McMurry reaction). If two different ketones are to be coupled, a more complex, indirect method such as the Barton–Kellogg reaction may be used.
A single ketone can also be converted to the corresponding alkene via its tosylhydrazone, using sodium methoxide (the Bamford–Stevens reaction) or an alkyllithium (the Shapiro reaction).
Synthesis from alkenes: olefin metathesis and hydrovinylation.
Alkenes can be prepared by exchange with other alkenes, in a reaction known as olefin metathesis. Frequently, loss of ethene gas is used to drive the reaction towards a desired product. In many cases, a mixture of geometric isomers is obtained, but the reaction tolerates many functional groups. The method is particularly effective for the preparation of cyclic alkenes, as in this synthesis of muscone:
Transition metal catalyzed hydrovinylation is another important alkene synthesis process starting from alkene itself. In general, it involves the addition of a hydrogen and a vinyl group (or an alkenyl group) across a double bond. The hydrovinylation reaction was first reported by Alderson, Jenner, and Lindsey by using rhodium and ruthenium salts, other metal catalysts commonly employed nowadays included iron, cobalt, nickel, and palladium. The addition can be done highly regio- and stereoselectively, the choices of metal centers, ligands, substrates and counterions often play very important role. Recent studies showed that the use of N-heterocyclic carbene with Ni can be useful for the selective preparations of functionalized geminal olefins or 1,1-disubstituted alkenes.
From alkynes.
Reduction of alkynes is a useful method for the stereoselective synthesis of disubstituted alkenes. If the "cis"-alkene is desired, hydrogenation in the presence of Lindlar's catalyst (a heterogeneous catalyst that consists of palladium deposited on calcium carbonate and treated with various forms of lead) is commonly used, though hydroboration followed by hydrolysis provides an alternative approach. Reduction of the alkyne by sodium metal in liquid ammonia gives the "trans"-alkene.
For the preparation multisubstituted alkenes, carbometalation of alkynes can give rise to a large variety of alkene derivatives.
Rearrangements and related reactions.
Alkenes can be synthesized from other alkenes via rearrangement reactions. Besides olefin metathesis (described above), a large number of pericyclic reactions can be used such as the ene reaction and the Cope rearrangement.
In the Diels–Alder reaction, a cyclohexene derivative is prepared from a diene and a reactive or electron-deficient alkene.
Nomenclature.
Although the nomenclature is not followed widely, according to IUPAC, alkenes are acyclic hydrocarbons with one double bond between carbon centers. Olefins comprise a larger collection of cyclic and acyclic alkenes as well as dienes and polyenes.
IUPAC names.
To form the root of the IUPAC names for alkenes, simply change the "-an-" infix of the parent to "-en-". For example, CH3-CH3 is the alkane "ethANe". The name of CH2=CH2 is therefore "ethENe".
In higher alkenes, where isomers exist that differ in location of the double bond, the following numbering system is used:
"Cis"–"trans" notation.
In the specific case of disubstituted alkenes where the two carbons have one substituent each, "cis"–"trans" notation may be used. If both substituents are on the same side of the bond, it is defined as "cis"-. If the substituents are on either side of the bond, it is defined as "trans"-.
"E"–"Z" notation.
When an alkene has more than one substituent (especially necessary with 3 or 4 substituents), the double bond geometry is described using the labels "E" and "Z". These labels come from the German words "entgegen", meaning "opposite", and "zusammen", meaning "together". Alkenes with the higher priority groups (as determined by CIP rules) on the same side of the double bond have these groups together and are designated "Z". Alkenes with the higher priority groups on opposite sides are designated "E". A mnemonic to remember this: "Z" notation has the higher priority groups on "ze zame zide."
Groups containing C=C double bonds.
IUPAC recognizes two names for hydrocarbon groups containing carbon–carbon double bonds, the vinyl group and the allyl group. .

</doc>
<doc id="2762" url="https://en.wikipedia.org/wiki?curid=2762" title="Allene">
Allene

An allene is a compound in which one carbon atom has double bonds with each of its two adjacent carbon centres. Allenes are classified as polyenes with cumulated dienes. The parent compound of allene is propadiene. Compounds with an allene-type structure but with more than three carbon atoms are called cumulenes. Allenes are much more reactive than most other alkenes. For example, their reactivity with gaseous chlorine is more like the reactivity of alkynes than that of alkenes.
Structure and bonding.
Geometry.
The central carbon of allene forms two sigma bonds and two pi bonds. The central carbon is sp-hybridized, and the two terminal carbons are sp2-hybridized. The bond angle formed by the three carbons is 180°, indicating linear geometry for the carbons of allene. It can also be viewed as an "extended tetrahedral" with a similar shape to methane.
Symmetry.
The symmetry and isomerism of allenes has long fascinated organic chemists. For allenes with four identical substituents, there exist two twofold axes of rotation through the center carbon, inclined at 45° to the CH2 planes at either end of the molecule. The molecule can thus be thought of as a two-bladed propeller. A third twofold axis of rotation passes through the C=C=C bonds, and there is a mirror plane passing through both CH2 planes. Thus this class of molecules belong to the D2d point group. Because of the symmetry, an unsubstituted allene has no net dipole moment.
An allene with two different substituents on each of the two carbons will be chiral because there will no longer be any mirror planes. Where A has a greater priority than B according to the Cahn-Ingold-Prelog priority rule, the configuration of the axial chirality can be determined by considering the substituents on the front atom followed by the back atom when viewed along the allene axis. For the bottom, only the group of higher priority need be considered. Chiral allenes have been recently used as building blocks in the construction of organic materials with exceptional chiroptical properties. 
Synthesis.
Although allenes often require specialized syntheses, the parent, propadiene is produced on a large scale as an equilibrium mixture with methylacetylene:
This mixture, known as MAPP gas, is commercially available.
Laboratory methods for the formation of allenes include:

</doc>
<doc id="2763" url="https://en.wikipedia.org/wiki?curid=2763" title="Alkyne">
Alkyne

In organic chemistry, an alkyne is an unsaturated hydrocarbon containing at least one carbon—carbon triple bond. The simplest acyclic alkynes with only one triple bond and no other functional groups form a homologous series with the general chemical formula "n"2"n"−2. Alkynes are traditionally known as acetylenes, although the name "acetylene" also refers specifically to C2H2, known formally as ethyne using IUPAC nomenclature. Like other hydrocarbons, alkynes are generally hydrophobic but tend to be more reactive.
Chemical properties.
Alkynes are characteristically more unsaturated than alkenes. Thus they add two equivalents of bromine whereas an alkene adds only one equivalent in the reaction. Other reactions are listed below. In some reactions, alkynes are less reactive than alkenes. For example, in a molecule with an -ene and an -yne group, addition occurs preferentially at the -ene. Possible explanations involve the two π-bonds in the alkyne delocalising, which would reduce the energy of the π-system or the stability of the intermediates during the reaction.
They show greater tendency to polymerize or oligomerize than alkenes do. The resulting polymers, called polyacetylenes (which do not contain alkyne units) are conjugated and can exhibit semiconducting properties.
Structure and bonding.
In acetylene, the H–C≡C bond angles are 180°. By virtue of this bond angle, alkynes tend to be rod-like. Correspondingly, cyclic alkynes are rare. Benzyne is highly unstable. The C≡C bond distance of 121 picometers is much shorter than the C=C distance in alkenes (134 pm) or the C–C bond in alkanes (153 pm).
The triple bond is very strong with a bond strength of 839 kJ/mol. The sigma bond contributes 369 kJ/mol, the first pi bond contributes 268 kJ/mol and the second pi-bond of 202 kJ/mol bond strength. Bonding usually discussed in the context of molecular orbital theory, which recognizes the triple bond as arising from overlap of s and p orbitals. In the language of valence bond theory, the carbon atoms in an alkyne bond are sp hybridized: they each have two unhybridized p orbitals and two sp hybrid orbitals. Overlap of an sp orbital from each atom forms one sp–sp sigma bond. Each p orbital on one atom overlaps one on the other atom, forming two pi bonds, giving a total of three bonds. The remaining sp orbital on each atom can form a sigma bond to another atom, for example to hydrogen atoms in the parent acetylene. The two sp orbitals project on opposite sides of the carbon atom.
Terminal and internal alkynes.
Internal alkynes feature carbon substituents on each acetylenic carbon. Symmetrical examples include diphenylacetylene and 3-hexyne.
Terminal alkynes have the formula RC2H. An example is methylacetylene (propyne using IUPAC nomenclature). Terminal alkynes, like acetylene itself, are mildly acidic, with p"K"a values of around 25. They are far more acidic than alkenes and alkanes, which have p"K"a values of around 40 and 50, respectively. The acidic hydrogen on terminal alkynes can be replaced by a variety of groups resulting in halo-, silyl-, and alkoxoalkynes. The carbanions generated by deprotonation of terminal alkynes are called acetylides.
Naming alkynes.
In systematic chemical nomenclature, alkynes are named with the Greek prefix system without any additional letters. Examples include ethyne or octyne. In parent chains with 4 or more carbons, it is necessary to say where the triple bond is located. For octyne, one can either write 3-octyne or oct-3-yne when the bond starts at the third carbon. The lowest number possible is given to the triple bond. When no superior functional groups are present, the parent chain must include the triple bond even if it is not the longest possible carbon chain in the molecule. Ethyne is commonly called by its trivial name acetylene.
In chemistry, the suffix -yne is used to denote the presence of a triple bond. 
The suffix follows IUPAC nomenclature, and is mainly used in organic chemistry. However, inorganic compounds featuring unsaturation in the form of triple bonds may be denoted by substitutive nomenclature with the same methods used with alkynes, i.e., the name of the corresponding saturated hydride is modified by replacing the "-ane" ending with "-yne". "-diyne" is used when there are two triple bonds, and so on. The position of unsaturation is indicated by a numerical locant immediately preceding the "-yne" suffix, or 'locants' in the case of multiple triple bonds. Locants are chosen to be as low as possible. "-yne" is also used as an infix to name substituent groups that are triply bound to the parent compound.
Sometimes a number between hyphens is inserted before it to state which atoms the triple bond is between. This suffix arose as a collapsed form of the end of the word "acetylene". The final "-e" disappears if it is followed by another suffix that starts with a vowel.
Synthesis.
Commercially, the dominant alkyne is acetylene itself, which is used as a fuel and a precursor to other compounds, e.g., acrylates. Hundreds of millions of kilograms are produced annually by partial oxidation of natural gas:
Propyne, also industrially useful, is also prepared by thermal cracking of hydrocarbons. Most other industrially useful alkyne derivatives are prepared from acetylene, e.g. via condensation with formaldehyde.
Specialty alkynes are prepared by dehydrohalogenation of vicinal alkyl dihalides or vinyl halides. Metal acetylides can be coupled with primary alkyl halides. Via the Fritsch–Buttenberg–Wiechell rearrangement, alkynes are prepared from vinyl bromides. Alkynes can be prepared from aldehydes using the Corey–Fuchs reaction and from aldehydes or ketones by the Seyferth–Gilbert homologation. In the alkyne zipper reaction, alkynes are generated from other alkynes by treatment with a strong base.
Reactions.
Featuring a reactive functional group, alkynes participate in many organic reactions.
Addition of hydrogen, halogens, and related reagents.
Alkynes characteristically undergo reactions that show that they are "doubly unsaturated", meaning that each alkyne unit is capable of adding two equivalents of H2, halogens or related HX reagents (X = halide, pseudohalide, etc.). Depending on catalysts and conditions, alkynes add one or two equivalents of hydrogen. Hydrogenation to the alkene is usually more desirable since alkanes are less useful:
The largest scale application of this technology is the conversion of acetylene to ethylene in refineries. The steam cracking of alkanes yields a few percent acetylene, which is selectively hydrogenated in the presence of a palladium/silver catalyst. For more complex alkynes, the Lindlar catalyst is widely recommended to avoid formation of the alkane, for example in the conversion of phenylacetylene to styrene.
Similarly, halogenation of alkynes gives the vinyl dihalides or alkyl tetrahalides:
The addition of nonpolar E–H bonds across C≡C is general for silanes, boranes, and related hydrides. The hydroboration of alkynes gives vinylic boranes which oxidize to the corresponding aldehyde or ketone. In the thiol-yne reaction the substrate is a thiol.
Hydrohalogenation gives the corresponding vinyl halides or alkyl dihalides, again depending on the number of equivalents of HX added. The addition of water to alkynes is a related reaction except the initial enol intermediate converts to the ketone or aldehyde. Illustrative is the hydration of phenylacetylene gives acetophenone, and the (Ph3P)AuCH3-catalyzed hydration of 1,8-nonadiyne to 2,8-nonanedione:
Cycloadditions and oxidation.
Alkynes undergo diverse cycloaddition reactions. Most notable is the Diels–Alder reaction with 1,3-dienes to give 1,4-cyclohexadienes. This general reaction has been extensively developed and electrophilic alkynes are especially effective dienophiles. The "cycloadduct" derived from the addition of alkynes to 2-pyrone eliminates carbon dioxide to give the aromatic compound. Other specialized cycloadditions include multicomponent reactions such as alkyne trimerisation to give aromatic compounds and the [2+2+1]-cycloaddition of an alkyne, alkene and carbon monoxide in the Pauson–Khand reaction. Non-carbon reagents also undergo cyclization, e.g. Azide alkyne Huisgen cycloaddition to give triazoles. Cycloaddition processes involving alkynes are often catalyzed by metals, e.g. enyne metathesis and alkyne metathesis, which allows the scrambling of carbyne (RC) centers:
Oxidative cleavage of alkynes proceeds via cycloaddition to metal oxides. Most famously, potassium permanganate converts alkynes to a pair of carboxylic acids.
Reactions specific for terminal alkynes.
In addition to undergoing the reactions characteristic of internal alkynes, terminal alkynes are reactive as weak acids, with p"K"a values (25) between that of ammonia (35) and ethanol (16). The acetylide conjugate base is stabilized as a result of the high s character of the sp orbital, in which the electron pair resides. Electrons in an s orbital benefit from closer proximity to the positively charged atom nucleus, and are therefore lower in energy. Treatment of terminal alkynes with a strong base gives the corresponding metal acetylides:
The reactions of alkynes with certain metal cations, e.g. Ag+ also gives acetylides. Thus, few drops of diamminesilver(I) hydroxide (Ag(NH3)2OH) reacts with terminal alkynes signaled by formation of a white precipitate of the silver acetylide.
Acetylide derivatives are synthetically useful nucleophiles that participate in C–C bond forming reactions, as illustrated in the area called "Reppe Chemistry".
In the Favorskii reaction and in alkynation in general, terminal alkynes add to carbonyl compounds to give the hydroxyalkyne. Coupling of terminal alkynes to give dialkynes is effected in the Cadiot–Chodkiewicz coupling, Glaser coupling, and the Eglinton coupling reactions. Terminal alkynes can also be coupled to aryl or vinyl halides as in the Sonogashira coupling.
Alkynes in nature and medicine.
According to Ferdinand Bohlmann, the first naturally occurring acetylenic compound, dehydromatricaria ester, was isolated from an "Artemisia" species in 1826. In the nearly two centuries that have followed, well over a thousand naturally occurring acetylenes have been discovered and reported. Polyynes, a subset of this class of natural products, have been isolated from a wide variety of plant species, cultures of higher fungi, bacteria, marine sponges, and corals. Some acids like tariric acid contains an alkyne group. Diynes and triynes, species with the linkage RC≡C–C≡CR′ and RC≡C–C≡C–C≡CR′ respectively, occur in certain plants ("Ichthyothere", "Chrysanthemum", "Cicuta", "Oenanthe" and other members of the Asteraceae and Apiaceae families). Some examples are cicutoxin, oenanthotoxin, falcarinol and carotatoxin. These compounds are highly bioactive, e.g. as nematocides. 1-Phenylhepta-1,3,5-triyne is illustrative of a naturally occurring triyne.
Alkynes occur in some pharmaceuticals, including the contraceptive noretynodrel. A carbon–carbon triple bond is also present in marketed drugs such as the antiretroviral Efavirenz and the antifungal Terbinafine. Molecules called ene-diynes feature a ring containing an alkene ("ene") between two alkyne groups ("diyne"). These compounds, e.g. calicheamicin, are some of the most aggressive antitumor drugs known, so much so that the ene-diyne subunit is sometimes referred to as a "warhead". Ene-diynes undergo rearrangement via the Bergman cyclization, generating highly reactive radical intermediates that attack DNA within the tumor.

</doc>
<doc id="2764" url="https://en.wikipedia.org/wiki?curid=2764" title="AbiWord">
AbiWord

AbiWord () is a free and open source software word processor written in C++. Since version 3 it is based on GTK+ 3. The name "AbiWord" is derived from the root of the Spanish word ""abierto"", meaning "open".
AbiWord was originally started by SourceGear Corporation as the first part of a proposed AbiSuite but was adopted by open source developers after SourceGear changed its business focus and ceased development. It now runs on Linux, Microsoft Windows, ReactOS, Solaris, AmigaOS 4.0 (through its Cygnix X11 engine), MeeGo (on the Nokia N9 smartphone), Maemo (on the Nokia N810) QNX and other operating systems.
The Mac OS X port has remained on version 2.4 since 2005, although the current version does run non-natively on Mac OS X through XQuartz.
AbiWord is part of the AbiSource project which develops a number of office-related technologies.
The software is available on Android devices as part of the "Debian noroot" package from the Google Play Store.
Features.
AbiWord supports both basic word processing features such as lists, indents and character formats, and more sophisticated features including tables, styles, page headers and footers, footnotes, templates, multiple views, page columns, spell checking, and grammar checking. Starting with version 2.8.0, AbiWord includes a collaboration plugin that allows integration with AbiCollab.net, a Web-based service that permits multiple users to work on the same document in real time, in full synchronization. The Presentation view of AbiWord, which permits easy display of presentations created in AbiWord on "screen-sized" pages, is another feature not often found in word processors.
Interface.
AbiWord generally works similarly to classic versions (pre-Office 2007) of Microsoft Word, as direct ease of migration was a high priority early goal. While many interface similarities remain, cloning the Word interface is no longer a top priority. The interface is intended to follow user interface guidelines for each respective platform.
File formats.
AbiWord comes with several import and export filters providing a partial support for such formats as HTML, Microsoft Word (.doc), Office Open XML (.docx), OpenDocument Text (.odt), Rich Text Format (.rtf), and text documents (.txt). LaTeX is supported for export only. Plug-in filters are available to deal with many other formats, notably WordPerfect documents. The native file format, .abw, uses XML, so as to mitigate vendor lock-in concerns with respect to interoperability and digital archiving.
Grammar checking.
The AbiWord project includes a US English-only grammar checking plugin using Link Grammar. AbiWord had grammar checking before any other open source word processor, although a grammar checker was later added to OpenOffice.org. Link Grammar is both a theory of syntax and an open source parser which is now developed by the AbiWord project.

</doc>
<doc id="2766" url="https://en.wikipedia.org/wiki?curid=2766" title="Ames test">
Ames test

The Ames test is a widely employed method that uses bacteria to test whether a given chemical can cause mutations in the DNA of the test organism. More formally, it is a biological assay to assess the mutagenic potential of chemical compounds. A positive test indicates that the chemical is mutagenic and therefore may act as a carcinogen, because cancer is often linked to mutation. The test serves as a quick and convenient assay to estimate the carcinogenic potential of a compound because standard carcinogen assays on mice and rats are time-consuming (taking two to three years to complete) and expensive. However, false-positives and false-negatives are known. 
The procedure was described in a series of papers in the early 1970s by Bruce Ames and his group at the University of California, Berkeley.
General procedure.
The Ames test uses several strains of the bacterium "Salmonella typhimurium" that carry mutations in genes involved in histidine synthesis. These strains are auxotrophic mutants, i.e. they require histidine for growth, but cannot produce it. The method tests the capability of the tested substance in creating mutations that result in a return to a "prototrophic" state, so that the cells can grow on a histidine-free medium. 
The tester strains are specially constructed to detect either frameshift (e.g. strains TA-1537 and TA-1538) or point (e.g. strain TA-1531) mutations in the genes required to synthesize histidine, so that mutagens acting via different mechanisms may be identified. Some compounds are quite specific, causing reversions in just one or two strains. The tester strains also carry mutations in the genes responsible for lipopolysaccharide synthesis, making the cell wall of the bacteria more permeable, and in the excision repair system to make the test more sensitive. Rat liver extract is optionally added to simulate the effect of metabolism, as some compounds, like , are not mutagenic themselves but their metabolic products are.
The bacteria are spread on an agar plate with small amount of histidine. This small amount of histidine in the growth medium allows the bacteria to grow for an initial time and have the opportunity to mutate.
When the histidine is depleted only bacteria that have mutated to gain the ability to produce its own histidine will survive. The plate is incubated for 48 hours. The mutagenicity of a substance is proportional to the number of colonies observed.
Ames test and carcinogens.
Mutagens identified via Ames test are also possible carcinogens, and early studies by Ames showed that 90% of known carcinogens may be identified via this test. Later studies however showed identification of 50–70% of known carcinogens. The test was used to identify a number of compounds previously used in commercial products as potential carcinogens. Examples include tris(2,3-dibromopropyl)phosphate, which was used as a flame retardant in plastic and textiles such as children's sleepwear, and furylfuramide which was used as an antibacterial additive in food in Japan in 1960s and 1970s. Furylfuramide in fact had previously passed animal test, but more vigorous tests after its identification in the Ames test showed it to be carcinogenic. Their positive tests resulted in those chemicals being withdrawn from use in consumer products.
One interesting result from the Ames test is that the dose response curve using varying concentrations of chemical is almost always linear, indicating that there is no threshold concentration for mutagenesis. It therefore suggests that, as with radiations, there may be no safe threshold for chemical mutagens or carcinogens. However some proposed that organisms can tolerate low level of mutagens due to protective mechanisms such as DNA repair, and threshold may exist for certain chemical mutagens. Bruce Ames himself argued against linear dose-response extrapolation from the high dose used in carcinogenesis tests in animal systems to the lower dose of chemicals normally encountered in human exposure, as the results may be false positives due to mitogenic response caused by the artificially high dose of chemicals used in such tests. He also cautioned against the "hysteria over tiny traces of chemicals that may or may not cause cancer", that "completely drives out the major risks you should be aware of." 
The Ames test is often used as one of the initial screens for potential drugs to weed out possible carcinogens, and it is one of the eight tests required under the Pesticide Act (USA) and one of six tests required under the Toxic Substances Control Act (USA).
Limitations.
"Salmonella typhimurium" is a prokaryote, therefore it is not a perfect model for humans. Rat liver S9 fraction is used to mimic the mammalian metabolic conditions so that the mutagenic potential of metabolites formed by a parent molecule in the hepatic system can be assessed, however there are differences in metabolism between human and rat that can affect the mutagenicity of chemicals being tested. The test may therefore be improved by the use of human liver S9 fraction; its use was previously limited by its availability, but it is now available commercially and therefore may be more feasible. An adapted "in vitro" model has been made for eukaryotic cells, for example yeast. 
Mutagens identified in the Ames test need not necessarily be carcinogenic, and further tests are required for any potential carcinogen identified in the test. Drugs that contain the nitrate moiety sometimes come back positive for Ames when they are indeed safe. The nitrate compounds may generate nitric oxide, an important signal molecule that can give a false positive. Nitroglycerin is an example that gives a positive Ames yet is still used in treatment today. Nitrates in food however may be reduced by bacterial action to nitrites which are known to generate carcinogens by reacting with amines and amides. Long toxicology and outcome studies are needed with such compounds to disprove a positive Ames test.
Fluctuation method.
The Ames test was initially developed using agar plates (the plate incorporation technique), as described above. Since that time, a popular alternative to performing the Ames test has been developed, which is known as the "fluctuation method". This technique is the same in concept as the agar-based method, with bacteria being added to a reaction mixture with a small amount of histidine, which allows the bacteria to grow and mutate, returning to synthesize their own histidine. By including a pH indicator, the frequency of mutation is counted in microplates as the number of wells which have changed color (caused by a drop in pH due to metabolic processes of reproducing bacteria). As with the traditional Ames test, the sample is compared to the natural background rate of reverse mutation in order to establish the genotoxicity of a substance.The fluctuation method is performed entirely in liquid culture and is scored by counting the number of wells that turn yellow from purple in 96-well or 384-well microplates. 
In the 96-well plate method the frequency of mutation is counted as the number of wells out of 96 which have changed color. The plates are incubated for up to five days, with mutated (yellow) colonies being counted each day and compared to the background rate of reverse mutation using established tables of significance to determine the significant differences between the background rate of mutation and that for the tested samples.
In the more scaled-down 384-well plate microfluctuation method the frequency of mutation is counted as the number of wells out of 48 which have changed color after 2 days of incubation. A test sample is assayed across 6 dose levels with concurrent zero-dose (background) and positive controls which all fit into one 384-well plate. The assay is performed in triplicates to provide statistical robustness. It uses the recommended OECD Guideline 471 tester strains (histidine auxotrophs and tryptophan auxotrophs).
The fluctuation method is comparable to the traditional pour plate method in terms of sensitivity and accuracy, however, it does have a number of advantages: it needs less test sample, it has a simple colorimetric endpoint, counting the number of positive wells out of possible 96 or 48 wells is much less time consuming than counting individual colonies on an agar plate. Several commercial kits are available. Most kits have consumable components in a ready-to-use state, including lyophilized bacteria, and tests can be performed using multichannel pipettes. The fluctuation method also allows for testing higher volumes of aqueous samples (up to 75% v/v), increasing the sensitivity and extending its application to low-level environmental mutagens. 

</doc>
<doc id="2767" url="https://en.wikipedia.org/wiki?curid=2767" title="ACE inhibitor">
ACE inhibitor

An angiotensin-converting-enzyme inhibitor (ACE inhibitor) is a pharmaceutical drug used primarily for the treatment of hypertension (elevated blood pressure) and congestive heart failure.
This group of drugs cause relaxation of blood vessels, as well as a decreased blood volume, which leads to lower blood pressure and decreased oxygen demand from the heart. They inhibit the angiotensin-converting enzyme, an important component of the renin–angiotensin–aldosterone system.
Frequently prescribed ACE inhibitors include perindopril, captopril, enalapril, lisinopril, and ramipril.
Medical use.
ACE inhibitors were initially approved for the treatment of hypertension and can be used alone or in combination with other antihypertensive medications. Later, they were found useful for other cardiovascular and kidney diseases including:
In treating heart disease, ACE inhibitors are usually used with other medications. A typical treatment plan often includes an ACE inhibitor, a beta blocker, a long-acting nitrate, and a calcium channel blocker, in combinations that are adjusted to the individual patient's needs.
ACE inhibitors have also been used in chronic kidney failure and kidney involvement in systemic sclerosis (hardening of tissues, as scleroderma renal crisis).
Mechanism of action.
ACE inhibitors reduce the activity of the renin-angiotensin-aldosterone system (RAAS) as the primary etiologic (causal) event in the development of hypertension in people with diabetes mellitus, as part of the insulin-resistance syndrome or as a manifestation of renal disease.
Renin-angiotensin-aldosterone system.
One mechanism for maintaining the blood pressure is the release of renin, an enzyme, from cells in the kidney (to be specific, the juxtaglomerular apparatus). This proteolytically cleaves and activates another circulating protein, angiotensin. This system is activated in response to a fall in blood pressure (hypotension) and markers of problems with the salt-water balance of the body, such as decreased sodium concentration in the distal tubules of the kidney, decreased blood volume, and stimulation of the kidney by the sympathetic nervous system. In such situations, the kidneys release renin, which acts as an enzyme and cuts off all but the first ten amino acid residues of angiotensinogen (a protein made in the liver, and which circulates in the blood). These ten residues are then known as angiotensin I. ACE then removes a further two residues, converting angiotensin I into angiotensin II. Angiotensin II is found in the pulmonary circulation and in the endothelium of many blood vessels. The system increases blood pressure by increasing the amount of salt and water the body retains, although angiotensin is also very good at causing the blood vessels to tighten (a potent vasoconstrictor).
Effects.
ACE inhibitors block the conversion of angiotensin I (AI) to angiotensin II (AII). They thereby lower arteriolar resistance and increase venous capacity; decrease cardiac output, cardiac index, stroke work, and volume; lower resistance in blood vessels in the kidneys; and lead to increased natriuresis (excretion of sodium in the urine).
Renin increases in concentration in the blood as a result of negative feedback of conversion of AI to AII. AI increases for the same reason; AII and aldosterone decrease. Bradykinin increases because of less inactivation by ACE.
Under normal conditions, angiotensin II has these effects:
With ACE inhibitor use, the production of AII is decreased, leading to decreased blood pressure.
Epidemiological and clinical studies have shown ACE inhibitors reduce the progress of diabetic nephropathy independently from their blood pressure-lowering effect. This action of ACE inhibitors is used in the prevention of diabetic renal failure.
ACE inhibitors have been shown to be effective for indications other than hypertension even in patients with normal blood pressure. The use of a maximum dose of ACE inhibitors in such patients (including for prevention of diabetic nephropathy, congestive heart failure, and prophylaxis of cardiovascular events) is justified, because it improves clinical outcomes independently of the blood pressure-lowering effect of ACE inhibitors. Such therapy, of course, requires careful and gradual titration of the dose to prevent the effects of rapidly decreasing blood pressure (dizziness, fainting, etc.).
ACE inhibitors have also been shown to cause a central enhancement of parasympathetic nervous system activity in healthy volunteers and patients with heart failure. This action may reduce the prevalence of malignant cardiac arrhythmias, and the reduction in sudden death reported in large clinical trials.
ACE Inhibitors also reduce plasma norepinephrine levels, and its resulting vasoconstriction effects, in heart failure patients, thus breaking the vicious circles of sympathetic and renin angiotensin system activation, which sustains the downward spiral in cardiac function in congestive heart failure
The ACE inhibitor enalapril has also been shown to reduce cardiac cachexia in patients with chronic heart failure. Cachexia is a poor prognostic sign in patients with chronic heart failure.
ACE inhibitors are under early investigation for the treatment of frailty and muscle wasting (sarcopenia) in elderly patients without heart failure.
Adverse effects.
Common adverse drug reactions include: hypotension, cough, hyperkalemia, headache, dizziness, fatigue, nausea, and renal impairment. ACE inhibitors might increase inflammation-related pain, perhaps mediated by the buildup of bradykinin that accompanies ACE inhibition.
The main adverse effects of ACE inhibition can be understood from their pharmacological action. The other reported adverse effects are hepatotoxicity and effect on the fetus.
Renal impairment is a significant potential adverse effect of all ACE inhibitors that directly follows from their mechanism of action. Patients starting on an ACE inhibitor usually have a modest reduction in glomerular filtration rate (GFR) that stabilizes after several days. However, the decrease may be significant in conditions of decreased renal perfusion, such as renal artery stenosis, heart failure, polycystic kidney disease, or volume depletion. In these patients, maintenance of GFR depends on angiotensin-II-dependent efferent vasomotor tone. Therefore, renal function should be closely monitored over the first few days after initiation of treatment with ACE inhibitor in patients with decreased renal perfusion. A moderate reduction in renal function, no greater than 30% rise in serum creatinine, that is stabilized after a week of treatment is deemed acceptable as part of the therapeutic effect, providing the residual renal function is sufficient. This is especially a problem if the patient is concomitantly taking an NSAID and a diuretic. When the three drugs are taken together, the risk of developing renal failure is significantly increased.
Hyperkalemia (high concentration of potassium in the blood) is another possible complication of treatment with an ACE inhibitor due to its effect on aldosterone. Suppression of angiotensin II leads to a decrease in aldosterone levels. Since aldosterone is responsible for increasing the excretion of potassium, ACE inhibitors can cause retention of potassium. Some people, however, can continue to lose potassium while on an ACE inhibitor. Hyperkalemia may decrease the velocity of impulse conduction in the nerves and muscles, including cardiac tissues. This leads to cardiac dysfunction and neuromuscular consequences, such as muscle weakness, paresthesia, nausea, diarrhea, and others. Close monitoring of potassium levels is required in patients receiving treatment with ACE inhibitors who are at risk of hyperkalemia.
Another possible adverse effect specific for ACE inhibitors, but not for other RAAS blockers, is an increase in bradykinin level. Elevated bradykinin level due to ACE inhibition can be a cause of dry cough, angioedema and/or rash, hypotension, and inflammation-related pain.
A persistent dry cough is a relatively common adverse effect believed to be associated with the increases in bradykinin levels produced by ACE inhibitors, although the role of bradykinin in producing these symptoms has been disputed. Patients who experience this cough are often switched to angiotensin II receptor antagonists.
Some patients develop angioedema due to increased bradykinin levels. A genetic predisposition may exist toward this adverse effect in patients who degrade bradykinin more slowly than average.
Rash and taste disturbances, infrequent with most ACE inhibitors, are more prevalent in captopril, and this is attributed to its sulfhydryl moiety. This has led to decreased use of captopril in clinical setting, although it is still used in scintigraphy of the kidney.
A severe rare allergic reaction can affect the bowel wall and secondarily cause abdominal pain.
Adverse hematologic effects.
Hematologic effects, such as neutropenia, agranulocytosis and other blood dyscrasias, have occurred during therapy with ACE inhibitors, especially in patients with additional risk factors (see Warnings). Patients should be advised to report symptoms such as sore throat or fever to their physician.
In pregnant women, ACE inhibitors taken during all the trimesters have been reported to cause congenital malformations, stillbirths, and neonatal deaths. Commonly reported fetal abnormalities include hypotension, renal dysplasia, anuria/oliguria, oligohydramnios, intrauterine growth retardation, pulmonary hypoplasia, patent ductus arteriosus, and incomplete ossification of the skull. Overall, about half of newborns exposed to ACE inhibitors are adversely affected.
Overdose.
Symptoms and Treatment: There are few reports of ACE inhibitor overdose in the literature. The most likely manifestations are hypotension, which may be severe, hyperkalemia, hyponatremia and renal impairment with metabolic acidosis. Treatment should be mainly symptomatic and supportive, with volume expansion using normal saline to correct hypotension and improve renal function, and gastric lavage followed by activated charcoal and a cathartic to prevent further absorption of the drug. Captopril, enalapril, lisinopril and perindopril are known to be removable by hemodialysis.
Contraindications and precautions.
The ACE inhibitors are contraindicated in patients with:
ACE inhibitors should be used with caution in patients with:
ACE inhibitors are ADEC pregnancy category D, and should be avoided in women who are likely to become pregnant. In the U.S., ACE inhibitors must be labeled with a boxed warning concerning the risk of birth defects when taken during the second and third trimester. Their use in the first trimester is also associated with a risk of major congenital malformations, particularly affecting the cardiovascular and central nervous systems.
A combination of ACE inhibitor with other drugs may increase effects of these drugs, but also the risk of adverse effects. The commonly reported adverse effects of drug combination with ACE are acute renal failure, hypotension, and hyperkalemia. The drugs interacting with ACE inhibitor should be prescribed with caution. Special attention should be given to combinations of ACE inhibitor with other RAAS blockers, diuretics (especially potassium-sparing diuretics), NSAIDs, anticoagulants, cyclosporine, DPP-4 inhibitors, and potassium supplements.
Potassium supplementation should be used with caution and under medical supervision owing to the hyperkalemic effect of ACE inhibitors.
Examples.
ACE inhibitors are easily identifiable by their common suffix, '-pril'. ACE inhibitors can be divided into three groups based on their molecular structure:
Dicarboxylate-containing agents.
This is the largest group, including:
Comparative information.
All ACE inhibitors have similar antihypertensive efficacy when equivalent doses are administered. The main differences lie with captopril, the first ACE inhibitor. Captopril has a shorter duration of action and an increased incidence of adverse effects. It is also the only ACE inhibitor capable of passing through the blood–brain barrier, although the significance of this characteristic has not been shown to have any positive clinical effects.
In a large clinical study, one of the agents in the ACE inhibitor class, ramipril (Altace), demonstrated an ability to reduce the mortality rates of patients suffering from a myocardial infarction, and to slow the subsequent development of heart failure. This finding was made after it was discovered that regular use of ramipril reduced mortality rates even in test subjects not having suffered from hypertension.
Some believe ramipril's additional benefits may be shared by some or all drugs in the ACE-inhibitor class. However, ramipril currently remains the only ACE inhibitor for which such effects are actually evidence-based.
A meta-analysis confirmed that ACE inhibitors are effective and certainly the first-line choice in hypertension treatment. This meta-analysis was based on 20 trials and a cohort of 158,998 patients, of whom 91% were hypertensive. ACE inhibitors were used as the active treatment in seven trials (n=76,615) and angiotensin receptor blocker (ARB) in 13 trials (n=82,383).
ACE inhibitors were associated with a statistically significant 10% mortality reduction: (HR 0.90; 95% CI, 0.84-0.97; P=0.004). In contrast, no significant mortality reduction was observed with ARB treatment (HR 0.99; 95% CI, 0.94-1.04; P=0.683). Analysis of mortality reduction by different ACE inhibitors showed that perindopril-based regimens are associated with a statistically significant 13% all-cause mortality reduction.
Taking into account the broad spectrum of the hypertensive population, one might expect that an effective treatment with ACE inhibitors, in particular with perindopril, would result in an important gain of lives saved.
ACE inhibitor equivalent doses in hypertension.
The ACE inhibitors have different strengths with different starting dosages. Dosage should be adjusted according to the clinical response.
Angiotensin II receptor antagonists.
ACE inhibitors possess many common characteristics with another class of cardiovascular drugs, angiotensin II receptor antagonists, which are often used when patients are intolerant of the adverse effects produced by ACE inhibitors. ACE inhibitors do not completely prevent the formation of angiotensin II, as blockage is dose-dependent, so angiotensin II receptor antagonists may be useful because they act to prevent the action of angiotensin II at the AT1 receptor, leaving AT2 receptor unblocked; the latter may have consequences needing further study.
Use in combination.
The combination therapy of angiotensin II receptor antagonists with ACE inhibitors may be superior to either agent alone. This combination may increase levels of bradykinin while blocking the generation of angiotensin II and its activity at the AT1 receptor. This 'dual blockade' may be more effective than using an ACE inhibitor alone, because angiotensin II can be generated via non-ACE-dependent pathways. Preliminary studies suggest this combination of pharmacologic agents may be advantageous in the treatment of essential hypertension, chronic heart failure, and nephropathy. However, the more recent ONTARGET study showed no benefit of combining the agents and more adverse events. While statistically significant results have been obtained for its role in treating hypertension, clinical significance may be lacking. There are warnings about the combination of ACE inhibitors with ARBs.
Patients with heart failure may benefit from the combination in terms of reducing morbidity and ventricular remodeling.
The most compelling evidence for the treatment of nephropathy has been found: This combination therapy partially reversed the proteinuria and also exhibited a renoprotective effect in patients afflicted with diabetic nephropathy, and pediatric IgA nephropathy.
History.
The first step in the development of ACE inhibitors was the discovery of ACE in plasma by Leonard T. Skeggs and his colleagues in 1956. Brazilian scientist Sérgio Henrique Ferreira reported a bradykinin-potentiating factor (BPF) present in the venom of "Bothrops jararaca", a South American pit viper, in 1965. Ferreira then went to John Vane's laboratory as a postdoctoral fellow with his already-isolated BPF. The conversion of the inactive angiotensin I to the potent angiotensin II was thought to take place in the plasma. However, in 1967, Kevin K. F. Ng and John R. Vane showed plasma ACE is too slow to account for the conversion of angiotensin I to angiotensin II "in vivo". Subsequent investigation showed rapid conversion occurs during its passage through the pulmonary circulation.
Bradykinin is rapidly inactivated in the circulating blood, and it disappears completely in a single pass through the pulmonary circulation. Angiotensin I also disappears in the pulmonary circulation because of its conversion to angiotensin II. Furthermore, angiotensin II passes through the lungs without any loss. The inactivation of bradykinin and the conversion of angiotensin I to angiotensin II in the lungs was thought to be caused by the same enzyme. In 1970, Ng and Vane, using BPF provided by Ferreira, showed the conversion is inhibited during its passage through the pulmonary circulation.
BPFs are members of a family of peptides whose potentiating action is linked to inhibition of bradykinin by ACE. Molecular analysis of BPF yielded a nonapeptide BPF teprotide (SQ 20,881), which showed the greatest ACE inhibition potency and hypotensive effect "in vivo". Teprotide had limited clinical value as a result of its peptide nature and lack of activity when given orally. In the early 1970s, knowledge of the structure-activity relationship required for inhibition of ACE was growing. David Cushman, Miguel Ondetti and colleagues used peptide analogues to study the structure of ACE, using carboxypeptidase A as a model. Their discoveries led to the development of captopril, the first orally-active ACE inhibitor, in 1975.
Captopril was approved by the United States Food and Drug Administration in 1981. The first nonsulfhydryl-containing ACE inhibitor, enalapril, was marketed two years later. At least 12 other ACE inhibitors have since been marketed.
In 1991, Japanese scientists created the first milk-based ACE inhibitor, in the form of a fermented milk drink, using specific cultures to liberate the tripeptide isoleucine-proline-proline (IPP) from the dairy protein. Valine-proline-proline (VPP) is also liberated in this process—another milk tripeptide with a very similar chemical structure to IPP. Together, these peptides are now often referred to as lactotripeptides. In 1996, the first human study confirmed the blood pressure-lowering effect of IPP in fermented milk. Although twice the amount of VPP is needed to achieve the same ACE-inhibiting activity as the originally discovered IPP, VPP also is assumed to add to the total blood pressure lowering effect.
Since the first lactotripeptides discovery, more than 20 human clinical trials have been conducted in many different countries.

</doc>
<doc id="2769" url="https://en.wikipedia.org/wiki?curid=2769" title="Antianginal">
Antianginal

An antianginal is any drug used in the treatment of "angina pectoris", a symptom of ischaemic heart disease.
Types.
Stable Angina.
Pain due to atherosclerosis causing incomplete coronary artery occlusion. Pain onset with strenuous activity or emotional strain due to increased myocardial oxygen demand.
Unstable Angina.
Pain due to atherosclerotic plaque rupture and subsequent embolization causing incomplete coronary arterial occlusion.
Variant (Prinzmetal's) Angina.
Pain due to transient vasospasm causing coronary artery vasoconstriction.
Examples.
Drugs used are nitrates, beta blockers, or calcium channel blockers.
Nitrates.
Nitrates cause vasodilation of the venous capacitance vessels by stimulating the endothelium-derived relaxing factor (EDRF). Used to relieve both exertional and vasospastic angina by allowing venous pooling, reducing the pressure in the ventricles and so reducing wall tension and oxygen requirements in, the heart. Short-acting nitrates are used to abort angina attacks that have occurred, while longer-acting nitrates are used in the prophylactic management of the condition.
Agents include nitroglycerin (glyceryl trinitrate) or pentaerythritol tetranitrate, isosorbide dinitrate and isosorbide mononitrate.triglycerol nitrate
Beta blockers.
Beta blockers are used in the prophylaxis of exertional angina by reducing the myocardial oxygen demand below the level that would provoke an angina attack.
They are contraindicated in variant angina and can precipitate heart failure. They are also contraindicated in severe asthmatics due to bronchoconstriction, and should be used cautiously in diabetics as they can cause hypoglycemia
Agents include either cardioselectives such as acebutolol or metoprolol, or non-cardioselectives such as oxprenolol or sotalol.
Calcium channel blockers.
Calcium ion (Ca++) antagonists (Calcium channel blockers) are used in the treatment of chronic stable angina, and most effectively in the treatment of variant angina (directly preventing coronary artery vasospasm). They are not used in the treatment of unstable angina . 
In vitro, they dilate the coronary and peripheral arteries and have negative inotropic and chronotropic effects - decreasing afterload, improving myocardial efficiency, reducing heart rate and improving coronary blood flow.
"In vivo", the vasodilation and hypotension trigger the baroreceptor reflex. Therefore the net effect is the interplay of direct and reflex actions.
Examples include Class I agents ("e.g.", verapamil), Class II agents ("e.g.", amlodipine, nifedipine), or the Class III agent diltiazem.
Nifedipine is more a potent vasodilator and more effective in angina. It is in the class of dihydropyridines and does not affect refrectory period on SA node conduction.

</doc>
<doc id="2770" url="https://en.wikipedia.org/wiki?curid=2770" title="Anatomical Therapeutic Chemical Classification System">
Anatomical Therapeutic Chemical Classification System

The Anatomical Therapeutic Chemical (ATC) Classification System is used for the classification of active ingredients of drugs according to the organ or system on which they act and their therapeutic, pharmacological and chemical properties. It is controlled by the World Health Organization Collaborating Centre for Drug Statistics Methodology (WHOCC), and was first published in 1976.
This pharmaceutical coding system divides drugs into different groups according to the organ or system on which they act and/or their therapeutic and chemical characteristics. Each bottom-level ATC code stands for a pharmaceutically used substance, or a combination of substances, in a single indication (or use). This means that one drug can have more than one code: acetylsalicylic acid (aspirin), for example, has as a drug for local oral treatment, as a platelet inhibitor, and as an analgesic and antipyretic. On the other hand, several different brands share the same code if they have the same active substance and indications.
Classification.
In this system, drugs are classified into groups at 5 different levels:
First level.
The first level of the code indicates the anatomical main group and consists of one letter. There are 14 main groups:
"Example": C Cardiovascular system
Second level.
The second level of the code indicates the therapeutic main group and consists of two digits.
"Example": C03 Diuretics
Third level.
The third level of the code indicates the therapeutic/pharmacological subgroup and consists of one letter.
"Example": C03C High-ceiling diuretics
Fourth level.
The fourth level of the code indicates the chemical/therapeutic/pharmacological subgroup and consists of one letter.
"Example": C03CA Sulfonamides
Fifth level.
The fifth level of the code indicates the chemical substance and consists of two digits.
"Example": C03CA01 Furosemide
ATCvet.
The "Anatomical Therapeutic Chemical Classification System for veterinary medicinal products" (ATCvet) is used to classify veterinary drugs. ATCvet codes can be created by placing the letter Q in front of the ATC code of most human medications. For example, furosemide for veterinary use has the code QC03CA01.
Some codes are used exclusively for veterinary drugs, such as "QI Immunologicals", "QJ51 Antibacterials for intramammary use" or "QN05AX90 amperozide".
Defined daily dose.
The ATC system also includes defined daily doses (DDDs) for many drugs. This is a measurement of drug consumption based on the usual daily dose for a given drug. According to the definition, "he DDD is the assumed average maintenance dose per day for a drug used for its main indication in adults."
National adaptations.
National issues of the ATC classification, such as the German "Anatomisch-therapeutisch-chemische Klassifikation mit Tagesdosen", may include additional codes and DDDs not present in the WHO version.
Updates to ATC.
ATC follows guidelines in creating new codes for newly approved drugs. In order to create a new ATC code, an application has to be sent to ATC. New ATC codes are published twice annually. A formal release of new ATC edition occurs once a year.

</doc>
<doc id="2778" url="https://en.wikipedia.org/wiki?curid=2778" title="Parallel ATA">
Parallel ATA

Parallel ATA (PATA), originally ', is an interface standard for the connection of storage devices such as hard disk drives, floppy disk drives, and optical disc drives in computers. The standard is maintained by the X3/INCITS committee. It uses the underlying ' (ATA) and Packet Interface (ATAPI) standards.
The Parallel ATA standard is the result of a long history of incremental technical development, which began with the original AT Attachment interface, developed for use in early PC AT equipment. The ATA interface itself evolved in several stages from Western Digital's original Integrated Drive Electronics (IDE) interface. As a result, many near-synonyms for ATA/ATAPI and its previous incarnations are still in common informal use, in particular Extended IDE (EIDE) and Ultra ATA (UATA). After the introduction of Serial ATA (SATA) in 2003, the original ATA was renamed to Parallel ATA, or PATA for short.
Parallel ATA cables have a maximum allowable length of only . Because of this limit, the technology normally appears as an internal computer storage interface. For many years, ATA provided the most common and the least expensive interface for this application. It has largely been replaced by SATA in newer systems.
History and terminology.
The PATA standard was originally conceived as the "PC/AT Attachment" because its primary feature was a direct connection to the 16-bit ISA bus introduced with the IBM PC/AT. The "AT" in "IBM PC/AT" refers to "Advanced Technology", but the ATA specifications simply use the name "AT Attachment", to avoid possible trademark issues with IBM.
IDE and ATA-1.
The first version of what is now called the ATA/ATAPI interface was developed by Western Digital under the name "Integrated Drive Electronics" (IDE). Together with Control Data Corporation (the hard drive manufacturer) and Compaq Computer (the initial customer), they developed the connector, the signaling protocols and so on, with the goal of remaining software compatible with the existing ST-506 hard drive interface. The first such drives appeared in Compaq PCs in 1986.
The term "Integrated Drive Electronics" refers not just to the connector and interface definition, but also to the fact that the drive controller is integrated into the drive, as opposed to a separate controller on or connected to the motherboard. The interface cards used to connect a parallel ATA drive to, for example, a PCI slot are not drive controllers: they are merely bridges between the host bus and the ATA interface. Since the original ATA interface is essentially just a 16-bit ISA bus in disguise, the bridge was especially simple in case of an ATA connector being located on an ISA interface card. The integrated controller presented the drive to the host computer as an array of 512-byte blocks with a relatively simple command interface. This relieved the mainboard and interface cards in the host computer of the chores of stepping the disk head arm, moving the head arm in and out, and so on, as had to be done with earlier ST-506 and ESDI hard drives. All of these low-level details of the mechanical operation of the drive were now handled by the controller on the drive itself. This also eliminated the need to design a single controller that could handle many different types of drives, since the controller could be unique for the drive. The host need only ask for a particular sector, or block, to be read or written, and either accept the data from the drive or send the data to it.
The interface used by these drives was standardized in 1994 as ANSI standard X3.221-1994, "AT Attachment Interface for Disk Drives". After later versions of the standard were developed, this became known as "ATA-1".
A short-lived, seldom-used implementation of ATA was created for the IBM XT and similar machines that used the 8-bit version of the ISA bus. It has been referred to as "XT-IDE", "XTA" or "XT Attachment".
Second ATA interface.
When PC motherboard makers started to include onboard ATA interfaces in place of the earlier ISA plug-in cards, there was usually only one ATA connector on the board, which could support up to two hard drives. At the time, in combination with the floppy drive, this was sufficient for most people. When the CD-ROM was developed, many computers would have been unable to accept these drives if they had been ATA devices, due to already having two hard drives installed. Adding the CD-ROM drive would have required removal of one of the drives.
SCSI was available as a CD-ROM expansion option at the time, but devices with SCSI were more expensive than ATA devices due to the need for a smart interface that is capable of bus arbitration. SCSI typically added to the cost of a storage device, in addition to the cost of a SCSI host adapter.
The less expensive solution was the addition of a dedicated CD-ROM interface, which was typically included as an expansion option on a sound card. PC motherboards initially did not come with support for more than simple beeps from internal speakers; thus, sound cards (such as the Sound Blaster Pro) were available for use with games, operating system and software event sounds, or to listen to audio CDs. Also, sound cards commonly included a gameport joystick/gamepad port along with interfaces to control a CD-ROM and transmit CD audio to the system.
Initially, the second drive interface was not well defined. It was first introduced with interfaces specific to certain CD-ROM drives such as Mitsumi, Sony or Panasonic drives, and it was common to find early sound cards with two or three separate connectors each designed to match a certain brand of CD-ROM drive. This evolved into the standard ATA interface for ease of cross-compatibility, though the sound card ATA interface still usually supported only a single CD-ROM and not hard drives.
This second ATA interface on the sound card eventually evolved into the second motherboard ATA interface which was long included as a standard component in all PCs.
Called the "primary" and "secondary" ATA interfaces, they were assigned to base addresses 0x1F0 and 0x170 on ISA bus systems.
EIDE and ATA-2.
In 1994, about the same time that the ATA-1 standard was adopted, Western Digital introduced drives under a newer name, Enhanced IDE (EIDE). These included most of the features of the forthcoming ATA-2 specification and several additional enhancements. Other manufacturers introduced their own variations of ATA-1 such as "Fast ATA" and "Fast ATA-2".
The new version of the ANSI standard, "AT Attachment Interface with Extensions ATA-2" (X3.279-1996), was approved in 1996. It included most of the features of the manufacturer-specific variants.
ATA-2 also was the first to note that devices other than hard drives could be attached to the interface:
ATAPI.
As mentioned in the previous sections, ATA was originally designed for, and worked only with hard disk drives and devices that could emulate them. The introduction of ATAPI (ATA Packet Interface) by a group called the Small Form Factor committee (SFF) allowed ATA to be used for a variety of other devices that require functions beyond those necessary for hard disk drives. For example, any removable media device needs a "media eject" command, and a way for the host to determine whether the media is present, and these were not provided in the ATA protocol.
The Small Form Factor committee approached this problem by defining ATAPI, the "ATA Packet Interface". ATAPI is actually a protocol allowing the ATA interface to carry SCSI commands and responses; therefore, all ATAPI devices are actually "speaking SCSI" other than at the electrical interface. In fact, some early ATAPI devices were simply SCSI devices with an ATA/ATAPI to SCSI protocol converter added on. The SCSI commands and responses are embedded in "packets" (hence "ATA Packet Interface") for transmission on the ATA cable. This allows any device class for which a SCSI command set has been defined to be interfaced via ATA/ATAPI.
ATAPI devices are also "speaking ATA", as the ATA physical interface and protocol are still being used to send the packets. On the other hand, ATA hard drives and solid state drives do not use ATAPI.
ATAPI devices include CD-ROM and DVD-ROM drives, tape drives, and large-capacity floppy drives such as the Zip drive and SuperDisk drive.
The SCSI commands and responses used by each class of ATAPI device (CD-ROM, tape, etc.) are described in other documents or specifications specific to those device classes
and are not within ATA/ATAPI or the T13 committee's purview. One commonly used set is defined in the MMC SCSI command set.
ATAPI was adopted as part of ATA in INCITS 317-1998, "AT Attachment with Packet Interface Extension (ATA/ATAPI-4)".
UDMA and ATA-4.
The ATA/ATAPI-4 standard also introduced several "Ultra DMA" transfer modes. These initially supported speeds from 16 MByte/s to 33 MByte/second. In later versions, faster Ultra DMA modes were added, requiring new 80-wire cables to reduce crosstalk. The latest versions of Parallel ATA support up to 133 MByte/s.
Ultra ATA.
Ultra ATA, abbreviated UATA, is a designation that has been primarily used by Western Digital for different speed enhancements to the ATA/ATAPI standards. For example, in 2000 Western Digital published a document describing "Ultra ATA/100", which brought performance improvements for the then-current ATA/ATAPI-5 standard by improving maximum speed of the Parallel ATA interface from 66 to 100 MB/s. Most of Western Digital's changes, along with others, were included in the ATA/ATAPI-6 standard (2002).
Current terminology.
The terms "integrated drive electronics" (IDE), "enhanced IDE" and "EIDE" have come to be used interchangeably with ATA (now Parallel ATA, or PATA).
In addition, there have been several generations of "EIDE" drives marketed, compliant with various versions of the ATA specification. An early "EIDE" drive might be compatible with ATA-2, while a later one with ATA-6.
Nevertheless, a request for an "IDE" or "EIDE" drive from a computer parts vendor will almost always yield a drive that will work with most Parallel ATA interfaces.
Another common usage is to refer to the specification version by the fastest mode supported. For example, ATA-4 supported Ultra DMA modes 0 through 2, the latter providing a maximum transfer rate of 33 megabytes per second. ATA-4 drives are thus sometimes called "UDMA-33" drives, and sometimes "ATA-33" drives. Similarly, ATA-6 introduced a maximum transfer speed of 100 megabytes per second, and some drives complying to this version of the standard are marketed as "PATA/100" drives.
x86 BIOS size limitations.
Initially, the size of an ATA drive was stored in the system x86 BIOS using a type number (1 through 45) that predefined the C/H/S parameters and also often the landing zone, in which the drive heads are parked while not in use. Later, a "user definable" format called C/H/S or cylinders, heads, sectors was made available. These numbers were important for the earlier ST-506 interface, but were generally meaningless for ATA—the CHS parameters for later ATA large drives often specified impossibly high numbers of heads or sectors that did not actually define the internal physical layout of the drive at all. From the start, and up to ATA-2, every user had to specify explicitly how large every attached drive was. From ATA-2 on, an "identify drive" command was implemented that can be sent and which will return all drive parameters.
Owing to a lack of foresight by motherboard manufacturers, the system BIOS was often hobbled by artificial C/H/S size limitations due to the manufacturer assuming certain values would never exceed a particular numerical maximum.
The first of these BIOS limits occurred when ATA drives reached sizes in excess of 504 megabytes, because some motherboard BIOSes would not allow C/H/S values above 1024 cylinders, 16 heads, and 63 sectors. Multiplied by 512 bytes per sector, this totals bytes which, divided by bytes per megabyte, equals 504 megabytes.
The second of these BIOS limitations occurred at 1024 cylinders, 256 heads, and 63 sectors, and a bug in MS-DOS and MS-Windows 95 limited the number of heads to 255. This totals to bytes, commonly referred to as the 8.4 gigabyte barrier. This is again a limit imposed by x86 BIOSes, and not a limit imposed by the ATA interface.
It was eventually determined that these size limitations could be overridden with a tiny program loaded at startup from a hard drive's boot sector. Some hard drive manufacturers, such as Western Digital, started including these override utilities with new large hard drives to help overcome these problems. However, if the computer was booted in some other manner without loading the special utility, the invalid BIOS settings would be used and the drive could either be inaccessible or appear to the operating system to be damaged.
Later, an extension to the x86 BIOS disk services called the "Enhanced Disk Drive" (EDD) was made available, which makes it possible to address drives as large as 264 sectors.
Interface size limitations.
The first drive interface used 22-bit addressing mode which resulted in a maximum drive capacity of two gigabytes. Later, the first formalized ATA specification used a 28-bit addressing mode through LBA28, allowing for the addressing of 228 () sectors (blocks) of 512 bytes each, resulting in a maximum capacity of 128 GiB (137 GB).
ATA-6 introduced 48-bit addressing, increasing the limit to 128 PiB (144 PB). As a consequence, any ATA drive of capacity larger than about 137 GB must be an ATA-6 or later drive. Connecting such a drive to a host with an ATA-5 or earlier interface will limit the usable capacity to the maximum of the interface.
Some operating systems, including Windows XP pre-SP 1, and Windows 2000 pre-SP 3, disable LBA48 by default, requiring the user to take extra steps to use the entire capacity of an ATA drive larger than about 137 gigabytes.
Older operating systems, such as Windows 98, do not support 48-bit LBA at all. However, members of the third-party group MSFN have modified the Windows 98 disk drivers to add unofficial support for 48-bit LBA to Windows 95 OSR2, Windows 98, Windows 98 SE and Windows ME.
Some 16-bit and 32-bit operating systems supporting LBA48 may still not support disks larger than 2 TiB due to using 32-bit arithmetics only; a limitation also applying to many boot sectors.
Primacy and obsolescence.
Parallel ATA (then simply called ATA or IDE) became the primary storage device interface for PCs soon after 
its introduction. In some systems, a third and fourth motherboard interface was provided, allowing up to eight ATA devices to be attached to the motherboard. Often, these additional connectors were implemented by inexpensive RAID controllers.
Soon after the introduction of Serial ATA (SATA) in 2003, use of Parallel ATA declined. 
The first motherboards with built-in SATA interfaces usually had only a single PATA connector 
(for up to two PATA devices), along with multiple SATA connectors.
As of 2007, some PC chipsets, for example the Intel ICH10, had removed support for PATA. Motherboard vendors still wishing to offer Parallel ATA with those chipsets must include an additional interface chip. In more recent computers, the Parallel ATA interface is rarely used even if present, as four or more Serial ATA connectors are usually provided on the motherboard and SATA devices of all types are common.
With Western Digital's withdrawal from the PATA market, hard disk drives with the PATA interface were no longer in production after December 2013 for other than specialty applications.
Parallel ATA interface.
Parallel ATA cables transfer data 16 bits at a time. The traditional cable uses 40-pin connectors attached to a ribbon cable. Each cable has two or three connectors, one of which plugs into an adapter interfacing with the rest of the computer system. The remaining connector(s) plug into storage devices, most commonly hard disk drives or optical drives.
ATA's cables have had 40 wires for most of its history (44 conductors for the smaller form-factor version used for 2.5" drives—the extra four for power), but an 80-wire version appeared with the introduction of the "Ultra DMA/33" ("UDMA") mode. All of the additional wires in the new cable are ground wires, interleaved with the previously defined wires to reduce the effects of capacitive coupling between neighboring signal wires, reducing crosstalk. Capacitive coupling is more of a problem at higher transfer rates, and this change was necessary to enable the 66 megabytes per second (MB/s) transfer rate of "UDMA4" to work reliably. The faster "UDMA5" and "UDMA6" modes also require 80-conductor cables.
Though the number of wires doubled, the number of connector pins and the pinout remain the same as 40-conductor cables, and the external appearance of the connectors is identical. Internally, the connectors are different; the connectors for the 80-wire cable connect a larger number of ground wires to the ground pins, while the connectors for the 40-wire cable connect ground wires to ground pins one-for-one. 80-wire cables usually come with three differently colored connectors (blue, black, and gray for controller, master drive, and slave drive respectively) as opposed to uniformly colored 40-wire cable's connectors (commonly all gray). The gray connector on 80-conductor cables has pin 28 CSEL not connected, making it the slave position for drives configured cable select.
Round parallel ATA cables (as opposed to ribbon cables) were eventually made available for 'case modders' for cosmetic reasons, as well as claims of improved computer cooling and were easier to handle; however, only ribbon cables are supported by the ATA specifications.
In the ATA standard, pin 20 is defined as (mechanical) key and is not used. This socket on the female connector is often obstructed, requiring pin 20 to be omitted from the male cable or drive connector, making it impossible to plug it in the wrong way round; a male connector with pin 20 present cannot be used. However, some flash memory drives can use pin 20 as VCC_in to power the drive without requiring a special power cable; this feature can only be used if the equipment supports this use of pin 20.
Pin 28 of the gray (slave/middle) connector of an 80-conductor cable is not attached to any conductor of the cable. It is attached normally on the black (master drive end) and blue (motherboard end) connectors.
Pin 34 is connected to ground inside the blue connector of an 80-conductor cable but not attached to any conductor of the cable. It is attached normally on the gray and black connectors.
Differences between connectors on 80-conductor cables.
The image on the right shows PATA connectors after removal of strain relief, cover, and cable. Pin one is at bottom left of the connectors, pin 2 is top left, etc., except that the lower image of the blue connector shows the view from the opposite side, and pin one is at top right. 
The connector is an insulation-displacement connector—in other words, each contact comprises a pair of points which together pierce the insulation of the ribbon cable with such precision that they make a connection to the desired conductor without harming the insulation on the neighboring wires. The center row of contacts are all connected to the common ground bus and attached to the odd numbered conductors of the cable. The top row of contacts are the even-numbered sockets of the connector (mating with the even-numbered pins of the receptacle) and attach to every other even-numbered conductor of the cable. The bottom row of contacts are the odd-numbered sockets of the connector (mating with the odd-numbered pins of the receptacle) and attach to the remaining even-numbered conductors of the cable.
Note the connections to the common ground bus from sockets 2 (top left), 19 (center bottom row), 22, 24, 26, 30, and 40 on all connectors. Also note (enlarged detail, bottom, looking from the opposite side of the connector) that socket 34 of the blue connector does not contact any conductor but unlike socket 34 of the other two connectors, it does connect to the common ground bus. On the gray connector, note that socket 28 is completely missing, so that pin 28 of the drive attached to the gray connector will be open. On the black connector, sockets 28 and 34 are completely normal, so that pins 28 and 34 of the drive attached to the black connector will be connected to the cable. Pin 28 of the black drive reaches pin 28 of the host receptacle but not pin 28 of the gray drive, while pin 34 of the black drive reaches pin 34 of the gray drive but not pin 34 of the host. Instead, pin 34 of the host is grounded.
The standard dictates color-coded connectors for easy identification by both installer and cable maker. All three connectors are different from one another. The blue (host) connector has the socket for pin 34 connected to ground inside the connector but not attached to any conductor of the cable. Since the old 40 conductor cables do not ground pin 34, the presence of a ground connection indicates that an 80 conductor cable is installed. The wire for pin 34 is attached normally on the other types and is not grounded. Installing the cable backwards (with the black connector on the system board, the blue connector on the remote device and the gray connector on the center device) will ground pin 34 of the remote device and connect host pin 34 through to pin 34 of the center device. The gray center connector omits the connection to pin 28 but connects pin 34 normally, while the black end connector connects both pins 28 and 34 normally.
Multiple devices on a cable.
If two devices are attached to a single cable, one must be designated as "device 0" (commonly referred to as "master") and the other as "device 1" ("slave"). This distinction is necessary to allow both drives to share the cable without conflict. The "master" drive is the drive that usually appears "first" to the computer's BIOS and/or operating system. On old BIOSes (Intel 486 era and older), the drives are often referred to by the BIOS as "C" for the master and "D" for the slave following the way DOS would refer to the active primary partitions on each.
The mode that a drive must use is often set by a jumper setting on the drive itself, which must be manually set to "master" or "slave". If there is a single device on a cable, it should be configured as "master". However, some hard drives have a special setting called "single" for this configuration (Western Digital, in particular). Also, depending on the hardware and software available, a single drive on a cable will often work reliably even though configured as the "slave" drive (most often seen where an optical drive is the only device on the secondary ATA interface).
Cable select.
A drive mode called "cable select" was described as optional in ATA-1 and has come into fairly widespread use with ATA-5 and later. A drive set to "cable select" automatically configures itself as master or slave, according to its position on the cable. Cable select is controlled by pin 28. The host adapter grounds this pin; if a device sees that the pin is grounded, it becomes the master device; if it sees that pin 28 is open, the device becomes the slave device.
This setting is usually chosen by a jumper setting on the drive called "cable select", usually marked "CS", which is separate from the "master" or "slave" setting.
Note that if two drives are configured as "master" and "slave" manually, this configuration does not need to correspond to their position on the cable. Pin 28 is only used to let the drives know their position on the cable; it is not used by the host when communicating with the drives.
With the 40-wire cable, it was very common to implement cable select by simply cutting the pin 28 wire between the two device connectors; putting the slave device at the end of the cable, and the master on the middle connector. This arrangement eventually was standardized in later versions. If there is just one device on the cable, this results in an unused stub of cable, which is undesirable for physical convenience and electrical reasons. The stub causes signal reflections, particularly at higher transfer rates.
Starting with the 80-wire cable defined for use in ATAPI5/UDMA4, the master device goes at the end of the cable—the black connector—and the slave device goes on the middle connector—the gray one—and the blue connector goes onto the motherboard. So, if there is only one (master) device on the cable, there is no cable stub to cause reflections. Also, cable select is now implemented in the slave device connector, usually simply by omitting the contact from the connector body.
Master and slave clarification.
Although they are in extremely common use, the terms "master" and "slave" do not actually appear in current versions of the ATA specifications. The two devices are simply referred to as "device 0" and "device 1", respectively, in ATA-2 and later.
It is a common myth that the controller on the master drive assumes control over the slave drive, or that the master drive may claim priority of communication over the other device on the same ATA interface. In fact, the drivers in the host operating system perform the necessary arbitration and serialization, and each drive's onboard controller operates independently of the other.
Serialized, overlapped, and queued operations.
The parallel ATA protocols up through ATA-3 require that once a command has been given on an ATA interface, it must complete before any subsequent command may be given. Operations on the devices must be serialized—with only one operation in progress at a time—with respect to the ATA host interface. A useful mental model is that the host ATA interface is busy with the first request for its entire duration, and therefore can not be told about another request until the first one is complete. The function of serializing requests to the interface is usually performed by a device driver in the host operating system.
The ATA-4 and subsequent versions of the specification have included an "overlapped feature set" and a "queued feature set" as optional features, both being given the name "Tagged Command Queuing", a reference to a set of features from SCSI which the ATA version attempts to emulate. However, support for these is extremely rare in actual parallel ATA products and device drivers because these feature sets were implemented in such a way as to maintain software compatibility with its heritage as originally an extension of the ISA bus. This implementation resulted in excessive CPU utilization which largely negated the advantages of command queuing. By contrast, overlapped and queued operations have been common in other storage buses, in particular, SCSI's version of tagged command queuing had no need to be software compatible with ISA's APIs, allowing it to attain high performance with low overhead on buses which supported first party DMA like PCI. This has long been seen as a major advantage of SCSI.
The Serial ATA standard has supported native command queueing since its first release, but it is an optional feature for both host adapters and target devices. Many less expensive PC motherboards do not support NCQ. Many SATA/II hard drives sold today support NCQ, while no removable (CD/DVD) drives do because the ATAPI command set used to control them prohibits queued operations.
Two devices on one cable—speed impact.
There are many debates about how much a slow device can impact the performance of a faster device on the same cable. There is an effect, but the debate is confused by the blurring of two quite different causes, called here "Lowest speed" and "One operation at a time".
"Lowest speed".
It is a common misconception that, if two devices of different speed capabilities are on the same cable, both devices' data transfers will be constrained to the speed of the slower device.
For all modern ATA host adapters, this is not true, as modern ATA host adapters support "independent device timing". This allows each device on the cable to transfer data at its own best speed. Even with older adapters without independent timing, this effect applies only to the data transfer phase of a read or write operation. This is usually the shortest part of a complete read or write operation.
"One operation at a time".
This is caused by the omission of both overlapped and queued feature sets from most parallel ATA products. Only one device on a cable can perform a read or write operation at one time, therefore, a fast device on the same cable as a slow device under heavy use will find it has to wait for the slow device to complete its task first.
However, most modern devices will report write operations as complete once the data is stored in its onboard cache memory, before the data is written to the (slow) magnetic storage. This allows commands to be sent to the other device on the cable, reducing the impact of the "one operation at a time" limit.
The impact of this on a system's performance depends on the application. For example, when copying data from an optical drive to a hard drive (such as during software installation), this effect probably will not matter: Such jobs are necessarily limited by the speed of the optical drive no matter where it is. But if the hard drive in question is also expected to provide good throughput for other tasks at the same time, it probably should not be on the same cable as the optical drive.
HDD passwords and security.
The disk lock is a built-in security feature in the disk. It is part of the ATA specification, and thus not specific to any brand or device. The disk lock can be enabled and disabled by sending special ATA commands to the drive. If a disk is locked, it will refuse all access until it is unlocked.
A disk always has two passwords: A User password and a Master password. Most disks support a Master Password Revision Code. Reportedly, some disks can report if the Master password has been changed, or if it still is the factory default. The revision code is word 92 in the IDENTIFY response. Reportedly, on some disks, a value of 0xFFFE means the Master password is unchanged. The standard does not distinguish this value.
A disk can be locked in two modes: High security mode or Maximum security mode. Bit 8 in word 128 of the IDENTIFY response shows which mode the disk is in: 0 = High, 1 = Maximum.
In High security mode, the disk can be unlocked with either the User or Master password, using the "SECURITY UNLOCK DEVICE" ATA command. There is an attempt limit, normally set to 5, after which the disk must be power cycled or hard-reset before unlocking can be attempted again. Also in High security mode, the SECURITY ERASE UNIT command can be used with either the User or Master password.
In Maximum security mode, the disk can be unlocked only with the User password. If the User password is not available, the only remaining way to get at least the bare hardware back to a usable state is to issue the SECURITY ERASE PREPARE command, immediately followed by SECURITY ERASE UNIT. In Maximum security mode, the SECURITY ERASE UNIT command requires the Master password and will completely erase all data on the disk. The operation is slow. It may take half an hour or more, depending on the size of the disk. (Word 89 in the IDENTIFY response indicates how long the operation will take.) 
While the ATA disk lock is intended to be impossible to defeat without a valid password, there are workarounds to unlock a drive. Many data recovery companies offer unlocking services, so while the disk lock will deter a casual attacker, it is not secure against a qualified adversary.
External parallel ATA devices.
It is extremely uncommon to find external PATA devices that directly use the interface for connection to a computer. PATA is primarily restricted to devices installed internally, due to the short data cable specification. A device connected externally needs additional cable length to form a U-shaped bend so that the external device may be placed alongside, or on top of the computer case, and the standard cable length is too short to permit this.
For ease of reach from motherboard to device, the connectors tend to be positioned towards the front edge of motherboards, for connection to devices protruding from the front of the computer case. This front-edge position makes extension out the back to an external device even more difficult. Ribbon cables are poorly shielded, and the standard relies upon the cabling to be installed inside a shielded computer case to meet RF emissions limits.
All external PATA devices, such as external hard drives, use some other interface technology to bridge the distance between the external device and the computer. USB is the most common external interface, followed by Firewire. A bridge chip inside the external devices converts from the USB interface to PATA, and typically only supports a single external device without cable select or master/slave.
Compact Flash interface.
Compact Flash in its "IDE mode" is essentially just a miniaturized ATA interface, intended for use on devices that use flash memory storage. No interfacing chips or circuitry are required, other than to directly adapt the smaller CF socket onto the larger ATA connector.
The ATA connector specification does not include pins for supplying power to a CF device, so power is inserted into the connector from a separate source. The exception to this is when the CF device is connected to a 44-pin ATA bus designed for 2.5-inch hard disk drives, commonly found in notebook computers, as this bus implementation must provide power to a standard hard disk drive.
CF devices can be designated as master or slave on an ATA interface, though since most CF devices offer only a single socket, it is not necessary to offer this selection to end users. Although CF can be hot-pluggable with additional design methods, by default when wired directly to an ATA interface, it is not intended to be hot-pluggable.
ATA standards versions, transfer rates, and features.
The following table shows the names of the versions of the ATA standards and the transfer modes and rates supported by each. Note that the transfer rate for each mode (for example, 66.7 MB/s for UDMA4, commonly called "Ultra-DMA 66", defined by ATA-5) gives its maximum theoretical transfer rate on the cable. This is simply two bytes multiplied by the effective clock rate, and presumes that every clock cycle is used to transfer end-user data. In practice, of course, protocol overhead reduces this value.
Congestion on the host bus to which the ATA adapter is attached may also limit the maximum burst transfer rate. For example, the maximum data transfer rate for conventional PCI bus is 133 MB/s, and this is shared among all active devices on the bus.
In addition, no ATA hard drives existed in 2005 that were capable of measured sustained transfer rates of above 80 MB/s. Furthermore, sustained transfer rate tests do not give realistic throughput expectations for most workloads: They use I/O loads specifically designed to encounter almost no delays from seek time or rotational latency. Hard drive performance under most workloads is limited first and second by those two factors; the transfer rate on the bus is a distant third in importance. Therefore, transfer speed limits above 66 MB/s really affect performance only when the hard drive can satisfy all I/O requests by reading from its internal cache—a very unusual situation, especially considering that such data is usually already buffered by the operating system.
, mechanical hard disk drives can transfer data at up to 157 MB/s, which is beyond the capabilities of the PATA/133 specification. High-performance solid state drives can transfer data at up to 308 MB/s.
Only the Ultra DMA modes use CRC to detect errors in data transfer between the controller and drive. This is a 16-bit CRC, and it is used for data blocks only. Transmission of command and status blocks do not use the fast signaling methods that would necessitate CRC. For comparison, in Serial ATA, 32-bit CRC is used for both commands and data.
Related standards, features, and proposals.
ATAPI Removable Media Device (ARMD).
ATAPI devices with removable media, other than CD and DVD drives, are classified as ARMD (ATAPI Removable Media Device) and can appear as either a super-floppy (non-partitioned media) or a hard drive (partitioned media) to the operating system. These can be supported as bootable devices by a BIOS complying with the ATAPI Removable Media Device BIOS Specification, originally developed by Compaq Computer Corporation and Phoenix Technologies. It specifies provisions in the BIOS of a personal computer to allow the computer to be bootstrapped from devices such as Zip drives, Jaz drives, SuperDisk (LS-120) drives, and similar devices.
These devices have removable media like floppy disk drives, but capacities more commensurate with hard drives, and programming requirements unlike either. Due to limitations in the floppy controller interface most of these devices were ATAPI devices, connected to one of the host computer's ATA interfaces, similarly to a hard drive or CD-ROM device. However, existing BIOS standards did not support these devices. An ARMD-compliant BIOS allows these devices to be booted from and used under the operating system without requiring device-specific code in the OS.
A BIOS implementing ARMD allows the user to include ARMD devices in the boot search order. Usually an ARMD device is configured earlier in the boot order than the hard drive. Similarly to a floppy drive, if bootable media is present in the ARMD drive, the BIOS will boot from it; if not, the BIOS will continue in the search order, usually with the hard drive last.
There are two variants of ARMD, ARMD-FDD and ARMD-HDD. Originally ARMD caused the devices to appear as a sort of very large floppy drive, either the primary floppy drive device 00h or the secondary device 01h. Some operating systems required code changes to support floppy disks with capacities far larger than any standard floppy disk drive. Also, standard-floppy disk drive emulation proved to be unsuitable for certain high-capacity floppy disk drives such as Iomega Zip drives. Later the ARMD-HDD, ARMD-"Hard disk device", variant was developed to address these issues. Under ARMD-HDD, an ARMD device appears to the BIOS and the operating system as a hard drive.
ATA over Ethernet.
In August 2004, Sam Hopkins and Brantley Coile of Coraid specified a lightweight ATA over Ethernet protocol to carry ATA commands over Ethernet instead of directly connecting them to a PATA host adapter. This permitted the established block protocol to be reused in storage area network (SAN) applications.

</doc>
<doc id="2779" url="https://en.wikipedia.org/wiki?curid=2779" title="Atari 2600">
Atari 2600

The Atari 2600 (or Atari VCS before 1982) is a home video game console released on September 11, 1977 by Atari, Inc. It is credited with popularizing the use of microprocessor-based hardware and ROM cartridges containing game code, a format first used with the Fairchild Channel F video game console in 1976. This format contrasts with the older model of having non-microprocessor dedicated hardware, which could only play the games which were physically built into the unit.
The console was originally sold as the Atari VCS, an abbreviation for Video Computer System. Following the release of the Atari 5200 in 1982, the VCS was renamed to the "Atari 2600", after the unit's Atari part number, CX2600. The 2600 was typically bundled with two joystick controllers, a conjoined pair of paddle controllers, and a game cartridge, initially "Combat", and later "Pac-Man".
History.
Ted Dabney and Nolan Bushnell developed the Atari gaming system in the 1970s. Originally operating under the name "Syzygy", Bushnell and Dabney changed the name of their company to "Atari" in 1972. In 1973, Atari Inc. had purchased an engineering think tank called Cyan Engineering to research next-generation video game systems, and had been working on a prototype known as "Stella" (named after one of the engineers' bicycles) for some time. Unlike prior generations of machines that use custom logic to play a small number of games, its core is a complete CPU, the famous MOS Technology 6502 in a cost-reduced version known as the 6507. It was combined with a RAM-and-I/O chip, the MOS Technology 6532, and a display and sound chip known as the Television Interface Adaptor (TIA). The first two versions of the machine contain a fourth chip, a standard CMOS logic buffer IC, making Stella cost-effective. Some later versions of the console eliminated the buffer chip. 
Programs for small computers of the time were generally stored on cassette tapes, floppy disks, or paper tape. By the early 1970s, Hewlett-Packard manufactured desktop computers costing thousands of dollars such as the HP 9830, which packaged Read Only Memory (ROM) into removable cartridges to add special programming features, and these were being considered for use in games. At first, the design was not going to be cartridge-based, but after seeing a "fake" cartridge system on another machine, they realized they could place the games on cartridges essentially for the price of the connector and packaging.
In 1976, Fairchild Semiconductor released their own CPU-based system, the Video Entertainment System. Stella was still not ready for production, but it was clear that it needed to be before there were a number of "me too" products filling up the market, which had happened after they released "Pong". Atari Inc. didn't have the cash flow to complete the system quickly, given that sales of their "Pong" systems were cooling. Nolan Bushnell eventually turned to Warner Communications, and sold the company to them in 1976 for US$28 million on the promise that Stella would be produced as soon as possible.
Key to the eventual success of the machine was the hiring of Jay Miner, a chip designer who managed to squeeze an entire wire wrap of equipment making up the TIA into a single chip. Once that was completed and debugged, the system was ready for shipping.
Launch and success.
The unit was originally priced at US$199 ($ adjusted for inflation), and shipped with two joysticks and a "Combat" cartridge (eight additional games were available at launch and sold separately). In a move to compete directly with the Channel F, Atari Inc. named the machine the Video Computer System (or VCS for short), as the Channel F was at that point known as the VES, for "Video Entertainment System". The VCS was also rebadged as the Sears Video Arcade and sold through Sears, Roebuck and Company stores. Another break-through for gaming systems was Atari's invention of a computer-controlled opponent, rather than the usual two-player or asymmetric challenges of the past.
When Fairchild learned of Atari Inc.'s naming, they quickly changed the name of their system to become the Channel F. However, both systems were now in the midst of a vicious round of price-cutting: "Pong" clones that had been made obsolete by these newer and more powerful machines were sold off to discounters for ever-lower prices. Soon many of the clone companies were out of business, and both Fairchild and Atari Inc. were selling to a public that was completely burnt out on Pong. In 1977, Atari Inc. sold 250,000 Video Computer Systems.
For the first year of production, the Video Computer System was manufactured in Sunnyvale, California. The consoles manufactured there had thick plastic molding around the sides and bottom. These added weight to the console, and because all six switches were on the front, these consoles were nicknamed "Heavy Sixers". After this first year, production moved to Hong Kong, and the consoles manufactured there had thinner plastic molding. In 1978, only 550,000 units from a production run of 800,000 were sold, requiring further financial support from Warner to cover losses. This led directly to the disagreements that caused Atari Inc. founder Nolan Bushnell to leave the company in 1978. Despite Bushnell's retirement in 1978, Warren Robinett’s invention of the first graphical adventure game, "Adventure", was developed the same year and changed the fundamentals of gaming as it unlocked a game with a “virtual space bigger than the screen."
Once the public realized it was possible to play video games other than "Pong", and programmers learned how to push its hardware's capabilities, the VCS gained popularity. By this point, Fairchild had given up, thinking video games were a passing fad, thereby handing the entire quickly growing market to Atari Inc. By 1979, the VCS was the best-selling Christmas gift (and console), due to its exclusive content, and 1 million units were sold that year.
Atari Inc. then licensed the smash arcade hit "Space Invaders" by Taito, which greatly increased the unit's popularity when it was released in January 1980, doubling sales to over 2 million units. The VCS and its cartridges were the main factor behind Atari Inc. grossing more than $2 billion in 1980. Sales then doubled again for the next two years; by 1982, the console had sold 10 million units, while its best-selling game "Pac-Man" sold 7 million copies. The console also sold 450,000 units in West Germany by 1984. By 1982 the 2600 console cost Atari about $40 to make and was sold for an average of $125. The company spent $4.50 to $6 to manufacture each cartridge and $1 to $2 for advertising, and sold it for $18.95 wholesale.
In 1980, the VCS was given a minor revision in which the left and right difficulty switches were moved to the back of the console, leaving four switches on the front. Other than this, these four-switch consoles looked nearly identical to the earlier six-switch models. In 1982, another version of the four-switch console was released without woodgrain. They were nicknamed "Darth Vader" consoles due to their all-black appearance. These were also the first consoles to be officially called "Atari 2600", as the Atari 5200 was released the same year.
During this period, Atari Inc. expanded the 2600 family with two other compatible consoles. Despite the faux-wood panels and what would now appear to be primitive graphics, the game console became widely popular for the time. Later however, they designed the Atari 2700, a wireless version of the console that was never released because of a design flaw. The company also built a sleeker version of the machine dubbed the Atari 2800 to sell directly to the Japanese market in early 1983, but it suffered from competition with the newly released Nintendo Famicom.
In a survey mentioned by Jeff Rovin it is reported that more stores reported breakdowns of the Atari 2600 system than any other, and that Atari repair centers seemed to have the most trouble with consoles manufactured in 1980. In one case it is stated that a system was repaired five times before static electricity from a carpet was discovered as having caused the problem. The controllers were also a source of breakage because of the way they could be gripped by a player holding it with their fist, allowing players to get carried away and over control, which was less likely with other systems released at the time, such as the Magnavox Odyssey², which has controllers that are nearly half its size.
Sears Tele-Games 2600s.
Atari Inc. also continued their OEM relationship with Sears under the latter's Tele-Games brand label, which started in 1975 with the original "Pong". Sears released several versions of the 2600 as the Sears Video Arcade series from 1977 to 1983. These include the Rev. A "Heavy Sixer" model in 1977, the Rev. B "4 switch" model in 1980, and the US version of the Atari 2800 branded as the Sears Video Arcade II in 1983.
Sears also released their own versions of Atari Inc.'s games under the Tele-Games brand — often with different titles — which included the Tele-Games branded variations of text and picture labels. Three games were also produced by Atari Inc. for Sears as exclusive releases under the Tele-Games brand: "Steeplechase", "Stellar Track", and "Submarine Commander".
Sears's Tele-Games brand was unrelated to the company Telegames, which also produced cartridges for the Atari 2600 — mostly re-issues of M Network games.
Decline and remodel.
During the 1970s, Atari Inc. continued to grow until it had one of the largest R&D divisions in Silicon Valley. However, it spent much of its R&D budget on projects that seemed out of place at a video game (or even home computer) company; many of these projects never saw the light of day. Meanwhile, several attempts to bring out newer consoles failed for one reason or another, although Atari Inc.'s home computer system (the Atari 8-bit family) sold reasonably well, Warner was pleased as it seemed to have no end to the sales of the 2600, and Atari Inc. was responsible for over half of the company's income.
The programmers of many of Atari Inc.'s biggest hits grew disgruntled with the company for not crediting game developers and many left the company and formed their own independent software companies. The most prominent and longest-lasting of these third-party developers was Activision, founded in 1980, whose titles quickly became more popular than those of Atari Inc. itself. Atari Inc. attempted to block third-party development for the 2600 in court but failed, and soon other publishers, such as Imagic and Coleco, entered the market. Atari Inc. suffered from an image problem when a company named Mystique produced a number of pornographic games for the 2600. The most notorious of these, "Custer's Revenge", was protested by women's and Native American groups because it depicted General George Armstrong Custer raping a bound Native American woman. Atari Inc. sued Mystique in court over the release of the game.
Atari Inc. continued to acquire licenses for the 2600, the most prominent of which included "Pac-Man" and "E.T." Public disappointment with these two titles and the market saturation of poor third-party titles are cited as major contributors to the video game crash of 1983. Suddenly, Atari Inc.'s growth meant it was losing massive amounts of money during the crash, at one point about $10,000 a day. Warner quickly grew tired of supporting Atari Inc., and started looking for buyers in 1984.
By mid-1984 most software development for the 2600 had stopped except by Atari and Activision, with third-party developers emphasizing ColecoVision games. Although not formally discontinued, the 2600 was de-emphasized for two years after Warner's 1984 sale of Atari Inc.'s Consumer Division to Commodore Business Machines founder Jack Tramiel, who wanted to concentrate on home computers. He ended all development of console games, including a 2600 "Garfield" game and an Atari 5200 port of "Super Pac-Man". Due to a large library and a low price point, the 2600 and the 2600jr, continued to sell into the late 1980s and was not discontinued until 1992. The 2600 ended up outdoing all other hardware that Atari released, in attempt to replicate its success.
Atari 2800.
The Atari 2800 is the Japanese version of the Atari 2600, released in October 1983. It was the first release of a 2600 designed specifically for the Japanese market, despite companies like Epoch distributing the 2600 in Japan previously. In fact, Atari's name was inspired by the Japanese game 'Go'.
The 2800 never captured a large market in Japan. It was released a short time after Nintendo's Family Computer, which became the dominant console in the Japanese video game market of the time.
Codenamed "Cindy", and designed by Atari engineer Joe Tilly, the Atari 2800 had four controller ports instead of the standard two on the Atari 2600's. The controllers are an all-in one design using a combination of an 8-direction digital joystick and a 270-degree paddle, designed by John Amber.
The 2800's case design departed from the standard 2600 format, using a wedge shape with non-protruding switches.
Around 30 specially branded games were released for the 2800. Their boxes are in Japanese and have a silver/red color scheme similar to the packaging of Atari's 2600 branded games of the time. The ROM cartridges themselves had identical labels as their 2600 branded counterparts.
Sears liked the design of the Atari 2800 so much, they opted to sell a version under their Tele-Games label. It was released in the US in 1983 as the Sears Video Arcade II, and was packaged with 2 controllers and "Space Invaders".
The Atari 2800's case style was used as the basis for the Atari 7800's case style by Barney Huang.
Atari 2600 Jr..
In 1986, a new version of the 2600 was released. The newly redesigned version of the 2600, unofficially referred to as the 2600 Jr., features a smaller cost-reduced form factor with a modernized Atari 7800-like appearance. The redesigned 2600 was advertised as a budget gaming system (under US$50) that has the ability to run a large collection of classic games.
The Atari 2600 continued to sell in North America and Europe until 1991, and in Asia until the early 1990s. Its final Atari-licensed release is "KLAX" in 1990. In 2007, the Atari 2600 was inducted into the Toy Hall of Fame, with 40 million units sold in its lifetime, and the youngest toy to be inducted. In Brazil, the console became extremely popular in the mid-1980s. The Atari 2600 was officially retired by Atari Corp. on January 1, 1992, making it, at the time, the longest-lived home video game console (14 years, 4 months) in video game history. It was later surpassed by the Sega Master System, a console which never formally ended production in Brazil.
The Atari 2600 was also, at the time, the best-selling American-made console, selling 30 million units. This record would later be broken by the Xbox 360 which sold 84 million units.
The system was promoted on a United Kingdom TV ad in 1989 in the run-up to Christmas, in which it claimed "The fun is back!". The advertising campaign used its price of under £50 as a selling point. The advert was a re-dubbed version of the early original campaign in the United States. Also, the 2600 Jr. was originally to be packaged with a Pro-Line joystick (the same one used on the Atari 7800), but when it was released, it instead included the original CX-40 Joystick. Later European versions of the 2600 Jr. included a joypad, which was also featured with the European 7800.
Design.
Hardware.
The CPU was the MOS Technology 6507, a stripped-down version of the 6502, running at 1.19 MHz in the 2600. The 6507 included fewer memory-address pins—13 instead of 16—and no external interrupts to fit into a smaller 28-pin package. Smaller packaging was, and still is, an important factor in overall system cost, and since memory was very expensive at the time, the 6507's small 8 kB of maximum external memory space was not going to be used up anyway. In fact, memory was so expensive they could not imagine using up even 4 kB, and when Atari got a deal on 24-pin connectors for the cartridge socket, they took it, despite this limiting the games to 4 kB. Atari established their system design in order to be compatible with the cathode-ray tube television sets in the late 1970s and early 1980s. Later games get around this limitation with bank switching. The maximum supported cartridge size is 32 kilobytes.
The console has only 128 bytes of RAM for run-time data that includes the call stack and the state of the game world. There is no frame buffer, as the necessary RAM would have been too expensive. Instead the video device has two bitmapped sprites, two 1-pixel "missile" sprites, a 1-pixel "ball," and a 40-pixel "playfield" that is drawn by writing a bit pattern for each line into a register just before the television scans that line. As each line is scanned, a game must identify the non-sprite objects that overlaps the next line, assemble the appropriate bit patterns to draw for those objects, and write the pattern into the register. In a telling reveal of its Pong heritage, by default, the right side of the screen is a mirrored duplicate of the left; to control it separately, the software may modify the patterns as the scan line is drawn. After the controller scans the last active line, a more leisurely vertical blanking interval begins, during which the game can process inputs and update the positions & states of objects in the game world. Any mistake in timing produces visual artifacts, a problem that programmers call "racing the beam" and which users tend to call "flickering".
The video hardware gives the 2600 a reputation as one of the most complex game consoles in the world to program, but those programmers who sufficiently understand it realize that such direct control over the video picture is also a source of flexibility. One advantage the 2600 has over more powerful contemporary competitors such as the ColecoVision is that the 2600 has no protection against altering settings in mid-line. For example, although each sprite nominally has only one color, it is possible to color the rows differently by changing the sprite's color as it is drawn. If the two hardware sprites are not enough for a game, a developer may share one sprite among several objects (as with the ghosts in "Pac-Man") or draw software sprites, which is only a little more difficult than drawing a fixed playfield. The "Pitfall!" screenshot below (section: "Games") demonstrates some of these tricks: the player is a multicolor sprite, one sprite is multiplexed for the logs and the scorpion, and the swinging vine is drawn by shifting the position of the "ball" on each scan line. Despite the hardware limitations, many Atari 2600 games have a lot of action on the screen, creating an engaging experience. Furthermore, the Atari 2600 was one of the first consoles to introduce video game cartridges instead of having hardwired games built into it, allowing for the play of multiple different games rather than the usual one built in.
The Atari originally shipped with two types of controllers, a joystick as well as a pair of paddle controllers. Later, new controllers were added to the game system including a driving controller, a trak-ball controller, and finally keypad controllers. Additionally, the 2600 supports several types of input devices as well as third-party peripherals. Many of these peripherals are interchangeable with the MSX and other Japanese systems; and, in some cases, it is possible to use the Atari joysticks with the Commodore 64, Commodore 128, Amiga, Sega Master System, and Mega Drive/Genesis, though functionality may be somewhat limited. Also, although Master System and Mega Drive/Genesis controllers work on the Atari 2600, only the "B" button can be used in most games. Another adapter is the Starpath Supercharger, an add-on created by Starpath to expand the game capabilities of the Atari 2600. The Supercharger's interface adds an extra 6 kB to the Atari 2600's 128 bytes of RAM, allowing for larger games with higher-resolution graphics. A cord coming out of the side of the cartridge plugs into the earphone jack of any standard cassette player. Games for the Supercharger are stored on standard audio cassettes.
Third-party accessories include Wico's Command Control joystick.
Graphics.
The Atari 2600 uses different color palettes depending on the television signal format used. With the NTSC format, a 128-color palette is available, while in PAL, only 104 colors are available. Additionally, the SECAM palette consists of only 8 colors.
Games.
In 1977, nine games were released on cartridge to accompany the launch of the machine, including Outlaw, Space War and Breakout. During the console's lifetime, Atari, Inc. and Atari Corp. published many titles: these games included "Adventure" (often credited as starting the action-adventure game genre), "Breakout", and "Yars' Revenge". The console's popularity attracted many third-party developers, which led to popular titles such as Activision's "Pitfall!" and Imagic's "Atlantis". However, two Atari published titles, "E.T. the Extra-Terrestrial" and "Pac-Man", are frequently blamed for contributing to the video game crash of 1983.
Legacy.
The Atari 2600 was wildly successful, and during much of the 1980s, "Atari" was a synonym for this model in mainstream media and, by extension, for video games in general.
The Atari 2600 was inducted into the National Toy Hall of Fame at The Strong in Rochester, New York in 2007. In 2009, the Atari 2600 was named the second greatest video game console of all time by IGN, who cited its remarkable role as the console behind both the first video game boom and the video game crash of 1983, and called it "the console that our entire industry is built upon."
Atari 2000.
The Atari 2000 (model number CX-2000) was a prototype version of the Atari 2600 that was intended to be released as a cheaper alternative for children in 1982. Although identical in specification to the original 2600, the 2000 included built-in controllers and an innovative case design. The 2000 was originally intended to be black, but it was later recolored blue to appeal more to children. While Atari never officially stated the reason for not releasing the 2000, experts have cited the poor quality and durability of its built-in joysticks and the greater in-house popularity of the competing 2600 Jr. design as the most likely reasons.
Atari 3200.
Atari started work on a replacement to the 2600, called the Atari 3200, with codenames including Super Stella, Sylvia, and PAM (a note attached reads "Super Stella: Multipurpose"). The system was to have compatibility with Atari 2600 cartridges, and was rumored to be based on a 10-bit processor, although design documents shows it was to actually be based around the 6502 8-bit CPU. It was still unfinished when preliminary game programmers discovered that it was difficult to program. The project was cancelled, and Atari went with the second "System X", also titled PAM, that would later become the Atari 5200. Atari also cloned the Atari 3200 into the Sears Super Arcade II, but this was never released.
Clones and reissues.
The console and its old and new games are very popular with collectors because of its significant impact on video game and consumer electronics history and also due to its nostalgic value for many people, along with a number of games that are still considered highly playable. In addition, modern Atari 2600 clones remain on the market. One example is the Atari Classics 10-in-1 TV Game, manufactured by Jakks Pacific, which emulates the 2600 console, and includes converted versions of 10 games into a single Atari-brand-lookalike joystick with composite-video outputs for connecting directly to modern televisions or VCRs. Another is the TV Boy, which includes 127 games in an enlarged joypad.
The Atari Flashback 2 console, released in 2005, contains 40 games (with four additional programs unlockable by a cheat code). The console implements the original 2600 architecture and can be modified to play original 2600 cartridges by adding a cartridge port, and is also compatible with original 2600 controllers.
In music.
Many games for the Atari 2600 have detailed and easily identifiable music, and its distinctive sound makes it ideal for use in modern lo-fi and industrial music. In 2002, Dallas musician and visual artist Paul Slocum developed a cartridge called Synthcart for the Atari 2600, which allows the user to turn an Atari 2600 into a two-voice synthesizer and drum machine. Adapters have also been developed by amateurs enabling the Atari 2600's use with MIDI devices. A number of bands, such as 8 Bit Weapon, Black Moth Super Rainbow and The Squigs, as well as Slocum's own band Tree Wave, use Synthcart to make modern music on the Atari 2600. Some effects units like the MXR Blue Box are often cited for their ability to produce an Atari-like sound. Phonte from the hip-hop group Little Brother, along with fellow lyricist Eccentric, formed a mock group named Unheralded Symmetrics, and recorded a tribute to the system, entitled "Atari 2600".

</doc>
<doc id="2780" url="https://en.wikipedia.org/wiki?curid=2780" title="Atari 5200">
Atari 5200

The Atari 5200 SuperSystem, commonly known as the Atari 5200, is a home video game console that was introduced in 1982 by Atari Inc. as a higher-end complementary console for the popular Atari 2600. The 5200 was created to compete with the Intellivision, but wound up more directly competing with the ColecoVision shortly after its release.
The 5200's internal hardware is almost identical that of Atari's 8-bit computers, although software is not directly compatible between the two systems. The 5200's controllers have an analog joystick and a numeric keypad along with start, pause and reset buttons. The 360-degree non-centering joystick was touted as offering more control than the eight-way joystick controller offered with the Atari 2600.
Hardware.
Much of the technology in the Atari 8-bit family of home computer systems was originally developed as a second-generation games console intended to replace the 2600. However, as the system was reaching completion, the personal computer revolution was starting with the release of machines like the Commodore PET, TRS-80 and Apple II. These machines had less advanced hardware than the 5200, but sold for much higher prices with associated higher profit margins. Atari's management decided to enter this market, and the technology was repackaged into the Atari 400 and 800. The chipset used in the these machines was created with the mindset that the 2600 would likely be obsolete by the 1980 time frame. What was surprising, however, was that the entry into this new market of competition helped to quickly cut off the sales of the 2600.
Atari decided to re-enter the games market with a design that closely matched their original 1978 specifications. In its prototype stage, the Atari 5200 was originally called the "Atari Video System X - Advanced Video Computer System", and was codenamed "Pam" after a female employee at Atari Inc. It is also rumored that PAM actually stood for "Personal Arcade Machine", as the majority of games for the system ended up being arcade conversions. Actual working "Atari Video System X" machines, whose hardware is 100% identical to the Atari 5200 do exist, but are extremely rare.
The initial 1982 release of the system featured four controller ports, where nearly all other systems of the day had only one or two ports. The 5200 also featured a new style controller with an analog joystick, numeric keypad, two fire buttons on each side of the controller and game function keys for Start, Pause, and Reset. The 5200 also featured the innovation of the first automatic TV switchbox, allowing it to automatically switch from regular TV viewing to the game system signal when the system was activated. Previous RF adapters required the user to slide a switch on the adapter by hand. This unique RF box was also where the power supply connected in a unique dual power/television signal setup similar to the RCA Studio II's. A single cable coming out of the 5200 plugged into the switch box and was used for both electricity and the television signal.
The 1983 revision of the Atari 5200 has two controller ports instead of four, and a change back to the more conventional separate power supply and standard non-autoswitching RF switch. It also has changes in the cartridge port address lines to allow for the Atari 2600 adapter released that year. While the adapter was only made to work on the two-port version, modifications can be made to the four-port to make it line-compatible. In fact, towards the end of the four-port model's production run, there were a limited number of consoles produced which included these modifications. These consoles can be identified by an asterisk in their serial number.
Controllers.
Atari Inc. released the Pro-Line Trak-Ball controller for the system, which was used primarily for gaming titles such as "Centipede" and "Missile Command". A paddle controller and an updated self-centering version of the original controller were also in development, but never made it to market.
Games shipped with plastic card overlays that snapped in over the keypad. The card would indicate which game functions, such as changing the view or vehicle speed, were assigned to each key.
The primary controller was ranked the 10th worst video game controller by IGN editor Craig Harris.
Internal differences between the 5200 and the 400/800.
Although the Atari 5200's internal design was extensively based on that of the 400/800 home computers, the differences were sufficient that games designed for one would not run directly on the other. John J. Anderson of "Creative Computing" alluded to the incompatibility being intentional, caused by fierce rivalries between Atari's computer and console divisions.
One of the most obvious differences was the 5200's lack of a keyboard. However, there were several others:
Atari Corp.'s later XE Games System revisited the idea of a console based on the 400/800 hardware. However, as this was essentially just a 65XE computer with a detachable keyboard, it was (unlike the 5200) able to run most of the home computer titles directly.
Market performance.
The Atari 5200 did not fare well commercially, compared to its predecessor, the Atari 2600. While it touted superior graphics to the 2600 and Mattel's Intellivision, the system was initially incompatible with the 2600's expansive library of games, and some market analysts have speculated that this hurt its sales, especially since an Atari 2600 cartridge adapter had been released for the Intellivision II. (A revised 2-port model was released in 1983, along with a game adapter that allowed gamers to play all 2600 games.) This lack of new games was due in part to a lack of funding, with Atari continuing to develop most of its games for the saturated 2600 market.
Many of the 5200's games appeared simply as updated versions of 2600 titles, which failed to excite consumers. Its pack-in game, "Super Breakout", was particularly criticized for not doing enough to demonstrate the system's capabilities, and this gave the ColecoVision a significant advantage when its pack-in, "Donkey Kong", delivered a more authentic arcade experience than any previous game cartridge. In its list of the top 25 game consoles of all time, IGN claimed that the main reason for the 5200's market failure was the technological superiority of its competitor, while other sources maintain that the two consoles are roughly equivalent in power.
The 5200 received much criticism for the "sloppy" design of its non-centering analog controllers.
At one point following the 5200's release, Atari had planned a smaller, cost-reduced version of the Atari 5200, which would have removed the controller storage bin. Code-named the "Atari 5100" (a.k.a. "Atari 5200 Jr."), only a few fully working prototype 5100s were made before the project was canceled.
On May 21, 1984, during a press conference at which the Atari 7800 was introduced, company executives revealed that the 5200 had been discontinued after just two years on the market. Total sales of the 5200 were reportedly in excess of 1 million units.
Games.
There were a total of 69 games officially released for the system. "Super Breakout", "Galaxian" and "Space Invaders" were the system's launch titles. A port of "Asteroids" was advertised as a launch title, but was never released. "Gremlins", released in 1986, was the last game officially released for the system.

</doc>
<doc id="2781" url="https://en.wikipedia.org/wiki?curid=2781" title="Atari 7800">
Atari 7800

The Atari 7800 ProSystem, or simply the Atari 7800, is a home video game console officially released by Atari Corporation in 1986. It is almost fully backward-compatible with the Atari 2600, the first console to have backward compatibility without the use of additional modules. It was considered affordable at a price of US$140.
The 7800 has significantly improved graphics hardware over the 2600, but uses the same audio chip. It also shipped with a different model of joystick than the 2600-standard CX40.
The 1986 launch is sometimes referred to as a "re-release" or "relaunch" because the Atari 7800 had originally been announced on May 21, 1984, to replace Atari Inc.'s Atari 5200, but a general release was shelved due to the sale of the company. A few units were released to test markets in June 1984 though. However, by 1987 the Nintendo Entertainment System was already dominating the home console market, and the 7800 could not gain a significant foothold.
History.
The Atari 7800 ProSystem was the first game system from Atari Inc. designed by an outside company, General Computer Corporation (GCC). The system was designed in 1983-84 with an intended mass market rollout in June 1984, but was canceled shortly thereafter due to the sale of the company to Tramel Technology Ltd on July 2, 1984. The project was originally called the Atari 3600, though was later renamed the Atari 7800.
Atari had been facing mounting pressure in the form of competition from the ColecoVision, which boasted graphics that more closely mirrored arcade games of the time than Atari’s 2600 system. At the same time, the Atari 5200 (the original intended successor to the Atari 2600) had been widely criticized for not being able to play Atari 2600 games without an adapter.
GCC, which had a background in creating arcade games, designed their new system with a graphical architecture similar to arcade machines of the time. The 7800 allows a large number of moving objects (75 to 100) that far exceeds previous consoles. Powering the system is a slightly custom 6502 processor, the Atari SALLY (sometimes described as a "6502C"), running at 1.79 MHz.
In contrast to the Atari 5200, the Atari 7800 can play almost all Atari 2600 games out of the box, without the need for an adapter. In addition, it features a return to a digital controller.
To address the concerns of parents that home computers were a better investment than consoles, the system was designed to be upgraded to a full-fledged home computer. A keyboard was developed, and the keyboard had an expansion port (which was the SIO port from Atari's 8-bit computer line, though the 7800 could not run Atari computer programs) that allowed for the addition of peripherals such as disk drives and printers.
To further enhance the gaming experience, GCC had also designed a "high score cartridge", a battery-backed RAM cartridge designed for storing game scores. On the side of the 7800 was an expansion port, reportedly for a planned connection with a laserdisc player.
Launch.
The 7800 was initially released in southern California in June 1984, following an announcement on May 21, 1984 at the Summer Consumer Electronics Show. 13 games were announced for the system's launch, including "Ms. Pac-Man", "Pole Position II", "Centipede", "Joust", "Dig Dug", "Desert Falcon", "", "Galaga", "Xevious", "Food Fight", "Ballblazer", "Rescue on Fractalus!", and "Track & Field". Atari was a sponsor of the 1984 Summer Olympics and planned to push the 7800 aggressively in time for Christmas that year. 
On July 2, 1984, Warner Communications sold Atari's Consumer Division to Jack Tramiel. All projects were halted during an initial evaluation period. Modern publications have often incorrectly asserted that Jack Tramiel mothballed the Atari 7800 feeling video games were a past fad and subsequently asserted that he dusted off the Atari 7800 once the NES became successful. The reality was that a contractual issue arose in that GCC had not been paid for their development of the 7800. Warner and Tramiel battled back and forth over who was accountable, with Tramiel believing that the 7800 should have been covered as part of his acquisition deal. In May 1985, Jack relented and paid GCC the overdue payment. This led to additional negotiations regarding the initial launch titles that GCC had developed and then an effort to find someone to lead their new video game division, which was completed in November 1985.
The original production run of the Atari 7800 languished on warehouse shelves until it was re-introduced in January 1986 after strong 2600 sales the previous Christmas. The console was released nationwide in May 1986.
Atari's launch of the 7800 under Tramiel was far more subdued than Warner had planned for the system in 1984 with a marketing budget of just $300,000. Additionally, the keyboard and high score cartridge were canceled, the expansion port was removed from later production runs of the system and, in lieu of new titles, the system was launched with titles intended for the 7800's debut in 1984.
By the end of 1986, Computer Entertainer claimed the Atari 7800 had sold 100,000 consoles in the United States, less than the Sega Master System's 125,000 and the Nintendo Entertainment System's 1.1 million. According to Atari, due to manufacturing problems, they only managed to produce and sell 100,000 units by 1986, including units that had been in a warehouse since 1984. A common complaint in 1986 was a lack of games, including a gap of months between new releases ("Galaga"s release in August was followed by "Xevious" in November). By the end of 1986, the 7800 had 10 games, compared to Sega's 20 and Nintendo's 36; nine of the NES games were third-party, whereas the 7800 and Master System had no third-party games. A reason cited for the lack of third-party interest in the 7800 was its small 100,000 install base and low market penetration.
Marketplace challenges.
Atari's lineup for the 7800 emphasized high-quality versions of popular arcade games like "Joust" and "Asteroids". This had been a primary reason for the success of the Atari 2600 VCS against systems like the Intellivision.
During the Atari 7800’s life cycle, Atari found themselves struggling to get developers to create 7800 versions of then-popular arcade titles because of a controversial policy employed by Nintendo. When Nintendo revived the industry, they signed up software development companies to create Nintendo Entertainment System games under a strict license agreement which imposed serious restrictions on what they were allowed to do. One of the key clauses was that companies who made Nintendo games were not allowed to make that game on a competing system for a period of two years. Because of the market success of the Nintendo Entertainment System, companies chose to develop for it first and were thus barred from developing the same games on competing systems for two years. The software libraries of the Atari 7800 and Sega Master System suffered tremendously as a result.
Eleven titles were developed and sold by three third-party companies under their own labels for the 7800 (Absolute Entertainment, Activision, and Froggo) with the rest published by Atari themselves. However, most Atari development was contracted out.
Some NES titles were developed by companies who had licensed their title from a different arcade manufacturer. While the creator of the NES version would be restricted from making a competitive version of an NES game, the original arcade copyright holder was not precluded from licensing out rights for a home version of an arcade game to multiple systems. Through this loophole, Atari 7800 conversions of "Mario Bros.", "Double Dragon", "Commando", "Rampage", "Xenophobe", "Ikari Warriors", and "Kung-Fu Master" were licensed and developed.
Discontinuation.
The Atari 7800 remained officially active in the United States between 1986 and 1991 and in Europe between 1989 and 1991. On January 1, 1992, Atari Corp. formally announced that production of the Atari 7800, the Atari 2600, the Atari 8-bit computer line, and the Atari XE Game System would cease. (It has since been discovered that Atari Corp. continued to develop games such as "Toki" for the Atari 7800 until all development was shut down in May 1993.[http://betaphasegames.com/7800_Toki_Screens.html]) By the time of the cancellation, Nintendo's NES dominated the North American market, controlling 80% while Atari Corp. controlled just 12%.
Despite trailing the Nintendo Entertainment System in terms of number of units sold, the 7800 was a profitable enterprise for Atari Corp., benefiting largely from Atari’s name and the system's 2600 compatibility. Profits were strong owing to low investment in game development and marketing. Nonetheless, the 7800 failed to help Atari regain its dominance in the video game industry.
Technical specifications.
Graphics.
The graphics are generated by a custom graphics chip called MARIA, which uses an approach to graphics commonly used in arcade game system boards at the time. It was very different from other second and third generation consoles. Instead of a limited number of hardware sprites, MARIA allows for a much larger number of sprites described in a list of display lists. Each display list contains sprite entries with pointers to graphics data, color information, and horizontal positioning. The same display list is used for multiple rasters with the pointers being automatically adjusted. However, managing and displaying a large number of sprites required much more CPU time (both directly and indirectly since the MARIA would halt the CPU when drawing sprites) than consoles with hardware sprites and backgrounds.
MARIA has a number of different graphics modes which are either 160 pixels wide or 320 pixels wide. While the 320 pixel modes theoretically enable the 7800 to create games at higher resolution than the 256 pixel wide graphics found in the Nintendo Entertainment System and Sega Master System, the intense processing demands of MARIA typically meant that programmers created their games using the lower 160 pixel modes.
The 7800 features a broad (for its time) palette of 256 colors. Depending on various parameters, each individual sprite can use from 1 to 12 colors, with 3 colors (plus a 4th "transparency" color) being the most common. In this format, the sprite is referenced to one of 8 palettes, where each palette holds 3 assignable colors. There is also an assignable background color, which will be visible wherever another object has not covered it up. In total the system can utilize 25 colors on a scanline at one time.
The graphics resolution, color palette assignments, and background color can be adjusted in between scanlines. This technique is documented in the original 1983 "Atari 3600 Software Guide". Games often used this feature to render high resolution text in one area of the screen, while displaying more colorful graphics with less resolution in the gameplay area. Demos also exist which use this feature to place all 256 colors on the screen at the same time.
The MARIA’s approach had advantages and disadvantages when it came to generating graphics in software during the lifespan of the 7800. It excelled at moving around large numbers of sprites on a static screen without the screen flickering that plagued other 8-bit systems. Its flexible design enabled it to play games which used display list manipulation to generate a pseudo 3D appearance such as "Ballblazer" (1987) and "F-18 Hornet" (1988). While side-scrolling games in the vein of "Super Mario Bros." are possible on the system (1990's "Scrapyard Dog" is the best example), it is significantly harder to develop such a title than on a tile-based system such as the Nintendo Entertainment System.
Sound.
A common criticism of the 7800 regards its use of the TIA to provide 2-channel sound effects and music, resulting in sound quality that is virtually identical to the Atari 2600 VCS from 1977. While the inclusion of 2600 hardware is required to maintain compatibility with the older system, this drove up production costs and reduced available space on the 7800’s motherboard. As such, the 7800 does not include additional hardware for generating sound as it does with graphics and the sound hardware is considered the weakest part of the system.
To compensate for this, GCC’s engineers allowed games to include a POKEY audio chip in the cartridge which substantially improved the audio quality. To ensure software developers had an economical means of producing better sound than TIA, GCC had originally planned to make a low-cost, high performance sound chip, GUMBY, which could also be placed in 7800 cartridges to enhance its sound capabilities further. This project was cancelled when Atari was sold to Jack Tramiel.
Despite having the capability to support sound chips in cartridges, almost no 7800 cartridges feature POKEY hardware for enhanced sound. "Ballblazer", released in 1987, uses the POKEY to generate all music and sound effects. Similarly, "Commando", released in 1989, uses a POKEY to generate in-game music while the TIA generates the game's sound effects for a total of 6 channels of sound.
Lockout features.
Following the debate over "Custer's Revenge", an Atari 2600 VCS title with adult themes, Atari had concerns over similar adult titles finding their way onto the 7800 and displaying adult graphics on the significantly improved graphics of the MARIA chip. To combat this, they included a digital signature protection method which prevented unauthorized 7800 games from being played on the system.
When a cartridge was inserted into the system, the 7800 BIOS included code which would generate a digital signature of the cartridge ROM and compare it to the signature stored on the cartridge. If a correct signature was located on the cartridge, the 7800 would operate in 7800 mode, granting the game access to MARIA and other features. If a signature was not located, the 7800 remained in 2600 mode and MARIA was unavailable. All 7800 games released in North America had to be digitally signed by Atari. This digital signature code is not present in PAL 7800s, which use various heuristics to detect 2600 cartridges, due to export restrictions. The signing utility was found and released by Classic Gaming Expo in 2001.
Backward compatibility.
The Atari 7800 differs from the 2600 in several key areas. It features a full Atari SALLY 6502 processor whereas the 2600 VCS has a stripped-down 6507 processor running at a slower speed. It has additional RAM (Random Access Memory) and the ability to access more cartridge data at one time than the 2600. The most substantial difference, however, is a graphics architecture which differs markedly from either the Atari 2600 VCS or Atari’s 8-bit line of computers.
The 7800's compatibility with the Atari 2600 is made possible by including many of the same chips used in the Atari 2600. When operating in “2600” mode to play Atari 2600 titles, the 7800 uses a Television Interface Adapter (TIA) chip to generate graphics and sound. The processor is slowed to 1.19 MHz, enabling the 7800 to mirror the performance of the 2600's stripped-down 6507 processor. RAM is limited to 128 bytes found in the RIOT and game data is accessed in 4K blocks.
When in “7800” mode (signified by the appearance of the full-screen Atari logo), the graphics are generated entirely by the MARIA graphics processing unit, all system RAM is available and game data is accessed in larger 48K blocks. The system’s SALLY 6502 runs at its normal 1.79 MHz instead of the reduced speed of 2600 mode. The 2600 chips are used in 7800 mode to generate sound as well as switch and controller interfaces.
The Atari 7800 does not support backward compatibility for Atari 5200 games or accessories.
System revisions.
Prototypes:
Production:
Peripherals.
The Atari 7800 came bundled with the Atari Proline Joystick, a two button controller with a joystick for movement. In response to criticism over ergonomic issues in the 7800’s Pro-Line controllers, Atari later released joypad controllers with European 7800s, which were similar in style to controllers found on Nintendo and Sega Systems. The Joypad was not available in the United States.
Unlike the NES or Sega Master System, there were few add-on peripherals for the 7800, though its backwards compatibility feature allowed it to be compatible with most Atari 2600 peripherals.
The most notable exception was the XG-1 lightgun, which came bundled with the Atari XE Game System. The XG-1 was fully compatible with the 7800 and was sold separately for other Atari systems. Atari released four 7800 light gun games: "Alien Brigade", "Crossbow", "Meltdown", and "Barnyard Blaster".
Canceled peripherals.
Due to the acquisition of the Atari Consumer Division by Jack Tramiel in 1984, a number of planned peripherals for the system were canceled.
Software library.
While the 7800 can actually play hundreds of titles due to its compatibility with the Atari 2600, there was limited third party support for the 7800 and fewer than 100 titles were specifically designed for it.
Unreleased games.
As with most game consoles, there were many more games in development for the 7800 than were actually released. However, very few prototypes have been located, due to Tramiel Atari’s reluctance to make them in the first place. Atari 7800 prototypes tend to be highly coveted by collectors, often fetching hundreds of dollars when sold. Some collectors are unwilling to share the rare items publicly as doing so is assumed to decrease the value of their prototype.
Nonetheless, some unreleased Atari 7800 games, as well as early versions of released games have been released to the public. A few have been manufactured and sold.
These include
Engineering Notes list "Tempest" as a game that was between 15–20% completed for the Atari 7800; no code to date has been found. The Atari Museum located and posted unreleased box art and notes for a 7800 version of "Crystal Castles", but no code to date has been found for that game, either. Atari's earlier 7800 games listing showed "Millipede" as one of the games in the line up; however, it does not appear that it was ever started or worked on.
Source code release.
The source code for 13 games, as well as the OS and development tools (for the Atari ST computer system) were discovered in a dumpster behind the Atari building in Sunnyvale, California. Commented assembly language source code was made available for "Centipede", "Commando", "Crossbow", "Desert Falcon", "Dig Dug", "Food Fight", "Galaga", "Hat Trick", "Joust", "Ms. Pac-Man", "Super Stunt Cycle", "Robotron: 2084" and "Xevious" game titles.
Emulation and homebrew.
When emulators of 1980s video game consoles began to appear on home computers in the late 1990s, the Atari 7800 was one of the last to be emulated. The lack of awareness of the system, the lack of understanding of the hardware, and fears about the digital signature lockout initially caused concerns. Since that time, however, the 7800 has been emulated successfully and is now common on emulation sites. One such program is ProSystem, written in C/C++ for the Microsoft Windows operating system. It uses the Windows API and DirectX to display what it emulates in both PAL and NTSC.
The digital signature long prevented homebrew games from being developed until the original encryption generating software was discovered. When the original digital signature generating software was turned over to the Atari community, development of new Atari 7800 titles began. In addition, the Atari community has slowly uncovered the original 7800 development tools and released them into the public domain. New tools, documentation, source code and utilities for development have since been created which has sponsored additional homebrew development. Several new commercial Atari 7800 titles such as Beef Drop, B*nQ, Pac Man Collection, Combat 1990, Santa Simon, and Space War have been created and released.
System compatible hardware has also been produced for the system. Among these was the Cuttle Cart II, a device that allowed the Atari 7800 to read MMC cards containing binary files of Atari 7800 programs. The Cuttle Cart II has enabled more people to play the entire 2600 and 7800 library on an original system as well as binaries of unreleased games and new homebrew titles. The Cuttle Cart II was a success by homebrew standards, selling out both production runs and commanding high prices on eBay.
A more recent development is the Atari 7800 expansion module developed by Legacy Engineering with a high scores save feature (with compatible games), additional RAM capabilities, as well as vastly improved sound capabilities using the POKEY and YM2151 sound chips. The Expansion module is designed as a pass-through device that sits on top of the console and requires no system modding.
Atari Flashback.
In 2004, Atari (now owned by Infogrames) released the first Atari Flashback console. This system resembled a miniature Atari 7800 and joysticks and had 20 built in games (five 7800 and fifteen 2600 titles). While the unit sold well, it was controversial among Atari fans. Atari had given the engineering firm, Legacy Engineering, extremely limited development timelines. The firm was forced to build the Flashback using NES-On-A-Chip hardware instead of recreating the Atari 7800 hardware. As a result, the Flashback has been criticized for failing to properly replicate the actual Atari gaming experience.
Legacy Engineering was later commissioned to create another 7800 project that was subsequently cancelled after prototypes were made.

</doc>
<doc id="2782" url="https://en.wikipedia.org/wiki?curid=2782" title="Atari Jaguar">
Atari Jaguar

The Atari Jaguar is a home video game console that was developed by Atari Corporation. The console was the sixth and last programmable console to be developed under the Atari brand, originally released in North America in November 1993. Marketed by Atari as the first 64-bit video game console, the Jaguar was designed to compete with the existing 16-bit consoles (Sega Genesis and Super Nintendo Entertainment System) and the 32-bit 3DO Interactive Multiplayer platform (which launched the same year).
Development on the Atari Jaguar started in the early 90s, and was designed by Flare Technology, who were tasked by Atari to create two consoles; the Atari Panther, which would compete with the Genesis and the Super NES, and a successor, the Jaguar, which would surpass the capabilities of any other console on the market at the time. With development of the Jaguar running ahead of schedule, the Panther was cancelled, and the release of the Jaguar was pushed forward. It was originally released to test markets in New York City and San Francisco in November 1993, and to the general public in 1994, with "Cybermorph" as the pack-in launch game.
Upon release, it was criticized for its complex controller design, failure to distinguish itself from its 16-bit competitors, and low quality game library. The console's multi-chip architecture made game development for the console difficult, and underwhelming sales further contributed to the console's lack of third party support. This, in addition to the lack of internal development at Atari, led to a limited games library, comprising only 67 licensed titles.
Atari attempted to extend the lifespan of the Jaguar by releasing a CD-ROM add-on known as the Atari Jaguar CD and marketing the Jaguar as the low-cost next generation console, with a price tag over $100 less than any of its competitors. With the release of the Sega Saturn and Sony's PlayStation in 1995, sales of the Jaguar continued to fall, ultimately selling no more than 250,000 units before it was eventually discontinued in 1996. The Jaguar was deemed a commercial failure, and prompted Atari to leave the home video game console market. After Hasbro Interactive bought out Atari in the late 1990s, the patents to the Jaguar were released into the public domain, with the console being declared an open platform. Since then, the Jaguar has gained a cult following, with a developer base that produces homebrew games for the console.
History.
Development.
The Jaguar was developed by the members of Flare Technology, a company formed by Martin Brennan and John Mathieson. The team had claimed that they could not only make a console superior to the Genesis or the Super NES, but they could also be cost-effective. Impressed by their work on the Konix Multisystem, Atari persuaded them to close Flare and form a new company called Flare II, with Atari providing the funding. Flare II initially set to work designing two consoles for Atari Corp. One was a 32-bit architecture (codenamed "Panther"), and the other was a 64-bit system (codenamed "Jaguar"); however, work on the Jaguar design progressed faster than expected, so Atari Corp. canceled the Panther project to focus on the more promising Jaguar.
Launch.
The Jaguar was introduced in 1993 at a price of $249.99, under a $500 million manufacturing deal with IBM. The system was initially marketed only in New York City and San Francisco, under the slogan "Do the Math", claiming superiority over competing 16-bit and 32-bit systems. A US-wide release followed in early 1994.
The Atari Jaguar struggled to attain a substantial user base. In 1993, Atari reported that they had shipped 17,000 units as part of the system's initial test market. By the end of 1994, Atari reported that they had sold approximately 100,000 systems and had reduced the price to improve the competitive nature of the console. By the end of 1995, Sony and Sega had entered the marketplace with competing consoles and Atari's sales declined rapidly. In Atari's 1995 annual report, they noted:
"Jaguar sales were substantially below Atari's expectations, and Atari's business and financial results were materially adversely affected in 1995 as Atari continued to invest heavily in Jaguar game development, entered into arrangements to publish certain licensed titles and reduced the retail price for its Jaguar console unit. Atari attributes the poor performance of Jaguar to a number of factors including (i) extensive delays in development of software for the Jaguar which resulted in reduced orders due to consumer concern as to when titles for the platform would be released and how many titles would ultimately be available, and (ii) the introduction of competing products by Sega and Sony in May 1995 and September 1995, respectively."
Lack of titles was attributable to two main factors: the Jaguar's questionable long-term prospects among third-party game-publishers and the problematic nature of developing games for the Jaguar. Atari had one opportunity to convince third-party developers, vital for the diversity of Jaguar's game library, with a solid retail-performance, but as things played out, post-holiday sales figures questioned the viability of Atari's business; Atari failed to attract many third-party developers already committed to other game platforms. In addition, the Jaguar's underlying hardware was crippled by a flaw in the CPU's memory controller, which prevented code execution out of system RAM. Less severe, but still annoying defects included a buggy UART. The memory controller flaw could have been mitigated by a mature code-development environment, to unburden the programmer from having to micromanage small chunks of code. Jaguar's development tools left much to the programmer's own implementation, as documentation was incomplete. Writing game-code was often an endurance exercise in the tedious assembler.
In a July 1995 interview with "Next Generation", then-CEO Sam Tramiel declared that the Jaguar was as powerful, if not more powerful, than the Sega Saturn, and slightly weaker than the PlayStation.
Decline.
By the end of 1995, Atari's revenues declined by more than half, from US$38.7 million in 1994 to $14.6 million in 1995. In a last-ditch effort to revive the Jaguar, Atari Corp. tried to play down the other two consoles by proclaiming the Jaguar was the only "64-bit" system. This claim is questioned by some, because the CPU (68000) and GPU executed a 32-bit instruction-set, but sent control signals to the 64-bit graphics co-processors (or "graphics accelerators"). Atari Corp.'s reasoning that the 32-bit "Tom" and "Jerry" chips work in tandem to add up to a 64-bit system was ridiculed in a mini-editorial by "Electronic Gaming Monthly", which commented that "If Sega did the math for the Sega Saturn the way Atari did the math for their 64-bit Jaguar system, the Sega Saturn would be a 112-bit monster of a machine." Design specs for the console allude to the GPU or DSP being capable of acting as a CPU, leaving the Motorola 68000 to read controller inputs. In practice, however, many developers used the Motorola 68000 to drive gameplay logic.
Technical specifications.
From the Jaguar Software Reference manual, page 1:
Jaguar is a custom chip set primarily intended to be the heart of a very high-performance games/leisure computer. It may also be used as a graphics accelerator in more complex systems, and applied to workstation and business uses. As well as a general purpose CPU, Jaguar contains four processing units. These are the Object Processor, Graphics Processor, Blitter, and Digital Sound Processor. Jaguar provides these blocks with a 64-bit data path to external memory devices, and is capable of a very high data transfer rate into external dynamic RAM.
COJAG Arcade Games.
Atari Games licensed the Atari Jaguar's chipset for use in its arcade games. The system, named COJAG (for "Coin-Op Jaguar"), replaced the 68000 with a 68020 or MIPS R3000-based CPU (depending on the board version), and added a hard drive and more RAM. It ran the lightgun games "Area 51" and "Maximum Force", which were released by Atari as dedicated cabinets or as the Area 51/Maximum Force combo machine. Other games ("3 On 3 Basketball"; "Fishin' Frenzy"; "Freeze"; "Vicious Circle") were developed but never released.
Atari Jaguar Duo.
The Atari Jaguar Duo was a proposed console similar to the TurboDuo and Genesis CDX. It was an attempt by Atari to combine the Atari Jaguar and Atari Jaguar CD to make a new console. It was never completed and was thus never released. After cancelling the console, Atari was bought by Hasbro and ceased all console development.
Peripherals.
Prior to the launch of the console in November 1993, Atari had announced a variety of peripherals and add-ons for the Jaguar to be released over the console's lifespan. This included a CD-ROM-based add-on console, a dial-up internet link with support for online gaming, a virtual reality headset, and an MPEG-2 video card, among other things.
The redesigned second controller for the Jaguar, named the "ProController" by Atari, added three more face buttons, two triggers, and had a flat interface. The controller was created in response to the criticism of the original controller that the console came with. Sold independently, however, it was never bundled with the system after its release. A peripheral that allowed 4 controllers to be plugged into the console was also released. Dubbed the "Team Tap", it was released independently and as a bundle with "White Men Can't Jump". However, the Team Tap was only compatible with "White Men Can't Jump" and "NBA Jam Tournament Edition". Eight player gameplay with the Team Tap peripheral is also possible if a second Team Tap is plugged into the second controller port on the console. Local area network multiplayer gameplay was achieved through the use of the Jaglink Interface, which allowed two Jaguar consoles to be linked together through a modular extension and a UTP phone cable. The Jaglink was compatible with three games: "AirCars", "BattleSphere" and "Doom".
In 1994 at the CES, Atari announced that it partnered up with Phylon, Inc. to create the Jaguar Voice/Data Communicator. The unit was delayed and eventually in 1995 mass production was canceled all together, but not before an estimated 100 or so were made. The JVM as it became known, utilized a 19.9kbit/s dial up modem and had the ability to answer incoming phone calls and store up to 18 phone numbers. Players were required to directly dial each other for online game play. The only Jaguar game that supports the JVM is Ultra Vortek, the modem is initialized in the Ultra Vortek start up screen by entering 911 on the key pad.
Jaguar CD.
The Atari Jaguar CD is an add-on to the Jaguar that made use of CD-ROMs to distribute games. Developed and marketed in response to the PlayStation and Sega Saturn console, it was released in September 1995, two years after the Jaguar's launch. Twelve games were released for the system during its manufacturing lifetime, with many more being made after, by homebrew developers. Each copy of the Jaguar CD console also came with a Virtual Light Machine, which displayed light patterns corresponding to music, if the user inserts an Audio CD into the console. It was developed by Jeff Minter, who had created the program after experimenting with graphics during the development of "Tempest 2000". The program was deemed a spiritual successor to the Atari Video Music, a system which served a similar purpose, released in 1976.
An additional accessory for the Jaguar CD, which allowed Jaguar CD games to save persistent data such as preferences and saved games, was also released. Known as the Memory Track, it was a cartridge that contained a 128 K EEPROM, and was to be inserted into the cartridge slot on the Jaguar CD while the user played a Jaguar CD game. The program manager for the Memory Track is accessed by pushing the option button while the system is starting, and exited by pushing the * and # keys simultaneously. There were plans to make a second model of the Jaguar console that combined both the Jaguar and the Jaguar CD into one unit, a la the TurboDuo. Originally codenamed the Jaguar III, and later the Jaguar Duo, the proposed model was developed to feasibly compete with the PlayStation and Sega Saturn, however, the idea was scrapped after the discontinuation of the Jaguar.
Jaguar VR.
A virtual reality headset compatible with the console, tentatively titled the Jaguar VR, was unveiled by Atari at the 1995 Winter Consumer Electronics Show. The development of the peripheral was a response to Nintendo's virtual reality console, the Virtual Boy, which had been announced the previous year. The headset was developed in cooperation with Virtuality, who had previously created many virtual reality arcade systems, and was already developing a similar headset for practical purposes, named Project Elysium, for IBM. The peripheral was targeted for a commercial release before Christmas 1995. However, the project was eventually cancelled, and Atari severed ties with Virtuality afterwards. After Atari's merger with JTS in 1996, all prototypes of the headset were allegedly destroyed. However, two working units, one low-resolution prototype with red and grey-colored graphics, and one high-resolution prototype with blue and grey-colored graphics, have since been recovered, and are regularly showcased at retrogaming-themed conventions and festivals. Only one game was developed for the Jaguar VR prototype; a 3D-rendered version of the 1980 arcade game "Missile Command", entitled "Missile Command 3D", though, a demo of Virtuality's "Zone Hunter" was also created for Jaguar VR demonstrations.
Unlicensed peripherals.
An unofficial expansion peripheral for the Atari Jaguar dubbed the "Catbox" was released by the Rockford, Illinois company ICD. It was originally slated to be released early in the Jaguar's life, in the second quarter of 1994, but was not actually released until mid-1995. The ICD CatBox plugs directly into the AV/DSP connectors located in the rear of the Jaguar console and provides three main functions. These are audio, video, and communications. It features six output formats, three for audio (line level stereo, RGB monitor, headphone jack with volume control) and three for video (composite, S-Video, and RGB analog component video) making the Jaguar compatible with multiple high quality monitor systems and multiple monitors at the same time. It is capable of communications methods known as CatNet and RS-232 as well as DSP pass through, allowing the user to connect two or more Jaguars together for multi player games either directly or with modems. The ICD CatBox features a polished stainless steel casing and red LEDs in the jaguar's eyes on the logo that indicate communications activity. An IBM AT type null modem cable may be used to connect two Jaguars together. The CatBox is also compatible with Atari's Jaglink Interface peripheral.
An adaptor for the Jaguar that allows for WebTV access was revealed in 1998, one prototype is known to exist.
Reception.
In 2006 IGN editor Craig Harris rated the Jaguar controller as the worst ever, criticizing the complexity of the "phone keypad". A version that has six action buttons, the Pro Controller, is suggested for certain games. Reviewing the Jaguar just a few weeks prior to its launch, "GamePro" gave it a "thumbs sideways". They praised the power of the hardware but criticized the controller, and were dubious of how the software lineup would turn out, commenting that Atari's failure to secure support from key third party publishers such as Capcom was a bad sign. They concluded that "Like the 3DO, the Jaguar is a risky investment - just not quite as expensive." Jaguar did earn praise with titles such as "Tempest 2000", "Doom", and "Wolfenstein 3D". The most successful title during the Jaguar's first year was "Alien vs. Predator". Both it and "Tempest 2000" were named among the system's defining titles by "GamePro" in 2007. With such a small library of games to challenge the incumbent 16-bit game consoles, Jaguar's appeal never grew beyond a small gaming audience. Digital Spy commented: "Like many failed hardware ventures, it still maintains something of a cult following but can only be considered a misstep for Atari."
Legacy.
After the Atari Corporation properties were bought out by Hasbro Interactive in the late 1990s, Hasbro released the rights to the Jaguar, declaring the console an open platform and opening the doors for homebrew development. A few developers, including Telegames and Songbird Productions, have not only released previously unfinished materials from the Jaguar's past, but also several brand new titles to satisfy the system's cult following.
In the United Kingdom in 2001, a deal was struck between Telegames and retailer Game to bring the Jaguar to Game's retail outlets. The machine was initially sold for £29.99 brand new and software prices ranged between £9.99 for more common games such as "Doom" and "Ruiner Pinball", and £39.99 for more sought-after releases such as "Defender 2000" and "Checkered Flag". The machine had a presence in the stores until 2007 when remaining consoles were sold off for £9.99 and games were sold for as low as 97p.
This deal was seen as a move to remain competitive with Game's rival at the time, Gamestation, who were well known for stocking retro formats.
Imagin Systems, a manufacturer of dental imaging equipment, has since purchased the molding plates for the Jaguar's casing as with minor modification they were found to be the right size for housing their HotRod camera. The game cartridge molds were reused to create an optional memory expansion card.
In December 2014, the molds for the console and cartridges were purchased from Imagin Systems by Mike Kennedy, owner of the "GameGavel" video game auction website and "Retro Magazine", a Kickstarter funded print and digital retro video game magazine, to manufacture shells for a brand new, crowdfunded, cartridge-based video game console, called the "Retro VGS" (Retro Video Game System). The purchase of the molds from Imagin Systems was far cheaper than designing and manufacturing entirely new molds, and Kennedy described their acquisition as "the entire reason Retro VGS is possible". However, a functioning prototype was not produced before the scheduled "Kickstarter" crowdfunding campaign, prompting the team switch over to "Indiegogo" little over a week before the campaign began. The "Indiegogo" campaign failed to acquire funding when the campaign ended in November 2015, having raised only $81,158 (4%) of its 1,950,000 goal. In December, "Retro Video Game Systems Inc." entered a licensing deal with "Coleco", rebranding the proposed console as the "Coleco Chameleon". The proposed console generated more controversy when the promised "prototype" shown at the American International Toy Fair in February 2016 showed evidence that it was merely a "SNES Jr." motherboard crudely inserted into a Jaguar/Chameleon shell. Yet more controversy was generated shortly afterward when Retro Video Game Systems Inc., in response to the allegations, shared photos of another "prototype", showing a board inside of a clear Jaguar/Chameleon shell. It was quickly discovered that the board was in fact a "HICAP50B" DVR capture card. In response to the controversy, "Coleco Holdings LLC" demanded that "Retro Video Game Systems Inc." produce their prototype units for examination by independent engineers. On March 8, 2016, "Coleco Holdings" released a statement confirming the termination of the project, and Retro Video Game Systems Inc. deleted their website, Facebook page, and Twitter account. It is believed that Mike Kennedy is still in possession of the tooling for the Jaguar shells
The Jaguar continues to have a very small and dedicated game development circle.

</doc>
<doc id="2783" url="https://en.wikipedia.org/wiki?curid=2783" title="Atari Lynx">
Atari Lynx

The Atari Lynx is an 8 bit handheld game console that was released by Atari Corporation in October 1989 in North America, and in Europe and Japan in 1990. The Lynx holds the distinction of being the world's first handheld electronic game with a color LCD. The system is also notable for its forward-looking features, advanced graphics, and ambidextrous layout. As part of the fourth generation of gaming, the Lynx competed with the Game Boy (released just 2 months earlier), as well as the Game Gear and TurboExpress, both released the following year.
As with many classic consoles, there is a modern retrogaming community, creating and selling games for the system.
Features.
The Atari Lynx's innovative features include being the first color handheld, with a backlit display, a switchable right-handed/left-handed (upside down) configuration, and the ability to network with up to 17 other units via its "Comlynx" system (though most games would network eight or fewer players). Comlynx was originally developed to run over infrared links (and was codenamed RedEye). This was changed to a cable-based networking system before the final release.
The Lynx was cited as the "first gaming console with hardware support for zooming and distortion of sprites". Featuring a 4096 color palette and integrated math and graphics co-processors (including a blitter unit), its pseudo-3D color graphics display was said to be the key defining feature in the system's competition against Nintendo's monochromatic Game Boy. The fast pseudo-3D graphics features were made possible on a minimal hardware system by codesigner Dave Needle having "invented the technique for planar expansion/shrinking capability" and using stretched, textured, triangles instead of full polygons. These particular features were achieved over a year prior to the launch of the Super NES, whose stock hardware features the comparable Mode 7 but which can't scale sprites.
History.
The Lynx was the second handheld game system to be released with the Atari name. The first was Atari Inc.'s handheld electronic game "Touch Me". Atari Inc. had previously worked on several other handheld projects including the "Breakout", "Space Invaders", and the Atari Cosmos portable/tabletop console. However, those projects were shut down during development, some just short of their intended commercial release.
The Lynx system was originally developed by Epyx as the Handy Game. In 1986, two former Amiga designers, R. J. Mical and Dave Needle, had been asked by former manager at Amiga, David Morse, if they could come up with a design for a portable gaming system. Morse now worked at Epyx, a game software company that had a recent string of hit games. Morse's son had asked him if he could make a portable gaming system, prompting the lunch with Mical and Needle to discuss the idea. Morse convinced Mical and Needle to develop the idea and they were hired by Epyx to be a part of the design team. Planning and design of the console began in 1986 and was completed in 1987. Epyx first showed the Handy system at the Winter Consumer Electronics Show (CES) in January 1989. Facing financial difficulties, Epyx sought out partners. Atari Corp. and Epyx eventually agreed that Atari Corp. would handle production and marketing, while Epyx would handle software development.
The Handy was designed to run games from the cartridge format, and the game data must be copied from ROM to RAM before it can be used. Thus, less RAM is available and the games initially load relatively slowly. There are trace remnants of a cassette tape interface physically capable of being programmed to read a tape. Lynx developers have noted that "there is still reference of the tape and some hardware addresses" and an updated vintage Epyx manual describes the bare existence of what could be utilized for tape support. A 2009 retrospective interview clarifies that although some early reports claimed that games were loaded from tape, Mical says there was no truth in them: "We did think about hard disk a little".
Atari Corp. changed the internal speaker and removed the thumb-stick on the control pad before releasing it as the Lynx, initially retailing in the US at . Atari Corp. then showed the Lynx to the press at the Summer 1989 CES as the "Portable Color Entertainment System", which was changed to "Lynx" when actual consoles were distributed to resellers.
The Lynx started off successfully. Atari reported that they had sold 90% of the 50,000 units it shipped in its launch month in the U.S. with a limited launch in New York. US sales in 1990 were approximately 500,000 units according to the Associated Press In late 1991, it was reported that Atari sales estimates were about 800,000, which Atari claimed was within their expected projections. Lifetime sales by 1995 amounted to fewer than 7 million units when combined with the Game Gear. In comparison, the Game Boy sold 16 million units by 1995. In issue 129 of Retro Gamer magazine a special article was published to celebrate the 25th anniversary of the console which included interviews with numerous ex-Atari and ex-Epyx staff where lifetime Lynx sales figures were confirmed as being in the region of 3 million.
As with the actual console units, the game cartridges themselves evolved over the first year of the console's release. The first generation of cartridges were flat, and were designed to be stackable for ease of storage. However, this design proved to be very difficult to remove from the console and was replaced by a second design. This style, called "tabbed" or "ridged", used the same basic design as the original cartridges with the addition of two small tabs on the cartridge's underside to aid in removal. The original flat style cartridges could be stacked on top of the newer cartridges, but the newer cartridges could not be easily stacked on each other, nor were they stored easily. Thus a third style, the "curved lip" style was produced, and all official and third-party cartridges during the console's lifespan were released (or re-released) using this style.
In May 1991, Sega launched its Game Gear portable gaming handheld. Also a color handheld, in comparison to the Lynx it had a higher cost and shorter battery life (3–4 hours as opposed to 4-5 for the Lynx), but it was slightly smaller and was backed up by significantly more games. In North America the Game Gear took second place, and while in Europe sales of the Lynx were initially quite strong on the back of the popular Atari ST, it still could not compete with the software library of the Game Gear and was eventually pushed into third place. Retailers such as Game and Toys R Us continued to sell the Lynx well into the mid-90s on the back of the Atari Jaguar launch, helped by magazines such as Ultimate Future Games who continued to cover the Lynx alongside the new generation of 32-bit and 64-bit consoles.
During 1990, the Lynx had moderate sales. In July 1991, Atari Corp. introduced the Lynx II with a new marketing campaign, new packaging, slightly improved hardware, better battery life and a new sleeker look. The new system (referred to within Atari Corp. as the "Lynx II") featured rubber hand grips and a clearer backlit color screen with a power save option (which turned off the LCD panel's backlighting). It also replaced the monaural headphone jack of the original Lynx with one wired for stereo. The new packaging made the Lynx available without any accessories, dropping the price to $99. Although sales improved, Nintendo still dominated the handheld market.
In 1995, Atari Corp. shifted its focus away from the Lynx. As the Super NES and Genesis filled retailers' shelves, Atari Corp. refocused its efforts on its Jaguar console and its CD-ROM add-on. A handful of games were released during this time, including "Battlezone 2000". In 1996, Atari shut down its internal game development.
Telegames released a number of games in the second half of the 1990s, including a port of "Raiden" and a platformer called "Fat Bobby" in 1997, as well as an action sports game called "Hyperdrome" in 1999. At the end of the 1990s, Hasbro, the owners of the Atari properties at the time, released the rights to develop for the system to the public domain. Since then a number of independent developers released games into the new decade, like "Championship Rally", "CyberVirus", and "Alpine Games". Some of the late 90s/early 2000s games were under development by other companies at one time, but rights to the game programs and all of the existing code was bought and finished by other developers.
In 2008 Atari was honored at the 59th Annual Technology & Engineering Emmy Awards for pioneering the development of handheld games with its Lynx game unit.
On October 24, 2009, North American company Super Fighter Team released "Zaku", a horizontal shooter for the Lynx developed by PenguiNet. It was the first new game for the system since the 1990s whose game card has an authentic "curved lip" plastic shell instead of a custom bare circuit board.
Reception.
The game system was reviewed in 1990 in "Dragon", giving the Lynx 5 out of 5 stars. The review states that the Lynx "throws the into the prehistoric age"; and praises the built-in object scaling capabilities, the multiplayer feature of the ComLynx cable, and the strong set of launch games.

</doc>
<doc id="2784" url="https://en.wikipedia.org/wiki?curid=2784" title="Ahimsa">
Ahimsa

Ahimsa (; ; IAST: , Pāli: ) is a term meaning 'not to injure' and 'compassion'. The word is derived from the Sanskrit root "hiṃs" – to strike; "hiṃsā" is injury or harm, "a-hiṃsā" is the opposite of this, i.e. cause no injury, do no harm. Ahimsa is also referred to as nonviolence, and it applies to all living beings—including all animals—according to many Indian religions.
Ahimsa is one of the cardinal virtues and an important tenet of 3 major religions (Jainism, Hinduism, and Buddhism). Ahimsa is a multidimensional concept, inspired by the premise that all living beings have the spark of the divine spiritual energy; therefore, to hurt another being is to hurt oneself. Ahimsa has also been related to the notion that any violence has karmic consequences. While ancient scholars of Hinduism pioneered and over time perfected the principles of Ahimsa, the concept reached an extraordinary status in the ethical philosophy of Jainism. Most popularly, Mahatma Gandhi strongly believed in the principle of "ahimsa".
Ahimsa's precept of 'cause no injury' includes one's deeds, words, and thoughts. Classical literature of Hinduism such as Mahabharata and Ramayana, as well as modern scholars debate principles of Ahimsa when one is faced with war and situations requiring self-defence. The historic literature from India and modern discussions have contributed to theories of Just War, and theories of appropriate self-defence.
Etymology.
The word "Ahimsa"—sometimes spelled as "Ahinsa"—is derived from the Sanskrit root "hiṃs" – to strike; "hiṃsā" is injury or harm, "a-hiṃsā" is the opposite of this, i.e. "non harming" or "nonviolence".
There is a debate on the origins of the word "Ahimsa", and how its meaning evolved. Mayrhofer as well as Dumot suggest the root word may be "han" which means kill, which leads to the interpretation that "ahimsa" means "do not kill". Schmidt as well as Bodewitz explain the proper root word is "hiṃs" and the Sanskrit verb "hinasti", which leads to the interpretation "ahimsa" means "do not injure", or "do not hurt". Wackernagel-Debrunner concur with the latter explanation.
Ancient texts use ahimsa to mean non-injury, a broader concept than non-violence. Non-injury implies not killing others, as well as not hurting others mentally or verbally; it includes avoiding all violent means—including physical violence—anything that injures others. In classical Sanskrit literature of Hinduism, another word "Adrohi" is sometimes used instead of "Ahimsa", as one of the cardinal virtues necessary for moral life. One example is in Baudhayana Dharmasutra 2.6.23: वाङ्-मनः-कर्म-दण्डैर् भूतानाम् अद्रोही (One who does not injure others with words, thoughts or acts is named "Adrohi").
Hinduism.
Ancient Vedic Texts.
Ahimsa as an ethical concept evolved in Vedic texts. The oldest scripts, along with discussing ritual animal sacrifices, indirectly mention Ahimsa, but do not emphasise it. Over time, the Hindu scripts revise ritual practices and the concept of Ahimsa is increasingly refined and emphasised, ultimately Ahimsa becomes the concept that describes the highest virtue by the late Vedic era (about 500 BC). For example, hymn 10.22.13 in the Rig Veda uses the words Satya (truthfulness) and Ahimsa in a prayer to deity Indra; later, the Yajur Veda dated to be between 1000 BC and 600 BC, states, "may all beings look at me with a friendly eye, may I do likewise, and may we look at each other with the eyes of a friend".
The term "Ahimsa" appears in the text Taittiriya Shakha of the Yajurveda (TS 5.2.8.7), where it refers to non-injury to the sacrificer himself. It occurs several times in the "Shatapatha Brahmana" in the sense of "non-injury". The Ahimsa doctrine is a late Vedic era development in Brahmanical culture. The earliest reference to the idea of non-violence to animals ("pashu-Ahimsa"), apparently in a moral sense, is in the Kapisthala Katha Samhita of the Yajurveda (KapS 31.11), which may have been written in about the 8th century BCE.
Bowker states the word appears but is uncommon in the principal Upanishads. Kaneda gives examples of the word "Ahimsa" in these Upanishads. Other scholars suggest "Ahimsa" as an ethical concept that started evolving in the Vedas, becoming an increasingly central concept in Upanishads.
The Chāndogya Upaniṣad, dated to the 8th or 7th century BCE, one of the oldest Upanishads, has the earliest evidence for the use of the word "Ahimsa" in the sense familiar in Hinduism (a code of conduct). It bars violence against "all creatures" ("sarvabhuta") and the practitioner of Ahimsa is said to escape from the cycle of metempsychosis (CU 8.15.1). A few scholars are of the opinion that this might have been a concession to the growing influence of Jainism, in Vedic Hinduism.
Chāndogya Upaniṣad also names Ahimsa, along with Satyavacanam (truthfulness), Arjavam (sincerity), Danam (charity), Tapo (penance/meditation), as one of five essential virtues (CU 3.17.4).
The Sandilya Upanishad lists ten forbearances: Ahimsa, Satya, Asteya, Brahmacharya, Daya, Arjava, Kshama, Dhriti, Mitahara and Saucha. According to Kaneda, the term Ahimsa is an important spiritual doctrine shared by Hinduism, Buddhism and Jainism. It literally means 'non-injury' and 'non-killing'. It implies the total avoidance of harming of any kind of living creatures not only by deeds, but also by words and in thoughts.
The Epics.
The Mahabharata, one of the epics of Hinduism, has multiple mentions of the phrase "Ahimsa Paramo Dharma" (अहिंसा परमॊ धर्मः), which literally means: non-violence is the highest moral virtue. For example, Mahaprasthanika Parva has the verse:
<poem>
अहिंसा परमं दानम अहिंसा परमस तपः।
अहिंसा परमं मित्रम अहिंसा परमं सुखम।
</poem>
The above passage from Mahabharata emphasises the cardinal importance of Ahimsa in Hinduism, and literally means: Ahimsa is the highest virtue, Ahimsa is the highest self-control, Ahimsa is the greatest gift, Ahimsa is the best suffering, Ahimsa is the highest sacrifice, Ahimsa is the finest strength, Ahimsa is the greatest friend, Ahimsa is the greatest happiness, Ahimsa is the highest truth, and Ahimsa is the greatest teaching. Some other examples where the phrase "Ahimsa Paramo Dharma" are discussed include Adi Parva, Vana Parva and Anushasana Parva. The Bhagavad Gita, among other things, discusses the doubts and questions about appropriate response when one faces systematic violence or war. These verses develop the concepts of lawful violence in self-defence and the theories of just war. However, there is no consensus on this interpretation. Gandhi, for example, considers this debate about non-violence and lawful violence as a mere metaphor for the internal war within each human being, when he or she faces moral questions.
Self-defence, criminal law, and war.
The classical texts of Hinduism devote numerous chapters discussing what people who practice the virtue of Ahimsa, can and must do when they are faced with war, violent threat or need to sentence someone convicted of a crime. These discussions have led to theories of just war, theories of reasonable self-defence and theories of proportionate punishment. Arthashastra discusses, among other things, why and what constitutes proportionate response and punishment.
The precepts of Ahimsa under Hinduism require that war must be avoided, with sincere and truthful dialogue. Force must be the last resort. If war becomes necessary, its cause must be just, its purpose virtuous, its objective to restrain the wicked, its aim peace, its method lawful. War can only be started and stopped by a legitimate authority. Weapons used must be proportionate to the opponent and the aim of war, not indiscriminate tools of destruction. All strategies and weapons used in the war must be to defeat the opponent, not designed to cause misery to the opponent; for example, use of arrows is allowed, but use of arrows smeared with painful poison is not allowed. Warriors must use judgment in the battlefield. Cruelty to the opponent during war is forbidden. Wounded, unarmed opponent warriors must not be attacked or killed, they must be brought to your realm and given medical treatment. Children, women and civilians must not be injured. While the war is in progress, sincere dialogue for peace must continue.
In matters of self-defence, different interpretations of ancient Hindu texts have been offered. For example, Tähtinen suggests self-defence is appropriate, criminals are not protected by the rule of Ahimsa, and Hindu scriptures support the use of violence against an armed attacker. Ahimsa is not meant to imply pacifism.
Alternate theories of self-defence, inspired by Ahimsa, build principles similar to theories of just war. Aikido, pioneered in Japan, illustrates one such principles of self-defence. Morihei Ueshiba, the founder of Aikido, described his inspiration as Ahimsa. According to this interpretation of Ahimsa in self-defence, one must not assume that the world is free of aggression. One must presume that some people will, out of ignorance, error or fear, attack other persons or intrude into their space, physically or verbally. The aim of self-defence, suggested Ueshiba, must be to neutralise the aggression of the attacker, and avoid the conflict. The best defence is one where the victim is protected, as well as the attacker is respected and not injured if possible. Under Ahimsa and Aikido, there are no enemies, and appropriate self-defence focuses on neutralising the immaturity, assumptions and aggressive strivings of the attacker.
Tähtinen concludes that Hindus have no misgivings about death penalty; their position is that evil-doers who deserve death should be killed, and that a king in particular is obliged to punish criminals and should not hesitate to kill them, even if they happen to be his own brothers and sons.
Other scholars conclude that the scriptures of Hinduism suggest sentences for any crime must be fair, proportional and not cruel.
There is no universal consensus on pacifism among Hindu scholars of modern times. The conflict between pacifistic interpretations of Ahimsa and the theories of just war prescribed by the Gita has been resolved by some scholars such as Mohandas Karamchand Gandhi, as being an allegory, wherein the battlefield is the soul and Arjuna, the war is within each human being, where man's higher impulses struggle against his own evil impulses.
Non-human life.
The Hindu precept of 'cause no injury' applies to animals and all life forms. This precept isn’t found in the oldest verses of Vedas, but increasingly becomes one of the central ideas between 500 BC and 400 AD. In the oldest texts, numerous ritual sacrifices of animals, including cows and horses, are highlighted and hardly any mention is made of Ahimsa to non-human life.
Hindu scriptures, dated to between 5th century and 1st century BC, while discussing human diet, initially suggest ‘‘kosher’’ meat may be eaten, evolving it with the suggestion that only meat obtained through ritual sacrifice can be eaten, then that one should eat no meat because it hurts animals, with verses describing the noble life as one that lives on flowers, roots and fruits alone.
Later texts of Hinduism declare Ahimsa one of the primary virtues, declare any killing or harming any life as against ‘‘dharma’’ (moral life). Finally, the discussion in Upanishads and Hindu Epics shifts to whether a human being can ever live his or her life without harming animal and plant life in some way; which and when plants or animal meat may be eaten, whether violence against animals causes human beings to become less compassionate, and if and how one may exert least harm to non-human life consistent with ahimsa precept, given the constraints of life and human needs. The Mahabharata permits hunting by warriors, but opposes it in the case of hermits who must be strictly non-violent. Sushruta Samhita, a Hindu text written in the 3rd or 4th century, in Chapter XLVI suggests proper diet as a means of treating certain illnesses, and recommends various fishes and meats for different ailments and for pregnant women, and the Charaka Samhita describes meat as superior to all other kinds of food for convalescents.
Across the texts of Hinduism, there is a profusion of ideas about the virtue of Ahimsa when applied to non-human life, but without a universal consensus. Alsdorf claims the debate and disagreements between supporters of vegetarian lifestyle and meat eaters was significant. Even suggested exceptions – ritual slaughter and hunting – were challenged by advocates of Ahimsa. In the Mahabharata both sides present various arguments to substantiate their viewpoints. Moreover, a hunter defends his profession in a long discourse.
Many of the arguments proposed in favor of non-violence to animals refer to the bliss one feels, the rewards it entails before or after death, the danger and harm it prevents, as well as to the karmic consequences of violence.
The ancient Hindu texts discuss Ahimsa and non-animal life. They discourage wanton destruction of nature including of wild and cultivated plants. Hermits (sannyasins) were urged to live on a fruitarian diet so as to avoid the destruction of plants. Scholars claim the principles of ecological non-violence is innate in the Hindu tradition, and its conceptual fountain has been Ahimsa as their cardinal virtue.
The classical literature of Hinduism exists in many Indian languages. For example, "Tirukkuṛaḷ" written between 200 BC and 400 AD, and sometimes called the Tamil Veda, is one of the most cherished classics on Hinduism written in a South Indian language. Tirukkuṛaḷ dedicates Chapter 32 and 33 of Book 1 to the virtue of Ahimsa. "Tirukkuṛaḷ" suggests that Ahimsa applies to all life forms.
Modern times.
In the 19th and 20th centuries, prominent figures of Indian spirituality such as Swami Vivekananda, Ramana Maharshi, Swami Sivananda, A. C. Bhaktivedanta Swami and in the present time Vijaypal Baghel emphasised the importance of Ahimsa.
Mohandas Karamchand Gandhi promoted the principle of Ahimsa, very successful by applying it to all spheres of life, particularly to politics (Swaraj). His non-violent resistance movement satyagraha had an immense impact on India, impressed public opinion in Western countries, and influenced the leaders of various civil and political rights movements such as the American civil rights movement's Martin Luther King, Jr. and James Bevel. In Gandhi’s thought, Ahimsa precludes not only the act of inflicting a physical injury, but also mental states like evil thoughts and hatred, unkind behavior such as harsh words, dishonesty and lying, all of which he saw as manifestations of violence incompatible with Ahimsa. Gandhi believed Ahimsa to be a creative energy force, encompassing all interactions leading one's self to find satya, "Divine Truth". Sri Aurobindo criticised the Gandhian concept of Ahimsa as unrealistic and not universally applicable; he adopted a pragmatic non-pacifist position, saying that the justification of violence depends on the specific circumstances of the given situation. Sri Aurobindo also indicated that Gandhi's Ahimsa led to partition of India as it blocked the forceful action that the Indian people were engaged in during the 1920s and 30s, which caused delay in independence, allowing other forces to take root, including those who wanted India divided.
Gandhi stated that he viewed "Ahimsa is in Hinduism, it is in Christianity as well as in Islam." He added, "Nonviolence is common to all religions, but it has found the highest expression and application in Hinduism (I do not regard Jainism or Buddhism as separate from Hinduism)." When questioned whether violence and non-violence is both taught in Quran, he stated, "I have heard it from many Muslim friends that the Koran teaches the use of non-violence. (...The) argument about non-violence in the Holy Koran is an interpolation, not necessary for my thesis."
A historical and philosophical study of Ahimsa was instrumental in the shaping of Albert Schweitzer's principle of "reverence for life". Schweitzer praised Indian philosophical and religious traditions for ethics of Ahimsa as, "the laying down of the commandment not to kill and not to damage is one of the greatest events in the spiritual history of mankind", but suggested that "not-killing and not-harming" is not always practically possible as in self-defence, nor ethical as in chronic starving during a famine case.
Yoga.
Ahimsa is imperative for practitioners of Patañjali’s eight limb Raja yoga system. It is included in the first limb and is the first of five Yamas (self restraints) which, together with the second limb, make up the code of ethical conduct in Yoga philosophy. Ahimsa is also one of the ten "Yamas" in Hatha Yoga according to verse 1.1.17 of its classic manual "Hatha Yoga Pradipika".
Jainism.
In Jainism, the understanding and implementation of "Ahimsā" is more radical, scrupulous, and comprehensive than in any other religion. Killing any living being out of passions is considered "hiṃsā" (to injure) and abstaining from such an act is "ahimsā" (noninjury). The vow of ahimsā is considered the foremost among the 'five vows of Jainism'. Other vows like truth (satya) are meant for safeguarding the vow of ahimsā. In the practice of Ahimsa, the requirements are less strict for the lay persons (sravakas) who have undertaken "anuvrata" (Smaller Vows) than for the Jain monastics who are bound by the Mahavrata "Great Vows". The statement "" is often found inscribed on the walls of the Jain temples. Like in Hinduism, the aim is to prevent the accumulation of harmful karma. When Mahavira revived and reorganised the Jain faith in the 6th or 5th century BCE, Ahimsa was already an established, strictly observed rule. Rishabhanatha (Ādinātha), the first Jain Tirthankara, whom modern Western historians consider to be a historical figure, followed by Parshvanatha (Pārśvanātha) the twenty-third Tirthankara lived in about the 8th century BCE. He founded the community to which Mahavira’s parents belonged. Ahimsa was already part of the "Fourfold Restraint" ("Caujjama"), the vows taken by Parshva’s followers. In the times of Mahavira and in the following centuries, Jains were at odds with both Buddhists and followers of the Vedic religion or Hindus, whom they accused of negligence and inconsistency in the implementation of Ahimsa. According to the Jain tradition either lacto vegetarianism or veganism is mandatory.
The Jain concept of Ahimsa is characterised by several aspects. It does not make any exception for ritual sacrificers and professional warrior-hunters. Killing of animals for food is absolutely ruled out. Jains also make considerable efforts not to injure plants in everyday life as far as possible. Though they admit that plants must be destroyed for the sake of food, they accept such violence only inasmuch as it is indispensable for human survival, and there are special instructions for preventing unnecessary violence against plants. Jains go out of their way so as not to hurt even small insects and other minuscule animals. For example, Jains often do not go out at night, when they are more likely to step upon an insect. In their view, injury caused by carelessness is like injury caused by deliberate action. Eating honey is strictly outlawed, as it would amount to violence against the bees. Some Jains abstain from farming because it inevitably entails unintentional killing or injuring of many small animals, such as worms and insects, but agriculture is not forbidden in general and there are Jain farmers.
Theoretically, all life forms are said to deserve full protection from all kinds of injury, Jains recognise a hierarchy of life. Mobile beings are given higher protection than immobile ones. For the mobile beings, they distinguish between one-sensed, two-sensed, three-sensed, four-sensed and five-sensed ones; a one-sensed animal has touch as its only sensory modality. The more senses a being has, the more they care about non-injuring it. Among the five-sensed beings, the precept of non-injury and non-violence to the rational ones (humans) is strongest in Jain Ahimsa.
Jains agree with Hindus that violence in self-defence can be justified, and they agree that a soldier who kills enemies in combat is performing a legitimate duty. Jain communities accepted the use of military power for their defence, there were Jain monarchs, military commanders, and soldiers.
Buddhism.
In Buddhist texts "Ahimsa" (or its Pāli cognate ) is part of the Five Precepts (), the first of which has been to abstain from killing. However, this precept has been variously interpreted. In some Buddhist traditions, such as the Theravada tradition, vegetarianism is not mandatory. In these traditions, monks may eat meat and fish on condition that the animal was not killed specifically for them. For some monks, specifically monks of some Mahayana traditions, the eating of meat is strictly forbidden. Laypeople are also encouraged to eat vegetarian.
War.
Violent ways of punishing criminals and prisoners of war was not explicitly condemned in Buddhism, but peaceful ways of conflict resolution and punishment with the least amount of injury were encouraged. The early texts condemn the mental states that lead to violent behavior.
Nonviolence is an overriding theme within the Pali Canon. While the early texts condemn killing in the strongest terms, and portray the ideal king as a pacifist, such a king is nonetheless flanked by an army. It seems that the Buddha's teaching on nonviolence was not interpreted or put into practice in an uncompromisingly pacifist or anti-military-service way by early Buddhists. The early texts assume war to be a fact of life, and well-skilled warriors are viewed as necessary for defensive warfare. In Pali texts, injunctions to abstain from violence and involvement with military affairs are directed at members of the sangha; later Mahayana texts, which often generalise monastic norms to laity, require this of lay people as well.
The early texts do not contain just-war ideology as such. Some argue that a sutta in the "Gamani Samyuttam" rules out all military service. In this passage, a soldier asks the Buddha if it is true that, as he has been told, soldiers slain in battle are reborn in a heavenly realm. The Buddha reluctantly replies that if he is killed in battle while his mind is seized with the intention to kill, he will undergo an unpleasant rebirth. In the early texts, a person's mental state at the time of death is generally viewed as having a great impact on the next birth.
Some Buddhists point to other early texts as justifying defensive war. One example is the "Kosala Samyutta", in which King Pasenadi, a righteous king favored by the Buddha, learns of an impending attack on his kingdom. He arms himself in defence, and leads his army into battle to protect his kingdom from attack. He lost this battle but won the war. King Pasenadi eventually defeated King Ajatasattu and captured him alive. He thought that, although this King of Magadha has transgressed against his kingdom, he had not transgressed against him personally, and Ajatasattu was still his nephew. He released Ajatasattu and did not harm him. Upon his return, the Buddha said (among other things) that Pasenadi "is a friend of virtue, acquainted with virtue, intimate with virtue", while the opposite is said of the aggressor, King Ajatasattu.
According to Theravada commentaries, there are five requisite factors that must all be fulfilled for an act to be both an act of killing and to be karmically negative. These are: (1) the presence of a living being, human or animal; (2) the knowledge that the being is a living being; (3) the intent to kill; (4) the act of killing by some means; and (5) the resulting death. Some Buddhists have argued on this basis that the act of killing is complicated, and its ethicization is predicated upon intent. Some have argued that in defensive postures, for example, the primary intention of a soldier is not to kill, but to defend against aggression, and the act of killing in that situation would have minimal negative karmic repercussions.
According to Dr. Babasaheb Ambedkar, there is circumstantial evidence encouraging Ahimsa, from the Buddha's doctrine, ""Love all, so that you may not wish to kill any."" Gautama Buddha distinguished between a principle and a rule. He did not make Ahimsa a matter of rule, but suggested it as a matter of principle. This gives Buddhists freedom to act.
Laws.
The emperors of Sui dynasty, Tang dynasty and early Song dynasty banned killing in Lunar calendar 1st, 5th, and 9th month. Empress Wu Tse-Tien banned killing for more than half a year in 692. Some also banned fishing for some time each year.
There were bans after death of emperors, Buddhist and Taoist prayers, and natural disasters such as after a drought in 1926 summer Shanghai and an 8 days ban from August 12, 1959 after the August 7 flood (八七水災), the last big flood before the 88 Taiwan Flood.
People avoid killing during some festivals, like the Taoist Ghost Festival, the Nine Emperor Gods Festival, the Vegetarian Festival and many others.

</doc>
<doc id="2785" url="https://en.wikipedia.org/wiki?curid=2785" title="Annals of Mathematics">
Annals of Mathematics

The Annals of Mathematics is a bimonthly mathematical journal published by Princeton University and the Institute for Advanced Study.
Although its ISO 4 abbreviation is "Ann. Math.", "Mathematical Reviews" and many other mathematical publications abbreviate it as "Ann. of Math." instead.
History.
The journal was established as "The Analyst" in 1874 and with Joel E. Hendricks as the founding editor-in-chief. It was "intended to afford a medium for the presentation and analysis of any and all questions of interest or importance in pure and applied Mathematics, embracing especially all new and interesting discoveries in theoretical and practical astronomy, mechanical philosophy, and engineering". It was published in Des Moines, Iowa, and was the earliest American mathematics journal to be published continuously for more than a year or two. This incarnation of the journal ceased publication after its tenth year, in 1883, giving as an explanation Hendricks' declining health, but Hendricks made arrangements to have it taken over by new management, and it was continued from March 1884 as the "Annals of Mathematics". The new incarnation of the journal was edited by Ormond Stone (University of Virginia). It moved to Harvard in 1899 before reaching its current home in Princeton in 1911.
An important period for the journal was 1928–1958 with Solomon Lefschetz as editor. During this time, it became an increasingly well-known and respected journal. Its rise, in turn, stimulated American mathematics. Norman Steenrod characterized Lefschetz' impact as editor as follows: ""The importance to American mathematicians of a first-class journal is that it sets high standards for them to aim at. In this somewhat indirect manner, Lefschetz profoundly affected the development of mathematics in the United States.""
Princeton University continued to publish the annals on its own until 1933, when the Institute for Advanced Study took joint editorial control. Since 1998 it has been available in an electronic edition, alongside its regular print edition. The electronic edition was available without charge, as an open access journal, but since 2008 this is no longer the case. Issues from before 2003 were transferred to the non-free JSTOR archive, and articles are not freely available until 5 years after publication.
Editors.
The current editors of the "Annals of Mathematics" are David Gabai, Charles Fefferman, Nicholas M. Katz, Sergiu Klainerman, and Gang Tian (all from Princeton University) and Peter Sarnak (from the Institute for Advanced Study).
Abstracting and indexing.
The journal is abstracted and indexed in the Science Citation Index, Current Contents/Physical, Chemical & Earth Sciences, and Scopus. According to the "Journal Citation Reports", the journal has a 2012 impact factor of 3.027, ranking it third out of 296 journals in the category "Mathematics".

</doc>
<doc id="2786" url="https://en.wikipedia.org/wiki?curid=2786" title="Andrei Sakharov">
Andrei Sakharov

Andrei Dmitrievich Sakharov (; 21 May 192114 December 1989) was a Russian nuclear physicist, Soviet dissident, an activist for disarmament, peace and human rights.
He became renowned as the designer of the Soviet Union's Third Idea, a codename for Soviet development of thermonuclear weapons. Sakharov later became an advocate of civil liberties and civil reforms in the Soviet Union, for which he faced state persecution; these efforts earned him the Nobel Peace Prize in 1975. The Sakharov Prize, which is awarded annually by the European Parliament for people and organizations dedicated to human rights and freedoms, is named in his honour.
Biography.
Sakharov was born in Moscow on May 21, 1921. His father was Dmitri Ivanovich Sakharov, a private school physics teacher and an amateur pianist. His father later taught at the Second Moscow State University. Andrei's grandfather Ivan had been a prominent lawyer in the Russian Empire who had displayed respect for social awareness and humanitarian principles (including advocating the abolition of capital punishment) that would later influence his grandson. Sakharov's mother was Yekaterina Alekseyevna Sakharova, a great-granddaughter of the prominent military commander Alexey Semenovich Sofiano (who was of Greek ancestry). Sakharov's parents and paternal grandmother, Maria Petrovna, largely shaped his personality. Although Sakharov's paternal great-grandfather had been a priest in the Russian Orthodox Church, and his pious mother had him baptised, Sakharov was an atheist in later life. However, he did believe that a "guiding principle" governed the universe and human life.
Education and career.
Sakharov entered Moscow State University in 1938. Following evacuation in 1941 during the Great Patriotic War (World War II), he graduated in Aşgabat, in today's Turkmenistan. He was then assigned to laboratory work in Ulyanovsk. In 1943, he married Klavdia Alekseyevna Vikhireva, with whom he raised two daughters and a son before she died in 1969. He returned to Moscow in 1945 to study at the Theoretical Department of FIAN (the Physical Institute of the Soviet Academy of Sciences). He received his Ph.D. in 1947.
Development of thermonuclear devices.
After the end of World War II, he researched cosmic rays. In mid-1948 he participated in the Soviet atomic bomb project under Igor Kurchatov and Igor Tamm. Sakharov's study group at FIAN in 1948 came up with a second concept in August–September 1948. Adding a shell of natural, unenriched uranium around the deuterium would increase the deuterium concentration at the uranium-deuterium boundary and the overall yield of the device, because the natural uranium would capture neutrons and itself fission as part of the thermonuclear reaction. This idea of a layered fission-fusion-fission bomb led Sakharov to call it the sloika, or layered cake. The first Soviet atomic device was tested on August 29, 1949. After moving to Sarov in 1950, Sakharov played a key role in the development of the first megaton-range Soviet hydrogen bomb using a design known as "Sakharov's Third Idea" in Russia and the Teller-Ulam design in the United States. Before his "Third Idea", Sakharov tried a "layer cake" of alternating layers of fission and fusion fuel. The results were disappointing, yielding no more than a typical fission bomb. However the design was seen to be worth pursuing because deuterium is abundant and uranium is scarce, and he had no idea how powerful the US design was. One of the Bikini atomic experiments changed that, because the magnitude of the explosion became public knowledge when there was a dispute between Japan and the US over the contamination of a large area of ocean. Sakharov was surprised by the size of the explosion and realized that the Americans had harnessed the power of a separate fission explosion to compress the fusion fuel. Sakharov realised that in order to cause the explosion of one side of the fuel to symmetrically compress the fusion fuel, a mirror could be used to reflect the radiation. The details had not been officially declassified in Russia when Sakharov was writing his memoirs, but in the Teller-Ulam design, soft X-rays emitted by the fission bomb were focused onto a cylinder of lithium deuteride to compress it symmetrically. This is called radiation implosion. The Teller-Ulam design also had a secondary fission device inside the fusion cylinder to assist with the compression of the fusion fuel and generate neutrons to convert some of the lithium to tritium, producing a mixture of deuterium and tritium. Sakarov's idea was first tested as RDS-37 in 1955. A larger variation of the same design which Sakharov worked on was the 50 Mt Tsar Bomba of October 1961, which was the most powerful nuclear device ever detonated.
Sakharov saw "striking parallels" between his fate and those of J. Robert Oppenheimer and Edward Teller in the USA. Sakharov believed that in this "tragic confrontation of two outstanding people", both deserved respect, because "each of them was certain he had right on his side and was morally obligated to go to the end in the name of truth." While Sakharov strongly disagreed with Teller over nuclear testing in the atmosphere and the Strategic Defense Initiative, he believed that American academics had been unfair to Teller's resolve to get the H-bomb for the United States since "all steps by the Americans of a temporary or permanent rejection of developing thermonuclear weapons would have been seen either as a clever feint, or as the manifestation of stupidity. In both cases, the reaction would have been the same – avoid the trap and immediately take advantage of the enemy's stupidity."
Sakharov never felt that by creating nuclear weapons he had "known sin", in Oppenheimer's expression. He later wrote: "After more than forty years, we have had no third world war, and the balance of nuclear terror ... may have helped to prevent one. But I am not at all sure of this; back then, in those long-gone years, the question didn't even arise. What most troubles me now is the instability of the balance, the extreme peril of the current situation, the appalling waste of the arms race ... Each of us has a responsibility to think about this in global terms, with tolerance, trust, and candor, free from ideological dogmatism, parochial interests, or national egotism."
Support for peaceful use of nuclear technology.
In 1950 he proposed an idea for a controlled nuclear fusion reactor, the tokamak, which is still the basis for the majority of work in the area. Sakharov, in association with Igor Tamm, proposed confining extremely hot ionized plasma by torus shaped magnetic fields for controlling thermonuclear fusion that led to the development of the tokamak device.
Efforts to improve nuclear reactor technology.
In 1951 he invented and tested the first explosively pumped flux compression generators, compressing magnetic fields by explosives. He called these devices MC or MK (for "magnetocumulative") generators. The radial MK-1 produced a pulsed magnetic field of 25 megagauss (2500 teslas). The resulting helical MK-2 generated 1000 million amperes in 1953.
Sakharov then tested a MK-driven "plasma cannon" where a small aluminum ring was vaporized by huge eddy currents into a stable, self-confined toroidal plasmoid and was accelerated to 100 km/s. Sakharov later suggested replacing the copper coil in MK generators with a large superconductor solenoid to magnetically compress and focus underground nuclear explosions into a shaped charge effect. He theorized this could focus 1023 protons per second on a 1 mm2 surface.
Research and physics.
After 1965 Sakharov returned to fundamental science and began working on particle physics and cosmology.
He tried to explain the baryon asymmetry of the universe, being the first scientist to introduce two universes called "sheets", linked by the Big Bang. Sakharov achieved there a complete CPT symmetry since the second sheet is enantiomorph (P-symmetry), has an opposite arrow of time (T-symmetry) and is mainly populated by antimatter (C-symmetry) because of an opposite CP-violation. In this model the two universes do not interact, except via local matter accumulation whose density and pressure become high enough to connect the two sheets through a bridge without spacetime between them, but with geodesics continuity beyond the radius limit allowing an exchange of matter. Sakharov called such singularities a "collapse" and an "anticollapse", which are an alternative to the couple black hole and white hole in the wormhole theory. Sakharov also proposed the idea of induced gravity as an alternative theory of quantum gravity.
Turn to activism.
Since the late 1950s Sakharov had become concerned about the moral and political implications of his work. Politically active during the 1960s, Sakharov was against nuclear proliferation. Pushing for the end of atmospheric tests, he played a role in the 1963 Partial Test Ban Treaty, signed in Moscow.
Sakharov was also involved in an event with political consequences in 1964, when the USSR Academy of Sciences nominated for full membership Nikolai Nuzhdin, a follower of Trofim Lysenko (initiator of the Stalin-supported anti-genetics campaign Lysenkoism). Contrary to normal practice Sakharov, a member of the Academy, publicly spoke out against full membership for Nuzhdin, holding him responsible for "for the defamation, firing, arrest, even death, of many genuine scientists." In the end, Nuzhdin was not elected, but the episode prompted Sergei Khrushchev to order the KGB to gather compromising material on Sakharov.
The major turn in Sakharov's political evolution came in 1967, when anti-ballistic missile defense became a key issue in US–Soviet relations. In a secret detailed letter to the Soviet leadership of July 21, 1967, Sakharov explained the need to "take the Americans at their word" and accept their proposal for a "bilateral rejection by the USA and the Soviet Union of the development of antiballistic missile defense", because otherwise an arms race in this new technology would increase the likelihood of nuclear war. He also asked permission to publish his manuscript (which accompanied the letter) in a newspaper to explain the dangers posed by this kind of defense. The government ignored his letter and refused to let him initiate a public discussion of ABMs in the Soviet press.
In May 1968 Sakharov completed an essay entitled "Reflections on Progress, Peaceful Coexistence, and Intellectual Freedom". In it, he described the anti-ballistic missile defense as a major threat of world nuclear war. After this essay was circulated in "samizdat" and then published outside the Soviet Union, Sakharov was banned from conducting any military-related research and returned to FIAN to study fundamental theoretical physics. 
Over the next twelve years, until his exile to Gorky (Nizhny Novgorod) in January 1980, Andrei Sakharov assumed the role of a widely recognized and open dissident in Moscow. He stood vigil outside of closed courtrooms, wrote appeals on behalf of more than two hundred individual prisoners, and continued to write essays about the need for democratization. 
In 1970 Sakharov was among the three founding members of the Committee on Human Rights in the USSR along with Valery Chalidze and Andrei Tverdokhlebov. The Committee wrote appeals, collected signatures for petitions and succeeded in affiliating with several international human rights organizations. Its work was the subject of many KGB reports and brought Sakharov under increasing pressure from the government. 
Sakharvov married a fellow human rights activist, Yelena Bonner, in 1972. 
By 1973 Sakharov was meeting regularly with Western correspondents, holding press conferences in his apartment. He appealed to the U.S. Congress to approve the 1974 Jackson-Vanik Amendment to a trade bill, which coupled trade tariffs to the Kremlin's willingness to allow freer emigration.
Attacked by Soviet establishment, 1972 onwards.
In 1972 Sakharov became the target of sustained pressure and intimidation, from his fellow scientists in the USSR Academy of Sciences, the Soviet press and direct threats of physical assault. Dissident activists, including the writer Solzhenitsyn, sprang to his defence. 
In 1973 and 1974, the Soviet media campaign continued, targeting both Sakharov and Aleksandr Solzhenitsyn. While Sakharov disagreed with Solzhenitsyn's vision of Russian revival, he deeply respected him for his courage. Only a few individuals in the Soviet Union were willing to defend 'traitors' like Sakharov and Solzhenitsyn, and those who had dared were inevitably punished.
Sakharov later described that it took "years" for him to "understand how much substitution, deceit, and lack of correspondence with reality there was" in the Soviet ideals. "At first I thought, despite everything that I saw with my own eyes, that the Soviet State was a breakthrough into the future, a kind of prototype for all countries". Then he came, in his words, to "the theory of symmetry: all governments and regimes to a first approximation are bad, all peoples are oppressed, and all are threatened by common dangers." 
After that he realized that there is not much "symmetry between a cancer cell and a normal one. Yet our state is similar to a cancer cell – with its messianism and expansionism, its totalitarian suppression of dissent, the authoritarian structure of power, with a total absence of public control in the most important decisions in domestic and foreign policy, a closed society that does not inform its citizens of anything substantial, closed to the outside world, without freedom of travel or the exchange of information." Sakharov's ideas on social development led him to put forward the principle of human rights as a new basis of all politics. In his works he declared that "the principle 'what is not prohibited is allowed' should be understood literally", defying the unwritten ideological rules imposed by the Communist ruling elite on the society in spite of the seemingly democratic (1936) USSR Constitution.
In no way did Sakharov consider himself a prophet or the like: "I am no volunteer priest of the idea, but simply a man with an unusual fate. I am against all kinds of self-immolation (for myself and for others, including the people closest to me)." In a letter written from exile, he cheered up a fellow physicist and human rights activist with the words: "Fortunately, the future is unpredictable and also – because of quantum effects – uncertain." For Sakharov the indeterminacy of the future supported his belief that he could, and should, take personal responsibility for it.
Nobel Peace Prize (1975).
In 1973, Sakharov was nominated for the Nobel Peace Prize and in 1974 was awarded the Prix mondial Cino Del Duca. 
Sakharov was awarded the Nobel Peace Prize in 1975. The Norwegian Nobel Committee called him "a spokesman for the conscience of mankind". In the words of the Nobel Committee's citation: "In a convincing manner Sakharov has emphasised that Man's inviolable rights provide the only safe foundation for genuine and enduring international cooperation."
Sakharov was not allowed to leave the Soviet Union to collect the prize. His wife Yelena Bonner read his speech at the ceremony in Oslo, Norway. On the day the prize was awarded, Sakharov was in Vilnius, where human rights activist Sergei Kovalev was being tried. In his Nobel lecture, titled "Peace, Progress, Human Rights", Sakharov called for an end to the arms race, greater respect for the environment, international cooperation, and universal respect for human rights. He included a list of prisoners of conscience and political prisoners in the USSR, stating that he shares the prize with them.
By 1976 head of the KGB Yuri Andropov was prepared to call Sakharov "Domestic Enemy Number One" before a group of KGB officers.
Internal exile (1980–1986).
Sakharov was arrested on January 22, 1980, following his public protests against the Soviet intervention in Afghanistan in 1979, and was sent to internal exile in the city of Gorky, now Nizhny Novgorod, a city that was off limits to foreigners.
Between 1980 and 1986, Sakharov was kept under tight Soviet police surveillance. In his memoirs he mentions that their apartment in Gorky was repeatedly subjected to searches and heists. Sakharov was named the 1980 Humanist of the Year by the American Humanist Association.
In May 1984, Sakharov's wife, Yelena Bonner, was detained and Sakharov began a hunger strike, demanding permission for his wife to travel to the United States for heart surgery. He was forcibly hospitalized and force-fed. He was held in isolation for four months. In August 1984 Yelena Bonner was sentenced by a court to five years of exile in Gorky.
In April 1985, Sakharov started a new hunger strike for his wife to travel abroad for medical treatment. He again was taken to a hospital and force-fed. He remained in the hospital until October 1985 when his wife was allowed to travel to the United States. She had heart surgery in the United States and returned to Gorky in June 1986.
In December 1985, the European Parliament established the Sakharov Prize for Freedom of Thought, to be given annually for outstanding contributions to human rights.
On December 19, 1986, Mikhail Gorbachev, who had initiated the policies of perestroika and glasnost, called Sakharov to tell him that he and his wife could return to Moscow.
Political leader.
In 1988, Sakharov was given the International Humanist Award by the International Humanist and Ethical Union. He helped to initiate the first independent legal political organizations and became prominent in the Soviet Union's growing political opposition. In March 1989, Sakharov was elected to the new parliament, the All-Union Congress of People's Deputies and co-led the democratic opposition, the Inter-Regional Deputies Group.
Death.
Soon after 21:00 on December 14, 1989, Sakharov went to his study to take a nap before preparing an important speech he was to deliver the next day in the Congress. His wife went to wake him at 23:00 as he had requested but she found Sakharov dead on the floor. According to the notes of Yakov Rapoport, a senior pathologist present at the autopsy, it is most likely that Sakharov died of an arrhythmia consequent to dilated cardiomyopathy at the age of 68. He was interred in the Vostryakovskoye Cemetery in Moscow.
Influence.
Memorial prizes.
The Sakharov Prize for Freedom of Thought was established in 1988 by the European Parliament in his honour, and is the highest tribute to human rights endeavours awarded by the European Union. It is awarded annually by the parliament to "those who carry the spirit of Soviet dissident Andrei Sakharov"; to "Laureates who, like Sakharov, dedicate their lives to peaceful struggle for human rights."
An Andrei Sakharov prize has also been awarded by the American Physical Society every second year since 2006 "to recognize outstanding leadership and/or achievements of scientists in upholding human rights".
The Andrei Sakharov Prize For Writer's Civic Courage was established in October 1990.
In 2004, with the approval of Elena Bonner, an annual Sakharov Prize for journalism was established for reporters and commentators in Russia. Funded by former Soviet dissident Pyotr Vins, now a businessman in the USA, the prize is administered by the Glasnost Defence Foundation in Moscow. The prize "for journalism as an act of conscience" has been won over the years by famous journalists such as Anna Politkovskaya and young reporters and editors working far from Russia's media capital, Moscow. The 2015 winner was Yelena Kostyuchenko.
Andrei Sakharov Archives and Human Rights Center.
The Andrei Sakharov Archives and Human Rights Center, established at Brandeis University in 1993, are now housed at Harvard University.
The documents from that archive were published by the Yale University Press in 2005. These documents are available online.
Most of documents of the archive are letters from the head of the KGB to the Central Committee about activities of Soviet dissidents and recommendations about the interpretation in newspapers. The letters cover the period from 1968 to 1991 (Brezhnev stagnation). The documents characterize not only Sakharov's activity, but that of other dissidents, as well as that of highest-position apparatchiks and the KGB. No Russian equivalent of the KGB archive is available.
Honours and awards.
In 1980, Sakharov was stripped of all Soviet awards for "anti-Soviet activities". Later, during glasnost, he declined the return of his awards and, consequently, Mikhail Gorbachev did not sign the necessary decree.

</doc>
<doc id="2787" url="https://en.wikipedia.org/wiki?curid=2787" title="Astrobiology">
Astrobiology

Astrobiology is the study of the origin, evolution, distribution, and future of life in the universe: extraterrestrial life and life on Earth. Astrobiology addresses the question of whether life exists beyond Earth, and how humans can detect it if it does (the term exobiology is similar but more specific—it covers the search for life beyond Earth, and the effects of extraterrestrial environments on living things).
Astrobiology makes use of physics, chemistry, astronomy, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. The origin and early evolution of life is an inseparable part of the discipline of astrobiology. Astrobiology concerns itself with interpretation of existing scientific data; given more detailed and reliable data from other parts of the universe, the roots of astrobiology itself—physics, chemistry and biology—may have their theoretical bases challenged. Although speculation is entertained to give context, astrobiology concerns itself primarily with hypotheses that fit firmly into existing scientific theories.
This interdisciplinary field encompasses research on the origin and evolution of planetary systems, origins of organic compounds in space, rock-water-carbon interactions, abiogenesis on Earth, planetary habitability, research on biosignatures for life detection, and studies on the potential for life to adapt to challenges on Earth and in outer space.
The chemistry of life may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the Universe was only 10–17 million years old. According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe. According to research published in August 2015, very large galaxies may be more favorable to the creation and development of habitable planets than smaller galaxies, like the Milky Way galaxy. Nonetheless, Earth is the only place in the universe known to harbor life. Estimates of habitable zones around other stars, along with the discovery of hundreds of extrasolar planets and new insights into the extreme habitats here on Earth, suggest that there may be many more habitable places in the universe than considered possible until very recently.
Current studies on the planet Mars by the "Curiosity" and "Opportunity" rovers are now searching for evidence of ancient life as well as plains related to ancient rivers or lakes that may have been habitable. The search for evidence of habitability, taphonomy (related to fossils), and organic molecules on the planet Mars is now a primary NASA and ESA objective on Mars.
Overview.
"Astrobiology" is etymologically derived from the Greek , "astron", "constellation, star"; , "bios", "life"; and , "-logia", "study". The synonyms of astrobiology are diverse; however, the synonyms were structured in relation to the most important sciences implied in its development: astronomy and biology. A close synonym is "exobiology" from the Greek , "external"; Βίος, "bios", "life"; and λογία, -logia, "study". The term exobiology was coined by molecular biologist Joshua Lederberg. Exobiology is considered to have a narrow scope limited to search of life external to Earth, whereas subject area of astrobiology is wider and investigates the link between life and the universe, which includes the search for extraterrestrial life, but also includes the study of life on Earth, its origin, evolution and limits. 
Another term used in the past is xenobiology, ("biology of the foreigners") a word used in 1954 by science fiction writer Robert Heinlein in his work The Star Beast. The term "xenobiology" is now used in a more specialized sense, to mean "biology based on foreign chemistry", whether of extraterrestrial or terrestrial (possibly synthetic) origin. Since alternate chemistry analogs to some life-processes have been created in the laboratory, xenobiology is now considered as an extant subject.
While it is an emerging and developing field, the question of whether life exists elsewhere in the universe is a verifiable hypothesis and thus a valid line of scientific inquiry. Though once considered outside the mainstream of scientific inquiry, astrobiology has become a formalized field of study. Planetary scientist David Grinspoon calls astrobiology a field of natural philosophy, grounding speculation on the unknown, in known scientific theory. NASA's interest in exobiology first began with the development of the U.S. Space Program. In 1959, NASA funded its first exobiology project, and in 1960, NASA founded an Exobiology Program, which is now one of four main elements of NASA's current Astrobiology Program. In 1971, NASA funded the search for extraterrestrial intelligence (SETI) to search radio frequencies of the electromagnetic spectrum for interstellar communications transmitted by extraterrestrial life outside the Solar System. NASA's Viking missions to Mars, launched in 1976, included three biology experiments designed to look for metabolism of present life on Mars.
Advancements in the fields of astrobiology, observational astronomy and discovery of large varieties of extremophiles with extraordinary capability to thrive in the harshest environments on Earth, have led to speculation that life may possibly be thriving on many of the extraterrestrial bodies in the universe. A particular focus of current astrobiology research is the search for life on Mars due to its proximity to Earth and geological history. There is a growing body of evidence to suggest that Mars has previously had a considerable amount of water on its surface, water being considered an essential precursor to the development of carbon-based life.
Missions specifically designed to search for current life on Mars were the Viking program and Beagle 2 probes. The Viking results were inconclusive, and Beagle 2 failed minutes after landing. A future mission with a strong astrobiology role would have been the Jupiter Icy Moons Orbiter, designed to study the frozen moons of Jupiter—some of which may have liquid water—had it not been cancelled. In late 2008, the Phoenix lander probed the environment for past and present planetary habitability of microbial life on Mars, and to research the history of water there.
In November 2011, NASA launched the Mars Science Laboratory mission carrying the "Curiosity" rover, which landed on Mars at Gale Crater in August 2012. The "Curiosity" rover is currently probing the environment for past and present planetary habitability of microbial life on Mars. On 9 December 2013, NASA reported that, based on evidence from "Curiosity" studying Aeolis Palus, Gale Crater contained an ancient freshwater lake which could have been a hospitable environment for microbial life.
The European Space Agency is currently collaborating with the Russian Federal Space Agency (Roscosmos) and developing the ExoMars astrobiology rover, which is to be launched in 2018. While NASA is developing the Mars 2020 astrobiology rover and sample cacher for a later return to Earth.
Methodology.
Planetary habitability.
When looking for life on other planets like Earth, some simplifying assumptions are useful to reduce the size of the task of the astrobiologist. One is the informed assumption that the vast majority of life forms in our galaxy are based on carbon chemistries, as are all life forms on Earth. Carbon is well known for the unusually wide variety of molecules that can be formed around it. Carbon is the fourth most abundant element in the universe and the energy required to make or break a bond is just at an appropriate level for building molecules which are not only stable, but also reactive. The fact that carbon atoms bond readily to other carbon atoms allows for the building of arbitrarily long and complex molecules.
The presence of liquid water is an assumed requirement, as it is a common molecule and provides an excellent environment for the formation of complicated carbon-based molecules that could eventually lead to the emergence of life. Some researchers posit environments of ammonia, or more likely, water-ammonia mixtures as possible solvents for hypothetical types of biochemistry.
A third assumption is to focus on planets orbiting Sun-like stars for increased probabilities of planetary habitability. Very large stars have relatively short lifetimes, meaning that life might not have time to emerge on planets orbiting them. Very small stars provide so little heat and warmth that only planets in very close orbits around them would not be frozen solid, and in such close orbits these planets would be tidally "locked" to the star. The long lifetimes of red dwarfs could allow the development of habitable environments on planets with thick atmospheres. This is significant, as red dwarfs are extremely common. (See Habitability of red dwarf systems).
Since Earth is the only planet known to harbor life, there is no evident way to know if any of the simplifying assumptions are correct.
Communication attempts.
Research on communication with extraterrestrial intelligence (CETI) focuses on composing and deciphering messages that could theoretically be understood by another technological civilization. Communication attempts by humans have included broadcasting mathematical languages, pictorial systems such as the Arecibo message and computational approaches to detecting and deciphering 'natural' language communication. The SETI program, for example, uses both radio telescopes and optical telescopes to search for deliberate signals from an extraterrestrial intelligence.
While some high-profile scientists, such as Carl Sagan, have advocated the transmission of messages, scientist Stephen Hawking has warned against it, suggesting that aliens might simply raid Earth for its resources and then move on.
Elements of astrobiology.
Astronomy.
Most astronomy-related astrobiology research falls into the category of extrasolar planet (exoplanet) detection, the hypothesis being that if life arose on Earth, then it could also arise on other planets with similar characteristics. To that end, a number of instruments designed to detect Earth-sized exoplanets have been considered, most notably NASA's Terrestrial Planet Finder (TPF) and ESA's Darwin programs, both of which have been cancelled. NASA launched the Kepler mission in March 2009, and the French Space Agency launched the COROT space mission in 2006. There are also several less ambitious ground-based efforts underway.
The goal of these missions is not only to detect Earth-sized planets, but also to directly detect light from the planet so that it may be studied spectroscopically. By examining planetary spectra, it would be possible to determine the basic composition of an extrasolar planet's atmosphere and/or surface. Given this knowledge, it may be possible to assess the likelihood of life being found on that planet. A NASA research group, the Virtual Planet Laboratory, is using computer modeling to generate a wide variety of virtual planets to see what they would look like if viewed by TPF or Darwin. It is hoped that once these missions come online, their spectra can be cross-checked with these virtual planetary spectra for features that might indicate the presence of life.
An estimate for the number of planets with intelligent "communicative" extraterrestrial life can be gleaned from the Drake equation, essentially an equation expressing the probability of intelligent life as the product of factors such as the fraction of planets that might be habitable and the fraction of planets on which life might arise:
where:
However, whilst the rationale behind the equation is sound, it is unlikely that the equation will be constrained to reasonable error limits any time soon. The first term, "N", number of stars, is generally constrained within a few orders of magnitude. The second and third terms, "fp", stars with planets and "fe", planets with habitable conditions, are being evaluated for the star's neighborhood. The problem with the formula is that it is not usable to generate or support hypotheses because it contains factors that can never be verified. Drake originally formulated the equation merely as an agenda for discussion at the Green Bank conference, but some applications of the formula had been taken literally and related to simplistic or pseudoscientific arguments. Another associated topic is the Fermi paradox, which suggests that if intelligent life is common in the universe, then there should be obvious signs of it.
Another active research area in astrobiology is planetary system formation. It has been suggested that the peculiarities of the Solar System (for example, the presence of Jupiter as a protective shield) may have greatly increased the probability of intelligent life arising on our planet.
Biology.
Biology cannot state that a process or phenomenon, by being mathematically possible, has to exist forcibly in an extraterrestrial body. Biologists specify what is speculative and what is not.
Until the 1970s, life was thought to be entirely dependent on energy from the Sun. Plants on Earth's surface capture energy from sunlight to photosynthesize sugars from carbon dioxide and water, releasing oxygen in the process that is then consumed by oxygen-respiring organisms, passing their energy up the food chain. Even life in the ocean depths, where sunlight cannot reach, was thought to obtain its nourishment either from consuming organic detritus rained down from the surface waters or from eating animals that did. The world's ability to support life was thought to depend on its access to sunlight. However, in 1977, during an exploratory dive to the Galapagos Rift in the deep-sea exploration submersible "Alvin", scientists discovered colonies of giant tube worms, clams, crustaceans, mussels, and other assorted creatures clustered around undersea volcanic features known as black smokers. These creatures thrive despite having no access to sunlight, and it was soon discovered that they comprise an entirely independent ecosystem. Instead of plants, the basis for this food chain is a form of bacterium that derives its energy from oxidization of reactive chemicals, such as hydrogen or hydrogen sulfide, that bubble up from the Earth's interior. This chemosynthesis revolutionized the study of biology and astrobiology by revealing that life need not be sun-dependent; it only requires water and an energy gradient in order to exist.
Extremophiles, organisms able to survive in extreme environments, are a core research element for astrobiologists. Such organisms include biota which are able to survive several kilometers below the ocean's surface near hydrothermal vents and microbes that thrive in highly acidic environments. It is now known that extremophiles thrive in ice, boiling water, acid, alkali, the water core of nuclear reactors, salt crystals, toxic waste and in a range of other extreme habitats that were previously thought to be inhospitable for life. It opened up a new avenue in astrobiology by massively expanding the number of possible extraterrestrial habitats. Characterization of these organisms, their environments and their evolutionary pathways, is considered a crucial component to understanding how life might evolve elsewhere in the universe. For example, some organisms able to withstand exposure to the vacuum and radiation of outer space include the lichen fungi "Rhizocarpon geographicum" and "Xanthoria elegans", the bacterium "Bacillus safensis", "Deinococcus radiodurans", "Bacillus subtilis", yeast "Saccharomyces cerevisiae", seeds from "Arabidopsis thaliana" ('mouse-ear cress'), as well as the invertebrate animal Tardigrade.
Jupiter's moon, Europa, and Saturn's moon, Enceladus, are now considered the most likely locations for extant extraterrestrial life in the Solar System.
The origin of life, known as abiogenesis, distinct from the evolution of life, is another ongoing field of research. Oparin and Haldane postulated that the conditions on the early Earth were conducive to the formation of organic compounds from inorganic elements and thus to the formation of many of the chemicals common to all forms of life we see today. The study of this process, known as prebiotic chemistry, has made some progress, but it is still unclear whether or not life could have formed in such a manner on Earth. The alternative hypothesis of panspermia is that the first elements of life may have formed on another planet with even more favorable conditions (or even in interstellar space, asteroids, etc.) and then have been carried over to Earth — the panspermia hypothesis.
The cosmic dust permeating the universe contains complex organic matter ("amorphous organic solids with a mixed aromatic-aliphatic structure") that could be created naturally, and rapidly, by stars. Further, a scientist suggested that these compounds may have been related to the development of life on Earth and said that, "If this is the case, life on Earth may have had an easier time getting started as these organics can serve as basic ingredients for life." In September 2012, NASA scientists reported that polycyclic aromatic hydrocarbons (PAHs), subjected to interstellar medium conditions, are transformed through hydrogenation, oxygenation and hydroxylation, to more complex organics - "a step along the path toward amino acids and nucleotides, the raw materials of proteins and DNA, respectively".
More than 20% of the carbon in the universe may be associated with PAHs, possible starting materials for the formation of life. PAHs seem to have been formed shortly after the Big Bang, are widespread throughout the universe, and are associated with new stars and exoplanets.
Astroecology.
Astroecology concerns the interactions of life with space environments and resources, in planets, asteroids and comets. On a larger scale, astroecology concerns resources for life about stars in the galaxy through the cosmological future. Astroecology attempts to quantify future life in space, addressing this area of astrobiology.
Experimental astroecology investigates resources in planetary soils, using actual space materials in meteorites. The results suggest that Martian and carbonaceous chondrite materials can support bacteria, algae and plant (asparagus, potato) cultures, with high soil fertilities. The results support that life could have survived in early aqueous asteroids and on similar materials imported to Earth by dust, comets and meteorites, and that such asteroid materials can be used as soil for future space colonies.
On the largest scale, cosmoecology concerns life in the universe over cosmological times. The main sources of energy may be red giant stars and white and red dwarf stars, sustaining life for 1020 years. Astroecologists suggest that their mathematical models may quantify the potential amounts of future life in space, allowing a comparable expansion in biodiversity, potentially leading to diverse intelligent life forms.
Astrogeology.
Astrogeology is a planetary science discipline concerned with the geology of the celestial bodies such as the planets and their moons, asteroids, comets, and meteorites. The information gathered by this discipline allows the measure of a planet's or a natural satellite's potential to develop and sustain life, or planetary habitability.
An additional discipline of astrogeology is geochemistry, which involves study of the chemical composition of the Earth and other planets, chemical processes and reactions that govern the composition of rocks and soils, the cycles of matter and energy and their interaction with the hydrosphere and the atmosphere of the planet. Specializations include cosmochemistry, biochemistry and organic geochemistry.
The fossil record provides the oldest known evidence for life on Earth. By examining the fossil evidence, paleontologists are able to better understand the types of organisms that arose on the early Earth. Some regions on Earth, such as the Pilbara in Western Australia and the McMurdo Dry Valleys of Antarctica, are also considered to be geological analogs to regions of Mars, and as such, might be able to provide clues on how to search for past life on Mars.
The various organic functional groups, composed of hydrogen, oxygen, nitrogen, phosphorus, sulfur, and a host of metals, such as iron, magnesium, and zinc, provide the enormous diversity of chemical reactions necessarily catalyzed by a living organism. Silicon, in contrast, interacts with only a few other atoms, and the large silicon molecules are monotonous compared with the combinatorial universe of organic macromolecules. Indeed, it seems likely that the basic building blocks of life anywhere will be similar those on Earth, in the generality if not in the detail. Although terrestrial life and life that might arise independently of Earth are expected to use many similar, if not identical, building blocks, they also are expected to have some biochemical qualities that are unique. If life has had a comparable impact elsewhere in the Solar System, the relative abundances of chemicals key for its survival - whatever they may be - could betray its presence. Whatever extraterrestrial life may be, its tendency to chemically alter its environment might just give it away.
Life in the Solar System.
People have long speculated about the possibility of life in settings other than Earth, however, speculation on the nature of life elsewhere often has paid little heed to constraints imposed by the nature of biochemistry. The likelihood that life throughout the universe is probably carbon-based is suggested by the fact that carbon is one of the most abundant of the higher elements. Only two of the natural atoms, carbon and silicon, are known to serve as the backbones of molecules sufficiently large to carry biological information. As the structural basis for life, one of carbon's important features is that unlike silicon, it can readily engage in the formation of chemical bonds with many other atoms, thereby allowing for the chemical versatility required to conduct the reactions of biological metabolism and propagation.
Thought on where in the Solar System life might occur, was limited historically by the understanding that life relies ultimately on light and warmth from the Sun and, therefore, is restricted to the surfaces of planets. The three most likely candidates for life in the Solar System are the planet Mars, the Jovian moon Europa, and Saturn's moon Titan. More recently, Saturn's moon Enceladus may be considered a likely candidate as well.
Mars, Enceladus and Europa are considered likely candidates in the search for life primarily because they may have liquid water, a molecule essential for life as we know it for its use as a solvent in cells. Water on Mars is found in its polar ice caps, and newly carved gullies recently observed on Mars suggest that liquid water may exist, at least transiently, on the planet's surface. At the Martian low temperatures and low pressure, liquid water is likely to be highly saline. As for Europa, liquid water likely exists beneath the moon's icy outer crust. This water may be warmed to a liquid state by volcanic vents on the ocean floor, but the primary source of heat is probably tidal heating. On 11 December 2013, NASA reported the detection of "clay-like minerals" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa. The presence of the minerals may have been the result of a collision with an asteroid or comet according to the scientists.
Another planetary body that could potentially sustain extraterrestrial life is Saturn's largest moon, Titan. Titan has been described as having conditions similar to those of early Earth. On its surface, scientists have discovered the first liquid lakes outside Earth, but they seem to be composed of ethane and/or methane, not water. Some scientists think it possible that these liquid hydrocarbons might take the place of water in living cells different from those on Earth. After Cassini data was studied, it was reported on March 2008 that Titan may also have an underground ocean composed of liquid water and ammonia. Additionally, Saturn's moon Enceladus may have an ocean below its icy surface and, according to NASA scientists in May 2011, "is emerging as the most habitable spot beyond Earth in the Solar System for life as we know it".
Measuring the ratio of hydrogen and methane levels on Mars may help determine the likelihood of life on Mars. According to the scientists, "...low H2/CH4 ratios (less than approximately 40) indicate that life is likely present and active." Other scientists have recently reported methods of detecting hydrogen and methane in extraterrestrial atmospheres.
Complex organic compounds of life, including uracil, cytosine and thymine, have been formed in a laboratory under outer space conditions, using starting chemicals such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe.
Rare Earth hypothesis.
The Rare Earth hypothesis postulates that multicellular life forms found on Earth may actually be more of a rarity than scientists assume. It provides a possible answer to the Fermi paradox which suggests, "If extraterrestrial aliens are common, why aren't they obvious?" It is apparently in opposition to the principle of mediocrity, assumed by famed astronomers Frank Drake, Carl Sagan, and others. The Principle of Mediocrity suggests that life on Earth is not exceptional, but rather that life is more than likely to be found on innumerable other worlds.
The anthropic principle states that fundamental laws of the universe work specifically in a way that life would be possible. The anthropic principle supports the Rare Earth Hypothesis by arguing the overall elements that are needed to support life on Earth are so fine-tuned that it is nearly impossible for another just like it to exist by random chance (note that these terms are used by scientists in a different way from the vernacular conception of them).
Research.
The systematic search for possible life outside Earth is a valid multidisciplinary scientific endeavor. However, hypotheses and predictions as to its existence and origin vary widely, and at the present, the development of hypotheses firmly grounded on science may be considered astrobiology's most concrete practical application. It has been proposed that viruses are likely to be encountered on other life-bearing planets.
Research outcomes.
, no evidence of extraterrestrial life has been identified. Examination of the Allan Hills 84001 meteorite, which was recovered in Antarctica in 1984 and originated from Mars, is thought by David McKay, as well as few other scientists, to contain microfossils of extraterrestrial origin; this interpretation is controversial.
Yamato 000593 is the second largest meteorite from Mars, and was found on Earth in 2000. At a microscopic level, spheres are found in the meteorite that are rich in carbon compared to surrounding areas that lack such spheres. The carbon-rich spheres may have been formed by biotic activity according to some NASA scientists.
On 5 March 2011, Richard B. Hoover, a scientist with the Marshall Space Flight Center, speculated on the finding of alleged microfossils similar to cyanobacteria in CI1 carbonaceous meteorites. However, NASA formally distanced itself from Hoover's claim. According to American astrophysicist Neil deGrasse Tyson: "At the moment, life on Earth is the only known life in the universe, but there are compelling arguments to suggest we are not alone."
On 17 March 2013, researchers reported that microbial life forms thrive in the Mariana Trench, the deepest spot on the Earth. Other researchers reported related studies that microbes thrive inside rocks up to 1900 feet below the sea floor under 8500 feet of ocean off the coast of the northwestern United States. According to one of the researchers, "You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are." These finds expand the potential habitability of certain niches of other planets.
In 2004, the spectral signature of methane () was detected in the Martian atmosphere by both Earth-based telescopes as well as by the Mars Express orbiter. Because of solar radiation and cosmic radiation, methane is predicted to disappear from the Martian atmosphere within several years, so the gas must be actively replenished in order to maintain the present concentration. The "Curiosity" rover will perform precision measurements of oxygen and carbon isotope ratios in carbon dioxide (CO2) and methane (CH4) in the atmosphere of Mars in order to distinguish between a geochemical and a biological origin.
It is possible that some exoplanets may have moons with solid surfaces or liquid oceans that are hospitable. Most of the planets so far discovered outside the Solar System are hot gas giants thought to be inhospitable to life, so it is not yet known whether the Solar System, with a warm, rocky, metal-rich inner planet such as Earth, is of an aberrant composition. Improved detection methods and increased observing time will undoubtedly discover more planetary systems, and possibly some more like ours. For example, NASA's Kepler Mission seeks to discover Earth-sized planets around other stars by measuring minute changes in the star's light curve as the planet passes between the star and the spacecraft. Progress in infrared astronomy and submillimeter astronomy has revealed the constituents of other star systems.
Efforts to answer questions such as the abundance of potentially habitable planets in habitable zones and chemical precursors have had much success. Numerous extrasolar planets have been detected using the wobble method and transit method, showing that planets around other stars are more numerous than previously postulated. The first Earth-sized extrasolar planet to be discovered within its star's habitable zone is Gliese 581 c.
Missions.
Research into the environmental limits of life and the workings of extreme ecosystems is ongoing, enabling researchers to better predict what planetary environments might be most likely to harbor life. Missions such as the Phoenix lander, Mars Science Laboratory, ExoMars, Mars 2020 rover to Mars, and the "Cassini" probe to Saturn's moons aim to further explore the possibilities of life on other planets in the Solar System.
Viking program.
The two Viking landers each carried four types of biological experiments to the surface of Mars in the late 1970s. These were the only Mars landers to carry out experiments to look specifically for metabolism by current microbial life on Mars. The landers used a robotic arm to collect soil samples into sealed test containers on the craft. The two landers were identical, so the same tests were carried out at two places on Mars' surface; Viking 1 near the equator and Viking 2 further north. The result was inconclusive, and is still disputed by some scientists.
Beagle 2.
"Beagle 2" was an unsuccessful British Mars lander that formed part of the European Space Agency's 2003 Mars Express mission. Its primary purpose was to search for signs of life on Mars, past or present. Although it landed safely, it was unable to correctly deploy its solar panels and telecom antenna.
EXPOSE.
EXPOSE is a multi-user facility mounted in 2008 outside the International Space Station dedicated to astrobiology. EXPOSE was developed by the European Space Agency (ESA) for long-term spaceflights that allows to expose organic chemicals and biological samples to outer space in low Earth orbit.
Mars Science Laboratory.
The Mars Science Laboratory (MSL) mission landed a rover that is currently in operation on Mars. It was launched 26 November 2011, and landed at Gale Crater on 6 August 2012. Mission objectives are to help assess Mars' habitability and in doing so, determine whether Mars is or has ever been able to support life, collect data for a future human mission, study Martian geology, its climate, and further assess the role that water, an essential ingredient for life as we know it, played in forming minerals on Mars.
ExoMars rover.
ExoMars is a robotic mission to Mars to search for possible biosignatures of Martian life, past or present. This astrobiological mission is currently under development by the European Space Agency (ESA) in partnership with the Russian Federal Space Agency (Roscosmos); it is planned for a 2018 launch.
Red Dragon.
Red Dragon is a planned series low-cost Mars lander missions that will utilize the SpaceX Falcon Heavy launch vehicle, and a modified Dragon V2 capsule to enter the Martian atmosphere and land using retrorockets. The lander's primary mission would be a technology demonstration, and to search for evidence of life on Mars (biosignatures), past or present. The concept had been meant to compete for funding on 2012/2013 as a NASA Discovery mission. On April 2016, SpaceX announced that they will proceed with the mission, with technical support from NASA, to be launched with a Falcon Heavy rocket in 2018. These Mars missions will also be pathfinders for the much larger SpaceX Mars colonization architecture that will be announced in September 2016.
Mars 2020.
The 'Mars 2020' rover mission is a concept under development by NASA with a possible launch in 2020. It is intended to investigate environments on Mars relevant to astrobiology, investigate its surface geological processes and history, including the assessment of its past habitability and potential for preservation of biosignatures and biomolecules within accessible geological materials. The Science Definition Team is proposing the rover collect and package at least 31 samples of rock cores and soil for a later mission to bring back for more definitive analysis in laboratories on Earth. The rover could make measurements and technology demonstrations to help designers of a human expedition understand any hazards posed by Martian dust and demonstrate how to collect carbon dioxide (CO2), which could be a resource for making molecular oxygen (O2) and rocket fuel.
Proposed concepts.
Icebreaker Life.
"Icebreaker Life" is a lander mission that is being proposed for NASA's Discovery Program for the 2018 launch opportunity. If selected and funded, the stationary lander would be a near copy of the successful 2008 "Phoenix" and it would carry an upgraded astrobiology scientific payload, including a 1-meter-long core drill to sample ice-cemented ground in the northern plains to conduct a search for organic molecules and evidence of current or past life on Mars. One of the key goals of the "Icebreaker Life" mission is to test the hypothesis that the ice-rich ground in the polar regions has significant concentrations of organics due to protection by the ice from oxidants and radiation.
Journey to Enceladus and Titan.
Journey to Enceladus and Titan (JET) is an orbiter astrobiology mission concept to assess the habitability potential of Saturn's moons Enceladus and Titan.
Enceladus Life Finder.
Enceladus Life Finder (ELF) is a proposed astrobiology mission concept for a space probe intended to assess the habitability of the internal aquatic ocean of Enceladus, Saturn's sixth-largest moon.
Life Investigation For Enceladus.
Life Investigation For Enceladus (LIFE) is a proposed astrobiology sample-return mission concept for Enceladus. The spacecraft would enter into Saturn orbit and enable multiple flybys through Enceladus' icy plumes to collect icy plume particles and volatiles and return them to Earth on a capsule. The spacecraft may sample Enceladus' plumes, the E ring of Saturn, and the Titan upper atmosphere.
Europa Multiple-Flyby Mission.
Europa Multiple-Flyby Mission is a mission planned by NASA for a 2025 launch that will conduct detailed reconnaissance of Jupiter's moon Europa and will investigate whether the icy moon could harbor conditions suitable for life. It will also aid in the selection of future landing sites.

</doc>
<doc id="2790" url="https://en.wikipedia.org/wiki?curid=2790" title="Air show">
Air show

An air show, (also airshow, Air Fair, or Air Tattoo) is a public event at which aviators display their flying skills and the capabilities of their aircraft to spectators, usually by means of aerobatics. Air shows without aerobatic displays, having only aircraft displayed parked on the ground, are called "static air shows".
Outline.
Some air shows are held as a business venture or as a trade event where aircraft, avionics and other services are promoted to potential customers. Many air shows are held in support of local, national or military charities. Military air firms often organise air shows at military airfields as a public relations exercise to thank the local community, promote military careers and raise the profile of the military.
Air show "seasons" vary around the world. The United States enjoys a long season that generally runs from March to November, covering the spring, summer, and fall seasons. Other countries often have much shorter seasons. The European season usually starts in late April or Early May and is usually over by mid October. The Middle East, Australia and New Zealand hold their events between January and March. However, for many acts, the "off-season" does not mean a period of inactivity; pilots and performers use this time for maintenance and practice.
The type of displays seen at an event are constrained by a number of factors, including the weather and visibility. Most aviation authorities now publish rules and guidance on minimum display heights and criteria for differing conditions. In addition to the weather, pilots and organizers must also consider local airspace restrictions. Most exhibitors will plan "full," "rolling" and "flat" display for varying weather and airspace conditions.
The types of shows vary greatly. Some are large scale military events with large flying displays and ground exhibitions while others held at small local airstrips can often feature just one or two hours of flying with just a few stalls on the ground. Air Displays can be held during day or night with the latter becoming increasingly popular. Shows don't always take place over airfields; some have been held over the grounds of stately homes or castles and over the sea at coastal resorts.
Attractions.
Before the Second World War, air shows were associated with long distance air races, often lasting many days and covering thousands of miles. While the Reno Air Races keep this tradition alive, most air shows today primarily feature a series of aerial demos of short duration.
Most air shows feature warbirds, aerobatics, and demonstrations of modern military aircraft, and many air shows offer a variety of other aeronautical attractions as well, such as wing-walking, radio-controlled aircraft, water/slurry drops from firefighting aircraft, simulated helicopter rescues and sky diving.
Specialist aerobatic aircraft have powerful piston engines, light weight and big control surfaces, making them capable of very high roll rates and accelerations. A skilled pilot will be able to climb vertically, perform very tight turns, tumble his aircraft end-over-end and perform manoeuvres during loops.
Solo military jet demos, also known as tactical demo, feature one aircraft, usually a strike fighter or an advanced trainer. The demonstration focuses on the capabilities of modern aircraft used in combat operations. The display will usually demonstrate the aircraft's very short (and often very loud) takeoff rolls, fast speeds, slow approach speeds, as well as their ability to quickly make tight turns, to climb quickly, and their ability to be precisely controlled at a large range of speeds. Manoeuvres include aileron rolls, barrel rolls, hesitation rolls, Cuban-8s, tight turns, high-alpha flight, a high-speed pass, double Immelmans, and touch-and-gos. Tactical demos may include simulated bomb drops, sometimes with pyrotechnics on the ground for effect. Aircraft with special characteristics that give them unique capabilities will often display those in their demos; For example, Russian fighters with Thrust vectoring may be used to perform Pugachev's Cobra or the Kulbit, among other difficult manoeuvers that cannot be performed by other aircraft. Similarly, an F-22 pilot may hover his jet in the air with the nose pointed straight up, a Harrier or Osprey pilot may perform a vertical landing or vertical takeoff, and so on.
Safety.
Air shows may present some risk to spectators and aviators. Accidents have occurred, sometimes with a large loss of life, such as the 1988 disaster at Ramstein Air Base in Germany and the 2002 air show crash at Lviv, Ukraine. Because of these accidents, the various aviation authorities around the world have created set rules and guidance for those running and participating in air displays. Air displays are often monitored by aviation authorities to ensure safe procedures.
In the United Kingdom, local authorities will first need to approve any application for an event to which the public is admitted. No approval, no event. The first priority must be to arrange insurance cover and details can be obtained from your local authority. An added complication is a whole new raft of legislation concerning Health & Safety in particular Corporate Manslaughter, which can involve the event organiser being charged with a criminal offence if any of the insurances and risk assessments are not fully completed well in advance of the event. If this very basic step isn't completed then any further activity should be halted until it is.
Rules govern the distance from the crowds that aircraft must fly. These vary according to the rating of the pilot/crew, the type of aircraft and the way the aircraft is being flown. For instance, slower lighter aircraft are usually allowed closer and lower to the crowd than larger, faster types. Also, a fighter jet flying straight and level will be able to do so closer to the crowd and lower than if it were performing a roll or a loop.
Pilots can get authorizations for differing types of displays (i.e. limbo flying, basic aerobatics to unlimited aerobatics) and to differing minimum base heights above the ground. To gain such authorizations, the pilots will have to demonstrate to an examiner that they can perform to those limits without endangering themselves, ground crew or spectators.
Despite display rules and guidances, accidents have continued to happen. However, air show accidents are rare and where there is proper supervision air shows have impressive safety records. Each year, organisations such as International Council of Air Shows and European Airshow Council meet and discuss various subjects including air show safety where accidents are discussed and lessons learnt.

</doc>
