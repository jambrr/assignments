<doc id="2388" url="https://en.wikipedia.org/wiki?curid=2388" title="Antidepressant">
Antidepressant

Antidepressants are drugs used for the treatment of major depressive disorder and other conditions, including dysthymia, anxiety disorders, obsessive compulsive disorder, eating disorders, chronic pain, neuropathic pain and, in some cases, dysmenorrhoea, snoring, migraine, attention-deficit hyperactivity disorder (ADHD), addiction, dependence, and sleep disorders. They can be used alone or in combination with other medications but only when prescribed.
The most important classes of antidepressants are the selective serotonin reuptake inhibitors (SSRIs), serotonin–norepinephrine reuptake inhibitors (SNRIs), tricyclic antidepressants (TCAs), monoamine oxidase inhibitors (MAOIs), reversible monoamine oxidase A inhibitors (rMAO-A inhibitors), tetracyclic antidepressants (TeCAs), and noradrenergic and specific serotonergic antidepressant (NaSSAs). St John's wort is also used in the treatment of depression.
Medical uses.
For depression, the Hamilton Depression Rating Scale (HAM-D) is often used to measure the severity of depression. The maximum score for the 17-item HAM-D questionnaire is 52; the higher the score, the more severe the depression.
Major depressive disorder.
Clinical guidelines.
The UK National Institute for Health and Care Excellence (NICE) 2009 guidelines indicate that antidepressants should not be routinely used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressant treatment should be considered for:
The guidelines further note that antidepressant treatment should be used in combination with psychosocial interventions in most cases, should be continued for at least 6 months to reduce the risk of relapse, and that SSRIs are typically better tolerated than other antidepressants.
American Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors that include severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned.
Systematic reviews.
Conflicting results have arisen from studies analyzing the efficacy of antidepressants by comparisons to placebo in people with acute mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.
Researchers Irving Kirsch and Thomas Moore have contested the pharmacological activity of antidepressants in the relief of depression, and state that the evidence is most consistent a role as active placebos. Their study consisted of a meta analysis incorporating data from both published studies and unpublished data obtained from the FDA via a Freedom of Information Act request. Overall, antidepressant pills worked 18% better than placebos, a statistically significant difference, but not one that is clinically significant. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance.
Another study focusing on paroxetine (Paxil) and imipramine found that antidepressant drugs were only slightly better than placebo in cases of mild or moderate depression they surveyed but offered "substantial" benefit in those with severe depression.
In 2014 the U.S. FDA published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.
A review commissioned by the National Institute for Health and Care Excellence concluded that there is strong evidence that SSRIs have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. The treatment guidelines developed in conjunction with this review suggest that antidepressants should be considered in patients with moderate to severe depression and those with mild depression that is persistent or resistant to other treatment modalities.
The Cochrane Collaboration recently performed a systematic review of clinical trials of the tricyclic antidepressant amitriptyline. The study concluded that in spite of moderate evidence for publication bias, there is strong evidence that the efficacy of amitriptyline is superior to placebo.
A 2015 systematic review of add-on therapies for treatment-resistant depression concluded that quetiapine and aripiprazole have the strongest evidence-base supporting their efficacy, but they are associated with additional treatment-related side effects when used as an add-on therapy.
A 2008 Cochrane Collaboration review on St John's wort (specifically, any extracts which contain "hypericum perforatum"), and a 2015 meta-analytic systematic review by some of the same authors, both concluded that it: has superior efficacy to placebo in treating depression; is as effective as standard antidepressant pharmaceuticals for treating depression; and has fewer adverse effects than other antidepressants. The 2015 meta analysis concluded that it is difficult to assign a place for St. John's wort in the treatment of depression owing to limitations in the available evidence base, including large variations in efficacy seen in trials performed in German-speaking relative to other countries. Reversible monoamine oxidase A inhibitors (rMAO-A inhibitors) have also been shown to be an effective drug therapy with greater tolerability than other antidepressants; however, the efficacy of SSRIs, tricyclic, and tetracyclic antidepressants in treating depression is supported by a much larger evidence base compared to other antidepressant drug therapies (i.e., St John's wort, rMAO-A inhibitors, serotonin–norepinephrine reuptake inhibitor, serotonin antagonist and reuptake inhibitors, noradrenaline reuptake inhibitors, and noradrenergic and specific serotonergic antidepressants).
A study published in the "Journal of the American Medical Association" ("JAMA") demonstrated that the magnitude of the placebo effect in clinical trials of depression have been growing over time, while the effect size of tested drugs has remained relatively constant. The authors suggest that one possible explanation for the growing placebo effect in clinical trials is the inclusion of larger number of participants with shorter term, mild, or spontaneously remitting depression as a result of decreasing stigma associated with antidepressant use. Placebo response rates in clinical trials of complementary and alternative (CAM) therapies are significantly lower than those in clinical trials of traditional antidepressants.
A 2004 review concluded that antidepressant studies that failed to support efficacy claims were dramatically less likely to be published than those that did support favorable efficacy claims. Similar results were obtained for a study of publication of clinical trials of antidepressants in children. A 2015 investigation of meta-analyses of antidepressant studies found that 79% of them had "sponsorship or authors who were (pharmacutical) industry employees and/or had conflicts of interest".
A 2012 meta-analysis found that fluoxetine and venlafaxine were effective for major depression in all age groups. The authors also found no evidence of a relationship between baseline severity of depression and degree of benefit of antidepressants over placebo.
The STAR*D Trial.
The largest and most expensive study conducted to date, on the effectiveness of pharmacological treatment for depression, was commissioned by the National Institute of Mental Health. The study was dubbed "The Sequenced Treatment Alternatives to Relieve Depression" (STAR*D) Study. The results are summarized here.
Participants in the trial were recruited when they sought medical care at general medical or psychiatric clinics. No advertising was used to recruit subjects in order to maximize the generalizability of the study results. Participants were required to have a minimum score of 14 point on the Hamilton Depression Scale (HAM-D17) in order to be enrolled in the trial. Generally accepted cutoffs are 7–17 points for mild depression, 18–24 points for moderate depression, and ≥ 24 for severe depression. The average participant baseline HAM-D17 score was 22. The pre-specified primary endpoint of this trial was remission as determined by the HAM-D score, with all patients with missing scores rated as non-responders. In the aftermath of the trial, the investigators have presented the results mainly using the secondary endpoint of remission according to the QIDS-SR16 Score, which tend to be somewhat higher.
There were no statistical or meaningful clinical differences in remission rates, response rates, or times to remission or response among any of the medications compared in this study. These included bupropion sustained release, bupropion, citalopram, lithium, mirtazapine, nortriptyline, sertraline, triiodothyronine, tranylcypromine, and venlafaxine extended release.
A 2008 review of randomized controlled trials concluded that symptomatic improvement with SSRIs was greatest by the end of the first week of use, but that some improvement continued for at least 6 weeks.
Limitations and strategies.
Between 30% and 50% of individuals treated with a given antidepressant do not show a response. In clinical studies, approximately one-third of patients achieve a full remission, one-third experience a response and one-third are nonresponders. Partial remission is characterized by the presence of poorly defined residual symptoms. These symptoms typically include depressed mood, psychic anxiety, sleep disturbance, fatigue and diminished interest or pleasure. It is currently unclear which factors predict partial remission. However, it is clear that residual symptoms are powerful predictors of relapse, with relapse rates 3–6 times higher in patients with residual symptoms than in those who experience full remission. In addition, antidepressant drugs tend to lose efficacy over the course of treatment. According to data from the Centers for Disease Control and Prevention, less than one-third of Americans taking one antidepressant medication have seen a mental health professional in the previous year. A number of strategies are used in clinical practice to try to overcome these limits and variations. They include switching medication, augmentation, and combination.
"Trial and error" switching.
The American Psychiatric Association 2000 Practice Guideline advises that where no response is achieved following six to eight weeks of treatment with an antidepressant, to switch to an antidepressant in the same class, then to a different class of antidepressant.
A 2006 meta-analysis review found wide variation in the findings of prior studies; for patients who had failed to respond to an SSRI antidepressant, between 12% and 86% showed a response to a new drug. However, the more antidepressants an individual had already tried, the less likely they were to benefit from a new antidepressant trial. However, a later meta-analysis found no difference between switching to a new drug and staying on the old medication; although 34% of treatment resistant patients responded when switched to the new drug, 40% responded without being switched.
Augmentation and combination.
For a partial response, the American Psychiatric Association guidelines suggest augmentation, or adding a drug from a different class. These include lithium and thyroid augmentation, dopamine agonists, sex steroids, NRIs, glucocorticoid-specific agents, or the newer anticonvulsants.
A combination strategy involves adding another antidepressant, usually from a different class so as to have effect on other mechanisms. Although this may be used in clinical practice, there is little evidence for the relative efficacy or adverse effects of this strategy. Other tests recently conducted include the use of psychostimulants as an augmentation therapy. Several studies have shown the efficacy of combining modafinil to treatment-resistant patients. It has been used to help combat SSRI-associated fatigue.
Long-term use.
The therapeutic effects of antidepressants typically do not continue once the course of medication ends, resulting in a high rate of relapse. A recent meta-analysis of 31 placebo-controlled antidepressant trials, mostly limited to studies covering a period of one year, found that 18% of patients who had responded to an antidepressant relapsed while still taking it, compared to 41% whose antidepressant was switched for a placebo.
A gradual loss of therapeutic benefit occurs in a minority of people during the course of treatment. A strategy involving the use of pharmacotherapy in the treatment of the acute episode, followed by psychotherapy in its residual phase, has been suggested by some studies.
Comparative efficacy and tolerability.
Comparative efficacy and tolerability table
Where:
"For adverse effects/overdose toxicity"
4 means very strong effect/extreme toxicity.
3 strong effect; efficacious/high toxicity.
2 moderate effect/moderately toxic.
1 weak effect/weakly toxic.
v very weak/negligible effect
"For tolerability"
4 extremely tolerable. These drugs have proven to be better tolerated than the SSRIs.
3 very tolerable ? few, mild and transient side effects. These are drugs such as the SSRIs.
2 moderately tolerable. Some of the more tolerable of TCAs.
1 poor tolerability. TCAs and MAOIs mostly.
"For efficacy"
3 Superior efficacy drug, according to at least one review article.
2 Ordinary efficacy drug. Maybe some primary sources indicate superior efficacy relative to superior efficacy agents (e.g. agomelatine has shown superior efficacy to venlafaxine in one clinical trial) but insufficient data to say with much confidence.
1 Inferior efficacy compared to ordinary efficacy drugs, according to at least one review article.
Acronyms/terms used in the above table:
Activating effects – adverse effects such as agitation, anxiety, insomnia and tremor.
AMH – Australian Medicines Handbook.
GI – Gastrointestinal.
Inactivating effects – sedating effects such as drowsiness, somnolence and sedation.
IR – Immediate release tablets.
ND – No data.
Ortho hypot – Orthostatic hypotension
QTc i. p. – QTc interval prolongation
SD – Sexual dysfunction.
XR – Extended release tablets.
PER DRUG NOTES: 
Tricyclic antidepressants (TCAs)
Amitriptyline:
Preferentially (8x over norepinephrine) inhibits the reuptake of serotonin but norepinephrine reuptake inhibition is clinically significant. Listed as a more hepatotoxic antidepressant in a recent review article.
Amoxapine:
Sometimes classed with the tetracyclic antidepressants. Has atypical antipsychotic actions too. Not available in Australia, Canada or the UK but available in the US. May be faster acting. Antidopaminergic, which means that it can cause extrapyramidal side effects, tardive dyskinesia and neuroleptic malignant syndrome. Causes kidney failure and seizures in overdose, although it usually does not cause cardiotoxic effects in overdose.
Clomipramine:
Highly selective (~120x) for serotonin reuptake inhibition. More epileptogenic than other TCAs.
Desipramine:
Preferentially inhibits the reuptake of norepinephrine (22x over serotonin).
Dosulepin (Dothiepin):
Not available in the US. Available in Australia (where it is still commonly referred to as dothiepin) and the UK.
Weight gain: probably 2
Danger in overdose: 4 
Doxepin:
Somewhat selective for inhibiting norepinephrine reuptake (2.3x over serotonin).
Imipramine:
First marketed TCA. Somewhat selective for serotonin reuptake (26x over norepinephrine).
Relative efficacy: 3 More hepatotoxic than most other antidepressants.
Lofepramine:
Not licensed in Australia, US or Canada. Licensed in the UK and other European countries.
QTc i. p.: 1 (dose-dependent)
Maprotiline:
Fairly selective (~90x over dopamine) norepinephrine reuptake inhibitor.
Nortriptyline:
Active metabolite of amitriptyline. Somewhat selective (4.2x) for norepinephrine reuptake inhibition.
Protriptyline:
Relatively (14x over serotonin) selective norepinephrine reuptake inhibition.
Tianeptine:
Enhances the reuptake of serotonin and increases dopaminergic and glutamatergic neurotransmission. Not approved for clinical use in Australia, Canada, the UK, the US and Ireland. More hepatotoxic than most other antidepressants.
Trimipramine:
Has antidopaminergic effects and hence can cause extrapyramidal side effects, tardive dyskinesia and neuroleptic malignant syndrome.
Monoamine oxidase inhibitors (MAOIs)
Isocarboxazid:
Not licensed for use in Australia.
Moclobemide:
Only clinically utilized reversible inhibitor of monoamine oxidase A (RIMA). Not approved for use in the US. Approved for clinical use in Australia, Canada, most European countries (including the Czech Republic, Finland and Ireland), New Zealand, Singapore, South Africa and the UK.
Activating effects: ? (insomnia common according to the AMH)
Phenelzine:
Phenelzine is more prone than tranylcypromine and most other antidepressant to causing liver damage.
Seligiline:
Originally used a treatment for Parkinson's disease due to its selective, irreversible inhibition of MAO-B but at higher doses MAO-A inhibition occurs.
Tranylcypromine:
Metabolized into amphetamine analogues "in vivo". Can cause liver damage.
Selective serotonin reuptake inhibitors (SSRIs)
Citalopram:
Most likely of the SSRIs to prolong the QT interval. Also the most toxic SSRI in overdose. Less hepatotoxic than most other antidepressants.
QTc i. p.: 2 (dose dependent; doses >40 mg/day are particularly dangerous)
Escitalopram:
The more active S-enantiomer of citalopram. May be the most efficacious of the SSRIs (although no statistically significant difference between the efficacy of sertraline and escitalopram have been teased out to date). Based on the available evidence it is less toxic than its racemic counterpart, (R,S)-citalopram, in overdose. Less hepatotoxic than most other antidepressants.
Fluoxetine:
First SSRI to receive FDA approval in 1987. Some studies have shown slight (often statistically insignificant) weight reductions in those on fluoxetine. Has the longest net half-life (taking into account the effects of its active metabolite, norfluoxetine) of any antidepressant clinically used, and consequently, when abruptly stopped, withdrawal effects are usually mild and rare. Dermatologic reactions are more common than with sertraline.
Fluvoxamine:
Not FDA approved for major depression; FDA approved for OCD. Has the highest affinity of any SSRI towards the sigma-1 receptor at which it serves as an agonist. Less hepatotoxic than most other antidepressants.
Paroxetine:
Only SSRI that's not Australian pregnancy category C but is rather category D due to an increased risk of Persistent Pulmonary Hypertension of the Newborn. The FDA of the US has placed it in category D. It is associated with a higher risk of sexual dysfunction, weight gain, anticholinergic side effects and drowsiness than the other SSRIs. Has a short half life compared to other SSRIs and hence is the most prone to causing withdrawal effects whenever a dose is missed. Paroxetine has the lowest affinity for the sigma-1 receptors of all the SSRIs. It also possesses the highest propensity of any SSRI for causing extrapyramidal symptoms. Less hepatotoxic than most other antidepressants.
Sertraline:
Highest risk of psychiatric side effects (e.g. mania, suicidal behavior/ideation, psychosis, etc.) Has slight (but clinically significant) inhibitory effects on dopamine reuptake. Has the second highest affinity of the SSRIs towards the sigma-1 receptor where it may serve as a sigma-1 receptor antagonist.
GI toxicity: 2 (mostly diarrhoea)
Serotonin-norepinephrine reuptake inhibitors (SNRIs)
Desvenlafaxine:
Active metabolite of venlafaxine.
Duloxetine:
Unlike the other SNRIs listed here duloxetine does not cause dose-dependent hypertension as a common adverse effect. Used to relieve neuropathic pain too. More hepatotoxic than most other antidepressants.
Milnacipran:
Primarily used as a treatment for neuropathic pain.
Danger in overdose: ? (No single-drug fatal overdoses reported yet)
Venlafaxine:
Relatively selective (116x) for serotonin reuptake inhibition over norepinephrine.
GI toxicity: 2 (IR) / 1 (XR)
Noradrenergic and specific serotonergic antidepressants (NaSSAs)
Mianserin:
Not licensed for use in the US and Canada. Licensed for use in Australia and the UK. Can cause blood dyscrasias (including agranulocytosis) and consequently both the BNF and AMH recommend regular complete blood count monitoring.
Mirtazapine:
Licensed for use in the US, UK, Australia and Canada. Mianserin's successor and analogue.
Serotonin antagonist and reuptake inhibitors (SARIs)
Nefazodone:
Risk of hepatotoxicity. Available in the US but not in Canada, Australia or Europe.
Trazodone:
Not available in Australia. More hepatotoxic than other antidepressants.
Relative efficacy: 2 
Serotonin modulator and stimulators (SMSs)
Vilazodone:
Potential for serotonin syndrome as an adverse effect.
Danger in overdose: ? (probably low aside from an increased risk of serotonin syndrome)
Vortioxetine:
Introduced to the US market in September 2013 and hence data on its adverse effects may be lagging behind. Serotonin syndrome is a possible (rare) adverse effect.
Other
Agomelatine:
Not licensed in the US or Canada. Licensed in Australia and the UK.
Relative efficacy: 2 
Bupropion:
Only licensed in the UK and Australia as a smoking cessation aid, but in the US it is licensed for the treatment of major depressive disorder. More hepatotoxic than most other antidepressants.
Reboxetine:
Not licensed in the US or Canada. Licensed in Australia and the UK.
St John's wort:
Not a prescription drug in most countries; available as an over-the-counter herbal supplement.
Anxiety disorders.
Generalized anxiety disorder.
Antidepressants are recommended by the National Institute for Health and Care Excellence (NICE) for the treatment of generalized anxiety disorder (GAD) that has failed to respond to conservative measures such as education and self-help activities. GAD is a common disorder of which the central feature is excessive worry about a number of different events. Key symptoms include excessive anxiety about multiple events and issues, and difficulty controlling worrisome thoughts that persists for at least 6 months.
Antidepressants provide a modest-to-moderate reduction in anxiety in GAD, and are superior to placebo in treating GAD. The efficacy of different antidepressants is similar.
Obsessive-compulsive disorder.
SSRIs are a second-line treatment of adult obsessive-compulsive disorder (OCD) with mild functional impairment and as first-line treatment for those with moderate or severe impairment. In children, SSRIs can be considered as a second-line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs are efficacious in the treatment of OCD; patients treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term treatment trials of 6 to 24 weeks and in discontinuation trials of 28 to 52 weeks duration.
Eating disorders.
Antidepressants are recommended as an alternative or additional first step to self-help programs in the treatment of bulimia nervosa. SSRIs (fluoxetine in particular) are preferred over other antidepressants due to their acceptability, tolerability, and superior reduction of symptoms in short-term trials. Long-term efficacy remains poorly characterized. Bupropion is not recommended for the treatment of eating disorders due to an increased risk of seizure.
Similar recommendations apply to binge eating disorder. SSRIs provide short-term reductions in binge eating behavior, but have not been associated with significant weight loss.
Clinical trials have generated mostly negative results for the use of SSRIs in the treatment of anorexia nervosa. Treatment guidelines from the National Institute of Health and Care Excellence recommend against the use of SSRIs in this disorder. Those from the American Psychiatric Association note that SSRIs confer no advantage regarding weight gain, but that they may be used for the treatment of co-existing depressive, anxiety, or obsessive-compulsive disorders.
Pain.
Fibromyalgia.
A 2012 meta-analysis concluded that antidepressants treatment favorably affects pain, health-related quality of life, depression, and sleep in fibromyalgia syndrome. Tricyclics appear to be the most effective class, with moderate effects on pain and sleep and small effects on fatigue and health-related quality of life. The fraction of people experiencing a 30% pain reduction on tricyclics was 48% versus 28% for placebo. For SSRIs and SNRIs the fraction of people experiencing a 30% pain reduction was 36% (20% in the placebo comparator arms) and 42% (32% in the corresponding placebo comparator arms). Discontinuation of treatment due to side effects was common. Antidepressants including amitriptyline, fluoxetine, duloxetine, milnacipran, moclobemide, and pirlindole are recommended by the European League Against Rheumatism (EULAR) for the treatment of fibromyalgia based on "limited evidence".
Neuropathic pain.
A 2014 meta-analysis from the Cochrane Collaboration found the antidepressant duloxetine effective for the treatment of pain resulting from diabetic neuropathy. The same group reviewed data for amitryptyline in the treatment of neuropathic pain and found limited useful randomized clinical trial data, but concluded that the long history of successful use in the community for the treatment of fibromyalgia and neuropathic pain justified its continued use.
Adverse effects.
Difficulty tolerating adverse effects is the most common reason for antidepressant discontinuation.
General.
Almost any medication involved with serotonin regulation has the potential to cause serotonin toxicity (also known as "serotonin syndrome") an excess of serotonin that can induce mania, restlessness, agitation, emotional lability, insomnia and confusion as its primary symptoms. Although the condition is serious, it is not particularly common, generally only appearing at high doses or while on other medications. Assuming proper medical intervention has been taken (within about 24 hours) it is rarely fatal.
MAOIs tend to have pronounced (sometimes fatal) interactions with a wide variety of medications and over-the-counter drugs. If taken with foods that contain very high levels of tyramine (e.g., mature cheese, cured meats, or yeast extracts), they may cause a potentially lethal hypertensive crisis. At lower doses the person may be bothered by only a headache due to an increase in blood pressure.
In response to these adverse effects, a different type of MAOI has been developed: the reversible inhibitor of monoamine oxidase A (RIMA) class of drugs. Their primary advantage is that they do not require the person to follow a special diet, while being purportedly effective as SSRIs and tricyclics in treating depressive disorders.
Pregnancy.
SSRI use in pregnancy has been associated with a variety of risks with varying degrees of proof of causation. As depression is independently associated with negative pregnancy outcomes, determining the extent to which observed associations between antidepressant use and specific adverse outcomes reflects a causative relationship has been difficult in some cases. In other cases, the attribution of adverse outcomes to antidepressant exposure seems fairly clear.
SSRI use in pregnancy is associated with an increased risk of spontaneous abortion of about 1.7-fold, and is associated with preterm birth and low birth weight.
A systematic review of the risk of major birth defects in antidepressant-exposed pregnancies found a small increase (3% to 24%) in the risk of major malformations and a risk of cardiovascular birth defects that did not differ from non-exposed pregnancies. A study of fluoxetine-exposed pregnancies found a 12% increase in the risk of major malformations that just missed statistical significance. Other studies have found an increased risk of cardiovascular birth defects among depressed mothers not undergoing SSRI treatment, suggesting the possibility of ascertainment bias, e.g. that worried mothers may pursue more aggressive testing of their infants. Another study found no increase in cardiovascular birth defects and a 27% increased risk of major malformations in SSRI exposed pregnancies. The FDA advises for the risk of birth defects with the use of paroxetine and the MAOI should be avoided.
A 2013 systematic review and meta-analysis found that antidepressant use during pregnancy was statistically significantly associated with some pregnancy outcomes, such as gestational age and preterm birth, but not with other outcomes. The same review cautioned that because differences between the exposed and unexposed groups were small, it was doubtful whether they were clinically significant.
A neonate (infant less than 28 days old) may experience a withdrawal syndrome from abrupt discontinuation of the antidepressant at birth. Antidepressants have been shown to be present in varying amounts in breast milk, but their effects on infants are currently unknown.
Moreover, SSRIs inhibit nitric oxide synthesis, which plays an important role in setting vascular tone. Several studies have pointed to an increased risk of prematurity associated with SSRI use, and this association may be due to an increase risk of pre-eclampsia of pregnancy.
Antidepressant-induced mania.
Another possible problem with antidepressants is the chance of antidepressant-induced mania in patients with bipolar disorder. Many cases of bipolar depression are very similar to those of unipolar depression. Therefore, the patient can be misdiagnosed with unipolar depression and be given antidepressants. Studies have shown that antidepressant-induced mania can occur in 20–40% of bipolar patients. For bipolar depression, antidepressants (most frequently SSRIs) can exacerbate or trigger symptoms of hypomania and mania.
Suicide.
Studies have shown that the use of antidepressants is correlated with an increased risk of suicidal behaviour and thinking (suicidality) in those aged under 25. This problem has been serious enough to warrant government intervention by the US Food and Drug Administration (FDA) to warn of the increased risk of suicidality during antidepressant treatment. According to the FDA, the heightened risk of suicidality is within the first one to two months of treatment. The National Institute for Health and Care Excellence (NICE) places the excess risk in the "early stages of treatment". A meta-analysis suggests that the relationship between antidepressant use and suicidal behavior or thoughts is age-dependent. Compared to placebo the use of antidepressants is associated with an increase in suicidal behavior or thoughts among those aged under 25 (OR=1.62). This increase in suicidality approaches that observed in children and adolescents. There is no effect or possibly a mild protective effect among those aged 25 to 64 (OR=0.79). Antidepressant treatment has a protective effect against suicidality among those aged 65 and over (OR=0.37).
Sexual.
Sexual side-effects are also common with SSRIs, such as loss of sexual drive, failure to reach orgasm, and erectile dysfunction. Although usually reversible, these sexual side-effects can, in rare cases, last for months or years after the drug has been completely withdrawn.
In a study of 1022 outpatients, overall sexual dysfunction with all antidepressants averaged 59.1% with SSRIs values between 57 and 73%, mirtazapine 24%, nefazodone 8%, amineptine 7% and moclobemide 4%. Moclobemide, a selective reversible MAO-A inhibitor, does not cause sexual dysfunction, and can actually lead to an improvement in all aspects of sexual function.
Biochemical mechanisms suggested as causative include increased serotonin, particularly affecting 5-HT2 and 5-HT3 receptors; decreased dopamine; decreased norepinephrine; blockade of cholinergic and α1adrenergic receptors; inhibition of nitric oxide synthetase; and elevation of prolactin levels. Mirtazapine is reported to have fewer sexual side-effects, most likely because it antagonizes 5-HT2 and 5-HT3 receptors and may, in some cases, reverse sexual dysfunction induced by SSRIs by the same mechanism.
Bupropion, a weak NDRI and nicotinic antagonist, may be useful in treating reduced libido as a result of SSRI treatment.
Changes in weight.
Changes in appetite or weight are common among antidepressants, but largely drug-dependent and are related to which neurotransmitters they affect. Mirtazapine and paroxetine, for example, have the effect of weight gain and/or increased appetite, while others (such as bupropion and venlafaxine) achieve the opposite effect.
The antihistaminic properties of certain TCA- and TeCA-class antidepressants have been shown to contribute to the common side-effects of increased appetite and weight gain associated with these classes of medication.
Discontinuation syndrome.
Antidepressant discontinuation symptoms were first reported with imipramine, the first tricyclic antidepressant (TCA), in the late 1950s, and each new class of antidepressants has brought reports of similar conditions, including monoamine oxidase inhibitors (MAOIs), SSRIs, and SNRIs. As of 2001, at least 21 different antidepressants, covering all the major classes, were known to cause discontinuation syndromes. The problem has been poorly studied, and most of the literature has been case reports or small clinical studies; incidence is hard to determine and controversial.
People with discontinuation syndrome have been on an antidepressant for at least four weeks and have recently stopped taking the medication, either abruptly or after a fast taper. Common symptoms include flu-like symptoms (nausea, vomiting, diarrhea, headaches, sweating), sleep disturbances (insomnia, nightmares, constant sleepiness), sensory/movement disturbances (imbalance, tremors, vertigo, dizziness, electric-shock-like experiences), mood disturbances (dysphoria, anxiety, agitation) and cognitive disturbances (confusion and hyperarousal). Over fifty symptoms have been reported.
Most cases of discontinuation syndrome last between one and four weeks, are relatively mild, and resolve on their own; in rare cases symptoms can be severe or extended. Paroxetine and venlafaxine seem to be particularly difficult to discontinue and prolonged withdrawal syndrome lasting over 18 months have been reported with paroxetine.
With the explosion of use and interest in SSRIs in the late 1980s and early 1990s, focused especially on Prozac, interest grew as well in discontinuation syndromes. In the late 1990s, some investigators thought that symptoms that emerged when antidepressants were discontinued, might mean that antidepressants were causing addiction, and some used the term "withdrawal syndrome" to describe the symptoms. Addictive substances cause physiological dependence, so that drug withdrawal causes suffering. These theories were abandoned, since addiction leads to drug-seeking behavior, and people taking antidepressants do not exhibit drug-seeking behavior. The term "withdrawal syndrome" is no longer used with respect to antidepressants, to avoid confusion with problems that arise from addiction. There are case reports of antidepressants being abused, but these are rare and are mostly limited to antidepressants with stimulant effects and to people who already had a substance use disorder. A 2012 comparison of the effects of stopping therapy with benzodiazepines and SSRIs argued that because the symptoms are similar, it makes no sense to say that benzodiazepines are addictive while SSRIs are not. Responses to that review noted that there is no evidence that people who stop taking SSRIs exhibit drug-seeking behavior while people who stop taking benzodiazepines do, and that the drug classes should be considered differently.
Pharmacology.
The earliest and probably most widely accepted scientific theory of antidepressant action is the monoamine hypothesis (which can be traced back to the 1950s), which states that depression is due to an imbalance (most often a deficiency) of the monoamine neurotransmitters (namely serotonin, norepinephrine and dopamine). It was originally proposed based on the observation that certain hydrazine anti-tuberculosis agents produce antidepressant effects, which was later linked to their inhibitory effects on monoamine oxidase, the enzyme that catalyses the breakdown of the monoamine neurotransmitters. All currently marketed antidepressants have the monoamine hypothesis as their theoretical basis, with the possible exception of agomelatine which acts on a dual melatonergic-serotonergic pathway. Despite the success of the monoamine hypothesis it has a number of limitations: for one, all monoaminergic antidepressants have a delayed onset of action of at least a week; and secondly, there are a sizeable portion (>40%) of depressed patients that do not adequately respond to monoaminergic antidepressants. A number of alternative hypotheses have been proposed, including the glutamate, neurogenic, epigenetic, cortisol hypersecretion and inflammatory hypotheses.
Types.
Selective serotonin reuptake inhibitors.
Selective serotonin reuptake inhibitors (SSRIs) are believed to increase the extracellular level of the neurotransmitter serotonin by limiting its reabsorption into the presynaptic cell, increasing the level of serotonin in the synaptic cleft available to bind to the postsynaptic receptor. They have varying degrees of selectivity for the other monoamine transporters, with pure SSRIs having only weak affinity for the norepinephrine and dopamine transporters.
SSRIs are the most widely prescribed antidepressants in many countries. The efficacy of SSRIs in mild or moderate cases of depression has been disputed.
Serotonin-norepinephrine reuptake inhibitors.
Serotonin-norepinephrine reuptake inhibitors (SNRIs) are potent inhibitors of the reuptake of serotonin and norepinephrine. These neurotransmitters are known to play an important role in mood. SNRIs can be contrasted with the more widely used selective serotonin reuptake inhibitors (SSRIs), which act upon serotonin alone.
The human serotonin transporter (SERT) and norepinephrine transporter (NET) are membrane proteins that are responsible for the reuptake of serotonin and norepinephrine. Balanced dual inhibition of monoamine reuptake can possibly offer advantages over other antidepressants drugs by treating a wider range of symptoms.
SNRIs are sometimes also used to treat anxiety disorders, obsessive-compulsive disorder (OCD), attention deficit hyperactivity disorder (ADHD), chronic neuropathic pain, and fibromyalgia syndrome (FMS), and for the relief of menopausal symptoms.
Serotonin modulators and stimulators.
Serotonin modulator and stimulators (SMSs), sometimes referred to more simply as serotonin modulators, are a type of drug with a multimodal action specific to the serotonin neurotransmitter system. To be precise, SMSs simultaneously modulate one or more serotonin receptors and inhibit the reuptake of serotonin. The term was created to describe the mechanism of action of the serotonergic antidepressant vortioxetine (Brintellix/Trintellix), which acts as a serotonin reuptake inhibitor (SRI), partial agonist of the 5-HT1A receptor, and antagonist of the 5-HT3 and 5-HT7 receptors. However, it can also technically be applied to vilazodone (Viibryd), which is an antidepressant as well and acts as an SRI and 5-HT1A receptor partial agonist.
An alternative term is serotonin partial agonist/reuptake inhibitor (SPARI), which can be applied only to vilazodone.
Serotonin antagonists and reuptake inhibitors.
Serotonin antagonist and reuptake inhibitors (SARIs) while mainly used as antidepressants, are also anxiolytics and hypnotics. They act by antagonizing serotonin receptors such as 5-HT2A and inhibiting the reuptake of serotonin, norepinephrine, and/or dopamine. Additionally, most also act as α1-adrenergic receptor antagonists. The majority of the currently marketed SARIs belong to the phenylpiperazine class of compounds.
Norepinephrine reuptake inhibitors.
Norepinephrine reuptake inhibitors (NRIs or NERIs) are a type of drug that acts as a reuptake inhibitor for the neurotransmitter norepinephrine (noradrenaline) by blocking the action of the norepinephrine transporter (NET). This in turn leads to increased extracellular concentrations of norepinephrine.
NRIs are commonly used in the treatment of conditions like ADHD and narcolepsy due to their psychostimulant effects and in obesity due to their appetite suppressant effects. They are also frequently used as antidepressants for the treatment of major depressive disorder, anxiety and panic disorder. Additionally, many drugs of abuse such as cocaine and methylphenidate possess NRI activity, though it is important to mention that NRIs without combined dopamine reuptake inhibitor (DRI) properties are not significantly rewarding and hence are considered to have a negligible abuse potential. However, norepinephrine has been implicated as acting synergistically with dopamine when actions on the two neurotransmitters are combined (e.g., in the case of NDRIs) to produce rewarding effects in psychostimulant drugs of abuse.
Tricyclic antidepressants.
The majority of the tricyclic antidepressants (TCAs) act primarily as serotonin-norepinephrine reuptake inhibitors (SNRIs) by blocking the serotonin transporter (SERT) and the norepinephrine transporter (NET), respectively, which results in an elevation of the synaptic concentrations of these neurotransmitters, and therefore an enhancement of neurotransmission. Notably, with the sole exception of amineptine, the TCAs have negligible affinity for the dopamine transporter (DAT), and therefore have no efficacy as dopamine reuptake inhibitors (DRIs). Both serotonin and norepinephrine have been highly implicated in depression and anxiety, and it has been shown that facilitation of their activity has beneficial effects on these mental disorders.
Although TCAs are sometimes prescribed for depressive disorders, they have been largely replaced in clinical use in most parts of the world by newer antidepressants such as selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs) and norepinephrine reuptake inhibitors (NRIs). Adverse effects have been found to be of a similar level between TCAs and SSRIs.
Tetracyclic antidepressants.
Tetracyclic antidepressants (TeCAs) are a class of antidepressants that were first introduced in the 1970s. They are named after their chemical structure, which contains four rings of atoms, and are closely related to the tricyclic antidepressants (TCAs), which contain three rings of atoms.
Monoamine oxidase inhibitors.
Monoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.
Because of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed.
MAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a recent retrospective-analysis. There are reports of MAOI efficacy in obsessive-compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.
MAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety.
Others.
See the list of antidepressants for other drugs which are not specifically characterized.
Adjuncts.
Adjunct medications are an umbrella term used to describe substances that increase the potency or "enhance" antidepressants. They work by affecting variables very close to the antidepressant, sometimes affecting a completely different mechanism of action. This may be attempted when depression treatments have not been successful in the past.
Common types of adjunct medication techniques generally fall into the following categories:
Less common adjunct medication.
Lithium has been used to augment antidepressant therapy in those who have failed to respond to antidepressants alone. Furthermore, lithium dramatically decreases the suicide risk in recurrent depression. There is some evidence for the addition of a thyroid hormone, triiodothyronine, in patients with normal thyroid function. Stephen M. Stahl, renowned academician in psychopharmacology, has stated resorting to a dynamic psychostimulant, in particular, d-amphetamine is the ""classical augmentation strategy" for treatment-refractory depression". However, the use of stimulants in cases of treatment-resistant depression is relatively controversial. A review article published in 2007 found psychostimulants may be effective in treatment-resistant depression with concomitant antidepressant therapy, but a more certain conclusion could not be drawn due to substantial deficiencies in the studies available for consideration, and the somewhat contradictory nature of their results.
History.
Before the 1950s, opioids and amphetamines were commonly used as antidepressants. Their use was later restricted due to their addictive nature and side effects. Extracts from the herb St John's wort had been used as a "nerve tonic" to alleviate depression.
Isoniazid, iproniazid, and imipramine.
In 1951, Irving Selikoff and Edward Robitzek, working out of Sea View Hospital on Staten Island, began clinical trials on two new anti-tuberculosis agents developed by Hoffman-LaRoche, isoniazid and iproniazid. Only patients with a poor prognosis were initially treated; nevertheless, their condition improved dramatically. Selikoff and Robitzek noted "a subtle general stimulation … the patients exhibited renewed vigor and indeed this occasionally served to introduce disciplinary problems." The promise of a cure for tuberculosis in the Sea View Hospital trials was excitedly discussed in the mainstream press.
In 1952, learning of the stimulating side effects of isoniazid, the Cincinnati psychiatrist Max Lurie tried it on his patients. In the following year, he and Harry Salzer reported that isoniazid improved depression in two thirds of their patients and coined the term "antidepressant" to describe its action. A similar incident took place in Paris, where Jean Delay, head of psychiatry at Sainte-Anne Hospital, heard of this effect from his pulmonology colleagues at Cochin Hospital. In 1952 (before Lurie and Salzer), Delay, with the resident Jean-Francois Buisson, reported the positive effect of isoniazid on depressed patients. The mode of antidepressant action of isoniazid is still unclear. It is speculated that its effect is due to the inhibition of diamine oxidase, coupled with a weak inhibition of monoamine oxidase A.
Selikoff and Robitzek also experimented with another anti-tuberculosis drug, iproniazid; it showed a greater psychostimulant effect, but more pronounced toxicity. Later, Jackson Smith, Gordon Kamman, George Crane, and Frank Ayd, described the psychiatric applications of iproniazid. Ernst Zeller found iproniazid to be a potent monoamine oxidase inhibitor. Nevertheless, iproniazid remained relatively obscure until Nathan Kline, the influential and flamboyant head of research at Rockland State Hospital, began to popularize it in the medical and popular press as a "psychic energizer". Roche put a significant marketing effort behind iproniazid. Its sales grew until it was recalled in 1961, due to reports of lethal hepatotoxicity.
The antidepressant effect of a tricyclic, a three ringed compound, was first discovered in 1957 by Roland Kuhn in a Swiss psychiatric hospital. Antihistamine derivatives were used to treat surgical shock and later as neuroleptics. Although in 1955 reserpine was shown to be more effective than placebo in alleviating anxious depression, neuroleptics were being developed as sedatives and antipsychotics.
Attempting to improve the effectiveness of chlorpromazine, Kuhn in conjunction with the Geigy Pharmaceutical Company discovered the compound "G 22355", later renamed imipramine. Imipramine had a beneficial effect in patients with depression who showed mental and motor retardation. Kuhn described his new compound as a "thymoleptic" "taking hold of the emotions," in contrast with neuroleptics, "taking hold of the nerves" in 1955–56. These gradually became established, resulting in the patent and manufacture in the US in 1951 by Häfliger and SchinderA.
Second generation antidepressants.
Antidepressants became prescription drugs in the 1950s. It was estimated that no more than 50 to 100 individuals per million suffered from the kind of depression that these new drugs would treat, and pharmaceutical companies were not enthusiastic in marketing for this small market. Sales through the 1960s remained poor compared to the sales of tranquilizers, which were being marketed for different uses. Imipramine remained in common use and numerous successors were introduced. The use of monoamine oxidase inhibitors (MAOI) increased after the development and introduction of "reversible" forms affecting only the MAO-A subtype of inhibitors, making this drug safer to use.
By the 1960s, it was thought that the mode of action of tricyclics was to inhibit norepinephrine reuptake. However, norepinephrine reuptake became associated with stimulating effects. Later tricyclics were thought to affect serotonin as proposed in 1969 by Carlsson and Lindqvist as well as Lapin and Oxenkrug.
Researchers began a process of rational drug design to isolate antihistamine-derived compounds that would selectively target these systems. The first such compound to be patented was zimelidine in 1971, while the first released clinically was indalpine. Fluoxetine was approved for commercial use by the US Food and Drug Administration (FDA) in 1988, becoming the first blockbuster SSRI. Fluoxetine was developed at Eli Lilly and Company in the early 1970s by Bryan Molloy, Klaus Schmiegel, David Wong and others. SSRIs became known as "novel antidepressants" along with other newer drugs such as SNRIs and NRIs with various selective effects.
St John's wort fell out of favor in most countries through the 19th and 20th centuries, except in Germany, where Hypericum extracts were eventually licensed, packaged and prescribed. Small-scale efficacy trials were carried out in the 1970s and 1980s, and attention grew in the 1990s following a meta-analysis. It remains an over-the-counter drug (OTC) supplement in most countries. Research continues to investigate its active component hyperforin, and to further understand its mode of action.
Society and culture.
Prescription trends.
In the United States, antidepressants were the most commonly prescribed medication in 2013. Of the estimated 16 million "long term" (over 24 months) users, roughly 70 percent are female.
In the UK, figures reported in 2010 indicated that the number of antidepressant prescribed by the National Health Service (NHS) almost doubled over a decade. Further analysis published in 2014 showed that number of antidepressants dispensed annually in the community went up by 25 million in the 14 years between 1998 and 2012, rising from 15 million to 40 million. Nearly 50% of this rise occurred in the four years after the 2008 banking crash, during which time the annual increase in prescriptions rose from 6.7% to 8.5%. These sources also suggest that aside from the recession, other factors that may influence changes in prescribing rates may include: improvements in diagnosis, a reduction of the stigma surrounding mental health, broader prescribing trends, GP characteristics, geographical location and housing status. Another factor that contribute to increasing consumption of antidepressants is the fact that these medications now are used for other conditions including social anxiety and post traumatic stress.
Most commonly prescribed.
United States: The most commonly prescribed antidepressants in the US retail market in 2010 were:
Netherlands: In the Netherlands, paroxetine, marketed as Seroxat among generic preparations, is the most prescribed antidepressant, followed by amitriptyline, citalopram and venlafaxine.
Social science perspective.
In looking at the issue of antidepressant use, some academics have highlighted the need to examine the use of antidepressants and other medical treatments in cross-cultural terms, due to the fact that various cultures prescribe and observe different manifestations, symptoms, meanings and associations of depression and other medical conditions within their populations. These cross-cultural discrepancies, it has been argued, then have implications on the perceived efficacy and use of antidepressants and other strategies in the treatment of depression in these different cultures. In India antidepressants are largely seen as tools to combat marginality, promising the individual the ability to re-integrate into society through their use—a view and association not observed in the West.
Environmental impacts.
Somewhat less than 10% of orally administered fluoxetine is excreted from humans unchanged or as glucuronide. Because most antidepressants function by inhibiting the reuptake of neurotransmitters serotonin, dopamine, and norepinepherine these drugs can interfere with natural neurotransmitter levels in other organisms impacted by indirect exposure. Antidepressants fluoxetine and sertraline have been detected in aquatic organisms residing in effluent dominated streams. The presence of antidepressants in surface waters and aquatic organisms has caused concern because ecotoxicological effects to aquatic organisms due to fluoxetine exposure have been demonstrated. Coral reef fish have been demonstrated to modulate aggressive behavior through serotonin.
Exposure to fluoxetine has been demonstrated to increase serotonergic activity in fish, subsequently reducing aggressive behavior. Artificially increasing serotonin levels in crustaceans can temporarily reverse social status and turn subordinates into aggressive and territorial dominant males. Perinatal exposure to fluoxetine at relevant environmental concentrations has been shown to lead to significant modifications of memory processing in 1-month-old cuttlefish. This impairment may disadvantage cuttlefish and decrease their survival.

</doc>
<doc id="2389" url="https://en.wikipedia.org/wiki?curid=2389" title="Auger effect">
Auger effect

The Auger effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. When a core electron is removed, leaving a vacancy, an electron from a higher energy level may fall into the vacancy, resulting in a release of energy. Although most often this energy is released in the form of an emitted photon, the energy can also be transferred to another electron, which is ejected from the atom. This second ejected electron is called an Auger electron, after one of its discoverers, Pierre Victor Auger.
Upon ejection, the kinetic energy of the Auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the Auger electron was ejected. These energy levels depend on the type of atom and the chemical environment in which the atom was located. Auger electron spectroscopy involves the emission of Auger electrons by bombarding a sample with either X-rays or energetic electrons and measures the intensity of Auger electrons that result as a function of the Auger electron energy. The resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment. Auger recombination is a similar Auger effect which occurs in semiconductors. An electron and electron hole (electron-hole pair) can recombine giving up their energy to an electron in the conduction band, increasing its energy. The reverse effect is known as impact ionization.
Discovery.
The Auger emission process was observed and published in 1922 by Lise Meitner, an Austrian-Swedish physicist, as a side effect in her competitive search for the nuclear beta electrons with the British physicist Charles Drummond Ellis.
The French physicist Pierre Victor Auger independently discovered it in 1923 upon analysis of a Wilson cloud chamber experiment and it became the central part of his PhD work. High-energy X-rays were applied to ionize gas particles and observe photoelectric electrons. Observation of electron tracks independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition. Further investigation and theoretical work showed that the effect was a radiationless effect more than an internal conversion effect by use of elementary quantum mechanics and transition rate and transition probability calculations.

</doc>
<doc id="2391" url="https://en.wikipedia.org/wiki?curid=2391" title="Akio Morita">
Akio Morita

Akio Morita (盛田 昭夫 "Morita Akio"; 26 January 1921 – 3 October 1999) was a Japanese businessman and co-founder of Sony along with Masaru Ibuka.
Early life.
Akio Morita was born in Nagoya, Aichi, Japan. Morita's family was involved in sake, miso and soy sauce production in the village of Kosugaya (currently a part of Tokoname City) on the western coast of Chita Peninsula in Aichi Prefecture since 1665. He was the oldest of four siblings and his father Kyuzaemon trained him as a child to take over the family business. Akio, however, found his true calling in mathematics and physics, and in 1944 he graduated from Osaka Imperial University with a degree in physics. He was later commissioned as a sub-lieutenant in the Imperial Japanese Navy, and served in World War II. During his service, Morita met his future business partner Masaru Ibuka in the Navy's Wartime Research Committee.
Sony.
On May 7, 1946, Morita and Ibuka founded "Tokyo Tsushin Kogyo Kabushiki Kaisha" (Tokyo Telecommunications Engineering Corporation, the forerunner of Sony Corporation) with about 20 employees and initial capital of ¥190,000. Ibuka was 38 years old, Morita, 25. Morita's family invested in Sony during the early period and was the largest shareholder.
In 1949, the company developed magnetic recording tape and in 1950, sold the first tape recorder in Japan. In 1957, it produced a pocket-sized radio (the first to be fully transistorized), and in 1958, Morita and Ibuka decided to rename their company Sony (derived from "sonus"--Latin for "sound"—and "Sonny-boys" the most common American expression). Morita was an advocate for all the products made by Sony. However, since the radio was slightly too big to fit in a shirt pocket, Morita made his employees wear shirts with slightly larger pockets to give the radio a "pocket sized" appearance. In 1960, it produced the first transistor television in the world. In 1973, Sony received an Emmy Award for its Trinitron television-set technology. In 1975, it released the first Betamax home video recorder, a year before VHS format came out. In 1979, the Walkman was introduced, making it the world's first portable music player. In 1984, Sony launched the Discman series which extended their Walkman brand to portable CD products.
In 1960, the Sony Corporation of America (SONAM, currently abbreviated as SCA) was established in the United States. In 1961, Sony Corporation was the first Japanese company to be listed on the New York Stock Exchange, in the form of American depositary receipts (ADRs), which are traded over-the-counter. Sony bought CBS Records Group which consisted of Columbia Records, Epic Records and other CBS labels in 1988 and Columbia Pictures Entertainment (Columbia Pictures, TriStar Pictures and others) in 1989.
On November 25, 1994, Morita stepped down as Sony chairman after suffering a cerebral hemorrhage while playing tennis. He was succeeded by Norio Ohga, who had joined the company in the 1950s after sending Morita a letter denouncing the poor quality of the company's tape recorders.
Other affiliations.
Morita was vice chairman of the Japan Business Federation (Japan Federation of Economic Organizations), and was a member of the Japan-U.S. Economic Relations Group, also known as the "Wise Men's Group". He was also the third Japanese chairman of the Trilateral Commission. His amateur radio call sign is JP1DPJ.
Publications.
In 1966, Morita wrote a book called "Gakureki Muyō Ron" (学歴無用論, Never Mind School Records), where he stresses that school records are not important to success or one's business skills. In 1986, Morita wrote an autobiography titled "Made in Japan". He co-authored the 1991 book "The Japan That Can Say No" with politician Shintaro Ishihara, where they criticized American business practices and encouraged Japanese to take a more independent role in business and foreign affairs. The book was translated into English and caused controversy in the United States, and Morita later had his chapters removed from the English version and distanced himself from the book.
Awards.
Morita was awarded the Albert Medal by the United Kingdom's Royal Society of Arts in 1982, the first Japanese to receive the honor. Two years later, he received the prestigious Legion of Honour, and in 1991, was awarded the First Class Order of the Sacred Treasure from the Emperor of Japan. In 1993, he was awarded an honorary British knighthood (KBE). Morita received the International Distinguished Entrepreneur Award from the University of Manitoba in 1987. He was posthumously awarded the Grand Cordon of the Order of the Rising Sun in 1999.
Death.
Morita suffered a stroke in 1993, during a game of tennis. On November 25, 1994, he stepped down as Sony chairman. On October 3, 1999, Morita died of pneumonia at the age of 78.

</doc>
<doc id="2392" url="https://en.wikipedia.org/wiki?curid=2392" title="Anode">
Anode

An anode is an electrode through which conventional current flows into a polarized electrical device. A common mnemonic is ACID for "anode current into device". The direction of (positive) electric current is opposite to the direction of electron flow: (negatively charged) electrons flow out the anode to the outside circuit.
The polarity of voltage on an anode with respect to an associated cathode varies depending on the device type and on its operating mode. In the following examples, the anode is negative in a device that provides power, and positive in a device that consumes power:
Etymology.
The word was coined in 1834 from the Greek ἄνοδος ("anodos"), 'ascent', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the "decomposing body" (electrolyte) in a direction "from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move", the anode is where the current enters the electrolyte, on the East side: ""ano" upwards, "odos" a way ; the way which the sun rises" (, reprinted in ).
The use of 'East' to mean the 'in' direction (actually 'in' → 'East' → 'sunrise' → 'up') may appear contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term "eisode" (the doorway where the current enters). His motivation for changing it to something meaning 'the East electrode' (other candidates had been "eastode", "oriode" and "anatolode") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the East electrode would not have been the 'way in' any more. Therefore, "eisode" would have become inappropriate, whereas "anode" meaning 'East electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the anode's function any more, but more importantly because as we now know, the Earth's magnetic field direction on which the "anode" term is based is subject to reversals whereas the current direction convention on which the "eisode" term was based has no reason to change in the future.
Since the later discovery of the electron, an easier to remember and more durably correct technically although historically false, etymology has been suggested: anode, from the Greek "anodos", 'way up', 'the way (up) out of the cell (or other device) for electrons'.
Flow of electrons.
The flow of electrons is always from anode to cathode outside of the cell or device, regardless of the cell or device type and operating mode, with the exception of diodes, where electrode naming always assumes current in the forward direction (that of the arrow symbol), i.e., electrons flow in the opposite direction, even when the diode reverse-conducts either by accident (breakdown of a normal diode) or by design (breakdown of a Zener diode, photo-current of a photodiode).
Electrolytic anode.
In electrochemistry, the "anode" is where oxidation occurs and is the positive polarity contact in an electrolytic cell. At the anode, anions (negative ions) are forced by the electrical potential to react chemically and give off electrons (oxidation) which then flow up and into the driving circuit. Mnemonics: LEO Red Cat (Loss of Electrons is Oxidation, Reduction occurs at the Cathode), or AnOx Red Cat (Anode Oxidation, Reduction Cathode), or OIL RIG (Oxidation is Loss, Reduction is Gain of electrons), or Roman Catholic and Orthodox (Reduction – Cathode, anode – Oxidation), or LEO the lion says GER (Losing electrons is Oxidation, Gaining electrons is Reduction).
This process is widely used in metals refining. For example, in copper refining, copper anodes, an intermediate product from the furnaces, are electrolysed in an appropriate solution (such as sulfuric acid) to yield high purity (99.99%) cathodes. Copper cathodes produced using this method are also described as electrolytic copper.
Battery or galvanic cell anode.
In a battery or galvanic cell, the anode is the negative electrode from which electrons flow out towards the external part of the circuit. Internally the positively charged cations are flowing away from the anode (even though it is negative and therefore would be expected to attract them, this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems); but, external to the cell in the circuit, electrons are being pushed out through the negative contact and thus through the circuit by the voltage potential as would be expected. Note: in a galvanic cell, contrary to what occurs in an electrolytic cell, no anions flow to the anode, the internal current being entirely accounted for by the cations flowing away from it (cf drawing).
In the United States, many battery manufacturers regard the positive electrode as the anode, particularly in their technical literature. Though technically incorrect, it does resolve the problem of which electrode is the anode in a secondary (or rechargeable) cell. Using the traditional definition, the anode switches ends between charge and discharge cycles.
Vacuum tube anode.
In electronic vacuum devices such as a cathode ray tube, the anode is the positively charged electron collector. In a tube, the anode is a charged positive plate that collects the electrons emitted by the cathode through electric attraction. It also accelerates the flow of these electrons.
Diode anode.
In a semiconductor diode, the anode is the P-doped layer which initially supplies "holes" to the junction. In the junction region, the holes supplied by the anode combine with electrons supplied from the N-doped region, creating a depleted zone. As the P-doped layer supplies holes to the depleted region, negative dopant ions are left behind in the P-doped layer ('P' for positive charge-carrier ions). This creates a base negative charge on the anode. When a positive voltage is applied to anode of the diode from the circuit, more "holes" are able to be transferred to the depleted region, and this causes the diode to become conductive, allowing current to flow through the circuit. The terms anode and cathode should not be applied to a Zener diode, since it allows flow in either direction, depending on the polarity of the applied potential (i.e. voltage).
Sacrificial anode.
In cathodic protection, a metal anode that is more reactive to the corrosive environment of the system to be protected is electrically linked to the protected system, and partially corrodes or dissolves, which protects the metal of the system it is connected to. As an example, an iron or steel ship's hull may be protected by a zinc sacrificial anode, which will dissolve into the seawater and prevent the hull from being corroded. Sacrificial anodes are particularly needed for systems where a static charge is generated by the action of flowing liquids, such as pipelines and watercraft. Sacrificial anodes are also generally used in tank-type water heaters.
In 1824 to reduce the impact of this destructive electrolytic action on ships hulls, their fastenings and underwater equipment, the scientist-engineer Sir Humphry Davy, developed the first and still most widely used marine electrolysis protection system. Davy installed sacrificial anodes made from a more electrically reactive (less noble) metal attached to the vessel hull and electrically connected to form a cathodic protection circuit.
A less obvious example of this type of protection is the process of galvanising iron. This process coats iron structures (such as fencing) with a coating of zinc metal. As long as the zinc remains intact, the iron is protected from the effects of corrosion. Inevitably, the zinc coating becomes breached, either by cracking or physical damage. Once this occurs, corrosive elements act as an electrolyte and the zinc/iron combination as electrodes. The resultant current ensures that the zinc coating is sacrificed but that the base iron does not corrode. Such a coating can protect an iron structure for a few decades, but once the protecting coating is consumed, the iron rapidly corrodes.
If, conversely, tin is used to coat steel, when a breach of the coating occurs it actually accelerates oxidation of the iron.
Related antonym.
The opposite of an anode is a cathode. When the current through the device is reversed, the electrodes switch functions, so anode becomes cathode, while cathode becomes anode, as long as the reversed current is applied, with the exception of diodes where electrode naming is always based on the forward current direction.

</doc>
<doc id="2393" url="https://en.wikipedia.org/wiki?curid=2393" title="Analog television">
Analog television

Analog television or analogue television is the original television technology that uses analog signals to transmit video and audio. In an analog television broadcast, the brightness, colors and sound are represented by rapid variations of either the amplitude, frequency or phase of the signal.
Analog signals vary over a continuous range of possible values which means that electronic noise and interference becomes reproduced by the receiver. So with analog, a moderately weak signal becomes snowy and subject to interference. In contrast, a moderately weak digital signal and a very strong digital signal transmit equal picture quality. Analog television may be wireless or can be distributed over a cable network using cable converters.
All broadcast television systems preceding digital transmission of digital television (DTV) used analog signals.
Analog television around the world has been in the process of shutting down since the late 2000s.
Development.
The earliest systems were mechanical television systems which used spinning disks with patterns of holes punched into the disc to scan an image. A similar disk reconstructed the image at the receiver. Synchronization of the receiver disc rotation was handled through sync pulses broadcast with the image information. However these mechanical systems were slow, the images were dim and flickered severely, and the image resolution very low. Camera systems used similar spinning discs and required intensely bright illumination of the subject for the light detector to work.
Analog television did not really begin as an industry until the development of the cathode-ray tube (CRT), which uses a focused electron beam to trace lines across a phosphor coated surface. The electron beam could be swept across the screen much faster than any mechanical disc system, allowing for more closely spaced scan lines and much higher image resolution. Also far less maintenance was required of an all-electronic system compared to a spinning disc system. All-electronic systems became popular with households after the Second World War.
Standards.
Broadcasters using analog television systems encode their signal using NTSC, PAL or SECAM analog encoding, and then use RF modulation to modulate this signal onto a Very high frequency (VHF) or Ultra high frequency (UHF) carrier. Each frame of a television image is composed of lines drawn on the screen. The lines are of varying brightness; the whole set of lines is drawn quickly enough that the human eye perceives it as one image. The next sequential frame is displayed, allowing the depiction of motion. The analog television signal contains timing and synchronization information, so that the receiver can reconstruct a two-dimensional moving image from a one-dimensional time-varying signal.
The first commercial television systems were black-and-white; the beginning of color television was in the 1950s.
A practical television system needs to take luminance, chrominance (in a color system), synchronization (horizontal and vertical), and audio signals, and broadcast them over a radio transmission. The transmission system must include a means of television channel selection.
Analog broadcast television systems come in a variety of frame rates and resolutions. Further differences exist in the frequency and modulation of the audio carrier. The monochrome combinations still existing in the 1950s are standardized by the International Telecommunication Union (ITU) as capital letters A through N. When color television was introduced, the hue and saturation information was added to the monochrome signals in a way that black & white televisions ignore. In this way backwards compatibility was achieved. That concept is true for all analog television standards.
There were three standards for the way the additional color information can be encoded and transmitted. The first was the American NTSC (National Television Systems Committee) color television system. The European/Australian PAL (Phase Alternation Line rate) and the French-former Soviet Union SECAM (Séquentiel Couleur Avec Mémoire) standard were developed later and attempt to cure certain defects of the NTSC system. PAL's color encoding is similar to the NTSC systems. SECAM, though, uses a different modulation approach than PAL or NTSC.
In principle, all three color encoding systems can be combined with any scan line/frame rate combination. Therefore, in order to describe a given signal completely, it's necessary to quote the color system and the broadcast standard as a capital letter. For example, the United States uses NTSC-M, Japan uses NTSC-J (discontinued, switched to ISDB-T in 2012), the UK uses PAL-I (discontinued, switched to DVB-T in 2012), France uses SECAM-L (discontinued, switched to DVB-T in 2011), much of Western Europe and Australia uses PAL-B/G, most of Eastern Europe uses SECAM-D/K or PAL-D/K and so on.
However, not all of these possible combinations actually exist. NTSC is currently "only" used with system M, even though there were experiments with NTSC-A (405 line) and NTSC-I (625 line) in the UK. PAL is used with a variety of 625-line standards (B,G,D,K,I,N) but also with the North American 525-line standard, accordingly named PAL-M. Likewise, SECAM is used with a variety of 625-line standards.
For this reason many people refer to any 625/25 type signal as "PAL" and to any 525/30 signal as "NTSC", even when referring to digital signals; for example, on DVD-Video, which does not contain any analog color encoding, and thus no PAL or NTSC signals at all. Even though this usage is common, it is misleading, as that is not the original meaning of the terms PAL/SECAM/NTSC.
Although a number of different broadcast television systems were in use worldwide, the same principles of operation apply.
In many countries, over-the-air broadcast television of analog audio and analog video signals has been discontinued, to allow the re-use of the television broadcast radio spectrum for other services such as datacasting and subchannels.
Displaying an image.
A cathode-ray tube (CRT) television displays an image by scanning a beam of electrons across the screen in a pattern of horizontal lines known as a raster. At the end of each line the beam returns to the start of the next line; the end of the last line is a link that returns to the top of the screen. As it passes each point the intensity of the beam is varied, varying the luminance of that point. A color television system is identical except that an additional signal known as chrominance controls the color of the spot.
Raster scanning is shown in a slightly simplified form below.
When analog television was developed, no affordable technology for storing any video signals existed; the luminance signal has to be generated and transmitted at the same time at which it is displayed on the CRT. It is therefore essential to keep the raster scanning in the camera (or other device for producing the signal) in exact synchronization with the scanning in the television.
The physics of the CRT require that a finite time interval be allowed for the spot to move back to the start of the next line ("horizontal retrace") or the start of the screen ("vertical retrace"). The timing of the luminance signal must allow for this.
The human eye has a characteristic called Phi phenomenon. Quickly displaying successive scan images will allow the apparent illusion of smooth motion. Flickering of the image can be partially solved using a long persistence phosphor coating on the CRT, so that successive images fade slowly. However, slow phosphor has the negative side-effect of causing image smearing and blurring when there is a large amount of rapid on-screen motion occurring.
The maximum frame rate depends on the bandwidth of the electronics and the transmission system, and the number of horizontal scan lines in the image. A frame rate of 25 or 30 hertz is a satisfactory compromise, while the process of interlacing two video fields of the picture per frame is used to build the image. This process doubles the apparent number of video frames per second and further reduces flicker and other defects in transmission.
Other types of display screens.
Plasma screens and LCD screens have been used in analog television sets. These types of display screens use lower voltages than older CRT displays. Many dual system television receivers, equipped to receive both analog transmissions and digital transmissions have analog tuner receiving capability and must use a television antenna.
Receiving signals.
The television system for each country will specify a number of television channels within the UHF or VHF frequency ranges. A channel actually consists of two signals: the picture information is transmitted using amplitude modulation on one frequency, and the sound is transmitted with frequency modulation at a frequency at a fixed offset (typically 4.5 to 6 MHz) from the picture signal.
The channel frequencies chosen represent a compromise between allowing enough bandwidth for video (and hence satisfactory picture resolution), and allowing enough channels to be packed into the available frequency band. In practice a technique called vestigial sideband is used to reduce the channel spacing, which would be nearly twice the video bandwidth if pure AM was used.
Signal reception is invariably done via a superheterodyne receiver: the first stage is a "tuner" which selects a television channel and frequency-shifts it to a fixed intermediate frequency (IF). The signal amplifier performs amplification to the IF stages from the microvolt range to fractions of a volt.
Extracting the sound.
At this point the IF signal consists of a video carrier signal at one frequency and the sound carrier at a fixed offset. A demodulator recovers the video signal. Also at the output of the same demodulator is a new frequency modulated sound carrier at the offset frequency. In some sets made before 1948, this was filtered out, and the sound IF of about 22 MHz was sent to an FM demodulator to recover the basic sound signal. In newer sets, this new carrier at the offset frequency was allowed to remain as "intercarrier sound", and it was sent to an FM demodulator to recover the basic sound signal. One particular advantage of intercarrier sound is that when the front panel fine tuning knob is adjusted, the sound carrier frequency does not change with the tuning, but stays at the above-mentioned offset frequency. Consequently, it is easier to tune the picture without losing the sound.
So the FM sound carrier is then demodulated, amplified, and used to drive a loudspeaker. Until the advent of the NICAM and MTS systems, television sound transmissions were invariably monophonic.
Structure of a video signal.
The video carrier is demodulated to give a composite video signal; this contains luminance, chrominance and synchronization signals; this is identical to the video signal format used by analog video devices such as VCRs or CCTV cameras. Note that the RF signal modulation is inverted compared to the conventional AM: the minimum video signal level corresponds to maximum carrier amplitude, and vice versa. To ensure good linearity (fidelity), consistent with affordable manufacturing costs of transmitters and receivers, the video carrier is never shut off altogether. When intercarrier sound was invented later in 1948, not completely shutting off the carrier had the side effect of allowing intercarrier sound to be economically implemented.
Each line of the displayed image is transmitted using a signal as shown above. The same basic format (with minor differences mainly related to timing and the encoding of color) is used for PAL, NTSC and SECAM television systems. A monochrome signal is identical to a color one, with the exception that the elements shown in color in the diagram (the color burst, and the chrominance signal) are not present.
The "front porch" is a brief (about 1.5 microsecond) period inserted between the end of each transmitted line of picture and the leading edge of the next line sync pulse. Its purpose was to allow voltage levels to stabilise in older televisions, preventing interference between picture lines. The "front porch" is the first component of the horizontal blanking interval which also contains the horizontal sync pulse and the "back porch".
The "back porch" is the portion of each scan line between the end (rising edge) of the horizontal sync pulse and the start of active video. It is used to restore the black level (300 mV) reference in analog video. In signal processing terms, it compensates for the fall time and settling time following the sync pulse.
In color television systems such as PAL and NTSC, this period also includes the colorburst signal. In the SECAM system it contains the reference subcarrier for each consecutive color difference signal in order to set the zero-color reference.
In some professional systems, particularly satellite links between locations, the audio is embedded within the back porch of the video signal, to save the cost of renting a second channel.
Monochrome video signal extraction.
The luminance component of a composite video signal varies between 0 V and approximately 0.7 V above the "black" level. In the NTSC system, there is a "blanking" signal level used during the front porch and back porch, and a "black" signal level 75 mV above it; in PAL and SECAM these are identical.
In a monochrome receiver the luminance signal is amplified to drive the control grid in the electron gun of the CRT. This changes the intensity of the electron beam and therefore the brightness of the spot being scanned. Brightness and contrast controls determine the DC shift and amplification, respectively.
Color video signal extraction.
A color signal conveys picture information for each of the red, green, and blue components of an image (see the article on color space for more information). However, these are not simply transmitted as three separate signals, because:
Instead, the RGB signals are converted into YUV form, where the Y signal represents the lightness and darkness (luminance) of the colors in the image. Because the rendering of colors in this way is the goal of both black and white (monochrome) film and black and white (monochrome) television systems, the Y signal is ideal for transmission as the luminance signal. This ensures a monochrome receiver will display a correct picture in black and white, where a given color is reproduced by a shade of gray that correctly reflects how light or dark the original color is. The U and V signals are "color difference" signals. The U signal is the difference between the B signal and the Y signal, also known as B minus Y (B-Y), and the V signal is the difference between the R signal and the Y signal, also known as R minus Y (R-Y). The U signal then represents how "purplish-blue" or its complementary color "yellowish-green" the color is, and the V signal how "purplish-red" or its complementary "greenish-cyan" it is. The advantage of this scheme is that the U and V signals are zero when the picture has no color content. Since the human eye is more sensitive to errors in luminance than in color, the U and V signals can be transmitted in a relatively lossy (specifically: bandwidth-limited) way with acceptable results.
In the receiver, a single demodulator can extract an additive combination of U plus V. An example is the X demodulator used in the X/Z demodulation system. In that same system, a second demodulator, the Z demodulator, also extracts an additive combination of U plus V, but in a different ratio. The X and Z color difference signals are further matrixed into three color difference signals, (R-Y), (B-Y), and (G-Y). The combinations of usually two, but sometimes three demodulators were:
a) (I) / (Q), (as used in the 1954 RCA CTC-2 and the 1985 RCA "Colortrack" series, and the 1954 Arvin, and some professional color monitors in the 1990s),
b) (R-Y) / (Q), as used in the 1955 RCA 21 inch color receiver,
c) (R-Y) / (B-Y), used in the first color receiver on the market (Westinghouse, not RCA),
d) (R-Y) / (G-Y), (as used in the RCA Victor CTC-4 chassis),
e) (R-Y) / (B-Y) / (G-Y),
f) (X) / (Z), as used in many receivers of the late 50's and throughout the 60's.
In the end, further matrixing of the above color-difference signals c through f yielded the three color-difference signals, (R-Y), (B-Y), and (G-Y).
The R,G,B signals in the receiver needed for the display device (CRT, Plasma display or LCD display) are electronically derived by matrixing as follows: R is the additive combination of (R-Y) with Y, G is the additive combination of (G-Y) with Y, and B is the additive combination of (B-Y) with Y. All of this is accomplished electronically. It can be seen that in the combining process, the low resolution portion of the Y signals cancel out, leaving R,G, and B signals able to render a low-resolution image in full color. However, the higher resolution portions of the Y signals do not cancel out, and so are equally present in R, G, and B, producing the higher definition (higher resolution) image detail in monochrome, although it appears to the human eye as a full-color and full resolution picture.
In the NTSC and PAL color systems, U and V are transmitted by using quadrature amplitude modulation of a subcarrier. This kind of modulation applies two independent signals to one subcarrier, with the idea that both signals will be recovered independently at the receive end. Before transmission, the subcarrier itself, is removed from the active (visible) portion of the video, and moved, in the form of a burst, to the horizontal blanking portion, which is not directly visible on screen. (More about the burst below.)
For NTSC, the subcarrier is a 3.58 MHz sine wave. For the PAL system it is a 4.43 MHz sine wave. After the above-mentioned quadrature amplitude modulation of the subcarrier, subcarrier sidebands are produced, and the subcarrier itself is filtered out of the visible portion of the video, since it is the subcarrier sidebands that carry all of the U and V information, and the subcarrier itself carries no information.
The resulting subcarrier sidebands is also known as "chroma" or "chrominance". Physically, this chrominance signal is a 3.58 MHz(NTSC) or 4.43 MHz(PAL) sine wave which, in response to changing U and V values, changes phase as compared to the subcarrier, and also changes amplitude.
As it turns out, the chroma amplitude (when considered together with the Y signal) represents the approximate saturation of a color, and the chroma phase against the subcarrier as reference, approximately represents the hue of the color. For particular test colors found in the test color bar pattern, exact amplitudes and phases are sometimes defined for test and trouble shooting purposes only.
Although, in response to changing U and V values, the chroma sinewave changes phase with respect to the subcarrier, it's not correct to say that the subcarrier is simply "phase modulated". That is because a single sine wave U test signal with QAM produces only one pair of sidebands, whereas real phase modulation under the same test conditions would produce multiple sets of sidebands occupying more frequency spectrum.
In NTSC, the chrominance sine wave has the same average frequency as the subcarrier frequency. But a spectrum analyzer instrument shows that, for transmitted chrominance, the frequency component at the subcarrier frequency is actually zero energy, verifying that the subcarrier was indeed removed before transmission.
These sideband frequencies are within the luminance signal band, which is why they are called "subcarrier" sidebands instead of simply "carrier" sidebands. Their exact frequencies were chosen such that (for NTSC), they are midway between two harmonics of the frame repetition rate, thus ensuring that the majority of the power of the luminance signal does not overlap with the power of the chrominance signal.
In the British PAL (D) system, the actual chrominance center frequency, with equal lower and upper sidebands, is 4.43361875 MHz, a direct multiple of the scan rate frequency. This frequency was chosen to minimize the chrominance beat interference pattern that would be visible in areas of high color saturation in the transmitted picture.
At certain times, the chrominance signal represents only the U signal, and 70 nanoseconds (NTSC) later, the chrominance signal represents only the V signal. (This is the nature of the quadrature amplitude modulation process that created the chrominance signal.) About 70 nanoseconds later still, -U, and another 70 nanoseconds, -V.
So to extract U, a synchronous demodulator is utilized, which uses the subcarrier to briefly gate (sample) the chroma every 280 nanoseconds, so that the output is only a train of discrete pulses, each having an amplitude that is the same as the original U signal at the corresponding time. In effect, these pulses are discrete-time analog samples of the U signal. The pulses are then low-pass filtered so that the original analog continuous-time U signal is recovered. For V, a 90 degree shifted subcarrier briefly gates the chroma signal every 280 nanoseconds, and the rest of the process is identical to that used for the U signal.
Gating at any other time than those times mentioned above will yield an additive mixture of any two of U, V, -U, or -V. One of these "off-axis" (that is, off the U and V axis) gating methods is called I/Q demodulation. Another much more popular "off-axis" scheme was the X/Z demodulation system. Further matrixing recovered the original U and V signals. This scheme was actually the most popular demodulator scheme throughout the 60's.
The above process uses the subcarrier. But as previously mentioned, it was deleted before transmission, and only the chroma is transmitted. Therefore, the receiver must reconstitute the subcarrier. For this purpose, a short burst of subcarrier, known as the color burst, is transmitted during the back porch (re-trace blanking period) of each scan line. A subcarrier oscillator in the receiver locks onto this signal (see phase-locked loop) to achieve a phase reference, resulting in the oscillator producing the reconstituted subcarrier.
NTSC uses this process unmodified. Unfortunately, this often results in poor color reproduction due to phase errors in the received signal, caused sometimes by multipath, but mostly by poor implementation at the studio end. With the advent of solid state receivers, cable TV, and digital studio equipment for conversion to an over-the-air analog signal, these NTSC problems have been largely fixed, leaving operator error at the studio end as the sole color rendition weakness of the NTSC system. In any case, the PAL D (delay) system mostly corrects these kind of errors by reversing the phase of the signal on each successive line, and the averaging the results over pairs of lines. This process is achieved by the use of a 1H (where H = horizontal scan frequency) duration delay line. (A typical circuit used with this device converts the low frequency color signal to ultrasound and back again). Phase shift errors between successive lines are therefore cancelled out and the wanted signal amplitude is increased when the two in-phase (coincident) signals are re-combined.
NTSC is more spectrum efficient than PAL, giving more picture detail for a given bandwidth. This is because sophisticated comb filters in receivers are more effective with NTSC's 4 field color phase cadence compared to PAL's 8 field cadence. However, in the end, the larger channel width of most PAL systems in Europe still give their PAL systems the edge in transmitting more picture detail.
In the SECAM television system, U and V are transmitted on "alternate" lines, using simple frequency modulation of two different color subcarriers.
In some analog color CRT displays, starting in 1956, the brightness control signal (luminance) is fed to the cathode connections of the electron guns, and the color difference signals (chrominance signals) are fed to the control grids connections. This simple CRT matrix mixing technique was replaced in later solid state designs of signal processing with the original matrixing method used in the 1954 and 1955 color TV receivers.
Synchronization.
Synchronizing pulses added to the video signal at the end of every scan line and video frame ensure that the sweep oscillators in the receiver remain locked in step with the transmitted signal, so that the image can be reconstructed on the receiver screen.
A "sync separator" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync. (see section below – Other technical information, for extra detail.)
Horizontal synchronization.
The horizontal synchronization pulse ("horizontal sync" "HSYNC"), separates the scan lines. The horizontal sync signal is a single short pulse which indicates the start of every line. The rest of the scan line follows, with the signal ranging from 0.3 V (black) to 1 V (white), until the next horizontal or vertical synchronization pulse.
The format of the horizontal sync pulse varies. In the 525-line NTSC system it is a 4.85 µs-long pulse at 0 V. In the 625-line PAL system the pulse is 4.7 µs synchronization pulse at 0 V . This is lower than the amplitude of any video signal ("blacker than black") so it can be detected by the level-sensitive "sync stripper" circuit of the receiver.
Vertical synchronization.
Vertical synchronization (Also "vertical sync" or "VSYNC") separates the video fields. In PAL and NTSC, the vertical sync pulse occurs within the vertical blanking interval. The vertical sync pulses are made by prolonging the length of HSYNC pulses through almost the entire length of the scan line.
The "vertical sync" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or mid-way through).
The format of such a signal in 525-line NTSC is:
Each pre- or post- equalizing pulse consists in half a scan line of black signal: 2 µs at 0 V, followed by 30 µs at 0.3 V.
Each long sync pulse consists in an equalizing pulse with timings inverted: 30 µs at 0 V, followed by 2 µs at 0.3 V.
In video production and computer graphics, changes to the image are often kept in step with the vertical synchronization pulse to avoid visible discontinuity of the image. Since the frame buffer of a computer graphics display imitates the dynamics of a cathode-ray display, if it is updated with a new image while the image is being transmitted to the display, the display shows a mishmash of both frames, producing a page tearing artifact partway down the image.
Vertical synchronization eliminates this by timing frame buffer fills to coincide with the vertical blanking interval, thus ensuring that only whole frames are seen on-screen. Software such as video games and computer aided design (CAD) packages often allow vertical synchronization as an option, because it delays the image update until the vertical blanking interval. This produces a small penalty in latency, because the program has to wait until the video controller has finished transmitting the image to the display before continuing. Triple buffering reduces this latency significantly.
Two timing intervals are defined – the "front porch" between the end of displayed video and the start of the sync pulse, and the "back porch" after the sync pulse and before displayed video. These and the sync pulse itself are called the "horizontal blanking" (or "retrace") "interval" and represent the time that the electron beam in the CRT is returning to the start of the next display line.
Horizontal hold and vertical hold.
The lack of precision timing components in early television receivers meant that the timebase circuits occasionally needed manual adjustment.
If their free-run frequencies were too far from the actual line and field rates, the circuits would not be able to follow the incoming sync signals.
Loss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.
The adjustment took the form of "horizontal hold" and "vertical hold" controls, usually on the front panel along with other common controls. These adjusted the free-run frequencies of the corresponding timebase oscillators.
By the early 1980s the efficacy of the synchronization circuits, plus the inherent stability of the sets' oscillators, had been improved to the point where these controls were no longer necessary.
Other technical information.
Components of a television system.
A typical analog monochrome television receiver is based around the block diagram shown below:
Sync separator.
Image synchronization is achieved by transmitting negative-going pulses; in a composite video signal of 1 volt amplitude, these are approximately 0.3 V below the "black level". The "horizontal sync" signal is a single short pulse which indicates the start of every line. Two timing intervals are defined – the "front porch" between the end of displayed video and the start of the sync pulse, and the "back porch" after the sync pulse and before displayed video. These and the sync pulse itself are called the "horizontal blanking" (or "retrace") "interval" and represent the time that the electron beam in the CRT is returning to the start of the next display line.
The "vertical sync" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or mid-way through).
In the television receiver, a "sync separator" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync.
Loss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.
Timebase circuits.
In an analog receiver with a CRT display sync pulses are fed to horizontal and vertical "timebase" circuits (commonly called "sweep circuits" in the United States), each consisting of an oscillator and an amplifier. These generate modified sawtooth and parabola current waveforms to scan the electron beam in a linear way. The waveform shapes are necessary to make up for the distance variations from the electron beam source and the screen surface. The oscillators are designed to free-run at frequencies very close to the field and line rates, but the sync pulses cause them to reset at the beginning of each scan line or field, resulting in the necessary synchronization of the beam sweep with the originating signal. The output waveforms from the timebase amplifiers are fed to the horizontal and vertical "deflection coils" wrapped around the CRT tube. These coils produce magnetic fields proportional to the changing current, and these deflect the electron beam across the screen.
In the 1950s, the power for these circuits was derived directly from the mains supply.
A simple circuit consisted of a series voltage dropper resistance and a rectifier valve (tube) or semiconductor diode. This avoided the cost of a large high voltage mains supply (50 or 60 Hz) transformer. This type of circuit was used for thermionic valve (tube) technology. It was inefficient and produced a lot of heat which led to premature failures in the circuitry.
In the 1960s, semiconductor technology was introduced into timebase circuits. During the late 1960s in the UK, synchronous (with the scan line rate) power generation was introduced into solid state receiver designs. These had very complex circuits in which faults were difficult to trace, but had very efficient use of power.
In the early 1970s AC mains (50 or 60 Hz), and line timebase (15,625 Hz), thyristor based switching circuits were introduced. In the UK use of the simple (50 Hz) types of power circuits were discontinued. The reason for design changes arose from the electricity supply contamination problems arising from EMI, and supply loading issues due to energy being taken from only the positive half cycle of the mains supply waveform.
CRT flyback power supply design and operation principles.
Most of the receiver's circuitry (at least in transistor- or IC-based designs) operates from a comparatively low-voltage DC power supply. However, the anode connection for a cathode-ray tube requires a very high voltage (typically 10–30 kV) for correct operation.
This voltage is not directly produced by the main power supply circuitry; instead the receiver makes use of the circuitry used for horizontal scanning. Direct current (DC), is switched though the line output transformer, and alternating current (AC) is induced into the scan coils. At the end of each horizontal scan line the magnetic field, which has built up in both transformer and scan coils by the current, is a source of latent electromagnetic energy. This stored collapsing magnetic field energy can be captured. The reverse flow, short duration, (about 10% of the line scan time) current from both the line output transformer and the horizontal scan coil is discharged again into the primary winding of the flyback transformer by the use of a rectifier which blocks this negative reverse emf. A small value capacitor is connected across the scan switching device. This tunes the circuit inductances to resonate at a much higher frequency. This slows down (lengthens) the flyback time from the extremely rapid decay rate that would result if they were electrically isolated during this short period. One of the secondary windings on the flyback transformer then feeds this brief high voltage pulse to a Cockcroft–Walton generator design voltage multiplier. This produces the required EHT supply. A flyback converter is a power supply circuit operating on similar principles.
A typical modern design incorporates the flyback transformer and rectifier circuitry into a single unit with a captive output lead, (known as a diode split line output transformer or an Integrated High Voltage Transformer (IHVT)), so that all high-voltage parts are enclosed. Earlier designs used a separate line output transformer and a well insulated high voltage multiplier unit. The high frequency (15 kHz or so) of the horizontal scanning allows reasonably small components to be used.
Transition to digital.
The first country to make a wholesale switch to digital over-the-air (terrestrial television) broadcasting was Luxembourg in 2006, followed later in 2006 by the Netherlands; in 2007 by Finland, Andorra, Sweden and Switzerland; in 2008 by Belgium (Flanders) and Germany; in 2009 by the United States (high power stations), southern Canada, the Isle of Man, Norway, and Denmark. In 2010, Belgium (Wallonia), Spain, Wales, Latvia, Estonia, the Channel Islands, San Marino and Slovenia; in 2011 Israel, Austria, Monaco, Cyprus, Japan (excluding Miyagi, Iwate, and Fukushima Prefectures), Malta and France; in 2012 Czech Republic, Arab World, Taiwan, Portugal, Japan (including Miyagi, Iwate, and Fukushima Prefectures), Serbia, Italy, Canada, Mauritius, United Kingdom, Republic of Ireland, Lithuania, Slovakia, Gibraltar, South Korea; in 2013, Republic of Macedonia, Poland, Bulgaria, Hungary, Australia, New Zealand, completed the transition. The United Kingdom made the transition to digital television between 2008 and 2012, with the exception of Barrow-in-Furness, which made the switch over in 2007 and Wales which made the switch over in 2010. The first Digital TV only area in the United Kingdom was Ferryside in Carmarthenshire.
In the United States, high-power over-the-air broadcasts are solely in the ATSC digital format since 12 June 2009, the date that the Federal Communications Commission (FCC) set for the end of all high-power analog television transmissions. As a result, almost two million households could no longer watch television because they had not prepared for the transition. The switchover was originally scheduled for 17 February 2009, until the U.S. Congress passed the DTV Delay Act. By special dispensation, some analog television signals ceased on the original date. While the majority of the viewers of over-the-air broadcast television in the U.S. watch full-power stations (which number about 1800), there are three other categories of television stations in the U.S.: low-power broadcasting stations, Class A stations, and television translator stations. There is presently no deadline for these stations, about 7100 in number, to convert to digital broadcasting.In broadcasting, whatever happens in the United States also influences southern Canada and northern Mexico because those areas are covered by television stations in the U.S.
In Japan, the switch to digital occurred on the 24 July 2011, but in Fukushima, Iwate, and Miyagi prefectures, the conversion was delayed to 31 March 2012, due to complications from the 2011 Tōhoku earthquake and tsunami and its related nuclear accidents. In Canada, most of the larger cities turned off analog broadcasts on 31 August 2011. China is scheduled to end analog broadcasting between 2015 and 2018, due to the large size of the country.
Brazil switched to digital television on 2 December 2007 in its major cities, and now it is estimated that Brazil will end analog broadcasting in 2023.
In Malaysia, the Malaysian Communications & Multimedia Commission (MCMC) advertised for tender bids to be submitted in the third quarter of 2009 for the 470 through 742 MHz UHF allocation, to enable Malaysia's broadcast system to move into DTV. The new broadcast band allocation would result in Malaysia's having to build an infrastructure for all broadcasters, using a single digital terrestrial transmission/television broadcast (DTTB) channel. Large portions of Malaysia are covered by television broadcasts from Singapore, Thailand, Brunei, and/or Indonesia (from Borneo and Batam)
In the Philippines, the National Telecommunications Commission requires all broadcasting companies to end analog broadcasting on December 31, 2015 11:59 p.m. But due to delay of the release of the implementing rules and regulations for digital television broadcast, the target date was moved to 2020. Full digital broadcast expected in 2021.

</doc>
<doc id="2395" url="https://en.wikipedia.org/wiki?curid=2395" title="April 11">
April 11


</doc>
<doc id="2396" url="https://en.wikipedia.org/wiki?curid=2396" title="Adhesive">
Adhesive

Adhesive may be used interchangeably with glue, cement, mucilage, or paste, and is any substance applied to one surface, or both surfaces, of two separate items that binds them together and resists their separation. Adjectives may be used in conjunction with the word “adhesive” to describe properties based on the substance's physical or chemical form, the type of materials joined, or conditions under which it is applied.
The use of adhesives offers many advantages over binding techniques such as sewing, mechanical fastening, thermal bonding, etc. These include the ability to bind different materials together, to distribute stress more efficiently across the joint, the cost effectiveness of an easily mechanized process, an improvement in aesthetic design, and increased design flexibility. Disadvantages of adhesive use include decreased stability at high temperatures, relative weakness in bonding large objects with a small bonding surface area, and greater difficulty in separating objects during testing. Adhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural or synthetic origin, or by their starting physical phase.
Adhesives may be found naturally or produced synthetically. The earliest human use of adhesive-like substances was approximately 200,000 years ago. The first references to adhesives in literature first appeared in approximately 2000 BCE. The Greeks and Romans made great contributions to the development of adhesives. In Europe, glue was not widely used until the period 1500–1700 CE. From then until the 1900s increases in adhesive use and discovery were relatively gradual. Only since the last century has the development of synthetic adhesives accelerated rapidly, and innovation in the field continues to the present.
History.
The earliest use of adhesives was discovered in central Italy when two stone flakes partially covered with birch-bark tar and a third uncovered stone from the Middle Pleistocene era (circa 200,000 years ago) were found. This is thought to be the oldest discovered human use of tar-hafted stones.
The birch-bark-tar adhesive is a simple, one-component adhesive. Although sticky enough, plant-based adhesives are brittle and vulnerable to environmental conditions. The first use of compound adhesives was discovered in Sibudu, South Africa. Here, 70,000-year-old stone segments that were once inserted in axe hafts were discovered covered with an adhesive composed of plant gum and red ochre (natural iron oxide) as adding ochre to plant gum produces a stronger product and protects the gum from disintegrating under wet conditions. The ability to produce stronger adhesives allowed middle stone age humans to attach stone segments to sticks in greater variations, which led to the development of new tools.
More recent examples of adhesive use by prehistoric humans have been found at the burial sites of ancient tribes. Archaeologists studying the sites found that approximately 6,000 years ago the tribesmen had buried their dead together with food found in broken clay pots repaired with tree resins. Another investigation by archaeologists uncovered the use of bituminous cements to fasten ivory eyeballs to statues in Babylonian temples dating to approximately 4000 BCE
In 2000, a paper revealed the discovery of a 5,200-year-old man nicknamed the "Tyrolean Iceman" or "Ötzi", who was preserved in a glacier near the Austria-Italy border. Several of his belongings were found with him including two arrows with flint arrowheads and a copper hatchet, each with evidence of organic glue used to connect the stone or metal parts to the wooden shafts. The glue was analyzed as pitch, which requires the heating of tar during its production. The retrieval of this tar requires a transformation of birch bark by means of heat, in a process known as pyrolysis. 
The first references to adhesives in literature first appeared in approximately 2000 BCE. Further historical records of adhesive use are found from the period spanning 1500–1000 BCE. Artifacts from this period include paintings depicting wood gluing operations and a casket made of wood and glue in King Tutankhamun's tomb. Other ancient Egyptian artifacts employ animal glue for bonding or lamination. Such lamination of wood for bows and furniture is thought to have extended their life and was accomplished using casein (milk protein)-based glues. The ancient Egyptians also developed starch-based pastes for the bonding of papyrus to clothing and a plaster of Paris like material made of calcined gypsum.
From 1 to 500 AD the Greeks and Romans made great contributions to the development of adhesives. Wood veneering and marquetry were developed, the production of animal and fish glues refined, and other materials utilized. Egg-based pastes were used to bond gold leaves incorporated various natural ingredients such as blood, bone, hide, milk, cheese, vegetables, and grains. The Greeks began the use of slaked lime as mortar while the Romans furthered mortar development by mixing lime with volcanic ash and sand. This material, known as pozzolanic cement, was used in the construction of the Roman Colosseum and Pantheon. The Romans were also the first people known to have used tar and beeswax as caulk and sealant between the wooden planks of their boats and ships.
In Central Asia, the rise of the Mongols in approximately 1000 AD can be partially attributed to the good range and power of the bows of Genghis Khan's hordes. These bows were constructed with laminated lemonwood and bullhorn bonded by an unknown adhesive.
In Europe, glue fell into disuse until the period 1500-1700 AD. At this time, world-renowned cabinet and furniture makers such as Chippendale and Duncan Phyfe began to use adhesives to hold their products together.
The development of modern adhesives began in 1690 with the founding of the first commercial glue plant in Holland. This plant produced glues from animal hides.
In 1750, the first British glue patent was issued for fish glue. The following decades of the next century witnessed the manufacture of casein glues in German and Swiss factories. In 1876, the first US patent (number 183,024) was issued to the Ross brothers for the production of casein glue.
The first US postage stamps used starch-based adhesives when issued in 1840. The first US patent (number 61,991) on dextrin (a starch derivative) adhesive was issued in 1867.
Natural rubber was first used as material for adhesives starting in 1830. In 1839, Charles Goodyear discovered that a rubber and sulfur mixture, when heated, becomes elastic. In 1843, Thomas Hancock named this process vulcanization. In 1862, a British patent (number 3288) was issued for the plating of metal with brass by electrodeposition to obtain a stronger bond to rubber. The development of the automobile and the need for rubber shock mounts required stronger and more durable bonds of rubber and metal. This spurred the development of cyclized rubber treated in strong acids. By 1927, this process was used to produce solvent-based thermoplastic rubber cements for metal to rubber bonding.
Natural rubber-based sticky adhesives were first used on a backing by Henry Day (US Patent 3,965) in 1845. Later these kinds of adhesives were used in cloth backed surgical and electric tapes. By 1925, the pressure-sensitive tape industry was born.
Today, sticky notes, Scotch tape, and other tapes are examples of PSA (pressure-sensitive adhesives).
A key step in the development of synthetic plastics was the introduction of a thermoset plastic known as Bakelite phenolic in 1910. Within two years, phenolic resin was applied to plywood as a coating varnish. In the early 1930s, phenolics gained importance as adhesive resins.
The 1920s, 1930s, and 1940s witnessed great advances in the development and production of new plastics and resins due to the First and Second World Wars. These advances greatly improved the development of adhesives by allowing the use of newly developed materials that exhibited a variety of properties. With changing needs and ever evolving technology, the development of new synthetic adhesives continues to the present. However, due to their low cost, natural adhesives are still more commonly used.
Economic importance.
The adhesive manufacturing market was over US$11 billion in 2011 in the United States. 
In the course of time and during their development, adhesives have gained a stable position in an increasing number of production processes. There is hardly any product in our surroundings that does not contain at least one adhesive—be it the label on a beverage bottle, protective coatings on automobiles, or profiles on window frames. Market researchers forecast a turnover of almost US$50 billion for the global adhesives market in 2019. In particular, the economic development of emerging countries such as China, India, Russia, and Brazil will cause a rising demand for adhesives in the future.
Types.
Adhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural, or synthetic origin, or by their starting physical phase.
Types by reactiveness.
Non-reactive adhesives.
Drying adhesives.
There are two types of adhesives that harden by drying: "solvent-based adhesives" and "polymer dispersion adhesives", also known as "emulsion adhesives". 
Solvent-based adhesives are a mixture of ingredients (typically polymers) dissolved in a solvent. White glue, contact adhesives and rubber cements are members of the "drying adhesive" family. As the solvent evaporates, the adhesive hardens. Depending on the chemical composition of the adhesive, they will adhere to different materials to greater or lesser degrees.
Polymer dispersion adhesives are milky-white dispersions often based on polyvinyl acetate (PVAc). They are used extensively in the woodworking and packaging industries. They are also used with fabrics and fabric-based components, and in engineered products such as loudspeaker cones.
Pressure-sensitive adhesives.
"Pressure-sensitive adhesives" (PSA) form a bond by the application of light pressure to marry the adhesive with the adherend. They are designed to have a balance between flow and resistance to flow. The bond forms because the adhesive is soft enough to flow (i.e., "wet") to the adherend. The bond has strength because the adhesive is hard enough to resist flow when stress is applied to the bond. Once the adhesive and the adherend are in close proximity, molecular interactions, such as van der Waals forces, become involved in the bond, contributing significantly to its ultimate strength.
PSAs are designed for either permanent or removable applications. Examples of permanent applications include safety labels for power equipment, foil tape for HVAC duct work, automotive interior trim assembly, and sound/vibration damping films. Some high performance permanent PSAs exhibit high adhesion values and can support kilograms of weight per square centimeter of contact area, even at elevated temperatures. Permanent PSAs may initially be removable (for example to recover mislabeled goods) and build adhesion to a permanent bond after several hours or days.
Removable adhesives are designed to form a temporary bond, and ideally can be removed after months or years without leaving residue on the adherend. Removable adhesives are used in applications such as surface protection films, masking tapes, bookmark and note papers, barcodes labels, price marking labels, promotional graphics materials, and for skin contact (wound care dressings, EKG electrodes, athletic tape, analgesic and transdermal drug patches, etc.). Some removable adhesives are designed to repeatedly stick and unstick. They have low adhesion, and generally cannot support much weight.
Pressure-sensitive adhesives are manufactured with either a liquid carrier or in 100% solid form. Articles are made from liquid PSAs by coating the adhesive and drying off the solvent or water carrier. They may be further heated to initiate a cross-linking reaction and increase molecular weight. 100% solid PSAs may be low viscosity polymers that are coated and then reacted with radiation to increase molecular weight and form the adhesive, or they may be high viscosity materials that are heated to reduce viscosity enough to allow coating, and then cooled to their final form. Major raw material for PSA's are acrylate-based polymers.
Contact adhesives.
"Contact adhesives" are used in strong bonds with high shear-resistance like laminates, such as bonding Formica to a wooden counter, and in footwear, as in attaching outsoles to uppers.
Natural rubber and polychloroprene (Neoprene) are commonly used contact adhesives. Both of these elastomers undergo strain crystallization. In the construction industry a specialised proprietary adhesive known as "liquid nails" is used. This also copes with tasks such as sealing artificial turf.
Contact adhesives must be applied to both surfaces and allowed some time to dry before the two surfaces are pushed together. Some contact adhesives require as long as 24 hours to dry before the surfaces are to be held together. Once the surfaces are pushed together, the bond forms very quickly. It is usually not necessary to apply pressure for a long time, so there is less need for clamps.
Hot adhesives.
"Hot adhesives", also known as "hot melt adhesives", are thermoplastics applied in molten form (in the 65–180 °C range) which solidify on cooling to form strong bonds between a wide range of materials. Ethylene-vinyl acetate-based hot-melts are particularly popular for crafts because of their ease of use and the wide range of common materials they can join. A glue gun (shown at right) is one method of applying hot adhesives. The glue gun melts the solid adhesive, then allows the liquid to pass through its barrel onto the material, where it solidifies.
Thermoplastic glue may have been invented around 1940 by Procter & Gamble as a solution to the problem that water-based adhesives, commonly used in packaging at that time, failed in humid climates, causing packages to open.
Reactive adhesives.
Multi-part adhesives.
"Multi-component adhesives" harden by mixing two or more components which chemically react. This reaction causes polymers to cross-link into acrylics, urethanes, and epoxies.
There are several commercial combinations of multi-component adhesives in use in industry. Some of these combinations are:
The individual components of a multi-component adhesive are not adhesive by nature. The individual components react with each other after being mixed and show full adhesion only on curing. The multi-component resins can be either solvent-based or solvent-less. The solvents present in the adhesives are a medium for the polyester or the polyurethane resin. The solvent is dried during the curing process.
One-part adhesives.
"One-part adhesives" harden via a chemical reaction with an external energy source, such as radiation, heat, and moisture.
"Ultraviolet" (UV) "light curing adhesives", also known as "light curing materials" (LCM), have become popular within the manufacturing sector due to their rapid curing time and strong bond strength. Light curing adhesives can cure in as little as a second and many formulations can bond dissimilar substrates (materials) and withstand harsh temperatures. These qualities make UV curing adhesives essential to the manufacturing of items in many industrial markets such as electronics, telecommunications, medical, aerospace, glass, and optical. Unlike traditional adhesives, UV light curing adhesives not only bond materials together but they can also be used to seal and coat products. They are generally acrylic-based.
"Heat curing adhesives" consist of a pre-made mixture of two or more components. When heat is applied the components react and cross-link. This type of adhesive includes epoxies, urethanes, and polyimides.
"Moisture curing adhesives" cure when they react with moisture present on the substrate surface or in the air. This type of adhesive includes cyanoacrylates and urethanes.
Types by origin.
Natural adhesives.
Natural adhesives are made from organic sources such as vegetable starch (dextrin), natural resins, or animals (e.g. the milk protein casein and hide-based animal glues). These are often referred to as bioadhesives.
One example is a simple paste made by cooking flour in water. Starch-based adhesives are used in corrugated board and paper sack production, paper tube winding, and wallpaper adhesives. Casein glue is mainly used to adhere glass bottle labels. Animal glues have traditionally been used in bookbinding, wood joining, and many other areas but now are largely replaced by synthetic glues except in specialist applications like the production and repair of stringed instruments. Albumen made from the protein component of blood has been used in the plywood industry. Masonite, a wood hardboard, was originally bonded using natural wood lignin, an organic polymer, though most modern particle boards such as MDF use synthetic thermosetting resins.
Synthetic adhesives.
Synthetic adhesives are based on elastomers, thermoplastics, emulsions, and thermosets. Examples of thermosetting adhesives are: epoxy, polyurethane, cyanoacrylate and acrylic polymers. Pressure-sensitive adhesive is used in Post-it notes. The first commercially produced synthetic adhesive was Karlsons Klister in the 1920s.
Application.
Applicators of different adhesives are designed according to the adhesive being used and the size of the area to which the adhesive will be applied. The adhesive is applied to either one or both of the materials being bonded. The pieces are aligned and pressure is added to aid in adhesion and rid the bond of air bubbles.
Common ways of applying an adhesive include brushes, rollers, using films or pellets, spray guns and applicator guns ("e.g.", caulk gun). All of these can be used manually or automated as part of a machine.
Mechanisms of adhesion.
For an adhesive to be effective it must have three main properties. It must be able to wet the substrate. It must harden and finally it must be able to transmit load between the two surfaces/substrates being adhered.
Adhesion, the attachment between adhesive and substrate may occur either by mechanical means, in which the adhesive works its way into small pores of the substrate, or by one of several chemical mechanisms. The strength of adhesion depends on many factors, including the means by which it occurs.
In some cases, an actual chemical bond occurs between adhesive and substrate. In others, electrostatic forces, as in static electricity, hold the substances together. A third mechanism involves the van der Waals forces that develop between molecules. A fourth means involves the moisture-aided diffusion of the glue into the substrate, followed by hardening.
Failure of the adhesive joint.
There are several factors that could contribute to the failure of two adhered surfaces. Sunlight and heat may weaken the adhesive. Solvents can deteriorate or dissolve adhesive. Physical stresses may also cause the separation of surfaces. When subjected to loading, debonding may occur at different locations in the adhesive joint. The major fracture types are the following:
Cohesive fracture.
"Cohesive fracture" is obtained if a crack propagates in the bulk polymer which constitutes the adhesive. In this case the surfaces of both adherends after debonding will be covered by fractured adhesive. The crack may propagate in the center of the layer or near an interface. For this last case, the cohesive fracture can be said to be “cohesive near the interface”.
Adhesive fracture.
"Adhesive fracture" (sometimes referred to as "interfacial fracture") is when debonding occurs between the adhesive and the adherend. In most cases, the occurrence of adhesive fracture for a given adhesive goes along with smaller fracture toughness.
Other types of fracture.
Other types of fracture include:
Design of adhesive joints.
As a general design rule, the material properties of the object need to be greater than the forces anticipated during its use. (i.e. geometry, loads, etc.). The engineering work will consist of having a good model to evaluate the function. For most adhesive joints, this can be achieved using fracture mechanics. Concepts such as the stress concentration factor and the strain energy release rate can be used to predict failure. In such models, the behavior of the adhesive layer itself is neglected and only the adherents are considered.
Failure will also very much depend on the opening "mode" of the joint.
As the loads are usually fixed, an acceptable design will result from combination of a material selection procedure and geometry modifications, if possible. In adhesively bonded structures, the global geometry and loads are fixed by structural considerations and the design procedure focuses on the material properties of the adhesive and on local changes on the geometry.
Increasing the joint resistance is usually obtained by designing its geometry so that:
Shelf life.
Some glues and adhesives have a limited storage life, and will stop working in a reliable manner if their safe shelf life is exceeded.

</doc>
<doc id="2397" url="https://en.wikipedia.org/wiki?curid=2397" title="Anthony Hopkins">
Anthony Hopkins

Sir Philip Anthony Hopkins, CBE (born 31 December 1937), is a Welsh actor of film, stage, and television. After graduating from the Royal Welsh College of Music & Drama in 1957, he trained at the Royal Academy of Dramatic Art in London, and was then spotted by Laurence Olivier who invited him to join the Royal National Theatre. In 1968, he got his break in film in "The Lion in Winter", playing King Richard the Lionheart.
Considered to be one of the greatest living actors, Hopkins is well known for his portrayal of Hannibal Lecter in "The Silence of the Lambs", for which he won the Academy Award for Best Actor, its sequel "Hannibal", and the prequel "Red Dragon". Other notable films include "The Mask of Zorro", "The Bounty", "Meet Joe Black", "The Elephant Man", "Magic", "84 Charing Cross Road", "Bram Stoker's Dracula", "Legends of the Fall", "Thor", "The Remains of the Day", "Amistad", "Nixon", "The World's Fastest Indian", "Instinct", and "Fracture".
Along with his Academy Award, Hopkins has won three BAFTA Awards, two Emmys, and the Cecil B. DeMille Award. In 1993, he was knighted by Queen Elizabeth II for services to the arts. He received a star on the Hollywood Walk of Fame in 2003, and was made a Fellow of the British Academy of Film and Television Arts in 2008.
Early life.
Hopkins was born on New Year's Eve 1937, in Margam, a suburb of Port Talbot, Glamorgan. His parents are Annie Muriel ("née" Yeates) and Richard Arthur Hopkins, a baker. His school days were unproductive; he found that he would rather immerse himself in art, such as painting and drawing, or playing the piano, than attend to his studies. In 1949, to instill discipline, his parents insisted he attend Jones' West Monmouth Boys' School in Pontypool. He remained there for five terms and was then educated at Cowbridge Grammar School in the Vale of Glamorgan.
Hopkins was influenced and encouraged by Welsh compatriot Richard Burton, whom he met at the age of 15. Hopkins promptly enrolled at the Royal Welsh College of Music & Drama in Cardiff, from which he graduated in 1957. After two years in the British Army doing his national service, he moved to London, where he trained at the Royal Academy of Dramatic Art.
Career.
Hopkins made his first professional stage appearance in the Palace Theatre, Swansea, in 1960 with Swansea Little Theatre's production of "Have a Cigarette". In 1965, after several years in repertory, he was spotted by Laurence Olivier, who invited him to join the Royal National Theatre in London. Hopkins became Olivier's understudy, and filled in when Olivier was struck with appendicitis during a production of August Strindberg's "The Dance of Death". Olivier later noted in his memoir, "Confessions of an Actor", that "A new young actor in the company of exceptional promise named Anthony Hopkins was understudying me and walked away with the part of Edgar like a cat with a mouse between its teeth."
Despite his success at the National, Hopkins tired of repeating the same roles nightly and yearned to be in films. He made his small-screen debut in a 1967 BBC broadcast of "A Flea in Her Ear". His first starring role in a film came in 1964 in "Changes", a short directed by Drewe Henley, written and produced by James Scott and co-starring Jacqueline Pearce. In 1968, he got his break in "The Lion in Winter" playing Richard I. Although Hopkins continued in theatre (most notably at the National Theatre as Lambert Le Roux in "Pravda" by David Hare and Howard Brenton and as Antony in "Antony and Cleopatra" opposite Judi Dench as well as in the Broadway production of Peter Shaffer's "Equus") he gradually moved away from it to become more established as a television and film actor. He portrayed Charles Dickens in the BBC television film "The Great Inimitable Mr. Dickens" in 1970, and Pierre Bezukhov in the BBC's mini series "War and Peace" (1972). In 1972 he starred as WWI British Prime Minister David Lloyd George in "Young Winston", and in 1977 he played British Army officer John Frost in Richard Attenborough's WWII film "A Bridge Too Far".
In 1980, he starred in "The Elephant Man" as the English doctor Sir Frederick Treves, who attends to Joseph Merrick (portrayed by John Hurt), a severely deformed man in 19th century London. That year he also starred opposite Shirley MacLaine in "A Change of Seasons" and famously said "she was the most obnoxious actress I have ever worked with." In 1984, he starred opposite Mel Gibson in "The Bounty" as William Bligh, captain of the Royal Navy ship the HMS "Bounty", in a retelling of the mutiny on the "Bounty". In 1992, Hopkins portrayed Abraham Van Helsing in Francis Ford Coppola's "Bram Stoker's Dracula".
Set in 1950s post-war Britain, Hopkins starred opposite Emma Thompson in the critically acclaimed "The Remains of the Day" (1993). Hopkins was nominated for an Academy Award for Best Actor for his performance, and the film frequently ranks among the best British films of all time. Hopkins portrayed Oxford academic C. S. Lewis in the 1993 British biographical film "Shadowlands", and received the BAFTA Award for Best Actor. During the 1990s, Hopkins had the chance to work with Bart the Bear in two films: "Legends of the Fall" (1994) and "The Edge" (1997). According to trainer, Lynn Seus, "Tony Hopkins was absolutely brilliant with Bart...He acknowledged and respected him like a fellow actor. He would spend hours just looking at Bart and admiring him. He did so many of his own scenes with Bart."
Hopkins was Britain's highest paid performer in 1998, starring in "The Mask of Zorro" and "Meet Joe Black", and also agreed to reprise his role as Dr Hannibal Lecter for a fee of £15 million. In 2000, Hopkins narrated "Dr. Seuss' How the Grinch Stole Christmas". Hopkins received a star on the Hollywood Walk of Fame in 2003.
Hopkins stated that his role as Burt Munro, whom he portrayed in his 2005 film "The World's Fastest Indian", was his favourite. He also asserted that Munro was the easiest role that he had played because both men have a similar outlook on life. In 2006, Hopkins was the recipient of the Golden Globe Cecil B. DeMille Award for lifetime achievement. In 2008, he received the BAFTA Academy Fellowship Award, the highest award the British Film Academy can bestow.
On 24 February 2010, it was announced that Hopkins had been cast in "The Rite", which was released on 28 January 2011. He played a priest who is "an expert in exorcisms and whose methods are not necessarily traditional". Hopkins, who is quoted as saying "I don't know what I believe, myself personally", reportedly wrote a line--"Some days I don't know if I believe in God or Santa Claus or Tinkerbell"—into his character in order to identify with it. On the other hand, in other sources from the same time, he is quoted as saying that he did believe in God and had done so for decades. On 21 September 2011, Peter R. de Vries named Hopkins in the role of the Heineken owner Freddy Heineken in a future film about his kidnapping.
Hopkins portrayed Odin, the Allfather or "king" of Asgard, in the 2011 film adaptation of Marvel Comics' "Thor". Hopkins portrayed Alfred Hitchcock in Sacha Gervasi's biopic "Hitchcock", following his career while making "Psycho". The film was released on 23 November 2012. In 2013, he reprised his role as Odin in "". In 2014, he portrayed Methuselah in Darren Aronofsky's "Noah".
Hannibal Lecter.
Hopkins' most famous role is as the cannibalistic serial killer Hannibal Lecter in "The Silence of the Lambs", for which he won the Academy Award for Best Actor in 1991, with Jodie Foster as Clarice Starling, who also won for Best Actress. The film won Best Picture, Best Director and Academy Award for Best Adapted Screenplay. Hopkins reprised his role as Lecter twice; in Ridley Scott's "Hannibal" (2001), and "Red Dragon" (2002). His original portrayal of the character in "The Silence of the Lambs" has been labelled by the AFI as the number-one film villain. At the time he was offered the role, Hopkins was making a return to the London stage, performing in "M. Butterfly". He had come back to Britain after living for a number of years in Hollywood, having all but given up on a career there, saying, "Well that part of my life's over; it's a chapter closed. I suppose I'll just have to settle for being a respectable actor poncing around the West End and doing respectable BBC work for the rest of my life."
Hopkins played the iconic villain in adaptations of the first three of the Lecter novels by Thomas Harris. The author was reportedly very pleased with Hopkins' portrayal of his antagonist. However, Hopkins stated that "Red Dragon" would feature his final performance as the character, and that he would not reprise even a narrative role in the latest addition to the series, "Hannibal Rising".
Acting style.
Hopkins is renowned for his preparation for roles. He indicated in interviews that once he has committed to a project, he will go over his lines as many times as is needed (sometimes upwards of 200) until the lines sound natural to him, so that he can "do it without thinking". This leads to an almost casual style of delivery that belies the amount of groundwork done beforehand. While it can allow for some careful improvisation, it has also brought him into conflict with the occasional director who departs from the script, or demands what the actor views as an excessive number of takes. Hopkins has stated that after he is finished with a scene, he simply discards the lines, not remembering them later on. This is unlike others who usually remember their lines from a film, even years later.
Richard Attenborough, who directed Hopkins on five occasions, found himself going to great lengths during the filming of "Shadowlands" (1993) to accommodate the differing approaches of his two stars (Hopkins and Debra Winger), who shared many scenes. Whereas Hopkins, preferring the spontaneity of a fresh take, liked to keep rehearsals to a minimum, Winger rehearsed continuously. To allow for this, Attenborough stood in for Hopkins during Winger's rehearsals, only bringing him in for the last one before a take. The director praised Hopkins for "this extraordinary ability to make you believe when you hear him that it is the very first time he has ever said that line. It's an incredible gift."
Renowned for his ability to remember lines, Hopkins keeps his memory supple by learning things by heart such as poetry, and Shakespeare. In Steven Spielberg's "Amistad", Hopkins astounded the crew with his memorisation of a seven-page courtroom speech, delivering it in one go. An overawed Spielberg couldn't bring himself to call him Tony, and insisted on addressing him as Sir Anthony throughout the shoot.
Hopkins is a gifted mimic, adept at turning his native Welsh accent into whatever is required by a character. He duplicated the voice of his late mentor, Laurence Olivier, for additional scenes in "Spartacus" in its 1991 restoration. His interview on the 1998 relaunch edition of the British TV talk show "Parkinson" featured an impersonation of comedian Tommy Cooper. Hopkins has said acting "like a submarine" has helped him to deliver credible performances in his thriller movies. He said, "It's very difficult for an actor to avoid, you want to show a bit. But I think the less one shows the better."
Personal life.
Hopkins was made a Commander of the British Empire (CBE) in 1987, and was knighted at Buckingham Palace in 1993 for services to the arts. In 1988, Hopkins was made an Honorary D.Litt and in 1992 was awarded Honorary fellowship from the University of Wales, Lampeter. He was made a freeman of his hometown Port Talbot in 1996.
Hopkins resides in Malibu, California. He had moved to the US once before during the late 1970s to pursue his film career, but returned to London in the late 1980s. However, he decided to return to the US following his 1990s success. Retaining his British citizenship, he became a naturalised US citizen on 12 April 2000, with Hopkins stating: "I have dual citizenship, it just so happens I live in America".
Hopkins has been married three times. His first two wives were Petronella Barker from 1966 to 1972, and Jennifer Lynton from 1973 to 2002. He has a daughter from his first marriage, actress and singer Abigail Hopkins (born 20 August 1968). He married Stella Arroyave in 2003. On Christmas Eve 2012, he celebrated his 10th wedding anniversary by having a blessing at a private service at St David's Cathedral in Pembrokeshire.
Hopkins has offered his support to various charities and appeals, notably becoming President of the National Trust's Snowdonia Appeal, raising funds for the preservation of Snowdonia National Park in north Wales. In 1998 he donated £1 million towards the £3 million needed to aid the Trust's efforts in purchasing parts of Snowdon. Prior to the campaign, Hopkins authored "Anthony Hopkins' Snowdonia", which was published in 1995. Due to his contributions to Snowdonia, in addition to his film career, in 2004 Hopkins was named among the 100 Welsh Heroes in a Welsh poll.
Hopkins has been a patron of the YMCA centre in his hometown of Port Talbot, South Wales for more than 20 years, having first joined the YMCA in the 1950s. He supports other various philanthropic groups. He was a Guest of Honour at a Gala Fundraiser for Women in Recovery, Inc., a Venice, California-based non-profit organisation offering rehabilitation assistance to women in recovery from substance abuse. He is also a volunteer teacher at the Ruskin School of Acting in Santa Monica, California. Hopkins served as the Honorary Patron of The New Heritage Theatre Company in Boise, Idaho from 1997-2007, participating in fundraising and marketing efforts for the repertory theatre.
Hopkins is a recovering alcoholic; he stopped drinking on 25 December 1975. He said that a major help in his recovery was his belief in God. He has criticised atheism, saying "being an atheist must be like living in a closed cell with no windows". He quit smoking using the Allen Carr method. In 2008, he embarked on a weight loss programme, and by 2010, he had lost 80 pounds.
Hopkins contributed toward the refurbishment of a £2.3 million wing at his alma mater, the Royal Welsh College of Music & Drama in Cardiff, named the Anthony Hopkins Centre. It opened in 1999.
Hopkins is a prominent member of environmental protection group Greenpeace and as of early 2008 featured in a television advertisement campaign, voicing concerns about Japan's continuing annual whale hunt. He has also been a patron of RAPt (Rehabilitation for Addicted Prisoners Trust) since its early days and helped open their first intensive drug and alcohol rehabilitation unit at Downview (HM Prison) in 1992.
Hopkins is an admirer of the Welsh comedian Tommy Cooper. On 23 February 2008, as patron of the Tommy Cooper Society, he unveiled a commemorative statue in the entertainer's home town of Caerphilly. For the ceremony, he donned Cooper's trademark fez and performed a comic routine.
Other work.
In a 2012 interview, Hopkins stated, "I've been composing music all my life and if I'd been clever enough at school I would like to have gone to music college. As it was I had to settle for being an actor." In 1986, he released a single called "Distant Star", which peaked at No. 75 in the UK Singles Chart. In 2007, he announced he would retire temporarily from the screen to tour around the world. Hopkins has also written music for the concert hall, in collaboration with Stephen Barton as orchestrator. These compositions include "The Masque of Time", given its world premiere with the Dallas Symphony Orchestra in October 2008, and "Schizoid Salsa".
In 1990, Hopkins directed a film about his Welsh compatriot, poet Dylan Thomas, titled "Dylan Thomas: Return Journey", which was his directing debut for the screen. In the same year, as part of the restoration process for the Stanley Kubrick film "Spartacus", Hopkins was approached to re-record lines from a scene that was being added back to the film; this scene featured Laurence Olivier and Tony Curtis, with Hopkins recommended by Olivier's widow, Joan Plowright to perform her late husband's part thanks to his talent for mimicry.
In 1996, he directed "August", an adaptation of Chekhov's "Uncle Vanya" set in Wales. His first screenplay, an experimental drama called "Slipstream", which he also directed and scored, premiered at the Sundance Film Festival in 2007. In 1997, Hopkins narrated the BBC natural documentary series, "Killing for a Living", which showed predatory behaviour in nature. He narrated episode 1 through 3 before being replaced by John Shrapnel.
Hopkins is a fan of the BBC sitcom "Only Fools and Horses", and once remarked in an interview how he would love to appear in the series. Writer John Sullivan saw the interview, and with Hopkins in mind created the character Danny Driscoll, a local villain. However, filming of the new series coincided with the filming of "The Silence of the Lambs", making Hopkins unavailable. The role instead went to Roy Marsden.
On 31 October 2011, André Rieu released an album including a waltz which Hopkins had composed many years before, at the age of nineteen. Hopkins had never heard his composition, "And the Waltz Goes On", before it was premiered by Rieu's orchestra in Vienna; Rieu's album was given the same name as Hopkins' piece.
In January 2012, Hopkins released an album of classical music, entitled "Composer", performed by the City of Birmingham Symphony Orchestra, and released on CD via the UK radio station Classic FM. The album consists of nine of his original works and film scores, with one of the pieces titled "Margam" in tribute to his home town near Port Talbot in Wales.
In October 2015, Hopkins appeared as Sir in a BBC Two production of Ronald Harwood's "The Dresser", alongside Ian McKellen, Edward Fox and Emily Watson. "The Dresser" is set in a London theatre during the Blitz, where an aging actor-manager, Sir, prepares for his starring role in "King Lear" with the help of his devoted dresser, Norman.

</doc>
<doc id="2398" url="https://en.wikipedia.org/wiki?curid=2398" title="Ardal O'Hanlon">
Ardal O'Hanlon

Ardal O'Hanlon (; born 8 October 1965) is an Irish comedian and actor. He played Father Dougal McGuire in "Father Ted" and George Sunday in "My Hero".
Biography.
Early life.
O'Hanlon was born in 1965 in Carrickmacross, County Monaghan, Ireland, the son of Rory O'Hanlon, an Irish politician and doctor, and has five siblings. RTÉ's "Who do you think you are?" programme on Monday 6 October 2008 examined Ardal's family tree. He discovered that his paternal grandfather, Michael O'Hanlon, a UCD medicine student, had joined the Irish Republican Army during the Irish War of Independence and was a member of Michael Collins's squad which assassinated British secret service agents on the morning of Bloody Sunday. Details of his grandfather's activities survive in UCD Archives, as well as Blackrock College. It also transpired that on his mother's side he was a close relative of Peter Fenelon Collier, the founder of "Collier's Weekly" and "Collier's Encyclopedia".
O'Hanlon was schooled in Blackrock College in Dublin and graduated, in 1987, from the National Institute for Higher Education, Dublin (now Dublin City University) with a degree in Communications Studies.
Career.
Together with Kevin Gildea and Barry Murphy, Ardal O'Hanlon founded the International Comedy Cellar, upstairs in the International Bar on Dublin's South Wicklow Street. Dublin had no comedy scene at the time. As a stand up, O'Hanlon won the Hackney Empire New Act of the Year competition in 1994. For a time he was the presenter of "The Stand Up Show".
He was spotted by Graham Linehan, who was to cast him as Father Dougal McGuire in "Father Ted" (1995–98). In 1995 he received the Top TV Comedy Newcomer at the British Comedy Awards for this role. In 1995, he appeared (as Father Dougal) in a Channel 4 ident ("Hello, you're watching... television"), and during Comic Relief on BBC1. This was followed by the award-winning short comedy film "Flying Saucer Rock'n'Roll".
O'Hanlon moved into straight acting alongside Emma Fielding and Beth Goddard in the ITV comedy-drama "Big Bad World", which aired for two series in summer 1999 and winter 2001. He also played a minor role in "The Butcher Boy" as Joe's (Francie's best friend) father, and appeared in an episode of the original "Whose Line is it Anyway?".
In 2000, O'Hanlon starred in the comedy series "My Hero", in which he played a very naive superhero from the planet Ultron. His character juggled world-saving heroics with life in suburbia. He stayed in the role until early 2005 and was replaced by James Dreyfus for series 6 in 2006.
He also provided the voice of the lead character in the three Christmas television cartoon specials of "Robbie the Reindeer". He appeared in the 2005 BBC One sitcom "Blessed", written by Ben Elton; at the 2005 British Comedy Awards, it was publicly slated by Jonathan Ross, albeit in jest. Towards the end of 2005, he played an eccentric Scottish character, Coconut Tam, in the family-based film, "The Adventures of Greyfriars Bobby". Although more commonly on television, he has appeared on radio - on 18 July 2011, he appeared on "Quote... Unquote". Appropriately, one of his questions concerned a quotation from "Father Ted".
In 2006, O'Hanlon wrote and presented an RTE television series called "Leagues Apart", which saw him investigate the biggest and most passionate football rivalries in a number of European countries. Included were Roma vs Lazio in Italy, Barcelona vs Real Madrid in Spain, and Galatasaray vs Fenerbahce in Turkey. He followed this with another RTÉ show, "So You Want To Be Taoiseach?" in 2007. It was a political series where O'Hanlon gave tongue-in-cheek advice on how to go about becoming Taoiseach of Ireland. Both programmes went some way towards freeing O'Hanlon from his association with the character of Dougal in the minds of Irish audiences.
He appeared in the "Doctor Who" episode "Gridlock", broadcast on 14 April 2007, in which he played a cat-like creature named Thomas Kincade Brannigan. O'Hanlon appears in Series 3 of the TV show "Skins", playing Naomi Campbell (Lily Loveless)'s Politics teacher named Kieran, who attempted to kiss her. He then went on to form a relationship with Naomi's mother (Olivia Colman). O'Hanlon plays the lead role in Irish comedy television programme "Val Falvey, TD" on RTE One. He has recently performed in the Edinburgh Fringe.
In February 2011, O'Hanlon returned to the Gate Theatre, Dublin starring in the Irish premiere of Christopher Hampton's "God of Carnage", alongside Maura Tierney.
In 2011, he appeared in the comedy panel show "Argumental".
O'Hanlon has written a novel, "The Talk of the Town" (known in the United States as "Knick Knack Paddy Whack"), which was published in 1998. The novel is about a teenage boy, Patrick Scully, and his friends.
in February 2015 he officially launched the 2015 Sky Cat Laughs Comedy Festival which takes place in Kilkenny from 28 May- 1 June.
He plays the role of Peter the milkman in Sky 1 sitcom After Hours.
Stand-up.
Ardal has been doing stand up for many years appearing on many shows including Live at the Apollo, Michael McIntyre's Comedy Roadshow and Dave's One Night Stand. In 1994 he won the Hackney Empire New Act of the Year.
Personal life.
O'Hanlon is married to Melanie, whom he met as a teenager, and with whom he has three children: Emily, Rebecca and Red. He is a supporter of Leeds United.
His name comes from the Norwegian city of Årdal.

</doc>
<doc id="2400" url="https://en.wikipedia.org/wiki?curid=2400" title="Advanced Micro Devices">
Advanced Micro Devices

Advanced Micro Devices, Inc. (AMD) is an American multinational semiconductor company based in Sunnyvale, California, United States, that develops computer processors and related technologies for business and consumer markets. While initially it manufactured its own processors, the company became fabless after GlobalFoundries was spun off in 2009. AMD's main products include microprocessors, motherboard chipsets, embedded processors and graphics processors for servers, workstations and personal computers, and embedded systems applications.
AMD is the second-largest supplier and only significant rival to Intel in the market for x86-based microprocessors. Since acquiring ATI in 2006, AMD and its competitor Nvidia have dominated the discrete graphics processor unit (GPU) market.
Company history.
First twelve years.
Advanced Micro Devices was formally incorporated on May 1, 1969, by Jerry Sanders, along with seven of his colleagues from Fairchild Semiconductor. Sanders, an electrical engineer who was the director of marketing at Fairchild, had like many Fairchild executives grown frustrated with the increasing lack of support, opportunity, and flexibility within that company, and decided to leave to start his own semiconductor company. The previous year Robert Noyce, who had invented the first practical integrated circuit or microchip in 1959 at Fairchild, had left Fairchild together with Gordon Moore and founded the semiconductor company Intel in July 1968.
In September 1969, AMD moved from its temporary location in Santa Clara to Sunnyvale, California. To immediately secure a customer base, AMD initially became a second source supplier of microchips designed by Fairchild and National Semiconductor. AMD first focused on producing logic chips. The company guaranteed quality control to United States Military Standard, an advantage in the early computer industry since unreliability in microchips was a distinct problem that customers – including computer manufacturers, the telecommunications industry, and instrument manufacturers – wanted to avoid.
In November 1969, the company manufactured its first product, the Am9300, a 4-bit MSI shift register, which began selling in 1970. Also in 1970, AMD produced its first proprietary product, the Am2501 logic counter, which was highly successful. Its best-selling product in 1971 was the Am2505, the fastest multiplier available.
In 1971, AMD entered the RAM chip market, beginning with the Am3101, a 64-bit bipolar RAM. That year AMD also greatly increased the sales volume of its linear integrated circuits, and by year end the company's total annual sales reached $4.6 million.
AMD went public in September 1972. The company was a second source for Intel MOS/LSI circuits by 1973, with products such as Am14/1506 and Am14/1507, dual 100-bit dynamic shift registers. By 1975, AMD was producing 212 products – of which 49 were proprietary, including the Am9102 (a static N-channel 1024-bit RAM) and three low-power Schottky MSI circuits: Am25LS07, Am25LS08, and Am25LS09.
Intel had created the first microprocessor, its 4-bit 4004, in 1971. By 1975, AMD entered the microprocessor market with the Am9080, a reverse-engineered clone of the Intel 8080, and the Am2900 bit-slice microprocessor family. When Intel began installing microcode in its microprocessors in 1976, it entered into a cross-licensing agreement with AMD, granting AMD a copyright license to the microcode in its microprocessors and peripherals, effective October 1976.
In 1977, AMD entered into a joint venture with Siemens, a German engineering conglomerate wishing to enhance its technology expertise and enter the U.S. market. Siemens purchased 20% of AMD's stock, giving AMD an infusion of cash to increase its product lines. That year the two companies also jointly established Advanced Micro Computers, located in Silicon Valley and in Germany, giving AMD an opportunity to enter the microcomputer development and manufacturing field, in particular based on AMD's second-source Zilog Z8000 microprocessors. When the two companies' vision for Advanced Micro Computers diverged, AMD bought out Siemens' stake in the U.S. division in 1979. AMD closed its Advanced Micro Computers subsidiary in late 1981, after switching focus to manufacturing second-source Intel x86 microprocessors.
Total sales in fiscal year 1978 topped $100 million, and in 1979, AMD debuted on the New York Stock Exchange. In 1979, production also began in AMD's new semiconductor fab in Austin; the company already had overseas assembly facilities in Penang and Manila, and it began construction on a semiconductor fab in San Antonio in 1981. In 1980, AMD began supplying semiconductor products for telecommunications, an industry undergoing rapid expansion and innovation.
Technology exchange agreement with Intel.
Intel had introduced the first x86 microprocessors in 1978. In 1981, IBM created its PC, and wanted Intel's x86 processors, but only under the condition that Intel also provide a second-source manufacturer for its patented x86 microprocessors. Intel and AMD entered into a 10-year technology exchange agreement, first signed in October 1981 and formally executed in February 1982. The terms of the agreement were that each company could acquire the right to become a second-source manufacturer for semiconductor products developed by the other; that is, each party could "earn" the right to manufacture and sell a product developed by the other, if agreed to, by exchanging the manufacturing rights to a product of equivalent technical complexity. The technical information and licenses needed to make and sell a part would be exchanged for a royalty to the developing company. The 1982 agreement also extended the 1976 AMD–Intel cross-licensing agreement through 1995. The agreement included the right to invoke arbitration of disagreements, and after five years the right of either party to end the agreement with one year's notice. The main result of the 1982 agreement was that AMD became a second-source manufacturer of Intel's x86 microprocessors and related chips, and Intel provided AMD with database tapes for its 8086, 80186, and 80286 chips.
Beginning in 1982, AMD began volume-producing second-source Intel-licensed 8086, 8088, 80186, and 80188 processors, and by 1984 its own Am286 clone of Intel's 80286 processor, for the rapidly growing market of IBM PCs and IBM clones. It also continued its successful concentration on proprietary bipolar chips. In 1983, it introduced INT.STD.1000, the highest manufacturing quality standard in the industry.
The company continued to spend greatly on research and development, and in addition to other breakthrough products, created the world's first 512K EPROM in 1984. That year AMD was listed in the book "The 100 Best Companies to Work for in America", and based on 1984 income it made the "Fortune" 500 list for the first time in 1985.
By mid-1985, however, the microchip market experienced a severe downturn, mainly due to longterm aggressive trade practices (dumping) from Japan, but also due to a crowded and non-innovative chip market in the U.S. AMD rode out the mid-1980s crisis by aggressively innovating and modernizing, devising the Liberty Chip program of designing and manufacturing one new chip or chip set per week for 52 weeks in fiscal year 1986, and by heavily lobbying the U.S. government until sanctions and restrictions were put into place to prevent predatory Japanese pricing. During this time period, AMD withdrew from the DRAM market, and at the same time made some headway into the CMOS market, which it had lagged in entering, having focused instead on bipolar chips.
AMD had some success in the mid-1980s with the AMD7910 and AMD7911 "World Chip" FSK modem, one of the first multi-standard devices that covered both Bell and CCITT tones at up to 1200 baud half duplex or 300/300 full duplex. Beginning in 1986, AMD embraced the perceived shift toward RISC with their own AMD Am29000 (29k) processor; the 29k survived as an embedded processor. The company also increased its EPROM memory market share in the late 1980s. Throughout the 1980s, AMD was a second-source supplier of Intel x86 processors. In 1991, it introduced its own 386-compatible Am386, an AMD-designed chip. Creating its own chips, AMD began to compete directly with Intel.
AMD had a large and successful flash memory business, even during the dotcom bust. In 2003, to divest some manufacturing and aid its overall cash flow, which was under duress from aggressive microprocessor competition from Intel, AMD spun-off its flash memory business and manufacturing into Spansion, a joint venture with Fujitsu, which had been co-manufacturing flash memory with AMD since 1993. AMD divested itself of Spansion in December 2005, in order to focus on the microprocessor market, and Spansion went public in an IPO.
AMD announced the acquisition of the graphics processor company ATI Technologies on July 24, 2006. AMD paid $4.3 billion in cash and 58 million shares of its stock, for a total of approximately $5.4 billion. The transaction completed on October 25, 2006. On August 30, 2010, AMD announced that it would retire the ATI brand name for its graphics chipsets in favor of the AMD brand name.
In October 2008, AMD announced plans to spin off manufacturing operations in the form of a multibillion-dollar joint venture with Advanced Technology Investment Co., an investment company formed by the government of Abu Dhabi. The new venture is called GlobalFoundries Inc. The partnership and spin-off gave AMD an infusion of cash and allowed AMD to focus solely on chip design. To assure the Abu Dhabi investors of the new venture's success, CEO Hector Ruiz stepped down as CEO of AMD in July 2008, while remaining Executive Chairman, in preparation to becoming Chairman of Global Foundries in March 2009. President and COO Dirk Meyer became AMD's CEO. Recessionary losses necessitated AMD cutting 1,100 jobs in 2009.
In August 2011, AMD announced that former Lenovo executive Rory Read would be joining the company as CEO, replacing Meyer. AMD announced in November 2011 plans to lay off more than 10% (1,400) of its employees from across all divisions worldwide. In October 2012, it announced plans to lay off an additional 15% of its workforce to reduce costs in the face of declining sales revenue.
AMD acquired the low-power server manufacturer SeaMicro in early 2012, with an eye to bringing out an ARM architecture server chip.
On October 8, 2014, AMD announced that Rory Read had stepped down after three years as president and chief executive officer. He was succeeded by Lisa Su, a key lieutenant who had been serving as chief operating officer since June.
On October 16, 2014, AMD announced a new restructuring plan along with its Q3 results. Effective July 1, 2014, AMD reorganized into two business groups: Computing and Graphics, which primarily includes desktop and notebook processors and chipsets, discrete GPUs, and professional graphics; and Enterprise, Embedded and Semi-Custom, which primarily includes server and embedded processors, dense servers, semi-custom SoC products, engineering services, and royalties. As part of this restructuring AMD announced that 7% of its global workforce would be laid off by the end of 2014.
History of CPUs and APUs.
IBM PC and the x86 architecture.
In February 1982, AMD signed a contract with Intel, becoming a licensed second-source manufacturer of 8086 and 8088 processors. IBM wanted to use the Intel 8088 in its IBM PC, but IBM's policy at the time was to require at least two sources for its chips. AMD later produced the Am286 under the same arrangement. In 1984 Intel, in order to shore up its advantage in the marketplace, internally decided to no longer cooperate with AMD in supplying product information, and delayed and eventually refused to convey the technical details of the Intel 80386 to AMD. In 1987, AMD invoked arbitration over the issue, and Intel reacted by cancelling the 1982 technological-exchange agreement altogether. After three years of testimony, AMD eventually won in arbitration in 1992, but Intel disputed this decision. Another long legal dispute followed, ending in 1994 when the Supreme Court of California sided with the arbitrator and AMD.
In 1990, Intel also countersued AMD, reneging on AMD's right to use derivatives of Intel's microcode for its cloned processors. In the face of uncertainty during the legal dispute, AMD was forced to develop clean room designed versions of Intel code for its x386 and x486 processors, the former long after Intel had released its own x386 in 1985. In March 1991, AMD released the Am386, its clone of the Intel 386 processor. By October of the same year it had sold one million units.
In 1993, AMD introduced the first of the Am486 family of processors, which proved popular with a large number of original equipment manufacturers, including Compaq, which signed an exclusive agreement using the Am486. Another Am486-based processor, the Am5x86, was released in November 1995 and continued AMD's success as a fast, cost-effective processor.
Finally, in an agreement effective 1996, AMD received the rights to the microcode in Intel's x386 and x486 processor families, but not the rights to the microcode in the following generations of processors.
K5, K6, Athlon, Duron, and Sempron.
AMD's first in-house x86 processor was the K5, which was launched in 1996. The "K" was a reference to Kryptonite. (In comic books, the only substance which could harm Superman was Kryptonite. This is a reference to Intel's hegemony over the market, i.e., an anthropomorphization of them as Superman.) The numeral "5" refers to the fifth generation of x86 processors; rival Intel had previously introduced its line of fifth-generation x86 processors as Pentium because the U.S. Trademark and Patent Office had ruled that mere numbers could not be trademarked.
In 1996, AMD purchased NexGen, specifically for the rights to their Nx series of x86-compatible processors. AMD gave the NexGen design team their own building, left them alone, and gave them time and money to rework the Nx686. The result was the K6 processor, introduced in 1997. Although the K6 was based on Socket 7, variants such as K6-3/450 were faster than Intel's Pentium II (sixth-generation processor).
The K7 was AMD's seventh-generation x86 processor, making its debut on June 23, 1999, under the brand name Athlon. Unlike previous AMD processors, it could not be used on the same motherboards as Intel's, due to licensing issues surrounding Intel's Slot 1 connector, and instead used a Slot A connector, referenced to the Alpha processor bus. The Duron was a lower-cost and limited version of the Athlon (64KB instead of 256KB L2 cache) in a 462-pin socketed PGA (socket A) or soldered directly onto the motherboard. Sempron was released as a lower-cost Athlon XP, replacing Duron in the socket A PGA era. It has since been migrated upward to all new sockets, up to AM3.
On October 9, 2001, the Athlon XP was released. On February 10, 2003, the Athlon XP with 512KB L2 Cache was released.
Athlon 64, Opteron and Phenom.
The K8 was a major revision of the K7 architecture, with the most notable features being the addition of a 64-bit extension to the x86 instruction set (called x86-64, AMD64, or x64), the incorporation of an on-chip memory controller, and the implementation of an extremely high performance point-to-point interconnect called HyperTransport, as part of the Direct Connect Architecture. The technology was initially launched as the Opteron server-oriented processor on April 22, 2003. Shortly thereafter it was incorporated into a product for desktop PCs, branded Athlon 64.
On April 21, 2005, AMD released the first dual core Opteron, an x86-based server CPU. A month later, AMD released the Athlon 64 X2, the first desktop-based dual core processor family. In May 2007, AMD abandoned the string "64" in its dual-core desktop product branding, becoming Athlon X2, downplaying the significance of 64-bit computing in its processors. Further updates involved improvements to the microarchitecture, and a shift of target market from mainstream desktop systems to value dual-core desktop systems. In 2008, AMD started to release dual-core Sempron processors exclusively in China, branded as the Sempron 2000 series, with lower HyperTransport speed and smaller L2 cache. Thus AMD completed its dual-core product portfolio for each market segment.
After K8 came K10. In September 2007, AMD released the first K10 processors – nine quad-core Third Generation Opteron processors – followed in November by the Phenom processor for desktop. K10 processors came in dual-core, triple-core, and quad-core versions, with all cores on a single die. AMD released a new platform, codenamed "Spider", which utilized the new Phenom processor, as well as an R770 GPU and a 790 GX/FX chipset from the AMD 700 chipset series. However, AMD built the Spider at 65nm, which was uncompetitive with Intel's smaller and more power-efficient 45nm.
In January 2009, AMD released a new processor line dubbed Phenom II, a refresh of the original Phenom built using the 45 nm process. AMD's new platform, codenamed “Dragon”, utilised the new Phenom II processor, and an ATI R770 GPU from the R700 GPU family, as well as a 790 GX/FX chipset from the AMD 700 chipset series. The Phenom II came in dual-core, triple-core and quad-core variants, all using the same die, with cores disabled for the triple-core and dual-core versions. The Phenom II resolved issues that the original Phenom had, including a low clock speed, a small L3 cache and a Cool'n'Quiet bug that decreased performance. The Phenom II cost less but was not performance-competitive with Intel's mid-to-high-range Core 2 Quads. The Phenom II also enhanced the Phenom's memory controller, allowing it to use DDR3 in a new native socket AM3, while maintaining backwards compatibility with AM2+, the socket used for the Phenom, and allowing the use of the DDR2 memory that was used with the platform.
In April 2010, AMD released a new Phenom II hexa-core (6-core) processor codenamed "Thuban". This was a totally new die based on the hexa-core “Istanbul” Opteron processor. It included AMD's “turbo core” technology, which allows the processor to automatically switch from 6 cores to 3 faster cores when more pure speed is needed. AMD's enthusiast platform, codenamed "Leo", utilized the new Phenom II, a new chipset from the AMD 800 chipset series and an ATI “Cypress” GPU from the Evergreen GPU series.
The Magny Cours and Lisbon server parts were released in 2010. The Magny Cours part came in 8 to 12 cores and the Lisbon part in 4 and 6 core parts. Magny Cours is focused on performance while the Lisbon part is focused on high performance per watt. Magny Cours is an MCM (Multi-Chip Module) with two hexa-core “Istanbul” Opteron parts. This will use a new G34 socket for dual and quad socket processors and thus will be marketed as Opteron 61xx series processors. Lisbon uses C32 socket certified for dual socket use or single socket use only and thus will be marketed as Opteron 41xx processors. Both will be built on a 45 nm SOI process.
Fusion becomes the AMD APU, and new microarchitectures.
Following AMD's 2006 acquisition of Canadian graphics company ATI Technologies, an initiative codenamed "Fusion" was announced to integrate a CPU and GPU together on some of AMD's microprocessors, including a built in PCI Express link to accommodate separate PCI Express peripherals, eliminating the northbridge chip from the motherboard. The initiative intended to move some of the processing originally done on the CPU (e.g. floating-point unit operations) to the GPU, which is better optimized for some calculations. The Fusion was later renamed to the AMD APU (Accelerated Processing Unit).
Llano was AMD's first APU built for laptops. Llano was the second APU released, targeted at the mainstream market. Incorporating a CPU and GPU on the same die, as well as northbridge functions, and using "Socket FM1" with DDR3 memory. The CPU part of the processor was based on the Phenom II "Deneb" processor. AMD suffered an unexpected decrease in revenue based on production problems for the Llano.
Bulldozer is AMD's microarchitecture codename for server and desktop AMD FX processors first released on October 12, 2011. This family 15h microarchitecture is the successor to the family 10h (K10) microarchitecture design. Bulldozer is designed from scratch, not a development of earlier processors. The core is specifically aimed at 10-125 W TDP computing products. AMD claims dramatic performance-per-watt efficiency improvements in high-performance computing (HPC) applications with Bulldozer cores. While hopes were very high that Bulldozer would bring AMD to be performance competitive with arch rival Intel once more, most benchmarks were disappointing. In some cases the new Bulldozer products were slower than the K10 model they were built to replace.
Hondo is AMD's latest processor series used in Tablet computers.
Piledriver is the name of AMD's microarchitecture used in some AMD FX processors released in 2012. This AMD FX series processor lineup is called Vishera, and targets the desktop performance market.
Jaguar is a x86-64 microarchitecture codename for a processor core that is used in various APUs from AMD aimed at the low-power/low-cost market. It is also used as the microarchitecture for the custom APUs in the PS4 and Xbox One (which contain CPU, GPU and memory).
Jaguar's predecessor, Bobcat, was revealed during a speech from AMD executive vice-president Henri Richard in Computex 2007 and was put into production Q1 2011. One of the major supporters was executive vice-president Mario A. Rivas who felt it was difficult to compete in the x86 market with a single core optimized for the 10-100 W range and actively promoted the development of the simpler core with a target range of 1-10 watts. In addition, it was believed that the core could migrate into the hand-held space if the power consumption can be reduced to less than 1 W.
ARM architecture-based chip.
AMD intends to release 64-bit ARM System on Chips (SoC) that will begin sampling in early 2014 and shipping in the second half of 2015. They will be for use in servers as a low-power alternative to current x86 chips. Their implementation using the ARM architecture is codenamed "Seattle", based on the Cortex A57 core design (ARMv8-A), and will contain 8 and 16 cores each. They will include the proprietary SeaMicro "Freedom Fabric", as well as support for 128 GB RAM, and 10 gigabit Ethernet. This is to be followed by the custom ARM core K12 core, expected in 2016-2017.
Zen based CPUs and APUs.
Zen is a new architecture for x86-64 based CPUs and APUs, built from the ground up by a team led by Jim Keller, beginning with his arrival in 2012, and taping out before his departure in September 2015. Zen will be built on the 14 nm node and have a renewed focus on single-core performance and HSA compatibility. Zen will be the first chip encompassing CPUs and APUs from AMD built for a single socket. It will also support DDR4. It is expected to be released mid-late 2016, following the availability of the AMD A10-7890K FM2+ desktop CPU.
Other products and technologies.
Graphics products (discrete and AMD APU technology).
AMD's portfolio of dedicated graphics processors includes product families and associated technologies aimed at the consumer, professional and high-performance computing markets, such as:
AMD Catalyst is a collection of proprietary device driver software available for Microsoft Windows and Linux.
Since 2007, AMD has participated in the development of free and open-source graphics device drivers. The programming specifications for a number of chipsets and features were published in several rounds. Employees hired by AMD for this purpose contribute code to the Direct Rendering Manager in the Linux kernel.
AMD motherboard chipsets.
Before the launch of Athlon 64 processors in 2003, AMD designed chipsets for their processors spanning the K6 and K7 processor generations. The chipsets include the AMD-640, AMD-751 and the AMD-761 chipsets. The situation changed in 2003 with the release of Athlon 64 processors, and AMD chose not to further design its own chipsets for its desktop processors while opening the desktop platform to allow other firms to design chipsets. This was the “Open Platform Management Architecture” with ATI, VIA and SiS developing their own chipset for Athlon 64 processors and later Athlon 64 X2 and Athlon 64 FX processors, including the Quad FX platform chipset from Nvidia.
The initiative went further with the release of Opteron server processors as AMD stopped the design of server chipsets in 2004 after releasing the AMD-8111 chipset, and again opened the server platform for firms to develop chipsets for Opteron processors. As of today, Nvidia and Broadcom are the sole designing firms of server chipsets for Opteron processors.
As the company completed the acquisition of ATI Technologies in 2006, the firm gained the ATI design team for chipsets which previously designed the Radeon Xpress 200 and the Radeon Xpress 3200 chipsets. AMD then renamed the chipsets for AMD processors under AMD branding (for instance, the CrossFire Xpress 3200 chipset was renamed as AMD 580X CrossFire chipset). In February 2007, AMD announced the first AMD-branded chipset since 2004 with the release of the AMD 690G chipset (previously under the development codename "RS690"), targeted at mainstream IGP computing. It was the industry's first to implement a HDMI 1.2 port on motherboards, shipping for more than a million units. While ATI had aimed at releasing an Intel IGP chipset, the plan was scrapped and the inventories of Radeon Xpress 1250 (codenamed "RS600", sold under ATI brand) was sold to two OEMs, Abit and ASRock. Although AMD stated the firm would still produce Intel chipsets, Intel had not granted the license of FSB to ATI.
On November 15, 2007, AMD announced a new chipset series portfolio, the AMD 7-Series chipsets, covering from enthusiast multi-graphics segment to value IGP segment, to replace the AMD 480/570/580 chipsets and AMD 690 series chipsets, marking AMD's first enthusiast multi-graphics chipset. Discrete graphics chipsets were launched on November 15, 2007 as part of the codenamed "Spider" desktop platform, and IGP chipsets were launched at a later time in spring 2008 as part of the codenamed "Cartwheel" platform.
AMD returned to the server chipsets market with the AMD 800S series server chipsets. It includes support for up to six SATA 6.0 Gbit/s ports, the C6 power state, which is featured in Fusion processors and AHCI 1.2 with SATA FIS–based switching support. This is a chipset family supporting Phenom processors and Quad FX enthusiast platform (890FX), IGP(890GX).
AMD Live!
, AMD LIVE! was a platform marketing initiative focusing the consumer electronics segment, with an Active TV initiative for streaming Internet videos from web video services such as YouTube, into AMD Live! PC as well as connected digital TVs, together with a scheme for an ecosystem of certified peripherals for the ease of customers to identify peripherals for AMD LIVE! systems for digital home experience, called "AMD LIVE! Ready".
AMD Quad FX platform.
The AMD Quad FX platform, being an extreme enthusiast platform, allows two processors to connect through HyperTransport, which is a similar setup to dual-processor (2P) servers, excluding the use of buffered memory/registered memory DIMM modules, and a server motherboard, the current setup includes two Athlon 64 FX-70 series processors and a special motherboard. AMD pushed the platform for the surging demands for what AMD calls "megatasking", the ability to do more tasks on a single system. The platform refreshes with the introduction of Phenom FX processors and the next-generation RD790 chipset, codenamed ""FASN8"".
Server platform.
AMD's first multi-processor server platform, codenamed "Fiorano", consists of AMD SR5690 + SP5100 server chipsets, supporting 45 nm, codenamed "Shanghai" Socket F+ processors and registered DDR2 memory. It was followed by the "Maranello" platform supporting 45 nm, codenamed "Istanbul", Socket G34 processors with DDR3 memory. On single-processor platform, the codenamed "Catalunya" platform consists of codenamed "Suzuka" 45 nm quad-core processor with AMD SR5580 + SP5100 chipset and DDR3 support.
AMD's x86 virtualization extension to the 64-bit x86 architecture is named "AMD Virtualization", also known by the abbreviation "AMD-V", and is sometimes referred to by the code name "Pacifica". AMD processors using Socket AM2, Socket S1, and Socket F include AMD Virtualization support. AMD Virtualization is also supported by release two (8200, 2200 and 1200 series) of the Opteron processors. The third generation (8300 and 2300 series) of Opteron processors will see an update in virtualization technology, specifically the Rapid Virtualization Indexing (also known by the development name "Nested Page Tables"), alongside the tagged TLB and Device Exclusion Vector (DEV).
AMD also promotes the "AMD I/O Virtualization Technology" (also known as IOMMU) for I/O virtualization. The AMD IOMMU specification has been updated to version 1.2. The specification describes the use of a HyperTransport architecture.
AMD's server initiatives include the following:
Desktop platforms.
Starting in 2007, AMD, following Intel, began using codenames for its desktop platforms such as "Spider" or "Dragon". The platforms, unlike Intel's approach, will refresh every year, putting focus on platform specialization. The platform includes components such as AMD processors, chipsets, ATI graphics and other features, but continued to the open platform approach, and welcome components from other vendors such as VIA, SiS, and Nvidia, as well as wireless product vendors.
Updates to the platform includes the implementation of IOMMU I/O Virtualization with 45 nm generation of processors, and the AMD 800 chipset series in 2009.
Embedded systems.
In February 2002, AMD acquired Alchemy Semiconductor for its Alchemy line of MIPS processors for the hand-held and portable media player markets. On June 13, 2006, AMD officially announced that the line was to be transferred to Raza Microelectronics, Inc., a designer of MIPS processors for embedded applications.
In August 2003, AMD also purchased the Geode business which was originally the Cyrix MediaGX from National Semiconductor to augment its existing line of embedded x86 processor products. During the second quarter of 2004, it launched new low-power Geode NX processors based on the K7 Thoroughbred architecture with speeds of fanless processors and , and processor with fan, of TDP 25 W. This technology is used in a variety of embedded systems (Casino slot machines and customer kiosks for instance), several UMPC designs in Asia markets, as well as the OLPC XO-1 computer, an inexpensive laptop computer intended to be distributed to children in developing countries around the world. The Geode LX processor was announced in 2005 and is said will continue to be available through 2015.
For the past couple of years AMD has been introducing 64-bit processors into its embedded product line starting with the AMD Opteron processor. Leveraging the high throughput enabled through HyperTransport and the Direct Connect Architecture these server class processors have been targeted at high end telecom and storage applications. In 2007, AMD added the AMD Athlon, AMD Turion and Mobile AMD Sempron processors to its embedded product line. Leveraging the same 64-bit instruction set and Direct Connect Architecture as the AMD Opteron but at lower power levels, these processors were well suited to a variety of traditional embedded applications. Throughout 2007 and into 2008, AMD has continued to add both single-core Mobile AMD Sempron and AMD Athlon processors and dual-core AMD Athlon X2 and AMD Turion processors to its embedded product line and now offers embedded 64-bit solutions starting with 8W TDP Mobile AMD Sempron and AMD Athlon processors for fan-less designs up to multi-processor systems leveraging multi-core AMD Opteron processors all supporting longer than standard availability.
The ATI acquisition included the Imageon and Xilleon product lines. In late 2008, the entire handheld division was sold off to Qualcomm, who have since produced the Adreno series. The Xilleon division was sold to Broadcom.
In April 2007, AMD announced the release of the M690T integrated graphics chipset for embedded designs. This enabled AMD to offer complete processor and chipset solutions targeted at embedded applications requiring high performance 3D and video such as emerging digital signage, kiosk and Point of Sale applications. The M690T was followed by the M690E specifically for embedded applications which removed the TV output, which required Macrovision licensing for OEMs, and enabled native support for dual TMDS outputs, enabling dual independent DVI interfaces.
In 2008, AMD announced the Radeon E2400, the first discrete GPU in their embedded product line offering the same long term availability as their other embedded products. That was followed in 2009 with the higher performance Radeon E4690 discrete GPU.
In 2009, AMD announced their first BGA packaged e64 architecture processors, known as the ASB1 family.
In 2010, AMD announced a second generation BGA platform referred to as ASB2. They also announced several new AM3 based processors with support for DDR3 memory.
In January 2011, AMD announced the AMD Embedded G-Series Accelerated Processing Unit. The first Fusion family APU for embedded applications. This announcement was followed by announcements for the high performance AMD Radeon E6760 and the value-conscious Radeon E6460 discrete GPUs. These solutions all added support for DirectX 11, OpenGL 4.1 and OpenCL 1.1.
In May 2012, AMD Announced the AMD Embedded R-Series Accelerated Processing Unit. This family of products incorporates the Bulldozer CPU architecture, and Discrete-class AMD Radeon™ HD 7000G Series graphics.
AMD Embedded solutions offer 5+ year product life.
Production and fabrication.
Ever since the spin-off of AMD's fabrication plants in early 2009, GlobalFoundries has been responsible for producing AMD's processors.
GlobalFoundries' main microprocessor manufacturing facilities are located in Dresden, Germany. Additionally, highly integrated microprocessors are manufactured in Taiwan made by third-party manufacturers under strict license from AMD. Between 2003 and 2005, they constructed a second manufacturing plant ( 90 nm process SOI) in the same complex in order to increase the number of chips they could produce, thus becoming more competitive with Intel. The new plant was named "Fab 36", in recognition of AMD's 36 years of operation, and reached full production in mid-2007. Fab 36 was renamed to "Fab 1" during the spin-off of AMD's manufacturing business during the creation of GlobalFoundries. In July 2007, AMD announced that they completed the conversion of Fab 1 Module 1 from to 65 nm. They then shifted their focus to the 45 nm conversion.
Corporate affairs.
Partnerships.
AMD utilizes strategic industry partnerships to further its business interests as well as to rival Intel's dominance and resources.
A partnership between AMD and Alpha Processor Inc. developed HyperTransport, a point-to-point interconnect standard which was turned over to an industry standards body for finalization. It is now used in modern motherboards that are compatible with AMD processors.
AMD also formed a strategic partnership with IBM, under which AMD gained silicon on insulator (SOI) manufacturing technology, and detailed advice on 90 nm implementation. AMD announced that the partnership would extend to 2011 for 32 nm and 22 nm fabrication-related technologies.
To facilitate processor distribution and sales, AMD is loosely partnered with end-user companies, such as HP, Compaq, ASUS, Acer, and Dell.
In 1993, AMD established a 50-50 partnership with Fujitsu called FASL, and merged into a new company called FASL LLC in 2003. The joint venture went public under the name Spansion and ticker symbol SPSN in December 2005, with AMD shares drop to 37%. AMD no longer directly participates in the Flash memory devices market now as AMD entered into a non-competition agreement, as of December 21, 2005, with Fujitsu and Spansion, pursuant to which it agreed not to directly or indirectly engage in a business that manufactures or supplies standalone semiconductor devices (including single chip, multiple chip or system devices) containing only Flash memory.
On May 18, 2006, Dell announced that it would roll out new servers based on AMD's Opteron chips by year's end, thus ending an exclusive relationship with Intel. In September 2006, Dell began offering AMD Athlon X2 chips in their desktop line-up.
In June 2011, HP announced new business and consumer notebooks equipped with the latest versions of AMD APUsaccelerated processing units. AMD will power HP's Intel-based business notebooks as well.
In the spring of 2013, AMD announced that it would be powering all three major next-generation consoles. The Xbox One and Sony PlayStation 4 are both powered by a custom-built AMD APU, and the Nintendo Wii U is powered by an AMD GPU. According to AMD, having their processors in all three of these consoles will greatly assist developers with cross-platform development to competing consoles and PCs as well as increased support for their products across the board.
Litigation with Intel.
AMD has a long history of litigation with former partner and x86 creator Intel.
Guinness World Record Achievement.
On August 31, 2011, in Austin, Texas, AMD achieved a Guinness World Record for the "Highest frequency of a computer processor": 8.429 GHz. The company ran an 8-core FX-8150 processor with only one active module (two cores), and cooled with liquid helium.During the video, cooling transitions from air to water to liquid nitrogen and finally to liquid helium.</ref> The previous record was 8.308 GHz, with an Intel Celeron 352 (one core).
On November 1, 2011, geek.com reported that Andre Yang, an overclocker from Taiwan, used an FX-8150 to set another record: 8.461 GHz.
Corporate social responsibility.
In its 2012 report on progress relating to conflict minerals, the Enough Project rated AMD the fifth most progressive of 24 consumer electronics companies.

</doc>
<doc id="2402" url="https://en.wikipedia.org/wiki?curid=2402" title="Albrecht Dürer">
Albrecht Dürer

Albrecht Dürer (; ; 21 May 1471 – 6 April 1528) was a painter, printmaker and theorist of the German Renaissance. Born in Nuremberg, Dürer established his reputation and influence across Europe when he was still in his twenties, due to his high-quality woodcut prints.
He was in communication with the major Italian artists of his time, including Raphael, Giovanni Bellini and Leonardo da Vinci, and from 1512 he was patronized by emperor Maximilian I.
His vast body of work includes engravings, his preferred technique in his later prints, altarpieces, portraits and self-portraits, watercolours and books. 
The woodcuts, such as the "Apocalypse" series (1498), retain a more Gothic flavour than the rest of his work. 
His well-known engravings include the "Knight, Death, and the Devil" (1513), "Saint Jerome in his Study" (1514) and "Melencolia I" (1514), which has been the subject of extensive analysis and interpretation. His watercolours also mark him as one of the first European landscape artists, while his ambitious woodcuts revolutionized the potential of that medium.
Dürer's introduction of classical motifs into Northern art, through his knowledge of Italian artists and German humanists, has secured his reputation as one of the most important figures of the Northern Renaissance. This is reinforced by his theoretical treatises, which involve principles of mathematics, perspective and ideal proportions.
Early life (1471–90).
Dürer was born on 21 May 1471, third child and second son of his parents, who had between fourteen and eighteen children. His father, Albrecht Dürer the Elder, was a successful goldsmith, originally Ajtósi, who in 1455 had moved to Nuremberg from Ajtós, near Gyula in Hungary. The German name "Dürer" is a translation from the Hungarian, "Ajtósi". Initially, it was "Türer," meaning doormaker, which is "ajtós" in Hungarian (from "ajtó", meaning door). A door is featured in the coat-of-arms the family acquired. Albrecht Dürer the Younger later changed "Türer", his father's diction of the family's surname, to "Dürer", to adapt to the local Nuremberg dialect. Albrecht Dürer the Elder married Barbara Holper, the daughter of his master, when he himself became a master in 1467.
Dürer's godfather was Anton Koberger, who left goldsmithing to become a printer and publisher in the year of Dürer's birth and quickly became the most successful publisher in Germany, eventually owning twenty-four printing-presses and having many offices in Germany and abroad. Koberger's most famous publication was the "Nuremberg Chronicle", published in 1493 in German and Latin editions. It contained an unprecedented 1,809 woodcut illustrations (albeit with many repeated uses of the same block) by the Wolgemut workshop. Dürer may well have worked on some of these, as the work on the project began while he was with Wolgemut.
Because Dürer left autobiographical writings and became very famous by his mid-twenties, his life is well documented by several sources. After a few years of school, Dürer started to learn the basics of goldsmithing and drawing from his father. Though his father wanted him to continue his training as a goldsmith, he showed such a precocious talent in drawing that he started as an apprentice to Michael Wolgemut at the age of fifteen in 1486. A self-portrait, a drawing in silverpoint, is dated 1484 (Albertina, Vienna) "when I was a child," as his later inscription says. Wolgemut was the leading artist in Nuremberg at the time, with a large workshop producing a variety of works of art, in particular woodcuts for books. Nuremberg was then an important and prosperous city, a centre for publishing and many luxury trades. It had strong links with Italy, especially Venice, a relatively short distance across the Alps.
"Wanderjahre" and marriage (1490–94).
After completing his term of apprenticeship, Dürer followed the common German custom of taking "Wanderjahre"—in effect gap years —in which the apprentice learned skills from artists in other areas; Dürer was to spend about four years away. He left in 1490, possibly to work under Martin Schongauer, the leading engraver of Northern Europe, but who died shortly before Dürer's arrival at Colmar in 1492. It is unclear where Dürer travelled in the intervening period, though it is likely that he went to Frankfurt and the Netherlands. In Colmar, Dürer was welcomed by Schongauer's brothers, the goldsmiths Caspar and Paul and the painter Ludwig. In 1493 Dürer went to Strasbourg, where he would have experienced the sculpture of Nikolaus Gerhaert. Dürer's first painted self-portrait (now in the Louvre) was painted at this time, probably to be sent back to his fiancée in Nuremberg.
In early 1492 Dürer travelled to Basel to stay with another brother of Martin Schongauer, the goldsmith Georg. Very soon after his return to Nuremberg, on 7 July 1494, at the age of 23, Dürer was married to Agnes Frey following an arrangement made during his absence. Agnes was the daughter of a prominent brass worker (and amateur harpist) in the city. However, no children resulted from the marriage.
First journey to Italy (1494–95).
Within three months of his marriage, Dürer left for Italy, alone, perhaps stimulated by an outbreak of plague in Nuremberg. He made watercolour sketches as he traveled over the Alps. Some have survived and others may be deduced from accurate landscapes of real places in his later work, for example his engraving "Nemesis".
In Italy, he went to Venice to study its more advanced artistic world. Through Wolgemut's tutelage, Dürer had learned how to make prints in drypoint and design woodcuts in the German style, based on the works of Martin Schongauer and the Housebook Master. He also would have had access to some Italian works in Germany, but the two visits he made to Italy had an enormous influence on him. He wrote that Giovanni Bellini was the oldest and still the best of the artists in Venice. His drawings and engravings show the influence of others, notably Antonio Pollaiuolo with his interest in the proportions of the body, Andrea Mantegna, Lorenzo di Credi and others. Dürer probably also visited Padua and Mantua on this trip.
Return to Nuremberg (1495–1505).
On his return to Nuremberg in 1495, Dürer opened his own workshop (being married was a requirement for this). Over the next five years his style increasingly integrated Italian influences into underlying Northern forms. Dürer's father died in 1502, and his mother died in 1513. His best works in the first years of the workshop were his woodcut prints, mostly religious, but including secular scenes such as "The Men's Bath House" (ca. 1496). These were larger and more finely cut than the great majority of German woodcuts hitherto, and far more complex and balanced in composition.
It is now thought unlikely that Dürer cut any of the woodblocks himself; this task would have been performed by a specialist craftsman. However, his training in Wolgemut's studio, which made many carved and painted altarpieces and both designed and cut woodblocks for woodcut, evidently gave him great understanding of what the technique could be made to produce, and how to work with block cutters. Dürer either drew his design directly onto the woodblock itself, or glued a paper drawing to the block. Either way, his drawings were destroyed during the cutting of the block.
His famous series of sixteen great designs for the "Apocalypse" is dated 1498, as is his engraving of" St. Michael Fighting the Dragon". He made the first seven scenes of the "Great Passion" in the same year, and a little later, a series of eleven on the Holy Family and saints. The "Seven Sorrows Polyptych", commissioned by Frederick III of Saxony in 1496, was executed by Dürer and his assistants c. 1500. Around 1503–1505 he produced the first seventeen of a set illustrating the "Life of the Virgin", which he did not finish for some years. Neither these, nor the "Great Passion," were published as sets until several years later, but prints were sold individually in considerable numbers.
During the same period Dürer trained himself in the difficult art of using the burin to make engravings. It is possible he had begun learning this skill during his early training with his father, as it was also an essential skill of the goldsmith. In 1496 he executed the "Prodigal Son", which the Italian Renaissance art historian Giorgio Vasari singled out for praise some decades later, noting its Germanic quality. He was soon producing some spectacular and original images, notably "Nemesis" (1502), "The Sea Monster" (1498), and "Saint Eustace" (c. 1501), with a highly detailed landscape background and animals. His landscapes of this period, such as "Pond in the Woods" and "Willow Mill", are quite different from his earlier watercolours. There is a much greater emphasis on capturing atmosphere, rather than depicting topography. 
He made a number of Madonnas, single religious figures, and small scenes with comic peasant figures. Prints are highly portable and these works made Dürer famous throughout the main artistic centres of Europe within a very few years.
The Venetian artist Jacopo de' Barbari, whom Dürer had met in Venice, visited Nuremberg in 1500, and Dürer said that he learned much about the new developments in perspective, anatomy, and proportion from him. De' Barbari was unwilling to explain everything he knew, so Dürer began his own studies, which would become a lifelong preoccupation. A series of extant drawings show Dürer's experiments in human proportion, leading to the famous engraving of "Adam and Eve" (1504), which shows his subtlety while using the burin in the texturing of flesh surfaces. This is the only existing engraving signed with his full name.
Dürer created large numbers of preparatory drawings, especially for his paintings and engravings, and many survive, most famously the "Betende Hände" ("Praying Hands") from circa 1508, a study for an apostle in the Heller altarpiece. He also continued to make images in watercolour and bodycolour (usually combined), including a number of still lifes of meadow sections or animals, including his "Young Hare" (1502) and the "Great Piece of Turf" (1503).
Second journey to Italy (1505–1507).
In Italy, he returned to painting, at first producing a series of works executed in tempera on linen. These include portraits and altarpieces, notably, the Paumgartner altarpiece and the "Adoration of the Magi". In early 1506, he returned to Venice and stayed there until the spring of 1507. By this time Dürer's engravings had attained great popularity and were being copied. In Venice he was given a valuable commission from the emigrant German community for the church of San Bartolomeo. This was the altar-piece known as the "Adoration of the Virgin" or the "Feast of Rose Garlands". It includes portraits of members of Venice's German community, but shows a strong Italian influence. It was subsequently acquired by the Emperor Rudolf II and taken to Prague. Other paintings Dürer produced in Venice include "The Virgin and Child with the Goldfinch", "Christ among the Doctors" (supposedly produced in a mere five days), and a number of smaller works.
Nuremberg and the masterworks (1507–1520).
Despite the regard in which he was held by the Venetians, Dürer returned to Nuremberg by mid-1507, remaining in Germany until 1520. His reputation had spread throughout Europe and he was on friendly terms and in communication with most of the major artists including Raphael, Giovanni Bellini and — mainly through Lorenzo di Credi — Leonardo da Vinci.
Between 1507 and 1511 Dürer worked on some of his most celebrated paintings: "Adam and Eve" (1507), "The Martyrdom of the Ten Thousand" (1508, for Frederick of Saxony), "Virgin with the Iris" (1508), the altarpiece "Assumption of the Virgin" (1509, for Jacob Heller of Frankfurt), and "Adoration of the Trinity" (1511, for Matthaeus Landauer). During this period he also completed two woodcut series, the Great Passion and the Life of the Virgin, both published in 1511 together with a second edition of the Apocalypse series. The post-Venetian woodcuts show Dürer's development of chiaroscuro modelling effects, creating a mid-tone throughout the print to which the highlights and shadows can be contrasted.
Other works from this period include the thirty-seven woodcut subjects of the Little Passion, published first in 1511, and a set of fifteen small engravings on the same theme in 1512. Indeed, complaining that painting did not make enough money to justify the time spent when compared to his prints, he produced no paintings from 1513 to 1516. However, in 1513 and 1514 Dürer created his three most famous engravings: "Knight, Death, and the Devil" (1513, probably based on Erasmus's treatise "Enchiridion militis Christiani"), "St. Jerome in his Study", and the much-debated "Melencolia I" (both 1514).
In 1515, he created his "woodcut of a Rhinoceros" which had arrived in Lisbon from a written description and sketch by another artist, without ever seeing the animal himself. An image of the Indian rhinoceros, the image has such force that it remains one of his best-known and was still used in some German school science text-books as late as last century. In the years leading to 1520 he produced a wide range of works, including the woodblocks for the first western printed star charts in 1515 and portraits in tempera on linen in 1516.
Patronage of Maximilian I.
From 1512, Maximilian I became Dürer's major patron. His commissions included "The Triumphal Arch", a vast work printed from 192 separate blocks, the symbolism of which is partly informed by Pirckheimer's translation of Horapollo's "Hieroglyphica". The design program and explanations were devised by Johannes Stabius, the architectural design by the master builder and court-painter Jörg Kölderer and the woodcutting itself by Hieronymous Andreae, with Dürer as designer-in-chief. "The Arch" was followed by "The Triumphal Procession", the program of which was worked out in 1512 by Marx Treitz-Saurwein and includes woodcuts by Albrecht Altdorfer and Hans Springinklee, as well as Dürer.
Dürer worked with pen on the marginal images for an edition of the Emperor's printed Prayer-Book; these were quite unknown until facsimiles were published in 1808 as part of the first book published in lithography. Dürer's work on the book was halted for an unknown reason, and the decoration was continued by artists including Lucas Cranach the Elder and Hans Baldung. Dürer also made several portraits of the Emperor, including one shortly before Maximilian's death in 1519.
Journey to the Netherlands (1520–21).
Maximilian's death came at a time when Dürer was concerned he was losing "my sight and freedom of hand" (perhaps caused by arthritis) and increasingly affected by the writings of Martin Luther. In July 1520 Dürer made his fourth and last major journey, to renew the Imperial pension Maximilian had given him and to secure the patronage of the new emperor, Charles V, who was to be crowned at Aachen. Dürer journeyed with his wife and her maid via the Rhine to Cologne and then to Antwerp, where he was well received and produced numerous drawings in silverpoint, chalk and charcoal. In addition to going to the coronation, he made excursions to Cologne (where he admired the painting of Stefan Lochner), Nijmegen, 's-Hertogenbosch, Bruges (where he saw Michelangelo's Madonna of Bruges), Ghent (where he admired van Eyck's altarpiece), and Zeeland.
Dürer took a large stock of prints with him and wrote in his diary to whom he gave, exchanged or sold them, and for how much. This provides rare information of the monetary value placed on prints at this time. Unlike paintings, their sale was very rarely documented. While providing valuable documentary evidence, Dürer's Netherlandish diary also reveals that the trip was not a profitable one. For example, Dürer offered his last portrait of Maximilian to his daughter, Margaret of Austria, but eventually traded the picture for some white cloth after Margaret disliked the portrait and declined to accept it. During this trip he also met Bernard van Orley, Jan Provoost, Gerard Horenbout, Jean Mone, Joachim Patinir and Tommaso Vincidor, though he did not, it seems, meet Quentin Matsys.
At the request of Christian II of Denmark, Dürer went to Brussels to paint the King's portrait. There he saw "the things which have been sent to the king from the golden land"—the Aztec treasure that Hernán Cortés had sent home to Holy Roman Emperor Charles V following the fall of Mexico. Dürer wrote that this treasure "was much more beautiful to me than miracles. These things are so precious that they have been valued at 100,000 florins". Dürer also appears to have been collecting for his own cabinet of curiosities, and he sent back to Nuremberg various animal horns, a piece of coral, some large fish fins, and a wooden weapon from the East Indies.
Having secured his pension, Dürer finally returned home in July 1521, having caught an undetermined illness—perhaps malaria —which afflicted him for the rest of his life, and greatly reduced his rate of work.
Final years in Nuremberg (1521–28).
On his return to Nuremberg, Dürer worked on a number of grand projects with religious themes, including a crucifixion scene and a Sacra Conversazione, though neither was completed. This may have been due in part to his declining health, but perhaps also because of the time he gave to the preparation of his theoretical works on geometry and perspective, the proportions of men and horses, and fortification.
However, one consequence of this shift in emphasis was that during the last years of his life, Dürer produced comparatively little as an artist. In painting, there was only a portrait of , a , , and two panels showing St. John with St. Peter in and St. Paul with St. Mark in the . This last great work, the Four Apostles, was given by Dürer to the City of Nuremberg—although he was given 100 guilders in return.
As for engravings, Dürer's work was restricted to portraits and illustrations for his treatise. The portraits include Cardinal-Elector Albert of Mainz; Frederick the Wise, elector of Saxony; the humanist scholar Willibald Pirckheimer; Philipp Melanchthon, and Erasmus of Rotterdam. For those of the Cardinal, Melanchthon, and Dürer's final major work, a drawn portrait of the Nuremberg patrician Ulrich Starck, Dürer depicted the sitters in profile, perhaps reflecting a more mathematical approach.
Despite complaining of his lack of a formal classical education, Dürer was greatly interested in intellectual matters and learned much from his boyhood friend Willibald Pirckheimer, whom he no doubt consulted on the content of many of his images. He also derived great satisfaction from his friendships and correspondence with Erasmus and other scholars. Dürer succeeded in producing two books during his lifetime. "The Four Books on Measurement" were published at Nuremberg in 1525 and was the first book for adults on mathematics in German, as well as being cited later by Galileo and Kepler. The other, a work on city fortifications, was published in 1527. "The Four Books on Human Proportion" were published posthumously, shortly after his death in 1528.
Dürer died in Nuremberg at the age of 56, leaving an estate valued at 6,874 florins—a considerable sum. His large house (purchased in 1509 from the heirs of the astronomer Bernhard Walther), where his workshop was located and where his widow lived until her death in 1539, remains a prominent Nuremberg landmark. It is now a museum. He is buried in the "Johannisfriedhof" cemetery.
Dürer and the Reformation.
Dürer's writings suggest that he may have been sympathetic to Martin Luther's ideas, though it is unclear if he ever left the Catholic Church. Dürer wrote of his desire to draw Luther in his diary in 1520: "And God help me that I may go to Dr. Martin Luther; thus I intend to make a portrait of him with great care and engrave him on a copper plate to create a lasting memorial of the Christian man who helped me overcome so many difficulties." In a letter to Nicholas Kratzer in 1524, Dürer wrote "because of our Christian faith we have to stand in scorn and danger, for we are reviled and called heretics." Most tellingly, Pirckheimer wrote in a letter to Johann Tscherte in 1530: "I confess that in the beginning I believed in Luther, like our Albert of blessed memory...but as anyone can see, the situation has become worse." Dürer may even have contributed to the Nuremberg City Council's mandating Lutheran sermons and services in March 1525. Notably, Dürer had contacts with various reformers, such as Zwingli, Andreas Karlstadt, Melanchthon, Erasmus and Cornelius Grapheus from whom Dürer received Luther's "Babylonian Captivity" in 1520.
Dürer's later works have also been claimed to show Protestant sympathies. For example, his woodcut of "The Last Supper" of 1523 has often been understood to have an evangelical theme, focussing as it does on Christ espousing the Gospel, as well the inclusion of the Eucharistic cup, an expression of Protestant utraquism, although this interpretation has been questioned. The delaying of the engraving of St Philip, completed in 1523 but not distributed until 1526, may have been due to Dürer's uneasiness with images of Saints; even if Dürer was not an iconoclast, in his last years he evaluated and questioned the role of art in religion.
Legacy and influence.
Dürer exerted a huge influence on the artists of succeeding generations, especially in printmaking, the medium through which his contemporaries mostly experienced his art, as his paintings were predominantly in private collections located in only a few cities. His success in spreading his reputation across Europe through prints was undoubtedly an inspiration for major artists such as Raphael, Titian, and Parmigianino, all of whom collaborated with printmakers in order to promote and distribute their work.
His work in engraving seems to have had an intimidating effect upon his German successors, the "Little Masters" who attempted few large engravings but continued Dürer's themes in small, rather cramped compositions. Lucas van Leyden was the only Northern European engraver to successfully continue to produce large engravings in the first third of the 16th century. The generation of Italian engravers who trained in the shadow of Dürer all either directly copied parts of his landscape backgrounds (Giulio Campagnola and Christofano Robetta), or whole prints (Marcantonio Raimondi and Agostino Veneziano). However, Dürer's influence became less dominant after 1515, when Marcantonio perfected his new engraving style, which in turn travelled over the Alps to dominate Northern engraving also.
In painting, Dürer had relatively little influence in Italy, where probably only his altarpiece in Venice was seen, and his German successors were less effective in blending German and Italian styles. His intense and self-dramatizing self-portraits have continued to have a strong influence up to the present, especially on painters in the 19th and 20th century who desired a more dramatic portrait style. Dürer has never fallen from critical favour, and there have been significant revivals of interest in his works in Germany in the "Dürer Renaissance" of about 1570 to 1630, in the early nineteenth century, and in German nationalism from 1870 to 1945.
Dürer's study of human proportions and the use of transformations to a coordinate grid to demonstrate facial variation inspired similar work by D'Arcy Thompson in his book "On Growth and Form".
The Lutheran Church remembers Dürer as a great Christian annually on April 6, along with Lucas Cranach the Elder and Hans Burgkmair. The liturgical calendar of the Episcopal Church (United States) remembers him, Cranach and Matthias Grünewald on August 5.
Theoretical works.
In all his theoretical works, in order to communicate his theories in the German language rather than in Latin, Dürer used graphic expressions based on a vernacular, craftsmen's language. For example, 'Schneckenlinie' ('snail-line') was his term for a spiral form. Thus, Dürer contributed to the expansion in German prose which Martin Luther had begun with his translation of the Bible.
"Four Books on Measurement".
Dürer's work on geometry is called the "Four Books on Measurement" ("Underweysung der Messung mit dem Zirckel und Richtscheyt" or "Instructions for Measuring with Compass and Ruler"). The first book focuses on linear geometry. Dürer's geometric constructions include helices, conchoids and epicycloids. He also draws on Apollonius, and Johannes Werner's 'Libellus super viginti duobus elementis conicis' of 1522.
The second book moves onto two dimensional geometry, i.e. the construction of regular polygons. Here Dürer favours the methods of Ptolemy over Euclid.
The third book applies these principles of geometry to architecture, engineering and typography.
In architecture Dürer cites Vitruvius but elaborates his own classical designs and columns. In typography, Dürer depicts the geometric construction of the Latin alphabet, relying on Italian precedent. However, his construction of the Gothic alphabet is based upon an entirely different modular system. The fourth book completes the progression of the first and second by moving to three-dimensional forms and the construction of polyhedra. Here Dürer discusses the five Platonic solids, as well as seven Archimedean semi-regular solids, as well as several of his own invention.
In all these, Dürer shows the objects as nets. Finally, Dürer discusses the Delian Problem and moves on to the 'construzione legittima', a method of depicting a cube in two dimensions through linear perspective. It was in Bologna that Dürer was taught (possibly by Luca Pacioli or Bramante) the principles of linear perspective, and evidently became familiar with the 'costruzione legittima' in a written description of these principles found only, at this time, in the unpublished treatise of Piero della Francesca. He was also familiar with the 'abbreviated construction' as described by Alberti and the geometrical construction of shadows, a technique of Leonardo da Vinci. Although Dürer made no innovations in these areas, he is notable as the first Northern European to treat matters of visual representation in a scientific way, and with understanding of Euclidean principles. In addition to these geometrical constructions, Dürer discusses in this last book of "Underweysung der Messung" an assortment of mechanisms for drawing in perspective from models and provides woodcut illustrations of these methods that are often reproduced in discussions of perspective.
"Four Books on Human Proportion".
Dürer's work on human proportions is called the "Four Books on Human Proportion" ("Vier Bücher von Menschlicher Proportion") of 1528. The first book was mainly composed by 1512/13 and completed by 1523, showing five differently constructed types of both male and female figures, all parts of the body expressed in fractions of the total height. Dürer based these constructions on both Vitruvius and empirical observations of, "two to three hundred living persons," in his own words. The second book includes eight further types, broken down not into fractions but an Albertian system, which Dürer probably learned from Francesco di Giorgio's 'De harmonica mundi totius' of 1525. In the third book, Dürer gives principles by which the proportions of the figures can be modified, including the mathematical simulation of convex and concave mirrors; here Dürer also deals with human physiognomy. The fourth book is devoted to the theory of movement.
Appended to the last book, however, is a self-contained essay on aesthetics, which Dürer worked on between 1512 and 1528, and it is here that we learn of his theories concerning 'ideal beauty'. Dürer rejected Alberti's concept of an objective beauty, proposing a relativist notion of beauty based on variety. Nonetheless, Dürer still believed that truth was hidden within nature, and that there were rules which ordered beauty, even though he found it difficult to define the criteria for such a code. In 1512/13 his three criteria were function ('Nutz'), naïve approval ('Wohlgefallen') and the happy medium ('Mittelmass'). However, unlike Alberti and Leonardo, Dürer was most troubled by understanding not just the abstract notions of beauty but also as to how an artist can create beautiful images. Between 1512 and the final draft in 1528, Dürer's belief developed from an understanding of human creativity as spontaneous or inspired to a concept of 'selective inward synthesis'. In other words, that an artist builds on a wealth of visual experiences in order to imagine beautiful things. Dürer's belief in the abilities of a single artist over inspiration prompted him to assert that "one man may sketch something with his pen on half a sheet of paper in one day, or may cut it into a tiny piece of wood with his little iron, and it turns out to be better and more artistic than another's work at which its author labours with the utmost diligence for a whole year."
List of works.
For lists of Albrecht Dürer's works, see:

</doc>
<doc id="2403" url="https://en.wikipedia.org/wiki?curid=2403" title="Australian rules football">
Australian rules football

Australian rules football, officially known as Australian football, also called football, footy, or Aussie rules (and in some regions marketed as AFL after the Australian Football League, the most popular and only fully professional Australian football league in the country), is a sport played between two teams of eighteen players on the field of either an Australian football ground, a modified cricket field, or a similarly sized sports venue.
The main way to score points is by kicking the ball between the two tall goal posts. The team with the higher total score at the end of the match wins unless a draw is declared.
During general play, players may position themselves anywhere on the field and use any part of their bodies to move the ball. The primary methods are kicking, handballing and running with the ball. There are rules on how the ball can be handled: for example, players running with the ball must intermittently bounce or touch it on the ground. Throwing the ball is not allowed and players must not get caught holding the ball. A distinctive feature of the game is the mark, where players anywhere on the field who catch a ball from a kick (with specific conditions) are awarded possession. Possession of the ball is in dispute at all times except when a free kick or mark is paid.
Australian football is a contact sport in which players can tackle using their hands or use their whole body to obstruct opponents. Dangerous physical contact (such as pushing an opponent in the back), interference when marking and deliberately slowing the play are discouraged with free kicks, distance penalties or suspension for a certain number of matches, depending on the seriousness of the infringement. Frequent physical contests, spectacular marking, fast movement of both players and the ball and high scoring are the game's main attributes.
The game's origins can be traced to football matches played in Melbourne in 1858. Australian football became codified in May 1859 when the first laws were published by the Melbourne Football Club.
Australian football has the highest spectator attendance of all sports in Australia. The sport is also played at amateur level in many countries and in several variations.
The most prestigious competition is the Australian Football League (AFL), culminating in the annual AFL Grand Final, currently the highest attended club championship event in the world. The rules of Australian football are governed by the AFL Commission with the advice of the AFL's Laws of the Game Committee.
History.
Origins.
There is documented evidence of "foot-ball" being played sporadically in the Australian colonies in the first half of the 19th century. While the exact rules of these games are unknown, they were most likely forms of folk football, and share no causal link with Australian rules football.
In 1858, public schools in Melbourne, Victoria, are first recorded organising football games modelled on precedents at English schools. The earliest recorded match, held on 15 June, was between Scotch College and Melbourne Grammar School on the St Kilda foreshore.
On 10 July 1858, the Melbourne-based "Bell's Life in Victoria and Sporting Chronicle" published a letter by Tom Wills, captain of the Victoria cricket team, calling for the formation of a "foot-ball club" with a "code of laws" to keep cricketers fit during winter. Born in Australia, Wills learnt a nascent form of rugby football whilst a pupil at Rugby School in England, and returned to his homeland a star athlete and cricketer. His letter is regarded by many historians as giving impetus for the development of a new code of football today known as Australian football.
Two weeks after Wills' letter, his friend, cricketer Jerry Bryant, posted an advertisement for a scratch match at the Richmond Paddock adjoining the Melbourne Cricket Ground. This was the first of several "kickabouts" held that year involving members of the Melbourne Cricket Club, including Wills, Bryant, W. J. Hammersley and J. B. Thompson. Trees were used as goalposts and play typically lasted an entire afternoon. Without an agreed upon code of laws, some players were guided by rules they had learned in the British Isles, "others by no rules at all".
Another significant milestone in the sport's development was a match played under experimental rules between Melbourne Grammar School and Scotch College, held at the Richmond Paddock. This 40-a-side contest, umpired by Wills and Scotch College teacher John Macadam, began on 7 August and continued over two subsequent Saturdays, ending in a draw with each side kicking one goal. It is commemorated with a statue outside the Melbourne Cricket Ground, and the two schools have competed annually ever since in the Cordner-Eggleston Cup, the world's oldest continuous football competition.
The theory that Australian football was derived from Gaelic football emerged in the early 20th century, despite the fact that Australian football was codified almost 30 years before the Irish game. There is no archival evidence in favour of a Gaelic origin, and the style of play shared between the two modern codes was evident in Australia long before the Irish game evolved in a similar direction. Since the 1980s, the theory that Australian football comes from the Aboriginal game of Marn Grook has also gained attention. It is claimed that Wills, growing up amongst Aborigines in Victoria, may have seen or played Marn Grook, and used elements from the game when formulating the laws of Australian football. This is purely speculative, and according to biographer Greg de Moore's research, Wills was "almost solely influenced by his experience at Rugby School".
First rules.
A loosely organised Melbourne side, captained by Wills, played against other football enthusiasts in the winter and spring of 1858. The following year, on 14 May, the Melbourne Football Club officially came into being, making it one of the world's oldest football clubs. Three days after its formation, Wills, Hammersley, Thompson and teacher Thomas H. Smith met at the Parade Hotel in East Melbourne, owned by Bryant, and drafted ten simple rules: "The Rules of the Melbourne Football Club". These are the laws from which Australian rules football evolved. The document was signed by the rule-framers and three other club office bearers: Alex Bruce, T. Butterworth and J. Sewell. The rules were distributed throughout the colony; Thompson in particular did much to promote the new code in his capacity as a journalist. Australian football's date of codification predates that of any other major football code, including soccer (codified in 1863) and rugby union (codified in 1871).
Early competition in Victoria.
Following in Melbourne's footsteps, Castlemaine, Melbourne University and Geelong also formed football clubs in 1859. While many early teams from Melbourne and provincial Victoria participated in one-off matches, most had not yet formed clubs for regular competition.
The first Australian rules football trophy, the 1861 Challenge Cup, was won in 1862 under Melbourne's rules by University over Melbourne. The competition continued into the 1860s with the addition of other teams from Melbourne's suburbs. Two further competitions, the South Yarra Challenge Cup (which had evolved from the Caledonian Games) and "Second Twenties" were held in the 1860s and 1870s.
With input from other clubs, the Melbourne rules underwent several minor revisions in the early 1860s, thus establishing a uniform code known as "Victorian rules". In 1866, the "first distinctively Victorian rule", the running bounce, was formalised at a meeting of club delegates chaired by H. C. A. Harrison, an influential pioneer who started playing in 1859 at the invitation of Wills, his cousin. Behind posts, introduced at this time, are believed to have come from Geelong. In 1869, a 100-minute time limit was used for the first time. Previous to this, winners were decided in a number of ways, but most commonly the first side to kick two goals.
The relationship with cricket primarily came out of co-existence and many of football's founders were cricketers. As a result, the sport shares some terminology (i.e. "umpires" and "boundary"). However cricket authorities did not initially allow football on their grounds and in the early years football was played primarily in parks. While football was allowed on the MCG as early as 1859, it wasn't regularly played there until the late 1870s when cricket authorities saw an opportunity to capitalise on the rapid growth of Australian football, and soon most grounds in Victoria expanded to accommodate the dual purpose, a situation that continues to this day.
Football matches between 1859 and 1899 were played in a 20-per-side format.
Spread to other colonies.
As "Victorian rules" gained roots in other Australasian colonies—beginning with South Australia (1860), Tasmania (1864), Queensland (1866), and New Zealand (1871)—it came to be known as "Australian rules" or "Australasian rules". In 1877, the sport's first governing bodies, the South Australian Football Association (SAFA) and the Victorian Football Association (VFA), formed on 30 April and 17 May respectively. The game was introduced to New South Wales in 1877 and Western Australia in 1881, where it took hold during the colony's gold rushes.
By the 1880s, Australian football had become the prevailing football code in Australia's southern and western colonies, and experienced a period of dominance in Queensland, where, like in areas of New South Wales, it struggled to thrive, largely due to the spread of rugby football, regional rivalries and the lack of strong local governing bodies. In the case of Sydney, denial of access to grounds, the influence of university headmasters from Britain who favoured rugby, and the loss of players to other codes inhibited the game's growth.
In 1879, the first intercolonial match took place in Melbourne between Victoria and South Australia, and clubs began touring the colonies. By this stage, the sport had become the first code of football to develop mass spectator appeal, with important matches drawing up to 15,000 fans. New rules such as holding the ball led to a "golden era" of fast, long-kicking and high-marking football in the 1880s, a time which also saw the rise of professionalism, particularly in Western Australia and Victoria, and world record attendances for sports viewing. Australian football was now widely referred to as "the people's game".
Emergence of the VFL.
In 1896, delegates from the strongest and wealthiest VFA clubs—Carlton, Collingwood, Essendon, Fitzroy, Geelong, Melbourne, St Kilda and South Melbourne—met to form a breakaway professional competition and in 1897, the Victorian Football League (VFL) was born. The VFL's popularity grew rapidly and by 1925, with the addition of Hawthorn, Footscray and North Melbourne, had become the most prominent league in the country and would dominate many aspects of the sport.
Effects of the two world wars.
Both World War I and World War II had a devastating effect on Australian football and on Australian sport in general. While scratch matches were played by Australian "diggers" in remote locations around the world, the game lost many of its great players to wartime service. Some clubs and competitions never fully recovered. Between 1914 and 1915, a proposed hybrid code of Australian football and rugby league, the predominant code of football in New South Wales and Queensland, was trialed without success. World War I saw the game in New Zealand go into recess for three quarters of a century. In Queensland, the state league went into recess for the duration of the war. VFL club University left the league and went into recess due to severe casualties. The WAFL lost two clubs and the SANFL was suspended for one year in 1916 due to heavy club losses. The ANZAC Day clash is one example of how the war continues to be remembered in the football community.
Interstate football and the Australian National Football Council.
The Australian National Football Council's primary role was to govern the game at national level to facilitate interstate representative and club competition.
The ANFC ran the Championship of Australia, the first national club competition, which commenced in 1888 and saw clubs from different states compete on an even playing field. During this time, the Port Adelaide won a record four national club championships. Although clubs from other states were at times invited, the final was almost always between the premiers from the two strongest state competitions of the time—South Australia and Victoria—and the majority of matches were played in Adelaide at the request of the SAFA/SAFL. The last match was played in 1976, with North Adelaide being the last non-Victorian winner in 1972. Between 1976 and 1987, the ANFC, and later the Australian Football Championships (AFC) ran a night series, which invited clubs and representative sides from around the country to participate in a knock-out tournament parallel to the premiership seasons, which Victorian sides still dominated.
With the lack of international competition, state representative matches were regarded with great importance. The Australian Football Council co-ordinated regular interstate carnivals, including the Australasian Football Jubilee, held in Melbourne in 1908 to celebrate the game's bicentenary. Due in part to the VFL poaching talent from other states, Victoria dominated interstate matches for three quarters of a century. State of Origin rules, introduced in 1977, stipulated that rather than representing the state of their adopted club, players would return to play for the state they were first recruited in. This instantly broke Victoria's stranglehold over state titles and Western Australia and South Australia began to win more of their games against Victoria. Both New South Wales and Tasmania scored surprise victories at home against Victoria in 1990.
Towards a national competition.
The term "Barassi Line", named after VFL star Ron Barassi, was coined by scholar Ian Turner in 1978 to describe the "fictitious geographical barrier" in Australia's footballing landscape, separating large parts of New South Wales and Queensland which followed rugby from the rest of the country, where Australian football reigned. This description prompted the first suggestions of regular interstate club competition and of establishing a national Australian football league.
By 1980, the way the game was played had changed dramatically due to innovative coaching tactics, with the phasing out of many of the game's kicking styles and the increasing use of handball; while presentation was influenced by television.
In 1982, in a move that heralded big changes within the sport, one of the original VFL clubs and now struggling, South Melbourne, relocated to Sydney and became known as the Sydney Swans. In the late 1980s, due to the poor financial standing of many of the Victorian clubs, the VFL pursued a more national competition. Two more non-Victorian clubs, West Coast and Brisbane, began playing in 1987. In their early years, the Sydney and Brisbane clubs struggled both on and off-field because the substantial TV revenues they generated by playing on a Sunday went to the VFL. To protect these revenues the VFL granted significant draft concessions and financial aid to keep them competitive. Each club was required to pay a licence fee which allowed the Victorian-based clubs to survive.
The VFL changed its name to the Australian Football League (AFL) for the 1990 season, and over the next decade, three non-Victorian clubs gained entry: Adelaide (1991), Fremantle (1995) and the SANFL's Port Adelaide (1997), the only pre-existing club outside Victoria to join the league. In 2011 and 2012 respectively, two new non-Victorian clubs were added to the competition: Gold Coast and Greater Western Sydney. The AFL, currently with 18 member clubs, is the sport's elite competition and most powerful body.
Following the emergence of the AFL, state leagues were quickly relegated to a second-tier status. The VFA merged with the former VFL reserves competition in 1998, adopting the VFL name. State of Origin also declined in importance, especially after an increasing number of player withdrawals. The AFL turned its focus to the annual International Rules Series against Ireland in 1998 before abolishing State of Origin the following year. State and territorial leagues still contest interstate matches.
Although a Tasmanian AFL Bid is ongoing, the AFL's focus has been on expanding into markets outside Australian football's traditional heartlands. The AFL regularly schedules pre-season exhibition matches in all Australian states and territories as part of the Regional Challenge. The AFL signaled further attempts at expansion in the 2010s by hosting home-and-away matches in New Zealand, followed by China.
Laws of the game.
Field.
Both the ball and the field of play are oval in shape. No more than 18 players of each team are permitted to be on the field at any time.
Up to three interchange (reserve) players may be swapped for those on the field at any time during the game. In Australian rules terminology, these players wait for substitution "on the bench"—an area with a row of seats on the sideline. Players must interchange through a designated interchange "gate" with strict penalties for too many players from one team on the field. In addition, some leagues like the AFL have each team designate one player as a substitute who can be used to make a single permanent exchange of players during a game.
There is no offside rule nor are there set positions in the rules; unlike many other forms of football, players from both teams may disperse across the whole field before the start of play. However, a typical on-field structure consists of six forwards, six defenders or "backmen" and six midfielders, usually two wingmen, one centre and three followers, including a ruckman, ruck-rover and rover. Only four players from each team are allowed within the centre square () at every centre bounce, which occurs at the commencement of each quarter, and to restart the game after a goal is scored. There are also other rules pertaining to allowed player positions during set plays (that is, after a mark or free kick) and during kick-ins following the scoring of a behind.
Match duration.
A game consists of four quarters and a timekeeper officiates their duration. At professional level quarters consist of 20 minutes of play, with the clock being stopped for instances such as scores, the ball going out of play or at the umpire's discretion. The umpire signals "time-off" to stop the clock for various reasons, such as the player in possession being tackled to the ground and leading to stagnant play as neither side can recover the ball. Time resumes when the umpire signals "time-on" or when the ball is brought into play. Such stoppages generally lead to quarters being extended by between five and ten minutes. The official game clock is only known on the field by the timekeepers. Official game time is not displayed to the players or the public; the only knowledge they have of time is when sirens sound to mark the beginning and end of each quarter. Official time may be approximated by broadcasters to display to television audiences. Teams change ends at the end of each quarter; umpires change ends at half time.
General play.
Games are officiated by umpires. Before the game, the winner of a coin toss determines which directions the teams will play to begin. Australian football begins after the first siren, when the umpire bounces the ball on the ground (or throws it into the air if the condition of the ground is poor), and the two ruckmen (typically the tallest players from each team) battle for the ball in the air on its way back down. This is known as the "ball-up". Certain disputes during play may also be settled with a "ball-up" from the point of contention. If the ball ever goes out of bounds (beyond the oval boundary line around the edge of the field), a boundary umpire will stand with his back to the infield and return the ball into play with a "throw-in", a high backwards toss back into the field of play.
The ball can be propelled in any direction by way of a foot, clenched fist (called a handball or "handpass") or open-hand tap but it cannot be thrown under any circumstances. Once a player takes possession of the ball he must dispose of it by either kicking or handballing it. Any other method of disposal is illegal and will result in a free kick to the opposing team. This is usually called "incorrect disposal", "dropping the ball" or "throwing". If the ball is not in the possession of one player it can be moved on with any part of the body.
A player may run with the ball, but it must be bounced or touched on the ground at least once every 15 metres. Opposition players may bump or tackle the player to obtain the ball and, when tackled, the player must dispose of the ball cleanly or risk being penalised for holding the ball. The ball carrier may only be tackled between the shoulders and knees. If the opposition player forcefully contacts a player in the back while performing a tackle, the opposition player will be penalised for a push in the back. If the opposition tackles the player with possession below the knees (a "low tackle" or a "trip") or above the shoulders (a "high tackle"), the team with possession of the football gets a free kick.
If a player takes possession of the ball that has travelled more than from another player's kick, by way of a catch, it is claimed as a "mark" (meaning that the game stops while he prepares to kick from the point at which he marked). Alternatively, he may choose to "play on" forfeiting the set shot in the hope of pressing an advantage for his team (rather than allowing the opposition to reposition while he prepares for the free kick). Once a player has chosen to play on, normal play resumes and the player who took the mark is again able to be tackled.
There are different styles of kicking depending on how the ball is held in the hand. The most common style of kicking seen in today's game, principally because of its superior accuracy, is the drop punt, where the ball is dropped from the hands down, almost to the ground, to be kicked so that the ball rotates in a reverse end over end motion as it travels through the air. Other commonly used kicks are the torpedo punt (also known as the spiral, barrel, or screw punt), where the ball is held flatter at an angle across the body, which makes the ball spin around its long axis in the air, resulting in extra distance (similar to the traditional motion of an American football punt), and the checkside punt or "banana", kicked across the ball with the outside of the foot used to curve the ball (towards the right if kicked off the right foot) towards targets that are on an angle. There is also the "snap", which is almost the same as a checkside punt except that it is kicked off the inside of the foot and curves in the opposite direction. It is also possible to kick the ball so that it bounces along the ground. This is known as a "grubber". Grubbers can bounce in a straight line, or curve to the left or right.
Apart from free kicks, marks or when the ball is in the possession of an umpire for a "ball up" or "throw in", the ball is always in dispute and any player from either side can take possession of the ball.
Scoring.
A "goal", worth 6 points, is scored when the football is propelled through the goal posts at any height (including above the height of the posts) by way of a kick from the attacking team. It may fly through "on the full" (without touching the ground) or bounce through, but must not have been touched, on the way, by any player from either team. A goal cannot be scored from the foot of an opposition (defending) player.
A "behind", worth 1 point, is scored when the ball passes between a goal post and a behind post at any height, or if the ball hits a goal post, or if any player sends the ball between the goal posts by touching it with any part of the body other than a foot. A behind is also awarded to the attacking team if the ball touches any part of an opposition player, including his foot, before passing between the goal posts. When an opposition player deliberately scores a behind for the attacking team (generally as a last resort, because of the risk of their scoring a goal) this is termed a rushed behind. Before the start of the 2009 season, there was no additional penalty imposed for rushing a behind, compared to any other behind. However, for the start of the 2009 season a new rule was announced awarding a free kick against any player who deliberately rushes a behind.
The goal umpire signals a goal with two hands pointed forward at elbow height, or a behind with one hand. The umpire then confirms the signal with the other goal umpire by waving flags above their heads.
The team that has scored the most points at the end of play wins the game. If the scores are level on points at the end of play, then the game is a draw; extra time applies only during finals matches in some competitions.
As an example of a score report, consider a match between and with the former as the home team. Collingwood's score of 16 goals and 12 behinds equates to 108 points. St Kilda's score of 7 goals and 10 behinds equates to a 52-point tally. Collingwood wins the match by a margin of 56 points. Such a result would be written as:
And said:
Additionally, it can be said that:
The home team is typically listed first and the visiting side is listed second. The scoreline is written with respect to the home side.
For example, won in successive weeks, once as the home side and once as the visiting side. These would be written out thus:
Structure and competitions.
The "football season" proper is from March to August (early autumn to late winter in Australia) with finals being held in September and October. In the tropics, the game is sometimes played in the wet season (October to March). Pre-season competitions in southern Australia usually begin in late February.
The AFL is recognised by the Australian Sports Commission as being the National Sporting Organisation for Australian Football. There are also seven state/territory-based organisations in Australia, most of which are now either owned by or affiliated to the AFL.
Most of these hold annual semi-professional club competitions while the others oversee more than one league. Local semi-professional or amateur organisations and competitions are often affiliated to their state organisations.
The AFL is the "de facto" world governing body for Australian football. There are also a number of affiliated organisations governing amateur clubs and competitions around the world.
For almost all Australian football club competitions the aim is to win the "Premiership". The premiership is always decided by a "finals series". The teams that occupy the highest positions on the "ladder" after the "home-and-away" season play off in a "semi-knockout" finals series, culminating in a single Grand Final match to determine the premiers. Typically between four and eight teams contest the finals series. The team which finishes first on the ladder after the home-and-away season is referred to as a "minor premier", but this usually holds little stand-alone significance, other than receiving a better draw in the finals.
Many suburban and amateur leagues have a sufficient number of teams to be played across several tiered divisions, with promotion of the lower division premiers and relegation of the upper division's last placed team at the end of each year. At present, none of the top level national or state level leagues in Australia are large enough to warrant this structure.
Women's Australian football.
The level of interest shown by women in Australian football in considered unique among the world's football codes. It was the case in the 19th-century, as it is in modern times, that women made up approximately half of crowds at Australian football matches—a far greater proportion than association football and the two rugby codes. This has been attributed in part to the egalitarian character of Australian football's origins in public parks where women could mingle freely and support the game in various ways.
As of 2015, over 280,000 females participate in the game across Australia. The AFL Women's National Championships is the premier competition for women's Australian football. On the back of the inaugural AFL Women's Draft in 2013 and a series of exhibition matches at the MCG, the AFL stated that it would like to establish a semi-professional, nationally televised women's league competition by 2020. A surge in viewing interest and participation in women's football prompted the AFL to push the league's founding date to 2017.
Australian football internationally.
Australian football is played at an amateur level in various countries throughout the world. Twenty countries participated in the Euro Cup and 23 countries have participated in the International Cup with both competitions prohibiting Australian players. Over 20 countries have either affiliation or working agreements with the AFL. There have been many VFL/AFL players who were born outside Australia, an increasing number of which have been recruited through initiatives such as the Irish experiment and more recently, international scholarship programs.
In the late 19th and early 20th centuries, the game spread with the Australian diaspora to areas such as New Zealand and South Africa; however this growth went into rapid decline following World War I. After World War II, the sport experienced a small amount of growth in the Pacific region, particularly in Nauru, where Australian football is the national sport, as well as Papua New Guinea and New Zealand.
Most of the current amateur clubs and leagues in existence have developed since the 1980s, when leagues began to be established in North America, Europe and Asia. The sport developed a cult following in the United States when matches were broadcast on ESPN in the late 1980s. As the size of the Australian diaspora has increased, so has the number of clubs outside Australia. This expansion has been further aided by multiculturalism and assisted by exhibition matches as well as exposure generated through players who have converted to and from other football codes. In Papua New Guinea, New Zealand, South Africa, Canada, and the United States there are many thousands of players.
Prince Charles is the Patron of AFL Europe. In 2013, participation across AFL Europe's 21 member nations was more than 5,000 players, the majority of which are European nationals rather than Australian expats. The sport also has a growing presence in India.
The AFL became the de facto governing body when it pushed for the closure of the International Australian Football Council in 2002. The Australian Football International Cup is currently the highest level of senior international competition.
International rules football.
The similarities between Australian football and the Irish sport of Gaelic football have allowed for the creation of a hybrid code known as international rules football. The first international rules matches were contested in Ireland during the 1967 Australian Football World Tour. Since then, various sets of compromise rules have been trialed, and in 1984 the International Rules Series commenced with national representative sides selected by Australia's state leagues (later by the AFL) and the Gaelic Athletic Association (GAA). The competition became an annual event in 1998, but was postponed indefinitely in 2007 when the GAA pulled out due to Australia's severe and aggressive style of play. It resumed in Australia in 2008 under new rules to protect the player with the ball.
Cultural impact and popularity.
Australian football is a sport rich in tradition and Australian cultural references, especially surrounding the rituals of gameday for players, officials and supporters.
Australian football has been an inspiration for writers and poets including Manning Clarke, Bruce Dawe and Philip Hodgins. Paintings by Arthur Streeton ("The National Game", 1889) and Sidney Nolan ("Footballer", 1946) helped to establish Australian football as a serious subject for artists. Many Aboriginal artists have explored the game, often fusing it with the mythology of their region. Statues of Australian football identities can be found throughout the country. In cartooning, WEG's VFL/AFL premiership posters—inaugurated in 1954—have achieved iconic status among Australian football fans. Dance sequences based on Australian football feature heavily in Robert Helpmann's 1964 ballet "The Display", his first and most famous work for the Australian Ballet. The game has also inspired well-known plays such as "And the Big Men Fly" (1963) by Alan Hopgood and David Williamson's "The Club" (1977), which was adapted into a 1980 film by director Bruce Beresford. Mike Brady's 1979 hit "Up There Cazaly" is considered an Australian football anthem, and references to the sport can be found in works by popular musicians, from singer-songwriter Paul Kelly to the alternative rock band TISM. Many Australian football video games have been released, most notably the AFL series.
Australian football has attracted more overall interest among Australians (as measured by the Sweeney Sports report) than any other football code, and, when compared with all sports throughout the nation, has consistently ranked first in the winter reports, and most recently third behind cricket and swimming in summer.
In 2006, 615,549 registered participants played Australian football in Australia. Participation increased 7.84% between 2005 and 2006. The Australian Sports Commission statistics show a 64% increase in the total number of participants over the 10-year period between 2001 and 2010. In 2008 there were 35,000 people in 32 countries playing in structured competitions of Australian football outside of Australia.
Many related games have emerged from Australian football, mainly with variations of contact to encourage greater participation. These include kick-to-kick (and its variants end-to-end footy and marks up), Auskick, rec footy, 9-a-side footy, masters Australian football, handball and longest-kick competitions. Players outside of Australia sometimes engage in related games adapted to available fields, like metro footy (played on gridiron fields) and Samoa rules (played on rugby fields).
Australian Football Hall of Fame.
For the centenary of the VFL/AFL in 1996, the Australian Football Hall of Fame was established. In that year 136 identities were inducted, including 100 players, 10 coaches, 10 umpires, 10 administrators and six media representatives.
The elite "Legend" status was bestowed on 12 members of the Hall of Fame in 1996: Ron Barassi, Haydn Bunton Senior, Roy Cazaly, John Coleman, Jack Dyer, Polly Farmer, Leigh Matthews, John Nicholls, Bob Pratt, Dick Reynolds, Bob Skilton and Ted Whitten (see above list for further details).
The following thirteen members have been promoted to the status of "Legend" since 1996: Ian Stewart (1997), Gordon Coventry (1998), Peter Hudson (1999), Kevin Bartlett (2000), Barrie Robran (2001), Bill Hutchison (2003), Jock McHale (2005), Darrel Baldock (2006), Norm Smith (2007), Alex Jesaulenko (2008), Kevin Murray (2010), Barry Cable (2012), and Tony Lockett (2015).
Bibliography.
Books
Journals

</doc>
<doc id="2405" url="https://en.wikipedia.org/wiki?curid=2405" title="Aon (company)">
Aon (company)

Aon plc is a British multinational corporation headquartered in London, United Kingdom, that provides risk management, insurance and reinsurance brokerage, investment banking, human resource solutions and outsourcing services. Aon has approximately 500 offices worldwide, serving 120 countries with 65,000 employees.
In 2011, Aon was ranked as the largest insurance broker in the world based on revenue. Aon was the principal partner and global shirt sponsor of the Premier League team Manchester United F.C. from 2010 until 2014.
Aon was created in 1982, when the Ryan Insurance Group merged with the Combined Insurance Company of America. In 1987, that company was renamed Aon, a Gaelic word meaning .
In January 2012, Aon announced that its headquarters would be moved to London.
Corporate overview.
Aon is a global professional services firm that advises clients on the topics of risk and people. The company is a provider of risk management, insurance and reinsurance brokerage, human resource solutions and outsourcing services.
Aon is divided into three business units that each specialize in a particular line of business. The firm's risk management business, Aon Risk Solutions provides retail property/casualty, liability, and other insurance products for groups and businesses, as well as risk management services. Its reinsurance business, Aon Benfield, specializes in reinsurance brokerage and investment banking & capital advisory (through Aon Securities Inc.). The firm's human resource solutions business, Aon Hewitt, provides consulting and outsourcing services to clients.
History.
W. Clement Stone's mother bought a small Detroit insurance agency, and in 1918 brought her son into the business. Mr. Stone sold low-cost, low-benefit accident insurance, underwriting and issuing policies on-site. The next year he founded his own agency, the Combined Registry Co.
As the Great Depression began, Stone reduced his workforce and improved training. Forced by his son's respiratory illness to winter in the South, Stone moved to Arkansas and Texas. In 1939 he bought American Casualty Insurance Co. of Dallas, Texas. It was consolidated with other purchases as the Combined Insurance Co. of America in 1947. The company continued through the 1950s and 1960s, continuing to sell health and accident policies. In the 1970s, Combined expanded overseas despite being hit hard by the recession.
In 1982, after 10 years of stagnation under Clement Stone Jr., the elder Stone, then 79, resumed control until the completion of a merger with Ryan Insurance Co. allowed him to transfer control to Patrick Ryan. Ryan, the son of a Ford dealer in Wisconsin, had started his company as an auto credit insurer in 1964. In 1976, the company bought the insurance brokerage units of the Esmark conglomerate. Ryan focused on insurance brokering and added more upscale insurance products. He also trimmed staff and took other cost-cutting measures, and in 1987 he changed Combined's name to Aon. In 1992, he bought Dutch insurance broker Hudig-Langeveldt. In 1995, the company sold its remaining direct life insurance holdings to General Electric to focus on consulting. The following year, it began offering hostile takeover insurance policies to small and mid-sized companies.
Aon built a global presence through purchases. In 1997, it bought The Minet Group, as well as insurance brokerage Alexander & Alexander Services, Inc. in a deal that made Aon (temporarily) the largest insurance broker worldwide. The firm made no US buys in 1998, but doubled its employee base with purchases including Spain's largest retail insurance broker, Gil y Carvajal, and the formation of Aon Korea, the first non-Korean firm of its kind to be licensed there.
Responding to industry demands, Aon announced its new fee disclosure policy in 1999, and the company reorganised to focus on buying personal line insurance firms and to integrate its acquisitions. That year it bought Nikols Sedgwick Group, an Italian insurance firm, and formed RiskAttack (with Zurich US), a risk analysis and financial management concern aimed at technology companies. The cost of integrating its numerous purchases, however, hammered profits in 1999.
Despite its troubles, in 2000 Aon bought Reliance Group's accident and health insurance business, as well as Actuarial Sciences Associates, a compensation and employee benefits consulting company. Later in that year, however, the company decided to cut 6% of its workforce as part of a restructuring effort. In 2003, the company saw revenues increase primarily because of rate hikes in the insurance industry. Also that year, Endurance Specialty, a Bermuda-based underwriting operation that Aon helped to establish in November 2001 along with other investors, went public. The next year Aon sold most of its holdings in Endurance.
In late 2007, Aon announced the divestiture of its underwriting business. With this move, the firm sold off its two major underwriting subsidiaries: Combined Insurance Company of America (acquired by ACE Limited for $2.4 billion) and Sterling Life Insurance Company (purchased by Munich Re Group for $352 million). The low margin and capital-intensive nature of the underwriting industry was the primary reason for the firm's decision to divest. Upon completion of the move, Aon turned its attention to expanding its broking and consulting capabilities.
This growth strategy manifested in November 2008 when Aon announced it had acquired reinsurance intermediary and capital advisor Benfield Group Limited for $1.75 billion. The acquisition amplified the firm's broking capabilities, positioning Aon one of the largest players in the reinsurance brokerage industry.
In 2010, Aon made its most significant acquisition to date with the purchase of Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion. Aside from drastically boosting Aon's human resources consulting capacity and entering the firm into the business process outsourcing industry, the move added 23,000 colleagues and more than $3 billion in revenue.
September 11 attacks.
Aon's New York offices were on the 92nd and 98th–105th floors of the South Tower of the World Trade Center at the time of the 11 September 2001 terrorist attack. When the North Tower was struck at 8:46 a.m., many executives began evacuating their employees from the upper floors of the South Tower. The evacuation of Aon's offices, ordered by Eric Eisenberg, was carried out quickly as 924 of the estimated 1,100 Aon employees present at the time managed to evacuate the building before United Airlines Flight 175 struck it twenty stories below them at 9:03 a.m.
However, many were influenced to stay by security guards and security announcements, or did not exit the building in time. As a result, 175 employees of Aon were killed in the attacks, including Eisenberg and Kevin Cosgrove, a vice-president of the company, who made a call to 911 when the tower collapsed at 9:59 a.m.
Spitzer investigation.
In 2004–2005, Aon, along with other brokers including Marsh & McLennan and Willis, fell under regulatory investigation under New York Attorney General Eliot Spitzer and other state attorneys general. At issue was the practice of insurance companies' payments to brokers (known as contingent commissions). The payments were thought to bring a conflict of interest, swaying broker decisions on behalf of carriers, rather than customers. In the spring of 2005, without acknowledging any wrongdoing, Aon agreed to a $190 million settlement, payable over 30 months.
UK regulatory breach.
In January 2009, Aon was fined £5.25 million in the UK by the Financial Services Authority, who stated that the fine related to the company's inadequate bribery and corruption controls, claiming that between 14 January 2005 and 30 September 2007 Aon had failed to properly assess the risks involved in its dealings with overseas firms and individuals. The Authority did not find that any money had actually made its way to illegal organisations. Aon qualified for a 30% discount on the fine as a result of its co-operation with the investigation. Aon said its conduct was not deliberate, adding it had since "significantly strengthened and enhanced its controls around the usage of third parties".
US Foreign Corrupt Practices Act violations.
In December 2011, Aon Corporation paid a $16.26 million penalty to the US Securities and Exchange Commission (SEC) and the US Department of Justice (DOJ) for violations of the US Foreign Corrupt Practices Act (FCPA).
According to the SEC, Aon's subsidiaries made improper payments of over $3.6 million to government officials and third-party facilitators in Costa Rica, Egypt, Vietnam, Indonesia, the United Arab Emirates, Myanmar and Bangladesh, between 1983 and 2007, to obtain and retain insurance contracts.
Major acquisitions.
On 16 June 2014, Aon announced that it agreed to buy National Flood Services, Inc., a leading processor of flood insurance, from Stoneriver Group, L.P.
On 22 October 2012, Aon announced that it agreed to buy OmniPoint, Inc, a Workday consulting firm. Financial terms were not disclosed.
On 19 July 2011, Aon announced that it bought Westfield Financial Corp., the owner of insurance-industry consulting firm Ward Financial Group, from Ohio Farmers Insurance Co. Financial terms were not disclosed.
On 7 April 2011, Aon announced that it had acquired Johannesburg, South Africa-based Glenrand MIB. Financial terms were not disclosed.
On 12 July 2010, Aon announced that it had agreed to buy Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion in cash and stock.
On 5 Mar 2010, Hewitt Associates announced that it acquired Senior Educators Ltd. The acquisition offers companies a new way to address retiree medical insurance commitments.
On 22 August 2008, Aon announced that it had acquired London-based Benfield Group. The acquiring price was US$1.75 billion or £935 million, with US$170 million of debt.
Operations.
Manchester United.
On 3 June 2009, it was reported that Aon had signed a four-year shirt sponsorship deal with English football giant Manchester United. On 1 June 2010, Aon replaced American insurance company AIG as the principal sponsor of the club. The Aon logo was prominently displayed on the front of the club's shirts until the 2014/2015 season when Chevrolet replaced them. The deal was said to be worth £80 million over four years, replacing United's deal with AIG as the most lucrative shirt deal in history at the time.
In April 2013, Aon signed a new eight-year deal with Manchester United to rename their training ground as the Aon Training Complex and sponsor the club's training kits, reportedly worth £180 million to the club.

</doc>
<doc id="2406" url="https://en.wikipedia.org/wiki?curid=2406" title="Alban Berg">
Alban Berg

Alban Maria Johannes Berg (; ; February 9, 1885 – December 24, 1935) was an Austrian composer of the Second Viennese School. His compositional style combined Romantic lyricism with twelve-tone technique.
Biography.
Early life.
Berg was born in Vienna, the third of four children of Johanna and Conrad Berg. His family lived comfortably until the death of his father in 1900.
Education.
He was more interested in literature than music as a child and did not begin to compose until he was fifteen, when he started to teach himself music. In late February or early March 1902 he fathered a child with Marie Scheuchl, a servant girl in the Berg family household. His daughter, Albine, was born on December 4, 1902.
Berg had little formal music education before he became a student of Arnold Schoenberg in October 1904. With Schoenberg he studied counterpoint, music theory, and harmony. By 1906, he was studying music full-time; by 1907, he began composition lessons. His student compositions included five drafts for piano sonatas. He also wrote songs, including his "Seven Early Songs" ("Sieben Frühe Lieder"), three of which were Berg's first publicly performed work in a concert that featured the music of Schoenberg's pupils in Vienna that year. The early sonata sketches eventually culminated in Berg's Piano Sonata, Op. 1 (1907–1908); it is one of the most formidable "first" works ever written. Berg studied with Schoenberg for six years until 1911. Berg admired him as a composer and mentor, and they remained close lifelong friends.
Among Schoenberg's teaching was the idea that the unity of a musical composition depends upon all its aspects being derived from a single basic idea; this idea was later known as "developing variation". Berg passed this on to his students, one of whom, Theodor W. Adorno, stated: "The main principle he conveyed was that of variation: everything was supposed to develop out of something else and yet be intrinsically different". The Piano Sonata is an example—the whole composition is derived from the work's opening quartal gesture and its opening phrase.
Innovation.
Berg was a part of Vienna's cultural elite during the heady "fin de siècle" period. His circle included the musicians Alexander von Zemlinsky and Franz Schreker, the painter Gustav Klimt, the writer and satirist Karl Kraus, the architect Adolf Loos, and the poet Peter Altenberg. In 1906, Berg met the singer Helene Nahowski, daughter of a wealthy family (said by some to be in fact the illegitimate daughter of Emperor Franz Joseph I of Austria from his liaison with Anna Nahowski); despite the outward hostility of her family, the two were married on May 3, 1911.
In 1913, two of Berg's "Five Songs on Picture Postcard Texts by Peter Altenberg" (1912) were premièred in Vienna, conducted by Schoenberg in the infamous "Skandalkonzert". Settings of aphoristic poetic utterances, the songs are accompanied by a very large orchestra. The performance caused a riot, and had to be halted. This was a crippling blow to Berg's self-confidence: he effectively withdrew the work, which is surely one of the most innovative and assured first orchestral compositions in the literature, and it was not performed in full until 1952. The full score remained unpublished until 1966.
From 1915 to 1918, Berg served in the Austro-Hungarian Army and during a period of leave in 1917 he accelerated work on his first opera, "Wozzeck". After the end of World War I, he settled again in Vienna, where he taught private pupils. He also helped Schoenberg run his Society for Private Musical Performances, which sought to create the ideal environment for the exploration and appreciation of unfamiliar new music by means of open rehearsals, repeat performances, and the exclusion of professional critics.
Berg had a particular interest in the number 23, using it to structure several works. Various suggestions have been made as to the reason for this interest: that he took it from the Biorhythms theory of Wilhelm Fliess, in which a 23-day cycle is considered significant, or because he first suffered an asthma attack on 23rd of the month.
Success of "Wozzeck" and inception of "Lulu" 1925-29.
Three excerpts from "Wozzeck" were performed in 1924, and this brought Berg his first public success. The opera, which Berg completed in 1922, was first performed on December 14, 1925, when Erich Kleiber conducted the first performance in Berlin. Today "Wozzeck" is seen as one of the century's most important works. Berg made a start on his second opera, the three act "Lulu", in 1928 but interrupted the work in 1929 for the concert aria "Der Wein" which he completed that summer. "Der Wein" presaged "Lulu" in a number of ways, including vocal style, orchestration, design and text.
Other well-known Berg compositions include the "Lyric Suite" (1926), which was later shown to employ elaborate cyphers to document a secret love affair; the post-Mahlerian "Three Pieces for Orchestra" (completed in 1915 but not performed until after "Wozzeck"); and the "Chamber Concerto" ("Kammerkonzert", 1923–25) for violin, piano, and 13 wind instruments: this latter is written so conscientiously that Pierre Boulez has called it "Berg's strictest composition" and it, too, is permeated by cyphers and posthumously disclosed hidden programs.
Final years 1930-35.
Life for the musical world was becoming increasingly difficult in the 1930s both in Vienna and Germany due to the rising tide of antisemitism and the Nazi cultural ideology that denounced modernity. Even to have an association with someone who was Jewish could lead to denunciation, and Berg's "crime" was to have studied with the Jewish composer Arnold Schoenberg. Berg found that opportunities for his work to be performed in Germany were becoming rare, and eventually his music was proscribed and placed on the list of degenerate music. In 1932 Berg and his wife acquired an isolated lodge, the "Waldhaus" on the southern shore of the "Wörthersee", near Schiefling am See in Carinthia, where he was able to work in seclusion, mainly on Lulu and the Violin Concerto. At the end of 1934 Berg became involved in the political intrigues around finding a replacement for Clemens Krauss as director of the Vienna State Opera. As more of the performances of his work in Germany were cancelled by the Nazis, who had come to power in early 1933, he needed to ensure the new director would be an advocate for modernist music. Originally the premiere of Lulu had been planned for the Berlin State Opera, where Erich Kleiber continued to champion his music and had conducted the premiere of "Wozzeck" in 1925, but now this was looking increasingly uncertain, and Lulu was rejected by the Berlin authorities in the spring of 1934. Kleiber's production of the Lulu symphonic suite on 30 November 1934 in Berlin was also the occasion of his resignation in protest at the extent of conflation of culture with politics. Even in Vienna, the opportunities for the Vienna School of musicians was dwindling.
Berg had interrupted the orchestration of "Lulu" because of an unexpected (and financially much-needed) commission from the Russian-American violinist Louis Krasner for a Violin Concerto (1935). This profoundly elegiac work, composed at unaccustomed speed and posthumously premièred, has become Berg's best-known and beloved composition. Like much of his mature work, it employs an idiosyncratic adaptation of Schoenberg's "dodecaphonic" or twelve-tone technique, that enables the composer to produce passages openly evoking tonality, including quotations from historical tonal music, such as a Bach chorale and a Carinthian folk song. The Violin Concerto was dedicated "to the memory of an Angel", Manon Gropius, the deceased daughter of architect Walter Gropius and Alma Mahler.
Berg died in Vienna, on Christmas Eve 1935, from blood poisoning apparently caused by an insect-sting-induced carbuncle on his back that occurred in November. He was 50 years old.
Aftermath.
Berg completed the orchestration of only the first two acts of "Lulu" before he died. The first two acts were successfully premièred in Zürich in 1937, but for personal reasons Helene Berg subsequently imposed a ban on any attempt to "complete" the final act, which Berg had in fact completed in particell (short score) format. An orchestration was therefore commissioned in secret from Friedrich Cerha and premièred in Paris (under Pierre Boulez) only in 1979, soon after Helene Berg's own death. The complete opera has rapidly entered the repertoire as one of the landmarks of contemporary music and, like "Wozzeck", remains a consistent audience draw.
Legacy.
Berg is remembered as one of the most important composers of the 20th century and to date is the most widely performed opera composer among the Second Viennese School. He is considered to have brought more "human values" to the twelve-tone system, his works seen as more "emotional" than Schoenberg's. Critically he is seen to have preserved the Viennese tradition in his music. His popularity has been more easily secured than many other Modernists since he plausibly combined both Romantic and Expressionist idioms. Though Berg's Romanticism at one time seemed a drawback for some more modernist composers, the Berg scholar Douglas Jarman writes in the New Grove: "As the 20th century closed, the 'backward-looking' Berg suddenly came as Perle remarked, to look like its most forward-looking composer."

</doc>
<doc id="2408" url="https://en.wikipedia.org/wiki?curid=2408" title="Analytical chemistry">
Analytical chemistry

Analytical chemistry studies and uses instruments and methods used to separate, identify, and quantify matter. In practice separation, identification or quantification may constitute the entire analysis or be combined with another method. Separation isolates analytes. Qualitative analysis identifies analytes, while quantitative analysis determines the numerical amount or concentration.
Analytical chemistry consists of classical, wet chemical methods and modern, instrumental methods. Classical qualitative methods use separations such as precipitation, extraction, and distillation. Identification may be based on differences in color, odor, melting point, boiling point, radioactivity or reactivity. Classical quantitative analysis uses mass or volume changes to quantify amount. Instrumental methods may be used to separate samples using chromatography, electrophoresis or field flow fractionation. Then qualitative and quantitative analysis can be performed, often with the same instrument and may use light interaction, heat interaction, electric fields or magnetic fields . Often the same instrument can separate, identify and quantify an analyte.
Analytical chemistry is also focused on improvements in experimental design, chemometrics, and the creation of new measurement tools. Analytical chemistry has broad applications to forensics, medicine, science and engineering.
History.
Analytical chemistry has been important since the early days of chemistry, providing methods for determining which elements and chemicals are present in the object in question. During this period significant contributions to analytical chemistry include the development of systematic elemental analysis by Justus von Liebig and systematized organic analysis based on the specific reactions of functional groups.
The first instrumental analysis was flame emissive spectrometry developed by Robert Bunsen and Gustav Kirchhoff who discovered rubidium (Rb) and caesium (Cs) in 1860.
Most of the major developments in analytical chemistry take place after 1900. During this period instrumental analysis becomes progressively dominant in the field. In particular many of the basic spectroscopic and spectrometric techniques were discovered in the early 20th century and refined in the late 20th century.
The separation sciences follow a similar time line of development and also become increasingly transformed into high performance instruments. In the 1970s many of these techniques began to be used together as hybrid techniques to achieve a complete characterization of samples.
Starting in approximately the 1970s into the present day analytical chemistry has progressively become more inclusive of biological questions (bioanalytical chemistry), whereas it had previously been largely focused on inorganic or small organic molecules. Lasers have been increasingly used in chemistry as probes and even to initiate and influence a wide variety of reactions. The late 20th century also saw an expansion of the application of analytical chemistry from somewhat academic chemical questions to forensic, environmental, industrial and medical questions, such as in histology.
Modern analytical chemistry is dominated by instrumental analysis. Many analytical chemists focus on a single type of instrument. Academics tend to either focus on new applications and discoveries or on new methods of analysis. The discovery of a chemical present in blood that increases the risk of cancer would be a discovery that an analytical chemist might be involved in. An effort to develop a new method might involve the use of a tunable laser to increase the specificity and sensitivity of a spectrometric method. Many methods, once developed, are kept purposely static so that data can be compared over long periods of time. This is particularly true in industrial quality assurance (QA), forensic and environmental applications. Analytical chemistry plays an increasingly important role in the pharmaceutical industry where, aside from QA, it is used in discovery of new drug candidates and in clinical applications where understanding the interactions between the drug and the patient are critical.
Classical methods.
Although modern analytical chemistry is dominated by sophisticated instrumentation, the roots of analytical chemistry and some of the principles used in modern instruments are from traditional techniques many of which are still used today. These techniques also tend to form the backbone of most undergraduate analytical chemistry educational labs.
Qualitative analysis.
A qualitative analysis determines the presence or absence of a particular compound, but not the mass or concentration. By definition, qualitative analyses do not measure quantity.
Chemical tests.
There are numerous qualitative chemical tests, for example, the acid test for gold and the Kastle-Meyer test for the presence of blood.
Flame test.
Inorganic qualitative analysis generally refers to a systematic scheme to confirm the presence of certain, usually aqueous, ions or elements by performing a series of reactions that eliminate ranges of possibilities and then confirms suspected ions with a confirming test. Sometimes small carbon containing ions are included in such schemes. With modern instrumentation these tests are rarely used but can be useful for educational purposes and in field work or other situations where access to state-of-the-art instruments are not available or expedient.
Quantitative analysis.
Gravimetric analysis.
Gravimetric analysis involves determining the amount of material present by weighing the sample before and/or after some transformation. A common example used in undergraduate education is the determination of the amount of water in a hydrate by heating the sample to remove the water such that the difference in weight is due to the loss of water.
Volumetric analysis.
Titration involves the addition of a reactant to a solution being analyzed until some equivalence point is reached. Often the amount of material in the solution being analyzed may be determined. Most familiar to those who have taken chemistry during secondary education is the acid-base titration involving a color changing indicator. There are many other types of titrations, for example potentiometric titrations.
These titrations may use different types of indicators to reach some equivalence point.
Instrumental methods.
Spectroscopy.
Spectroscopy measures the interaction of the molecules with electromagnetic radiation. Spectroscopy consists of many different applications such as atomic absorption spectroscopy, atomic emission spectroscopy, ultraviolet-visible spectroscopy, x-ray fluorescence spectroscopy, infrared spectroscopy, Raman spectroscopy, dual polarization interferometry, nuclear magnetic resonance spectroscopy, photoemission spectroscopy, Mössbauer spectroscopy and so on.
Mass spectrometry.
Mass spectrometry measures mass-to-charge ratio of molecules using electric and magnetic fields. There are several ionization methods: electron impact, chemical ionization, electrospray, fast atom bombardment, matrix assisted laser desorption ionization, and others. Also, mass spectrometry is categorized by approaches of mass analyzers: magnetic-sector, quadrupole mass analyzer, quadrupole ion trap, time-of-flight, Fourier transform ion cyclotron resonance, and so on.
Electrochemical analysis.
Electroanalytical methods measure the potential (volts) and/or current (amps) in an electrochemical cell containing the analyte. These methods can be categorized according to which aspects of the cell are controlled and which are measured. The three main categories are potentiometry (the difference in electrode potentials is measured), coulometry (the cell's current is measured over time), and voltammetry (the cell's current is measured while actively altering the cell's potential).
Thermal analysis.
Calorimetry and thermogravimetric analysis measure the interaction of a material and heat.
Separation.
Separation processes are used to decrease the complexity of material mixtures. Chromatography, electrophoresis and Field Flow Fractionation are representative of this field.
Hybrid techniques.
Combinations of the above techniques produce a "hybrid" or "hyphenated" technique. Several examples are in popular use today and new hybrid techniques are under development. For example, gas chromatography-mass spectrometry, gas chromatography-infrared spectroscopy, liquid chromatography-mass spectrometry, liquid chromatography-NMR spectroscopy. liquid chromagraphy-infrared spectroscopy and capillary electrophoresis-mass spectrometry.
Hyphenated separation techniques refers to a combination of two (or more) techniques to detect and separate chemicals from solutions. Most often the other technique is some form of chromatography. Hyphenated techniques are widely used in chemistry and biochemistry. A slash is sometimes used instead of hyphen, especially if the name of one of the methods contains a hyphen itself.
Microscopy.
The visualization of single molecules, single cells, biological tissues and nanomaterials is an important and attractive approach in analytical science. Also, hybridization with other traditional analytical tools is revolutionizing analytical science. Microscopy can be categorized into three different fields: optical microscopy, electron microscopy, and scanning probe microscopy. Recently, this field is rapidly progressing because of the rapid development of the computer and camera industries.
Lab-on-a-chip.
Devices that integrate (multiple) laboratory functions on a single chip of only millimeters to a few square centimeters in size and that are capable of handling extremely small fluid volumes down to less than picoliters.
Errors.
Error can be defined as numerical difference between observed value and true value.
In error the true value and observed value in chemical analysis can be related with each other by the equation
where 
Error of a measurement is an inverse measure of accurate measurement i.e. smaller the error greater the accuracy of the measurement. Errors are expressed relatively as:
Standards.
Standard curve.
A general method for analysis of concentration involves the creation of a calibration curve. This allows for determination of the amount of a chemical in a material by comparing the results of unknown sample to those of a series of known standards. If the concentration of element or compound in a sample is too high for the detection range of the technique, it can simply be diluted in a pure solvent. If the amount in the sample is below an instrument's range of measurement, the method of addition can be used. In this method a known quantity of the element or compound under study is added, and the difference between the concentration added, and the concentration observed is the amount actually in the sample.
Internal standards.
Sometimes an internal standard is added at a known concentration directly to an analytical sample to aid in quantitation. The amount of analyte present is then determined relative to the internal standard as a calibrant. An ideal internal standard is isotopically-enriched analyte which gives rise to the method of isotope dilution.
Standard addition.
The method of standard addition is used in instrumental analysis to determine concentration of a substance (analyte) in an unknown sample by comparison to a set of samples of known concentration, similar to using a calibration curve. Standard addition can be applied to most analytical techniques and is used instead of a calibration curve to solve the matrix effect problem.
Signals and noise.
One of the most important components of analytical chemistry is maximizing the desired signal while minimizing the associated noise. The analytical figure of merit is known as the signal-to-noise ratio (S/N or SNR).
Noise can arise from environmental factors as well as from fundamental physical processes.
Thermal noise.
Thermal noise results from the motion of charge carriers (usually electrons) in an electrical circuit generated by their thermal motion. Thermal noise is white noise meaning that the power spectral density is constant throughout the frequency spectrum.
The root mean square value of the thermal noise in a resistor is given by
where "kB" is Boltzmann's constant, "T" is the temperature, "R" is the resistance, and formula_5 is the bandwidth of the frequency formula_6.
Shot noise.
Shot noise is a type of electronic noise that occurs when the finite number of particles (such as electrons in an electronic circuit or photons in an optical device) is small enough to give rise to statistical fluctuations in a signal.
Shot noise is a Poisson process and the charge carriers that make up the current follow a Poisson distribution. The root mean square current fluctuation is given by
where "e" is the elementary charge and "I" is the average current. Shot noise is white noise.
Flicker noise.
Flicker noise is electronic noise with a 1/"ƒ" frequency spectrum; as "f" increases, the noise decreases. Flicker noise arises from a variety of sources, such as impurities in a conductive channel, generation and recombination noise in a transistor due to base current, and so on. This noise can be avoided by modulation of the signal at a higher frequency, for example through the use of a lock-in amplifier.
Environmental noise.
Environmental noise arises from the surroundings of the analytical instrument. Sources of electromagnetic noise are power lines, radio and television stations, wireless devices, Compact fluorescent lamps and electric motors. Many of these noise sources are narrow bandwidth and therefore can be avoided. Temperature and vibration isolation may be required for some instruments.
Noise reduction.
Noise reduction can be accomplished either in computer hardware or software. Examples of hardware noise reduction are the use of shielded cable, analog filtering, and signal modulation. Examples of software noise reduction are digital filtering, ensemble average, boxcar average, and correlation methods.
Applications.
Analytical chemistry has applications including in forensics, bioanalysis, clinical analysis, environmental analysis, and materials analysis. Analytical chemistry research is largely driven by performance (sensitivity, detection limit, selectivity, robustness, dynamic range, linear range, accuracy, precision, and speed), and cost (purchase, operation, training, time, and space). Among the main branches of contemporary analytical atomic spectrometry, the most widespread and universal are optical and mass spectrometry. In the direct elemental analysis of solid samples, the new leaders are laser-induced breakdown and laser ablation mass spectrometry, and the related techniques with transfer of the laser ablation products into inductively coupled plasma. Advances in design of diode lasers and optical parametric oscillators promote developments in fluorescence and ionization spectrometry and also in absorption techniques where uses of optical cavities for increased effective absorption pathlength are expected to expand. The use of plasma- and laser-based methods is increasing. An interest towards absolute (standardless) analysis has revived, particularly in emission spectrometry.
Great effort is being put in shrinking the analysis techniques to chip size. Although there are few examples of such systems competitive with traditional analysis techniques, potential advantages include size/portability, speed, and cost. (micro total analysis system (µTAS) or lab-on-a-chip). Microscale chemistry reduces the amounts of chemicals used.
Many developments improve the analysis of biological systems. Examples of rapidly expanding fields in this area are genomics, DNA sequencing and related research in genetic fingerprinting and DNA microarray; proteomics, the analysis of protein concentrations and modifications, especially in response to various stressors, at various developmental stages, or in various parts of the body, metabolomics, which deals with metabolites; transcriptomics, including mRNA and associated fields; lipidomics - lipids and its associated fields; peptidomics - peptides and its associated fields; and metalomics, dealing with metal concentrations and especially with their binding to proteins and other molecules.
Analytical chemistry has played critical roles in the understanding of basic science to a variety of practical applications, such as biomedical applications, environmental monitoring, quality control of industrial manufacturing, forensic science and so on.
The recent developments of computer automation and information technologies have extended analytical chemistry into a number of new biological fields. For example, automated DNA sequencing machines were the basis to complete human genome projects leading to the birth of genomics. Protein identification and peptide sequencing by mass spectrometry opened a new field of proteomics.
Analytical chemistry has been an indispensable area in the development of nanotechnology. Surface characterization instruments, electron microscopes and scanning probe microscopes enables scientists to visualize atomic structures with chemical characterizations.

</doc>
<doc id="2411" url="https://en.wikipedia.org/wiki?curid=2411" title="A cappella">
A cappella

A cappella (Italian for "in the manner of the chapel") music is specifically group or solo singing without instrumental accompaniment, or a piece intended to be performed in this way. It contrasts with cantata, which is accompanied singing. The term "a cappella" was originally intended to differentiate between Renaissance polyphony and Baroque concertato style. In the 19th century a renewed interest in Renaissance polyphony coupled with an ignorance of the fact that vocal parts were often doubled by instrumentalists led to the term coming to mean unaccompanied vocal music. The term is also used, albeit rarely, as a synonym for alla breve.
Religious origins.
A cappella music was originally used in religious music, especially church music as well as anasheed and zemirot. Gregorian chant is an example of a cappella singing, as is the majority of secular vocal music from the Renaissance. The madrigal, up until its development in the early Baroque into an instrumentally-accompanied form, is also usually in a cappella form. Jewish and Christian music were originally a cappella, and this practice has continued in both of these religions as well as in Islam.
Christian.
The polyphony of Christian a cappella music began to develop in Europe around the late 15th century AD, with compositions by Josquin des Prez. The early a cappella polyphonies may have had an accompanying instrument, although this instrument would merely double the singers' parts and was not independent. By the 16th century, a cappella polyphony had further developed, but gradually, the cantata began to take the place of a cappella forms. 16th century a cappella polyphony, nonetheless, continued to influence church composers throughout this period and to the present day. Recent evidence has shown that some of the early pieces by Palestrina, such as what was written for the Sistine Chapel was intended to be accompanied by an organ "doubling" some or all of the voices. Such is seen in the life of Palestrina becoming a major influence on Bach, most notably in the aforementioned "Mass in B Minor". Other composers that utilized the a cappella style, if only for the occasional piece, were Claudio Monteverdi and his masterpiece, "Lagrime d'amante al sepolcro dell'amata" (A lover's tears at his beloved's grave), which was composed in 1610, and Andrea Gabrieli when upon his death it was discovered many choral pieces, one of which was in the unaccompanied style. Learning from the preceding two composeres, Heinrich Schütz utilized the a cappella style in numerous pieces, chief among these were the pieces in the oratorio style, which were traditionally performed during the Easter week and dealt with the religious subject matter of that week, such as Christ's suffering and the Passion. Five of Schutz's "Historien" were Easter pieces, and of these the latter three, which dealt with the passion from three different viewpoints, those of Matthew, Luke and John, were all done a cappella style. This was a near requirement for this type of piece, and the parts of the crowd were sung while the solo parts which were the quoted parts from either Christ or the authors were performed in a plainchant.
Byzantine Rite.
In the Byzantine Rite of the Eastern Orthodox Church and the Eastern Catholic Churches, the music performed in the liturgies is exclusively sung without instrumental accompaniment. Bishop Kallistos Ware says, "The service is sung, even though there may be no choir... In the Orthodox Church today, as in the early Church, singing is unaccompanied and instrumental music is not found." This "a cappella" behavior arises from strict interpretation of Psalms 150, which states, "Let every thing that hath breath praise the Lord. Praise ye the Lord." In keeping with this philosophy, early Russian "musika" which started appearing in the late 17th century, in what was known as "khorovïye kontsertï" (choral concertos) made a cappella adaptations of Venetian-styled pieces, such as the treatise, "Grammatika musikiyskaya" (1675), by Nikolai Diletsky. Divine Liturgies and Western Rite masses composed by famous composers such as Peter Tchaikovsky, Sergei Rachmaninoff, Alexander Arkhangelsky, and Mykola Leontovych are fine examples of this.
Opposition to instruments in worship.
Present-day Christian religious bodies known for conducting their worship services without musical accompaniment include some Presbyterian churches devoted to the regulative principle of worship, Old Regular Baptists, Primitive Baptists, Plymouth Brethren, Churches of Christ, the Old German Baptist Brethren, Doukhobors the Byzantine Rite and the Amish, Old Order Mennonites and Conservative Mennonites. Certain high church services and other musical events in liturgical churches (such as the Roman Catholic Mass and the Lutheran Divine Service) may be a cappella, a practice remaining from apostolic times. Many Mennonites also conduct some or all of their services without instruments. Sacred Harp, a type of folk music, is an a cappella style of religious singing with shape notes, usually sung at singing conventions.
Opponents of musical instruments in the Christian worship believe that such opposition is supported by the Christian scriptures and Church history. The scriptures typically referenced are Matthew 26:30; Acts 16:25; Romans 15:9; 1 Corinthians 14:15; Ephesians 5:19; Colossians 3:16; Hebrews 2:12, 13:15; James 5:13, which show examples and exhortations for Christians to sing.
There is no reference to instrumental music in early church worship in the New Testament, or in the worship of churches for the first six centuries. Several reasons have been posited throughout church history for the absence of instrumental music in church worship.
Christians who believe in a cappella music today believe that in the Israelite worship assembly during Temple worship only the Priests of Levi sang, played, and offered animal sacrifices, whereas in the church era, all Christians are commanded to sing praises to God. They believe that if God wanted instrumental music in New Testament worship, He would have commanded not just singing, but singing and playing like he did in the Hebrew scriptures.
The first recorded example of a musical instrument in Roman Catholic worship was a pipe organ introduced by Pope Vitalian into a cathedral in Rome around 670.
Instruments have divided Christendom since their introduction into worship. They were considered a Catholic innovation, not widely practiced until the 18th century, and were opposed vigorously in worship by a number of Protestant Reformers, including Martin Luther (1483–1546), Ulrich Zwingli, John Calvin (1509–1564) and John Wesley (1703–1791). Alexander Campbell referred to the use of an instrument in worship as "a cow bell in a concert". In Sir Walter Scott's "The Heart of Midlothian", the heroine, Jeanie Deans, a Scottish Presbyterian, writes to her father about the church situation she has found in England (bold added):
Acceptance of instruments in worship.
Those who do not adhere to the regulative principle of interpreting Christian scripture, believe that limiting praise to the unaccompanied chant of the early church is not commanded in scripture, and that churches in any age are free to offer their songs with or without musical instruments.
Those who subscribe to this interpretation believe that since the Christian scriptures never counter instrumental language with any negative judgment on instruments, opposition to instruments instead comes from an interpretation of history. There is no written opposition to musical instruments in any setting in the first century and a half of Christian churches (33 AD to 180AD). The use of instruments for Christian worship during this period is also undocumented. Toward the end of the 2nd century, Christians began condemning the instruments themselves. Those who oppose instruments today believe these Church Fathers had a better understanding of God's desire for the church, but there are significant differences between the teachings of these Church Fathers and Christian opposition to instruments today.
Since "a cappella" singing brought a new polyphony (more than one note at a time) with instrumental accompaniment, it is not surprising that Protestant reformers who opposed the instruments (such as Calvin and Zwingli) also opposed the polyphony. While Zwingli was burning organs in Switzerland – Luther called him a fanatic – the Church of England was burning books of polyphony.
Some Holiness Churches such as the Free Methodist Church opposed the use of musical instruments in church worship until the mid-20th century. The Free Methodist Church allowed for local church decision on the use of either an organ or piano in the 1943 Conference before lifting the ban entirely in 1955.
Jewish.
While worship in the Temple in Jerusalem included musical instruments (), traditional Jewish religious services in the Synagogue, both before and after the last destruction of the Temple, did not include musical instruments given the practice of scriptural cantillation. The use of musical instruments is traditionally forbidden on the Sabbath out of concern that players would be tempted to repair (or tune) their instruments, which is forbidden on those days. (This prohibition has been relaxed in many Reform and some Conservative congregations.) Similarly, when Jewish families and larger groups sing traditional Sabbath songs known as zemirot outside the context of formal religious services, they usually do so a cappella, and Bar and Bat Mitzvah celebrations on the Sabbath sometimes feature entertainment by a cappella ensembles. During the Three Weeks musical instruments are prohibited. Many Jews consider a portion of the 49-day period of the counting of the omer between Passover and Shavuot to be a time of semi-mourning and instrumental music is not allowed during that time. This has led to a tradition of a cappella singing sometimes known as "sefirah" music.
The popularization of the Jewish chant may be found in the writings of the Jewish philosopher Philo, born 20 BCE. Weaving together Jewish and Greek thought, Philo promoted praise without instruments, and taught that "silent singing" (without even vocal chords) was better still. This view parted with the Jewish scriptures, where Israel offered praise with instruments by God's own command (). The shofar is the only temple instrument still being used today in the synagogue, and it is only used from Rosh Chodesh Elul through the end of Yom Kippur. The shofar is used by itself, without any vocal accompaniment, and is limited to a very strictly defined set of sounds and specific places in the synagogue service.
In the United States.
Peter Christian Lutkin, dean of the Northwestern University School of Music, helped popularize a cappella music in the United States by founding the Northwestern A Cappella Choir in 1906. The A Cappella Choir was "the first permanent organization of its kind in America."
A strong and prominent a cappella tradition was begun in the midwest part of the United States in 1911 by F. Melius Christiansen, a music faculty member at St. Olaf College in Northfield, Minnesota. The St. Olaf College Choir was established as an outgrowth of the local St. John's Lutheran Church, where Christiansen was organist and the choir was composed, at least partially, of students from the nearby St. Olaf campus. The success of the ensemble was emulated by other regional conductors, and a rich tradition of a cappella choral music was born in the region at colleges like Concordia College (Moorhead, Minnesota), Augustana College (Rock Island, Illinois), Wartburg College (Waverly, Iowa), Luther College (Decorah, Iowa), Gustavus Adolphus College (St. Peter, Minnesota), Augustana College (Sioux Falls, South Dakota), and Augsburg College (Minneapolis, Minnesota). The choirs typically range from 40 to 80 singers and are recognized for their efforts to perfect blend, intonation, phrasing and pitch in a large choral setting.
Major movements in modern a cappella over the past century include Barbershop and doo wop. The Barbershop Harmony Society, Sweet Adelines International, and Harmony Inc. host educational events including Harmony University, Directors University, and the International Educational Symposium, and international contests and conventions, recognizing international champion choruses and quartets.
These days, many a cappella groups can be found in high schools and colleges. There are amateur Barbershop Harmony Society and professional groups that sing a cappella exclusively. Although a cappella is technically defined as singing without instrumental accompaniment, some groups use their voices to emulate instruments; others are more traditional and focus on harmonizing. A cappella styles range from gospel music to contemporary to barbershop quartets and choruses.
A cappella music was popularized between the late 2000s and the mid 2010s with media hits such as the 2009–2014 TV show "The Sing-Off", the musical "Perfect Harmony", and the musical comedy film series "Pitch Perfect".
Recording artists.
In July 1943, as a result of the American Federation of Musicians boycott of US recording studios, the a cappella vocal group "The Song Spinners" had a best-seller with "Comin' In On A Wing And A Prayer". In the 1950s several recording groups, notably The Hi-Los and the Four Freshmen, introduced complex jazz harmonies to a cappella performances. The King's Singers are credited with promoting interest in small-group a cappella performances in the 1960s. In 1983 an a cappella group known as The Flying Pickets had a Christmas 'number one' in the UK with a cover of Yazoo's (known in the US as Yaz) "Only You". A cappella music attained renewed prominence from the late 1980s onward, spurred by the success of Top 40 recordings by artists such as The Manhattan Transfer, Bobby McFerrin, Huey Lewis and the News, All-4-One, The Nylons, Backstreet Boys and Boyz II Men.
Contemporary a cappella includes many vocal groups and bands who add vocal percussion or beatboxing to create a pop/rock/gospel sound, in some cases very similar to bands with instruments. Examples of such professional groups include Straight No Chaser, Pentatonix, The House Jacks, Rockapella, Mosaic, and M-pact. There also remains a strong a cappella presence within Christian music, as some denominations purposefully do not use instruments during worship. Examples of such groups are Take 6, Glad and Acappella. Arrangements of popular music for small a cappella ensembles typically include one voice singing the lead melody, one singing a rhythmic bass line, and the remaining voices contributing chordal or polyphonic accompaniment.
A cappella can also describe the isolated vocal track(s) from a multitrack recording that originally included instrumentation. These vocal tracks may be remixed or put onto vinyl records for DJs, or released to the public so that fans can remix them. One such example is the a cappella release of Jay-Z's "Black Album", which Danger Mouse mixed with The Beatles' "White Album" to create "The Grey Album".
A cappella's growth is not limited to live performance, with hundreds of recorded a cappella albums produced over the past decade. As of December 2006, the Recorded A Cappella Review Board (RARB) had reviewed over 660 a cappella albums since 1994, and its popular discussion forum had over 900 users and 19,000 articles.
On their 1966 album titled "Album", Peter, Paul and Mary included the song "Normal Normal." All the sounds on that song, both vocals and instruments, were created by Paul's voice, with no actual instruments used.
Recording artist Brandy Norwood included a song on her 2008 album "Human" titled "A Capella (Something's Missing)". Brandy uses her voice for background music in this song, showing her capabilities of using her voice as an instrument. No other instruments are used, except for an electric guitar.
In 2010, American dance recording artist Kelis released a song called "Acapella" as the first single from her album "Flesh Tone". The song is not actually performed a cappella, but rather explains that before her son was born, her life was without music.
In 2013, an artist by the name Smooth McGroove rose to prominence with his style of a cappella music. He is best known for his a cappella covers of video game music tracks on YouTube.
Musical theater.
A cappella has been used as the sole orchestration for original works of musical theater that have had commercial runs Off-Broadway (theaters in New York City with 99 to 500 seats) only four times. The first was Avenue X which opened on 28 January 1994 and ran for 77 performances. It was produced by Playwrights Horizons with book by John Jiler, music and lyrics by Ray Leslee. The musical style of the show's score was primarily Doo-Wop as the plot revolved around Doo-Wop group singers of the 1960s.
In 2001, The Kinsey Sicks, produced and starred in the critically acclaimed off-Broadway hit, "DRAGAPELLA! Starring the Kinsey Sicks" at New York's legendary Studio 54. That production received a nomination for a Lucille Lortel award as Best Musical and a Drama Desk nomination for Best Lyrics. It was directed by Glenn Casale with original music and lyrics by Ben Schatz.
The a cappella musical Perfect Harmony, a comedy about two high school a cappella groups vying to win the National championship, made its Off Broadway debut at Theatre Row’s Acorn Theatre on 42nd Street in New York City in October, 2010 after a successful out-of-town run at the Stoneham Theatre, in Stoneham, Massachusetts. Perfect Harmony features the hit music of The Jackson 5, Pat Benatar, Billy Idol, Marvin Gaye, Scandal, Tiffany, The Romantics, The Pretenders, The Temptations, The Contours, The Commodores, Tommy James & the Shondells and The Partridge Family, and has been compared to a cross between Altar Boyz and The 25th Annual Putnam County Spelling Bee.
The fourth a cappella musical to appear Off-Broadway, In Transit, premiered 5 October 2010 and was produced by Primary Stages with book, music, and lyrics by Kristen Anderson-Lopez, James-Allen Ford, Russ Kaplan, and Sara Wordsworth. Set primarily in the New York City subway system its score features an eclectic mix of musical genres (including jazz, hip hop, Latin, rock, and country). In Transit incorporates vocal beat boxing into its contemporary a cappella arrangements through the use of a subway beat boxer character. Beat boxer and actor Chesney Snow performed this role for the 2010 Primary Stages production. According to the show's website, it is scheduled to reopen for an open-ended commercial run in the Fall of 2011. In 2011 the production received four Lucille Lortel Award nominations including Outstanding Musical, Outer Critics Circle and Drama League nominations, as well as five Drama Desk nominations including Outstanding Musical and won for Outstanding Ensemble Performance.
, no show with a cappella orchestrations has ever run on Broadway.
Barbershop style.
Barbershop music is one of several uniquely American art forms. The earliest reports of this style of a cappella music involved African Americans. The earliest documented quartets all began in barbershops. In 1938, the first formal men's barbershop organization was formed, known as the Society for the Preservation and Encouragement of Barber Shop Quartet Singing in America (S.P.E.B.S.Q.S.A), and in 2004 rebranded itself and officially changed its public name to the Barbershop Harmony Society (BHS). Today the BHS has over 22,000 members in approximately 800 chapters across the United States, and the barbershop style has spread around the world with organizations in many other countries. The Barbershop Harmony Society provides a highly organized competition structure for a cappella quartets and choruses singing in the barbershop style.
In 1945, the first formal women's barbershop organization, Sweet Adelines, was formed. In 1953 Sweet Adelines became an international organization, although it didn't change its name to Sweet Adelines International until 1991. The membership of nearly 25,000 women, all singing in English, includes choruses in most of the fifty United States as well as in Australia, Canada, England, Finland, Germany, Ireland, Japan, New Zealand, Scotland, Sweden, Wales and the Netherlands. Headquartered in Tulsa, Oklahoma, the organization encompasses more than 1,200 registered quartets and 600 choruses.
In 1959, a second women's barbershop organization started as a break off from Sweet Adelines due to ideological differences. Based on democratic principles which continue to this day, Harmony, Inc. is smaller than its counterpart, but has an atmosphere of friendship and competition. With about 2,500 members in the United States and Canada, Harmony, Inc. uses the same rules in contest that the Barbershop Harmony Society uses. Harmony, Inc. is registered in Providence, Rhode Island.
Amateur and high school.
The popularity of a cappella among high schools and amateurs was revived by television shows and movies such as "Glee" and "Pitch Perfect". High school groups have conductors or student leaders who keep the tempo for the group.
In other countries.
Sri Lanka.
Composer Dinesh Subasinghe became the first Sri Lankan to write a cappella pieces for SATB choirs. He wrote "The Princes of the Lost Tribe" and "Ancient Queen of Somawathee" for Menaka De Shabandu and Bridget Halpe's choirs, respectively, based on historical incidents in ancient Sri Lanka. Voice Print is also a professional a cappella music group in Sri Lanka.
Sweden.
The European a cappella tradition is especially strong in the countries around the Baltic and perhaps most so in Sweden as described by Richard Sparks in his doctoral thesis "The Swedish Choral Miracle" in 2000.
Swedish a cappella choirs have over the last 25 years won around 25% of the annual prestigious European Grand Prix for Choral Singing (EGP) that despite its name is open to choirs from all over the world (see list of laureates in the Wikipedia article on the EGP competition).
The reasons for the strong Swedish dominance are as explained by Richard Sparks manifold; suffice to say here that there is a long-standing tradition, an unsusually large proportion of the populations (5% is often cited) regularly sing in choirs, the Swedish choral director Eric Ericson had an enormous impact on a cappella choral development not only in Sweden but around the world, and finally there are a large number of very popular primary and secondary schools ("music schools") with high admission standards based on auditions that combine a rigid academic regimen with high level choral singing on every school day, a system that started with Adolf Fredrik's Music School in Stockholm in 1939 but has spread over the country.
United Kingdom.
A cappella has gained attention in the UK in recent years, with many groups forming at British universities by students seeking an alternative singing pursuit to traditional choral and chapel singing. This movement has been bolstered by organisations such as The Voice Festival UK.
Collegiate.
It is not clear exactly where collegiate a cappella began. The Rensselyrics of Rensselaer Polytechnic Institute (formerly known as the RPI Glee Club), established in 1873 is perhaps the oldest known collegiate a cappella group. However the longest continuously-singing group is probably The Whiffenpoofs of Yale University, which was formed in 1909 and once included Cole Porter as a member. Collegiate a cappella groups grew throughout the 20th century. Some notable historical groups formed along the way include Princeton University's Tigertones (1946), Colgate University's The Colgate 13 (1942), Dartmouth College's Aires (1946), Cornell University's Cayuga's Waiters (1949) and The Hangovers (1968), the University of Maine Maine Steiners (1958), the Columbia University Kingsmen (1949), the Jabberwocks of Brown University (1949), and the University of Rochester YellowJackets (1956). All-women a cappella groups followed shortly, frequently as a parody of the men's groups: the Smiffenpoofs of Smith College (1936), The Shwiffs of Connecticut College (The She-Whiffenpoofs, 1944), and The Chattertocks of Brown University (1951). A cappella groups exploded in popularity beginning in the 1990s, fueled in part by a change in style popularized by the Tufts University Beelzebubs and the Boston University Dear Abbeys. The new style used voices to emulate modern rock instruments, including vocal percussion/"beatboxing". Some larger universities now have multiple groups. Groups often join one another in on-campus concerts, such as the Georgetown Chimes' Cherry Tree Massacre, a 3-weekend a cappella festival held each February since 1975, where over a hundred collegiate groups have appeared, as well as International Quartet Champions The Boston Common and the contemporary commercial a cappella group Rockapella. Co-ed groups have produced many up-and-coming and major artists, including John Legend, an alumnus of the Counterparts at the University of Pennsylvania, and Sara Bareilles, an alumna of Awaken A Cappella at University of California, Los Angeles. Mira Sorvino is an alumna of the Harvard-Radcliffe Veritones of Harvard College where she had the solo on Only You by Yaz.
A cappella is gaining popularity among South Asians with the emergence of primarily Hindi-English College groups. The first South Asian a cappella group was Penn Masala, founded in 1996 at the University of Pennsylvania. Co-ed South Asian a cappella groups are also gaining in popularity. The first co-ed south Asian a cappella was Anokha, from the University of Maryland, formed in 2001. Also, Dil se, another co-ed a cappella from UC Berkeley, hosts the "Anahat" competition at the University of California, Berkeley annually. Maize Mirchi, the co-ed a cappella group from the University of Michigan hosts "Sa Re Ga Ma Pella", an annual South Asian a cappella invitational with various groups from the Midwest.
Jewish-interest groups such as Tufts University's Shir Appeal, University of Chicago's Rhythm and Jews, Binghamton University's Kaskeset, Ohio State University's Meshuganotes, Rutgers University's Kol Halayla, New York University's Ani V'Ata and Yale University's Magevet are also gaining popularity across the U.S.
Increased interest in modern a cappella (particularly collegiate a cappella) can be seen in the growth of awards such as the Contemporary A Cappella Recording Awards (overseen by the Contemporary A Cappella Society) and competitions such as the International Championship of Collegiate A Cappella for college groups and the Harmony Sweepstakes for all groups. In December 2009, a new television competition series called "The Sing-Off" aired on NBC. The show featured eight a cappella groups from the United States and Puerto Rico vying for the prize of $100,000 and a recording contract with Epic Records/Sony Music. The show was judged by Ben Folds, Shawn Stockman, and Nicole Scherzinger and was won by an all-male group from Puerto Rico called Nota. The show returned for a second and third season, won by Committed and Pentatonix, respectively.
Each year, hundreds of Collegiate a cappella groups submit their strongest songs in a competition to be on The Best of College A Cappella (BOCA), an album compilation of tracks from the best college a cappella groups around the world. The album is produced by Varsity Vocals – which also produces the International Championship of Collegiate A Cappella – and Deke Sharon. A group chosen to be on the BOCA album earns much credibility among the a cappella community.
Collegiate a cappella groups may also submit their tracks to Voices Only, a two-disc series released at the beginning of each school year. A Voices Only album has been released every year since 2005.
In addition, all women's a cappella groups can send their strongest song tracks to the Women’s A Cappella Association (WACA) for its annual best of women's a cappella album. WACA offers another medium for women's voices to receive recognition and has released an album every year since 2014, featuring women's groups from across the United States.
Emulating instruments.
In addition to singing words, some a cappella singers also emulate instrumentation by reproducing instrumental sounds with their vocal cords and mouth. One of the earliest 20th century practitioners of this method were The Mills Brothers whose early recordings of the 1930s clearly stated on the label that all instrumentation was done vocally. More recently, "Twilight Zone" by 2 Unlimited was sung a cappella to the instrumentation on the comedy television series "Tompkins Square". Another famous example of emulating instrumentation instead of singing the words is the theme song for "The New Addams Family" series on Fox Family Channel (now ABC Family). Groups such as Vocal Sampling and Undivided emulate Latin rhythms a cappella. In the 1960s, the Swingle Singers used their voices to emulate musical instruments to Baroque and Classical music. Vocal artist Bobby McFerrin is famous for his instrumental emulation. A cappella group Naturally Seven recreates entire songs using vocal tones for every instrument.
The Swingle Singers used nonsense words to sound like instruments, but have been known to produce non-verbal versions of musical instruments. Like the other groups, examples of their music can be found on YouTube. Beatboxing, more accurately known as vocal percussion, is a technique used in a cappella music popularized by the hip-hop community, where rap is often performed a cappella also. The advent of vocal percussion added new dimensions to the a cappella genre and has become very prevalent in modern arrangements. Petra Haden used a four-track recorder to produce an a cappella version of "The Who Sell Out" including the instruments and fake advertisements on her album "" in 2005. Haden has also released a cappella versions of Journey's "Don't Stop Believin'", The Beach Boys' "God Only Knows" and Michael Jackson's "Thriller". In 2009, Toyota commissioned Haden to perform three songs for television commercials for the third-generation Toyota Prius, including an a cappella version of The Bellamy Brothers' 1970s song "Let Your Love Flow".
Christian rock group Relient K recorded the song "Plead the Fifth" a cappella on its album "Five Score and Seven Years Ago". The group recorded lead singer Matt Thiessen making drum noises and played them with an electronic drum machine to record the song.
The German metal band van Canto uses vocal noises to imitate guitars on covers of well-known rock and metal songs (such as "Master of Puppets" by Metallica) as well as original compositions. Although they are generally classified as a cappella metal, the band also includes a drummer, and uses amplifiers on some songs to distort the voice to sound more like an electric guitar.

</doc>
<doc id="2414" url="https://en.wikipedia.org/wiki?curid=2414" title="Arrangement">
Arrangement

In music, an arrangement is a musical reconceptualization of a previously composed work. It may differ from the original work by means of reharmonization, melodic paraphrasing, orchestration, or development of the formal structure. Arranging differs from orchestration in that the latter process is limited to the assignment of notes to instruments for performance by an orchestra, concert band, or other musical ensemble. Arranging "involves adding compositional techniques, such as new thematic material for introductions, transitions, or modulations, and endings... Arranging is the art of giving an existing melody musical variety".
Classical music.
Arrangements and transcriptions of classical and serious music go back to the early history of this genre. In particular, music written for the piano has frequently undergone this treatment. The suite of ten piano pieces "Pictures at an Exhibition", by Modest Mussorgsky, has been arranged over twenty times, notably by Maurice Ravel.
Due to his lack of expertise in orchestration, the American composer George Gershwin had his "Rhapsody in Blue" orchestrated and arranged by Ferde Grofé.
Popular music.
Popular music recordings often include parts for brass, string, and other instruments which were added by arrangers and not composed by the original songwriters. Popular music arrangements may also be considered to include new releases of existing songs with a new musical treatment. These changes can include alterations to tempo, meter, key, instrumentation, and other musical elements.
Well-known examples include Joe Cocker's version of the Beatles' "With a Little Help from My Friends" and Ike And Tina Turner's version of Creedence Clearwater Revival's "Proud Mary". The American group Vanilla Fudge and British group Yes based their early careers on radical re-arrangements of contemporary hits. Bonnie Pointer performed disco and Motown-themed versions of "Heaven Must Have Sent You." Remixes, such as in dance music, can also be considered arrangements.
Though arrangers may contribute substantially to finished musical products, for copyright and royalty purposes, they usually hold no legal claim to their work.
Jazz.
Arrangements for small jazz combos are usually informal, minimal, and uncredited. Larger ensembles have generally had greater requirements for notated arrangements, though the early Count Basie big band is known for its many "head" arrangements, so called because they were worked out by the players themselves, memorized (in the player's "head"), and never written down. Most arrangements for big bands, however, were written down and credited to a specific arranger, as with arrangements by Sammy Nestico and Neal Hefti for Count Basie's later big bands.
Don Redman made innovations in jazz arranging as a part of Fletcher Henderson's orchestra in the 1920s. Redman's arrangements introduced a more intricate melodic presentation and "soli" performances for various sections of the big band. Benny Carter became Henderson's primary arranger in the early 1930s, becoming known for his arranging abilities in addition to his previous recognition as a performer. Beginning in 1938, Billy Strayhorn became an arranger of great renown for the Duke Ellington orchestra. Jelly Roll Morton is sometimes considered the earliest jazz arranger. While he toured around the years 1912 to 1915, he wrote down parts to enable "pick-up" bands to perform his compositions.
Big band arrangements are informally called "charts". In the swing era they were usually either arrangements of popular songs or they were entirely new compositions. Duke Ellington's and Billy Strayhorn's arrangements for the Duke Ellington big band were usually new compositions, and some of Eddie Sauter's arrangements for the Benny Goodman band and Artie Shaw's arrangements for his own band were new compositions as well. It became more common to arrange sketchy jazz combo compositions for big band after the bop era.
After 1950, the big bands declined in number. However, several bands continued and arrangers provided renowned arrangements. Gil Evans wrote a number of large-ensemble arrangements in the late 1950s and early 1960s intended for recording sessions only. Other arrangers of note include Vic Schoen, Pete Rugolo, Oliver Nelson, Johnny Richards, Billy May, Thad Jones, Maria Schneider, Bob Brookmeyer, Lou Marini, Nelson Riddle, Ralph Burns, Billy Byers, Gordon Jenkins, Ray Conniff, Henry Mancini, Ray Reach, and Claus Ogerman.
In the 21st century, the Big Band arrangement has made a modest comeback. Gordon Goodwin, Roy Hargrove, and Christian McBride have all rolled out New Big Bands with both original compositions and new arrangements of standard tunes.
Arranging for instrumental groups.
Strings.
The string section is a body of instruments composed of various stringed instruments. By the 19th century orchestral music in Europe had standardized the string section into the following homogeneous instrumental groups: first violins, second violins, violas, cellos, and double basses. The string section in a multi-sectioned orchestra is referred sometimes to as the "string choir."
The harp is also a stringed instrument, but is not a member of or homogeneous with the violin family and is not considered part of the string choir. Samuel Adler classifies the harp as a plucked string instrument in the same category as the guitar (acoustic or electric), mandolin, banjo, or zither. Like the harp these instruments do not belong to the violin family and are not homogeneous with the string choir. In modern arranging these instruments are considered part of the rhythm section. The electric string bass and upright string bass—depending on the circumstance—can be treated by the arranger as either string section or rhythm section instruments.
A group of instruments in which each member plays a unique part—rather than playing in unison with other like instruments—is referred to as a chamber ensemble. A chamber ensemble made up entirely of strings of the violin family is referred to by its size. A string trio consists of three players, a string quartet four, a string quintet five, and so on.
In most circumstances the string section is treated by the arranger as one homogeneous unit and its members are required to play preconceived material rather than improvise.
A string section can be utilized on its own (this is referred to as a string orchestra) or in conjunction with any of the other instrumental sections. More than one string orchestra can be utilized.
A standard string section (vln., vln 2., vla., vcl, cb.) with each section playing unison allows the arranger to create a five-part texture. Often an arranger will divide each violin section in half or thirds to achieve a denser texture. It is possible to carry this division to its logical extreme in which each member of the string section plays his or her own unique part.
Size of the string section.
Artistic, budgetary and logistical concerns will determine the size and instrumentation of a string section. The Broadway musical West Side Story, in 1957, was booked into the Winter Garden theater; composer Leonard Bernstein disliked the playing of "house" viola players he would have to use there, and so he chose to leave them out of the show's instrumentation; a benefit was the creation of more space in the pit for an expanded percussion section.
George Martin, producer and arranger for The Beatles, warns arrangers about the intonation issues when only two like instruments play in unison. "After a string quartet," Martin explains, "I do not think there is a satisfactory sound for strings until one has at least three players on each line...as a rule two stringed instruments together create a slight "beat" which does not give a smooth sound."
While any combination and number of string instruments is possible in a section, a traditional string section sound is achieved with a violin-heavy balance of instruments.

</doc>
<doc id="2416" url="https://en.wikipedia.org/wiki?curid=2416" title="Athanasian Creed">
Athanasian Creed

The Athanasian Creed, or Quicunque Vult (also "Quicumque Vult"), is a Christian statement of belief focused on Trinitarian doctrine and Christology. The Latin name of the creed, "Quicunque vult", is taken from the opening words, "Whosoever wishes". The creed has been used by Christian churches since the sixth century. It is the first creed in which the equality of the three persons of the Trinity is explicitly stated. It differs from the Nicene-Constantinopolitan and Apostles' Creeds in the inclusion of anathemas, or condemnations of those who disagree with the creed (like the original Nicene Creed).
Widely accepted among Western Christians, including the Roman Catholic Church and some Anglican churches, Lutheran churches (it is considered part of the Lutheran confessions in the Book of Concord), and ancient, liturgical churches generally, the Athanasian Creed has been used in public worship less and less frequently, but part of it can be found as an "Authorized Affirmation of Faith" in the recent (2000) Common Worship liturgy of the Church of England Volume page 145. The creed has never gained much acceptance in liturgy among Eastern Christians. It was designed to distinguish Nicene Christianity from the heresy of Arianism. Liturgically, this Creed was recited at the Sunday Office of Prime in the Western Church; it is not in common use in the Eastern Church. Today, the Athanasian Creed is rarely used even in the Western Church. When used, one common practice is to use it once a year on Trinity Sunday.
Origin.
A medieval account credited Athanasius of Alexandria, the famous defender of Nicene theology, as the author of the Creed. According to this account, Athanasius composed it during his exile in Rome and presented it to Pope Julius I as a witness to his orthodoxy. This traditional attribution of the Creed to Athanasius was first called into question in 1642 by Dutch Protestant theologian G.J. Voss, and it has since been widely accepted by modern scholars that the creed was not authored by Athanasius, that it was not originally called a creed at all, nor was Athanasius' name originally attached to it. Athanasius' name seems to have become attached to the creed as a sign of its strong declaration of Trinitarian faith. The reasoning for rejecting Athanasius as the author usually relies on a combination of the following:
The use of the creed in a sermon by Caesarius of Arles, as well as a theological resemblance to works by Vincent of Lérins, point to Southern Gaul as its origin. The most likely time frame is in the late fifth or early sixth century AD – at least 100 years after Athanasius. The theology of the creed is firmly rooted in the Augustinian tradition, using exact terminology of Augustine's "On the Trinity" (published 415 AD). In the late 19th century, there was a great deal of speculation about who might have authored the creed, with suggestions including Ambrose of Milan, Venantius Fortunatus, and Hilary of Poitiers, among others. The 1940 discovery of a lost work by Vincent of Lérins, which bears a striking similarity to much of the language of the Athanasian Creed, have led many to conclude that the creed originated either with Vincent or with his students. For example, in the authoritative modern monograph about the creed, J.N.D. Kelly asserts that Vincent of Lérin was not its author, but that it may have come from the same milieu, namely the area of Lérins in southern Gaul. The oldest surviving manuscripts of the Athanasian Creed date from the late 8th century.
Content.
The Athanasian Creed is usually divided into two sections: lines 1–28 addressing the doctrine of the Trinity, and lines 29–44 addressing the doctrine of Christology. Enumerating the three persons of the Trinity (i.e., Father, the Son, and the Holy Spirit), the first section of the creed ascribes the divine attributes to each individually. Thus, each person of the Trinity is described as uncreated ("increatus"), limitless ("Immensus"), eternal ("æternus"), and omnipotent ("omnipotens"). While ascribing the divine attributes and divinity to each person of the Trinity, thus avoiding subordinationism, the first half of the Athanasian Creed also stresses the unity of the three persons in the one Godhead, thus avoiding a theology of tritheism. Furthermore, although one God, the Father, Son, and Holy Spirit are distinct from each other. For the Father is neither made nor begotten; the Son is not made but is begotten from the Father; the Holy Spirit is neither made nor begotten but proceeds from the Father and the Son (filioque).
The text of the Athanasian Creed is as follows:
The Christology of the second section is more detailed than that of the Nicene Creed, and reflects the teaching of the First Council of Ephesus (431) and the definition of the Council of Chalcedon (451). The 'Athanasian' Creed uses the Nicene term "homoousios"' ('one substance', 'one in Being') not only with respect to the relation of the Son to the Father according to his divine nature, but that the Son is "homoousios" with his mother Mary, according to his human nature.
The Creed's wording thus excludes not only Sabellianism and Arianism, but the Christological heresies of Nestorianism and Eutychianism. A need for a clear confession against Arianism arose in western Europe when the Ostrogoths and Visigoths, who had Arian beliefs, invaded at the beginning of the 5th century.
The final section of this Creed also moved beyond the Nicene (and Apostles') Creeds in making negative statements about the people's fate: "They that have done good shall go into life everlasting: and they that have done evil into everlasting fire." This caused considerable debate in England in the mid-nineteenth century, centred on the teaching of Frederick Denison Maurice.
Uses.
Composed of 44 rhythmic lines, the Athanasian Creed appears to have been intended as a liturgical document – that is, the original purpose of the creed was to be spoken or sung as a part of worship. The creed itself uses the language of public worship, speaking of the worship of God rather than the language of belief ("Now this is the catholic faith: We worship one God"). In the Catholic Church in medieval times, this creed was recited following the Sunday sermon or at the Sunday Office of Prime. The creed was often set to music and used in the place of a Psalm.
Early Protestants inherited the late medieval devotion to the Athanasian Creed, and it was considered to be authoritative in many Protestant churches. The statements of Protestant belief (confessional documents) of various Reformers commend the Athanasian Creed to their followers, including the Augsburg Confession, the Formula of Concord, the Second Helvetic Confession, the Belgic Confession, the Bohemian Confession and the Thirty-nine Articles. A metric version titled "Quicumque vult", with a musical setting, was published in "The Whole Booke of Psalmes" printed by John Day in 1562. Among modern Lutheran and Reformed churches adherence to the Athanasian Creed is prescribed by the earlier confessional documents, but the creed does not receive much attention outside of occasional use – especially on Trinity Sunday.
In Reformed circles, it is included (for example) in the Christian Reformed Churches of Australia's Book of Forms (publ. 1991). However, it is rarely recited in public worship.
In the successive Books of Common Prayer of the reformed Church of England, from 1549 to 1662, its recitation was provided for on 19 occasions each year, a practice which continued until the nineteenth century, when vigorous controversy regarding its statement about 'eternal damnation' saw its use gradually decline. It remains one of the three Creeds approved in the Thirty-Nine Articles, and is printed in several current Anglican prayer books (e.g. A Prayer Book for Australia (1995)). As with Roman Catholic practice, its use is now generally only on Trinity Sunday or its octave. The Episcopal Church based in the United States has never provided for its use in worship, but added it to its Book of Common Prayer for the first time in 1979, where it is included in small print in a reference section entitled "Historical Documents of the Church."
In Roman Catholic churches, it was traditionally said at Prime on Sundays after Epiphany and Pentecost, except when a Double feast or day within an octave occurred, and on Trinity Sunday. In the 1960 reforms, it was reduced to once a year on Trinity Sunday. It has been effectively dropped from the Catholic liturgy since the Second Vatican Council. It is however maintained in the "Forma Extraordinaria", per the decree Summorum Pontificum, and also in the rite of exorcism, both in the "Forma Ordinaria" and the "Forma Extraordinaria" of the Roman Rite.
In Lutheranism, the Athanasian Creed is—along with the Apostles' and Nicene Creeds—one of the three ecumenical creeds placed at the beginning of the 1580 Book of Concord, the historic collection of authoritative doctrinal statements (confessions) of the Lutheran Church. It is still used in the liturgy on Trinity Sunday.
A common visualisation of the first half of the Creed is the Shield of the Trinity.

</doc>
<doc id="2417" url="https://en.wikipedia.org/wiki?curid=2417" title="Alicante">
Alicante

Alicante (, ), or (), both the Valencian and Spanish being official names, is a city and port in Spain on the Costa Blanca, the capital of the province of Alicante and of the comarca of Alacantí, in the south of the Valencian Community. It is also a historic Mediterranean port. The population of the city of Alicante proper was 328,648, estimated , ranking as the second-largest Valencian city. Including nearby municipalities, the Alicante conurbation had 452,462 residents. The population of the metropolitan area (including Elche and satellite towns) was 757,085 estimates, ranking as the eighth-largest metropolitan area of Spain.
Toponymy.
The name of the city echoes the Arabic name "Laqant" (لَقَنْت) or "Al-Laqant" (ألَلَقَنْت), which in turn reflects the Latin "Lucentum".
History.
The area around Alicante has been inhabited for over 7000 years. The first tribes of hunter gatherers moved down gradually from Central Europe between 5000 and 3000 BC. Some of the earliest settlements were made on the slopes of Mount Benacantil. By 1000 BC Greek and Phoenician traders had begun to visit the eastern coast of Spain, establishing small trading ports and introducing the native Iberian tribes to the alphabet, iron and the pottery wheel. By the 3rd century BC, the rival armies of Carthage and Rome began to invade and fight for control of the Iberian Peninsula. The Carthaginian general Hamilcar Barca established the fortified settlement of "Akra Leuka" (Greek: , meaning "White Mountain" or "White Point"), where Alicante stands today.
Although the Carthaginians conquered much of the land around Alicante, the Romans would eventually rule Hispania Tarraconensis for over 700 years. By the 5th century AD, Rome was in decline and the Roman predecessor town of Alicante, known as "Lucentum" (Latin), was more or less under the control of the Visigothic warlord Theudimer. However neither the Romans nor the Goths put up much resistance to the Arab conquest of "Medina Laqant" in the 8th century. The Moors ruled southern and eastern Spain until the 13th century "Reconquista" (Reconquest). Alicante was finally taken in 1246 by the Castilian king Alfonso X, but it passed soon and definitively to the Kingdom of Valencia in 1298 with King Chaime II of Aragon. It gained the status of Royal Village ("Vila Reial") with representation in the medieval Valencian Parliament ("Corts Valencianes").
After several decades of being the battlefield where the Kingdom of Castile and the Crown of Aragon clashed, Alicante became a major Mediterranean trading station exporting rice, wine, olive oil, oranges and wool. But between 1609 and 1614 King Felipe III expelled thousands of Moriscos who had remained in Valencia after the Reconquista, due to their cooperation with Barbary pirates who continually attacked coastal cities and caused much harm to trade. This act cost the region dearly; with so many skilled artisans and agricultural labourers gone, the feudal nobility found itself sliding into bankruptcy. Things got worse in the early 18th century; after the War of Spanish Succession, Alicante went into a long, slow decline, surviving through the 18th and 19th centuries by making shoes and growing agricultural produce such as oranges and almonds, and thanks to its fisheries. The end of the 19th century witnessed a sharp recovery of the local economy with increasing international trade and the growth of the city harbour leading to increased exports of several products (particularly during World War I when Spain was a neutral country).
During the early 20th century, Alicante was a minor capital that enjoyed the benefit of Spain's neutrality during World War I, and that provided new opportunities for the local industry and agriculture. The Rif War in the 1920s saw numerous "alicantinos" drafted to fight in the long and bloody campaigns in the former Spanish protectorate (Northern Morocco) against the Rif rebels. The political unrest of the late 1920s led to the victory of Republican candidates in local council elections throughout the country, and the abdication of King Alfonso XIII. The proclamation of the Second Spanish Republic was much celebrated in the city on 14 April 1931. The Spanish Civil War broke out on 17 July 1936. Alicante was the last city loyal to the Republican government to be occupied by dictator Franco's troops on 1 April 1939, and its harbour saw the last Republican government officials fleeing the country. Vicious air bombings were targeted on Alicante during the three years of civil conflict, most notably the bombing by the Italian "Aviazione Legionaria" of the Mercado de Abastos on 25 May 1938 in which more than 300 civilians perished.
The late 1950s and early 1960s saw the onset of a lasting transformation of the city by the tourist industry. Large buildings and complexes rose in nearby Albufereta (e.g. El Barco) and Playa de San Juan, with the benign climate being the biggest draw to attract prospective buyers and tourists who kept the hotels reasonably busy. New construction benefited the whole economy, as the development of the tourism sector also spawned new businesses such as restaurants, bars and other tourist-oriented enterprises. Also, the old airfield at Rabassa was closed and air traffic moved to the new El Altet Airport, which made a more convenient and modern facility for charter flights bringing tourists from northern European countries.
When dictator Franco died in 1975, his successor Juan Carlos I played his part as the living symbol of the transition of Spain to a democratic constitutional monarchy. The governments of regional communities were given constitutional status as "nationalities", and their governments were given more autonomy, including that of the Valencian region, the "Generalitat Valenciana".
The Port of Alicante has been reinventing itself since the industrial decline the city suffered in the 1980s (with most mercantile traffic lost to Valencia's harbour). In recent years, the Port Authority has established it as one of the most important ports in Spain for cruises, with 72 calls to port made by cruise ships in 2007 bringing some 80,000 passengers and 30,000 crew to the city each year. The moves to develop the port for more tourism have been welcomed by the city and its residents, but the latest plans to develop an industrial estate in the port have caused great controversy.
Economy.
Until the global recession which started in 2008, Alicante was one of the fastest-growing cities in Spain. The boom depended partly on tourism directed to the beaches of the Costa Blanca and particularly on the second residence-construction boom which started in the 1960s and revived again by the late 1990s. Services and public administration also play a major role in the city's economy. The construction boom has raised many environmental concerns and both the local autonomous government and city council are under scrutiny by the European Union. The construction surge was the subject of hot debates among politicians and citizens alike. The latest of many public battles concerns the plans of the Port Authority of Alicante to construct an industrial estate on reclaimed land in front of the city's coastal strip, in breach of local, national and European regulations. (See Port of Alicante for details).
The city serves as the headquarters of the European Union's Office for Harmonization in the Internal Market and a sizeable population of European public workers live there.
The campus of the University of Alicante lies in San Vicente del Raspeig, bordering the city of Alicante to the north. More than 27,000 students attend the University.
Since 2005 Ciudad de la Luz, one of the largest film studios in Europe, has had its base in Alicante. The studio has shot Spanish and international movies such as "Asterix at the Olympic Games" by Frédéric Forestier and Thomas Langmann, "Manolete" by Menno Meyjes.
Population.
The official population of Alicante in 2014 was 332,067 inhabitants and 757,085 in the metropolitan area "Alicante-Elche". About 15% of the population is foreign, most of them immigrants from Argentina, Ecuador, United Kingdom and Colombia who have arrived in the previous 20 years. There are also immigrants from other countries such as Germany, Romania, Russia, Algeria, Ukraine, Morocco and Italy, many of whom coming outside the EU are under illegal alien status and therefore are not accounted for in official population figures. The real percentage of foreign residents is higher, since the Alicante metropolitan area is home to many Northern European retirees who are officially still residents of their own countries. In the same pattern, a sizable number of permanent residents are Spanish nationals who officially still live in Madrid, the Basque provinces, or other areas of the country.
Government.
Gabriel Echávarri is the Mayor of the city. He was elected for the post on June 13, 2015, following the municipal elections on May 24, 2015. He was supported by the votes from his own group (6), plus those from leftist parties Guanyar Alacant (6) and Compromís (3), as well as from centre-right party Ciudadanos (6). The People's Party ("Partido Popular", PP), with only 8 elected seats, lost the majority.
In the previous municipal elections of May 2011, Sonia Castedo of People's Party won the elections with an absolute majority, but resigned in December 2014 due to her involvement in several corruption scandals, at present being under investigation. Her fellow party member Miguel Valor went on to become mayor up until Echávarri's election.
At the foot of the main staircase of the City Hall Building ("Ayuntamiento") is the zero point ("cota cero"), used as the point of reference for measuring the height above or below sea level of any point in Spain, due to the marginal tidal variations of the Mediterranean sea in Alicante.
Climate.
Alicante enjoys mild winter temperatures, hot summers and little rain, concentrated in equinoctial periods. Scientists tend to classify the climate of Alicante region according to Köppen climate classification as hot semi-arid ("BSh"). On average the temperature ranges between and in January, and between and in August, with an average annual temperature of . Daily variations in temperature are generally small because of the stabilising influence of the sea, although occasional periods of westerly wind can produce temperature changes of or more. Seasonal variations in temperature are also relatively small, meaning that winters are mild and summers are hot.
The average rainfall is per year. The cold drop means that September and October are the wettest months. Rainfall can be torrential, reaching over in a 24-hour period, leading to severe flooding. Because of this irregularity, only 35 rainy days are observed on average per year, and the annual number of sunshine hours is 2,953.
The record maximum temperature of was observed on 4 July 1994. The record minimum temperature of was recorded on 26 December 1970. The worst flooding in modern history occurred on 30 September 1997 when of rain fell within six hours. Temperatures under are very rare. Snow is unknown since 1926
Transport.
Alicante Airport outranks its Valencian counterpart, being among the busiest airports in Spain after Madrid, Barcelona, Palma de Mallorca and Málaga. It is connected with Madrid and Barcelona by frequent Iberia and Vueling flights, and with many Western European cities through carriers such as Ryanair, Easyjet, Air Berlin, Monarch Airlines, and Jet2.com. There are also regular flights to Algeria and Russia.
Alicante railway station is used by Cercanías linking Alicante with suburbs and Murcia. Long-range RENFE trains run frequently to Madrid, Barcelona, and Valencia.
Alicante Tram connects the city with outlying settlements along Costa Blanca. , electric tram-trains run up to Benidorm, and diesel trains go further to Dénia.
The city has regular ferry services to the Balearic Islands and Algeria. The city is strongly fortified, with a spacious harbour.
Main sights.
Amongst the most notable features of the city are the Castle of Santa Bárbara, which sits high above the city, and the port of Alicante. The latter was the subject of bitter controversy in 2006–2007 as residents battled, successfully, to keep it from being changed into an industrial estate.
The Santa Bárbara castle is situated on Mount Benacantil, overlooking the city. The tower ("La Torreta") at the top, is the oldest part of the castle, while part of the lowest zone and the walls were constructed later in the 18th century.
The promenade "Explanada de España", lined by palm trees, is paved with 6.5 million marble floor tiles creating a wavy form and is one of the most lovely promenades in Spain. The Promenade extends from the Port of Alicante to the Gran Vía and ends at the famous statue of Mark Hersch. For the people of Alicante, the promenade is the meeting place for the traditional Spanish "paseo", or stroll along the waterfront in the evenings, and a venue for outdoor musical concerts. At the end of the promenade is a monument by the artist Bañuls of the 19th century.
"Barrio de la Santa Cruz" is a colourful quarter of the old city, situated on the south-west of Santa Bárbara castle. Its small houses climb up the hill leading to the walls and the castle, through narrow streets decorated with flags and tubs of flowers.
"L'Ereta Park" is situated on the foothills of Mount Benacantil, on the way to the castle. It runs from the Santa Bárbara castle down to the old part of Alicante and consists of several levels, routes, decks and rest stops which offer a panoramic view overlooking the city.
"El Palmeral Park" is one of the favorite parks of Alicante's citizens. It includes walking trails, children's playgrounds, ponds and brooks, picnic tables and an auditorium for concerts.
Just a few kilometers from Alicante on the Mediterranean Sea lies Tabarca island. What was once a haven for Barbary pirates is now a beautiful tourist attraction.
Other sights include:
There are a dozen museums in Alicante. On exhibition at the Archaeological Museum of Alicante (MARQ) are local artifacts dating from 100,000 years ago till the early 20th century. The collection is divided into different rooms representing three divisions of archaeological methodology: ground, urban and underwater archaeology, with dioramas, audiovisual and interactive zones. The archaeological museum won the European Museum of the Year Award in 2004. Gravina Museum of Fine Arts presents a number of paintings and sculptures from the 16th century to the 19th century. Asegurada Museum of Contemporary Art houses a major collection of twentieth-century art, composed mainly of works donated by Eusebio Sempere.
Festivals.
The most important festival, the "Bonfires of Saint John" ("Fogueres de Sant Joan"), takes place during the summer solstice. This is followed a week later by seven nights of firework and pyrotechnic contests between companies on the urban beach "Playa del Postiguet". Another well-known festival is "Moros i Cristians" in Altozano or "San Blas" district. Overall, the city boasts a year-round nightlife for the enjoyment of tourists, residents, and a large student population of the University of Alicante. The nightlife social scene tends to shift to nearby Playa de San Juan (St. John's Beach) during the summer months.
Every summer in Alicante, a two-month-long programme of music, theatre and dance is staged in the Paseo del Puerto.
Sport.
The two established Alicante football teams are Hércules CF, which competes in the Spanish Segunda División B, and Alicante CF, which plays in Tercera División and was dissolved in 2014 due to economic problems. Hércules CF is more well known as it was in the first league in Spain during 96/97 and had many popular players as David Trezeguet, Royston Drenthe and Aedo Valvez. It is also known because, thanks to this team winning over FC Barcelona, Real Madrid won the league in 1997. Nowadays it hosts their home games at Estadio José Rico Pérez.
Basketball club Lucentum Alicante participates in the Spanish basketball league. It plays at the Centro de Tecnificación de Alicante.
Alicante serves as headquarters and the starting point of Volvo Ocean Race, a yacht race around the world. The latest race sailed in October 2014.
International relations.
Twin towns – sister cities.
Alicante is twinned with:
In 2009 a bid was made to twin Newcastle, United Kingdom with Alicante.

</doc>
<doc id="2418" url="https://en.wikipedia.org/wiki?curid=2418" title="August 4">
August 4


</doc>
<doc id="2421" url="https://en.wikipedia.org/wiki?curid=2421" title="Albrecht Achilles">
Albrecht Achilles

Albrecht Achilles may refer to:

</doc>
<doc id="2422" url="https://en.wikipedia.org/wiki?curid=2422" title="Ann Widdecombe">
Ann Widdecombe

Ann Noreen Widdecombe, (born 4 October 1947) is a former British Conservative Party politician and has been a novelist since 2000. She is a Privy Councillor and was the Member of Parliament for Maidstone from 1987 to 1997 and for Maidstone and The Weald from 1997 to 2010. She was a social conservative and a member of the Conservative Christian Fellowship. She retired from politics at the 2010 general election. Since 2002 she has also made numerous television and radio appearances, including as a television presenter. She is a convert from Anglicanism to Roman Catholicism.
As an MP, Widdecombe was known for opposing the legality of abortion, her opposition to various issues of LGBT equality such as an equal age of consent and the repeal of Section 28, her support for the re-introduction of the death penalty, the retention of blasphemy laws and her opposition to fox hunting.
Early life.
Born in Bath, Somerset, Widdecombe is the daughter of Rita Noreen (née Plummer; 1911-2007) and Ministry of Defence civil servant James Murray Widdecombe. Widdecombe's maternal grandfather, James Henry Plummer, was born to an Irish Catholic family of English descent in Crosshaven, County Cork in 1874. She attended the Royal Naval School in Singapore, and La Sainte Union Convent School in Bath. She then read Latin at the University of Birmingham and later attended Lady Margaret Hall, Oxford, to read Philosophy, Politics and Economics (PPE). She worked for Unilever (1973–75) and then as an administrator at the University of London (1975–87) before entering Parliament.
Councillor.
From 1976 to 1978, Widdecombe was a councillor on Runnymede District Council in Surrey. She contested the seat of Burnley in Lancashire in the 1979 general election and then, against David Owen, the Plymouth Devonport seat in the 1983 general election.
Member of Parliament.
She was first elected to the House of Commons in the 1987 general election as member for the constituency of Maidstone (which became Maidstone and The Weald in 1997).
Political views.
As an MP, Widdecombe expressed conservative views, including opposition to abortion; it was understood during her time in frontline politics that she would not become Health Secretary as long as this involved responsibility for abortions. Although a committed Christian, she has characterised the issue as one of life and death on which her view had been the same when she was agnostic. Along with John Gummer MP, she converted from the Church of England to the Catholic Church following the decision of the Church of England on the Ordination of women as priests. In her speech at the 2000 Conservative conference, she called for a zero tolerance policy of prosecution, with the punishment of £100 GBP fines for users of cannabis. This was well received by rank-and-file Conservative delegates.
Widdecombe consistently opposed LGBT equality. On the issue of an equal age of consent, she said in 2000: "I do not believe that issues of equality should override the imperatives of protecting the young." In 2003, Widdecombe proposed an amendment opposing repeal of Section 28 of the Local Government Act, which banned the promotion of homosexuality by local governments. Out of the 17 parliamentary votes considered by the Public Whip website to concern equal rights for homosexuals, Widdecombe took the opposing position in 15 cases, not being present at the other two votes. Widdecombe has also expressed her opposition to same-sex marriage, introduced by David Cameron's government in 2014, claiming that "the state must have a preferred model" and "a union that is generally open to procreation".
She is a committed animal lover and one of the few Conservative MPs to have consistently voted for the ban on fox hunting. Widdecombe was among more than 20 high-profile people who signed a letter to Members of Parliament in 2015 to oppose David Cameron's plan to amend the Hunting Act 2004.
She has expressed a variety of views on scientific issues such as climate change but has been opposed to legislation reducing emissions. Her views on the subject appear to have hardened over time. In 2007, she wrote that she did not want to belittle the issue but was sceptical of the claims that specific actions would prevent catastrophe, then in 2008 that her doubts had been "crystalised" by Nigel Lawson's book "An Appeal to Reason", before stating in 2009 that "There is no climate change, hasn’t anybody looked out of their window recently?" She was one of the five MPs who voted against the Climate Change Act 2008. In 2011 she expressed the view that "climate change money should go to armed services". The previous year, she voted to support a parliamentary motion supporting homeopathy, criticizing the Science and Technology Committee's Report on the subject.
Over the years, Widdecombe has expressed her support for a reintroduction of the death penalty, which was abolished in the UK in 1965. She notably spoke of her support for its reintroduction for the worst cases of murder in the aftermath of the murder of two 10-year-old girls from Soham, Cambridgeshire, in August 2002, in the Soham murders. She supported the argument that the death penalty would have deterrent value, as within five years of its abolition the national murder rate had more than doubled.
In government.
Widdecombe joined John Major's government as Parliamentary Under-Secretary of State for Social Security in 1990. In 1993, she was moved to the Department of Employment, and she was promoted to Minister of State the following year. In 1995, she joined the Home Office as Minister of State for Prisons and visited every prison in Britain.
Shadow Cabinet.
After the fall of the Conservative government to Labour in 1997, she served as Shadow Health Secretary between 1998 and 1999 and later as Shadow Home Secretary between 1999 and 2001 under William Hague.
Leadership contest and backbenches.
During the 2001 Conservative leadership election, she could not find sufficient support amongst Conservative MPs for her leadership candidacy. She first supported Michael Ancram, who was eliminated in the first round, and then Kenneth Clarke, who lost in the final round. She afterwards declined to serve in Iain Duncan Smith's Shadow Cabinet (although she indicated on the television programme "When Louis Met...", prior to the leadership contest, that she wished to retire to the backbenches anyway).
In the 2005 leadership election, she initially supported Kenneth Clarke again. Once he was eliminated, she turned support towards Liam Fox. Following Fox's subsequent elimination, she took time to reflect before finally declaring for David Davis. She expressed reservations over the eventual winner David Cameron, feeling that he did not, like the other candidates, have a proven track record, and she was later a leading figure in parliamentary opposition to his A-List policy, which she has said is "an insult to women". At the October 2006 Conservative Conference, she was Chief Dragon in a political version of the television programme "Dragons' Den", in which A-list candidates were invited to put forward a policy proposal, which was then torn apart by her team of Rachel Elnaugh, Oliver Letwin and Michael Brown.
In an interview with "Metro" in September 2006 she stated that if Parliament were of a normal length, it was likely she would retire at the next general election. She confirmed her intention to stand down to "The Observer'"s Pendennis diary in September 2007, and again in October 2007 after Prime Minister Gordon Brown quashed speculation of an autumn 2007 general election.
Widdecombe was one of the 98 MPs who voted to keep their expense details secret. When the expenses claims were leaked, however, Widdecombe was described by "The Daily Telegraph" as one of the "saints" amongst all MPs.
In May 2009, following the resignation of Michael Martin as Speaker of the House of Commons, it was reported that Widdecombe was gathering support for election as interim Speaker until the next general election. On 11 June 2009, she confirmed her bid to be the Speaker. She made it through to the second ballot but came last and was eliminated.
Widdecombe retired from politics at the 2010 general election. It was rumoured that she would be a Conservative candidate for Police and Crime Commissioner in 2012, but she refused. She has since spoken about her opposition to the Coalition Government and her surprise at not being given a peerage by David Cameron.
Recognition.
Widdecombe was appointed an Honorary Fellow of Canterbury Christ Church University at a ceremony held at Canterbury Cathedral on 30 January 2009.
Personal life and family.
Until her retirement at the 2010 general election, Widdecombe divided her time between her two homes – one in London and one in the village of Sutton Valence, Kent, in her constituency. She sold both of these properties, however, upon deciding to retire at the next general election. She shared her home in London with her widowed mother, Rita Widdecombe, until Rita's death, on 25 April 2007, aged 95. In March 2008, she purchased a house in Haytor, on Dartmoor in Devon, to where she has now retired. Her brother, Malcolm (1937–2010), who was an Anglican Canon in Bristol, retired in May 2009 and died of metastatic oesophageal cancer on 12 October 2010. Her nephew, Rev Roger Widdecombe, is an Anglican priest.
She has never married nor had any children. In November 2007 on BBC Radio 4 she described how a journalist once produced a profile on her with the assumption that she had had at least "one sexual relationship", to which Widdecombe replied: "Be careful, that's the way you get sued". When interviewer Jenni Murray asked if she had ever had a sexual relationship, Widdecombe laughed "it's nobody else's business".
Widdecombe has a fondness for cats and has a section of her website devoted to all the pet cats with which she has shared her life. In a recent interview, Widdecombe talked about her appreciation of music despite describing herself as "pretty well tone-deaf".
Religious views.
Widdecombe is a practising Roman Catholic. She converted in 1993 after leaving the Church of England. Her reasons for leaving the latter were many, as she explained to reporters from the "New Statesman":
In 2010, Widdecombe turned down an offer to be Britain's next ambassador to the Holy See, being prevented from accepting by suffering a detached retina. She was made a Dame of the Order of St. Gregory the Great by Pope Benedict XVI for services to politics and public life on 31 January 2013.
Controversies.
In 1990, following the assassination of the Conservative politician Ian Gow by the Provisional Irish Republican Army (IRA), the Eastbourne by-election for his seat in the House of Commons was won by the Liberal Democrat David Bellotti. Upon the announcement, Widdecombe told the voters that the IRA would be "toasting their success".
In 1996, Widdecombe, as prisons minister, defended the Government's policy to shackle pregnant prisoners with handcuffs and chains when in hospital receiving ante-natal care. Widdecombe told the Commons the restrictions were needed to prevent prisoners from escaping. "Some MPs may like to think that a pregnant woman would not or could not escape. Unfortunately this is not true. The fact is that hospitals are not secure places in which to keep prisoners, and since 1990, 20 women have escaped from hospitals". Jack Straw, Labour's Home Affairs spokesman at the time, said it was "degrading and unnecessary" for a woman to be shackled at any stage.
In 1997, during the Conservative leadership election of William Hague, Widdecombe spoke out against Michael Howard, under whom she had served when he was Home Secretary. She remarked that "there is something of the night about him". The remark was considered to be extremely damaging to Howard, who was frequently satirised as a vampire thereafter. He came last in the poll. Howard went on to become party leader in 2003, however, and Widdecombe then stated, "I explained fully what my objections were in 1997 and I do not retract anything I said then. But this is 2005 and we have to look to the future and not the past."
In 2001, when Michael Portillo was running for leader of the Conservative Party, Widdecombe described him and his allies as "backbiters". She went on to say that, should he be appointed leader, she would never give him her allegiance.
Media work and appearances.
In 2002, she took part in the ITV programme "Celebrity Fit Club". Also in 2002 she took part in a Louis Theroux television documentary, depicting her life, both in and out of politics. In March 2004 she briefly became "The Guardian" newspaper's agony aunt, introduced with an Emma Brockes interview. In 2005 BBC Two showed six episodes of "The Widdecombe Project", an agony aunt television programme. In 2005, she appeared in a new series of "Celebrity Fit Club", but this time as a panel member dispensing wisdom and advice to the celebrities taking part. Also in 2005, she presented the show "Ann Widdecombe to the Rescue" in which she acted as an agony aunt, dispensing no-nonsense advice to disputing families, couples, and others across the UK. In 2005, she also appeared in a discussion programme on Five to discuss who had been England's greatest monarch since the Norman Conquest; her choice of monarch was Charles II.
She was the guest host of news quiz "Have I Got News for You" twice, in 2006 and 2007. Following her second appearance, Widdecombe vowed she would never appear on the show again because of comments made by panellist Jimmy Carr. She wrote, "His idea of wit is a barrage of filth and the sort of humour most men grow out of in their teens... here's no amount of money for which I would go through those two recording hours again. At one stage I nearly walked out." She did, however, stand by her appraisal of regular panellists Ian Hislop and Paul Merton, whom she has called "the fastest wits in showbusiness".
In 2007, she awarded the "University Challenge" trophy to the winners. In the same year, she was cast as herself in "The Sound of Drums", the 12th episode of the third series of the science-fiction drama "Doctor Who" supporting Mr Saxon, the alias of the Master.
Since 2007, Widdecombe has fronted a television series called "Ann Widdecombe Versus", on ITV1, in which she speaks to various people about things related to her as an MP, with an emphasis on confronting those responsible for problems she wished to tackle. On 15 August 2007 she talked about prostitution, the next week about benefits and the week after that about truancy. A fourth episode was screened on 18 September 2008 in which she travelled around London and Birmingham talking to girl gangs.
In 2009, Widdecombe appeared with Archbishop John Onaiyekan in an "Intelligence Squared" debate in which they defended the motion that the Catholic Church was a force for good. Arguing against the motion were Stephen Fry and Christopher Hitchens.
In October 2010, she appeared on BBC One's "Strictly Come Dancing", partnered by Anton du Beke, winning the support of some viewers despite low marks from the judges. After nine weeks of routines strongly flavoured by comedy the couple had received enough support in the public vote to stay in the contest. Widdecombe was eliminated from the competition on Sunday 5 December after the public vote had been combined with the judges' score; she was with Scott Maslen of "EastEnders" in the bottom two.
Widdecombe is currently filming a new quiz show with herself as questionmaster, for the Sky Atlantic channel, called "Cleverdicks". The show is being shown in 30 one-hour episodes in an initial series, starting 2012. It features four contestants, usually high quality members of the UK national quiz circuit and ends with a money round for the winner of each show.
On 23 April 2012 Widdecombe presented an hour-long documentary for BBC Radio 5 Live, "Drunk Again: Ann Widdecombe Investigates", looking at how the British attitude to getting drunk has changed over the last few years.
It was revealed in October 2012, that the year's Children in Need's appeal night will feature a "Strictly Come Dancing" special with former show favourites Russell Grant and Ann Widdecombe.
On 4 November 2012, Ann presented guest hosted one episode of BBC's "Songs of Praise" programme about singleness.
In October 2014 she appeared in the BBC series "Celebrity Antiques Road Trip", partnered with expert Mark Stacey, where the pair beat the rival team of Craig Revel Horwood and Catherine Southon.
Ann Widdecombe was a part of BBC TV Series 24 Hours in the Past, along with Colin Jackson, Alistair McGowan, Miquita Oliver, Tyger Drew-Honey and Zoe Lucker. The 4 part series was aired from 28 April till 19 May 2015 on BBC 1
Stage acting career.
Following her retirement, Widdecombe made her stage debut, on 9 December 2011, at The Orchard Theatre, Dartford in the Christmas pantomime "Snow White and the Seven Dwarfs", alongside "Strictly Come Dancing" judge Craig Revel Horwood. In April 2012, she had a ten-minute non-singing cameo part in Gaetano Donizetti's comic opera "La Fille Du Regiment", playing the Duchesse de Crackentorp. Ann reprised her pantomime performance, again with Revel Horwood, at The Swan Theatre, High Wycombe in December 2012.
Other interests.
Her non-political accomplishments include being a popular novelist. Widdecombe also currently writes a weekly column for the "Daily Express".
In October 2006, she pledged to boycott British Airways for suspending a worker who refused to hide her cross. The matter was resolved when the company reversed the suspension. In November 2006, she moved into the house of an Islington Labour Councillor to experience life on a council estate, her response to her experience being "Five years ago I made a speech in the House of Commons about the forgotten decents. I have spent the last week on estates in the Islington area finding out that they are still forgotten."
In January 2011 Widdecombe was joint President of the North of England Education Conference in Blackpool. She shared the responsibility with a young person from the town. She has also become a patron of The Grace Charity for M.E.
Widdecombe revealed, in an April 2012 interview with Matt Chorley of The Independent, that she was writing her autobiography, which she described as ".. rude about all and sundry, but an amount of truth is always necessary."
Widdecombe is a Patron of the charity Safe Haven for Donkeys in the Holy Land (SHADH) and in 2014 visited the SHADH Donkey Sanctuary in Palestine.

</doc>
<doc id="2425" url="https://en.wikipedia.org/wiki?curid=2425" title="Aurangzeb">
Aurangzeb

Abul Muzaffar Muhi-ud-Din Muhammad Aurangzeb (3 November 1618 – 3 March 1707), commonly known as Aurangzeb Alamgir and by his imperial title Alamgir ("world conqueror" or "universe conqueror") and simply referred to as Aurangzeb was the sixth Mughal Emperor and ruled over most of the Indian subcontinent during some parts of his reign. His reign lasted for 49 years from 1658 until his death in 1707.
Aurangzeb was a notable expansionist and during his reign, the Mughal Empire temporarily reached its greatest extent. During his lifetime, victories in the south expanded the Mughal Empire to more than 3.2 million square kilometres and he ruled over a population estimated as being in the range of 100–150 million subjects, with an annual yearly tribute of £38,624,680 (2,879,469,894 rupees) in 1690 (the highest in the world at that time).
Aurangzeb's policies partly abandoned the legacy of pluralism, which remains a very controversial aspect of his reign and led to the downfall of the Mughal Empire. Rebellions and wars led to the exhaustion of the imperial Mughal treasury and army. He was a strong-handed authoritarian ruler, and following his death the expansionary period of the Mughal Empire came to an end, and centralized control of the empire declined rapidly.
Early life.
Aurangzeb was born on 3 November 1618, in Dahod, Gujarat. He was the third son and sixth child of Shah Jahan and Mumtaz Mahal. His father was a governor of Gujarat at that time. In June 1626, after an unsuccessful rebellion by his father, Aurangzeb and his brother Dara Shikoh were kept as hostages under their grandparents' (Nur Jahan and Jahangir) Lahore court. On 26 February 1628, Shah Jahan was officially declared the Mughal Emperor, and Aurangzeb returned to live with his parents at Agra Fort, where Aurangzeb received his formal education in Arabic and Persian. His daily allowance was fixed at Rs. 500 which he spent on religious education and the study of history. He also accused his brothers of alcoholism and womanising.
On 28 May 1633, Aurangzeb escaped death when a powerful war elephant stampeded through the Mughal Imperial encampment. He rode against the elephant and struck its trunk with a lance, and successfully defended himself from being crushed. Aurangzeb's valour was appreciated by his father who conferred him the title of "Bahadur" (Brave) and had him weighed in gold and presented gifts worth Rs. 200,000. This event was celebrated in Persian and Urdu verses and Aurangzeb said:
Early military campaigns and administration.
Bundela War.
On 15 December 1634, Aurangzeb was given his first command, comprising 10,000 horse and 4000 troopers. He was allowed to use the red tent, which was an imperial prerogative.
Subsequently, Aurangzeb was nominally in charge of the force sent to Bundelkhand with the intent of subduing the rebellious ruler of Orchha, Jhujhar Singh, who had attacked another territory in defiance of Shah Jahan's policy and was refusing to atone for his actions. By arrangement, Aurangzeb stayed in the rear, away from the fighting, and took the advice of his generals as the Mughal Army gathered and commenced the Siege of Orchha in 1635. The campaign was successful and Singh was removed from power.
Viceroy of the Deccan.
Aurangzeb was appointed Viceroy of the Deccan in 1636. After Shah Jahan's vassals had been devastated by the alarming expansion of Ahmednagar during the reign of the Nizam Shahi boy-prince Murtaza Shah III, the emperor dispatched Aurangzeb, who in 1636 brought the Nizam Shahi dynasty to an end. In 1637, Aurangzeb married the Safavid princess, Dilras Banu Begum, also known as Rabia-ud-Daurani. She was his first wife and chief consort. He also had an infatuation with a slave girl, Hira Bai, whose death at a young age greatly affected him. In his old age, he was under the charms of his concubine, Udaipuri Bai. The latter had formerly been a companion to Dara Shikoh. In the same year, 1637, Aurangzeb was placed in charge of annexing the small Rajput kingdom of Baglana, which he did with ease.
In 1644, Aurangzeb's sister, Jahanara, was burned when the chemicals in her perfume were ignited by a nearby lamp while in Agra. This event precipitated a family crisis with political consequences. Aurangzeb suffered his father's displeasure by not returning to Agra immediately but rather three weeks later. Shah Jahan had been nursing Jahanara back to health in that time and thousands of vassals had arrived in Agra to pay their respects. Shah Jahan was outraged to see Aurangzeb enter the interior palace compound in military attire and immediately dismissed him from his position of Viceroy of the Deccan; Aurangzeb was also no longer allowed to use red tents or to associate himself with the official military standard of the Mughal emperor.
In 1645, he was barred from the court for seven months and mentioned his grief to fellow Mughal commanders. Thereafter, Shah Jahan appointed him governor of Gujarat where he served well and was rewarded for bringing stability.
In 1647, Shah Jahan moved Aurangzeb from Gujarat to be governor of Balkh, replacing a younger son, Murad Baksh, who had proved ineffective there. The area was under attack from Uzbek and Turkmen tribes. Whilst the Mughal artillery and muskets were a formidable force, so too were the skirmishing skills of their opponents. The two sides were in stalemate and Aurangzeb discovered that his army could not live off the land, which was devastated by war. With the onset of winter, he and his father had to make a largely unsatisfactory deal with the Uzbeks, giving away territory in exchange for nominal recognition of Mughal sovereignty. The Mughal force suffered still further with attacks by Uzbeks and other tribesmen as it retreated through snow to Kabul. By the end of this two-year campaign, into which Aurangzeb had been plunged at a late stage, a vast sum of money had been expended for little gain.
Further inauspicious military involvements followed, as Aurangzeb was appointed governor of Multan and Sindh. His efforts in 1649 and 1652 to dislodge the Safavids at Kandahar, which they had recently retaken after a decade of Mughal control, both ended in failure as winter approached. The logistical problems of supplying an army at the extremity of the empire, combined with the poor quality of armaments and the intransigence of the opposition have been cited by John Richards as the reasons for failure, and a third attempt in 1653, led by Dara Shikoh, met with the same outcome.
Dara Shikoh's appointment followed the removal of Aurangzeb, who once again became Viceroy in the Deccan. He regretted this and harboured feelings that Shikoh had manipulated the situation to serve his own ends. Aurangbad's two "jagirs" (land grants) were moved there as a consequence of his return and, because the Deccan was a relatively impoverished area, this caused him to lose out financially. So poor was the area that grants were required from Malwa and Gujarat in order to maintain the administration and the situation caused ill-feeling between father and son. Shah Jahan insisted that things could be improved if Aurangzeb made efforts to develop cultivation, but the efforts that were made proved too slow in producing results to satisfy the emperor.
Aurangzeb proposed to resolve the situation by attacking the dynastic occupants of Golconda (the Qutb Shahis) and Bijapur (the Adil Shahis). As an adjunct to resolving the financial difficulties, the proposal would also extend Mughal influence by accruing more lands. Again, he was to feel that Dara had exerted influence on his father: believing that he was on the verge of victory in both instances, Aurangzeb was frustrated that Shah Jahan chose then to settle for negotiations with the opposing forces rather than pushing for complete victory.
War of Succession.
The four sons of Shah Jahan all held posts as governors during their father's reign. The emperor favoured the eldest, Dara Shikoh, and this had caused resentment among the younger three, who sought at various times to strengthen alliances between themselves and against Dara. There was no Muslim tradition of primogeniture and historian Satish Chandra says that "In the ultimate resort, connections among the powerful military leaders, and military strength and capacity the real arbiters." Jacques Weber, emeritus professor of modern history at the University of Nantes, explains that "... the loyalties of these officials seem to have been motivated more by their own interests, the closeness of the family relation and above all the charisma of the pretenders than by ideological divides." The contest for power was primarily between Dara Shikoh and Aurangzeb because, although all four sons had demonstrated competence in their official roles, it was around these two that the supporting cast of officials and other influential people mostly circulated. There were ideological differences — Dara was an intellectual and a religious liberal in the mould of Akbar, while Aurangzeb was much more conservative — but, as historians Barbara D. Metcalf and Thomas R. Metcalf say, "To focus on divergent philosophies neglects the fact that Dara was a poor general and leader. It also ignores the fact that factional lines in the succession dispute were not, by and large, shaped by ideology ..." Muslims and Hindus did not divide along religious lines in their support for one pretender or the other nor, according to Chandra, is there much evidence to support the belief that Jahanara and other members of the royal family were split in their support. Jahanara, certainly, interceded at various times on behalf of all of the princes and was well-regarded by Aurangzeb even though she shared the religious outlook of Dara.
In 1656, a general under Qutb Shahi dynasty named Musa Khan lead an army of 12,000 Musketeers to attack Aurangzeb, and later on the same campaign Aurangzeb in turn rode against an army consisting 8,000 horsemen and 20,000 Karnataka Musketeers
Having made clear that he wanted Dara to succeed him, Shah Jahan became ill with stranguary in 1657 and was closeted under the care of his favourite son in the newly built city of Shahjahanabad (Old Delhi). Rumours of the death of Shah Jahan abounded and the younger sons were concerned that Dara might be hiding it for Machiavellian reasons. Thus, they took action: Shah Shuja prepared to contest the throne from Bengal, where he had been governor since 1637, while Murad did the same in his governorship of Gujarat and Aurangzeb did so in the Deccan. It is not known whether these preparations were made in the mistaken belief that the rumours of death were true or whether the challengers were just taking advantage of the situation.
After regaining some of his health, Shah Jahan moved to Agra and Dara urged him to send forces to challenge Shah Shuja and Murad, who had declared themselves rulers in their respective territories. While Shah Shuja was defeated at Banares in February 1658, the army sent to deal with Murad discovered to their surprise that he and Aurangzeb had combined their forces, the two brothers having agreed to partition the empire once they had gained control of it. The two armies clashed at Dharmat in April 1658, with Aurangzeb being the victor. Shuja was being chased through Bihar and the victory of Aurangzeb proved this to be a poor decision by Dara Shikoh, who now had a defeated force on one front and a successful force unnecessarily pre-occupied on another. Realising that his recalled Bihar forces would not arrive at Agra in time to resist the emboldened Aurangzeb's advance, Dara scrambled to form alliances in order but found that Aurangzeb had already courted key potential candidates. When Dara's disparate, hastily concocted army clashed with Aurangzeb's well-disciplined, battle-hardened force at the Battle of Samugarh in late May, neither Dara's men nor his generalship were any match for Aurangzeb. Dara had also become over-confident in his own abilities and, by ignoring advice not to lead in battle while his father was alive, he cemented the idea that he had usurped the throne. "After the defeat of Dara, Shah Jahan was imprisoned in the fort of Agra where he spent eight long years under the care of his favourite daughter Jahanara."
Aurangzeb then broke his arrangement with Murad Baksh, which probably had been his intention all along. Instead of looking to partition the empire between himself and Murad, he had his brother arrested and imprisoned at Gwalior Fort. Murad was executed on 4 December 1661, ostensibly for the murder of the "diwan" of Gujarat some time earlier. The allegation was encouraged by Aurangzeb, who caused the "diwan's" son to seek retribution for the death under the principles of Sharia law. Meanwhile, Dara gathered his forces, and moved to the Punjab. The army sent against Shuja was trapped in the east, its generals Jai Singh and Dilir Khan submitted to Aurangzeb, but Dara's son, Suleiman Shikoh, escaped. Aurangzeb offered Shah Shuja the governorship of Bengal. This move had the effect of isolating Dara Shikoh and causing more troops to defect to Aurangzeb. Shah Shuja, who had declared himself emperor in Bengal began to annex more territory and this prompted Aurangzeb to march from Punjab with a new and large army that fought during the Battle of Khajwa, where Shah Shuja and his chain-mail armored war elephants were routed by the forces loyal to Aurangzeb. Shah Shuja then fled to Arakan (in present-day Burma), where he was executed by the local rulers.
With Shuja and Murad disposed of, and with his father immured in Agra, Aurangzeb pursued Dara Shikoh, chasing him across the north-western bounds of the empire. Aurangzeb claimed that Dara was no longer a Muslim and accused him of poisoning the Mughal Grand Vizier Saadullah Khan. Both of these statements however lacked any evidence. After a series of battles, defeats and retreats, Dara was betrayed by one of his generals, who arrested and bound him. In 1658, Aurangzeb arranged his formal coronation in Delhi.
On 10 August 1659, Dara was executed on grounds of apostasy. Having secured his position, Aurangzeb confined his frail father at the Agra Fort but did not mistreat him. Shah Jahan was cared for by Jahanara and died in 1666.
Reign.
Establishment of Islamic law.
Historian Katherine Brown has noted that "The very name of Aurangzeb seems to act in the popular imagination as a signifier of politico-religious bigotry and repression, regardless of historical accuracy." The subject is controversial and, despite no proof, has resonated in modern times with popularly accepted claims that he intended to destroy the Bamiyan Buddhas. As a political and religious conservative, Aurangzeb chose not to follow the liberal religious viewpoints of his predecessors after his ascension. Shah Jahan had already moved away from the liberalism of Akbar, although in a token manner rather than with the intent of suppressing Hinduism, and Aurangzeb took the change still further. Though the approach to faith of Akbar, Jahangir and Shah Jahan was more syncretic than Babur, the founder of the empire, Aurangzeb's position is not so obvious. His emphasis on sharia competed, or was directly in conflict, with his insistence that "zawabit" or secular decrees could supersede sharia. Despite claims of sweeping edicts and policies, contradictory accounts exist. He sought to codify Hanafi law by the work of several hundred jurists, called Fatawa-e-Alamgiri. It is possible the War of Succession and continued incursions combined with Shah Jahan's spending made cultural expenditure impossible.
As emperor, Aurangzeb banned alcoholism, gambling, castration, servitude, eunuchs, music, nautch and narcotics in the Mughal Empire. He learnt that at Sindh, Multan, Thatta and particularly at Varanasi, the Hindu Brahmins attracted large numbers of indigenous local Muslims to their discourses. He ordered the Subahdars of these provinces to demolish the schools and the temples of non-Muslims. Aurangzeb also ordered Subahdars to punish Muslims who dressed like non-Muslims. The executions of the antinomian Sufi mystic Sarmad Kashani and the ninth Sikh Guru Tegh Bahadur bear testimony to Aurangzeb's religious intolerance; the former was beheaded on multiple accounts of heresy, the latter, according to Sikhs, because he objected to Aurangzeb's forced conversions. According to other sources, there is no official account that Aurangzeb forcefully converted people. He imposed Jizya on non-Muslims. Further, Aurangzeb levied discriminatory taxes on Hindu merchants at the rate of 5% as against 2.5% on Muslim merchants. He ordered to dismiss all Hindu "quanungos" and "patwaris" from revenue administration.
Another instance of Aurangzeb's notoriety was his policy of temple destruction, for which figures vary wildly from 80 to 60,000. Indian historian Harbans Mukhia wrote that "In the end, as recently recorded in Richard Eaton's careful tabulation, some 80 temples were demolished between 1192 and 1760 (15 in Aurangzeb's reign) and he compares this figure with the claim of 60,000 demolitions, advanced rather nonchalantly by 'Hindu nationalist' propagandists,' although even in that camp professional historians are slightly more moderate." Among the Hindu temples he demolished were the three most sacred: the Kashi Vishwanath temple, Kesava Deo temple and Somnath temple. He built large mosques in their place. In 1679, he ordered destruction of several prominent temples that had become associated with his enemies: these included the temples of Khandela, Udaipur, Chittor and Jodhpur. Historian Richard Eaton believes the overall understanding of temples to be flawed. As early as the sixth century, temples became vital political landmarks as well as religious ones. He writes that not only was temple desecration widely practised and accepted, it was a necessary part of political struggle. Catherine Asher has said that Aurangzeb's temple destruction was a political response for the challenges to his authority rather than bigotry. Francois Bernier, who traveled and chronicled Mughal India during the War of Succession, notes the distaste of both Shah Jahan and Aurangzeb for Christians. This led to the demolition of Christian settlements near the European factories and enslavement of Christian converts by Shah Jahan. Furthermore, Aurangzeb stopped all the aid to Christian missionaries (Frankish Padres) that had been initiated by Akbar and Jahangir.
Ram Puniyani states that Aurangzeb was not always fanatically anti-Hindu, and kept changing his policies depending on the needs of the situation. He banned the construction of new temples, but permitted the repair and maintenance of existing temples. He also made generous donations of "jagir"s to several temples to win the sympathies of his Hindu subjects. There are several "firman"s (orders) in his name, supporting temples and gurudwaras, including Mahakaleshwar temple of Ujjain, Balaji temple of Chitrakoot, Umananda Temple of Guwahati and the Shatrunjaya Jain temples. During his time, the number of Hindu Mansabdars increased from 22% to 31% in the Mughal administration as he needed them to continue his fight in the Deccan.
Execution of opponents.
The first prominent execution during the long reign of Aurangzeb started with that of his brother Prince Dara Shikoh, who was accused of being influenced by Hinduism although some sources argue it was done for political reasons. Aurangzeb had his allied brother Prince Murad Baksh held for murder, judged and then executed. Aurangzeb is accused of poisoning his imprisoned nephew Sulaiman Shikoh.
Aurangzeb then executed Sarmad Kashani a controversial Sufi mystic of Jewish origins.
Later Aurangzeb executed Sambhaji the leader of the Maratha Confederacy. During his trial he was found guilty of murder and violence, atrocities against the Muslims of Burhanpur and Bahadurpur in Berar by Marathas under his command.
The Sikh leader Guru Tegh Bahadur was arrested on orders by Aurangzeb, found guilty of blasphemy by a Qadi's court and executed.
Expansion of the Mughal Empire.
Throughout his reign, Aurangzeb engaged in almost constant warfare. He built up a massive army and began a program of military expansion along all the boundaries of his empire. He pushed north-west into the Punjab and also drove south, conquering two further Muslim kingdoms - the Adil Shahis of Bijapur and Qutbshahis of Golconda — to add to the defeat of the Ahmednagar Sultanate that had been accomplished in 1636 while he had been viceroy of the Deccan. These new territories were administered by the Mughal Nawabs loyal to Aurangzeb.
Soon after seizing the throne, Aurangzeb began advancements against the unruly Sultan of Bijapur and during 1657, the Mughals are known to have utilized rockets during the Siege of Bidar, against Sidi Marjan. Aurangzeb's forces discharged rockets and grenades while scaling the walls, and Sidi Marjan himself was mortally wounded after a rocket struck his large gunpowder depot. After twenty-seven days of hard fighting, Bidar was captured by the Mughals.
In 1663, during his visit to Ladakh, Aurangzeb established direct control over that part of the empire and loyal subjects such as Deldan Namgyal agreed to pledge tribute and loyalty. Deldan Namgyal is also known to have constructed a Grand Mosque in Leh, which he dedicated to Mughal rule.
In 1664, Shaista Khan (the son of Asaf Khan IV), was appointed the Subedar of Bengal. He immediately eliminated Portuguese and Arakanese pirates from the region, and in 1666 led an army of 70,000 men to recapture the port of Chittagong from the Arakanese king Sanda Thudhamma. Chittagong remained a key port throughout Mughal rule.
In 1685, Aurangzeb dispatched his son, Muhammad Azam Shah, with a force of nearly 50,000 men to capture Bijapur Fort and defeat Sikandar Adil Shah (the ruler of Bijapur) who refused to be a vassal. The Mughals could not make any advancements upon Bijapur Fort mainly because of the superior usage of cannon batteries on both sides. Outraged by the stalemate Aurangzeb himself arrived on 4 September 1686 and commanded the Siege of Bijapur; after eight days of fighting, the Mughals were victorious.
Only one remaining ruler, Abul Hasan Qutb Shah (the Qutbshahi ruler of Golconda), refused to surrender. He and his servicemen fortified themselves at Golconda and fiercely protected the Kollur Mine, which was then probably the world's most productive diamond mine, and an important economic asset. In 1687, Aurangzeb led his grand Mughal army against the Deccan Qutbshahi fortress during the Siege of Golconda. The Qutbshahis had constructed massive fortifications throughout successive generations on a granite hill over 400 ft high with an enormous eight-mile long wall enclosing the city. The main gates of Golconda had the ability to repulse any war elephant attack. Although the Qutbshahis maintained the impregnability of their walls, at night Aurangzeb and his infantry erected complex scaffolding that allowed them to scale the high walls. During the eight-month siege the Mughals faced many hardships including the death of their experienced commander Kilich Khan Bahadur. Eventually, Aurangzeb and his forces managed to penetrate the walls by capturing a gate, and their entry into the fort led Abul Hasan Qutb Shah to surrender peacefully.
Military equipment.
Mughal cannon making skills advanced during the 17th century. One of the most impressive Mughal cannons is known as the Zafarbaksh, which is a very rare "composite cannon", that required skills in both wrought-iron forge welding and bronze-casting technologies and the in-depth knowledge of the qualities of both metals.
Aurangzeb military entourage consisted of 16 cannons including the "Azdaha Paikar" (which, was capable of firing a 33.5 kg ordnance) and "Fateh Rahber" (20 feet long with Persian and Arabic inscriptions).
The "Ibrahim Rauza" was also a famed cannon, which was well known for its multi-barrels. François Bernier, the personal physician to Aurangzeb, observed versatile Mughal gun-carriages each drawn by two horses.
Despite these innovations, most soldiers used bows and arrows, the quality of sword manufacture was so poor that they preferred to use ones imported from England, and the operation of the cannons was entrusted not to Mughals but to European gunners. Other weapons used during the period included rockets, cauldrons of boiling oil, muskets and manjaniqs (stone-throwing catapults).
Infantry who were later called Sepoy and who specialized in siege and artillery emerged during the reign of Aurangzeb
War elephants.
In the year 1703, the Mughal commander at Coromandel, Daud Khan Panni spent 10,500 coins to purchase 30 to 50 war elephants from Ceylon.
Art and Culture.
Aurangzeb was known to be of a more austere nature than his predecessors. Being religious he encouraged Islamic calligraphy. His reign also saw the building of the Lahore badshahi Mosque, and Bibi ka Maqbara in Aurangabad for his wife Rabia-ud-Daurani.
Calligraphy.
The Mughal Emperor Aurangzeb is known to have patronized works of Islamic Calligraphy during his reign particularly Syed Ali Tabrizi.
Architecture.
Unlike his father, Aurangzeb was not much interested in architecture. The structure of Bibi Ka Maqbara in Aurangabad,which now is a historical monument was constructed by the sons of Aurangzeb in remembrance of their mother. The inspiration came from Taj mahal as is quite visible from its architecture. Aurangzeb ordered the construction of the Badshahi Mosque in Lahore. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. He also constructed a mosque on Benares. The mosque he constructed in Srinagar is still the largest in Kashmir.
Textile.
The Textile industry in the Mughal Empire emerged very firmly during the reign of the Mughal Emperor Aurangzeb and was particularly well noted by Francois Bernier, a French physician of the Mughal Emperor. Francois Bernier writes how "Karkanahs", or workshops for the artisans, particularly in textiles flourished by "employing hundreds of embroiderers, who were superintended by a master". He further writes how "Artisans manufacture of silk, fine brocade, and other fine muslins, of which are made turbans, robes of gold flowers, and tunics worn by females, so delicately fine as to wear out in one night, and cost even more if they were well embroidered with fine needlework".
He also explains the different techniques employed to produce such complicated textiles such as "Himru" (whose name is Persian for "brocade"), "Paithani" (whose pattern is identical on both sides), "Mushru" (satin weave) and how "Kalamkari", in which fabrics are painted or block-printed, was a technique that originally came from Persia. Francois Bernier provided some of the first, impressive descriptions of the designs and the soft, delicate texture of Pashmina Shawls also known as "Kani", which were very valued for their warmth and comfort among the Mughals, and how these textiles and shawls eventually began to find their way to France and England.
Foreign relations.
As soon as he became emperor, Aurangzeb sent some of the finest ornate gifts such as carpets, lamps, tiles and others to the Islamic shrines at Mecca and Medina. He also ordered the construction of very large ships in Surat that would transport these gifts and even pilgrims to the Hijaz. These annual expeditions organized by Aurangzeb were led by Mir Aziz Badakhshi who died in Mecca of natural causes but managed to deliver more than 45,000 silver coins and several thousand Kaftans of honor.
Relations with the Uzbek.
Subhan Quli, Balkh's Uzbek ruler was the first to recognize him in 1658 and requested for a general alliance, he worked alongside the new Mughal Emperor since 1647, when Aurangzeb was the Subedar of Balkh.
Relations with the Safavid dynasty.
Aurangzeb received the embassy of Abbas II of Persia in 1660 and returned them with gifts. However relations between the Mughal Empire and the Safavid dynasty were tense because the Persians attacked the Mughal army positioned near Kandahar. Aurangzeb prepared his armies in the Indus River Basin for a counteroffensive, but Abbas II's death in 1666 caused Aurangzeb to end all hostilities. Aurangzeb's rebellious son, Sultan Muhammad Akbar, sought refuge with Suleiman I of Persia, who had rescued him from the Imam of Musqat and later refused to assist him in any military adventures against Aurangzeb.
Relations with the French.
In 1667, the French East India Company ambassadors Le Gouz and Bebert presented Louis XIV of France's letter which urged the protection of French merchants from various rebels in the Deccan. In response to the letter Aurangzeb issued a Firman allowing the French to open a factory in Surat.
Relations with the Sultanate of Maldives.
In the 1660s, the Sultan of the Maldives, Ibrahim Iskandar I, requested help from Aurangzeb's representative, the Faujdar of Balasore. The sultan was concerned about the impact of Dutch and English trading ships but the powers of Aurangzeb did not extend to the seas, the Maldives were not under his governance and nothing came of the request.
Relations with the Ottoman Empire.
In 1688, the desperate Ottoman Sultan Suleiman II urgently requested for assistance against the rapidly advancing Austrians, during the Ottoman–Habsburg War. However, Aurangzeb and his forces were heavily engaged in the Deccan Wars against the Marathas to commit any formal assistance to their Ottoman allies.
Relations with the English.
In 1686, the English East India Company, which had unsuccessfully tried to obtain a firman, an imperial directive that would grant England regular trading privileges throughout the Mughal empire, initiated the so-called Child's War. This hostility against the empire ended in disaster for the English, particularly when Aurangzeb dispatched a strong fleet from Janjira commanded by the Sidi Yaqub and manned by Mappila loyal to Ali Raja Ali II and Abyssinian sailors firmly blockaded Bombay in 1689. In 1690, the company sent envoys to Aurangzeb's camp to plead for a pardon. The company's envoys had to prostrate themselves before the emperor, pay a large indemnity, and promise better behavior in the future.
In September 1695, English pirate Henry Every perpetrated one of the most profitable pirate raids in history with his capture of a Grand Mughal convoy near Surat. The Indian ships had been returning home from their annual pilgrimage to Mecca when the pirates struck, capturing the "Ganj-i-Sawai", reportedly the greatest ship in the Muslim fleet, and its escorts in the process. When news of the piracy reached the mainland, a livid Aurangzeb nearly ordered an armed attack against the English-governed city of Bombay, though he finally agreed to compromise after the East India Company promised to pay financial reparations, estimated at £600,000 by the Mughal authorities. Meanwhile, Aurangzeb shut down four of the East India Company's factories, imprisoned the workers and captains (who were nearly lynched by a rioting mob), and threatened to put an end to all English trading in India until Every was captured. The Privy Council and East India Company offered a massive bounty for Every's apprehension, leading to the first worldwide manhunt in recorded history. However, Every successfully eluded capture.
In 1702, Aurangzeb sent Daud Khan Panni, the Mughal Empire's Subhedar of the Carnatic region, to besiege and blockade Fort St. George for more than three months. The governor of the fort Thomas Pitt was instructed by the English East India Company to sue for peace.
Administrative reforms.
Revenue.
Aurangzeb's exchequer raised a record £100 million in annual revenue through various sources like taxes, customs and land revenue, "et al." from 24 provinces.
Coins.
Aurangzeb felt that verses from the "Quran" should not be stamped on coins, as done in former times, because they were constantly touched by the hands and feet of people. His coins had the name of the mint city and the year of issue on one face, and, the following couplet on other:
Rebellions.
By 1700, the Marathas attacked the Mughal provinces from the Deccan and secessionist agendas from the Rajputs, Hindu Jats, Pashtuns and Sikhs rebelled against the Mughal Empire's administrative and economic systems.
Jat rebellion.
In 1669, Hindu Jats began to organize a rebellion that is believed to have been caused by Aurangzeb's imposition of Jizya (a form of organized religious taxation). The Jats were led by "Gokula", a rebel landholder from Tilpat. By the year 1670 20,000 Jat rebels were quelled and the Mughal Army took control of Tilpat, Gokula's personal fortune amounted to 93,000 gold coins and hundreds of thousands of silver coins.
Gokula was caught and executed. But the Jats continued to terrorize the Mughals and attacked Akbar's mausoleum the gold, silver and fine carpets within the tomb . There are claims that Jats caused two large silver doors at the entrance of the Taj Mahal to be stolen and melted down. However, Jats later established their independent state of Bharatpur.
Mughal–Maratha Wars.
In 1657, while Aurangzeb attacked Golconda and Bijapur in the Deccan, the Hindu Maratha warrior aristocrat, Shivaji, used guerrilla tactics to take control of three Adil Shahi forts formerly under his father's command. With these victories, Shivaji assumed de facto leadership of many independent Maratha clans. The Marathas harried the flanks of the warring Adil Shahis and Mughals, gaining weapons, forts, and territory. Shivaji's small and ill-equipped army survived an all out Adil Shahi attack, and Shivaji personally killed the Adil Shahi general, Afzal Khan. With this event, the Marathas transformed into a powerful military force, capturing more and more Adil Shahi and Mughal territories. Shivaji went on to neutralise Mughal power in the region.
In 1659, Aurangzeb sent his trusted general and maternal uncle Shaista Khan, the Wali in Golconda to recover forts lost to the Maratha rebels. Shaista Khan drove into Maratha territory and took up residence in Pune. But in a daring raid on the governor's palace in Pune during a midnight wedding celebration, the Marathas killed Shaista Khan's son and maimed Shaista Khan by cutting off the fingers of his hand. Shaista Khan, however, survived and was re-appointed the administrator of Bengal going on to become a key commander in the war against the Ahoms.
Shivaji captured forts belonging to both Mughals and Bijapur. At last Aurangzeb ordered the armament of the Daulatabad Fort with two bombards (the Daulatabad Fort was later utilized as a Mughal bastion during the Deccan Wars). Aurangzeb also sent his general Raja Jai Singh of Amber, a Hindu Rajput, to attack the Marathas. Jai Singh won the fort of Purandar after fierce battle in which the Maratha commander Murarbaji fell. Foreseeing defeat, Shivaji agreed for a truce and a meeting with Aurangjeb at Delhi. Jai Singh also promised Shivaji his safety, placing him under the care of his own son, the future Raja Ram Singh I. However, circumstances at the Mughal court were beyond the control of the Raja, and when Shivaji and his son Sambhaji went to Agra to meet Aurangzeb, they were placed under house arrest, from which they managed to effect a daring escape.
Shivaji returned to the Deccan, and crowned himself "Chhatrapati" or the ruler of the Maratha Confederacy in 1674. While Aurangzeb continued to send troops against him, Shivaji expanded Maratha control throughout the Deccan until his death in 1680. Shivaji was succeeded by his son, Sambhaji. Militarily and politically, Mughal efforts to control the Deccan continued to fail.
Aurangzeb's reign over the empire reached its climax the emperor, he no longer honored the rights of Christians, Jews, Muslims, Dadupanthis, Stargazers, Malakis, Atheists, Brahmins, Jains, in fact all the communities of the Empire. His imposition of Jizya upon communities that were not adherents of Islam, led to the rise of the opportunistic Shivaji and his Maratha Confederacy, whose leadership clearly indicated to Aurangzeb in a letter "Protesting against Imposition of Jaziya (2nd April 1679)".
On the other hand, Aurangzeb's third son Akbar left the Mughal court along with a few Muslim Mansabdar supporters and joined Muslim rebels in the Deccan. Aurangzeb in response moved his court to Aurangabad and took over command of the Deccan campaign. The rebels were defeated and Akbar fled south to the shelter of Sambhaji, Shivaji's successor. More battles ensued, and Akbar fled to Persia and never returned.
In 1689, Aurangzeb's forces captured Sambhaji. His successor Rajaram and his Maratha forces fought individual battles against the forces of the Mughal Empire, and territory changed hands repeatedly during years of interminable warfare. As there was no central authority among the Marathas, Aurangzeb was forced to contest every inch of territory, at great cost in lives and money. Even as Aurangzeb drove west, deep into Maratha territory – notably conquering Satara — the Marathas expanded their attacks further into Mughal lands – Malwa, Hyderabad and Jinji in Tamil Nadu. Aurangzeb waged continuous war in the Deccan for more than two decades with no resolution. He thus lost about a fifth of his army fighting rebellions led by the Marathas in Deccan India. He traveled a long distance to the Deccan to conquer the Marathas and eventually died at the age of 90, still fighting the Marathas.
Aurangzeb's shift from conventional warfare to anti-insurgency in the Deccan region shifted the paradigm of Mughal military thought. There were conflicts between Marathas and Mughals in Pune, Jinji, Malwa and Vadodara. The Mughal Empire's port city of Surat was sacked twice by the Marathas during the reign of Aurangzeb and the valuable port was in ruins.
Ahom campaign.
While Aurangzeb and his brother Shah Shuja had been fighting against each other, the Hindu rulers of Kuch Behar and Assam took advantage of the disturbed conditions in the Mughal Empire, had invaded imperial dominions. For three years they were not attacked, but in 1660 Mir Jumla II, the viceroy of Bengal, was ordered to recover the lost territories.
The Mughals set out in November 1661, and within weeks occupied the capital of Kuch Behar after a few fierce skirmishes. The Kuch Behar was annexed, and the Mughal Army reorganized and began to retake their territories in Assam. Mir Jumla II's forces captured Pandu, Guwahati, and Kajali practically unopposed. In February 1662, Mir Jumla II initiated the Siege of Simalugarh and after the Mughal cannon breached the fortifications, the Ahoms abandoned the fort and escaped. Mir Jumla II then proceeded towards Garhgaon the capital of the Ahom kingdom, which was reached on 17 March 1662, although the ruler Raja Sutamla fled and the victorious Mughals captured 100 elephants, about 300,000 coins of silver, 8000 shields, 1000 ships, and 173 massive stores of rice.
Later that year in December 1663, the aged Mir Jumla II died on his way back to Dacca of natural causes, but skirmishes continued between the Mughals and Ahoms after the rise of Chakradhwaj Singha, who refused to pay further indemnity to the Mughals and during the wars that continued the Mughals suffered great hardships. Munnawar Khan emerged as a leading figure and is known to have supplied food to vulnerable Mughal forces in the region near Mathurapur. Although the Mughals under the command of Syed Firoz Khan the Faujdar at Guwahati were overrun by two Ahom armies in the year 1667, but they continued to hold and maintain presence along their the eastern territories even after the Battle of Saraighat in the year 1671.
The Battle of Saraighat was fought in 1671 between the Mughal empire (led by the Kachwaha king, Raja Ramsingh I), and the Ahom Kingdom (led by Lachit Borphukan) on the Brahmaputra river at Saraighat, now in Guwahati. Although much weaker, the Ahom Army defeated the Mughal Army by brilliant uses of the terrain, clever diplomatic negotiations to buy time, guerrilla tactics, psychological warfare, military intelligence and by exploiting the sole weakness of the Mughal forces—its navy.
The Battle of Saraighat was the last battle in the last major attempt by the Mughals to extend their empire into Assam. Though the Mughals managed to regain Guwahati briefly after a later Borphukan deserted it, the Ahoms wrested control in the Battle of Itakhuli in 1682 and maintained it till the end of their rule.
Satnami rebellion.
In May 1672, the Satnami sect obeying the commandments of an "old toothless woman" (according to Mughal accounts) organized a massive revolt in the agricultural heartlands of the Mughal Empire. The Satnamis were known to have shaved off their heads and even eyebrows and had temples in many regions of Northern India. They began a large-scale rebellion 75 miles southwest of Delhi.
The Satnamis believed they were invulnerable to Mughal bullets and believed they could multiply in any region they entered. The Satnamis initiated their march upon Delhi and overran small-scale Mughal infantry units.
Aurangzeb responded by organizing a Mughal army of 10,000 troops and artillery, and dispatched detachments of his own personal Mughal imperial guards to carry out several tasks. In order to boost Mughal morale, Aurangzeb wrote Islamic prayers, made amulets, and drew designs that would become emblems in the Mughal Army. This rebellion would have a serious aftermath effect on the Punjab.
Sikh Rebels.
Early in Aurangzeb's reign, various insurgent groups of Sikhs engaged Mughal troops in increasingly bloody battles. The ninth Sikh Guru, Guru Tegh Bahadur, like his predecessors was opposed to conversion of the local population as he considered it wrong. According to Sikh sources, approached by Kashmiri Pandits to help them retain their faith and avoid forced religious conversions, Guru Tegh Bahadur took on Aurangzeb. Other sources however state that Aurangzeb did not forcefully convert people. The emperor perceived the rising popularity of the Guru as a threat to his sovereignty and in 1670 had him executed, which infuriated the Sikhs. In response, Guru Tegh Bahadur's son and successor, Guru Gobind Singh, further militarized his followers, starting with the establishment of Khalsa in 1699, eight years before Aurangzeb's death. In 1705, Guru Gobind Singh sent a letter entitled "Zafarnamah" to Aurangzeb. This drew attention to Auranzeb's cruelty and how he had betrayed Islam. The letter caused him much distress and remorse. Guru Gobind Singh's formation of Khalsa in 1699 led to the establishment of the Sikh Confederacy and later Sikh Empire.
Pashtun rebellion.
The Pashtun revolt in 1672 under the leadership of the warrior poet Khushal Khan Khattak of Kabul, was triggered when soldiers under the orders of the Mughal Governor Amir Khan allegedly molested women of the Pashtun tribes in modern-day Kunar Province of Afghanistan. The Safi tribes retaliated against the soldiers. This attack provoked a reprisal, which triggered a general revolt of most of tribes. Attempting to reassert his authority, Amir Khan led a large Mughal Army to the Khyber Pass, where the army was surrounded by tribesmen and routed, with only four men, including the Governor, managing to escape.
After that the revolt spread, with the Mughals suffering a near total collapse of their authority in the Pashtun belt. The closure of the important Attock-Kabul trade route along the Grand Trunk road was particularly disastrous. By 1674, the situation had deteriorated to a point where Aurangzeb camped at Attock to personally take charge. Switching to diplomacy and bribery along with force of arms, the Mughals eventually split the rebels and partially suppressed the revolt, although they never managed to wield effective authority outside the main trade route.
Death and legacy.
By 1689, almost all of Southern India was a part of the Mughal Empire and after the conquest of Golconda, Aurangzeb may have been the richest and most powerful man alive. Mughal victories in the south expanded the Mughal Empire to 3.2 million square kilometres, with a population estimated as being between 100 million and 150 million. But this supremacy was short-lived. Jos Gommans, Professor of Colonial and Global History at the University of Leiden, says that "... the highpoint of imperial centralisation under emperor Aurangzeb coincided with the start of the imperial downfall."
Aurangzeb's vast imperial campaigns against rebellion-affected areas of the Mughal Empire caused his opponents to exaggerate the "importance" of their rebellions. The results of his campaigns were made worse by the incompetence of his regional Nawabs.
Muslim views regarding Aurangzeb vary. Most Muslim historians believe that Aurangzeb was the last powerful ruler of an empire inevitably on the verge of decline. The major rebellions organized by the Sikhs and the Marathas had deep roots in the remote regions of the Mughal Empire.
Unlike his predecessors, Aurangzeb considered the royal treasury to be held in trust for the citizens of his empire. He made caps and copied the Quran to earn money for his use. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. However, his constant warfare, especially with the Marathas, drove his empire to the brink of bankruptcy just as much as the wasteful personal spending and opulence of his predecessors. Aurangzeb knew he would not return to the throne after his final campaign against the Marathas in 1706, in which he was joined by newly emerging commanders in the Mughal army such as Syed Hassan Ali Khan Barha, Saadat Ali Khan and Asaf Jah I, and Daud Khan.
The Indologist Stanley Wolpert, emeritus professor at UCLA, says that:
Even when ill and dying, Aurangzeb made sure that the populace knew he was still alive, for if they had thought otherwise then the turmoil of another war of succession was likely. He died in Ahmednagar on 20 February 1707 at the age of 88, having outlived many of his children. His modest open-air grave in Khuldabad expresses his deep devotion to his Islamic beliefs. It is sited in the courtyard of the shrine of the Sufi saint Shaikh Burhan-u'd-din Gharib, who was a disciple of Nizamuddin Auliya of Delhi.
Brown writes that after his death, "a string of weak emperors, wars of succession, and coups by noblemen heralded the irrevocable weakening of Mughal power". She notes that the populist but "fairly old-fashioned" explanation for the decline is that there was a reaction to Aurangzeb's oppression. Aurangzeb's son, Bahadur Shah I, succeeded him and the empire, both because of Aurangzeb's over-extension and because of Bahadur Shah's weak military and leadership qualities, entered a period of terminal decline. Immediately after Bahadur Shah occupied the throne, the Maratha Empire – which Aurangzeb had held at bay, inflicting high human and monetary costs even on his own empire – consolidated and launched effective invasions of Mughal territory, seizing power from the weak emperor. Within decades of Aurangzeb's death, the Mughal Emperor had little power beyond the walls of Delhi.
According to Matthew White's "The Great Big Book of Horrible Things", Aurangzeb was the 23rd worst marauder in world history, during whose reign 4.6 million people perished due to war and devastation.
Full title.
His full imperial title was: Al-Sultan al-Azam wal Khaqan al-Mukarram Hazrat Abul Muzaffar Muhy-ud-Din Muhammad Aurangzeb Bahadur Alamgir I, Badshah Ghazi, Shahanshah-e-Sultanat-ul-Hindiya Wal Mughaliya.
References.
Notes
Citations

</doc>
<doc id="2427" url="https://en.wikipedia.org/wiki?curid=2427" title="Alexandrine">
Alexandrine

An alexandrine () is a line of poetic meter comprising 12 syllables. Alexandrines are common in the German literature of the Baroque period and in French poetry of the early modern and modern periods. Drama in English often used alexandrines before Marlowe and Shakespeare, by whom it was supplanted by iambic pentameter (5-foot verse). In non-Anglo-Saxon or French contexts, the term dodecasyllable is often used.
Origin.
There is some doubt as to the origin of the name; but most probably it is derived from a collection of Alexandrine romances, collected in the 12th century, of which Alexander the Great was the hero, and in which he was represented, somewhat like the British Arthur, as the pride and crown of chivalry. Before the publication of this work most of the trouvère romances appeared in octosyllabic verse. There is also a theory that the form was invented by the 12th-century poet Alexander of Paris. The new work, which was henceforth to set the fashion to French literature, was written in lines of twelve syllables, but with a freedom of pause which was afterwards greatly curtailed. The new fashion, however, was not adopted all at once. The metre fell into disuse until the reign of Francis I, when it was revived by Jean-Antoine de Baïf, one of the seven poets known as La Pléiade.
Syllabic verse.
In syllabic verse, such as that used in French literature, an alexandrine is a line of twelve syllables. Most commonly, the line is divided into two equal parts by a caesura between the sixth and seventh syllables. Alternatively, the line is divided into three four-syllable sections by two caesuras.
The dramatic works of Pierre Corneille and Jean Racine are typically composed of rhyming alexandrine couplets. The caesura after the sixth syllable is here marked ||. Note that in these examples, as in the vast majority of pre-20th-century French poetry, the pronunciation of the "e muet" follows rigid, indeed formal, rules: normally it is pronounced if followed by a consonant sound. Thus "partîm-euh cinq cents", "esclav-euh des Mores" and, still in the 20th-century verse of the Eluard extract, "perl-euh z-en placard".
<poem>Nous partîmes cinq cents ; || mais par un prompt renfort
Nous nous vîmes trois mille || en arrivant au port
Baudelaire's "Les Bijoux" (The Jewels) is a typical example of the use of the alexandrine in 19th-century French poetry:
<poem>La très-chère était nue, || et, connaissant mon cœur,
Elle n'avait gardé || que ses bijoux sonores,
Dont le riche attirail || lui donnait l'air vainqueur
Qu'ont dans leurs jours heureux || les esclaves des Mores.</poem>
Even a 20th-century Surrealist, such as Paul Éluard, used alexandrines on occasion, such as in these lines from "L'Égalité des sexes" (in "Capitale de la douleur") (note the variation between caesuras after the sixth syllable, and after fourth and eighth):
<poem>Ni connu la beauté || des yeux, beauté des pierres,
Celle des gouttes d'eau, || des perles en placard,
Des pierres nues || et sans squelette, || ô ma statue</poem>
Accentual-syllabic verse.
In accentual-syllabic verse, it is a line of Iambic hexameter—a line of six feet or measures ("iambs"), each of which has two syllables with an unstressed syllable followed by a stressed syllable. It is also usual for there to be a caesura between the sixth and seventh syllables (as the examples from Pope below illustrate). Robert Bridges noted that in the lyrical sections of "Samson Agonistes", Milton significantly varied the placement of the caesura.
In Edmund Spenser's "Faerie Queene" eight lines of pentameter are followed by an alexandrine, the eponymous Spenserian stanza. The six-foot line slowed the regular rhythm of the five-foot lines. After Spenser, alexandrine couplets were used by Michael Drayton in his "Poly-Olbion".
Alexander Pope famously characterized the alexandrine's potential to slow or speed the flow of a poem in two rhyming couplets consisting of an iambic pentameter followed by an alexandrine:
<poem>A needless alexandrine ends the song
That like a wounded snake, drags its slow length along.</poem>
A few lines later Pope continues:
<poem>Not so, when swift Camilla scours the Plain,
Flies o'er th'unbending corn and skims along the Main.</poem>
As in the Spenserian stanza above, alexandrines are sometimes mixed with pentameter verse. Shakespeare used them rarely in his blank verse. In the Restoration and eighteenth century, poetry written in couplets is sometimes varied by the introduction of a triplet in which the third line is an alexandrine, as in this sample from Dryden, which introduces a 5-5-6 triplet after two pentameter couplets:
<poem>But satire needs not those, and wit will shine
Through the harsh cadence of a rugged line
A noble error, and but seldom made,
When poets are by too much force betrayed.
Thy generous fruits, though gathered ere their prime,
Still showed a quickness; and maturing time
But mellows what we write to the dull sweets of rhyme.</poem>
Alexandrines also formed the first line of the couplet form Poulter's Measure (the second line being a fourteener) as exemplified in Henry Howard, Earl of Surrey's poem, "Complaint of the Absence of her lover, being upon the sea" (1547).
Modern references.
In the comic book "Asterix and Cleopatra", the author Goscinny inserted a pun about alexandrines: when the Druid Panoramix ("Getafix" in the English translation) meets his Alexandrian (Egyptian) friend the latter exclaims "Je suis, mon cher ami, || très heureux de te voir" at which Panoramix observes "C'est un Alexandrin" ("That's an alexandrine!"/"He's an Alexandrian!"). The pun can also be heard in the theatrical adaptations. The English translation renders this as "My dear old Getafix || How good to see you here", with the reply "Aha, an Alexandrine".

</doc>
<doc id="2428" url="https://en.wikipedia.org/wiki?curid=2428" title="Analog computer">
Analog computer

An analog computer is a form of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically, as their numerical values change. As an analog computer does not use discrete values, but rather continuous values, processes cannot be reliably repeated with exact equivalence, as they can with Turing machines. Analog computers do not suffer from the quantization noise inherent in digital computers, but are limited instead by analog noise.
Analog computers were widely used in scientific and industrial applications where digital computers of the time lacked sufficient performance. Analog computers can have a very wide range of complexity. Slide rules and nomographs are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.
The advent of digital computing and its success made analog computers largely obsolete in 1950s and 1960s, though they remain in use in some specific applications, like the flight computer in aircraft, and for teaching control systems in universities.
Setup.
Setting up an analog computer required scale factors to be chosen, along with initial conditions—that is, starting values. Another essential was creating the required network of interconnections between computing elements. Sometimes it was necessary to re-think the structure of the problem so that the computer would function satisfactorily. No variables could be allowed to exceed the computer's limits, and differentiation was to be avoided, typically by rearranging the "network" of interconnects, using integrators in a different sense.
Running an electronic analog computer, assuming a satisfactory setup, started with the computer held with some variables fixed at their initial values. Moving a switch released the holds and permitted the problem to run. In some instances, the computer could, after a certain running time interval, repeatedly return to the initial-conditions state to reset the problem, and run it again.
Timeline of analog computers.
Precursors.
This is a list of examples of early computation devices which are considered to be precursors of the modern computers. Some of them may even have been dubbed as 'computers' by the press, although they may fail to fit the modern definitions.
The Antikythera mechanism is believed to be the earliest known mechanical analog "computer", according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to "circa" 100 BC. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.
Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. 
The planisphere was a star chart invented by Abū Rayḥān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, "circa" 1000 AD.
The sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.
The planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.
The slide rule was invented around 1620–1630, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Aviation is one of the few fields where slide rules are still in widespread use, particularly for solving time–distance problems in light aircraft.
The tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.
The differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876 Lord Kelvin had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.
Modern era.
The Dumaresq was a mechanical calculating device invented around 1902 by Lieutenant John Dumaresq of the Royal Navy. It was an analog computer which related vital variables of the fire control problem to the movement of one's own ship and that of a target ship. It was often used with other devices, such as a Vickers range clock to generate range and deflection data so the gun sights of the ship could be continuously set. A number of versions of the Dumaresq were produced of increasing complexity as development proceeded.
By 1912 Arthur Pollen had developed an electrically driven mechanical analog computer for fire-control systems, based on the differential analyser. It was used by the Imperial Russian Navy in World War I.
Starting in 1929, AC network analyzers were constructed to solve calculation problems related to electrical power systems that were too large to solve with numerical methods at the time. These were essentially scale models of the electrical properties of the full-size system. Since network analyzers could handle problems too large for analytic methods or hand computation, they were also used to solve problems in nuclear physics and in the design of structures. More than 50 large network analyzers were built by the end of the 1950s.
World War II era gun directors, gun data computers, and bomb sights used mechanical analog computers. Mechanical analog computers were very important in gun fire control in World War II, The Korean War and well past the Vietnam War; they were made in significant numbers.
The FERMIAC was an analog computer invented by physicist Enrico Fermi in 1947 to aid in his studies of neutron transport. Project Cyclone was an analog computer developed by Reeves in 1950 for the analysis and design of dynamic systems. Project Typhoon was an analog computer developed by RCA in 1952. It consisted of over 4000 electron tubes and used 100 dials and 6000 plug-in connectors to program. The MONIAC Computer was a hydraulic model of a national economy first unveiled in 1949.
Computer Engineering Associates was spun out of Caltech in 1950 to provide commercial services using the "Direct Analogy Electric Analog Computer" ("the largest and most impressive general-purpose analyzer facility for the solution of field problems") developed there by Gilbert D. McCann, Charles H. Wilts, and Bart Locanthi.
Educational analog computers illustrated the principles of analog calculation. The Heathkit EC-1, a $199 educational analog computer, was made by the Heath Company, USA c. 1960. It was programmed using patch cords that connected nine operational amplifiers and other components. General Electric also marketed an "educational" analog computer kit of a simple design in the early 1960s consisting of a two transistor tone generator and three potentiometers wired such that the frequency of the oscillator was nulled when the potentiometer dials were positioned by hand to satisfy an equation. The relative resistance of the potentiometer was then equivalent to the formula of the equation being solved. Multiplication or division could be performed depending on which dials were considered inputs and which was the output. Accuracy and resolution was limited and a simple slide rule was more accurate; however, the unit did demonstrate the basic principle.
In industrial process control, thousands of analog loop controllers were used to automatically regulate temperature, flow, pressure, or other process conditions. The technology of these controllers ranged from purely mechanical integrators, through vacuum-tube and solid-state devices, to emulation of analog controllers by microprocessors.
Electronic analog computers.
The similarity between linear mechanical components, such as springs and dashpots (viscous-fluid dampers), and electrical components, such as capacitors, inductors, and resistors is striking in terms of mathematics. They can be modeled using equations of the same form.
However, the difference between these systems is what makes analog computing useful. If one considers a simple mass–spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.
The electrical equivalent can be constructed with a few operational amplifiers (op amps) and some passive linear components; all measurements can be taken directly with an oscilloscope. In the circuit, the (simulated) 'stiffness of the spring', for instance, can be changed by adjusting the parameters of a capacitor. The electrical system is an analogy to the physical system, hence the name, but it is less expensive to construct, generally safer, and typically much easier to modify.
As well, an electronic circuit can typically operate at higher frequencies than the system being simulated. This allows the simulation to run faster than real time (which could, in some instances, be hours, weeks, or longer). Experienced users of electronic analog computers said that they offered a comparatively intimate control and understanding of the problem, relative to digital simulations.
The drawback of the mechanical-electrical analogy is that electronics are limited by the range over which the variables may vary. This is called dynamic range. They are also limited by noise levels. Floating-point digital calculations have a comparatively huge dynamic range.
These electric circuits can also easily perform a wide variety of simulations. For example, voltage can simulate water pressure and electric current can simulate rate of flow in terms of cubic metres per second. An integrator can provide the total accumulated volume of liquid, using an input current proportional to the (possibly varying) flow rate.
Analog computers are especially well-suited to representing situations described by differential equations. Occasionally, they were used when a differential equation proved very difficult to solve by traditional means.
The accuracy of an analog computer is limited by its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer is limited by the word size; arbitrary-precision arithmetic, while relatively slow, provides any practical degree of precision that might be needed.
Many small computers dedicated to specific computations are still part of industrial regulation equipment, but from the 1950s to the 1970s, general-purpose analog computers were the only systems fast enough for real time simulation of dynamic systems, especially in the aircraft, military and aerospace field.
In the 1960s, the major manufacturer was Electronic Associates of Princeton, New Jersey, with its 231R Analog Computer (vacuum tubes, 20 integrators) and subsequently its 8800 Analog Computer (solid state operational amplifiers, 64 integrators). Its challenger was Applied Dynamics of Ann Arbor, Michigan.
Although the basic technology for analog computers is usually operational amplifiers (also called "continuous current amplifiers" because they have no low frequency limitation), in the 1960s an attempt was made in the French ANALAC computer to use an alternative technology: medium frequency carrier and non dissipative reversible circuits.
In the 1970s every big company and administration concerned with problems in dynamics had a big analog computing center, for example: 
Analog–digital hybrids.
Analog computing devices are fast, digital computing devices are more versatile and accurate, so the idea is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal and the output is analog. It acts as an analog potentiometer upgradable digitally. This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.
In the early 1970s analog computer manufacturers tried to tie together their analog computer with a digital computer to get the advantages of the two techniques. In such systems, the digital computer controlled the analog computer, providing initial set-up, initiating multiple analog runs, and automatically feeding and collecting data. The digital computer may also participate to the calculation itself using analog-to-digital and digital-to-analog converters.
The largest manufacturer of hybrid computers was Electronics Associates. Their hybrid computer model 8900 was made of a digital computer and one or more analog consoles. These systems were mainly dedicated to large projects such as the Apollo program and Space Shuttle at NASA, or Ariane in Europe, especially during the integration step where at the beginning everything is simulated, and progressively real components replace their simulated part. 
Only one company was known as offering general commercial computing services on its hybrid computers, CISI of France, in the 1970s.
The best reference in this field is the 100 000 simulations runs for each certification of the automatic landing systems of Airbus and Concorde aircraft. 
After 1980, purely digital computers progressed more and more rapidly and were fast enough to compete with analog computers.
One key to the speed of analog computers was their fully parallel computation, but this was also a limitation. The more equations required for a problem, the more analog components were needed, even when the problem wasn't time critical. "Programming" a problem meant interconnecting the analog operators; even with a removable wiring panel this was not very versatile. Today there are no more big hybrid computers, but only hybrid components.
Implementations.
Mechanical analog computers.
While a wide variety of mechanisms have been developed throughout history, some stand out because of their theoretical importance, or because they were manufactured in significant quantities.
Most practical mechanical analog computers of any significant complexity used rotating shafts to carry variables from one mechanism to another. Cables and pulleys were used in a Fourier synthesizer, a tide-predicting machine, which summed the individual harmonic components. Another category, not nearly as well known, used rotating shafts only for input and output, with precision racks and pinions. The racks were connected to linkages that performed the computation. At least one US Naval sonar fire control computer of the later 1950s, made by Librascope, was of this type, as was the principal computer in the Mk. 56 Gun Fire Control System.
Online, there is a remarkably clear illustrated reference (OP 1140) that describes the fire control computer mechanisms. 
For adding and subtracting, precision miter-gear differentials were in common use in some computers; the Ford Instrument Mark I Fire Control Computer contained about 160 of them.
Integration with respect to another variable was done by a rotating disc driven by one variable. Output came from a pickoff device (such as a wheel) positioned at a radius on the disc proportional to the second variable. (A carrier with a pair of steel balls supported by small rollers worked especially well. A roller, its axis parallel to the disc's surface, provided the output. It was held against the pair of balls by a spring.)
Arbitrary functions of one variable were provided by cams, with gearing to convert follower movement to shaft rotation.
Functions of two variables were provided by three-dimensional cams. In one good design, one of the variables rotated the cam. A hemispherical follower moved its carrier on a pivot axis parallel to that of the cam's rotating axis. Pivoting motion was the output. The second variable moved the follower along the axis of the cam. One practical application was ballistics in gunnery.
Coordinate conversion from polar to rectangular was done by a mechanical resolver (called a "component solver" in US Navy fire control computers). Two discs on a common axis positioned a sliding block with pin (stubby shaft) on it. One disc was a face cam, and a follower on the block in the face cam's groove set the radius. The other disc, closer to the pin, contained a straight slot in which the block moved. The input angle rotated the latter disc (the face cam disc, for an unchanging radius, rotated with the other (angle) disc; a differential and a few gears did this correction).
Referring to the mechanism's frame, the location of the pin corresponded to the tip of the vector represented by the angle and magnitude inputs. Mounted on that pin was a square block.
Rectilinear-coordinate outputs (both sine and cosine, typically) came from two slotted plates, each slot fitting on the block just mentioned. The plates moved in straight lines, the movement of one plate at right angles to that of the other. The slots were at right angles to the direction of movement. Each plate, by itself, was like a Scotch yoke, known to steam engine enthusiasts.
During World War II, a similar mechanism converted rectilinear to polar coordinates, but it was not particularly successful and was eliminated in a significant redesign (USN, Mk. 1 to Mk. 1A).
Multiplication was done by mechanisms based on the geometry of similar right triangles. Using the trigonometric terms for a right triangle, specifically opposite, adjacent, and hypotenuse, the adjacent side was fixed by construction. One variable changed the magnitude of the opposite side. In many cases, this variable changed sign; the hypotenuse could coincide with the adjacent side (a zero input), or move beyond the adjacent side, representing a sign change.
Typically, a pinion-operated rack moving parallel to the (trig.-defined) opposite side would position a slide with a slot coincident with the hypotenuse. A pivot on the rack let the slide's angle change freely. At the other end of the slide (the angle, in trig, terms), a block on a pin fixed to the frame defined the vertex between the hypotenuse and the adjacent side.
At any distance along the adjacent side, a line perpendicular to it intersects the hypotenuse at a particular point. The distance between that point and the adjacent side is some fraction that is the product of "1" the distance from the vertex, and "2" the magnitude of the opposite side.
The second input variable in this type of multiplier positions a slotted plate perpendicular to the adjacent side. That slot contains a block, and that block's position in its slot is determined by another block right next to it. The latter slides along the hypotenuse, so the two blocks are positioned at a distance from the (trig.) adjacent side by an amount proportional to the product.
To provide the product as an output, a third element, another slotted plate, also moves parallel to the (trig.) opposite side of the theoretical triangle. As usual, the slot is perpendicular to the direction of movement. A block in its slot, pivoted to the hypotenuse block positions it.
A special type of integrator, used at a point where only moderate accuracy was needed, was based on a steel ball, instead of a disc. It had two inputs, one to rotate the ball, and the other to define the angle of the ball's rotating axis. That axis was always in a plane that contained the axes of two movement-pickoff rollers, quite similar to the mechanism of a rolling-ball computer mouse (in this mechanism, the pickoff rollers were roughly the same diameter as the ball). The pickoff roller axes were at right angles.
A pair of rollers "above" and "below" the pickoff plane were mounted in rotating holders that were geared together. That gearing was driven by the angle input, and established the rotating axis of the ball. The other input rotated the "bottom" roller to make the ball rotate.
Essentially, the whole mechanism, called a component integrator, was a variable-speed drive with one motion input and two outputs, as well as an angle input. The angle input varied the ratio (and direction) of coupling between the "motion" input and the outputs according to the sine and cosine of the input angle.
Although they did not accomplish any computation, electromechanical position servos were essential in mechanical analog computers of the "rotating-shaft" type for providing operating torque to the inputs of subsequent computing mechanisms, as well as driving output data-transmission devices such as large torque-transmitter synchros in naval computers.
Other non-computational mechanisms included internal odometer-style counters with interpolating drum dials for indicating internal variables, and mechanical multi-turn limit stops.
Considering that accurately controlled rotational speed in analog fire-control computers was a basic element of their accuracy, there was a motor with its average speed controlled by a balance wheel, hairspring, jeweled-bearing differential, a twin-lobe cam, and spring-loaded contacts (ship's AC power frequency was not necessarily accurate, nor dependable enough, when these computers were designed).
Electronic analog computers.
Electronic analog computers typically have front panels with numerous jacks (single-contact sockets) that permit patch cords (flexible wires with plugs at both ends) to create the interconnections which define the problem setup. In addition, there are precision high-resolution potentiometers (variable resistors) for setting up (and, when needed, varying) scale factors. In addition, there is likely to be a zero-center analog pointer-type meter for modest-accuracy voltage measurement. Stable, accurate voltage sources provide known magnitudes.
Typical electronic analog computers contain anywhere from a few to a hundred or more operational amplifiers ("op amps"), named because they perform mathematical operations. Op amps are a particular type of feedback amplifier with very high gain and stable input (low and stable offset). They are always used with precision feedback components that, in operation, all but cancel out the currents arriving from input components. The majority of op amps in a representative setup are summing amplifiers, which add and subtract analog voltages, providing the result at their output jacks. As well, op amps with capacitor feedback are usually included in a setup; they integrate the sum of their inputs with respect to time.
Integrating with respect to another variable is the nearly exclusive province of mechanical analog integrators; it is almost never done in electronic analog computers. However, given that a problem solution does not change with time, time can serve as one of the variables.
Other computing elements include analog multipliers, nonlinear function generators, and analog comparators.
Electrical elements such as inductors and capacitors used in electrical analog computers had to be carefully manufactured to reduce non-ideal effects. For example, in the construction of AC power network analyzers, one motive for using higher frequencies for the calculator (instead of the actual power frequency) was that higher-quality inductors could be more easily made. Many general-purpose analog computers avoided the use of inductors entirely, re-casting the problem in a form that could be solved using only resistive and capacitive elements, since high-quality capacitors are relatively easy to make.
The use of electrical properties in analog computers means that calculations are normally performed in real time (or faster), at a speed determined mostly by the frequency response of the operational amplifiers and other computing elements. In the history of electronic analog computers, there were some special high-speed types.
Nonlinear functions and calculations can be constructed to a limited precision (three or four digits) by designing function generators — special circuits of various combinations of resistors and diodes to provide the nonlinearity. Typically, as the input voltage increases, progressively more diodes conduct.
When compensated for temperature, the forward voltage drop of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps scale the output voltage so that it is usable with the rest of the computer.
Any physical process which models some computation can be interpreted as an analog computer. Some examples, invented for the purpose of illustrating the concept of analog computation, include using a bundle of spaghetti as a model of sorting numbers; a board, a set of nails, and a rubber band as a model of finding the convex hull of a set of points; and strings tied together as a model of finding the shortest path in a network. These are all described in Dewdney (1984).
Components.
Analog computers often have a complicated framework, but they have, at their core, a set of key components which perform the calculations, which the operator manipulates through the computer's framework.
Key hydraulic components might include pipes, valves and containers.
Key mechanical components might include rotating shafts for carrying data within the computer, miter gear differentials, disc/ball/roller integrators, cams (2-D and 3-D), mechanical resolvers and multipliers, and torque servos.
Key electrical/electronic components might include:
The core mathematical operations used in an electric analog computer are:
In some analog computer designs, multiplication is much preferred to division. Division is carried out with a multiplier in the feedback path of an Operational Amplifier.
Differentiation with respect to time is not frequently used, and in practice is avoided by redefining the problem when possible. It corresponds in the frequency domain to a high-pass filter, which means that high-frequency noise is amplified; differentiation also risks instability.
Limitations.
In general, analog computers are limited by non-ideal effects. An analog signal is composed of four basic components: DC and AC magnitudes, frequency, and phase. The real limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. For commercially available electronic components, ranges of these aspects of input and output signals are always figures of merit.
Decline.
In 1950s to 1970s, digital computers based on first vacuum tubes, transistors, integrated circuits and then micro-processors became more economical and precise. This led digital computers to largely replace analog computers. Even so, some research in analog computation is still being done. A few universities still use analog computers to teach control system theory. The American company Comdyna manufactures small analog computers. At Indiana University Bloomington, Jonathan Mills has developed the Extended Analog Computer based on sampling voltages in a foam sheet. At the Harvard Robotics Laboratory, analog computation is a research topic. [ Lyric Semiconductor]'s error correction circuits use analog probabilistic signals. Slide rules are still popular among aircraft personnel. 
Resurgence in VLSI technology.
With the development of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250 nm) by Glenn Cowan in 2005 and an 4th-order hybrid computer (65 nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDEs applications. Glenn's chip contains 16 macros, in which there are 25 analog computing blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1~2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing.
Practical examples.
These are examples of analog computers that have been constructed or practically used:
Analog (audio) synthesizers can also be viewed as a form of analog computer, and their technology was originally based in part on electronic analog computer technology. The ARP 2600's Ring Modulator was actually a moderate-accuracy analog multiplier.
The Simulation Council (or Simulations Council) was an association of analog computer users in USA. It is now known as The Society for Modeling and Simulation International. The Simulation Council newsletters from 1952 to 1963 are available online and show the concerns and technologies at the time, and the common use of analog computers for missilry.
Real computers.
Computer theorists often refer to idealized analog computers as real computers (because they operate on the set of real numbers). Digital computers, by contrast, must first quantize the signal into a finite number of values, and so can only work with the rational number set (or, with an approximation of irrational numbers).
These idealized analog computers may "in theory" solve problems that are intractable on digital computers; however as mentioned, in reality, analog computers are far from attaining this ideal, largely because of noise minimization problems. "In theory", ambient noise is limited by quantum noise (caused by the quantum movements of ions). Ambient noise may be severely reduced – but never to zero – by using cryogenically cooled parametric amplifiers. Moreover, given unlimited time and memory, the (ideal) digital computer may also solve real number problems.

</doc>
<doc id="2429" url="https://en.wikipedia.org/wiki?curid=2429" title="Audio">
Audio

Audio may refer to:

</doc>
<doc id="2431" url="https://en.wikipedia.org/wiki?curid=2431" title="Minute and second of arc">
Minute and second of arc

A minute of arc (MOA), arcminute (arcmin) or minute arc is a unit of angular measurement equal to one-sixtieth () of one degree. As one degree is of a circle, one minute of arc is of a circle (or, in radians, ). It is used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying and marksmanship.
The number of square arcminutes in a complete sphere is formula_1 approximately 148,510,660 square arcminutes.
A second of arc (arcsecond, arcsec) is of an arcminute, of a degree, of a circle, and (about ) of a radian. This is approximately the angle subtended by a U.S. dime coin (18mm) at a distance of . An arcsecond is also the angle subtended by
To express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas), for instance, is commonly used in astronomy.
Symbols and abbreviations.
The standard symbol for marking the arcminute is the prime (′) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1′. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (formula_2).
The standard symbol for the arcsecond is the double prime (″) (U+2033), though a double quote (") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1″. It is also abbreviated as arcsec or asec.
In celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, written for example as 42° 25.32′ or 42° 25.322′. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.
Uses.
Firearms.
The arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the Imperial measurement system because 1 MOA subtends 1.047 inches at 100 yards, a traditional distance on target ranges. This calculation applies to distances beyond 100 yards, for example, 500 yards = 5.235 inches, and 1000 yards = 10.47 inches. Since lots of modern telescopic sights are adjustable in half (), quarter (), or eighth () MOA increments, also known as "clicks", this makes zeroing and adjustments much easier. For example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards, the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that "click" in fractions of MOA. 
One thing to be aware of is that some scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA corresponds to exactly 1 inch, rather than 1.047". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.
The physical group size equivalent to "m" minutes of arc can be calculated as follows: group size = tan() × distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan() ≈ 1.047 inches. In metric units 1 MOA at 100 meters ≈ 2.908 centimeters.
Sometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a "1 MOA rifle" should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.
Rifle manufacturers and gun magazines often refer to this capability as "sub-MOA", meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.
The Metric System counterpart of the MOA is the angular mil or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 × × 1000, regardless the target range. Therefore, 1 MOA = 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 Milrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system. The markings on a reticle that mark mils are called mil-dots. Such reticle is called a "mil-dot reticle".
Cartography.
Minutes of arc (and its subunit, seconds of arc or SOA—equal to a sixtieth of a MOA) are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals approximately one Nautical mile (). A second of arc, one sixtieth of this amount, is about 30 meters or roughly 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate.
Positions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, because of the somewhat clumsy base-60 nature of minutes and seconds, positions are frequently expressed in fractional degrees only, expressed in decimal form to an equal amount of precision. Degrees given to three decimal places ( of a degree) have about the precision of degrees-minutes-seconds ( of a degree) and specify locations within about 120 meters or 400 feet.
Property cadastral surveying.
Related to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary "mete" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, "North 65° 39′ 18″ West 85.69 feet" would describe a line running from the starting point 85.69 feet in a direction 65° 39′ 18″ (or 65.655°) away from north toward the west.
Astronomy.
The arcminute and arcsecond are also used in astronomy. Degrees (and therefore arcminutes) are used to measure declination, or angular distance north or south of the celestial equator. The arcsecond is also often used to describe parallax, due to very small parallax angles for stellar parallax, and tiny angular diameters (e.g. Venus varies between 10″ and 60″). The parallax, proper motion and angular diameter of a star may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The parsec gets its name from "parallax second", for those arcseconds.
The ESA astrometric space probe Gaia is hoped to measure star positions to 20 microarcseconds (µas) when it begins producing catalog positions sometime after 2016. There are about 1.3 trillion µas in a circle. As seen from Earth, one µas is about the size of a period at the end of a sentence in the Apollo mission manuals left on the moon. Currently the best catalog positions of stars actually measured are in terms of milliarcseconds, by the U.S. Naval Observatory. A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.
Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond. This is roughly equivalent to a (40 mm) ping-pong ball viewed at a distance of 50 miles (80 km).
Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble space telescope can reach an angular size of stars down to about 0.1″. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.
Human vision.
In humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.
A 20/20 letter subtends 5 minutes of arc total.
Materials.
The deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.
External links.
MOA / mils By Robert Simeone

</doc>
<doc id="2433" url="https://en.wikipedia.org/wiki?curid=2433" title="Alberto Giacometti">
Alberto Giacometti

Alberto Giacometti (; 10 October 1901 – 11 January 1966) was a Swiss sculptor, painter, draughtsman and printmaker.
He was born in the canton Graubünden's southerly alpine valley Val Bregaglia, as the eldest of four children to Giovanni Giacometti, a well-known post-Impressionist painter. Coming from an artistic background, he was interested in art from an early age.
Early life.
Giacometti was born in Borgonovo, now part of the Swiss municipality of Bregaglia, near the Italian border. He was a descendant of Protestant refugees escaping the inquisition. Alberto attended the Geneva School of Fine Arts. His brothers Diego (1902–85) and Bruno (1907–2012) would go on to become artists as well. Additionally, Zaccaria Giacometti, later professor of constitutional law and chancellor of the University of Zurich grew up together with them, having been orphaned at the age of 12 in 1905.
In 1922 he moved to Paris to study under the sculptor Antoine Bourdelle, an associate of Rodin. It was there that Giacometti experimented with cubism and surrealism and came to be regarded as one of the leading surrealist sculptors. Among his associates were Miró, Max Ernst, Picasso, Bror Hjorth and Balthus.
Between 1936 and 1940, Giacometti concentrated his sculpting on the human head, focusing on the sitter's gaze. He preferred models he was close to, his sister and the artist Isabel Rawsthorne (then known as Isabel Delmer). This was followed by a phase in which his statues of Isabel became stretched out; her limbs elongated. Obsessed with creating his sculptures exactly as he envisioned through his unique view of reality, he often carved until they were as thin as nails and reduced to the size of a pack of cigarettes, much to his consternation. A friend of his once said that if Giacometti decided to sculpt you, "he would make your head look like the blade of a knife". After his marriage to Annette Arm in 1946 his tiny sculptures became larger, but the larger they grew, the thinner they became. Giacometti said that the final result represented the sensation he felt when he looked at a woman.
His paintings underwent a parallel procedure. The figures appear isolated and severely attenuated, as the result of continuous reworking. Subjects were frequently revisited: one of his favorite models was his younger brother Diego Giacometti. A third brother, Bruno Giacometti, was a noted architect.
Later years.
In 1958 Giacometti was asked to create a monumental sculpture for the Chase Manhattan Bank building in New York, which was beginning construction. Although he had for many years "harbored an ambition to create work for a public square", he "had never set foot in New York, and knew nothing about life in a rapidly evolving metropolis. Nor had he ever laid eyes on an actual skyscraper", according to his biographer James Lord. Giacometti's work on the project resulted in the four figures of standing women—his largest sculptures—entitled "Grande femme debout" I through IV (1960). The commission was never completed, however, because Giacometti was unsatisfied by the relationship between the sculpture and the site, and abandoned the project.
In 1962, Giacometti was awarded the grand prize for sculpture at the Venice Biennale, and the award brought with it worldwide fame. Even when he had achieved popularity and his work was in demand, he still reworked models, often destroying them or setting them aside to be returned to years later. The prints produced by Giacometti are often overlooked but the catalogue raisonné, "Giacometti – The Complete Graphics and 15 Drawings by Herbert Lust" (Tudor 1970), comments on their impact and gives details of the number of copies of each print. Some of his most important images were in editions of only 30 and many were described as rare in 1970.
In his later years Giacometti's works were shown in a number of large exhibitions throughout Europe. Riding a wave of international popularity, and despite his declining health, he travelled to the United States in 1965 for an exhibition of his works at the Museum of Modern Art in New York. As his last work he prepared the text for the book "Paris sans fin", a sequence of 150 lithographs containing memories of all the places where he had lived.
Death.
Giacometti died in 1966 of heart disease (pericarditis) and chronic bronchitis at the Kantonsspital in Chur, Switzerland. His body was returned to his birthplace in Borgonovo, where he was interred close to his parents. In May 2007 the executor of his widow's estate, former French foreign minister Roland Dumas, was convicted of illegally selling Giacometti's works to a top auctioneer, Jacques Tajan, who was also convicted. Both were ordered to pay €850,000 to the Alberto and Annette Giacometti Foundation.
Artistic analysis.
Regarding Giacometti's sculptural technique and according to the Metropolitan Museum of Art: "The rough, eroded, heavily worked surfaces of Three Men Walking (II), 1949, typify his technique. Reduced, as they are, to their very core, these figures evoke lone trees in winter that have lost their foliage. Within this style, Giacometti would rarely deviate from the three themes that preoccupied him—the walking man; the standing, nude woman; and the bust—or all three, combined in various groupings".""
In a letter to Pierre Matisse, Giacometti wrote: "Figures were never a compact mass but like a transparent construction". In the letter, Giacometti writes about how he looked back at the realist, classical busts of his youth with nostalgia, and tells the story of the existential crisis which precipitated the style he became known for.
"rediscovered the wish to make compositions with figures. For this I had to make (quickly I thought; in passing), one or two studies from nature, just enough to understand the construction of a head, of a whole figure, and in 1935 I took a model. This study should take, I thought, two weeks and then I could realize my compositions...I worked with the model all day from 1935 to 1940...Nothing was as I imagined. A head, became for me an object completely unknown and without dimensions."
Since Giacometti achieved exquisite realism with facility when he was executing busts in his early adolescence, Giacometti's difficulty in re-approaching the figure as an adult is generally understood as a sign of existential struggle for meaning, rather than as a technical deficit.
Giacometti was a key player in the Surrealist art movement, but his work resists easy categorization. Some describe it as formalist, others argue it is expressionist or otherwise having to do with what Deleuze calls "blocs of sensation" (as in Deleuze's analysis of Francis Bacon). Even after his excommunication from the Surrealist group, while the intention of his sculpting was usually imitation, the end products were an expression of his emotional response to the subject. He attempted to create renditions of his models the way he saw them, and the way he thought they ought to be seen. He once said that he was sculpting not the human figure but "the shadow that is cast".
Scholar William Barrett in "Irrational Man: A Study in Existential Philosophy" (1962), argues that the attenuated forms of Giacometti's figures reflect the view of 20th century modernism and existentialism that modern life is increasingly empty and devoid of meaning. "All the sculptures of today, like those of the past, will end one day in pieces...So it is important to fashion ones work carefully in its smallest recess and charge every particle of matter with life."
A new exhibition in Paris, since September 2011, shows how Giacometti strongly drew his inspiration for his work from Etruscan art.
Legacy.
Exhibitions.
Giacometti's work has been the subject of numerous solo exhibitions including most recently Pera Museum, Istanbul (2015) Pushkin Museum, Moscow (2008); “The Studio of Alberto Giacometti: Collection of the Fondation Alberto et Annette Giacometti”, Centre Pompidou, Paris (2007–2008); Kunsthal Rotterdam (2008); Fondation Beyeler, Basel (2009), Buenos Aires (2012); and Kunsthalle Hamburg (2013).
The National Portrait Gallery, London's first solo exhibition of Giacometti's work, "Pure Presence" opened to five star reviews on 13 October 2015 (to January 10, 2016, in honour of the fiftieth anniversary of the artist's death).
Public collections.
Giacometti's work is displayed in numerous public collections, including:
Art Foundations.
The Fondation Alberto et Annette Giacometti, having received a bequest from Alberto Giacometti's widow Annette, holds a collection of circa 5,000 works, frequently displayed around the world through exhibitions and long-term loans. A public interest institution, the Foundation was created in 2003 and aims at promoting, disseminating, preserving and protecting Alberto Giacometti's work.
The Alberto Giacometti-Stiftung established in Zürich in 1965, holds a smaller collection of works acquired from the collection of the Pittsburgh industrialist G. David Thompson.
Notable sales.
In November 2000 a Giacometti bronze, "Grande Femme Debout I", sold for $14.3 million. "Grande Femme Debout II" was bought by the Gagosian Gallery for $27.4 million at Christie's auction in New York City on May 6, 2008.
"L'Homme qui marche I", a life-sized bronze sculpture of a man, became one of the most expensive works of art and the most expensive sculpture ever sold at auction on February 2, 2010, when it sold for £65 million (US$104.3 million) at Sotheby's, London. "Grande tête mince", a large bronze bust, sold for $53.3 million just three months later.
"L'Homme au doigt" ("Pointing Man") sold for $126 million (£81314455.32), or $141.3 million with fees, in Christie's May 11, 2015 Looking Forward to the Past sale in New York, a record for a sculpture at auction. The work had been in the same private collection for 45 years.
Other legacy.
Giacometti created the monument on the grave of Gerda Taro at Père Lachaise Cemetery.
In 2001 he was included in the exhibition held at the National Portrait Gallery, London.
Giacometti and his sculpture "L'Homme qui marche I" appear on the current 100 Swiss Franc banknote.
According to a lecture by Michael Peppiatt at Cambridge University on July 8, 2010, Giacometti, who had a friendship with author/playwright Samuel Beckett, created a tree for the set of a 1961 Paris production of "Waiting For Godot".

</doc>
<doc id="2439" url="https://en.wikipedia.org/wiki?curid=2439" title="Anthem">
Anthem

An anthem is a musical composition of celebration, usually used as a symbol for a distinct group, particularly the national anthems of countries. Originally, and in music theory and religious contexts, it also refers more particularly to short sacred choral work and still more particularly to a specific form of Anglican church music
Etymology.
"Anthem" is derived from the Greek ("antíphōna") via Old English . Both words originally referred to antiphons, a call-and-response style of singing. The adjectival form is "anthemic".
History.
Anthems were originally a form of liturgical music. In the Church of England, the rubric appoints them to follow the third collect at morning and evening prayer. Several anthems are included in the British coronation service. The words are selected from Holy Scripture or in some cases from the Liturgy and the music is generally more elaborate and varied than that of psalm or hymn tunes. Being written for a trained choir rather than the congregation, the Anglican anthem is analogous to the motet of the Roman Catholic and Lutheran Churches but represents an essentially English musical form. Anthems may be described as "verse", "full", or "full with verse", depending on whether they are intended for soloists, the full choir, or both.
The anthem developed as a replacement for the Catholic "votive antiphon" commonly sung as an appendix to the main office to the Blessed Virgin Mary or other saints. During the Elizabethan period, notable anthems were composed by Thomas Tallis, William Byrd, Tye, and Farrant but they were not mentioned in the Book of Common Prayer until 1662 when the famous rubric "In quires and places where they sing here followeth the Anthem" first appears. Early anthems tended to be simple and homophonic in texture, so that the words could be clearly heard. During the 17th century, notable anthems were composed by Orlando Gibbons, Henry Purcell, and John Blow, with the verse anthem becoming the dominant musical form of the Restoration. In the 18th century, famed anthems were composed by Croft, Boyce, James Kent, James Nares, Benjamin Cooke, and Samuel Arnold. In the 19th, Samuel Sebastian Wesley wrote anthems influenced by contemporary oratorio which stretch to several movements and last twenty minutes or longer. Later in the century, Charles Villiers Stanford used symphonic techniques to produce a more concise and unified structure. Many anthems have been composed since this time, generally by organists rather than professional composers and often in a conservative style. Major composers have usually composed anthems in response to commissions and for special occasions. Examples include Edward Elgar's 1912 "Great is the Lord" and 1914 "Give unto the Lord" (both with orchestral accompaniment), Benjamin Britten's 1943 "Rejoice in the Lamb" (a modern example of a multi-movement anthem, today heard mainly as a concert piece), and, on a much smaller scale, Ralph Vaughan Williams's 1952 "O Taste and See" written for the coronation of Queen Elizabeth II. With the relaxation of the rule, in England at least, that anthems should be only in English, the repertoire has been greatly enhanced by the addition of many works from the Latin repertoire.
The word "anthem" is now commonly used to describe any celebratory song or composition for a distinct group, as in national anthems. Many pop songs are used as sports anthems, notably including Queen's "We Are the Champions" and "We Will Rock You", and some sporting events have their own anthems, most notably including UEFA Champions League. Further, some songs are artistically styled as anthems, whether or not they are used as such, including Marilyn Manson's "Irresponsible Hate Anthem", Silverchair's "Anthem for the Year 2000", and Toto's "Child's Anthem".

</doc>
<doc id="2440" url="https://en.wikipedia.org/wiki?curid=2440" title="Albrecht Altdorfer">
Albrecht Altdorfer

Albrecht Altdorfer (c. 1480 – February 12, 1538) was a German painter, engraver and architect of the Renaissance working in Regensburg. Along with Lucas Cranach the Elder and Wolf Huber he is regarded to be the main representative of the so-called Danube School setting biblical and historical subjects against landscape backgrounds of expressive colours. As an artist also making small intricate engravings he is seen to belong to the Nuremberg Little Masters.
Biography.
Altdorfer was born in Regensburg or Altdorf around 1480.
He acquired an interest in art from his father, Ulrich Altdorfer, who was a painter and miniaturist. At the start of his career, he won public attention by creating small, intimate modestly scaled works in unconventional media and with eccentric subject matter. He settled in the free imperial city of Regensburg, a town located on the Danube River in 1505, eventually becoming the town architect and a town councillor. His first signed works date to c. 1506, including engravings and drawings such the "Stygmata of St. Francis" and "St. Jerome". His models were niellos and copper engravings from the workshops of Jacopo de Barbari and Albrecht Dürer.
Around 1511 or earlier, he travelled down the river and south into the Alps, where the scenery moved him so deeply that he became the first landscape painter in the modern sense, making him the leader of the Danube School, a circle that pioneered landscape as an independent genre, in southern Germany. From 1513 he was at the service of Maximilian I in Innsbruck, where he received several commissions from the imperial court. During the turmoil of the Protestant Reformation, he dedicated mostly to architecture; paintings of the period, showing his increasing attention to architecture, include the "Nativity of the Virgin".
In 1529 he executed "The Battle of Alexander at Issus" for Duke William IV of Bavaria. In the 1520s he returned to Regensburg as a wealthy man, and became a member of the city's council. He was also responsible for the fortifications of Regensburg.
In that period his works are influenced by artists such as Giorgione and Lucas Cranach, as shown by his "Crucifixion". In 1535 he was in Vienna. He died at Regensburg in 1538.
The remains of Altdorfer's surviving work comprises 55 panels, 120 drawings, 125 woodcuts, 78 engravings, 36 etchings, 24 paintings on parchment, and fragments from a mural for the bathhouse of the Kaiserhof in Regensburg. This production extends at least over the period 1504–1537. He signed and dated each one of his works.
Painting.
Altdorfer was the pioneer painter of pure landscape, making them the subject of the painting, as well as compositions dominated by their landscape. He believed that the human figure shouldn't disrupt nature, but rather participate in it or imitate its natural processes. Taking and developing the landscape style of Lucas Cranach the Elder, he shows the hilly landscape of the Danube valley with thick forests of drooping and crumbling firs and larches hung with moss, and often dramatic colouring from a rising or setting sun. His "Landscape with Footbridge" (National Gallery, London) of 1518–1520 is claimed to be the first pure landscape in oil. In this painting, Altdorfer places a large tree that is cut off by the margins at the center of the landscape, making it the central axis and focus within the piece. He uses anthropomorphism to give the tree human qualities such as the drapery of its limbs. He also made many fine finished drawings, mostly landscapes, in pen and watercolour such as the "Landscape with the Woodcutter" in 1522. The drawing opens at ground level on a clearing surrounding an enormous tree that is placed in the center, dominating the picture. It poses and gesticulates as if it was human, splaying its branches out in every corner. Halfway up the tree trunk, hangs a gabled shrine. At the time, a shrine like this might shelter an image of the Crucifixion or the Virgin Mary, but since it is turned away from the viewer, we are not sure what it truly is. At the bottom of the tree, a tiny figure of a seated man, crossed legged, holds a knife and axe, declaring his status in society/occupation.
Also, he often painted scenes of historical and biblical subjects, set in atmospheric landscapes. His best religious scenes are intense, with their glistening lights and glowing colours sometimes verging on the expressionistic. They often depict moments of intimacy between Christ and his mother, or various saints. His sacral masterpiece and one of the most famous religious works of art of the later Middle Ages is "The Legend of St. Sebastian" and "The Passion of Christ" of the so-called "Sebastian Altar" in "St. Florian's Priory" ("Stift Sankt Florian") near Linz, Upper Austria. When closed the altarpiece displayed the four panels of the legend of St. Sebastian’s Martyrdom, while the opened wings displayed the Stations of the Cross. Today the altarpiece is dismantled and the predellas depicting the two final scenes, "Entombment" and "Resurrection" were sold to Kunsthistorisches Museum in Vienna in 1923 and 1930. Both these paintings share a similar formal structure that consists of an open landscape that is seen beyond and through the opening of a dark grotto. The date of completion on the resurrection panel is 1518.
Altdorfer often distorts perspective to subtle effect. His donor figures are often painted completely out of scale with the main scene, as in paintings of the previous centuries. He also painted some portraits; overall his painted oeuvre was not large. In his later works, Altdorfer moved more towards mannerism and began to depict the human form to the conformity of the Italian model, as well as dominate the picture with frank colors.
Paintings in Munich.
His rather atypical "Battle of Issus" (or of "Alexander") of 1529 was commissioned by William IV, Duke of Bavaria as part of a series of eight historical battle scenes destined to hang in the Residenz in Munich. Albrecht Altdorfer's depiction of the moment in 333 BCE when Alexander the Great routed Darius III for supremacy in Asia Minor is vast in ambition, sweeping in scope, vivid in imagery, rich in symbols, and obviously heroic—the Iliad of painting, as literary critic Friedrich Schlegel suggested In the painting, a swarming cast of thousands of soldiers surround the central action: Alexander on his white steed, leading two rows of charging cavalrymen, dashes after a fleeing Darius, who looks anxiously over his shoulder from a chariot. The opposing armies are distinguished by the colors of their uniforms: Darius' army in red and Alexander's in blue. The upper half of "The Battle of Alexander" expands with unreal rapidity into an arcing panorama comprehending vast coiling tracts of globe and sky. The victory also lies on the planar surface; The sun outshone the moon just as the Imperial and allied army successfully repel the Turks.
By making the mass number of soldiers blend within the landscape/painting, it shows that he believed that the usage and depiction of landscape was just as significant as a historical event, such as a war. He renounced the office of "Mayor of Regensburg" to accept the commission. Few of his other paintings resemble this apocalyptic scene of two huge armies dominated by an extravagant landscape seen from a very high viewpoint, which looks south over the whole Mediterranean from modern Turkey to include the island of Cyprus and the mouths of the Nile and the Red Sea (behind the isthmus to the left) on the other side. However his style here is a development of that of a number of miniatures of battle-scenes he had done much earlier for Maximilian I in his illuminated manuscript "Triumphal Procession" in 1512-14. It is thought to be the earliest painting to show the curvature of the Earth from a great height.
The "Battle" is now in the Alte Pinakothek, which has the best collection of Altdorfer's paintings, including also his small "St. George and the Dragon" (1510), in oil on parchment, where the two figures are tiny and almost submerged in the lush, dense forest that towers over them. Altdorfer seems to exaggerate the measurements of the forest in comparison to the figures: the leaves appear to be larger than the horse, showing the significance of nature and landscape. He also emphasizes line within the work, by displaying the upward growth of the forest with the vertical and diagonal lines of the trunks. There is a small opening of the forest on the lower right hand corner that provides a rest for your eyes. It serves to create depth within the painting and is the only place you can see the characters. The human form is completely absorbed by the thickness of the forest. Fantastic light effects provide a sense of mystery and dissolve the outline of objects. Without the contrast of light, the figures would blend in with its surrounding environment. Altdorfer's figures are invariably the complement of his romantic landscapes; for them he borrowed Albrecht Dürer's inventive iconography, but the panoramic setting is personal and has nothing to do with the fantasy landscapes of the Netherlands A "Susanna in the Bath and the Stoning of the Elders" (1526) set outside an Italianate skyscraper of a palace shows his interest in architecture. Another small oil on parchment, "Danube Landscape with Castle Wörth" (c. 1520) is one of the earliest accurate topographical paintings of a particular building in its setting, of a type that was to become a cliché in later centuries.
Printmaking.
Altdorfer was a significant printmaker, with numerous engravings and about ninety-three woodcuts. These included some for the "Triumphs of Maximilian", where he followed the overall style presumably set by Hans Burgkmair, although he was able to escape somewhat from this in his depictions of the more disorderly baggage-train, still coming through a mountain landscape. However most of his best prints are etchings, many of landscapes; in these he was able most easily to use his drawing style. He was one of the most successful early etchers, and was unusual for his generation of German printmakers in doing no book illustrations. He often combined etching and engraving techniques in a single plate, and produced about 122 intaglio prints altogether. Many of Altdorfer's prints are quite small in size, and he is considered to be of the main members of the group of artists known as the Little Masters. Arthur Mayger Hind considers his graphical work to be somewhat lacking in technical skill but with an "intimate personal touch", and notes his characteristic feeling for landscape.
Public life.
As the superintendent of the municipal buildings Altdorfer had overseen the construction of several commercial structures, such as a slaughterhouse and a building for wine storage, possibly even designing them. He was considered to be an outstanding politician of his day. In 1517 he was a member of the "Ausseren Rates", the council on external affairs, and in this capacity was involved in the expulsion of the Jews, the destruction of the synagogue and in its place the construction of a church and shrine to the Schöne Maria that occurred in 1519. Altdorfer made etchings of the interior of the synagogue and designed a woodcut of the cult image of the Schöne Maria. In 1529–1530 he was also charged with reinforcing certain city fortifications in response to the Turkish threat.
Albrecht's brother, Erhard Altdorfer, was also a painter and printmaker in woodcut and engraving, and a pupil of Lucas Cranach the Elder.

</doc>
