<doc id="5300" url="https://en.wikipedia.org/wiki?curid=5300" title="Computer data storage">
Computer data storage

Computer data storage, often called storage or memory, is a technology consisting of computer components and recording media used to retain digital data. It is a core function and fundamental component of computers.
The central processing unit (CPU) of a computer is what manipulates data by performing computations. In practice, almost all computers use a storage hierarchy, which puts fast but expensive and small storage options close to the CPU and slower but larger and cheaper options farther away. Often the fast volatile technologies (which lose data when powered off) are referred to as "memory", while slower persistent technologies are referred to as "storage"; however, "memory" is sometimes also used when referring to persistent storage.
In the Von Neumann architecture, the CPU consists of two main parts: control unit and arithmetic logic unit (ALU). The former controls the flow of data between the CPU and memory, while the latter performs arithmetic and logical operations on data.
Functionality.
Without a significant amount of memory, a computer would merely be able to perform fixed operations and immediately output the result. It would have to be reconfigured to change its behavior. This is acceptable for devices such as desk calculators, digital signal processors, and other specialized devices. Von Neumann machines differ in having a memory in which they store their operating instructions and data. Such computers are more versatile in that they do not need to have their hardware reconfigured for each new program, but can simply be reprogrammed with new in-memory instructions; they also tend to be simpler to design, in that a relatively simple processor may keep state between successive computations to build up complex procedural results. Most modern computers are von Neumann machines.
Data organization and representation.
A modern digital computer represents data using the binary numeral system. Text, numbers, pictures, audio, and nearly any other form of information can be converted into a string of bits, or binary digits, each of which has a value of 1 or 0. The most common unit of storage is the byte, equal to 8 bits. A piece of information can be handled by any computer or device whose storage space is large enough to accommodate "the binary representation of the piece of information", or simply data. For example, the complete works of Shakespeare, about 1250 pages in print, can be stored in about five megabytes (40 million bits) with one byte per character.
Data is encoded by assigning a bit pattern to each character, digit, or multimedia object. Many standards exist for encoding (e.g., character encodings like ASCII, image encodings like JPEG, video encodings like MPEG-4).
By adding bits to each encoded unit, redundancy allows the computer to both detect errors in coded data and correct them based on mathematical algorithms. Errors generally occur in low probabilities due to random bit value flipping, or "physical bit fatigue", loss of the physical bit in storage its ability to maintain distinguishable value (0 or 1), or due to errors in inter or intra-computer communication. A random bit flip (e.g., due to random radiation) is typically corrected upon detection. A bit, or a group of malfunctioning physical bits (not always the specific defective bit is known; group definition depends on specific storage device) is typically automatically fenced-out, taken out of use by the device, and replaced with another functioning equivalent group in the device, where the corrected bit values are restored (if possible). The cyclic redundancy check (CRC) method is typically used in communications and storage for error detection. A detected error is then retried.
Data compression methods allow in many cases (such as a database) to represent a string of bits by a shorter bit string ("compress") and reconstruct the original string ("decompress") when needed. This utilizes substantially less storage (tens of percents) for many types of data at the cost of more computation (compress and decompress when needed). Analysis of trade-off between storage cost saving and costs of related computations and possible delays in data availability is done before deciding whether to keep certain data compressed or not.
For security reasons certain types of data (e.g., credit-card information) may be kept encrypted in storage to prevent the possibility of unauthorized information reconstruction from chunks of storage snapshots.
Hierarchy of storage.
Generally, the lower a storage is in the hierarchy, the lesser its bandwidth and the greater its access latency is from the CPU. This traditional division of storage to primary, secondary, tertiary and off-line storage is also guided by cost per bit.
In contemporary usage, "memory" is usually semiconductor storage read-write random-access memory, typically DRAM (dynamic RAM) or other forms of fast but temporary storage. "Storage" consists of storage devices and their media not directly accessible by the CPU (secondary or tertiary storage), typically hard disk drives, optical disc drives, and other devices slower than RAM but non-volatile (retaining contents when powered down).
Historically, "memory" has been called "core memory", "main memory", "real storage" or "internal memory". Meanwhile, non-volatile storage devices have been referred to as "secondary storage", "external memory" or "auxiliary/peripheral storage".
Primary storage.
"Primary storage" (also known as "main memory" or "internal memory"), often referred to simply as "memory", is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in uniform manner.
Historically, early computers used delay lines, Williams tubes, or rotating magnetic drums as primary storage. By 1954, those unreliable methods were mostly replaced by magnetic core memory. Core memory remained dominant until the 1970s, when advances in integrated circuit technology allowed semiconductor memory to become economically competitive.
This led to modern random-access memory (RAM). It is small-sized, light, but quite expensive at the same time. (The particular types of RAM used for primary storage are also volatile, i.e. they lose the information when not powered).
As shown in the diagram, traditionally there are two more sub-layers of the primary storage, besides main large-capacity RAM:
Main memory is directly or indirectly connected to the central processing unit via a "memory bus". It is actually two buses (not on the diagram): an address bus and a data bus. The CPU firstly sends a number through an address bus, a number called memory address, that indicates the desired location of data. Then it reads or writes the data in the memory cells using the data bus. Additionally, a memory management unit (MMU) is a small device between CPU and RAM recalculating the actual memory address, for example to provide an abstraction of virtual memory or other tasks.
As the RAM types used for primary storage are volatile (uninitialized at start up), a computer containing only such storage would not have a source to read instructions from, in order to start the computer. Hence, non-volatile primary storage containing a small startup program (BIOS) is used to bootstrap the computer, that is, to read a larger program from non-volatile "secondary" storage to RAM and start to execute it. A non-volatile technology used for this purpose is called ROM, for read-only memory (the terminology may be somewhat confusing as most ROM types are also capable of "random access").
Many types of "ROM" are not literally "read only", as updates to them are possible; however it is slow and memory must be erased in large portions before it can be re-written. Some embedded systems run programs directly from ROM (or similar), because such programs are rarely changed. Standard computers do not store non-rudimentary programs in ROM, and rather, use large capacities of secondary storage, which is non-volatile as well, and not as costly.
Recently, "primary storage" and "secondary storage" in some uses refer to what was historically called, respectively, "secondary storage" and "tertiary storage".
Secondary storage.
"Secondary storage" (also known as external memory or auxiliary storage), differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its input/output channels to access secondary storage and transfers the desired data using intermediate area in primary storage. Secondary storage does not lose the data when the device is powered down—it is non-volatile. Per unit, it is typically also two orders of magnitude less expensive than primary storage. Modern computer systems typically have two orders of magnitude more secondary storage than primary storage and data are kept for a longer time there.
In modern computers, hard disk drives are usually used as secondary storage. The time taken to access a given byte of information stored on a hard disk is typically a few thousandths of a second, or milliseconds. By contrast, the time taken to access a given byte of information stored in random-access memory is measured in billionths of a second, or nanoseconds. This illustrates the significant access-time difference which distinguishes solid-state memory from rotating magnetic storage devices: hard disks are typically about a million times slower than memory. Rotating optical storage devices, such as CD and DVD drives, have even longer access times. With disk drives, once the disk read/write head reaches the proper placement and the data of interest rotates under it, subsequent data on the track are very fast to access. To reduce the seek time and rotational latency, data are transferred to and from disks in large contiguous blocks.
When data reside on disk, blocking access to hide latency offers an opportunity to design efficient external memory algorithms. Sequential or block access on disks is orders of magnitude faster than random access, and many sophisticated paradigms have been developed to design efficient algorithms based upon sequential and block access. Another way to reduce the I/O bottleneck is to use multiple disks in parallel in order to increase the bandwidth between primary and secondary memory.
Some other examples of secondary storage technologies are flash memory (e.g. USB flash drives or keys), floppy disks, magnetic tape, paper tape, punched cards, standalone RAM disks, and Iomega Zip drives.
The secondary storage is often formatted according to a file system format, which provides the abstraction necessary to organize data into files and directories, providing also additional information (called metadata) describing the owner of a certain file, the access time, the access permissions, and other information.
Most computer operating systems use the concept of virtual memory, allowing utilization of more primary storage capacity than is physically available in the system. As the primary memory fills up, the system moves the least-used chunks ("pages") to secondary storage devices (to a swap file or page file), retrieving them later when they are needed. As more of these retrievals from slower secondary storage are necessary, the more the overall system performance is degraded.
Tertiary storage.
"Tertiary storage" or "tertiary memory" provides a third level of storage. Typically, it involves a robotic mechanism which will "mount" (insert) and "dismount" removable mass storage media into a storage device according to the system's demands; this data is often copied to secondary storage before use. It is primarily used for archiving rarely accessed information since it is much slower than secondary storage (e.g. 5–60 seconds vs. 1–10 milliseconds). This is primarily useful for extraordinarily large data stores, accessed without human operators. Typical examples include tape libraries and optical jukeboxes.
When a computer needs to read information from the tertiary storage, it will first consult a catalog database to determine which tape or disc contains the information. Next, the computer will instruct a robotic arm to fetch the medium and place it in a drive. When the computer has finished reading the information, the robotic arm will return the medium to its place in the library.
Tertiary storage is also known as "nearline storage" because it is "near to online". The formal distinction between online, nearline, and offline storage is:
For example, always-on spinning hard disk drives are online storage, while spinning drives that spin down automatically, such as in massive arrays of idle disks (MAID), are nearline storage. Removable media such as tape cartridges that can be automatically loaded, as in tape libraries, are nearline storage, while tape cartridges that must be manually loaded are offline storage.
Off-line storage.
"Off-line storage" is a computer data storage on a medium or a device that is not under the control of a processing unit. The medium is recorded, usually in a secondary or tertiary storage device, and then physically removed or disconnected. It must be inserted or connected by a human operator before a computer can access it again. Unlike tertiary storage, it cannot be accessed without human interaction.
Off-line storage is used to transfer information, since the detached medium can be easily physically transported. Additionally, in case a disaster, for example a fire, destroys the original data, a medium in a remote location will probably be unaffected, enabling disaster recovery. Off-line storage increases general information security, since it is physically inaccessible from a computer, and data confidentiality or integrity cannot be affected by computer-based attack techniques. Also, if the information stored for archival purposes is rarely accessed, off-line storage is less expensive than tertiary storage.
In modern personal computers, most secondary and tertiary storage media are also used for off-line storage. Optical discs and flash memory devices are most popular, and to much lesser extent removable hard disk drives. In enterprise uses, magnetic tape is predominant. Older examples are floppy disks, Zip disks, or punched cards.
Characteristics of storage.
Storage technologies at all levels of the storage hierarchy can be differentiated by evaluating certain core characteristics as well as measuring characteristics specific to a particular implementation. These core characteristics are volatility, mutability, accessibility, and addressability. For any particular implementation of any storage technology, the characteristics worth measuring are capacity and performance.
Volatility.
Non-volatile memory retains the stored information even if not constantly supplied with electric power. It is suitable for long-term storage of information. Volatile memory requires constant power to maintain the stored information. The fastest memory technologies are volatile ones, although that is not a universal rule. Since the primary storage is required to be very fast, it predominantly uses volatile memory.
Dynamic random-access memory is a form of volatile memory that also requires the stored information to be periodically reread and rewritten, or refreshed, otherwise it would vanish. Static random-access memory is a form of volatile memory similar to DRAM with the exception that it never needs to be refreshed as long as power is applied; it loses its content when the power supply is lost.
An uninterruptible power supply (UPS) can be used to give a computer a brief window of time to move information from primary volatile storage into non-volatile storage before the batteries are exhausted. Some systems, for example EMC Symmetrix, have integrated batteries that maintain volatile storage for several minutes.
Storage media.
, the most commonly used data storage technologies are semiconductor, magnetic, and optical, while paper still sees some limited usage. "Media" is a common name for what actually holds the data in the storage device. Some other fundamental storage technologies have also been used in the past or are proposed for development.
Semiconductor.
Semiconductor memory uses semiconductor-based integrated circuits to store information. A semiconductor memory chip may contain millions of tiny transistors or capacitors. Both "volatile" and "non-volatile" forms of semiconductor memory exist. In modern computers, primary storage almost exclusively consists of dynamic volatile semiconductor memory or dynamic random-access memory. Since the turn of the century, a type of non-volatile semiconductor memory known as flash memory has steadily gained share as off-line storage for home computers. Non-volatile semiconductor memory is also used for secondary storage in various advanced electronic devices and specialized computers.
As early as 2006, notebook and desktop computer manufacturers started using flash-based solid-state drives (SSDs) as default configuration options for the secondary storage either in addition to or instead of the more traditional HDD.
Magnetic.
Magnetic storage uses different patterns of magnetization on a magnetically coated surface to store information. Magnetic storage is "non-volatile". The information is accessed using one or more read/write heads which may contain one or more recording transducers. A read/write head only covers a part of the surface so that the head or medium or both must be moved relative to another in order to access data. In modern computers, magnetic storage will take these forms:
In early computers, magnetic storage was also used as:
Optical.
Optical storage, the typical optical disc, stores information in deformities on the surface of a circular disc and reads this information by illuminating the surface with a laser diode and observing the reflection. Optical disc storage is "non-volatile". The deformities may be permanent (read only media), formed once (write once media) or reversible (recordable or read/write media). The following forms are currently in common use:
Magneto-optical disc storage is optical disc storage where the magnetic state on a ferromagnetic surface stores information. The information is read optically and written by combining magnetic and optical methods. Magneto-optical disc storage is "non-volatile", "sequential access", slow write, fast read storage used for tertiary and off-line storage.
3D optical data storage has also been proposed.
Paper.
Paper data storage, typically in the form of paper tape or punched cards, has long been used to store information for automatic processing, particularly before general-purpose computers existed. Information was recorded by punching holes into the paper or cardboard medium and was read mechanically (or later optically) to determine whether a particular location on the medium was solid or contained a hole.
A few technologies allow people to make marks on paper that are easily read by machine—these are widely used for tabulating votes and grading standardized tests. Barcodes made it possible for any object that was to be sold or transported to have some computer readable information securely attached to it.
Related technologies.
Redundancy.
While a group of bits malfunction may be resolved by error detection and correction mechanisms (see above), storage device malfunction requires different solutions. The following solutions are commonly used and valid for most storage devices:
Device mirroring and typical RAID are designed to handle a single device failure in the RAID group of devices. However, if a second failure occurs before the RAID group is completely repaired from the first failure, then data can be lost. The probability of a single failure is typically small. Thus the probability of two failures in a same RAID group in time proximity is much smaller (approximately the probability squared, i.e., multiplied by itself). If a database cannot tolerate even such smaller probability of data loss, then the RAID group itself is replicated (mirrored). In many cases such mirroring is done geographically remotely, in a different storage array, to handle also recovery from disasters (see disaster recovery above).
Network connectivity.
A secondary or tertiary storage may connect to a computer utilizing computer networks.
This concept does not pertain to the primary storage, which is shared between multiple processors to a lesser degree.
Robotic storage.
Large quantities of individual magnetic tapes, and optical or magneto-optical discs may be stored in robotic tertiary storage devices. In tape storage field they are known as tape libraries, and in optical storage field optical jukeboxes, or optical disk libraries per analogy. Smallest forms of either technology containing just one drive device are referred to as autoloaders or autochangers.
Robotic-access storage devices may have a number of slots, each holding individual media, and usually one or more picking robots that traverse the slots and load media to built-in drives. The arrangement of the slots and picking devices affects performance. Important characteristics of such storage are possible expansion options: adding slots, modules, drives, robots. Tape libraries may have from 10 to more than 100,000 slots, and provide terabytes or petabytes of near-line information. Optical jukeboxes are somewhat smaller solutions, up to 1,000 slots.
Robotic storage is used for backups, and for high-capacity archives in imaging, medical, and video industries. Hierarchical storage management is a most known archiving strategy of automatically "migrating" long-unused files from fast hard disk storage to libraries or jukeboxes. If the files are needed, they are "retrieved" back to disk.

</doc>
<doc id="5302" url="https://en.wikipedia.org/wiki?curid=5302" title="Conditional">
Conditional

Conditional may refer to:
In grammar and linguistics:

</doc>
<doc id="5304" url="https://en.wikipedia.org/wiki?curid=5304" title="Cone (disambiguation)">
Cone (disambiguation)

A cone is a basic geometrical shape.
Cone may also refer to:

</doc>
<doc id="5306" url="https://en.wikipedia.org/wiki?curid=5306" title="Chemical equilibrium">
Chemical equilibrium

In a chemical reaction, chemical equilibrium is the state in which both reactants and products are present in concentrations which have no further tendency to change with time. Usually, this state results when the forward reaction proceeds at the same rate as the reverse reaction. The reaction rates of the forward and backward reactions are generally not zero, but equal. Thus, there are no net changes in the concentrations of the reactant(s) and product(s). Such a state is known as dynamic equilibrium.
Historical introduction.
The concept of chemical equilibrium was developed after Berthollet (1803) found that some chemical reactions are reversible. For any reaction mixture to exist at equilibrium, the rates of the forward and backward (reverse) reactions are equal. In the following chemical equation with arrows pointing both ways to indicate equilibrium, A and B are reactant chemical species, S and T are product species, and α, β, σ, and τ are the stoichiometric coefficients of the respective reactants and products:
The equilibrium concentration position of a reaction is said to lie "far to the right" if, at equilibrium, nearly all the reactants are consumed. Conversely the equilibrium position is said to be "far to the left" if hardly any product is formed from the reactants.
Guldberg and Waage (1865), building on Berthollet’s ideas, proposed the law of mass action:
where A, B, S and T are active masses and k+ and k− are rate constants. Since at equilibrium forward and backward rates are equal:
and the ratio of the rate constants is also a constant, now known as an equilibrium constant.
By convention the products form the numerator.
However, the law of mass action is valid only for concerted one-step reactions that proceed through a single transition state and is not valid in general because rate equations do not, in general, follow the stoichiometry of the reaction as Guldberg and Waage had proposed (see, for example, nucleophilic aliphatic substitution by SN1 or reaction of hydrogen and bromine to form hydrogen bromide). Equality of forward and backward reaction rates, however, is a necessary condition for chemical equilibrium, though it is not sufficient to explain why equilibrium occurs.
Despite the failure of this derivation, the equilibrium constant for a reaction is indeed a constant, independent of the activities of the various species involved, though it does depend on temperature as observed by the van 't Hoff equation. Adding a catalyst will affect both the forward reaction and the reverse reaction in the same way and will not have an effect on the equilibrium constant. The catalyst will speed up both reactions thereby increasing the speed at which equilibrium is reached.
Although the macroscopic equilibrium concentrations are constant in time, reactions do occur at the molecular level. For example, in the case of acetic acid dissolved in water and forming acetate and hydronium ions,
a proton may hop from one molecule of acetic acid on to a water molecule and then on to an acetate anion to form another molecule of acetic acid and leaving the number of acetic acid molecules unchanged. This is an example of dynamic equilibrium. Equilibria, like the rest of thermodynamics, are statistical phenomena, averages of microscopic behavior.
Le Chatelier's principle (1884) gives an idea of the behavior of an equilibrium system when changes to its reaction conditions occur. "If a dynamic equilibrium is disturbed by changing the conditions, the position of equilibrium moves to partially reverse the change". For example, adding more S from the outside will cause an excess of products, and the system will try to counteract this by increasing the reverse reaction and pushing the equilibrium point backward (though the equilibrium constant will stay the same).
If mineral acid is added to the acetic acid mixture, increasing the concentration of hydronium ion, the amount of dissociation must decrease as the reaction is driven to the left in accordance with this principle. This can also be deduced from the equilibrium constant expression for the reaction:
If {H3O+} increases {CH3CO2H} must increase and {CH3CO2−} must decrease. The H2O is left out, as it is the solvent and its concentration remains high and nearly constant.
A quantitative version is given by the reaction quotient.
J. W. Gibbs suggested in 1873 that equilibrium is attained when the Gibbs free energy of the system is at its minimum value (assuming the reaction is carried out at constant temperature and pressure). What this means is that the derivative of the Gibbs energy with respect to reaction coordinate (a measure of the extent of reaction that has occurred, ranging from zero for all reactants to a maximum for all products) vanishes, signalling a stationary point. This derivative is called the reaction Gibbs energy (or energy change) and corresponds to the difference between the chemical potentials of reactants and products at the composition of the reaction mixture. This criterion is both necessary and sufficient. If a mixture is not at equilibrium, the liberation of the excess Gibbs energy (or Helmholtz energy at constant volume reactions) is the “driving force” for the composition of the mixture to change until equilibrium is reached. The equilibrium constant can be related to the standard Gibbs free energy change for the reaction by the equation
where R is the universal gas constant and T the temperature.
When the reactants are dissolved in a medium of high ionic strength the quotient of activity coefficients may be taken to be constant. In that case the concentration quotient, Kc,
where is the concentration of A, etc., is independent of the analytical concentration of the reactants. For this reason, equilibrium constants for solutions are usually determined in media of high ionic strength. Kc varies with ionic strength, temperature and pressure (or volume). Likewise Kp for gases depends on partial pressure. These constants are easier to measure and encountered in high-school chemistry courses.
Thermodynamics.
At constant temperature and pressure, one must consider the Gibbs free energy, G, while at constant temperature and volume, one must consider the Helmholtz free energy: A, for the reaction; and at constant internal energy and volume, one must consider the entropy for the reaction: S.
The constant volume case is important in geochemistry and atmospheric chemistry where pressure variations are significant. Note that, if reactants and products were in standard state (completely pure), then there would be no reversibility and no equilibrium. Indeed, they would necessarily occupy disjoint volumes of space. The mixing of the products and reactants contributes a large entropy (known as entropy of mixing) to states containing equal mixture of products and reactants. The standard Gibbs energy change, together with the Gibbs energy of mixing, determine the equilibrium state.
In this article only the constant pressure case is considered. The relation between the Gibbs free energy and the equilibrium constant can be found by considering chemical potentials.
At constant temperature and pressure, the Gibbs free energy, G, for the reaction depends only on the extent of reaction: ξ (Greek letter xi), and can only decrease according to the second law of thermodynamics. It means that the derivative of G with ξ must be negative if the reaction happens; at the equilibrium the derivative being equal to zero.
In general an equilibrium system is defined by writing an equilibrium equation for the reaction
In order to meet the thermodynamic condition for equilibrium, the Gibbs energy must be stationary, meaning that the derivative of G with respect to the extent of reaction: ξ, must be zero. It can be shown that in this case, the sum of chemical potentials of the products is equal to the sum of those corresponding to the reactants. Therefore, the sum of the Gibbs energies of the reactants must be the equal to the sum of the Gibbs energies of the products.
where μ is in this case a partial molar Gibbs energy, a chemical potential. The chemical potential of a reagent A is a function of the
activity, {A} of that reagent.
The definition of the Gibbs energy equation interacts with the fundamental thermodynamic relation to produce
Inserting formula_15 into the above equation gives a Stoichiometric coefficient (formula_16) and a differential that denotes the reaction occurring once (formula_17). At constant pressure and temperature the above equations can be written as 
This results in:
By substituting the chemical potentials:
the relationship becomes:
The reaction quotient is defined as formula_23
Therefore
At equilibrium formula_25
leading to:
and
Obtaining the value of the standard Gibbs energy change, allows the calculation of the equilibrium constant
Addition of reactants or products.
For a reactional system at equilibrium: formula_28; formula_29.
formula_31
and
formula_32
then
formula_33
formula_35, the reaction quotient decreases.
formula_36 and formula_37 : The reaction will shift to the right (i.e. in the forward direction, and thus more products will form).
formula_39 and formula_40 : The reaction will shift to the left (i.e. in the reverse direction, and thus less products will form).
"Note" that activities and equilibrium constants are dimensionless numbers.
Treatment of activity.
The expression for the equilibrium constant can be rewritten as the product of a concentration quotient, "K"c and an activity coefficient quotient, Γ.
This is a set of "(m+k)" equations in "(m+k)" unknowns (the formula_42 and the formula_43) and may, therefore, be solved for the equilibrium concentrations formula_42 as long as the chemical potentials are known as functions of the concentrations at the given temperature and pressure. (See Thermodynamic databases for pure substances).
This method of calculating equilibrium chemical concentrations is useful for systems with a large number of different molecules. The use of "k" atomic element conservation equations for the mass constraint is straightforward, and replaces the use of the stoichiometric coefficient equations.
Symbol.
In Wikipedia, the math syymbol formula_45 ( source code: formula_45) may be used as the equilibrium sign. This is preferable to ( source code: ) as it is more readable.
In general the Unicode character may be used. It can be typed in Microsoft Windows as + , , , on the numeric keypad, and in most Linux distributions with + + , , , , , .

</doc>
<doc id="5308" url="https://en.wikipedia.org/wiki?curid=5308" title="Combination">
Combination

In mathematics, a combination is a way of selecting items from a collection, such that (unlike permutations) the order of selection does not matter. In smaller cases it is possible to count the number of combinations. For example, given three fruits, say an apple, an orange and a pear, there are three combinations of two that can be drawn from this set: an apple and a pear; an apple and an orange; or a pear and an orange.
More formally, a "k"-combination of a set "S" is a subset of "k" distinct elements of "S". If the set has "n" elements, the number of "k"-combinations is equal to the binomial coefficient
which can be written using factorials as formula_2 whenever formula_3, and which is zero when formula_4. The set of all "k"-combinations of a set "S" is sometimes denoted by formula_5.
Combinations refer to the combination of "n" things taken "k" at a time without repetition. To refer to combinations in which repetition is allowed, the terms "k"-selection, "k"-multiset, or "k"-combination with repetition are often used. If, in the above example, it was possible to have two of any one kind of fruit there would be 3 more 2-selections: one with two apples, one with two oranges, and one with two pears.
Although the set of three fruits was small enough to write a complete list of combinations, with large sets this becomes impractical. For example, a poker hand can be described as a 5-combination ("k" = 5) of cards from a 52 card deck ("n" = 52). The 5 cards of the hand are all distinct, and the order of cards in the hand does not matter. There are 2,598,960 such combinations, and the chance of drawing any one hand at random is 1 / 2,598,960.
Number of "k"-combinations.
The number of "k"-combinations from a given set "S" of "n" elements is often denoted in elementary combinatorics texts by formula_6, or by a variation such as formula_7, formula_8, formula_9, formula_10 or even formula_11 (the latter form was standard in French, Romanian, Russian, Chinese and Polish texts). The same number however occurs in many other mathematical contexts, where it is denoted by formula_12 (often read as ""n" choose "k""); notably it occurs as a coefficient in the binomial formula, hence its name binomial coefficient. One can define formula_12 for all natural numbers "k" at once by the relation
from which it is clear that formula_15 and formula_16 for "k" > "n". To see that these coefficients count "k"-combinations from "S", one can first consider a collection of "n" distinct variables "X""s" labeled by the elements "s" of "S", and expand the product over all elements of "S":
it has 2"n" distinct terms corresponding to all the subsets of "S", each subset giving the product of the corresponding variables "X""s". Now setting all of the "X""s" equal to the unlabeled variable "X", so that the product becomes , the term for each "k"-combination from "S" becomes "X""k", so that the coefficient of that power in the result equals the number of such "k"-combinations.
Binomial coefficients can be computed explicitly in various ways. To get all of them for the expansions up to , one can use (in addition to the basic cases already given) the recursion relation
for 0 < "k" < "n", which follows from =; this leads to the construction of Pascal's triangle.
For determining an individual binomial coefficient, it is more practical to use the formula
The numerator gives the number of "k"-permutations of "n", i.e., of sequences of "k" distinct elements of "S", while the denominator gives the number of such "k"-permutations that give the same "k"-combination when the order is ignored.
When "k" exceeds "n"/2, the above formula contains factors common to the numerator and the denominator, and canceling them out gives the relation
for 0 ≤ "k" ≤ "n". This expresses a symmetry that is evident from the binomial formula, and can also be understood in terms of "k"-combinations by taking the complement of such a combination, which is an -combination.
Finally there is a formula which exhibits this symmetry directly, and has the merit of being easy to remember:
where "n"! denotes the factorial of "n". It is obtained from the previous formula by multiplying denominator and numerator by !, so it is certainly inferior as a method of computation to that formula.
The last formula can be understood directly, by considering the "n"! permutations of all the elements of "S". Each such permutation gives a "k"-combination by selecting its first "k" elements. There are many duplicate selections: any combined permutation of the first "k" elements among each other, and of the final ("n" − "k") elements among each other produces the same combination; this explains the division in the formula.
From the above formulas follow relations between adjacent numbers in Pascal's triangle in all three directions:
Together with the basic cases formula_23, these allow successive computation of respectively all numbers of combinations from the same set (a row in Pascal's triangle), of "k"-combinations of sets of growing sizes, and of combinations with a complement of fixed size .
Example of counting combinations.
As a specific example, one can compute the number of five-card hands possible from a standard fifty-two card deck as:
Alternatively one may use the formula in terms of factorials and cancel the factors in the numerator against parts of the factors in the denominator, after which only multiplication of the remaining factors is required:
Another alternative computation, equivalent to the first, is based on writing
which gives
When evaluated in the following order, , this can be computed using only integer arithmetic. The reason is that when each division occurs, the intermediate result that is produced is itself a binomial coefficient, so no remainders ever occur.
Using the symmetric formula in terms of factorials without performing simplifications gives a rather extensive calculation:
Enumerating "k"-combinations.
One can enumerate all "k"-combinations of a given set "S" of "n" elements in some fixed order, which establishes a bijection from an interval of formula_12 integers with the set of those "k"-combinations. Assuming "S" is itself ordered, for instance "S" = { 1, 2, …, "n" }, there are two natural possibilities for ordering its "k"-combinations: by comparing their smallest elements first (as in the illustrations above) or by comparing their largest elements first. The latter option has the advantage that adding a new largest element to "S" will not change the initial part of the enumeration, but just add the new "k"-combinations of the larger set after the previous ones. Repeating this process, the enumeration can be extended indefinitely with "k"-combinations of ever larger sets. If moreover the intervals of the integers are taken to start at 0, then the "k"-combination at a given place "i" in the enumeration can be computed easily from "i", and the bijection so obtained is known as the combinatorial number system. It is also known as "rank"/"ranking" and "unranking" in computational mathematics.
There are many ways to enumerate "k" combinations. One way is to visit all the binary numbers less than 2"n". Choose those numbers having "k" nonzero bits, although this is very inefficient even for small "n" (e.g. "n" = 20 would require visiting about one million numbers while the maximum number of allowed "k" combinations is about 186 thousand for "k" = 10). The positions of these 1 bits in such a number is a specific "k"-combination of the set { 1, …, "n" }. Another simple, faster way is to track "k" index numbers of the elements selected, starting with {0.."k"-1} (zero-based) or {1.."k"} (one-based) as the first allowed "k"-combination and then repeatedly moving to the next allowed "k"-combination by incrementing the first index number that is less than the index number following it minus one if such an index exists, or incrementing the last index number as long as it is lower than "n"-1 (zero-based) or "n" (one-based) and resetting the first "k"-1 index numbers to {0.."k"-2} (zero-based) or {1.."k"-1} (one-based).
Number of combinations with repetition.
A "k"-combination with repetitions, or "k"-multicombination, or multisubset of size "k" from a set "S" is given by a sequence of "k" not necessarily distinct elements of "S", where order is not taken into account: two sequences of which one can be obtained from the other by permuting the terms define the same multiset. In other words, the number of ways to sample "k" elements from a set of "n" elements allowing for duplicates (i.e., with replacement) but disregarding different orderings (e.g. {2,1,2} = {1,2,2}). Associate an index to each element of "S" and think of the elements of "S" as "types" of objects, then we can let formula_30 denote the number of elements of type "i" in a multisubset. The number of multisubsets of size "k" is then the number of nonnegative integer solutions of the Diophantine equation:
If "S" has "n" elements, the number of such "k"-multisubsets is denoted by,
a notation that is analogous to the binomial coefficient which counts "k"-subsets. This expression, "n" multichoose "k", is also given by a binomial coefficient:
This relationship can be easily seen using a representation known as stars and bars. A solution of the above Diophantine equation can be represented by formula_34 "stars", a separator (a "bar"), then formula_35 more stars, another separator, and so on. The total number of stars in this representation is "k" and the number of bars is "n" - 1 (since no separator is needed at the very end). Thus, a string of "k" + "n" - 1 symbols (stars and bars) corresponds to a solution if there are "k" stars in the string. Any solution can be represented by choosing "k" out of positions to place stars and filling the remaining positions with bars. For example, the solution formula_36 of the equation formula_37 can be represented by
formula_38.
The number of such strings is the number of ways to place 10 stars in 13 positions, formula_39 which is the number of 10-multisubsets of a set with 4 elements.
As with binomial coefficients, there are several relationships between these multichoose expressions. For example, for formula_40,
This identity follows from interchanging the stars and bars in the above representation.
Example of counting multisubsets.
For example, if you have four types of donuts ("n" = 4) on a menu to choose from and you want three donuts ("k" = 3), the number of ways to choose the donuts with repetition can be calculated as
This result can be verified by listing all the 3-multisubsets of the set "S" = {1,2,3,4}. This is displayed in the following table. The second column shows the nonnegative integer solutions formula_43 of the equation formula_44 and the last column gives the stars and bars representation of the solutions.
Number of "k"-combinations for all "k".
The number of "k"-combinations for all "k" is the number of subsets of a set of "n" elements. There are several ways to see that this number is 2"n". In terms of combinations, formula_45, which is the sum of the "n"th row (counting from 0) of the binomial coefficients in Pascal's triangle. These combinations (subsets) are enumerated by the 1 digits of the set of base 2 numbers counting from 0 to 2"n"  -  1, where each digit position is an item from the set of "n".
Given 3 cards numbered 1 to 3, there are 8 distinct combinations (subsets), including the empty set:
Representing these subsets (in the same order) as base 2 numbers:
Probability: sampling a random combination.
There are various algorithms to pick out a random combination from a given set or list. Rejection sampling is extremely slow for large sample sizes. One way to select a "k"-combination efficiently from a population of size "n" is to iterate across each element of the population, and at each step pick that element with a dynamically changing probability of formula_47. (see reservoir sampling).

</doc>
<doc id="5309" url="https://en.wikipedia.org/wiki?curid=5309" title="Software">
Software

Computer software, or simply software, is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. The term is roughly synonymous with computer program, but is more generic in scope.
The term "software" was first proposed by Alan Turing and used in this sense by John W. Tukey in 1957. In computer science and software engineering, computer software is all information processed by computer systems, programs and data.
Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. Computer hardware and software require each other and neither can be realistically used on its own.
At the lowest level, executable code consists of machine language instructions specific to an individual processor—typically a central processing unit (CPU). A machine language consists of groups of binary values signifying processor instructions that change the state of the computer from its preceding state. For example, an instruction may change the value stored in a particular storage location in the computer—an effect that is not directly observable to the user. An instruction may also (indirectly) cause something to appear on a display of the computer system—a state change which should be visible to the user. The processor carries out the instructions in the order they are provided, unless it is instructed to "jump" to a different instruction, or interrupted. 
The majority of software is written in high-level programming languages that are easier and more efficient for programmers, meaning closer to a natural language. High-level languages are translated into machine language using a compiler or an interpreter or a combination of the two. Software may also be written in a low-level assembly language, essentially, a vaguely mnemonic representation of a machine language using a natural language alphabet, which is translated into machine language using an assembler.
History.
An outline (algorithm) for what would have been the first piece of software was written by Ada Lovelace in the 19th century, for the planned Analytical Engine. However, neither the Analytical Engine nor any software for it were ever created.
The first theory about software—prior to the creation of computers as we know them today—was proposed by Alan Turing in his 1935 essay "Computable numbers with an application to the Entscheidungsproblem" (decision problem).
This eventually led to the creation of the twin academic fields of computer science and software engineering, which both study software and its creation. Computer science is more theoretical (Turing's essay is an example of computer science), whereas software engineering focuses on more practical concerns.
However, prior to 1946, software as we now understand it—programs stored in the memory of stored-program digital computers—did not yet exist. The very first electronic computing devices were instead rewired in order to "reprogram" them.
Types of software.
On virtually all computer platforms, software can be grouped into a few broad categories.
Purpose, or domain of use.
Based on the goal, computer software can be divided into:
Programming tools.
Programming tools are also software in the form of programs or applications that software developers (also known as "programmers, coders, hackers" or "software engineers") use to create, debug, maintain (i.e. improve or fix), or otherwise support software. Software is written in one or more programming languages; there are many programming languages in existence, and each has at least one implementation, each of which consists of its own set of programming tools. These tools may be relatively self-contained programs such as compilers, debuggers, interpreters, linkers, and text editors, that can be combined together to accomplish a task; or they may form an integrated development environment (IDE), which combines much or all of the functionality of such self-contained tools. IDEs may do this by either invoking the relevant individual tools or by re-implementing their functionality in a new way. An IDE can make it easier to do specific tasks, such as searching in files in a particular project. Many programming language implementations provide the option of using both individual tools or an IDE.
Software topics.
Architecture.
Users often see things differently from programmers. People who use modern general purpose computers (as opposed to embedded systems, analog computers and supercomputers) usually see three layers of software performing a variety of tasks: platform, application, and user software.
Execution.
Computer software has to be "loaded" into the computer's storage (such as the hard drive or memory). Once the software has loaded, the computer is able to "execute" the software. This involves passing instructions from the application software, through the system software, to the hardware which ultimately receives the instruction as machine code. Each instruction causes the computer to carry out an operation—moving data, carrying out a computation, or altering the control flow of instructions.
Data movement is typically from one place in memory to another. Sometimes it involves moving data between memory and registers which enable high-speed data access in the CPU. Moving data, especially large amounts of it, can be costly. So, this is sometimes avoided by using "pointers" to data instead. Computations include simple operations such as incrementing the value of a variable data element. More complex computations may involve many operations and data elements together.
Quality and reliability.
Software quality is very important, especially for commercial and system software like Microsoft Office, Microsoft Windows and Linux. If software is faulty (buggy), it can delete a person's work, crash the computer and do other unexpected things. Faults and errors are called "bugs" which are often discovered during alpha and beta testing. Software is often also a victim to what is known as software aging, the progressive performance degradation resulting from a combination of unseen bugs.
Many bugs are discovered and eliminated (debugged) through software testing. However, software testing rarely—if ever—eliminates every bug; some programmers say that "every program has at least one more bug" (Lubarsky's Law). In the waterfall method of software development, separate testing teams are typically employed, but in newer approaches, collectively termed agile software development, developers often do all their own testing, and demonstrate the software to users/clients regularly to obtain feedback. Software can be tested through unit testing, regression testing and other methods, which are done manually, or most commonly, automatically, since the amount of code to be tested can be quite large. For instance, NASA has extremely rigorous software testing procedures for many operating systems and communication functions. Many NASA-based operations interact and identify each other through command programs. This enables many people who work at NASA to check and evaluate functional systems overall. Programs containing command software enable hardware engineering and system operations to function much easier together.
License.
The software's license gives the user the right to use the software in the licensed environment, and in the case of free software licenses, also grants other rights such as the right to make copies.
Proprietary software can be divided into two types:
Open source software, on the other hand, comes with a free software license, granting the recipient the rights to modify and redistribute the software.
Patents.
Software patents, like other types of patents, are theoretically supposed to give an inventor an exclusive, time-limited license for a "detailed idea (e.g. an algorithm) on how to implement" a piece of software, or a component of a piece of software. Ideas for useful things that software could "do", and user "requirements", are not supposed to be patentable, and concrete implementations (i.e. the actual software packages implementing the patent) are not supposed to be patentable either—the latter are already covered by copyright, generally automatically. So software patents are supposed to cover the middle area, between requirements and concrete implementation. In some countries, a requirement for the claimed invention to have an effect on the physical world may also be part of the requirements for a software patent to be held valid—although since "all" useful software has effects on the physical world, this requirement may be open to debate.
Software patents are controversial in the software industry with many people holding different views about them. One of the sources of controversy is that the aforementioned split between initial ideas and patent does not seem to be honored in practice by patent lawyers—for example the patent for Aspect-Oriented Programming (AOP), which purported to claim rights over "any" programming tool implementing the idea of AOP, howsoever implemented. Another source of controversy is the effect on innovation, with many distinguished experts and companies arguing that software is such a fast-moving field that software patents merely create vast additional litigation costs and risks, and actually retard innovation. In the case of debates about software patents outside the US, the argument has been made that large American corporations and patent lawyers are likely to be the primary beneficiaries of allowing or continue to allow software patents.
Design and implementation.
Design and implementation of software varies depending on the complexity of the software. For instance, the design and creation of Microsoft Word took much more time than designing and developing Microsoft Notepad because the latter has much more basic functionality.
Software is usually designed and created (a.k.a. coded/written/programmed) in integrated development environments (IDE) like Eclipse, IntelliJ and Microsoft Visual Studio that can simplify the process and compile the software (if applicable). As noted in a different section, software is usually created on top of existing software and the application programming interface (API) that the underlying software provides like GTK+, JavaBeans or Swing. Libraries (APIs) can be categorized by their purpose. For instance, the Spring Framework is used for implementing enterprise applications, the Windows Forms library is used for designing graphical user interface (GUI) applications like Microsoft Word, and Windows Communication Foundation is used for designing web services. When a program is designed, it relies upon the API. For instance, if a user is designing a Microsoft Windows desktop application, he or she might use the .NET Windows Forms library to design the desktop application and call its APIs like "Form1.Close()" and "Form1.Show()" to close or open the application, and write the additional operations him/herself that it needs to have. Without these APIs, the programmer needs to write these APIs him/herself. Companies like Oracle and Microsoft provide their own APIs so that many applications are written using their software libraries that usually have numerous APIs in them.
Data structures such as hash tables, arrays, and binary trees, and algorithms such as quicksort, can be useful for creating software.
Computer software has special economic characteristics that make its design, creation, and distribution different from most other economic goods.
A person who creates software is called a programmer, software engineer or software developer, terms that all have a similar meaning. More informal terms for programmer also exist such as "coder" and "hacker"although use of the latter word may cause confusion, because it is more often used to mean someone who illegally breaks into computer systems.
Industry and organizations.
A great variety of software companies and programmers in the world comprise a software industry. Software can be quite a profitable industry: Bill Gates, the founder of Microsoft was the richest person in the world in 2009, largely due to his ownership of a significant number of shares in Microsoft, the company responsible for Microsoft Windows and Microsoft Office software products.
Non-profit software organizations include the Free Software Foundation, GNU Project and Mozilla Foundation. Software standard organizations like the W3C, IETF develop recommended software standards such as XML, HTTP and HTML, so that software can interoperate through these standards.
Other well-known large software companies include Oracle, Novell, SAP, Symantec, Adobe Systems, and Corel, while small companies often provide innovation.

</doc>
<doc id="5311" url="https://en.wikipedia.org/wiki?curid=5311" title="Computer programming">
Computer programming

Computer programming (often shortened to programming) is a process that leads from an original formulation of a computing problem to executable computer programs. Programming involves activities such as analysis, developing understanding, generating algorithms, verification of requirements of algorithms including their correctness and resources consumption, and implementation (commonly referred to as coding) of algorithms in a target programming language. Source code is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate performing a specific task or solving a given problem. The process of programming thus often requires expertise in many different subjects, including knowledge of the application domain, specialized algorithms and formal logic.
Related tasks include testing, debugging, and maintaining the source code, implementation of the build system, and management of derived artifacts such as machine code of computer programs. These might be considered part of the programming process, but often the term "software development" is used for this larger process with the term "programming", "implementation", or "coding" reserved for the actual writing of source code. Software engineering combines engineering techniques with software development practices.
Overview.
Within software engineering, programming (the "implementation") is regarded as one phase in a software development process.
There is an ongoing debate on the extent to which the writing of programs is an art form, a craft, or an engineering discipline. In general, good programming is considered to be the measured application of all three, with the goal of producing an efficient and evolvable software solution (the criteria for "efficient" and "evolvable" vary considerably). The discipline differs from many other technical professions in that programmers, in general, do not need to be licensed or pass any standardized (or governmentally regulated) certification tests in order to call themselves "programmers" or even "software engineers." Because the discipline covers many areas, which may or may not include critical applications, it is debatable whether licensing is required for the profession as a whole. In most cases, the discipline is self-governed by the entities which require the programming, and sometimes very strict environments are defined (e.g. United States Air Force use of AdaCore and security clearance). However, representing oneself as a "professional software engineer" without a license from an accredited institution is illegal in many parts of the world.
Another ongoing debate is the extent to which the programming language used in writing computer programs affects the form that the final program takes. This debate is analogous to that surrounding the Sapir–Whorf hypothesis in linguistics and cognitive science, which postulates that a particular spoken language's nature influences the habitual thought of its speakers. Different language patterns yield different patterns of thought. This idea challenges the possibility of representing the world perfectly with language, because it acknowledges that the mechanisms of any language condition the thoughts of its speaker community.
History.
Ancient cultures seemed to have no conception of computing beyond arithmetic, algebra, and geometry, occasionally devising computational systems with elements of calculus (e.g. the method of exhaustion). The only mechanical device that existed for numerical computation at the beginning of human history was the abacus, invented in Sumeria circa 2500 BC. Later, the Antikythera mechanism, invented some time around 100 BC in ancient Greece, is the first known mechanical calculator utilizing gears of various sizes and configuration to perform calculations, which tracked the metonic cycle still used in lunar-to-solar calendars, and which is consistent for calculating the dates of the Olympiads.
The Kurdish medieval scientist Al-Jazari built programmable automata in 1206 AD. One system employed in these devices was the use of pegs and cams placed into a wooden drum at specific locations, which would sequentially trigger levers that in turn operated percussion instruments. The output of this device was a small drummer playing various rhythms and drum patterns. The Jacquard loom, which Joseph Marie Jacquard developed in 1801, uses a series of pasteboard cards with holes punched in them. The hole pattern represented the pattern that the loom had to follow in weaving cloth. The loom could produce entirely different weaves using different sets of cards.
Charles Babbage adopted the use of punched cards around 1830 to control his Analytical Engine. Mathematician Ada Lovelace, a friend of Babbage, between 1842 and 1843 translated an article by Italian military engineer Luigi Menabrea on the engine, which she supplemented with a set of notes, simply called Notes. These notes include an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by a machine. Despite controversy over scope of her contribution, many consider this algorithm to be the first computer program.
In the 1880s, Herman Hollerith invented the recording of data on a medium that could then be read by a machine. Prior uses of machine readable media, above, had been for lists of instructions (not data) to drive programmed machines such as Jacquard looms and mechanized musical instruments. "After some initial trials with paper tape, he settled on punched cards..." To process these punched cards, first known as "Hollerith cards" he invented the keypunch, sorter, and tabulator unit record machines. These inventions were the foundation of the data processing industry. In 1896 he founded the "Tabulating Machine Company" (which later became the core of IBM). The addition of a control panel (plugboard) to his 1906 Type I Tabulator allowed it to do different jobs without having to be physically rebuilt. By the late 1940s, there were several unit record calculators, such as the IBM 602 and IBM 604, whose control panels specified a sequence (list) of operations and thus were programmable machines.
The invention of the von Neumann architecture allowed computer programs to be stored in computer memory. Early programs had to be painstakingly crafted using the instructions (elementary operations) of the particular machine, often in binary notation. Every model of computer would likely use different instructions (machine language) to do the same task. Later, assembly languages were developed that let the programmer specify each instruction in a text format, entering abbreviations for each operation code instead of a number and specifying addresses in symbolic form (e.g., ADD X, TOTAL). Entering a program in assembly language is usually more convenient, faster, and less prone to human error than using machine language, but because an assembly language is little more than a different notation for a machine language, any two machines with different instruction sets also have different assembly languages.
The synthesis of numerical calculation, predetermined operation and output, along with a way to organize and input instructions in a manner relatively easy for humans to conceive and produce, led to the modern development of computer programming. In 1954, FORTRAN was invented; it was the first widely used high level programming language to have a functional implementation, as opposed to just a design on paper. (A high-level language is, in very general terms, any programming language that allows the programmer to write programs in terms that are more abstract than assembly language instructions, i.e. at a level of abstraction "higher" than that of an assembly language.) It allowed programmers to specify calculations by entering a formula directly (e.g. ). The program text, or "source", is converted into machine instructions using a special program called a compiler, which translates the FORTRAN program into machine language. In fact, the name FORTRAN stands for "Formula Translation". Many other languages were developed, including some for commercial programming, such as COBOL. Programs were mostly still entered using punched cards or paper tape. (See computer programming in the punch card era). By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers. Text editors were developed that allowed changes and corrections to be made much more easily than with punched cards. (Usually, an error in punching a card meant that the card had to be discarded and a new one punched to replace it.)
As time has progressed, computers have made giant leaps in processing power, which have allowed the development of programming languages that are more abstracted from the underlying hardware. Popular programming languages of the modern era include ActionScript, C, C++, C#, Haskell, Java, JavaScript, Objective-C, Perl, PHP, Python, Ruby, Smalltalk, SQL, Visual Basic, and dozens more. Although these high-level languages usually incur greater overhead, the increase in speed of modern computers has made the use of these languages much more practical than in the past. These increasingly abstracted languages are typically easier to learn and allow the programmer to develop applications much more efficiently and with less source code. However, high-level languages are still impractical for a few programs, such as those where low-level hardware control is necessary or where maximum processing speed is vital. Computer programming has become a popular career in the developed world, particularly in the United States, Europe, and Japan. Due to the high labor cost of programmers in these countries, some forms of programming have been increasingly subject to outsourcing (importing software and services from other countries, usually at a lower wage), making programming career decisions in developed countries more complicated, while increasing economic opportunities for programmers in less developed areas, particularly China and India. 
Modern programming.
Quality requirements.
Whatever the approach to development may be, the final program must satisfy some fundamental properties. The following properties are among the most important:
Readability of source code.
In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code. It affects the aspects of quality above, including portability, usability and most importantly maintainability.
Readability is important because programmers spend the majority of their time reading, trying to understand and modifying existing source code, rather than writing new source code. Unreadable code often leads to bugs, inefficiencies, and duplicated code. A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Following a consistent programming style often helps readability. However, readability is more than just programming style. Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability. Some of these factors include:
Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display. Techniques like Code refactoring can enhance readability.
Algorithmic complexity.
The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problem. For this purpose, algorithms are classified into "orders" using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input. Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances..
Methodologies.
The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging). There exist a lot of differing approaches for each of those tasks. One approach popular for requirements analysis is Use Case analysis. Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years. There are many approaches to the Software development process.
Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA). The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
Measuring language usage.
It is very difficult to determine what are the most popular of modern programming languages. Methods of measuring programming language popularity include: counting the number of job advertisements that mention the language, the number of books sold and courses teaching the language (this overestimates the importance of newer languages), and estimates of the number of existing lines of code written in the language (this underestimates the number of users of business languages such as COBOL).
Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications. For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software. Many applications use a mix of several languages in their construction and use. New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).
Debugging.
Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users. Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages. Use of a static code analysis tool can help detect some possible problems.
Debugging is often done with IDEs like Eclipse, Visual Studio, Kdevelop, NetBeans and . Standalone debuggers like gdb are also used, and these often provide less of a visual environment, usually using a command line.
Programming languages.
Different programming languages support different styles of programming (called "programming paradigms"). The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference. Ideally, the programming language best suited for the task at hand will be selected. Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute. Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly. It is usually easier to code in "high-level" languages than in "low-level" ones.
Allen Downey, in his book "How To Think Like A Computer Scientist", writes:
Many computer languages provide a mechanism to call functions provided by shared libraries. Provided the functions in a library follow the appropriate run time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
Programmers.
Computer programmers are those who write computer software. Their jobs usually involve:

</doc>
<doc id="5312" url="https://en.wikipedia.org/wiki?curid=5312" title="The Consolation of Philosophy">
The Consolation of Philosophy

The Consolation of Philosophy () is a work by the sixth-century philosopher Boethius that has been described as having had the single most important influence on the Christianity of the Middle Ages and early Renaissance and as the last great work of the Classical Period.
Description.
"The Consolation of Philosophy" was written in AD 523 during a one-year imprisonment Boethius served while awaiting trial – and eventual execution – for the alleged crime of treason under the Ostrogothic King Theodoric the Great. Boethius was at the very heights of power in Rome and was brought down by treachery. This experience inspired the text, which reflects on how evil can exist in a world governed by God (the problem of theodicy), and how happiness can be attainable amidst fickle fortune, while also considering the nature of happiness and God. It has been described as "by far the most interesting example of prison literature the world has ever seen."
A link to Christianity is often assumed, yet there is no reference made to Jesus Christ or Christianity or any other specific religion other than a few oblique references to Pauline scripture, such as the symmetry between the opening lines of Book 4 Chapter 3 and 1 Corinthians 9:24. God is however represented not only as an eternal and all-knowing being, but as the source of all Good.
Boethius writes the book as a conversation between himself and Lady Philosophy. She consoles Boethius by discussing the transitory nature of fame and wealth ("no man can ever truly be secure until he has been forsaken by Fortune"), and the ultimate superiority of things of the mind, which she calls the "one true good". She contends that happiness comes from within, and that one's virtue is all that one truly has, because it is not imperilled by the vicissitudes of fortune.
Boethius engages questions such as the nature of predestination and free will, why evil men often prosper and good men fall into ruin, human nature, virtue, and justice. He speaks about the nature of free will versus determinism when he asks if God knows and sees all, or does man have free will. To quote V.E. Watts on Boethius, "God is like a spectator at a chariot race; He watches the action the charioteers perform, but this does not cause them." On human nature, Boethius says that humans are essentially good and only when they give in to “wickedness” do they “sink to the level of being an animal.” On justice, he says criminals are not to be abused, rather treated with sympathy and respect, using the analogy of doctor and patient to illustrate the ideal relationship between prosecutor and criminal.
In the "Consolation", Boethius answered religious questions without reference to Christianity, relying solely on natural philosophy and the Classical Greek tradition. He believed in the correspondence between faith and reason. The truths found in Christianity would be no different from the truths found in philosophy. In the words of Henry Chadwick, "If the "Consolation" contains nothing distinctively Christian, it is also relevant that it contains nothing specifically pagan either... is a work written by a Platonist who is also a Christian, but is not a Christian work."
Influence.
From the Carolingian epoch to the end of the Middle Ages and beyond it was one of the most popular and influential philosophical works, read by statesmen, poets, and historians, as well as of philosophers and theologians. It is through Boethius that much of the thought of the Classical period was made available to the Western Medieval world. It has often been said Boethius was the “last of the Romans and the first of the Scholastics”.
The philosophical message of the book fits well with the religious piety of the Middle Ages. Readers were encouraged not to seek worldly goods such as money and power, but to seek internalized virtues. Evil had a purpose, to provide a lesson to help change for good; while suffering from evil was seen as virtuous. Because God ruled the universe through Love, prayer to God and the application of Love would lead to true happiness. The Middle Ages, with their vivid sense of an overruling fate, found in Boethius an interpretation of life closely akin to the spirit of Christianity. "The Consolation of Philosophy" stands, by its note of fatalism and its affinities with the Christian doctrine of humility, midway between the pagan philosophy of Seneca the Younger and the later Christian philosophy of consolation represented by Thomas Aquinas.
The book is heavily influenced by Plato and his dialogues (as was Boethius himself). Its popularity can in part be explained by its Neoplatonic and Christian ethical messages, although current scholarly research is still far from clear exactly why and how the work became so vastly popular in the Middle Ages.
Translations into the vernacular were done by famous notables, including King Alfred (Old English), Jean de Meun (Old French), Geoffrey Chaucer (Middle English), Queen Elizabeth I (Early Modern English), and Notker Labeo (Old High German).
Found within the "Consolation" are themes that have echoed throughout the Western canon: the female figure of wisdom that informs Dante, the ascent through the layered universe that is shared with Milton, the reconciliation of opposing forces that find their way into Chaucer in The Knight's Tale, and the Wheel of Fortune so popular throughout the Middle Ages.
Citations from it occur frequently in Dante's "Divina Commedia". Of Boethius, Dante remarked "“The blessed soul who exposes the deceptive world to anyone who gives ear to him.”
Boethian influence can be found nearly everywhere in Geoffrey Chaucer's poetry, e.g. in "Troilus and Criseyde", "The Knight's Tale", "The Clerk's Tale", "The Franklin's Tale", "The Parson's Tale" and "The Tale of Melibee", in the character of Lady Nature in "The Parliament of Fowls" and some of the shorter poems, such as "Truth", "The Former Age" and "Lak of Stedfastnesse". Chaucer translated the work in his "Boece".
The Italian composer Luigi Dallapiccola used some of the text in his choral work "Canti di prigionia" (1938). The Australian composer Peter Sculthorpe quoted parts of it in his opera or music theatre work "Rites of Passage" (1972–73), which was commissioned for the opening of the Sydney Opera House but was not ready in time.
Tom Shippey in "The Road to Middle-earth" says how “Boethian” much of the treatment of evil is in Tolkien's "The Lord of the Rings". Shippey says that Tolkien knew well the translation of Boethius that was made by King Alfred and he quotes some “Boethian” remarks from Frodo, Treebeard and Elrond.
Boethius and "Consolatio Philosophiae" are cited frequently by the main character Ignatius J. Reilly in the Pulitzer Prize-winning "A Confederacy of Dunces" (1980).
Boethius is also referenced in the 2002 film "24 Hour Party People", when Tony Wilson's character gives pocket change to a panhandler, who recites an excerpt of "The Consolation of Philosophy." This reference is related to viewing history as a wheel, with the fortunes of man rising and falling as cyclically as its spokes. It speaks largely to the wheel as a metaphor for the vicissitudes of life.
It is a prosimetrical text, meaning that it is written in alternating sections of prose and metered verse. In the course of the text, Boethius displays a virtuosic command of the forms of Latin poetry. It is classified as a Menippean satire, a fusion of allegorical tale, platonic dialogue, and lyrical poetry.
In the 20th century there were close to four hundred manuscripts still surviving, a testament to its popularity.

</doc>
<doc id="5313" url="https://en.wikipedia.org/wiki?curid=5313" title="Crouching Tiger, Hidden Dragon">
Crouching Tiger, Hidden Dragon

Crouching Tiger, Hidden Dragon () is a 2000 Taiwanese-Chinese-Hong Kong-American martial arts film. A Chinese co-production, the film was directed by Ang Lee and featured an international cast of Han Chinese actors, including Chow Yun-fat, Michelle Yeoh, Zhang Ziyi and Chang Chen. The film was based on the fourth novel in a pentalogy, known in China as the "Crane Iron Pentalogy", by Wuxia novelist Wang Dulu. The martial arts and action sequences were choreographed by Yuen Wo Ping. A was released in 2016.
Made on a US$17 million budget, with dialogue in Mandarin, "Crouching Tiger, Hidden Dragon" became a surprise international success, grossing $213.5 million. It grossed US$128 million in the United States, becoming the highest-grossing foreign-language film in American history. It has won over 40 awards. The film won the Academy Award for Best Foreign Language Film (Taiwan) and three other Academy Awards, and was nominated for six other Academy Awards, including Best Picture. The film also won four BAFTAs and two Golden Globe Awards, one for Best Foreign Film. Along with its awards success, "Crouching Tiger" continues to be hailed as one of the greatest and most influential foreign language films in the United States, especially coming out of Taiwan. It has been praised for its martial arts sequences, story, direction, musical score, and cinematography.
Plot.
The film is set in the Qing Dynasty during the 43rd year (1779) of the reign of the Qianlong Emperor. Li Mu Bai (Chow Yun-fat) is an accomplished Wudang swordsman. Long ago, his master was murdered by Jade Fox (Cheng Pei-pei), a woman who sought to learn Wudang skills. Mu Bai is also a good friend of Yu Shu Lien (Michelle Yeoh), a female warrior. Mu Bai and Shu Lien have developed feelings for each other, but they have never acknowledged or acted on them due to Yu's arranged marriage with Meng Sizhao (Donnie Yen). Mu Bai, intending to give up his warrior life, asks Shu Lien to transport his sword, also referred to as the "Green Destiny", to the city of Beijing, as a gift for their friend Sir Te (Sihung Lung). At Sir Te's estate, Shu Lien meets Jen (Zhang Ziyi), the daughter of Governor Yu (Li Fazeng), a visiting Manchu aristocrat. Jen, destined for an arranged marriage and yearning for adventure, seems envious of Shu Lien's warrior lifestyle.
One evening, a masked thief sneaks into Sir Te's estate and steals the sword. Mu Bai and Shu Lien trace the theft to Governor Yu's compound and learn that Jade Fox has been posing as Jen's governess for many years. Mu Bai makes the acquaintance of Inspector Tsai (Wang Deming), a police investigator from the provinces, and his daughter May (Li Li), who have come to Peking in pursuit of Fox. Fox challenges the pair and Sir Te's servant Master Bo (Gao Xi'an) to a showdown that night. Following a protracted battle, the group is on the verge of defeat when Mu Bai arrives and outmaneuvers Fox. Before Mu Bai can kill Fox, the masked thief reappears and partners with Fox to fight. Fox resumes the fight and kills Tsai before fleeing with the thief (who is revealed to be Fox's protégé, Jen). After seeing Jen fight Mu Bai, Fox realizes Jen had been secretly studying the Wudang manual and has surpassed her in combative skills.
At night, a desert bandit named Lo (Chang Chen) breaks into Jen's bedroom and asks her to leave with him. A flashback reveals that in the past, when Governor Yu and his family were traveling in the western deserts, Lo and his bandits had raided Jen's caravan and Lo had stolen her comb. She chased after him, following him to his desert cave seemingly in a quest to get her comb back. However, the pair soon fell passionately in love. Lo eventually convinced Jen to return to her family, though not before telling her a legend of a man who jumped off a cliff to make his wishes come true. Because the man's heart was pure, he did not die. Lo came to Peking to persuade Jen not to go through with her arranged marriage. However, Jen refuses to leave with him. Later, Lo interrupts Jen's wedding procession, begging her to come away with him. Nearby, Shu Lien and Mu Bai convince Lo to wait for Jen at Mount Wudang, where he will be safe from Jen's family, who are furious with him. Jen runs away from her husband on the wedding night before the marriage could be consummated. Disguised in male clothing, she is accosted at an inn by a large group of warriors; armed with the "Green Destiny" and her own superior combat skills, she emerges victorious.
Jen visits Shu Lien, who tells her that Lo is waiting for her at Mount Wudang. After an angry dispute, the two women engage in a duel. Although Shu Lien is the superior fighter, Jen, wielding the "Green Destiny", destroys each weapon that Shu Lien wields, until Jen loses to a broken sword held at her neck. When Shu Lien shows mercy and lowers the sword, Jen injures Shu Lien's arm. Mu Bai arrives and pursues Jen into a bamboo forest. Following a duel where Mu Bai regains possession of the "Green Destiny", he decides to throw the sword over a waterfall. In pursuit, Jen dives into an adjoining river to retrieve the sword and is then rescued by Fox. Fox puts Jen into a drugged sleep and places her in a cavern; Mu Bai and Shu Lien discover her there. Fox suddenly reappears and attacks the others with poisoned darts. Mu Bai blocks the needles with his sword and avenges his master's death by mortally wounding Fox, only to realize that one of the darts hit him in the neck. Fox dies, confessing that her goal had been to kill Jen because she was furious that Jen had hid the secrets of Wudang's far superior fighting techniques from her.
As Jen exits to gather up an antidote for the poisoned dart, Mu Bai prepares to die. With his last breaths, he finally confesses his romantic affections for Shu Lien. He dies in her arms as Jen returns, too late to save him. The "Green Destiny" is returned to Sir Te. Jen later goes to Mount Wudang and spends one last night with Lo. The next morning, Lo finds Jen standing on a balcony overlooking the edge of the mountain. In an echo of the legend that they spoke about in the desert, she asks him to make a wish. He complies and wishes for them to be together again; back in the desert. Jen then suddenly leaps over the side of the mountain.
Themes and interpretations.
Title.
The name "Crouching Tiger Hidden Dragon" is a literal translation of the Chinese idiom "臥虎藏龍" which describes a place or situation that is full of unnoticeable masters. It is from a poem of the ancient Chinese poet Yu Xin's (513–581) that reads "暗石疑藏虎，盤根似臥龍", which means "behind the rock in the dark probably hides a tiger, and the coiling giant root resembles a crouching dragon." The last character in Xiaohu and Jiaolong's names mean "Tiger" and "Dragon" respectively.
Teacher-student relationship.
A teacher's desire to have a worthy student, the obligations between a student and a master, and tensions in these relationships are central to the characters' motives, conflicts between the characters, and the unfolding of the film's plot. Li Mu Bai is burdened with the responsibility for avenging his master's death, and turns his back on retirement to live up to this obligation. His fascination with the prospect of having Jen as a disciple also motivates his behavior, and that of Jade Fox.
Regarding conflicts in the student-teacher relationship, the potential for exploitation created by the subordinate position of the student and the tensions that exist when a student surpasses or resists a teacher are explored. Jen hides her mastery of martial arts from her teacher, Jade Fox, which leads both to their parting of ways and to Jade Fox's attempt on Jen's life. At the same time, Jade Fox's own unorthodox relationship with a Wudang master (who she claims would not teach her, but did take sexual advantage of her) brought her to a life of crime. At times, Li Mu Bai and Jen's conversations more than hint that the desire for a teacher-student relationship could turn into a romantic relationship. Jen responds to these feelings, and her desire to not submit to a teacher, by turning away from Li Mu Bai when she jumps in the lake after the "Green Destiny".
Poison.
Poison is also a significant theme in the film. In the world of martial arts, poison is considered the act of one who is too cowardly and dishonorable to fight; and indeed, the only character that explicitly fits these characteristics is Jade Fox. The poison is a weapon of her bitterness, and quest for vengeance: She poisons the master of Wudang, attempts to poison Jen, and succeeds in killing Mu Bai using a poisoned needle.
However, the poison is not only of the physical sort: Jade Fox's tutelage of Jen has left Jen spiritually poisoned, which can be seen in the lying, stealing and betrayal Jen commits. Even though she is the one who initially trained Jen, Jen is never seen to use poison herself. This indicates that there is hope yet to reform her and integrate her into society. In further play on this theme by the director, Jade Fox, as she dies, refers to the poison from a young child, "the deceit of an eight-year-old girl," obviously referring to what she considers her own spiritual poisoning by her young apprentice Jen. Li Mu Bai himself warns that without guidance, Jen could become a "poison dragon."
Production.
The film was originally written as a novel series by Wang Dulu starting in the late 1930s. The film is adapted from the storyline of the fourth book in the series, "Crouching Tiger, Hidden Dragon".
Filming.
Although its Academy Award was presented to Taiwan, "Crouching Tiger, Hidden Dragon" was in fact an international co-production between companies in four regions: the Chinese company China Film Co-Production Corporation; the American companies Columbia Pictures Film Production Asia, Sony Pictures Classics and Good Machine; the Hong Kong company EDKO Film; and the Taiwanese Zoom Hunt International Productions Company, Ltd; as well as the unspecified United China Vision, and Asia Union Film & Entertainment Ltd., created solely for this film.
The film was made in Beijing, with location shooting in the Anhui, Hebei, Jiangsu and Xinjiang provinces of China. The first phase of shooting was in the Gobi Desert where it would consistently rain. Director Ang Lee noted that "I didn't take one break in eight months, not even for half a day. I was miserable -- I just didn't have the extra energy to be happy. Near the end, I could hardly breathe. I thought I was about to have a stroke." The stunt work was mostly performed by the actors themselves and Ang Lee stated in an interview that computers were used "only to remove the safety wires that held the actors." "Most of the time you can see their faces," he added, "That's really them in the trees."
Another compounding issue was the difference between accents of the four lead actors: Chow Yun-fat is from Hong Kong and spoke Cantonese natively and Michelle Yeoh is from Malaysia and spoke English. Only Zhang Ziyi spoke with a native Mandarin accent that Ang Lee wanted. Chow Yun Fat said that on "the first day shooting I had to do 28 takes just because of the language. That's never happened before in my life."
Because the film specifically targeted Western audiences rather than the domestic audiences who were already used to Wuxia films, English subtitles were needed. Ang Lee, who was educated in the West, personally edited the subtitles to ensure they were satisfactory for Western audiences.
Soundtrack.
The score was composed by Tan Dun, originally performed by Shanghai Symphony Orchestra, Shanghai National Orchestra, and Shanghai Percussion Ensemble. It also features many solo passages for cello played by Yo-Yo Ma. The "last track" ("A Love Before Time") features Coco Lee, who later performed it at the Academy Awards. The music for the entire film was produced in two weeks.
Marketing.
The film was adapted into a video game, a comics series, and a 34-episode Taiwanese television series based on the original novel. The latter was released in 2004 as "New Crouching Tiger, Hidden Dragon" for US and Canadian release.
Reception.
Critical response.
"Crouching Tiger, Hidden Dragon" was very well received in the Western world, numerous awards. The review aggregator Rotten Tomatoes reported that 97% of critics gave the film positive reviews based on 150 reviews. The site's consensus states: "The movie that catapulted Ang Lee into the ranks of upper echelon Hollywood filmmakers, "Crouching Tiger, Hidden Dragon" features a deft mix of amazing martial arts battles, beautiful scenery, and tasteful drama." Metacritic reported the film had an average score of 93 out of 100, based on 31 reviews.
Some Chinese-speaking viewers were bothered by the accents of the leading actors. Neither Chow (a native Cantonese speaker) nor Yeoh (who was born and raised in Malaysia) speaks Mandarin as a mother tongue. All four main actors spoke with different accents: Chow speaks with a Cantonese accent; Yeoh with a Malaysian accent; Chang Chen a Taiwanese accent; and Zhang Ziyi a Beijing accent. Yeoh responded to this complaint in a December 28, 2000, interview with "Cinescape". She argued that "My character lived outside of Beijing, and so I didn't have to do the Beijing accent." When the interviewer, Craig Reid, remarked that "My mother-in-law has this strange Sichuan-Mandarin accent that's hard for me to understand.", Yeoh responded: "Yes, provinces all have their very own strong accents. When we first started the movie, Cheng Pei Pei was going to have her accent, and Chang Zhen was going to have his accent, and this person would have that accent. And in the end nobody could understand what they were saying. Forget about us, even the crew from Beijing thought this was all weird."
The film led to a boost in popularity of Chinese wuxia films in the western world, where they were previously little known, and led to films such as "House of Flying Daggers" and "Hero" marketed towards western audiences. The film also provided the breakthrough role for Zhang Ziyi's career, who noted that:
The character of Lo, or "Dark Cloud" the desert bandit, influenced the development of the protagonist of the "Prince of Persia" series of video games.
The film is ranked at No. 497 on "Empire" magazine's 2008 list of the 500 greatest movies of all time and at No. 66 in the magazine's 100 Best Films of World Cinema, published in 2010.
Counter-Flow.
Wu & Chan (2007) look at "Crouching Tiger, Hidden Dragon" as somewhat of an example of “counter-flow”, a film that has challenged Hollywood’s grip on the film market. They argue that as a product of globalization, the movie did not demonstrate a one-way flow based on Western Ideology, but was multi-directional with the ability for local resources to influence the West and gain economic capital. Despite its international success however and perceived ability to change the flow from East to West, there were still instances of Western adaptation for the movie, such as putting more emphasis on female characters in order to greater execute a balance between gender roles in the East and West. The script of the film was written between Taiwan and Hollywood and in translating the film to English, many cultural references were lost which proved difficult in maintaining the cultural authenticity of the film while still reaching out to the West. The thematic conflict throughout the movie between societal roles and personal desires attribute to the international reception of the film, which resonates with both the Eastern and Western audiences. Additionally, international and western networks were used in the production and promotion of the film, which were needed to conceive its global distribution. Additional marketing strategies were needed for the film in order to attract the Western audience who were unfamiliar with the cultural products of the East.
Box office.
The film premiered in cinemas on December 8, 2000, in limited release within the US. During its opening weekend, the film opened in 15th place, grossing $663,205 in business, showing at 16 locations. On January 12, 2001, "Crouching Tiger, Hidden Dragon" premiered in cinemas in wide release throughout the US grossing $8,647,295 in business, ranking in 6th place. The film "Save the Last Dance" came in 1st place during that weekend grossing $23,444,930. The film's revenue dropped by almost 30% in its second week of release, earning $6,080,357. For that particular weekend, the film fell to 8th place screening in 837 theaters. "Save the Last Dance" remained unchanged in first place grossing $15,366,047 in box office revenue. During its final week in release, "Crouching Tiger, Hidden Dragon" opened in a distant 50th place with $37,233 in revenue. The film went on to top out domestically at $128,078,872 in total ticket sales through a 31-week theatrical run. Internationally, the film took in an additional $85,446,864 in box office business for a combined worldwide total of $213,525,736. For 2000 as a whole, the film would cumulatively rank at a worldwide box office performance position of 19.
Accolades.
Gathering widespread critical acclaim at the Toronto and New York film festivals, the film also became a favorite when Academy Awards nominations were announced in 2001. The film was however screened out of competition at the 2000 Cannes Film Festival.
Sequel.
A sequel to the film, "", was released in 2016. It was directed by Yuen Woo-ping, who was the action choreographer for the first film. It is a co-production between Pegasus Media, China Film Group Corporation, and the Weinstein Company. Unlike the original film, the sequel was filmed in English.
"Sword of Destiny" is based on the book "Iron Knight, Silver Vase", the next (and last) novel in the Crane-Iron Pentalogy. It features a mostly new cast, headed by Donnie Yen. Michelle Yeoh reprised her role from the original. Zhang Ziyi was also approached to appear in "Sword of Destiny" but refused, stating that she would only appear in a sequel if Ang Lee were directing it.
In the United States, the sequel was for the most part not shown in theaters, instead being distributed via the video streaming service Netflix.
Cultural references.
The theme of Janet Jackson's song "China Love" was related to the film by MTV News, in which Jackson sings of the daughter of an emperor in love with a warrior, unable to sustain relations when forced to marry into royalty.
The names of the pterosaur genus "Kryptodrakon" and the ceratopsian genus "Yinlong" (both meaning "hidden dragon") allude to the film.

</doc>
<doc id="5314" url="https://en.wikipedia.org/wiki?curid=5314" title="Charlemagne">
Charlemagne

Charlemagne (; 2 April 742/747/748Matthias Becher: "Neue Überlegungen zum Geburtsdatum Karls des Großen", in: "Francia" 19/1, 1992, pp. 37-60 (online);R. McKitterick: "Charlemagne". Cambridge 2008, p. 72.</ref>28 January 814), also known as Charles the Great () or Charles I (Frankish: "*Karl"), was King of the Franks. He united most of Western Europe during the early Middle Ages and laid the foundations for modern France and Germany. He took the Frankish throne in 768 and became King of Italy from 774. From 800, he became the first Holy Roman Emperor — the first recognized emperor in Western Europe since the fall of the Western Roman Empire three centuries earlier. Charlemagne already ruled his kingdom without the help of the Pope, but recognition from the pontiff granted him divine legitimacy in the eyes of his contemporaries.
The expanded Frankish state which Charlemagne founded was called the Carolingian Empire.
Charlemagne was the oldest son of Pepin the Short and Bertrada of Laon. He became king in 768 following the death of his father, initially as co-ruler with his brother Carloman I. Carloman's sudden death in 771 under unexplained circumstances left Charlemagne as the undisputed ruler of the Frankish Kingdom. Charlemagne continued his father's policy towards the papacy and became its protector, removing the Lombards from power in northern Italy, and leading an incursion into Muslim Spain. He also campaigned against the Saxons to his east, Christianizing them upon penalty of death, leading to events such as the Massacre of Verden. Charlemagne reached the height of his power in 800 when he was crowned "Emperor of the Romans" by Pope Leo III on Christmas Day at Old St. Peter's Basilica.
Charlemagne has been called the "Father of Europe" ("Pater Europae"), as he united most of Western Europe for the first time since the Roman Empire. His rule spurred the Carolingian Renaissance, a period of energetic cultural and intellectual activity within the Western Church. All Holy Roman Emperors up to the last Emperor Francis II, as well as both the French and German monarchies, considered their kingdoms to be descendants of Charlemagne's empire.
However, the Eastern Orthodox Church views Charlemagne more controversially, labeling as heterodox his support of the filioque and recognition by the Bishop of Rome as legitimate Roman Emperor rather than Irene of Athens of the Eastern Roman Empire. This was but two of the machinations that led to the eventual split of Rome and Constantinople in the Great Schism of 1054 AD.
Charlemagne died in 814, having ruled as emperor for just over thirteen years. He was laid to rest in his imperial capital of Aachen in what is today Germany. His son Louis the Pious succeeded him.
Political background.
By the 6th century, the western Germanic Franks had been Christianised, and Francia, ruled by the Merovingians, was the most powerful of the kingdoms that succeeded the Western Roman Empire. Following the Battle of Tertry, however, the Merovingians declined into a state of powerlessness, for which they have been dubbed the "rois fainéants" (""do-nothing kings""). Almost all government powers of any consequence were exercised by their chief officer, the mayor of the palace.
In 687, Pepin of Herstal, mayor of the palace of Austrasia, ended the strife between various kings and their mayors with his victory at Tertry and became the sole governor of the entire Frankish kingdom.
In 750, Pepin was elected by an assembly of the Franks, anointed by the archbishop, and then raised to the office of king. The Pope branded Childeric III as "the false king" and ordered him into a monastery. Thus was the Merovingian dynasty replaced by the Carolingian dynasty, named after Pepin's father Charles Martel. In 753, Pope Stephen II fled from Italy to Francia, appealing to Pepin for assistance for the rights of St. Peter. He was supported in this appeal by Carloman, Charles' brother. In return, the pope could provide only legitimacy, which he did by again anointing and confirming Pepin, this time adding his young sons Carolus and Carloman to the royal patrimony, now heirs to the great realm that already covered most of western Europe. In 754, Pepin accepted the Pope's invitation to visit Italy on behalf of St. Peter's rights, dealing successfully with the Lombards.
Under the Carolingians, the Frankish kingdom spread to encompass an area including most of Western Europe; the division of the kingdom formed the basis for modern France and Germany. The religious, political, and artistic developments originating from a centrally positioned Francia made a defining imprint on the whole of Europe.
Rise to power.
Early life.
Date of birth.
The most likely date of Charlemagne's birth is reconstructed from several sources. The date of 742 — calculated from Einhard's date of death of January 814 at age 72 - predates the marriage of his parents in 744. The year given in the "Annales Petaviani", 747, would be more likely, except that it contradicts Einhard and a few other sources in making Charlemagne seventy years old at his death. The month and day of April 2 is established by a calendar from Lorsch Abbey.
In 747, that day fell on Easter, a coincidence that likely would have been remarked upon by chroniclers but was not. If Easter was being used as the beginning of the calendar year, then 2 April 747 could have been, by modern reckoning, 2 April 748 (not on Easter). The date favored by the preponderance of evidence is 2 April 742, based on Charlemagne's being a septuagenarian at the time of his death. This date would appear to support the idea that Charlemagne was born illegitimate, which is not, however, mentioned by Einhard.
Place of birth.
Charlemagne’s exact birthplace is unknown, although historians have suggested Aachen in modern-day Germany, and Liège (Herstal) in present-day Belgium as possible locations. Aachen and Liège are close to the region from where both the Merovingian and Carolingian families originated. Other cities have been suggested, including Düren, Gauting, Mürlenbach, Quierzy and Prüm. No definitive evidence as to which is the right candidate exists.
Charlemagne was the eldest child of Pepin the Short (714 – 24 September 768, reigned from 751) and his wife Bertrada of Laon (720 – 12 July 783), daughter of Caribert of Laon and Bertrada of Cologne. Records name only Carloman, Gisela, and three short-lived children named Pepin, Chrothais and Adelais as his younger siblings.
The ambiguous high office.
The most powerful officers of the Frankish people, the Mayor of the Palace (Maior Domus) and one or more kings (rex, reges), were appointed by the election of the people; that is, no regular elections were held, but they were held as required to elect officers "ad quos summa imperii pertinebat", "to whom the highest matters of state pertained". Evidently interim decisions could be made by the Pope, which ultimately needed to be ratified using an assembly of the people, which met once a year.
Before he was elected king in 750, Pepin the Short was initially a mayor, a high office he held "as though hereditary" (velut hereditario fungebatur). Einhard explains that "the honor" was usually "given by the people" to the distinguished, but Pepin the Great and his brother Carloman the Wise received it as though hereditary, as had their father, Charles Martel. There was, however, a certain ambiguity about quasi-inheritance. The office was treated as joint property: one Mayorship held by two brothers jointly. Each, however, had his own geographic jurisdiction. When Carloman decided to resign, becoming ultimately a Benedictine at Monte Cassino, the question of the disposition of his quasi-share was settled by the pope. He converted the Mayorship into a Kingship and awarded the joint property to Pepin, who now had the full right to pass it on by inheritance.
This decision was not accepted by all members of the family. Carloman had consented to the temporary tenancy of his own share, which he intended to pass on to his own son, Drogo, when the inheritance should be settled at someone's death. By the Pope's decision, in which Pepin had a hand, Drogo was to be disqualified as an heir in favour of his cousin Charles. He took up arms in opposition to the decision and was joined by Grifo, a half-brother of Pepin and Carloman, who had been given a share by Charles Martel, but was stripped of it and held under loose arrest by his half-brothers after an attempt to seize their shares by military action. By 753 all was over. Grifo perished in combat in the Battle of Saint-Jean-de-Maurienne while Drogo was hunted down and taken into custody.
On the death of Pepin, 24 September 768, the kingship passed jointly to his sons, "with divine assent" (divino nutu). According to the "Life", Pepin died in Paris. The Franks "in general assembly" (generali conventu) gave them both the rank of king (reges) but "partitioned the whole body of the kingdom equally" (totum regni corpus ex aequo partirentur). The "annals" tell a slightly different version, with the king dying at St-Denis, near Paris. The two "lords" (domni) were "elevated to kingship" (elevati sunt in regnum), Charles on 9 October in Noyon, Carloman on an unspecified date in Soissons. If born in 742, Charles was 26 years old, but he had been campaigning at his father's right hand for several years, which may help to account for his military skill. Carloman was 17.
The language in either case suggests that there were not two inheritances, which would have created distinct kings ruling over distinct kingdoms, but a single joint inheritance and a joint kingship tenanted by two equal kings, Charles and his brother Carloman. As before, distinct jurisdictions were awarded. Charles received Pepin's original share as Mayor: the outer parts of the kingdom bordering on the sea, namely Neustria, western Aquitaine, and the northern parts of Austrasia; while Carloman was awarded his uncle's former share, the inner parts: southern Austrasia, Septimania, eastern Aquitaine, Burgundy, Provence, and Swabia, lands bordering Italy. The question of whether these jurisdictions were joint shares reverting to the other brother if one brother died or were inherited property passed on to the descendants of the brother who died was never definitely settled by the Frankish people. It came up repeatedly over the succeeding decades until the grandsons of Charlemagne created distinct sovereign kingdoms.
Aquitanian rebellion.
An inheritance in the countries formerly under Roman law (ius or iustitia) represented not only a transmission of the properties and privileges but also the encumbrances and obligations attached to the inheritance. Pepin at his death had been in process of building an empire, a difficult task. According to Russell:"In those times, to build a kingdom from an aggregation of small states was itself no great difficulty ... But to keep the state intact after it had been formed was a colossal task ... Each of the minor states ... had its little sovereign ... who ... gave himself chiefly to ... plotting, pillaging and fighting."
Formation of a new Aquitania.
Aquitania under Rome had been in southern Gaul, Romanized and speaking a Romance language. Similarly Hispania had been populated by peoples who spoke various languages, including Celtic, but the area was now populated entirely by Romance language speakers. Between Aquitania and Hispania were the Euskaldunak, Latinized to Vascones, or Basques, living in Basque country, Vasconia, which extended, according to the distributions of place names attributable to the Basques, most densely in the western Pyrenees but also as far south as the upper Ebro River in Spain and as far north as the Garonne River in France. The French name, Gascony, derives from Vasconia. The Romans were never able to entirely subject Vasconia. The parts they did, in which they placed the region's first cities, were sources of legions in the Roman army valued for their fighting abilities. The border with Aquitania was Toulouse.
At about 660 the Duchy of Vasconia united with the Duchy of Aquitania to form a single kingdom under Felix of Aquitaine, governing from Toulouse. This was a joint kingship with a 28-year-old Basque king, Lupus I. The kingdom was sovereign and independent. On the one hand Vasconia gave up predation to become a player on the field of European politics. On the other, whatever arrangements Felix had made with the weak Merovingians were null and void. At Felix's death in 670 the joint property of the kingship reverted entirely to Lupus. As the Basques had no law of joint inheritance, but practised primogeniture, Lupus in effect founded a hereditary dynasty of Basque kings of an expanded Aquitania.
Acquisition of Aquitania by the Carolingians.
The Latin chronicles on the end of Visigothic Hispania leave much to be desired, such as identification of characters, filling in the gaps, and reconciliation of numerous contradictions. The Muslim sources, however, present a more coherent view, such as in the "Ta'rikh iftitah al-Andalus" ("History of the Conquest of al-Andalus") by Ibn al-Qūṭiyya (a name meaning "the son of the Gothic woman", referring to the granddaughter of the last king of all Visigothic Spain, who married a Moor). Ibn al-Qūṭiyya, who had another, much longer name, must have been relying to some degree on family oral tradition.
According to Ibn al-Qūṭiyya, the last Visigothic king of a united Hispania died before his three sons, Almund, Romulo, and Ardabast, reached majority. Their mother was regent at Toledo, but Roderic, army chief of staff, staged a rebellion, capturing Cordova. Of all the possible outcomes, he chose to impose a joint rule over distinct jurisdictions on the true heirs. Evidence of a division of some sort can be found in the distribution of coins imprinted with the name of each king and in the king lists. Wittiza is succeeded by Roderic, who reigned for seven and a half years, followed by a certain Achila (Aquila), who reigned three and a half years. If the reigns of both terminated with the incursion of the Saracens, then Roderic appears to have reigned a few years before the majority of Achila. The latter's kingdom is securely placed to the northeast, while Roderic seems to have taken the rest, notably Portugal.
The Saracens crossed the mountains to claim Ardo's Septimania, only to encounter the Basque dynasty of Aquitania, always the allies of the Goths. Odo the Great of Aquitania was at first victorious at the Battle of Toulouse in 721. Saracen troops gradually massed in Septimania and in 732 an army under Emir Abd al-Rahman abd Allah al-Ghafiqi advanced into Vasconia, and Odo was defeated at the Battle of the River Garonne. They took Bordeaux and were advancing toward Tours when Odo, powerless to stop them, appealed to his arch-enemy, Charles Martel, mayor of the Franks. In one of the first of the lightning marches for which the Carolingian kings became famous, Charles and his army appeared in the path of the Saracens between Tours and Poitiers, and in the Battle of Tours decisively defeated and killed al-Ghafiqi. The Moors would come back twice more, only to suffer defeat at Charles' hands twice more - at the River Berre near Narbonne in 737 and a second time in the Dauphine in 740. Odo's price for salvation from the Saracens was incorporation into Frankish kingdom, a decision that was repugnant to him and also to his heirs.
Loss and recovery of Aquitania.
After the death of his son, Hunald allied himself with free Lombardy. However, Odo had ambiguously left the kingdom jointly to his two sons, Hunald and Hatto. The latter, loyal to Francia, now went to war with his brother over full possession. Victorious, Hunald blinded and imprisoned his brother, only to be so stricken by conscience that he resigned and entered the church as a monk to do penance according to Carolingian sources. His son Waifer took an early inheritance, becoming duke of Aquitania, and ratified the alliance with Lombardy. Waifer decided to honor it, repeating his father's decision, which he justified by arguing that any agreements with Charles Martel became invalid on Martel's death. Since Aquitania was now Pepin's inheritance because of the earlier assistance given by Charles Martel, according to some the latter and his son, the young Charles, hunted down Waifer, who could only conduct a guerrilla war, and executed him.
Among the contingents of the Frankish army were Bavarians under Tassilo III, Duke of Bavaria, an Agilofing, the hereditary Bavarian ducal family. Grifo had installed himself as Duke of Bavaria, but Pepin replaced him with a member of the ducal family yet a child, Tassilo, whose protector he had become after the death of his father. The loyalty of the Agilolfings was perpetually in question, but Pepin exacted numerous oaths of loyalty from Tassilo. However, the latter had married Liutperga, a daughter of Desiderius, king of Lombardy. At a critical point in the campaign, Tassilo with all his Bavarians left the field. Out of reach of Pepin, he repudiated all loyalty to Francia. Pepin had no chance to respond as he grew ill and within a few weeks after the execution of Waifer died himself.
The first event of the brothers' reign was the uprising of the Aquitainians and Gascons, in 769, in that territory split between the two kings. One year before, Pepin had finally defeated Waifer, Duke of Aquitaine, after waging a destructive, ten-year war against Aquitaine. Now, one Hunald (seemingly other than Hunald the duke) led the Aquitainians as far north as Angoulême. Charles met Carloman, but Carloman refused to participate and returned to Burgundy. Charles went to war, leading an army to Bordeaux, where he set up a fort at Fronsac. Hunald was forced to flee to the court of Duke Lupus II of Gascony. Lupus, fearing Charles, turned Hunald over in exchange for peace, and he was put in a monastery. Gascon lords also surrendered, and Aquitaine and Gascony were finally fully subdued by the Franks.
Perforce Union.
The brothers maintained lukewarm relations with the assistance of their mother Bertrada, but in 770 Charles signed a treaty with Duke Tassilo III of Bavaria and married a Lombard Princess (commonly known today as Desiderata), the daughter of King Desiderius, to surround Carloman with his own allies. Though Pope Stephen III first opposed the marriage with the Lombard princess, he would soon have little to fear from a Frankish-Lombard alliance.
Less than a year after his marriage, Charlemagne repudiated Desiderata and quickly married a 13-year-old Swabian named Hildegard. The repudiated Desiderata returned to her father's court at Pavia. Her father's wrath was now aroused, and he would have gladly allied with Carloman to defeat Charles. Before any open hostilities could be declared, however, Carloman died on 5 December 771, seemingly of natural causes. Carloman's widow Gerberga fled to Desiderius' court in Lombardy with her sons for protection.
Italian campaigns.
Conquest of the Lombard kingdom.
At his succession in 772, Pope Adrian I demanded the return of certain cities in the former exarchate of Ravenna in accordance with a promise at the succession of Desiderius. Instead, Desiderius took over certain papal cities and invaded the Pentapolis, heading for Rome. Adrian sent ambassadors to Charlemagne in autumn requesting he enforce the policies of his father, Pepin. Desiderius sent his own ambassadors denying the pope's charges. The ambassadors both met at Thionville, and Charlemagne upheld the pope's side. Charlemagne demanded what the pope had requested, and Desiderius promptly swore never to comply. Charlemagne and his uncle Bernard crossed the Alps in 773 and chased the Lombards back to Pavia, which they then besieged. Charlemagne temporarily left the siege to deal with Adelchis, son of Desiderius, who was raising an army at Verona. The young prince was chased to the Adriatic littoral, and he fled to Constantinople to plead for assistance from Constantine V, who was waging war with Bulgaria.
The siege lasted until the spring of 774, when Charlemagne visited the pope in Rome. There he confirmed his father's grants of land, with some later chronicles claiming—falsely—that he also expanded them, granting Tuscany, Emilia, Venice, and Corsica. The pope granted him the title "patrician". He then returned to Pavia, where the Lombards were on the verge of surrendering. In return for their lives, the Lombards surrendered and opened the gates in early summer. Desiderius was sent to the abbey of Corbie, and his son Adelchis died in Constantinople a patrician. Charles, unusually, had himself crowned with the Iron Crown and made the magnates of Lombardy do homage to him at Pavia. Only Duke Arechis II of Benevento refused to submit and proclaimed independence. Charlemagne was then master of Italy as king of the Lombards. He left Italy with a garrison in Pavia and a few Frankish counts in place the same year.
There was still instability, however, in Italy. In 776, Dukes Hrodgaud of Friuli and Hildeprand of Spoleto rebelled. Charlemagne rushed back from Saxony and defeated the duke of Friuli in battle; the duke was slain. His children were also taught skills in line with their aristocratic status, which included training in riding and weaponry for his sons, and embroidery, spinning, and weaving for his daughters.
The sons fought many wars on behalf of their father when they came of age. Charles was mostly preoccupied with the Bretons, whose border he shared and who insurrected on at least two occasions and were easily put down, but he was also sent against the Saxons on multiple occasions. In 805 and 806, he was sent into the Böhmerwald (modern Bohemia) to deal with the Slavs living there (Bohemian tribes, ancestors of the modern Czechs). He subjected them to Frankish authority and devastated the valley of the Elbe, forcing a tribute on them. Pippin had to hold the Avar and Beneventan borders but also fought the Slavs to his north. He was uniquely poised to fight the Byzantine Empire when finally that conflict arose after Charlemagne's imperial coronation and a Venetian rebellion. Finally, Louis was in charge of the Spanish March and also went to southern Italy to fight the duke of Benevento on at least one occasion. He took Barcelona in a great siege in 797 (see below).
Charlemagne's attitude toward his daughters has been the subject of much discussion. He kept them at home with him and refused to allow them to contract sacramental marriages (though he originally condoned an engagement between his eldest daughter Rotrude and Constantine VI of Byzantium, this engagement was annulled when Rotrude was 11). Charlemagne's stance in opposition to his daughters' marriages may possibly have intended to prevent the creation of cadet branches of the family to challenge the main line, as had been the case with Tassilo of Bavaria – yet he tolerated their extramarital relationships, even rewarding their common-law husbands, and treasured the illegitimate grandchildren they produced for him. He also, apparently, refused to believe stories of their wild behaviour. After his death the surviving daughters were banished from the court by their brother, the pious Louis, to take up residence in the convents they had been bequeathed by their father. At least one of them, Bertha, had a recognised relationship, if not a marriage, with Angilbert, a member of Charlemagne's court circle.
Carolingian expansion to the south.
Vasconia and the Pyrenees.
The destructive war led by Pepin in Aquitaine, although brought to a satisfactory conclusion for the Franks, proved the Frankish power structure south of the Loire was feeble and unreliable. After the defeat and death of Waifer of Aquitaine in 768, while Aquitaine submitted again to the Carolingian dynasty, a new rebellion broke out in 769 led by Hunald II, maybe son of Waifer. He took refuge with the ally duke Lupus II of Gascony, but probably out of fear of Charlemagne's reprisal, handed him over to the new King of the Franks besides pledging loyalty to him, which seemed to confirm the peace in the Basque area south of the Garonne.
However, wary of new Basque uprisings, Charlemagne seems to have tried to diminish duke Lupus's power by appointing a certain Seguin as count of Bordeaux (778) and other counts of Frankish background in bordering areas (, County of Fézensac), a decision that seriously undermined the authority of the duke of Gascony (Vasconia). The Basque duke in turn seems to have contributed decisively or schemed the Battle of Roncevaux Pass (referred to as "Basque treachery"). The defeat of Charlemagne's army in Roncevaux (778) confirmed him in his determination to rule directly by establishing the Kingdom of Aquitaine (son Louis the Pious proclaimed first king) based on a power base of Frankish officials, distributing lands among colonisers and allocating lands to the Church, which he took as ally. A Christianization program was put on place across the high Pyrenees (778).
The new political arrangement for Vasconia did not sit well with local lords. As of 788 we hear of Adalric fighting and capturing Chorson, Carolingian count of Toulouse. He was eventually released, but Charlemagne, enraged at the compromise, decided to depose him and appointed his trustee William of Orange. William in turn fought the Basques and defeated them after banishing Adalric (790).
From 781 (Pallars, Ribagorça) to 806 (Pamplona under Frankish influence), taking the County of Toulouse for a power base, Charlemagne managed to assert Frankish authority over the Pyrenees by bringing to heel the south-western marches of Toulouse (790) and establishing vassal counties on the southern Pyrenees that were to make up the Marca Hispanica. As of 794, we hear for the first time of a Frankish vassal, the Basque lord Belasko ("al-Galashki", 'the Gaul') in the lands of Álava, but Pamplona remained in Cordovan and local hands up to 806. Belasko and the counties in the Marca Hispánica provided the necessary springboard to attack the Andalusians (expedition led by William Count of Toulouse and Louis the Pious to capture Barcelona in 801), in a way that Charlemagne had succeeded in expanding the Carolingian rule all around the Pyrenees by 812, although events in the Duchy of Vasconia (rebellion in Pamplona, count overthrown in Aragon, duke Seguin of Bordeaux deposed, uprising of the Basque lords, etc.) were to prove it ephemeral on his death.
Roncesvalles campaign.
According to the Muslim historian Ibn al-Athir, the Diet of Paderborn had received the representatives of the Muslim rulers of Zaragoza, Girona, Barcelona, and Huesca. Their masters had been cornered in the Iberian peninsula by Abd ar-Rahman I, the Umayyad emir of Cordova. These "Saracen" (Moorish and Muladi) rulers offered their homage to the great king of the Franks in return for military support. Seeing an opportunity to extend Christendom and his own power and believing the Saxons to be a fully conquered nation, Charlemagne agreed to go to Spain.
In 778, he led the Neustrian army across the Western Pyrenees, while the Austrasians, Lombards, and Burgundians passed over the Eastern Pyrenees. The armies met at Saragossa and Charlemagne received the homage of the Muslim rulers, Sulayman al-Arabi and Kasmin ibn Yusuf, but the city did not fall for him. Indeed, Charlemagne was facing the toughest battle of his career where the Muslims had the upper hand and forced him to retreat. He decided to go home, since he could not trust the Basques, whom he had subdued by conquering Pamplona. He turned to leave Iberia, but as he was passing through the Pass of Roncesvalles one of the most famous events of his long reign occurred. The Basques fell on his rearguard and baggage train, utterly destroying it. The Battle of Roncevaux Pass, though less a battle than a mere skirmish, left many famous dead, including the seneschal Eggihard, the count of the palace Anselm, and the warden of the Breton March, Roland, inspiring the subsequent creation of the Song of Roland ("La Chanson de Roland").
Contact with the Saracens.
The conquest of Italy brought Charlemagne in contact with the Saracens who, at the time, controlled the Mediterranean. Pippin, his son, was much occupied with Saracens in Italy. Charlemagne conquered Corsica and Sardinia at an unknown date and in 799 the Balearic Islands. The islands were often attacked by Saracen pirates, but the counts of Genoa and Tuscany (Boniface) kept them at bay with large fleets until the end of Charlemagne's reign. Charlemagne even had contact with the caliphal court in Baghdad. In 797 (or possibly 801), the caliph of Baghdad, Harun al-Rashid, presented Charlemagne with an Asian elephant named Abul-Abbas and a clock.
Wars with the Moors.
In Hispania, the struggle against the Moors continued unabated throughout the latter half of his reign. His son Louis was in charge of the Spanish border. In 785, his men captured Girona permanently and extended Frankish control into the Catalan littoral for the duration of Charlemagne's reign (and much longer; it remained nominally Frankish until the Treaty of Corbeil in 1258). The Muslim chiefs in the northeast of Islamic Spain were constantly revolting against Cordovan authority, and they often turned to the Franks for help. The Frankish border was slowly extended until 795, when Girona, Cardona, Ausona, and Urgell were united into the new Spanish March, within the old duchy of Septimania.
In 797, Barcelona, the greatest city of the region, fell to the Franks when Zeid, its governor, rebelled against Cordova and, failing, handed it to them. The Umayyad authority recaptured it in 799. However, Louis of Aquitaine marched the entire army of his kingdom over the Pyrenees and besieged it for two years, wintering there from 800 to 801, when it capitulated. The Franks continued to press forward against the emir. They took Tarragona in 809 and Tortosa in 811. The last conquest brought them to the mouth of the Ebro and gave them raiding access to Valencia, prompting the Emir al-Hakam I to recognize their conquests in 813.
Eastern campaigns.
Saxon Wars.
Charlemagne was engaged in almost constant battle throughout his reign, often at the head of his elite "scara" bodyguard squadrons, with his legendary sword Joyeuse in hand. In the Saxon Wars, spanning thirty years and eighteen battles, he conquered Saxonia and proceeded to convert the conquered to Christianity.
The Germanic Saxons were divided into four subgroups in four regions. Nearest to Austrasia was Westphalia and furthest away was Eastphalia. In between these two kingdoms was that of Engria and north of these three, at the base of the Jutland peninsula, was Nordalbingia.
In his first campaign, in 773, Charlemagne forced the Engrians to submit and cut down an Irminsul pillar near Paderborn. The campaign was cut short by his first expedition to Italy. He returned in 775, marching through Westphalia and conquering the Saxon fort at Sigiburg. He then crossed Engria, where he defeated the Saxons again. Finally, in Eastphalia, he defeated a Saxon force, and its leader Hessi converted to Christianity. Charlemagne returned through Westphalia, leaving encampments at Sigiburg and Eresburg, which had been important Saxon bastions. With the exception of Nordalbingia, Saxony was under his control, but Saxon resistance had not ended.
Following his campaign in Italy to subjugate the dukes of Friuli and Spoleto, Charlemagne returned very rapidly to Saxony in 776, where a rebellion had destroyed his fortress at Eresburg. The Saxons were once again brought to heel, but their main leader, Widukind, managed to escape to Denmark, home of his wife. Charlemagne built a new camp at Karlstadt. In 777, he called a national diet at Paderborn to integrate Saxony fully into the Frankish kingdom. Many Saxons were baptised as Christians.
In the summer of 779, he again invaded Saxony and reconquered Eastphalia, Engria, and Westphalia. At a diet near Lippe, he divided the land into missionary districts and himself assisted in several mass baptisms (780). He then returned to Italy and, for the first time, there was no immediate Saxon revolt. Saxony was peaceful from 780 to 782.
He returned to Saxony in 782 and instituted a code of law and appointed counts, both Saxon and Frank. The laws were draconian on religious issues; for example, the "Capitulatio de partibus Saxoniae" prescribed death to Saxon pagans who refused to convert to Christianity. This revived a renewal of the old conflict. That year, in autumn, Widukind returned and led a new revolt. In response, at Verden in Lower Saxony, Charlemagne is recorded as having ordered the execution of 4,500 Saxon prisoners, known as the Massacre of Verden ("Verdener Blutgericht"). The killings triggered three years of renewed bloody warfare (783–785). During this war the Frisians were also finally subdued and a large part of their fleet was burned. The war ended with Widukind accepting baptism.
Thereafter, the Saxons maintained the peace for seven years, but in 792 the Westphalians again rose against their conquerors. The Eastphalians and Nordalbingians joined them in 793, but the insurrection did not catch on and was put down by 794. An Engrian rebellion followed in 796, but the presence of Charlemagne, Christian Saxons and Slavs quickly crushed it. The last insurrection of the independent-minded people occurred in 804, more than thirty years after Charlemagne's first campaign against them. This time, the most restive of them, the Nordalbingians, found themselves effectively disempowered from rebellion for the time being. According to Einhard:
The war that had lasted so many years was at length ended by their acceding to the terms offered by the King; which were renunciation of their national religious customs and the worship of devils, acceptance of the sacraments of the Christian faith and religion, and union with the Franks to form one people.
Submission of Bavaria.
By 774, Charlemagne had invaded the Kingdom of Lombardy, and he later annexed the Lombardian territories and assumed its crown, placing the Papal States under Frankish protection. The Duchy of Spoleto south of Rome was also acquired in 774, while in the central western parts of Europe, the Duchy of Bavaria was absorbed and the Bavarian policy continued of establishing tributary marches, (borders protected in return for tribute or taxes) among the Slavic Serbs, and Czechs. The remaining power confronting the Franks in the east were the Avars, however Charlemagne went on acquiring other Slav areas, including Bohemia, Moravia, Austria and Croatia.
In 789, Charlemagne turned his attention to Bavaria. He claimed Tassilo was an unfit ruler, due to his oath-breaking. The charges were exaggerated, but Tassilo was deposed anyway and put in the monastery of Jumièges. In 794, he was made to renounce any claim to Bavaria for himself and his family (the Agilolfings) at the synod of Frankfurt. Bavaria was subdivided into Frankish counties, as had been done with Saxony.
Avar campaigns.
In 788, the Avars, a pagan Asian horde that had settled down in what is today Hungary (Einhard called them Huns), invaded Friuli and Bavaria. Charlemagne was preoccupied with other matters until 790, when he marched down the Danube and ravaged Avar territory to the Győr. A Lombard army under Pippin then marched into the Drava valley and ravaged Pannonia. The campaigns would have continued if the Saxons had not revolted again in 792, breaking seven years of peace.
For the next two years, Charlemagne was occupied, along with the Slavs, against the Saxons. Pippin and Duke Eric of Friuli continued, however, to assault the Avars' ring-shaped strongholds. The great Ring of the Avars, their capital fortress, was taken twice. The booty was sent to Charlemagne at his capital, Aachen, and redistributed to all his followers and even to foreign rulers, including King Offa of Mercia. Soon the Avar tuduns had lost the will to fight and traveled to Aachen to subject themselves to Charlemagne as vassals and Christians. Charlemagne accepted their surrender and sent one native chief, baptised Abraham, back to Avaria with the ancient title of khagan. Abraham kept his people in line, but in 800, the Bulgarians under Khan Krum also attacked the remains of Avar state.
In 803, Charlemagne sent a huge Bavarian army into Pannonia, defeating and bringing an end to the Avar confederation. In November of the same year, Charlemagne went to Regensburg where the Avar leaders acknowledged him as their own ruler. In 805, the Avar khagan, who had already been baptised, went to Aachen to ask permission to settle with his people south-eastward from Vienna. The Transdanubian territories became integral parts of the Frankish realm, which was abolished by the Magyars in 899-900.
Northeast Slav expeditions.
In 789, in recognition of his new pagan neighbours, the Slavs, Charlemagne marched an Austrasian-Saxon army across the Elbe into Obotrite territory. The Slavs ultimately submitted, led by their leader Witzin. Charlemagne then accepted the surrender of the Wiltzes under Dragovit and demanded many hostages. Charlemagne also demanded the permission to send missionaries into this pagan region unmolested. The army marched to the Baltic before turning around and marching to the Rhine, winning much booty with no harassment. The tributary Slavs became loyal allies. In 795, when the Saxons broke the peace, the Abotrites and Wiltzes rose in arms with their new master against the Saxons. Witzin died in battle and Charlemagne avenged him by harrying the Eastphalians on the Elbe. Thrasuco, his successor, led his men to conquest over the Nordalbingians and handed their leaders over to Charlemagne, who greatly honoured him. The Abotrites remained loyal until Charles' death and fought later against the Danes.
Southeast Slav expeditions.
When Charlemagne incorporated much of Central Europe, he brought the Frankish state face to face with the Avars and Slavs in the southeast. The most southeast Frankish neighbors were Croats, who settled in Pannonian Croatia and Dalmatian Croatia. While fighting the Avars, the Franks had called for their support. During the 790s, when Charlemagne campaigned against the Avars, he won a major victory in 796. Pannonian Croat duke Vojnomir of Pannonian Croatia aided Charlemagne, and the Franks made themselves overlords over the Croats of northern Dalmatia, Slavonia, and Pannonia.
The Frankish commander Eric of Friuli wanted to extend his dominion by conquering the Littoral Croat Duchy. During that time, Dalmatian Croatia was ruled by duke Višeslav of Croatia. In the Battle of Trsat, the forces of Eric fled their positions and were totally routed by the forces of Višeslav. Eric himself was among those killed, and his death and defeat proved a great blow for the Carolingian Empire.
Charlemagne also directed his attention to the Slavs to the west of the Avar khaganate: the Carantanians and Carniolans. These people were subdued by the Lombards and Bavarii, were made tributaries, but were never fully incorporated into the Frankish state.
Imperium.
Coronation.
In 799, Pope Leo III had been mistreated by the Romans, who tried to put out his eyes and tear out his tongue. Leo escaped and fled to Charlemagne at Paderborn, asking him to intervene in Rome and restore him. Charlemagne, advised by scholar Alcuin of York, agreed to travel to Rome, doing so in November 800 and holding a council on December 1. On 23 December, Leo swore an oath of innocence. At Mass, on Christmas Day (25 December), when Charlemagne knelt at the altar to pray, the Pope crowned him "Imperator Romanorum" ("Emperor of the Romans") in Saint Peter's Basilica. In so doing, the Pope effectively nullified the legitimacy of Empress Irene of Constantinople:
Charlemagne's coronation as Emperor, though intended to represent the continuation of the unbroken line of Emperors from Augustus to Constantine VI, had the effect of setting up two separate (and often opposing) Empires and two separate claims to imperial authority. For centuries to come, the Emperors of both West and East would make competing claims of sovereignty over the whole.
Einhard says that Charlemagne was ignorant of the Pope's intent and did not want any such coronation:
at first had such an aversion that he declared that he would not have set foot in the Church the day that they [the imperial titles were conferred, although it was a great feast-day, if he could have foreseen the design of the Pope.
A number of modern scholars, however, suggest that Charlemagne was indeed aware of the coronation; certainly he cannot have missed the bejeweled crown waiting on the altar when he came to pray; something even contemporary sources support when thoroughly analysed.
Debate over coronation.
Historians have debated for centuries whether Charlemagne was aware before the coronation of the Pope's intention to crown him Emperor (Charlemagne declared that he would not have entered Saint Peter's had he known), but that debate has often obscured the arguably more significant question of "why" the Pope granted the title and why Charlemagne chose to accept it once he did.
Roger Collins points out "hat the motivation behind the acceptance of the imperial title was a romantic and antiquarian interest in reviving the Roman empire is highly unlikely." For one thing, such romance would not have appealed either to Franks or Roman Catholics at the turn of the ninth century, both of whom viewed the Classical heritage of the Roman Empire with distrust. The Franks took pride in having "fought against and thrown from their shoulders the heavy yoke of the Romans" and "from the knowledge gained in baptism, clothed in gold and precious stones the bodies of the holy martyrs whom the Romans had killed by fire, by the sword and by wild animals", as Pippin III described it in a law of 763 or 764.
Furthermore, the new title—carrying with it the risk that the new emperor would "make drastic changes to the traditional styles and procedures of government" or "concentrate his attentions on Italy or on Mediterranean concerns more generally"—risked alienating the Frankish leadership.
For both the Pope and Charlemagne, the Roman Empire remained a significant power in European politics at this time, and continued to hold a substantial portion of Italy, with borders not very far south of the city of Rome itself—this is the empire that historiography has labelled the Byzantine Empire, for its capital was Constantinople (ancient Byzantium) and its people and rulers were Greek; it was a thoroughly Hellenic state. Indeed, Charlemagne was usurping the prerogatives of the Roman Emperor in Constantinople simply by sitting in judgement over the Pope in the first place:
For the Pope, then, there was "no living Emperor at the that time" though Henri Pirenne disputes this saying that the coronation "was not in any sense explained by the fact that at this moment a woman was reigning in Constantinople." Nonetheless, the Pope took the extraordinary step of creating one. The papacy had since 727 been in conflict with Irene's predecessors in Constantinople over a number of issues, chiefly the continued Byzantine adherence to the doctrine of iconoclasm, the destruction of Christian images; while from 750, the secular power of the Byzantine Empire in central Italy had been nullified.
By bestowing the Imperial crown upon Charlemagne, the Pope arrogated to himself "the right to appoint ... the Emperor of the Romans, ... establishing the imperial crown as his own personal gift but simultaneously granting himself implicit superiority over the Emperor whom he had created." And "because the Byzantines had proved so unsatisfactory from every point of view—political, military and doctrinal—he would select a westerner: the one man who by his wisdom and statesmanship and the vastness of his dominions ... stood out head and shoulders above his contemporaries."
With Charlemagne's coronation, therefore, "the Roman Empire remained, so far as either of them and Leo were concerned, one and indivisible, with Charles as its Emperor", though there can have been "little doubt that the coronation, with all that it implied, would be furiously contested in Constantinople."
How realistic either Charlemagne or the Pope felt it to be that the people of Constantinople would ever accept the King of the Franks as their Emperor, we cannot know; Alcuin speaks hopefully in his letters of an "Imperium Christianum" ("Christian Empire"), wherein, "just as the inhabitants of the Empire had been united by a common Roman citizenship", presumably this new empire would be united by a common Christian faith, certainly this is the view of Pirenne when he says "Charles was the Emperor of the "ecclesia" as the Pope conceived it, of the Roman Church, regarded as the universal Church". The "Imperium Christianum" was further supported at a number of synods all across the Europe by Paulinus of Aquileia.
What is known, from the Byzantine chronicler Theophanes, is that Charlemagne's reaction to his coronation was to take the initial steps toward securing the Constantinopolitan throne by sending envoys of marriage to Irene, and that Irene reacted somewhat favorably to them.
It is important to distinguish between the universalist and localist conceptions of the empire, which have been the source of considerable controversy among historians. According to the former, the empire was a universal monarchy, a "commonwealth of the whole world, whose sublime unity transcended every minor distinction"; and the emperor "was entitled to the obedience of Christendom." According to the latter, the emperor had no ambition for universal dominion; his policy was limited in the same way as that of every other ruler, and when he made more far-reaching claims his object was normally to ward off the attacks either of the pope or of the Byzantine emperor. According to this view, also, the origin of the empire is to be explained by specific local circumstances rather than by far-flung theories.
According to Werner Ohnsorge, for a long time it had been the custom of Byzantium to designate the German princes as spiritual "sons" of the Byzantines. What might have been acceptable in the fifth century, to the pride of the Franks in the eighth century was provoking and insulting. Charles came to the realization that the great Roman emperor, who claimed to be the head of the world hierarchy of states, in reality was no greater than Charles himself, a king as other kings, since beginning in 629 he had entitled himself "Basileus" (translated literally as "king"). Ohnsorge finds it significant that the chief wax seal of Charles, which bore only the inscription: "Christe, protege Carolum regem Francorum protect Charles, king of the Franks, was used from 772 to 813, even during the imperial period and was not replaced by a special imperial seal; indicating that Charles felt himself to be king of the Franks and wished only for the greatness of his Frankish people. Finally, Ohnsorge points out that in the spring of 813 at Aachen Charles crowned his youngest, only surviving son, Louis, as emperor without recourse to Rome and only with the acclamation of his Franks, also the form in which this acclamation was offered was no longer Roman, but Frankish-Christian; thus demonstrating both independence from Rome, and a Frankish understanding of empire different from Rome's.
Imperial title.
In any event, Charlemagne used these circumstances to claim that he was the renewer of the Roman Empire, which had apparently fallen into degradation under the Byzantines. In his official charters, Charles preferred the style "Karolus serenissimus Augustus a Deo coronatus magnus pacificus imperator Romanum gubernans imperium" ("Charles, most serene Augustus crowned by God, the great, peaceful emperor ruling the Roman empire") to the more direct "Imperator Romanorum" ("Emperor of the Romans").
The title of emperor remained in the Carolingian family for years to come, but divisions of territory and in-fighting over supremacy of the Frankish state weakened its power and ability to lead. The papacy itself never forgot the title nor abandoned the right to bestow it. When the family of Charles ceased to produce worthy heirs, the pope gladly crowned whichever Italian magnate could best protect him from his local enemies. This devolution led to the dormancy of the title from 924 to 962. The title was revived when Otto I was crowned emperor in 962, fashioning himself as the successor of Charlemagne. The empire would remain in continuous existence for nearly a millennium, as the Holy Roman Empire, a true imperial successor to Charles.
Imperial diplomacy.
The iconoclasm of the Byzantine Isaurian Dynasty was endorsed by the Franks. The Second Council of Nicaea reintroduced the veneration of icons under Empress Irene. The council was not recognized by Charlemagne since no Frankish emissaries had been invited, even though Charlemagne ruled more than three provinces of the old Roman empire and was considered equal in rank to the Byzantine emperor. And while the Pope supported the reintroduction of the iconic veneration, he politically digressed from Byzantium. He certainly desired to increase the influence of the papacy, to honour his saviour Charlemagne, and to solve the constitutional issues then most troubling to European jurists in an era when Rome was not in the hands of an emperor. Thus, Charlemagne's assumption of the imperial title was not a usurpation in the eyes of the Franks or Italians. It was, however, seen as such in Byzantium, where it was protested by Irene and her successor Nicephorus I — neither of whom had any great effect in enforcing their protests.
The Byzantines, however, still held several territories in Italy: Venice (what was left of the Exarchate of Ravenna), Reggio (in Calabria), Brindisi (in Apulia), and Naples (the "Ducatus Neapolitanus"). These regions remained outside of Frankish hands until 804, when the Venetians, torn by infighting, transferred their allegiance to the Iron Crown of Pippin, Charles' son. The "Pax Nicephori" ended. Nicephorus ravaged the coasts with a fleet, initiating the only instance of war between the Byzantines and the Franks. The conflict lasted until 810, when the pro-Byzantine party in Venice gave their city back to the Byzantine Emperor, and the two emperors of Europe made peace: Charlemagne received the Istrian peninsula and in 812 the emperor Michael I Rhangabes recognised his status as Emperor, although not necessarily as "Emperor of the Romans".
Danish attacks.
After the conquest of Nordalbingia, the Frankish frontier was brought into contact with Scandinavia. The pagan Danes, "a race almost unknown to his ancestors, but destined to be only too well known to his sons" as Charles Oman described them, inhabiting the Jutland peninsula, had heard many stories from Widukind and his allies who had taken refuge with them about the dangers of the Franks and the fury which their Christian king could direct against pagan neighbours.
In 808, the king of the Danes, Godfred, built the vast Danevirke across the isthmus of Schleswig. This defence, last employed in the Danish-Prussian War of 1864, was at its beginning a long earthenwork rampart. The Danevirke protected Danish land and gave Godfred the opportunity to harass Frisia and Flanders with pirate raids. He also subdued the Frank-allied Wiltzes and fought the Abotrites.
Godfred invaded Frisia, joked of visiting Aachen, but was murdered before he could do any more, either by a Frankish assassin or by one of his own men. Godfred was succeeded by his nephew Hemming, who concluded the Treaty of Heiligen with Charlemagne in late 811.
Death.
In 813, Charlemagne called Louis the Pious, king of Aquitaine, his only surviving legitimate son, to his court. There Charlemagne crowned his son with his own hands as co-emperor and sent him back to Aquitaine. He then spent the autumn hunting before returning to Aachen on 1 November. In January, he fell ill with pleurisy. In deep depression (mostly because many of his plans were not yet realized), he took to his bed on 21 January and as Einhard tells it:
He died January twenty-eighth, the seventh day from the time that he took to his bed, at nine o'clock in the morning, after partaking of the Holy Communion, in the seventy-second year of his age and the forty-seventh of his reign.
He was buried the same day as his death, in Aachen Cathedral, although the cold weather and the nature of his illness made such a hurried burial unnecessary. The earliest surviving "planctus", the "Planctus de obitu Karoli", was composed by a monk of Bobbio, which he had patronised. A later story, told by Otho of Lomello, Count of the Palace at Aachen in the time of Otto III, would claim that he and Emperor Otto had discovered Charlemagne's tomb: the emperor, they claimed, was seated upon a throne, wearing a crown and holding a sceptre, his flesh almost entirely incorrupt. In 1165, Frederick I re-opened the tomb again and placed the emperor in a sarcophagus beneath the floor of the cathedral. In 1215 Frederick II re-interred him in a casket made of gold and silver.
Charlemagne's death greatly affected many of his subjects, particularly those of the literary clique who had surrounded him at Aachen. An anonymous monk of Bobbio lamented:
From the lands where the sun rises to western shores, people are crying and wailing ... the Franks, the Romans, all Christians, are stung with mourning and great worry ... the young and old, glorious nobles, all lament the loss of their Caesar ... the world laments the death of Charles ... O Christ, you who govern the heavenly host, grant a peaceful place to Charles in your kingdom. Alas for miserable me.
He was succeeded by his surviving son, Louis, who had been crowned the previous year. His empire lasted only another generation in its entirety; its division, according to custom, between Louis's own sons after their father's death laid the foundation for the modern states of Germany and France.
Administration.
As an administrator, Charlemagne stands out for his many reforms: monetary, governmental, military, cultural, and ecclesiastical. He is the main protagonist of the "Carolingian Renaissance."
Military.
It has long been held that the dominance of Charlemagne's military was based on a "cavalry revolution" led by Charles Martel in 730s. However, the stirrup, which made the "shock cavalry" lance charge possible, was not introduced to the Frankish kingdom until the late eighth century. Instead, Charlemagne's success rested primarily on novel siege technologies and excellent logistics.
However, large numbers of horses were used by the Frankish military during the age of Charlemagne. This was because horses provided a quick, long-distance method of transporting troops, which was critical to building and maintaining such a large empire.
Economic and monetary reforms.
Charlemagne had an important role in determining the immediate economic future of Europe. Pursuing his father's reforms, Charlemagne abolished the monetary system based on the gold , and he and the Anglo-Saxon King Offa of Mercia took up the system set in place by Pippin. There were strong pragmatic reasons for this abandonment of a gold standard, notably a shortage of gold itself.
The gold shortage was a direct consequence of the conclusion of peace with Byzantium, which resulted in ceding Venice and Sicily to the East and losing their trade routes to Africa. The resulting standardisation economically harmonized and unified the complex array of currencies which had been in use at the commencement of his reign, thus simplifying trade and commerce.
Charlemagne established a new standard, the (from the Latin , the modern pound), which was based upon a pound of silver—a unit of both money and weight—which was worth 20 sous (from the Latin was primarily an accounting device and never actually minted, the modern shilling) or 240 (from the Latin , the modern penny). During this period, the and the were counting units; only the was a coin of the realm.
Charlemagne instituted principles for accounting practice by means of the Capitulare de villis of 802, which laid down strict rules for the way in which incomes and expenses were to be recorded.
Early in Charlemagne's rule he tacitly allowed the Jews to monopolize money lending. Then lending money for interest was proscribed in 814, being against Church law at the time, Charlemagne introduced the "Capitulary for the Jews", a prohibition on Jews engaging in money-lending due to the religious convictions of the majority of his constituents, in essence banning it across the board, a reversal of his earlier recorded general policy. In addition to this macro-oriented reform of the economy, Charlemagne also performed a significant number of microeconomic reforms, such as direct control of prices and levies on certain goods and commodities.
His Capitulary for the Jews, however, was not representative of his overall economic relationship or attitude toward the Frankish Jews, and certainly not his earlier relationship with them, which had evolved over his lifespan. His paid personal physician for example was Jewish, he employed at least one Jew for his diplomatic missions, Isaac was his personal representative to the Muslim caliphate of Baghdad. Letters have been credited to him as well inviting Jews to settle in his kingdom, for economic purposes, generally welcoming them through his overall, progressive policies.
Charlemagne applied this system to much of the European continent, and Offa's standard was voluntarily adopted by much of England. After Charlemagne's death, continental coinage degraded, and most of Europe resorted to using the continued high-quality English coin until about 1100.
Education reforms.
A part of Charlemagne's success as a warrior, an administrator and ruler can be traced to his admiration for learning and education. His reign and the era it ushered in are often referred to as the Carolingian Renaissance because of the flowering of scholarship, literature, art, and architecture which characterize it. Charlemagne, brought into contact with the culture and learning of other countries (especially Moorish Spain, Anglo-Saxon England, and Lombard Italy) due to his vast conquests, greatly increased the provision of monastic schools and scriptoria (centres for book-copying) in Francia.
Most of the presently surviving works of classical Latin were copied and preserved by Carolingian scholars. Indeed, the earliest manuscripts available for many ancient texts are Carolingian. It is almost certain that a text which survived to the Carolingian age survives still.
The pan-European nature of Charlemagne's influence is indicated by the origins of many of the men who worked for him: Alcuin, an Anglo-Saxon from York; Theodulf, a Visigoth, probably from Septimania; Paul the Deacon, Lombard; Peter of Pisa and Paulinus of Aquileia, Italians; and Angilbert, Angilram, Einhard, and Waldo of Reichenau, Franks.
Charlemagne took a serious interest in scholarship, promoting the liberal arts at the court, ordering that his children and grandchildren be well-educated, and even studying himself (in a time when even leaders who promoted education did not take time to learn themselves) under the tutelage of Peter of Pisa, from whom he learned grammar; Alcuin, with whom he studied rhetoric, dialectic (logic), and astronomy (he was particularly interested in the movements of the stars); and Einhard, who assisted him in his studies of arithmetic.
His great scholarly failure, as Einhard relates, was his inability to write: when in his old age he began attempts to learn—practicing the formation of letters in his bed during his free time on books and wax tablets he hid under his pillow—"his effort came too late in life and achieved little success", and his ability to read – which Einhard is silent about, and which no contemporary source supports—has also been called into question.
In 800, Charlemagne enlarged the hostel at the Muristan in Jerusalem and added a library to it. He certainly had not been personally in Jerusalem.
Church reforms.
Unlike his father, Pippin, and uncle, Carloman, Charlemagne expanded the reform program of the church. The deepening of the spiritual life was later to be seen as central to public policy and royal governance. His reform focused on the strengthening of the church's power structure, improving the skill and moral quality of the clergy, standardizing liturgical practices, improvements on the basic tenets of the faith and moral, and the rooting out of paganism. His authority was now extended over church and state. He could discipline clerics, control ecclesiastical property and define orthodox doctrine. Despite the harsh legislation and sudden change, he had grown a well developed support from the clergy who approved his desire to deepen the piety and morals of his Christian subjects.
In 809–810, Charlemagne called together a church council in Aachen, which confirmed the unanimous belief in the West that the Holy Spirit proceeds from the Father and the Son ("ex Patre Filioque") and sanctioned inclusion in the Nicene Creed of the phrase "Filioque" (and the Son). For this Charlemagne sought the approval of Pope Leo III. The Pope, while affirming the doctrine and approving its use in teaching, opposed its inclusion in the text of the Creed as adopted in the 381 First Council of Constantinople. This spoke of the procession of the Holy Spirit from the Father, without adding phrases such as "and the Son", "through the Son", or "alone". Stressing his opposition, the Pope had the original text inscribed in Greek and Latin on two heavy shields, which were displayed in Saint Peter's Basilica.
Writing reforms.
During Charles' reign, the Roman half uncial script and its cursive version, which had given rise to various continental minuscule scripts, were combined with features from the insular scripts that were being used in Irish and English monasteries. Carolingian minuscule was created partly under the patronage of Charlemagne. Alcuin of York, who ran the palace school and scriptorium at Aachen, was probably a chief influence in this.
The revolutionary character of the Carolingian reform, however, can be over-emphasised; efforts at taming the crabbed Merovingian and Germanic hands had been underway before Alcuin arrived at Aachen. The new minuscule was disseminated first from Aachen and later from the influential scriptorium at Tours, where Alcuin retired as an abbot.
Political reforms.
Charlemagne engaged in many reforms of Frankish governance, but he continued also in many traditional practices, such as the division of the kingdom among sons.
Organization.
The Carolingian king exercised the "bannum", the right to rule and command. He had supreme jurisdiction in judicial matters, made legislation, led the army, and protected both the Church and the poor. His administration was an attempt to organize the kingdom, church, and nobility around him. However, the effort was heavily dependent upon the efficiency, loyalty, and support of his subjects.
Divisio regnorum.
In 806, Charlemagne first made provision for the traditional division of the empire on his death. For Charles the Younger he designated Austrasia and Neustria, Saxony, Burgundy, and Thuringia. To Pippin he gave Italy, Bavaria, and Swabia. Louis received Aquitaine, the Spanish March, and Provence. There was no mention of the imperial title however, which has led to the suggestion that, at that particular time, Charlemagne regarded the title as an honorary achievement which held no hereditary significance.
This division might have worked, but it was never to be tested. Pippin died in 810 and Charles in 811. Charlemagne then reconsidered the matter, and in 813, crowned his youngest son, Louis, co-emperor and co-King of the Franks, granting him a half-share of the empire and the rest upon Charlemagne's own death. The only part of the Empire which Louis was not promised was Italy, which Charlemagne specifically bestowed upon Pippin's illegitimate son Bernard.
Personality.
Language.
By Charlemagne's time the French vernacular had already diverged significantly from Latin. This is evidenced by one of the regulations of the Council of Tours (813), which required that the parish priests preach either in the "rusticam Romanam linguam" (Romance) or "Theotiscam" (the Germanic vernacular) rather than in Latin. The goal of this rule was to make the sermons comprehensible to the common people, who must therefore have been either Romance speakers or Germanic speakers. Charlemagne himself probably spoke a Rhenish Franconian dialect of Old High German.
Apart from his native language he also spoke Latin and understood a bit of Greek, according to his biographer Einhard ("Grecam vero melius intellegere quam pronuntiare poterat", "he could understand Greek better than he could speak it").
The largely fictional account of Charlemagne's Iberian campaigns by Pseudo-Turpin, written some three centuries after his death, gave rise to the legend that the king also spoke Arabic.
Appearance.
Charlemagne's personal appearance is known from a good description by a personal associate, Einhard, author after his death of the biography "Vita Karoli Magni". Einhard tells in his twenty-second chapter:
"He was heavily built, sturdy, and of considerable stature, although not exceptionally so, since his height was seven times the length of his own foot. He had a round head, large and lively eyes, a slightly larger nose than usual, white but still attractive hair, a bright and cheerful expression, a short and fat neck, and he enjoyed good health, except for the fevers that affected him in the last few years of his life. Toward the end, he dragged one leg. Even then, he stubbornly did what he wanted and refused to listen to doctors, indeed he detested them, because they wanted to persuade him to stop eating roast meat, as was his wont, and to be content with boiled meat."
The physical portrait provided by Einhard is confirmed by contemporary depictions of the emperor, such as coins and his bronze statuette kept in the Louvre. In 1861, Charlemagne's tomb was opened by scientists who reconstructed his skeleton and estimated it to be measured . An estimate of his height from a X-ray and CT Scan of his tibia performed in 2010 is . This puts him in the 99th percentile of tall people of his period, given that average male height of his time was . The width of the bone suggested he was gracile but not robust in body build.
Dress.
Charlemagne wore the traditional costume of the Frankish people, described by Einhard thus:
"He used to wear the national, that is to say, the Frank, dress—next his skin a linen shirt and linen breeches, and above these a tunic fringed with silk; while hose fastened by bands covered his lower limbs, and shoes his feet, and he protected his shoulders and chest in winter by a close-fitting coat of otter or marten skins."
He wore a blue cloak and always carried a sword with him. The typical sword was of a golden or silver hilt. He wore fancy jewelled swords to banquets or ambassadorial receptions. Nevertheless:
"He despised foreign costumes, however handsome, and never allowed himself to be robed in them, except twice in Rome, when he donned the Roman tunic, chlamys, and shoes; the first time at the request of Pope Hadrian, the second to gratify Leo, Hadrian's successor."
He could rise to the occasion when necessary. On great feast days, he wore embroidery and jewels on his clothing and shoes. He had a golden buckle for his cloak on such occasions and would appear with his great diadem, but he despised such apparel, according to Einhard, and usually dressed like the common people.
Family.
Marriages and heirs.
Charlemagne had eighteen children over the course of his life with eight of his ten known wives or concubines. Nonetheless, he only had four legitimate grandsons, the four sons of his fourth son, Louis. In addition, he had a grandson (Bernard of Italy, the only son of his third son, Pippin of Italy), who was born illegitimate, but included in the line of inheritance. So, despite eighteen children, the claimants to his inheritance were few. Among Charlemagne descendants are the Habsburg and Plantagenet dynasties.
Name.
He was named Karl ("Charles" in French and English, "Carolus" in Latin) after his grandfather, Charles Martel. Later Old French historians dubbed him "Charles le Magne" (Charles the Great), becoming Charlemagne in English after the Norman conquest of England. The epithet Carolus Magnus was widely used, leading to numerous translations into many languages of Europe. He was known in German as Karl der Große; Dutch, Karel de Grote; Danish/Norwegian/Swedish, Karl den Store; Italian, Carlo Magno; Catalan, Carlemany; Bosnian, Croatian and Serbian, Karlo Veliki; Spanish, Carlomagno; Portuguese, Carlos Magno; and various others.
Charles' achievements gave a new meaning to his name. In many European languages, the very word for "king" derives from his name; e.g., , , , , , , , , , , , , , , . This development parallels that of the name of the Caesars in the original Roman Empire, which became "kaiser" and "czar", among others.
Beatification.
Charlemagne was accorded sainthood inside the Holy Roman Empire after the twelfth century. His canonisation by Antipope Paschal III, to gain the favour of Frederick Barbarossa in 1165, was never recognised by the Holy See, which annulled all of Paschal's ordinances at the Third Lateran Council in 1179. His name does not appear among the 28 saints named Charles who are listed in the Roman Martyrology. His beatification has been acknowledged as "cultus confirmed" and is celebrated on 28 January.
Cultural uses.
Middle ages.
Charlemagne had an immediate afterlife. The author of the "Visio Karoli Magni" written around 865 uses facts gathered apparently from Einhard and his own observations on the decline of Charlemagne's family after the dissensions war (840–43) as the basis for a visionary tale of Charles' meeting with a prophetic spectre in a dream.
Charlemagne, being a model knight as one of the Nine Worthies, enjoyed an important afterlife in European culture. One of the great medieval literary cycles, the Charlemagne cycle or the "Matter of France", centres on the deeds of Charlemagne—the Emperor with the Flowing Beard of "Roland" fame—and his historical commander of the border with Brittany, Roland, and the paladins who are analogous to the knights of the Round Table or King Arthur's court. Their tales constitute the first "chansons de geste". In the Divine Comedy the spirit of Charlemagne appears to Dante in the Heaven of Mars, among the other "warriors of the faith."
Modern era.
In 1867, an equestrian statue of Charlemagne, was made by Louis Jehotte and was inaugurated in 1868 on the Boulevard d'Avroy in Liège. In the niches of the neo-roman pedestal are six statues of the ancestors of Charlemagne (Sainte Begge, Pépin de Herstal, Charles Martel, Bertrude, Pépin de Landen and Pépin le Bref).
The city of Aachen has, since 1949, awarded an international prize (called the "Karlspreis der Stadt Aachen") in honour of Charlemagne. It is awarded annually to "personages of merit who have promoted the idea of western unity by their political, economic and literary endeavours." Winners of the prize include Count Richard Coudenhove-Kalergi, the founder of the pan-European movement, Alcide De Gasperi, and Winston Churchill.
In its national anthem, El Gran Carlemany, the nation of Andorra credits Charlemagne with its independence.
In 1964, the young French singer France Gall released the hit song "Sacré Charlemagne" in which the lyrics blame the great king for imposing the burden of compulsory education on French children.
Charlemagne is quoted by Dr Henry Jones Sr. (played by Sean Connery) in "Indiana Jones and the Last Crusade". After using his umbrella to induce a flock of seagulls to smash through the glass cockpit of a pursuing German fighter plane, Henry Jones remarks, "I suddenly remembered my Charlemagne: 'Let my armies be the rocks and the trees and the birds in the sky'." Despite the quote's popularity since the movie, there is no evidence that Charlemagne actually said this.
"The Economist", the weekly news and international affairs newspaper, features a one-page article every week entitled "Charlemagne", focusing generally on European affairs and, more usually and specifically, on the European Union and its politics.
There is a play named "Carelman Charitham" in the Indian art-form Chavittu Nadakam which is based on the life of Charlemagne.
Actor and singer Christopher Lee's Symphonic Metal concept album ' and its Heavy Metal follow-up ' feature the events of Charlemagne's life.
A 2010 episode of "QI" discussed the mathematics completed by Mark Humphrys that calculated that all modern Europeans are highly likely to share Charlemagne as a common ancestor. (also see Most Recent Common Ancestor)
The 2002 survival-horror video game "" contains a segment wherein the player takes control of one of Charlemagne's loyal messengers. The goal of the player is to protect the emperor against an insidious cult seeking to murder Charlemagne in order to stifle political and religious reform.
In April 2014, on the occasion of the 1200th anniversary of Charlemagne's death, there was a 2-week public art installation "Mein Karl" by Ottmar Hörl at Katschhof place between city hall and cathedral of Aachen, displaying 500 Charlemagne statues.
On 14 October 2014, the eighth major DLC for Crusader Kings II, a grand strategy game, was released. It focuses on Charlemagne's ascent to power, the formation of the Holy Roman Empire and the regions of Europe, India, and northern Africa.
Books and libraries.
Charlemagne was a lover of books, sometimes having them read to him during meals. He was thought to enjoy the works of St. Augustine. His court played a key role in producing books that taught elementary Latin and different aspects of the church. It also played a part in creating a royal library that contained in-depth works on language and Christian faith.
Despite his efforts to make every one of his subjects educated and literate, Charlemagne himself could not write. Late in life he attempted to learn, and even kept a wax tablet under his pillow to practice making letters on during his leisure hours, but with little progress. Though an excellent scholar in many other subjects, including language and mathematics, in the end he never learned to write.
Charlemagne encouraged clerics to translate Christian creeds and prayers into their respective vernaculars as well to teach grammar and music. Due to the increased interest of intellectual pursuits and the urging of their king, the monks accomplished so much copying that almost every manuscript from that time was preserved. At the same time, at the urging of their king, scholars were producing more secular books on many subjects, including history, poetry, art, music, law, theology, etc. Due to the increased number of titles, many private libraries came into being. These were mainly supported by aristocrats and churchmen who could afford to sustain them. At Charlemagne’s court, a library was founded and a number of copies of books were produced, to be distributed by Charlemagne. Book production was completed slowly by hand, and took place mainly in large monastic libraries. Books were so in demand during Charlemagne’s time that these libraries lent out some books, but only if that borrower offered valuable collateral in return. Most books, however, were held by chains in order to discourage theft. This made it difficult for multiple students to study one title, but helped ensure the safety of the tomes.
Charlemagne also employed Alcuin of York at his court. Originally from Northumbria in modern England, Alcuin was a proponent of education and wrote thoughtfully on Christian religion. Considered the greatest scholar of his day, he became the king's confidant and adviser. It was he who brought his interest in libraries to the king’s court. He was also a tutor to the king and his sons, teaching them liberal arts, theology, and astrology.

</doc>
<doc id="5315" url="https://en.wikipedia.org/wiki?curid=5315" title="Character encodings in HTML">
Character encodings in HTML

HTML (Hypertext Markup Language) has been in use since 1991, but HTML 4.0 (December 1997) was the first standardized version where international characters were given reasonably complete treatment. When an HTML document includes special characters outside the range of seven-bit ASCII two goals are worth considering: the information's integrity, and universal browser display.
Specifying the document's character encoding.
There are several ways to specify which character encoding is used in the document. First, the web server can include the character encoding or "codice_1" in the Hypertext Transfer Protocol (HTTP) codice_2 header, which would typically look like this:
This method gives the HTTP server a convenient way to alter document's encoding according to content negotiation; certain HTTP server software can do it, for example Apache with the module mod_charset_lite.
For HTML it is possible to include this information inside the codice_3 element near the top of the document:
HTML5 also allows the following syntax to mean exactly the same:
XHTML documents have a third option: to express the character encoding via XML declaration, as follows:
Note that as the character encoding can't be known until this declaration is parsed, there can be a problem knowing which encoding is used for the declaration itself. The main principle is that the declaration shall be encoded in pure ASCII, and therefore (if the declaration is inside the file) the encoding needs to be an ASCII extension. In order to allow encodings not backwards compatible with ASCII, browsers must be able to parse declarations in such encodings. Examples of such encodings are UTF-16BE and UTF-16LE.
As of HTML5 the recommended charset is UTF-8. An "encoding sniffing algorithm" is defined in the specification to determine the character encoding of the document based on multiple sources of input, including:
For ASCII-compatible character encodings the consequence of choosing incorrectly is that characters outside the printable ASCII range (32 to 126) usually appear incorrectly. This presents few problems for English-speaking users, but other languages regularly—in some cases, always—require characters outside that range. In CJK environments where there are several different multi-byte encodings in use, auto-detection is also often employed. Finally, browsers usually permit the user to override "incorrect" charset label manually as well.
It is increasingly common for multilingual websites and websites in non-Western languages to use UTF-8, which allows use of the same encoding for all languages. UTF-16 or UTF-32, which can be used for all languages as well, are less widely used because they can be harder to handle in programming languages that assume a byte-oriented ASCII superset encoding, and they are less efficient for text with a high frequency of ASCII characters, which is usually the case for HTML documents.
Successful viewing of a page is not necessarily an indication that its encoding is specified correctly. If the page's creator and reader are both assuming some platform-specific character encoding, and the server does not send any identifying information, then the reader will nonetheless see the page as the creator intended, but other readers on different platforms or with different native languages will not see the page as intended.
Character references.
In addition to native character encodings, characters can also be encoded as "character references", which can be "numeric character references" (decimal or hexadecimal) or "character entity references". Character entity references are also sometimes referred to as "named entities", or "HTML entities" for HTML. HTML's usage of character references derives from SGML.
HTML character references.
A "numeric character reference" in HTML refers to a character by its Universal Character Set/Unicode "code point", and uses the format
or
where "nnnn" is the code point in decimal form, and "hhhh" is the code point in hexadecimal form. The "x" must be lowercase in XML documents. The "nnnn" or "hhhh" may be any number of digits and may include leading zeros. The "hhhh" may mix uppercase and lowercase, though uppercase is the usual style.
Not all web browsers or email clients used by receivers of HTML documents, or text editors used by authors of HTML documents, will be able to render all HTML characters. Most modern software is able to display most or all of the characters for the user's language, and will draw a box or other clear indicator for characters they cannot render.
For codes from 0 to 127, the original 7-bit ASCII standard set, most of these characters can be used without a character reference. Codes from 160 to 255 can all be created using character entity names. Only a few higher-numbered codes can be created using entity names, but all can be created by decimal number character reference.
Character entity references can also have the format codice_6 where "name" is a case-sensitive alphanumeric string. For example, "λ" can also be encoded as codice_7 in an HTML document. The character entity references codice_8, codice_9, codice_10 and codice_11 are predefined in HTML and SGML, because codice_12, codice_13, codice_14 and codice_15 are already used to delimit markup. This notably does not include XML's codice_16 (') entity. For a list of all named HTML character entity references (about 250), see List of XML and HTML character entity references.
Unnecessary use of HTML character references may significantly reduce HTML readability. If the character encoding for a web page is chosen appropriately, then HTML character references are usually only required for markup delimiting characters as mentioned above, and for a few special characters (or none at all if a native Unicode encoding like UTF-8 is used). Incorrect HTML entity escaping may also open up security vulnerabilities for injection attacks such as cross-site scripting. If HTML attributes are left unquoted, certain characters, most importantly whitespace, such as space and tab, must be escaped using entities. Other languages related to HTML have their own methods of escaping characters.
XML character references.
Unlike traditional HTML with its large range of character entity references, in XML there are only five predefined character entity references. These are used to escape characters that are markup sensitive in certain contexts:
All other character entity references have to be defined before they can be used. For example, use of codice_22 (which gives é, Latin lower-case E with acute accent, U+00E9 in Unicode) in an XML document will generate an error unless the entity has already been defined. XML also requires that the codice_23 in hexadecimal numeric references be in lowercase: for example codice_24 rather than codice_25. XHTML, which is an XML application, supports the HTML entity set, along with XML's predefined entities.

</doc>
<doc id="5320" url="https://en.wikipedia.org/wiki?curid=5320" title="Carbon nanotube">
Carbon nanotube

Carbon nanotubes (CNTs) are allotropes of carbon with a cylindrical nanostructure. Nanotubes have been constructed with length-to-diameter ratio of up to 132,000,000:1, significantly larger than for any other material. These cylindrical carbon molecules have unusual properties, which are valuable for nanotechnology, electronics, optics and other fields of materials science and technology. In particular, owing to their extraordinary thermal conductivity and mechanical and electrical properties, carbon nanotubes find applications as additives to various structural materials. For instance, nanotubes form a tiny portion of the material(s) in some (primarily carbon fiber) baseball bats, golf clubs, car parts or damascus steel.
Nanotubes are members of the fullerene structural family. Their name is derived from their long, hollow structure with the walls formed by one-atom-thick sheets of carbon, called graphene. These sheets are rolled at specific and discrete ("chiral") angles, and the combination of the rolling angle and radius decides the nanotube properties; for example, whether the individual nanotube shell is a metal or semiconductor. Nanotubes are categorized as single-walled nanotubes (SWNTs) and multi-walled nanotubes (MWNTs). Individual nanotubes naturally align themselves into "ropes" held together by van der Waals forces, more specifically, pi-stacking.
Applied quantum chemistry, specifically, orbital hybridization best describes chemical bonding in nanotubes. The chemical bonding of nanotubes is composed entirely of "sp"2 bonds, similar to those of graphite. These bonds, which are stronger than the "sp"3 bonds found in alkanes and diamond, provide nanotubes with their unique strength.
Types of carbon nanotubes and related structures.
Terminology.
There is no consensus on some terms describing carbon nanotubes in scientific literature: both "-wall" and "-walled" are being used in combination with "single", "double", "triple" or "multi", and the letter C is often omitted in the abbreviation; for example, multi-walled carbon nanotube (MWNT).
Single-walled.
Most single-walled nanotubes (SWNTs) have a diameter of close to 1 nanometer, and can be many millions of times longer. The structure of a SWNT can be conceptualized by wrapping a one-atom-thick layer of graphite called graphene into a seamless cylinder. The way the graphene sheet is wrapped is represented by a pair of indices ("n","m"). The integers "n" and "m" denote the number of unit vectors along two directions in the honeycomb crystal lattice of graphene. If "m" = 0, the nanotubes are called zigzag nanotubes, and if "n" = "m", the nanotubes are called armchair nanotubes. Otherwise, they are called chiral. The diameter of an ideal nanotube can be calculated from its (n,m) indices as follows
where "a" = 0.246 nm.
SWNTs are an important variety of carbon nanotube because most of their properties change significantly with the ("n","m") values, and this dependence is non-monotonic (see Kataura plot). In particular, their band gap can vary from zero to about 2 eV and their electrical conductivity can show metallic or semiconducting behavior. Single-walled nanotubes are likely candidates for miniaturizing electronics. The most basic building block of these systems is the electric wire, and SWNTs with diameters of an order of a nanometer can be excellent conductors. One useful application of SWNTs is in the development of the first intermolecular field-effect transistors (FET). The first intermolecular logic gate using SWCNT FETs was made in 2001. A logic gate requires both a p-FET and an n-FET. Because SWNTs are p-FETs when exposed to oxygen and n-FETs otherwise, it is possible to protect half of an SWNT from oxygen exposure, while exposing the other half to oxygen. This results in a single SWNT that acts as a "not" logic gate with both p and n-type FETs within the same molecule.
Single-walled nanotubes are dropping precipitously in price, from around $1500 per gram as of 2000 to retail prices of around $50 per gram of as-produced 40–60% by weight SWNTs as of March 2010. As of 2016 the retail price of as-produced 75% by weight SWNTs drops to $2 per gram, cheap enough for widespread application [http://ocsial.com/en/product/tuball/].
SWNTs are forecast to make a large impact in electronics applications by 2020 according to "The Global Market for Carbon Nanotubes" report.
Multi-walled.
Multi-walled nanotubes (MWNTs) consist of multiple rolled layers (concentric tubes) of graphene. There are two models that can be used to describe the structures of multi-walled nanotubes. In the "Russian Doll" model, sheets of graphite are arranged in concentric cylinders, e.g., a (0,8) single-walled nanotube (SWNT) within a larger (0,17) single-walled nanotube. In the "Parchment" model, a single sheet of graphite is rolled in around itself, resembling a scroll of parchment or a rolled newspaper. The interlayer distance in multi-walled nanotubes is close to the distance between graphene layers in graphite, approximately 3.4 Å. The Russian Doll structure is observed more commonly. Its individual shells can be described as SWNTs, which can be metallic or semiconducting. Because of statistical probability and restrictions on the relative diameters of the individual tubes, one of the shells, and thus the whole MWNT, is usually a zero-gap metal.
Double-walled carbon nanotubes (DWNTs) form a special class of nanotubes because their morphology and properties are similar to those of SWNTs but their resistance to chemicals is significantly improved. This is especially important when functionalization is required (this means grafting of chemical functions at the surface of the nanotubes) to add new properties to the CNT. In the case of SWNTs, covalent functionalization will break some C=C double bonds, leaving "holes" in the structure on the nanotube and, thus, modifying both its mechanical and electrical properties. In the case of DWNTs, only the outer wall is modified. DWNT synthesis on the gram-scale was first proposed in 2003 by the CCVD technique, from the selective reduction of oxide solutions in methane and hydrogen.
The telescopic motion ability of inner shells and their unique mechanical properties will permit the use of multi-walled nanotubes as main movable arms in coming nanomechanical devices. Retraction force that occurs to telescopic motion caused by the Lennard-Jones interaction between shells and its value is about 1.5 nN.
Torus.
In theory, a nanotorus is a carbon nanotube bent into a torus (doughnut shape). Nanotori are predicted to have many unique properties, such as magnetic moments 1000 times larger than previously expected for certain specific radii. Properties such as magnetic moment, thermal stability, etc. vary widely depending on radius of the torus and radius of the tube.
Nanobud.
Carbon nanobuds are a newly created material combining two previously discovered allotropes of carbon: carbon nanotubes and fullerenes. In this new material, fullerene-like "buds" are covalently bonded to the outer sidewalls of the underlying carbon nanotube. This hybrid material has useful properties of both fullerenes and carbon nanotubes. In particular, they have been found to be exceptionally good field emitters. In composite materials, the attached fullerene molecules may function as molecular anchors preventing slipping of the nanotubes, thus improving the composite’s mechanical properties.
Three-dimensional carbon nanotube architectures.
Recently, several studies have highlighted the prospect of using carbon nanotubes as building blocks to fabricate three-dimensional macroscopic (>100 nm in all three dimensions) all-carbon devices. Lalwani et al. have reported a novel radical initiated thermal crosslinking method to fabricate macroscopic, free-standing, porous, all-carbon scaffolds using single- and multi-walled carbon nanotubes as building blocks. These scaffolds possess macro-, micro-, and nano- structured pores and the porosity can be tailored for specific applications. These 3D all-carbon scaffolds/architectures may be used for the fabrication of the next generation of energy storage, supercapacitors, field emission transistors, high-performance catalysis, photovoltaics, and biomedical devices and implants.
Graphenated carbon nanotubes (g-CNTs).
Graphenated CNTs are a relatively new hybrid that combines graphitic foliates grown along the sidewalls of multiwalled or bamboo style CNTs. Yu "et al." reported on "chemically bonded graphene leaves" growing along the sidewalls of CNTs. Stoner "et al." described these structures as "graphenated CNTs" and reported in their use for enhanced supercapacitor performance. Hsu "et al." further reported on similar structures formed on carbon fiber paper, also for use in supercapacitor applications. Pham "et al." also reported a similar structure, namely "graphene-carbon nanotube hybrids", grown directly onto carbon fiber paper to form an integrated, binder free, high surface area conductive catalyst support for Proton Exchange Membrane Fuel Cells electrode applications with enhanced performance and durability. The foliate density can vary as a function of deposition conditions (e.g. temperature and time) with their structure ranging from few layers of graphene (< 10) to thicker, more graphite-like.
The fundamental advantage of an integrated graphene-CNT structure is the high surface area three-dimensional framework of the CNTs coupled with the high edge density of graphene. Graphene edges provide significantly higher charge density and reactivity than the basal plane, but they are difficult to arrange in a three-dimensional, high volume-density geometry. CNTs are readily aligned in a high density geometry (i.e., a vertically aligned forest) but lack high charge density surfaces—the sidewalls of the CNTs are similar to the basal plane of graphene and exhibit low charge density except where edge defects exist. Depositing a high density of graphene foliates along the length of aligned CNTs can significantly increase the total charge capacity per unit of nominal area as compared to other carbon nanostructures.
Nitrogen-doped carbon nanotubes.
Nitrogen doped carbon nanotubes (N-CNTs) can be produced through five main methods, chemical vapor deposition, high-temperature and high-pressure reactions, gas-solid reaction of amorphous carbon with NH3 at high temperature, solid reaction, and solvothermal synthesis.
N-CNTs can also be prepared by a CVD method of pyrolyzing melamine under Ar at elevated temperatures of 800–980 °C. However synthesis by CVD of melamine results in the formation of bamboo-structured CNTs. XPS spectra of grown N-CNTs reveal nitrogen in five main components, pyridinic nitrogen, pyrrolic nitrogen, quaternary nitrogen, and nitrogen oxides. Furthermore, synthesis temperature affects the type of nitrogen configuration.
Nitrogen doping plays a pivotal role in lithium storage, as it creates defects in the CNT walls allowing for Li ions to diffuse into interwall space. It also increases capacity by providing more favorable bind of N-doped sites. N-CNTs are also much more reactive to metal oxide nanoparticle deposition which can further enhance storage capacity, especially in anode materials for Li-ion batteries. However boron-doped nanotubes have been shown to make batteries with triple capacity.
Peapod.
A carbon peapod is a novel hybrid carbon material which traps fullerene inside a carbon nanotube. It can possess interesting magnetic properties with heating and irradiation. It can also be applied as an oscillator during theoretical investigations and predictions.
Cup-stacked carbon nanotubes.
Cup-stacked carbon nanotubes (CSCNTs) differ from other quasi-1D carbon structures, which normally behave as quasi-metallic conductors of electrons. CSCNTs exhibit semiconducting behaviors due to the stacking microstructure of graphene layers.
Extreme carbon nanotubes.
The observation of the "longest" carbon nanotubes grown so far are over 1/2 m (550 mm long) was reported in 2013. These nanotubes were grown on Si substrates using an improved chemical vapor deposition (CVD) method and represent electrically uniform arrays of single-walled carbon nanotubes.
The "shortest" carbon nanotube is the organic compound cycloparaphenylene, which was synthesized in early 2009.
The "thinnest" carbon nanotube is the armchair (2,2) CNT with a diameter of 0.3 nm. This nanotube was grown inside a multi-walled carbon nanotube. Assigning of carbon nanotube type was done by a combination of high-resolution transmission electron microscopy (HRTEM), Raman spectroscopy and density functional theory (DFT) calculations.
The "thinnest freestanding" single-walled carbon nanotube is about 0.43 nm in diameter. Researchers suggested that it can be either (5,1) or (4,2) SWCNT, but the exact type of carbon nanotube remains questionable. (3,3), (4,3) and (5,1) carbon nanotubes (all about 0.4 nm in diameter) were unambiguously identified using aberration-corrected high-resolution transmission electron microscopy inside double-walled CNTs.
The "highest density" of CNTs was achieved in 2013, grown on a conductive titanium-coated copper surface that was coated with co-catalysts cobalt and molybdenum at lower than typical temperatures of 450 °C. The tubes averaged a height of 380 nm and a mass density of 1.6 g cm−3. The material showed ohmic conductivity (lowest resistance ∼22 kΩ).
Properties.
Strength.
Carbon nanotubes are the strongest and stiffest materials yet discovered in terms of tensile strength and elastic modulus respectively. This strength results from the covalent sp2 bonds formed between the individual carbon atoms. In 2000, a multi-walled carbon nanotube was tested to have a tensile strength of . (For illustration, this translates into the ability to endure tension of a weight equivalent to on a cable with cross-section of .) Further studies, such as one conducted in 2008, revealed that individual CNT shells have strengths of up to ~, which is in agreement with quantum/atomistic models. Since carbon nanotubes have a low density for a solid of 1.3 to 1.4 g/cm3, its specific strength of up to 48,000 kN·m·kg−1 is the best of known materials, compared to high-carbon steel's 154 kN·m·kg−1.
Under excessive tensile strain, the tubes will undergo plastic deformation, which means the deformation is permanent. This deformation begins at strains of approximately 5% and can increase the maximum strain the tubes undergo before fracture by releasing strain energy.
Although the strength of individual CNT shells is extremely high, weak shear interactions between adjacent shells and tubes lead to significant reduction in the effective strength of multi-walled carbon nanotubes and carbon nanotube bundles down to only a few GPa. This limitation has been recently addressed by applying high-energy electron irradiation, which crosslinks inner shells and tubes, and effectively increases the strength of these materials to ~60 GPa for multi-walled carbon nanotubes and ~17 GPa for double-walled carbon nanotube bundles.
CNTs are not nearly as strong under compression. Because of their hollow structure and high aspect ratio, they tend to undergo buckling when placed under compressive, torsional, or bending stress.
EExperimental observation; TTheoretical prediction
The above discussion referred to axial properties of the nanotube, whereas simple geometrical considerations suggest that carbon nanotubes should be much softer in the radial direction than along the tube axis. Indeed, TEM observation of radial elasticity suggested that even the van der Waals forces can deform two adjacent nanotubes. Nanoindentation experiments, performed by several groups on multiwalled carbon nanotubes and tapping/contact mode atomic force microscope measurements performed on single-walled carbon nanotubes, indicated a Young's modulus of the order of several GPa, confirming that CNTs are indeed rather soft in the radial direction.
Hardness.
Standard single-walled carbon nanotubes can withstand a pressure up to 25 GPa without [plastic/permanent] deformation. They then undergo a transformation to superhard phase nanotubes. Maximum pressures measured using current experimental techniques are around 55 GPa. However, these new superhard phase nanotubes collapse at an even higher, albeit unknown, pressure.
The bulk modulus of superhard phase nanotubes is 462 to 546 GPa, even higher than that of diamond (420 GPa for single diamond crystal).
Wettability.
The surface wettability of CNT is of importance for its applications in various settings. Although the intrinsic contact angle of graphite is around 90°, the contact angles of most as-synthesized CNT arrays are over 160°, exhibiting a superhydrophobic property. By applying a low voltage as low as 1.3V, the extreme water repellant surface can be switched into superhydrophilic.
Kinetic properties.
Multi-walled nanotubes are multiple concentric nanotubes precisely nested within one another. These exhibit a striking telescoping property whereby an inner nanotube core may slide, almost without friction, within its outer nanotube shell, thus creating an atomically perfect linear or rotational bearing.
This is one of the first true examples of molecular nanotechnology, the precise positioning of atoms to create useful machines. Already, this property has been utilized to create the world's smallest rotational motor. Future applications such as a gigahertz mechanical oscillator are also envisioned.
Electrical properties.
Because of the symmetry and unique electronic structure of graphene, the structure of a nanotube strongly affects its electrical properties. For a given ("n","m") nanotube, if "n" = "m", the nanotube is metallic; if "n" − "m" is a multiple of 3, then the nanotube is semiconducting with a very small band gap, otherwise the nanotube is a moderate semiconductor. Thus all armchair ("n" = "m") nanotubes are metallic, and nanotubes (6,4), (9,1), etc. are semiconducting.
However, this rule has exceptions, because curvature effects in small diameter tubes can strongly influence electrical properties. Thus, a (5,0) SWCNT that should be semiconducting in fact is metallic according to the calculations. Likewise, zigzag and chiral SWCNTs with small diameters that should be metallic have a finite gap (armchair nanotubes remain metallic). In theory, metallic nanotubes can carry an electric current density of 4 × 109 A/cm2, which is more than 1,000 times greater than those of metals such as copper, where for copper interconnects current densities are limited by electromigration.
Because of its nanoscale cross-section, electrons propagate only along the tube's axis. As a result, carbon nanotubes are frequently referred to as one-dimensional conductors. The maximum electrical conductance of a single-walled carbon nanotube is 2"G"0, where "G"0 = 2"e"2/"h" is the conductance of a single ballistic quantum channel.
Intrinsic superconductivity has been reported,</ref> although other experiments found no evidence of this, leaving the claim a subject of debate.
Thermal properties.
All nanotubes are expected to be very good thermal conductors along the tube, exhibiting a property known as "ballistic conduction", but good insulators laterally to the tube axis. Measurements show that a SWNT has a room-temperature thermal conductivity along its axis of about 3500 W·m−1·K−1; compare this to copper, a metal well known for its good thermal conductivity, which transmits 385 W·m−1·K−1. A SWNT has a room-temperature thermal conductivity across its axis (in the radial direction) of about 1.52 W·m−1·K−1, which is about as thermally conductive as soil. The temperature stability of carbon nanotubes is estimated to be up to 2800 °C in vacuum and about 750 °C in air.
Defects.
As with any material, the existence of a crystallographic defect affects the material properties. Defects can occur in the form of atomic vacancies. High levels of such defects can lower the tensile strength by up to 85%. An important example is the Stone Wales defect, which creates a pentagon and heptagon pair by rearrangement of the bonds. Because of the very small structure of CNTs, the tensile strength of the tube is dependent on its weakest segment in a similar manner to a chain, where the strength of the weakest link becomes the maximum strength of the chain.
Crystallographic defects also affect the tube's electrical properties. A common result is lowered conductivity through the defective region of the tube. A defect in armchair-type tubes (which can conduct electricity) can cause the surrounding region to become semiconducting, and single monatomic vacancies induce magnetic properties.
Crystallographic defects strongly affect the tube's thermal properties. Such defects lead to phonon scattering, which in turn increases the relaxation rate of the phonons. This reduces the mean free path and reduces the thermal conductivity of nanotube structures. Phonon transport simulations indicate that substitutional defects such as nitrogen or boron will primarily lead to scattering of high-frequency optical phonons. However, larger-scale defects such as Stone Wales defects cause phonon scattering over a wide range of frequencies, leading to a greater reduction in thermal conductivity.
Safety and Health.
Toxicity.
The toxicity of carbon nanotubes has been an important question in nanotechnology. As of 2007, such research had just begun. The data is still fragmentary and subject to criticism. Preliminary results highlight the difficulties in evaluating the toxicity of this heterogeneous material. Parameters such as structure, size distribution, surface area, surface chemistry, surface charge, and agglomeration state as well as purity of the samples, have considerable impact on the reactivity of carbon nanotubes. However, available data clearly show that, under some conditions, nanotubes can cross membrane barriers, which suggests that, if raw materials reach the organs, they can induce harmful effects such as inflammatory and fibrotic reactions.
Under certain conditions CNTs can enter human cells and accumulate in the cytoplasm, causing cell death.
Results of rodent studies collectively show that regardless of the process by which CNTs were synthesized and the types and amounts of metals they contained, CNTs were capable of producing inflammation, epithelioid granulomas (microscopic nodules), fibrosis, and biochemical/toxicological changes in the lungs. Comparative toxicity studies in which mice were given equal weights of test materials showed that SWCNTs were more toxic than quartz, which is considered a serious occupational health hazard when chronically inhaled. As a control, ultrafine carbon black was shown to produce minimal lung responses.
Carbon nanotubes deposit in the alveolar ducts by aligning lengthwise with the airways; the nanotubes will often combine with metals. The needle-like fiber shape of CNTs is similar to asbestos fibers. This raises the idea that widespread use of carbon nanotubes may lead to pleural mesothelioma, a cancer of the lining of the lungs, or peritoneal mesothelioma, a cancer of the lining of the abdomen (both caused by exposure to asbestos). A recently published pilot study supports this prediction. Scientists exposed the mesothelial lining of the body cavity of mice to long multiwalled carbon nanotubes and observed asbestos-like, length-dependent, pathogenic behavior that included inflammation and formation of lesions known as granulomas.
Authors of the study conclude:
Although further research is required, the available data suggest that under certain conditions, especially those involving chronic exposure, carbon nanotubes can pose a serious risk to human health.
In 2014, experts from the International Agency for Research on Cancer (IARC) assessed the carcinogenicity of CNTs, including SWCNTs and MWCNTs. No human epidemiologic or cancer data was available to the IARC Working Group at the time, so the evaluation focused on the results of "in vivo" animal studies assessing the carcinogenicity of SWCNTs and MWCNTs in rodents.
The Working Group concluded that there was sufficient evidence for the specific MWCNT type “MWCNT-7”, limited evidence for the two other types of MWCNTs with dimensions similar to MWCNT-7, and inadequate evidence for SWCNTs. Therefore, it was agreed to specifically classify MWCNT-7 as possibly carcinogenic to humans (Group 2B) while the other forms of CNT, namely SWCNT and other types of MWCNT, excluding MWCNT-7, were considered not classifiable as to their carcinogenicity to humans (Group 3) due to a lack of coherent evidence.
Epidemiology and Risk Management.
Currently, there is a lack of epidemiological evidence linking exposure to CNT to human health effects. To date, there have been only a handful of published epidemiological studies that have solely examined the health effects related to the exposure of CNT, while several other studies are currently underway and yet to be published. With the limited amount of human data, scientists are more reliant on the results of current animal toxicity studies to predict adverse health effects, as well as applying what is already known about exposures to other fibrous materials such as asbestos or fine and ultra-fine particulates. This limitation of human data has lead to the use of the precautionary principle, which urges workplaces to limit exposure levels to CNT as low as possibly achievable in the absence of known health effects data.
To date, several international government agencies, as well as individual authors, have developed occupational exposure limits (OEL) to reduce the risk of any possible human health effects associated with workplace exposures to CNT. The National Institute for Occupational Safety and Health (NIOSH) conducted a risk assessment using animal and other toxicological data relevant to assessing the potential non-malignant adverse respiratory effects of CNT and proposed an OEL of 1 μg/m3 elemental carbon as a respirable mass 8-hour time-weighted average (TWA) concentration. Several individual authors have also performed similar risk assessments using animal toxicity data and have established inhalation exposure limits ranging from 2.5 to 50 ug/m3.
Safety and Exposure Prevention.
Occupational exposures that could potentially allow the inhalation of CNT is of the greatest concern, especially in situations where the CNT is handled in powder form which can easily be aerosolized and inhaled. Also of concern are any high-energy processes that are applied to various CNT preparations such as the mixing or sonication of CNT in liquids as well as processes that cut or drill into CNT based composites in downstream products. These types of high-energy processes will aerosolize CNT which can then be inhaled.
Guidance for minimizing exposure and risk to CNT have been published by several international agencies which includes several documents from the British Health and Safety Executive titled "Using nanomaterials at work Including carbon nanotubes and other bio-persistent high aspect ratio nanomaterials" and the "Risk Management of Carbon Nanotubes" Safe Work Australia has also published guidance titled "Safe Handling and use of Carbon Nanotubes" which describes two approaches to managing the risks that include risk management with detailed hazard analysis and exposure assessment as well as risk management by using Control Banding. The National Institute for Occupational Safety and Health has also published a document titled "Current Intelligence Bulletin 65: Occupational Exposure to Carbon Nanotubes and Nanofibers" describes strategies for controlling workplace exposures and implementing a medical surveillance program.
These guidance documents generally advocate instituting the principles of the Hierarchy of Hazard Control which is a system used in industry to minimize or eliminate exposure to hazards. The hazard controls in the hierarchy are, in order of decreasing effectiveness:
Synthesis.
Techniques have been developed to produce nanotubes in sizable quantities, including arc discharge, laser ablation, high-pressure carbon monoxide disproportionation, and chemical vapor deposition (CVD). Most of these processes take place in a vacuum or with process gases. CVD growth of CNTs can occur in vacuum or at atmospheric pressure. Large quantities of nanotubes can be synthesized by these methods; advances in catalysis and continuous growth are making CNTs more commercially viable.
Arc discharge.
Nanotubes were observed in 1991 in the carbon soot of graphite electrodes during an arc discharge, by using a current of 100 amps, that was intended to produce fullerenes. However the first macroscopic production of carbon nanotubes was made in 1992 by two researchers at NEC's Fundamental Research Laboratory. The method used was the same as in 1991. During this process, the carbon contained in the negative electrode sublimates because of the high-discharge temperatures.
The yield for this method is up to 30% by weight and it produces both single- and multi-walled nanotubes with lengths of up to 50 micrometers with few structural defects.
Arc-discharge technique uses higher temperatures (above 1,700 °C) for CNT synthesis which typically causes the expansion of CNTs with fewer structural defects in comparison with other methods.
Laser ablation.
In laser ablation, a pulsed laser vaporizes a graphite target in a high-temperature reactor while an inert gas is bled into the chamber. Nanotubes develop on the cooler surfaces of the reactor as the vaporized carbon condenses. A water-cooled surface may be included in the system to collect the nanotubes.
This process was developed by Dr. Richard Smalley and co-workers at Rice University, who at the time of the discovery of carbon nanotubes, were blasting metals with a laser to produce various metal molecules. When they heard of the existence of nanotubes they replaced the metals with graphite to create multi-walled carbon nanotubes. Later that year the team used a composite of graphite and metal catalyst particles (the best yield was from a cobalt and nickel mixture) to synthesize single-walled carbon nanotubes.
The laser ablation method yields around 70% and produces primarily single-walled carbon nanotubes with a controllable diameter determined by the reaction temperature. However, it is more expensive than either arc discharge or chemical vapor deposition.
The effective equation for few cycle optical pulse dynamics was obtained by virtue of the Boltzmann collision-less equation solution for conduction band electrons of semiconductor carbon nanotubes in the case when medium with carbon nanotubes has spatially-modulated refractive index.
Plasma torch.
Single-walled carbon nanotubes can also be synthesized by a thermal plasma method. It was first invented in 2000 at INRS (Institut National de la Recherche Scientifique in Varennes, Canada), by Olivier Smiljanic. In this method, the aim is to reproduce the conditions prevailing in the arc discharge and laser ablation approaches, but a carbon-containing gas is used instead of graphite vapors to supply the carbon necessary for the production of SWNT. Doing so, the growth of SWNT is more efficient (decomposing a carbon containing gas can be 10 times less energy-consuming than graphite vaporization). It is also continuous and occurs at low cost. To produce a continuous process, a gas mixture composed of argon, ethylene and ferrocene is introduced into a microwave plasma torch, where it is atomized by the atmospheric pressure plasma, which has the form of an intense 'flame'. The fumes created by the flame are found to contain SWNT, metallic and carbon nanoparticles and amorphous carbon.
Another way to produce single-walled carbon nanotubes with a plasma torch, is to use the induction thermal plasma method, implemented in 2005 by groups from the University of Sherbrooke and the National Research Council of Canada. The method is similar to arc-discharge in that both use ionized gas to reach the high temperature necessary to vaporize carbon-containing substances and the metal catalysts necessary for the ensuing nanotube growth. The thermal plasma is induced by high frequency oscillating currents in a coil, and is maintained in flowing inert gas. Typically, a feedstock of carbon black and metal catalyst particles is fed into the plasma, and then cooled down to form single-walled carbon nanotubes. Different single-wall carbon nanotube diameter distributions can be synthesized.
The induction thermal plasma method can produce up to 2 grams of nanotube material per minute, which is higher than the arc-discharge or the laser ablation methods.
Chemical vapor deposition (CVD).
The catalytic vapor phase deposition of carbon was reported in 1952 and 1959, but it was not until 1993 that carbon nanotubes were formed by this process. In 2007, researchers at the University of Cincinnati (UC) developed a process to grow aligned carbon nanotube arrays of length 18 mm on a FirstNano ET3000 carbon nanotube growth system.
During CVD, a substrate is prepared with a layer of metal catalyst particles, most commonly nickel, cobalt, iron, or a combination. The metal nanoparticles can also be produced by other ways, including reduction of oxides or oxides solid solutions. The diameters of the nanotubes that are to be grown are related to the size of the metal particles. This can be controlled by patterned (or masked) deposition of the metal, annealing, or by plasma etching of a metal layer. The substrate is heated to approximately 700 °C. To initiate the growth of nanotubes, two gases are bled into the reactor: a process gas (such as ammonia, nitrogen or hydrogen) and a carbon-containing gas (such as acetylene, ethylene, ethanol or methane). Nanotubes grow at the sites of the metal catalyst; the carbon-containing gas is broken apart at the surface of the catalyst particle, and the carbon is transported to the edges of the particle, where it forms the nanotubes. This mechanism is still being studied. The catalyst particles can stay at the tips of the growing nanotube during growth, or remain at the nanotube base, depending on the adhesion between the catalyst particle and the substrate. Thermal catalytic decomposition of hydrocarbon has become an active area of research and can be a promising route for the bulk production of CNTs. Fluidised bed reactor is the most widely used reactor for CNT preparation. Scale-up of the reactor is the major challenge.
CVD is the most widely used method for the production of carbon nanotubes. For this purpose, the metal nanoparticles are mixed with a catalyst support such as MgO or Al2O3 to increase the surface area for higher yield of the catalytic reaction of the carbon feedstock with the metal particles. One issue in this synthesis route is the removal of the catalyst support via an acid treatment, which sometimes could destroy the original structure of the carbon nanotubes. However, alternative catalyst supports that are soluble in water have proven effective for nanotube growth.
If a plasma is generated by the application of a strong electric field during growth (plasma-enhanced chemical vapor deposition), then the nanotube growth will follow the direction of the electric field. By adjusting the geometry of the reactor it is possible to synthesize vertically aligned carbon nanotubes (i.e., perpendicular to the substrate), a morphology that has been of interest to researchers interested in electron emission from nanotubes. Without the plasma, the resulting nanotubes are often randomly oriented. Under certain reaction conditions, even in the absence of a plasma, closely spaced nanotubes will maintain a vertical growth direction resulting in a dense array of tubes resembling a carpet or forest.
Of the various means for nanotube synthesis, CVD shows the most promise for industrial-scale deposition, because of its price/unit ratio, and because CVD is capable of growing nanotubes directly on a desired substrate, whereas the nanotubes must be collected in the other growth techniques. The growth sites are controllable by careful deposition of the catalyst. In 2007, a team from Meijo University demonstrated a high-efficiency CVD technique for growing carbon nanotubes from camphor. Researchers at Rice University, until recently led by the late Richard Smalley, have concentrated upon finding methods to produce large, pure amounts of particular types of nanotubes. Their approach grows long fibers from many small seeds cut from a single nanotube; all of the resulting fibers were found to be of the same diameter as the original nanotube and are expected to be of the same type as the original nanotube.
Super-growth CVD.
Super-growth CVD (water-assisted chemical vapor deposition) was developed by Kenji Hata, Sumio Iijima and co-workers at AIST, Japan. In this process, the activity and lifetime of the catalyst are enhanced by addition of water into the CVD reactor. Dense millimeter-tall nanotube "forests", aligned normal to the substrate, were produced. The forests height could be expressed, as
In this equation, β is the initial growth rate and formula_3 is the characteristic catalyst lifetime.
Their specific surface exceeds 1,000 m2/g (capped) or 2,200 m2/g (uncapped), surpassing the value of 400–1,000 m2/g for HiPco samples. The synthesis efficiency is about 100 times higher than for the laser ablation method. The time required to make SWNT forests of the height of 2.5 mm by this method was 10 minutes in 2004. Those SWNT forests can be easily separated from the catalyst, yielding clean SWNT material (purity >99.98%) without further purification. For comparison, the as-grown HiPco CNTs contain about 5–35% of metal impurities; it is therefore purified through dispersion and centrifugation that damages the nanotubes. Super-growth avoids this problem. Patterned highly organized single-walled nanotube structures were successfully fabricated using the super-growth technique.
The mass density of super-growth CNTs is about 0.037 g/cm3. It is much lower than that of conventional CNT powders (~1.34 g/cm3), probably because the latter contain metals and amorphous carbon.
The super-growth method is basically a variation of CVD. Therefore, it is possible to grow material containing SWNT, DWNTs and MWNTs, and to alter their ratios by tuning the growth conditions. Their ratios change by the thinness of the catalyst. Many MWNTs are included so that the diameter of the tube is wide.
The vertically aligned nanotube forests originate from a "zipping effect" when they are immersed in a solvent and dried. The zipping effect is caused by the surface tension of the solvent and the van der Waals forces between the carbon nanotubes. It aligns the nanotubes into a dense material, which can be formed in various shapes, such as sheets and bars, by applying weak compression during the process. Densification increases the Vickers hardness by about 70 times and density is 0.55 g/cm3. The packed carbon nanotubes are more than 1 mm long and have a carbon purity of 99.9% or higher; they also retain the desirable alignment properties of the nanotubes forest.
Natural, incidental, and controlled flame environments.
Fullerenes and carbon nanotubes are not necessarily products of high-tech laboratories; they are commonly formed in such mundane places as ordinary flames, produced by burning methane, ethylene, and benzene, and they have been found in soot from both indoor and outdoor air. However, these naturally occurring varieties can be highly irregular in size and quality because the environment in which they are produced is often highly uncontrolled. Thus, although they can be used in some applications, they can lack in the high degree of uniformity necessary to satisfy the many needs of both research and industry. Recent efforts have focused on producing more uniform carbon nanotubes in controlled flame environments. Such methods have promise for large-scale, low-cost nanotube synthesis based on theoretical models, though they must compete with rapidly developing large scale CVD production.
Removal of catalysts.
Nanoscale metal catalysts are important ingredients for fixed- and fluidized-bed CVD synthesis of CNTs. They allow increasing the growth efficiency of CNTs and may give control over their structure and chirality. During synthesis, catalysts can convert carbon precursors into tubular carbon structures but can also form encapsulating carbon overcoats. Together with metal oxide supports they may therefore attach to or become incorporated into the CNT product. The presence of metal impurities can be problematic for many applications. Especially catalyst metals like nickel, cobalt or yttrium may be of toxicological concern. While unencapsulated catalyst metals may be readily removable by acid washing, encapsulated ones require oxidative treatment for opening their carbon shell. The effective removal of catalysts, especially of encapsulated ones, while preserving the CNT structure is a challenge and has been addressed in many studies. A new approach to break carbonaceaous catalyst encapsulations is based on rapid thermal annealing.
Application-related issues.
Many electronic applications of carbon nanotubes crucially rely on techniques of selectively producing either semiconducting or metallic CNTs, preferably of a certain chirality. Several methods of separating semiconducting and metallic CNTs are known, but most of them are not yet suitable for large-scale technological processes. The most efficient method relies on density-gradient ultracentrifugation, which separates surfactant-wrapped nanotubes by the minute difference in their density. This density difference often translates into difference in the nanotube diameter and (semi)conducting properties. Another method of separation uses a sequence of freezing, thawing, and compression of SWNTs embedded in agarose gel. This process results in a solution containing 70% metallic SWNTs and leaves a gel containing 95% semiconducting SWNTs. The diluted solutions separated by this method show various colors. The separated carbon nanotubes using this method have been applied to electrodes, e.g. electric double-layer capacitor. Moreover, SWNTs can be separated by the column chromatography method. Yield is 95% in semiconductor type SWNT and 90% in metallic type SWNT.
In addition to separation of semiconducting and metallic SWNTs, it is possible to sort SWNTs by length, diameter, and chirality. The highest resolution length sorting, with length variation of <10%, has thus far been achieved by size exclusion chromatography (SEC) of DNA-dispersed carbon nanotubes (DNA-SWNT). SWNT diameter separation has been achieved by density-gradient ultracentrifugation (DGU) using surfactant-dispersed SWNTs and by ion-exchange chromatography (IEC) for DNA-SWNT. Purification of individual chiralities has also been demonstrated with IEC of DNA-SWNT: specific short DNA oligomers can be used to isolate individual SWNT chiralities. Thus far, 12 chiralities have been isolated at purities ranging from 70% for (8,3) and (9,5) SWNTs to 90% for (6,5), (7,5) and (10,5)SWNTs. There have been successful efforts to integrate these purified nanotubes into devices, e. g. FETs.
An alternative to separation is development of a selective growth of semiconducting or metallic CNTs. Recently, a new CVD recipe that involves a combination of ethanol and methanol gases and quartz substrates resulting in horizontally aligned arrays of 95–98% semiconducting nanotubes was announced.
Nanotubes are usually grown on nanoparticles of magnetic metal (Fe, Co), which facilitates production of electronic (spintronic) devices. In particular, control of current through a field-effect transistor by magnetic field has been demonstrated in such a single-tube nanostructure.
Chemical modification.
Carbon nanotubes can be functionalized to attain desired properties that can be used in a wide variety of applications. The two main methods of carbon nanotube functionalization are covalent and non-covalent modifications. Because of their hydrophobic nature, carbon nanotubes tend to agglomerate hindering their dispersion is solvents or viscous polymer melts. The resulting nanotube bundles or aggregates reduce the mechanical performance of the final composite. The surface of the carbon nanotubes can be modified to reduce the hydrophobicity and improve interfacial adhesion to a bulk polymer through chemical attachment.
Current applications.
Current use and application of nanotubes has mostly been limited to the use of bulk nanotubes, which is a mass of rather unorganized fragments of nanotubes. Bulk nanotube materials may never achieve a tensile strength similar to that of individual tubes, but such composites may, nevertheless, yield strengths sufficient for many applications. Bulk carbon nanotubes have already been used as composite fibers in polymers to improve the mechanical, thermal and electrical properties of the bulk product.
Other current applications include:
There is also ongoing research in using carbon nanotubes as a scaffold for diverse microfabrication techniques.
Potential applications.
The strength and flexibility of carbon nanotubes makes them of potential use in controlling other nanoscale structures, which suggests they will have an important role in nanotechnology engineering. The highest tensile strength of an individual multi-walled carbon nanotube has been tested to be 63 GPa. Carbon nanotubes were found in Damascus steel from the 17th century, possibly helping to account for the legendary strength of the swords made of it. Recently, several studies have highlighted the prospect of using carbon nanotubes as building blocks to fabricate three-dimensional macroscopic (>1mm in all three dimensions) all-carbon devices. Lalwani et al. have reported a novel radical initiated thermal crosslinking method to fabricated macroscopic, free-standing, porous, all-carbon scaffolds using single- and multi-walled carbon nanotubes as building blocks. These scaffolds possess macro-, micro-, and nano- structured pores and the porosity can be tailored for specific applications. These 3D all-carbon scaffolds/architectures maybe used for the fabrication of the next generation of energy storage, supercapacitors, field emission transistors, high-performance catalysis, photovoltaics, and biomedical devices and implants.
Biomedical.
Researchers from Rice University and State University of New York - Stony Brook have shown that the addition of low weight % of carbon nanotubes can lead to significant improvements in the mechanical properties of biodegradable polymeric nanocomposites for applications in tissue engineering including bone, cartilage, muscle and nerve tissue. Dispersion of low weight % of graphene (~0.02 wt.%) results in significant increases in compressive and flexural mechanical properties of polymeric nanocomposites. Researchers at Rice University, Stony Brook University, Radboud University Nijmegen Medical Centre and University of California, Riverside have shown that carbon nanotubes and their polymer nanocomposites are suitable scaffold materials for bone tissue engineering and bone formation.
In November 2012 researchers at the American National Institute of Standards and Technology (NIST) proved that single-wall carbon nanotubes may help protect DNA molecules from damage by oxidation.
A highly effective method of delivering carbon nanotubes into cells is Cell squeezing, a high-throughput vector-free microfluidic platform for intracellular delivery developed at the Massachusetts Institute of Technology in the labs of Robert S. Langer.
Carbon nanotubes have furthermore been grown inside microfluidic channels for chemical analysis, based on electrochromatography. Here, the high surface-area-to-volume ratio and high hydrophobicity of CNTs are used in order to greatly decrease the analysis time of small neutral molecules that typically require large bulky equipment for analysis.
Structural.
Because of the carbon nanotube's superior mechanical properties, many structures have been proposed ranging from everyday items like clothes and sports gear to combat jackets and space elevators. However, the space elevator will require further efforts in refining carbon nanotube technology, as the practical tensile strength of carbon nanotubes must be greatly improved.
For perspective, outstanding breakthroughs have already been made. Pioneering work led by Ray H. Baughman at the NanoTech Institute has shown that single and multi-walled nanotubes can produce materials with toughness unmatched in the man-made and natural worlds.
Carbon nanotubes are also a promising material as building blocks in hierarchical composite materials given their exceptional mechanical properties (~1 TPa in modulus, and ~100 GPa in strength). Initial attempts to incorporate CNTs into hierarchical structures (such as yarns, fibres or films) has led to mechanical properties that were significantly lower than these potential limits. Windle "et al." have used an "in situ" chemical vapor deposition (CVD) spinning method to produce continuous CNT yarns from CVD-grown CNT aerogels. CNT yarns can also be manufactured by drawing out CNT bundles from a CNT forest and subsequently twisting to form the fibre (draw-twist method, see picture on right). The Windle group have fabricated CNT yarns with strengths as high as ~9 GPa at small gage lengths of ~1 mm, however, strengths of only about ~1 GPa were reported at the longer gage length of 20 mm. The reason why fibre strengths have been low compared to the strength of individual CNTs is due to a failure to effectively transfer load to the constituent (discontinuous) CNTs within the fibre. One potential route for alleviating this problem is via irradiation (or deposition) induced covalent inter-bundle and inter-CNT cross-linking to effectively 'join up' the CNTs. Espinosa "et al." developed high performance DWNT-polymer composite yarns by twisting and stretching ribbons of randomly oriented bundles of DWNTs thinly coated with polymeric organic compounds. These DWNT-polymer yarns exhibited an unusually high energy to failure of ~100 J·g−1 (comparable to one of the toughest natural materials – spider silk), and strength as high as ~1.4 GPa. Effort is ongoing to produce CNT composites that incorporate tougher matrix materials, such as Kevlar, to further improve on the mechanical properties toward those of individual CNTs.
Because of the high mechanical strength of carbon nanotubes, research is being made into weaving them into clothes to create stab-proof and bulletproof clothing. The nanotubes would effectively stop the bullet from penetrating the body, although the bullet's kinetic energy would likely cause broken bones and internal bleeding.
Electrical circuits.
Nanotube-based transistors, also known as carbon nanotube field-effect transistors (CNTFETs), have been made that operate at room temperature and that are capable of digital switching using a single electron. However, one major obstacle to realization of nanotubes has been the lack of technology for mass production. In 2001 IBM researchers demonstrated how metallic nanotubes can be destroyed, leaving semiconducting ones behind for use as transistors. Their process is called "constructive destruction," which includes the automatic destruction of defective nanotubes on the wafer. This process, however, only gives control over the electrical properties on a statistical scale.
The potential of carbon nanotubes was demonstrated in 2003 when room-temperature ballistic transistors with ohmic metal contacts and high-k gate dielectric were reported, showing 20–30x higher ON current than state-of-the-art Si MOSFETs. This presented an important advance in the field as CNT was shown to potentially outperform Si. At the time, a major challenge was ohmic metal contact formation. In this regard, palladium, which is a high-work function metal was shown to exhibit Schottky barrier-free contacts to semiconducting nanotubes with diameters >1.7 nm.
The first nanotube integrated memory circuit was made in 2004. One of the main challenges has been regulating the conductivity of nanotubes. Depending on subtle surface features a nanotube may act as a plain conductor or as a semiconductor. A fully automated method has however been developed to remove non-semiconductor tubes.
Another way to make carbon nanotube transistors has been to use random networks of them. By doing so one averages all of their electrical differences and one can produce devices in large scale at the wafer level. This approach was first patented by Nanomix Inc. (date of original application June 2002). It was first published in the academic literature by the United States Naval Research Laboratory in 2003 through independent research work. This approach also enabled Nanomix to make the first transistor on a flexible and transparent substrate.
Large structures of carbon nanotubes can be used for thermal management of electronic circuits. An approximately 1 mm–thick carbon nanotube layer was used as a special material to fabricate coolers, this material has very low density, ~20 times lower weight than a similar copper structure, while the cooling properties are similar for the two materials.
In 2013, researchers demonstrated a Turing-complete prototype micrometer-scale computer. Carbon nanotube transistors as logic-gate circuits with densities comparable to modern CMOS technology has not yet been demonstrated.
Electrical cables and wires.
Wires for carrying electric current may be fabricated from pure nanotubes and nanotube-polymer composites. It has already been demonstrated that carbon nanotube wires can successfully be used for power or data transmission. Recently small wires have been fabricated with specific conductivity exceeding copper and aluminum; these cables are the highest conductivity carbon nanotube and also highest conductivity non-metal cables.
Recently, composite of carbon nanotube and copper have been shown to exhibit nearly one hundred times higher current-carrying-capacity than pure copper or gold. Significantly, the electrical conductivity of such a composite is similar to pure Cu. Thus, this Carbon nanotube-copper (CNT-Cu) composite possesses the highest observed current-carrying capacity among electrical conductors. Thus for a given cross-section of electrical conductor, the CNT-Cu composite can withstand and transport one hundred times higher current compared to metals such as copper and gold.
Actuators.
The exceptional electrical and mechanical properties of carbon nanotubes have made them alternatives to the traditional electrical actuators for both microscopic and macroscopic applications. Carbon nanotubes are very good conductors of both electricity and heat, and they are also very strong and elastic molecules in certain directions.
Batteries.
Carbon nanotubes' (CNTs) exciting electronic properties have shown promise in the field of batteries, where typically they are being experimented as a new electrode material, particularly the anode for lithium ion batteries. This is due to the fact that the anode requires a relatively high reversible capacity at a potential close to metallic lithium, and a moderate irreversible capacity, observed thus far only by graphite-based composites, such as CNTs. They have shown to greatly improve capacity and cyclability of lithium-ion batteries, as well as the capability to be very effective buffering components, alleviating the degradation of the batteries that is typically due to repeated charging and discharging. Further, electronic transport in the anode can be greatly improved using highly metallic CNTs.
More specifically, CNTs have shown reversible capacities from 300 to 600 mAhg−1, with some treatments to them showing these numbers rise to up to 1000 mAhg−1. Meanwhile, graphite, which is most widely used as an anode material for these lithium batteries, has shown capacities of only 320 mAhg−1. By creating composites out of the CNTs, scientists see much potential in taking advantage of these exceptional capacities, as well as their excellent mechanical strength, conductivities, and low densities.
Paper batteries.
A paper battery is a battery engineered to use a paper-thin sheet of cellulose (which is the major constituent of regular paper, among other things) infused with aligned carbon nanotubes. The potential for these devices is great, as they may be manufactured via a roll-to-roll process, which would make it very low-cost, and they would be lightweight, flexible, and thin. In order to productively use paper electronics (or any thin electronic devices), the power source must be equally thin, thus indicating the need for paper batteries. Recently, it has been shown that surfaces coated with CNTs can be used to replace heavy metals in batteries. More recently, functional paper batteries have been demonstrated, where a lithium-ion battery is integrated on a single sheet of paper through a lamination process as a composite with Li4Ti5O12 (LTO) or LiCoO2 (LCO). The paper substrate would function well as the separator for the battery, where the CNT films function as the current collectors for both the anode "and" the cathode. These rechargeable energy devices show potential in RFID tags, functional packaging, or new disposable electronic applications.
Solar cells.
One of the promising applications of single-walled carbon nanotubes (SWNTs) is their use in solar panels, due to their strong UV/Vis-NIR absorption characteristics. Research has shown that they can provide a sizable increase in efficiency, even at their current unoptimized state. Solar cells developed at the New Jersey Institute of Technology use a carbon nanotube complex, formed by a mixture of carbon nanotubes and carbon buckyballs (known as fullerenes) to form snake-like structures. Buckyballs trap electrons, but they can't make electrons flow. Add sunlight to excite the polymers, and the buckyballs will grab the electrons. Nanotubes, behaving like copper wires, will then be able to make the electrons or current flow.
Additional research has been conducted on creating SWNT hybrid solar panels to increase the efficiency further. These hybrids are created by combining SWNT's with photo-excitable electron donors to increase the number of electrons generated. It has been found that the interaction between the photo-excited porphyrin and SWNT generates electro-hole pairs at the SWNT surfaces. This phenomenon has been observed experimentally, and contributes practically to an increase in efficiency up to 8.5%.
Hydrogen storage.
In addition to being able to store electrical energy, there has been some research in using carbon nanotubes to store hydrogen to be used as a fuel source. By taking advantage of the capillary effects of the small carbon nanotubes, it is possible to condense gases in high density inside single-walled nanotubes. This allows for gases, most notably hydrogen (H2), to be stored at high densities without being condensed into a liquid. Potentially, this storage method could be used on vehicles in place of gas fuel tanks for a hydrogen-powered car. A current issue regarding hydrogen-powered vehicles is the on-board storage of the fuel. Current storage methods involve cooling and condensing the H2 gas to a liquid state for storage which causes a loss of potential energy (25–45%) when compared to the energy associated with the gaseous state. Storage using SWNTs would allow one to keep the H2 in its gaseous state, thereby increasing the storage efficiency. This method allows for a volume to energy ratio slightly smaller to that of current gas powered vehicles, allowing for a slightly lower but comparable range.
An area of controversy and frequent experimentation regarding the storage of hydrogen by adsorption in carbon nanotubes is the efficiency by which this process occurs. The effectiveness of hydrogen storage is integral to its use as a primary fuel source since hydrogen only contains about one fourth the energy per unit volume as gasoline. Studies however show that what is the most important is the surface area of the materials used. Hence activated carbon with surface area of 2600 m2/g can store up to 5,8% w/w. In all these carbonaceous materials, hydrogen is stored by physisorption at 70-90K.
Experimental capacity.
One experiment sought to determine the amount of hydrogen stored in CNTs by utilizing elastic recoil detection analysis (ERDA). CNTs (primarily SWNTs) were synthesized via chemical vapor disposition (CVD) and subjected to a two-stage purification process including air oxidation and acid treatment, then formed into flat, uniform discs and exposed to pure, pressurized hydrogen at various temperatures. When the data was analyzed, it was found that the ability of CNTs to store hydrogen decreased as temperature increased. Moreover, the highest hydrogen concentration measured was ~0.18%; significantly lower than commercially viable hydrogen storage needs to be. A separate experimental work performed by using a gravimetric method also revealed the maximum hydrogen uptake capacity of CNTs to be as low as 0.2%.
Limitations on efficient hydrogen adsorption.
The biggest obstacle to efficient hydrogen storage using CNTs is the purity of the nanotubes. To achieve maximum hydrogen adsorption, there must be minimum graphene, amorphous carbon, and metallic deposits in the nanotube sample. Current methods of CNT synthesis require a purification step. However, even with pure nanotubes, the absorption capacity is only maximized under high pressures, which are undesirable in commercial fuel tanks.
Supercapacitor.
MIT Research Laboratory of Electronics uses nanotubes to improve supercapacitors. The activated charcoal used in conventional ultracapacitors has many small hollow spaces of various size, which create together a large surface to store electric charge. But as charge is quantized into elementary charges, i.e. electrons, and each such elementary charge needs a minimum space, a significant fraction of the electrode surface is not available for storage because the hollow spaces are not compatible with the charge's requirements. With a nanotube electrode the spaces may be tailored to size—few too large or too small—and consequently the capacity should be increased considerably.
Radar absorption.
Radars work in the microwave frequency range, which can be absorbed by MWNTs. Applying the MWNTs to the aircraft would cause the radar to be absorbed and therefore seem to have a smaller radar cross-section. One such application could be to paint the nanotubes onto the plane. Recently there has been some work done at the University of Michigan regarding carbon nanotubes usefulness as stealth technology on aircraft. It has been found that in addition to the radar absorbing properties, the nanotubes neither reflect nor scatter visible light, making it essentially invisible at night, much like painting current stealth aircraft black except much more effective. Current limitations in manufacturing, however, mean that current production of nanotube-coated aircraft is not possible. One theory to overcome these current limitations is to cover small particles with the nanotubes and suspend the nanotube-covered particles in a medium such as paint, which can then be applied to a surface, like a stealth aircraft.
Textile.
The previous studies on the use of CNTs for textile functionalization were focused on fiber spinning for improving physical and mechanical properties. Recently a great deal of attention has been focused on coating CNTs on textile fabrics. Various methods have been employed for modifying fabrics using CNTs. Shim et al. produced intelligent e-textiles for Human Biomonitoring using a polyelectrolyte-based coating with CNTs. Additionally, Panhuis et al. dyed textile material by immersion in either a poly (2-methoxy aniline-5-sulfonic acid) PMAS polymer solution or PMAS-SWNT dispersion with enhanced conductivity and capacitance with a durable behavior. In another study, Hu and coworkers coated single-walled carbon nanotubes with a simple “dipping and drying” process for wearable electronics and energy storage applications. In the recent study, Li and coworkers using elastomeric separator and almost achieved a fully stretchable supercapacitor based on buckled single-walled carbon nanotube macrofilms. The electrospun polyurethane was used and provided sound mechanical stretchability and the whole cell achieve excellent charge-discharge cycling stability. CNTs have an aligned nanotube structure and a negative surface charge. Therefore, they have similar structures to direct dyes, so the exhaustion method is applied for coating and absorbing CNTs on the fiber surface for preparing multifunctional fabric including antibacterial, electric conductive, flame retardant and electromagnetic absorbance properties.
Optical power detectors.
A spray-on mixture of carbon nanotubes and ceramic demonstrates unprecedented ability to resist damage while absorbing laser light. Such coatings that absorb as the energy of high-powered lasers without breaking down are essential for optical power detectors that measure the output of such lasers. These are used, for example, in military equipment for defusing unexploded mines. The composite consists of multiwall carbon nanotubes and a ceramic made of silicon, carbon and nitrogen. Including boron boosts the breakdown temperature. The nanotubes and graphene-like carbon transmit heat well, while the oxidation-resistant ceramic boosts damage resistance.
Creating the coating involves dispersing the nanotubes in toluene, to which a clear liquid polymer containing boron was added. The mixture was heated to . The result is crushed into a fine powder, dispersed again in toluene and sprayed in a thin coat on a copper surface.
The coating absorbed 97.5 percent of the light from a far-infrared laser and tolerated 15 kilowatts per square centimeter for 10 seconds. Damage tolerance is about 50 percent higher than for similar coatings, e.g., nanotubes alone and carbon paint.
Acoustics.
Carbon nanotubes have also been applied in the acoustics(such as loudspeaker and earphone). In 2008 it was shown that a sheet of nanotubes can operate as a loudspeaker if an alternating current is applied. The sound is not produced through vibration but thermoacoustically.
In 2013, a carbon nanotube (CNT) thin yarn thermoacoustic earphone together with CNT thin yarn thermoacoustic chip was demonstrated by a research group of Tsinghua-Foxconn Nanotechnology Research Center in Tsinghua University, using a Si-based semi-conducting technology compatible fabrication process.
Environmental remediation.
A CNT nano-structured sponge (nanosponge) containing sulfur and iron is more effective at soaking up water contaminants such as oil, fertilizers, pesticides and pharmaceuticals. Their magnetic properties make them easier to retrieve once the clean-up job is done. The sulfur and iron increases sponge size to around . It also increases porosity due to beneficial defects, creating buoyancy and reusability. Iron, in the form of ferrocene makes the structure easier to control and enables recovery using magnets. Such nanosponges increase the absorption of the toxic organic solvent dichlorobenzene from water by 3.5 times. The sponges can absorb vegetable oil up to 150 times their initial weight and can absorb engine oil as well.
Earlier, a magnetic boron-doped MWNT nanosponge that could absorb oil from water. The sponge was grown as a forest on a substrate via chemical vapor disposition. Boron puts kinks and elbows into the tubes as they grow and promotes the formation of covalent bonds. The nanosponges retain their elastic property after 10,000 compressions in the lab. The sponges are both superhydrophobic, forcing them to remain at the water's surface and oleophilic, drawing oil to them.
Water treatment.
It has been shown that carbon nanotubes exhibit strong adsorption affinities to a wide range of aromatic and aliphatic contaminants in water, due to their large and hydrophobic surface areas. They also showed similar adsorption capacities as activated carbons in the presence of natural organic matter. As a result, they have been suggested as promising adsorbents for removal of contaminant in water and wastewater treatment systems.
Moreover, membranes made out of carbon nanotube arrays have been suggested as switchable molecular sieves, with sieving and permeation features that can be dynamically activated/deactivated by either pore size distribution (passive control) or external electrostatic fields (active control).
Other applications.
Carbon nanotubes have been implemented in nanoelectromechanical systems, including mechanical memory elements (NRAM being developed by Nantero Inc.) and nanoscale electric motors (see Nanomotor or Nanotube nanomotor).
Carboxyl-modified single-walled carbon nanotubes (so called zig-zag, armchair type) can act as sensors of atoms and ions of alkali metals Na, Li, K. 
In May 2005, Nanomix Inc. placed on the market a hydrogen sensor that integrated carbon nanotubes on a silicon platform. Since then, Nanomix has been patenting many such sensor applications, such as in the field of carbon dioxide, nitrous oxide, glucose, DNA detection, etc. End of 2014, Tulane University researchers have tested Nanomix's fast and fully automated point of care diagnostic system in Sierra Leone to help for rapid testing for Ebola. Nanomix announced that a product could be launched within three to six months.
Eikos Inc of Franklin, Massachusetts and Unidym Inc. of Silicon Valley, California are developing transparent, electrically conductive films of carbon nanotubes to replace indium tin oxide (ITO). Carbon nanotube films are substantially more mechanically robust than ITO films, making them ideal for high-reliability touchscreens and flexible displays. Printable water-based inks of carbon nanotubes are desired to enable the production of these films to replace ITO. Nanotube films show promise for use in displays for computers, cell phones, PDAs, and ATMs.
A nanoradio, a radio receiver consisting of a single nanotube, was demonstrated in 2007.
A flywheel made of carbon nanotubes could be spun at extremely high velocity on a floating magnetic axis in a vacuum, and potentially store energy at a density approaching that of conventional fossil fuels. Since energy can be added to and removed from flywheels very efficiently in the form of electricity, this might offer a way of storing electricity, making the electrical grid more efficient and variable power suppliers (like wind turbines) more useful in meeting energy needs. The practicality of this depends heavily upon the cost of making massive, unbroken nanotube structures, and their failure rate under stress.
Carbon nanotube springs have the potential to indefinitely store elastic potential energy at ten times the density of lithium-ion batteries with flexible charge and discharge rates and extremely high cycling durability.
Ultra-short SWNTs (US-tubes) have been used as nanoscaled capsules for delivering MRI contrast agents in vivo.
Carbon nanotubes provide a certain potential for metal-free catalysis of inorganic and organic reactions. For instance, oxygen groups attached to the surface of carbon nanotubes have the potential to catalyze oxidative dehydrogenations or selective oxidations. Nitrogen-doped carbon nanotubes may replace platinum catalysts used to reduce oxygen in fuel cells. A forest of vertically aligned nanotubes can reduce oxygen in alkaline solution more effectively than platinum, which has been used in such applications since the 1960s. Here, the nanotubes have the added benefit of not being subject to carbon monoxide poisoning.
Wake Forest University engineers are using multiwalled carbon nanotubes to enhance the brightness of field-induced polymer electroluminescent technology, potentially offering a step forward in the search for safe, pleasing, high-efficiency lighting. In this technology, moldable polymer matrix emits light when exposed to an electric current. It could eventually yield high-efficiency lights without the mercury vapor of compact fluorescent lamps or the bluish tint of some fluorescents and LEDs, which has been linked with circadian rhythm disruption.
Candida albicans has been used in combination with carbon nanotubes (CNT) to produce stable electrically conductive bio-nano-composite tissue materials that have been used as temperature sensing elements.
The SWNT production company OCSiAl developed a series of masterbatches for industrial use of single-wall CNTs in multiple types of rubber blends and tires, with initial trials showing increases in hardness, viscosity, tensile strain resistance and resistance to abrasion while reducing elongation and compression In tires the three primary characteristics of durability, fuel efficiency and traction were improved using SWNTs. The development of 
rubber masterbatches built on earlier work by the Japanese National Institute of Advanced Industrial Science & Technology showing rubber to be a viable candidate for improvement with SWNTs.
Introducing MWNTs to polymers can improve flame retardancy and retard thermal degradation of polymer. The results confirmed that combination of MWNTs and ammonium polyphosphates show a synergistic effect for improving flame retardancy.
Discovery.
The true identity of the discoverers of carbon nanotubes is a subject of some controversy. For years, scientists assumed that Sumio Iijima of NEC had discovered carbon nanotubes in 1991. He published a paper describing his discovery which initiated a flurry of excitement and could be credited by inspiring the many scientists now studying applications of carbon nanotubes. Though Iijima has been given much of the credit for discovering carbon nanotubes, it turns out that the timeline of carbon nanotubes goes back much further than 1991.
In 1952 L. V. Radushkevich and V. M. Lukyanovich published clear images of 50 nanometer diameter tubes made of carbon in the Soviet "Journal of Physical Chemistry". This discovery was largely unnoticed, as the article was published in Russian, and Western scientists' access to Soviet press was limited during the Cold War. 
Before they came to be known as carbon nanotubes, in 1976, Morinobu Endo of CNRS observed hollow tubes of rolled up graphite sheets synthesised by a chemical vapour-growth technique. The first specimens observed would later come to be known as single-walled carbon nanotubes (SWNTs). The three scientists have been the first ones to show images of a nanotube with a solitary graphene wall.
Endo, in his early review of vapor-phase-grown carbon fibers (VPCF), also reminded us that he had observed a hollow tube, linearly extended with parallel carbon layer faces near the fiber core. This appears to be the observation of multi-walled carbon nanotubes at the center of the fiber. The mass-produced MWCNTs today are strongly related to the VPGCF developed by Endo. In fact, they call it the “Endo-process”, out of respect for his early work and patents.
In 1979, John Abrahamson presented evidence of carbon nanotubes at the 14th Biennial Conference of Carbon at Pennsylvania State University. The conference paper described carbon nanotubes as carbon fibers that were produced on carbon anodes during arc discharge. A characterization of these fibers was given as well as hypotheses for their growth in a nitrogen atmosphere at low pressures.
In 1981, a group of Soviet scientists published the results of chemical and structural characterization of carbon nanoparticles produced by a thermocatalytical disproportionation of carbon monoxide. Using TEM images and XRD patterns, the authors suggested that their “carbon multi-layer tubular crystals” were formed by rolling graphene layers into cylinders. They speculated that by rolling graphene layers into a cylinder, many different arrangements of graphene hexagonal nets are possible. They suggested two possibilities of such arrangements: circular arrangement (armchair nanotube) and a spiral, helical arrangement (chiral tube).
In 1987, Howard G. Tennent of Hyperion Catalysis was issued a U.S. patent for the production of "cylindrical discrete carbon fibrils" with a "constant diameter between about 3.5 and about 70 nanometers..., length 102 times the diameter, and an outer region of multiple essentially continuous layers of ordered carbon atoms and a distinct inner core..."
Iijima's discovery of multi-walled carbon nanotubes in the insoluble material of arc-burned graphite rods in 1991 and Mintmire, Dunlap, and White's independent prediction that if single-walled carbon nanotubes could be made, then they would exhibit remarkable conducting properties helped create the initial buzz that is now associated with carbon nanotubes. Nanotube research accelerated greatly following the independent discoveries by Bethune at IBM and Iijima at NEC of "single-walled" carbon nanotubes and methods to specifically produce them by adding transition-metal catalysts to the carbon in an arc discharge. The arc discharge technique was well-known to produce the famed Buckminster fullerene on a preparative scale, and these results appeared to extend the run of accidental discoveries relating to fullerenes. The discovery of nanotubes remains a contentious issue. Many believe that Iijima's report in 1991 is of particular importance because it brought carbon nanotubes into the awareness of the scientific community as a whole.
References.
"This article incorporates public domain text from National Institute of Environmental Health Sciences (NIEHS) as quoted."

</doc>
<doc id="5321" url="https://en.wikipedia.org/wiki?curid=5321" title="Czech Republic">
Czech Republic

The Czech Republic ( ; ), also known as Czechia ( ; ), is a nation state in Central Europe bordered by Germany to the west, Austria to the south, Slovakia to the east and Poland to the northeast. The Czech Republic covers an area of with mostly temperate continental climate. It is a unitary parliamentary republic, has 10.5 million inhabitants and the capital and largest city is Prague, with over 1.2 million residents. The Czech Republic includes its historical territories of Bohemia, Moravia, and Czech Silesia.
The Czech state was formed in the late 9th century as the Duchy of Bohemia under the Great Moravian Empire. After the fall of the Empire in 907, the centre of power transferred from Moravia to Bohemia under the Přemyslid dynasty. In 1004, the duchy was formally recognized as part of the Holy Roman Empire, becoming the Kingdom of Bohemia in 1212, and reaching its greatest territorial extent in the 14th century. Besides Bohemia itself, the king of Bohemia ruled the lands of the Bohemian Crown, he had a vote in the election of the Holy Roman Emperor, and Prague was the imperial seat in periods between the 14th and 17th century. In the Hussite wars of the 15th century driven by the Bohemian Reformation, the kingdom faced economic embargoes and defeated five crusades proclaimed by the leaders of the Roman Catholic Church.
Following the Battle of Mohács in 1526, the whole Crown of Bohemia was gradually integrated into the Habsburg Monarchy alongside the Archduchy of Austria and the Kingdom of Hungary. The Protestant Bohemian Revolt (1618–20) against the Catholic Habsburgs led to the Thirty Years' War, after which the monarchy consolidated its rule, reimposed Catholicism, and adopted a policy of gradual Germanization. With the dissolution of the Holy Roman Empire in 1806, the Bohemian Kingdom became part of the Austrian Empire and the Czech language experienced a revival as a consequence of widespread romantic nationalism. In the 19th century, the Czech lands became the industrial powerhouse of the monarchy and were subsequently the core of the Republic of Czechoslovakia, which was formed in 1918 following the collapse of the Austro-Hungarian Empire after World War I.
Czechoslovakia was occupied by Germany in World War II, and was liberated in 1945 by the Soviet and the United States Army. Most of the German-speaking inhabitants were expelled after the war and thus the country lost its sizable minority and its bilingual character. The Communist Party of Czechoslovakia won the 1946 elections. Following the 1948 coup d'état, Czechoslovakia became a one-party communist state under Soviet influence. In 1968, increasing dissatisfaction with the regime culminated in a reform movement known as the Prague Spring, which ended in a Soviet-led invasion. Czechoslovakia remained occupied until the 1989 Velvet Revolution, when the communist regime collapsed and a multiparty parliamentary republic was formed. On 1 January 1993, Czechoslovakia peacefully dissolved, with its constituent states becoming the independent states of the Czech Republic and Slovakia.
The Czech Republic joined NATO in 1999 and the European Union in 2004; it is a member of the United Nations, the OECD, the OSCE, and the Council of Europe. It is a developed country with an advanced, high income economy and high living standards. The UNDP ranks the country 14th in inequality-adjusted human development. The Czech Republic also ranks as the 10th most peaceful country, while achieving strong performance in democratic governance. The Czech Republic has the lowest unemployment rate in the European Union.
Etymology.
The traditional English name "Bohemia" derives from Latin "Boiohaemum", which means "home of the Boii". The current name comes from the endonym "Čech", spelled "Cžech" until the orthographic reform in 1842.
The name comes from the Slavic tribe (Czechs, ) and, according to legend, their leader Čech, who brought them to Bohemia, to settle on Říp Mountain. The etymology of the word "Čech" can be traced back to the Proto-Slavic root "*čel-", meaning "member of the people; kinsman", thus making it cognate to the Czech word "člověk" (a person).
The country has been traditionally divided into three lands, namely Bohemia ("Čechy") in the west, Moravia (Morava) in the southeast, and Czech Silesia ("Slezsko"; the smaller, south-eastern part of historical Silesia, most of which is located within modern Poland) in the northeast. Known as the "lands of the Bohemian Crown" since the 14th century, a number of other names for the country have been used, including "Czech/Bohemian lands", "Bohemian Crown", and the "lands of the Crown of Saint Wenceslas". When the country regained its independence after the dissolution of the Austro-Hungarian empire in 1918, the new name of "Czechoslovakia" was coined to reflect the union of the Czech and Slovak nations within the one country.
Following the dissolution of Czechoslovakia at the end of 1992, the Czech part of the former nation found itself without a common single-word geographical name in English. The name "Czechia" was recommended by the Czech Ministry of Foreign Affairs (minister Josef Zieleniec). In a memorandum to all Czech embassies and diplomatic missions in 1993, the full name "Czech Republic" was recommended for use only in official documents and titles of official institutions (cit.). The geographical name still has not reached general recognition, but its usage is increasing. It can be found in dictionaries, tourist road atlases, maps, encyclopedias, media, and on the web. Czech president Miloš Zeman uses the name "Czechia" in his official speeches and he announced in April 2016 the government would make a formal request to the UN to include the name in its geographical database.
History.
Prehistory.
Archaeologists have found evidence of prehistoric human settlements in the area, dating back to the Paleolithic era. The figurine Venus of Dolní Věstonice, together with a few others from nearby locations, found here is the oldest known ceramic article in the world.
In the classical era, from the 3rd century BC Celtic migrations, the Boii and later in the 1st century, Germanic tribes of Marcomanni and Quadi settled there. Their king Maroboduus is the first documented ruler of Bohemia. During the Migration Period around the 5th century, many Germanic tribes moved westwards and southwards out of Central Europe.
Slavic people from the Black Sea–Carpathian region settled in the area (a movement that was also stimulated by the onslaught of peoples from Siberia and Eastern Europe: Huns, Avars, Bulgars and Magyars). In the sixth century they moved westwards into Bohemia, Moravia and some of present-day Austria and Germany. During the 7th century, the Frankish merchant Samo, supporting the Slavs fighting against nearby settled Avars, became the ruler of the first known Slav state in Central Europe, the Samo's Empire. The Moravian principality Great Moravia arose in the 8th century and reached its zenith in the 9th, when it held off the influence of the Franks and won the protection of the Pope.
Bohemia.
The Duchy of Bohemia emerged in the late 9th century, when it was unified by the Přemyslid dynasty. In 10th century Boleslaus I, Duke of Bohemia conquered Moravia, Silesia and expanded farther to the east. The Kingdom of Bohemia was, as the only kingdom in the Holy Roman Empire, a significant regional power during the Middle Ages. It was part of the Empire from 1002 till 1806, with the exception of the years 1440–1526. In 1212, King Přemysl Ottokar I (bearing the title "king" since 1198) extracted the Golden Bull of Sicily (a formal edict) from the emperor, confirming Ottokar and his descendants' royal status; the Duchy of Bohemia was raised to a Kingdom. The bull declared that the King of Bohemia would be exempt from all future obligations to the Holy Roman Empire except for participation in imperial councils. German immigrants settled in the Bohemian periphery in the 13th century. Germans populated towns and mining districts and, in some cases, formed German colonies in the interior of Bohemia. In 1235, the Mongols launched an invasion of Europe. After the Battle of Legnica in Poland, the Mongols carried their raids into Moravia, but were defensively defeated at the fortified town of Olomouc. The Mongols subsequently invaded and defeated Hungary.
King Přemysl Otakar II earned the nickname "Iron and Golden King" because of his military power and wealth. He acquired Austria, Styria, Carinthia and Carniola, thus spreading the Bohemian territory to the Adriatic Sea. He met his death at the Battle on the Marchfeld in 1278 in a war with his rival, King Rudolph I of Germany. Ottokar's son Wenceslaus II acquired the Polish crown in 1300 for himself and the Hungarian crown for his son. He built a great empire stretching from the Danube river to the Baltic Sea. In 1306, the last king of Přemyslid line was murdered in mysterious circumstances in Olomouc while he was resting. After a series of dynastic wars, the House of Luxembourg gained the Bohemian throne.
The 14th century, in particular, the reign of the Bohemian king Charles IV (1316–1378), who in 1346 became King of the Romans and in 1354 both King of Italy and Holy Roman Emperor, is considered the Golden Age of Czech history. Of particular significance was the founding of Charles University in Prague in 1348, Charles Bridge, Charles Square. Much of Prague Castle and the cathedral of Saint Vitus in Gothic style were completed during his reign. He unified Brandenburg (until 1415), Lusatia (until 1635), and Silesia (until 1742) under the Czech crown. The Black Death, which had raged in Europe from 1347 to 1352, decimated the Kingdom of Bohemia in 1380, killing about 10% of the population.
By the end of the 14th century started the process of the so-called Bohemian (Czech) Reformation. The religious and social reformer Jan Hus formed a reform movement later named after him. Although Hus was named a heretic and burnt in Constance in 1415, his followers seceded from the Catholic Church and in the Hussite Wars (1419–1434) defeated five crusades organized against them by the Holy Roman Emperor Sigismund. Petr Chelčický continued with the Hussite Reformation movement. During the next two centuries, 90% of the inhabitants became adherents of the Hussite movement. Hus's thoughts were a major influence on the later emerging Lutheranism. Luther himself said “we are all Hussites, without having been aware of it” and considered himself as Hus' direct successor . 
After 1526 Bohemia came increasingly under Habsburg control as the Habsburgs became first the elected and then in 1627 the hereditary rulers of Bohemia. The of the 16th century, the founders of the central European Habsburg Monarchy, were buried in Prague. Between 1583–1611 Prague was the official seat of the Holy Roman Emperor Rudolf II and his court.
The Defenestration of Prague and subsequent revolt against the Habsburgs in 1618 marked the start of the Thirty Years' War, which quickly spread throughout Central Europe. In 1620, the rebellion in Bohemia was crushed at the Battle of White Mountain, and the ties between Bohemia and the Habsburgs' hereditary lands in Austria were strengthened. The leaders of the Bohemian Revolt were executed in 1621. The nobility and the middle class Protestants had to either convert to Catholicism or leave the country.
The following period, from 1620 to the late 18th century, has often been called colloquially the "Dark Age". The population of the Czech lands declined by a third through the expulsion of Czech Protestants as well as due to the war, disease and famine. The Habsburgs prohibited all Christian confessions other than Catholicism. The flowering of Baroque culture shows the ambiguity of this historical period.
Ottoman Turks and Tatars invaded Moravia in 1663. In 1679–1680 the Czech lands faced a devastating plague and an uprising of serfs.
The reigns of Maria Theresa of Austria and her son Joseph II, Holy Roman Emperor and co-regent from 1765, were characterized by enlightened absolutism. In 1740, most of Silesia (except the southernmost area) was seized by King Frederick II of Prussia in the Silesian Wars. In 1757 the Prussians invaded Bohemia and after the Battle of Prague (1757) occupied the city. More than one quarter of Prague was destroyed and St. Vitus Cathedral also suffered heavy damage. However, soon after, at the Battle of Kolín Frederick was defeated and had to leave Prague and retreat from Bohemia. In 1770 and 1771 Great Famine killed about one tenth of the Czech population, or 250,000 inhabitants, and radicalised the countryside leading to peasant uprisings. Serfdom was abolished (in two steps) between 1781 and 1848.
The end of the Holy Roman Empire in 1806 led to degradation of the political status of the Kingdom of Bohemia. Bohemia lost its position of an electorate of the Holy Roman Empire as well as its own political representation in the Imperial Diet. Bohemian lands became part of the Austrian Empire and later of Austria–Hungary. During the 18th and 19th century the Czech National Revival began its rise, with the purpose to revive Czech language, culture and national identity. The Revolution of 1848 in Prague, striving for liberal reforms and autonomy of the Bohemian Crown within the Austrian Empire, was suppressed. In 1866 Austria was defeated by Prussia in the Austro-Prussian War. The Austrian Empire needed to redefine itself to maintain unity in the face of nationalism. At first it seemed that some concessions would be made also to Bohemia, but in the end the Emperor Franz Joseph I effected a compromise with Hungary only. The Austro-Hungarian Compromise of 1867 and the never realized coronation of Franz Joseph as King of Bohemia led to a huge disappointment of Czech politicians. The Bohemian Crown lands became part of the so-called Cisleithania (officially "The Kingdoms and Lands represented in the Imperial Council"). The first elections under universal male suffrage were held in 1907. The last King of Bohemia was Blessed Charles of Austria who ruled in 1916–1918.
Czechoslovakia.
[[File:28. říjen 1918.jpg|thumb|Czechoslovak declaration of independence rally in Prague on Wenceslas Square,
28 October 1918]]
An estimated 1.4 million Czech soldiers fought in World War I, of whom some 150,000 died. Although the majority of Czech soldiers fought for the Austro-Hungarian Empire, more than 90,000 Czech volunteers formed the Czechoslovak Legions in France, Italy and Russia, where they fought against the Central Powers and later against Bolshevik troops. In 1918, during the collapse of the Habsburg Empire at the end of World War I, the independent republic of Czechoslovakia, which joined the winning Allied powers, was created. This new country incorporated the Bohemian Crown (Bohemia, Moravia and Silesia) and parts of the Kingdom of Hungary (Slovakia and the Carpathian Ruthenia) with significant German, Hungarian, Polish and Ruthenian speaking minorities.
In 1929 compared to 1913, the gross domestic product increased by 52% and industrial production by 41%. In 1938 Czechoslovakia held a 10th place in the world industrial production.
Although Czechoslovakia was a unitary state, it provided what were at the time rather extensive rights to its minorities and remained the only democracy in this part of Europe in the interwar period. The effects of the Great Depression including high unemployment and massive propaganda from Nazi Germany, however, resulted in discontent and strong support among ethnic Germans for a break from Czechoslovakia.
Adolf Hitler took advantage of this opportunity and, using Konrad Henlein's separatist Sudeten German Party, gained the largely German speaking Sudetenland (and its substantial Maginot Line-like border fortifications) through the 1938 Munich Agreement (signed by Nazi Germany, France, Britain and Italy). Czechoslovakia was not invited to the conference, therefore in fact betrayed by the United Kingdom and France, so Czechs and Slovaks call the Munich Agreement the Munich Betrayal because the Western powers decided to give up Czechoslovakia instead of facing Hitler, which later proved inevitable. All that despite the fact that Czechoslovakia had alliance agreement with France.
Despite the mobilization of 1.2 million-strong Czechoslovak army and the Franco-Czech military alliance, Poland annexed the Zaolzie area around Český Těšín; Hungary gained parts of Slovakia and the Subcarpathian Rus as a result of the First Vienna Award in November 1938. The remainders of Slovakia and the Subcarpathian Rus gained greater autonomy, with the state renamed to "Czecho-Slovakia". After Nazi Germany threatened to annex part of Slovakia, allowing the remaining regions to be partitioned by Hungary and Poland, Slovakia chose to maintain its national and territorial integrity, seceding from Czecho-Slovakia in March 1939, and allying itself, as demanded by Germany, with Hitler's coalition.
The remaining Czech territory was occupied by Germany, which transformed it into the so-called Protectorate of Bohemia and Moravia. The protectorate was proclaimed part of the Third Reich, and the president and prime minister were subordinated to the Nazi Germany's "Reichsprotektor". Subcarpathian Rus declared independence as the Republic of Carpatho-Ukraine on 15 March 1939 but was invaded by Hungary the same day and formally annexed the next day. Approximately 345,000 Czechoslovak citizens, including 277,000 Jews, were killed or executed while hundreds of thousands of others were sent to prisons and Nazi concentration camps or used as forced labour. Up to two-thirds of the citizens were in groups targeted by the Nazis for deportation or death. One concentration camp was located within the Czech territory at Terezín, north of Prague.
There was Czech resistance to Nazi occupation, both at home and abroad, most notably with the assassination of Nazi German leader Reinhard Heydrich by Czechoslovakian soldiers Jozef Gabčík and Jan Kubiš in a Prague suburb on 27 May 1942. On 9 June 1942 Hitler ordered bloody reprisals against the Czechs as a response to the Czech anti-Nazi resistance. The Czechoslovak government-in-exile and its army fought against the Germans and were acknowledged by the Allies; Czech/Czechoslovak troops fought from the very beginning of the war in Poland, France, the UK, North Africa, the Middle East and the Soviet Union. The German occupation ended on 9 May 1945, with the arrival of the Soviet and American armies and the Prague uprising. An estimated 140,000 Soviet soldiers died in liberating Czechoslovakia from German rule.
In 1945–1946, almost the entire German-speaking minority in Czechoslovakia, about 3 million people, were expelled to Germany and Austria. During this time, thousands of Germans were held in prisons and detention camps or used as forced labour. In the summer of 1945, there were several massacres. The only Germans not expelled were some 250,000 who had been active in the resistance against the Nazi Germans or were considered economically important, though many of these emigrated later. Following a Soviet-organised referendum, the Subcarpathian Rus never returned under Czechoslovak rule but became part of the Ukrainian Soviet Socialist Republic, as the Zakarpattia Oblast in 1946.
Czechoslovakia uneasily tried to play the role of a "bridge" between the West and East. However, the Communist Party of Czechoslovakia rapidly increased in popularity, with a general disillusionment with the West, because of the pre-war Munich Agreement, and a favourable popular attitude towards the Soviet Union, because of the Soviets' role in liberating Czechoslovakia from German rule. In the 1946 elections, the Communists gained 38% of the votes and became the largest party in the Czechoslovak parliament. They formed a coalition government with other parties of the National Front and moved quickly to consolidate power. A significant change came in 1948 with coup d'état by the Communist Party. The Communist People's Militias secured control of key locations in Prague, and a single party government was formed.
For the next 41 years, Czechoslovakia was a Communist state within the Eastern Bloc. This period is characterized by lagging behind the West in almost every aspect of social and economic development. The country's GDP per capita fell from the level of neighboring Austria below that of Greece or Portugal in the 1980s. The Communist government completely nationalized the means of production and established a command economy. The economy grew rapidly during the 1950s but slowed down in the 1960s and 1970s and stagnated in the 1980s. The political climate was highly repressive during the 1950s, including numerous show trials and hundreds of thousands of political prisoners, but became more open and tolerant in the late 1960s, culminating in Alexander Dubček's leadership in the 1968 Prague Spring, which tried to create "socialism with a human face" and perhaps even introduce political pluralism. This was forcibly ended by invasion by all Warsaw Pact member countries with the exception of Romania and Albania on 21 August 1968.
The invasion was followed by a harsh program of "Normalization" in the late 1960s and the 1970s. Until 1989, the political establishment relied on censorship of the opposition. Dissidents published Charter 77 in 1977, and the first of a new wave of protests were seen in 1988. Between 1948 and 1989 more than 250,000 Czechs and Slovaks were sent to prison, and over 400,000 emigrated.
Velvet Revolution and independence.
In November 1989, Czechoslovakia returned to a liberal democracy through the peaceful "Velvet Revolution". However, Slovak national aspirations strengthened and on 1 January 1993, the country peacefully split into the independent Czech Republic and Slovakia. Both countries went through economic reforms and privatisations, with the intention of creating a market economy. This process was largely successful; in 2006 the Czech Republic was recognised by the World Bank as a "developed country", and in 2009 the Human Development Index ranked it as a nation of "Very High Human Development".
From 1991, the Czech Republic, originally as part of Czechoslovakia and since 1993 in its own right, has been a member of the Visegrád Group and from 1995, the OECD. The Czech Republic joined NATO on 12 March 1999 and the European Union on 1 May 2004. On 21 December 2007 the Czech Republic joined the Schengen Area.
Government and politics.
The Czech Republic is a pluralist multi-party parliamentary representative democracy, with the Prime Minister as the head of government. The Parliament ("Parlament České republiky") is bicameral, with the Chamber of Deputies () (200 members) and the Senate () (81 members).
The president is a formal head of state with limited and specific powers, most importantly to return bills to the parliament, appoint members to the board of the Czech National Bank, nominate constitutional court judges for the Senate's approval and dissolve the Chamber of Deputies under certain special and unusual circumstances. He also appoints the prime minister, as well the other members of the cabinet on a proposal by the prime minister. From 1993 until 2012, the President of the Czech Republic was selected by a joint session of the parliament for a five-year term, with no more than two consecutive terms. Since 2013 the presidential election is direct.
The Government of the Czech Republic's exercise of executive power derives from the Constitution. The members of the government are the Prime Minister, Deputy ministers and other ministers. The Government is responsible to the Chamber of Deputies.
The Prime Minister is the head of government and wields considerable powers, such as the right to set the agenda for most foreign and domestic policy and choose government ministers. The current Prime Minister of the Czech Republic is Bohuslav Sobotka, serving since 17 January 2014 as 11th Prime Minister.
The members of the Chamber of Deputies are elected for a four-year term by proportional representation, with a 5% election threshold. There are 14 voting districts, identical to the country's administrative regions. The Chamber of Deputies, the successor to the Czech National Council, has the powers and responsibilities of the now defunct federal parliament of the former Czechoslovakia.
The members of the Senate are elected in single-seat constituencies by two-round runoff voting for a six-year term, with one-third elected every even year in the autumn. The first election was in 1996, for differing terms. This arrangement is modeled on the U.S. Senate, but each constituency is roughly the same size and the voting system used is a two-round runoff. The Senate is unpopular among the public and suffers from low election turnout.
Law.
Czech Republic has a civil law system based on the continental type, rooted in Germanic legal culture. Czech judiciary has triumvirate system of the main courts, the Constitutional Court which oversees violations of the Constitution by either the legislature or by the government consisting of 15 constitutional judges, the Supreme Court is the court of highest appeal for almost all legal cases heard in the Czech Republic formed of 67 judges and the Supreme Administrative Court decides on issues of procedural and administrative propriety. It also has jurisdiction over many political matters, such as the formation and closure of political parties, jurisdictional boundaries between government entities, and the eligibility of persons to stand for public office.
Foreign relations.
The Czech Republic has an established structure of foreign relations. It is a member of the United Nations, the European Union, NATO, Organisation for Economic Co-operation and Development, Council of Europe and is an observer to the Organization of American States. All countries with diplomatic relations with the Czech Republic have embassy located in Prague, and some of them have consulates across the country.
The Prime Minister and Minister of Foreign Affairs have primary roles in setting foreign policy. Membership in the European Union is central to the Czech Republic's foreign policy. The Czech Republic held the Presidency of the Council of the European Union for the first half of 2009.
The Czech Republic has strong ties with Slovakia, Poland and Hungary as member of Visegrad Group, as well as with Germany, Israel, United States and European Union and their members.
Czech officials have supported dissenters in Burma, Belarus, Moldova and Cuba.
Military.
The Czech armed forces consist of the Czech Army, the Czech Air Force and of specialized support units. The armed forces are managed by the Ministry of Defence. The President of the Czech Republic is Commander-in-chief of the armed forces. In 2004 the army transformed itself into a fully professional organization and compulsory military service was abolished. The country has been a member of NATO since 12 March 1999. Defense spending is approximately 1.04% of the GDP (2015). The armed forces are charged with protecting the Czech Republic and its allies, promoting global security interests, and contributing to NATO.
Currently, as a member of NATO, the Czech military are participating in KFOR and ISAF (renamed to Resolute Support) operations and have soldiers in Afghanistan, Kosovo, Bosnia and Herzegovina, Somalia, Israel and Mali. The Czech Air Force also served in the Baltic states and Iceland. Main equipment includes: multi-role fighters JAS 39 Gripen, combat aircraft Aero L-159 Alca, modernized attack helicopters Mi-35, armored vehicles Pandur II, OT-64, OT-90, BVP-2 and Czech modernized tanks T-72 (T-72M4CZ).
Administrative divisions.
Since 2000, the Czech Republic has been divided into thirteen regions (Czech: "kraje", singular "kraj") and the capital city of Prague. Every region has its own elected regional assembly ("krajské zastupitelstvo") and "hejtman" (a regional governor). In Prague, the assembly and presidential powers are executed by the city council and the mayor.
The older seventy-six districts ("okresy", singular "okres") including three "statutory cities" (without Prague, which had special status) lost most of their importance in 1999 in an administrative reform; they remain as territorial divisions and seats of various branches of state administration.
Geography.
The Czech Republic lies mostly between latitudes 48° and 51° N (a small area lies north of 51°), and longitudes 12° and 19° E.
The Czech landscape is exceedingly varied. Bohemia, to the west, consists of a basin drained by the Elbe () and the Vltava rivers, surrounded by mostly low mountains, such as the Krkonoše range of the Sudetes. The highest point in the country, Sněžka at , is located here. Moravia, the eastern part of the country, is also quite hilly. It is drained mainly by the Morava River, but it also contains the source of the Oder River ().
Water from the landlocked Czech Republic flows to three different seas: the North Sea, Baltic Sea and Black Sea. The Czech Republic also leases the Moldauhafen, a lot in the middle of the Hamburg Docks, which was awarded to Czechoslovakia by Article 363 of the Treaty of Versailles, to allow the landlocked country a place where goods transported down river could be transferred to seagoing ships. The territory reverts to Germany in 2028.
Phytogeographically, the Czech Republic belongs to the Central European province of the Circumboreal Region, within the Boreal Kingdom. According to the World Wide Fund for Nature, the territory of the Czech Republic can be subdivided into four ecoregions: the Western European broadleaf forests, Central European mixed forests, Pannonian mixed forests, and Carpathian montane conifer forests.
There are four national parks in the Czech Republic. The oldest is
Krkonoše National Park (Biosphere Reserve), Šumava National Park (Biosphere Reserve), Podyjí National Park, Bohemian Switzerland.
The three historical lands of the Czech Republic (formerly the core countries of the Bohemian Crown) correspond almost prefectly with the river basins of the Elbe () and the Vltava basin for Bohemia, the Morava one for Moravia, and the Oder river basin for Czech Silesia (in terms of the Czech territory).
Climate.
The Czech Republic has a temperate continental climate, with warm summers and cold, cloudy and snowy winters. The temperature difference between summer and winter is relatively high, due to the landlocked geographical position.
Within the Czech Republic, temperatures vary greatly, depending on the elevation. In general, at higher altitudes, the temperatures decrease and precipitation increases. The wettest area in the Czech Republic is found around Bílý Potok in Jizera Mountains and the driest region is the Louny District to the northwest of Prague. Another important factor is the distribution of the mountains; therefore, the climate is quite varied.
At the highest peak of Sněžka (), the average temperature is only , whereas in the lowlands of the South Moravian Region, the average temperature is as high as . The country's capital, Prague, has a similar average temperature, although this is influenced by urban factors.
The coldest month is usually January, followed by February and December. During these months, there is usually snow in the mountains and sometimes in the major cities and lowlands. During March, April and May, the temperature usually increases rapidly, especially during April, when the temperature and weather tends to vary widely during the day. Spring is also characterized by high water levels in the rivers, due to melting snow with occasional flooding.
The warmest month of the year is July, followed by August and June. On average, summer temperatures are about – higher than during winter. Summer is also characterized by rain and storms.
Autumn generally begins in September, which is still relatively warm and dry. During October, temperatures usually fall below or and deciduous trees begin to shed their leaves. By the end of November, temperatures usually range around the freezing point.
The coldest temperature ever measured was in Litvínovice near České Budějovice in 1929, at and the hottest measured, was at in Dobřichovice in 2012.
Most rain falls during the summer. Sporadic rainfall is relatively constant throughout the year (in Prague, the average number of days per month experiencing at least 0.1 mm of rain varies from 12 in September and October to 16 in November) but concentrated heavy rainfall (days with more than 10 mm per day) are more frequent in the months of May to August (average around two such days per month).
Environment.
The Czech Republic ranks as the fifth most environmentally conscious country in the world in Environmental Performance Index.
Economy.
The Czech Republic possesses a developed, high-income economy with a per capita GDP rate that is 87% of the European Union average. The most stable and prosperous of the post-Communist states, the Czech Republic saw growth of over 6% annually in the three years before the outbreak of the recent global economic crisis. Growth has been led by exports to the European Union, especially Germany, and foreign investment, while domestic demand is reviving.
Most of the economy has been privatised, including the banks and telecommunications. A 2009 survey in cooperation with the Czech Economic Association found that the majority of Czech economists favour continued liberalization in most sectors of the economy.
The country has been a member of the Schengen Area since 1 May 2004, having abolished border controls, completely opening its borders with all of its neighbours (Germany, Austria, Poland and Slovakia) on 21 December 2007. The Czech Republic became a member of the World Trade Organisation on 1 January 1995. In 2012, Nearly 80% of Czech exports went to, and more than 65% of Czech imports came from, other European Union member states.
Czech Republic would become the 49th largest economy in the world by 2050 with a GDP of US$ $342 billion.
Monetary policy is conducted by the Czech National Bank, whose independence is guaranteed by the Constitution. The official currency is the Czech crown, and it had been floating until 7. 11. 2013, when the central bank temporarily pegged the exchange rate at 27 crowns per euro in order to fight deflation. When it joined EU, the Czech Republic obligated itself to adopt the euro, but the date of adoption has not been determined.
The Programme for International Student Assessment, coordinated by the OECD, currently ranks the Czech education system as the 15th best in the world, higher than the OECD average. The Czech Republic is ranked 24th in the 2015 Index of Economic Freedom.
Leading Czech transportation companies include Škoda Auto (automobiles), Škoda Transportation (tramways, trolleybuses, metro), Tatra (the third oldest car maker in the world), Karosa (buses), Aero Vodochody (airplanes) and Jawa Motors (motorcycles). http://www.worlddiplomacy.org states that "Elections in 2013 brought a new government for the Czech republic. Although starting off 2013 rather weakly, the economy rebounded strongly in the coming quarters and most recently (Q1,2015) the economy has enjoyed the fastest GDP increase in the entire EU, clocking at 2.8% compared with Q4,2014, or 3.9% year-on-year."
In November 2015, Czech GDP growth was 4.5%, giving the Czech economy the highest growth rate in Europe.
Unemployment rate is at 4.1 %, giving the Czech Republic the lowest unemployment rate in the whole European Union.
Energy.
Production of Czech electricity exceeds consumption by about 10 TWh per year, which are exported. Nuclear power presently provides about 30 percent of the total power needs, its share is projected to increase to 40 percent. In 2005, 65.4 percent of electricity was produced by steam and combustion power plants (mostly coal); 30 percent by nuclear plants; and 4.6 percent from renewable sources, including hydropower. The largest Czech power resource is Temelín Nuclear Power Station, another nuclear power plant is in Dukovany.
The Czech Republic is reducing its dependence on highly polluting low-grade brown coal as a source of energy. Natural gas is procured from Russian Gazprom, roughly three-fourths of domestic consumption and from Norwegian companies, which make up most of the remaining one-fourth. Russian gas is imported via Ukraine (Druzhba pipeline), Norwegian gas is transported through Germany. Gas consumption (approx. 100 TWh in 2003–2005) is almost double electricity consumption. South Moravia has small oil and gas deposits.
Transportation infrastructure.
Václav Havel Airport in Prague is the main international airport in the country. In 2010, it handled 11.6 million passengers, which makes it the fifth busiest airport in Central and Eastern Europe. In total, the Czech Republic has 46 airports with paved runways, six of which provide international air services in Brno, Karlovy Vary, Mošnov (near Ostrava), Pardubice, Prague and Kunovice (near Uherské Hradiště).
České dráhy (the Czech Railways) is the main railway operator in the Czech Republic, with about 180 million passengers carried yearly. Its cargo division, ČD Cargo, is the fifth largest railway cargo operator in the European Union. With of tracks, the Czech Republic has one of the densest railway networks in Europe. Of that number, is electrified, are single-line tracks and are double and multiple-line tracks. In 2006 the new Italian tilting trains Pendolino ČD Class 680 entered service. They have reached a speed of 237 km/h setting a new Czech railway speed record.
Russia, via pipelines through Ukraine and to a lesser extent, Norway, via pipelines through Germany, supply the Czech Republic with liquid and natural gas.
The road network in the Czech Republic is long. There are 775,8 km of motorways and 439,1 km of expressways. The speed limit is 50 km/h within towns, 90 km/h outside of towns and 130 km/h on expressways.
Communications.
The Czech Republic ranks in the top 10 countries worldwide with the fastest average internet speed.
The Czech Republic has the most Wi-Fi subscribers in the European Union. By the beginning of 2008, there were over 800 mostly local WISPs, with about 350,000 subscribers in 2007. Plans based on either GPRS, EDGE, UMTS or CDMA2000 are being offered by all three mobile phone operators (T-Mobile, Telefónica O2, Vodafone) and internet provider . Government-owned Český Telecom slowed down broadband penetration. At the beginning of 2004, local-loop unbundling began and alternative operators started to offer ADSL and also SDSL. This and later privatisation of Český Telecom helped drive down prices.
On 1 July 2006, Český Telecom was acquired by globalized company (Spain owned) Telefónica group and adopted new name Telefónica O2 Czech Republic. As of June 2014, VDSL and ADSL2+ are offered in many variants, with download speeds of up to 40 Mbit/s and upload speeds of up to 2Mbit/s. Cable internet is gaining popularity with its higher download speeds ranging from 2 Mbit/s to 1 Gbit/s.
Science and technology.
The Czech lands have a long and rich scientific tradition. The research based on cooperation between universities, Academy of Sciences and specialised research centers brings new inventions and impulses in this area. Important inventions include the modern contact lens, the separation of modern blood types, and the production of Semtex plastic explosive. In March 1978, Czechoslovakian Vladimír Remek was the first person outside of the Soviet Union and the United States to go into space.
Prominent scientists who lived and worked in historically Czech lands include:
A number of other scientists are also connected in some way with the Czech lands, including astronomers Johannes Kepler and Tycho Brahe, the founder of the psychoanalytic school of psychiatry Sigmund Freud, physicists Christian Doppler, Ernst Mach, Nikola Tesla, Albert Einstein, engineer Viktor Kaplan, automotive engineer Ferdinand Porsche and logician Kurt Gödel.
Tourism.
The Czech economy gets a substantial income from tourism. Prague is the fifth most visited city in Europe after London, Paris, Istanbul and Rome. In 2001, the total earnings from tourism reached 118 billion CZK, making up 5.5% of GNP and 9% of overall export earnings. The industry employs more than 110,000 people – over 1% of the population.
The country's reputation has suffered with guidebooks and tourists reporting overcharging by taxi drivers and pickpocketing problems mainly in Prague, though the situation has improved recently. Since 2005, Prague's mayor, Pavel Bém, has worked to improve this reputation by cracking down on petty crime and, aside from these problems, Prague is a safe city. Also, the Czech Republic as a whole generally has a low crime rate. For tourists, the Czech Republic is considered a safe destination to visit. The low crime rate makes most cities and towns very safe to walk around.
There are several centres of tourist activity. The spa towns, such as Karlovy Vary, Mariánské Lázně and Františkovy Lázně and Jáchymov, are particularly popular relaxing holiday destinations.
Architectural heritage is another object of visitor´s interest – it includes many castles and châteaux from different historical epoques, namely Karlštejn Castle, Český Krumlov and the Lednice–Valtice area.
There are 12 cathedrals and 15 churches elevated to the rank of basilica by the Pope, calm monasteries, many modern and ancient churches – for example Pilgrimage Church of Saint John of Nepomuk is one of those inscribed on the World Heritage List. Away from the towns, areas such as Český ráj, Šumava and the Krkonoše Mountains attract visitors seeking outdoor pursuits.
The country is also known for its various museums. Puppetry and marionette exhibitions are very popular, with a number of puppet festivals throughout the country.
Aquapalace Praha in Čestlice near Prague, is the biggest water park in central Europe.
The Czech Republic has a number of beer festivals, including: Czech Beer Festival (the biggest Czech beer festival, it is usually 17 days long and held every year in May in Prague), Pilsner Fest (every year in August in Plzeň), The "Olomoucký pivní festival" (in Olomouc) or festival "Slavnosti piva v Českých Budějovicích" (in České Budějovice).
Demographics.
According to preliminary results of the 2011 census, the majority of the inhabitants of the Czech Republic are Czechs (63.7%), followed by Moravians (4.9%), Slovaks (1.4%), Poles (0.4%), Germans (0.2%) and Silesians (0.1%). As the 'nationality' was an optional item, a substantial number of people left this field blank (26.0%). According to some estimates, there are about 250,000 Romani people in the Czech Republic.
There were 437,581 foreigners residing in the country in September 2013, according to the Czech Statistical Office, with the largest groups being Ukrainian (106,714), Slovak (89,273), Vietnamese (61,102), Russian (32,828), Polish (19,378), German (18,099), Bulgarian (8,837), American (6,695), Romanian (6,425), Moldovan (5,860), Chinese (5,427), British (5,413), Mongolian (5,308), Kazakh (4,850), Belarusian (4,562).
The Jewish population of Bohemia and Moravia, 118,000 according to the 1930 census, was virtually annihilated by the Nazi Germans during the Holocaust. There were approximately 4,000 Jews in the Czech Republic in 2005. The former Czech prime minister, Jan Fischer, is of Jewish origin and faith.
The total fertility rate (TFR) in 2015 was estimated at 1.44 children born/woman, which is below the replacement rate of 2.1, and one of the lowest in the world. In 2015, 47.8% of births were to unmarried women.
The life expectancy in 2013 was estimated at 77.56 years (74.29 years male, 81.01 years female). Immigration increased the population by almost 1% in 2007. About 77,000 people immigrate to the Czech Republic annually. Vietnamese immigrants began settling in the Czech Republic during the Communist period, when they were invited as guest workers by the Czechoslovak government. In 2009, there were about 70,000 Vietnamese in the Czech Republic. Most decide to stay in the country permanently.
At the turn of the 20th century, Chicago was the city with the third largest Czech population, after Prague and Vienna. According to the 2010 US census, there are 1,533,826 Americans of full or partial Czech descent.
Religion.
The Czech Republic has one of the least religious populations in the world, being the country with the third most atheistic population by percentage, behind only China and Japan. Historically, the Czech people have been characterised as "tolerant and even indifferent towards religion". According to the 2011 census, 34% of the population stated they had no religion, 10.3% was Roman Catholic, 0.8% was Protestant (0.5% Czech Brethren and 0.4% Hussite), and 9% followed other forms of religion both denominational or not (of which 863 people answered they are Pagan). 45% of the population did not answer the question about religion. From 1991 to 2001 and further to 2011 the adherence to Roman Catholicism decreased from 39% to 27% and then to 10%; Protestantism similarly declined from 3.7% to 2% and then to 0.8%.
According to a Eurobarometer Poll in 2010, 16% of Czech citizens responded that "they believe there is a God" (the lowest rate among the countries of the European Union), whereas 44% answered that "they believe there is some sort of spirit or life force" and 37% said that "they do not believe there is any sort of spirit, God or life force".
According to new polls about Religiosity in the European Union in 2012 by Eurobarometer found that Non believer/Agnostic is the largest religion in Czech Republic accounting 39% of Czech citizens. Christianity account 34% of Czech citizens, Catholics are the largest Christian group in Czech Republic, accounting for 29% of Czech citizens, while Protestants make up 2%, and Other Christian make up 3%. Atheist accounts for 20%, Undeclared accounts for 6%.
Education.
Education in the Czech Republic is compulsory for 9 years, but the average number of years of education is 13.1. Additionally, the Czech Republic has a relatively equal educational system in comparison with other countries in Europe.
Culture.
Art.
The Czech Republic is known worldwide for its individually made, mouth blown and decorated art glass and crystal. One of the best Czech painters and decorative artists was Alphonse Mucha (1860–1939) mainly known for art nouveau posters and his cycle of 20 large canvases named the Slav Epic, which depicts the history of Czechs and other Slavs. , the Slav Epic can be seen in Veletržní Palace of National Gallery in Prague, which manages the largest collection of art in the Czech Republic.
Other notable Czech artists include:
Architecture.
The earliest preserved stone buildings in Bohemia and Moravia date back to the time of the Christianization in the 9th and 10th century. Since the Middle Ages the Czech lands have been using the same architectural styles like most of Western and Central Europe. The oldest still standing churches were built in the Romanesque style. During the 13th century it was replaced by the Gothic style. In the 14th century Emperor Charles IV invited to his court in Prague talented architects from France and Germany, Matthias of Arras and Peter Parler. During the Middle Ages, many fortified castles were built by the king and aristocracy, as well as many monasteries. During the Hussite wars, many of them were damaged or destroyed.
The Renaissance style penetrated the Bohemian Crown in the late 15th century when the older Gothic style started to be slowly mixed with Renaissance elements (architects Matěj Rejsek, Benedikt Rejt). An outstanding example of the pure Renaissance architecture in Bohemia is the Royal Summer Palace, which was situated in a newly established garden of Prague Castle. Evidence of the general reception of the Renaissance in Bohemia, involving a massive influx of Italian architects, can be found in spacious châteaux with elegant arcade courtyards and geometrically arranged gardens. Emphasis was placed on comfort, and buildings that were built for entertainment purposes also appeared.
In the 17th century, the Baroque style spread throughout the Crown of Bohemia. Very outstanding are the architectural projects of the Czech nobleman and imperial generalissimo Albrecht von Wallenstein from the 1620s. His architects Andrea Spezza and Giovanni Pieroni reflected the most recent Italian production and were very innovative at the same time. Czech Baroque architecture is considered to be a unique part of the European cultural heritage thanks to its extensiveness and extraordinariness. In the first third of the 18th century the Bohemian lands were one of the leading artistic centers of the Baroque style. In Bohemia there was completed the development of the Radical Baroque style created in Italy by Francesco Borromini and Guarino Guarini in a very original way. Leading architects of the Bohemian Baroque were Jean-Baptiste Mathey, František Maxmilián Kaňka, Christoph Dientzenhofer, and his son Kilian Ignaz Dientzenhofer.
In the 18th century Bohemia produced an architectural peculiarity – the "Baroque Gothic style", a synthesis of the Gothic and Baroque styles. This was not a simple return to Gothic details, but rather an original Baroque transformation. The main representative and originator of this style was Jan Blažej Santini-Aichel, who used this style in renovating medieval monastic buildings.
During the 19th century, the revival architectural styles were very popular in the Bohemian monarchy. Many churches were restored to their presumed medieval appearance and there were constructed many new buildings in the Neo-Romanesque, Neo-Gothic and Neo-Renaissance styles. At the turn of the 19th and 20th centuries the new art style appeared in the Czech lands – Art Nouveau. The best-known representatives of Czech Art Nouveau architecture were Osvald Polívka, who designed the Municipal House in Prague, Josef Fanta, the architect of the Prague Main Railway Station, and Jan Kotěra.
Bohemia contributed an unusual style to the world's architectural heritage when Czech architects attempted to transpose the Cubism of painting and sculpture into architecture. During the first years of the independent Czechoslovakia (after 1918), a specifically Czech architectural style, called "‘Rondo-Cubism’", came into existence. Together with the pre-war Czech Cubist architecture it is unparalleled elsewhere in the world. The first Czechoslovak president T. G. Masaryk invited the prominent Slovene architect Jože Plečnik to Prague, where he modernized the Castle and built some other buildings. Between World Wars I and II, Functionalism, with its sober, progressive forms, took over as the main architectural style in the newly established Czechoslovak Republic. In the city of Brno, one of the most impressive functionalist works has been preserved – Villa Tugendhat, designed by the architect Ludwig Mies van der Rohe. The most significant Czech architects of this era were Adolf Loos, Pavel Janák and Josef Gočár.
After the World War II and the Communist coup in 1948 the art in Czechoslovakia came under the strong Soviet influence. Hotel International in Prague is a brilliant example of the so-called Socialist realism, the Stalinistic art style of the 1950s. Czechoslovak avant-garde artistic movement known as the "Brussels style" (called after the Brussels World's Fair Expo 58) became popular in the time of political liberalization of Czechoslovakia in the 1960s.
Even today, the Czech Republic is not shying away from the most modern trends of international architecture. This fact is attested to by a number of projects by world-renowned architects (Frank Gehry, Jean Nouvel, Ricardo Bofill, and John Pawson). There are also contemporary Czech architects whose works can be found all over the world (Eva Jiřičná, Jan Kaplický).
Literature.
Czech literature is the literature written by Czechs, mostly in the Czech language, although other languages like Old Church Slavonic, Latin or German have been also used, such as by author Franz Kafka, who—while bilingual in Czech and German—wrote his works in German, during the era of Austrian rule.
Influential Czech authors who wrote in Latin include Cosmas of Prague († 1125), Peter of Zittau († 1339), John Hus († 1415), Bohuslav Hasištejnský z Lobkovic (1461–1510), Jan Dubravius (1486–1553), Tadeáš Hájek (1525–1600), Johannes Vodnianus Campanus (1572–1622), and Bohuslav Balbín (1621–1688). In the late 13th century the royal court in Prague was one of the centers of German Minnesang. The most famous Czech medieval German-language work is the "Ploughman of Bohemia" ("Der Ackermann aus Böhmen"), written around 1401 by Johannes von Tepl. The heyday of Czech German-language literature can be seen in the first half of the 20th century, which is represented by the well-known names of Franz Kafka, Max Brod, Franz Werfel, Rainer Maria Rilke, Egon Erwin Kisch, and others.
The Bible translations played an important role in the development of Czech literature and standard Czech language. The oldest Czech translation of the Psalms originated in the late 13th century and the first Czech translation of the whole Bible was finished around 1360. The first complete printed Czech Bible was published in 1488 (Prague Bible). The first complete Czech Bible translation from original languages was published between 1579–93 and is known as the Bible of Kralice.
Czech-language literature can be divided into several main time periods: the Middle Ages (Chronicle of Dalimil); the Hussite period (Tomáš Štítný ze Štítného, Jan Hus, Petr Chelčický); the Renaissance humanism (Henry the Younger of Poděbrady, Luke of Prague, Wenceslaus Hajek, Jan Blahoslav, Daniel Adam z Veleslavína); the Baroque period (John Amos Comenius, Adam Václav Michna z Otradovic, Bedřich Bridel, Jan František Beckovský); the Enlightenment and Czech reawakening in the 19th century (Václav Matěj Kramerius, Karel Hynek Mácha, Karel Jaromír Erben, Karel Havlíček Borovský, Božena Němcová, Jan Neruda, Alois Jirásek); the avant-garde of the interwar period (Karel Čapek, Jaroslav Hašek, Vítězslav Nezval, Jaroslav Seifert, Bohuslav Reynek); the years under Communism and the Prague Spring (Josef Škvorecký, Bohumil Hrabal, Milan Kundera, Arnošt Lustig, Václav Havel); and the literature of the post-Communist Czech Republic (Ivan Martin Jirous).
Jaroslav Seifert was the only Czech writer awarded the Nobel Prize in Literature. A famous antiwar comedy novel "The Good Soldier Švejk" by Jaroslav Hašek is the most translated Czech book in history. It was depicted by Karel Steklý in two color films "The Good Soldier Schweik" in 1956 and 1957.
Czech literature and culture played a major role on at least two occasions, when Czechs lived under oppression and political activity was suppressed. On both of these occasions, in the early 19th century and then again in the 1960s, the Czechs used their cultural and literary effort to strive for political freedom, establishing a confident, politically aware nation.
Music.
The musical tradition of Czech lands arose from first church hymns, whose first evidence is suggested at the break of 10th and 11th century. The first significant pieces of Czech music include two chorales, which in their time performed the function of anthems: "Hospodine pomiluj ny" (Lord, Have Mercy on Us) from around 1050, unmistakably the oldest and most faithfully preserved popular spiritual song to have survived to the present, and the hymn "Svatý Václave" (Saint Wenceslas) or "Saint Wenceslas Chorale" from around 1250. Its roots can be found in the 12th century and it still belongs to the most popular religious songs to this day. In 1918, in the beginning of the Czechoslovak state, the song was discussed as one of the possible choices for the national anthem. The authorship of the anthem "Lord, Have Mercy on Us" is ascribed by some historians to Saint Adalbert of Prague (sv.Vojtěch), bishop of Prague, living between 956 and 997.
The wealth of musical culture in the Czech Republic lies in the long-term high-culture classical music tradition during all historical periods, especially in the Baroque, Classicism, Romantic, modern classical music and in the traditional folk music of Bohemia, Moravia and Silesia. Since the early eras of artificial music, Czech musicians and composers have often been influenced by genuine folk music (e.g. polka which originated in Bohemia). Among the most notable Czech composers are Adam Michna, Jan Dismas Zelenka, Jan Václav Antonín Stamic, Jiří Antonín Benda, Jan Křtitel Vaňhal, Josef Mysliveček, Antonín Rejcha, Bedřich Smetana, Antonín Dvořák, Gustav Mahler, Josef Suk, Leoš Janáček, Bohuslav Martinů, Alois Hába, Miloslav Kabeláč and Petr Eben, not forgetting the famous musicians and interpreters, e.g. František Benda, Jan Kubelík, Emma Destinnová, Rudolf Firkušný, Czech Philharmonic Orchestra, Panocha Quartet and many others.
Czech music can be considered to have been beneficial in both the European and worldwide context, several times co-determined or even determined a newly arriving era in musical art, above all of Classical era, as well as by original attitudes in Baroque, Romantic and modern classical music.
The most famous music festival in the country is Prague Spring International Music Festival of classical music, a permanent showcase for outstanding performing artists, symphony orchestras and chamber music ensembles of the world.
Theatre.
The roots of Czech theatre can be found in the Middle Ages, especially in cultural life of gothic period. In the 19th century, the theatre played an important role in the national awakening movement and later, in the 20th century it became a part of the modern European theatre art. Original Czech cultural phenomenon came into being at the end of the 1950s. This project called Laterna magika (The Magic Lantern) was the brainchild of renowned film and theater director Alfred Radok, resulting in productions that combined theater, dance and film in a poetic manner, considered the first multimedia art project in international context
Film.
The tradition of Czech cinematography started in the second half of 1890s. Peaks of the production in the era of silent movies represent historical drama "The Builder of the Temple", social and erotic (very controversial and innovative at that time ) drama "Erotikon" directed by Gustav Machatý. Early sound film era of Czech film was very productive, above all in mainstream genres with special role of comedies by Martin Frič or Karel Lamač, however more internationally 
successful were drammatic movies, above all famous romantic drama film "Ecstasy" by Gustav Machatý, and romantic "The River" by Josef Rovenský. 
After the repressive period of Nazi occupation of the country and early communist official dramaturgy of socialist realism in movies at the turn of 1940s and 1950s with a few exceptions such a "Krakatit" by Otakar Vávra or "Men without wings" by František Čáp (awarded by Palme d'Or of the Cannes Film Festival in 1946), new era of the Czech film begun by outstanding animated films by important filmmakers such as Karel Zeman, a pioneer with special effects (culminating in successful films such as artistically exceptional "Vynález zkázy" (A Deadly Invention), performed in anglophone countries under the name "The Fabulous World of Jules Verne" from 1958, which combined acted drama with animation, and Jiří Trnka, the founder of the modern puppet film. Another Czech cultural phenomenon came into being at the end of the 1950s. This project called Laterna magika (The Magic Lantern), resulting in productions that combined theater, dance and film in a poetic manner, considered the first multimedia art project in international context (mentioned also in "Theatre section" above).
In 1960s, so called Czech New Wave (also Czechoslovak New Wave) received international acclaim. It is linked with names of Miloš Forman, Věra Chytilová, Jiří Menzel, Ján Kadár, Elmar Klos, Evald Schorm, Vojtěch Jasný, Ivan Passer, Jan Schmidt, Juraj Herz, Jan Němec, Jaroslav Papoušek, etc. The hallmark of the films of this movement were long, often improvised dialogues, black and absurd humor and the occupation of non-actors. Directors are trying to preserve natural atmosphere wthout refinement and artificial arrangement of scenes. The unique personality of 1960s and the beginning of 1970s with original manuscript, deep psychological impact and extraordinarily high quality art is the director František Vláčil. His films Marketa Lazarová, Údolí včel ("The Valley of The Bees") or Adelheid belong to the srtistic peaks of Czech cinema production. The film "Marketa Lazarová" was voted the all-time best Czech movie in a prestigious 1998 poll of Czech film critics and publicists. Another internationally well-known author is Jan Švankmajer (in the beginning of the career conjoined with above mentioned project "Laterna Magika"), a filmmaker and artist whose work spans several media. He is a self-labeled surrealist known for his animations and features, which have greatly influenced many artists worldwide.
Films The Shop on Main Street (1965), Closely Watched Trains (1967) and Kolya (1996) won the Academy Award for Best Foreign Language Film while six others earned 
a nomination: Loves of a Blonde (1966), The Fireman's Ball (1968), My Sweet Little Village (1986), The Elementary School (1991), Divided We Fall (2000) and Želary (2003). 
The Czech Lion is the highest award for Czech film achievement.
The Barrandov Studios in Prague are the largest film studios in country and one of the largest in Europe with many many popular film locations in the country. Filmmakers have come to Prague to shoot scenery no longer found in Berlin, Paris and Vienna. The city of Karlovy Vary was used as a location for the 2006 James Bond film Casino Royale.
Karlovy Vary International Film Festival is one of the oldest in the world and has become Central and Eastern Europe's leading film event. It is also one of few film festivals have been given competitive status by the FIAPF. Other film festivals held in the country include Febiofest, Jihlava International Documentary Film Festival, One World Film Festival, Zlín Film Festival and Fresh Film Festival.
Media.
Since the Czech Republic is a democratic republic, journalists and media should be free to write about everything, except supporting nazism, racism and violating the Czech law. The country was ranked as the 13th most free press in the World Freedom Index by Reporters Without Borders in 2014.
The most trustful media in the Czech Republic are public services. Czech Television, the only national public television service, owns the 24-hour news channel ČT24. Other public services are Czech Radio and the Czech News Agency (ČTK). Privately owned television services such as TV Nova, TV Prima and TV Barrandov are also very popular, with TV Nova being the most popular channel in the Czech Republic.
Newspapers are quite popular in the Czech Republic. The best-selling daily national newspapers are Blesk (average 1.15M daily readers), Mladá fronta DNES (average 752,000 daily readers) and Daily (average 72,000 daily readers).
Video games.
The Czech Republic is home to several globally successful video game developers, including Illusion Softworks (2K Czech), Bohemia Interactive, Keen Software House, Amanita Design and Madfinger Games. The Czech video game development scene has a long history, and a number of Czech games were produced for the ZX Spectrum, PMD 85 and Atari systems in the 1980s. In the early 2000s, a number of Czech games achieved international acclaim, including Hidden & Dangerous, , Vietcong and . Today, the most globally successful Czech games include ARMA, DayZ, Space Engineers, Machinarium, Shadowgun and BLACKHOLE. The Czech Game of the Year Awards are held annually at the Anifilm festival in Třeboň.
Cuisine.
Czech cuisine is marked by a strong emphasis on meat dishes. Pork is quite common; beef and chicken are also popular. Goose, duck, rabbit and wild game are served. Fish is rare, with the occasional exception of fresh trout and carp, which is served at Christmas.
Czech beer has a long and important history. The first brewery is known to have existed in 993 and the Czech Republic has the highest beer consumption per capita in the world. The famous "pilsner style beer" (pils) originated in the western Bohemian city of Plzeň, where the world's first-ever blond lager Pilsner Urquell is still being produced, making it the inspiration for more than two-thirds of the beer produced in the world today. Further south the town of České Budějovice, known as Budweis in German, lent its name to its beer, eventually known as Budweiser Budvar. Apart from these and other major brands, the Czech Republic also boasts a growing number of top quality small breweries and mini-breweries seeking to continue the age-old tradition of quality and taste, whose output matches the best in the world.
Tourism is slowly growing around the Southern Moravian region too, which has been producing wine since the Middle Ages; about 94% of vineyards in the Czech Republic are Moravian. Aside from slivovitz, Czech beer and wine, the Czechs also produce two unique liquors, Fernet Stock and Becherovka. Kofola is a non-alcoholic domestic cola soft drink which competes with Coca-Cola and Pepsi in popularity.
Some popular Czech dishes include:
There is also a large variety of local sausages, wurst, pâtés, and smoked and cured meats. Czech desserts include a wide variety of whipped cream, chocolate, and fruit pastries and tarts, crêpes, creme desserts and cheese, poppy seed filled and other types of traditional cakes such as "buchty", "koláče" and "štrůdl".
Sports.
Sports play a part in the life of many Czechs, who are generally loyal supporters of their favorite teams or individuals. The two leading sports in the Czech Republic are ice hockey and football. Tennis is also a very popular sport in the Czech Republic. The many other sports with professional leagues and structures include basketball, volleyball, team handball, track and field athletics and floorball. The Czech ice hockey team won the gold medal at the 1998 Winter Olympics and has won twelve gold medals at the World Championships (including 6 as Czechoslovakia), including three straight from 1999 to 2001. In total the country has won 14 gold medals in summer (plus 49 as Czechoslovakia) and five gold medals (plus two as Czechoslovakia) in winter Olympic history.
The Czechoslovakia national football team was a consistent performer on the international scene, with eight appearances in the FIFA World Cup Finals, finishing in second place in 1934 and 1962. The team also won the European Football Championship in 1976, came in third in 1980 and won the Olympic gold in 1980. After dissolution of Czechoslovakia, the Czech national football team finished in second (1996) and thrird (2004) place at the European Football Championship.
Sport is a source of strong waves of patriotism, usually rising several days or weeks before an event. The events considered the most important by Czech fans are: the Ice Hockey World Championships, Olympic Ice hockey tournament, UEFA European Football Championship, UEFA Champions League, FIFA World Cup and qualification matches for such events. In general, any international match of the Czech ice hockey or football national team draws attention, especially when played against a traditional rival.
The Czech Republic also has great influence in tennis, with such players as Ivan Lendl, 8 times Grand Slam singles champion, 2010 Wimbledon Championships – Men's Singles finalist Tomáš Berdych, 2011 and 2014 Wimbledon Championships – Women's Singles champion Petra Kvitová, 1998 Wimbledon Women's Singles title Jana Novotná, 2015 French Open – Women's Singles finalist Lucie Šafářová, 2011 Wimbledon Championships – Women's Doubles champion Květa Peschke and 18 time Grand Slam champion Martina Navratilova.
One of the most popular Czech sport is hiking, mainly in the Czech mountains. The word "tourist" in the Czech language also means a trekker or hiker. For beginners, thanks to the more than 100 years long tradition, there is a unique system of waymarking, one of the best in Europe. There is a network of around 40,000 km of perfectly marked short and long distance trails crossing the whole country and all the Czech mountains – not only in the Šumava Mountains, but also in the Vysočina, Krušné hory, Jizerské hory, Beskydy, Jeseníky, Orlické hory and Giant Mountains – Krkonoše.
External links.
Government
News
Statistics
Trade
Travel

</doc>
<doc id="5322" url="https://en.wikipedia.org/wiki?curid=5322" title="Czechoslovakia">
Czechoslovakia

Czechoslovakia or Czecho-Slovakia (Czech and , "Česko-Slovensko") was a sovereign state in Central Europe that existed from October 1918, when it declared its independence from the Austro-Hungarian Empire, until its peaceful dissolution into the Czech Republic and Slovakia on 1 January 1993.
From 1939 to 1945, following its forced division and partial incorporation into Nazi Germany, the state did not "de facto" exist but its government-in-exile continued to operate. 
From 1948 to 1990 Czechoslovakia was part of the Marxist–Leninist Warsaw Pact, which was formed in May 1955, and had a command or planned economy. A period of political liberalization in 1968, known as the Prague Spring, was forcibly ended when several other Warsaw Pact countries invaded. In 1989, as Marxist–Leninist governments and communism were ending all over Europe, Czechoslovaks peacefully deposed their government in the Velvet Revolution; state price controls were removed after a period of preparation. In 1993 Czechoslovakia divided into two sovereign states, the Czech Republic and Slovakia.
Basic characteristics.
The country was of generally irregular terrain. The western area was part of the north-central European uplands. The eastern region was composed of the northern reaches of the Carpathian Mountains and lands of the Danube River basin.
The weather is mild winters and mild summers. Influenced by the Atlantic ocean from the west, Baltic Sea from the north, and Mediterranean Sea from the south. There is no continental weather.
History.
Origins.
The area was long a part of the Austro Hungarian Empire until the Empire collapsed at the end of World War I. The new state was founded by Tomáš Garrigue Masaryk (1850–1937), who served as its first president from 14 November 1918 to 14 December 1935. He was succeeded by his close ally, Edvard Beneš (1884–1948).
The roots of Czech nationalism go back to the 19th century, when philologists and educators, influenced by Romanticism, promoted the Czech language and pride in the Czech people. Nationalism became a mass movement in the last half of the 19th century. Taking advantage of the opportunities for limited participation in political life available under the Austrian rule, Czech leaders such as historian František Palacký (1798–1876) founded many patriotic, self-help organizations which provided a chance for many of their compatriots to participate in communal life prior to independence. Palacký supported Austroslavism and worked for a reorganized and federal Austrian Empire, which would protect the Slavic speaking peoples of Central European against Russian and German threats.
An advocate of democratic reform and Czech autonomy within Austria-Hungary, Masaryk was elected twice to "Reichsrat" (Austrian Parliament), the first time being from 1891 to 1893 in the Young Czech Party and again from 1907 to 1914 in the Czech Realist Party, which he founded in 1889 with Karel Kramář and Josef Kaizl.
During World War I small numbers of Czechs, the Czechoslovak Legions, fought with the Allies in France and Italy, while large numbers deserted to Russia, in exchange for their support for the independence of Czechoslovakia from the Austrian Empire. With the outbreak of World War I, Masaryk began working for Czech independence in union with Slovakia. With Edvard Beneš and Milan Rastislav Štefánik, Masaryk visited several Western countries and won support from influential publicists.
Bohemia and Moravia, under Austrian rule, were Czech-speaking industrial centres, while Slovakia, which was part of Hungary, was an undeveloped agrarian region. Conditions were much better for the development of a mass national movement in the Czech lands than in Slovakia. Nevertheless, the two regions united and created a new nation.
First Czechoslovak Republic.
Formation.
The Bohemian Kingdom officially ceased to exist in 1918 by transformation into Czechoslovakia. Czechoslovakia was founded in October 1918, as one of the successor states of Austro-Hungarian Empire at the end of World War I and as part of the Treaty of St. Germain. It consisted of the present day territories of Bohemia, Moravia, Slovakia and Carpathian Ruthenia. Its territory included some of the most industrialized regions of the former Austria-Hungary.
Ethnicity.
The new country was a multi-ethnic state. The population consisted of Czechs (51%), Slovaks (16%), Germans (22%), Hungarians (5%) and Rusyns (4%). Many of the Germans, Hungarians, Ruthenians and Poles and some Slovaks, felt oppressed because the political elite did not generally allow political autonomy for minority ethnic groups. This policy, combined with increasing Nazi propaganda especially in the industrialized German-speaking Sudetenland, led to unrest among the non-Czech population.
The state proclaimed the official ideology that there are no Czechs and Slovaks, but only one nation of Czechoslovaks (see Czechoslovakism), to the disagreement of Slovaks and other ethnic groups. Once a unified Czechoslovakia was restored after World War II (after the country had been divided during the war), the conflict between the Czechs and the Slovaks surfaced again. The governments of Czechoslovakia and other eastern European nations deported ethnic Germans to the West, reducing the presence of minorities in the nation. Most of the Jews had been killed during the war by the Nazis and their allies.
"*Jews proclaimed themselves even as Germans or Hungarians (and Jews only by religion not ethnicity), the sum is, therefore, more than 100%."
Interwar period.
The period between the two world wars saw the flowering of democracy in Czechoslovakia. Of all the new states established in central Europe after 1918, only Czechoslovakia preserved a democratic government until the war broke out. The persistence of democracy suggests that Czechoslovakia was better prepared to maintain democracy than were other countries in the region. Thus, despite regional disparities, its level of development was much higher than that of neighboring states. The population was generally literate, and contained fewer alienated groups. The influence of these conditions was augmented by the political values of Czechoslovakia's leaders and the policies they adopted. Under Masaryk, Czech and Slovak politicians promoted progressive social and economic conditions that served to defuse discontent.
Foreign minister Beneš became the prime architect of the Czechoslovak-Romanian-Yugoslav alliance (the "Little Entente", 1921–38) directed against Hungarian attempts to reclaim lost areas. Beneš worked closely with France. Far more dangerous was the German element, which after 1933 became allied with the Nazis in Germany. The increasing feeling of inferiority among the Slovaks, who were hostile to the more numerous Czechs, weakened the country in the late 1930s. Many Slovaks supported an extreme nationalist movement and welcomed the puppet Slovak state set up under Hitler's control in 1939.
After 1933, Czechoslovakia remained the only democracy in central and eastern Europe.
Munich Agreement and German occupation.
In 1938, Adolf Hitler demanded control of the Sudetenland. Britain and France ceded control in the Appeasement at the Munich Conference, ignoring the military alliance Czechoslovakia had with France. First, in October 1938, Nazi Germany occupied and annexed the Sudetenland border region. In March 1939, the remainder ("rump") of Czechoslovakia was invaded and divided into the Protectorate of Bohemia and Moravia and the puppet Slovak State. Much of Slovakia and all of Carpathian Ruthenia were annexed by Hungary. Poland occupied Zaolzie, an area with Polish minority, in October 1938.
The eventual goal of the German state under Nazi leadership was to eradicate Czech nationality through assimilation, deportation, and extermination of the Czech intelligentsia; the intellectual elites and middle class made up a considerable number of the 200,000 people who passed through concentration camps and the 250,000 who died during German occupation. Under Generalplan Ost, it was assumed that around 50% Czechs would be fit for Germanization. The Czech intellectual elites were to be removed not only from Czech territories but from Europe completely. The authors of Generalplan Ost believed it would be best if they emigrated overseas, as even in Siberia they were considered a threat to German rule. Just like Jews, Poles, Serbs, and several other nations, Czechs were considered to be untermenschen by the Nazi state. In 1940, in a secret Nazi plan for the Germanization of the Protectorate of Bohemia and Moravia it was declared that those considered to be of racially Mongoloid origin and the Czech intelligentsia were not to be Germanized and about half of the Czech population were suitable for Germanization.
The deportation of Jews to concentration camps was organized under the direction of Reinhard Heydrich, and the fortress town of Terezín was made into a ghetto way station for Jewish families. On 4 June 1942 Heydrich died after being wounded by an assassin in Operation Anthropoid. Heydrich's successor, Colonel General Kurt Daluege, ordered mass arrests and executions and the destruction of the villages of Lidice and Ležáky. In 1943 the German war effort was accelerated. Under the authority of Karl Hermann Frank, German minister of state for Bohemia and Moravia, some 350,000 Czech labourers were dispatched to the Reich. Within the protectorate, all non-war-related industry was prohibited. Most of the Czech population obeyed quiescently up until the final months preceding the end of the war, while thousands were involved in the resistance movement.
For the Czechs of the Protectorate Bohemia and Moravia, German occupation was a period of brutal oppression. Czech losses resulting from political persecution and deaths in concentration camps totaled between 36,000 and 55,000. The Jewish population of Bohemia and Moravia (118,000 according to the 1930 census) was virtually annihilated. Many Jews emigrated after 1939; more than 70,000 were killed; 8,000 survived at Terezín. Several thousand Jews managed to live in freedom or in hiding throughout the occupation.
Despite the estimated 136,000 deaths at the hands of the Nazi regime, the population in the Reichsprotektorate saw a net increase during the war years of approximately 250,000 in line with an increased birth rate.
On 9 May 1945, Soviet Red Army troops entered Prague. 
On May 3, 1945, the third US Army of General Patton entered Pilsen from the south west.
Communist Czechoslovakia.
After World War II, pre-war Czechoslovakia was re-established, with the exception of Subcarpathian Ruthenia, which was annexed by the Soviet Union and incorporated into the Ukrainian Soviet Socialist Republic. The Beneš decrees were promulgated concerning ethnic Germans (see Potsdam Agreement) and ethnic Hungarians. Under the decrees, citizenship was abrogated for people of German and Hungarian ethnic origin, who had accepted German or Hungarian citizenship during the occupations. In 1948, this provision was cancelled for the Hungarians, but only partially for the Germans. The government then confiscated the property of the Germans and expelled about 90% of the ethnic German population, over 2 million people. Those who remained were collectively accused of supporting the Nazis after the Munich Agreement, as 97.32% of Sudeten Germans voted for the NSDAP in the December 1938 elections. Almost every decree explicitly stated that the sanctions did not apply to antifascists. Some 250,000 Germans, many married to Czechs, some antifascists, and also those required for the post-war reconstruction of the country, remained in Czechoslovakia. The Beneš Decrees still causes controversy among nationalist groups in the Czech Republic, Germany, Austria and Hungary.
Carpathian Ruthenia (Podkarpatská Rus) was occupied by (and in June 1945 formally ceded to) the Soviet Union. In the 1946 parliamentary election, the Communist Party of Czechoslovakia was the winner in the Czech lands, and the Democratic Party won in Slovakia. In February 1948 the Communists seized power. Although they would maintain the fiction of political pluralism through the existence of the National Front, except for a short period in the late 1960s (the Prague Spring) the country was characterized by the absence of liberal democracy. Since citizens lacked significant electoral methods of registering protest against government policies, periodically there were street protests that became violent. Such was the case in the town of Plzeň, where riots occurred in 1953, reflecting economic discontent. Police and army units put down the rebellion, and hundreds were injured but no one was killed. While its economy remained more advanced than those of its neighbours in Eastern Europe, Czechoslovakia grew increasingly economically weak relative to Western Europe.
In 1968, when the reformer Alexander Dubček was appointed to the key post of First Secretary of the Czechoslovak Communist Party, there was a brief period of liberalization known as the Prague Spring. In response, after failing to persuade the Czechoslovak leaders to change course, five other Eastern Bloc members of the Warsaw Pact invaded. Soviet tanks rolled into Czechoslovakia on the night of 20–21 August 1968. The General Secretary of the Soviet Communist Party Leonid Brezhnev viewed this intervention as vital to the preservation of the Soviet, socialist system and vowed to intervene in any state that sought to replace Marxism-Leninism with capitalism. In the week after the invasion there was a spontaneous campaign of civil resistance against the occupation. This resistance involved a wide range of acts of non-cooperation and defiance: this was followed by a period in which the Czechoslovak Communist Party leadership, having been forced in Moscow to make concessions to the Soviet Union, gradually put the brakes on their earlier liberal policies. In April 1969 Dubček was finally dismissed from the First Secretaryship of the Czechoslovak Communist Party. Meanwhile, one plank of the reform programme had been carried out: in 1968-9, Czechoslovakia was turned into a federation of the Czech Socialist Republic and Slovak Socialist Republic. The theory was that under the federation, social and economic inequities between the Czech and Slovak halves of the state would be largely eliminated. A number of ministries, such as education, now became two formally equal bodies in the two formally equal republics. However, the centralised political control by the Czechoslovak Communist Party severely limited the effects of federalisation.
The 1970s saw the rise of the dissident movement in Czechoslovakia, represented among others by Václav Havel. The movement sought greater political participation and expression in the face of official disapproval, manifested in limitations on work activities, which went as far as a ban on professional employment, the refusal of higher education for the dissidents' children, police harassment and prison.
After 1989.
In 1989, the Velvet Revolution restored democracy. This occurred at around the same time as the fall of communism in Romania, Bulgaria, Hungary and Poland. Within three years communist rule was extirpated from Europe.
Unlike Yugoslavia and the Soviet Union, the end of communism in this country did not automatically mean the end of the "communist" name: the word "socialist" was removed from the name on 29 March 1990 and replaced by "federal".
In 1992, because of growing nationalist tensions in the government, Czechoslovakia was peacefully dissolved by parliament. On 1 January 1993 it formally separated into two independent countries, the Czech Republic and Slovakia.
Foreign policy.
International agreements and membership.
In the 1930s, the nation formed a military alliance with France and Great Britain, which collapsed in the Munich Agreement of 1938. After World War II, active participant in Council for Mutual Economic Assistance (Comecon), Warsaw Pact, United Nations and its specialized agencies; signatory of conference on Security and Cooperation in Europe.
Politics.
After World War II, a political monopoly was held by the Communist Party of Czechoslovakia (KSC). Gustáv Husák was elected first secretary of the KSC in 1969 (changed to general secretary in 1971) and president of Czechoslovakia in 1975. Other parties and organizations existed but functioned in subordinate roles to the KSC. All political parties, as well as numerous mass organizations, were grouped under umbrella of the National Front. Human rights activists and religious activists were severely repressed.
Constitutional development.
Czechoslovakia had the following constitutions during its history (1918–1992):
Economy.
Before World War II, the economy was about the fourth in industrial states in Europe. The state was based on strong economy, manufacturing cars (Skoda, Tatra), streetcars (trolleys), aeroplanes, ships, ship engines (Skoda), canons, shoes (Bata), turbines. It was the industrial workshop for Austro-Hungarian empire. The Slovak lands were more in agriculture.
After World War II, the economy was centrally planned, with command links controlled by the communist party, similarly to the Soviet Union. The large metallurgical industry was dependent on imports of iron and non-ferrous ores.
Resource base.
After World War II, the country was short of energy, relying on imported crude oil and natural gas from Soviet Union, domestic brown coal, and nuclear and hydroelectric energy. Energy constraints were a major factor in the 1980s.
Education.
Education was free at all levels and compulsory from age 6 to 15. The vast majority of the population was literate. There was a highly developed system of apprenticeship training and vocational schools supplemented general secondary schools and institutions of higher education.
Religion.
In 1991: Roman Catholics 46%, Evangelical Lutheran 5.3%, Atheist 30%, n/a 17%, but there were huge differences in religious practices between the two constituent republics; see Czech Republic and Slovakia.
Health, social welfare and housing.
After World War II, free health care was available to all citizens. National health planning emphasised preventive medicine; factory and local health care centres supplemented hospitals and other inpatient institutions. There was substantial improvement in rural health care during the 1960s and 1970s.
Mass media.
During Communist rule, the mass media in Czechoslovakia were controlled by the Communist Party. Private ownership of any publication or agency of the mass media was generally forbidden, although churches and other organizations published small periodicals and newspapers. Even with this information monopoly in the hands of organizations under KSČ control, all publications were reviewed by the government's Office for Press and Information.
Sports.
The Czechoslovakia national football team was a consistent performer on the international scene, with eight appearances in the FIFA World Cup Finals, finishing in second place in 1934 and 1962. The team also won the European Football Championship in 1976, came in third in 1980 and won the Olympic gold in 1980.
The Czechoslovak national ice hockey team won many medals from the world championships and Olympic Games. Peter Šťastný, Jaromír Jágr, Dominik Hašek, Peter Bondra, Petr Klíma, Marián Gáborík, and Pavol Demitra all come from Czechoslovakia.
Emil Zátopek, winner of four Olympic gold medals in athletics, is considered one of the top athletes in history.
Věra Čáslavská was an Olympic gold medallist in gymnastics, winning seven gold medals and four silver medals. She represented Czechoslovakia in three consecutive Olympics.
The famous tennis players Ivan Lendl, Miloslav Mečíř, Hana Mandlíková, Martina Hingis, Martina Navratilova and Daniela Hantuchová were born in Czechoslovakia.

</doc>
<doc id="5323" url="https://en.wikipedia.org/wiki?curid=5323" title="Computer science">
Computer science

Computer science deals with the theoretical foundations of information and computation, together with practical techniques for the implementation and application of these foundations.
Computer science is the scientific and practical approach to computation and its applications. It is the systematic study of the feasibility, structure, expression, and mechanization of the methodical procedures (or algorithms) that underlie the acquisition, representation, processing, storage, communication of, and access to information. An alternate, more succinct definition of computer science is the study of automating algorithmic processes that scale. A computer scientist specializes in the theory of computation and the design of computational systems.
Its fields can be divided into a variety of theoretical and practical disciplines. Some fields, such as computational complexity theory (which explores the fundamental properties of computational and intractable problems), are highly abstract, while fields such as computer graphics emphasize real-world visual applications. Still other fields focus on challenges in implementing computation. For example, programming language theory considers various approaches to the description of computation, while the study of computer programming itself investigates various aspects of the use of programming language and complex systems. Human–computer interaction considers the challenges in making computers and computations useful, usable, and universally accessible to humans.
History.
The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Further, algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment. The ancient Sanskrit treatise Shulba Sutras, or "Rules of the Chord", is a book of algorithms written in 800 BC for constructing geometric objects like altars using a peg and chord, an early precursor of the modern field of computational geometry.
Blaise Pascal designed and constructed the first working mechanical calculator, Pascal's calculator, in 1642. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. He may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he released his simplified arithmometer, which was the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first "automatic mechanical calculator", his Difference Engine, in 1822, which eventually gave him the idea of the first "programmable mechanical calculator", his Analytical Engine. He started developing this machine in 1834 and "in less than two years he had sketched out many of the salient features of the modern computer". "A crucial step was the adoption of a punched card system derived from the Jacquard loom" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first computer program. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as "Babbage's dream come true".
During the 1940s, as new and more powerful computing machines were developed, the term "computer" came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science degree program in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.
Although many initially believed it was impossible that computers themselves could actually be a scientific field of study, in the late fifties it gradually became accepted among the greater academic population. It is the now well-known IBM brand that formed part of the computer science revolution during this time. IBM (short for International Business Machines) released the IBM 704 and later the IBM 709 computers, which were widely used during the exploration period of such devices. "Still, working with the IBM was frustrating [… if you had misplaced as much as one letter in one instruction, the program would crash, and you would have to start the whole process over again". During the late 1950s, the computer science discipline was very much in its developmental stages, and such issues were commonplace.
Time has seen significant improvements in the usability and effectiveness of computing technology. Modern society has seen a significant shift in the users of computer technology, from usage only by experts and professionals, to a near-ubiquitous user base. Initially, computers were quite costly, and some degree of human aid was needed for efficient use—in part from professional computer operators. As computer adoption became more widespread and affordable, less human assistance was needed for common usage.
Contributions.
Despite its short history as a formal academic discipline, computer science has made a number of fundamental contributions to science and society—in fact, along with electronics, it is a founding science of the current epoch of human history called the Information Age and a driver of the Information Revolution, seen as the third major leap in human technological progress after the Industrial Revolution (1750–1850 CE) and the Agricultural Revolution (8000–5000 BC).
These contributions include:
Philosophy.
A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the "rationalist paradigm" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the "technocratic paradigm" (which might be found in engineering approaches, most prominently in software engineering), and the "scientific paradigm" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).
Name of the field.
Although first proposed in 1956, the term "computer science" appears in a 1959 article in "Communications of the ACM",
in which Louis Fein argues for the creation of a "Graduate School in Computer Sciences" analogous to the creation of Harvard Business School in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.
His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such programs, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term "computing science", to emphasize precisely that difference. Danish scientist Peter Naur suggested the term "datalogy", to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a distinct field of data analysis, including statistics and databases.
Also, in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the "Communications of the ACM"—"turingineer", "turologist", "flow-charts-man", "applied meta-mathematician", and "applied epistemologist". Three months later in the same journal, "comptologist" was suggested, followed next year by "hypologist". The term "computics" has also been suggested. In Europe, terms derived from contracted translations of the expression "automatic information" (e.g. "informazione automatica" in Italian) or "information and mathematics" are often used, e.g. "informatique" (French), "Informatik" (German), "informatica" (Italian, Dutch), "informática" (Spanish, Portuguese), "informatika" (Slavic languages and Hungarian) or "pliroforiki" ("πληροφορική", which means informatics) in Greek. Similar words have also been adopted in the UK (as in "the School of Informatics of the University of Edinburgh").
A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that "computer science is no more about computers than astronomy is about telescopes." The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been much cross-fertilization of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as philosophy, cognitive science, linguistics, mathematics, physics, biology, statistics, and logic.
Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel and Alan Turing, and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.
The relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term "software engineering" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.
The academic, political, and funding aspects of computer science tend to depend on whether a department formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.
Areas of computer science.
As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.
CSAB, formerly called "Computing Sciences Accreditation Board"—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: "theory of computation", "algorithms and data structures", "programming methodology and languages", and "computer elements and architecture". In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.
Theoretical computer science.
The broader field of theoretical computer science encompasses both the classical theory of computation and a wide range of other topics that focus on the more abstract, logical, and mathematical aspects of computing.
Theory of computation.
According to Peter Denning, the fundamental question underlying computer science is, "What can be (efficiently) automated?" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.
The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.
Information and coding theory.
Information theory is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.
Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.
Algorithms and data structures.
Algorithms and data structures is the study of commonly used computational methods and their computational efficiency.
Programming language theory.
Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.
Formal methods.
Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.
Applied computer science.
Applied computer science aims at identifying certain computer science concepts that can be used directly in solving real world problems.
Artificial intelligence.
Artificial intelligence (AI) aims to or is required to synthesise goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting-point in the late 1940s was Alan Turing's question "Can computers think?", and the question remains effectively unanswered although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.
Computer architecture and engineering.
Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. The field often involves disciplines of computer engineering and electrical engineering, selecting and interconnecting hardware components to create computers that meet functional, performance, and cost goals.
Computer performance analysis.
Computer performance analysis is the study of work flowing through computers with the general goals of improving throughput, controlling response time, using resources efficiently, eliminating bottlenecks, and predicting performance under anticipated peak loads.
Computer graphics and visualization.
Computer graphics is the study of digital visual contents, and involves synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.
Computer security and cryptography.
Computer security is a branch of computer technology, whose objective includes protection of information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. Cryptography is the practice and study of hiding (encryption) and therefore deciphering (decryption) information. Modern cryptography is largely related to computer science, for many encryption and decryption algorithms are based on their computational complexity.
Computational science.
Computational science (or scientific computing) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. In practical use, it is typically the application of computer simulation and other forms of computation to problems in various scientific disciplines.
Computer networks.
This branch of computer science aims to manage networks between computers worldwide.
Concurrent, parallel and distributed systems.
Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. A distributed system extends the idea of concurrency onto multiple computers connected through a network. Computers within the same distributed system have their own private memory, and information is often exchanged among themselves to achieve a common goal.
Databases.
A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages.
Software engineering.
Software engineering is the study of designing, implementing, and modifying software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it doesn't just deal with the creation or manufacture of new software, but its internal maintenance and arrangement. Both computer applications software engineers and computer systems software engineers are projected to be among the fastest growing occupations from 2008 to 2018.
The great insights of computer science.
The philosopher of computing Bill Rapaport noted three "Great Insights of Computer Science":
Academia.
Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.
Education.
Since computer science is a relatively new field, it is not as widely taught in schools and universities as other academic subjects. For example, in 2014, Code.org estimated that only 10 percent of high schools in the United States offered computer science education. A 2010 report by Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA) revealed that only 14 out of 50 states have adopted significant education standards for high school computer science. However, computer science education is growing. Some countries, such as Israel, New Zealand and South Korea, have already included computer science in their respective national secondary education curriculum. Several countries are following suit.
In most countries, there is a significant gender gap in computer science education. For example, in the US about 20% of computer science degrees in 2012 were conferred to women. This gender gap also exists in other Western countries. However, in some parts of the world, the gap is small or nonexistent. In 2011, approximately half of all computer science degrees in Malaysia were conferred to women. In 2001, women made up 54.5% of computer science graduates in Guyana.

</doc>
<doc id="5324" url="https://en.wikipedia.org/wiki?curid=5324" title="Catalan">
Catalan

Catalan may refer to:

</doc>
<doc id="5326" url="https://en.wikipedia.org/wiki?curid=5326" title="Creationism">
Creationism

Creationism is the religious belief that the Universe and life originated "from specific acts of divine creation." For young Earth creationists, this includes a biblical literalist interpretation of the Genesis creation narrative and the rejection of the scientific theory of evolution. As the history of evolutionary thought developed from the 18th century on, various views aimed at reconciling the Abrahamic religions and Genesis with biology and other sciences developed in Western culture. Those holding that species had been created separately (such as Philip Gosse in 1857) were generally called "advocates of creation" but were also called "creationists," as in private correspondence between Charles Darwin and his friends. As the creation–evolution controversy developed over time, the term "anti-evolutionists" became common. In 1929 in the United States, the term "creationism" first became associated with Christian fundamentalists, specifically with their rejection of human evolution and belief in a young Earth—although this usage was contested by other groups, such as old Earth creationists and evolutionary creationists, who hold different concepts of creation, such as the acceptance of the age of the Earth and biological evolution as understood by the scientific community.
Today, the American Scientific Affiliation, a prominent religious organization in the US, recognizes that there are different opinions among creationists on the method of creation, while acknowledging unity on the Abrahamic belief that God "created the universe." Since the 1920s, literalist creationism in America has contested scientific theories, such as that of evolution, which derive from natural observations of the Universe and life. Literalist creationists believe that evolution cannot adequately account for the history, diversity, and complexity of life on Earth. Fundamentalist creationists of the Christian faith usually base their belief on a literal reading of the Genesis creation narrative. Other religions either share the Genesis creation myth or have different deity-led creation myths, while different members of individual faiths vary in their acceptance of scientific findings.
When scientific research produces empirical evidence and theoretical conclusions which contradict a literalist creationist interpretation of scripture, young Earth creationists often reject the conclusions of the research or its underlying scientific theories or its methodology. This tendency has led to political and theological controversy. Pseudoscientific branches of creationism include creation science, flood geology, and intelligent design, as well as subsets of pseudoarchaeology, pseudohistory, and even pseudolinguistics. Creationists commonly reject the scientific consensus on evolution and common descent, the geological history of the Earth, the formation of the Solar System and the origin of the Universe.
Theistic evolution, also known as Evolutionary Creationism, is an attempt to reconcile religion with scientific findings on the age of the Earth and evolution. The term covers a range of views including Old Earth creationism.
History.
The term "creationist" to describe a proponent of creationism was first used in a letter by Charles Darwin in 1856. In the 1920s, the term became particularly associated with Christian fundamentalist movements that insisted on a literalist interpretation of the Genesis creation narrative and likewise opposed the idea of human evolution. These groups succeeded in getting teaching of evolution banned in American public schools, then from the mid-1960s the young Earth creationists promoted the teaching of "scientific creationism" using "Flood geology" in public school science classes as support for a purely literal reading of the Book of Genesis. After the legal judgment of the case "Daniel v. Waters" (1975) ruled that teaching creationism in public schools contravened the Establishment Clause of the First Amendment to the United States Constitution, the content was stripped of overt biblical references and renamed creation science. When the court case "Edwards v. Aguillard" (1987) ruled that creation science similarly contravened the constitution, all references to "creation" in a draft school textbook were changed to refer to intelligent design, which was presented by creationists as a new scientific theory. The "Kitzmiller v. Dover" (2005) ruling concluded that intelligent design is not science and contravenes the constitutional restriction on teaching religion in public school science classes. In September 2012, Bill Nye ("The Science Guy") expressed his concern that "creationist views" threaten science education and innovations in the US.
Early and medieval times.
The first-century Jewish philosopher Philo of Alexandria admired the literal narrative of passages concerning the Patriarchs, but in other passages viewed the literal interpretation as being for those unable to see an underlying deeper meaning. For example, he noted that Moses said the world was created in six days, but did not consider this as a length of time as "we must think of God as doing all things simultaneously" and the six days were mentioned because of a need for order and according with a perfect number. Genesis was about real events, but God through Moses described them in figurative or allegorical language.
The early Christian Church Fathers largely read creation history as an allegory, and followed Philo's ideas of time beginning with an instantaneous creation without the convention that a day was the conventional time period. Christian orthodoxy rejected the second-century Gnostic belief that the Book of Genesis was purely allegorical, but without taking a purely literal view of the texts. Thus, Origen believed that the physical world is ‘literally’ a creation of God, but did not take the chronology or the days as ‘literal’. Similarly, Saint Basil the Great in the fourth century while literal in many ways, described creation as instantaneous and timeless, being immeasurable and indivisible.
Augustine of Hippo in "On the Literal Meaning of Genesis" was insistent that the Book of Genesis describes the creation of physical objects, but also shows creation occurring simultaneously, with the days of creation being categories for didactic reasons, a logical framework which has nothing to do with time. For him, light was the illumination of angels rather than visible light, and spiritual light was just as literal as physical light. Augustine emphasized that the text was difficult to understand and should be reinterpreted as new knowledge became available. In particular, Christians should not make absurd dogmatic interpretations of scripture which contradict what people know from physical evidence.
In the 13th century, Thomas Aquinas, like Augustine, asserted the need to hold the truth of scripture without wavering while cautioning "that since Holy Scripture can be explained in a multiplicity of senses, one should not adhere to a particular explanation, only in such measure as to be ready to abandon it if it be proved with certainty to be false; lest holy Scripture be exposed to the ridicule of unbelievers, and obstacles be placed to their believing."
Impact of the Reformation.
From 1517 the Protestant Reformation brought a new emphasis on lay literacy. Martin Luther taught young Earth creationism, that creation took six literal days about 6000 years ago. John Calvin also rejected instantaneous creation, but criticised those who, contradicting the contemporary understanding of nature, asserted that there are "waters above the heavens."
Discoveries of new lands brought knowledge of a huge diversity of life, and a new belief developed that each of these biological species had been individually created by God. In 1605, Francis Bacon emphasized that the works of God in nature teach us how to interpret the word of God in the Bible, and his Baconian method introduced the empirical approach which became central to modern science. Natural theology developed the study of nature with the expectation of finding evidence supporting Christianity, and numerous attempts were made to reconcile new knowledge with the biblical deluge myth and story of Noah's Ark.
In 1650 the Archbishop of Armagh, James Ussher, published the Ussher chronology based on Bible history giving a date for Creation of 4004 BC. This was generally accepted, but the development of modern geology in the 18th and 19th centuries found geological strata and fossil sequences indicating an ancient Earth. Catastrophism was favoured in England as supporting the biblical flood, but this was found to be untenable and by 1850 all geologists and most Evangelical Christians had adopted various forms of old Earth creationism.
Modern science.
From around the start of the 19th century, ideas such as Jean-Baptiste Lamarck's concept of transmutation of species had gained some supporters in Paris and Edinburgh, mostly amongst anatomists. The anonymous publication of "Vestiges of the Natural History of Creation" in 1844 aroused wide public interest with support from Quakers and Unitarians, but was strongly criticised by the scientific community, which called for solidly backed science. In 1859, Charles Darwin's "On the Origin of Species" provided that evidence from an authoritative and respected source, and within a decade or so convinced scientists that evolution occurs. This view clashed with that of conservative evangelicals in the Church of England, but their attention quickly turned to the much greater uproar about "Essays and Reviews" by liberal Anglican theologians, which introduced into the controversy "higher criticism" begun by Erasmus centuries earlier. This book re-examined the Bible and cast doubt on a literal interpretation. By 1875 most American naturalists supported ideas of theistic evolution, often involving special creation of human beings.
At this time those holding that species had been separately created were generally called "advocates of creation," but they were occasionally called "creationists" in private correspondence between Charles Darwin and his friends. The term appears in letters Darwin wrote between 1856 and 1863, and was also used in a response by Charles Lyell.
Types of creationism.
Several attempts have been made to categorize the different types of creationism, and create a "taxonomy" of creationists. Creationism (broadly construed) covers a spectrum of beliefs which have been categorized into the general types listed below.
Young Earth creationism.
Young Earth creationists believe that God created the Earth within the last ten thousand years, literally as described in the Genesis creation narrative, within the approximate time-frame of biblical genealogies (detailed for example in the Ussher chronology). Most young Earth creationists believe that the Universe has a similar age as the Earth. A few assign a much older age to the Universe than to Earth. Creationist cosmologies give the Universe an age consistent with the Ussher chronology and other young Earth time frames. Other young Earth creationists believe that the Earth and the Universe were created with the appearance of age, so that the world appears to be much older than it is, and that this appearance is what gives the geological findings and other methods of dating the Earth and the Universe their much longer timelines.
The Christian organizations Institute for Creation Research (ICR) and the Creation Research Society (CRS) both promote young Earth creationism in the US. Another organization with similar views, Answers in Genesis (AiG)—based in both the US and the United Kingdom—has opened the Creation Museum in Petersburg, Kentucky, to promote young Earth creationism. Creation Ministries International promotes young Earth views in Australia, Canada, South Africa, New Zealand, the US, and the UK. Among Roman Catholics, the Kolbe Center for the Study of Creation promotes similar ideas.
Creation science.
Creation science, or initially scientific creationism, is a pseudoscience that emerged in the 1960s with proponents aiming to have young Earth creationist beliefs taught in school science classes as a counter to teaching of evolution. Common features of Creation science argument include: creationist cosmologies which accommodate a Universe on the order of thousands of years old, criticism of radiometric dating through a technical argument about radiohalos, explanations for the fossil record as a record of the Genesis flood narrative (see Flood geology), and explanations for the present diversity as a result of pre-designed genetic variability and partially due to the rapid degradation of the perfect genomes God placed in "created kinds" or "Baramin" (see creationist biology) due to mutations.
Old Earth creationism.
Old Earth creationism holds that the physical universe was created by God, but that the creation event described in the Book of Genesis is to be taken figuratively. This group generally believes that the age of the Universe and the age of the Earth are as described by astronomers and geologists, but that details of modern evolutionary theory are questionable.
Old Earth creationism itself comes in at least three types:
Gap creationism.
Gap creationism, also called "restoration creationism," holds that life was recently created on a pre-existing old Earth. This theory relies on a particular interpretation of . It is considered that the words "formless" and "void" in fact denote waste and ruin, taking into account the original Hebrew and other places these words are used in the Old Testament. Genesis 1:1-2 is consequently translated:
Thus, the six days of creation (verse 3 onwards) start sometime after the Earth was "without form and void." This allows an indefinite "gap" of time to be inserted after the original creation of the Universe, but prior to the creation according to Genesis, (when present biological species and humanity were created). Gap theorists can therefore agree with the scientific consensus regarding the age of the Earth and Universe, while maintaining a literal interpretation of the biblical text.
Some gap theorists expand the basic theory by proposing a "primordial creation" of biological life within the "gap" of time. This is thought to be "the world that then was" mentioned in 2 Peter 3:3-7. Discoveries of fossils and archaeological ruins older than 10,000 years are generally ascribed to this "world that then was," which may also be associated with Lucifer's rebellion. These views became popular with publications of Hebrew Lexicons such as "Strong's Concordance", and Bible commentaries such as the "Scofield Reference Bible" and "The Companion Bible".
Day-age creationism.
Day-age creationism states that the "six days" of the Book of Genesis are not ordinary 24-hour days, but rather much longer periods (for instance, each "day" could be the equivalent of millions, or billions of years of human time). Physicist Gerald Schroeder is one such proponent of this view. This theory often states that the Hebrew word "yôm," in the context of Genesis 1, can be properly interpreted as "age." Some adherents claim we are still living in the seventh age ("seventh day").
Strictly speaking, day-age creationism is not so much a creationist theory as a hermeneutic option which may be combined with theories such as progressive creationism.
Progressive creationism.
Progressive creationism holds that species have changed or evolved in a process continuously guided by God, with various ideas as to how the process operated—though it is generally taken that God directly intervened in the natural order at key moments in Earth history. This view accepts most of modern physical science including the age of the Earth, but rejects much of modern evolutionary biology or looks to it for evidence that evolution by natural selection alone is incorrect. Organizations such as Reasons To Believe, founded by Hugh Ross, promote this theory.
Progressive creationism can be held in conjunction with hermeneutic approaches to the Genesis creation narrative such as the day-age theory or framework/metaphoric/poetic views.
Neo-creationism.
Neo-Creationists intentionally distance themselves from other forms of creationism, preferring to be known as wholly separate from creationism as a philosophy. Neo-creationism aims to restate creationism in terms more likely to be well received by the public, policy makers, educators and the scientific community. It aims to re-frame the debate over the origins of life in non-religious terms and without appeals to scripture, and to bring the debate before the public.
Neo-creationism sees ostensibly objective mainstream science as a dogmatically atheistic religion. Neo-creationists argue that the scientific method excludes certain explanations of phenomena, particularly where they point towards supernatural elements. They argue that this effectively excludes any possible religious insight from contributing to a scientific understanding of the Universe. Neo-creationists also argue that science, as an "atheistic enterprise," lies at the root of many of contemporary society's ills including social unrest and family breakdown.
The intelligent design movement arguably represents the most recognized form of neo-creationism in the US. Unlike their philosophical forebears, neo-creationists largely do not believe in many of the traditional cornerstones of creationism such as a young Earth, or in a dogmatically literal interpretation of the Bible. Common to all forms of neo-creationism is a rejection of naturalism, usually made together with a tacit admission of supernaturalism, and an open and often hostile opposition to what they term "Darwinism," meaning evolution.
Intelligent design.
Intelligent design (ID) is the pseudoscientific view that "certain features of the universe and of living things are best explained by an intelligent cause, not an undirected process such as natural selection." All of its leading proponents are associated with the Discovery Institute, a think tank whose Wedge strategy aims to replace the scientific method with "a science consonant with Christian and theistic convictions" which accepts supernatural explanations. It is widely accepted in the scientific and academic communities that intelligent design is a form of creationism, and is sometimes referred to as "intelligent design creationism."
ID originated as a re-branding of creation science in an attempt to avoid a series of court decisions ruling out the teaching of creationism in American public schools, and the Discovery Institute has run a series of campaigns to change school curricula. In Australia, where curricula are under the control of state governments rather than local school boards, there was a public outcry when the notion of ID being taught in science classes was raised by the Federal Education Minister Brendan Nelson; the minister quickly conceded that the correct forum for ID, if it were to be taught, is in religious or philosophy classes.
In the US, teaching of intelligent design in public schools has been decisively ruled by a federal district court to be in violation of the Establishment Clause of the First Amendment to the United States Constitution. In Kitzmiller v. Dover, the court found that intelligent design is not science and "cannot uncouple itself from its creationist, and thus religious, antecedents," and hence cannot be taught as an alternative to evolution in public school science classrooms under the jurisdiction of that court. This sets a persuasive precedent, based on previous US Supreme Court decisions in "Edwards v. Aguillard" and "Epperson v. Arkansas" (1968), and by the application of the Lemon test, that creates a legal hurdle to teaching intelligent design in public school districts in other federal court jurisdictions.
Obscure and largely discounted beliefs.
In astronomy, the geocentric model (also known as geocentrism, or the Ptolemaic system), is a description of the Cosmos where Earth is at the orbital center of all celestial bodies. This model served as the predominant cosmological system in many ancient civilizations such as ancient Greece. As such, they assumed that the Sun, Moon, stars, and naked eye planets circled Earth, including the noteworthy systems of Aristotle (see Aristotelian physics) and Ptolemy.
Articles arguing that geocentrism was the biblical perspective appeared in some early creation science newsletters associated with the Creation Research Society pointing to some passages in the Bible, which, when taken literally, indicate that the daily apparent motions of the Sun and the Moon are due to their actual motions around the Earth rather than due to the rotation of the Earth about its axis for example, Joshua 10:12 where the Sun and Moon are said to stop in the sky, and Psalms 93:1 where the world is described as immobile. Contemporary advocates for such religious beliefs include Robert Sungenis, co-author of the self-published "Galileo Was Wrong: The Church Was Right" (2006). These people subscribe to the view that a plain reading of the Bible contains an accurate account of the manner in which the Universe was created and requires a geocentric worldview. Most contemporary creationist organizations reject such perspectives.
Omphalos hypothesis.
The Omphalos hypothesis argues that in order for the world to be functional, God must have created a mature Earth with mountains and canyons, rock strata, trees with growth rings, and so on; therefore "no" evidence that we can see of the presumed age of the Earth and age of the Universe can be taken as reliable. The idea has seen some revival in the 20th century by some modern creationists, who have extended the argument to light that originates in far-off stars and galaxies (see the "starlight problem").
Theistic evolution.
Theistic evolution, or evolutionary creation, is a belief that "the personal God of the Bible created the universe and life through evolutionary processes." According to the American Scientific Affiliation:
Through the 19th century the term "creationism" most commonly referred to direct creation of individual souls, in contrast to traducianism. Following the publication of "Vestiges of the Natural History of Creation", there was interest in ideas of Creation by divine law. In particular, the liberal theologian Baden Powell argued that this illustrated the Creator's power better than the idea of miraculous creation, which he thought ridiculous. When "On the Origin of Species" was published, the cleric Charles Kingsley wrote of evolution as "just as noble a conception of Deity." Darwin's view at the time was of God creating life through the laws of nature, and the book makes several references to "creation," though he later regretted using the term rather than calling it an unknown process. In America, Asa Gray argued that evolution is the secondary effect, or "modus operandi", of the first cause, design, and published a pamphlet defending the book in theistic terms, "Natural Selection not inconsistent with Natural Theology". Theistic evolution, also called, evolutionary creation, became a popular compromise, and St. George Jackson Mivart was among those accepting evolution but attacking Darwin's naturalistic mechanism. Eventually it was realised that supernatural intervention could not be a scientific explanation, and naturalistic mechanisms such as neo-Lamarckism were favoured as being more compatible with purpose than natural selection.
Some theists took the general view that, instead of faith being in opposition to biological evolution, some or all classical religious teachings about Christian God and creation are compatible with some or all of modern scientific theory, including specifically evolution; it is also known as "evolutionary creation." In Evolution versus Creationism, Eugenie Scott and Niles Eldredge state that it is in fact a type of evolution.
It generally views evolution as a tool used by God, who is both the first cause and immanent sustainer/upholder of the Universe; it is therefore well accepted by people of strong theistic (as opposed to deistic) convictions. Theistic evolution can synthesize with the day-age creationist interpretation of the Genesis creation narrative; however most adherents consider that the first chapters of the Book of Genesis should not be interpreted as a "literal" description, but rather as a literary framework or allegory.
From a theistic viewpoint, the underlying laws of nature were designed by God for a purpose, and are so self-sufficient that the complexity of the entire physical universe evolved from fundamental particles in processes such as stellar evolution, life forms developed in biological evolution, and in the same way the origin of life by natural causes has resulted from these laws.
In one form or another, theistic evolution is the view of creation taught at the majority of mainline Protestant seminaries. For Roman Catholics, human evolution is not a matter of religious teaching, and must stand or fall on its own scientific merits. Evolution and the Roman Catholic Church are not in conflict. The Catechism of the Catholic Church comments positively on the theory of evolution, which is neither precluded nor required by the sources of faith, stating that scientific studies "have splendidly enriched our knowledge of the age and dimensions of the cosmos, the development of life-forms and the appearance of man." Roman Catholic schools teach evolution without controversy on the basis that scientific knowledge does not extend beyond the physical, and scientific truth and religious truth cannot be in conflict. Theistic evolution can be described as "creationism" in holding that divine intervention brought about the origin of life or that divine laws govern formation of species, though many creationists (in the strict sense) would deny that the position is creationism at all. In the creation–evolution controversy its proponents generally take the "evolutionist" side. This sentiment was expressed by Fr. George Coyne, (the Vatican's chief astronomer between 1978 and 2006):...in America, creationism has come to mean some fundamentalistic, literal, scientific interpretation of Genesis. Judaic-Christian faith is radically creationist, but in a totally different sense. It is rooted in a belief that everything depends upon God, or better, all is a gift from God.
While supporting the methodological naturalism inherent in modern science, the proponents of theistic evolution reject the implication taken by some atheists that this gives credence to ontological materialism. In fact, many modern philosophers of science, including atheists, refer to the long-standing convention in the scientific method that observable events in nature should be explained by natural causes, with the distinction that it does not assume the actual existence or non-existence of the supernatural. 
Religious views.
Christianity.
Most contemporary Christian leaders and scholars from mainstream churches, such as Anglicans and Lutherans, consider that there is no conflict between the spiritual meaning of creation and the science of evolution. According to the former Archbishop of Canterbury, Rowan Williams, "...for most of the history of Christianity, and I think this is fair enough, most of the history of the Christianity there's been an awareness that a belief that everything depends on the creative act of God, is quite compatible with a degree of uncertainty or latitude about how precisely that unfolds in creative time."
Leaders of the Anglican and Roman Catholic churches have made statements in favor of evolutionary theory, as have scholars such as the physicist John Polkinghorne, who argues that evolution is one of the principles through which God created living beings. Earlier supporters of evolutionary theory include Frederick Temple, Asa Gray and Charles Kingsley who were enthusiastic supporters of Darwin's theories upon their publication, and the French Jesuit priest and geologist Pierre Teilhard de Chardin saw evolution as confirmation of his Christian beliefs, despite condemnation from Church authorities for his more speculative theories. Another example is that of Liberal theology, not providing any creation models, but instead focusing on the symbolism in beliefs of the time of authoring Genesis and the cultural environment.
Many Christians and Jews had been considering the idea of the creation history as an allegory (instead of historical) long before the development of Darwin's theory of evolution. For example, Philo, whose works were taken up by early Church writers, wrote that it would be a mistake to think that creation happened in six days, or in any set amount of time. Augustine of the late fourth century who was also a former neoplatonist argued that everything in the Universe was created by God at the same moment in time (and not in six days as a literal reading of the Book of Genesis would seem to require); It appears that both Philo and Augustine felt uncomfortable with the idea of a seven-day creation because it detracted from the notion of God's omnipotence. In 1950, Pope Pius XII stated limited support for the idea in his encyclical "Humani generis". In 1996, Pope John Paul II stated that "new knowledge has led to the recognition of the theory of evolution as more than a hypothesis," but, referring to previous papal writings, he concluded that "if the human body takes its origin from pre-existent living matter, the spiritual soul is immediately created by God."
In the US, Evangelical Christians have continued to believe in a literal Genesis. Members of evangelical Protestant (70%), Mormon (76%) and Jehovah's Witnesses (90%) denominations are the most likely to reject the evolutionary interpretation of the origins of life. The historic Christian literal interpretation of creation requires the harmonization of the two creation stories, Genesis 1:1-2:3 and Genesis 2:4-25, for there to be a consistent interpretation. They sometimes seek to ensure that their belief is taught in science classes, mainly in American schools. Opponents reject the claim that the literalistic biblical view meets the criteria required to be considered scientific. Many religious groups teach that God created the Cosmos. From the days of the early Christian Church Fathers there were allegorical interpretations of the Book of Genesis as well as literal aspects.
Christian Science, a system of thought and practice derived from the writings of Mary Baker Eddy, interprets the Book of Genesis figuratively rather than literally. It holds that the material world is an illusion, and consequently not created by God: the only real creation is the spiritual realm, of which the material world is a distorted version. Christian Scientists regard the story of the creation in the Book of Genesis as having symbolic rather than literal meaning. According to Christian Science, both creationism and evolution are false from an absolute or "spiritual" point of view, as they both proceed from a (false) belief in the reality of a material universe. However, Christian Scientists do not oppose the teaching of evolution in schools, nor do they demand that alternative accounts be taught: they believe that both material science and literalist theology are concerned with the illusory, mortal and material, rather than the real, immortal and spiritual. With regard to material theories of creation, Mary Baker Eddy showed a preference for Darwin's theory of evolution over others.
Hinduism.
According to Hindu creationism all species on Earth including humans have "devolved" or come down from a high state of pure consciousness. Hindu creationists claim that species of plants and animals are material forms adopted by pure consciousness which live an endless cycle of births and rebirths. Ronald Numbers says that: "Hindu Creationists have insisted on the antiquity of humans, who they believe appeared fully formed as long, perhaps, as trillions of years ago." Hindu creationism is a form of old Earth creationism, according to Hindu creationists the Universe may even be older than billions of years. These views are based on the Vedas, the creation myths of which depict an extreme antiquity of the Universe and history of the Earth.
Islam.
Islamic creationism is the belief that the Universe (including humanity) was directly created by God as explained in the Qur'an. It usually views the Book of Genesis as a corrupted version of God's message. The creation myths in the Qur'an are vaguer and allow for a wider range of interpretations similar to those in other Abrahamic religions.
Islam also has its own school of theistic evolutionism, which holds that mainstream scientific analysis of the origin of the Universe is supported by the Qur'an. Some Muslims believe in evolutionary creation, especially among liberal movements within Islam.
Khalid Anees, president of the Islamic Society of Britain, at a conference called 'Creationism: Science and Faith in Schools', made points including the following:There is no contradiction between what is revealed in the Koran and natural selection and survival of the fittest. However, Muslims do not agree that one species can develop from another.
Writing for "The Boston Globe", Drake Bennett noted: "Without a Book of Genesis to account for ... Muslim creationists have little interest in proving that the age of the Earth is measured in the thousands rather than the billions of years, nor do they show much interest in the problem of the dinosaurs. And the idea that animals might evolve into other animals also tends to be less controversial, in part because there are passages of the Koran that seem to support it. But the issue of whether human beings are the product of evolution is just as fraught among Muslims." However, some Muslims, such as Adnan Oktar (also known as Harun Yahya), do not agree that one species can develop from another.
But there is also a growing movement of Islamic creationism. Similar to Christian creationism, there is concern regarding the perceived conflicts between the Qur'an and the main points of evolutionary theory. The main location for this has been in Turkey, where fewer than 25% of people believe in evolution.
There are several verses in the Qur'an which some modern writers have interpreted as being compatible with the expansion of the Universe, Big Bang and Big Crunch theories:
Ahmadiyya.
The Ahmadiyya movement activey promotes evolutionary theory. Ahmadis interpret scripture from the Qur'an to support the concept of macroevolution and give precedence to scientific theories. Furthermore, unlike orthodox Muslims, Ahmadis believe that mankind has gradually evolved from different species. Ahmadis regard Adam as being the first Prophet of Godas opposed to him being the first man on Earth. Rather than wholly adopting the theory of natural selection, Ahmadis promote the idea of a "guided evolution," viewing each stage of the evolutionary process as having been selectively woven by God. Mirza Tahir Ahmad, Fourth Caliph of the Ahmadiyya Muslim Community has stated in his magnum opus "Revelation, Rationality, Knowledge & Truth" (1998) that evolution did occur but only through God being the One who brings it about. It does not occur itself, according to the Ahmadiyya Muslim Community.
Judaism.
For Orthodox Jews who seek to reconcile discrepancies between science and the creation myths in the Bible, the notion that science and the Bible should even be reconciled through traditional scientific means is questioned. To these groups, science is as true as the Torah and if there seems to be a problem, our own epistemological limits are to blame for any apparent irreconcilable point. They point to various discrepancies between what is expected and what actually is to demonstrate that things are not always as they appear. They point out the fact that even the root word for "world" in the Hebrew language—עולם (Olam)—means hidden—נעלם (Neh-Eh-Lahm). Just as they know from the Torah that God created man and trees and the light on its way from the stars in their observed state, so too can they know that the World was created in its over the six days of Creation that reflects progression to its currently-observed state, with the understanding that physical ways to verify this may eventually be identified. This knowledge has been advanced by Rabbi Dovid Gottlieb, former philosophy professor at Johns Hopkins University. Also, relatively old Kabbalistic sources from well before the scientifically apparent age of the Universe was first determined are in close concord with modern scientific estimates of the age of the Universe, according to Rabbi Aryeh Kaplan, and based on Sefer Temunah, an early kabbalistic work attributed to the first-century Tanna Nehunya ben HaKanah. Many kabbalists accepted the teachings of the Sefer HaTemunah, including the medieval Jewish scholar Nahmanides, his close student Isaac ben Samuel of Acre, and David ben Solomon ibn Abi Zimra. Other interesting parallels are derived, among other sources, from Nahmanides, who expounds that there was a Neanderthal-like species with which Adam mated (he did this long before Neanderthals had even been discovered scientifically). Reform Judaism does not take the Torah as a literal text, but rather as a symbolic or open-ended work.
Bahá'í Faith.
In the creation myth taught by Bahá'u'lláh, the Bahá'í Faith founder, the Universe has "neither beginning nor ending," and that the component elements of the material world have always existed and will always exist. With regard to evolution and the origin of human beings, `Abdu'l-Bahá gave extensive comments on the subject when he addressed western audiences in the beginning of the 20th century. Transcripts of these comments can be found in "Some Answered Questions", "Paris Talks" and "The Promulgation of Universal Peace". `Abdu'l-Bahá described the human species as having evolved from a primitive form to modern man, but that the capacity to form human intelligence was always in existence.
Creationism by country.
Creationism is widely accepted and taught throughout the Middle East. Although it has been prominent in the US but not widely accepted in academia, it has been making a resurgence in other countries as well.
Europe.
In recent years the teaching of creationism has become a subject of debate in a variety of countries including Germany, the UK, Italy, the Netherlands, Poland, and Serbia.
Creation science has been heavily promoted in immigrant communities in Western Europe, primarily by Adnan Oktar. On October 4, 2007, the Parliamentary Assembly of the Council of Europe adopted "The dangers of creationism in education", a resolution on the attempt by American-inspired creationists to promote creationism in European schools. It concludes "The war on the theory of evolution and on its proponents most often originates in forms of religious extremism closely linked to extreme right-wing political movements... some advocates of strict creationism are out to replace democracy by theocracy... If we are not careful, the values that are the very essence of the Council of Europe will be under direct threat from creationist fundamentalists."
Germany.
In 1978, British Professor A. E. Wilder-Smith, who came to Germany after World War II and lectured at Marburg and other cities, published a book arguing against evolution with a secular, well known publishing house, titled "The Natural Sciences Know Nothing of Evolution" (1978). At the end of the year Horst W. Beck became a creationist. Both an engineer and theologian, he was a leading figure in the "Karl-Heim-Gesellschaft" (Karl Heim Society) and had previously published articles and books defending theistic evolution. Together with other members of the society, which they soon left, he followed the arguments of Willem Ouweneel, a Dutch biologist lecturing in Germany. Beck soon found other scientists who had changed their view or were "hidden" creationists. Under his leadership, the first creationist society was founded ("Wort und Wissen"—Word and Knowledge). Three book series were soon published, an independent creationist monthly journal started ("Factum"), and the first German article in the "Creation Research Society Quarterly" was published.
In 2006, a documentary on the Arte television network, "Von Göttern und Designern" ("Genesis vs. Darwin"), by filmmaker Frank Papenbroock, demonstrated that creationism had already been taught in biology classes in at least two schools in Giessen, Hesse, without this being noticed. During this, the Education Minister of Hessen, Karin Wolff, said she believed creationism should be taught in biology class as a theory, like the theory of evolution: "I think it makes sense to bring up multidisciplinary and interdisciplinary problems for discussion." In 2009, an article on the German news site Spiegel Online stated approximately 20% of people disbelieve evolutionary theory in Germany. More recently, a 2011 Ipsos poll commissioned by Reuters found 12% of Germans identify as creationists.
Romania.
In Romania, in 2002, the Ministry of Education approved the use of a biology book endorsing creationism, titled "Biologie clasa a IX-a – Măiestrie şi strălucire divină în biosferă" ("Biology Class IX – Divine Mastery and Light in the Biosphere"), in public high schools. Following a protest of the Romanian Humanist Association the Romanian Ministry of Education replied that the book is not a "textbook" but merely an "accessory." The president of the Association labeled the reply as "disappointing" since, whether a textbook or an accessory, the book remains available for usage in schools. Reports indicate that at least one teacher in Oradea did use the book.
Russia.
Russia is home to the Moscow Creation Society. The department of extracurricular and alternative education of the Ministry of Education and Science of the Russian Federation has cosponsored numerous creationist conferences. Since 1994, Alexander Asmolov, the previous deputy minister of education, has urged that creationism be taught to help restore academic freedom in Russia after years of state-enforced scientific orthodoxy. In February 2007, a 16-year-old girl and her father launched a court case against the Ministry of Education and Science, backed by the Russian Orthodox Church, challenging the teaching of just one "theory" of biology in school textbooks as a breach of her human rights.
A 2005 poll reportedly found 26% of Russians accepting evolution and 49% accepting creationism. But a 2003 poll reported that 44% agreed with "Human beings are developed from earlier species of animals," and a 2009 poll reported that 48% of Russians who "know something about Charles Darwin and his theory of evolution" agreed that there was sufficient evidence for the theory. The 2009 poll indicated that 53% of Russians agreed with "Evolutionary theories should be taught in science lessons in schools together with other possible perspectives, such as intelligent design and creationism," with 13% preferring that such perspectives be taught instead of evolution; only 10% agreed with "Evolutionary theories alone should be taught in science lessons in schools."
Serbia.
On September 7, 2004, the Serbian Minister for Education and Sport, Ljiljana Čolić, temporarily banned evolution from being taught in the country. After statewide outcry she resigned on September 16, 2004, from her post.
Switzerland.
A 2006 international survey found that 30% of the Swiss reject evolution, one of the highest national percentages in Europe. Another survey in 2007, commissioned by the Christian organization Pro Genesis, controversially claims 80%. This resulted in schools in the Canton of Bern printing science textbooks that presented creationism as a valid alternative theory to evolution. Scientists and education experts harshly criticized the move, which quickly prompted school authorities to revise the books.
United Kingdom.
Since the development of evolutionary theory by Charles Darwin in England, where his portrait appears on the back of the revised Series E £10 note issued in 2000, significant shifts in British public opinion have occurred. A 2006 survey for the BBC showed that "more than a fifth of those polled were convinced by the creationist argument," a massive decrease from the almost total acceptance of creationism before Darwin published his theory. A 2010 Angus Reid poll found that "In Britain, two-thirds of respondents (68%) side with evolution while less than one-in-five (16%) choose creationism. At least seven-in-ten respondents in the South of England (70%) and Scotland (75%) believe human beings evolved from less advanced life forms over millions of years." A subsequent 2010 YouGov poll on the origin of humans found that 9% opted for creationism, 12% intelligent design, 65% evolutionary theory and 13% did not know.
Speaking at the British Science Association's British Science Festival at the University of Liverpool in 2008, Professor Michael Reiss estimated that about only 10% of children were from a family that supported a creationist rather than evolutionary viewpoint. Richard Dawkins has been quoted saying "I have spoken to a lot of science teachers in schools here in Britain who are finding an increasing number of students coming to them and saying they are Young Earth creationists."
The director of education at the Royal Society has said that creationism should be discussed in school science lessons, rather than be excluded, to explain why creationism had no scientific basis. Wales has the largest proportion of theistic evolutionists—the belief that evolution is part of God's plan (38%). Northern Ireland has the highest proportion of people who believe in 'intelligent design' (16%), which holds that "certain features of the universe and of living things are best explained by an intelligent cause, not an undirected process such as natural selection." Some private religious schools in the UK teach creationism rather than evolution. The British Humanist Association and leading scientists campaigned to make creationism illegal in state funded schools from 2011 onwards. In 2014 they achieved their goal when the Department for Education updated the funding contracts of Academies and Free Schools to this effect, and at the same time, clarified that creationism being taught as science contravened existing 'British values' requirements.
Muslim world.
A 2007 study of religious patterns found that only 8% of Egyptians, 11% of Malaysians, 14% of Pakistanis, 16% of Indonesians, and 22% of Turks agree that Darwin's theory is probably or most certainly true, and a 2006 survey reported that about a quarter of Turkish adults agreed that human beings evolved from earlier animal species. Surveys carried out by researchers affiliated with McGill University's Evolution Education Research Centre found that in Egypt and Pakistan, while the official high school curriculum does include evolution, many of the teachers there do not believe in it themselves, and will often tell their students so.
Currently in Egypt, evolution is taught in schools but Saudi Arabia and Sudan have both banned the teaching of evolution in schools. In recent times, creationism has become more widespread in other Islamic countries.
The results of a survey of the adherence to creation science of 5,700 teachers from 14 countries was presented during the 2008 XIII IOSTE Symposium in Izmir, Turkey. Lebanon, Senegal, Tunisia, Morocco and Algeria had 62% to 81% of creationist teachers (with no difference between biologists and others). Romania and Burkina Faso had 45% to 48% of creationist teachers in Romania and Burkina Faso, with no difference between biologists and other in Romania, but a clear difference (p<0.001) in Burkina Faso (with 61% of creationists for the not biology teachers). Portugal and Cyprus had 15% to 30% of creationist teachers, with no significant difference between biologists, but a significant difference in Portugal (p=0.004, 17% and 26%).
Iran.
Iranian scientific development, especially the health-related aspects of biology, has been a goal of the Islamic government since the revolution of 1979. Since Iranian traditional practice of Shi'a religion is not preoccupied with Qur'anic literalism as in case of Saudi Wahhabism but ijtihad, many influential Iranian Shi'ite scholars, including several who were closely involved in Iranian Revolution, are not opposed to evolutionary ideas in general, disagreeing that evolution necessarily conflicts with the Muslim mainstream. Iranian pupils, since 5th grade of elementary school, learn only about evolution, thus portraying geologists and scientists in general as authoritative voices of scientific knowledge.
Turkey.
Since the 1980s, creationism in Turkey has grown significantly and is now the government's official position on origins. In 1985, the conservative political party then in control of the country’s education ministry added creationist explanations alongside the passages on evolution in the standard high school biology textbook. In Turkey, unlike in the US, the public school curriculum is set by the national government. In 2008, Richard Dawkins' website was banned in Turkey. However, the ban was lifted in July 2011. In 2009, the Turkish government agency Scientific and Technological Research Council of Turkey (TÜBİTAK), publisher of the popular Turkish science magazine "Bilim ve Teknik" ("Science and Technology"), was accused of stripping a cover story about the life and work of Charles Darwin from the March 2009 issue of the Council's publication just before it went to press. The planned portrait of Darwin for the magazine's cover was replaced and the editor of the magazine, Çiğdem Atakuman, claims that she was removed from her post. Most of the Turkish population expressed support for the censorship. In 2012, it was found that the government's internet content filter, designed to prevent the public having access to pornographic websites, also blocked the words 'evolution' and 'Darwin' on one mode of the filter.
Australia.
In the late 1970s, Answers in Genesis, a creationist research organization, was founded in Australia. In 1994, Answers in Genesis expanded from Australia and New Zealand to the US. It subsequently expanded into the UK, Canada, South Africa and New Zealand. Creationists in Australia have been the leading influence on the development of creation science in the US for the last 20 years. Two of the three main international creation science organizations all have original roots within Australia—Answers in Genesis and Creation Ministries. Ken Ham, Andrew Snelling, Jason Lisle, Jonathan Sarfati and Tasman Bruce Walker have all had significant impact on the development of creationism in Australia, and have brought their teaching to the US.
In 1980, the Queensland state government of Joh Bjelke-Petersen allowed the teaching of creationism as science to school children. On May 29, 2010, it was announced that creationism and intelligent design will be discussed in history classes as part of the new national curriculum. It will be placed in the subject of ancient history, under the topic of "controversies." One Australian scientist who adheres to creation science is Dr Pierre Gunnar Jerlström.
Professor Ian Plimer, an anti-creationist geologist, reported being attacked by creationists. A few public lectures have been given in rented rooms at universities, by visiting American speakers, and speakers with doctorates purchased by mail from Florida sites. A court case taken by Plimer against prominent creationists found "that the creationists had stolen the work of others for financial profit, that the creationists told lies under oath and that the creationists were engaged in fraud." The debate was featured on the science television program "Quantum". In 1989, Plimer debated American creationist Duane Gish.
Asia.
South Korea.
Since 1981, the Korea Association for Creation Research has grown to 16 branches, with 1000 members and 500 Ph.Ds. On August 22–24, 1991, recognizing the 10th anniversary of KACR, an International Symposium on Creation Science was held with 4,000 in attendance. In 1990, the book "The Natural Sciences" was written by Dr. Young-Gil Kim and 26 other fellow scientists in Korea with a creationist viewpoint. The textbook drew the interest of college communities, and today, many South Korean universities are using it.
Since 1991, creation science has become a regular university course at Myongji University, which has a centre for creation research. Since that time, other universities have begun to offer creation science courses. At Handong Global University, creationist Dr. Young-Gil Kim was inaugurated as president in March 1995. At Myongji University, creationist Dr. Woongsang Lee is a biology professor. The Korea Advanced Institute of Science and Technology is where the Research Association of Creation Science was founded and many graduate students are actively involved. In 2008, a survey found that 36% of South Koreans disagreed with the statement that "Human beings, as we know them today, developed from earlier species of animals." In May 2012, publishers of high school science textbooks decided to remove references to evolution following a petition by a creationist group. However, the ensuing controversy prompted the government to appoint a panel of scientists to look into the matter, and the government urged the publishers to keep the references to evolution following the recommendation of the panel.
Americas.
Brazil.
Brazil has had two creationist societies since the 1970s—the Brazilian Association for Creation Research and the Brazilian Creation Society. According to a 2004 survey, 31% of Brazil believe that "the first humans were created no more than 10,000 years ago."
United States.
In the US some religious communities have refused to accept naturalistic explanations and tried to counter them. The term started to become associated with Christian fundamentalist opposition to human evolution and belief in a young Earth in 1929. Several US states passed laws against the teaching of evolution in public schools, as upheld in the Scopes Trial. Evolution was omitted entirely from school textbooks in most of the US until the 1960s. Since then, renewed efforts to introduce teaching creationism in American public schools in the form of Flood geology, creation science, and intelligent design have been consistently held to contravene the constitutional separation of church and state by a succession of legal judgments. The meaning of the term creationism was contested, but by the 1980s it had been co-opted by proponents of creation science and Flood geology.
Most of the anti-evolutionists of the 1920s believed in forms of old Earth creationism, which accepts geological findings and other methods of dating the Earth and believes that these findings do not contradict the Book of Genesis, but rejects evolution. At that time only a minority held to young Earth creationism, proponents of which believe that the Earth is thousands rather than billions of years old, and typically believe that the days in chapter one of the Book of Genesis are 24 hours in length. In the 1960s, this became the most prominent form of anti-evolution. From the 1860s forms of theistic evolution had developed; this term refers to beliefs in creation which are compatible with the scientific view of evolution and the age of the Earth, as held by mainstream Christian denominations. There are other religious people who support creationism, but in terms of allegorical interpretations of the Book of Genesis.
By the start of the 20th century, evolution was widely accepted and was beginning to be taught in American public schools. After World War I, popular belief that German aggression resulted from a Darwinian doctrine of "survival of the fittest" inspired William Jennings Bryan to campaign against the teaching of Darwinian ideas of human evolution. In the 1920s, the Fundamentalist–Modernist Controversy led to an upsurge of fundamentalist religious fervor in which schools were prevented from teaching evolution through state laws such as Tennessee’s 1925 Butler Act, and by getting evolution removed from biology textbooks nationwide. "Creationism" became associated in common usage with opposition to evolution.
In 1961 in the US, an attempt to repeal the Butler Act failed. "The Genesis Flood" by Henry M. Morris brought the Seventh-day Adventist biblically literal Flood geology of George McCready Price to a wider audience, popularizing the idea of young Earth creationism, and by 1965 the term "scientific creationism" had gained currency. The 1968 "Epperson v. Arkansas" judgment ruled that state laws prohibiting the teaching of evolution violate the Establishment Clause of the First Amendment to the United States Constitution which prohibits state aid to religion. and when in 1975 "Daniel v. Waters" ruled that a state law requiring biology textbooks discussing "origins or creation of man and his world" to give equal treatment to creation as per the Book of Genesis was unconstitutional, a new group identifying themselves as creationists promoted 'creation science' which omitted explicit biblical references.
In 1981, the state of Arkansas passed a law, Act 590, mandating that "creation science" be given equal time in public schools with evolution, and defining creation science as positing the "creation of the universe, energy, and life from nothing," as well as explaining the Earth's geology by "the occurrence of a worldwide flood." This was ruled unconstitutional at "McLean v. Arkansas" in January 1982 as the creationists' methods were not scientific but took the literal wording of the Book of Genesis and attempted to find scientific support for it. Louisiana introduced similar legislation that year. A series of judgments and appeals led to the 1987 Supreme Court ruling in "Edwards v. Aguillard" that it too violated the Establishment Clause of the First Amendment to the United States Constitution.
"Creation science" could no longer be taught in public schools, and in drafts of the creation science school textbook "Of Pandas and People" all references to creation or creationism were changed to refer to intelligent design. Proponents of the intelligent design movement organised widespread campaigning to considerable effect. They officially denied any links to creation or religion, and claimed that "creationism" only referred to young Earth creationism with Flood geology; but in "Kitzmiller v. Dover" the court found intelligent design to be religious, and unable to dissociate itself from its creationist roots, as part of the ruling that teaching intelligent design in public school science classes was unconstitutional.
The percentage of people in the US who accept the idea of human evolution declined from 45% in 1985 to 40% in 2005. A Gallup poll reported that the percentage of people in the US who believe in a strict interpretation of creationism had fallen to 40% in 2010 after a high of 46% in 2006. The highest the percentage has risen between 1982 and 2010 was 47% in 1994 and 2000 according to the report. The report found that Americans who are less educated are more likely to hold a creationist view while those with a college education are more likely to hold a view involving evolution. 47% of those with no more than a high school education believe in creationism while 22% of those with a post graduate education hold that view. The poll also found that church attendance dramatically increased adherence to a strict creationist view (22% for those who do not attend church, 60% for those who attend weekly). The higher percentage of Republicans who identified with a creationist view is described as evidence of the strong relationship between religion and politics in the US. Republicans also attend church weekly more than Democratic or independent voters. Non-Republican voters are twice as likely to hold a nontheistic view of evolution than Republican voters.
Among US states, acceptance of evolution has a strong negative correlation with religiosity and a strong positive relationship with science degrees awarded, bachelor's degree attainment, advanced degree attainment, average teacher salary, and GDP per capita. In other words, states in which more people say that religion is very important to their lives tend to show less acceptance of evolution. The better the education of individuals, their educational system, or the higher their income, the more they accept evolution, though the US as a country has a comparatively well educated population but lower acceptance of evolution than other countries.
Prevalence.
Most vocal literalist creationists are from the US, and strict creationist views are much less common in other developed countries. According to a study published in "Science", a survey of the US, Turkey, Japan and Europe showed that public acceptance of evolution is most prevalent in Iceland, Denmark and Sweden at 80% of the population. There seems to be no significant correlation between believing in evolution and understanding evolutionary science.
Australia.
A 2009 Nielsen poll showed that almost a quarter of Australians believe "the biblical account of human origins." Forty-two percent believe in a "wholly scientific" explanation for the origins of life, while 32 percent believe in an evolutionary process "guided by God."
Canada.
A 2012 survey by Angus Reid Public Opinion revealed that 61 percent of Canadians believe in evolution. The poll asked "Where did human beings come from — did we start as singular cells millions of year ago and evolve into our present form, or did God create us in his image 10,000 years ago?"
Europe.
In Europe, literalist creationism is more widely rejected, though regular opinion polls are not available. Most people accept that evolution is the most widely accepted scientific theory as taught in most schools. In countries with a Roman Catholic majority, papal acceptance of evolutionary creationism as worthy of study has essentially ended debate on the matter for many people.
In the UK, a 2006 poll on the "origin and development of life" asked participants to choose between three different perspectives on the origin of life: 22% chose creationism, 17% opted for intelligent design, 48% selected evolutionary theory, and the rest did not know. A subsequent 2010 YouGov poll on the correct explanation for the origin of humans found that 9% opted for creationism, 12% intelligent design, 65% evolutionary theory and 13% didn't know. The former Archbishop of Canterbury Rowan Williams, head of the worldwide Anglican Communion, views the idea of teaching creationism in schools as a mistake.
In Italy, Education Minister Letizia Moratti wanted to retire evolution from the secondary school level; after one week of massive protests, she reversed her opinion.
There continues to be scattered and possibly mounting efforts on the part of religious groups throughout Europe to introduce creationism into public education. In response, the Parliamentary Assembly of the Council of Europe has released a draft report titled "The dangers of creationism in education" on June 8, 2007, reinforced by a further proposal of banning it in schools dated October 4, 2007.
Serbia suspended the teaching of evolution for one week in September 2004, under education minister Ljiljana Čolić, only allowing schools to reintroduce evolution into the curriculum if they also taught creationism. "After a deluge of protest from scientists, teachers and opposition parties" says the BBC report, Čolić's deputy made the statement, "I have come here to confirm Charles Darwin is still alive" and announced that the decision was reversed. Čolić resigned after the government said that she had caused "problems that had started to reflect on the work of the entire government."
Poland saw a major controversy over creationism in 2006 when the Deputy Education Minister, Mirosław Orzechowski, denounced evolution as "one of many lies" taught in Polish schools. His superior, Minister of Education Roman Giertych, has stated that the theory of evolution would continue to be taught in Polish schools, "as long as most scientists in our country say that it is the right theory." Giertych's father, Member of the European Parliament Maciej Giertych, has opposed the teaching of evolution and has claimed that dinosaurs and humans co-existed.
United States.
According to a 2014 Gallup poll, about 42% of Americans believe that "God created human beings pretty much in their present form at one time within the last 10,000 years or so." Another 31% believe that "human beings have developed over millions of years from less advanced forms of life, but God guided this process,"and 19% believe that "human beings have developed over millions of years from less advanced forms of life, but God had no part in this process."
Belief in creationism is inversely correlated to education; of those with postgraduate degrees, 74% accept evolution. In 1987, "Newsweek" reported: "By one count there are some 700 scientists with respectable academic credentials (out of a total of 480,000 U.S. earth and life scientists) who give credence to creation-science, the general theory that complex life forms did not evolve but appeared 'abruptly.'"
A 2000 poll for People for the American Way found 70% of the US public felt that evolution was compatible with a belief in God.
According to a study published in "Science", between 1985 and 2005 the number of adult North Americans who accept evolution declined from 45% to 40%, the number of adults who reject evolution declined from 48% to 39% and the number of people who were unsure increased from 7% to 21%. Besides the US the study also compared data from 32 European countries, Turkey, and Japan. The only country where acceptance of evolution was lower than in the US was Turkey (25%).
According to a 2011 Fox News poll, 45% of Americans believe in Creationism, down from 50% in a similar poll in 1999. 21% believe in 'the theory of evolution as outlined by
Darwin and other scientists' (up from 15% in 1999), and 27% answered that both are true (up from 26% in 1999).
In September 2012, educator and television personality Bill Nye spoke with the Associated Press and aired his fears about acceptance of creationist theory, believing that teaching children that creationism is the only true answer and without letting them understand the way science works will prevent any future innovation in the world of science. In February 2014, Nye defended evolution in the classroom in a debate with creationist Ken Ham on the topic of whether creation is a viable model of origins in today's modern, scientific era.
Education controversies.
In the US, creationism has become centered in the political controversy over creation and evolution in public education, and whether teaching creationism in science classes conflicts with the separation of church and state. Currently, the controversy comes in the form of whether advocates of the intelligent design movement who wish to "Teach the Controversy" in science classes have conflated science with religion.
People for the American Way polled 1500 North Americans about the teaching of evolution and creationism in November and December 1999. They found that most North Americans were not familiar with Creationism, and most North Americans had heard of evolution, but many did not fully understand the basics of the theory. The main findings were:
In such political contexts, creationists argue that their particular religiously based origin belief is superior to those of other belief systems, in particular those made through secular or scientific rationale. Political creationists are opposed by many individuals and organizations who have made detailed critiques and given testimony in various court cases that the alternatives to scientific reasoning offered by creationists are opposed by the consensus of the scientific community.
Criticism.
Christian criticism.
Many Christians disagree with the teaching of creationism. Several religious organizations, among them the Catholic Church, hold that their faith does not conflict with the scientific consensus regarding evolution. The Clergy Letter Project, which has collected more than 13,000 signatures, is an "endeavor designed to demonstrate that religion and science can be compatible."
In his 2002 article "Intelligent Design as a Theological Problem," George Murphy argues against the view that life on Earth, in all its forms, is direct evidence of God's act of creation (Murphy quotes Phillip E. Johnson's claim that he is speaking "of a God who acted openly and left his fingerprints on all the evidence."). Murphy argues that this view of God is incompatible with the Christian understanding of God as "the one revealed in the cross and resurrection of Christ." The basis of this theology is Isaiah 45:15, "Verily thou art a God that hidest thyself, O God of Israel, the Saviour."
Murphy observes that the execution of a Jewish carpenter by Roman authorities is in and of itself an ordinary event and did not require divine action. On the contrary, for the crucifixion to occur, God had to limit or "empty" Himself. It was for this reason that Paul the Apostle wrote, in Philippians 2:5-8:
Murphy concludes that,"Just as the Son of God limited himself by taking human form and dying on a cross, God limits divine action in the world to be in accord with rational laws which God has chosen. This enables us to understand the world on its own terms, but it also means that natural processes hide God from scientific observation."For Murphy, a theology of the cross requires that Christians accept a "methodological" naturalism, meaning that one cannot invoke God to explain natural phenomena, while recognizing that such acceptance does not require one to accept a "metaphysical" naturalism, which proposes that nature is all that there is.
Teaching of creationism.
Other Christians have expressed qualms about teaching creationism. In March 2006, then Archbishop of Canterbury Rowan Williams, the leader of the world's Anglicans, stated his discomfort about teaching creationism, saying that creationism was "a kind of category mistake, as if the Bible were a theory like other theories." He also said: "My worry is creationism can end up reducing the doctrine of creation rather than enhancing it." The views of the Episcopal Church - a major American-based branch of the Anglican Communion - on teaching creationism resemble those of Williams.
The National Science Teachers Association is opposed to teaching creationism as a science, as is the Association for Science Teacher Education, the National Association of Biology Teachers, the American Anthropological Association, the American Geosciences Institute, the Geological Society of America, the American Geophysical Union, and numerous other professional teaching and scientific societies.
In April 2010, the American Academy of Religion issued "Guidelines for Teaching About Religion in K‐12 Public Schools in the United States" which included guidance that creation science or intelligent design should not be taught in science classes, as "Creation science and intelligent design represent worldviews that fall outside of the realm of science that is defined as (and limited to) a method of inquiry based on gathering observable and measurable evidence subject to specific principles of reasoning." However, they, as well as other "worldviews that focus on speculation regarding the origins of life represent another important and relevant form of human inquiry that is appropriately studied in literature or social sciences courses. Such study, however, must include a diversity of worldviews representing a variety of religious and philosophical perspectives and must avoid privileging one view as more legitimate than others."
Randy Moore and Sehoya Cotner, from the biology program at the University of Minnesota, reflect on the relevance of teaching creationism in the article "The Creationist Down the Hall: Does It Matter When Teachers Teach Creationism?" They conclude that "Despite decades of science education reform, numerous legal decisions declaring the teaching of creationism in public-school science classes to be unconstitutional, overwhelming evidence supporting evolution, and the many denunciations of creationism as nonscientific by professional scientific societies, creationism remains popular throughout the United States."
Scientific criticism.
Science is a system of knowledge based on observation, empirical evidence, and the development of theories that yield testable explanations and predictions of natural phenomena. By contrast, creationism is often based on literal interpretations of the narratives of particular religious texts. Some creationist beliefs involve purported forces that lie outside of nature, such as supernatural intervention, and often do not allow predictions at all. Therefore, these can neither be confirmed nor disproved by scientists. However, many creationist beliefs can be framed as testable predictions about phenomena such as the age of the Earth, its geological history and the origins, distributions and relationships of living organisms found on it. Early science incorporated elements of these beliefs, but as science developed these beliefs were gradually falsified and were replaced with understandings based on accumulated and reproducible evidence that often allows the accurate prediction of future results. Some scientists, such as Stephen Jay Gould, consider science and religion to be two compatible and complementary fields, with authorities in distinct areas of human experience, so-called non-overlapping magisteria. This view is also held by many theologians, who believe that ultimate origins and meaning are addressed by religion, but favor verifiable scientific explanations of natural phenomena over those of creationist beliefs. Other scientists, such as Richard Dawkins, reject the non-overlapping magisteria and argue that, in disproving literal interpretations of creationists, the scientific method also undermines religious texts as a source of truth. Irrespective of this diversity in viewpoints, since creationist beliefs are not supported by empirical evidence, the scientific consensus is that any attempt to teach creationism as science should be rejected.

</doc>
<doc id="5329" url="https://en.wikipedia.org/wiki?curid=5329" title="History of Chad">
History of Chad

Chad (; ), officially the Republic of Chad, is a landlocked country in Central Africa. It borders Libya to the north, Sudan to the east, the Central African Republic to the south, Cameroon and Nigeria to the southwest, and Niger to the west. Due to its distance from the sea and its largely desert climate, the country is sometimes referred to as the "Dead Heart of Africa".
Prehistory.
During the 7th millennium BC, the northern half of Chad was part of a broad expanse of land, stretching from the Indus River in the east to the Atlantic Ocean in the west, in which ecological conditions favored early human settlement. Rock art of the "Round Head" style, found in the Ennedi region, has been dated to before the 7th millennium BC and, because of the tools with which the rocks were carved and the scenes they depict, may represent the oldest evidence in the Sahara of Neolithic industries. Many of the pottery-making and Neolithic activities in Ennedi date back further than any of those of the Nile Valley to the east.
In the prehistoric period, Chad was much wetter than it is today, as evidenced by large game animals depicted in rock paintings in the Tibesti and Borkou regions.
Recent linguistic research suggests that all of Africa's major language groupings south of the Sahara Desert (except Khoisan, which is not considered a valid genetic grouping anyway), i. e. the Afro-Asiatic, Nilo-Saharan and Niger–Congo phyla, originated in prehistoric times in a narrow band between Lake Chad and the Nile Valley. The origins of Chad's peoples, however, remain unclear. Several of the proven archaeological sites have been only partially studied, and other sites of great potential have yet to be mapped.
Era of Empires (AD 900–1900).
Toward the end of the 1st millennium AD, the formation of states began across central Chad in the sahelian zone between the desert and the savanna. For almost the next 1,000 years, these states, their relations with each other, and their effects on the peoples who lived in stateless societies along their peripheries dominated Chad's political history. Recent research suggests that indigenous Africans founded most of these states, not migrating Arabic-speaking groups, as was believed previously. Nonetheless, immigrants, Arabic-speaking or otherwise, played a significant role, along with Islam, in the formation and early evolution of these states.
Most states began as kingdoms, in which the king was considered divine and endowed with temporal and spiritual powers. All states were militaristic (or they did not survive long), but none was able to expand far into southern Chad, where forests and the tsetse fly complicated the use of cavalry. Control over the trans-Saharan trade routes that passed through the region formed the economic basis of these kingdoms. Although many states rose and fell, the most important and durable of the empires were Kanem-Bornu, Baguirmi, and Ouaddai, according to most written sources (mainly court chronicles and writings of Arab traders and travelers).[http://countrystudies.us/chad/5.htm]
Kanem-Bornu.
The Kanem Empire originated in the 9th century AD to the northeast of Lake Chad. Historians agree that the leaders of the new state were ancestors of the Kanembu people. Toward the end of the 11th century the Sayfawa king (or "mai", the title of the Sayfawa rulers) Hummay, converted to Islam. In the following century the Sayfawa rulers expanded southward into Kanem, where was to rise their first capital, Njimi. Kanem's expansion peaked during the long and energetic reign of Mai Dunama Dabbalemi (c. 1221–1259).
By the end of the 14th century, internal struggles and external attacks had torn Kanem apart. Finally, around 1396 the Bulala invaders forced "Mai" Umar Idrismi to abandon Njimi and move the Kanembu people to Bornu on the western edge of Lake Chad. Over time, the intermarriage of the Kanembu and Bornu peoples created a new people and language, the Kanuri, and founded a new capital, Ngazargamu.
Kanem-Bornu peaked during the reign of the outstanding statesman "Mai" Idris Aluma (c. 1571–1603). Aluma is remembered for his military skills, administrative reforms, and Islamic piety. The administrative reforms and military brilliance of Aluma sustained the empire until the mid-17th century, when its power began to fade. By the early 19th century, Kanem-Bornu was clearly an empire in decline, and in 1808 Fulani warriors conquered Ngazargamu. Bornu survived, but the Sayfawa dynasty ended in 1846 and the Empire itself fell in 1893.
Baguirmi and Ouaddai.
In addition to Kanem-Bornu, two other states in the region, Baguirmi and Ouaddai, achieved historical prominence. Baguirmi emerged to the southeast of Kanem-Bornu in the 16th century. Islam was adopted, and the state became a sultanate. Absorbed into Kanem-Bornu, Baguirmi broke free later in the 17th century, only to be returned to tributary status in the mid-18th century. Early in the 19th century, Baguirmi fell into decay and was threatened militarily by the nearby kingdom of Ouaddai. Although Baguirmi resisted, it accepted tributary status in order to obtain help from Ouaddai in putting down internal dissension. When the capital was burned in 1893, the sultan sought and received protectorate status from the French.
Located northeast of Baguirmi, Ouaddai was a non-Muslim kingdom that emerged in the 16th century as an offshoot of the state of Darfur (in present-day Sudan). Early in the 12th century, groups in the region rallied to Abd al-Karim Sabun, who overthrew the ruling Tunjur group, transforming Ouaddai into an Islamic sultanate. During much of the 18th century, Ouaddai resisted reincorporation into Darfur.
In about 1804, under the rule of Sabun, the sultanate began to expand its power. A new trade route north was discovered, and Sabun outfitted royal caravans to take advantage of it. He began minting his own coinage and imported chain mail, firearms, and military advisers from North Africa. Sabun's successors were less able than he, and Darfur took advantage of a disputed political succession in 1838 to put its own candidate in power. This tactic backfired when Darfur's choice, Muhammad Sharif, rejected Darfur and asserted his own authority. In doing so, he gained acceptance from Ouaddai's various factions and went on to become Ouaddai's ablest ruler. Sharif eventually established Ouaddai's hegemony over Baguirmi and kingdoms as far away as the Chari River. The Ouaddai opposed French domination until well into the 20th century.
Colonialism (1900–40).
In 1905, administrative responsibility for Chad was placed under a governor-general stationed at Brazzaville, capital of French Equatorial Africa (AEF). Chad did not have a separate colonial status until 1920, when it was placed under a lieutenant-governor stationed in Fort-Lamy (today N'Djamena).
Two fundamental themes dominated Chad's colonial experience with the French: an absence of policies designed to unify the territory and an exceptionally slow pace of modernization. In the French scale of priorities, the colony of Chad ranked near the bottom, and the French came to perceive Chad primarily as a source of raw cotton and untrained labour to be used in the more productive colonies to the south.
Throughout the colonial period, large areas of Chad were never governed effectively: in the huge BET Prefecture, the handful of French military administrators usually left the people alone, and in central Chad, French rule was only slightly more substantive. Truly speaking, France managed to govern effectively only the south.
Decolonization (1940–60).
After the war ended local parties started to develop in Chad. The first to be born was the radical Chadian Progressive Party (PPT) in February 1947, initially headed by Panamanian born Gabriel Lisette, but from 1959 headed by François Tombalbaye. The more conservative Chadian Democratic Union (UDT) was founded in November 1947 and represented French commercial interests and a bloc of traditional leaders composed primarily of Muslim and Ouaddaïan nobility. The confrontation between the PPT and UDT was more than simply ideological; it represented different regional identities, with the PPT representing the Christian and animist south and the UDT the Islamic north. 
The PPT won the May 1957 pre-independence elections thanks to a greatly expanded franchise, and Lisette led the government of the Territorial Assembly until he lost a confidence vote on 11 February 1959. After a referendum on territorial autonomy on 28 September 1958, French Equatorial Africa was dissolved, and its four constituent states – Gabon, Congo (Brazzaville), the Central African Republic, and Chad became autonomous members of the French Community from 28 November 1958. Following Lisette's fall in February 1959 the opposition leaders Gontchome Sahoulba and Ahmed Koulamallah could not form a stable government, so the PPT was again asked to form an administration - which it did under the leadership of François Tombalbaye on 26 March 1959. On 12 July 1960 France agreed to Chad becoming fully independent. On 11 August 1960, Chad became an independent country and François Tombalbaye became its first President.
The Tombalbaye era (1960–75).
One of the most prominent aspects of Tombalbaye's rule to prove itself was his authoritarianism and distrust of democracy. Already in January 1962 he banned all political parties except his own PPT, and started immediately concentrating all power in his own hands. His treatment of opponents, real or imagined, was extremely harsh, filling the prisons with thousands of political prisoners.
What was even worse was his constant discrimination against the central and northern regions of Chad, where the southern Chadian administrators came to be perceived as arrogant and incompetent. This resentment at last exploded in a tax revolt on November 1, 1965, in the Guéra Prefecture, causing 500 deaths. The year after saw the birth in Sudan of the National Liberation Front of Chad (FROLINAT), created to militarily oust Tombalbaye and the Southern dominance. It was the start of a bloody civil war.
Tombalbaye resorted to calling in French troops; while moderately successful, they were not fully able to quell the insurgency. Proving more fortunate was his choice to break with the French and seek friendly ties with Libyan president Gaddafi, taking away the rebels' principal source of supplies.
But while he had reported some success against the rebels, Tombalbaye started behaving more and more irrationally and brutally, continuously eroding his consensus among the southern elites, which dominated all key positions in the army, the civil service and the ruling party. As a consequence on April 13, 1975, several units of N'Djamena's gendarmerie killed Tombalbaye during a coup.
Military rule (1975–78).
The coup d'état that terminated Tombalbaye's government received an enthusiastic response in N'Djamena. The southerner General Félix Malloum emerged early as the chairman of the new "junta".
The new military leaders were unable to retain for long the popularity that they had gained through their overthrow of Tombalbaye. Malloum proved himself unable to cope with the FROLINAT and at the end decided his only chance was in coopting some of the rebels: in 1978 he allied himself with the insurgent leader Hissène Habré, who entered the government as prime minister.
Civil war (1979-82).
Internal dissent within the government led Prime Minister Habré to send his forces against Malloum's national army in the capital in February 1979. Malloum was ousted from the presidency, but the resulting civil war amongst the 11 emergent factions was so widespread that it rendered the central government largely irrelevant. At that point, other African governments decided to intervene.
A series of four international conferences held first under Nigerian and then Organization of African Unity (OAU) sponsorship attempted to bring the Chadian factions together. At the fourth conference, held in Lagos, Nigeria, in August 1979, the Lagos Accord was signed. This accord established a transitional government pending national elections. In November 1979, the Transitional Government of National Unity (GUNT) was created with a mandate to govern for 18 months. Goukouni Oueddei, a northerner, was named President; Colonel Kamougué, a southerner, Vice President; and Habré, Minister of Defense. This coalition proved fragile; in January 1980, fighting broke out again between Goukouni's and Habré's forces. With assistance from Libya, Goukouni regained control of the capital and other urban centers by year’s end. However, Goukouni’s January 1981 statement that Chad and Libya had agreed to work for the realization of complete unity between the two countries generated intense international pressure and Goukouni's subsequent call for the complete withdrawal of external forces.
The Habré era (1982–90).
Libya's partial withdrawal to the Aozou Strip in northern Chad cleared the way for Habré's forces to enter N’Djamena in June. French troops and an OAU peacekeeping force of 3,500 Nigerian, Senegalese, and Zairian troops (partially funded by the United States) remained neutral during the conflict.
Habré continued to face armed opposition on various fronts, and was brutal in his repression of suspected opponents, massacring and torturing many during his rule. In the summer of 1983, GUNT forces launched an offensive against government positions in northern and eastern Chad with heavy Libyan support. In response to Libya's direct intervention, French and Zairian forces intervened to defend Habré, pushing Libyan and rebel forces north of the 16th parallel. In September 1984, the French and the Libyan governments announced an agreement for the mutual withdrawal of their forces from Chad. By the end of the year, all French and Zairian troops were withdrawn. Libya did not honor the withdrawal accord, and its forces continued to occupy the northern third of Chad.
Rebel commando groups (Codos) in southern Chad were broken up by government massacres in 1984. In 1985 Habré briefly reconciled with some of his opponents, including the Democratic Front of Chad (FDT) and the Coordinating Action Committee of the Democratic Revolutionary Council. Goukouni also began to rally toward Habré, and with his support Habré successfully expelled Libyan forces from most of Chadian territory. A cease-fire between Chad and Libya held from 1987 to 1988, and negotiations over the next several years led to the 1994 International Court of Justice decision granting Chad sovereignty over the Aouzou strip, effectively ending Libyan occupation.
The Déby era.
Rise to power.
However, rivalry between Hadjerai, Zaghawa and Gorane groups within the government grew in the late 1980s. In April 1989, Idriss Déby, one of Habré's leading generals and a Zaghawa, defected and fled to Darfur in Sudan, from which he mounted a Zaghawa-supported series of attacks on Habré (a Gorane). In December 1990, with Libyan assistance and no opposition from French troops stationed in Chad, Déby’s forces successfully marched on N’Djamena. After 3 months of provisional government, Déby’s Patriotic Salvation Movement (MPS) approved a national charter on February 28, 1991, with Déby as president.
During the next two years, Déby faced at least two coup attempts. Government forces clashed violently with rebel forces, including the Movement for Democracy and Development, MDD, National Revival Committee for Peace and Democracy (CSNPD), Chadian National Front (FNT) and the Western Armed Forces (FAO), near Lake Chad and in southern regions of the country. Earlier French demands for the country to hold a National Conference resulted in the gathering of 750 delegates representing political parties (which were legalized in 1992), the government, trade unions and the army to discuss the creation of a pluralist democratic regime.
However, unrest continued, sparked in part by large-scale killings of civilians in southern Chad. The CSNPD, led by Kette Moise and other southern groups entered into a peace agreement with government forces in 1994, which later broke down. Two new groups, the Armed Forces for a Federal Republic (FARF) led by former Kette ally Laokein Barde and the Democratic Front for Renewal (FDR), and a reformulated MDD clashed with government forces from 1994 to 1995.
Multiparty elections.
Talks with political opponents in early 1996 did not go well, but Déby announced his intent to hold presidential elections in June. Déby won the country’s first multi-party presidential elections with support in the second round from opposition leader Kebzabo, defeating General Kamougue (leader of the 1975 coup against Tombalbaye). Déby’s MPS party won 63 of 125 seats in the January 1997 legislative elections. International observers noted numerous serious irregularities in presidential and legislative election proceedings.
By mid-1997 the government signed peace deals with FARF and the MDD leadership and succeeded in cutting off the groups from their rear bases in the Central African Republic and Cameroon. Agreements also were struck with rebels from the National Front of Chad (FNT) and Movement for Social Justice and Democracy in October 1997. However, peace was short-lived, as FARF rebels clashed with government soldiers, finally surrendering to government forces in May 1998. Barde was killed in the fighting, as were hundreds of other southerners, most civilians.
Since October 1998, Chadian Movement for Justice and Democracy (MDJT) rebels, led by Youssuf Togoimi until his death in September 2002, have skirmished with government troops in the Tibesti region, resulting in hundreds of civilian, government, and rebel casualties, but little ground won or lost. No active armed opposition has emerged in other parts of Chad, although Kette Moise, following senior postings at the Ministry of Interior, mounted a smallscale local operation near Moundou which was quickly and violently suppressed by government forces in late 2000.
Déby, in the mid-1990s, gradually restored basic functions of government and entered into agreements with the World Bank and IMF to carry out substantial economic reforms. Oil exploitation in the southern Doba region began in June 2000, with World Bank Board approval to finance a small portion of a project, the Chad-Cameroon Petroleum Development Project, aimed at transport of Chadian crude through a 1000-km. buried pipeline through Cameroon to the Gulf of Guinea. The project established unique mechanisms for World Bank, private sector, government, and civil society collaboration to guarantee that future oil revenues benefit local populations and result in poverty alleviation. Success of the project depended on multiple monitoring efforts to ensure that all parties keep their commitments. These "unique" mechanisms for monitoring and revenue management have faced intense criticism from the beginning. Debt relief was accorded to Chad in May 2001.
Déby won a flawed 63% first-round victory in May 2001 presidential elections after legislative elections were postponed until spring 2002. Having accused the government of fraud, six opposition leaders were arrested (twice) and one opposition party activist was killed following the announcement of election results. However, despite claims of government corruption, favoritism of Zaghawas, and abuses by the security forces, opposition party and labor union calls for general strikes and more active demonstrations against the government have been unsuccessful. Despite movement toward democratic reform, power remains in the hands of a northern ethnic oligarchy.
In 2003, Chad began receiving refugees from the Darfur region of western Sudan. More than 200,000 refugees fled the fighting between two rebel groups and government-supported militias known as Janjaweed. A number of border incidents led to the Chadian-Sudanese War.
War in the East.
An attack on the Chadian town of Adre near the Sudanese border led to the deaths of either one hundred rebels, as every news source other than CNN has reported, or three hundred rebels. The Sudanese government was blamed for the attack, which was the second in the region in three days, but Sudanese foreign ministry spokesman Jamal Mohammed Ibrahim denies any Sudanese involvement, "We are not for any escalation with Chad. We technically deny involvement in Chadian internal affairs." This attack was the final straw that led to the declaration of war by Chad and the alleged deployment of the Chadian airforce into Sudanese airspace, which the Chadian government denies.
An attack on N'Djamena was defeated on April 13, 2006 in the Battle of N'Djamena. The President on national radio stated that the situation was under control, but residents, diplomats and journalists reportedly heard shots of weapons fire.
On November 25, 2006, rebels captured the eastern town of Abeche, capital of the Ouaddaï Region and center for humanitarian aid to the Darfur region in Sudan. On the same day, a separate rebel group Rally of Democratic Forces had captured Biltine. On November 26, 2006, the Chadian government claimed to have recaptured both towns, although rebels still claimed control of Biltine. Government buildings and humanitarian aid offices in Abeche were said to have been looted. The Chadian government denied a warning issued by the French Embassy in N'Djamena that a group of rebels was making its way through the Batha Prefecture in central Chad. Chad insists that both rebel groups are supported by the Sudanese government.
Rebel attack on Ndjamena.
On Friday, February 1, 2008, rebels, an opposition alliance of leaders Mahamat Nouri, a former defense minister, and Timane Erdimi, a nephew of Idriss Déby who was his chief of staff, attacked the Chadian capital of Ndjamena - even surrounding the Presidential Palace. But Idris Deby with government troops fought back. French forces flew in ammunition for Chadian government troops but took no active part in the fighting. UN has said that up to 20,000 people left the region, taking refuge in nearby Cameroon and Nigeria. Hundreds of people were killed, mostly civilians. The rebels accuse Deby of corruption and embezzling millions in oil revenue. While many Chadians may share that assessment, the uprising appears to be a power struggle within the elite that has long controlled Chad. The French government believes that the opposition has regrouped east of the capital. Déby has blamed Sudan for the current unrest in Chad.
International orphanage scandal.
Nearly 100 children at the center of an international scandal that left them stranded at an orphanage in remote eastern Chad returned home after nearly five months March 14, 2008. The 97 children were taken from their homes in October 2007 by a then-obscure French charity, Zoé's Ark, which claimed they were orphans from Sudan's war-torn Darfur region.

</doc>
<doc id="5330" url="https://en.wikipedia.org/wiki?curid=5330" title="Geography of Chad">
Geography of Chad

Chad is one of the 48 land-locked countries in the world and is located in North Central Africa, measuring , nearly twice the size of France and slightly more than three times the size of California. Most of its ethnically and linguistically diverse population lives in the south, with densities ranging from 54 persons per square kilometer in the Logone River basin to 0.1 persons in the northern B.E.T. (Borkou-Ennedi-Tibesti) desert region, which itself is larger than France. The capital city of N'Djaména, situated at the confluence of the Chari and Logone Rivers, is cosmopolitan in nature, with a current population in excess of 700,000 people.
Chad has four bioclimatic zones. The northernmost Saharan zone averages less than of rainfall annually. The sparse human population is largely nomadic, with some livestock, mostly small ruminants and camels. The central Sahelian zone receives between rainfall and has vegetation ranging from grass/shrub steppe to thorny, open savanna. The southern zone, often referred to as the Sudanian zone, receives between , with woodland savanna and deciduous forests for vegetation. Rainfall in the Guinea zone, located in Chad's southwestern tip, ranges between .
The country's topography is generally flat, with the elevation gradually rising as one moves north and east away from Lake Chad. The highest point in Chad is Emi Koussi, a mountain that rises in the northern Tibesti Mountains. The Ennedi Plateau and the Ouaddaï highlands in the east complete the image of a gradually sloping basin, which descends towards Lake Chad. There are also central highlands in the Guera region rising to .
Lake Chad is the second largest lake in west Africa and is one of the most important wetlands on the continent. Home to 120 species of fish and at least that many species of birds, the lake has shrunk dramatically in the last four decades due to increased water usage from an expanding population and low rainfall. Bordered by Chad, Niger, Nigeria, and Cameroon, Lake Chad currently covers only 1350 square kilometers, down from 25,000 square kilometers in 1963. The Chari and Logone Rivers, both of which originate in the Central African Republic and flow northward, provide most of the surface water entering Lake Chad.
Geographical setting.
Located in north-central Africa, Chad stretches for about 1,800 kilometers from its northernmost point to its southern boundary. Except in the far northwest and south, where its borders converge, Chad's average width is about 800 kilometers. Its area of 1,284,000 square kilometers is roughly equal to the combined areas of Idaho, Wyoming, Utah, Nevada, and Arizona. Chad's neighbors include Libya to the north, Niger and Nigeria to the west, Sudan to the east, Central African Republic to the south, and Cameroon to the southwest.
Chad exhibits two striking geographical characteristics. First, the country is landlocked. N'Djamena, the capital, is located more than 1,100 kilometers northeast of the Atlantic Ocean; Abéché, a major city in the east, lies 2,650 kilometers from the Red Sea; and Faya-Largeau, a much smaller but strategically important center in the north, is in the middle of the Sahara Desert, 1,550 kilometers from the Mediterranean Sea. These vast distances from the sea have had a profound impact on Chad's historical and contemporary development.
The second noteworthy characteristic is that the country borders on very different parts of the African continent: North Africa, with its Islamic culture and economic orientation toward the Mediterranean Basin and West Africa, with its diverse religions and cultures and its history of highly developed states and regional economies;
Chad also borders Northeast Africa, oriented toward the Nile Valley and the Red Sea region - and Central or Equatorial Africa, some of whose people have retained classical African religions while others have adopted Christianity, and whose economies were part of the great Congo River system. Although much of Chad's distinctiveness comes from this diversity of influences, since independence the diversity has also been an obstacle to the creation of a national identity.
Land.
Although Chadian society is economically, socially, and culturally fragmented, the country's geography is unified by the Lake Chad Basin. Once a huge inland sea (the Pale-Chadian Sea) whose only remnant is shallow Lake Chad, this vast depression extends west into Nigeria and Niger. The larger, northern portion of the basin is bounded within Chad by the Tibesti Mountains in the northwest, the Ennedi Plateau in the northeast, the Ouaddaï Highlands in the east along the border with Sudan, the Guéra Massif in central Chad, and the Mandara Mountains along Chad's southwestern border with Cameroon. The smaller, southern part of the basin falls almost exclusively in Chad. It is delimited in the north by the Guéra Massif, in the south by highlands 250 kilometers south of the border with Central African Republic, and in the southwest by the Mandara Mountains.
Lake Chad, located in the southwestern part of the basin at an altitude of 282 meters, surprisingly does not mark the basin's lowest point; instead, this is found in the Bodele and Djourab regions in the north-central and northeastern parts of the country, respectively. This oddity arises because the great stationary dunes (ergs) of the Kanem region create a dam, preventing lake waters from flowing to the basin's lowest point. At various times in the past, and as late as the 1870s, the Bahr el Ghazal Depression, which extends from the northeastern part of the lake to the Djourab, acted as an overflow canal; since independence, climatic conditions have made overflows impossible.
North and northeast of Lake Chad, the basin extends for more than 800 kilometers, passing through regions characterized by great rolling dunes separated by very deep depressions. Although vegetation holds the dunes in place in the Kanem region, farther north they are bare and have a fluid, rippling character. From its low point in the Djourab, the basin then rises to the plateaus and peaks of the Tibesti Mountains in the north. The summit of this formation—as well as the highest point in the Sahara Desert—is Emi Koussi, a dormant volcano that reaches 3,414 meters above sea level.
The basin's northeastern limit is the Ennedi Plateau, whose limestone bed rises in steps etched by erosion. East of the lake, the basin rises gradually to the Ouaddaï Highlands, which mark Chad's eastern border and also divide the Chad and Nile watersheds. These highland areas are part of the East Saharan montane xeric woodlands ecoregion.
Southeast of Lake Chad, the regular contours of the terrain are broken by the Guéra Massif, which divides the basin into its northern and southern parts. South of the lake lie the floodplains of the Chari and Logone rivers, much of which are inundated during the rainy season. Farther south, the basin floor slopes upward, forming a series of low sand and clay plateaus, called koros, which eventually climb to 615 meters above sea level. South of the Chadian border, the koros divide the Lake Chad Basin from the Ubangi-Zaire river system.
Water systems.
Permanent streams do not exist in northern or central Chad. Following infrequent rains in the Ennedi Plateau and Ouaddaï Highlands, water may flow through depressions called enneris and wadis. Often the result of flash floods, such streams usually dry out within a few days as the remaining puddles seep into the sandy clay soil. The most important of these streams is the Batha, which in the rainy season carries water west from the Ouaddaï Highlands and the Guéra Massif to Lake Fitri.
's major rivers are the Chari and the Logone and their tributaries, which flow from the southeast into Lake Chad. Both river systems rise in the highlands of Central African Republic and Cameroon, regions that receive more than 1,250 millimeters of rainfall annually. Fed by rivers of Central African Republic, as well as by the Bahr Salamat, Bahr Aouk, and Bahr Sara rivers of southeastern Chad, the Chari River is about 1,200 kilometers long. From its origins near the city of Sarh, the middle course of the Chari makes its way through swampy terrain; the lower Chari is joined by the Logone River near N'Djamena. The Chari's volume varies greatly, from 17 cubic meters per second during the dry season to 340 cubic meters per second during the wettest part of the year.
The Logone River is formed by tributaries flowing from Cameroon and Central African Republic. Both shorter and smaller in volume than the Chari, it flows northeast for 960 kilometers; its volume ranges from five to eighty-five cubic meters per second. At N'Djamena the Logone empties into the Chari, and the combined rivers flow together for thirty kilometers through a large delta and into Lake Chad. At the end of the rainy season in the fall, the river overflows its banks and creates a huge floodplain in the delta.
The seventh largest lake in the world (and the fourth largest in Africa), Lake Chad is located in the sahelian zone, a region just south of the Sahara Desert. The Chari River contributes 95 percent of Lake Chad's water, an average annual volume of 40 billion cubic meters, 95% of which is lost to evaporation. The size of the lake is determined by rains in the southern highlands bordering the basin and by temperatures in the Sahel. Fluctuations in both cause the lake to change dramatically in size, from 9,800 square kilometers in the dry season to 25,500 at the end of the rainy season.
Lake Chad also changes greatly in size from one year to another. In 1870 its maximum area was 28,000 square kilometers. The measurement dropped to 12,700 in 1908. In the 1940s and 1950s, the lake remained small, but it grew again to 26,000 square kilometers in 1963. The droughts of the late 1960s, early 1970s, and mid-1980s caused Lake Chad to shrink once again, however. The only other lakes of importance in Chad are Lake Fitri, in Batha Prefecture, and Lake Iro, in the marshy southeast.
Climate.
The Lake Chad Basin embraces a great range of tropical climates from north to south, although most of these climates tend to be dry. Apart from the far north, most regions are characterized by a cycle of alternating rainy and dry seasons. In any given year, the duration of each season is determined largely by the positions of two great air masses—a maritime mass over the Atlantic Ocean to the southwest and a much drier continental mass.
During the rainy season, winds from the southwest push the moister maritime system north over the African continent where it meets and slips under the continental mass along a front called the "intertropical convergence zone". At the height of the rainy season, the front may reach as far as Kanem Prefecture. By the middle of the dry season, the intertropical convergence zone moves south of Chad, taking the rain with it. This weather system contributes to the formation of three major regions of climate and vegetation.
Saharan region.
The Saharan region covers roughly the northern half of the country, including Borkou-Ennedi-Tibesti Prefecture along with the northern parts of Kanem, Batha, and Biltine prefectures. Much of this area receives only traces of rain during the entire year; at Faya Largeau, for example, annual rainfall averages less than . Scattered small oases and occasional wells provide water for a few date palms or small plots of millet and garden crops.
In much of the north, the average daily maximum temperature is about during January, the coolest month of the year, and about during May, the hottest month. On occasion, strong winds from the northeast produce violent sandstorms. In northern Biltine Prefecture, a region called the Mortcha plays a major role in animal husbandry. Dry for nine months of the year, it receives or more of rain, mostly during July and August.
A carpet of green springs from the desert during this brief wet season, attracting herders from throughout the region who come to pasture their cattle and camels. Because very few wells and springs have water throughout the year, the herders leave with the end of the rains, turning over the land to the antelopes, gazelles, and ostriches that can survive with little groundwater. Northern Chad averages over 3500 hours of sunlight per year, the south somewhat less.
Sahelian region.
The semiarid sahelian zone, or Sahel, forms a belt about wide that runs from Lac and Chari-Baguirmi prefectures eastward through Guéra, Ouaddaï, and northern Salamat prefectures to the Sudanese frontier. The climate in this transition zone between the desert and the southern soudanian zone is divided into a rainy season (from June to early September) and a dry period (from October to May).
In the northern Sahel, thorny shrubs and acacia trees grow wild, while date palms, cereals, and garden crops are raised in scattered oases. Outside these settlements, nomads tend their flocks during the rainy season, moving southward as forage and surface water disappear with the onset of the dry part of the year. The central Sahel is characterized by drought-resistant grasses and small woods. Rainfall is more abundant there than in the Saharan region. For example, N'Djamena records a maximum annual average rainfall of , while Ouaddaï Prefecture receives just a bit less.
During the hot season, in April and May, maximum temperatures frequently rise above . In the southern part of the Sahel, rainfall is sufficient to permit crop production on unirrigated land, and millet and sorghum are grown. Agriculture is also common in the marshlands east of Lake Chad and near swamps or wells. Many farmers in the region combine subsistence agriculture with the raising of cattle, sheep, goats, and poultry.
Soudanian region.
The humid "soudanian" zone includes the southern prefectures of Mayo-Kebbi, Tandjilé, Logone Occidental, Logone Oriental, Moyen-Chari, and southern Salamat. Between April and October, the rainy season brings between of precipitation. Temperatures are high throughout the year. Daytime readings in Moundou, the major city in the southwest, range from in the middle of the cool season in January to about in the hot months of March, April, and May.
The soudanian region is predominantly East Sudanian savanna, or plains covered with a mixture of tropical or subtropical grasses and woodlands. The growth is lush during the rainy season but turns brown and dormant during the five-month dry season between November and March. Over a large part of the region, however, natural vegetation has yielded to agriculture.
2010 drought.
On 22 June, the temperature reached in Faya, breaking a record set in 1961 at the same location. Similar temperature rises were also reported in Niger, which began to enter a famine situation.
On 26 July the heat reached near-record levels over Chad and Niger.
Area.
Area:
<br>"total:"
1.284 million km²
<br>"land:"
1,259,200 km²
<br>"water:"
24,800 km²
Area - comparative:
<br>Canada: smaller than the Northwest Territories
<br>US: slightly more than three times the size of California
Boundaries.
Land boundaries:
<br>"total:"
6,406 km
<br>"border countries:"
Cameroon 1,116 km, Central African Republic 1,556 km, Libya 1,050 km, Niger 1,196 km, Nigeria 85 km, Sudan 1,403 km
Coastline:
0 km (landlocked)
Maritime claims:
none (landlocked)
Elevation extremes:
<br>"lowest point:"
Djourab Depression 160 m
<br>"highest point:'
Emi Koussi 3,415 m
Land use and resources.
Natural resources:
petroleum, uranium, natron, kaolin, fish (Chari River, Logone River), gold, limestone, sand and gravel, salt
Land use:
<br>"arable land:"
3.89%
<br>"permanent crops:"
0.03%
<br>"other:"
96.08% (2012)
Irrigated land:
302.7 km² (2003)
Total renewable water resources:
43 km3 (2011)
Freshwater withdrawal (domestic/industrial/agricultural):
<br>"total:"
0.88 km3/yr (12%/12%/76%)
<br>"per capita:"
84.81 m3/yr (2005)
Environmental issues.
Natural hazards:
hot, dry, dusty, Harmattan winds occur in north; periodic droughts; locust plagues
Environment - current issues:
inadequate supplies of potable water; improper waste disposal in rural areas contributes to soil and water pollution; desertification
Also see- 2010 Sahel drought
Extreme points.
This is a list of the extreme points of Chad, the points that are farther north, south, east or west than any other location.
"*Note: technically Chad does not have an easternmost point, the northern section of the border being formed by the 24° of longitude"

</doc>
<doc id="5331" url="https://en.wikipedia.org/wiki?curid=5331" title="Demographics of Chad">
Demographics of Chad

The people of Chad speak more than 100 different languages and divide themselves into many ethnic groups. However, language and ethnicity are not the same. Moreover, neither element can be tied to a particular physical type.
Although the possession of a common language shows that its speakers have lived together and have a common history, peoples also change languages. This is particularly so in Chad, where the openness of the terrain, marginal rainfall, frequent drought and famine, and low population densities have encouraged physical and linguistic mobility. Slave raids among{specify} non-Muslim peoples, internal slave trade, and exports of captives northward from the ninth to the twentieth centuries also have resulted in language changes.
Anthropologists view ethnicity as being more than genetics. Like language, ethnicity implies a shared heritage, partly economic, where people of the same ethnic group may share a livelihood, and partly social, taking the form of shared ways of doing things and organizing relations among individuals and groups. Ethnicity also involves a cultural component made up of shared values and a common worldview. Like language, ethnicity is not immutable. Shared ways of doing things change over time and alter a group's perception of its own identity.
Not only do the social aspects of ethnic identity change but the biological composition (or gene pool) also may change over time. Although most ethnic groups emphasize intermarriage, people are often proscribed from seeking partners among close relatives—a prohibition that promotes biological variation. In all groups, the departure of some individuals or groups and the integration of others also changes the biological component.
The Chadian government has avoided official recognition of ethnicity. With the exception of a few surveys conducted shortly after independence, little data were available on this important aspect of Chadian society. Nonetheless, ethnic identity was a significant component of life in Chad.
Chad's languages fall into ten major groups, each of which belongs to either the
Nilo-Saharan, Afro-Asiatic, or Niger–Congo language family. These represent three of the four major language families in Africa; only the Khoisan languages of southern Africa are not represented. The presence of such different languages suggests that the Lake Chad Basin may have been an important point of dispersal in ancient times.
Population.
According to the 2010 revison of the World Population Prospects the total population was 11 227 000 in 2010, compared to only 2 429 000 in 1950. The proportion of children below the age of 15 in 2010 was 45.4%, 51.7% was between 15 and 65 years of age, while 2.9% was 65 years or older
Vital statistics.
Registration of vital events is in Chad not complete. The Population Departement of the United Nations prepared the following estimates.
Fertility and Births.
Total Fertility Rate (TFR) (Wanted Fertility Rate) and Crude Birth Rate (CBR):
Religions.
The separation of religion from social structure in Chad represents a false dichotomy, for they are perceived as two sides of the same coin. Three religious traditions coexist in Chad- classical African religions, Islam, and Christianity. None is monolithic. The first tradition includes a variety of ancestor and/or place-oriented religions whose expression is highly specific. Islam, although characterized by an orthodox set of beliefs and observances, also is expressed in diverse ways. Christianity arrived in Chad much more recently with the arrival of Europeans. Its followers are divided into Roman Catholics and Protestants (including several denominations); as with Chadian Islam, Chadian Christianity retains aspects of pre-Christian religious belief.
The number of followers of each tradition in Chad is unknown. Estimates made in 1962 suggested that 35 percent of Chadians practiced classical African religions, 55 percent were Muslims, and 10 percent were Christians. In the 1970s and 1980s, this distribution undoubtedly changed. Observers report that Islam has spread among the Hajerai and among other non-Muslim populations of the Saharan and sahelian zones. However, the proportion of Muslims may have fallen because the birthrate among the followers of traditional religions and Christians in southern Chad is thought to be higher than that among Muslims. In addition, the upheavals since the mid-1970s have resulted in the departure of some missionaries; whether or not Chadian Christians have been numerous enough and organized enough to have attracted more converts since that time is unknown.
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population.
10,543,000 (2010, According to the U.S. Census Bureau, International Data Base: Demographics of Chad)
Ethnic groups.
About 5,000 French citizens live in Chad.
References.
"U.S. Census Bureau." Census Bureau Home Page. Web. 29 Jan. 2010. <http://www.census.gov/ipc/www/idb/country.php>.

</doc>
<doc id="5332" url="https://en.wikipedia.org/wiki?curid=5332" title="Politics of Chad">
Politics of Chad

Politics of Chad takes place in a framework of a presidential republic, whereby the President of Chad is both head of state and head of government. Executive power is exercised by the government. Legislative power is vested in both the government and parliament. Chad is one of the most corrupt countries in the world.
In May 2013, security forces in Chad foiled a coup against the President Idriss Deby that had been in preparation for several months.
Executive branch.
A strong executive branch headed by President Idriss Déby dominates the Chadian political system. Following his military overthrow of Hissène Habré in December 1990, Déby won presidential elections in 1996 and 2001. The constitutional basis for the government is the 1996 constitution, under which the president was limited to two terms of office until Déby had that provision repealed in 2005. The president has the power to appoint the prime minister and the Council of State (or cabinet), and exercises considerable influence over appointments of judges, generals, provincial officials and heads of Chad’s parastatal firms. In cases of grave and immediate threat, the president, in consultation with the National Assembly President and Council of State, may declare a state of emergency. Most of the Déby's key advisors are members of the Zaghawa clan, although some southern and opposition personalities are represented in his government.
Legislative branch.
According to the 1996 constitution, the National Assembly deputies are elected by universal suffrage for 4-year terms. Parliamentary elections are scheduled for spring 2002. The Assembly holds regular sessions twice a year, starting in March and October, and can hold special sessions as necessary and called by the prime minister. Deputies elect a president of the National Assembly every 2 years. Assembly deputies or members of the executive branch may introduce legislation; once passed by the Assembly, the president must take action to either sign or reject the law within 15 days. The National Assembly must approve the prime minister’s plan of government and may force the prime minister to resign through a majority vote of no-confidence. However, if the National Assembly rejects the executive branch’s program twice in one year, the president may disband the Assembly and call for new legislative elections. In practice, the president exercises considerable influence over the National Assembly through the MPS party structure.
Judicial branch.
Despite the constitution’s guarantee of judicial independence from the executive branch, the president names most key judicial officials. The Supreme Court is made up of a chief justice, named by the president, and 15 councilors chosen by the president and National Assembly; appointments are for life. The Constitutional Council, with nine judges elected to 9-year terms, has the power to review all legislation, treaties and international agreements prior to their adoption. The constitution recognizes customary and traditional law in locales where it is recognized and to the extent it does not interfere with public order or constitutional guarantees of equality for all citizens.
International organization participation.
ACCT, 
ACP, 
AfDB, 
AU, 
BDEAC, 
CEMAC, 
FAO, 
FZ, 
G-77, 
IBRD, 
ICAO, 
ICCt, 
ICFTU, 
ICRM, 
IDA, 
IDB, 
IFAD, 
IFC, 
IFRCS, 
ILO, 
IMF, 
Interpol, 
IOC, 
ITU, 
MIGA, 
NAM, 
OIC, 
ONUB, 
OPCW, 
UN, 
UNCTAD, 
UNESCO, 
UNIDO, 
UNOCI, 
UPU, 
WCL, 
WHO, 
WIPO, 
WMO, 
WToO, 
WTrO

</doc>
<doc id="5333" url="https://en.wikipedia.org/wiki?curid=5333" title="Economy of Chad">
Economy of Chad

Landlocked Chad's economic development suffers from its geographic remoteness, drought, lack of infrastructure, and political turmoil. About 85% of the population depends on agriculture, including the herding of livestock. Of Africa's Francophone countries, Chad benefited least from the 50% devaluation of their currencies in January 1994. Financial aid from the World Bank, the African Development Bank, and other sources is directed largely at the improvement of agriculture, especially livestock production. Because of lack of financing, the development of oil fields near Doba, originally due to finish in 2000, was delayed until 2003. It was finally developed and is now operated by Exxon Mobil Corporation.

</doc>
<doc id="5334" url="https://en.wikipedia.org/wiki?curid=5334" title="Telecommunications in Chad">
Telecommunications in Chad

Telecommunications in Chad include radio, television, fixed and mobile telephones, and the Internet.
Radio and television.
Radio stations:
Radios:
1.7 million (1997).
Television stations:
Television sets:
10,000 (1997).
Radio is the most important medium of mass communication. State-run Radiodiffusion Nationale Tchadienne operates national and regional radio stations. Around a dozen private radio stations are on the air, despite high licensing fees, some run by religious or other non-profit groups. The BBC World Service (FM 90.6) and Radio France Internationale (RFI) broadcast in the capital, N'Djamena. The only television station, Tele Tchad, is state-owned.
State control of many broadcasting outlets allows few dissenting views. Journalists are harassed and attacked. On rare occasions journalists are warned in writing by the High Council for Communication to produce more "responsible" journalism or face fines. Some journalists and publishers practice self-censorship. On 10 October 2012, the High Council on Communications issued a formal warning to La Voix du Paysan, claiming that the station’s live broadcast on 30 September incited the public to "insurrection against the government." The station had broadcast a sermon by a bishop who criticized the government for allegedly failing to use oil wealth to benefit the region.
Telephones.
Calling code: +235
International call prefix: 00
Main lines:
Mobile cellular:
Telephone system: inadequate system of radiotelephone communication stations with high costs and low telephone density; fixed-line connections for less than 1 per 100 persons coupled with mobile-cellular subscribership base of only about 35 per 100 persons (2011).
Satellite earth stations: 1 Intelsat (Atlantic Ocean) (2011).
Internet.
Top-level domain: .td
Internet users:
Fixed broadband: 18,000 subscriptions, 132nd in the world; 0.2% of the population, 161st in the world (2012).
Wireless broadband: Unknown (2012).
Internet hosts:
IPv4: 4,096 addresses allocated, less than 0.05% of the world total, 0.4 addresses per 1000 people (2012).
Internet censorship and surveillance.
There are no government restrictions on access to the Internet or credible reports that the government monitors e-mail or Internet chat rooms.
The constitution provides for freedom of opinion, expression, and press, but the government does not always respect these rights. Private individuals are generally free to criticize the government without reprisal, but reporters and publishers risk harassment from authorities when publishing critical articles. The 2010 media law abolished prison sentences for defamation and insult, but prohibits "inciting racial, ethnic, or religious hatred," which is punishable by one to two years in prison and a fine of one to three million CFA francs ($2,000 to $6,000).

</doc>
<doc id="5335" url="https://en.wikipedia.org/wiki?curid=5335" title="Transport in Chad">
Transport in Chad

Transport infrastructure within Chad is generally poor, especially in the north and east of the country. River transport is limited to the south-west corner. As of 2011 Chad had no railways though two lines are planned - from the capital to the Sudanese and Cameroonian borders.
Roads are mostly unsurfaced and are likely to be impassable during the wet season, especially in the southern half of the country. In the north, roads are merely tracks across the desert and land mines continue to present a danger. Draft animals (horses, donkeys and camels) remain important in much of the country.
Fuel supplies can be erratic, even in the south-west of the country, and are expensive. Elsewhere they are practically non-existent.
Railways.
As of 2011 Chad had no railways. Two lines are planned to Sudan and Cameroon from the capital, with construction expected to start in 2012.
Highways.
Chad has a total of 33,400 km of roads of which approximately 500 km are paved. Some, but not all of the roads in the capital N'Djamena are paved. Outside of N'Djamena there is one paved road which runs from Massakory in the north, through N'Djamena and then south, through the cities of Guelendeng, Bongor, Kélo and Moundou, with a short spur leading in the direction of Kousseri, Cameroon, near N'Djamena. Expansion of the road towards Cameroon through Pala and Léré is reportedly in the preparatory stages.
Waterways.
Most rivers flow but intermittently. On the Chari, between N’Djamena and Lake Chad, transportation is possible all year round. In September and October, the Logone is navigable between N’Djamena and Moundou, and the Chari between N’Djamena and Sarh. Total waterways cover 4,800 km (3,000 mi), of which 2,000 km (1,250 mi) are navigable all year.
Chari and Logone Rivers are navigable only in wet season (2002). Both flow northwards, from the south of Chad, into Lake Chad.
Pipelines.
Since 2003, a 1,070 km pipeline has been used to export crude oil from the oilfields around Doba to offshore oil-loading facilities on Cameroon's Atlantic coast at Kribi.
Seaports and harbors.
None (landlocked).
Chad's main routes to the sea are:
In colonial times, the main access was by road to Bangui, in the Central African Republic, then by river boat to Brazzaville, and onwards by rail from Brazzaville to Pointe Noire, on Congo's Atlantic coast. This route is now little used.
There is also a route across Sudan, to the Red Sea, but very little trade goes this way.
Links with Niger, north of Lake Chad, are practically nonexistent; it is easier to reach Niger via Cameroon and Nigeria.
Airports.
Airports with paved runways.
Statistics on airports with paved runways as of 2012:
List of airports with paved runways:
Airports - with unpaved runways.
Statistics on airports with unpaved runways as of 2012:

</doc>
