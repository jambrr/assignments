<doc id="5679" url="https://en.wikipedia.org/wiki?curid=5679" title="Christian Social Union in Bavaria">
Christian Social Union in Bavaria

The Christian Social Union in Bavaria () is a Christian democratic and conservative political party in Germany. The CSU operates only in Bavaria, while its larger sister party, the Christian Democratic Union (CDU), operates in the other fifteen states of Germany. The CSU has 45 seats in the Bundestag, making it the smallest of the five parties represented.
The CSU was founded in some ways as a continuation of the Weimar-era Catholic Bavarian People's Party (BVP). At the federal level, the CSU forms a common 'CDU/CSU' faction in the Bundestag with the CDU, which is frequently referred to as the Union Faction ("die Unionsfraktion"). Until the 2013 election, the CSU governed at the federal level along with the CDU in a coalition government with the liberal Free Democratic Party (FDP). In the state of Bavaria, the CSU governed as the major party in a coalition government with the FDP from 2008 to 2013. Since the 2013 Bavarian state election the CSU governs alone with an absolute majority. The CSU differs from their coalition partners, the CDU, by being somewhat more conservative in social matters while the CSU is economically a bit more pro-interventionist.
The CSU is a member of the European People's Party (EPP) and the International Democrat Union. The CSU currently has three ministers in the cabinet of Germany of the federal government in Berlin, while party leader Horst Seehofer serves as Minister-President of Bavaria: a position that CSU representatives have held since 1957.
History.
Franz Josef Strauß (1915–1988) had left behind the strongest legacy as a leader of the party, having led the party from 1961 until his death in 1988. His political career in the federal cabinet was unique in that he had served four ministerial posts in the years between 1953 and 1969. From 1978 until his death in 1988, Strauß served as the Minister-president of Bavaria. Strauß was the first leader of the CSU to be a candidate for the German chancellery, in 1980. In the 1980 federal election Strauß ran against the incumbent Helmut Schmidt of the Social Democratic Party of Germany (SPD), but lost thereafter, as the SPD and the Free Democratic Party (FDP) managed to secure an absolute majority together, forming a Social-liberal coalition.
The CSU has led the Bavarian state government since it came into existence in 1946, save from 1950 to 1953 when the Bavaria Party formed a state government in coalition with the state branches of the SPD and FDP. Before the 2008 elections in Bavaria, the CSU perennially achieved absolute majorities at the state level by itself. This level of dominance is unique among Germany's 16 states. Edmund Stoiber took over the CSU leadership in 1999. He ran for Chancellor of Germany in 2002, but his preferred CDU/CSU–FDP coalition lost against the SPD candidate Gerhard Schröder's SPD-Green alliance.
In the 2003 Bavarian state election, the CSU won 60.7% of the vote and 124 of 180 seats in the state parliament. This was the first time any party had won a 2/3 majority in a German state parliament. "The Economist" later suggested that this exceptional result was due to a backlash against Schröder's government in Berlin. The CSU's popularity declined in subsequent years. Stoiber stepped down from the posts of Minister-President and CSU chairman in September 2007. A year later, the CSU lost its majority in the 2008 Bavarian state election, with its vote share dropping from 60.7% to 43.4%. The CSU remained in power by forming a coalition with the Free Democratic Party. In the 2009 general election, the CSU received only 42.5% of the vote in Bavaria in the 2009 election, which constitutes its weakest showing in the party's history.
The CSU made gains in the 2013 Bavarian state election and the 2013 federal election, which were held a week apart in September 2013. The CSU regained their majority in the Bavarian Landtag and remained in government in Berlin. They have three ministers in Angela Merkel's current cabinet: Christian Schmidt (Minister of Food and Agriculture), Alexander Dobrindt (Minister of Transport and Digital Infrastructure) and Gerd Müller (Minister for Economic Cooperation and Development).
Relationship with the CDU.
The CSU is the sister party of the Christian Democratic Union (CDU). Together, they are called 'The Union'. The CSU operates only within Bavaria, and the CDU operates in all other states, but not Bavaria. While virtually independent, at the federal level, the parties form a common CDU/CSU faction. No Chancellor has ever come from the CSU, although Strauß and Edmund Stoiber were CDU/CSU candidates for Chancellor in the 1980 federal election and the 2002 federal election, respectively, which were both won by the Social Democratic Party of Germany (SPD). Below the federal level, the parties are entirely independent.
Since its formation, the CSU has been more conservative than the CDU. It is also regarded as a right-populistic party. The CSU and the state of Bavaria decided not to sign the "Grundgesetz" of the Federal Republic of Germany, as they could not agree with the division of Germany into two states, after World War 2. Although Bavaria has a separate police and justice system (distinctive and non-federal), the CSU has actively participated in all political affairs of the German Parliament, the German Government, the German Bundesrat, the parliamentary elections of the German President, the European Parliament, and meetings with Gorbachev in Russia.
Leaders.
Ministers-President.
The CSU has contributed eleven of the twelve Ministers-President of Bavaria since 1945, with only Wilhelm Hoegner (1945–46, 1954–57) of the SPD also holding the office.
Politicians.
See: List of Bavarian Christian Social Union politicians

</doc>
<doc id="5681" url="https://en.wikipedia.org/wiki?curid=5681" title="Corporate title">
Corporate title

Corporate titles or business titles are given to company and organization officials to show what duties and responsibilities they have in the organization. Such titles are used in publicly and privately held for-profit corporations. In addition, many non-profit organizations, educational institutions, partnerships, and sole proprietorships also confer corporate titles.
Variations.
There are considerable variations in the composition and responsibilities of corporate titles.
Within the corporate office or corporate center of a company, some companies have a chairman and CEO as the top-ranking executive, while the number two is the president and COO; other companies have a president and CEO but no official deputy. Typically, senior managers are "higher" than vice presidents, although many times a senior officer may also hold a vice president title, such as executive vice president and CFO. The board of directors is technically not part of management itself, although its chairman may be considered part of the corporate office if he or she is an executive chairman.
A corporation often consists of different businesses, whose senior executives report directly to the CEO or COO. If organized as a division then the top manager is often known as an executive vice president (for example, Todd Bradley, who used to head the Personal Systems Group in Hewlett-Packard). If that business is a subsidiary which has considerably more independence, then the title might be chairman and CEO.
In many countries, particularly in Europe and Asia, there is a separate executive board for day-to-day business and supervisory board (elected by shareholders) for control purposes. In these countries, the CEO presides over the executive board and the chairman presides over the supervisory board, and these two roles will always be held by different people. This ensures a distinction between management by the executive board and governance by the supervisory board. This seemingly allows for clear lines of authority. There is a strong parallel here with the structure of government, which tends to separate the political cabinet from the management civil service.
In the United States and other countries that follow a single-board corporate structure, the board of directors (elected by the shareholders) is often equivalent to the European/Asian supervisory board, while the functions of the executive board may be vested either in the board of directors or in a separate committee, which may be called an operating committee (J.P. Morgan Chase), management committee (Goldman Sachs), executive committee (Lehman Brothers), or executive council (Hewlett-Packard), or executive board (HeiG) composed of the division/subsidiary heads and senior officers that report directly to the CEO.
United States.
State laws in the United States traditionally required certain positions to be created within every corporation, such as president, secretary and treasurer. Today, the approach under the Model Business Corporation Act, which is employed in many states, is to grant companies discretion in determining which titles to have, with the only mandated organ being the board of directors.
Some states that do not employ the MBCA continue to require that certain offices be established. Under the law of Delaware, where most large US corporations are established, stock certificates must be signed by two officers with titles specified by law (e.g. a president and secretary or a president and treasurer). Every corporation incorporated in California must have a chairman of the board or a president (or both), as well as a secretary and a chief financial officer.
LLC-structured companies are generally run directly by their members (shareholders), but the members can agree to appoint officers such as a CEO, or to appoint "managers" to operate the company.
American companies are generally led by a chief executive officer (CEO). In some companies, the CEO also has the title of president. In other companies, the president is a different person, and the primary duties of the two positions are defined in the company's bylaws (or the laws of the governing legal jurisdiction). Many companies also have a chief financial officer (CFO), chief operating officer (COO) and other senior positions as necessary such as chief information officer, chief sales officer, etc. that report to the president and CEO as "senior vice presidents" of the company. The next level of middle management may be called vice president, director or manager, depending on the size and required managerial depth of the company.
United Kingdom.
In British English, the title of managing director is generally synonymous with that of chief executive officer. Managing directors do not have any particular authority under the Companies Act in the UK, but do have implied authority based on the general understanding of what their position entails, as well as any authority expressly delegated by the board of directors.
Japan and South Korea.
In Japan, corporate titles are roughly standardized across companies and organizations; although there is variation from company to company, corporate titles within a company are always consistent, and the large companies in Japan generally follow the same outline. These titles are the formal titles that are used on business cards. Korean corporate titles are similar to those of Japan, as the South Korean corporate structure had been influenced by the Japanese model.
Legally, Japanese and Korean companies are only required to have a board of directors with at least one representative director. In Japanese, a company director is called a "torishimariyaku" (取締役) and the representative director is called a "daihyo torishimariyaku" (代表取締役). The equivalent Korean titles are "isa" (이사, 理事) and "daepyo-isa" (대표이사, 代表理事). These titles are often combined with lower titles, e.g. "senmu torishimariyaku" or "jomu torishimariyaku" for Japanese executives who are also board members. Most Japanese companies also have statutory auditors, who operate alongside the board of directors in a supervisory role.
The typical structure of executive titles in large companies includes the following:
The top management group, comprising "jomu"/"sangmu" and above, is often referred to collectively as "senior management" (幹部 or 重役; "kambu" or "juyaku" in Japanese; "ganbu" or "jungyŏk" in Korean).
Some Japanese and Korean companies have also adopted American-style titles, but these are not yet widespread and their usage varies. For example, although there is a Korean translation for chief operating officer ("최고운영책임자, choego unyŏng chaegimja"), not many companies have yet adopted it with an exception of a few multi-national companies such as Samsung and CJ, while the chief financial officer title is often used alongside other titles such as "bu-sajang" (SEVP) or "Jŏnmu" (EVP).
Since the late 1990s, many Japanese companies have introduced the title of "shikko yakuin" (執行役員) or "officer," seeking to emulate the separation of directors and officers found in American companies. In 2002, the statutory title of "shikko yaku" (執行役) was introduced for use in companies that introduced a three-committee structure in their board of directors. The titles are frequently given to "bucho" and higher-level personnel. Although the two titles are very similar in intent and usage, there are several legal distinctions: "shikko yaku" make their own decisions in the course of performing work delegated to them by the board of directors, and are considered managers of the company rather than employees, with a legal status similar to that of directors. "Shikko yakuin" are considered employees of the company that follow the decisions of the board of directors, although in some cases directors may have the "shikko yakuin" title as well.
Corporate titles.
Senior management.
The highest-level executives in senior management usually have titles beginning with "chief". The traditional three such officers are chief executive officer (CEO), chief operations officer (COO), and chief financial officer (CFO). Depending on the management structure, titles may exist instead of or are blended/overlapped with other traditional executive titles, such as "president", various designations of "vice presidents" (e.g. VP of marketing), and "general managers" or "directors" of various divisions (such as director of marketing); the latter may or may not imply membership of the "board of directors".
Certain other prominent positions have emerged, some of which are sector-specific. For example, CEO and chief risk officer (CRO) positions are often found in many types of financial services companies. Technology companies of all sorts now tend to have a chief technology officer (CTO) to manage technology development. A chief information officer (CIO) oversees IT (information technology) matters, either in companies that specialize in IT or in any kind of company that relies on it for supporting infrastructure.
Many companies now also have a chief marketing officer (CMO), particularly mature companies in competitive sectors, where brand management is a high priority. In creative/design industries, there is sometimes a chief creative officer (CCO), responsible for keeping the overall look and feel of different products consistent across a brand. A chief administrative officer may be found in many large complex organizations that have various departments or divisions. Additionally, many companies now call their top diversity leadership position the chief diversity officer (CDO). However, this and many other nontraditional and/or lower-ranking titles (see below) are not universally recognized as corporate officers, and they tend to be specific to particular organizational cultures or the preferences of employees.

</doc>
<doc id="5683" url="https://en.wikipedia.org/wiki?curid=5683" title="Computer expo">
Computer expo

A computer expo or computer show is a trade fair or exposition for computers and electronics. Expos usually include company or organization booths where products and technologies are demonstrated; talks and lectures; and general mixing of people with common interests.

</doc>
<doc id="5685" url="https://en.wikipedia.org/wiki?curid=5685" title="Cambridge, Massachusetts">
Cambridge, Massachusetts

Cambridge is a city in Middlesex County, Massachusetts, United States, in the Boston metropolitan area. Situated directly north of the city of Boston, across the Charles River, it was named in honor of the University of Cambridge in the United Kingdom, an important center of the Puritan theology embraced by the town's founders. Cambridge is home to two of the world's most prominent universities, Harvard University and the Massachusetts Institute of Technology. Cambridge has also been home to Radcliffe College, once one of the leading colleges for women in the United States before it merged with Harvard. According to the 2010 Census, the city's population was 105,162. , it was the fifth most populous city in the state, behind Boston, Worcester, Springfield, and Lowell. Cambridge was one of the two seats of Middlesex County prior to the abolition of county government in 1997; Lowell was the other.
History.
The site for what would become Cambridge was chosen in December 1630, because it was located safely upriver from Boston Harbor, which made it easily defensible from attacks by enemy ships. Thomas Dudley, his daughter Anne Bradstreet and her husband Simon, were among the first settlers of the town. The first houses were built in the spring of 1631. The settlement was initially referred to as "the newe towne". Official Massachusetts records show the name capitalized as Newe Towne by 1632, and a single word, Newtowne, by 1638. Located at the first convenient Charles River crossing west of Boston, Newe Towne was one of a number of towns (including Boston, Dorchester, Watertown, and Weymouth), founded by the 700 original Puritan colonists of the Massachusetts Bay Colony under governor John Winthrop. The original village site is in the heart of today's Harvard Square. The marketplace where farmers brought in crops from surrounding towns to sell survives today as the small park at the corner of John F. Kennedy (J.F.K.) and Winthrop Streets, then at the edge of a salt marsh, since filled. The town included a much larger area than the present city, with various outlying parts becoming independent towns over the years: Newton (originally Cambridge Village, then Newtown) in 1688, Lexington (Cambridge Farms) in 1712, and both West Cambridge (originally Menotomy) and Brighton (Little Cambridge) in 1807. Part of West Cambridge joined the new town of Belmont in 1859, and the rest of West Cambridge was renamed Arlington in 1867; Brighton was annexed by Boston in 1874. In the late 19th century, various schemes for annexing Cambridge itself to the city of Boston were pursued and rejected.
In 1636, the Newe College (later renamed Harvard College, after benefactor John Harvard), was founded by the colony to train ministers. The Newe Towne (later named Cambridge) was chosen for the site of the new college by the Great and General Court (the Massachusetts legislature)...primarily, according to testimony by Cotton Mather, to be near the highly respected, popular Puritan preacher Thomas Shepard. By 1638, the name "Newe Towne" had "compacted by usage into 'Newtowne'." In May 1638 the name was changed to Cambridge in honor of the university in Cambridge, England. Thomas Shepard, the minister of Cambridge's church; Harvard's first president (Henry Dunster); its first benefactor (John Harvard); and the first schoolmaster (Nathaniel Eaton), were all Cambridge University alumni, as was the then ruling (and first) governor of the Massachusetts Bay Colony, John Winthrop. In 1629, Winthrop had led the signing of the founding document of the city of Boston, which was known as the Cambridge Agreement, after the university. It was Governor Thomas Dudley who, in 1650, signed the charter creating the corporation which still governs Harvard College.
Cambridge grew slowly as an agricultural village eight miles (13 km) by road from Boston, the capital of the colony. By the American Revolution, most residents lived near the Common and Harvard College, with farms and estates comprising most of the town. Most of the inhabitants were descendants of the original Puritan colonists, but there was also a small elite of Anglican "worthies" who were not involved in village life, who made their livings from estates, investments, and trade, and lived in mansions along "the Road to Watertown" (today's Brattle Street, still known as Tory Row). In 1775, George Washington came up from Virginia to take command of fledgling volunteer American soldiers camped on the Cambridge Common—today called the birthplace of the U.S. Army. (The name of today's nearby Sheraton Commander Hotel refers to that event.) Most of the Tory estates were confiscated after the Revolution. On January 24, 1776, Henry Knox arrived with artillery captured from Fort Ticonderoga, which enabled Washington to drive the British army out of Boston.
Between 1790 and 1840, Cambridge began to grow rapidly, with the construction of the West Boston Bridge in 1792, that connected Cambridge directly to Boston, making it no longer necessary to travel eight miles (13 km) through the Boston Neck, Roxbury, and Brookline to cross the Charles River. A second bridge, the Canal Bridge, opened in 1809 alongside the new Middlesex Canal. The new bridges and roads made what were formerly estates and marshland into prime industrial and residential districts.
In the mid-19th century, Cambridge was the center of a literary revolution when it gave the country a new identity through poetry and literature. Cambridge was home to some of the famous Fireside Poets—so called because their poems would often be read aloud by families in front of their evening fires. In their day, the Fireside Poets—Henry Wadsworth Longfellow, James Russell Lowell, and Oliver Wendell Holmes—were as popular and influential as rock stars are today.
Soon after, turnpikes were built: the Cambridge and Concord Turnpike (today's Broadway and Concord Ave.), the Middlesex Turnpike (Hampshire St. and Massachusetts Ave. northwest of Porter Square), and what are today's Cambridge, Main, and Harvard Streets were roads to connect various areas of Cambridge to the bridges. In addition, railroads crisscrossed the town during the same era, leading to the development of Porter Square as well as the creation of neighboring town Somerville from the formerly rural parts of Charlestown.
Cambridge was incorporated as a city in 1846. This was despite noticeable tensions between East Cambridge, Cambridgeport, and Old Cambridge that stemmed from differences in each area's culture, sources of income, and the national origins of the residents. The city's commercial center began to shift from Harvard Square to Central Square, which became the downtown of the city around this time. Between 1850 and 1900, Cambridge took on much of its present character—streetcar suburban development along the turnpikes, with working-class and industrial neighborhoods focused on East Cambridge, comfortable middle-class housing being built on old estates in Cambridgeport and Mid-Cambridge, and upper-class enclaves near Harvard University and on the minor hills of the city. The coming of the railroad to North Cambridge and Northwest Cambridge then led to three major changes in the city: the development of massive brickyards and brickworks between Massachusetts Ave., Concord Ave. and Alewife Brook; the ice-cutting industry launched by Frederic Tudor on Fresh Pond; and the carving up of the last estates into residential subdivisions to provide housing to the thousands of immigrants that arrived to work in the new industries.
For many decades, the city's largest employer was the New England Glass Company, founded in 1818. By the middle of the 19th century it was the largest and most modern glassworks in the world. In 1888, all production was moved, by Edward Drummond Libbey, to Toledo, Ohio, where it continues today under the name Owens Illinois. Flint glassware with heavy lead content, produced by that company, is prized by antique glass collectors today. There is none on public display in Cambridge, but there is a large collection in the Toledo Museum of Art. There are also a few pieces in the Museum of Fine Arts, Boston and in the Sandwich Glass Museum on Cape Cod.
By 1920, Cambridge was one of the main industrial cities of New England, with nearly 120,000 residents. Among the largest businesses located in Cambridge during the period of industrialization was the firm of Carter's Ink Company, whose neon sign long adorned the Charles River and which was for many years the largest manufacturer of ink in the world. Next door was the Atheneum Press. Confectionery and snack manufacturers in the Cambridgeport-Area 4-Kendall corridor included the Kennedy Biscuit Factory (later part of Nabisco and originator of the Fig Newton), Necco, Squirrel Brands), George Close Company (1861–1930s), Daggett Chocolate (1892–1960s, recipes bought by Necco), Fox Cross Company (1920–1980, originator of the Charleston Chew, and now part of Tootsie Roll Industries), Kendall Confectionery Company, and James O. Welch (1927–1963, originator of Junior Mints, Sugar Daddies, Sugar Mamas and Sugar Babies, now part of Tootsie Roll Industries). In the 2010s, only the Cambridge Brands subsidiary of Tootsie Roll Industries remains in town, still manufacturing Junior Mints in the old Welch factory on Main Street. The Blake and Knowles Steam Pump Company (1886) and the Kendall Boiler and Tank Company (1880, now in Chelmsford, Massachusetts) and the New England Glass Company (1818–1878) were among the industrial manufacturers in what are now the Kendall Square and East Cambridge neighborhoods.
As industry in New England began to decline during the Great Depression and after World War II, Cambridge lost much of its industrial base. It also began the transition to being an intellectual, rather than an industrial, center. Harvard University had always been important in the city (both as a landowner and as an institution), but it began to play a more dominant role in the city's life and culture. When Radcliffe College was established in 1879 the town became a mecca for some of the nation's most academically talented female students. Also, the move of the Massachusetts Institute of Technology from Boston in 1916 ensured Cambridge's status as an intellectual center of the United States.
After the 1950s, the city's population began to decline slowly, as families tended to be replaced by single people and young couples. The 1980s brought a wave of high-technology startups, creating software such as Visicalc and Lotus 1-2-3, and advanced computers, but many of these companies fell into decline with the fall of the minicomputer and DOS-based systems. The city continues to be home to many startups as well as a thriving biotech industry which includes headquarters for Biogen and Genzyme and laboratories for Novartis. Kendall Square continued to be a major software hub through the dot-com boom and today hosts offices of major technology companies including Google, Microsoft, Amazon.com, and Akamai (headquarters).
By the end of the 20th century, Cambridge had one of the most expensive housing markets in the Northeastern United States. While maintaining much diversity in class, race, and age, it became harder and harder for those who grew up in the city to be able to afford to stay. The end of rent control in 1994 prompted many Cambridge renters to move to housing that was more affordable, in Somerville and other communities. In 2005, a reassessment of residential property values resulted in a disproportionate number of houses owned by non-affluent people jumping in value relative to other houses, with hundreds having their property tax increased by over 100%; this forced many homeowners in Cambridge to move elsewhere.
, Cambridge's mix of amenities and proximity to Boston has kept housing prices relatively stable despite the bursting of the United States housing bubble. Cambridge has been a sanctuary city since 1985 and reaffirmed its status as such in 2006.
Geography.
According to the United States Census Bureau, Cambridge has a total area of , of which is land and (9.82%) is water.
Adjacent municipalities.
Cambridge is located in eastern Massachusetts, bordered by:
The border between Cambridge and the neighboring city of Somerville passes through densely populated neighborhoods which are connected by the MBTA Red Line. Some of the main squares, Inman, Porter, and to a lesser extent, Harvard and Lechmere, are very close to the city line, as are Somerville's Union and Davis Squares.
Neighborhoods.
Squares.
Cambridge has been called the "City of Squares" by some, as most of its commercial districts are major street intersections known as squares. Each of the squares acts as a neighborhood center. These include:
Other neighborhoods.
The residential neighborhoods in Cambridge border, but are not defined by the squares. These neighborhoods include:
Parks and outdoors.
Consisting largely of densely built residential space, Cambridge lacks significant tracts of public parkland. This is partly compensated for, however, by the presence of easily accessible open space on the university campuses, including Harvard Yard, the Radcliffe Yard, and MIT's Great Lawn, as well as the considerable open space of Mount Auburn Cemetery. At the western edge of Cambridge, the cemetery is well known as the first garden cemetery, for its distinguished inhabitants, for its superb landscaping (the oldest planned landscape in the country), and as a first-rate arboretum. Although known as a Cambridge landmark, much of the cemetery lies within the bounds of Watertown. It is also a significant Important Bird Area (IBA) in the Greater Boston area.
Public parkland includes the esplanade along the Charles River, which mirrors its Boston counterpart; Cambridge Common, a busy and historic public park immediately adjacent to the Harvard campus; and the Alewife Brook Reservation and Fresh Pond in the western part of the city.
Demographics.
As of the census of 2010, there were 105,162 people, 44,032 households, and 17,420 families residing in the city. The population density was 16,354.9 people per square mile (6,314.6/km²). There were 47,291 housing units at an average density of 7,354.7 per square mile (2,840.3/km²). The racial makeup of the city was 66.60% White, 11.70% Black or African American, 0.20% Native American, 15.10% Asian (3.7% Chinese, 1.4% Asian Indian, 1.2% Korean, 1.0% Japanese), 0.01% Pacific Islander, 2.10% from other races, and 4.30% from two or more races. 7.60% of the population were Hispanic or Latino of any race (1.6% Puerto Rican, 1.4% Mexican, 0.6% Dominican, 0.5% Colombian, 0.5% Salvadoran, 0.4% Spaniard). Non-Hispanic Whites were 62.1% of the population in 2010, down from 89.7% in 1970. An individual resident of Cambridge is known as a Cantabrigian.
In 2010, there were 44,032 households out of which 16.9% had children under the age of 18 living with them, 28.9% were married couples living together, 8.4% had a female householder with no husband present, and 60.4% were non-families. 40.7% of all households were made up of individuals and 9.6% had someone living alone who was 65 years of age or older. The average household size was 2.00 and the average family size was 2.76.
In the city the population was spread out with 13.3% of the population under the age of 18, 21.2% from 18 to 24, 38.6% from 25 to 44, 17.8% from 45 to 64, and 9.2% who were 65 years of age or older. The median age was 30.5 years. For every 100 females, there were 96.1 males. For every 100 females age 18 and over, there were 94.7 males.
The median income for a household in the city was $47,979, and the median income for a family was $59,423 (these figures had risen to $58,457 and $79,533 respectively ). Males had a median income of $43,825 versus $38,489 for females. The per capita income for the city was $31,156. About 8.7% of families and 12.9% of the population were below the poverty line, including 15.1% of those under age 18 and 12.9% of those age 65 or over.
Cambridge has been ranked as one of the most liberal cities in America. Locals living in and near the city jokingly refer to it as "The People's Republic of Cambridge." For 2016, the residential property tax rate in Cambridge was $6.99 per $1,000. Cambridge enjoys the highest possible bond credit rating, AAA, with all three Wall Street rating agencies.
Cambridge is the birthplace of Thai king Bhumibol Adulyadej (Rama IX), who is the world's longest reigning monarch at age 85 (early 2013), as well as the longest reigning monarch in Thai history. He is also the first king of a foreign country to be born in the United States.
In 2000, 11.0% of city residents were of Irish ancestry; 7.2% were of English, 6.9% Italian, 5.5% West Indian and 5.3% German ancestry. 69.4% spoke only English at home, while 6.9% spoke Spanish, 3.2% Chinese or Mandarin, 3.0% Portuguese, 2.9% French Creole, 2.3% French, 1.5% Korean, and 1.0% Italian.
Income.
Data is from the 2009–2013 American Community Survey 5-Year Estimates.
Government.
Federal and state representation.
Cambridge is split between Massachusetts's 5th and 7th U.S. congressional districts. The 5th district seat is held by Democrat Katherine Clark, who replaced now-Senator Ed Markey in a 2013 special election; the 7th is represented by Democrat Mike Capuano, elected in 1998. The state's senior member of the United States Senate is Democrat Elizabeth Warren, elected in 2012, who lives in Cambridge. The Governor of Massachusetts is Republican Charlie Baker, elected in 2014.
On the state level, Cambridge is represented in six districts in the Massachusetts House of Representatives: the 24th Middlesex (which includes parts of Belmont and Arlington), the 25th and 26th Middlesex (the latter which includes a portion of Somerville), the 29th Middlesex (which includes a small part of Watertown), and the Eighth and Ninth Suffolk (both including parts of the City of Boston). The city is represented in the Massachusetts Senate as a part of the "First Suffolk and Middlesex" district (this contains parts of Boston, Revere and Winthrop each in Suffolk County); the "Middlesex, Suffolk and Essex" district, which includes Everett and Somerville, with Boston, Chelsea, and Revere of Suffolk, and Saugus in Essex; and the "Second Suffolk and Middlesex" district, containing parts of the City of Boston in Suffolk County, and Cambridge, Belmont and Watertown in Middlesex County.
City government.
Cambridge has a city government led by a mayor and nine-member city council. There is also a six-member school committee which functions alongside the Superintendent of public schools. The councilors and school committee members are elected every two years using the single transferable vote (STV) system.
The mayor is elected by the city councilors from amongst themselves, and serves as the chair of city council meetings. The mayor also sits on the school committee. However, the mayor is not the chief executive of the city. Rather, the city manager, who is appointed by the city council, serves in that capacity.
Under the city's Plan E form of government, the city council does not have the power to appoint or remove city officials who are under direction of the city manager. The city council and its individual members are also forbidden from giving orders to any subordinate of the city manager.
Richard C. Rossi is the city manager. On March 11, 2016, Rossi announced that he had opted out of his contract renewal and would retire as of June 2016. Rossi succeeded Robert W. Healy, who retired in June 2013 after serving 32 years in the position. In recent history, the media has highlighted the salary of the city manager as being one of the highest for a civic employee in Massachusetts.
The city council consists of:
"* = current mayor"<br>
"** = former mayor"
Police department.
In addition to the Cambridge Police Department, the city is patrolled by the Fifth (Brighton) Barracks of Troop H of the Massachusetts State Police. Due, however, to close proximity, the city also practices functional cooperation with the Fourth (Boston) Barracks of Troop H, as well. The campuses of Harvard and MIT are patrolled by the Harvard University Police Department and MIT Police Department, respectively.
Fire department.
The city of Cambridge is protected by the Cambridge Fire Department. Established in 1832, the CFD currently operates eight engine companies, four ladder companies, one rescue company, and two paramedic squad companies from eight fire stations located throughout the city. The current Chief is Gerald R. Reardon.
Water department.
Cambridge is unusual among cities inside Route 128 in having a non-MWRA water supply. City water is obtained from Hobbs Brook (in Lincoln and Waltham), Stony Brook (Waltham and Weston. The city owns over of land in other towns that includes these reservoirs and portions of their watershed. Water from these reservoirs flows by gravity through an aqueduct to Fresh Pond in Cambridge. It is then treated in an adjacent plant and pumped uphill to an elevation of above sea level at the Payson Park Reservoir (Belmont); From there, the water is redistributed downhill via gravity to individual users in the city. A new water treatment plant opened in 2001. The city used MWRA water during the old plant's demolition and the new plant's construction.
County government.
Cambridge was a county seat of Middlesex County, along with Lowell, prior to the abolition of county government. Though the county government was abolished in 1997, the county still exists as a geographical and political region. The employees of Middlesex County courts, jails, registries, and other county agencies now work directly for the state. At present, the county's registrars of Deeds and Probate remain in Cambridge; however, the Superior Court and District Attorney have had their base of operations transferred to Woburn. Third District court has shifted operations to Medford, and the Sheriff's office for the county is still awaiting a near-term relocation.
Education.
Higher education.
Cambridge is perhaps best known as an academic and intellectual center, owing to its colleges and universities, which include:
At least 129 of the world's total 780 Nobel Prize winners have been, at some point in their careers, affiliated with universities in Cambridge.
The American Academy of Arts and Sciences is also based in Cambridge.
Primary and secondary public education.
The 5 upper schools which are physically located in some of the same buildings as the elementary schools offer grades 6–8. They are:
There are three district public high school programs serving Cambridge students, the principal one being the Cambridge Rindge and Latin School (CRLS).
Outside of the main public schools are other public charter schools including: Benjamin Banneker Charter School, which serves students in grades K–6, Community Charter School of Cambridge, which is located in Kendall Square and serves students in grades 7–12, and Prospect Hill Academy, a charter school whose upper school is in Central Square, though it is not a part of the Cambridge Public School District.
Primary and secondary private education.
There are also many private schools in the city including:
Public library services.
Further educational services are provided at the Cambridge Public Library. The large modern main building was built in 2009, and connects to the restored 1888 Richardson Romanesque building. It was originally founded as the private Cambridge Athenaeum in 1849 and was acquired by the city in 1858, and became the Dana Library. The 1888 building was a donation of Frederick H. Rindge.
Economy.
Manufacturing was an important part of the economy in the late 19th and early 20th century, but educational institutions are the city's biggest employers today. Harvard and MIT together employ about 20,000. As a cradle of technological innovation, Cambridge was home to technology firms Analog Devices, Akamai, Bolt, Beranek, and Newman (BBN Technologies) (now part of Raytheon), General Radio (later GenRad), Lotus Development Corporation (now part of IBM), Polaroid, Symbolics, and Thinking Machines.
In 1996, Polaroid, Arthur D. Little, and Lotus were top employers with over 1,000 employees in Cambridge, but faded out a few years later. Health care and biotechnology firms such as Genzyme, Biogen Idec, Millennium Pharmaceuticals, Sanofi, Pfizer and Novartis have significant presences in the city. Though headquartered in Switzerland, Novartis continues to expand its operations in Cambridge. Other major biotech and pharmaceutical firms expanding their presence in Cambridge include GlaxoSmithKline, AstraZeneca, Shire, and Pfizer. Most Biotech firms in Cambridge are located around Kendall Square and East Cambridge, which decades ago were the city's center of manufacturing. A number of biotechnology companies are also located in University Park at MIT, a new development in another former manufacturing area.
None of the high technology firms that once dominated the economy was among the 25 largest employers in 2005, but by 2008 high tech companies Akamai and ITA Software had grown to be among the largest 25 employers. Google, IBM Research, Microsoft Research, and Philips Research maintain offices in Cambridge. In late January 2012—less than a year after acquiring Billerica-based analytic database management company, Vertica—Hewlett-Packard announced it would also be opening its first offices in Cambridge. Around this same time, e-commerce giants Staples and Amazon.com said they would be opening research and innovation centers in Kendall Square. LabCentral also provides a shared laboratory facility for approximately 25 emerging biotech companies.
The proximity of Cambridge's universities has also made the city a center for nonprofit groups and think tanks, including the National Bureau of Economic Research, the Smithsonian Astrophysical Observatory, the Lincoln Institute of Land Policy, Cultural Survival, and One Laptop per Child.
In September 2011, an initiative by the City of Cambridge called the "Entrepreneur Walk of Fame" was launched. It seeks to highlight individuals who have made contributions to innovation in the global business community.
Top employers.
, the ten largest employers in the city are:
Transportation.
Road.
Several major roads lead to Cambridge, including Route 2, Route 16 and the McGrath Highway (Route 28). The Massachusetts Turnpike does not pass through Cambridge, but provides access by an exit in nearby Allston. Both U.S. Route 1 and Interstate 93 also provide additional access on the eastern end of Cambridge at Leverett Circle in Boston. Route 2A runs the length of the city, chiefly along Massachusetts Avenue. The Charles River forms the southern border of Cambridge and is crossed by 11 bridges connecting Cambridge to Boston, including the Longfellow Bridge and the Harvard Bridge, eight of which are open to motorized road traffic.
Cambridge has an irregular street network because many of the roads date from the colonial era. Contrary to popular belief, the road system did not evolve from longstanding cow-paths. Roads connected various village settlements with each other and nearby towns, and were shaped by geographic features, most notably streams, hills, and swampy areas. Today, the major "squares" are typically connected by long, mostly straight roads, such as Massachusetts Avenue between Harvard Square and Central Square, or Hampshire Street between Kendall Square and Inman Square.
Mass transit.
Cambridge is well served by the MBTA, including the Porter Square Station on the regional Commuter Rail; the Lechmere Station on the Green Line; and the Red Line at Alewife, Porter Square, Harvard Square, Central Square, and Kendall Square/MIT Stations. Alewife Station, the current terminus of the Red Line, has a large multi-story parking garage (at a rate of $7 per day ). The Harvard Bus Tunnel, under Harvard Square, reduces traffic congestion on the surface, and connects to the Red Line underground. This tunnel was originally opened for streetcars in 1912, and served trackless trolleys (trolleybuses) and buses as the routes were converted; four lines of the MBTA trolleybus system continue to use it. The tunnel was partially reconfigured when the Red Line was extended to Alewife in the early 1980s.
Besides the state-owned transit agency, the city is also served by the Charles River Transportation Management Agency (CRTMA) shuttles which are supported by some of the largest companies operating in city, in addition to the municipal government itself.
Cycling.
Cambridge has several bike paths, including one along the Charles River, and the Linear Park connecting the Minuteman Bikeway at Alewife with the Somerville Community Path. Bike parking is common and there are bike lanes on many streets, although concerns have been expressed regarding the suitability of many of the lanes. On several central MIT streets, bike lanes transfer onto the sidewalk. Cambridge bans cycling on certain sections of sidewalk where pedestrian traffic is heavy.
While "Bicycling Magazine" in 2006 rated Boston as one of the worst cities in the nation for bicycling, it has given Cambridge honorable mention as one of the best and was called by the magazine "Boston's Great Hope". Boston has since then followed the example of Cambridge, and made considerable efforts to improve bicycling safety and convenience.
Cambridge has an official bicycle committee. The LivableStreets Alliance, headquartered in Cambridge, is an advocacy group for bicyclists, pedestrians, and walkable neighborhoods.
Walking.
Walking is a popular activity in Cambridge. In 2000, of US communities with more than 100,000 residents, Cambridge had the highest percentage of commuters who walked to work. Cambridge's major historic squares have changed into modern walking neighborhoods, including traffic calming features based on the needs of pedestrians rather than of motorists.
Intercity.
The Boston intercity bus and train stations at South Station, Boston, and Logan International Airport in East Boston, are accessible by subway. The Fitchburg Line rail service from Porter Square connects to some western suburbs. Since October 2010, there has also been intercity bus service between Alewife Station (Cambridge) and New York City.
Media.
Newspapers.
Cambridge is served by a weekly newspaper, the "Cambridge Chronicle", which is also the oldest surviving weekly paper in the United States.
Radio.
Cambridge is home to the following commercially licensed and student-run radio stations:
Television and broadband.
Cambridge Community Television (CCTV) has served the Cambridge community since its inception in 1988. CCTV operates Cambridge's public access television facility and programs three television channels, 8, 9, and 96 on the Cambridge cable system (Comcast). The city has invited tenders from other cable providers; however, presently Comcast remains the only fixed television and broadband utility for Cambridge. Services from American satellite TV providers, however, are available. In October 2014, Cambridge City Manager Richard Rossi appointed a citizen Broadband Task Force to "examine options to increase competition, reduce pricing, and improve speed, reliability and customer service for both residents and businesses."
Culture, art and architecture.
Public art.
Cambridge has a large and varied collection of permanent public art, both on city property (managed by the Cambridge Arts Council), and on the campuses of Harvard and MIT. Temporary public artworks are displayed as part of the annual Cambridge River Festival on the banks of the Charles River, during winter celebrations in Harvard and Central Squares, and at university campus sites. Experimental forms of public artistic and cultural expression include the Central Square World's Fair, the Somerville-based annual Honk! Festival, and If This House Could Talk, a neighborhood art and history event. An active tradition of street musicians and other performers in Harvard Square entertains an audience of tourists and local residents during the warmer months of the year. The performances are coordinated through a public process that has been developed collaboratively by the performers, city administrators, private organizations and business groups.
Architecture.
Despite intensive urbanization during the late 19th century and 20th century, Cambridge has several historic buildings, including some dating to the 17th century. The city also contains an abundance of innovative contemporary architecture, largely built by Harvard and MIT.
Music.
The city has an active music scene, from classical performances to the latest popular bands. Beyond performances at the colleges and universities, there are many venues in Cambridge including: The Middle East, Club Passim, The Plough and Stars, and the Nameless Coffeehouse.
Twin towns – Sister cities.
Cambridge has six official sister cities with active relationships:
Cambridge is in the process of developing a relationship with Les Cayes, Haiti.
Cambridge has ten additional official sister cities which are not currently active:

</doc>
<doc id="5686" url="https://en.wikipedia.org/wiki?curid=5686" title="Cambridge (disambiguation)">
Cambridge (disambiguation)

Cambridge is a city and the county town of Cambridgeshire, United Kingdom, famous for being the location of the University of Cambridge.
Cambridge may also refer to:

</doc>
<doc id="5688" url="https://en.wikipedia.org/wiki?curid=5688" title="Colin Dexter">
Colin Dexter

Norman Colin Dexter, OBE, (born 29 September 1930) is an English crime writer known for his Inspector Morse novels, which were written between 1975 and 1999 and adapted as a television series from 1987 to 2000.
Early life and career.
Dexter was born in Stamford, Lincolnshire, and was educated at Stamford School, a boys' public school. After completing his national service with the Royal Corps of Signals, he read Classics at Christ's College, Cambridge, graduating in 1953 and receiving an honorary master's degree in 1958.
In 1954, he started his teaching career in the East Midlands, becoming assistant Classics master at Wyggeston School, Leicester. A post at Loughborough Grammar School followed before he took up the position of senior Classics teacher at Corby Grammar School, Northamptonshire, in 1959.
In 1956 he married Dorothy Cooper, and they had a son and a daughter.
In 1966, he was forced by the onset of deafness to retire from teaching and took up the post of senior assistant secretary at the University of Oxford Delegacy of Local Examinations (UODLE) in Oxford, a job he held until his retirement in 1988.
Dexter featured prominently in the BBC programme "How to Solve a Cryptic Crossword" as part of the "Time Shift" series broadcast in November 2008, in which he recounted some of the crossword clues solved by Morse.
Writing career.
The first books that he wrote were General Studies text books.
He started writing mysteries in 1972 during a family holiday. "We were in a little guest house halfway between Caernarfon and Pwllheli. It was a Saturday and it was raining—it's not unknown for it to rain in North Wales. The children were moaning... I was sitting at the kitchen table with nothing else to do, and I wrote the first few paragraphs of a potential detective novel." "Last Bus to Woodstock" was published in 1975 and introduced the character of Inspector Morse, the irascible detective whose penchants for cryptic crosswords, English literature, cask ale, and Wagner reflect Dexter's own enthusiasms. Dexter's plots are notable for his use of false leads and other red herrings.
The success of the 33 episodes of the TV series "Inspector Morse", produced between 1987 and 2001, brought further acclaim for Dexter. In the manner of Alfred Hitchcock, he also makes a cameo appearance in almost all episodes. 
More recently, Sergeant (now Inspector) Lewis, his character from the Morse series, features in 27 episodes of the new ITV series "Lewis". Dexter is currently a consultant on the TV series "Endeavour" starring Shaun Evans and Roger Allam. This series is a prequel to "Inspector Morse". As with "Morse", Dexter occasionally makes cameo appearances in "Lewis" and "Endeavour".
Dexter selected English poet A.E. Housman for the BBC Radio 4 programme "Great Lives" in May 2008. Dexter and Housman were both Classicists who found a popular audience in another genre of writing.
Awards and honours.
Dexter has received several Crime Writers' Association awards: two Silver Daggers for "Service of All the Dead" in 1979 and "The Dead of Jericho" in 1981; two Gold Daggers for "The Wench is Dead" in 1989 and "The Way Through the Woods" in 1992; and a Cartier Diamond Dagger for lifetime achievement in 1997. In 1996 Dexter received a Macavity Award for his short story "Evans Tries an O-Level". In 1980, he was elected a member of the by-invitation-only Detection Club.
In 2000 Dexter was appointed an Officer of the Order of the British Empire for services to literature. In 2001 he was awarded the Freedom of the City of Oxford. In September 2011, the University of Lincoln awarded Dexter an honorary Doctor of Letters degree.

</doc>
<doc id="5689" url="https://en.wikipedia.org/wiki?curid=5689" title="College">
College

College (Latin: "collegium") is an educational institution or a constituent part of one. Usage of the word "college" varies in English-speaking nations. A college may be a degree-awarding tertiary educational institution, a part of a collegiate university, or an institution offering vocational education.
In the United States and Italy, "College" formally refers to a constituent part of a university, but generally "College" and "university" are used interchangeably, whereas in Oceania and South Asia, "College" may refer to a secondary or high school, a college of further education, a training institution that awards trade qualifications, or a constituent part of a university (See this comparison of British and American English educational terminology for further information).
Etymology.
In ancient Rome a "collegium" was a club or society, a group of people living together under a common set of rules ("con-" = "together" + "leg-" = "law" or "lego" = "I choose" or "I read").
Overview.
Higher education.
Within higher education, the term can be used to refer to:
Secondary education.
In some national education systems, secondary schools may be called "colleges" or have "college" as part of their title.
In Australia the term "college" is applied to any private or independent (non-government) primary and, especially, secondary school as distinct from a state school. Melbourne Grammar School, Cranbrook School, Sydney and The King's School, Parramatta are considered colleges.
There has also been a recent trend to rename or create government secondary schools as "colleges". In the state of Victoria, some state high schools are referred to as "secondary colleges". Interestingly, the pre-eminent government secondary school for boys in Melbourne is still named Melbourne High School. In Western Australia, South Australia and the Northern Territory, "college" is used in the name of all state high schools built since the late 1990s, and also some older ones. In New South Wales, some high schools, especially multi-campus schools resulting from mergers, are known as "secondary colleges". In Queensland some newer schools which accept primary and high school students are styled "state college", but state schools offering only secondary education are called "State High School". In Tasmania and the Australian Capital Territory, "college" refers to the final two years of high school (years 11 and 12), and the institutions which provide this. In this context, "college" is a system independent of the other years of high school. Here, the expression is a shorter version of "matriculation college".
In a number of Canadian cities, many government-run secondary schools are called "collegiates" or "collegiate institutes" (C.I.), a complicated form of the word "college" which avoids the usual "post-secondary" connotation. This is because these secondary schools have traditionally focused on academic, rather than vocational, subjects and ability levels (for example, collegiates offered Latin while vocational schools offered technical courses). Some private secondary schools (such as Upper Canada College, Vancouver College) choose to use the word "college" in their names nevertheless. Some secondary schools elsewhere in the country, particularly ones within the separate school system, may also use the word "college" or "collegiate" in their names.
In New Zealand the word "college" normally refers to a secondary school for ages 13 to 17 and "college" appears as part of the name especially of private or integrated schools. "Colleges" most frequently appear in the North Island, whereas "high schools" are more common in the South Island.
In South Africa, some secondary schools, especially private schools on the English public school model, have "college" in their title. Thus no less than six of South Africa's Elite Seven high schools call themselves "college" and fit this description. A typical example of this category would be St John's College.
Private schools that specialize in improving children's marks through intensive focus on examination needs are informally called "cram-colleges".
In Sri Lanka the word "college" (known as "Vidyalaya" in "Sinhala") normally refers to a secondary school, which usually signifies above the 5th standard. During the British colonial period a limited number of exclusive secondary schools were established based on English public school model (Royal College Colombo, S. Thomas' College, Mount Lavinia, Trinity College, Kandy) these along with several Catholic schools (St. Joseph's College, Colombo, St Anthony's College) traditionally carry their name as colleges. Following the start of free education in 1931 large group of central colleges were established to educate the rural masses. Since Sri Lanka gained Independence in 1948, many schools that have been established have been named as "college".
Other.
As well as an educational institution, the term can also refer, following its etymology, to any formal group of colleagues set up under statute or regulation; often under a Royal Charter. Examples are an electoral college, the College of Arms, a college of canons, and the College of Cardinals. Other collegiate bodies include professional associations, particularly in medicine and allied professions. In the UK these include the Royal College of Nursing and the Royal College of Physicians. Examples in the United States include the American College of Physicians, the American College of Surgeons, and the American College of Dentists. An example in Australia is the Royal Australian College of General Practitioners.
Country by country.
Australia.
In Australia a college may be an institution of tertiary education that is smaller than a university, run independently or as part of a university. Following a reform in the 1980s many of the formerly independent colleges now belong to a larger universities.
Referring to parts of a university, there are "residential colleges" which provide residence for students, both undergraduate and postgraduate, called university colleges. These colleges often provide additional tutorial assistance, and some host theological study. Many colleges have strong traditions and rituals, so are a combination of dormitory style accommodation and fraternity or sorority culture.
Most technical and further education institutions (TAFEs), which offer certificate and diploma vocational courses, are styled "TAFE colleges" or "Colleges of TAFE".
Some senior high schools also refer to themselves as colleges.
Canada.
In Canada, the term "college" usually refers to a trades school, applied arts/science/technology/business/health school or community college. These are post-secondary institutions granting certificates, diplomas, associate's degree, and in some cases bachelor's degrees. In Quebec, the term is seldom used; the French acronym for public colleges, CEGEP ("Collège d'enseignement général et professionnel", "college of general and professional education"), is colloquially, yet incorrectly, used as an umbrella term to refer to all collegiate level institutions specific to the Quebec education system, a step that is required to continue onto university (unless one applies as a "mature" student, meaning 21 years of age or over, and out of the educational system for at least 2 years), or to learn a trade. In Ontario and Alberta, there are also institutions which are designated university colleges, as they only grant undergraduate degrees. This is to differentiate between universities, which have both undergraduate and graduate programs and those that do not. In contrast to usage in the United States, there is a strong distinction between "college" and "university" in Canada. In conversation, one specifically would say either "They are going to university" (i.e., studying for a three- or four-year degree at a university) or "They are going to college" (suggesting technical/career training or university transfer courses).
The Royal Military College of Canada, a full-fledged degree-granting university, does not follow the naming convention used by the rest of the country, nor does its sister school Royal Military College Saint-Jean or the now closed Royal Roads Military College.
The term "college" also applies to distinct entities within a university (usually referred to as "federated colleges" or "affiliated colleges"), to the residential colleges in the United Kingdom. These colleges act independently, but in affiliation or federation with the university that actually grants the degrees. For example, Trinity College was once an independent institution, but later became federated with the University of Toronto, and is now one of its residential colleges (though it remains a degree-granting institution through its Faculty of Divinity). In the case of Memorial University of Newfoundland, located in St. John's, the Corner Brook campus is called Sir Wilfred Grenfell College. Occasionally, "college" refers to a subject specific faculty within a university that, while distinct, are neither "federated" nor "affiliated"—College of Education, College of Medicine, College of Dentistry, College of Biological Science among others.
There are also universities referred to as art colleges, empowered to grant academic degrees of BFA, Bdes, MFA, Mdes and sometimes collaborative PhD degrees. Some of them have "university" in their name (NSCAD University, OCAD University and Emily Carr University of Art and Design)and others do not.
Online and distance education (E-learning) use "college" in the name in the British sense, for example : Canada Capstone College.
One use of the term "college" in the American sense is by the Canadian Football League (CFL), which calls its annual entry draft the Canadian College Draft. The draft is restricted to players who qualify under CFL rules as "non-imports"—essentially, players who were raised in Canada (see the main CFL article for a more detailed definition). Because a player's designation as "non-import" is not affected by where he plays post-secondary football, the category includes former players at U.S. college football programs ("universities" in the Canadian sense) as well as CIS football programs at Canadian universities.
Chile.
In Chile, the term "college" is usually used in the name of some bilingual schools, like Santiago College, Saint George's College etc.
Georgia.
International Association of "Tourists and Travelers" College. International association "tourists and travelers" is a non-commercial, non political and non industrial organization, which is created to develop tourism in Georgia.
Greece.
The Centers of Postsecondary Education (abbreviated KEME in Greek, also can be referred to as "Colleges"), belong to the Greek Post-secondary Education and are principally private and have some link with foreign (mainly from the EU, but also from the US) higher education institutions or accreditation organizations. The word 'college' is also used to describe some non-tertiary schools.
Hong Kong.
In Hong Kong, the term 'college' is used by tertiary institutions as either part of their names or to refer to a constituent part of the university, such as the colleges in the collegiate The Chinese University of Hong Kong; or to a residence hall of a university, such as St. John's College, University of Hong Kong. Many older secondary schools have the term 'college' as part of their names.
India.
The modern system of education was heavily influenced by the British starting in 1835.
In India, the term "college" is commonly reserved for institutions that offer degrees at year 12 (""Junior College"", similar to American "high schools"), and those that offer the bachelor's degree. Generally, colleges are located in different parts of a state and all of them are affiliated to a regional university. The colleges offer programmes under that university. Examinations are conducted by the university at the same time for all colleges under its affiliation. There are several hundred universities and each university has affiliated colleges.
The first liberal arts and sciences college in India was C. M. S. College Kottayam, Kerala, established in 1817, and the Presidency College, Kolkata, also 1817, initially known as Hindu College. The first college for the study of Christian theology and ecumenical enquiry was Serampore College (1818). The first Missionary institution to impart Western style education in India was the Scottish Church College, Calcutta (1830). The first commerce and economics college in India was Sydenham College, Mumbai (1913).
Ireland.
In Ireland the term "college" is normally used to describe an institution of tertiary education. University students often say they attend "college" rather than "university". Until 1989, no university provided teaching or research directly; they were formally offered by a constituent college of the university.
There are number of secondary education institutions that traditionally used the word "college" in their names: these are either older, private schools (such as Belvedere College, Gonzaga College and St. Michael's College) or what were formerly a particular kind of secondary school. These secondary schools, formerly known as "technical colleges," were renamed "community colleges," but remain secondary schools.
The country's only ancient university is the University of Dublin. Created during the reign of Elizabeth I, it is modelled on the collegiate universities of Cambridge and Oxford. However, only one constituent college was ever founded, hence the curious position of Trinity College, Dublin today; although both are usually considered one and the same, the University and College are completely distinct corporate entities with separate and parallel governing structures.
Among more modern foundations, the National University of Ireland, founded in 1908, consisted of constituent colleges and recognised colleges until 1997. The former are now referred to as constituent universities – institutions that are essentially universities in their own right. The National University can trace its existence back to 1850 and the creation of the Queen's University of Ireland and the creation of the Catholic University of Ireland in 1854. From 1880, the degree awarding roles of these two universities was taken over by the Royal University of Ireland, which remained until the creation of the National University in 1908 and Queen's University Belfast.
The state's two new universities Dublin City University and University of Limerick were initially National Institute for Higher Education institutions. These institutions offered university level academic degrees and research from the start of their existence and were awarded university status in 1989 in recognition of this.
Third level technical education in the state has been carried out in the Institutes of Technology, which were established from the 1970s as Regional Technical Colleges. These institutions have "delegated authority" which entitles them to give degrees and diplomas from the Higher Education and Training Awards Council in their own name.
A number of Private Colleges exist such as DBS, providing undergraduate and postgraduate courses validated by HETAC and in some cases by other Universities.
Other types of college include Colleges of Education, such as the Church of Ireland College of Education. These are specialist institutions, often linked to a university, which provide both undergraduate and postgraduate academic degrees for people who want to train as teachers.
A number of state funded further education colleges exist - which offer vocational education and training in a range of areas from business studies, I.C.T to sports injury therapy. These courses are usually 1, 2 or less often 3 three years in duration and are validated by FETAC at levels 5 or 6 or for the BTEC Higher National Diploma award - validated by Edexcel which is a level 6/7 qualification. There are numerous private colleges (particularly in Dublin and Limerick) which offer both further and higher education qualifications. These degrees and diplomas are often certified by foreign universities/international awarding bodies and are aligned to the National Framework of Qualifications at level 6, 7 and 8.
Israel.
In Israel, any non university higher-learning facility is called a college. Institutions accredited by the Council for Higher Education in Israel (CHE) to confer a bachelor's degree are called "Academic Colleges." These colleges (at least 4 for 2012) may also offer master's degrees and act as Research facilities. There are also over twenty teacher training colleges or seminaries, most of which may award only a Bachelor of Education (B.Ed.) degree.
Macau.
Following the Portuguese usage, the term "college" ("colégio") in Macau has traditionally been used in the names for private (and non-governmental) pre-university educational institutions, which correspond to form one to form six levels. Such schools are usually run by the Roman Catholic church or missionaries in Macau. Examples include Chan Sui Ki Perpetual Help College, Yuet Wah College, and Sacred Heart Canossian College.
New Zealand.
The constituent colleges of the former University of New Zealand (such as Canterbury University College) have become independent universities. Some halls of residence associated with New Zealand universities retain the name of "college", particularly at the University of Otago (which although brought under the umbrella of the University of New Zealand, already possessed university status and degree awarding powers). The institutions formerly known as "Teacher-training colleges" now style themselves "College of education".
Some universities, such as the University of Canterbury, have divided their University into constituent administrative "Colleges" – the College of Arts containing departments that teach Arts, Humanities and Social Sciences, College of Science containing Science departments, and so on. This is largely modelled on the Cambridge model, discussed above.
Like the United Kingdom some professional bodies in New Zealand style themselves as "colleges", for example, the Royal Australasian College of Surgeons, the Royal Australasian College of Physicians.
Secondary school is often referred to as college and the term is used interchangeably with high school. This is reflected in the names of many secondary schools such as Rangitoto College, New Zealand's largest secondary.
Philippines.
In the Philippines, colleges usually refer to institutions of learning that grant degrees but whose scholastic fields are not as diverse as that of a university (University of Santo Tomas, University of the Philippines, Ateneo de Manila University, and De La Salle University), such as the San Beda College which specializes in law and the Central Colleges of the Philippines which specializes in engineering, or to component units within universities that do not grant degrees but rather facilitate the instruction of a particular field, such as a College of Science and College of Engineering, among many other colleges of the University of the Philippines.
A state college may not have the word "college" on its name, but may have several component colleges, or departments. Thus, the Eulogio Amang Rodriguez Institute of Science and Technology is a state college by classification.
Usually, the term "college" is also thought of as a hierarchical demarcation between the term "university", and quite a number of colleges seek to be recognized as universities as a sign of improvement in academic standards (Colegio de San Juan de Letran, San Beda College), and increase in the diversity of the offered degree programs (called "courses"). For private colleges, this may be done through a survey and evaluation by the Commission on Higher Education and accrediting organizations, as was the case of Urios College which is now the Fr. Saturnino Urios University. For state colleges, it is usually done by a legislation by the Congress or Senate. In common usage, "going to college" simply means attending school for an undergraduate degree, whether it's from an institution recognized as a college or a university.
When it comes to referring to the level of education, "college" is the term more used to be synonymous to tertiary or higher education. A student who is or has studied her undergraduate degree at either an institution with "college" or "university" in its name is considered to be going to or have gone to "college".
Portugal.
Presently in Portugal, the term "colégio" (college) is normally used as a generic reference to a private (non-government) school that provides from basic to secondary education. Many of the private schools include the term "colégio" in their name. Some special public schools - usually of the boarding school type - also include the term in their name, with a notable example being the "Colégio Militar" (Military College). The term "colégio interno" (literally "internal college") is used specifically as a generic reference to a boarding school.
Until the 19th century, a "colégio" was usually a secondary or pre-university school, of public or religious nature, where the students usually lived together. A model for these colleges was the Royal College of Arts and Humanities, founded in Coimbra by King John III of Portugal in 1542.
Singapore.
The term "college" in Singapore is generally only used for pre-university educational institutions called "Junior Colleges", which provide the final two years of secondary education (equivalent to sixth form in British terms or grades 11–12 in the American system). Since 1 January 2005, the term also refers to the three campuses of the Institute of Technical Education with the introduction of the "collegiate system", in which the three institutions are called ITE College East, ITE College Central, and ITE College West respectively.
The term "university" is used to describe higher-education institutions offering locally conferred degrees. Institutions offering diplomas are called "polytechnics", while other institutions are often referred to as "institutes" and so forth.
South Africa.
Although the term "college" is hardly used in any context at any university in South Africa, some non-university tertiary institutions call themselves colleges. These include teacher training colleges, business colleges and wildlife management colleges. See: List of universities in South Africa#Private colleges and universities; List of post secondary institutions in South Africa.
Sri Lanka.
There are several professional and vocational institutions that offer post-secondary education without granting degrees that are referred to as "colleges". This includes the Sri Lanka Law College, the many Technical Colleges and Teaching Colleges.
United Kingdom.
Sixth Form.
A Sixth form college or College of further education is an educational institution in England, Wales, Northern Ireland, Belize, The Caribbean, Malta, Norway, Brunei Southern Africa, among others, where students aged 16 to 19 typically study for advanced school-level qualifications, such as A-levels, BTEC and the International Baccalaureate Diploma, or school-level qualifications such as GCSEs. In Singapore and India, this is known as a junior college. The municipal government of the city of Paris uses the phrase "sixth form college" as the English name for a lycée.
In the United Kingdom, "college" can refer to either sixth form in the context of secondary education, or a constituent part of a university in the context of higher education.
Higher education.
In higher education a college is usually part of a university; such colleges do not award degrees. Universities with constituent colleges are collegiate universities. A college may also be a grouping of faculties or departments, notably in the University of Edinburgh, the University of Salford, the University of Birmingham and the University of Leicester.
In the University of Oxford, University of Cambridge, and University of the Arts London (and formerly in the University of Wales), colleges provide accommodation, tuition and other facilities to students of the university: the university conducts examinations and grants degrees. However the colleges of the University of London are now "de facto" universities in their own right.
In the other collegiate universities, including the University of Lancaster, University of York, University of Kent, University of St Andrews and University of Durham, the colleges only provide accommodation and pastoral care.
A university college is an independent institution which prepares students to sit as external candidates at other universities or has the authority to run courses that lead to the degrees of those universities. It may also be an independent higher education institution with the power to award degrees, but does not have university status, although it is usually working towards it.
Historically, some universities originated as university colleges. For example, the University of Reading was an external college of the University of Oxford, as University College, Reading. The University is now faculty based.
United States.
In the United States, there are over 7,021 colleges and universities. A "college" in the US formally denotes a constituent part of a university, but in popular usage, the word "college" is the generic term for any post-secondary undergraduate education. Americans "go to college" after high school, regardless of whether the specific institution is formally a college or a university. Some students choose to dual-enroll, by taking college classes while still in high school. The word and its derivatives are the standard terms used to describe the institutions and experiences associated with American post-secondary undergraduate education.Students must pay for college before taking classes. Some borrow the money via loans, and some students fund their educations with cash, scholarships, or grants, or some combination of any two or more of those payment methods. In 2011, the state or federal government subsidized $8,000 to $100,000 for each undergraduate degree. For state-owned schools (called "public" universities), the subsidy was given to the college, with the student benefiting from lower tuition.
Colleges vary in terms of size, degree, and length of stay. Two-year colleges, also known as junior or community colleges, usually offer an associate's degree, and four-year colleges usually offer a bachelor's degree. Often, these are entirely undergraduate institutions, although some have graduate school programs.
Four-year institutions in the U.S. that emphasize a liberal arts curriculum are known as liberal arts colleges. Until the 20th century, liberal arts, law, medicine, theology, and divinity were about the only form of higher education available in the United States. These schools have traditionally emphasized instruction at the undergraduate level, although advanced research may still occur at these institutions.While there is no national standard in the United States, the term "university" primarily designates institutions that provide undergraduate and graduate education. A university typically has as its core and its largest internal division an undergraduate college teaching a liberal arts curriculum, also culminating in a bachelor's degree. What often distinguishes a university is having, in addition, one or more graduate schools engaged in both teaching graduate classes and in research. Often these would be called a School of Law or School of Medicine, (but may also be called a college of law, or a faculty of law). An exception is Vincennes University, Indiana, which is styled and chartered as a "university" even though almost all of its academic programs lead only to two-year associate degrees. Some institutions, such as Dartmouth College and The College of William & Mary, have retained the term "college" in their names for historical reasons. In one unique case, Boston College and Boston University, both located in Boston, Massachusetts, are completely separate institutions.Usage of the terms varies among the states. In 1996 for example, Georgia changed all of its four-year institutions previously designated as colleges to universities, and all of its vocational technology schools to technical colleges.
The terms "university" and "college" do not exhaust all possible titles for an American institution of higher education. Other options include "institute" (Massachusetts Institute of Technology), "academy" (United States Military Academy), "union" (Cooper Union), "conservatory" (New England Conservatory), and "school" (Juilliard School). In colloquial use, they are still referred to as "college" when referring to their undergraduate studies.
The term "college" is also, as in the United Kingdom, used for a constituent semi-autonomous part of a larger university but generally organized on academic rather than residential lines. For example, at many institutions, the undergraduate portion of the university can be briefly referred to as the college (such as The College of the University of Chicago, Harvard College at Harvard, or Columbia College at Columbia) while at others, such as the University of California, Berkeley, each of the faculties may be called a "college" (the "college of engineering", the "college of nursing", and so forth). There exist other variants for historical reasons; for example, Duke University, which was called Trinity College until the 1920s, still calls its main undergraduate subdivision Trinity College of Arts and Sciences. Some American universities, such as Princeton, Rice, and Yale do have residential colleges along the lines of Oxford or Cambridge, but the name was clearly adopted in homage to the British system. Unlike the Oxbridge colleges, these residential colleges are not autonomous legal entities nor are they typically much involved in education itself, being primarily concerned with room, board, and social life. At the University of Michigan, University of California, San Diego and the University of California, Santa Cruz, however, each of the residential colleges does teach its own core writing courses and has its own distinctive set of graduation requirements.
The founders of the first institutions of higher education in the United States were graduates of the University of Oxford and the University of Cambridge. The small institutions they founded would not have seemed to them like universities – they were tiny and did not offer the higher degrees in medicine and theology. Furthermore, they were not composed of several small colleges. Instead, the new institutions felt like the Oxford and Cambridge colleges they were used to – small communities, housing and feeding their students, with instruction from residential tutors (as in the United Kingdom, described above). When the first students graduated, these "colleges" assumed the right to confer degrees upon them, usually with authority—for example, The College of William & Mary has a Royal Charter from the British monarchy allowing it to confer degrees while Dartmouth College has a charter permitting it to award degrees "as are usually granted in either of the universities, or any other college in our realm of Great Britain."
The leaders of Harvard College (which granted America's first degrees in 1642) might have thought of their college as the first of many residential colleges that would grow up into a New Cambridge university. However, over time, few new colleges were founded there, and Harvard grew and added higher faculties. Eventually, it changed its title to university, but the term "college" had stuck and "colleges" have arisen across the United States.
In U.S. usage, the word "college" embodies not only a particular type of school, but has historically been used to refer to the general concept of higher education when it is not necessary to specify a school, as in "going to college" or "college savings accounts" offered by banks.
In a survey of more than 2,000 college students in 33 states and 156 different campuses, the U.S. Public Interest Research Group found the average student spends as much as $1,200 each year on textbooks and supplies alone. By comparison, the group says that's the equivalent of 39 percent of tuition and fees at a community college, and 14 percent of tuition and fees at a four-year public university.
In addition to private colleges and universities, the U.S. also has a system of government funded, public universities. Many were founded under the Morrill Land-Grant Colleges Act of 1862. When the Morrill Act was established, the original colleges on the east coast, primarily those of the Ivy League and several religious based colleges, were the only form of higher education available, and were often confined only to the children of the elite. A movement had arisen to bring a form of more practical higher education to the masses, as "...many politicians and educators wanted to make it possible for all young Americans to receive some sort of advanced education." The Morrill Act "...made it possible for the new western states to establish colleges for the citizens." Its goal was to make higher education more easily accessible to the citizenry of the country, specifically to improve agricultural systems by providing training and scholarship in the production and sales of agricultural products, and to provide formal education in "...agriculture, home economics, mechanical arts, and other professions that seemed practical at the time."
The act was eventually extended to allow all states that had remained with the Union during the American Civil War, and eventually all states, to establish such institutions. Most of the colleges established under the Morrill Act have since become full universities, and some are among the elite of the world.
Selection of a four-year college as compared to a two-year junior college, even by marginal students such as those with a C+ grade average in high school and SAT scores in the mid 800s, increases the probability of graduation and confers substantial economic and social benefits.
Zimbabwe.
The term college is mainly used by private or independent secondary schools with Advanced Level (Upper 6th formers) and also Polytechnic Colleges which confer diplomas only. A student can complete secondary education (International General Certificate of Secondary Education, IGCSE) at 16 years and proceed straight to a poly-technical college or they can proceed to Advanced level (16 to 19 years) and obtain a General Certificate of Education (GCE) certificate which enables them to enrol at a University provided they have good grades alternatively with lower grades the GCE certificate holders will have an added advantage over their GCSE counterparts if they choose to enrol at a Poly-technical College. Some schools in Zimbabwe choose to offer the International Baccalaureate studies as an alternative to the IGCSE and GCE.

</doc>
<doc id="5690" url="https://en.wikipedia.org/wiki?curid=5690" title="Chalmers University of Technology">
Chalmers University of Technology

Chalmers University of Technology (, often shortened to Chalmers) is a Swedish university located in Gothenburg that focuses on research and education in technology, natural science, architecture, maritime and other management areas.
History.
The University was founded in 1829 following a donation by William Chalmers, a director of the Swedish East India Company. He donated part of his fortune for the establishment of an "industrial school". Chalmers was run as a private institution until 1937, when the institute became a state-owned university. In 1994, the school was incorporated as an
aktiebolag under the control of the Swedish Government, the faculty and the Student Union. Chalmers is one of only three universities in Sweden which are named after a person, the other two being Karolinska Institutet and Linnaeus University.
Departments.
On 1 January 2005, the old schools were replaced by new departments:
As of 1 January 2016, the former departments of Applied Physics and Fundamental Physics have been joined to form the Department of Physics.
In addition to these, Chalmers is home to six national competence centres in key fields like Mathematical Modelling, Environmental Science and Vehicle Safety (SAFER).
Students.
Approximately 40% of Sweden's graduate engineers and architects are educated at Chalmers. Each year, around 250 post graduate degrees are awarded as well as 850 graduate degrees. About 1,000 post-graduate students attend programmes at the university and many students are taking Master of Science engineering programmes and the Master of Architecture programme. From 2007, all Master's programmes are taught in English for both national and international students. This was a result of the adaptation to the Bologna process that started in 2004 at Chalmers (as the first technical university in Sweden).
Currently, about 10% of all students at Chalmers come from countries outside Sweden to enroll in a Master's or PhD program.
List of International Masters Programmes at Chalmers<br>
Previous List of International Masters Programmes at Chalmers (login now required)
Around 2,700 students also attend Bachelor of Science engineering programmes, merchant marine and other undergraduate courses at Campus Lindholmen. Chalmers also shares some students with Gothenburg University in the joint IT University project. The IT University focuses exclusively on information technology and offers Bachelor and Master programmes with degrees issued from either Chalmers or Gothenburg University, depending on the programme.
Chalmers confers honorary doctoral degrees to people outside the university who have shown great merit in their research or in society.
Organization.
Chalmers is an aktiebolag with 100 shares à 1,000 SEK, all of which are owned by the Chalmers University of Technology Foundation, a private foundation, which appoints the university board and the president. The foundation has its members appointed by the Swedish government (4 to 8 seats), the departments appoints one member, the student union appoints one member and the president automatically gains one chair. Each department is led by a department head, usually a member of the faculty of that department. The faculty senate represents members of the faculty when decisions are taken.
Campuses.
In 1937, the school moved from the city center to the new Gibraltar Campus, named after the mansion which owned the grounds, where it is now located. The Lindholmen College Campus was created in the early 1990s and is located on the island of Hisingen. Campus Johanneberg and Campus Lindholmen, as they are now called, are connected by bus line number 16, but there have been numerous complaints that the campuses are too isolated from each other.
Societies and traditions.
Traditions include the graduation ceremony and the Cortège procession, an annual public event.
Ties and partnerships.
Chalmers has partnerships with major industries mostly in the Gothenburg region such as Ericsson, Volvo, and SKF.
The University has general exchange agreements with many European and U.S. universities and maintains a special exchange program agreement with National Chiao Tung University (NCTU) in Taiwan where the exchange students from the two universities maintains offices for, among other things, helping local students with applying and preparing for an exchange year as well as acting as representatives. It contributes also to the Top Industrial Managers for Europe (TIME) network.
A close collaboration between the Department of Computer Science and Engineering at Chalmers and ICVR at ETH Zurich is being established. As of 2014, Chalmers University of Technology is a member of the IDEA League network.
Rankings.
In the 2011 International Professional Ranking of Higher Education Institutions, which is established on the basis of the number of alumni holding a post of Chief Executive Officer (CEO) or equivalent in one of the Fortune Global 500 companies, Chalmers University of Technology ranked 38th in the world, ranking 1st in Sweden and 15th in Europe.
In the latest QS World University Rankings (2015), the university was ranked 132nd in the world (overall). In the latest Times Higher Education World University Rankings 2015/2016, Chalmers ranked between 201 and 250 of all global universities. In the latest Academic Ranking of World Universities (2015), the university was ranked between places 301 - 400 of all universities in the world.
Presidents.
Although the official Swedish title for the head is "rektor", the university now uses "President" as the English translation.

</doc>
<doc id="5691" url="https://en.wikipedia.org/wiki?curid=5691" title="Codex">
Codex

A codex (from the Latin "caudex" for "trunk of a tree" or "block of wood", "book"; plural "codices") is a book constructed of a number of sheets of paper, vellum, papyrus, or similar materials, with hand-written content. The book is usually bound by stacking the pages and fixing one edge, and using a cover thicker than the sheets. Some codices are continuously folded like a concertina. The alternative to paged codex format for a long document is the continuous scroll. Examples of folded codices include the Maya codices. Sometimes people use the term for a book-style format, including modern printed books but excluding folded books.
The Romans developed the form from wooden writing tablets. The codex's gradual replacement of the scroll—the dominant book form in the ancient world—has been called the most important advance in book making before the invention of printing. The codex transformed the shape of the book itself, and offered a form that lasted for centuries. The spread of the codex is often associated with the rise of Christianity, which adopted the format for use with the Bible early on. First described by the 1st-century AD Roman poet Martial, who praised its convenient use, the codex achieved numerical parity with the scroll around AD 300, and had completely replaced it throughout the now Christianised Greco-Roman world by the 6th century.
Origins.
The codex provides considerable advantages over other book formats:
The change from rolls to codices roughly coincides with the transition from papyrus to parchment as the preferred writing material, but the two developments are unconnected. In fact, any combination of codices and scrolls with papyrus and parchment is technically feasible and common in the historical record.
The codex began to replace the scroll almost as soon as it was invented. In Egypt, by the fifth century, the codex outnumbered the scroll by ten to one based on surviving examples. By the sixth century, the scroll had almost vanished as a medium for literature.
Technically, even modern paperbacks are codices, but publishers and scholars reserve the term for manuscript (hand-written) books produced from Late antiquity until the Middle Ages. The scholarly study of these manuscripts from the point of view of the bookbinding craft is called codicology. The study of ancient documents in general is called paleography.
History.
The Romans used precursors made of reusable wax-covered tablets of wood for taking notes and other informal writings. Two ancient polyptychs, a "pentatych" and "octotych", excavated at Herculaneum used a unique connecting system that presages later sewing on of thongs or cords. Julius Caesar may have been the first Roman to reduce scrolls to bound pages in the form of a note-book, possibly even as a papyrus codex. At the turn of the 1st century AD, a kind of folded parchment notebook called "pugillares membranei" in Latin became commonly used for writing in the Roman Empire. This term was used by the Classical Latin poet, Martial. Martial used the term for gifts of literature that Romans exchanged during the festival of Saturnalia. According to T.C. Skeat, “…in at least three cases and probably in all, in the form of codices," and he theorized that this form of notebook was invented in Rome and then “…must have spread rapidly to the Near East…” In his discussion of one of the earliest parchment codices to survive from Oxyrhynchus in Egypt, Eric Turner seems to challenge Skeat’s notion when stating, “…its mere existence is evidence that this book form had a prehistory”, and that “early experiments with this book form may well have taken place outside of Egypt.” Early codices of parchment or papyrus appear to have been widely used as personal notebooks, for instance in recording copies of letters sent (Cicero "Fam." 9.26.1). The parchment notebook pages were commonly washed or scraped for re-use (called a palimpsest) and consequently, writings in a codex were often considered informal and impermanent.
As early as the early 2nd century, there is evidence that a codex—usually of papyrus—was the preferred format among Christians. In the library of the Villa of the Papyri, Herculaneum (buried in AD 79), all the texts (of Greek literature) are scrolls (see Herculaneum papyri). However, in the Nag Hammadi library, hidden about AD 390, all texts (Gnostic Christian) are codices. Despite this comparison, a fragment of a non-Christian parchment codex of Demosthenes' "De Falsa Legatione" from Oxyrhynchus in Egypt demonstrates that the surviving evidence is insufficient to conclude whether Christians played a major or central role in the development of early codices—or if they simply adopted the format to distinguish themselves from Jews. 
The earliest surviving fragments from codices come from Egypt, and are variously dated (always tentatively) towards the end of the 1st century or in the first half of the 2nd. This group includes the Rylands Library Papyrus P52, containing part of St John's Gospel, and perhaps dating from between 125 and 160.
In Western culture, the codex gradually replaced the scroll. Between the 4th century, when the codex gained wide acceptance, and the Carolingian Renaissance in the 8th century, many works that were not converted from scroll to codex were lost. The codex improved on the scroll in several ways. It could be opened flat at any page for easier reading, pages could be written on both front and back (recto and verso), and the protection of durable covers made it more compact and easier to transport.
The ancients stored codices with spines facing inward, and not always vertically. The spine could be used for the incipit, before the concept of a proper title developed in medieval times. Though most early codices were made of papyrus, papyrus was fragile and supplies from Egypt, the only place where papyrus grew and was made into paper, became scanty. The more durable parchment and vellum gained favor, despite the cost.
The codices of pre-Columbian Mesoamerica had the same form as the European codex, but were instead made with long folded strips of either fig bark (amatl) or plant fibers, often with a layer of whitewash applied before writing. New World codices were written as late as the 16th century (see Maya codices and Aztec codices). Those written before the Spanish conquests seem all to have been single long sheets folded concertina-style, sometimes written on both sides of the local amatl paper.
In East Asia, the scroll remained standard for far longer than in the Mediterranean world. There were intermediate stages, such as scrolls folded concertina-style and pasted together at the back and books that were printed only on one side of the paper. 
Judaism still retains the Torah scroll, at least for ceremonial use.
From scrolls to codex.
Among the experiments of earlier centuries, scrolls were sometimes unrolled horizontally, as a succession of columns. (The Dead Sea Scrolls are a famous example of this format.) This made it possible to fold the scroll as an accordion. The next step was then to cut the folios, sew and glue them at their centers, making it easier to use the papyrus or vellum recto-verso as with a modern book. Traditional bookbinders would call one of these assembled, trimmed and bound folios a "codex" to differentiate it from the "case," which we now know as "hard cover". Binding the codex was clearly a different procedure from binding the case.
Preparing a codex.
The first stage in creating a codex is to prepare the animal skin. The skin is washed with water and lime, but not together, and it has to soak in the lime for a couple of days. The hair is removed and the skin is dried by attaching it to a frame called a herse. The parchment maker attaches the skin at points around the circumference. The skin attaches to the herse by cords. To prevent tearing, the maker wraps the area of the skin the cord attaches to around a pebble called a pippin. After completing that, the maker uses a crescent shaped knife called a "lunarium" or "lunellum" to clean any surviving hairs. Once the skin completely dries, the maker gives it a deep clean and processes it into sheets. The number of sheets from a piece of skin depends on the size of the skin and the final product dimensions. For example, the average calfskin can provide three and half medium sheets of writing material. This can be doubled when folded into two conjoint leaves, also known as a "bifolium". Historians have found evidence of manuscripts where the scribe wrote down the medieval instructions now followed by modern membrane makers. Defects can often be found in the membrane, whether from the original animal, human error during the preparation period, or from when the animal was killed. Defects can also appear during the writing process. Unless it is kept in perfect condition, defects can appear later in the manuscript’s life as well.
Preparation of the pages for writing.
First the membrane must be prepared. The first step is to set up the quires. The quire is a group of several sheets put together. Raymond Clemens and Timothy Graham point out, in "Introduction to Manuscript Studies", that “the quire was the scribe’s basic writing unit throughout the Middle Ages”. They note “Pricking is the process of making holes in a sheet of parchment (or membrane) in preparation of it ruling. The lines were then made by ruling between the prick marks...The process of entering ruled lines on the page to serve as a guide for entering text. Most manuscripts were ruled with horizontal lines that served as the baselines on which the text was entered and with vertical bounding lines that marked the boundaries of the columns.”
Forming the quire.
From the Carolingian period and all the way up to the Middle Ages, different styles of folding the quire came about. For example, in mainland Europe throughout the Middle Ages, the quire was put into a system in which each side folded on to the same style. The hair side met the hair side and the flesh side to the flesh side. This was not the same style used in the British Isles, where the membrane was folded so that it turned out an eight-leaf quire, with single leaves in the third and sixth positions. The next stage was tacking the quire. Tacking is when the scribe would hold together the leaves in quire with thread. Once threaded together, the scribe would then sew a line of parchment up the “spine” of the manuscript, as to protect the tacking.

</doc>
<doc id="5692" url="https://en.wikipedia.org/wiki?curid=5692" title="Calf">
Calf

A calf (plural, calves) is the young of domestic cattle. Calves are reared to become adult cattle, or are slaughtered for their meat, called veal, and for their calfskin. 
The term "calf" is also used for some other species. See "Other animals" below.
Terminology.
"Calf" is the term used from birth to weaning, when it becomes known as a "weaner" or "weaner calf", though in some areas the term "calf" may be used until the animal is a yearling. The birth of a calf is known as "calving". A calf that has lost its mother is an orphan calf, also known as a "poddy" or "poddy-calf" in British English. "Bobby calves" are young calves which are to be slaughtered for human consumption. A "vealer" is a fat calf weighing less than about which is at about eight to nine months of age. A young female calf from birth until she has had a calf of her own is called a "heifer"
(). In the American Old West, a motherless or small, runty calf was sometimes referred to as a "dogie," (pronounced with a long "o") though in the classic traditional folk song, "Git Along, Little Dogies", the "dogies" in question meant cattle strong enough to be herded from Texas to Wyoming, including weaners, yearling steers and other young, non-orphaned animals.
The term "calf" is also used for some other species. See "Other animals" below.
Early development.
Calves may be produced by natural means, or by artificial breeding using artificial insemination or embryo transfer.
Calves are born after a gestation of nine months. They usually stand within a few minutes of calving, and suckle within an hour. However, for the first few days they are not easily able to keep up with the rest of the herd, so young calves are often left hidden by their mothers, who visit them several times a day to suckle them. By a week old the calf is able to follow the mother all the time.
Some calves are ear tagged soon after birth, especially those that are stud cattle in order to correctly identify their dams (mothers), or in areas (such as the EU) where tagging is a legal requirement for cattle. A calf must have the very best of everything until it is at least eight months old if it is to reach its maximum potential. Typically when the calves are about two months old they are branded, ear marked, castrated and vaccinated.
Calf rearing systems.
The "single suckler" system of rearing calves is similar to that occurring naturally in wild cattle, where each calf is suckled by its own mother until it is weaned at about nine months old. This system is commonly used for rearing beef cattle throughout the world.
Cows kept on poor forage (as is typical in subsistence farming) produce a limited amount of milk. A calf left with such a mother all the time can easily drink all the milk, leaving none for human consumption. For dairy production under such circumstances, the calf's access to the cow must be limited, for example by penning the calf and bringing the mother to it once a day after partly milking her. The small amount of milk available for the calf under such systems may mean that it takes a longer time to rear, and in subsistence farming it is therefore common for cows to calve only in alternate years.
In more intensive dairy farming, cows can easily be bred and fed to produce far more milk than one calf can drink. In the "multi-suckler" system, several calves are fostered onto one cow in addition to her own, and these calves' mothers can then be used wholly for milk production. More commonly, calves of dairy cows are fed formula milk from a bottle or bucket from soon after birth.
Purebred female calves of dairy cows are reared as replacement dairy cows. Most purebred dairy calves are produced by artificial insemination (AI). By this method each bull can serve very many cows, so only a very few of the purebred dairy male calves are needed to provide bulls for breeding. The remainder of the male calves may be reared for beef or veal; however, some extreme dairy breeds carry so little muscle that rearing the purebred male calves may be uneconomic, and in this case they are often killed soon after birth and disposed of. Only a proportion of purebred heifers are needed to provide replacement cows, so often some of the cows in dairy herds are put to a beef bull to produce crossbred calves suitable for rearing as beef.
Veal calves may be reared entirely on milk formula and killed at about 18 or 20 weeks as "white" veal, or fed on grain and hay and killed at 22 to 35 weeks to produce red or pink veal.
Growth.
A commercial steer or bull calf is expected to put on about per month. A nine-month-old steer or bull is therefore expected to weigh about . Heifers will weigh at least at eight months of age.
Calves are usually weaned at about eight to nine months of age, but depending on the season and condition of the dam, they might be weaned earlier. They may be paddock weaned, often next to their mothers, or weaned in stockyards. The latter system is preferred by some as it accustoms the weaners to the presence of people and they are trained to take feed other than grass. Small numbers may also be weaned with their dams with the use of weaning nose rings or nosebands which results in the mothers rejecting the calves' attempts to suckle. Many calves are also weaned when they are taken to the large weaner auction sales that are conducted in the south eastern states of Australia. Victoria and New South Wales have yardings of up to 8,000 weaners (calves) for auction sale in one day. The best of these weaners may go to the butchers. Others will be purchased by re-stockers to grow out and fatten on grass or as potential breeders. In the United States these weaners may be known as "feeders" and would be placed directly into feedlots.
At about 12 months old a beef heifer reaches puberty if she is well grown.
Diseases.
Calves suffer from few congenital abnormalities but the Akabane virus is widely distributed in temperate to tropical regions of the world. The virus is a teratogenic pathogen which causes abortions, stillbirths, premature births and congenital abnormalities, but occurs only during some years.
Uses.
Calf meat for human consumption is called veal; also eaten are calf's brains and calf liver. The hide is used to make calfskin, or tanned into leather and called calf leather, or sometimes in the US "novillo", the Spanish term. The fourth compartment of the stomach of slaughtered milk-fed calves is the source of rennet. The intestine is used to make Goldbeater's skin, and is the source of Calf Intestinal Alkaline Phosphatase (CIP).
Dairy cows can only produce milk after having calved, and so every dairy cow is allowed to produce one calf each year throughout her productive life. On average one of these calves will become a replacement dairy cow, and some of the rest may be reared for beef or veal; however some are effectively produced solely to allow the cow to produce milk.
Other animals.
In English the term "calf" is used by extension for the young of various other large species of mammal. In addition to other cattle (such as bison, yak and water buffalo), these include the young of camels, dolphins, elephants, giraffes, hippopotamuses, larger deer (such as moose, elk (wapiti) and red deer), rhinoceroses, porpoises, whales, walruses and larger seals. But common domestic species tend to have their own names, such as foal and lamb.

</doc>
<doc id="5693" url="https://en.wikipedia.org/wiki?curid=5693" title="Claude Shannon">
Claude Shannon

Claude Elwood Shannon (April 30, 1916 – February 24, 2001) was an American mathematician, electrical engineer, and cryptographer known as "the father of information theory".
Shannon is noted for having founded information theory with a landmark paper that he published in 1948. He is perhaps equally well known for founding digital circuit design theory in 1937, when, as a 21-year-old master's degree student at the Massachusetts Institute of Technology (MIT), he wrote his thesis demonstrating that electrical applications of Boolean algebra could construct any logical, numerical relationship. Shannon contributed to the field of cryptanalysis for national defense during World War II, including his basic work on codebreaking and secure telecommunications.
Biography.
Shannon was born in Petoskey, Michigan and grew up in Gaylord, Michigan. His father, Claude, Sr. (1862–1934), a descendant of early settlers of New Jersey, was a self-made businessman, and for a while, a Judge of Probate. Shannon's mother, Mabel Wolf Shannon (1890–1945), was a language teacher, and for a number of years she was the principal of Gaylord High School. Most of the first 16 years of Shannon's life were spent in Gaylord, where he attended public school, graduating from Gaylord High School in 1932. Shannon showed an inclination towards mechanical and electrical things. His best subjects were science and mathematics, and at home he constructed such devices as models of planes, a radio-controlled model boat and a wireless telegraph system to a friend's house a half-mile away. While growing up, he also worked under Andrew Coltrey as a messenger for the Western Union company.
His childhood hero was Thomas Edison, who he later learned was a distant cousin. Both were descendants of John Ogden (1609–1682), a colonial leader and an ancestor of many distinguished people.
Shannon was apolitical and an atheist.
Boolean theory and beyond.
In 1932, Shannon entered the University of Michigan, where he took a course that introduced him to the work of George Boole. He graduated in 1936 with two bachelor's degrees, one in electrical engineering and one in mathematics. He soon began his graduate studies in electrical engineering at the Massachusetts Institute of Technology (MIT), where he worked on Vannevar Bush's differential analyzer, an early analog computer.
While studying the complicated "ad hoc" circuits of the differential analyzer, Shannon saw that Boole's concepts had great utility. A paper drawn from his 1937 master's degree thesis, "A Symbolic Analysis of Relay and Switching Circuits", was published in the 1938 issue of the "Transactions of the American Institute of Electrical Engineers". It also earned Shannon the Alfred Noble American Institute of American Engineers Award in 1939. Howard Gardner called Shannon's thesis "possibly the most important, and also the most noted, master's thesis of the century."
In this work, Shannon proved that his switching circuits could be used to simplify the arrangement of the electromechanical relays that were used then in telephone call routing switches. Next, he expanded this concept, proving that these circuits could solve all problems that Boolean algebra could solve. In the last chapter he presents diagrams of several circuits, including a 4-bit full adder.
Using this property of electrical switches to implement logic is the fundamental concept that underlies all electronic digital computers. Shannon's work became the foundation of digital circuit design, as it became widely known in the electrical engineering community during and after World War II. The theoretical rigor of Shannon's work superseded the "ad hoc" methods that had prevailed previously.
Through the Carnegie Institution, Vannevar Bush suggested that Shannon, emboldened by his master's thesis success, should work on his dissertation at the Cold Spring Harbor Laboratory, in order to develop similar mathematical relationships for quantifying Mendelian genetics. This research resulted in Shannon's Doctor of Philosophy (Ph.D.) thesis at MIT in 1940, called "An Algebra for Theoretical Genetics."
In 1940, Shannon became a National Research Fellow at the Institute for Advanced Study in Princeton, New Jersey. In Princeton, Shannon had the opportunity to discuss his ideas with influential scientists and mathematicians such as Hermann Weyl and John von Neumann, and he also had occasional encounters with Albert Einstein and Kurt Gödel. Shannon worked freely across disciplines, and this ability may have contributed to his later development of mathematical Information theory.
Wartime research.
Shannon then joined Bell Labs to work on fire-control systems and cryptography during World War II, under a contract with section D-2 (Control Systems section) of the National Defense Research Committee (NDRC).
Shannon met his wife Betty when she was a numerical analyst at Bell Labs. They were married in 1949.
Shannon is credited with the invention of signal-flow graphs, in 1942. He discovered the topological gain formula while investigating the functional operation of an analog computer.
For two months early in 1943, Shannon came into contact with the leading British cryptanalyst and mathematician Alan Turing. Turing had been posted to Washington to share with the U.S. Navy's cryptanalytic service the methods used by the British Government Code and Cypher School at Bletchley Park to break the ciphers used by the Kriegsmarine U-boats in the north Atlantic Ocean. He was also interested in the encipherment of speech and to this end spent time at Bell Labs. Shannon and Turing met at teatime in the cafeteria. Turing showed Shannon his 1936 paper that defined what is now known as the "Universal Turing machine"; this impressed Shannon, as many of its ideas complemented his own.
In 1945, as the war was coming to an end, the NDRC was issuing a summary of technical reports as a last step prior to its eventual closing down. Inside the volume on fire control a special essay titled "Data Smoothing and Prediction in Fire-Control Systems", coauthored by Shannon, Ralph Beebe Blackman, and Hendrik Wade Bode, formally treated the problem of smoothing the data in fire-control by analogy with "the problem of separating a signal from interfering noise in communications systems." In other words, it modeled the problem in terms of data and signal processing and thus heralded the coming of the Information Age.
Shannon's work on cryptography was even more closely related to his later publications on communication theory. At the close of the war, he prepared a classified memorandum for Bell Telephone Labs entitled "A Mathematical Theory of Cryptography," dated September 1945. A declassified version of this paper was published in 1949 as "Communication Theory of Secrecy Systems" in the "Bell System Technical Journal". This paper incorporated many of the concepts and mathematical formulations that also appeared in his "A Mathematical Theory of Communication". Shannon said that his wartime insights into communication theory and cryptography developed simultaneously and that "they were so close together you couldn’t separate them". In a footnote near the beginning of the classified report, Shannon announced his intention to "develop these results … in a forthcoming memorandum on the transmission of information."
While he was at Bell Labs, Shannon proved that the cryptographic one-time pad is unbreakable in his classified research that was later published in October 1949. He also proved that any unbreakable system must have essentially the same characteristics as the one-time pad: the key must be truly random, as large as the plaintext, never reused in whole or part, and be kept secret.
Later on in the American Venona project, a supposed "one-time pad" system by the Soviets was partially broken by the National Security Agency, but this was because of misuses of the one-time pads by Soviet cryptographic technicians in the United States and Canada. The Soviet technicians made the mistake of using the same pads more than once sometimes, and this was noticed by American cryptanalysts.
Postwar contributions.
In 1948, the promised memorandum appeared as "A Mathematical Theory of Communication", an article in two parts in the July and October issues of the "Bell System Technical Journal". This work focuses on the problem of how best to encode the information a sender wants to transmit. In this fundamental work he used tools in probability theory, developed by Norbert Wiener, which were in their nascent stages of being applied to communication theory at that time. Shannon developed information entropy as a measure for the uncertainty in a message while essentially inventing the field of information theory.
The book, co-authored with Warren Weaver, "The Mathematical Theory of Communication", reprints Shannon's 1948 article and Weaver's popularization of it, which is accessible to the non-specialist. Warren Weaver pointed out that the word information in communication theory is not related to what you do say, but to what you could say. That is, information is a measure of one's freedom of choice when one selects a message. Shannon's concepts were also popularized, subject to his own proofreading, in John Robinson Pierce's "Symbols, Signals, and Noise".
Information theory's fundamental contribution to natural language processing and computational linguistics was further established in 1951, in his article "Prediction and Entropy of Printed English", showing upper and lower bounds of entropy on the statistics of English – giving a statistical foundation to language analysis. In addition, he proved that treating whitespace as the 27th letter of the alphabet actually lowers uncertainty in written language, providing a clear quantifiable link between cultural practice and probabilistic cognition.
Another notable paper published in 1949 is "Communication Theory of Secrecy Systems", a declassified version of his wartime work on the mathematical theory of cryptography, in which he proved that all theoretically unbreakable ciphers must have the same requirements as the one-time pad. He is also credited with the introduction of sampling theory, which is concerned with representing a continuous-time signal from a (uniform) discrete set of samples. This theory was essential in enabling telecommunications to move from analog to digital transmissions systems in the 1960s and later.
He returned to MIT to hold an endowed chair in 1956.
Hobbies and inventions.
Outside of his academic pursuits, Shannon was interested in juggling, unicycling, and chess. He also invented many devices, including a Roman numeral computer called THROBAC, juggling machines, and a flame-throwing trumpet. One of his more humorous devices was a box kept on his desk called the "Ultimate Machine", based on an idea by Marvin Minsky. Otherwise featureless, the box possessed a single switch on its side. When the switch was flipped, the lid of the box opened and a mechanical hand reached out, flipped off the switch, then retracted back inside the box. Renewed interest in the "Ultimate Machine" has emerged on YouTube and Thingiverse. In addition he built a device that could solve the Rubik's Cube puzzle.
Shannon designed the Minivac 601, a digital computer trainer to teach business people about how computers functioned. It was sold by the Scientific Development Corp starting in 1961.
He is also considered the co-inventor of the first wearable computer along with Edward O. Thorp. The device was used to improve the odds when playing roulette.
Legacy and tributes.
In 1956 Shannon joined the MIT faculty to work in the Research Laboratory of Electronics (RLE). He continued to serve on the MIT faculty until 1978. To commemorate his achievements, there were celebrations of his work in 2001, and there are currently six statues of Shannon sculpted by Eugene Daub: one at the University of Michigan; one at MIT in the Laboratory for Information and Decision Systems; one in Gaylord, Michigan; one at the University of California, San Diego; one at Bell Labs; and another at AT&T Shannon Labs. After the breakup of the Bell System, the part of Bell Labs that remained with AT&T Corporation was named Shannon Labs in his honor.
According to Neil Sloane, an AT&T Fellow who co-edited Shannon's large collection of papers in 1993, the perspective introduced by Shannon's communication theory (now called information theory) is the foundation of the digital revolution, and every device containing a microprocessor or microcontroller is a conceptual descendant of Shannon's publication in 1948: "He's one of the great men of the century. Without him, none of the things we know today would exist. The whole digital revolution started with him." The unit shannon is named after Claude Shannon.
Shannon had three children, Robert James Shannon, Andrew Moore Shannon, and Margarita Shannon. His oldest son, Robert Shannon, died when he was 45 years old in 1998. Shannon developed Alzheimer's disease, and eventually died in 2001. His last few years were spent in a nursing home in Massachusetts oblivious to the marvels of the digital revolution he had helped create. He was survived by his wife, Mary Elizabeth Moore Shannon, his son, Andrew Moore Shannon, his daughter, Margarita Shannon, his sister, Catherine Shannon Kay, and his two granddaughters. His wife stated in his obituary that, had it not been for Alzheimer's disease, "He would have been bemused" by it all.
Other work.
Shannon's mouse.
Theseus, created in 1950, was a magnetic mouse controlled by a relay circuit that enabled it to move around a maze of 25 squares. Its dimensions were the same as those of an average mouse. The maze configuration was flexible and it could be modified at will. The mouse was designed to search through the corridors until it found the target. Having travelled through the maze, the mouse would then be placed anywhere it had been before and because of its prior experience it could go directly to the target. If placed in unfamiliar territory, it was programmed to search until it reached a known location and then it would proceed to the target, adding the new knowledge to its memory thus learning. Shannon's mouse appears to have been the first artificial learning device of its kind.
Shannon's computer chess program.
In 1950, Shannon published a paper on computer chess entitled "Programming a Computer for Playing Chess". It describes how a machine or computer could be made to play a reasonable game of chess. His process for having the computer decide on which move to make is a minimax procedure, based on an evaluation function of a given chess position. Shannon gave a rough example of an evaluation function in which the value of the black position was subtracted from that of the white position. "Material" was counted according to the usual chess piece relative value (1 point for a pawn, 3 points for a knight or bishop, 5 points for a rook, and 9 points for a queen). He considered some positional factors, subtracting ½ point for each doubled pawns, backward pawn, and isolated pawn. Another positional factor in the evaluation function was "mobility", adding 0.1 point for each legal move available. Finally, he considered checkmate to be the capture of the king, and gave the king the artificial value of 200 points. Quoting from the paper:
The evaluation function is clearly for illustrative purposes, as Shannon stated. For example, according to the function, pawns that are doubled as well as isolated would have no value at all, which is clearly unrealistic.
Card counting in Las Vegas.
Shannon and his wife Betty also used to go on weekends to Las Vegas with MIT mathematician Ed Thorp, and made very successful forays in blackjack using game theory type methods co-developed with fellow Bell Labs associate John L. Kelly Jr., a physicist, based on principles of information theory. His method, known as the High-Low method, a level 1 count methodology, works by adding 1, 0, or -1 depending on the cards that appear. Shannon and Thorp also invented a small, concealable computer to help them calculate odds while gambling. They made a fortune, as detailed in the book "Fortune's Formula" by William Poundstone and corroborated by the writings of Elwyn Berlekamp, Kelly's research assistant in 1960 and 1962. Shannon and Thorp also applied the same theory, later known as the "Kelly criterion", to the stock market with even better results. Claude Shannon's card count techniques were explained in "Bringing Down the House", the best-selling book published in 2003 about the MIT Blackjack Team by Ben Mezrich. In 2008, the book was adapted into a drama film titled "21".
Shannon's maxim.
Shannon formulated a version of Kerckhoffs' principle as "The enemy knows the system". In this form it is known as "Shannon's maxim".
Commemorations.
Shannon Centenary.
The Shannon Centenary, 2016, marks the life and influence of Claude Elwood Shannon on the hundredth anniversary of his birth on 30 April 1916. It is inspired in part by the Alan Turing Year. An ad hoc committee of the IEEE Information Theory Society including Christina Fragouli, Rüdiger Urbanke, Michelle Effros, Lav Varshney and Sergio Verdú, is coordinating worldwide events. The initiative was announced in the History Panel at the 2015 IEEE Information Theory Workshop Jerusalem and the IEEE Information Theory Society Newsletter.
A detailed listing of confirmed events is available on the website of the IEEE Information Theory Society.
Some of the planned activities include:
Awards and honors list.
The Claude E. Shannon Award was established in his honor; he was also its first recipient, in 1972.

</doc>
<doc id="5694" url="https://en.wikipedia.org/wiki?curid=5694" title="Cracking">
Cracking

Cracking may refer to:
In computing:

</doc>
<doc id="5695" url="https://en.wikipedia.org/wiki?curid=5695" title="Community">
Community

A community is a social unit of any size that shares common values, or that is situated in a given geographical area (e.g. a village or town). It is a group of people who are connected by durable relations that extend beyond immediate genealogical ties, and who usually define that relationship as important to their social identity and practice. Although communities are usually small, "community" may also refer to large groups, such as national communities, international communities, and virtual communities.
The word "community" derives from the Old French "comuneté" which comes from the Latin "communitas" (from Latin "communis", things held in common).
Human communities may share intent, belief, resources, preferences, needs, and risks in common, affecting the identity of the participants and their degree of cohesiveness.
Perspectives from various disciplines.
Archaeology.
In archaeological studies of social communities the term "community" is used in two ways, paralleling usage in other areas. The first is an informal definition of community as a place where people used to live. In this sense it is synonymous with the concept of an ancient settlement, whether a hamlet, village, town, or city. The second meaning is similar to the usage of the term in other social sciences: a community is a group of people living near one another who interact socially. Social interaction on a small scale can be difficult to identify with archaeological data. Most reconstructions of social communities by archaeologists rely on the principle that social interaction is conditioned by physical distance. Therefore, a small village settlement likely constituted a social community, and spatial subdivisions of cities and other large settlements may have formed communities. Archaeologists typically use similarities in material culture—from house types to styles of pottery—to reconstruct communities in the past. This is based on the assumption that people or households will share more similarities in the types and styles of their material goods with other members of a social community than they will with outsiders.
Ecology.
In ecology, a community is an assemblage of populations of different species, interacting with one another. Community ecology is the branch of ecology that studies interactions between and among species. It considers how such interactions, along with interactions between species and the abiotic environment, affect community structure and species richness, diversity and patterns of abundance. Species interact in three ways: competition, predation and mutualism. Competition typically results in a double negative—that is both species lose in the interaction. Predation is a win/lose situation with one species winning. Mutualism, on the other hand, involves both species cooperating in some way, with both winning.
Key concepts.
Gemeinschaft and Gesellschaft.
In "Gemeinschaft und Gesellschaft" (1887), German sociologist Ferdinand Tönnies described two types of human association: "Gemeinschaft" (usually translated as "community") and "Gesellschaft" ("society" or "association"). Tönnies proposed the "Gemeinschaft–Gesellschaft" dichotomy as a way to think about social ties. No group is exclusively one or the other. "Gemeinschaft" stress personal social interactions, and the roles, values, and beliefs based on such interactions. "Gesellschaft" stress indirect interactions, impersonal roles, formal values, and beliefs based on such interactions.
Internet communities.
Groups of people are complex, in ways that make those groups hard to form and hard to sustain; much of the shape of traditional institutions is a response to those difficulties. New social tools relieve some of those burdens, allowing for new kinds of group-forming, like using simple sharing to anchor the creation of new groups.
One simple form of cooperation, almost universal with social tools, is conversation; when people are in one another's company, even virtually, they like to talk. Conversation creates more of a sense of community than sharing does.
Collaborative production is a more involved form of cooperation, as it increases the tension between individual and group goals. The litmus test for collaborative production is simple: no one person can take credit for what gets created, and the project could not come into being without the participation of many.
An online community builds weaker bonds and allows users to be anonymous. Clay Shirky, a researcher on digital media, states in reference to the audience of an online community, "An audience isn’t just a big community; it can be more anonymous, with many fewer ties among users. A community isn’t just a small audience either; it has a social density that audiences lack." The sites that offer online communities, like Myspace, Twitter, Facebook, Instagram, Tumblr, and Pinterest allow users to "stalk" their community and act anonymously.
Organizational communication.
Effective communication practices in group and organizational settings are very important to the formation and maintenance of communities. The ways that ideas and values are communicated within communities are important to the induction of new members, the formulation of agendas, the selection of leaders and many other aspects. Organizational communication is the study of how people communicate within an organizational context and the influences and interactions within organizational structures. Group members depend on the flow of communication to establish their own identity within these structures and learn to function in the group setting. Although organizational communication, as a field of study, is usually geared toward companies and business groups, these may also be seen as communities. The principles of organizational communication can also be applied to other types of communities.
Public administration.
Public administration is the province of local, state and federal governments, with local governments responsible for units in towns, cities, villages, and counties, among others. The most well known "community department" is housing and community development which has responsibility for both economic development initiatives, and as public housing and community infrastructure (e.g., business development).
Sense of community.
In a seminal 1986 study, McMillan and Chavis identify four elements of "sense of community":
They give the following example of the interplay between these factors:
Someone puts an announcement on the dormitory bulletin board about the formation of an intramural dormitory basketball team. People attend the organizational meeting as strangers out of their individual needs (integration and fulfillment of needs). The team is bound by place of residence (membership boundaries are set) and spends time together in practice (the contact hypothesis). They play a game and win (successful shared valent event). While playing, members exert energy on behalf of the team (personal investment in the group). As the team continues to win, team members become recognized and congratulated (gaining honor and status for being members), Influencing new members to join and continue to do the same. Someone suggests that they all buy matching shirts and shoes (common symbols) and they do so (influence).
A "Sense of Community Index" (SCI) has been developed by Chavis and colleagues and revised and adapted by others. Although originally designed to assess sense of community in neighborhoods, the index has been adapted for use in schools, the workplace, and a variety of types of communities.
Studies conducted by the APPA show substantial evidence that young adults who feel a sense of belonging in a community, particularly small communities, develop fewer psychiatric and depressive disorders than those who do not have the feeling of love and belonging.
Socialization.
The process of learning to adopt the behavior patterns of the community is called socialization. The most fertile time of socialization is usually the early stages of life, during which individuals develop the skills and knowledge and learn the roles necessary to function within their culture and social environment. For some psychologists, especially those in the psychodynamic tradition, the most important period of socialization is between the ages of one and ten. But socialization also includes adults moving into a significantly different environment, where they must learn a new set of behaviors.
Socialization is influenced primarily by the family, through which children first learn community norms. Other important influences include schools, peer groups, people, mass media, the workplace, and government. The degree to which the norms of a particular society or community are adopted determines one's willingness to engage with others. The norms of tolerance, reciprocity, and trust are important "habits of the heart," as de Tocqueville put it, in an individual's involvement in community.
Community development.
Community development is often linked with community work or community planning, and may involve stakeholders, foundations, governments, or contracted entities including non-government organisations (NGOs), universities or government agencies to progress the social well-being of local, regional and, sometimes, national communities. More grassroots efforts, called community building or community organizing, seek to empower individuals and groups of people by providing them with the skills they need to effect change in their own communities. These skills often assist in building political power through the formation of large social groups working for a common agenda. Community development practitioners must understand both how to work with individuals and how to affect communities' positions within the context of larger social institutions. Public administrators, in contrast, need to understand community development in the context of rural and urban development, housing and economic development, and community, organizational and business development.
Formal accredited programs conducted by universities, as part of degree granting institutions, are often used to build a knowledge base to drive curricula in public administration, sociology and community studies. The General Social Survey from the National Opinion Research Center at the University of Chicago and the Saguaro Seminar at the John F. Kennedy School of Government at Harvard University are examples of national community development in the United States. The Maxwell School of Citizenship and Public Affairs at Syracuse University in New York State offers core courses in community and economic development, and in areas ranging from non-profit development to US budgeting (federal to local, community funds). In the United Kingdom, Oxford University has led in providing extensive research in the field through its " Community Development Journal," used worldwide by sociologists and community development practitioners.
At the intersection between community "development" and community "building" are a number of programs and organizations with community development tools. One example of this is the program of the Asset Based Community Development Institute of Northwestern University. The institute makes available downloadable tools to assess community assets and make connections between non-profit groups and other organizations that can help in community building. The Institute focuses on helping communities develop by "mobilizing neighborhood assets" — building from the inside out rather than the outside in. In the disability field, community building was prevalent in the 1980s and 1990s with roots in John McKnight's approaches.
Community building and organizing.
In "The Different Drum: Community-Making and Peace," Scott Peck argues that the almost accidental sense of community that exists at times of crisis can be consciously built. Peck believes that conscious community building is a process of deliberate design based on the knowledge and application of certain rules. He states that this process goes through four stages:
More recently Peck remarked that building a sense of community is easy but maintaining this sense of community is difficult in the modern world. Community building can use a wide variety of practices, ranging from simple events such as potlucks and small book clubs to larger-scale efforts such as mass festivals and construction projects that involve local participants rather than outside contractors.
Community building that is geared toward citizen action is usually termed "community organizing." In these cases, organized community groups seek accountability from elected officials and increased direct representation within decision-making bodies. Where good-faith negotiations fail, these constituency-led organizations seek to pressure the decision-makers through a variety of means, including picketing, boycotting, sit-ins, petitioning, and electoral politics. The ARISE Detroit! coalition and the Toronto Public Space Committee are examples of activist networks committed to shielding local communities from government and corporate domination and inordinate influence.
Community organizing is sometimes focused on more than just resolving specific issues. Organizing often means building a widely accessible power structure, often with the end goal of distributing power equally throughout the community. Community organizers generally seek to build groups that are open and democratic in governance. Such groups facilitate and encourage consensus decision-making with a focus on the general health of the community rather than a specific interest group. The three basic types of community organizing are grassroots organizing, coalition building, and "institution-based community organizing," (also called "broad-based community organizing," an example of which is faith-based community organizing, or Congregation-based Community Organizing).
If communities are developed based on something they share in common, whether that be location or values, then one challenge for developing communities is how to incorporate individuality and differences. Indeed, as Rebekah Nathan suggests in her book, "My Freshman Year", we are actually drawn to developing communities totally based on sameness, despite stated commitments to diversity, such as those found on university websites. Nathan states that certain commonalities allow college students to cohere: "What holds students together, really, is age, pop culture, a handful of (recent) historical events, and getting a degree" (qtd. In Barrios 229). Universities may try to create community through all freshman reads, freshman seminars, and school pride; however, Nathan argues students will only form communities based on the attributes, such as age and pop culture, that they bring with them to college. Nathan's point, then, is that people come to college and don't expand their social horizons and cultural tolerance, which can prevent the development of your social community. (Barrios, Barclay. "Emerging: Contemporary Readings for Writers". New York: Bedford St. Martins, 2010.)
Community currencies.
Some communities have developed their own "Local Exchange Trading Systems" (LETS) and local currencies, such as the Ithaca Hours system, to encourage economic growth and an enhanced sense of community. Community currencies have recently proven valuable in meeting the needs of people living in various South American nations, particularly Argentina, that recently suffered as a result of the collapse of the Argentinian national currency.
Community services.
Community services is a term that refers to a wide range of community institutions, governmental and non-governmental services, voluntary, third sector organizations, and grassroots and neighborhood efforts in local communities, towns, cities, and suburban-exurban areas. In line with governmental and community thinking, volunteering and unpaid services are often preferred (e.g., altruism, beneficence) to large and continued investments in infrastructure and community services personnel, with private-public partnerships often common.
Non-profit organizations from youth services, to family and neighborhood centers, recreation facilities, civic clubs, and employment, housing and poverty agencies are often the foundation of community services programs, but it may also be undertaken under the auspices of government (which funds all NGOs), one or more businesses, or by individuals or newly formed collaboratives. Community services is also the broad term given to health and human services in local communities and was specifically used as the framework for deinstitutionalization and community integration to homes, families and local communities (e.g., community residential services).
In a broad discussion of community services, schools, hospitals, clinics, rehabilitation and criminal justice institutions also view themselves as community planners and decisionmakers together with governmental leadership (e.g., city and county offices, state-regional offices). However, while many community services are voluntary, some may be part of alternative sentencing approaches in a justice system and it can be required by educational institutions as part of internships, employment training, and post-graduation plans.
Community services may be paid for through different revenue streams which include targeted federal funds, taxpayer contributions, state and local grants and contracts, voluntary donations, Medicaid or health care funds, community development block grants, targeted education funds, and so forth. In the 2000s, the business sector began to contract with government, and also consult on government policies, and has shifted the framework of community services to the for-profit domains.
However, by the 1990s, the call was to return to community and to go beyond community services to belonging, relationships, community building and welcoming new population groups and diversity in community life.
Bangladesh Community, is a rapidly expanding and extending community in Canada with its professionals, students and families. In Alberta, Bangladesh Heritage and Ethnic
Society (BHESA), a not-for-profit socio-cultural & heritage association known to lead to greater understanding of culture and heritage of Bangladesh, and characterized by planning, action and mobilization of community, the promotion of
multicultural changes and, ultimately, influence within larger systems. Through establishing its link to the larger or more extended communities with national, international, and virtual community.
^BHESA celebrates Bangladesh culture,
^MJMF supports Bangladeshi and Canadian Youth,
^International Mother Language Day Celebration 2015, ^BHESA,^MJMF,
Types of community.
A number of ways to categorize types of community have been proposed. One such breakdown is as follows:
The usual categorizations of community relations have a number of problems: 1. they tend to give the impression that a particular community can be defined as just this kind or another; 2. they tend to conflate modern and customary community relations; 3. they tend to take sociological categories such as ethnicity or race as given, forgetting that different ethnically defined persons live in different kinds of communities — grounded, interest-based, diasporic, etc.
In response to these problems, Paul James and his colleagues have developed a taxonomy that maps community relations, and recognizes that actual communities can be characterized by different kinds of relations at the same time:
In these terms, communities can be nested and/or intersecting; one community can contain another—for example a location-based community may contain a number of ethnic communities. Both lists above can used in a cross-cutting matrix in relation to each other.
Location.
Possibly the most common usage of the word ""community"" indicates a large group living in close proximity. Examples of local community include:
Identity.
In some contexts, ""community"" indicates a group of people with a common identity other than location. Members often interact regularly. Common examples in everyday usage include:
Overlaps.
Some communities share both location and other attributes. Members choose to live near each other because of one or more common interests.
Special nature of human community.
Definitions of community as "organisms inhabiting a common environment and interacting with one another," while scientifically accurate, do not convey the richness, diversity and complexity of human communities. Their classification, likewise is almost never precise. Untidy as it may be, community is vital for humans. M. Scott Peck expresses this in the following way: "There can be no vulnerability without risk; there can be no community without vulnerability; there can be no peace, and ultimately no life, without community."

</doc>
<doc id="5696" url="https://en.wikipedia.org/wiki?curid=5696" title="Community college">
Community college

A community college is a type of educational institution. The term can have different meanings in different countries.
Australia.
In Australia, the term community college is not used. Analogous to community colleges are colleges or institutes of Technical and Further Education (TAFEs); institutions mostly regulated at state and territory level. There are also an increasing number of private providers of varying social esteem; often these are colloquially called "colleges".
TAFEs and other providers carry on the tradition of adult education, which was established in Australia around mid 19th century when evening classes were held to help adults enhance their numeracy and literacy skills. The majority of Australian universities can also be traced back to such forerunners, although obtaining a university charter has always changed their nature. In TAFEs and colleges today, courses are designed for personal development of an individual and/or for employment outcomes. Educational programs cover a variety of topics such as arts, languages, business and lifestyle; and are usually timetabled to be conducted in the evenings or weekends to accommodate people working full-time. Funding for colleges may come from government grants and course fees; and many are not-for-profit organisations. There are located in metropolitan, regional and rural locations of Australia.
Learning offered by TAFEs and colleges has changed over the years. By the 1980s many colleges had recognised a community need for computer training and since then thousands of people have been up-skilled through IT courses. The majority of colleges by the late 20th century had also become Registered Training Organisations; recognising the need to offer individuals a nurturing, non-traditional education venue to gain skills that would better prepare them for the workplace and potential job openings. TAFEs and colleges have not traditionally offered bachelor's degrees, instead providing pathway arrangements with universities to continue towards degrees. The American innovation of the associate degree is emerging at some institutions. Certificate courses I to IV, diplomas and advanced diplomas are typically offered, the latter deemed equivalent to an undergraduate qualification, albeit typically in more vocational areas. Recently, some TAFE institutes (and private providers) have also become Higher Education providers in their own right and are now starting to offer bachelor's degrees programs.
Canada.
In Canada, Community Colleges are adult educational institutions that provide higher education and tertiary education, and grant certificates and diplomas. Each province has its own educational system, as prescribed by the Canadian federalism model of governance. Most Canadian colleges began in the mid-1960s and early 1970s to provide practical education and training for the emerging baby boom generation, and for immigrants from around the world who were entering Canada in increasing numbers at that time. A formative trend was the merging of the then separate vocational training and adult education (night-school) institutions.
Canadian colleges are either publicly funded or private post secondary institutions (run for profit). There are 150 institutions that are generally equivalent to the US community college in certain contexts. They are usually referred to simply as "colleges" since in common usage a degree granting institution is almost exclusively a university.
In addition to graduate degrees, universities generally grant Associate's degrees and Bachelor's degrees, but in some regions and/or courses of study, colleges and universities collaborate so college students can earn transfer credits toward undergraduate university degrees.
University degrees are usually attained through 4-years of study. The term associate degree is used in western Canada to refer to a 2-year college arts or science degree, similar to how the term is used in the United States. In other parts of Canada the term advanced degree is used to indicate a 3 or 4 year college program.
In the province of Quebec, 3 years is the norm for a university degree because a year of credit is earned in the CEGEP (college) system. Even when speaking in English, people often refer to all colleges as Cégeps, however the term is an acronym more correctly applied specifically to the French language public system: Collège d'enseignement général et professionnel (CEGEP); in English: College of General and Vocational Education. The word College can also refer to a private High School in Quebec.
India.
In India, 98 community colleges are recognized by the University Grants Commission. The courses offered by these colleges are diplomas, advance diplomas and certificate courses. The duration of these courses usually range from six months to two years.
Malaysia.
Community colleges in Malaysia are a network of educational institutions whereby vocational and technical skills training could be provided at all levels for school leavers before they entered the workforce. The community colleges also provide an infrastructure for rural communities to gain skills training through short courses as well as providing access to a post-secondary education.
At the moment, most community colleges award qualifications up to Level 3 in the Malaysian Qualifications Framework (Certificate 3) in both the Skills sector (Sijil Kemahiran Malaysia or the Malaysian Skills Certificate) as well as the Vocational and Training sector but the number of community colleges that are starting to award Level 4 qualifications (Diploma) are increasing. This is two levels below a bachelor's degree (Level 6 in the MQF) and students within the system who intend to further their studies to that level will usually seek entry into Advanced Diploma programs in public universities, polytechnics or accredited private providers.
Philippines.
In the Philippines, a community school functions as elementary or secondary school at daytime and towards the end of the day convert into a community college. This type of institution offers night classes under the supervision of the same principal, and the same faculty members who are given part-time college teaching load.
The concept of community college dates back to the time of the former Minister of Education, Culture and Sports (MECS) that had under its wings the Bureaus of Elementary Education, Secondary Education, Higher Education and Vocational-Technical Education. MECS Secretary, Dr. Cecilio Putong, who in 1971 wrote that a community school is a school established in the community, by the community, and for the community itself. Dr. Pedro T. Orata of Pangasinan shared the same idea, hence the establishment of a Community College, now called the City College of Urdaneta.
A community college like the one in Abuyog, Leyte can operate with only PHP 124,000 annual budget in a 2-storey structure housing more than 700 students.
United Kingdom (excluding Scotland).
In the United Kingdom, except for Scotland, a community college is a school which not only provides education for the school age population (11–18) of the locality, but also additional services and education to adults and other members of the community. This education includes but is not limited to sports, adult literacy and lifestyle education. Usually at the age of 16 when students finish their secondary school studies, they move on to a sixth form college where they study for their A-levels (although some secondary schools have integrated sixth forms). After the 2 year A-level period, they may then proceed to a college of further education or a university.
United States.
In the United States, community colleges, sometimes called junior colleges, technical colleges, two-year colleges, or city colleges, are primarily two-year public institutions providing higher education and lower-level tertiary education, granting certificates, diplomas, and associate's degrees. Many also offer continuing and adult education.
After graduating from a community college, some students transfer to a four-year liberal arts college or university for two to three years to complete a bachelor's degree.
Before the 1970s, community colleges in the United States were more commonly referred to as junior colleges, and that term is still used at some institutions. However, the term "junior college" has evolved to describe private two-year institutions, whereas the term "community college" has evolved to describe publicly funded two-year institutions. The name derives from the fact that community colleges primarily attract and accept students from the local community, and are often supported by local tax revenue.
Research.
There are research organizations and publications who focus upon the activities of community college, junior college, and technical college institutions. Many of these institutions and organizations present the most current research and practical outcomes at annual community college conferences.
Additionally, several peer-reviewed journals extensively publish research on community colleges:

</doc>
<doc id="5697" url="https://en.wikipedia.org/wiki?curid=5697" title="Civil Rights Memorial">
Civil Rights Memorial

The Civil Rights Memorial is a memorial in Montgomery, Alabama to 41 people who died in the struggle for the equal and integrated treatment of all people, regardless of race, during the Civil Rights Movement in the United States. The memorial is sponsored by the Southern Poverty Law Center.
The names included in the memorial belong to those who died between 1954 and 1968. Those dates were chosen because in 1954 the U.S. Supreme Court ruled that racial segregation in schools was unlawful and 1968 is the year of Martin Luther King's assassination. The monument was created by Maya Lin, who is best known for creating the Vietnam Veterans Memorial in Washington, D.C. The Civil Rights Memorial was dedicated in 1989.
The concept of Maya Lin's design is based on the soothing and healing effect of water. It was inspired by Martin Luther King, Jr.'s paraphrase ""... we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream. ..."", from the "I Have a Dream" speech, delivered at the Lincoln Memorial, Washington D.C. on August 28, 1963. This passage in King's speech is a direct reference to Amos , as translated in the American Standard Version of the Bible. The memorial is a fountain in the form of an asymmetric inverted stone cone. A film of water flows over the base of the cone, which contains the 41 names included. It is possible to touch the smooth film of water and temporarily alter the surface film, which quickly returns to smoothness. As such, the memorial represents the aspirations of the American Civil Rights Movement against legalized racism.
Tours and Location.
The memorial is located downtown at 400 Washington Avenue in an open plaza in front of the Civil Rights Memorial Center, which was formerly the offices of the Southern Poverty Law Center and which moved across the street into a new building in 2001. The memorial may be visited freely 24 hours a day, 7 days a week.
The Civil Rights Memorial Center offers guided group tours lasting approximately one hour. Tours are available by appointment, Monday through Saturday.
The memorial is only a few blocks from other historic sites, including the Dexter Avenue King Memorial Baptist Church, the Alabama State Capitol, the Alabama Department of Archives and History and the Rosa Parks Library and Museum.
Names included.
The 41 names included in the Civil Rights Memorial are those of:

</doc>
<doc id="5698" url="https://en.wikipedia.org/wiki?curid=5698" title="Charles Babbage">
Charles Babbage

Charles Babbage (; 26 December 1791 – 18 October 1871) was an English polymath. A mathematician, philosopher, inventor and mechanical engineer, Babbage is best remembered for originating the concept of a programmable computer.
Considered by some to be a "father of the computer", Babbage is credited with inventing the first mechanical computer that eventually led to more complex designs. His varied work in other fields has led him to be described as "pre-eminent" among the many polymaths of his century.
Parts of Babbage's uncompleted mechanisms are on display in the London Science Museum. In 1991, a perfectly functioning difference engine was constructed from Babbage's original plans. Built to tolerances achievable in the 19th century, the success of the finished engine indicated that Babbage's machine would have worked.
Early life.
Babbage's birthplace is disputed, but according to the "Oxford Dictionary of National Biography" he was most likely born at 44 Crosby Row, Walworth Road, London, England. A blue plaque on the junction of Larcom Street and Walworth Road commemorates the event.
His date of birth was given in his obituary in "The Times" as 26 December 1792; but then a nephew wrote to say that Babbage was born one year earlier, in 1791. The parish register of St. Mary's Newington, London, shows that Babbage was baptised on 6 January 1792, supporting a birth year of 1791.
Babbage was one of four children of Benjamin Babbage and Betsy Plumleigh Teape. His father was a banking partner of William Praed in founding Praed's & Co. of Fleet Street, London, in 1801. In 1808, the Babbage family moved into the old Rowdens house in East Teignmouth. Around the age of eight, Babbage was sent to a country school in Alphington near Exeter to recover from a life-threatening fever. For a short time he attended King Edward VI Grammar School in Totnes, South Devon, but his health forced him back to private tutors for a time.
Babbage then joined the 30-student Holmwood academy, in Baker Street, Enfield, Middlesex, under the Reverend Stephen Freeman. The academy had a library that prompted Babbage's love of mathematics. He studied with two more private tutors after leaving the academy. The first was a clergyman near Cambridge; through him Babbage encountered Charles Simeon and his evangelical followers, but the tuition was not what he needed. He was brought home, to study at the Totnes school: this was at age 16 or 17. The second was an Oxford tutor, under whom Babbage reached a level in Classics sufficient to be accepted by Cambridge.
At the University of Cambridge.
Babbage arrived at Trinity College, Cambridge, in October 1810. He was already self-taught in some parts of contemporary mathematics; he had read in Robert Woodhouse, Joseph Louis Lagrange, and Marie Agnesi. As a result, he was disappointed in the standard mathematical instruction available at Cambridge.
Babbage, John Herschel, George Peacock, and several other friends formed the Analytical Society in 1812; they were also close to Edward Ryan. As a student, Babbage was also a member of other societies such as The Ghost Club, concerned with investigating supernatural phenomena, and the Extractors Club, dedicated to liberating its members from the madhouse, should any be committed to one.
In 1812 Babbage transferred to Peterhouse, Cambridge. He was the top mathematician there, but did not graduate with honours. He instead received a degree without examination in 1814. He had defended a thesis that was considered blasphemous in the preliminary public disputation; but it is not known whether this fact is related to his not sitting the examination.
After Cambridge.
Considering only his reputation, Babbage quickly made progress. He lectured to the Royal Institution on astronomy in 1815, and was elected a Fellow of the Royal Society in 1816. After graduation, on the other hand, he applied for positions unsuccessfully, and had little in the way of career. In 1816 he was a candidate for a teaching job at Haileybury College; he had recommendations from James Ivory and John Playfair, but lost out to Henry Walter. In 1819, Babbage and Herschel visited Paris and the Society of Arcueil, meeting leading French mathematicians and physicists. That year Babbage applied to be professor at the University of Edinburgh, with the recommendation of Pierre Simon Laplace; the post went to William Wallace.
With Herschel, Babbage worked on the electrodynamics of Arago's rotations, publishing in 1825. Their explanations were only transitional, being picked up and broadened by Michael Faraday. The phenomena are now part of the theory of eddy currents, and Babbage and Herschel missed some of the clues to unification of electromagnetic theory, staying close to Ampère's force law.
Babbage purchased the actuarial tables of George Barrett, who died in 1821 leaving unpublished work, and surveyed the field in 1826 in "Comparative View of the Various Institutions for the Assurance of Lives". This interest followed a project to set up an insurance company, prompted by Francis Baily and mooted in 1824, but not carried out. Babbage did calculate actuarial tables for that scheme, using Equitable Society mortality data from 1762 onwards.
During this whole period Babbage depended awkwardly on his father's support, given his father's attitude to his early marriage, of 1814: he and Edward Ryan wedded the Whitmore sisters. He made a home in Marylebone in London, and founded a large family. On his father's death in 1827, Babbage inherited a large estate (value around £100,000, equivalent to £ in today's pounds), making him independently wealthy. After his wife's death in the same year he spent time travelling. In Italy he met Leopold II, Grand Duke of Tuscany, foreshadowing a later visit to Piedmont. In April 1828 he was in Rome, and relying on Herschel to manage the difference engine project, when he heard that he had become professor at Cambridge, a position he had three times failed to obtain (in 1820, 1823 and 1826).
Astronomical Society.
Babbage was instrumental in founding the Astronomical Society in 1820. Its initial aims were to reduce astronomical calculations to a more standard form, and to circulate data. These directions were closely connected with Babbage's ideas on computation, and in 1824 he won its Gold Medal, cited "for his invention of an engine for calculating mathematical and astronomical tables".
Babbage's motivation to overcome errors in tables by mechanisation has been a commonplace since Dionysius Lardner wrote about it in 1834 in the "Edinburgh Review" (under Babbage's guidance). The context of these developments is still debated. Babbage's own account of the origin of the difference engine begins with the Astronomical Society's wish to improve "The Nautical Almanac". Babbage and Herschel were asked to oversee a trial project, to recalculate some part of those tables. With the results to hand, discrepancies were found. This was in 1821 or 1822, and was the occasion on which Babbage formulated his idea for mechanical computation. The issue of the "Nautical Almanac" is now described as a legacy of a polarisation in British science caused by attitudes to Sir Joseph Banks, who had died in 1820.
Babbage studied the requirements to establish a modern postal system, with his friend Thomas Frederick Colby, concluding there should be a uniform rate that was put into effect with the introduction of the Uniform Fourpenny Post supplanted by the Uniform Penny Post in 1839 and 1840. Colby was another of the founding group of the Society. He was also in charge of the Survey of Ireland. Herschel and Babbage were present at a celebrated operation of that survey, the remeasuring of the Lough Foyle baseline.
British Lagrangian School.
The Analytical Society had initially been no more than an undergraduate provocation. During this period it had some more substantial achievements. In 1816 Babbage, Herschel and Peacock published a translation from French of the lectures of Sylvestre Lacroix, which was then the state-of-the-art calculus textbook.
Reference to Lagrange in calculus terms marks out the application of what are now called formal power series. British mathematicians had used them from about 1730 to 1760. As re-introduced, they were not simply applied as notations in differential calculus. They opened up the fields of functional equations (including the difference equations fundamental to the difference engine) and operator (D-module) methods for differential equations. The analogy of difference and differential equations was notationally changing Δ to D, as a "finite" difference becomes "infinitesimal". These symbolic directions became popular, as operational calculus, and pushed to the point of diminishing returns. The Cauchy concept of limit was kept at bay. Woodhouse had already founded this second "British Lagrangian School" with its treatment of Taylor series as formal.
In this context function composition is complicated to express, because the chain rule is not simply applied to second and higher derivatives. This matter was known to Woodhouse by 1803, who took from Louis François Antoine Arbogast what is now called Faà di Bruno's formula (a misnomer). In essence it was known to Abraham De Moivre (1697). Herschel found the method impressive, Babbage knew of it, and it was later noted by Ada Lovelace as compatible with the analytical engine. In the period to 1820 Babbage worked intensively on functional equations in general, and resisted both conventional finite differences and Arbogast's approach (in which Δ and D were related by the simple additive case of the exponential map). But via Herschel he was influenced by Arbogast's ideas in the matter of iteration, i.e. composing a function with itself, possibly many times. Writing in a major paper on functional equations in the "Philosophical Transactions" (1815/6), Babbage said his starting point was work of Gaspard Monge.
Academic.
From 1828 to 1839 Babbage was Lucasian Professor of Mathematics at Cambridge. Not a conventional resident don, and inattentive to teaching, he wrote three topical books during this period of his life. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1832. Babbage was out of sympathy with colleagues: George Biddell Airy, his predecessor as Lucasian Professor of Mathematics at Trinity College, Cambridge, thought an issue should be made of his lack of interest in lecturing. Babbage planned to lecture in 1831 on political economy. Babbage's reforming direction looked to see university education more inclusive, universities doing more for research, a broader syllabus and more interest in applications; but William Whewell found the programme unacceptable. A controversy Babbage had with Richard Jones lasted for six years. He never did give a lecture.
It was during this period that Babbage tried to enter politics. Simon Schaffer writes that his views of the 1830s included disestablishment of the Church of England, a broader political franchise, and inclusion of manufacturers as stakeholders. He twice stood for Parliament as a candidate for the borough of Finsbury. In 1832 he came in third among five candidates, missing out by some 500 votes in the two-member constituency when two other reformist candidates, Thomas Wakley and Christopher Temple, split the vote. In his memoirs Babbage related how this election brought him the friendship of Samuel Rogers: his brother Henry Rogers wished to support Babbage again, but died within days. In 1834 Babbage finished last among four. In 1832, Babbage, Herschel and Ivory were appointed Knights of the Royal Guelphic Order, however they were not subsequently made knights bachelor to entitle them to the prefix "Sir", which often came with appointments to that foreign order (though Herschel was later created a baronet).
"Declinarians", learned societies and the BAAS.
Babbage now emerged as a polemicist. One of his biographers notes that all his books contain a "campaigning element". His "Reflections on the Decline of Science and some of its Causes" (1830) stands out, however, for its sharp attacks. It aimed to improve British science, and more particularly to oust Davies Gilbert as President of the Royal Society, which Babbage wished to reform. It was written out of pique, when Babbage hoped to become the junior secretary of the Royal Society, as Herschel was the senior, but failed because of his antagonism to Humphry Davy. Michael Faraday had a reply written, by Gerrit Moll, as "On the Alleged Decline of Science in England" (1831). On the front of the Royal Society Babbage had no impact, with the bland election of the Duke of Sussex to succeed Gilbert the same year. As a broad manifesto, on the other hand, his "Decline" led promptly to the formation in 1831 of the British Association for the Advancement of Science (BAAS).
The "Mechanics' Magazine" in 1831 identified as Declinarians the followers of Babbage. In an unsympathetic tone it pointed out David Brewster writing in the "Quarterly Review" as another leader; with the barb that both Babbage and Brewster had received public money.
In the debate of the period on statistics ("qua" data collection) and what is now statistical inference, the BAAS in its Statistical Section (which owed something also to Whewell) opted for data collection. This Section was the sixth, established in 1833 with Babbage as chairman and John Elliot Drinkwater as secretary. The foundation of the Statistical Society followed. Babbage was its public face, backed by Richard Jones and Robert Malthus.
"On the Economy of Machinery and Manufactures".
Babbage published "On the Economy of Machinery and Manufactures" (1832), on the organisation of industrial production. It was an influential early work of operational research. John Rennie the Younger in addressing the Institute of Civil Engineers on manufacturing in 1846 mentioned mostly surveys in encyclopaedias, and Babbage's book was first an article in the "Encyclopædia Metropolitana", the form in which Rennie noted it, in the company of related works by John Farey, Jr., Peter Barlow and Andrew Ure. From "An essay on the general principles which regulate the application of machinery to manufactures and the mechanical arts" (1827), which became the "Encyclopædia Metropolitana" article of 1829, Babbage developed the schematic classification of machines that, combined with discussion of factories, made up the first part of the book. The second part considered the "domestic and political economy" of manufactures.
The book sold well, and quickly went to a fourth edition (1836). Babbage represented his work as largely a result of actual observations in factories, British and abroad. It was not, in its first edition, intended to address deeper questions of political economy; the second (late 1832) did, with three further chapters including one on piece rate. The book also contained ideas on rational design in factories, and profit sharing.
"Babbage principle".
In "Economy of Machinery" was described what is now called the "Babbage principle". It pointed out commercial advantages available with more careful division of labour. As Babbage himself noted, it had already appeared in the work of Melchiorre Gioia in 1815. The term was introduced in 1974 by Harry Braverman. Related formulations are the "principle of multiples" of Philip Sargant Florence, and the "balance of processes".
What Babbage remarked is that skilled workers typically spend parts of their time performing tasks that are below their skill level. If the labour process can be divided among several workers, labour costs may be cut by assigning only high-skill tasks to high-cost workers, restricting other tasks to lower-paid workers. He also pointed out that training or apprenticeship can be taken as fixed costs; but that returns to scale are available by his approach of standardisation of tasks, therefore again favouring the factory system. His view of human capital was restricted to minimising the time period for recovery of training costs.
Publishing.
Another aspect of the work was its detailed breakdown of the cost structure of book publishing. Babbage took the unpopular line, from the publishers' perspective, of exposing the trade's profitability. He went as far as to name the organisers of the trade's restrictive practices. Twenty years later he attended a meeting hosted by John Chapman to campaign against the Booksellers Association, still a cartel.
Influence.
It has been written that "what Arthur Young was to agriculture, Charles Babbage was to the factory visit and machinery". Babbage's theories are said to have influenced the layout of the 1851 Great Exhibition, and his views had a strong effect on his contemporary George Julius Poulett Scrope. Karl Marx argued that the source of the productivity of the factory system was exactly the combination of the division of labour with machinery, building on Adam Smith, Babbage and Ure. Where Marx picked up on Babbage and disagreed with Smith was on the motivation for division of labour by the manufacturer: as Babbage did, he wrote that it was for the sake of profitability, rather than productivity, and identified an impact on the concept of a trade.
John Ruskin went further, to oppose completely what manufacturing in Babbage's sense stood for. Babbage also affected the economic thinking of John Stuart Mill. George Holyoake saw Babbage's detailed discussion of profit sharing as substantive, in the tradition of Robert Owen and Charles Fourier, if requiring the attentions of a benevolent captain of industry, and ignored at the time.
Works by Babbage and Ure were published in French translation in 1830; "On the Economy of Machinery" was translated in 1833 into French by Édouard Biot, and into German the same year by Gottfried Friedenberg. The French engineer and writer on industrial organisation Léon Lalanne was influenced by Babbage, but also by the economist Claude Lucien Bergery, in reducing the issues to "technology". William Jevons connected Babbage's "economy of labour" with his own labour experiments of 1870. The Babbage principle is an inherent assumption in Frederick Winslow Taylor's scientific management.
Natural theology.
In 1837, responding to the series of eight "Bridgewater Treatises", Babbage published his "Ninth Bridgewater Treatise", under the title "On the Power, Wisdom and Goodness of God, as manifested in the Creation". In this work Babbage weighed in on the side of uniformitarianism in a current debate. He preferred the conception of creation in which a God-given natural law dominated, removing the need for continuous "contrivance".
The book is a work of natural theology, and incorporates extracts from related correspondence of Herschel with Charles Lyell. Babbage put forward the thesis that God had the omnipotence and foresight to create as a divine legislator. In this book, Babbage dealt with relating interpretations between science and religion; on the one hand, he insisted that ""there exists no fatal collision between the words of Scripture and the facts of nature;"" on the one hand, he wrote the Book of Genesis was not meant to be read literally in relation to scientific terms. Against those who said these were in conflict, he wrote ""that the contradiction they have imagined can have no real existence, and that whilst the testimony of Moses remains unimpeached, we may also be permitted to confide in the testimony of our senses.""
The Ninth Bridgewater Treatise was quoted extensively in "Vestiges of the Natural History of Creation". The parallel with Babbage's computing machines is made explicit, as allowing plausibility to the theory that transmutation of species could be pre-programmed.
Jonar Ganeri, author of "Indian Logic", believes Babbage may have been influenced by Indian thought; one possible route would be through Henry Thomas Colebrooke. Mary Everest Boole argues that Babbage was introduced to Indian thought in the 1820s by her uncle George Everest:
Some time about 1825, came to England for two or three years, and made a fast and lifelong friendship with Herschel and with Babbage, who was then quite young. I would ask any fair-minded mathematician to read Babbage's Ninth Bridgewater Treatise and compare it with the works of his contemporaries in England; and then ask himself whence came the peculiar conception of the nature of miracle which underlies Babbage's ideas of Singular Points on Curves (Chap, viii) – from European Theology or Hindu Metaphysic? Oh! how the English clergy of that day hated Babbage's book!
Religious views.
Babbage was raised in the Protestant form of the Christian faith, his family having inculcated in him an orthodox form of worship. He explained:
Rejecting the Athanasian Creed as a "direct contradiction in terms", in his youth he looked to Samuel Clarke's works on religion, of which "Being and Attributes of God" (1704) exerted a particularly strong influence on him. Later in life, Babbage concluded that "the true value of the Christian religion rested, not on speculative theology, but on "those doctrines of kindness and benevolence which that religion claims and enforces, not merely in favour of man himself but of every creature susceptible of pain or of happiness."
In his autobiography "Passages from the Life of a Philosopher" (1864), Babbage wrote a whole chapter on the topic of religion, where he identified three sources of divine knowledge:
He stated, on the basis of the design argument, that studying the works of nature had been the more appealing evidence, and the one which led him to actively profess the existence of God. Advocating for natural theology, he wrote:
Like Samuel Vince, Babbage also wrote a defense of the belief in divine miracles. Against objections previously posed by David Hume, Babbage advocated for the belief of divine agency, stating "we must not measure the credibility or incredibility of an event by the narrow sphere of our own experience, nor forget that there is a Divine energy which overrides what we familiarly call the laws of nature." He alluded to the limits of human experience, expressing: "all that we see in a miracle is an effect which is new to our observation, and whose cause is concealed. The cause may be beyond the sphere of our observation, and would be thus beyond the familiar sphere of nature; but this does not make the event a violation of any law of nature. The limits of man's observation lie within very narrow boundaries, and it would be arrogance to suppose that the reach of man's power is to form the limits of the natural world."
Later life.
The British Association was consciously modelled on the Deutsche Naturforscher-Versammlung, founded in 1822. It rejected romantic science as well as metaphysics, and started to entrench the divisions of science from literature, and professionals from amateurs. Belonging as he did to the "Wattite" faction in the BAAS, represented in particular by James Watt the younger, Babbage identified closely with industrialists. He wanted to go faster in the same directions, and had little time for the more gentlemanly component of its membership. Indeed, he subscribed to a version of conjectural history that placed industrial society as the culmination of human development (and shared this view with Herschel). A clash with Roderick Murchison led in 1838 to his withdrawal from further involvement. At the end of the same year he sent in his resignation as Lucasian professor, walking away also from the Cambridge struggle with Whewell. His interests became more focussed, on computation and metrology, and on international contacts.
Metrology programme.
A project announced by Babbage was to tabulate all physical constants (referred to as "constants of nature", a phrase in itself a neologism), and then to compile an encyclopaedic work of numerical information. He was a pioneer in the field of "absolute measurement". His ideas followed on from those of Johann Christian Poggendorff, and were mentioned to Brewster in 1832. There were to be 19 categories of constants, and Ian Hacking sees these as reflecting in part Babbage's "eccentric enthusiasms". Babbage's paper "On Tables of the Constants of Nature and Art" was reprinted by the Smithsonian Institution in 1856, with an added note that the physical tables of Arnold Henry Guyot "will form a part of the important work proposed in this article".
Exact measurement was also key to the development of machine tools. Here again Babbage is considered a pioneer, with Henry Maudslay, William Sellers, and Joseph Whitworth.
Engineer and inventor.
Through the Royal Society Babbage acquired the friendship of the engineer Marc Brunel. It was through Brunel that Babbage knew of Joseph Clement, and so came to encounter the artisans whom he observed in his work on manufactures. Babbage provided an introduction for Isambard Kingdom Brunel in 1830, for a contact with the proposed Bristol & Birmingham Railway. He carried out studies, around 1838, to show the superiority of the broad gauge for railways, used by Brunel's Great Western Railway.
In 1838, Babbage invented the pilot (also called a cow-catcher), the metal frame attached to the front of locomotives that clears the tracks of obstacles; he also constructed a dynamometer car. His eldest son, Benjamin Herschel Babbage, worked as an engineer for Brunel on the railways before emigrating to Australia in the 1850s.
Babbage also invented an ophthalmoscope, which he gave to Thomas Wharton Jones for testing. Jones, however, ignored it. The device only came into use after being independently invented by Hermann von Helmholtz.
Cryptography.
Babbage achieved notable results in cryptography, though this was still not known a century after his death. Letter frequency was category 18 of Babbage's tabulation project. Joseph Henry later defended interest in it, in the absence of the facts, as relevant to the management of movable type.
As early as 1845, Babbage had solved a cipher that had been posed as a challenge by his nephew Henry Hollier, and in the process, he made a discovery about ciphers that were based on Vigenère tables. Specifically, he realized that enciphering plain text with a keyword rendered the cipher text subject to modular arithmetic. During the Crimean War of the 1850s, Babbage broke Vigenère's autokey cipher as well as the much weaker cipher that is called Vigenère cipher today. His discovery was kept a military secret, and was not published. Credit for the result was instead given to Friedrich Kasiski, a Prussian infantry officer, who made the same discovery some years later. However, in 1854, Babbage published the solution of a Vigenère cipher, which had been published previously in the "Journal of the Society of Arts". In 1855, Babbage also published a short letter, "Cypher Writing", in the same journal. Nevertheless, his priority wasn't established until 1985.
Public nuisances.
Babbage involved himself in well-publicised but unpopular campaigns against public nuisances. He once counted all the broken panes of glass of a factory, publishing in 1857 a "Table of the Relative Frequency of the Causes of Breakage of Plate Glass Windows": Of 464 broken panes, 14 were caused by "drunken men, women or boys".
Babbage's distaste for commoners ("the Mob") included writing "Observations of Street Nuisances" in 1864, as well as tallying up 165 "nuisances" over a period of 80 days. He especially hated street music, and in particular the music of organ grinders, against whom he railed in various venues. The following quotation is typical: 
Babbage was not alone in his campaign. A convert to the cause was the MP Michael Thomas Bass.
In the 1860s, Babbage also took up the anti-hoop-rolling campaign. He blamed hoop-rolling boys for driving their iron hoops under horses' legs, with the result that the rider is thrown and very often the horse breaks a leg. Babbage achieved a certain notoriety in this matter, being denounced in debate in Commons in 1864 for "commencing a crusade against the popular game of tip-cat and the trundling of hoops."
Computing pioneer.
Babbage's machines were among the first mechanical computers. That they were not actually completed was largely because of funding problems and clashes of personality, most notably with Airy, the Astronomer Royal.
Babbage directed the building of some steam-powered machines that achieved some modest success, suggesting that calculations could be mechanised. For more than ten years he received government funding for his project, which amounted to £17,000, but eventually the Treasury lost confidence in him.
While Babbage's machines were mechanical and unwieldy, their basic architecture was similar to a modern computer. The data and program memory were separated, operation was instruction-based, the control unit could make conditional jumps, and the machine had a separate I/O unit.
John Tucker, Professor of Computer Science at Swansea University, argues that it was the Welsh mathematician Robert Recorde who first laid down the foundations of these concepts.
Background on mathematical tables.
In Babbage's time, printed mathematical tables were calculated by human computers, in other words by hand. They were central to navigation, science and engineering, as well as mathematics. Mistakes were known to occur in transcription as well as calculation.
At Cambridge, Babbage saw the fallibility of this process, and the opportunity of adding mechanisation into its management. His own account of his path towards mechanical computation references a particular occasion:
In 1812 he was sitting in his rooms in the Analytical Society looking at a table of logarithms, which he knew to be full of mistakes, when the idea occurred to him of computing all tabular functions by machinery. The French government had produced several tables by a new method. Three or four of their mathematicians decided how to compute the tables, half a dozen more broke down the operations into simple stages, and the work itself, which was restricted to addition and subtraction, was done by eighty computers who knew only these two arithmetical processes. Here, for the first time, mass production was applied to arithmetic, and Babbage was seized by the idea that the labours of the unskilled computers could be taken over completely by machinery which would be quicker and more reliable.
There was another period, seven years later, when his interest was aroused by the issues around computation of mathematical tables. The French official initiative by Gaspard de Prony, and its problems of implementation, were familiar to him. After the Napoleonic Wars came to a close, scientific contacts were renewed on the level of personal contact: in 1819 Charles Blagden was in Paris looking into the printing of the stalled de Prony project, and lobbying for the support of the Royal Society. In works of the 1820s and 1830s, Babbage referred in detail to de Prony's project.
Difference engine.
Babbage began in 1822 with what he called the difference engine, made to compute values of polynomial functions. It was created to calculate a series of values automatically. By using the method of finite differences, it was possible to avoid the need for multiplication and division.
For a prototype difference engine, Babbage brought in Joseph Clement to implement the design, in 1823. Clement worked to high standards, but his machine tools were particularly elaborate. Under the standard terms of business of the time, he could charge for their construction, and would also own them. He and Babbage fell out over costs around 1831.
Some parts of the prototype survive in the Museum of the History of Science, Oxford. This prototype evolved into the "first difference engine." It remained unfinished and the finished portion is located at the Science Museum in London. This first difference engine would have been composed of around 25,000 parts, weigh fifteen tons (13,600 kg), and would have been tall. Although Babbage received ample funding for the project, it was never completed. He later (1847–1849) produced detailed drawings for an improved version,"Difference Engine No. 2", but did not receive funding from the British government. His design was finally constructed in 1989–1991, using his plans and 19th century manufacturing tolerances. It performed its first calculation at the London Science Museum, returning results to 31 digits.
Nine years later, the Science Museum completed the printer Babbage had designed for the difference engine.
Completed models.
The London Science Museum has constructed two Difference Engines according to Babbage's plans for the Difference Engine No 2. One is owned by the museum. The other, owned by the technology multimillionaire Nathan Myhrvold, went on exhibition at the Computer History Museum in Mountain View, California on 10 May 2008. The two models that have been constructed are not replicas; Myhrvold's engine is the first design by Babbage, and the London Science Museum's is a later model.
Analytical Engine.
After the attempt at making the first difference engine fell through, Babbage worked to design a more complex machine called the Analytical Engine. He hired C. G. Jarvis, who had previously worked for Clement as a draughtsman. The Analytical Engine marks the transition from mechanised arithmetic to fully-fledged general purpose computation. It is largely on it that Babbage's standing as computer pioneer rests.
The major innovation was that the Analytical Engine was to be programmed using punched cards: the Engine was intended to use loops of Jacquard's punched cards to control a mechanical calculator, which could use as input the results of preceding computations. The machine was also intended to employ several features subsequently used in modern computers, including sequential control, branching and looping. It would have been the first mechanical device to be, in principle, Turing-complete. The Engine was not a single physical machine, but rather a succession of designs that Babbage tinkered with until his death in 1871.
Ada Lovelace and Italian followers.
Ada Lovelace corresponded with him during his development of the Analytical Engine. She is credited with developing an algorithm for the Analytical Engine to calculate a sequence of Bernoulli numbers. Although there is disagreement over how much of the ideas were Lovelace's own, she is often described as the first computer programmer. She also translated and wrote literature supporting the project. With respect to the engine's programming by punch cards, she once wrote: "We may say most aptly that the Analytical Engine weaves algebraical patterns just as the Jacquard-loom weaves flowers and leaves."
Babbage visited Turin in 1840 at the invitation of Giovanni Plana. In 1842 Charles Wheatstone approached Lovelace to translate a paper of Luigi Menabrea, who had taken notes of Babbage's Turin talks; and Babbage asked her to add something of her own. Fortunato Prandi who acted as interpreter in Turin was an Italian exile and follower of Giuseppe Mazzini.
Swedish followers.
Per Georg Scheutz wrote about the difference engine in 1830, and experimented in automated computation. After 1834 and Lardner's "Edinburgh Review" article he set up a project of his own, doubting whether Babbage's initial plan could be carried out. This he pushed through with his son, Edvard Scheutz. Another Swedish engine was that of Martin Wiberg (1860).
Legacy.
In 2011, researchers in Britain embarked on a multimillion-pound project, "Plan 28", to construct Babbage's Analytical Engine. Since Babbage's plans were continually being refined and were never completed, they intended to engage the public in the project and crowd-source the analysis of what should be built. It would have the equivalent of 675 bytes of memory, and run at a clock speed of about 7 Hz. They hope to complete it by the 150th anniversary of Babbage's death, in 2021.
Advances in MEMs and nanotechnology have led to recent high-tech experiments in mechanical computation. The benefits suggested include operation in high radiation or high temperature environments. These modern versions of mechanical computation were highlighted in "The Economist" in its special "end of the millennium" black cover issue in an article entitled "Babbage's Last Laugh".
Due to his association with the town Babbage was chosen in 2007 to appear on the 5 Totnes pound note.
Family.
On 25 July 1814, Babbage married Georgiana Whitmore at St. Michael's Church in Teignmouth, Devon; her sister Louisa married Edward Ryan. The couple lived at Dudmaston Hall, Shropshire (where Babbage engineered the central heating system), before moving to 5 Devonshire Street, Portland Place, London.
Charles and Georgiana had eight children,Also see </ref> but only four – Benjamin Herschel, Georgiana Whitmore, Dugald Bromhead and Henry Prevost – survived childhood. Charles' wife Georgiana died in Worcester on 1 September 1827, the same year as his father, their second son (also named Charles) and their newborn son Alexander.
His youngest son, Henry Prevost Babbage (1824–1918), went on to create six small demonstration pieces for Difference Engine No. 1 based on his father's designs, one of which was sent to Harvard University where it was later discovered by Howard H. Aiken, pioneer of the Harvard Mark I. Henry Prevost's 1910 Analytical Engine Mill, previously on display at Dudmaston Hall, is now on display at the Science Museum.
Death.
Babbage lived and worked for over 40 years at 1 Dorset Street, Marylebone, where he died, at the age of 79, on 18 October 1871; he was buried in London's Kensal Green Cemetery. According to Horsley, Babbage died "of renal inadequacy, secondary to cystitis." He had declined both a knighthood and baronetcy. He also argued against hereditary peerages, favouring life peerages instead.
Autopsy report.
In 1983 the autopsy report for Charles Babbage was discovered and later published by his great-great-grandson. A copy of the original is also available. Half of Babbage's brain is preserved at the Hunterian Museum in the Royal College of Surgeons in London. The other half of Babbage's brain is on display in the Science Museum, London.
Memorials.
There is a green plaque commemorating the 40 years Babbage spent at 1 Dorset Street, London. Locations, institutions and other things named after Babbage include:
In fiction and film.
Babbage frequently appears in steampunk works; he has been called an iconic figure of the genre. Other works in which Babbage appears include:

</doc>
<doc id="5700" url="https://en.wikipedia.org/wiki?curid=5700" title="Cross-dressing">
Cross-dressing

Cross-dressing is the act of wearing items of clothing and other accoutrements commonly associated with the opposite sex within a particular society. Cross-dressing has been used for purposes of disguise, comfort, and self-actualization in modern times and throughout history.
Almost every human society throughout history has had expected norms for each gender relating to style, color, or type of clothing they are expected to wear, and likewise most societies have had a set of guidelines, views or even laws defining what type of clothing is appropriate for each gender.
The term "cross-dressing" denotes an action or a behavior without attributing or implying any specific causes for that behavior. It is often assumed that the connotation is directly correlated with behaviors of transgender identity or sexual, fetishist, and homosexual behavior, but the term itself does not imply any motives and is not synonymous to one's gender identity.
History.
Cross-dressing has been practiced throughout much of recorded history and in many societies. There are many examples in Greek, Norse, and Hindu mythology. A reasonable number of historical figures are known to have cross-dressed to varying degrees and for a variety of reasons. There is a rich history of cross-dressing found in folklore, literature, theater, and music. Examples include Kabuki and Korean shamanism.
Varieties.
There are many different kinds of cross-dressing and many different reasons why an individual might engage in cross-dressing behavior. Some people cross-dress as a matter of comfort or style, out of personal preference for clothing associated with the opposite sex. In this case, a person's cross-dressing may or may not be apparent to other people. Some people cross-dress to shock others or challenge social norms.
Gender disguise has been used by women and girls to pass as male in society and by men and boys to pass themselves off as female. Gender disguise has also been used as a plot device in storytelling and is a recurring motif in literature, theater, and film. It is a common plot device in narrative ballads. Historically, some women have cross-dressed to take up male-dominated or male-exclusive professions, such as military service. Conversely, some men have cross-dressed to escape from mandatory military service or as a disguise to assist in political or social protest, as men did in the Rebecca Riots.
Single-sex theatrical troupes often have some performers who cross-dress to play roles written for members of the opposite sex (travesti). Cross-dressing, particularly the depiction of males wearing dresses, is often used for comic effect onstage and onscreen.
Drag is a special form of performance art based on the act of cross-dressing. A drag queen is usually a male-bodied person who performs as an exaggeratedly feminine character, in heightened costuming sometimes consisting of a showy dress, high-heeled shoes, obvious makeup, and wig. A drag queen may imitate famous female film or pop-music stars. A faux queen is a female-bodied person employing the same techniques.
A drag king is a counterpart of the drag queen but usually for much different audiences, and is defined as a female-bodied person who adopts a masculine persona in performance or imitates a male film or pop-music star. Some female-bodied people undergoing gender reassignment therapy also self-identify as "drag kings" although this use of "drag king" would generally be considered inaccurate.
A transvestic fetishist is a person (typically a heterosexual male) who cross-dresses as part of a sexual fetish.
The term "underdressing" is used by male cross-dressers to describe wearing female undergarments under their male clothes. The famous low-budget filmmaker Edward D. Wood, Jr. said he often wore women's underwear under his military uniform during World War II.
Some people who cross-dress may endeavor to project a complete impression of belonging to another gender, including mannerisms, speech patterns, and emulation of sexual characteristics. This is referred to as passing or "trying to pass" depending how successful the person is. An observer who sees through the cross-dresser's attempt to pass is said to have "read" or "clocked" them. There are videos, books, and magazines on how a man may look more like a woman.
"Female masking" is a form of cross-dressing in which men wear masks that present them as female.
Sometimes either member of a heterosexual couple will crossdress in order to arouse the other. For example, the male might wear skirts or lingerie and/or the female will wear boxers or other male clothing. (See also forced feminization)
Others may choose to take a mixed approach, adopting some feminine traits and some masculine traits in their appearance. For instance, a man might wear both a dress and a beard. This is sometimes known as "genderfuck".
Clothes.
The actual determination of cross-dressing is largely socially constructed. For example, in Western society, trousers have been adopted for usage by women, and it is not regarded as cross-dressing. In cultures where men have traditionally worn skirt-like garments such as the kilt or sarong, these are not seen as female clothing, and wearing them is not seen as cross-dressing for men. As societies are becoming more global in nature, both men's and women's clothing are adopting styles of dress associated with other cultures.
It was once considered taboo in Western society for women to wear clothing traditionally associated with men, except when done in certain circumstances such as cases of necessity (as per St. Thomas Aquinas's guidelines in "Summa Theologiae II").
While this prohibition remained in force in general throughout the Middle Ages and early modern era, this is no longer the case and Western women are often seen wearing trousers, ties, and men's hats. Nevertheless, many cultures around the world still prohibit women from wearing trousers or other traditionally male clothing.
Cosplaying may also involve cross-dressing, for some females may wish to dress as a male, and vice versa (see Crossplay). Breast binding (for females) is not uncommon and is one of the things likely needed to cosplay a male character.
In most parts of the world it remains socially disapproved for men to wear clothes traditionally associated with women. Attempts are occasionally made, e.g. by fashion designers, to promote the acceptance of skirts as everyday wear for men. Cross-dressers have complained that society permits women to wear pants or jeans and other masculine clothing, while condemning any man who wants to wear clothing sold for women.
While creating a more feminine figure, male cross-dressers will often utilize different types and styles of breast forms, which are silicone prostheses traditionally used by women who have undergone mastectomies to recreate the visual appearance of a breast.
While most male cross-dressers utilize clothing associated with modern women, there are some who are involved in subcultures that involve dressing as little girls or in vintage clothing. Some such men have written that they enjoy dressing as femininely as possible, so they will wear frilly dresses with lace and ribbons, bridal gowns complete with veils, as well as multiple petticoats, corsets, girdles and/or garter belts with nylon stockings.
Social issues.
Cross-dressers may begin wearing clothing associated with the opposite sex in childhood, using the clothes of a sibling, parent, or friend. Some parents have said they allowed their children to cross-dress and, in many cases, the child stopped when they became older. The same pattern often continues into adulthood, where there may be confrontations with a spouse. Married cross-dressers experience considerable anxiety and guilt if their spouse objects to their behavior. Sometimes cross-dressers have periodically disposed of all their clothing, a practice called "purging", only to start collecting other gender's clothing again.
Analysis.
The historical associations of maleness with power and femaleness with submission and frivolity mean that in the present time a woman dressing in men's clothing and a man dressing in women's clothing evoke very different responses. A woman dressing in men's clothing is considered to be a more acceptable activity.
Advocacy for social change has done much to relax the constrictions of gender roles on men and women, but they are still subject to prejudice from some people. It is noticeable that as 'transgender' is becoming more socially accepted as a normal human condition, the prejudices against cross-dressing are changing quite quickly, just as the similar prejudices against homosexuals have changed rapidly in recent decades.
The reason it is so hard to have statistics for female-bodied crossdressers is that the line where non-crossdressing stops and crossdressing begins has become blurred, whereas the same line for men is as well defined as ever. This is one of the many issues being addressed by third wave feminism as well as the modern-day masculist movement.
Culture has very mixed views about cross-dressing. A woman who wears her husband's shirt to bed is considered attractive while a man who wears his wife's nightgown to bed may be considered transgressive. Marlene Dietrich in a tuxedo was considered very erotic; Jack Lemmon in a dress was considered ridiculous. All this may result from an overall gender role rigidity for males; that is, because of the prevalent gender dynamic throughout the world, men frequently encounter discrimination when deviating from masculine gender norms, particularly violations of heteronormativity. A man's adoption of feminine clothing is often considered a going down in the gendered social order whereas a woman's adoption of what are traditionally men's clothing (at least in the English-speaking world) has less of an impact because women have been traditionally subordinate to men, unable to affect serious change through style of dress. Thus when a male cross-dresser puts on his clothes, he transforms into the quasi-female and thereby becomes an embodiment of the conflicted gender dynamic. Following the work of Butler, gender proceeds along through ritualized performances, but in male cross-dressing it becomes a performative "breaking" of the masculine and a "subversive repetition" of the feminine.
Psychoanalysts today do not regard cross-dressing by itself as a psychological problem, unless it interferes with a person's life. "For instance," said Dr. Joseph Merlino, senior editor of "Freud at 150: 21st Century Essays on a Man of Genius", "that...I'm a cross-dresser and I don't want to keep it confined to my circle of friends, or my party circle, and I want to take that to my wife and I don't understand why she doesn't accept it, or I take it to my office and I don't understand why they don't accept it, then it's become a problem because it's interfering with my relationships and environment."
References.
Notes
Further reading

</doc>
<doc id="5702" url="https://en.wikipedia.org/wiki?curid=5702" title="Channel Tunnel">
Channel Tunnel

The Channel Tunnel (; also nicknamed and shortened to Chunnel) is a rail tunnel linking Folkestone, Kent, in the United Kingdom, with Coquelles, Pas-de-Calais, near Calais in northern France, beneath the English Channel at the Strait of Dover. At its lowest point, it is deep. At , the tunnel has the longest undersea portion of any tunnel in the world, although the Seikan Tunnel in Japan is both longer overall at and deeper at below sea level. The speed limit in the tunnel is .
The tunnel carries high-speed Eurostar passenger trains, the Eurotunnel Shuttle for road vehicles—the largest such transport in the world—and international freight trains. The tunnel connects end-to-end with the LGV Nord and High Speed 1 high-speed railway lines.
Ideas for a cross-Channel fixed link appeared as early as 1802, but British political and press pressure over the compromising of national security stalled attempts to construct a tunnel. An early attempt at building a Channel Tunnel was made in the late 19th century, on the English side "in the hope of forcing the hand of the English Government". The eventual successful project, organised by Eurotunnel, began construction in 1988 and opened in 1994. At £4.65 billion, the project came in 80% over its predicted budget. Since its construction, the tunnel has faced several problems. Both fires and cold weather have disrupted its operation. Illegal immigrants have attempted to use the tunnel to enter the UK, causing a minor diplomatic disagreement over the siting of the refugee camp at Sangatte, which was eventually closed in 2002.
Origins.
Earlier proposals.
In 1802, Albert Mathieu, a French mining engineer, put forward a proposal to tunnel under the English Channel, with illumination from oil lamps, horse-drawn coaches, and an artificial island mid-Channel for changing horses.
In the 1830s, Aimé Thomé de Gamond, a Frenchman, performed the first geological and hydrographical surveys on the Channel, between Calais and Dover. Thomé de Gamond explored several schemes and, in 1856, he presented a proposal to Napoleon III for a mined railway tunnel from Cap Gris-Nez to Eastwater Point with a port/airshaft on the Varne sandbank at a cost of 170 million francs, or less than £7 million.
In 1865, a deputation led by George Ward Hunt proposed the idea of a tunnel to the Chancellor of the Exchequer of the day, William Ewart Gladstone.
Around 1866, William Low and Sir John Hawkshaw promoted ideas, but apart from preliminary geological studies none were implemented. An official Anglo-French protocol was established in 1876 for a cross-Channel railway tunnel. In 1881, the British railway entrepreneur Sir Edward Watkin and Alexandre Lavalley, a French Suez Canal contractor, were in the Anglo-French Submarine Railway Company that conducted exploratory work on both sides of the Channel. On the English side a diameter Beaumont-English boring machine dug a pilot tunnel from Shakespeare Cliff. On the French side, a similar machine dug from Sangatte. The project was abandoned in May 1882, owing to British political and press campaigns asserting that a tunnel would compromise Britain's national defences. These early works were encountered more than a century later during the TML project.
In 1919, during the Paris Peace Conference, the British prime minister, David Lloyd George, repeatedly brought up the idea of a Channel tunnel as a way of reassuring France about British willingness to defend against another German attack. The French did not take the idea seriously and nothing came of Lloyd George's proposal.
In 1929 there was another proposal but nothing came of this discussion and the idea was shelved. Proponents estimated construction to be about US$150 million. The engineers had addressed the concerns of both nations' military leaders by designing two sumps—one near the coast of each country—that could be flooded at will to block the tunnel. This design feature did not override the concerns of both nations' military leaders, and other concerns about hordes of undesirable tourists who would disrupt English habits of living. Military fears continued during World War II. After the fall of France, as Britain prepared for an expected German invasion, a Royal Navy officer in the Directorate of Miscellaneous Weapons Development calculated that Hitler could use slave labour to build two Channel tunnels in 18 months. The estimate caused rumours that Germany had already begun digging.
In 1955, defence arguments were accepted to be irrelevant because of the dominance of air power, and both the British and French governments supported technical and geological surveys. In 1958 the 1881 workings were cleared in preparation for a £100,000 geological survey by the Channel Tunnel Study Group. 30% of the funding came from the Channel Tunnel Co Ltd, the largest shareholder of which was the British Transport Commission, as successor to the South Eastern Railway. A detailed geological survey was carried out in 1964–65.
Although the two countries agreed to build a tunnel in 1964, the phase 1 initial studies and signing of a second agreement to cover phase 2 took until 1973. Construction work of this government-funded project to create two tunnels designed to accommodate car shuttle wagons on either side of a service tunnel started on both sides of the Channel in 1974.
On 20 January 1975, to the dismay of their French partners, the now governing Labour Party in Britain cancelled the project due to uncertainty about EEC membership, doubling cost estimates and the general economic crisis at the time. By this time the British tunnel boring machine was ready and the Ministry of Transport was able to do a experimental drive. This short tunnel was reused as the starting and access point for tunnelling operations from the British side. The cancellation costs were estimated to be £17 million.
Initiation of project.
In 1979, the "Mouse-hole Project" was suggested when the Conservatives came to power in Britain. The concept was a single-track rail tunnel with a service tunnel, but without shuttle terminals. The British government took no interest in funding the project, but Margaret Thatcher, the prime minister, said she had no objection to a privately funded project. In 1981 Thatcher and François Mitterrand, the French president, agreed to set up a working group to look into a privately funded project, and in June 1982 the Franco-British study group favoured a twin tunnel to take conventional trains and a vehicle shuttle service. In April 1985 promoters were formally invited to submit scheme proposals. Four submissions were shortlisted:
The cross-Channel ferry industry protested under the name "Flexilink". In 1975 there was no campaign protesting against a fixed link, with one of the largest ferry operators (Sealink) being state-owned. Flexilink continued rousing opposition throughout 1986 and 1987. Public opinion strongly favoured a drive-through tunnel, but ventilation issues, concerns about accident management, and fear of driver mesmerisation led to the only shortlisted rail submission, CTG/F-M, being awarded the project in January 1986. Among reasons given for the selection was that it caused least disruption to shipping in the Channel, least environmental disruption, was the best protected against terrorism, and was the most likely to attract sufficient private finance.
Arrangement.
The British "Channel Tunnel Group" consisted of two banks and five construction companies, while their French counterparts, "France–Manche", consisted of three banks and five construction companies. The role of the banks was to advise on financing and secure loan commitments. On 2 July 1985, the groups formed Channel Tunnel Group/France–Manche (CTG/F–M). Their submission to the British and French governments was drawn from the 1975 project, including 11 volumes and a substantial environmental impact statement.
The design and construction was done by the ten construction companies in the CTG/F-M group. The French terminal and boring from Sangatte was undertaken by the five French construction companies in the joint venture group "GIE Transmanche Construction". The English Terminal and boring from Shakespeare Cliff was undertaken by the five British construction companies in the "Translink Joint Venture". The two partnerships were linked by TransManche Link (TML), a bi-national project organisation. The Maître d'Oeuvre was a supervisory engineering body employed by Eurotunnel under the terms of the concession that monitored project activity and reported back to the governments and banks.
In France, with its long tradition of infrastructure investment, the project garnered widespread approval. In April the French National Assembly gave unanimous support and, in June 1987, after a public inquiry, the Senate gave unanimous support. In Britain, select committees examined the proposal, making history by holding hearings away from Westminster, in Kent. In February 1987, the third reading of the Channel Tunnel Bill took place in the House of Commons, and was carried by 94 votes to 22. The Channel Tunnel Act gained Royal assent and passed into law in July. Parliamentary support for the project came partly from provincial members of Parliament on the basis of promises of regional Eurostar through train services that never materialised; the promises were repeated in 1996 when the contract for construction of the Channel Tunnel Rail Link was awarded.
The tunnel is a build-own-operate-transfer (BOOT) project with a concession. TML would design and build the tunnel, but financing was through a separate legal entity, Eurotunnel. Eurotunnel absorbed CTG/F-M and signed a construction contract with TML, but the British and French governments controlled final engineering and safety decisions, now in the hands of the Channel Tunnel Safety Authority. The British and French governments gave Eurotunnel a 55-year operating concession (from 1987; extended by 10 years to 65 years in 1993) to repay loans and pay dividends. A Railway Usage Agreement was signed between Eurotunnel, British Rail and SNCF guaranteeing future revenue in exchange for the railways obtaining half of the tunnel's capacity.
Private funding for such a complex infrastructure project was of unprecedented scale. An initial equity of £45 million was raised by CTG/F-M, increased by £206 million private institutional placement, £770 million was raised in a public share offer that included press and television advertisements, a syndicated bank loan and letter of credit arranged £5 billion. Privately financed, the total investment costs at 1985 prices were £2600 million. At the 1994 completion actual costs were, in 1985 prices, £4650 million: an 80% cost overrun. The cost overrun was partly due to enhanced safety, security, and environmental demands.
Construction.
Working from both the English side and the French side of the Channel, eleven tunnel boring machines or TBMs cut through chalk marl to construct two rail tunnels and a service tunnel. The vehicle shuttle terminals are at Cheriton (part of Folkestone) and Coquelles, and are connected to the English M20 and French A16 motorways respectively.
Tunnelling commenced in 1988, and the tunnel began operating in 1994. In 1985 prices, the total construction cost was £4.650 billion (equivalent to £ billion today), an 80% cost overrun. At the peak of construction 15,000 people were employed with daily expenditure over £3 million. Ten workers, eight of them British, were killed during construction between 1987 and 1993, most in the first few months of boring.
Completion.
A two-inch (50-mm) diameter pilot hole allowed the service tunnel to break through without ceremony on 30 October 1990. On 1 December 1990, Englishman Graham Fagg and Frenchman Phillippe Cozette broke through the service tunnel with the media watching. Eurotunnel completed the tunnel on time, Following the ceremony President Mitterrand and the Queen travelled on Le Shuttle to a similar ceremony in Folkestone. A full public service did not start for several months.
The Channel Tunnel Rail Link (CTRL), now called High Speed 1, runs from St Pancras railway station in London to the tunnel portal at Folkestone in Kent. It cost £5.8 billion. On 16 September 2003 the prime minister, Tony Blair, opened the first section of High Speed 1, from Folkestone to north Kent. On 6 November 2007 the Queen officially opened High Speed 1 and St Pancras International station, replacing the original slower link to Waterloo International railway station. High Speed 1 trains travel at up to , the journey from London to Paris taking 2 hours 15 minutes, to Brussels 1 hour 51 minutes.
In 1994, the American Society of Civil Engineers elected the tunnel as one of the seven modern Wonders of the World. In 1995, the American magazine "Popular Mechanics" published the results.
Engineering.
Surveying undertaken in the 20 years before construction confirmed earlier speculations that a tunnel could be bored through a chalk marl stratum. The chalk marl was conducive to tunnelling, with impermeability, ease of excavation and strength. On the English side the chalk marl ran along the entire length of the tunnel, but on the French a length of had variable and difficult geology. The tunnel consists of three bores: two diameter rail tunnels, apart, in length with a diameter service tunnel in between. There are also cross-passages and piston relief ducts. The service tunnel was used as a pilot tunnel, boring ahead of the main tunnels to determine the conditions. English access was provided at Shakespeare Cliff, French access from a shaft at Sangatte. The French side used five tunnel boring machines (TBMs), the English side six. The service tunnel uses Service Tunnel Transport System (STTS) and Light Service Tunnel Vehicles (LADOGS). Fire safety was a critical design issue.
Between the portals at Beussingue and Castle Hill the tunnel is long, with under land on the French side and on the UK side, and under sea. It is the second-longest rail tunnel in the world, behind the Seikan Tunnel in Japan, but with the longest under-sea section. The average depth is below the seabed. On the UK side, of the expected of spoil approximately was used for fill at the terminal site, and the remainder was deposited at Lower Shakespeare Cliff behind a seawall, reclaiming of land. This land was then made into the Samphire Hoe Country Park. Environmental impact assessment did not identify any major risks for the project, and further studies into safety, noise, and air pollution were overall positive. However, environmental objections were raised over a high-speed link to London.
Geology.
Successful tunnelling required a sound understanding of the topography and geology and the selection of the best rock strata through which to dig. The geology of this site generally consists of northeasterly dipping Cretaceous strata, part of the northern limb of the Wealden-Boulonnais dome. Characteristics include:
On the English side, the stratum dip is less than 5°; on the French side this increases to 20°. Jointing and faulting are present on both sides. On the English side, only minor faults of displacement less than exist; on the French side, displacements of up to are present owing to the Quenocs anticlinal fold. The faults are of limited width, filled with calcite, pyrite and remoulded clay. The increased dip and faulting restricted the selection of route on the French side. To avoid confusion, microfossil assemblages were used to classify the chalk marl. On the French side, particularly near the coast, the chalk was harder, more brittle and more fractured than on the English side. This led to the adoption of different tunnelling techniques on the two sides.
The Quaternary undersea valley Fosse Dangaered, and Castle Hill landslip at the English portal, caused concerns. Identified by the 1964–65 geophysical survey, the Fosse Dangaered is an infilled valley system extending below the seabed, south of the tunnel route in mid-channel. A 1986 survey showed that a tributary crossed the path of the tunnel, and so the tunnel route was made as far north and deep as possible. The English terminal had to be located in the Castle Hill landslip, which consists of displaced and tipping blocks of lower chalk, glauconitic marl and gault debris. Thus the area was stabilised by buttressing and inserting drainage adits. The service tunnel acted as a pilot preceding the main ones, so that the geology, areas of crushed rock, and zones of high water inflow could be predicted. Exploratory probing took place in the service tunnel, in the form of extensive forward probing, vertical downward probes and sideways probing.
Surveying.
Marine soundings and samplings by Thomé de Gamond were carried out during 1833–67, establishing the seabed depth at a maximum of and the continuity of geological strata (layers). Surveying continued over many years, with 166 marine and 70 land-deep boreholes being drilled and over 4,000-line-kilometres of marine geophysical survey completed. Surveys were undertaken in 1958–1959, 1964–1965, 1972–1974 and 1986–1988.
The surveying in 1958–59 catered for immersed tube and bridge designs as well as a bored tunnel, and thus a wide area was investigated. At this time, marine geophysics surveying for engineering projects was in its infancy, with poor positioning and resolution from seismic profiling. The 1964–65 surveys concentrated on a northerly route that left the English coast at Dover harbour; using 70 boreholes, an area of deeply weathered rock with high permeability was located just south of Dover harbour.
Given the previous survey results and access constraints, a more southerly route was investigated in the 1972–73 survey, and the route was confirmed to be feasible. Information for the tunnelling project also came from work before the 1975 cancellation. On the French side at Sangatte, a deep shaft with adits was made. On the English side at Shakespeare Cliff, the government allowed of diameter tunnel to be driven. The actual tunnel alignment, method of excavation and support were essentially the same as the 1975 attempt. In the 1986–87 survey, previous findings were reinforced, and the characteristics of the gault clay and the tunnelling medium (chalk marl that made up 85% of the route) were investigated. Geophysical techniques from the oil industry were employed.
Tunnelling.
Tunnelling was a major engineering challenge, with the only precedent being the undersea Seikan Tunnel in Japan. A serious risk with underwater tunnels is major water inflow due to the pressure from the sea above, under weak ground conditions. The tunnel also had the challenge of time: being privately funded, early financial return was paramount.
The objective was to construct two rail tunnels, apart, in length; a service tunnel between the two main ones; pairs of cross-passages linking the rail tunnels to the service one at spacing; piston relief ducts in diameter connecting the rail tunnels apart; two undersea crossover caverns to connect the rail tunnels, with the service tunnel always preceding the main ones by at least to ascertain the ground conditions. There was plenty of experience with excavating through chalk in the mining industry, while the undersea crossover caverns were a complex engineering problem. The French one was based on the Mount Baker Ridge freeway tunnel in Seattle; the UK cavern was dug from the service tunnel ahead of the main ones, to avoid delay.
Precast segmental linings in the main TBM drives were used, but two different solutions were used. On the French side, neoprene and grout sealed bolted linings made of cast iron or high-strength reinforced concrete were used; on the English side, the main requirement was for speed so bolting of cast-iron lining segments was only carried out in areas of poor geology. In the UK rail tunnels, eight lining segments plus a key segment were used; in the French side, five segments plus a key. On the French side, a diameter deep grout-curtained shaft at Sangatte was used for access. On the English side, a marshalling area was below the top of Shakespeare Cliff, the New Austrian Tunnelling method (NATM) was first applied in the chalk marl here. On the English side, the land tunnels were driven from Shakespeare Cliff - same place as the marine tunnels - not from Folkestone. The platform at the base of the cliff was not large enough for all of the drives and, despite environmental objections, tunnel spoil was placed behind a reinforced concrete seawall, on condition of placing the chalk in an enclosed lagoon, to avoid wide dispersal of chalk fines. Owing to limited space, the precast lining factory was on the Isle of Grain in the Thames estuary, which used Scottish granite aggregate delivered by ship from the Foster Yeoman coastal super quarry at Glensanda in Loch Linnhe on the west coast of Scotland.
On the French side, owing to the greater permeability to water, earth pressure balance TBMs with open and closed modes were used. The TBMs were of a closed nature during the initial , but then operated as open, boring through the chalk marl stratum. This minimised the impact to the ground, allowed high water pressures to be withstood and it also alleviated the need to grout ahead of the tunnel. The French effort required five TBMs: two main marine machines, one main land machine (the short land drives of allowed one TBM to complete the first drive then reverse direction and complete the other), and two service tunnel machines. On the English side, the simpler geology allowed faster open-faced TBMs. Six machines were used, all commenced digging from Shakespeare Cliff, three marine-bound and three for the land tunnels. Towards the completion of the undersea drives, the UK TBMs were driven steeply downwards and buried clear of the tunnel. These buried TBMs were then used to provide an electrical earth. The French TBMs then completed the tunnel and were dismantled. A gauge railway was used on the English side during construction.
In contrast to the English machines, which were given alphanumeric names, the French tunnelling machines were all named after women: Brigitte, Europa, Catherine, Virginie, Pascaline, Séverine.
Railway design.
Communications.
There are three communication systems: concession radio (CR) for mobile vehicles and personnel within Eurotunnel's Concession (terminals, tunnels, coastal shafts); track-to-train radio (TTR) for secure speech and data between trains and the railway control centre; Shuttle internal radio (SIR) for communication between shuttle crew and to passengers over car radios. This service was discontinued within one year of opening because of drivers' difficulty setting their radios to the correct frequency (88.8 MHz).
Power supply.
Power is delivered to the locomotives via an overhead line (catenary) at 25 kV AC railway electrification. All tunnel services run on electricity, shared equally from English and French sources. There are two sub-stations fed at 400 kV at each terminal, but in an emergency the tunnel's lighting (about 20,000 light fittings) and plant can be powered solely from either England or France.
The traditional railway south of London uses a 750 V DC third rail to deliver electricity, but since the opening of High Speed 1 there is no longer any need for tunnel trains to use the third rail system. High Speed 1, the tunnel and the LGV Nord all have power provided via overhead catenary at 25 kV 50 Hz. The railways on "classic" lines in Belgium are also electrified by overhead wires, but at 3000 V DC.
Signalling.
A cab signalling system gives information directly to train drivers on a display. There is a train protection system that stops the train if the speed exceeds that indicated on the in-cab display. TVM430, as used on LGV Nord and High Speed 1, is used in the tunnel. The TVM signalling is interconnected with the signalling on the high-speed lines either side, allowing trains to enter and exit the tunnel system without stopping. The maximum speed is .
Signalling in the tunnel is coordinated from two control centres: The main control centre at the Folkestone terminal, and a backup at the Calais terminal, which is staffed at all times and can take over all operations in the event of a breakdown or emergency.
Track system.
Conventional ballasted tunnel-track was ruled out owing to the difficulty of maintenance and lack of stability and precision. The Sonneville International Corporation's track system was chosen based on reliability and cost-effectiveness based on good performance in Swiss tunnels and worldwide. The type of track used is known as Low Vibration Track (LVT). Like ballasted track the LVT is of the free floating type, held in place by gravity and friction. Reinforced concrete blocks of 100 kg support the rails every 60 cm and are held by 12 mm thick closed cell polymer foam pads placed at the bottom of rubber boots. The latter separate the blocks' mass movements from the lean encasement concrete. Ballastless track provides extra overhead clearance necessary for the passage of larger trains. The corrugated rubber walls of the boots add a degree of isolation of horizontal wheel-rail vibrations, and are insulators of the track signal circuit in the humid tunnel environment. UIC60 (60 kg/m) rails of 900A grade rest on rail pads, which fit the RN/Sonneville bolted dual leaf-springs. The rails, LVT-blocks and their boots with pads were assembled outside the tunnel, in a fully automated process developed by the LVT inventor, Mr. Roger Sonneville. About 334,000 Sonneville blocks were made on the Sangatte site.
Maintenance activities are less than projected. Initially the rails were ground on a yearly basis or after approximately 100MGT of traffic. Ride quality continues to be noticeably smooth and of low noise. Maintenance is facilitated by the existence of two tunnel junctions or crossover facilities, allowing for two-way operation in each of the six tunnel segments thereby created, and thus providing safe access for maintenance of one isolated tunnel segment at a time. The two crossovers are the largest artificial undersea caverns ever built; 150 m long, 10 m high and 18 m wide. The English crossover is from Shakespeare Cliff, and the French crossover is from Sangatte.
Ventilation, cooling and drainage.
The ventilation system maintains the air pressure in the service tunnel higher than in the rail tunnels, so that in the event of a fire, smoke does not enter the service tunnel from the rail tunnels. Two cooling water pipes in each rail tunnel circulate chilled water to remove heat generated by the rail traffic. Pumping stations remove water in the tunnels from rain, seepage, and so on.
Rolling stock.
Eurotunnel Shuttle.
Initially 38 Le Shuttle locomotives were commissioned, with one at each end of a shuttle train. The shuttles have two separate halves: single and double deck. Each half has two loading/unloading wagons and 12 carrier wagons. Eurotunnel's original order was for nine tourist shuttles.
HGV (Heavy goods vehicle) shuttles also have two halves, with each half containing one loading wagon, one unloading wagon and 14 carrier wagons. There is a club car behind the leading locomotive. Eurotunnel originally ordered six HGV shuttle rakes.
Freight locomotives.
Forty-six Class 92 locomotives for hauling freight trains and overnight passenger trains (the Nightstar project, which was abandoned) were commissioned, running on both overhead AC and third-rail DC power. However, RFF does not let these run on French railways, so there are plans to certify Alstom Prima II locomotives for use in the tunnel.
International passenger.
Thirty-one Eurostar trains, based on the French TGV, built to UK loading gauge with many modifications for safety within the tunnel, were commissioned, with ownership split between British Rail, French national railways (SNCF) and Belgian national railways (SNCB). British Rail ordered seven more for services north of London. Around 2010, Eurostar ordered ten trains from Siemens based on its Velaro product.
Deutsche Bahn (DB) has since around 2005 tried to get permission to run train services to London. At the end of 2009, extensive fire-proofing requirements were dropped and DB received permission to run German Intercity-Express (ICE) test trains through the tunnel. In June 2013 DB was granted access to the tunnel. In June 2014 the plans were shelved, because there are special safety rules that requires custom made trains (DB calls them Class 407). Another problem was passengers would have to leave the train in Lille, go through passport and security checks and go back on board, because of British rules (the British Border Force refuses to do passport check on board).
Service locomotives.
Diesel locomotives for rescue and shunting work are Eurotunnel Class 0001 and Eurotunnel Class 0031.
Operation.
The following chart presents the estimated number of passengers and tonnes of freight, respectively, annually transported through the Channel Tunnel since 1994, in millions:
Usage and services.
Services offered by the tunnel are as follows:
Both the freight and passenger traffic forecasts that led to the construction of the tunnel were overestimated; in particular, Eurotunnel's commissioned forecasts were over-predictions. Although the captured share of Channel crossings was forecast correctly, high competition (especially from budget airlines which expanded rapidly in the 1990s and 2000s) and reduced tariffs led to low revenue. Overall cross-Channel traffic was overestimated.
With the EU's liberalisation of international rail services, the tunnel and High Speed 1 have been open to competition since 2010. There have been a number of operators interested in running trains through the tunnel and along High Speed 1 to London. In June 2013, after several years, DB obtained a license to operate Frankfurt – London trains, not expected to run before 2016 because of delivery delays of the custom-made trains.
Passenger traffic volumes.
Cross-tunnel passenger traffic volumes peaked at 18.4 million in 1998, dropped to 14.9 million in 2003, then rose to 21.0 million in 2014.
At the time of the decision about building the tunnel, 15.9 million passengers were predicted for Eurostar trains in the opening year. In 1995, the first full year, actual numbers were a little over 2.9 million, growing to 7.1 million in 2000, then dropping to 6.3 million in 2003. Eurostar was limited by the lack of a high-speed connection on the British side. After the completion of High Speed 1 in two stages in 2003 and 2007, traffic increased. In 2008, Eurostar carried 9,113,371 passengers, a 10% increase over the previous year, despite traffic limitations due to the 2008 Channel Tunnel fire. Eurostar passenger numbers continued to increase, reaching 10,397,894 in 2014.
Freight traffic volumes.
Freight volumes have been erratic, with a decrease during 1997 due to a closure caused by a fire in a freight shuttle. Freight crossings increased over the period, indicating the substitutability of the tunnel by sea crossings. The tunnel has achieved a market share close to or above Eurotunnel's 1980s predictions but Eurotunnel's 1990 and 1994 predictions were overestimates.
For through freight trains, the first year prediction was 7.2 million gross tonnes; the actual 1995 figure was 1.3M gross tonnes. Through freight volumes peaked in 1998 at 3.1M tonnes. This fell back to 1.21M tonnes in 2007, increasing slightly to 1.24M tonnes in 2008. Together with that carried on freight shuttles, freight growth has occurred since opening, with 6.4M tonnes carried in 1995, 18.4M tonnes recorded in 2003 and 19.6M tonnes in 2007. Numbers fell back in the wake of the 2008 fire.
Eurotunnel's freight subsidiary is Europorte 2. In September 2006 EWS, the UK's largest rail freight operator, announced that owing to cessation of UK-French government subsidies of £52 million per annum to cover the tunnel "Minimum User Charge" (a subsidy of around £13,000 per train, at a traffic level of 4,000 trains per annum), freight trains would stop running after 30 November.
Economic performance.
Shares in Eurotunnel were issued at £3.50 per share on 9 December 1987. By mid-1989 the price had risen to £11.00. Delays and cost overruns led to the price dropping; during demonstration runs in October 1994 it reached an all-time low. Eurotunnel suspended payment on its debt in September 1995 to avoid bankruptcy. In December 1997 the British and French governments extended Eurotunnel's operating concession by 34 years, to 2086. Financial restructuring of Eurotunnel occurred in mid-1998, reducing debt and financial charges. Despite the restructuring, "The Economist" reported in 1998 that to break even Eurotunnel would have to increase fares, traffic and market share for sustainability. A cost benefit analysis of the tunnel indicated that there were few impacts on the wider economy and few developments associated with the project, and that the British economy would have been better off if it had not been constructed.
Under the terms of the Concession, Eurotunnel was obliged to investigate a cross-Channel road tunnel. In December 1999 road and rail tunnel proposals were presented to the British and French governments, but it was stressed that there was not enough demand for a second tunnel. A three-way treaty between the United Kingdom, France and Belgium governs border controls, with the establishment of "control zones" wherein the officers of the other nation may exercise limited customs and law enforcement powers. For most purposes these are at either end of the tunnel, with the French border controls on the UK side of the tunnel and vice versa. For some city-to-city trains, the train is a control zone. A binational emergency plan coordinates UK and French emergency activities.
In 1999 Eurostar posted its first net profit, having made a loss of £925m in 1995. In 2005 Eurotunnel was described as being in a serious situation. In 2013, operating profits rose 4 per cent from 2012, to £54 million.
Security.
There is a need for full passport controls, since this is the border between the Schengen Area and the Common Travel Area. There are juxtaposed controls, meaning that passports are checked before boarding first by officials belonging to departing country and then officials of the destination country. These are only placed at the main Eurostar stations - (London, Ebbsfleet, Ashford, Calais, Lille, Brussels and Paris). There are security checks before boarding as well. For the shuttle road-vehicle trains, there are juxtaposed passport controls before boarding the trains.
For Eurostar trains travelling from places south of Paris, there is no passport and security check before departure, and those trains must stop in Lille at least 30 minutes to allow all passengers to be checked. No checks are done on board. There have been plans for services from Amsterdam, Frankfurt and Cologne to London, but a major reason to cancel them was the need for a stop in Lille.
The reason for juxtaposed controls is a wish to prevent illegal immigration before reaching British soil, and because a check of all passengers on a train can take 30 minutes, which creates long queues if done at arrival.
Terminals.
The terminal's sites are at Cheriton (near Folkestone in the United Kingdom) and Coquelles (near Calais in France). The terminals are designed to transfer vehicles from the motorway onto trains at a rate of 700 cars and 113 heavy vehicles per hour. The UK site uses the M20 motorway for access. The terminals are organised with the frontier controls juxtaposed with the entry to the system to allow travellers to go onto the motorway at the destination country immediately after leaving the shuttle. The area of the UK site was severely constrained and the design was challenging. The French layout was achieved more easily. To achieve design output, the shuttles accept cars on double-deck wagons; for flexibility, ramps were placed inside the shuttles to provide access to the top decks. At Folkestone there are of main-line track, 45 turnouts and eight platforms. At Calais there are of track and 44 turnouts. At the terminals the shuttle trains traverse a figure eight to reduce uneven wear on the wheels. There is a freight marshalling yard west of Cheriton at Dollands Moor Freight Yard.
Regional impact.
A 1996 report from the European Commission predicted that Kent and Nord-Pas de Calais had to face increased traffic volumes due to general growth of cross-Channel traffic and traffic attracted by the tunnel. In Kent, a high-speed rail line to London would transfer traffic from road to rail. Kent's regional development would benefit from the tunnel, but being so close to London restricts the benefits. Gains are in the traditional industries and are largely dependent on the development of Ashford International passenger station, without which Kent would be totally dependent on London's expansion. Nord-Pas-de-Calais enjoys a strong internal symbolic effect of the Tunnel which results in significant gains in manufacturing.
The removal of a bottleneck by means like the tunnel does not necessarily induce economic gains in all adjacent regions. The image of a region being connected to the European high-speed transport and active political response are more important for regional economic development. Some small-medium enterprises located in the immediate vicinity of the terminal have used the opportunity to re-brand the profile of their business with positive effect, such as "The New Inn" at Etchinghill which was able to commercially exploit its unique selling point as being 'the closest pub to the Channel Tunnel'. Tunnel-induced regional development is small compared to general economic growth. The South East of England is likely to benefit developmentally and socially from faster and cheaper transport to continental Europe, but the benefits are unlikely to be equally distributed throughout the region. The overall environmental impact is almost certainly negative.
Since the opening of the tunnel, small positive impacts on the wider economy have been felt, but it is difficult to identify major economic successes directly attributed to the tunnel. The Eurotunnel does operate profitably, offering an alternative transportation mode unaffected by poor weather. High costs of construction did delay profitability, however, and companies involved in the tunnel's construction and operation early in operation relied on government aid to deal with debts amounted.
Incidents.
Fires.
There have been three fires in the tunnel, all on the heavy goods vehicle (HGV) shuttles, that were significant enough to close the tunnel, as well as other more minor incidents.
During an "invitation only" testing phase on 9 December 1994, a fire broke out in a Ford Escort car whilst its owner was loading it on to the upper deck of a tourist shuttle. The fire started at about 10:00 with the shuttle train stationary in the Folkestone terminal and was put out about 40 minutes later with no passenger injuries.
On 18 November 1996, a fire broke out on an HGV shuttle wagon in the tunnel but nobody was seriously hurt. The exact cause is unknown, although it was not a Eurotunnel equipment or rolling stock problem; it may have been due to arson of a heavy goods vehicle. It is estimated that the heart of the fire reached , with the tunnel severely damaged over , with some affected to some extent. Full operation recommenced six months after the fire.
The tunnel was closed for several hours on 21 August 2006, when a truck on an HGV shuttle train caught fire.
On 11 September 2008, a fire occurred in the Channel Tunnel at 13:57 GMT. The incident started on an HGV shuttle train travelling towards France. The event occurred from the French entrance to the tunnel. No one was killed but several people were taken to hospitals suffering from smoke inhalation, and minor cuts and bruises. The tunnel was closed to all traffic, with the undamaged South Tunnel reopening for limited services two days later. Full service resumed on 9 February 2009 after repairs costing €60 million.
The tunnel was closed for several hours on 29 November 2012 after a truck on an HGV shuttle caught fire.
Both tunnels were closed on 17 January 2015 following a lorry fire which filled the midsection of Running Tunnel North with smoke. Eurostar cancelled all services. The shuttle train had been heading from Folkestone to Coquelles and stopped adjacent to cross-passage CP 4418 just before 12:30 UTC. Thirty-eight passengers and four members of Eurotunnel staff were evacuated into the service tunnel, and then transported to France using special STTS road vehicles in the Service Tunnel. The passengers and crew were taken to the Eurotunnel Fire/Emergency Management Centre close to the French portal.
Train failures.
On the night of 19/20 February 1996, about 1,000 passengers became trapped in the Channel Tunnel when Eurostar trains from London broke down owing to failures of electronic circuits caused by snow and ice being deposited and then melting on the circuit boards.
On 3 August 2007, an electrical failure lasting six hours caused passengers to be trapped in the tunnel on a shuttle.
On the evening of 18 December 2009, during the December 2009 European snowfall, five London-bound Eurostar trains failed inside the tunnel, trapping 2,000 passengers for approximately 16 hours, during the coldest temperatures in eight years. A Eurotunnel spokesperson explained that snow had evaded the train's winterisation shields, and that the transition from cold air outside to the tunnel's warm atmosphere had melted the snow, resulting in electrical failures. One train was turned back before reaching the tunnel; two trains were hauled out of the tunnel by Eurotunnel Class 0001 diesel locomotives. The blocking of the tunnel led to the implementation of Operation Stack, the transformation of the M20 motorway into a linear car park.
The occasion was the first time that a Eurostar train was evacuated inside the tunnel; the failing of four at once was described as "unprecedented". The Channel Tunnel reopened the following morning. Nirj Deva, Member of the European Parliament for South East England, had called for Eurostar chief executive Richard Brown to resign over the incidents. An independent report by Christopher Garnett (former CEO of Great North Eastern Railway) and Claude Gressier (a French transport expert) on the 18/19 December 2009 incidents was issued in February 2010, making 21 recommendations.
A Brussels–London Eurostar broke down in the tunnel on 7 January 2010. The train had 236 passengers on board and was towed to Ashford; other trains that had not yet reached the tunnel were turned back.
Asylum and immigration.
Illegal Immigrants and would-be asylum seekers have used the tunnel to attempt to enter Britain. By 1997 the problem had attracted international press attention, and the French Red Cross opened a refugee centre at Sangatte in 1999, using a warehouse once used for tunnel construction; by 2002 it housed up to 1,500 people at a time, most of them trying to get to the UK. In 2001, most came from Afghanistan, Iraq and Iran, but African and Eastern European countries were also represented.
Most illegal immigrants and would-be asylum seekers who got into Britain found some way to ride a freight train, but others used Eurostar. They would usually get onboard trucks, which would then get onto the freight trains. In a few instances, groups of men claiming to be refugees were able to sneak into a tanker truck carrying liquid chocolate and managed to survive, though they did not enter the UK in one attempt. Although the facilities were fenced, airtight security was deemed impossible; refugees would even jump from bridges onto moving trains. In several incidents people were injured during the crossing; others tampered with railway equipment, causing delays and requiring repairs. Eurotunnel said it was losing £5m per month because of the problem. A dozen refugees/illegal immigrants have died in crossing attempts.
In 2001 and 2002, several riots broke out at Sangatte and groups of refugees (up to 550 in a December 2001 incident) stormed the fences and attempted to enter "en masse". Immigrants have also arrived as legitimate Eurostar passengers without proper entry papers.
Local authorities in both France and the UK called for the closure of Sangatte, and Eurotunnel twice sought an injunction against the centre. The United Kingdom blamed France for allowing Sangatte to open, and France blamed the UK for its lax asylum rules and the EU for not having a uniform immigration policy. The "cause célèbre" nature of the problem even included journalists detained as they followed refugees onto railway property.
In 2002, after the European Commission told France that it was in breach of European Union rules on the free transfer of goods because of the delays and closures as a result of its poor security, a double fence was built at a cost of £5 million, reducing the numbers of refugees detected each week reaching Britain on goods trains from 250 to almost none. Other measures included CCTV cameras and increased police patrols. At the end of 2002, the Sangatte centre was closed after the UK agreed to take some of its refugees.
On 23 & 30 June 2015 striking workers associated with MyFerryLink damaged the sections of track by burning car tires, leading to all trains being cancelled and a backlog of vehicles. Hundreds seeking to reach Britain made use of the situation to attempt to stowaway inside and underneath transport trucks destined for the United Kingdom. Extra security measures including: £2-million upgrade of detection technology; £1 million extra for dog searches; £12 million (over three years) towards a joint fund with France for security surrounding the Port of Calais. The UK Home Office stated that approximately 19,000 attempts to cross the Channel during the first half of 2015 had been detected and prevented.
On 6 July 2015 a migrant died while attempting to climb onto a freight train while trying to reach Britain from the French side of the Channel. The previous month an Eritrean man was killed under similar circumstances.
Eurotunnel, the company that operates the crossing, said that it has intercepted more than 37,000 migrants since January 2015. During the night of 28 July 2015, one person aged 25–30, was found dead, after a night in which 1,500–2,000 refugees had attempted to enter the Eurotunnel terminal. According to the last official count in July 2015, about 3,000 migrants, mainly from Ethiopia, Eritrea, Sudan and Afghanistan, were living in the makeshift camps in Calais. It is estimated that about 5,000 refugees are waiting in the harbour town Calais to find a chance to get to England. Ten migrants have died near the Channel tunnel terminal since June 2015.
On 4 August 2015, a Sudanese migrant walked nearly the entire length of one of the tunnels. He was arrested close to the British side, after having walked about through the tunnel.
Safety.
The Channel Tunnel Safety Authority is responsible for some aspects of safety regulation in the tunnel; it reports to the IGC.
The service tunnel is used for access to technical equipment in cross-passages and equipment rooms, to provide fresh-air ventilation and for emergency evacuation. The Service Tunnel Transport System (STTS) allows fast access to all areas of the tunnel. The service vehicles are rubber-tyred with a buried wire guidance system. The 24 STTS vehicles are used mainly for maintenance but also for firefighting and in emergencies. "Pods" with different purposes, up to a payload of , are inserted into the side of the vehicles. The vehicles cannot turn around within the tunnel, and are driven from either end. The maximum speed is when the steering is locked. A fleet of 15 Light Service Tunnel Vehicles (LADOGS) was introduced to supplement the STTSs. The LADOGS have a short wheelbase with a turning circle, allowing two-point turns within the service tunnel. Steering cannot be locked like the STTS vehicles, and maximum speed is . Pods up to 1 tonne can be loaded onto the rear of the vehicles. Drivers in the tunnel sit on the right, and the vehicles drive on the left. Owing to the risk of French personnel driving on their native right side of the road, sensors in the vehicles alert the driver if the vehicle strays to the right side.
The three tunnels contain of air that needs to be conditioned for comfort and safety. Air is supplied from ventilation buildings at Shakespeare Cliff and Sangatte, with each building capable of providing 100% standby capacity. Supplementary ventilation also exists on either side of the tunnel. In the event of a fire, ventilation is used to keep smoke out of the service tunnel and move smoke in one direction in the main tunnel to give passengers clean air. The tunnel was the first main-line railway tunnel to have special cooling equipment. Heat is generated from traction equipment and drag. The design limit was set at , using a mechanical cooling system with refrigeration plants on both sides that run chilled water circulating in pipes within the tunnel.
Trains travelling at high speed create piston-effect pressure changes that can affect passenger comfort, ventilation systems, tunnel doors, fans and the structure of the trains, and drag on the trains. Piston relief ducts of diameter were chosen to solve the problem, with 4 ducts per kilometre to give close to optimum results. Unfortunately this design led to unacceptable lateral forces on the trains so a reduction in train speed was required and restrictors were installed in the ducts.
The safety issue of a possible fire on a passenger-vehicle shuttle garnered much attention, with Eurotunnel noting that fire was the risk attracting the most attention in a 1994 safety case for three reasons: the opposition of ferry companies to passengers being allowed to remain with their cars; Home Office statistics indicating that car fires had doubled in ten years; and the long length of the tunnel. Eurotunnel commissioned the UK Fire Research Station - now part of the Building Research Establishment - to give reports of vehicle fires, and liaised with Kent Fire Brigade to gather vehicle fire statistics over one year. Fire tests took place at the French Mines Research Establishment with a mock wagon used to investigate how cars burned. The wagon door systems are designed to withstand fire inside the wagon for 30 minutes, longer than the transit time of 27 minutes. Wagon air conditioning units help to purge dangerous fumes from inside the wagon before travel. Each wagon has a fire detection and extinguishing system, with sensing of ions or ultraviolet radiation, smoke and gases that can trigger halon gas to quench a fire. Since the HGV wagons are not covered, fire sensors are located on the loading wagon and in the tunnel. A water main in the service tunnel provides water to the main tunnels at intervals. The ventilation system can control smoke movement. Special arrival sidings accept a train that is on fire, as the train is not allowed to stop whilst on fire in the tunnel, unless continuing its journey would lead to a worse outcome. Eurotunnel has banned a wide range of hazardous goods from travelling in the tunnel. Two STTS (Service Tunnel Transportation System) vehicles with firefighting pods are on duty at all times, with a maximum delay of 10 minutes before they reach a burning train.
Unusual traffic.
In 2009, former F1 racing champion John Surtees drove a Ginetta G50 EV electronic sports car prototype from England to France, using the service tunnel, as part of a charity event. He was required to keep to the speed limit. To celebrate the Tour de France moving from Britain to France in July 2014, Chris Froome of Team Sky rode a bicycle through the service tunnel, becoming the first solo rider to do so. The Crossing took under an hour, reaching speeds of 40 mph–faster than most cross-channel ferries.
Mobile network coverage.
Since 2012, French operators Bouygues Telecom, Orange and SFR have covered Running Tunnel South, the tunnel bore normally used for travel from France to Britain.
In January 2014, UK operators EE and Vodafone signed ten-year contracts with Eurotunnel for Running Tunnel North. The agreements will enable both operators' subscribers to use 2G and 3G services. Both EE and Vodafone plan to offer LTE services on the route; EE said it expected to cover the route with LTE connectivity by summer 2014. EE and Vodafone will offer Channel Tunnel network coverage for travellers from the UK to France. Eurotunnel said it also held talks with Three UK but has yet to reach an agreement with the operator.
On 6 May 2014, Eurotunnel announced that they had installed equipment from Alcatel-Lucent to cover Running Tunnel North and simultaneously to provide mobile service (GSM 900/1800 MHz and UMTS 2100 MHz) by EE, O2 and Vodafone. The service of EE and Vodafone commenced on the same date as the announcement. O2 service was expected to be available soon afterwards.
On 21 November 2014, EE announced that it had previously switched on LTE earlier in September 2014. O2 turned on 2G, 3G and 4G services in November 2014. Whilst Vodafone's 4G was due to go live later.

</doc>
<doc id="5703" url="https://en.wikipedia.org/wiki?curid=5703" title="Cyberpunk">
Cyberpunk

Cyberpunk, a subgenre of science fiction in a future setting, tends to focus on the society of the proverbial "high tech low life"; featuring advanced technological and scientific achievements, such as information technology and cybernetics, juxtaposed with a degree of breakdown or radical change in the social order.
Cyberpunk plots often center on conflict among artificial intelligences and among megacorporations, and tend to be set in a future Earth, rather than in the far-future settings or galactic vistas found in novels such as Isaac Asimov's "Foundation" or Frank Herbert's "Dune". The settings are usually post-industrial dystopias but tend to feature extraordinary cultural ferment and the use of technology in ways never anticipated by its original inventors ("the street finds its own uses for things"). Much of the genre's atmosphere echoes film noir, and written works in the genre often use techniques from detective fiction.
Style and ethos.
Primary exponents of the cyberpunk field include William Gibson, Neal Stephenson, Bruce Sterling, Bruce Bethke, Pat Cadigan, Rudy Rucker, and John Shirley.
"Blade Runner" can be seen as a quintessential example of the cyberpunk style and theme. Video games, board games, and tabletop role-playing games, such as "Cyberpunk 2020" and "Shadowrun", often feature storylines that are heavily influenced by cyberpunk writing and movies. Beginning in the early 1990s, some trends in fashion and music were also labeled as cyberpunk. Cyberpunk is also featured prominently in anime and manga: "Akira", "Gunnm", "Ghost in the Shell", "Serial Experiments Lain", "Dennou Coil", "Ergo Proxy" and "Psycho Pass" being among the most notable.
Setting.
Cyberpunk writers tend to use elements from hardboiled detective fiction, film noir, and postmodernist prose to describe the often nihilistic underground side of an electronic society. The genre's vision of a troubled future is often called the antithesis of the generally utopian visions of the future popular in the 1940s and 1950s. Gibson defined cyberpunk's antipathy towards utopian SF in his 1981 short story "The Gernsback Continuum," which pokes fun at and, to a certain extent, condemns utopian science fiction.
In some cyberpunk writing, much of the action takes place online, in cyberspace, blurring the border between actual and virtual reality. A typical trope in such work is a direct connection between the human brain and computer systems. Cyberpunk settings are dystopias with corruption, computers and internet connectivity. Giant, multinational corporations have for the most part replaced governments as centers of political, economic, and even military power.
The economic and technological state of Japan in the 80s influenced Cyberpunk literature at the time. Of Japan's influence on the genre, William Gibson said, "Modern Japan simply was cyberpunk." Cyberpunk is often set in urbanized, artificial landscapes, and "city lights, receding" was used by Gibson as one of the genre's first metaphors for cyberspace and virtual reality.
Protagonists.
One of the cyberpunk genre's prototype characters is Case, from Gibson's "Neuromancer". Case is a "console cowboy," a brilliant hacker who has betrayed his organized criminal partners. Robbed of his talent through a crippling injury inflicted by the vengeful partners, Case unexpectedly receives a once-in-a-lifetime opportunity to be healed by expert medical care but only if he participates in another criminal enterprise with a new crew.
Like Case, many cyberpunk protagonists are manipulated, placed in situations where they have little or no choice, and although they might see things through, they do not necessarily come out any further ahead than they previously were. These anti-heroes—"criminals, outcasts, visionaries, dissenters and misfits"—call to mind the private eye of detective fiction. This emphasis on the misfits and the malcontents is the "punk" component of cyberpunk.
Society and government.
Cyberpunk can be intended to disquiet readers and call them to action. It often expresses a sense of rebellion, suggesting that one could describe it as a type of culture revolution in science fiction. In the words of author and critic David Brin:
...a closer look cyberpunk authors reveals that they nearly always portray future societies in which governments have become wimpy and pathetic ...Popular science fiction tales by Gibson, Williams, Cadigan and others "do" depict Orwellian accumulations of power in the next century, but nearly always clutched in the secretive hands of a wealthy or corporate elite.
Cyberpunk stories have also been seen as fictional forecasts of the evolution of the Internet. The earliest descriptions of a global communications network came long before the World Wide Web entered popular awareness, though not before traditional science-fiction writers such as Arthur C. Clarke and some social commentators such as James Burke began predicting that such networks would eventually form.
Media.
Literature.
The science-fiction editor Gardner Dozois is generally acknowledged as the person who popularized the use of the term "cyberpunk" as a kind of literature , although Minnesota writer Bruce Bethke coined the term in 1980 for his short story "Cyberpunk," which was published in the November 1983 issue of "Amazing Science Fiction Stories". The term was quickly appropriated as a label to be applied to the works of William Gibson, Bruce Sterling, Pat Cadigan and others. Of these, Sterling became the movement's chief ideologue, thanks to his fanzine "Cheap Truth." John Shirley wrote articles on Sterling and Rucker's significance. John Brunner's 1975 novel "The Shockwave Rider" is considered by many to be the first cyberpunk novel with many of the tropes commonly associated with the genre, some five years before the term was popularized by Dozois.
William Gibson with his novel "Neuromancer" (1984) is likely the most famous writer connected with the term cyberpunk. He emphasized style, a fascination with surfaces, and atmosphere over traditional science-fiction tropes. Regarded as ground-breaking and sometimes as "the archetypal cyberpunk work," "Neuromancer" was awarded the Hugo, Nebula, and Philip K. Dick Awards. "Count Zero" (1986) and "Mona Lisa Overdrive" (1988) followed after Gibson's popular debut novel. According to the Jargon File, "Gibson's near-total ignorance of computers and the present-day hacker culture enabled him to speculate about the role of computers and hackers in the future in ways hackers have since found both irritatingly naïve and tremendously stimulating."
Early on, cyberpunk was hailed as a radical departure from science-fiction standards and a new manifestation of vitality. Shortly thereafter, however, some critics arose to challenge its status as a revolutionary movement. These critics said that the SF New Wave of the 1960s was much more innovative as far as narrative techniques and styles were concerned. Furthermore, while "Neuromancer"'s narrator may have had an unusual "voice" for science fiction, much older examples can be found: Gibson's narrative voice, for example, resembles that of an updated Raymond Chandler, as in his novel "The Big Sleep" (1939). Others noted that almost all traits claimed to be uniquely cyberpunk could in fact be found in older writers' works—often citing J. G. Ballard, Philip K. Dick, Harlan Ellison, Stanisław Lem, Samuel R. Delany, and even William S. Burroughs. For example, Philip K. Dick's works contain recurring themes of social decay, artificial intelligence, paranoia, and blurred lines between objective and subjective realities, and the influential cyberpunk movie "Blade Runner" (1982) is based on his book, "Do Androids Dream of Electric Sheep?". Humans linked to machines are found in Pohl and Kornbluth's "Wolfbane" (1959) and Roger Zelazny's "Creatures of Light and Darkness" (1968).
In 1994, scholar Brian Stonehill suggested that Thomas Pynchon's 1973 novel "Gravity's Rainbow" "not only curses but precurses what we now glibly dub cyberspace." Other important predecessors include Alfred Bester's two most celebrated novels, "The Demolished Man" and "The Stars My Destination", as well as Vernor Vinge's novella "True Names".
Reception and impact.
Science-fiction writer David Brin describes cyberpunk as "the finest free promotion campaign ever waged on behalf of science fiction." It may not have attracted the "real punks," but it did ensnare many new readers, and it provided the sort of movement that postmodern literary critics found alluring. Cyberpunk made science fiction more attractive to academics, argues Brin; in addition, it made science fiction more profitable to Hollywood and to the visual arts generally. Although the "self-important rhetoric and whines of persecution" on the part of cyberpunk fans were irritating at worst and humorous at best, Brin declares that the "rebels did shake things up. We owe them a debt."
Fredric Jameson considers cyberpunk the "supreme literary expression if not of postmodernism, then of late capitalism itself".
Cyberpunk further inspired many professional writers who were not among the "original" cyberpunks to incorporate cyberpunk ideas into their own works, such as George Alec Effinger's "When Gravity Fails". "Wired" magazine, created by Louis Rossetto and Jane Metcalfe, mixes new technology, art, literature, and current topics in order to interest today’s cyberpunk fans, which Paula Yoo claims "proves that hardcore hackers, multimedia junkies, cyberpunks and cellular freaks are poised to take over the world."
Film and television.
The film "Blade Runner" (1982)—adapted from Philip K. Dick's "Do Androids Dream of Electric Sheep?"—is set in 2019 in a dystopian future in which manufactured beings called replicants are slaves used on space colonies and are legal prey on Earth to various bounty hunters who "retire" (kill) them. Although "Blade Runner" was largely unsuccessful in its first theatrical release, it found a viewership in the home video market and became a cult film. Since the movie omits the religious and mythical elements of Dick's original novel (e.g. empathy boxes and Wilbur Mercer), it falls more strictly within the cyberpunk genre than the novel does. William Gibson would later reveal that upon first viewing the film, he was surprised at how the look of this film matched his vision when he was working on "Neuromancer". The film's tone has since been the staple of many cyberpunk movies, such as "The Matrix" (1999), which uses a wide variety of cyberpunk elements.
The number of films in the genre or at least using a few genre elements has grown steadily since "Blade Runner". Several of Philip K. Dick's works have been adapted to the silver screen. The films "Johnny Mnemonic" and "New Rose Hotel", both based upon short stories by William Gibson, flopped commercially and critically.
In addition, "tech-noir" film as a hybrid genre, means a work of combining neo-noir and science fiction or cyberpunk. It includes many cyberpunk films such as "Blade Runner", "Burst City", "The Terminator", "Robocop", "12 Monkeys", "The Lawnmower Man", "Hackers", "Hardware", and "Strange Days."
Anime and manga.
Cyberpunk themes are widely visible in anime and manga. In Japan, where cosplay is popular and not only teenagers display such fashion styles, cyberpunk has been accepted and its influence is widespread. William Gibson’s "Neuromancer," whose influence dominated the early cyberpunk movement, was also set in Chiba, one of Japan’s largest industrial areas, although at the time of writing the novel Gibson did not know the location of Chiba and had no idea how perfectly it fit his vision in some ways. The exposure to cyberpunk ideas and fiction in the mid 1980s has allowed it to seep into the Japanese culture.
Cyberpunk anime and manga draw upon a futuristic vision which has elements in common with western science fiction and therefore have received wide international acceptance outside Japan. “The conceptualization involved in cyberpunk is more of forging ahead, looking at the new global culture. It is a culture that does not exist right now, so the Japanese concept of a cyberpunk future, seems just as valid as a Western one, especially as Western cyberpunk often incorporates many Japanese elements.” William Gibson is now a frequent visitor to Japan, and he came to see that many of his visions of Japan have become a reality:
Modern Japan simply was cyberpunk. The Japanese themselves knew it and delighted in it. I remember my first glimpse of Shibuya, when one of the young Tokyo journalists who had taken me there, his face drenched with the light of a thousand media-suns—all that towering, animated crawl of commercial information—said, "You see? You see? It is "Blade Runner" town." And it was. It so evidently was.
Cyberpunk has influenced many anime and manga including the ground-breaking "Akira", "Ghost in the Shell", "Ergo Proxy", "Battle Angel Alita", "Megazone 23", "Neo Tokyo", "Goku Midnight Eye", "Cyber City Oedo 808", "Bubblegum Crisis", "", "Angel Cop", "Extra", "Blame!", "Armitage III", "Texhnolyze, Neon Genesis Evangelion" and "Psycho-Pass".
Games.
There are many cyberpunk video games. Popular series include the "Metal Gear" series, "Megami Tensei" series, "Deus Ex" series, "Syndicate" series, and "System Shock" and its sequel. Other games, like "Blade Runner", "Ghost in the Shell", and the "Matrix" series, are based upon genre movies, or role-playing games (for instance the various "Shadowrun" games). CD Projekt RED are currently developing a cyberpunk game, "Cyberpunk 2077".
Several role-playing games (RPGs) called "Cyberpunk" exist: "Cyberpunk", "Cyberpunk 2020" and "Cyberpunk v3", by R. Talsorian Games, and "GURPS Cyberpunk", published by Steve Jackson Games as a module of the GURPS family of RPGs. "Cyberpunk 2020" was designed with the settings of William Gibson's writings in mind, and to some extent with his approval, unlike the approach taken by FASA in producing the transgenre "Shadowrun" game. Both are set in the near future, in a world where cybernetics are prominent. In addition, Iron Crown Enterprises released an RPG named "Cyberspace", which was out of print for several years until recently being re-released in online PDF form.
In 1990, in a convergence of cyberpunk art and reality, the United States Secret Service raided Steve Jackson Games's headquarters and confiscated all their computers. This was allegedly because the "GURPS Cyberpunk" sourcebook could be used to perpetrate computer crime. That was, in fact, not the main reason for the raid, but after the event it was too late to correct the public's impression. Steve Jackson Games later won a lawsuit against the Secret Service, aided by the new Electronic Frontier Foundation. This event has achieved a sort of notoriety, which has extended to the book itself as well. All published editions of "GURPS Cyberpunk" have a tagline on the front cover, which reads "The book that was seized by the U.S. Secret Service!" Inside, the book provides a summary of the raid and its aftermath.
Cyberpunk has also inspired several tabletop, miniature and board games such as "Necromunda" by Games Workshop. "Netrunner" is a collectible card game introduced in 1996, based on the "Cyberpunk 2020" role-playing game. "Tokyo NOVA", debuting in 1993, is a cyberpunk role-playing game that uses playing cards instead of dice.
Music.
Some musicians and acts have been classified as cyberpunk due to their aesthetic style and musical content. Often dealing with dystopian visions of the future or biomechanical themes, some fit more squarely in the category than others. Bands whose music has been classified as cyberpunk include Psydoll, Front Line Assembly, Clock DVA and Sigue Sigue Sputnik. Some musicians not normally associated with cyberpunk have at times been inspired to create concept albums exploring such themes. Albums such as Gary Numan's Replicas, The Pleasure Principle and Telekon were heavily inspired by the works of Philip K. Dick. Kraftwerk's The Man-Machine and Computer World albums both explored the theme of humanity becoming dependent on technology. Nine Inch Nails' concept album Year Zero also fits into this category. Billy Idol's "Cyberpunk" drew heavily from cyberpunk literature and the cyberdelic counter culture in its creation. "1. Outside", a cyberpunk narrative fueled concept album by David Bowie, was warmly met by critics upon its release in 1995. Many musicians have also taken inspiration from specific cyberpunk works or authors, including Sonic Youth, whose albums Sister and Daydream Nation take influence from the works of Phillip K. Dick and William Gibson respectively.
Vaporwave and Synthwave are also influenced by cyberpunk. The former has been interpreted as a dystopian critique of capitalism in the vein of cyberpunk and the latter as a nostalgic retrofuturistic revival of aspects of cyberpunk's origins.
Furthermore, many dubstep producers, such as Machine Man and Ghosthack, have found inspiration in cyberpunk themes for their works.
Social impact.
Art and architecture.
Some Neo-Futurism artworks and cityscapes have been influenced by cyberpunk, such as the Sony Center in the Potsdamer Platz public square of Berlin, Germany, Hong Kong, and Shanghai.
Society and counterculture.
Several subcultures have been inspired by cyberpunk fiction. These include the cyberdelic counter culture of the late 1980s and early 90s. Cyberdelic, whose adherents referred to themselves as "cyberpunks", attempted to blend the psychedelic art and drug movement with the technology of cyberculture. Early adherents included Timothy Leary, Mark Frauenfelder and R. U. Sirius. The movement largely faded following the dot-com bubble implosion of 2000.
Cybergoth is a fashion and dance subculture which draws its inspiration from cyberpunk fiction, as well as rave and Gothic subcultures. In addition, a distinct cyberpunk fashion of its own has emerged in recent years which rejects the raver and goth influences of cybergoth, and draws inspiration from urban street fashion, "post apocalypse", functional clothing, high tech sports wear, tactical uniform and multifunction. This fashion goes by names like "tech wear", "goth ninja" or "tech ninja". Important designers in this type of fashion are ACRONYM, Demobaza, Boris Bidjan Saberi, Rick Owens and Alexander Wang.
The Kowloon Walled City in Hong Kong (demolished in 1994) is often referenced as the model cyberpunk/dystopian slum as, given its poor living conditions at the time coupled by the city's political, physical, and economic isolation has caused many in academia to be fascinated by the ingenuity of its spawning.
Related genres.
As a wider variety of writers began to work with cyberpunk concepts, new subgenres of science fiction emerged, some of which could be considered as playing off the cyberpunk label, others which could be considered as legitimate explorations into newer territory. These focused on technology and its social effects in different ways. One prominent subgenre is "steampunk," which is set in an alternate history Victorian era that combines anachronistic technology with cyberpunk's bleak film noir world view. The term was originally coined around 1987 as a joke to describe some of the novels of Tim Powers, James P. Blaylock, and K.W. Jeter, but by the time Gibson and Sterling entered the subgenre with their collaborative novel "The Difference Engine" the term was being used earnestly as well.
Another subgenre is "biopunk" (cyberpunk themes dominated by biotechnology) from the early 1990s, a derivative style building on biotechnology rather than informational technology. In these stories, people are changed in some way not by mechanical means, but by genetic manipulation. Paul Di Filippo is seen as the most prominent biopunk writer, including his half-serious ribofunk. Bruce Sterling's Shaper/Mechanist cycle is also seen as a major influence. In addition, some people consider works such as Neal Stephenson's "The Diamond Age" to be postcyberpunk.
Cyberpunk works have been described as well-situated within postmodern literature.

</doc>
<doc id="5704" url="https://en.wikipedia.org/wiki?curid=5704" title="Comic strip">
Comic strip

A comic strip is a sequence of drawings arranged in interrelated panels to display brief humor or form a narrative, often serialized, with text in balloons and captions. Traditionally, throughout the 20th century and into the 21st, these have been published in newspapers and magazines, with horizontal strips printed in black-and-white in daily newspapers, while Sunday newspapers offered longer sequences in special color comics sections. With the development of the internet, they began to appear online as web comics.
There were more than 200 different comic strips and daily cartoon panels in American newspapers alone each day for most of the 20th century, for a total of at least 7,300,000 episodes.
Strips are written and drawn by a comics artist or cartoonist. As the name implies, comic strips can be humorous (for example, "gag-a-day" strips such as "Blondie", "Bringing Up Father", "Marmaduke", and "Pearls Before Swine").
Starting in the late 1920s, comic strips expanded from their mirthful origins to feature adventure stories, as seen in "Popeye", "Captain Easy", "Buck Rogers", "Tarzan", and "The Adventures of Tintin". Soap-opera continuity strips such as "Judge Parker" and "Mary Worth" gained popularity in the 1940s. All are called, generically, comic strips, though cartoonist Will Eisner has suggested that "sequential art" would be a better genre-neutral name.
In the UK and the rest of Europe, comic strips are also serialized in comic book magazines, with a strip's story sometimes continuing over three pages or more. Comic strips have appeared in American magazines such as "Liberty" and "Boys' Life" and also on the front covers of magazines, such as the "Flossy Frills" series on "The American Weekly" Sunday newspaper supplement.
History.
Storytelling using a sequence of pictures has existed through history. One medieval European example in textile form is the Bayeux Tapestry. Printed examples emerged in 19th-century Germany and in 18th-century England, where some of the first satirical or humorous sequential narrative drawings were produced. William Hogarth's 18th century English cartoons include both narrative sequences, such as "A Rake's Progress", and single panels.
The Biblia pauperum ("Paupers' Bible"), a tradition of picture Bibles beginning in the later Middle Ages, sometimes depicted Biblical events with words spoken by the figures in the miniatures written on scrolls coming out of their mouths—which makes them to some extent ancestors of the modern cartoon strips.
In China, with its traditions of block printing and of the incorporation of text with image, experiments with what became "lianhuanhua" date back to 1884.
Newspapers.
The first newspaper comic strips appeared in North America in the late 19th century. "The Yellow Kid" is usually credited as the first. However, the art form combining words and pictures developed gradually and there are many examples of proto-comic strips.
The Swiss teacher, author and caricature artist Rodolphe Töpffer (Geneva, 1799–1846) is considered the father of the modern comic strips. His illustrated stories such as "Histoire de M. Vieux Bois" (1827), first published in the USA in 1842 as "The Adventures of Obadiah Oldbuck" or "Histoire de Monsieur Jabot" (1831), inspired subsequent generations of German and American comic artists. In 1865, the German painter, author and caricaturist Wilhelm Busch created the strip "Max and Moritz", about two trouble-making boys, which had a direct influence on the American comic strip. "Max and Moritz" was a series of severely moralistic tales in the vein of German children's stories such as "Struwwelpeter" ("Shockheaded Peter"); in one, the boys, after perpetrating some mischief, are tossed into a sack of grain, run through a mill and consumed by a flock of geese. "Max and Moritz" provided an inspiration for German immigrant Rudolph Dirks, who created the "Katzenjammer Kids" in 1897. Familiar comic-strip iconography such as stars for pain, sawing logs for snoring, speech balloons, and thought balloons originated in Dirks' strip.
Hugely popular, "Katzenjammer Kids" occasioned one of the first comic-strip copyright ownership suits in the history of the medium. When Dirks left William Randolph Hearst for the promise of a better salary under Joseph Pulitzer, it was an unusual move, since cartoonists regularly deserted Pulitzer for Hearst. In a highly unusual court decision, Hearst retained the rights to the name "Katzenjammer Kids", while creator Dirks retained the rights to the characters. Hearst promptly hired Harold Knerr to draw his own version of the strip. Dirks renamed his version "Hans and Fritz" (later, "The Captain and the Kids"). Thus, two versions distributed by rival syndicates graced the comics pages for decades. Dirks' version, eventually distributed by United Feature Syndicate, ran until 1979.
In the United States, the great popularity of comics sprang from the newspaper war (1887 onwards) between Pulitzer and Hearst. "The Little Bears" (1893–96) was the first American comic with recurring characters, while the first color comic supplement was published by the "Chicago Inter-Ocean" sometime in the latter half of 1892, followed by the "New York Journal"'s first color Sunday comic pages in 1897. On January 31, 1912, Hearst introduced the nation's first full daily comic page in his "New York Evening Journal". The history of this newspaper rivalry and the rapid appearance of comic strips in most major American newspapers is discussed by Ian Gordon. Numerous events in newspaper comic strips have reverberated throughout society at large, though few of these events occurred in recent years, owing mainly to the declining role of the newspaper comic strip as an entertainment form.
The longest running American comic strips are:
Newspaper comic strips come in two different types: daily strips and Sunday strips. Most newspaper comic strips are syndicated; a syndicate hires people to write and draw a strip and then distributes it to many newspapers for a fee. A few newspaper strips are exclusive to one newspaper. For example, the "Pogo" comic strip by Walt Kelly originally appeared only in the "New York Star" in 1948 and was not picked up for syndication until the following year.
In the United States, a daily strip appears in newspapers on weekdays, Monday through Saturday, as contrasted with a Sunday strip, which typically only appears on Sundays. Daily strips usually are printed in black and white, and Sunday strips are usually in color. However, a few newspapers have published daily strips in color, and some newspapers have published Sunday strips in black and white. The two conventional formats for newspaper comics are strips and single gag panels. The strips are usually displayed horizontally, wider than they are tall. Single panels are square, circular or taller than they are wide. Strips usually, but not always, are broken up into several smaller panels with continuity from panel to panel. A horizontal strip can also be used for a single panel with a single gag, as seen occasionally in Mike Peters' "Mother Goose and Grimm".
During the 1930s, the original art for a daily strip could be drawn as large as 25 inches wide by six inches high. As strips have become smaller, the number of panels have been reduced.
The popularity and accessibility of strips meant they were often clipped and saved; authors including John Updike and Ray Bradbury have written about their childhood collections of clipped strips. Often posted on bulletin boards, clipped strips had an ancillary form of distribution when they were faxed, photocopied or mailed. The "Baltimore Sun"'s Linda White recalled, "I followed the adventures of "Winnie Winkle", "Moon Mullins" and "Dondi", and waited each fall to see how Lucy would manage to trick Charlie Brown into trying to kick that football. (After I left for college, my father would clip out that strip each year and send it to me just to make sure I didn’t miss it.)"
Proof sheets were the means by which syndicates provided newspapers with black-and-white line art for the reproduction of strips (which they arranged to have colored in the case of Sunday strips). Michigan State University Comic Art Collection librarian Randy Scott describes these as "large sheets of paper on which newspaper comics have traditionally been distributed to subscribing newspapers. Typically each sheet will have either six daily strips of a given title or one Sunday strip. Thus, a week of "Beetle Bailey" would arrive at the "Lansing State Journal" in two sheets, printed much larger than the final version and ready to be cut apart and fitted into the local comics page." Comic strip historian Allan Holtz described how strips were provided as mats (the plastic or cardboard trays in which molten metal is poured to make plates) or even plates ready to be put directly on the printing press. He also notes that with electronic means of distribution becoming more prevalent printed sheets "are definitely on their way out."
Cartoon panels.
Single panels usually, but not always, are not broken up and lack continuity. The daily "Peanuts" is a strip, and the daily "Dennis the Menace" is a single panel. J. R. Williams' long-run "Out Our Way" continued as a daily panel even after it expanded into a Sunday strip, "Out Our Way with the Willets". Jimmy Hatlo's "They'll Do It Every Time" was often displayed in a two-panel format with the first panel showing some deceptive, pretentious, unwitting or scheming human behavior and the second panel revealing the truth of the situation.
Early daily strips were large, often running the entire width of the newspaper, and were sometimes three or more inches high. Initially, a newspaper page included only a single daily strip, usually either at the top or the bottom of the page. By the 1920s, many newspapers had a comics page on which many strips were collected together. Over decades, the size of daily strips became smaller and smaller, until by the year 2000, four standard daily strips could fit in an area once occupied by a single daily strip.
NEA Syndicate experimented briefly with a two-tier daily strip, "Star Hawks", but after a few years, "Star Hawks" dropped down to a single tier.
In Flanders, the two-tier strip is the standard publication style of most daily strips like "Spike and Suzy" and "Nero". They appear Monday through Saturday; until 2003 there were no Sunday papers in Flanders. In the last decades, they have switched from black and white to color.
Sunday comics.
Sunday newspapers traditionally included a special color section. Early Sunday strips, such as "Thimble Theatre" and "Little Orphan Annie", filled an entire newspaper page, a format known to collectors as full page. Sunday pages during the 1930s and into the 1940s often carried a secondary strip by the same artist as the main strip. No matter whether it appeared above or below a main strip, the extra strip was known as the topper, such as "The Squirrel Cage" which ran along with "Room and Board", both drawn by Gene Ahern.
During the 1930s, the original art for a Sunday strip was usually drawn quite large. For example, in 1930, Russ Westover drew his "Tillie the Toiler" Sunday page at a size of 17" × 37". In 1937, the cartoonist Dudley Fisher launched the innovative "Right Around Home", drawn as a huge single panel filling an entire Sunday page.
Full-page strips were eventually replaced by strips half that size. Strips such as "The Phantom" and "Terry and the Pirates" began appearing in a format of two strips to a page in full-size newspapers, such as the "New Orleans Times Picayune", or with one strip on a tabloid page, as in the "Chicago Sun-Times". When Sunday strips began to appear in more than one format, it became necessary for the cartoonist to allow for rearranged, cropped or dropped panels. During World War II, because of paper shortages, the size of Sunday strips began to shrink. After the war, strips continued to get smaller and smaller because of increased paper and printing costs. The last full-page comic strip was the "Prince Valiant" strip for 11 April 1971.
Comic strips have also been published in Sunday newspaper magazines. Russell Patterson and Carolyn Wells' "New Adventures of Flossy Frills" was a continuing strip series seen on Sunday magazine covers. Beginning January 26, 1941, it ran on the front covers of Hearst's "American Weekly" newspaper magazine supplement, continuing until March 30 of that year. Between 1939 and 1943, four different stories featuring Flossy appeared on "American Weekly" covers.
Sunday comics sections employed offset color printing with multiple print runs imitating a wide range of colors. Printing plates were created with four or more colors—traditionally, the CMYK color model: cyan, magenta, yellow and "K" for black. With a screen of tiny dots on each printing plate, the dots allowed an image to be printed in a halftone that appears to the eye in different gradations. The semi-opaque property of ink allows halftone dots of different colors to create an optical effect of full-color imagery.
Underground comic strips.
The decade of the 1960s saw the rise of underground newspapers, which often carried comic strips, such as "Fritz the Cat" and "The Fabulous Furry Freak Brothers". "Zippy the Pinhead" initially appeared in underground publications in the 1970s before being syndicated. "Bloom County" and "Doonesbury" began as strips in college newspapers under different titles, and later moved to national syndication. Underground comic strips covered subjects that are usually taboo in newspaper strips, such as sex and drugs. Many underground artists, notably Vaughn Bode, Dan O'Neill, Gilbert Shelton, and Art Spiegelman went on to draw comic strips for magazines such as "Playboy", "National Lampoon", and Pete Millar's "CARtoons". Jay Lynch graduated from undergrounds to alternative weekly newspapers to "Mad" and children's books.
Webcomic.
"Webcomics", also known as "online comics" and "internet comics", are comics that are available to read on the Internet. Many are exclusively published online, but the majority of traditional newspaper comic strips have some Internet presence. King Features Syndicate and other syndicates often provide archives of recent strips on their websites. Some, such as Scott Adams, creator of "Dilbert", include an email address in each strip.
Conventions and genres.
Most comic strip characters do not age throughout the strip's life, but in some strips, like Lynn Johnston's award-winning "For Better or For Worse", the characters age as the years pass. The first strip to feature aging characters was "Gasoline Alley".
The history of comic strips also includes series that are not humorous, but tell an ongoing dramatic story. Examples include "The Phantom", "Prince Valiant", "Dick Tracy", "Mary Worth", "Modesty Blaise", "Little Orphan Annie", "Flash Gordon", and "Tarzan". Sometimes these are spin-offs from comic books, for example "Superman", "Batman", and "The Amazing Spider-Man".
A number of strips have featured animals ('funny animals') as main characters. Some are non-verbal ("Marmaduke", "The Angriest Dog in the World"), some have verbal thoughts but are not understood by humans, ("Garfield", Snoopy in "Peanuts"), and some can converse with humans ("Bloom County", "Calvin and Hobbes", "Mutts", "Citizen Dog", "Buckles", "Get Fuzzy", "Pearls Before Swine", and "Pooch Cafe"). Other strips are centered entirely on animals, as in "Pogo" and "Donald Duck". Gary Larson's "The Far Side" was unusual, as there were no central characters. Instead "The Far Side" used a wide variety of characters including humans, monsters, aliens, chickens, cows, worms, amoebas, and more. John McPherson's "Close to Home" also uses this theme, though the characters are mostly restricted to humans and real-life situations. Wiley Miller not only mixes human, animal, and fantasy characters, but also does several different comic strip continuities under one umbrella title, "Non Sequitur". Bob Thaves's "Frank & Ernest" began in 1972 and paved the way for some of these strips, as its human characters were manifest in diverse forms — as animals, vegetables, and minerals.
Social and political influence.
The comics have long held a distorted mirror to contemporary society, and almost from the beginning have been used for political or social commentary. This ranged from the conservative slant of "Little Orphan Annie" to the unabashed liberalism of "Doonesbury". "Pogo" used animals to particularly devastating effect, caricaturing many prominent politicians of the day as animal denizens of Pogo's Okeefenokee Swamp. In a fearless move, Pogo's creator Walt Kelly took on Joseph McCarthy in the 1950s, caricaturing him as a bobcat named Simple J. Malarkey, a megalomaniac who was bent on taking over the characters' birdwatching club and rooting out all undesirables. Kelly also defended the medium against possible government regulation in the McCarthy era. At a time when comic books were coming under fire for supposed sexual, violent, and subversive content, Kelly feared the same would happen to comic strips. Going before the Congressional subcommittee, he proceeded to charm the members with his drawings and the force of his personality. The comic strip was safe for satire.
During the early 20th century, comic strips were widely associated with publisher William Randolph Hearst, whose papers had the largest circulation of strips in the United States. Hearst was notorious for his practice of yellow journalism, and he was frowned on by readers of "The New York Times" and other newspapers which featured few or no comic strips. Hearst's critics often assumed that all the strips in his papers were fronts for his own political and social views. Hearst did occasionally work with or pitch ideas to cartoonists, most notably his continued support of George Herriman's "Krazy Kat". An inspiration for Bill Watterson and other cartoonists, "Krazy Kat" gained a considerable following among intellectuals during the 1920s and 1930s.
Some comic strips, such as "Doonesbury" and "The Boondocks", may be printed on the editorial or op-ed page rather than the comics page because of their regular political commentary. For example, the August 12, 1974 "Doonesbury" strip awarded a 1975 Pulitzer Prize for its depiction of the Watergate scandal. "Dilbert" is sometimes found in the business section of a newspaper instead of the comics page because of the strip's commentary about office politics, and Tank McNamara often appears on the sports page because of its subject matter. Lynn Johnston's "For Better or for Worse" created an uproar when one of its supporting characters came out of the closet and announced he was gay.
Publicity and recognition.
The world's longest comic strip is long and on display at Trafalgar Square as part of the London Comedy Festival. The London Cartoon Strip was created by 15 of Britain's best known cartoonists and depicts the history of London.
The Reuben, named for cartoonist Rube Goldberg, is the most prestigious award for U.S. comic strip artists. Reuben awards are presented annually by the National Cartoonists Society (NCS).
Today's strip artists, with the help of the NCS, enthusiastically promote the medium, which is considered to be in decline due to fewer markets (today few strips are published in newspapers outside the United States, the United Kingdom, and Canada, mainly because of the smaller interest there, with translated versions of popular strips - particularly in Spanish - are primarily read over the internet) and ever-shrinking newspaper space. One particularly humorous example of such promotional efforts is the Great Comic Strip Switcheroonie, held in 1997 on April Fool's Day, an event in which dozens of prominent artists took over each other's strips. "Garfield"’s Jim Davis, for example, switched with "Blondie"’s Stan Drake, while Scott Adams ("Dilbert") traded strips with Bil Keane ("The Family Circus"). Even the United States Postal Service got into the act, issuing a series of commemorative stamps marking the comic-strip centennial in 1996.
While the Switcheroonie was a one-time publicity stunt, for one artist to take over a feature from its originator is an old tradition in newspaper cartooning (as it is in the comic book industry). In fact, the practice has made possible the longevity of the genre's more popular strips. Examples include "Little Orphan Annie" (drawn and plotted by Harold Gray from 1924 to 1944 and thereafter by a succession of artists including Leonard Starr and Andrew Pepoy), and "Terry and The Pirates", started by Milton Caniff in 1934 and picked up by George Wunder.
A business-driven variation has sometimes led to the same feature continuing under a different name. In one case, in the early 1940s, Don Flowers' "Modest Maidens" was so admired by William Randolph Hearst that he lured Flowers away from the Associated Press and to King Features Syndicate by doubling the cartoonist's salary, and renamed the feature "Glamor Girls" to avoid legal action by the AP. The latter continued to publish "Modest Maidens", drawn by Jay Allen in Flowers' style.
Issues in U.S. newspaper comic strips.
As newspapers have declined, the changes have affected comic strips. Jeff Reece, lifestyle editor of "The Florida Times-Union", wrote, "Comics are sort of the 'third rail' of the newspaper."
Size.
In the early decades of the 20th century, all Sunday comics received a full page, and daily strips were generally the width of the page. The competition between papers for having more cartoons than the rest from the mid-1920s, the growth of large-scale newspaper advertising during most of the thirties, paper rationing during World War II, the decline on news readership (as television newscasts began to be more common) and inflation (which has caused higher printing costs) beginning during the fifties and sixties led to Sunday strips being published on smaller and more diverse formats. Daily strips have suffered as well, in 1910 the strips had an unlimited amount of panels, covering the entire width page, while by 1930 most "dailies" had four or five panels covering six of the eight columns occupied by a traditional broadsheet paper, by 1958 those four panels would be narrower, and those would have half of the space a 1910 daily strip had, and by 1998 most strips would have three panels only (with a few exceptions), or even two or one on an occasional basis, apart from strips being smaller, as most papers became slightly narrower. While most cartoonist decided to follow the tide, some cartoonists have complained about this, with "Pogo" ending in 1975 as a form of protest from its creators against the practice. Since then "Calvin and Hobbes" creator Bill Watterson has written extensively on the issue, arguing that size reduction and dropped panels reduce both the potential and freedom of a cartoonist. After a lengthy battle with his syndicator, Watterson won the privilege of making half page-sized Sunday strips where he could arrange the panels any way he liked. Many newspaper publishers and a few cartoonists objected to this, and some papers continued to print "Calvin and Hobbes" at small sizes. Opus won that same privilege years after "Calvin and Hobbes" ended, while Wiley Miller circumvented further downsizings by making his "Non Sequitur" Sunday strip available only in an extremely vertical (near-page-long) arrangement. Few newspapers still run half-page strips, as with "Prince Valiant" and "Hägar the Horrible" in the front page of the "Reading Eagle" Sunday comics section. Actually Universal Uclick and United Media practically have no half-page comics, with the remaining strips from both syndicates in this format are published only as "thirds", "fourths", and "sixths" (also called "third tabs").
Format.
In an issue related to size limitations, Sunday comics are often bound to rigid formats that allow their panels to be rearranged in several different ways while remaining readable. Such formats usually include throwaway panels at the beginning, which some newspapers will omit for space. As a result, cartoonists have less incentive to put great efforts into these panels. "Garfield" and "Mutts" were known during the mid-to-late 80s and 1990s respectively for their throwaways on their Sunday strips, however both strips now run "generic" title panels.
With the success of "The Gumps" during the 1920s, it became commonplace for strips (comedy- and adventure-laden alike) to have lengthy stories spanning weeks or months. The "Monarch of Medioka" story in Floyd Gottfredson's "Mickey Mouse" comic strip ran from September 8, 1937 to May 2, 1938. Between the 1960s and the late 1980s, as television news relegated newspaper reading to an occasional basis rather than daily, syndicators were abandoning long stories and urging cartoonists to switch to simple daily gags, or week-long "storylines" (with six consecutive (mostly unrelated) strips following a same subject), with longer storylines being used mainly on adventure-based and dramatic strips. Strips begun during the mid-1980s or after (such as "Get Fuzzy", "Over the Hedge", "Monty", and others) are known for their heavy use of storylines, lasting between one and three weeks in most cases.
The writing style of comic strips changed as well after World War II. With an increase in the number of college-educated readers, there was a shift away from slapstick comedy and towards more cerebral humor. Slapstick and visual gags became more confined to Sunday strips, because as "Garfield" creator Jim Davis put it, "Children are more likely to read Sunday strips than dailies."
Second author.
Many older strips are no longer drawn by the original cartoonist, who has either died or retired. Such strips are known as "zombie strips". A cartoonist, paid by the syndicate or sometimes a relative of the original cartoonist, continues writing the strip, a tradition that became commonplace in the early half of the 20th century. "Hägar the Horrible" and "Frank and Ernest" are both drawn by the sons of the creators. Some strips which are still in affiliation with the original creator are produced by small teams or entire companies, such as Jim Davis' "Garfield", however there is some debate if these strips fall in this category.
This act is commonly criticized by modern cartoonists including Watterson and "Pearls Before Swine"'s Stephan Pastis. The issue was addressed in six consecutive "Pearls" strips in 2005. Charles Schulz, of "Peanuts" fame, requested that his strip not be continued by another cartoonist after his death. He also rejected the idea of hiring an inker or letterer, comparing it to a golfer hiring a man to make his putts. Schulz's family has honored his wishes and refused numerous proposals by syndicators to continue "Peanuts" with a new author.
Assistants.
Since the consolidation of newspaper comics by the first quarter of the 20th century, most cartoonists have used a group of assistants (with usually one of them credited). However, quite a few cartoonists (e.g.: George Herriman and Charles Schulz, among others) have done their strips almost completely by themselves; often criticizing the use of assistants for the same reasons most have about their editors hiring anyone else to continue their work after their retirement.
Rights to the strips.
Since the dawn of comic strips, the ownership of them has been a recurrent issue. Traditionally, the syndicate owned the rights to the strips. However, throughout history there have been exceptions, with "Mutt and Jeff" being an early (if not the earliest) case in which the creator owned his works. However this was later limited to adaptations of animated properties. When it started in 1970, the Universal Press Syndicate gave cartoonists a 50-percent share on the ownership of their works, while the Creators Syndicate (founded in 1987) granted artists full rights to the strips, something that Universal Press did in 1990. followed by King Features in 1995, while before 1999 both the Tribune and United Feature services began granting rights to creators over their works; however the latter three syndicates only applied this to new strips, or to ones popular enough.
Censorship.
Starting in the late 1940s, the national syndicates which distributed newspaper comic strips subjected them to very strict censorship. "Li'l Abner" was censored in September 1947 and was pulled from papers by Scripps-Howard. The controversy, as reported in "Time", centered on Capp's portrayal of the U.S. Senate. Said Edward Leech of Scripps, "We don't think it is good editing or sound citizenship to picture the Senate as an assemblage of freaks and crooks... boobs and undesirables."
As comics are easier for children to access compared to other types of media, they have a significantly more rigid censorship code than other media. Stephan Pastis has lamented that the "unwritten" censorship code is still "stuck somewhere in the 1950s." Generally, comics are not allowed to include such words as "damn", "sucks", "screwed", and "hell", although there have been exceptions such as the September 22, 2010 "Mother Goose and Grimm" in which an elderly man says, "This nursing home food sucks," and a pair of "Pearls Before Swine" comics from January 11, 2011 with a character named Ned using the word "crappy". Naked backsides and shooting guns cannot be shown, according to "Dilbert" cartoonist Scott Adams. Such comic strip taboos were detailed in Dave Breger's book "But That's Unprintable" (Bantam, 1955).
Many issues such as sex, narcotics, and terrorism cannot or can very rarely be openly discussed in strips, although there are exceptions, usually for satire, as in "Bloom County". This led some cartoonists to resort to double entendre or dialogue children do not understand, as in Greg Evans' "Luann". Young cartoonists have claimed commonplace words, images, and issues should be allowed in the comics. Some of the taboo words and topics are mentioned daily on television and other forms of visual media. Web comics and comics distributed primarily to college newspapers are much freer in this respect.

</doc>
<doc id="5705" url="https://en.wikipedia.org/wiki?curid=5705" title="Continuum hypothesis">
Continuum hypothesis

In mathematics, the continuum hypothesis (abbreviated CH) is a hypothesis about the possible sizes of infinite sets. It states:
The continuum hypothesis was advanced by Georg Cantor in 1878, and
establishing its truth or falsehood is the first of Hilbert's 23 problems presented in 1900. Τhe answer to this problem is independent of ZFC set theory (that is, Zermelo–Fraenkel set theory with the axiom of choice included), so that either the continuum hypothesis or its negation can be added as an axiom to ZFC set theory, with the resulting theory being consistent if and only if ZFC is consistent. This independence was proved in 1963 by Paul Cohen, complementing earlier work by Kurt Gödel in 1940.
The name of the hypothesis comes from the term "the continuum" for the real numbers.
Cardinality of infinite sets.
Two sets are said to have the same "cardinality" or "cardinal number" if there exists a bijection (a one-to-one correspondence) between them. Intuitively, for two sets "S" and "T" to have the same cardinality means that it is possible to "pair off" elements of "S" with elements of "T" in such a fashion that every element of "S" is paired off with exactly one element of "T" and vice versa. Hence, the set has the same cardinality as .
With infinite sets such as the set of integers or rational numbers, this becomes more complicated to demonstrate. The rational numbers seemingly form a counterexample to the continuum hypothesis: the integers form a proper subset of the rationals, which themselves form a proper subset of the reals, so intuitively, there are more rational numbers than integers, and more real numbers than rational numbers. However, this intuitive analysis does not take account of the fact that all three sets are infinite. It turns out the rational numbers can actually be placed in one-to-one correspondence with the integers, and therefore the set of rational numbers is the same size ("cardinality") as the set of integers: they are both countable sets.
Cantor gave two proofs that the cardinality of the set of integers is strictly smaller than that of the set of real numbers (see Cantor's first uncountability proof and Cantor's diagonal argument). His proofs, however, give no indication of the extent to which the cardinality of the integers is less than that of the real numbers. Cantor proposed the continuum hypothesis as a possible solution to this question.
The hypothesis states that the set of real numbers has minimal possible cardinality which is greater than the cardinality of the set of integers. Equivalently, as the cardinality of the integers is formula_1 ("aleph-naught") and the cardinality of the real numbers is formula_2 (i.e. it equals the cardinality of the power set of the integers), the continuum hypothesis says that there is no set formula_3 for which
Assuming the axiom of choice, there is a smallest cardinal number formula_5 greater than formula_1, and the continuum hypothesis is in turn equivalent to the equality
A consequence of the continuum hypothesis is that every infinite subset of the real numbers either has the same cardinality as the integers or the same cardinality as the entire set of the reals.
There is also a generalization of the continuum hypothesis called the generalized continuum hypothesis (GCH) which says that for all ordinals formula_8
That is, GCH asserts that the cardinality of the power set of any infinite set is the smallest cardinality greater than that of the set.
Independence from ZFC.
Cantor believed the continuum hypothesis to be true and tried for many years to prove it, in vain . It became the first on David Hilbert's list of important open questions that was presented at the International Congress of Mathematicians in the year 1900 in Paris. Axiomatic set theory was at that point not yet formulated.
Kurt Gödel showed in 1940 that the continuum hypothesis (CH for short) cannot be disproved from the standard Zermelo–Fraenkel set theory (ZF), even if the axiom of choice is adopted (ZFC) (). Paul Cohen showed in 1963 that CH cannot be proven from those same axioms either ( & ). Hence, CH is "independent" of ZFC. Both of these results assume that the Zermelo–Fraenkel axioms are consistent; this assumption is widely believed to be true. Cohen was awarded the Fields Medal in 1966 for his proof.
The continuum hypothesis is closely related to many statements in analysis, point set topology and measure theory. As a result of its independence, many substantial conjectures in those fields have subsequently been shown to be independent as well.
So far, CH appears to be independent of all known "large cardinal axioms" in the context of ZFC. ()
The independence from ZFC means that proving or disproving the CH within ZFC is impossible. However, Gödel and Cohen's negative results are not universally accepted as disposing of the hypothesis. Hilbert's problem remains an active topic of research; see and for an overview of the current research status.
The continuum hypothesis was not the first statement shown to be independent of ZFC. An immediate consequence of Gödel's incompleteness theorem, which was published in 1931, is that there is a formal statement (one for each appropriate Gödel numbering scheme) expressing the consistency of ZFC that is independent of ZFC, assuming that ZFC is consistent. The continuum hypothesis and the axiom of choice were among the first mathematical statements shown to be independent of ZF set theory. These proofs of independence were not completed until Paul Cohen developed forcing in the 1960s. They all rely on the assumption that ZF is consistent. These proofs are called proofs of relative consistency (see "Forcing (mathematics))".
A result of Solovay, proved shortly after Cohen's result on the independence of the continuum hypothesis, shows that in any model of ZFC, if formula_10 is a cardinal of uncountable cofinality, then there is a forcing extension in which formula_11. However, it is not consistent to assume formula_2 is formula_13 or formula_14 or any cardinal with cofinality formula_15.
Arguments for and against CH.
Gödel believed that CH is false and that his proof that CH is consistent with ZFC only shows that the Zermelo–Fraenkel axioms do not adequately characterize the universe of sets. Gödel was a platonist and therefore had no problems with asserting the truth and falsehood of statements independent of their provability. Cohen, though a formalist , also tended towards rejecting CH.
Historically, mathematicians who favored a "rich" and "large" universe of sets were against CH, while those favoring a "neat" and "controllable" universe favored CH. Parallel arguments were made for and against the axiom of constructibility, which implies CH. More recently, Matthew Foreman has pointed out that ontological maximalism can actually be used to argue in favor of CH, because among models that have the same reals, models with "more" sets of reals have a better chance of satisfying CH (Maddy 1988, p. 500).
Another viewpoint is that the conception of set is not specific enough to determine whether CH is true or false. This viewpoint was advanced as early as 1923 by Skolem, even before Gödel's first incompleteness theorem. Skolem argued on the basis of what is now known as Skolem's paradox, and it was later supported by the independence of CH from the axioms of ZFC, since these axioms are enough to establish the elementary properties of sets and cardinalities. In order to argue against this viewpoint, it would be sufficient to demonstrate new axioms that are supported by intuition and resolve CH in one direction or another. Although the axiom of constructibility does resolve CH, it is not generally considered to be intuitively true any more than CH is generally considered to be false (Kunen 1980, p. 171).
At least two other axioms have been proposed that have implications for the continuum hypothesis, although these axioms have not currently found wide acceptance in the mathematical community. In 1986, Chris Freiling presented an argument against CH by showing that the negation of CH is equivalent to Freiling's axiom of symmetry, a statement about probabilities. Freiling believes this axiom is "intuitively true" but others have disagreed. A difficult argument against CH developed by W. Hugh Woodin has attracted considerable attention since the year 2000 (Woodin 2001a, 2001b). Foreman (2003) does not reject Woodin's argument outright but urges caution.
Solomon Feferman (2011) has made a complex philosophical argument that CH is not a definite mathematical problem. He proposes a theory of "definiteness" using a semi-intuitionistic subsystem of ZF that accepts classical logic for bounded quantifiers but uses intuitionistic logic for unbounded ones, and suggests that a proposition formula_16 is mathematically "definite" if the semi-intuitionistic theory can prove formula_17. He conjectures that CH is not definite according to this notion, and proposes that CH should therefore be considered not to have a truth value. Peter Koellner (2011b) wrote a critical commentary on Feferman's article.
Joel David Hamkins proposes a multiverse approach to set theory and argues that "the continuum hypothesis is settled on the multiverse view by our extensive knowledge about how it behaves in the multiverse, and as a result it can no longer be settled in the manner formerly hoped for." (Hamkins 2012). In a related vein, Saharon Shelah wrote that he does "not agree with the pure Platonic view that the interesting problems in set theory can be decided, that we just have to discover the additional axiom. My mental picture is that we have many possible set theories, all conforming to ZFC." (Shelah 2003).
The generalized continuum hypothesis.
The "generalized continuum hypothesis" (GCH) states that if an infinite set's cardinality lies between that of an infinite set "S" and that of the power set of "S", then it either has the same cardinality as the set "S" or the same cardinality as the power set of "S". That is, for any infinite cardinal formula_18 there is no cardinal formula_19 such that formula_20 GCH is equivalent to:
The beth numbers provide an alternate notation for this condition: formula_23 for every ordinal formula_22
This is a generalization of the continuum hypothesis since the continuum has the same cardinality as the power set of the integers. It was first suggested by .
Like CH, GCH is also independent of ZFC, but Sierpiński proved that ZF + GCH implies the axiom of choice (AC) (and therefore the negation of the axiom of determinacy, AD), so choice and GCH are not independent in ZF; there are no models of ZF in which GCH holds and AC fails. To prove this, Sierpiński showed GCH implies that every cardinality n is smaller than some Aleph number, and thus can be ordered. This is done by showing that n is smaller than formula_25 which is smaller than its own Hartogs number — this uses the equality formula_26; for the full proof, see Gillman (2002).
Kurt Gödel showed that GCH is a consequence of ZF + V=L (the axiom that every set is constructible relative to the ordinals), and is therefore consistent with ZFC. As GCH implies CH, Cohen's model in which CH fails is a model in which GCH fails, and thus GCH is not provable from ZFC. W. B. Easton used the method of forcing developed by Cohen to prove Easton's theorem, which shows it is consistent with ZFC for arbitrarily large cardinals formula_27 to fail to satisfy formula_28 Much later, Foreman and Woodin proved that (assuming the consistency of very large cardinals) it is consistent that formula_29 holds for every infinite cardinal formula_30 Later Woodin extended this by showing the consistency of formula_31 for every formula_19. showed that, for each "n" ≥ 1, it is consistent with ZFC that for each κ, 2κ is the "n"th successor of κ. On the other hand, proved, that if γ is an ordinal and for each infinite cardinal κ, 2κ is the γth successor of κ, then γ is finite.
For any infinite sets A and B, if there is an injection from A to B then there is an injection from subsets of A to subsets of B. Thus for any infinite cardinals A and B,
References.
, , etc. - instead, fix new citations so that they use the existing citation style

</doc>
<doc id="5706" url="https://en.wikipedia.org/wiki?curid=5706" title="Çevik Bir">
Çevik Bir

Çevik Bir is a retired Turkish army general. He was a member of the Turkish General Staff in the 1990s. He took a major part in several important international missions in the Middle East and North Africa. He was born in Buca, Izmir Province, in 1939 and is married with one child.
He graduated from the Turkish Military Academy as an engineer officer in 1958, from the Army Staff College in 1970 and from the Armed Forces College in 1971. He graduated from NATO Defense College, Rome, Italy in 1973.
From 1973 to 1985, he served at SHAPE, NATO's headquarters in Belgium. He was promoted to brigadier general and commanded an armed brigade and division in Turkey. From 1987 to 1991, he served as major general, and then was promoted to lieutenant general.
After the dictator Siad Barre’s ousting, conflicts between the General Farah Aidid's party and other clans in Somalia had led to famine and lawlessness throughout the country. An estimated 300,000 people had died from starvation. A combined military force of United States and United Nations (under the name "UNOSOM") were deployed to Mogadishu, to monitor the ceasefire and deliver food and supplies to the starving people of Somali. Çevik Bir, who was then a lieutenant-general of Turkey, became the force commander of UNOSOM II in 1993. Despite the retreat of US and UN forces after several deaths due to local hostilities mainly led by Aidid, the introduction of a powerful military force opened the transportation routes, enabling the provision of supplies and ended the famine quickly.
He became a four-star general and served three years as vice chairman of the Turkish Armed Forces, then appointed commander of the Turkish First Army, in Istanbul. While he was vice chairman of the TAF, he signed the Turkish-Israeli Military Coordination agreement in 1996.
Çevik Bir became the Turkish army's deputy chief of general staff shortly after the Somali operation and played a vital role in establishing a Turkish-Israeli entente against the emerging fundamentalism in the Middle East.
Çevik Bir retired from the army on August 30, 1999. He is a former member of the Association for the Study of the Middle East and Africa (ASMEA).
On April 12, 2012, Bir and 30 other officers were taken in custody for their role in the 1997 military memorandum that forced the then Turkish government, led by the Refah Partisi (Welfare Party), to step down.

</doc>
<doc id="5708" url="https://en.wikipedia.org/wiki?curid=5708" title="Collectivism">
Collectivism

Collectivism is the moral stance, political philosophy, ideology, or social outlook that emphasizes the significance of groups—their identities, goals, rights, outcomes, etc.—and tends to analyze issues in those terms. Collectivism is a basic cultural element that exists as the reverse of individualism (in the same way high context culture exists as the reverse of low context culture), and in some cases stresses the priority of group goals over individual goals and the importance of cohesion within social groups (such as an ingroup, in whichever specific context it is defined).
Collectivists usually focus on community, society, or nation. It is used and has been used as an element in many different and diverse types of government and political, economic and educational philosophies throughout history and all human societies in practice contain elements of both individualism and collectivism.
Collectivism can be divided into horizontal collectivism and vertical collectivism. Horizontal collectivism stresses collective decision-making among relatively equal individuals, and is thus usually based on decentralization. Vertical collectivism is based on hierarchical structures of power and on moral and cultural conformity, and is therefore based on centralization. A cooperative enterprise would be an example of horizontal collectivism, whereas a military hierarchy would be an example of vertical collectivism.
Typology.
Collectivism has been used to refer to a diverse range of political and economic positions, including nationalism, direct democracy, representative democracy, monarchy, and communism. Collectivism does not need a government or political system to exist (another example of that would be a religious organization that stresses "group goals" within it that is not backed by a government like American or Canadian society), but it can also exist within a political system rather than simply "on the ground". Primarily, Collectivism describes how groups orient themselves naturally within a society.
Collectivism can be typified as "horizontal collectivism", wherein equality is emphasized and people engage in sharing and cooperation, or "vertical collectivism", wherein hierarchy is emphasized and people submit to specific authorities. Horizontal collectivism is based on the assumption that each individual is more or less equal, while vertical collectivism assumes that individuals are fundamentally different from each other. Social anarchist Alexander Berkman, who was a horizontal collectivist, argued that equality does not imply a lack of unique individuality, but an equal amount of freedom and equal opportunity to develop one's own skills and talents.
Horizontal collectivists tend to favor democratic decision-making, while vertical collectivists believe in a more strict chain of command. Horizontal collectivism stresses common goals, interdependence and sociability. Vertical collectivism stresses the integrity of the in-group (e.g. the family or the nation, for example), expects individuals to sacrifice themselves for the in-group if necessary, and promotes competition between different in-groups.
Collectivism and individualism.
Collectivism is often portrayed as the polar opposite of individualism, which is usually characterized as the economic, political, social or cultural autonomy of the individual within society; but given the different interpretations of individualism, from egocentric perspectives to more integrative ones, this apparent opposition is not necessarily true. For example, worker cooperatives operate on a collective basis but require the direct input of each individual member. While the ideas of holism posit that a sum is greater than its parts, this does not necessarily imply that a collectivity is greater or more powerful than the individuals that make it up, but instead that the collective energies of all individuals involved produce something that goes beyond each person (whereas, in authoritarian collectivities, power accrues to a person or group who is supposed to embody the collective). Theoretically, collectivism goes beyond considering the individual as the prime mover of society, but instead considers the numerous associations individuals voluntarily form as society's basis. In doing so it recognizes society as a "collection" of individuals and so remains with the understanding that any collective organization is fundamentally composed of individuals.
Depending on how conscious a collectivity is of this reality determines how genuinely it maintains respect for individuality. On the other hand, individualism which encourages individuality at the expense of others cannot be considered collectivist, nor even individualist, since individualism is not the same as egotism.
Culture and politics.
Collectivism is a basic element of human culture that exists independently of any one political system and has existed since the founding of human society ten thousand years ago. It is a feature that all societies use to some degree or another and therefore an inherent feature of human nature. For example, monarchical societies often had a system of "social ranks" which were collectivist because the social rank one had or did not have was more important than his or her individual will, and the specific rank in question could only be overridden in very limited cases. An example of collectivism in more modern times are the police and fire departments. All individuals (except in rare cases) are expected to pay taxes to these organizations and their will has been overridden in making them do so under law, thus they are collectivist institutions. We also see, that in regards to a police department, an individual can be detained whether he or she wishes to or not, overriding his or her will as an example of collectivism.
An example of a collectivist political system is representative democracy, as in such systems, after voting occurs and a leader has been chosen by the populace everyone is expected to accept that individual as their leader regardless of whether they voted for them or not. For example, in the United States Presidential election of 2012 Barack Obama received a majority of the electoral college votes cast, and the opposition was expected to submit to letting him lead them whether or not they had originally voted for him. The will of the "collective" (President Obama voters) mattered more and is considered "collectivist" because ultimately, the totality of decision by the voters in the country, expressed through the electoral college system, was more important than the will of any single individual in that context.
Though all human societies contain elements of both individualism and collectivism by definition (if not they would become unstable), some societies are on the whole more collectivist and some on the whole more individualist. In collectivist societies, the group is considered more important than any one individual and groups in such societies are expected to "take care" of their members and individuals are expected to "take care" of the group (usually called an "in-group") that they are a member of. Harmony within these groups is considered paramount. For example, it may be considered "inappropriate" for a member of an in-group to openly criticize another in public (though they are often allowed to do so in private). Collectivism does have its advantages as compared to individualist societies as people in collectivist societies almost always have access to a "group" and as such are known to be considered "happier", "less lonely", and have lower rates of mental illness in studies done by psychologists and political scientists. People in individual societies are known to feel "lonely" at some times or another compared to their collectivist counterparts. Many people also find it easier to live in a society where social harmony is emphasized, and groups by definition remain more cohesive than in individualist societies, where groups are observed to be inherently less stable. However, it depends on the preference of an individual if they wish to live in a collectivist society like Japan or an individualist one like the United States. One type could not be said to be better than another and both are known to come into existence naturally as a consequence of human nature.
Criticisms.
Classical liberal criticisms.
There are two main objections to collectivism from the ideas of individualism. One is that collectivism stifles individuality and diversity by insisting upon a common social identity, such as nationalism or some other group focus. The other is that collectivism is linked to statism and the diminution of freedom when political authority is used to advance collectivist goals.
Criticism of collectivism comes from liberal individualists, such as classical liberals, libertarians, Objectivists, and individualist anarchists. Perhaps the most notable modern criticism of economic collectivism is the one put forward by Friedrich Hayek in his book "The Road to Serfdom", published in 1944.
Ludwig von Mises wrote:
On the other hand the application of the basic ideas of collectivism cannot result in anything but social disintegration and the perpetuation of armed conflict. It is true that every variety of collectivism promises eternal peace starting with the day of its own decisive victory and the final overthrow and extermination of all other ideologies and their supporters. ... As soon as a faction has succeeded in winning the support of the majority of citizens and thereby attained control of the government machine, it is free to deny to the minority all those democratic rights by means of which it itself has previously carried on its own struggle for supremacy.
Socialist criticisms.
Many socialists, particularly libertarian socialists, individualist anarchists, and De Leonists criticise the concept of collectivism. Some anti-collectivists often argue that all authoritarian and totalitarian societies are (vertically) collectivist in nature. Socialists argue that modern capitalism and private property, which is based on socialized production and joint-stock or corporate ownership structures, is a form of organic collectivism that sharply contrasts with the perception that capitalism is a system of free individuals exchanging commodities. Socialists sometimes argue that true individualism can only exist when individuals are free from coercive social structures to pursue their own interests, which can only be accomplished by common ownership of socialized, productive assets and free access to the means of life so that no individual has coercive power over other individuals.
George Orwell, a dedicated democratic socialist, believed that collectivism resulted in the empowerment of a minority of individuals that led to further oppression of the majority of the population in the name of some ideal such as freedom.
It cannot be said too often – at any rate, it is not being said nearly often enough – that collectivism is not inherently democratic, but, on the contrary, gives to a tyrannical minority such powers as the Spanish Inquisitors never dreamt of.
Yet in the subsequent sentence he also warns of the tyranny of private ownership over the means of production:
... that a return to 'free' competition means for the great mass of people a tyranny probably worse, because more irresponsible, than that of the state.
Marxists criticize this use of the term "collectivism," on the grounds that all societies are based on class interests and therefore all societies could be considered "collectivist." The liberal ideal of the free individual is seen from a Marxist perspective as a smokescreen for the collective interests of the capitalist class. Social anarchists argue that "individualism" is a front for the interests of the upper class. As anarchist Emma Goldman wrote:
'rugged individualism'... is only a masked attempt to repress and defeat the individual and his individuality. So-called Individualism is the social and economic laissez-faire: the exploitation of the masses by the classes by means of legal trickery, spiritual debasement and systematic indoctrination of the servile spirit ... That corrupt and perverse 'individualism' is the straitjacket of individuality. ... [It has inevitably resulted in the greatest modern slavery, the crassest class distinctions driving millions to the breadline. 'Rugged individualism' has meant all the 'individualism' for the masters, while the people are regimented into a slave caste to serve a handful of self-seeking 'supermen.' ... Their 'rugged individualism' is simply one of the many pretenses the ruling class makes to mask unbridled business and political extortion.
In response to criticism made by various pro-capitalist groups that claim that public ownership or common ownership of the means of production is a form of collectivism, socialists maintain that common ownership over productive assets does not infringe upon the individual, but is instead a liberating force that transcends the false dichotomy of individualism and collectivism. Socialists maintain that these critiques conflate the concept of private property in the means of production with personal possessions and individual production.
Other criticisms.
Ayn Rand, creator of the philosophy of Objectivism and a particularly vocal opponent of collectivism, argued that it led to totalitarianism. She argued that "collectivism means the subjugation of the individual to a group," and that "throughout history, no tyrant ever rose to power except on the claim of representing "the common good"." She further claimed that "horrors which no man would dare consider for his own selfish sake are perpetrated with a clear conscience by "altruists" who justify themselves by the common good." (The "altruists" Rand refers to are not those who practice simple benevolence or charity, but rather those who believe in Auguste Comte's ethical doctrine of altruism which holds that there is "a moral and political obligation of the individual to sacrifice his own interests for the sake of a greater social good.").

</doc>
<doc id="5711" url="https://en.wikipedia.org/wiki?curid=5711" title="Nepeta">
Nepeta

Nepeta is a genus of flowering plants in the family Lamiaceae also known as catmints. The genus name is reportedly in reference to Nepete, an ancient Etruscan city. There are about 250 species.
The genus is native to Europe, Asia, and Africa, and has also naturalized in North America.
Some members of this group are known as catnip or catmint because of their effect on house cats – the nepetalactone contained in some "Nepeta" species binds to the olfactory receptors of cats, typically resulting in temporary euphoria.
Description.
Most of the species are herbaceous perennial plants, but some are annuals. They have sturdy stems with opposite heart-shaped, green to gray-green leaves. "Nepeta" plants are usually aromatic in foliage and flowers.
The tubular flowers can be lavender, blue, white, pink, or lilac, and spotted with tiny lavender-purple dots. The flowers are located in verticillasters grouped on spikes; or the verticillasters are arranged in opposite cymes, racemes, or panicles – toward the tip of the stems.
The calyx is tubular or campanulate, they are slightly curved or straight, and the limbs are often 2-lipped with five teeth. The lower lip is larger, with 3-lobes, and the middle lobe is the largest. The flowers have 4 hairless stamens that are nearly parallel, and they ascend under the upper lip of the corolla. Two stamen are longer and stamens of pistillate flowers are rudimentary. The style protrudes outside of the mouth of the flowers.
The fruits are nutlets, which are oblong-ovoid, ellipsoid, ovoid, or obovoid in shape. The surfaces of the nutlets can be slightly ribbed, smooth or warty.
Uses.
Cultivation.
Some "Nepeta" species are cultivated as ornamental plants. They can be drought tolerant – water conserving, often deer repellent, with long bloom periods from late spring to autumn. Some species also have repellent properties to insect pests, including aphids and squash bugs, when planted in a garden.
"Nepeta" species are used as food plants by the larvae of some Lepidoptera (butterfly and moth) species including "Coleophora albitarsella", and as nectar sources for pollinators, such as honeybees and hummingbirds.

</doc>
<doc id="5714" url="https://en.wikipedia.org/wiki?curid=5714" title="Cornish Nationalist Party">
Cornish Nationalist Party

The Cornish Nationalist Party (CNP), , is a political party, founded by Dr James Whetter, who campaigned for independence for Cornwall. It was formed by people who left Cornwall's main nationalist party Mebyon Kernow on 28 May 1975, but it is no longer for independence.
A separate party with a similar name (Cornish National Party) existed from 1969.
The split with Mebyon Kernow was based on the same debate that was occurring in most of the other political parties campaigning for autonomy from the United Kingdom at the time (such as the Scottish National Party and Plaid Cymru): whether to be a centre-left party, appealing to the electorate on a social democratic line, or whether to appeal emotionally on a centre-right cultural line. Originally, another subject of the split was whether to embrace devolution as a first step to full independence (or as the sole step if this was what the electorate wished) or for it to be "all or nothing".
The CNP essentially represented a more right-wing outlook from those who disagree that economic arguments were more likely to win votes than cultural. The CNP worked to preserve the identity of Cornwall and improve its economy, and encouraged links with Cornish people overseas and with other regions with distinct identities. It also gave support to the Cornish language and commemorated Thomas Flamank, a leader of the Cornish Rebellion in 1497, at an annual ceremony at Bodmin on 27 June each year.
While the CNP is not a racist organisation, there was a perceived image problem from the similarly-styled BNP (the nativist British National Party). The CNP was for some time seen as more of a pressure group, as it did not put up candidates for any elections, although its visibility and influence within Cornwall is negligible. , it is now registered on the UK political parties register, and so Mebyon Kernow is no longer the only registered political party based in Cornwall. In April 2009, a news story reported that the CNP had re-formed following a conference in Bodmin; however, it did not contest any elections that year.
Whetter and the CNP still publish a quarterly journal, "The Cornish Banner" ("An Baner Kernewek"), within the actions of the Roseland Institute.
A newspaper article and a revamp of the party website in October 2014 state that the party is now to contest elections once more.
John Le Bretton, vice-chairman of the party, said: "The CNP supports the retention of Cornwall council as a Cornwall-wide authority running Cornish affairs and we call for the British government in Westminster to devolve powers to the council so that decisions affecting Cornwall can be made in Cornwall".
The party's policies include the following:

</doc>
<doc id="5715" url="https://en.wikipedia.org/wiki?curid=5715" title="Cryptanalysis">
Cryptanalysis

Cryptanalysis (from the Greek "kryptós", "hidden", and "analýein", "to loosen" or "to untie") is the study of analyzing information systems in order to study the hidden aspects of the systems. Cryptanalysis is used to breach cryptographic security systems and gain access to the contents of encrypted messages, even if the cryptographic key is unknown.
In addition to mathematical analysis of cryptographic algorithms, cryptanalysis includes the study of side-channel attacks that do not target weaknesses in the cryptographic algorithms themselves, but instead exploit weaknesses in their implementation.
Even though the goal has been the same, the methods and techniques of cryptanalysis have changed drastically through the history of cryptography, adapting to increasing cryptographic complexity, ranging from the pen-and-paper methods of the past, through machines like the British Bombes and Colossus computers at Bletchley Park in World War II, to the mathematically advanced computerized schemes of the present. Methods for breaking modern cryptosystems often involve solving carefully constructed problems in pure mathematics, the best-known being integer factorization.
Overview.
Given some encrypted data (""ciphertext""), the goal of the "cryptanalyst" is to gain as much information as possible about the original, unencrypted data (""plaintext"").
Amount of information available to the attacker.
Attacks can be classified based on what type of information the attacker has available. As a basic starting point it is normally assumed that, for the purposes of analysis, the general algorithm is known; this is Shannon's Maxim "the enemy knows the system"—in its turn, equivalent to Kerckhoffs' principle. This is a reasonable assumption in practice — throughout history, there are countless examples of secret algorithms falling into wider knowledge, variously through espionage, betrayal and reverse engineering. (And on occasion, ciphers have been reconstructed through pure deduction; for example, the German Lorenz cipher and the Japanese Purple code, and a variety of classical schemes):
Computational resources required.
Attacks can also be characterised by the resources they require. Those resources include:
It's sometimes difficult to predict these quantities precisely, especially when the attack isn't practical to actually implement for testing. But academic cryptanalysts tend to provide at least the estimated "order of magnitude" of their attacks' difficulty, saying, for example, "SHA-1 collisions now 252."
Bruce Schneier notes that even computationally impractical attacks can be considered breaks: "Breaking a cipher simply means finding a weakness in the cipher that can be exploited with a complexity less than brute force. Never mind that brute-force might require 2128 encryptions; an attack requiring 2110 encryptions would be considered a break...simply put, a break can just be a certificational weakness: evidence that the cipher does not perform as advertised."
Partial breaks.
The results of cryptanalysis can also vary in usefulness. For example, cryptographer Lars Knudsen (1998) classified various types of attack on block ciphers according to the amount and quality of secret information that was discovered:
Academic attacks are often against weakened versions of a cryptosystem, such as a block cipher or hash function with some rounds removed. Many, but not all, attacks become exponentially more difficult to execute as rounds are added to a cryptosystem, so it's possible for the full cryptosystem to be strong even though reduced-round variants are weak. Nonetheless, partial breaks that come close to breaking the original cryptosystem may mean that a full break will follow; the successful attacks on DES, MD5, and SHA-1 were all preceded by attacks on weakened versions.
In academic cryptography, a "weakness" or a "break" in a scheme is usually defined quite conservatively: it might require impractical amounts of time, memory, or known plaintexts. It also might require the attacker be able to do things many real-world attackers can't: for example, the attacker may need to choose particular plaintexts to be encrypted or even to ask for plaintexts to be encrypted using several keys related to the secret key. Furthermore, it might only reveal a small amount of information, enough to prove the cryptosystem imperfect but too little to be useful to real-world attackers. Finally, an attack might only apply to a weakened version of cryptographic tools, like a reduced-round block cipher, as a step towards breaking of the full system.
History.
Cryptanalysis has coevolved together with cryptography, and the contest can be traced through the history of cryptography—new ciphers being designed to replace old broken designs, and new cryptanalytic techniques invented to crack the improved schemes. In practice, they are viewed as two sides of the same coin: in order to create secure cryptography, you have to design against possible cryptanalysis.
Successful cryptanalysis has undoubtedly influenced history; the ability to read the presumed-secret thoughts and plans of others can be a decisive advantage. For example, in England in 1587, Mary, Queen of Scots was tried and executed for treason as a result of her involvement in three plots to assassinate Elizabeth I of England. The plans came to light after her coded correspondence with fellow conspirators was deciphered by Thomas Phelippes.
In World War I, the breaking of the Zimmermann Telegram was instrumental in bringing the United States into the war. In World War II, the Allies benefitted enormously from their joint success cryptanalysis of the German ciphers — including the Enigma machine and the Lorenz cipher — and Japanese ciphers, particularly 'Purple' and JN-25. 'Ultra' intelligence has been credited with everything between shortening the end of the European war by up to two years, to determining the eventual result. The war in the Pacific was similarly helped by 'Magic' intelligence.
Governments have long recognized the potential benefits of cryptanalysis for intelligence, both military and diplomatic, and established dedicated organizations devoted to breaking the codes and ciphers of other nations, for example, GCHQ and the NSA, organizations which are still very active today. In 2004, it was reported that the United States had broken Iranian ciphers. (It is unknown, however, whether this was pure cryptanalysis, or whether other factors were involved:).
Classical ciphers.
Although the actual word ""cryptanalysis"" is relatively recent (it was coined by William Friedman in 1920), methods for breaking codes and ciphers are much older. The first known recorded explanation of cryptanalysis was given by 9th-century Arabian polymath, Al-Kindi (also known as "Alkindus" in Europe), in "A Manuscript on Deciphering Cryptographic Messages". This treatise includes a description of the method of frequency analysis (Ibrahim Al-Kadi, 1992- ref-3). Italian scholar Giambattista della Porta was author of a seminal work on cryptanalysis ""De Furtivis Literarum Notis"."
Frequency analysis is the basic tool for breaking most classical ciphers. In natural languages, certain letters of the alphabet appear more frequently than others; in English, "E" is likely to be the most common letter in any sample of plaintext. Similarly, the digraph "TH" is the most likely pair of letters in English, and so on. Frequency analysis relies on a cipher failing to hide these statistics. For example, in a simple substitution cipher (where each letter is simply replaced with another), the most frequent letter in the ciphertext would be a likely candidate for "E". Frequency analysis of such a cipher is therefore relatively easy, provided that the ciphertext is long enough to give a reasonably representative count of the letters of the alphabet that it contains.
In Europe during the 15th and 16th centuries, the idea of a polyalphabetic substitution cipher was developed, among others by the French diplomat Blaise de Vigenère (1523–96). For some three centuries, the Vigenère cipher, which uses a repeating key to select different encryption alphabets in rotation, was considered to be completely secure ("le chiffre indéchiffrable"—"the indecipherable cipher"). Nevertheless, Charles Babbage (1791–1871) and later, independently, Friedrich Kasiski (1805–81) succeeded in breaking this cipher. During World War I, inventors in several countries developed rotor cipher machines such as Arthur Scherbius' Enigma, in an attempt to minimise the repetition that had been exploited to break the Vigenère system.
Ciphers from World War I and World War II.
Cryptanalysis of enemy messages played a significant part in the Allied victory in World War II. F. W. Winterbotham, quoted the western Supreme Allied Commander, Dwight D. Eisenhower, at the war's end as describing Ultra intelligence as having been "decisive" to Allied victory. Sir Harry Hinsley, official historian of British Intelligence in World War II, made a similar assessment about Ultra, saying that it shortened the war "by not less than two years and probably by four years"; moreover, he said that in the absence of Ultra, it is uncertain how the war would have ended.
In practice, frequency analysis relies as much on linguistic knowledge as it does on statistics, but as ciphers became more complex, mathematics became more important in cryptanalysis. This change was particularly evident before and during World War II, where efforts to crack Axis ciphers required new levels of mathematical sophistication. Moreover, automation was first applied to cryptanalysis in that era with the Polish Bomba device, the British Bombe, the use of punched card equipment, and in the Colossus computers — the first electronic digital computers to be controlled by a program.
Indicator.
With reciprocal machine ciphers such as the Lorenz cipher and the Enigma machine used by Nazi Germany during World War II, each message had its own key. Usually, the transmitting operator informed the receiving operator of this message key by transmitting some plaintext and/or ciphertext before the enciphered message. This is termed the "indicator", as it indicates to the receiving operator how to set his machine to decipher the message.
Poorly designed and implemented indicator systems allowed first the Poles and then the British at Bletchley Park to break the Enigma cipher system. Similar poor indicator systems allowed the British to identify "depths" that led to the diagnosis of the Lorenz SZ40/42 cipher system, and the comprehensive breaking of its messages without the cryptanalysts seeing the cipher machine.
Depth.
Sending two or more messages with the same key is an insecure process. To a cryptanalyst the messages are then said to be ""in depth."" This may be detected by the messages having the same "indicator" by which the sending operator informs the receiving operator about the key generator initial settings for the message.
Generally, the cryptanalyst may benefit from lining up identical enciphering operations among a set of messages. For example, the Vernam cipher enciphers by bit-for-bit combining plaintext with a long key using the "exclusive or" operator, which is also known as "modulo-2 addition" (symbolized by ⊕ ):
Deciphering combines the same key bits with the ciphertext to reconstruct the plaintext:
(In modulo-2 arithmetic, addition is the same as subtraction.) When two such ciphertexts are aligned in depth, combining them eliminates the common key, leaving just a combination of the two plaintexts:
The individual plaintexts can then be worked out linguistically by trying "probable words" (or phrases), also known as ""cribs,"" at various locations; a correct guess, when combined with the merged plaintext stream, produces intelligible text from the other plaintext component:
The recovered fragment of the second plaintext can often be extended in one or both directions, and the extra characters can be combined with the merged plaintext stream to extend the first plaintext. Working back and forth between the two plaintexts, using the intelligibility criterion to check guesses, the analyst may recover much or all of the original plaintexts. (With only two plaintexts in depth, the analyst may not know which one corresponds to which ciphertext, but in practice this is not a large problem.) When a recovered plaintext is then combined with its ciphertext, the key is revealed:
Knowledge of a key of course allows the analyst to read other messages encrypted with the same key, and knowledge of a set of related keys may allow cryptanalysts to diagnose the system used for constructing them.
Development of modern cryptography.
Even though computation was used to great effect in Cryptanalysis of the Lorenz cipher and other systems during World War II, it also made possible new methods of cryptography orders of magnitude more complex than ever before. Taken as a whole, modern cryptography has become much more impervious to cryptanalysis than the pen-and-paper systems of the past, and now seems to have the upper hand against pure cryptanalysis. The historian David Kahn notes:
Kahn goes on to mention increased opportunities for interception, bugging, side channel attacks, and quantum computers as replacements for the traditional means of cryptanalysis. In 2010, former NSA technical director Brian Snow said that both academic and government cryptographers are "moving very slowly forward in a mature field."
However, any postmortems for cryptanalysis may be premature. While the effectiveness of cryptanalytic methods employed by intelligence agencies remains unknown, many serious attacks against both academic and practical cryptographic primitives have been published in the modern era of computer cryptography:
Thus, while the best modern ciphers may be far more resistant to cryptanalysis than the Enigma, cryptanalysis and the broader field of information security remain quite active.
Asymmetric ciphers.
Asymmetric cryptography (or public key cryptography) is cryptography that relies on using two (mathematically related) keys; one private, and one public. Such ciphers invariably rely on "hard" mathematical problems as the basis of their security, so an obvious point of attack is to develop methods for solving the problem. The security of two-key cryptography depends on mathematical questions in a way that single-key cryptography generally does not, and conversely links cryptanalysis to wider mathematical research in a new way.
Asymmetric schemes are designed around the (conjectured) difficulty of solving various mathematical problems. If an improved algorithm can be found to solve the problem, then the system is weakened. For example, the security of the Diffie-Hellman key exchange scheme depends on the difficulty of calculating the discrete logarithm. In 1983, Don Coppersmith found a faster way to find discrete logarithms (in certain groups), and thereby requiring cryptographers to use larger groups (or different types of groups). RSA's security depends (in part) upon the difficulty of integer factorization — a breakthrough in factoring would impact the security of RSA.
In 1980, one could factor a difficult 50-digit number at an expense of 1012 elementary computer operations. By 1984 the state of the art in factoring algorithms had advanced to a point where a 75-digit number could be factored in 1012 operations. Advances in computing technology also meant that the operations could be performed much faster, too. Moore's law predicts that computer speeds will continue to increase. Factoring techniques may continue to do so as well, but will most likely depend on mathematical insight and creativity, neither of which has ever been successfully predictable. 150-digit numbers of the kind once used in RSA have been factored. The effort was greater than above, but was not unreasonable on fast modern computers. By the start of the 21st century, 150-digit numbers were no longer considered a large enough key size for RSA. Numbers with several hundred digits were still considered too hard to factor in 2005, though methods will probably continue to improve over time, requiring key size to keep pace or other methods such as elliptic curve cryptography to be used.
Another distinguishing feature of asymmetric schemes is that, unlike attacks on symmetric cryptosystems, any cryptanalysis has the opportunity to make use of knowledge gained from the public key.
Quantum computing applications for cryptanalysis.
Quantum computers, which are still in the early phases of research, have potential use in cryptanalysis. For example, Shor's Algorithm could factor large numbers in polynomial time, in effect breaking some commonly used forms of public-key encryption.
By using Grover's algorithm on a quantum computer, brute-force key search can be made quadratically faster. However, this could be countered by doubling the key length.

</doc>
<doc id="5716" url="https://en.wikipedia.org/wiki?curid=5716" title="Chicano">
Chicano

Chicano or Chicana (also spelled Xicano or Xicana) is a chosen identity of some Mexican Americans in the United States. The term "Chicano" is sometimes used interchangeably with "Mexican[-]American". Both names are chosen identities within the Mexican-American community in the United States. However, these terms have a wide range of meanings in various parts of the Southwest. The term became widely used during the Chicano Movement by Mexican Americans to express pride in a shared cultural, ethnic and community identity.
The term "Chicano" had negative connotations before the Chicano Movement, and still is viewed negatively by more conservative members of this community, but it over time gained more acceptance as an identity of pride within the Mexican-American community in the United States. Still, many American-born Mexicans view the term to be distracting, as it often represents a refusal to identify with either Mexican or American identities, while Mexicans from Mexico usually aren't familiar with or do not identify with the term.
The pro-indigenous/Mestizo nature of Chicano nationalism is cemented in the nature of Mexican national identity, in which the culture is heavily syncretic between indigenous and Spanish cultures, and where 60% of the population is Mestizo, and another 30% are indigenous, with the remaining 10% being of European heritage and others racial/ethnic groups. Ultimately it was the experience of the Mexican American in the United States which culminated in the creation of a Chicano identity.
Recorded usage.
The Chicano poet and writer Tino Villanueva traced the first documented use of the term as an ethnonym to 1911, as referenced in a then-unpublished essay by University of Texas anthropologist José Limón. Linguists Edward R. Simmen and Richard F. Bauerle report the use of the term in an essay by Mexican-American writer, Mario Suárez, published in the "Arizona Quarterly" in 1947.
However, a gunboat, the "Chicana", was sold in 1857 to Jose Maria Carvajal to ship arms on the Rio Grande. The King and Kenedy firm submitted a voucher to the Joint Claims Commission of the United States in 1870 to cover the costs of this gunboat's conversion from a passenger steamer. No particular explanation of the boat's name is known.
Etymology.
The origin of the word "chicano" is disputed. Some claim it is a shortened form of "Mexicano" (from the Nahuatl name for a member of the Mexica, the indigenous Aztec people of Anahuac, the Valley of Mexico). The name "Mexica" as spoken in its original Nahuatl, and "Mexico" by the Spaniards at the time of the Conquistadors, was pronounced originally with a "sh" sound (All pronunciations that follow are English approximations of the original Spanish or Indigenous languages; roughly and , respectively) and was transcribed with an "x" during this time period. According to this etymological hypothesis, the difference between the pronunciation and spelling of "chicano" and "mexicano" stems from the fact that the modern-day Spanish language experienced a change in pronunciation regarding a majority of words containing the "x" (for example: México, Ximenez, Xavier, Xarabe). In most cases the "sh" sound has been replaced with the "h" sound (thus ) and a change of spelling ("x" to "j", though this has not been done to "Mexico" and various other proper names). The word "Chicano" would have also been affected by this change. Many Chicanos replace the "ch" with the letter "x", forming "Xicano", due to the original spelling of the Mexica Empire. In the United States, some Mexican Americans choose the "Xicano" spelling to emphasize their indigenous ancestry.
In Mexico's indigenous regions, ' (mestizos) and Westernized natives are referred to as "mexicanos", referring to the modern nation, rather than the ' (village or tribal) identification of the speaker, be it Mayan, Zapotec, Mixtec, Huasteco, or any of hundreds of other indigenous groups. Thus, a newly emigrated Nahuatl speaker in an urban center might referred to his cultural relatives in this country, different from himself, as "", shortened to "chicanos".
The "Handbook of Texas" combines the two ideas:
Some believe that the early 20th-century Hispanic Texan epithet "chicamo" shifted into "chicano" to reflect the grammatical conventions of Spanish-language ethno- and demonyms, such as "americano", "castellano", and "peruano". However, Chicanos generally do not agree that "chicamo" was ever a word used within the culture, as its assertion is thus far entirely unsubstantiated. Therefore, most self-identifying Chicanos do not agree that "Chicano" was ever derived from the word "chicamo".
Another hypothesis is that "chicano" derives from the indigenous population of Guanajuato, the Chichimecas, combined with the word "Mexicano". An alternative idea is that it is an altered form of "Chilango", meaning someone from Mexico City or Central Mexico (i.e. the highland states of México, Sinaloa, Jalisco, Puebla and Michoacán). A similar notion is that the word derives from Chichen Itza, the Mayan temple ruin (dating to around 1,500 years ago) its associated culture in Mexico's Yucatán Peninsula. "Chicano" would thus be a Hispanized word for "Chichen" and Mayans, rather than the Aztec or Nahua people.
Yet another etymological speculation is that it derives from the term "Chileno" (a person from Chile), by way of the Chilean American presence in mid 19th-century California, when miners from Chile arrived in the California Gold Rush (1848–51). This seems dubious, as the term is not frequently used other than in reference to Mexican Americans, is certainly not primarily used for Chilean-Americans.
Thus far, explanations of the origins of the word remain inconclusive. This is an indication that the term originated as a self-identification.
Distinction from "Hispanic" and "Latino".
Chicanos, like many Mexicans, are Mestizos who have heritage of both indigenous American cultures and European, mainly Spanish, through colonization and immigration. More broadly, "Latino" and "Hispanic" refer to people with cultural ties to Spanish-speaking Latin America.
"Latino" may sometimes include Iberian-descended people of all nationalities within Latin America, including those of Portuguese descent, plus Portuguese immigrants to the US; these are otherwise sometimes called Lusitanic in distinction from Hispanic. "Latino" has occasionally been used even more broadly, to include people descended from Italian and other Latin languages cultures descended from the Western Roman Empire. Hispanic is a demonym that can be used narrowly, to refer to the Western Hemisphere only, or to include the Iberian Spanish, and other speakers of the Spanish language as well as the Latinos of the Western Hemisphere.
Meanings.
The term's meanings are highly debatable, but self-described Chicanos view the term as a positive, self-identifying social construction. Outside of Mexican-American communities, and even within them, by those who do not prefer the term, "Chicano" has sometimes been considered pejorative. Regardless, its implications are subjective, but usually consist of one or more of the following elements.
Ethnic identity.
From a popular perspective, the term "Chicano" became widely visible outside of Chicano communities during the American civil rights movement. It was commonly used during the mid-1960s by Mexican-American activists, who, in attempts to assert their civil rights, tried to rid the word of its polarizing negative connotation by reasserting a unique ethnic identity and political consciousness, proudly identifying themselves as "Chicanos".
Although the U.S. Federal Census Bureau provided no way for Mexican Americans or other Latinos to officially identify as a racial/ethnic category prior to 1980, when the broader-than-Mexican term "Hispanic" was first available as a self-identification in census forms, there is ample literary evidence to substantiate that "Chicano" is a long-standing endonym, as a large body of Chicano literature pre-dates the 1950s.
Political identity.
According to the "Handbook of Texas":
At certain points in the 1970s, "Chicano" was the preferred term for reference to Mexican Americans, particularly in the scholarly literature. However, as the term became politicized, its use fell out of favor as a means of referring to the entire population. Since then, "Chicano" has tended to refer to participants in Mexican-American activism. Sabine Ulibarrí, an author from Tierra Amarilla, New Mexico, once labeled "Chicano" as a politically "loaded" term, though later recanted that assessment.
Ambiguous identity.
The identity may be seen as uncertain. For example, in the 1991 Culture Clash play "A Bowl of Beings", in response to Che Guevara's demand for a definition of "Chicano", an "armchair activist" cries out, "I still don't know!". Juan Bruce-Novoa wrote in 1990: "A Chicano lives in the space between the hyphen in Mexican-American".
For Chicanos, the term usually implies being "neither from here, nor from there" in reference to the US and Mexico. As a mixture of cultures from both countries, being Chicano represents the struggle of being accepted into the Anglo-dominated society of the United States, while maintaining the cultural sense developed as a Latino-cultured, US-born Mexican child.
Indigenous identity.
The identity may be seen as native to the land, and distinct from a European identity, despite partial European descent. As Rubén Salazar put it in "Who is a Chicano? And what is it the Chicanos want?, a 1970 "Los Angeles Times" piece: "A Chicano is a Mexican-American with a non-Anglo image of himself." According to Leo Limón: "...a Chicano is ... an indigenous Mexican American".
Political device.
Reies Tijerina (who died on January 19, 2015) was a vocal claimant to the rights of Hispanics and Mexican Americans, and he remains a major figure of the early Chicano Movement. Of the term, he wrote: "The Anglo press degradized the word 'Chicano'. They use it to divide us. We use it to unify ourselves with our people and with Latin America."
Term of derision.
Long a disparaging term in Mexico, the term "Chicano" gradually transformed from a class-based label of derision to one of ethnic pride and general usage within Mexican-American communities, beginning with the rise of the Chicano Movement in the 1960s. In their "Latinas in the United States: A Historical Encyclopedia", Vicki Ruíz and Virginia Sánchez report that demographic differences in the adoption of the term existed; because of the prior vulgar connotations, it was more likely to be used by males than females, and as well, less likely to be used among those in a higher socioeconomic status. Usage was also generational, with the more assimilated third-generation members (again, more likely male) likely to adopt the usage. This group was also younger, of more radical persuasion, and less-connected to a Mexican cultural heritage.
In his essay "Chicanismo" in "The Oxford Encyclopedia of Mesoamerican Cultures" (2002), José Cuéllar, a professor of Chicano studies at San Francisco State University, dates the transition from derisive to positive to the late 1950s, with a usage by young Mexican-American high school students.
Outside of Mexican-American communities, the term might assume a negative meaning if it is used in a manner that embodies the prejudices and bigotries long directed at Mexican and Mexican-American people in the United States. For example, in one case, a prominent Chicana feminist writer and poet has indicated the following subjective meaning through her creative work.
Ana Castillo has referred to herself as a Chicana, and her literary work reflects that she primarily considers the term to be a positive one of self-determination and political solidarity.
The Mexican archeologist and anthropologist Manuel Gamio reported in 1930 that the term "chicamo" (with an "m") was used as a derogatory term used by Hispanic Texans for recently arrived Mexican immigrants displaced during the Mexican Revolution in the beginning of the early 20th century. At this time, the term "Chicano" began to reference those who resisted total assimilation, while the term "Pochos" referred (often pejoratively) to those who strongly advocated assimilation.
In Mexico, which by American standards would be considered class discrimination or racist, the term is associated with a Mexican-American person of low importance class and poor morals. The term "Chicano" is widely known and used in Mexico.
While some Mexican Americans may embrace the term "Chicano", others prefer to identify themselves as:
When it comes to the use of loanwords, Romance-language orthographies, unlike French for example, do not use uppercase for non-name nouns, such as those used for nationalities or ethnic groups, of whatever sort – even Chicano/Chicana are best written with lowercase as "" in Spanish and related languages such as Portuguese, Galician, and Catalan.
Some of them might be used more commonly in English and others in Spanish: e.g. one might identify as a "Mexican" in a mixed American context, in which English would generally be expected, but to identify as part of the white/Euro-American demographic segment of the ethnic Mexican populations, in a strictly Mexican or Mexican-American context, in which one might be speaking Spanish.
Anyone from the United States is referred to in Spanish as ' or '. Romance languages conserved the original standard (formerly shared with English) of counting the entire New World as a single America, as was the consensus in the Age of Discovery; to Spanish- and Portuguese-speakers in the Americas, they are just as "americano" as someone from Belgium would be European. Geological validation of the current English norm is bound by controversies and potential inconsistency, so the best explanation for both cases is mere tradition.
' refers to the Mexicans of Northern Mexico as opposed to '. Mexican Americans do not refer to their shared identity as '. The only people who identify themselves as such are Mexicans from Northern Mexico which represents the whiter and relatively wealthier half of Mexico, compared to ' or southern Mexicans, more related in descent to the original Indigenous peoples of the continent and thus being the ones to actually have greater likelihood for an identity a bit closer to the Chicano one. Mainstream Spanish-language discourse does not treat the American Southwest as a contemporary part of Mexico (cultural, identitarian or otherwise), and the indigenist Chicano nationalism is hardly related at all to non-American Mexican desire for reconquering, an irredentist narrative of what might be perceived as a colonial state and collective mentality.
Social aspects.
Chicanos, regardless of their generational status, tend to connect their culture to the indigenous peoples of North America and to a nation of Aztlán. According to the Aztec legend, Aztlán is a region; Chicano nationalists have equated it with the Southwestern United States.
Some historians may place Aztlán in Nayarit or the Caribbean while other historians entirely disagree, and make a distinction between legend and the contemporary socio-political ideology.
Political aspects.
Many currents came together to produce the revived Chicano political movement of the 1960s and 1970s. Early struggles were against school segregation, but the Mexican-American cause, or "" as it was called, soon came under the banner of the United Farm Workers and César Chávez. However, Corky Gonzales and Reies Tijerina stirred up old tensions about New Mexican land claims with roots going back to before the Mexican–American War. Simultaneous movements like the Young Lords, to empower youth, question patriarchy, democratize the Church, end police brutality, and end the Vietnam War, all intersected with other ethnic nationalist, peace, countercultural, and feminist movements.
Since Chicanismo covers a wide array of political, religious and ethnic beliefs, and not everybody agrees with what exactly a Chicano is, most new Latino immigrants see it as a lost cause, as a lost culture, because Chicanos do not identify with Mexico or wherever their parents migrated from as new immigrants do. Chicanoism is an appreciation of a historical movement, but also is used by many to bring a new revived politicized feeling to voters young and old in the defense of Mexican and Mexican-American rights. People descended from Aztlan (both in the contemporary U.S. and in Mexico) use the Chicano ideology to create a platform for fighting for immigration reform and equality for all people.
Rejection of borders.
For some, Chicano ideals involve a rejection of borders. The 1848 Treaty of Guadalupe Hidalgo transformed the Rio Grande region from a rich cultural center to a rigid border poorly enforced by the United States government. At the end of the Mexican–American War, 80,000 Spanish-Mexican-Indian people were forced into sudden U.S. habitation. As a result, Chicano identification is aligned with the idea of Aztlán, which extends to the Aztec period of Mexico, celebrating a time preceding land division.
Paired with the dissipation of militant political efforts of the Chicano movement in the 1960s was the emergence of the Chicano generation. Like their political predecessors, the Chicano generation rejects the "immigrant/foreigner" categorization status. Chicano identity has expanded from its political origins to incorporate a broader community vision of social integration and nonpartisan political participation.
The shared Spanish language, Catholic faith, close contact with their political homeland (Mexico) to the south, a history of labor segregation, ethnic exclusion and racial discrimination encourage a united "Chicano" or Mexican folkloric tradition in the United States. Ethnic cohesiveness is a resistance strategy to assimilation and the accompanying cultural dissolution.
Mexican nationalists in Mexico, however, condemn the advocates of Chicanoism for attempting to create a new identity for the Mexican-American population, distinct from that of the Mexican nation.
Cultural aspects.
The term "Chicano" is also used to describe the literary, artistic, and musical movements that emerged with the Chicano Movement.
Literature.
Chicano literature tends to focus on themes of identity, discrimination, and culture, with an emphasis on validating Mexican-American and Chicano culture in the United States. Rodolfo "Corky" Gonzales's "Yo Soy Joaquin" is one of the first examples of explicitly Chicano poetry, while José Antonio Villarreal's "Pocho" is widely recognized as the first major Chicano novel. The novel "Chicano" by Richard Vasquez, was the first novel about Mexican Americans to be released by a major publisher (Doubleday, 1970).
It was widely read in high schools and Universities during the 1970s, and has now been recognized as a literary classic. Vasquez's writing has been compared to Upton Sinclair and John Steinbeck. Other important writers include Norma Elia Cantú, Rudolfo Anaya, Anthony Burciaga, Sandra Cisneros, Gary Soto, Sergio Troncoso, Rigoberto González, Raul Salinas, Oscar Zeta Acosta, Daniel Olivas, John Rechy, Ana Castillo, Denise Chávez, Benjamin Alire Sáenz, Luís Alberto Urrea, Dagoberto Gilb, Alicia Gaspar de Alba, Luis J. Rodriguez and Gloria Anzaldúa.
Visual arts.
In the visual arts, works by Chicanos address similar themes as works in literature. The preferred media for Chicano art are murals and graphic arts. San Diego's Chicano Park, home to the largest collection of murals in the world, was created as an outgrowth of the city's political movement by Chicanos. Rasquache art is a unique style subset of the Chicano Arts movement.
Chicano art emerged in the mid-60s as a necessary component to the urban and agarian civil rights movement in the Southwest, known as ', ', or the Chicano Renaissance. The artistic spirit, based on historical and traditional cultural evolution, within the movement has continued into the present millennium. There are artists, for example, who have chosen to do work within ancestral/historical references or who have mastered traditional techniques. Some artists and crafters have transcended the motifs, forms, functions, and context of Chicano references in their work but still acknowledge their identity as Chicano. These emerging artists are incorporating new materials to present mixed-media, digital media, and transmedia works.
Chicano performance art blends humor and pathos for tragicomic effect as shown by Los Angeles' comedy troupe Culture Clash and Mexican-born performance artist Guillermo Gómez-Peña and Nao Bustamante is a Chicana artist known internationally for her conceptual art pieces and as a participant in "", produced by Sarah Jessica Parker. Lalo Alcaraz often depicts the issues of Chicanos in his cartoon series called "La Cucaracha".
One of the most powerful and far-reaching cultural aspects of Chicano culture is the indigenous current that strongly roots Chicano culture to the American continent. It also unifies ' within the larger Pan-Indian Movement. Since its arrival in 1974, an art movement known as ' in the U.S., (and known by several names in its homeland of the central States of Mexico: ', ', "", and so on.) has had a deep impact in Chicano muralism, graphic design, tattoo art (flash), poetry, music, and literature. Lowrider cars also figure prominently as functional art in the Chicano community.
Music.
Lalo Guerrero has been lauded as the "father of Chicano music". Beginning in the 1930s, he wrote songs in the big band and swing genres that were popular at the time. He expanded his repertoire to include songs written in traditional genres of Mexican music, and during the farmworkers' rights campaign, wrote music in support of César Chávez and the United Farm Workers.
Jeffrey Lee Pierce of The Gun Club often spoke about being half Mexican and growing up with the Chicano culture.
Other Chicano/Mexican-American singers include Selena, who sang a mixture of Mexican, Tejano, and American popular music, but died in 1995 at the age of 23; Zack de la Rocha, lead vocalist of Rage Against the Machine and social activist; and Los Lonely Boys, a Texas-style country rock band who have not ignored their Mexican-American roots in their music. In recent years, a growing Tex-Mex polka band trend influenced by the ' and ' music of Mexican immigrants, has in turn influenced much new Chicano folk music, especially on large-market Spanish language radio stations and on television music video programs in the U.S. Some of these artists, like the band Quetzal, are known for the political content of political songs.
Rock.
In the 1950s, 1960s and 1970s, a wave of Chicano pop music surfaced through innovative musicians Carlos Santana, Johnny Rodriguez, Ritchie Valens and Linda Ronstadt. Joan Baez, who was also of Mexican-American descent, included Hispanic themes in some of her protest folk songs. Chicano rock is rock music performed by Chicano groups or music with themes derived from Chicano culture.
There are two undercurrents in Chicano rock. One is a devotion to the original rhythm and blues roots of Rock and roll including Ritchie Valens, Sunny and the Sunglows, and ? and the Mysterians. Groups inspired by this include Sir Douglas Quintet, Thee Midniters, Los Lobos, War, Tierra, and El Chicano, and, of course, the Chicano Blues Man himself, the late Randy Garribay.
The second theme is the openness to Latin American sounds and influences. Trini Lopez, Santana, Malo, Azteca, Toro, Ozomatli and other Chicano Latin rock groups follow this approach. Chicano rock crossed paths of other Latin rock genres (Rock en español) by Cubans, Puerto Ricans, such as Joe Bataan and Ralphi Pagan and South America (Nueva canción). Rock band The Mars Volta combines elements of progressive rock with traditional Mexican folk music and Latin rhythms along with Cedric Bixler-Zavala's Spanglish lyrics.
Chicano punk is a branch of Chicano rock. Examples of the genre include music by the bands The Zeros, Los Illegals, The Brat, The Plugz, Manic Hispanic, Los Crudos, and the Cruzados; these bands emerged from the California punk scene. Some music historians argue that Chicanos of Los Angeles in the late 1970s might have independently co-founded punk rock along with the already-acknowledged founders from British-European sources when introduced to the US in major cities. The rock band ? and the Mysterians, which was composed primarily of Mexican-American musicians, was the first band to be described as punk rock. The term was reportedly coined in 1971 by rock critic Dave Marsh in a review of their show for "Creem" magazine.
Jazz.
Although Latin jazz is most popularly associated with artists from the Caribbean (particularly Cuba) and Brazil, young Mexican Americans have played a role in its development over the years, going back to the 1930s and early 1940s, the era of the zoot suit, when young Mexican-American musicians in Los Angeles and San Jose, such as Jenni Rivera, began to experiment with "", a jazz-like fusion genre that has grown recently in popularity among Mexican Americans.
Rap.
Chicano rap is a unique style of hip hop music which started with Kid Frost, who saw some mainstream exposure in the early 1990s. While Mellow Man Ace was the first mainstream rapper to use Spanglish, Frost's song "La Raza" paved the way for its use in American hip hop. Chicano rap tends to discuss themes of importance to young urban Chicanos. Some of today's Chicano artists include A.L.T., Lil Rob, Psycho Realm, Baby Bash, Serio, A Lighter Shade of Brown, and Funky Aztecs.
Pop and R&B.
Paula DeAnda, Frankie J, and Victor Ivan Santos (early member of the Kumbia Kings and associated with Baby Bash).

</doc>
<doc id="5717" url="https://en.wikipedia.org/wiki?curid=5717" title="Canary Islands">
Canary Islands

The Canary Islands (; , ), also known as the Canaries (), are a Spanish archipelago located just off the southern coast of Morocco, west of its southern border. The Canaries constitute one of Spain's 17 autonomous communities and are among the outermost regions (OMR) of the European Union proper. The main islands are (from largest to smallest) Tenerife, Fuerteventura, Gran Canaria, Lanzarote, La Palma, La Gomera and El Hierro. The archipelago also includes a number of islands and islets: La Graciosa, Alegranza, Isla de Lobos, Montaña Clara, Roque del Oeste and Roque del Este. In ancient times, the island chain was often referred to as "the Fortunate Isles".
The archipelago's beaches, climate and important natural attractions, especially Maspalomas in Gran Canaria and Teide National Park and Mount Teide (a World Heritage Site) in Tenerife (the third tallest volcano in the world measured from its base on the ocean floor), make it a major tourist destination with over 12 million visitors per year, especially Tenerife, Fuerteventura, Gran Canaria and Lanzarote. The islands have a subtropical climate, with long warm summers and moderately warm winters. The precipitation levels and the level of maritime moderation varies depending on location and elevation. Green areas as well as desert exist on the archipelago. Due to their location above the temperature inversion layer, the high mountains of these islands are ideal for astronomical observation. For this reason, two professional observatories, Teide Observatory on the island of Tenerife and Roque de los Muchachos Observatory on the island of La Palma, have been built on the islands.
The capital of the Autonomous Community is shared by the rival cities of Santa Cruz de Tenerife and Las Palmas de Gran Canaria, which in turn are the capitals of the provinces of Santa Cruz de Tenerife and Province of Las Palmas. Las Palmas de Gran Canaria has been the largest city in the Canaries since 1768, except for a brief period in the 1910s. Between the 1833 territorial division of Spain and 1927 Santa Cruz de Tenerife was the sole capital of the Canary Islands. In 1927 a decree ordered that the capital of the Canary Islands be shared, as it remains at present. The third largest city of the Canary Islands is San Cristóbal de La Laguna (a World Heritage Site) on Tenerife. This city is also home to the "Consejo Consultivo de Canarias", which is the supreme consultative body of the Canary Islands.
During the times of the Spanish Empire the Canaries were the main stopover for Spanish galleons on their way to the Americas, who came South to catch the prevailing Northeast trade winds.
Etymology.
The name "Islas Canarias" is likely derived from the Latin name "Canariae Insulae", meaning "Islands of the Dogs", a name applied originally only to Gran Canaria. According to the historian Pliny the Elder, the Mauretanian king Juba II named the island "Canaria" because it contained "vast multitudes of dogs of very large size".
Another speculation is that the so-called dogs were actually a species of monk seal ("canis marinus" or "sea dog" was a Latin term for "seal"), critically endangered and no longer present in the Canary Islands. The dense population of seals may have been the characteristic that most struck the few ancient Romans who established contact with these islands by sea.
Alternatively, it is said that the original inhabitants of the island, Guanches, used to worship dogs, mummified them and treated dogs generally as holy animals. The ancient Greeks also knew about a people, living far to the west, who are the "dog-headed ones", who worshipped dogs on an island. Some hypothesize that the Canary Islands dog-worship and the ancient Egyptian cult of the dog-headed god, Anubis are closely connected but there is no explanation given as to which one was first.
Other theories speculate that the name comes from a reported Berber tribe living in the Moroccan Atlas, named in Roman sources as "Canarii", though Pliny again mentions the relation of this term with dogs.
The connection to dogs is retained in their depiction on the islands' coat-of-arms (shown above).
What is certain is that the name of the islands does not derive from the canary bird; rather, the birds are named after the islands.
Geography.
Tenerife is the most populous island, and also the largest island of the archipelago. Gran Canaria, with 865,070 inhabitants, is both the Canary Islands' second most populous island, and the third most populous one in Spain after Majorca. The island of Fuerteventura is the second largest in the archipelago and located from the African coast.
The islands form the Macaronesia ecoregion with the Azores, Cape Verde, Madeira, and the Savage Isles. The archipelago consists of seven large and several smaller islands, all of which are volcanic in origin. The Teide volcano on Tenerife is the highest mountain in Spain, and the third tallest volcano on Earth on a volcanic ocean island. All the islands except La Gomera have been active in the last million years; four of them (Lanzarote, Tenerife, La Palma and El Hierro) have historical records of eruptions since European discovery. The islands rise from Jurassic oceanic crust associated with the opening of the Atlantic. Underwater magmatism commenced during the Cretaceous, and reached the ocean's surface during the Miocene. The islands are considered as a distinct physiographic section of the Atlas Mountains province, which in turn is part of the larger African Alpine System division.
In the summer of 2011 a series of low-magnitude earthquakes occurred beneath El Hierro. These had a linear trend of northeast-southwest. In October a submarine eruption occurred about south of Restinga. This eruption produced gases and pumice but no explosive activity was reported.
According to the position of the islands with respect to the north-east trade winds, the climate can be mild and wet or very dry. Several native species form laurisilva forests.
As a consequence, the individual islands in the Canary archipelago tend to have distinct microclimates. Those islands such as El Hierro, La Palma and La Gomera lying to the west of the archipelago have a climate which is influenced by the moist Gulf Stream. They are well vegetated even at low levels and have extensive tracts of sub-tropical laurisilva forest. As one travels east toward the African coast, the influence of the gulf stream diminishes, and the islands become increasingly arid. Fuerteventura and Lanzarote the islands which are closest to the African mainland are effectively desert or semi desert. Gran Canaria is known as a "continent in miniature" for its diverse landscapes like Maspalomas and Roque Nublo. In terms of its climate Tenerife is particularly interesting. The north of the island lies under the influence of the moist Atlantic winds and is well vegetated, while the south of the island around the tourist resorts of Playa de las Americas and Los Cristianos is arid. The island rises to almost above sea level, and at altitude, in the cool relatively wet climate, forests of the endemic pine "Pinus canariensis" thrive. Many of the plant species in the Canary Islands, like the Canary Island pine and the dragon tree, "Dracaena draco" are endemic, as noted by Sabin Berthelot and Philip Barker Webb in their epic work, "L'Histoire Naturelle des Îles Canaries" (1835–50).
Four of Spain's thirteen national parks are located in the Canary Islands, more than any other autonomous community. Teide National Park is the most visited in Spain, and the oldest and largest within the Canary Islands. The parks are:
The following table shows the highest mountains in each of the islands:
Climate.
The climate is subtropical and desertic, moderated by the sea and in summer by the trade winds. There are a number of microclimates and the classifications range mainly from semi-arid to desert. According to the Köppen climate classification, the majority of the Canary Islands have a hot desert climate represented as BWh. There also exists a subtropical humid climate which is very influenced by the ocean in the middle of the islands of La Gomera, Tenerife and La Palma; where the laurisilva forests grow.
Geology.
The originally volcanic islands –seven major islands, one minor island, and several small islets– were formed by the Canary hotspot. The Canary Islands is the only place in Spain where volcanic eruptions have been recorded during the Modern Era, with some volcanoes still active (El Hierro, 2011).
Volcanic islands such as the those in the Canary chain often have steep ocean cliffs caused by catastrophic debris avalanches and landslides.
Political geography.
The Autonomous Community of the Canary Islands consists of two provinces, Las Palmas and Santa Cruz de Tenerife, whose capitals (Las Palmas de Gran Canaria and Santa Cruz de Tenerife) are capitals of the autonomous community. Each of the seven major islands is ruled by an island council named "Cabildo Insular".
The international boundary of the Canaries is the subject of dispute between Spain and Morocco. Morocco's official position is that international laws regarding territorial limits do not authorise Spain to claim seabed boundaries based on the territory of the Canaries, since the Canary Islands enjoy a high degree of autonomy. 
The boundary determines the ownership of seabed oil deposits and other ocean resources. Morocco and Spain have therefore been unable to agree on a compromise regarding the territorial boundary, since neither nation wants to cede its claimed right to the vast resources whose ownership depends upon the boundary. In 2002, for example, Morocco rejected a unilateral Spanish proposal.
The Islands have 13 seats in the Spanish Senate. Of these, 11 seats are directly elected, 3 for Gran Canaria, 3 for Tenerife, 1 for each other island; 2 seats are indirectly elected by the regional Autonomous Government. The local government is presided over by Paulino Rivero, the current President of the Canary Islands.
History.
Ancient and pre-colonial times.
Before the arrival of the aborigines, the Canaries were inhabited by prehistoric animals; for example, the giant lizard ("Gallotia goliath"), or giant rats ("Canariomys bravoi" and "Canariomys tamarani").
The islands were visited by the Phoenicians, the Greeks, and the Carthaginians. According to the 1st century AD Roman author and philosopher Pliny the Elder, the archipelago was found to be uninhabited when visited by the Carthaginians under Hanno the Navigator, but that they saw ruins of great buildings. This story may suggest that the islands were inhabited by other peoples prior to the Guanches. King Juba, Augustus's Numidian protégé, is credited with discovering the islands for the Western world. He dispatched a naval contingent to re-open the dye production facility at Mogador in what is now western Morocco in the early 1st century AD. That same naval force was subsequently sent on an exploration of the Canary Islands, using Mogador as their mission base.
The Romans named the islands "Ninguaria" or "Nivaria" (Tenerife), "Canaria" (Gran Canaria), "Pluvialia" or "Invale" (Lanzarote), "Ombrion" (La Palma), "Planasia" (Fuerteventura), "Iunonia" or "Junonia" (El Hierro) and "Capraria" (La Gomera).
When the Europeans began to explore the islands in the late Middle Ages, they encountered several indigenous populations living at a Neolithic level of technology. Although the prehistory of the settlement of the Canary Islands is still unclear, linguistic and genetic analyses seem to indicate that at least some of these inhabitants shared a common origin with the Berbers of northern Africa. The pre-colonial inhabitants came to be known collectively as the Guanches, although "Guanches" was originally the name for only the indigenous inhabitants of Tenerife. From the 14th century onward, numerous visits were made by sailors from Majorca, Portugal and Genoa. Lancelotto Malocello settled on Lanzarote in 1312. The Majorcans established a mission with a bishop in the islands that lasted from 1350 to 1400.
Castilian conquest.
There may have been a Portuguese expedition that attempted to colonise the islands as early as 1336, but there is not enough hard evidence to support this. In 1402, the Castilian conquest of the islands began, with the expedition of French explorers Jean de Béthencourt and Gadifer de la Salle, nobles and vassals of Henry III of Castile, to Lanzarote. From there, they conquered Fuerteventura (1405) and El Hierro. Béthencourt received the title King of the Canary Islands, but still recognised King Henry III as his overlord.
Béthencourt also established a base on the island of La Gomera, but it would be many years before the island was truly conquered. The natives of La Gomera, and of Gran Canaria, Tenerife, and La Palma, resisted the Castilian invaders for almost a century. In 1448 Maciot de Béthencourt sold the lordship of Lanzarote to Portugal's Prince Henry the Navigator, an action that was not accepted by the natives nor by the Castilians. Despite Pope Nicholas V ruling that the Canary Islands were under Portuguese control, a crisis swelled to a revolt which lasted until 1459 with the final expulsion of the Portuguese. In 1479, Portugal and Castile signed the Treaty of Alcáçovas. The treaty settled disputes between Castile and Portugal over the control of the Atlantic, in which Castilian control of the Canary Islands was recognised but which also confirmed Portuguese possession of the Azores, Madeira, the Cape Verde islands and gave them rights to lands discovered and to be discovered ... and any other island which might be found and conquered from the Canary islands beyond toward Guinea.
The Castilians continued to dominate the islands, but due to the topography and the resistance of the native Guanches, complete pacification was not achieved until 1495, when Tenerife and La Palma were finally subdued by Alonso Fernández de Lugo. After that, the Canaries were incorporated into the Kingdom of Castile.
After the conquest.
After the conquest, the Castilians imposed a new economic model, based on single-crop cultivation: first sugar cane; then wine, an important item of trade with England. In this era, the first institutions of colonial government were founded. Both Gran Canaria, a colony of Castile since March 6, 1480 (from 1556, of Spain), and Tenerife, a Spanish colony since 1495, had separate governors.
The cities of Santa Cruz de Tenerife and Las Palmas de Gran Canaria became a stopping point for the Spanish conquerors, traders, and missionaries on their way to the New World. This trade route brought great prosperity to some of the social sectors of the islands. The islands became quite wealthy and soon were attracting merchants and adventurers from all over Europe. Magnificent palaces and churches were built on La Palma during this busy, prosperous period. The Church of El Salvador survives as one of the island's finest examples of the architecture of the 16th century.
The Canaries' wealth invited attacks by pirates and privateers. Ottoman Turkish admiral and privateer Kemal Reis ventured into the Canaries in 1501, while Murat Reis the Elder captured Lanzarote in 1585.
The most severe attack took place in 1599, during the Dutch War of Independence. A Dutch fleet of 74 ships and 12,000 men, commanded by Pieter van der Does, attacked the capital Las Palmas de Gran Canaria (the city had 3,500 of Gran Canaria's 8,545 inhabitants). The Dutch attacked the Castillo de la Luz, which guarded the harbor. The Canarians evacuated civilians from the city, and the Castillo surrendered (but not the city). The Dutch moved inland, but Canarian cavalry drove them back to Tamaraceite, near the city.
The Dutch then laid siege to the city, demanding the surrender of all its wealth. They received 12 sheep and 3 calves. Furious, the Dutch sent 4,000 soldiers to attack the Council of the Canaries, who were sheltering in the village of Santa Brígida. 300 Canarian soldiers ambushed the Dutch in the village of Monte Lentiscal, killing 150 and forcing the rest to retreat. The Dutch concentrated on Las Palmas de Gran Canaria, attempting to burn it down. The Dutch pillaged Maspalomas, on the southern coast of Gran Canaria, San Sebastian on La Gomera, and Santa Cruz on La Palma, but eventually gave up the siege of Las Palmas de Gran Canaria and withdrew.
In 1618 the Algerian pirates attacked Lanzarote and La Gomera taking 1000 captives to be sold as slaves. Another noteworthy attack occurred in 1797, when Santa Cruz de Tenerife was attacked by a British fleet under the future Lord Nelson on 25 July. The British were repulsed, losing almost 400 men. It was during this battle that Nelson lost his right arm.
18th to 19th century.
The sugar-based economy of the islands faced stiff competition from Spain's American colonies. Low prices in the sugar market in the 19th century caused severe recessions on the islands. A new cash crop, cochineal ("cochinilla"), came into cultivation during this time, saving the islands' economy.
By the end of the 18th century, Canary Islanders had already emigrated to Spanish American territories, such as Havana, Veracruz, Santo Domingo, San Antonio, Texas and St. Bernard Parish, Louisiana. These economic difficulties spurred mass emigration, primarily to the Americas, during the 19th and first half of the 20th century. Between 1840 and 1890 as many as 40,000 Canary Islanders emigrated to Venezuela. Also, thousands of Canarians moved to Puerto Rico where the Spanish monarchy felt that Canarians would adapt to island life better than other immigrants from the mainland of Spain. Deeply entrenched traditions, such as the Mascaras Festival in the town of Hatillo, Puerto Rico, are an example of Canarian culture still preserved in Puerto Rico. Similarly, many thousands of Canarians emigrated to the shores of Cuba. During the Spanish–American War of 1898, the Spanish fortified the islands against possible American attack, but an attack never came.
Romantic period and scientific expeditions.
Sirera and Renn (2004) distinguish two different types of expeditions, or voyages, during the period 1770–1830, which they term "the Romantic period":
First are "expeditions financed by the States, closely related with the official scientific Institutions. characterised by having strict scientific objectives (and inspired by) the spirit of Illustration and progress".
In this type of expedition, Sirera and Renn include the following travellers:
The second type of expedition identified by Sirera and Renn is one that took place starting from more or less private initiatives. Among these, the key exponents were the following:
Sirera and Renn identify the period 1770–1830 as one in which "In a panorama dominated until that moment by France and England enters with strength and brio Germany of the Romantic period whose presence in the islands will increase".
Early 20th century.
At the beginning of the 20th century, the British introduced a new cash-crop, the banana, the export of which was controlled by companies such as Fyffes.
The rivalry between the elites of the cities of Las Palmas de Gran Canaria and Santa Cruz de Tenerife for the capital of the islands led to the division of the archipelago into two provinces in 1927. This has not laid to rest the rivalry between the two cities, which continues to this day.
During the time of the Second Spanish Republic, Marxist and anarchist workers' movements began to develop, led by figures such as Jose Miguel Perez and Guillermo Ascanio. However, outside of a few municipalities, these organisations were a minority and fell easily to Nationalist forces during the Spanish Civil War.
Franco regime.
In 1936, Francisco Franco was appointed General Commandant of the Canaries. He joined the military revolt of July 17 which began the Spanish Civil War. Franco quickly took control of the archipelago, except for a few points of resistance on La Palma and in the town of Vallehermoso, on La Gomera. Though there was never a proper war in the islands, the post-war suppression of political dissent on the Canaries was most severe.
During the Second World War, Winston Churchill prepared plans for the British seizure of the Canary Islands as a naval base, in the event of Gibraltar being invaded from the Spanish mainland.
Opposition to Franco's regime did not begin to organise until the late 1950s, which experienced an upheaval of parties such as the Communist Party of Spain and the formation of various nationalist, leftist parties.
Self-governance.
After the death of Franco, there was a pro-independence armed movement based in Algeria, the Movement for the Independence and Self-determination of the Canaries Archipelago (MAIAC). In 1968, the Organisation of African Unity recognized the MAIAC as a legitimate African independence movement, and declared the Canary Islands as an African territory still under foreign rule.
Currently, there are some pro-independence political parties, like the CNC and the Popular Front of the Canary Islands, but these parties are non-violent, and their popular support is almost insignificant, with no presence in either the autonomous parliament or the "cabildos insulares".
After the establishment of a democratic constitutional monarchy in Spain, autonomy was granted to the Canaries via a law passed in 1982. In 1983, the first autonomous elections were held. The Spanish Socialist Workers' Party (PSOE) won. In the 2007 elections, the PSOE gained a plurality of seats, but the nationalist Canarian Coalition and the conservative Partido Popular (PP) formed a ruling coalition government.
According to "Centro de Investigaciones Sociológicas" (Sociological Research Center) in 2010, 43.5% of the population of the Canary Islands feels more Canarian than Spanish (37.6%), only Canarian (7.6%), compared to 5.4% that feels more Spanish than Canarian (2.4%) or only Spanish (3%). The most popular choice of those who feel equally Spanish and Canarian, with 49.9%. With these data, one of the Canary recorded levels of identification with higher autonomy from Spain.
Demographics.
The Canary Islands have a population of 2,117,519 inhabitants (2011), making it the eighth most populous of Spain's autonomous communities, with a density of 282.6 inhabitants per km². The total area of the archipelago is .
The Canarian population includes long-tenured residents and new waves of mainland Spanish immigrants, as well as Portuguese, Italians, Flemings and Britons. Of the total Canarian population in 2009 (2,098,593) 1,799,373 were Spanish and 299,220 foreigners. Of these, the majority are Europeans (55%), including Germans (39,505), British (37,937) and Italians (24,177). There are also 86,287 inhabitants from the Americas, mainly Colombians (21,798), Venezuelans (11,958), Cubans (11,098) and Argentines (10,159). There are also 28,136 African residents, mostly Moroccans (16,240).
Population of the individual islands.
The population of the islands according to the 2010 data are:
Religion.
The Roman Catholic branch of Christianity has been since the Conquest of the Canary Islands the majority religion in the archipelago (for more than five centuries). However, there are other religious communities:
Roman Catholic Church.
The overwhelming majority of native Canarians are Roman Catholic with various smaller foreign-born populations of other Christian beliefs such as Protestants from northern Europe.
The appearance of the Virgin of Candelaria (Patron of Canary Islands) was credited with moving the Canary Islands toward Christianity. In the Canary Islands they were born two important Catholic saints: Peter of Saint Joseph de Betancur and José de Anchieta. Both born on the island of Tenerife, they were respectively missionaries in Guatemala and Brazil.
The Canary Islands are divided into two Catholic dioceses, each governed by a bishop:
Other religions.
Separate from the overwhelming Christian majority are a minority of Muslims, though no official mention is made of them. Other religious faiths represented include The Church of Jesus Christ of Latter-day Saints as well as Hinduism. Minority religions are also present such as the Church of the Guanche People which is classified as a neo-pagan native religion, it also highlights Buddhism, Baha'i, Chinese religions and Afro-American religion.
Statistics.
The distribution of beliefs in 2012 according to the CIS Barometer Autonomy was as follows:
Among the believers 38.7% go to religious services frequently.
Islands.
El Hierro.
El Hierro, the westernmost island, covers , making it the smallest of the major islands, and the least populous with 10,753 inhabitants. The whole island was declared Reserve of the Biosphere in 2000. Its capital is Valverde. Also known as Ferro, it was once believed to be the westernmost land in the world.
Fuerteventura.
Fuerteventura, with a surface of , is the second-most extensive island of the archipelago. It has been declared a Biosphere reserve by Unesco. It has a population of 100,929. Being also the most ancient of the islands, it is the one that is more eroded: its highest point is the Peak of the Bramble, at a height of . Its capital is Puerto del Rosario.
Gran Canaria.
Gran Canaria has 845,676 inhabitants. The capital, Las Palmas de Gran Canaria (377,203 inhabitants), is the most populous city and shares the status of capital of the Canaries with Santa Cruz de Tenerife. Gran Canaria's surface area is . In center of the island lie the Roque Nublo and Pico de las Nieves ("Peak of Snow") . In the south of island are the Maspalomas Dunes (Gran Canaria), these are the biggest tourist attractions.
La Gomera.
La Gomera has an area of and is the second least populous island with 22,622 inhabitants. Geologically it is one of the oldest of the archipelago. The insular capital is San Sebastian de La Gomera. Garajonay's National Park is here.
Lanzarote.
Lanzarote is the easternmost island and one of the most ancient of the archipelago, and it has shown evidence of recent volcanic activity. It has a surface of , and a population of 139,506 inhabitants, including the adjacent islets of the Chinijo Archipelago. The capital is Arrecife, with 56,834 inhabitants.
Chinijo Archipelago.
The Chinijo Archipelago includes the islands La Graciosa, Alegranza, Montaña Clara, Roque del Este and Roque del Oeste. It has a surface of , and a population of 658 inhabitants all of them in the la Graciosa island. With , La Graciosa, is the smallest inhabited island of the Canaries, and the major island of the Chinijo Archipelago.
La Palma.
La Palma, with 86,528 inhabitants covering an area of , is in its entirety a biosphere reserve. It shows no recent signs of volcanic activity, even though the volcano Teneguía entered into eruption last in 1971. In addition, it is the second-highest island of the Canaries, with the Roque de los Muchachos as highest point. Santa Cruz de La Palma (known to those on the island as simply "Santa Cruz") is its capital.
Tenerife.
Tenerife is, with its area of , the most extensive island of the Canary Islands. In addition, with 906,854 inhabitants it is the most populated island of the archipelago and Spain. Two of the islands' principal cities are located on it: The capital, Santa Cruz de Tenerife and San Cristóbal de La Laguna (a World Heritage Site). San Cristóbal de La Laguna, the second city of the island is home to the oldest university in the Canary Islands, the University of La Laguna. The Teide, with its is the highest peak of Spain and also a World Heritage Site. Tenerife is the site of the worst air disaster in the history of aviation, in which 583 people were killed in the collision of two Boeing 747s on March 27, 1977.
Economy.
The economy is based primarily on tourism, which makes up 32% of the GDP. The Canaries receive about 12 million tourists per year. Construction makes up nearly 20% of the GDP and tropical agriculture, primarily bananas and tobacco, are grown for export to Europe and the Americas. Ecologists are concerned that the resources, especially in the more arid islands, are being overexploited but there are still many agricultural resources like tomatoes, potatoes, onions, cochineal, sugarcane, grapes, vines, dates, oranges, lemons, figs, wheat, barley, maize, apricots, peaches and almonds.
The economy is € 25 billion (2001 GDP figures). The islands experienced continuous growth during a 20-year period, up until 2001, at a rate of approximately 5% annually. This growth was fueled mainly by huge amounts of Foreign Direct Investment, mostly to develop tourism real estate (hotels and apartments), and European Funds (near €11 billion euro in the period from 2000 to 2007), since the Canary Islands are labelled Region Objective 1 (eligible for euro structural funds). Additionally, the EU allows the Canary Islands Government to offer special tax concessions for investors who incorporate under the Zona Especial Canaria (ZEC) regime and create more than 5 jobs.
Spain gave permission in August 2014 for Repsol and its partners to explore oil and gas prospects off the Canary Islands, involving an investment of €7.5 billion over four years, commencing at the end of 2016. Repsol at the time said the area could ultimately produce 100,000 barrels of oil a day, which would meet 10 percent of Spain's energy needs.
The Canary Islands have great natural attractions, climate and beaches make the islands a major tourist destination, being visited each year by about 12 million people (11,986,059 in 2007, noting 29% of Britons, 22% of Spanish, not residents of the Canaries, and 21% of Germans). Among the islands, Tenerife has the largest number of tourists received annually, followed by Gran Canaria and Lanzarote. The archipelago's principal tourist attraction is the Teide National Park (in Tenerife) where the highest mountain in Spain and third largest volcano in the world (Mount Teide), receives over 2.8 million visitors annually.
The combination of high mountains, proximity to Europe, and clean air has made the Roque de los Muchachos peak (on La Palma island) a leading location for telescopes like the Grantecan.
The islands are outside the European Union customs territory and VAT area, though politically within the EU. Instead of VAT there is a local Sales Tax (IGIC) which has a general rate of 7%, an increased tax rate of 13.5%, a reduced tax rate of 3% and a zero tax rate for certain basic need products and services. Consequently, some products are subject to import tax and VAT if being exported from the islands into mainland Spain or the rest of the EU.
Canarian time is Western European Time (WET) (or GMT; in summer one hour ahead of GMT). So Canarian time is one hour behind that of mainland Spain and the same as that of the UK, Ireland and Portugal all year round.
Transport.
The Canary Islands have eight airports altogether, two of the main ports of Spain, and an extensive network of autopistas (highways) and other roads. For a road map see multimap.
There are large ferry boats that link islands as well as fast ferries linking most of the islands. Both types can transport large numbers of passengers and cargo (including vehicles). Fast ferries are made of aluminium and powered by modern and efficient diesel engines, while conventional ferries have a steel hull and are powered by heavy oil. Fast ferries travel relatively quickly (in excess of 30 knots) and are a faster method of transportation than the conventional ferry (some 20 knots). A typical ferry ride between La Palma and Tenerife may take up to eight hours or more while a fast ferry takes about 2 and a half hours and between Tenerife and Gran Canaria can be about one hour.
The largest airport is the Gran Canaria airport. It is also the 5th largest airport in Spain. The biggest port is in Las Palmas de Gran Canaria. It is an important port for commerce with Europe, Africa and the Americas. It is the 4th biggest commercial port in Spain with more than 1,400,000 TEU's. The largest commercial companies of the world, including MSC and Maersk, operate here. In this port there is an international post of the Red Cross, one of only four points like this all around the world. Tenerife has two airports, Tenerife North Airport and Tenerife South Airport.
The two main islands (Tenerife and Gran Canaria) receive the greatest number of passengers.
The port of Las Palmas is first in freight traffic in the islands, while the port of Santa Cruz de Tenerife is the first fishing port with approximately 7,500 tons of fish caught, according to the Spanish government publication Statistical Yearbook of State Ports. Similarly, it is the second port in Spain as regards ship traffic, only surpassed by the Port of Algeciras Bay. The port's facilities include a border inspection post (BIP) approved by the European Union, which is responsible for inspecting all types of imports from third countries or exports to countries outside the European Economic Area. The port of Los Cristianos (Tenerife) has the greatest number of passengers recorded in the Canary Islands, followed by the port of Santa Cruz de Tenerife. The Port of Las Palmas is the third port in the islands in passengers and first in number of vehicles transported.
Rail transport.
The Tenerife Tram opened in 2007 and the only one in the Canary Islands, travelling between the cities of Santa Cruz de Tenerife and San Cristóbal de La Laguna. It is currently planned to have three lines in the Canary Islands (two in Tenerife and one in Gran Canaria). The planned Gran Canaria tram route will be from Las Palmas de Gran Canaria to Maspalomas (south).
Wildlife.
The official symbols from nature associated with Canary Islands are the bird "Serinus canaria" (canary) and the "Phoenix canariensis" palm.
Terrestrial wildlife.
With a range of habitats, the Canary Islands exhibit diverse plant species. The bird life includes European and African species, such as the black-bellied sandgrouse; and a rich variety of endemic (local) taxa including the:
Terrestrial fauna includes geckos (such as the striped Canary Islands gecko) and wall lizards, and three endemic species of recently rediscovered and critically endangered giant lizard: the El Hierro giant lizard (or Roque Chico de Salmor giant lizard), La Gomera giant lizard, and La Palma giant lizard. Mammals include the Canarian shrew, Canary big-eared bat, the Algerian hedgehog (which may have been introduced) and the more recently introduced mouflon. Some endemic mammals, the lava mouse, Tenerife giant rat and Gran Canaria giant rat, are extinct, as are the Canary Islands quail, long-legged bunting, and the eastern Canary Islands chiffchaff.
Marine life.
The marine life found in the Canary Islands is also varied, being a combination of North Atlantic, Mediterranean and endemic species. In recent years, the increasing popularity of both scuba diving and underwater photography have provided biologists with much new information on the marine life of the islands.
Fish species found in the islands include many species of shark, ray, moray eel, bream, jack, grunt, scorpionfish, triggerfish, grouper, goby, and blenny. In addition, there are many invertebrate species, including sponge, jellyfish, anemone, crab, mollusc, sea urchin, starfish, sea cucumber and coral.
There are a total of 5 different species of marine turtle that are sighted periodically in the islands, the most common of these being the endangered loggerhead sea turtle. The other four are the green sea turtle, hawksbill sea turtle, leatherback sea turtle and Kemp's ridley sea turtle. Currently, there are no signs that any of these species breed in the islands, and so those seen in the water are usually migrating. However, it is believed that some of these species may have bred in the islands in the past, and there are records of several sightings of leatherback sea turtle on beaches in Fuerteventura, adding credibility to the theory.
Marine mammals include the large varieties of cetaceans including rare and not well-known species (see more details in the "Marine life of the Canary Islands"). Hooded seals have also been known to be vagrant in the Canary Islands every now and then. The Canary Islands were also formerly home to a population of the rarest pinniped in the world, the Mediterranean monk seal.
National parks of the Canary Islands.
The Canary Islands officially has four national parks, of which two have been declared World Heritage Site by UNESCO, and the other two declared a World Biosphere Reserve, these national parks are:
Sports.
A unique form of wrestling known as Canarian wrestling ("lucha canaria") has opponents stand in a special area called a "terrero" and try to throw each other to the ground using strength and quick movements.
Another sport is the "game of the sticks" where opponents fence with long sticks. This may have come about from the shepherds of the islands who would challenge each other using their long walking sticks.
Another sport is called the shepherd's jump ("salto del pastor"). This involves using a long stick to vault over an open area. This sport possibly evolved from the shepherd's need to occasionally get over an open area in the hills as they were tending their sheep.
The two main football teams in the archipelago are: the CD Tenerife (founded in 1912) and UD Las Palmas (founded in 1949). Now Tenerife play in Liga Adelante and Las Palmas in La Liga.
Carnival.
The Carnival of Santa Cruz de Tenerife and Carnival of Las Palmas are one of the most famous Carnivals in Spain. It is celebrated on the streets between the months of February and March.

</doc>
<doc id="5718" url="https://en.wikipedia.org/wiki?curid=5718" title="Chuck D">
Chuck D

Carlton Douglas Ridenhour (born August 1, 1960), better known by his stage name Chuck D, is an American emcee, author, and producer. He helped create politically and socially conscious hip hop music in the mid-1980s as the leader of the rap group Public Enemy. About.com ranked him at No. 9 on their list of the Top 50 MCs of Our Time, while "The Source" ranked him at No. 12 on their list of the Top 50 Hip-Hop Lyricists of All Time.
Early life.
Ridenhour was born in Queens, New York. After graduating from Roosevelt Junior-Senior High School, he went to Adelphi University on Long Island to study graphic design, where he met William Drayton (Flavor Flav). He received a B.F.A. from Adelphi in 1984 and later received an honorary doctorate from Adelphi in 2013. He is the son of Lorenzo Ridenhour.
Career.
Upon hearing Ridenhour's demo track "Public Enemy Number One", fledgling producer/upcoming music-mogul Rick Rubin insisted on signing him to his Def Jam label.
Their major label albums were "Yo! Bum Rush the Show" (1987), "It Takes a Nation of Millions to Hold Us Back" (1988), "Fear of a Black Planet" (1990), "Apocalypse 91... The Enemy Strikes Black" (1991), "Greatest Misses" (1992), and "Muse Sick-n-Hour Mess Age" (1994). They also released a full-length album soundtrack for the film "He Got Game" in 1998. Ridenhour also contributed (as Chuck D) to several episodes of the PBS documentary series "The Blues". He has appeared as a featured artist on many other songs and albums, having collaborated with artists such as Janet Jackson, Kool Moe Dee, The Dope Poet Society, Run–D.M.C., Ice Cube, Boom Boom Satellites, Rage Against the Machine, Anthrax, John Mellencamp and many others. In 1990, he appeared on "Kool Thing", a song by the alternative rock band Sonic Youth, and along with Flavor Flav, he sang on George Clinton's song "Tweakin'", which appears on his 1989 album "The Cinderella Theory". In 1993, he executive produced "Got 'Em Running Scared", an album by Ichiban Records group Chief Groovy Loo and the Chosen Tribe.
Later career.
In 1996, Ridenhour released "Autobiography of Mistachuck" on Mercury Records. Chuck D made a rare appearance at the 1998 MTV Video Music Awards, presenting the Video Vanguard Award to the Beastie Boys, whilst commending their musicianship. In November 1998, he settled out of court with Christopher "The Notorious B.I.G." Wallace's estate over the latter's sampling of his voice in the song "Ten Crack Commandments". The specific sampling is Ridenhour counting off the numbers one to nine on the track "Shut 'Em Down".
In September 1999, he launched a multi-format "supersite" on the web site Rapstation.com. A home for the vast global hip hop community, the site boasts a TV and radio station with original programming, many of hip hop's most prominent DJs, celebrity interviews, free MP3 downloads (the first was contributed by multi-platinum rapper Coolio), downloadable ringtones by ToneThis, social commentary, current events, and regular features on turning rap careers into a viable living. Since 2000, he has been one of the most vocal supporters of peer-to-peer file sharing in the music industry.
He loaned his voice to ' as DJ Forth Right MC for the radio station Playback FM. In 2000, he collaborated with Public Enemy's Gary G-Whiz and MC Lyte on the theme music to the television show "Dark Angel". He appeared with Henry Rollins in a cover of Black Flag's "Rise Above" for the album '. He was also featured on Z-Trip's album "Shifting Gears" on a track called "Shock and Awe"; a 12-inch of the track was released featuring artwork by Shepard Fairey. In 2008 he contributed a chapter to "Sound Unbound: Sampling Digital Music and Culture" (The MIT Press, 2008) edited by Paul D. Miller a.k.a. DJ Spooky, and also turned up on The Go! Team's album "Proof of Youth" on the track "Flashlight Fight." He also fulfilled his childhood dreams of being a sports announcer by performing the play-by-play commentary in the video game "NBA Ballers: Chosen One" on Xbox 360 and PlayStation 3.
In 2009, Ridenhour wrote the foreword to the book "The Love Ethic: The Reason Why You Can't Find and Keep Beautiful Black Love" by Kamau and Akilah Butler. He also appeared on Brother Ali's album, "Us".
In March 2011, Chuck D re-recorded vocals with The Dillinger Escape Plan for a cover of "Fight the Power".
Chuck D duetted with Rock singer Meat Loaf on his 2011 album "Hell in a Handbasket" on the song "Mad Mad World/The Good God Is a Woman and She Don't Like Ugly".
Rapping technique and creative process.
Chuck D is known for his powerful rapping voice - "How to Rap" says, “Chuck D of Public Enemy has a powerful, resonant voice that is often acclaimed as one of the most distinct and impressive in hip-hop”. Chuck D says this was based on listening to Melle Mel and sportscasters such as Marv Albert.
Chuck D often comes up with a title for a song first and that he writes on paper, though he sometimes edits using a computer. He also prefers to not punch in vocals, and he prefers to not overdub vocals.
Politics.
Ridenhour is politically active; he co-hosted "Unfiltered" on Air America Radio, testified before Congress in support of peer-to-peer MP3 sharing, and was involved in a 2004 rap political convention. He continues to be an activist, publisher, lecturer, and producer. Addressing the negative views associated with rap music, he co-wrote the essay book "Fight the Power: Rap, Race, and Reality", along with Yusuf Jah. He argues that "music and art and culture is escapism, and escapism sometimes is healthy for people to get away from reality", but sometimes the distinction is blurred and that's when "things could lead a young mind in a direction." He also founded the record company Slam Jamz and acted as narrator in Kareem Adouard's short film "Bling: Consequences and Repercussions", which examines the role of conflict diamonds in bling fashion. Despite Chuck D and Public Enemy's success, Chuck D claims that popularity or public approval was never a driving motivation behind their work. He is admittedly skeptical of celebrity status, revealing in a 1999 interview with BOMB Magazine that, "The key for the record companies is to just keep making more and more stars, and make the ones who actually challenge our way of life irrelevant. The creation of celebrity has clouded the minds of most people in America, Europe and Asia. It gets people off the path they need to be on as individuals." 
In an interview with "Le Monde" published January 29, 2008, Chuck D stated that rap is devolving so much into a commercial enterprise, that the relationship between the rapper and the record label is that of slave to a master. He believes that nothing has changed for African-Americans since the debut of Public Enemy and, although he thinks that an Obama-Clinton alliance is great, he does not feel that the establishment will allow anything of substance to be accomplished. He also stated that French President Sarkozy is like any other European elite: he has profited through the murder, rape, and pillaging of those less fortunate and he refuses to allow equal opportunity for those men and women from Africa. In this article, he also defended a comment made by Professor Griff in the past that he says was taken out of context by the media. The real statement was a critique of the Israeli government and its treatment of the Palestinian people. Chuck D stated that it is Public Enemy's belief that all human beings are equal.
In an interview with the magazine "N'Digo" published in late June 2008, he spoke of today's mainstream urban music seemingly relishing the addictive euphoria of materialism and sexism, perhaps being the primary cause of many people harboring resentment towards the genre and its future. However he has expressed hope for its resurrection, saying "It's only going to be dead if it doesn’t talk about the messages of life as much as the messages of death and non-movement", citing artists such as NYOil, M.I.A. and The Roots as socially conscious artists who push the envelope creatively. "A lot of cats are out there doing it, on the Web and all over. They’re just not placing their career in the hands of some major corporation."
Most recently Chuck D became involved in "Let Freedom Sing: The Music of the Civil Rights", a 3-CD box set from Time Life. He wrote the introduction to the liner notes and is visiting colleges across the nation discussing the significance of the set. He's also set to appear in a follow up movie called "Let Freedom Sing: The Music That Inspired the Civil Rights Movement".
In 2010, Chuck D released a track entitled "Tear Down That Wall". He said, “I talked about the wall not only just dividing the U.S. and Mexico but the states of California, New Mexico and Texas. But Arizona, it's like, come on. Now they're going to enforce a law that talks about basically racial profiling.”
He is on the board of the TransAfrica Forum a Pan African organization that works for the right of Africa, Caribbean and Latin American issues.
Personal life.
Chuck D is married to Gaye Theresa Johnson, an associate professor in the Department of Black Studies at the University of California, Santa Barbara.
He is a pescatarian.
Discography.
Chuck D.
Studio albums
Compilation albums

</doc>
<doc id="5719" url="https://en.wikipedia.org/wiki?curid=5719" title="Cutaway (filmmaking)">
Cutaway (filmmaking)

In film and video, a cutaway shot is the interruption of a continuously filmed action by inserting a view of something else. It is usually, although not always, followed by a cut back to the first shot, when the cutaway avoids a jump cut. The cutaway shot does not necessarily contribute any dramatic content of its own, but is used to help the editor assemble a longer sequence. For this reason, editors choose cutaway shots related to the main action, such as another action or object in the same location. For example, if the main shot is of a man walking down an alley, possible cutaways may include a shot of a cat on a nearby dumpster or a shot of a person watching from a window overhead.
Similarly, a cutaway scene is the interruption of a scene with the insertion of another scene, generally unrelated or only peripherally related to the original scene. The interruption is usually quick, and is usually, although not always, ended by a return to the original scene. The effect is of commentary to the original scene, frequently comic in nature.
Usage.
The most common use of cutaway shots in dramatic films is to adjust the pace of the main action, to conceal the deletion of some unwanted part of the main shot, or to allow the joining of parts of two versions of that shot. For example, a scene may be improved by cutting a few frames out of an actor's pause; a brief view of a listener can help conceal the break. Or the actor may fumble some of his lines in a group shot; rather than discarding a good version of the shot, the director may just have the actor repeat the lines for a new shot, and cut to that alternate view when necessary.
Cutaways are also used often in older horror films in place of special effects. For example, a shot of a zombie getting its head cut off may, for instance, start with a view of an axe being swung through the air, followed by a close-up of the actor swinging it, then followed by a cut back to the now severed head. George A. Romero, creator of the Dead Series, and Tom Savini pioneered effects that removed the need for cutaways in horror films. The animated television show "Family Guy" often uses cutaway gags as humor.
In news broadcasting and documentary work, the cutaway is used much as it would be in fiction. On location, there is usually just one camera to film an interview, and it's usually trained on the interviewee. Often there is also only one microphone. After the interview, the interviewer will usually repeat his questions while he himself is being filmed, with pauses as they act as if to listen to the answers. These shots can be used as cutaways. Cutaways to the interviewer, called noddies, can also be used to cover cuts.

</doc>
<doc id="5721" url="https://en.wikipedia.org/wiki?curid=5721" title="Coma">
Coma

In medicine, coma (from the Greek "koma", meaning "deep sleep") is a state of unconsciousness in which a person: cannot be awakened; fails to respond normally to painful stimuli, light, or sound; lacks a normal wake-sleep cycle; and does not initiate voluntary actions. A person in a state of coma is described as being comatose. Typically, a distinction is made in the medical community between a coma and a medically induced coma, the former is generally understood to be a result of circumstances beyond the control of the medical community, while the latter is generally understood to be a means by which medical professionals may allow a patient's injuries to heal in a controlled environment.
A comatose person exhibits a complete absence of wakefulness and is unable to consciously feel, speak, hear, or move. For a patient to maintain consciousness, two important neurological components must function. The first is the cerebral cortex—the gray matter that forms the outer layer of the brain. The other is a structure located in the brainstem, called reticular activating system (RAS).
Injury to either or both of these components is sufficient to cause a patient to experience a coma. The cerebral cortex is a group of tight, dense, "gray matter" composed of the nuclei of the neurons whose axons then form the "white matter", and is responsible for perception, relay of the sensory input (sensation) via the thalamic pathway, and many other neurological functions, including complex thinking.
RAS, on the other hand, is a more primitive structure in the brainstem that is tightly in connection with reticular formation (RF). The RAS area of the brain has two tracts, the ascending and descending tract. Made up of a system of acetylcholine-producing neurons, the ascending track, or ascending reticular activating system (ARAS), works to arouse and wake up the brain, from the RF, through the thalamus, and then finally to the cerebral cortex. A failure in ARAS functioning may then lead to a coma.
Signs and symptoms.
Generally, a person who is unable to voluntarily open the eyes, does not have a sleep-wake cycle, is unresponsive in spite of strong tactile (painful) or verbal stimuli, and who generally scores between 3 and 8 on the Glasgow Coma Scale is considered in a coma. Coma may have developed in humans as a response to injury to allow the body to pause bodily actions and heal the most immediate injuries - if at all - before waking. It therefore could be a compensatory state in which the body's expenditure of energy is not superfluous. The severity and mode of onset of coma depends on the underlying cause. For instance, severe hypoglycemia (low blood sugar) or hypercapnia (increased carbon dioxide levels in the blood) initially cause mild agitation and confusion, but progress to obtundation, stupor, and finally, complete unconsciousness. In contrast, coma resulting from a severe traumatic brain injury or subarachnoid hemorrhage can be instantaneous. The mode of onset may therefore be indicative of the underlying cause.
Causes of coma.
Coma may result from a variety of conditions, including intoxication (such as drug abuse, overdose or misuse of over the counter medications, prescribed medication, or controlled substances), metabolic abnormalities, central nervous system diseases, acute neurologic injuries such as strokes or herniations, hypoxia, hypothermia, hypoglycemia, Eclampsia or traumatic injuries such as head trauma caused by falls or vehicle collisions. It may also be deliberately induced by pharmaceutical agents during major neurosurgery, to preserve higher brain functions following brain trauma, or to save the patient from extreme pain during healing of injuries or diseases.
Forty percent of comatose states result from drug poisoning. Drugs damage or weaken the synaptic functioning in the ARAS and keep the system from properly functioning to arouse the brain. Secondary effects of drugs, which include abnormal heart rate and blood pressure, as well as abnormal breathing and sweating, may also indirectly harm the functioning of the ARAS and lead to a coma. Seizures and hallucinations have shown to also play a major role in ARAS malfunction. Given that drug poisoning is the cause for a large portion of patients in a coma, hospitals first test all comatose patients by observing pupil size and eye movement, through the vestibular-ocular reflex.
The second most common cause of coma, which makes up about 25% of comatose patients, occurs from lack of oxygen, generally resulting from cardiac arrest. The Central Nervous System (CNS) requires a great deal of oxygen for its neurons. Oxygen deprivation in the brain, also known as hypoxia, causes neuronal extracellular sodium and calcium to decrease and intracellular calcium to increase, which harms neuron communication. Lack of oxygen in the brain also causes ATP exhaustion and cellular breakdown from cytoskeleton damage and nitric oxide production.
Twenty percent of comatose states result from the side effects of a stroke. During a stroke, blood flow to part of the brain is restricted or blocked. An ischemic stroke, brain hemorrhage, or tumor may cause such cessation of blood flow. Lack of blood to cells in the brain prevents oxygen from getting to the neurons, and consequently causes cells to become disrupted and eventually die. As brain cells die, brain tissue continues to deteriorate, which may affect functioning of the ARAS.
The remaining 15% of comatose cases result from trauma, excessive blood loss, malnutrition, hypothermia, hyperthermia, abnormal glucose levels, and many other biological disorders.
Diagnosis.
Diagnosis of coma is simple, but diagnosing the cause of the underlying disease process is often challenging. The first priority in treatment of a comatose patient is stabilization following the basic ABCs (standing for airway, breathing, and circulation). Once a person in a coma is stable, investigations are performed to assess the underlying cause. Investigative methods are divided into physical examination findings and imaging (such as CAT scan, MRI, etc.) and special studies (EEG, etc.)
Diagnostic steps.
When an unconscious patient enters a hospital, the hospital utilizes a series of diagnostic steps to identify the cause of unconsciousness. According to Young, the following steps should be taken when dealing with a patient possibly in a coma:
Initial assessment and evaluation.
In the initial assessment of coma, it is common to gauge the level of consciousness by spontaneously exhibited actions, response to vocal stimuli ("Can you hear me?"), and painful stimuli; this is known as the AVPU (alert, vocal stimuli, painful stimuli, unresponsive) scale. More elaborate scales, such as the Glasgow Coma Scale, quantify an individual's reactions such as eye opening, movement and verbal response on a scale; Glasgow Coma Scale (GCS) is an indication of the extent of brain injury varying from 3 (indicating severe brain injury and death) to a maximum of 15 (indicating mild or no brain injury).
In those with deep unconsciousness, there is a risk of asphyxiation as the control over the muscles in the face and throat is diminished. As a result, those presenting to a hospital with coma are typically assessed for this risk ("airway management"). If the risk of asphyxiation is deemed high, doctors may use various devices (such as an oropharyngeal airway, nasopharyngeal airway or endotracheal tube) to safeguard the airway.
Physical examination findings.
Physical examination is critical after stabilization. It should include vital signs, a general portion dedicated to making observations about the patient's respiration (breathing pattern), body movements (if any), and of the patient's body habitus (physique); it should also include assessment of the brainstem and cortical function through special reflex tests such as the oculocephalic reflex test (doll's eyes test), oculovestibular reflex test (cold caloric test), nasal tickle, corneal reflex, and the gag reflex.
Vital signs in medicine are temperature (rectal is most accurate), blood pressure, heart rate (pulse), respiratory rate, and oxygen saturation. It should be easy to evaluate these vitals quickly to gain insight into a patient's metabolism, fluid status, heart function, vascular integrity, and tissue oxygenation.
Respiratory pattern (breathing rhythm) is significant and should be noted in a comatose patient. Certain stereotypical patterns of breathing have been identified including Cheyne–Stokes, a form of breathing in which the patient's breathing pattern is described as alternating episodes of hyperventilation and apnea. This is a dangerous pattern and is often seen in pending herniations, extensive cortical lesions, or brainstem damage. Another pattern of breathing is apneustic breathing, which is characterized by sudden pauses of inspiration and is due to a lesion of the pons. Ataxic breathing is irregular and is due to a lesion (damage) of the medulla.
Assessment of posture and body habitus is the next step. It involves general observation about the patient's positioning. There are often two stereotypical postures seen in comatose patients. Decorticate posturing is a stereotypical posturing in which the patient has arms flexed at the elbow, and arms adducted toward the body, with both legs extended. Decerebrate posturing is a stereotypical posturing in which the legs are similarly extended (stretched), but the arms are also stretched (extended at the elbow). The posturing is critical since it indicates where the damage is in the central nervous system. A decorticate posturing indicates a lesion (a point of damage) at or above the red nucleus, whereas a decerebrate posturing indicates a lesion at or below the red nucleus. In other words, a decorticate lesion is closer to the cortex, as opposed to a decerebrate cortex that is closer to the brainstem.
Oculocephalic reflex also known as the doll's eye is performed to assess the integrity of the brainstem. Patient's eyelids are gently elevated and the cornea is visualized. The patient's head is then moved to the patient's left, to observe if the eyes stay or deviate toward the patient's right; same maneuver is attempted on the opposite side. If the patient's eyes move in a direction opposite to the direction of the rotation of the head, then the patient is said to have an intact brainstem. However, failure of both eyes to move to one side, can indicate damage or destruction of the affected side. In special cases, where only one eye deviates and the other does not, this often indicates a lesion (or damage) of the medial longitudinal fasciculus (MLF), which is a brainstem nerve tract. Caloric reflex test also evaluates both cortical and brainstem function; cold water is injected into one ear and the patient is observed for eye movement; if the patient's eyes slowly deviate toward the ear where the water was injected, then the brainstem is intact, however failure to deviate toward the injected ear indicates damage of the brainstem on that side. Cortex is responsible for a rapid nystagmus away from this deviated position and is often seen in patients who are conscious or merely lethargic.
An important part of the physical exam is also assessment of the cranial nerves. Due to the unconscious status of the patient, only a limited number of the nerves can be assessed. These include the cranial nerves number 2 (CN II), number 3 (CN III), number 5 (CN V), number 7 (CN VII), and cranial nerves 9 and 10 (CN IX, CN X). Gag reflex helps assess cranial nerves 9 and 10. Pupil reaction to light is important because it shows an intact retina, and cranial nerve number 2 (CN II); if pupils are reactive to light, then that also indicates that the cranial nerve number 3 (CN III) (or at least its parasympathetic fibers) are intact. Corneal reflex assess the integrity of cranial nerve number 7 (CN VII), and cranial nerve number 5 (CN V). Cranial nerve number 5 (CN V), and its ophthalmic branch (V1) are responsible for the afferent arm of the reflex, and the cranial nerve number 7 (CN VII) also known a facial nerve, is responsible for the efferent arm, causing contraction of the muscle orbicularis oculi resulting in closing of the eyes.
Pupil assessment is often a critical portion of a comatose examination, as it can give information as to the cause of the coma; the following table is a technical, medical guideline for common pupil findings and their possible interpretations:
Imaging and special tests findings.
Imaging basically encompasses computed tomography (CAT or CT) scan of the brain, or MRI for example, and is performed to identify specific causes of the coma, such as hemorrhage in the brain or herniation of the brain structures. Special tests such as an EEG can also show a lot about the activity level of the cortex such as semantic processing, presence of seizures, and are important available tools not only for the assessment of the cortical activity but also for predicting the likelihood of the patient's awakening. The autonomous responses such as the skin conductance response may also provide further insight on the patient's emotional processing.
History.
When diagnosing any neurological condition, history and examination are fundamental. History is obtained by family, friends or EMS. The Glasgow Coma Scale is a helpful system used to examine and determine the depth of coma, track patients progress and predict outcome as best as possible. In general a correct diagnosis can be achieved by combining findings from physical exam, imaging, and history components and directs the appropriate therapy.
Severity and classification.
A coma can be classified as (1) supratentoral (above Tentorium cerebelli), (2) infratentoral (below Tentorium cerebelli), (3) metabolic or (4) diffused. This classification is merely dependent on the position of the original damage that caused the coma, and does not correlate with severity or the prognosis.
The severity of coma impairment however is categorized into several levels. Patients may or may not progress through these levels. In the first level, the brain responsiveness lessens, normal reflexes are lost, the patient no longer responds to pain and cannot hear.
The Rancho Los Amigos Scale is a complex scale that has eight separate levels, and is often used in the first few weeks or months of coma while the patient is under closer observation, and when shifts between levels are more frequent.
Treatment.
Medical treatment.
The treatment hospitals use on comatose patients depends on both the severity and cause of the comatose state. Although the best treatment for comatose patients remains unknown, hospitals usually place comatose patients in an Intensive Care Unit (ICU) immediately. In the ICU, the hospital monitors a patient’s breathing and brain activity through CT scans. Attention must first be directed to maintaining the patient's respiration and circulation, using intubation and ventilation, administration of intravenous fluids or blood and other supportive care as needed. Once a patient is stable and no longer in immediate danger, the medical staff may concentrate on maintaining the health of patient’s physical state. The concentration is directed to preventing infections such as pneumonias, bedsores (decubitus ulcers), and providing balanced nutrition. Infections may appear from the patient not being able to move around, and being confined to the bed. The nursing staff moves the patient every 2–3 hours from side to side and depending on the state of consciousness sometimes to a chair. The goal is to move the patient as much as possible to try to avoid bedsores, atelectasis and pneumonia. Pneumonia can occur from the person’s inability to swallow leading to aspiration, lack of gag reflex or from feeding tube, (aspiration pneumonia). Physical therapy may also be used to prevent contractures and orthopedic deformities that would limit recovery for those patients who awaken from coma.
A person in a coma may become restless, or seize and need special care to prevent them from hurting themselves. Medicine may be given to calm such individuals. Patients who are restless may also try to pull on tubes or dressings so soft cloth wrist restraints may be put on. Side rails on the bed should be kept up to prevent the patient from falling.
In attempt to wake comatose patients, some hospitals treat their patients by either reversing the cause of the coma (i.e., glucose shock if low sugar), giving medication to stop brain swelling, or inducing hypothermia. Inducing hypothermia on comatose patients provides one of the main treatments for patients after suffering from cardiac arrest. In this treatment, medical personnel expose patients to “external or intravascular cooling” at 32-34 °C for 24 hours; this treatment cools patients down about 2-3 °C less than normal body temperature. In 2002, Baldursdottir and her coworkers found that in the hospital, more comatose patients survived after induced hypothermia than patients that remained at normal body temperature. For this reason, the hospital chose to continue the induced hypothermia technique for all of its comatose patients that suffered from cardiac arrest.
Emotional challenges.
Coma has a wide variety of emotional reactions from the family members of the affected patients, as well as the primary care givers taking care of the patients. Common reactions, such as desperation, anger, frustration, and denial are possible. The focus of the patient care should be on creating an amicable relationship with the family members or dependents of a comatose patient as well as creating a rapport with the medical staff.
Prognosis.
Comas can last from several days to several weeks. In more severe cases a coma may last for over five weeks, while some have lasted as long as several years. After this time, some patients gradually come out of the coma, some progress to a vegetative state, and others die. Some patients who have entered a vegetative state go on to regain a degree of awareness. Others remain in a vegetative state for years or even decades (the longest recorded period being 42 years).
The outcome for coma and vegetative state depends on the cause, location, severity and extent of neurological damage. A deeper coma alone does not necessarily mean a slimmer chance of recovery, because some people in deep coma recover well while others in a so-called milder coma sometimes fail to improve.
People may emerge from a coma with a combination of physical, intellectual, and psychological difficulties that need special attention. Recovery usually occurs gradually—patients acquire more and more ability to respond. Some patients never progress beyond very basic responses, but many recover full awareness. Regaining consciousness is not instant: in the first days, patients are only awake for a few minutes, and duration of time awake gradually increases. This is unlike the situation in many movies where people who awake from comas are instantly able to continue their normal lives. In reality, the coma patient awakes sometimes in a profound state of confusion, not knowing how they got there and sometimes suffering from dysarthria, the inability to articulate any speech, and with many other disabilities.
Predicted chances of recovery are variable owing to different techniques used to measure the extent of neurological damage. All the predictions are based on statistical rates with some level of chance for recovery present: a person with a low chance of recovery may still awaken. Time is the best general predictor of a chance of recovery: after four months of coma caused by brain damage, the chance of partial recovery is less than 15%, and the chance of full recovery is very low.
The most common cause of death for a person in a vegetative state is secondary infection such as pneumonia, which can occur in patients who lie still for extended periods.
There are reports of patients coming out of coma after long periods of time. After 19 years in a minimally conscious state, Terry Wallis spontaneously began speaking and regained awareness of his surroundings. Similarly, Polish railroad worker Jan Grzebski woke up from a 19-year coma in 2007.
A brain-damaged man, trapped in a coma-like state for six years, was brought back to consciousness in 2003 by doctors who planted electrodes deep inside his brain. The method, called deep brain stimulation (DBS) successfully roused communication, complex movement and eating ability in the 38-year-old American man who suffered a traumatic brain injury. His injuries left him in a minimally conscious state (MCS), a condition akin to a coma but characterized by occasional, but brief, evidence of environmental and self-awareness that coma patients lack.
Comas lasting seconds to minutes result in post-traumatic amnesia (PTA) that lasts hours to days; recovery plateau occurs over days to weeks.
Comas that last hours to days result in PTA lasting days to weeks; recovery plateau occurs over months.
Comas lasting weeks result in PTA that lasts months; recovery plateau occurs over months to years.
Society and culture.
Research by Dr. Eelco Wijdicks on the depiction of comas in movies was published in Neurology in May 2006. Dr. Wijdicks studied 30 films (made between 1970 and 2004) that portrayed actors in prolonged comas, and he concluded that only two films accurately depicted the state of a coma victim and the agony of waiting for a patient to awaken: "Reversal of Fortune" (1990) and "The Dreamlife of Angels" (1998). The remaining 28 were criticized for portraying miraculous awakenings with no lasting side effects, unrealistic depictions of treatments and equipment required, and comatose patients remaining muscular and tanned.

</doc>
<doc id="5722" url="https://en.wikipedia.org/wiki?curid=5722" title="Call of Cthulhu (role-playing game)">
Call of Cthulhu (role-playing game)

Call of Cthulhu is a horror fiction role-playing game based on H. P. Lovecraft's story of the same name and the associated Cthulhu Mythos. The game, often abbreviated as "CoC", is published by Chaosium; it was first released in 1981 and is currently in its seventh edition, with many different versions released. It makes use of Chaosium's Basic Role-Playing (BRP) system, with special rules for Sanity.
Gameplay.
The setting of "Call of Cthulhu" is a darker version of our world, based on H. P. Lovecraft's observation (from his essay, "Supernatural Horror in Literature") that "The oldest and strongest emotion of mankind is fear, and the strongest kind of fear is fear of the unknown." The original game, first published in 1981, uses mechanics from Basic Role-Playing, and is set in the 1920s, the setting of many of Lovecraft's stories. Additional settings were developed in the 1890s "Cthulhu by Gaslight" supplement, a blend of occult and Holmesian mystery and mostly set in England, and modern/1980s conspiracy with "Cthulhu Now." More recent additions include 1000 AD ("Cthulhu: Dark Ages"), 23rd century ("Cthulhu Rising") and Ancient Roman times ("Cthulhu Invictus"). The protagonists may also travel to places that are not of this earth, represented in the Dreamlands (which can be accessed through dreams as well as being physically connected to the earth), to other planets, or into the voids of space.
"Call of Cthulhu" uses the Basic Role-Playing system used by other Chaosium games (first seen in "RuneQuest"). For as long as they stay functionally healthy and sane, characters grow and develop. "Call of Cthulhu" does not use levels, but is completely skill-based, with player characters getting better with their skills by succeeding at them. They do not, however, gain "hit points" and do not become significantly harder to kill.
Unlike Dungeons and Dragons, which typically uses a d20 to determine outcomes of particular decisions and events, "Call of Cthulhu" uses percentile dice (with a results ranging from 1 to 100) to determine such events. Every player statistic is intended to be compatible with the notion that there is a probability of success for a particular action given what the player is capable of doing. For example, an artist may have a 75% of being able to draw something (represented by having 75 in Art skill), and thus rolling a number under 75 would yield a success. Rolling 1/5 or less of the skill level (1-15 in our example) would be a "special success" (or an "impale" for combat skills) and would yield some extra bonus to be determined by the keeper. For example, the artist character might draw especially well or especially fast, or catch some unapparent detail in the drawing.
The players take the roles of ordinary people drawn into the realm of the mysterious: detectives, criminals, scholars, artists, war veterans, etc. Often, happenings begin innocently enough, until more and more of the workings behind the scenes are revealed. As the characters learn more of the true horrors of the world and the irrelevance of humanity, their sanity (represented by "Sanity Points", abbreviated SAN) inevitably withers away. The game includes a mechanism for determining how damaged a character's sanity is at any given point; encountering the horrific beings usually triggers a loss of SAN points. To gain the tools they need to defeat the horrors – mystic knowledge and magic – the characters may end up losing some of their sanity, though other means such as pure firepower or simply outsmarting one's opponents also exist. "Call of Cthulhu" has a reputation as a game in which it is quite common for a player character to die in gruesome circumstances or end up in a mental institution. Eventual triumph of the players is not assumed.
History.
The original conception of "Call of Cthulhu" was "Dark Worlds", a game commissioned by the publisher Chaosium but never published. Sandy Petersen, now best known for his work on the "Doom" computer game, contacted them regarding writing a supplement for their popular fantasy game "RuneQuest" set in Lovecraft's Dreamlands. He took over the writing of "Call of Cthulhu", and the game was released in 1981, using a version of the Basic Role-Playing system used in "RuneQuest".
Editions.
Since Petersen's departure from Chaosium, continuing development of "Call of Cthulhu" passed to Lynn Willis, credited as co-author in the fifth and sixth editions, and more recently to Paul Fricker and Mike Mason. The game system underwent only minor rules changes in its first six editions (between 1981 and 2011); the current seventh edition, released 2014, includes more significant rules alterations than in any previous release.
Early releases.
For those grounded in the RPG tradition, the very first release of "Call of Cthulhu" created a brand new framework for table-top gaming. Rather than the traditional format established by "Dungeons & Dragons", which often involved the characters wandering through caves or tunnels and fighting different types of monsters, Sandy Petersen introduced the concept of the "Onion Skin": Interlocking layers of information and nested clues that lead the Player Characters from seemingly minor investigations into a missing person to discovering mind-numbingly awful, global conspiracies to destroy the world. Unlike its predecessor games, "CoC" assumed that most investigators would not survive, alive or sane, and that the only safe way to deal with the vast majority of nasty things described in the rule books was to run away. A well-run "CoC" campaign should engender a sense of foreboding and inevitable doom in its players. The style and setting of the game, in a relatively modern time period, created an emphasis on real-life settings, character research, and thinking one's way around trouble.
The first book of "Call of Cthulhu" adventures was "Shadows of Yog-Sothoth". In this work, the characters come upon a secret society's foul plot to destroy mankind, and pursue it first near to home and then in a series of exotic locations. This template was to be followed in many subsequent campaigns, including "Fungi from Yuggoth" (later known as "Curse of Cthulhu" and "Day of the Beast"), "Spawn of Azathoth", and possibly the most highly acclaimed, "Masks of Nyarlathotep". Many of these seem closer in tone to the pulp adventures of "Indiana Jones" than H. P. Lovecraft, but they are nonetheless beloved by many gamers.
"Shadows of Yog-Sothoth" is important not only because it represents the first published addition to the boxed first edition of "Call of Cthulhu", but because its format defined a new way of approaching a campaign of linked RPG scenarios involving actual clues for the would-be detectives amongst the players to follow and link in order to uncover the dastardly plots afoot. Its format has been used by every other campaign-length "Call of Cthulhu" publication. The standard of "CoC" scenarios was well received by independent reviewers. "The Asylum and Other Tales", a series of stand alone articles released in 1983, rated an overall 9/10 in Issue 47 of "White Dwarf" magazine.
The standard of the included 'clue' material varies from scenario to scenario, but reached its zenith in the original boxed versions of the "Masks of Nyarlathotep" and "Horror on the Orient Express" campaigns. Inside these one could find matchbooks and business cards apparently defaced by non-player characters, newspaper cuttings and (in the case of "Orient Express") period passports to which players could attach their photographs, bringing a Live Action Role Playing feel to a tabletop game. Indeed, during the period that these supplements were produced, third party campaign publishers strove to emulate the quality of the additional materials, often offering separately-priced 'deluxe' clue packages for their campaigns.
Additional milieu were provided by Chaosium with the release of "Dreamlands", a boxed supplement containing additional rules needed for playing within the Lovecraft Dreamlands, a large map and a scenario booklet, and "Cthulhu By Gaslight", another boxed set which moved the action from the 1920s to the 1890s.
"Cthulhu Now".
In 1987, Chaosium issued the supplement titled "Cthulhu Now", a collection of rules, supplemental source materials and scenarios for playing "Call of Cthulhu" in the present day. This proved to be a very popular alternative milieu, so much so that much of the supplemental material is now included in the core rule book.
"Delta Green".
Pagan Publishing has released a series of supplements in a similar vein, by the name "Delta Green", that is set in the 1990s (although later supplements add support for playing closer to the present day).
Lovecraft Country.
"Lovecraft Country" was a line of supplements for "Call of Cthulhu" released in 1990. These supplements were overseen by Keith Herber and provided backgrounds and adventures set in Lovecraft's fictional towns of Arkham, Kingsport, Innsmouth, Dunwich, and their environs. The intent was to give investigators a common base, as well as to center the action on well-drawn characters with clear motivations.
Recent history.
In the years since the collapse of the "Mythos" collectible card game (production ceased in 1997), the release of "CoC" books has been very sporadic with up to a year between releases. Chaosium struggled with near bankruptcy for many years before finally starting their upward climb again.
2005 was Chaosium's busiest year for many years with ten releases for the game. Chaosium took to marketing "monographs"—short books by individual writers with editing and layout provided out-of-house—directly to the consumer, allowing the company to gauge market response to possible new works. The range of times and places in which the horrors of the Mythos can be encountered was also expanded in late 2005 onwards with the addition of "Cthulhu Dark Ages" by Stéphane Gesbert, which gives a framework for playing games set in 11th century Europe, "Secrets of Japan" by Michael Dziesinski for gaming in modern-day Japan, and "Secrets of Kenya" by David Conyers for gaming in interwar period Africa.
In July 2011, Chaosium announced it would re-release a 30th anniversary edition of the "CoC" 6th edition role-playing game. This 320-page book features thick (3 mm) leatherette hard-covers with the front cover and spine stamped with gold foil. The interior pages are printed in black ink, on 90 gsm matte art paper. The binding is thread sewn, square backed. Chaosium offered a one-time printing of this Collector's Edition.
In May 28, 2013, a kickstarter for the 7th Edition of Call of Cthulhu was launched, it ended in June 29 of the same year and collected $561,836.
Licenses.
Chaosium has licensed other publishers to create supplements using their rule system, notably including "Delta Green" by Pagan Publishing. Other licensees have included Miskatonic River Press, Theater of the Mind Enterprises, Triad Entertainment, Games Workshop, Fantasy Flight Games, RAFM, Goodman Games, Grenadier Models Inc. and Yog-Sothoth.com. These supplements may be set in different time frames or even different game universes from the original game.
"D20 Call of Cthulhu".
In 2001, a stand-alone version of "Call of Cthulhu" was released by Wizards of the Coast, for the d20 system. Intended to preserve the feeling of the original game, the d20 conversion of the game rules were supposed to make the game more accessible to the large "D&D" player base. The d20 system also made it possible to use "Dungeons & Dragons" characters in "Call of Cthulhu", as well as to introduce the Cthulhu Mythos into "Dungeons & Dragons" games. The d20 version of the game is no longer supported by Wizards as per their contract with Chaosium. Chaosium included d20 stats as an appendix in three releases (see Lovecraft Country), but have since dropped the "dual stat" idea.
"Dark Corners of the Earth".
A licensed first-person shooter adventure game by Headfirst Productions, based on "Call of Cthulhu" campaign "Escape from Innsmouth" and released by Bethesda Softworks in 2005/2006 for the PC and Xbox.
"Trail of Cthulhu".
In February 2008, Pelgrane Press published "Trail of Cthulhu", a stand-alone game created by Kenneth Hite using the GUMSHOE System developed by Robin Laws. "Trail of Cthulhu"s system is more mystery oriented and focuses mostly on interpreting clues.
"Shadows of Cthulhu".
In September 2008, Reality Deviant Publications published "Shadows of Cthulhu", a supplement that brings Lovecraftian gaming to Green Ronin's True20 system.
"Realms of Cthulhu".
In October 2009, Reality Blurs published "Realms of Cthulhu", a supplement for Pinnacle Entertainment's Savage Worlds system.
"The Laundry".
In 2010, Cubicle 7 published an official role-playing game, "The Laundry" (2010, ISBN 1-907204-93-8, Gareth Hanrahan) and a number of supplements, all based on Charles Stross's "Bob Howard – Laundry" series.
"The Wasted Land".
In April 2011, Chaosium and new developer Red Wasp Design announced a joint project to produce a mobile video game based on the "Call of Cthulhu" RPG, entitled "Call of Cthulhu: The Wasted Land". The game was released on 30 January 2012.
Card games.
"Mythos" was a collectible card game (CCG) based on the Cthulhu Mythos that Chaosium produced and marketed during the mid-1990s. While generally praised for its fast gameplay and unique mechanics, it ultimately failed to gain a very large market presence. It bears mention because its eventual failure brought the company to hard times that affected its ability to produce material for "Call of Cthulhu". "Call of Cthulhu: The Card Game" is a second collectible card game, produced by Fantasy Flight Games.
Miniatures.
The first licensed "Call of Cthulhu" gaming miniatures were sculpted by Andrew Chernack and released by Grenadier Models in boxed sets and blister packs in 1983. The license was later transferred to RAFM. As of 2011, RAFM still produce licensed C"all of Cthulhu" models sculpted by Bob Murch. Both lines include investigator player character models and the iconic monsters of the Cthulhu mythos.
As of July 2015, Reaper Miniatures started its third "Bones Kickstarter", a Kickstarter intended to help the company migrate some miniatures from metal to plastic, and introducing some new ones. Among the stretch goals was the second $50 expansion, devoted to the Mythos, with miniatures such as Cultists, Deep Ones, Mi'Go, and an extra $15 Shub-Niggurath "miniature" (it is, at least, 6x4 squares). It is expected for those miniatures to remain in the Reaper Miniatures catalogue after the Kickstarter project finishes.
Reception.
The game won several major awards in the following years:

</doc>
<doc id="5723" url="https://en.wikipedia.org/wiki?curid=5723" title="Constellations (journal)">
Constellations (journal)

Constellations: An International Journal of Critical and Democratic Theory is a quarterly peer-reviewed academic journal of critical and democratic theory and successor of "Praxis International". It is edited by Andrew Arato, Amy Allen, and Andreas Kalyvas. Seyla Benhabib is a co-founding former editor and Nancy Fraser a former co-editor.

</doc>
<doc id="5724" url="https://en.wikipedia.org/wiki?curid=5724" title="Cape Breton Island">
Cape Breton Island

Cape Breton Island (—formerly "Île Royale", Scottish Gaelic: "Ceap Breatainn" or "Eilean Cheap Bhreatainn", Míkmaq: "Únamakika", simply: "Cape Breton") is an island on the Atlantic coast of North America. Its name may derive from Capbreton near Bayonne, or more probably from the word "Breton", the French adjective form of the proper noun "Bretagne", the French historical region.
Cape Breton Island is part of the province of Nova Scotia, Canada. The island accounts for 18.7% of the total area of Nova Scotia. Although physically separated from the Nova Scotia peninsula by the Strait of Canso, it is artificially connected to mainland Nova Scotia by the long rock-fill Canso Causeway. The island is located east-northeast of the mainland with its northern and western coasts fronting on the Gulf of Saint Lawrence; its western coast also forming the eastern limits of the Northumberland Strait. The eastern and southern coasts front the Atlantic Ocean; its eastern coast also forming the western limits of the Cabot Strait. Its landmass slopes upward from south to north, culminating in the highlands of its northern cape. One of the world's larger salt water lakes, Bras d'Or ("Arm of Gold" in French), dominates the centre of the island.
The island is divided into four of Nova Scotia's eighteen counties: Cape Breton, Inverness, Richmond, and Victoria. Their total population at the 2011 census numbered 135,974 "Cape Bretoners"; this is approximately 15% of the provincial population. Cape Breton Island has experienced a decline in population of approximately 4.4% since the previous census in 2006. Approximately 75% of the island's population is located in the Cape Breton Regional Municipality (CBRM) which includes all of Cape Breton County and is often referred to as Industrial Cape Breton, given the history of coal mining and steel manufacturing in this area, which was Nova Scotia's industrial heartland throughout the 20th century.
The island contains five reserves of the Mi'kmaq Nation, these being: Eskasoni, Membertou, Wagmatcook, Waycobah, and Potlotek/Chapel Island. Eskasoni is the largest in both population and land area.
History.
Cape Breton Island's first residents were most likely Archaic maritime natives, ancestors of the Mi'kmaq, the people who were inhabiting the island at the time of European arrival. John Cabot reportedly visited the island in 1497. However, historians are unclear as to whether Cabot first visited Newfoundland or Cape Breton Island. This discovery is commemorated by Cape Breton's Cabot Trail, and by the "Cabot's Landing Historic Site & Provincial Park", located near the village of Dingwall.
In about 1521–22, the Portuguese under João Álvares Fagundes established a fishing colony on the island. As many as two hundred settlers lived in a village, the name of which is not known, located according to some historians at what is now present day Ingonish on the island's northeastern peninsula. The fate of this Portuguese colony is unknown, but it is mentioned as late as 1570.
During the Anglo-French War of 1627 to 1629, under Charles I, by 1629 the Kirkes took Quebec City; Sir James Stewart of Killeith, Lord Ochiltree planted a colony on Cape Breton Island at Baleine, Nova Scotia; and Alexander’s son, William Alexander, 1st Earl of Stirling, established the first incarnation of "New Scotland" at Port Royal. This set of Scottish triumphs which left Cape Sable as the only major French holding in North America was not destined to last. Charles I’s haste to make peace with France on the terms most beneficial to him meant that the new North American gains would be bargained away in the Treaty of Saint-Germain-en-Laye (1632).
The French quickly defeated the Scottish at Baleine, and established the first permanent settlements on Île Royale: present day Englishtown (1629) and St. Peter's (1630). These settlements lasted almost continuously until Nicolas Denys left in 1659. Île Royale then remained vacant for more than fifty years, until the communities along with Louisbourg were established in 1713.
Île Royale.
Known as "Île Royale" to the French, the island also saw active settlement by France. After the French ceded their colonies on Newfoundland and the Acadian mainland to the British by the Treaty of Utrecht in 1713, the French relocated the population of Plaisance, Newfoundland, to Île Royale and the French garrison was established in the central eastern part at Sainte Anne. As the harbour at Sainte Anne experienced icing problems, it was decided to construct a much larger fortification at Louisbourg to improve defences at the entrance to the Gulf of Saint Lawrence and to defend France's fishing fleet on the Grand Banks. The French also built the Louisbourg Lighthouse in 1734, the first lighthouse in Canada and one of the first in North America. In addition to Cape Breton Island, the French colony of Île Royale also included Île Saint-Jean, today called Prince Edward Island.
Louisbourg itself was one of the most important commercial and military centres in New France. Louisbourg was captured by New Englanders with British naval assistance in 1745 and by British forces in 1758. The French population of Île Royale was deported to France after each siege. While French settlers returned to their homes in Île Royale after the Treaty of Aix-la-Chapelle was signed in 1748, the fortress was demolished after the second siege. Île Royale remained formally part of New France until it was ceded to Great Britain by the Treaty of Paris in 1763. It was then merged with the adjacent, British colony of Nova Scotia (present day peninsular Nova Scotia and New Brunswick). Acadians who had been expelled from Nova Scotia and Île Royale were permitted to settle in Cape Breton beginning in 1764, and established communities in north-western Cape Breton, near Cheticamp, and southern Cape Breton, on and near Isle Madame.
Some of the first British-sanctioned settlers on the island following the Seven Years' War were Irish, although upon settlement they merged with local French communities to form a culture rich in music and tradition. From 1763 to 1784, the island was administratively part of the colony of Nova Scotia and was governed from Halifax.
The first permanently settled Scottish community on Cape Breton Island was Judique, settled in 1775 by Michael Mor MacDonald. He spent his first winter using his upside-down boat for shelter, which is reflected in the architecture of the village's Community Centre. He composed a song about the area called "O's alainn an t-aite", or "Fair is the Place."
Colony of Cape Breton.
In 1784, Britain split the colony of Nova Scotia into three separate colonies: New Brunswick, Cape Breton Island, and present-day peninsular Nova Scotia, in addition to the adjacent colonies of St. John's Island (renamed Prince Edward Island in 1798) and Newfoundland. The colony of Cape Breton Island had its capital at Sydney on its namesake harbour fronting on Spanish Bay and the Cabot Strait. Its first Lieutenant-Governor was Joseph Frederick Wallet DesBarres (1784–1787) and his successor was William Macarmick (1787).
A number of United Empire Loyalists emigrated to the Canadian colonies, including Cape Breton. David Mathews, the former Mayor of New York City during the American Revolution, emigrated with his family to Cape Breton in 1783. He succeeded Macarmick as head of the colony and served from 1795 to 1798.
From 1799 to 1807, the military commandant was John Despard, brother of Edward.
An order forbidding the granting of land in Cape Breton, issued in 1763, was removed in 1784. The mineral rights to the island were given over to the Duke of York by an order-in-council. The British government had intended that the Crown take over the operation of the mines when Cape Breton was made a colony, but this was never done, probably because of the rehabilitation cost of the mines. The mines were in a neglected state, caused by careless operations dating back at least to the time of the final fall of Louisbourg.
Large-scale shipbuilding began in the 1790s, beginning with schooners for local trade moving in the 1820s to larger brigs and brigantines, mostly built for British shipowners. Shipbuilding peaked in the 1850s, marked in 1851 by the full rigged ship "Lord Clarendon", the largest wooden ship ever built in Cape Breton.
Merger with Nova Scotia.
In 1820, the colony of Cape Breton Island was merged for the second time with Nova Scotia. This development is one of the factors which led to large-scale industrial development in the Sydney Coal Field of eastern Cape Breton County. By the late 19th century, as a result of the faster shipping, expanding fishery and industrialization of the island, exchanges of people between the island of Newfoundland and Cape Breton increased, beginning a cultural exchange that continues to this day.
During the first half of the 19th century, Cape Breton Island experienced an influx of Highland Scots numbering approximately 50,000 as a result of the Highland Clearances. Today, the descendants of the Highland Scots dominate Cape Breton Island's culture, particularly in rural communities. To this day, Gaelic is still the first language of a number of elderly Cape Bretoners. The growing influence of English-dominated media from outside the Scottish communities saw the use of this language erode quickly during the 20th century. Many of the Scots who immigrated there were either Roman Catholics or Presbyterians, which can be seen in a number of island landmarks and place names.
The 1920s were some of the most violent times in Cape Breton. They were marked by several severe labour disputes. The famous murder of William Davis by strike breakers, and the seizing of the New Waterford power plant by striking miners led to a major union sentiment that persists to this day in some circles. William Davis Miners' Memorial Day is celebrated in coal mining towns to commemorate the deaths of miners at the hands of the coal companies.
20th century.
The turn of the 20th century saw Cape Breton Island at the forefront of scientific achievement with the now-famous activities launched by inventors Alexander Graham Bell and Guglielmo Marconi.
Following his successful invention of the telephone and being relatively wealthy, Bell acquired land near Baddeck in 1885, largely due to surroundings reminiscent of his early years in Scotland. He established a summer estate complete with research laboratories, working with deaf people—including Helen Keller—and continued to invent. Baddeck would be the site of his experiments with hydrofoil technologies as well as the Aerial Experiment Association, financed by his wife, which saw the first powered flight in the British Empire when the AEA "Silver Dart" took off from the ice-covered waters of Bras d'Or Lake. Bell also built the forerunner to the iron lung and experimented with breeding sheep.
Marconi's contributions to Cape Breton Island were also quite significant, as he used the island's geography to his advantage in transmitting the first North American trans-Atlantic radio message from a station constructed at Table Head in Glace Bay to a receiving station at Poldhu in Cornwall, England. Marconi's pioneering work in Cape Breton marked the beginning of modern radio technology. Marconi's station at Marconi Towers, on the outskirts of Glace Bay, became the chief communication centre for the Royal Canadian Navy in World War I through to the early years of World War II. During World War II, there was also a significant drop of Gaelic speakers due to a prejudice caused by Ireland's neutrality during the war.
Promotions for tourism beginning in the 1950s recognized the importance of the Scottish culture to the province, and the provincial government started encouraging the use of Gaelic once again. The establishment of funding for the Gaelic College of Celtic Arts and Crafts and formal Gaelic language courses in public schools are intended to address the near-loss of this culture to English assimilation.
In the 1960s, the Fortress of Louisbourg was partially reconstructed by Parks Canada. Since 2009, this National Historic Site of Canada has attracted an average of 90 000 visitors per year.
Environment.
Geography.
The island measures in area, making it the 77th largest island in the world and Canada's 18th largest island. Cape Breton Island is composed mainly of rocky shores, rolling farmland, glacial valleys, barren headlands, mountains, woods and plateaus. Geological evidence suggests that at least part of the island was originally joined with present-day Scotland and Norway, now separated by millions of years of continental drift.
The northern portion of Cape Breton Island is dominated by the Cape Breton Highlands, commonly shortened to simply the "Highlands", which are an extension of the Appalachian mountain chain. The Highlands comprise the northern portions of Inverness and Victoria counties. In 1936 the federal government established the Cape Breton Highlands National Park covering across the northern third of the Highlands. The Cabot Trail scenic highway also encircles the coastal perimeter of the plateau.
Cape Breton Island's hydrological features include the Bras d'Or Lake system, a salt-water fjord at the heart of the island, and freshwater features including Lake Ainslie, the Margaree River system, and the Mira River. Innumerable smaller rivers and streams drain into the Bras d'Or Lake estuary and onto the Gulf of St. Lawrence and Atlantic coasts.
Cape Breton Island is joined to the mainland by the Canso Causeway, which was completed in 1955, enabling direct road and rail traffic to and from the island, but requiring marine traffic to pass through the Canso Canal at the eastern end of the causeway.
Cape Breton Island is divided into four counties: Cape Breton, Inverness, Richmond, and Victoria.
The climate is one of mild, often pleasantly warm summers and cold winters, although the proximity to the Atlantic Ocean and Gulf Stream moderates the extreme winter cold found on the mainland, especially on the east side facing the open Atlantic. Precipitation is abundant year round, with annual totals up to 60 inches on the eastern side facing the Atlantic storms. Considerable snowfall can be expected in winter, especially in the highlands.
Demographics.
The island's residents can be grouped into five main cultures; Scottish, Mi'kmaq, Acadian, Irish, and English, with respective languages Gaelic (Scottish and Irish), Mi'kmaq, French, and English. English is now the primary spoken language, though Mi'kmaq, Gaelic and French are still heard.
Later migrations of Black Loyalists, Italians, and Eastern Europeans mostly settled in the eastern part of the island around the Industrial Cape Breton region. The population of Cape Breton Island has been in decline for almost two decades with an increasing population exodus in recent years due to economic conditions.
According to the Census of Canada, the population of Cape Breton Island in 2011 was 135,974, a 4.4% decline from 142,298 in 2006, and a 14.1% decline from 158,260 in 1996.
Religious groups
Statistics Canada in 2001 reported a "religion" total of 145,525 for Cape Breton, including 5,245 with "no religious affiliation." Major categories included:
A Synagogue in Sydney serves a small historic Jewish community which was once one of the largest ones in eastern Canada with four shuls: one in Glace Bay, one in New Waterford, one in Whitney Pier, and the one in Sydney. More recent Muslim immigrants hold Friday prayers at Cape Breton University and the former Holy Redeemer Hall in Whitney Pier. Buddhists are a small minority (105 in 2001, according to Statistics Canada), although Gampo Abbey in Pleasant Bay has been operational since 1984.
Economy.
Much of the recent economic history of Cape Breton Island can be tied to the coal industry.
The island has two major coal deposits:
Sydney has traditionally been the main port, with various facilities in a large, sheltered, natural harbour. It is the island's largest commercial centre and home to the "Cape Breton Post" daily newspaper, as well as one television station, CJCB-TV (CTV), and several radio stations. The Marine Atlantic terminal at North Sydney is the terminal for large ferries traveling to Channel-Port aux Basques and seasonally to Argentia, both on the island of Newfoundland.
Point Edward on the west side of Sydney Harbour is the location of Sydport, a former navy base () now converted to commercial use. The Canadian Coast Guard College is located nearby at Westmount. Petroleum, bulk coal, and cruise ship facilities are also located in Sydney Harbour.
Glace Bay is the second largest urban community in population and was the island's main coal mining centre until its last mine ceased operation in the 1980s. Glace Bay served as the hub of the Sydney & Louisburg Railway and also as a major fishing port. At one time, Glace Bay was known as the largest town in Nova Scotia, based on population.
Port Hawkesbury has risen to prominence since the completion of the Canso Causeway and Canso Canal created an artificial deep-water port, allowing extensive petrochemical, pulp and paper, and gypsum handling facilities to be established. The Strait of Canso is completely navigable to Seawaymax vessels, and Port Hawkesbury is open to the deepest-draught vessels on the world's oceans. Large marine vessels may also enter Bras d'Or Lake through the Great Bras d'Or channel, whereas small craft have the additional use of the Little Bras d'Or channel or St. Peters Canal. The St. Peters Canal is no longer used by commercial shipping on Cape Breton Island, but is an important waterway for recreational vessels.
The industrial Cape Breton area faced several challenges with the closure of the Cape Breton Development Corporation's (DEVCO) coal mines and the Sydney Steel Corporation's (SYSCO) steel mill. In recent years, the Island's residents have been attempting to diversify the area economy by investing in tourism developments, call centres, and small businesses, as well as manufacturing ventures in such fields as auto parts, pharmaceuticals, and window glazings.
While the Cape Breton Regional Municipality is in transition from an industrial to a service-based economy, the rest of Cape Breton Island outside the industrial area surrounding Sydney-Glace Bay has been more stable, with a mixture of fishing, forestry, small-scale agriculture, and tourism.
Tourism in particular has grown throughout the post-Second World War era, especially the growth in vehicle-based touring, which was furthered by the creation of the Cabot Trail scenic drive. The scenery of the island is rivalled in northeastern North America by only Newfoundland; and Cape Breton Island tourism marketing places a heavy emphasis on its Scottish Gaelic heritage through events such as the Celtic Colours Festival, held each October, as well as promotions through the Gaelic College of Celtic Arts and Crafts.
Whale-watching is a popular attraction for tourists. Whale-watching cruises are operated by numerous vendors from Baddeck to Cheticamp. The most popular species of whale found in Cape Breton's waters is the Pilot whale.
The primary east-west road on the island is Highway 105, the Trans-Canada Highway, although Trunk 4 is also heavily used. Highway 125 is an important arterial route around Sydney Harbour in the Cape Breton Regional Municipality. The Cabot Trail, circling the Cape Breton Highlands, and Trunk 19, along the western coast of the island, are important secondary roads. Railway connections between the port of Sydney to Canadian National Railway in Truro are maintained by the Cape Breton and Central Nova Scotia Railway.
The Cabot Trail is a scenic road circuit around and over the Cape Breton Highlands with spectacular coastal vistas; over 400,000 visitors drive the Cabot Trail each summer and fall. Coupled with the Fortress of Louisbourg, it has driven the growth of the tourism industry on the island in recent decades. The "Condé Nast" travel guide has rated Cape Breton Island as one of the best island destinations in the world.
Traditional music.
Cape Breton is well known for its traditional fiddle music, which was brought to North America by Scottish immigrants during the Highland Clearances. The traditional style has been well preserved in Cape Breton, and céilidhs have become a popular attraction for summer tourists. Inverness County in particular has a heavy concentration of musical activity, with regular performances in communities such as Mabou and Judique. Judique is recognized as 'Baile nam Fonn', (literally: Village of Tunes) or the 'Home of Celtic Music', featuring the Celtic Music Interpretive Centre. Performers who have received significant recognition outside of Cape Breton include Bruce Guthro, Buddy MacMaster, Natalie MacMaster, Ashley MacIsaac, The Rankin Family, Aselin Debison, Lee Cremo, and the Barra MacNeils.
The Men of the Deeps are a male choral group of current and former miners from the industrial Cape Breton area.
Notable people.
Cape Breton artists who have been recognized with major national or international awards include actor Harold Russell of North Sydney, who won an Academy Award in 1946 for his portrayal of Homer Parrish in "The Best Years of Our Lives", and Lynn Coady and Linden MacIntyre of Inverness County, who are both past winners of the Giller Prize for Canadian literature. The Rankin Family and Rita MacNeil have both recorded multiple albums certified as Double Platinum by Music Canada.
People from Cape Breton have also achieved a number of firsts in Canadian politics and governance. These include Mayann Francis of Whitney Pier, the first Black Lieutenant Governor of Nova Scotia, and Elizabeth May of Margaree Harbour, the first member of the Green Party of Canada elected to the Canadian House of Commons.

</doc>
