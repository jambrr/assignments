<doc id="6111" url="https://en.wikipedia.org/wiki?curid=6111" title="Chemical vapor deposition">
Chemical vapor deposition

Chemical vapor deposition (CVD) is a chemical process used to produce high quality, high-performance, solid materials. The process is often used in the semiconductor industry to produce thin films. In typical CVD, the wafer (substrate) is exposed to one or more volatile precursors, which react and/or decompose on the substrate surface to produce the desired deposit. Frequently, volatile by-products are also produced, which are removed by gas flow through the reaction chamber.
Microfabrication processes widely use CVD to deposit materials in various forms, including: monocrystalline, polycrystalline, amorphous, and epitaxial. These materials include: silicon (SiO2, germanium, carbide, nitride, oxynitride), carbon (fiber, nanofibers, nanotubes, diamond and graphene), fluorocarbons, filaments, tungsten, titanium nitride and various high-k dielectrics.
Types.
CVD is practiced in a variety of formats. These processes generally differ in the means by which chemical reactions are initiated.
Most modern CVD is either LPCVD or UHVCVD.
Uses.
CVD is commonly used to deposit conformal films and augment substrate surfaces in ways that more traditional surface modification techniques are not capable of. CVD is extremely useful in the process of atomic layer deposition at depositing extremely thin layers of material. A variety of applications for such films exist. Gallium arsenide is used in some integrated circuits (ICs) and photovoltaic devices. Amorphous polysilicon is used in photovoltaic devices. Certain carbides and nitrides confer wear-resistance. Polymerization by CVD, perhaps the most versatile of all applications, allows for super-thin coatings which possess some very desirable qualities, such as lubricity, hydrophobicity and weather-resistance to name a few. CVD of metal-organic frameworks, a class of crystalline nanoporous materials, has recently been demonstrated. Applications for these films are anticipated in gas sensing and low-k dielectrics
Commercially important materials prepared by CVD.
Polysilicon.
Polycrystalline silicon is deposited from trichlorosilane (SiHCl3) or silane (SiH4), using the following reactions:
This reaction is usually performed in LPCVD systems, with either pure silane feedstock, or a solution of silane with 70–80% nitrogen. Temperatures between 600 and 650 °C and pressures between 25 and 150 Pa yield a growth rate between 10 and 20 nm per minute. An alternative process uses a hydrogen-based solution. The hydrogen reduces the growth rate, but the temperature is raised to 850 or even 1050 °C to compensate. Polysilicon may be grown directly with doping, if gases such as phosphine, arsine or diborane are added to the CVD chamber. Diborane increases the growth rate, but arsine and phosphine decrease it.
Silicon dioxide.
Silicon dioxide (usually called simply "oxide" in the semiconductor industry) may be deposited by several different processes. Common source gases include silane and oxygen, dichlorosilane (SiCl2H2) and nitrous oxide (N2O), or tetraethylorthosilicate (TEOS; Si(OC2H5)4). The reactions are as follows :
The choice of source gas depends on the thermal stability of the substrate; for instance, aluminium is sensitive to high temperature. Silane deposits between 300 and 500 °C, dichlorosilane at around 900 °C, and TEOS between 650 and 750 °C, resulting in a layer of "low- temperature oxide" (LTO). However, silane produces a lower-quality oxide than the other methods (lower dielectric strength, for instance), and it deposits nonconformally. Any of these reactions may be used in LPCVD, but the silane reaction is also done in APCVD. CVD oxide invariably has lower quality than thermal oxide, but thermal oxidation can only be used in the earliest stages of IC manufacturing.
Oxide may also be grown with impurities (alloying or "doping"). This may have two purposes. During further process steps that occur at high temperature, the impurities may diffuse from the oxide into adjacent layers (most notably silicon) and dope them. Oxides containing 5–15% impurities by mass are often used for this purpose. In addition, silicon dioxide alloyed with phosphorus pentoxide ("P-glass") can be used to smooth out uneven surfaces. P-glass softens and reflows at temperatures above 1000 °C. This process requires a phosphorus concentration of at least 6%, but concentrations above 8% can corrode aluminium. Phosphorus is deposited from phosphine gas and oxygen:
Glasses containing both boron and phosphorus (borophosphosilicate glass, BPSG) undergo viscous flow at lower temperatures; around 850 °C is achievable with glasses containing around 5 weight % of both constituents, but stability in air can be difficult to achieve. Phosphorus oxide in high concentrations interacts with ambient moisture to produce phosphoric acid. Crystals of BPO4 can also precipitate from the flowing glass on cooling; these crystals are not readily etched in the standard reactive plasmas used to pattern oxides, and will result in circuit defects in integrated circuit manufacturing.
Besides these intentional impurities, CVD oxide may contain byproducts of the deposition. TEOS produces a relatively pure oxide, whereas silane introduces hydrogen impurities, and dichlorosilane introduces chlorine.
Lower temperature deposition of silicon dioxide and doped glasses from TEOS using ozone rather than oxygen has also been explored (350 to 500 °C). Ozone glasses have excellent conformality but tend to be hygroscopic – that is, they absorb water from the air due to the incorporation of silanol (Si-OH) in the glass. Infrared spectroscopy and mechanical strain as a function of temperature are valuable diagnostic tools for diagnosing such problems.
Silicon nitride.
Silicon nitride is often used as an insulator and chemical barrier in manufacturing ICs. The following two reactions deposit silicon nitride from the gas phase:
Silicon nitride deposited by LPCVD contains up to 8% hydrogen. It also experiences strong tensile stress, which may crack films thicker than 200 nm. However, it has higher resistivity and dielectric strength than most insulators commonly available in microfabrication (1016 Ω·cm and 10 MV/cm, respectively).
Another two reactions may be used in plasma to deposit SiNH:
These films have much less tensile stress, but worse electrical properties (resistivity 106 to 1015 Ω·cm, and dielectric strength 1 to 5 MV/cm).
Metals.
CVD for tungsten is achieved from tungsten hexafluoride (WF6), which may be deposited in two ways:
Other metals, notably aluminium and copper, can be deposited by CVD. , commercially cost-effective CVD for copper did not exist, although volatile sources exist, such as Cu(hfac)2. Copper is typically deposited by electroplating. Aluminum can be deposited from triisobutylaluminium (TIBAL) and related organoaluminium compounds.
CVD for molybdenum, tantalum, titanium, nickel is widely used. These metals can form useful silicides when deposited onto silicon. Mo, Ta and Ti are deposited by LPCVD, from their pentachlorides. Nickel, molybdenum, and tungsten can be deposited at low temperatures from their carbonyl precursors. In general, for an arbitrary metal "M", the chloride deposition reaction is as follows:
whereas the carbonyl decomposition reaction can happen spontaneously under thermal treatment or acoustic cavitation and is as follows:
the decomposition of metal carbonyls is often violently precipitated by moisture or air, where oxygen reacts with the metal precursor to form metal or metal oxide along with carbon dioxide.
Niobium(V) oxide layers can be produced by the thermal decomposition of niobium(V) ethoxide with the loss of diethyl ether according to the equation:
Graphene.
Many variations of CVD can be utilized to synthesize graphene. Although many advancements have been made, the processes listed below are not commercially viable yet.
The most popular carbon source used to produce graphene is methane gas. Less popular choices include petroleum asphalt, notable for being inexpensive but more difficult to work with.
The use of catalyst is viable in changing the physical process of graphene production. Notable examples include iron nanoparticles, nickel foam, and gallium vapor. These catalysts can either be used in situ during graphene buildup, or situated at some distance away at the deposition area. Some catalysts require another step to remove them from the sample material.
Physical conditions such as surrounding pressure, temperature, carrier gas, and chamber material play a big role in production of graphene.
Most systems use LPCVD with pressures ranging from 1 to 1500 Pa. However, some still use APCVD. Low pressures are used more commonly as they help prevent unwanted reactions and produce more uniform thickness of deposition on the substrate.
On the other hand, temperatures used range from 800-1050 °C. High temperatures translate to an increase of the rate of reaction. Caution has to be exercised as high temperatures do pose higher danger levels in addition to greater energy costs. 
Hydrogen gas and inert gases such as argon are flowed into the system. These gases act as a carrier, enhancing surface reaction and improving reaction rate, thereby increasing deposition of graphene onto the substrate. 
Standard quartz tubing and chambers are used in CVD of graphene. Quartz is chosen because it has a very high melting point and is chemically inert. In other words, quartz does not interfere with any physical or chemical reactions regardless of the conditions. 
Raman spectroscopy, X-ray spectroscopy, transmission electron microscopy (TEM), and scanning electron microscopy (SEM) are used to examine and characterize the graphene samples.
Raman spectroscopy is used to characterize and identify the graphene particles; X-ray spectroscopy is used to characterize chemical states; TEM is used to provide fine details regarding the internal composition of graphene; SEM is used to examine the surface and topography.
Sometimes, atomic force microscopy (AFM) is used to measure local properties such as friction and magnetism.
Diamond.
Chemical vapor deposition (CVD) can be used to produce a synthetic diamond by creating the circumstances necessary for carbon atoms in a gas to settle on a substrate in crystalline form.
CVD production of diamonds has received a great deal of attention in the materials sciences because it allows many new applications of diamonds that had previously been considered too difficult to make economical. CVD diamond growth typically occurs under low pressure (1–27 kPa; 0.145–3.926 psi; 7.5-203 Torr) and involves feeding varying amounts of gases into a chamber, energizing them and providing conditions for diamond growth on the substrate. The gases always include a carbon source, and typically include hydrogen as well, though the amounts used vary greatly depending on the type of diamond being grown. Energy sources include hot filament, microwave power, and arc discharges, among others. The energy source is intended to generate a plasma in which the gases are broken down and more complex chemistries occur. The actual chemical process for diamond growth is still under study and is complicated by the very wide variety of diamond growth processes used.
Using CVD, films of diamond can be grown over large areas of substrate with control over the properties of the diamond produced. In the past, when high pressure high temperature (HPHT) techniques were used to produce a diamond, the result was typically very small free standing diamonds of varying sizes. With CVD diamond growth areas of greater than fifteen centimeters (six inches) diameter have been achieved and much larger areas are likely to be successfully coated with diamond in the future. Improving this process is key to enabling several important applications.
The growth of diamond directly on a substrate allows the addition of many of diamond's important qualities to other materials. Since diamond has the highest thermal conductivity of any bulk material, layering diamond onto high heat producing electronics (such as optics and transistors) allows the diamond to be used as a heat sink. Diamond films are being grown on valve rings, cutting tools, and other objects that benefit from diamond's hardness and exceedingly low wear rate. In each case the diamond growth must be carefully done to achieve the necessary adhesion onto the substrate. Diamond's very high scratch resistance and thermal conductivity, combined with a lower coefficient of thermal expansion than Pyrex glass, a coefficient of friction close to that of Teflon (Polytetrafluoroethylene) and strong lipophilicity would make it a nearly ideal non-stick coating for cookware if large substrate areas could be coated economically.
CVD growth allows one to control the properties of the diamond produced. In the area of diamond growth, the word "diamond" is used as a description of any material primarily made up of sp3-bonded carbon, and there are many different types of diamond included in this. By regulating the processing parameters—especially the gases introduced, but also including the pressure the system is operated under, the temperature of the diamond, and the method of generating plasma—many different materials that can be considered diamond can be made. Single crystal diamond can be made containing various dopants. Polycrystalline diamond consisting of grain sizes from several nanometers to several micrometers can be grown. Some polycrystalline diamond grains are surrounded by thin, non-diamond carbon, while others are not. These different factors affect the diamond's hardness, smoothness, conductivity, optical properties and more.
Chalcogenides.
Commercially, mercury cadmium telluride is of continuing interest for detection of infrared radiation. Consisting of an alloy of CdTe and HgTe, this material can be prepared from the dimethyl derivatives of the respective elements.

</doc>
<doc id="6112" url="https://en.wikipedia.org/wiki?curid=6112" title="CN Tower">
CN Tower

The CN Tower () is a concrete communications and observation tower in downtown Toronto, Ontario, Canada. Built on the former Railway Lands, it was completed in 1976, becoming the world's tallest free-standing structure and world's tallest tower at the time. It held both records for 34 years until the completion of Burj Khalifa and Canton Tower in 2010. Since then, it became the 3rd tallest tower in the world and remains the tallest free-standing structure in the Western Hemisphere, a signature icon of Toronto's skyline, and a symbol of Canada, attracting more than two million international visitors annually.
Its name "CN" originally referred to Canadian National, the railway company that built the tower. Following the railway's decision to divest non-core freight railway assets, prior to the company's privatization in 1995, it transferred the tower to the Canada Lands Company, a federal Crown corporation responsible for real estate development. Since the name "CN Tower" became common in daily usage, the abbreviation was eventually expanded to Canadian National Tower or Canada's National Tower. However, neither of these names is commonly used.
In 1995, the CN Tower was declared one of the modern Seven Wonders of the World by the American Society of Civil Engineers. It also belongs to the World Federation of Great Towers, where it holds second-place ranking.
History.
The idea of the CN Tower originated in 1968 when the Canadian National Railway wanted to build a large TV and radio communication platform to serve the Toronto area, as well as demonstrate the strength of Canadian industry and CN in particular. These plans evolved over the next few years, and the project became official in 1972. The tower would have been part of Metro Centre (see CityPlace), a large development south of Front Street on the Railway Lands, a large railway switching yard that was being made redundant by newer yards outside the city. Key project team members were NCK Engineering as structural engineer; John Andrews Architects; Webb, Zerafa, Menkes, Housden Architects; Foundation Building Construction; and Canron (Eastern Structural Division).
As Toronto grew rapidly during the late 1960s and early 1970s, multiple skyscrapers were constructed in the downtown core, most notably First Canadian Place. The reflective nature of the new buildings compromised the quality of broadcast signals necessitating new, higher antennas that were at least tall.
At the time, most data communications took place over point-to-point microwave links, whose dish antennae covered the roofs of large buildings. As each new skyscraper was added to the downtown, former line-of-sight links were no longer possible. CN intended to rent "hub" space for microwave links, visible from almost any building in the Toronto area. The CN Tower can be seen from at least as far away as Kennedy Street in Aurora, Ontario, approximately to the north, east of Toronto, in Oshawa, and from several points on the south shore of Lake Ontario, to the south in the U.S. state of New York.
The original plan for the tower envisioned a tripod consisting of three independent cylindrical "pillars" linked at various heights by structural bridges. Had it been built, this design would have been considerably shorter, with the metal antenna located roughly where the concrete section between the main level and the SkyPod lies today. As the design effort continued, it evolved into the current design with a single continuous hexagonal core to the SkyPod, with three support legs blended into the hexagon below the main level, forming a large Y-shape structure at the ground level.
The idea for the main level in its current form evolved around this time, but the Space Deck (now named SkyPod) was not part of the plans until some time later. One engineer in particular felt that visitors would feel the higher observation deck would be worth paying extra for, and the costs in terms of construction were not prohibitive. It was also some time around this point that it was realized that the tower could become the world's tallest structure, and plans were changed to incorporate subtle modifications throughout the structure to this end.
Construction.
Construction on the CN Tower began on February 6, 1973, with massive excavations at the tower base for the foundation. By the time the foundation was complete, of earth and shale were removed to a depth of in the centre, and a base incorporating of concrete with of rebar and of steel cable had been built to a thickness of . This portion of the construction was fairly rapid, with only four months needed between the start and the foundation being ready for construction on top.
To build the main support pillar, a hydraulically raised slipform was built at the base. This was a fairly impressive engineering feat on its own, consisting of a large metal platform that raised itself on jacks at about per day as the concrete below set. Concrete was poured continuously by a team of 1,532 people until February 22, 1974, during which it had already become the tallest structure in Canada, surpassing the recently built Inco Superstack in Sudbury, which was built using similar methods. In total, the tower contains of concrete, all of which was mixed on-site in order to ensure batch consistency. Through the pour, the vertical accuracy of the tower was maintained by comparing the slip form's location to massive plumb bobs hanging from it, observed by small telescopes from the ground. Over the height of the tower, it varies from true vertical accuracy by only .
In August 1974, construction of the main level commenced. Using 45 hydraulic jacks attached to cables strung from a temporary steel crown anchored to the top of the tower, twelve giant steel and wooden bracket forms were slowly raised, ultimately taking about a week to crawl up to their final position. These forms were used to create the brackets that support the main level, as well as a base for the construction of the main level itself. The Space Deck (currently named SkyPod) was built of concrete poured into a wooden frame attached to rebar at the lower level deck, and then reinforced with a large steel compression band around the outside.
The antenna was originally to be raised by crane as well, but during construction the Sikorsky S-64 Skycrane helicopter became available when the United States Army sold off theirs to civilian operators. The helicopter, named "Olga", was first used to remove the crane, and then flew the antenna up in 36 sections. The flights of the antenna pieces were a minor tourist attraction of their own, and the schedule was printed in the local newspapers. Use of the helicopter saved months of construction time, with this phase taking only three and a half weeks instead of the planned six months. The tower was topped off on April 2, 1975, after 26 months of construction, officially capturing the height record from Moscow's Ostankino Tower, and bringing the total mass to .
Two years into the construction, plans for Metro Centre were scrapped, leaving the tower isolated on the Railway Lands in what was then a largely abandoned light-industrial space. This caused serious problems for tourists to access the tower. Ned Baldwin, project architect with John Andrews, wrote at the time that "All of the logic which dictated the design of the lower accommodation has been upset," and that "Under such ludicrous circumstances Canadian National would hardly have chosen this location to build."
Opening.
The CN Tower opened to the public on June 26, 1976, although the official opening date was October 1, 1976. The construction costs of approximately CDN$63 million ($ in dollars) were repaid in fifteen years. Canadian National Railway sold the tower prior to taking the company private in 1995, when they decided to divest themselves of all operations not directly related to their core freight shipping businesses.
From the mid-1970s to the mid-1980s, the CN Tower was practically the only development along Front Street West; it was still possible to see Lake Ontario from the foot of the CN Tower due to the expansive parking lots and lack of development in the area at the time. As the area around the tower was developed, particularly with the completion of the Metro Toronto Convention Centre in 1984 and the SkyDome in 1989 (renamed Rogers Centre in 2005), the former Railway Lands were redeveloped and the tower became the centre of a newly developing entertainment area. Access was greatly improved with the construction of the SkyWalk in 1989, which connected the tower and SkyDome to the nearby Union Station railway and subway station, and, in turn, to the city's PATH underground pedestrian system. By the mid-1990s, it was the centre of a thriving tourist district. The entire area continues to be an area of intense building, notably a boom in condominium construction in the first two decades of the 21st century, as well as the Ripley's Aquarium by the base of the tower.
Events.
Falling ice danger.
A freezing rain storm on March 2, 2007, resulted in a layer of ice several centimetres thick forming on the side of the tower and other downtown buildings. The sun thawed the ice, and winds of up to blew some of it away from the structure. There were fears that cars and windows of nearby buildings would be smashed by large chunks of ice. In response, police closed some streets surrounding the tower. During morning rush hour on March 5 of the same year, police expanded the area of closed streets to include the Gardiner Expressway away from the tower, as increased winds blew the ice farther away, as far north as King Street, away, where a taxicab window was shattered.
Subsequently, on March 6, 2007, the Gardiner Expressway was reopened after winds died down.
Structure.
The CN Tower consists of several substructures. The main portion of the tower is a hollow concrete hexagonal pillar containing the stairwells and power and plumbing connections. The Tower's six elevators are located in the three inverted angles created by the Tower's hexagonal shape (two elevators per angle). Each of the three elevator shafts are lined with glass, allowing for views of the city as the glass-windowed elevators make their way up the Tower. The stairwell was originally located in one of these angles (the one facing north), but was moved into the central hollow of the Tower; the Tower's new fifth and sixth elevators were placed in the hexagonal angle that once contained the stairwell. On top of the main concrete portion of the Tower is a tall metal broadcast antenna, carrying TV and radio signals. There are three visitor areas: the Glass Floor and Outdoor Observation Terrace which are both located at an elevation of , the Indoor Lookout Level (formerly known as "Indoor Observation Level") located at , and the higher SkyPod (formerly known as "Space Deck") at , just below the metal antenna. The hexagonal shape can be seen between the two areas; however, below the main deck, three large supporting legs give the tower the appearance of a large tripod.
The main deck level is seven storeys, some of which are open to the public. Below the public areas — at — is a large white donut-shaped radome containing the structure's microwave receivers. The glass floor and outdoor observation deck are at . The glass floor has an area of and can withstand a pressure of . The floor's thermal glass units are thick, consisting of a pane of laminated glass, airspace and a pane of laminated glass. Some people experience acrophobia when standing on the glass floor and looking down at the ground below. In 2008, one elevator was upgraded to add a glass floor panel, believed to have the highest vertical rise of any elevator equipped with this feature. The Horizons Cafe and the lookout level are at . The 360 Restaurant, a revolving restaurant that completes a full rotation once every 72 minutes, is at . When the tower first opened, it also featured a disco named Sparkles, billed as the highest disco and dance floor in the world.
The SkyPod was once the highest public observation deck in the world until it was surpassed by the Shanghai World Financial Center in 2008.
A metal staircase reaches the main deck level after 1,776 steps, and the SkyPod above after 2,579 steps; it is the tallest metal staircase on Earth. These stairs are intended for emergency use only and are not open to the public, except for two times per year for charity stair-climb events. The average climber takes approximately 30 minutes to climb to the base of the radome, but the fastest climb on record is 7 minutes and 52 seconds in 1989 by Brendan Keenoy, an Ontario Provincial Police officer. In 2002, Canadian Olympian and Paralympic champion Jeff Adams climbed the stairs of the tower in a specially designed wheelchair. The stairs were originally on one of the three sides of the tower, with a glass view, but these were later replaced with the third elevator pair and the stairs were moved to the inside of the core. Top climbs on the new, windowless stairwell used since around 2003 have generally been over ten minutes.
EdgeWalk.
On August 1, 2011, the CN Tower opened the EdgeWalk, an amusement in which thrill-seekers can walk on and around the roof of the main pod of the tower at , which is directly above the 360 Restaurant. It is the world's highest full-circle, hands-free walk. Visitors are tethered to an overhead rail system and walk around the edge of the CN Tower's main pod above the 360 Restaurant on a metal floor. The attraction is closed throughout the winter season and during periods of electrical storms and high winds.
One of the notable guests who visited EdgeWalk includes comedian Rick Mercer, as featured on his CBC Television show, "Rick Mercer Report".
Safety features.
In August 2000, a fire broke out at the Ostankino Tower in Moscow. It killed three people and caused extensive damage. The fire was blamed on poor maintenance and outdated equipment. The failure of the fire-suppression systems and the lack of proper equipment for firefighters allowed the fire to destroy most of the interior and spark fears the tower might even collapse.
The Ostankino Tower was completed nine years before the CN Tower, and is only shorter. The parallels between the towers led to some concern that the CN Tower could be at risk of a similar tragedy. However, Canadian officials subsequently stated that it is "highly unlikely" that a similar disaster could occur at the CN Tower, as it has important safeguards that were not present in the Ostankino Tower. Specifically, officials cited:
Officials also noted that the CN Tower has an excellent safety record and that there has never been an accidental fire in the tower since it was opened in 1976. Moreover, other supertall structures built between 1967 and 1976 — such as the Willis Tower (formerly the Sears Tower), the World Trade Center (until its destruction on September 11, 2001), the Fernsehturm Berlin, the Aon Center, the John Hancock Center, and First Canadian Place — also have excellent safety records, which suggests that the Ostankino Tower accident was a rare safety failure, and that the likelihood of similar events occurring at other supertall structures is extremely low.
Lighting.
The CN Tower was originally lit at night with incandescent lights, but they were removed in 1997, because they were inefficient and expensive to repair. In June 2007, the tower was outfitted with 1,330 super-bright LED lights inside the elevator shafts, shooting up over the main pod and upward to the top of the tower's mast to light the tower from dusk until 2 a.m. The official opening ceremony took place on June 28 before the Canada Day holiday weekend.
The tower changes its lighting scheme on holidays and to commemorate major events. After the 95th Grey Cup in Toronto, the tower was lit up in green and white to represent the colours of the Grey Cup champion Saskatchewan Roughriders. From sundown on August 27, 2011, to sunrise the following day, the tower was lit in orange, the official colour of the New Democratic Party (NDP), to commemorate the death of federal NDP leader and leader of the official opposition Jack Layton. When former South African president Nelson Mandela died, the tower was lit up in the colours of the South African flag. When former federal finance minister under Stephen Harper's Conservatives Jim Flaherty died, the tower was lit in green to reflect his Irish Canadian heritage. On the night of the attacks on Paris on November 13, 2015, the CN Tower was lit up in the colours of the French flag.
Programmed from a desktop computer with a wireless network interface controller in Burlington, Ontario, the LEDs use less energy to light than the previously used incandescent lights (10% less energy than the dimly lit version and 60% less than the brightly lit version). The estimated cost to use the LEDs is $1,000 per month.
During the spring and autumn bird migration seasons, the lights would be turned off to comply with the voluntary Fatal Light Awareness Program, which "encourages buildings to dim unnecessary exterior lighting to mitigate bird mortality during spring and summer migration."
Height comparisons.
The CN Tower is the tallest freestanding structure in the Western Hemisphere. As of 2013, there are only two other freestanding structures in the Western Hemisphere which exceed in height; the Willis Tower in Chicago, which stands at when measured to its pinnacle; and the topped-out One World Trade Center in New York City, which has a pinnacle height of , or approximately shorter than the CN Tower. Due to the symbolism of the number 1776 (the year of the signing of the United States Declaration of Independence), the height of One World Trade Center is unlikely to be increased. The proposed Chicago Spire was expected to exceed the height of the CN Tower, but its construction was halted early due to financial difficulties amid the Great Recession, and was eventually cancelled in 2010.
Height distinction debate.
"World's Tallest Tower" title.
"Guinness World Records" has called the CN Tower "the world's tallest self-supporting tower" and "the world's tallest free-standing tower". Although Guinness did list this description of the CN Tower under the heading "tallest building" at least once, it has also listed it under "tallest tower", omitting it from its list of "tallest buildings." In 1996, Guinness changed the tower's classification to "World's Tallest Building and Freestanding Structure". Emporis and the Council on Tall Buildings and Urban Habitat both listed the CN Tower as the world's tallest free-standing structure on land, and specifically state that the CN Tower is not a true building, thereby awarding the title of world's tallest building to Taipei 101, which is shorter than the CN Tower. The issue of what was tallest became moot when Burj Khalifa, then under construction, exceeded the height of the CN Tower in 2007 (see below).
Although the CN Tower contains a restaurant, a gift shop and multiple observation levels, it does not have floors continuously from the ground, and therefore it is not considered a building by the Council on Tall Buildings and Urban Habitat (CTBUH) or Emporis. CTBUH defines a building as "a structure that is designed for residential, business, or manufacturing purposes. An essential characteristic of a building is that it has floors." The CN Tower and other similar structures — such as the Ostankino Tower in Moscow, Russia; the Oriental Pearl Tower in Shanghai, China; the Stratosphere Tower in Las Vegas, Nevada, USA; and the Eiffel Tower in Paris, France — are categorized as "towers", which are free-standing structures that may have observation decks and a few other habitable levels, but do not have floors from the ground up. The CN Tower was the tallest tower by this definition, until 2010 (see below).
Taller than the CN Tower are numerous radio masts and towers, which are held in place by guy-wires, the tallest being the KVLY-TV mast in Blanchard, North Dakota, USA at tall, leading to a distinction between these and "free-standing" structures. Additionally, the Petronius Platform stands above its base on the bottom of the Gulf of Mexico, but only the top of this oil and natural gas platform are above water, and the structure is thus partially supported by its buoyancy. Like the CN Tower, none of these taller structures are commonly considered buildings.
On September 12, 2007, Burj Khalifa, which is a hotel, residential and commercial building in Dubai, United Arab Emirates, and was formerly known as Burj Dubai before opening, passed the CN Tower's 553.33-metre height. The CN Tower held the record of tallest free-standing structure on land for over 30 years.
After Burj Khalifa had been formally recognized by the Guinness World Records as the world's tallest freestanding structure, Guinness re-certified CN Tower as the world's tallest freestanding tower. The tower definition used by Guinness was defined by the Council on Tall Buildings and Urban Habitat as 'a building in which less than 50% of the construction is usable floor space'. "Guinness World Records" editor-in-chief Craig Glenday announced that Burj Khalifa was not classified as a tower because it has too much usable floor space to be considered to be a tower. CN Tower still held world records for highest above ground wine cellar (in 360 Restaurant) at 351 metres, highest above ground restaurant at 346 metres (Horizons Restaurant), and tallest free-standing concrete tower during Guinness's recertification. The CN Tower was surpassed by the Canton Tower in Guangzhou, China, which stands at tall, as the world's tallest tower, in 2010; which in turn was surpassed by the Tokyo Skytree, completed in February 2012, which currently is the tallest tower at in height. The CN Tower, as of 2014, stands as the fifth-tallest free-standing structure on land in the world and the third-tallest free-standing tower.
Other height records.
Since the construction of the tower had been completed, it has gained following world height records:
Use.
The CN Tower has been and continues to be used as a communications tower for a number of different media and by numerous companies.
Radio.
There is no AM broadcasting on the CN Tower. The FM antennas are situated above ground.
Bobbie Rosenfeld Park.
In 1991, two years following the completion of the Rogers Centre, which was known as SkyDome at the time, the open space between Rogers Centre and CN Tower was renamed Bobbie Rosenfeld Park, in honour of the Canadian athlete Bobbie Rosenfeld. The city-owned park is mainly an open space covered by paving stone and planters. There are some trees and concession stands selling food and other items to tourists and visitors in the area.
Located along the south end facing Bremner Avenue, there is a piece of artwork by artist Susan Schelle called "Salmon Run". The sculpture consisting of a representation of salmon leaping up a waterfall. The water fountain piece was not functional for many years, until it was restored in 2006.
Near both the park and the base of the tower, the Ripley's Aquarium of Canada opened on October 16, 2013.

</doc>
<doc id="6113" url="https://en.wikipedia.org/wiki?curid=6113" title="Chain rule">
Chain rule

In calculus, the chain rule is a formula for computing the derivative of the composition of two or more functions. That is, if "f" and "g" are functions, then the chain rule expresses the derivative of their composition (the function which maps "x" to "f"("g"("x")) in terms of the derivatives of "f" and "g" and the product of functions as follows:
This can be written more explicitly in terms of the variable. Let , or equivalently, for all "x". Then one can also write
The chain rule may be written, in Leibniz's notation, in the following way. We consider "z" to be a function of the variable "y", which is itself a function of "x" ("y" and "z" are therefore dependent variables), and so, "z" becomes a function of "x" as well:
In integration, the counterpart to the chain rule is the substitution rule.
History.
The chain rule seems to have first been used by Leibniz. He used it to calculate the derivative of formula_4 as the composite of the square root function and the function formula_5. He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of chain rule is due to Leibniz. L'Hôpital uses the chain rule implicitly in his "Analyse des infiniment petits". The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.
One dimension.
First example.
Suppose that a skydiver jumps from an aircraft. Assume that "t" seconds after his jump, his height above sea level in meters is given by . One model for the atmospheric pressure at a height "h" is . These two equations can be differentiated and combined in various ways to produce the following data:
The chain rule gives a method for computing in terms of and . While it is always possible to directly apply the definition of the derivative to compute the derivative of a composite function, this is usually very difficult. The utility of the chain rule is that it turns a complicated derivative into several easy derivatives.
The chain rule states that, under appropriate conditions,
In this example, this equals
In the statement of the chain rule, "f" and "g" play slightly different roles because "f"′ is evaluated at "g"("t") whereas "g"′ is evaluated at "t". This is necessary to make the units work out correctly. For example, suppose that we want to compute the rate of change in atmospheric pressure ten seconds after the skydiver jumps. This is and has units of Pascals per second. The factor "g"′(10) in the chain rule is the velocity of the skydiver ten seconds after his jump, and it is expressed in meters per second. "f"′("g"(10)) is the change in pressure with respect to height at the height "g"(10) and is expressed in Pascals per meter. The product of "f"′("g"(10)) and "g"′(10) therefore has the correct units of Pascals per second. It is not possible to evaluate "f" anywhere else. For instance, because the 10 in the problem represents ten seconds, the expression "f"′(10) represents the change in pressure at a height of ten seconds, which is nonsense. Similarly, because meters per second, the expression "f"′("g"′(10)) represents the change in pressure at a height of −98 meters per second, which is also nonsense. However, "g"(10) is 3020 meters above sea level, the height of the skydiver ten seconds after his jump. This has the correct units for an input to "f".
Statement.
The simplest form of the chain rule is for real-valued functions of one real variable. It says that if "g" is a function that is differentiable at a point "c" (i.e. the derivative "g"′("c") exists) and "f" is a function that is differentiable at "g"("c"), then the composite function "f" ∘ "g" is differentiable at "c", and the derivative is
The rule is sometimes abbreviated as
If and , then this abbreviated form is written in Leibniz notation as:
The points where the derivatives are evaluated may also be stated explicitly:
Further examples.
Absence of formulas.
It may be possible to apply the chain rule even when there are no formulas for the functions which are being differentiated. This can happen when the derivatives are measured directly. Suppose that a car is driving up a tall mountain. The car's speedometer measures its speed directly. If the grade is known, then the rate of ascent can be calculated using trigonometry. Suppose that the car is ascending at . Standard models for the Earth's atmosphere imply that the temperature drops about per kilometer ascended (called the lapse rate). To find the temperature drop per hour, we apply the chain rule. Let the function be the altitude of the car at time , and let the function be the temperature kilometers above sea level. and are not known exactly: For example, the altitude where the car starts is not known and the temperature on the mountain is not known. However, their derivatives are known: is , and is . The chain rule says that the derivative of the composite function is the product of the derivative of and the derivative of . This is .
One of the reasons why this computation is possible is because is a constant function. This is because the above model is very simple. A more accurate description of how the temperature near the car varies over time would require an accurate model of how the temperature varies at different altitudes. This model may not have a constant derivative. To compute the temperature change in such a model, it would be necessary to know and not just , because without knowing it is not possible to know where to evaluate .
Composites of more than two functions.
The chain rule can be applied to composites of more than two functions. To take the derivative of a composite of more than two functions, notice that the composite of "f", "g", and "h" (in that order) is the composite of "f" with . The chain rule says that to compute the derivative of , it is sufficient to compute the derivative of "f" and the derivative of . The derivative of "f" can be calculated directly, and the derivative of can be calculated by applying the chain rule again.
For concreteness, consider the function
This can be decomposed as the composite of three functions:
Their derivatives are:
The chain rule says that the derivative of their composite at the point is:
In Leibniz notation, this is:
or for short,
The derivative function is therefore:
Another way of computing this derivative is to view the composite function as the composite of and "h". Applying the chain rule to this situation gives:
This is the same as what was computed above. This should be expected because .
Sometimes it is necessary to differentiate an arbitrarily long composition of the form formula_20. In this case, define
where formula_22 and formula_23 when formula_24
or, in the Lagrange notation,
Quotient rule.
The chain rule can be used to derive some well-known differentiation rules. For example, the quotient rule is a consequence of the chain rule and the product rule. To see this, write the function "f"("x")/"g"("x") as the product . First apply the product rule:
To compute the derivative of 1/"g"("x"), notice that it is the composite of "g" with the reciprocal function, that is, the function that sends "x" to 1/"x". The derivative of the reciprocal function is −1/"x"2. By applying the chain rule, the last expression becomes:
which is the usual formula for the quotient rule.
Derivatives of inverse functions.
Suppose that has an inverse function. Call its inverse function "f" so that we have . There is a formula for the derivative of "f" in terms of the derivative of "g". To see this, note that "f" and "g" satisfy the formula
Because the functions "f"("g"("x")) and "x" are equal, their derivatives must be equal. The derivative of "x" is the constant function with value 1, and the derivative of "f"("g"("x")) is determined by the chain rule. Therefore, we have:
To express "f"′ as a function of an independent variable "y", we substitute "f"("y") for "x" wherever it appears. Then we can solve for "f"′.
For example, consider the function . It has an inverse . Because , the above formula says that
This formula is true whenever "g" is differentiable and its inverse "f" is also differentiable. This formula can fail when one of these conditions is not true. For example, consider . Its inverse is , which is not differentiable at zero. If we attempt to use the above formula to compute the derivative of "f" at zero, then we must evaluate 1/"g"′("f"(0)). and , so we must evaluate 1/0, which is undefined. Therefore, the formula fails in this case. This is not surprising because "f" is not differentiable at zero.
Higher derivatives.
Faà di Bruno's formula generalizes the chain rule to higher derivatives. Assuming that and , then the first few derivatives are:
Proofs.
First proof.
One proof of the chain rule begins with the definition of the derivative:
Assume for the moment that "g"("x") does not equal "g"("a") for any "x" near "a". Then the previous expression is equal to the product of two factors:
When "g" oscillates near "a", then it might happen that no matter how close one gets to "a", there is always an even closer "x" such that "g"("x") equals "g"("a"). For example, this happens for near the point . Whenever this happens, the above expression is undefined because it involves division by zero. To work around this, introduce a function "Q" as follows:
We will show that the difference quotient for is always equal to:
Whenever "g"("x") is not equal to "g"("a"), this is clear because the factors of cancel. When "g"("x") equals "g"("a"), then the difference quotient for is zero because "f"("g"("x")) equals "f"("g"("a")), and the above product is zero because it equals "f"′("g"("a")) times zero. So the above product is always equal to the difference quotient, and to show that the derivative of at "a" exists and to determine its value, we need only show that the limit as "x" goes to "a" of the above product exists and determine its value.
To do this, recall that the limit of a product exists if the limits of its factors exist. When this happens, the limit of the product of these two factors will equal the product of the limits of the factors. The two factors are "Q"("g"("x")) and . The latter is the difference quotient for "g" at "a", and because "g" is differentiable at "a" by assumption, its limit as "x" tends to "a" exists and equals "g"′("a").
It remains to study "Q"("g"("x")). "Q" is defined wherever "f" is. Furthermore, because "f" is differentiable at "g"("a") by assumption, "Q" is continuous at "g"("a"). "g" is continuous at "a" because it is differentiable at "a", and therefore is continuous at "a". So its limit as "x" goes to "a" exists and equals "Q"("g"("a")), which is "f"′("g"("a")).
This shows that the limits of both factors exist and that they equal "f"′("g"("a")) and "g"′("a"), respectively. Therefore, the derivative of at "a" exists and equals "f"′("g"("a"))"g"′("a").
Second proof.
Another way of proving the chain rule is to measure the error in the linear approximation determined by the derivative. This proof has the advantage that it generalizes to several variables. It relies on the following equivalent definition of differentiability at a point: A function "g" is differentiable at "a" if there exists a real number "g"′("a") and a function "ε"("h") that tends to zero as "h" tends to zero, and furthermore
Here the left-hand side represents the true difference between the value of "g" at "a" and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.
In the situation of the chain rule, such a function "ε" exists because "g" is assumed to be differentiable at "a". Again by assumption, a similar function also exists for "f" at "g"("a"). Calling this function "η", we have
The above definition imposes no constraints on "η"(0), even though it is assumed that "η"("k") tends to zero as "k" tends to zero. If we set , then "η" is continuous at 0.
Proving the theorem requires studying the difference as "h" tends to zero. The first step is to substitute for using the definition of differentiability of "g" at "a":
The next step is to use the definition of differentiability of "f" at "g"("a"). This requires a term of the form for some "k". In the above equation, the correct "k" varies with "h". Set and the right hand side becomes . Applying the definition of the derivative gives:
To study the behavior of this expression as "h" tends to zero, expand "k""h". After regrouping the terms, the right-hand side becomes:
Because "ε"("h") and "η"("k""h") tend to zero as "h" tends to zero, the first two bracketed terms tend to zero as "h" tends to zero. Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero. Because the above expression is equal to the difference , by the definition of the derivative is differentiable at "a" and its derivative is 
The role of "Q" in the first proof is played by "η" in this proof. They are related by the equation:
The need to define "Q" at "g"("a") is analogous to the need to define "η" at zero.
Third proof.
Carathéodory's alternative definition of the differentiability of a function can be used to give an elegant proof of the chain rule.
Under this definition, a function is differentiable at a point if and only if there is a function , continuous at and such that . There is at most one such function, and if is differentiable at then .
Given the assumptions of the chain rule and the fact that differentiable functions and compositions of continuous functions are continuous, we have that there exist functions , continuous at and , continuous at and such that,
and
Therefore,
but the function given by is continuous at , and we get, for this 
A similar approach works for continuously differentiable (vector-)functions of many variables. This ideology of factoring also allows a unified approach to stronger forms of differentiability, when the derivative is required to be Lipschitz, Holder, etc. Differentiation itself can be viewed as the polynomial remainder theorem (the little Bezout, or factor theorem), generalized to an appropriate class of functions. 
Proof via infinitesimals.
If formula_50 and formula_51 then choosing infinitesimal formula_52 we compute the corresponding formula_53 and then the corresponding formula_54, so that
and applying the standard part we obtain
which is the chain rule.
Higher dimensions.
The simplest generalization of the chain rule to higher dimensions uses the total derivative. The total derivative is a linear transformation that captures how the function changes in all directions. Fix differentiable functions and and a point a in R"n". Let "D"a"g" denote the total derivative of "g" at a and "D""g"(a)"f" denote the total derivative of "f" at "g"(a). These two derivatives are linear transformations and , respectively, so they can be composed. The chain rule for total derivatives says that their composite is the total derivative of at a:
or for short,
The higher-dimensional chain rule can be proved using a technique similar to the second proof given above.
Because the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices. The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices. From this perspective the chain rule therefore says:
or for short,
That is, the Jacobian of a composite function is the product of the Jacobians of the composed functions (evaluated at the appropriate points).
The higher-dimensional chain rule is a generalization of the one-dimensional chain rule. If "k", "m", and "n" are 1, so that and , then the Jacobian matrices of "f" and "g" are . Specifically, they are:
The Jacobian of "f" ∘ "g" is the product of these matrices, so it is , as expected from the one-dimensional chain rule. In the language of linear transformations, "D""a"("g") is the function which scales a vector by a factor of "g"′("a") and "D""g"("a")("f") is the function which scales a vector by a factor of "f"′("g"("a")). The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by "f"′("g"("a"))⋅"g"′("a").
Another way of writing the chain rule is used when "f" and "g" are expressed in terms of their components as and . In this case, the above rule for Jacobian matrices is usually written as:
The chain rule for total derivatives implies a chain rule for partial derivatives. Recall that when the total derivative exists, the partial derivative in the "i"th coordinate direction is found by multiplying the Jacobian matrix by the "i"th basis vector. By doing this to the formula above, we find:
Since the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:
More conceptually, this rule expresses the fact that a change in the "x""i" direction may change all of "g"1 through "g""k", and any of these changes may affect "f".
In the special case where , so that "f" is a real-valued function, then this formula simplifies even further:
This can be rewritten as a dot product. Recalling that , the partial derivative is also a vector, and the chain rule says that:
Example.
Given where and , determine the value of and using the chain rule.
and
Higher derivatives of multivariable functions.
Faà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case. If is a function of as above, then the second derivative of is:
Further generalizations.
All extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.
One generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of is the composite of the derivative of "f" and the derivative of "g". This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.
The chain rule is also valid for Fréchet derivatives in Banach spaces. The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.
In abstract algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings determines a morphism of Kähler differentials which sends an element "dr" to "d"("f"("r")), the exterior differential of "f"("r"). The formula holds in this context as well.
The common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a "C""r"-manifold to a "C""r"−1-manifold (its tangent bundle) and a "C""r"-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives. This is exactly the formula .
There are also chain rules in stochastic calculus. One of these, Itō's lemma, expresses the composite of an Itō process (or more generally a semimartingale) "dX""t" with a twice-differentiable function "f". In Itō's lemma, the derivative of the composite function depends not only on "dX""t" and the derivative of "f" but also on the second derivative of "f". The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types.

</doc>
<doc id="6115" url="https://en.wikipedia.org/wiki?curid=6115" title="P versus NP problem">
P versus NP problem

The P versus NP problem is a major unsolved problem in computer science. Informally speaking, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer. 
It was essentially first mentioned in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether a certain NP-complete problem could be solved in quadratic or linear time. The precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" and is considered by many to be the most important open problem in the field. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.
The informal term "quickly", used above, means the existence of an algorithm for the task that runs in polynomial time. The general class of questions for which some algorithm can provide an answer in polynomial time is called "class P" or just "P". For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. The class of questions for which an answer can be "verified" in polynomial time is called NP, which stands for "nondeterministic polynomial time."
Consider the subset sum problem, an example of a problem that is easy to verify, but whose answer may be difficult to compute. Given a set of integers, does some nonempty subset of them sum to 0? For instance, does a subset of the set add up to 0? The answer "yes, because the subset adds up to zero" can be quickly verified with three additions. There is no known algorithm to find such a subset in polynomial time (there is one, however, in exponential time, which consists of 2"n"-n-1 tries), but such an algorithm exists if P = NP; hence this problem is in NP (quickly checkable) but not necessarily in P (quickly solvable).
An answer to the P = NP question would determine whether problems that can be verified in polynomial time, like the subset-sum problem, can also be solved in polynomial time. If it turned out that P ≠ NP, it would mean that there are problems in NP (such as NP-complete problems) that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time.
Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields.
Context.
The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).
In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is "deterministic" (given the computer's present state and any inputs, there is only one possible action that the computer might take) and "sequential" (it performs actions one after the other).
In this theory, the class P consists of all those "decision problems" (defined below) that can be solved on a deterministic sequential machine in an amount of time that is polynomial in the size of the input; the class NP consists of all those decision problems whose positive solutions can be verified in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P ⊆ NP. Arguably the biggest open question in theoretical computer science concerns the relationship between those two classes:
In a 2002 poll of 100 researchers, 61 believed the answer to be no, 9 believed the answer is yes, and 22 were unsure; 8 believed the question may be independent of the currently accepted axioms and therefore impossible to prove or disprove.
In 2012, 10 years later, the same poll was repeated. The number of researchers who answered was 151: 126 (83%) believed the answer to be no, 12 (9%) believed the answer is yes, 5 (3%) believed the question may be independent of the currently accepted axioms and therefore impossible to prove or disprove, 8 (5%) said either don't know or don't care or don't want the answer to be yes nor the problem to be resolved.
NP-complete.
To attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are a set of problems to each of which any other NP-problem can be reduced in polynomial time, and whose solution may still be verified in polynomial time. That is, any NP problem can be transformed into any of the NP-complete problems. Informally, an NP-complete problem is an NP problem that is at least as "tough" as any other problem in NP.
NP-hard problems are those at least as hard as NP problems, i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP, i.e., they need not have solutions verifiable in polynomial time.
For instance, the Boolean satisfiability problem is NP-complete by the Cook–Levin theorem, so "any" instance of "any" problem in NP can be transformed mechanically into an instance of the Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many such NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems have been shown to be NP-complete, and no fast algorithm for any of them is known.
Based on the definition alone it is not obvious that NP-complete problems exist; however, a trivial and contrived NP-complete problem can be formulated as follows: given a description of a Turing machine M guaranteed to halt in polynomial time, does there exist a polynomial-size input that M will accept? It is in NP because (given an input) it is simple to check whether M accepts the input by simulating M; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine M that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists.
The first natural problem proven to be NP-complete was the Boolean satisfiability problem. As noted above, this is the Cook–Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the subset sum problem discussed earlier. Thus, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense "the same problem".
Harder problems.
Although it is unknown whether P = NP, problems outside of P are known. A number of succinct problems (problems that operate not on normal input, but on a computational description of the input) are known to be EXPTIME-complete. Because it can be shown that P ≠ EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess (on an "N" × "N" board) and some other board games.
The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements has a runtime of at least formula_1 for some constant "c". Here, "n" is the length of the Presburger statement. Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all.
Problems in NP not known to be in P or NP-complete.
It was shown by Ladner that if P ≠ NP then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.
The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to Laszlo Babai and Eugene Luks has run time 2O(√"n"log("n")) for graphs with "n" vertices.
The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than "k". No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP). The best known algorithm for integer factorization is the general number field sieve, which takes expected time
to factor an "n"-bit integer. However, the best known quantum algorithm for this problem, Shor's algorithm, does run in polynomial time. Unfortunately, this fact doesn't say much about where the problem lies with respect to non-quantum complexity classes.
Does P mean "easy"?
All of the above discussion has assumed that P means "easy" and "not in P" means "hard", an assumption known as "Cobham's thesis". It is a common and reasonably accurate assumption in complexity theory; however, it has some caveats.
First, it is not always true in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents thus rendering it impractical. On the other hand, even if a problem is shown to be NP-complete, and even if P ≠ NP, there may still be effective approaches to tackling the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity it runs on par with the best known polynomial-time algorithms.
Second, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.
Reasons to believe P ≠ NP.
According to polls, many computer scientists believe that P ≠ NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH.
It is also intuitively argued that the existence of problems that are hard to solve but for which the solutions are easy to verify matches real-world experience.
On the other hand, some researchers believe that there is overconfidence in believing P ≠ NP and that researchers should explore proofs of P = NP as well. For example, in 2002 these statements were made:
Consequences of solution.
One of the reasons the problem attracts so much attention is the consequences of the answer. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.
P = NP.
A proof that P = NP could have stunning practical consequences, if the proof leads to efficient methods for solving some of the important problems in NP. It is also possible that a proof would not lead directly to efficient methods, perhaps if the proof is non-constructive, or the size of the bounding polynomial is too big to be efficient in practice. The consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields.
Cryptography, for example, relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including:
These would need to be modified or replaced by information-theoretically secure solutions not inherently based on P-NP equivalence.
On the other hand, there are enormous positive consequences that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as some types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; if these problems were efficiently solvable it could spur considerable advances in life sciences and biotechnology.
But such changes may pale in significance compared to the revolution an efficient method for solving NP-complete problems would cause in mathematics itself. Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics:
Similarly, Stephen Cook says
Research mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, Fermat's Last Theorem took over three centuries to prove. A method that is guaranteed to find proofs to theorems, should one exist of a "reasonable" size, would essentially end this struggle.
Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof:
P ≠ NP.
A proof that showed that P ≠ NP would lack the practical computational benefits of a proof that P = NP, but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. It would allow one to show in a formal way that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P ≠ NP, much of this focusing of research has already taken place.
Also P ≠ NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical "worlds" that could result from different possible resolutions to the average-case complexity question. These range from "Algorithmica", where P = NP and problems like SAT can be solved efficiently in all instances, to "Cryptomania", where P ≠ NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The "world" where P ≠ NP but all problems in NP are tractable in the average case is called "Heuristica" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds.
Results about difficulty of proof.
Although the P = NP? problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are not powerful enough to answer the question, thus suggesting that novel technical approaches are required.
As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, each of which is known to be insufficient to prove that P ≠ NP:
These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results.
These barriers have also led some computer scientists to suggest that the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). The interpretation of an independence result could be that either no polynomial-time algorithm exists for any NP-complete problem, and such a proof cannot be constructed in (e.g.) ZFC, or that polynomial-time algorithms for NP-complete problems may exist, but it's impossible to prove in ZFC that such algorithms are correct. However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the Peano axioms (PA) for integer arithmetic, then there would necessarily exist nearly-polynomial-time algorithms for every problem in NP. Therefore, if one believes (as most complexity theorists do) that not all problems in NP have efficient algorithms, it would follow that proofs of independence using those techniques cannot be possible. Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in NP.
Claimed solutions.
While the P versus NP problem is generally considered unsolved, many amateur and some professional researchers have claimed solutions. Gerhard J. Woeginger has a comprehensive list. An August 2010 claim of proof that P ≠ NP, by Vinay Deolalikar, a researcher at HP Labs, Palo Alto, received heavy Internet and press attention after being initially described as " to be a relatively serious attempt" by two leading specialists. The proof has been reviewed publicly by academics, and Neil Immerman, an expert in the field, had pointed out two possibly fatal errors in the proof.
In September 2010, Deolalikar was reported to be working on a detailed expansion of his attempted proof. However, opinions expressed by several notable theoretical computer scientists indicate that the attempted proof is neither correct nor a significant advancement in the understanding of the problem. This assessment prompted a May 2013 "The New Yorker" article to call the proof attempt "thoroughly discredited."
Logical characterizations.
The P = NP problem can be restated in terms of expressible certain classes of logical statements, as a result of work in descriptive complexity.
Consider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P can be expressed in first-order logic with the addition of a suitable least fixed-point combinator. Effectively, this, in combination with the order, allows the definition of recursive functions. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P.
Similarly, NP is the set of languages expressible in existential second-order logic—that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question "is P a proper subset of NP" can be reformulated as "is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?". The word "existential" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH).
Polynomial-time algorithms.
No algorithm for any NP-complete problem is known to run in polynomial time. However, there are algorithms for NP-complete problems with the property that if P = NP, then the algorithm runs in polynomial time (although with enormous constants, making the algorithm impractical). The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time if and only if P = NP:
If, and only if, P = NP, then this is a polynomial-time algorithm accepting an NP-complete language. "Accepting" means it gives "yes" answers in polynomial time, but is allowed to run forever when the answer is "no" (also known as a "semi-algorithm").
This algorithm is enormously impractical, even if P = NP. If the shortest program that can solve SUBSET-SUM in polynomial time is "b" bits long, the above algorithm will try at least 2"b"−1 other programs first.
Formal definitions.
P and NP.
Conceptually speaking, a "decision problem" is a problem that takes as input some string "w" over an alphabet Σ, and outputs "yes" or "no". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that can produce the correct answer for any input string of length "n" in at most "cnk" steps, where "k" and "c" are constants independent of the input string, then we say that the problem can be solved in "polynomial time" and we place it in the class P. Formally, P is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. That is,
where
and a deterministic polynomial-time Turing machine is a deterministic Turing machine "M" that satisfies the following two conditions:
NP can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach to define NP is to use the concept of "certificate" and "verifier". Formally, NP is defined as the set of languages over a finite alphabet that have a verifier that runs in polynomial time, where the notion of "verifier" is defined as follows.
Let "L" be a language over a finite alphabet, Σ.
"L" ∈ NP if, and only if, there exists a binary relation formula_9 and a positive integer "k" such that the following two conditions are satisfied:
A Turing machine that decides "LR" is called a "verifier" for "L" and a "y" such that ("x", "y") ∈ "R" is called a "certificate of membership" of "x" in "L".
In general, a verifier does not have to be polynomial-time. However, for "L" to be in NP, there must be a verifier that runs in polynomial time.
Example.
Let
Clearly, the question of whether a given "x" is a composite is equivalent to the question of whether "x" is a member of COMPOSITE. It can be shown that COMPOSITE ∈ NP by verifying that it satisfies the above definition (if we identify natural numbers with their binary representations).
COMPOSITE also happens to be in P.
NP-completeness.
There are many equivalent ways of describing NP-completeness.
Let "L" be a language over a finite alphabet Σ.
"L" is NP-complete if, and only if, the following two conditions are satisfied:

</doc>
<doc id="6117" url="https://en.wikipedia.org/wiki?curid=6117" title="Charles Sanders Peirce">
Charles Sanders Peirce

Charles Sanders Peirce (, like "purse",
September 10, 1839 – April 19, 1914) was an American philosopher, logician, mathematician, and scientist who is sometimes known as "the father of pragmatism". He was educated as a chemist and employed as a scientist for 30 years. Today he is appreciated largely for his contributions to logic, mathematics, philosophy, scientific methodology, and semiotics, and for his founding of pragmatism.
An innovator in mathematics, statistics, philosophy, research methodology, and various sciences, Peirce considered himself, first and foremost, a logician. He made major contributions to logic, but logic for him encompassed much of that which is now called epistemology and philosophy of science. He saw logic as the formal branch of semiotics, of which he is a founder, and which foreshadowed the debate among logical positivists and proponents of philosophy of language that dominated 20th century Western philosophy; additionally, he defined the concept of abductive reasoning, as well as rigorously formulated mathematical induction and deductive reasoning. As early as 1886 he saw that logical operations could be carried out by electrical switching circuits; the same idea was used decades later to produce digital computers.
In 1934, the philosopher Paul Weiss called Peirce "the most original and versatile of American philosophers and America's greatest logician". "Webster's Biographical Dictionary" said in 1943 that Peirce was "now regarded as the most original thinker and greatest logician of his time." Keith Devlin similarly referred to Peirce as one of the greatest philosophers ever.
Life.
Peirce was born at 3 Phillips Place in Cambridge, Massachusetts. He was the son of Sarah Hunt Mills and Benjamin Peirce, himself a professor of astronomy and mathematics at Harvard University and perhaps the first serious research mathematician in America. At age 12, Charles read his older brother's copy of Richard Whately's "Elements of Logic", then the leading English-language text on the subject. So began his lifelong fascination with logic and reasoning. He went on to earn the A.B. and A.M. (1862) from Harvard; in 1863 the Lawrence Scientific School awarded him a B.Sc. that was Harvard's first "summa cum laude" chemistry degree; and otherwise his academic record was undistinguished. At Harvard, he began lifelong friendships with Francis Ellingwood Abbot, Chauncey Wright, and William James. One of his Harvard instructors, Charles William Eliot, formed an unfavorable opinion of Peirce. This opinion proved fateful, because Eliot, while President of Harvard 1869–1909—a period encompassing nearly all of Peirce's working life—repeatedly vetoed Harvard's employing Peirce in any capacity.
Peirce suffered from his late teens onward from a nervous condition then known as "facial neuralgia", which would today be diagnosed as trigeminal neuralgia. Brent says that when in the throes of its pain "he was, at first, almost stupefied, and then aloof, cold, depressed, extremely suspicious, impatient of the slightest crossing, and subject to violent outbursts of temper". Its consequences may have led to the social isolation which made his life's later years so tragic.
Early employment.
Between 1859 and 1891, Peirce was intermittently employed in various scientific capacities by the United States Coast Survey and its successor, the United States Coast and Geodetic Survey, where he enjoyed his highly influential father's protection until the latter's death in 1880. That employment exempted Peirce from having to take part in the Civil War; it would have been very awkward for him to do so, as the Boston Brahmin Peirces sympathized with the Confederacy. At the Survey, he worked mainly in geodesy and gravimetry, refining the use of pendulums to determine small local variations in the Earth's gravity. He was elected a resident fellow of the American Academy of Arts and Sciences in January 1867. The Survey sent him to Europe five times, first in 1871 as part of a group sent to observe a solar eclipse; there, he sought out Augustus De Morgan, William Stanley Jevons, and William Kingdon Clifford, British mathematicians and logicians whose turn of mind resembled his own. From 1869 to 1872, he was employed as an Assistant in Harvard's astronomical observatory, doing important work on determining the brightness of stars and the shape of the Milky Way. On April 20, 1877 he was elected a member of the National Academy of Sciences. Also in 1877, he proposed measuring the meter as so many wavelengths of light of a certain frequency, the kind of definition employed from 1960 to 1983.
During the 1880s, Peirce's indifference to bureaucratic detail waxed while his Survey work's quality and timeliness waned. Peirce took years to write reports that he should have completed in months. Meanwhile, he wrote entries, ultimately thousands during 1883–1909, on philosophy, logic, science, and other subjects for the encyclopedic "Century Dictionary". In 1885, an investigation by the Allison Commission exonerated Peirce, but led to the dismissal of Superintendent Julius Hilgard and several other Coast Survey employees for misuse of public funds. In 1891, Peirce resigned from the Coast Survey at Superintendent Thomas Corwin Mendenhall's request. He never again held regular employment.
Johns Hopkins University.
In 1879, Peirce was appointed Lecturer in logic at the new Johns Hopkins University, which had strong departments in a number of areas that interested him, such as philosophy (Royce and Dewey completed their PhDs at Hopkins), psychology (taught by G. Stanley Hall and studied by Joseph Jastrow, who coauthored a landmark empirical study with Peirce), and mathematics (taught by J. J. Sylvester, who came to admire Peirce's work on mathematics and logic). 1883 saw publication of his "Studies in Logic by Members of the Johns Hopkins University" containing works by himself and Allan Marquand, Christine Ladd, Benjamin Ives Gilman, and Oscar Howard Mitchell, several of whom were his graduate students. Peirce's nontenured position at Hopkins was the only academic appointment he ever held.
Brent documents something Peirce never suspected, namely that his efforts to obtain academic employment, grants, and scientific respectability were repeatedly frustrated by the covert opposition of a major Canadian-American scientist of the day, Simon Newcomb. Peirce's efforts may also have been hampered by a difficult personality; Brent conjectures as to further psychological difficulty. Conversely, Keith Devlin believes that Peirce's work was too far ahead of his time to be appreciated by the academic establishment of the day and that this played a large role in Peirce's inability to obtain a tenured position.
Peirce's personal life worked against his professional success. After his first wife, Harriet Melusina Fay ("Zina"), left him in 1875, Peirce, while still legally married, became involved with Juliette, whose name, given variously as Froissy and Pourtalai and nationality (she spoke French) remain uncertain. When his divorce from Zina became final in 1883, he married Juliette. That year, Newcomb pointed out to a Johns Hopkins trustee that Peirce, while a Hopkins employee, had lived and traveled with a woman to whom he was not married; the ensuing scandal led to his dismissal in January 1884. Over the years Peirce sought academic employment at various universities without success. He had no children by either marriage.
Poverty.
In 1887 Peirce spent part of his inheritance from his parents to buy of rural land near Milford, Pennsylvania, which never yielded an economic return. There he had an 1854 farmhouse remodeled to his design. The Peirces named the property "Arisbe". There they lived with few interruptions for the rest of their lives, Charles writing prolifically, much of it unpublished to this day (see Works). Living beyond their means soon led to grave financial and legal difficulties. He spent much of his last two decades unable to afford heat in winter and subsisting on old bread donated by the local baker. Unable to afford new stationery, he wrote on the verso side of old manuscripts. An outstanding warrant for assault and unpaid debts led to his being a fugitive in New York City for a while. Several people, including his brother James Mills Peirce and his neighbors, relatives of Gifford Pinchot, settled his debts and paid his property taxes and mortgage.
Peirce did some scientific and engineering consulting and wrote much for meager pay, mainly encyclopedic dictionary entries, and reviews for "The Nation" (with whose editor, Wendell Phillips Garrison, he became friendly). He did translations for the Smithsonian Institution, at its director Samuel Langley's instigation. Peirce also did substantial mathematical calculations for Langley's research on powered flight. Hoping to make money, Peirce tried inventing. He began but did not complete a number of books. In 1888, President Grover Cleveland appointed him to the Assay Commission.
From 1890 on, he had a friend and admirer in Judge Francis C. Russell of Chicago, who introduced Peirce to editor Paul Carus and owner Edward C. Hegeler of the pioneering American philosophy journal "The Monist", which eventually published at least 14 articles by Peirce. He wrote many texts in James Mark Baldwin's "Dictionary of Philosophy and Psychology" (1901–5); half of those credited to him appear to have been written actually by Christine Ladd-Franklin under his supervision. He applied in 1902 to the newly formed Carnegie Institution for a grant to write a systematic book of his life's work. The application was doomed; his nemesis Newcomb served on the Institution's executive committee, and its President had been the President of Johns Hopkins at the time of Peirce's dismissal.
The one who did the most to help Peirce in these desperate times was his old friend William James, dedicating his "Will to Believe" (1897) to Peirce, and arranging for Peirce to be paid to give two series of lectures at or near Harvard (1898 and 1903). Most important, each year from 1907 until James's death in 1910, James wrote to his friends in the Boston intelligentsia to request financial aid for Peirce; the fund continued even after James died. Peirce reciprocated by designating James's eldest son as his heir should Juliette predecease him. It has been believed that this was also why Peirce used "Santiago" ("St. James" in English) as a middle name, but he appeared in print as early as 1890 as Charles Santiago Peirce. (See Charles Santiago Sanders Peirce for discussion and references).
Peirce died destitute in Milford, Pennsylvania, twenty years before his widow.
Slavery, the Civil War and racism.
Peirce grew up in a home where the supremacy of the white Anglo-Saxon male was taken for granted, Irish immigrants were considered inferior and Negro slavery was considered natural.
Until the outbreak of the Civil War his father described himself as a secessionist, but after the outbreak of the war, this stopped and he became a Union partisan, supporting with donations the Sanitary Commission, the leading Northern war charity. No members of the Peirce family volunteered or enlisted.
Peirce shared his father's views and liked to use the syllogism
to illustrate the unreliability of traditional forms of logic. "See: Peirce's law#Other proofs of Peirce's law"
Reception.
Bertrand Russell (1959) wrote, "Beyond doubt [...] he was one of the most original minds of the later nineteenth century, and certainly the greatest American thinker ever." (Russell and Whitehead's "Principia Mathematica", published from 1910 to 1913, does not mention Peirce; Peirce's work was not widely known until later.) A. N. Whitehead, while reading some of Peirce's unpublished manuscripts soon after arriving at Harvard in 1924, was struck by how Peirce had anticipated his own "process" thinking. (On Peirce and process metaphysics, see Lowe 1964.) Karl Popper viewed Peirce as "one of the greatest philosophers of all times". Yet Peirce's achievements were not immediately recognized. His imposing contemporaries William James and Josiah Royce admired him, and Cassius Jackson Keyser at Columbia and C. K. Ogden wrote about Peirce with respect, but to no immediate effect.
The first scholar to give Peirce his considered professional attention was Royce's student Morris Raphael Cohen, the editor of an anthology of Peirce's writings titled "Chance, Love, and Logic" (1923) and the author of the first bibliography of Peirce's scattered writings. John Dewey studied under Peirce at Johns Hopkins and, from 1916 onwards, Dewey's writings repeatedly mention Peirce with deference. His 1938 "Logic: The Theory of Inquiry" is much influenced by Peirce. The publication of the first six volumes of the "Collected Papers" (1931–35), the most important event to date in Peirce studies and one that Cohen made possible by raising the needed funds, did not prompt an outpouring of secondary studies. The editors of those volumes, Charles Hartshorne and Paul Weiss, did not become Peirce specialists. Early landmarks of the secondary literature include the monographs by Buchler (1939), Feibleman (1946), and Goudge (1950), the 1941 Ph.D. thesis by Arthur W. Burks (who went on to edit volumes 7 and 8), and the studies edited by Wiener and Young (1952). The Charles S. Peirce Society was founded in 1946. Its "Transactions", an academic quarterly specializing in Peirce, pragmatism, and American philosophy, has appeared since 1965.
In 1949, while doing unrelated archival work, the historian of mathematics Carolyn Eisele (1902–2000) chanced on an autograph letter by Peirce. So began her 40 years of research on Peirce the mathematician and scientist, culminating in Eisele (1976, 1979, 1985). Beginning around 1960, the philosopher and historian of ideas Max Fisch (1900–1995) emerged as an authority on Peirce; Fisch (1986) includes many of his relevant articles, including a wide-ranging survey (Fisch 1986: 422–48) of the impact of Peirce's thought through 1983.
Peirce has gained a significant international following, marked by university research centers devoted to Peirce studies and pragmatism in Brazil (CeneP/CIEP), Finland (HPRC, including ), Germany (Wirth's group, Hoffman's and Otte's group, and Deuser's and Härle's group), France (L'I.R.S.C.E.), Spain (GEP), and Italy (CSP). His writings have been translated into several languages, including German, French, Finnish, Spanish, and Swedish. Since 1950, there have been French, Italian, Spanish, British, and Brazilian Peirceans of note. For many years, the North American philosophy department most devoted to Peirce was the University of Toronto's, thanks in good part to the leadership of Thomas Goudge and David Savan. In recent years, U.S. Peirce scholars have clustered at Indiana University - Purdue University Indianapolis, home of the Peirce Edition Project (PEP), and the Pennsylvania State University.
In recent years, Peirce's trichotomy of signs is exploited by a growing number of practitioners for marketing and design tasks.
Works.
Peirce's reputation rests largely on a number of academic papers published in American scientific and scholarly journals such as "Proceedings of the American Academy of Arts and Sciences", the "Journal of Speculative Philosophy", "The Monist", "Popular Science Monthly", the "American Journal of Mathematics", "Memoirs of the National Academy of Sciences", "The Nation", and others. See Articles by Peirce, published in his lifetime for an extensive list with links to them online. The only full-length book (neither extract nor pamphlet) that Peirce authored and saw published in his lifetime was "Photometric Researches" (1878), a 181-page monograph on the applications of spectrographic methods to astronomy. While at Johns Hopkins, he edited "Studies in Logic" (1883), containing chapters by himself and his graduate students. Besides lectures during his years (1879–1884) as Lecturer in Logic at Johns Hopkins, he gave at least nine series of lectures, many now published; see Lectures by Peirce.
Harvard University obtained from Peirce's widow soon after his death the papers found in his study, but did not microfilm them until 1964. Only after Richard Robin (1967) catalogued this "Nachlass" did it become clear that Peirce had left approximately 1650 unpublished manuscripts, totaling over 100,000 pages, mostly still unpublished except on microfilm. On the vicissitudes of Peirce's papers, see Houser (1989). Reportedly the papers remain in unsatisfactory condition.
The first published anthology of Peirce's articles was the one-volume "Chance, Love and Logic: Philosophical Essays", edited by Morris Raphael Cohen, 1923, still in print. Other one-volume anthologies were published in 1940, 1957, 1958, 1972, 1994, and 2009, most still in print. The main posthumous editions of Peirce's works in their long trek to light, often multi-volume, and some still in print, have included:
1931–58: "Collected Papers of Charles Sanders Peirce" (CP), 8 volumes, includes many published works, along with a selection of previously unpublished work and a smattering of his correspondence. This long-time standard edition drawn from Peirce's work from the 1860s to 1913 remains the most comprehensive survey of his prolific output from 1893 to 1913. It is organized thematically, but texts (including lecture series) are often split up across volumes, while texts from various stages in Peirce's development are often combined, requiring frequent visits to editors' notes. Edited (1–6) by Charles Hartshorne and Paul Weiss and (7–8) by Arthur Burks, in print and online.
1975–87: "Charles Sanders Peirce: Contributions to" The Nation, 4 volumes, includes Peirce's more than 300 reviews and articles published 1869–1908 in "The Nation". Edited by Kenneth Laine Ketner and James Edward Cook, online.
1976: "The New Elements of Mathematics by Charles S. Peirce", 4 volumes in 5, included many previously unpublished Peirce manuscripts on mathematical subjects, along with Peirce's important published mathematical articles. Edited by Carolyn Eisele, back in print.
1977: "Semiotic and Significs: The Correspondence between C. S. Peirce and Victoria Lady Welby" (2nd edition 2001), included Peirce's entire correspondence (1903–1912) with Victoria, Lady Welby. Peirce's other published correspondence is largely limited to the 14 letters included in volume 8 of the "Collected Papers", and the 20-odd pre-1890 items included so far in the "Writings". Edited by Charles S. Hardwick with James Cook, out of print.
1982–now: "Writings of Charles S. Peirce, A Chronological Edition" (W), Volumes 1–6 & 8, of a projected 30. The limited coverage, and defective editing and organization, of the "Collected Papers" led Max Fisch and others in the 1970s to found the Peirce Edition Project (PEP), whose mission is to prepare a more complete critical chronological edition. Only seven volumes have appeared to date, but they cover the period from 1859–1892, when Peirce carried out much of his best-known work. W 8 was published in November 2010; and work continues on W 7, 9, and 11. In print and online.
1985: "Historical Perspectives on Peirce's Logic of Science: A History of Science", 2 volumes. Auspitz has said, "The extent of Peirce's immersion in the science of his day is evident in his reviews in the "Nation" [...] and in his papers, grant applications, and publishers' prospectuses in the history and practice of science", referring latterly to "Historical Perspectives". Edited by Carolyn Eisele, back in print.
1992: "Reasoning and the Logic of Things" collects in one place Peirce's 1898 series of lectures invited by William James. Edited by Kenneth Laine Ketner, with commentary by Hilary Putnam, in print.
1992–98: "The Essential Peirce" (EP), 2 volumes, is an important recent sampler of Peirce's philosophical writings. Edited (1) by Nathan Hauser and Christian Kloesel and (2) by PEP editors, in print.
1997: "Pragmatism as a Principle and Method of Right Thinking" collects Peirce's 1903 Harvard "Lectures on Pragmatism" in a study edition, including drafts, of Peirce's lecture manuscripts, which had been previously published in abridged form; the lectures now also appear in EP 2. Edited by Patricia Ann Turisi, in print.
2010: "Philosophy of Mathematics: Selected Writings" collects important writings by Peirce on the subject, many not previously in print. Edited by Matthew E. Moore, in print.
Mathematics.
Peirce's most important work in pure mathematics was in logical and foundational areas. He also worked on linear algebra, matrices, various geometries, topology and Listing numbers, Bell numbers, graphs, the four-color problem, and the nature of continuity.
He worked on applied mathematics in economics, engineering, and map projections (such as the Peirce quincuncial projection), and was especially active in probability and statistics.
Peirce made a number of striking discoveries in formal logic and foundational mathematics, nearly all of which came to be appreciated only long after he died:
In 1860 he suggested a cardinal arithmetic for infinite numbers, years before any work by Georg Cantor (who completed his dissertation in 1867) and without access to Bernard Bolzano's 1851 (posthumous) "Paradoxien des Unendlichen".
↓ The Peirce arrow, <br>symbol for "(neither)...nor...", also called the Quine dagger.
In 1880–81 he showed how Boolean algebra could be done via a repeated sufficient single binary operation (logical NOR), anticipating Henry M. Sheffer by 33 years. (See also De Morgan's Laws).
In 1881 he set out the axiomatization of natural number arithmetic, a few years before Richard Dedekind and Giuseppe Peano. In the same paper Peirce gave, years before Dedekind, the first purely cardinal definition of a finite set in the sense now known as "Dedekind-finite", and implied by the same stroke an important formal definition of an infinite set (Dedekind-infinite), as a set that can be put into a one-to-one correspondence with one of its proper subsets.
In 1885 he distinguished between first-order and second-order quantification. In the same paper he set out what can be read as the first (primitive) axiomatic set theory, anticipating Zermelo by about two decades (Brady 2000, pp. 132–3).
In 1886 he saw that Boolean calculations could be carried out via electrical switches, anticipating Claude Shannon by more than 50 years. 
By the later 1890s he was devising existential graphs, a diagrammatic notation for the predicate calculus. Based on them are John F. Sowa's conceptual graphs and Sun-Joo Shin's diagrammatic reasoning.
Peirce wrote drafts for an introductory textbook, with the working title "The New Elements of Mathematics", that presented mathematics from an original standpoint. Those drafts and many other of his previously unpublished mathematical manuscripts finally appeared in "The New Elements of Mathematics by Charles S. Peirce" (1976), edited by mathematician Carolyn Eisele.
Peirce agreed with Auguste Comte in regarding mathematics as more basic than philosophy and the special sciences (of nature and mind). Peirce classified mathematics into three subareas: (1) mathematics of logic, (2) discrete series, and (3) pseudo-continua (as he called them, including the real numbers) and continua. Influenced by his father Benjamin, Peirce argued that mathematics studies purely hypothetical objects and is not just the science of quantity but is more broadly the science which draws necessary conclusions; that mathematics aids logic, not vice versa; and that logic itself is part of philosophy and is the science "about" drawing conclusions necessary and otherwise.
Mathematics of logic.
Mathematical logic and foundations, some noted articles
Relational logic gained applications. In mathematics, it influenced the abstract analysis of E. H. Moore and the lattice theory of Garrett Birkhoff. In computer science, the relational model for databases was developed with Peircean ideas in work of Edgar F. Codd, who was a doctoral student of Arthur W. Burks, a Peirce scholar. In economics, relational logic was used by Frank P. Ramsey, John von Neumann, and Paul Samuelson to study preferences and utility and by Kenneth J. Arrow in "Social Choice and Individual Values", following Arrow's association with Tarski at City College of New York.
On Peirce and his contemporaries Ernst Schröder and Gottlob Frege, Hilary Putnam (1982) documented that Frege's work on the logic of quantifiers had little influence on his contemporaries, although it was published four years before the work of Peirce and his student Oscar Howard Mitchell. Putnam found that mathematicians and logicians learned about the logic of quantifiers through the independent work of Peirce and Mitchell, particularly through Peirce's "On the Algebra of Logic: A Contribution to the Philosophy of Notation" (1885), published in the premier American mathematical journal of the day, and cited by Peano and Schröder, among others, who ignored Frege. They also adopted and modified Peirce's notations, typographical variants of those now used. Peirce apparently was ignorant of Frege's work, despite their overlapping achievements in logic, philosophy of language, and the foundations of mathematics.
Peirce's work on formal logic had admirers besides Ernst Schröder:
A philosophy of logic, grounded in his categories and semiotic, can be extracted from Peirce's writings and, along with Peirce's logical work more generally, is exposited and defended in Hilary Putnam (1982); the Introduction in Nathan Houser "et al." (1997); and Randall Dipert's chapter in Cheryl Misak (2004).
Continua.
Continuity and synechism are central in Peirce's philosophy: "I did not at first suppose that it was, as I gradually came to find it, the master-Key of philosophy".
From a mathematical point of view, he embraced infinitesimals and worked long on the mathematics of continua. He long held that the real numbers constitute a pseudo-continuum; that a true continuum is the real subject matter of "analysis situs" (topology); and that a true continuum of instants exceeds—and within any lapse of time has room for—any Aleph number (any infinite "multitude" as he called it) of instants.
In 1908 Peirce wrote that he found that a true continuum might have or lack such room. Jérôme Havenel (2008): "It is on May 26, 1908, that Peirce finally gave up his idea that in every continuum there is room for whatever collection of any multitude. From now on, there are different kinds of continua, which have different properties."
Probability and statistics.
Peirce held that science achieves statistical probabilities, not certainties, and that spontaneity (absolute chance) is real (see Tychism on his view). Most of his statistical writings promote the frequency interpretation of probability (objective ratios of cases), and many of his writings express skepticism about (and criticize the use of) probability when such models are not based on objective randomization. Though Peirce was largely a frequentist, his possible world semantics introduced the "propensity" theory of probability before Karl Popper. Peirce (sometimes with Joseph Jastrow) investigated the probability judgments of experimental subjects, "perhaps the very first" elicitation and estimation of subjective probabilities in experimental psychology and (what came to be called) Bayesian statistics.
Peirce was one of the founders of statistics. He formulated modern statistics in "Illustrations of the Logic of Science" (1877–8) and "A Theory of Probable Inference" (1883). With a repeated measures design, Charles Sanders Peirce and Joseph Jastrow introduced blinded, controlled randomized experiments in 1884 (Hacking 1990:205) (before Ronald A. Fisher). He invented optimal design for experiments on gravity, in which he "corrected the means". He used correlation and smoothing. Peirce extended the work on outliers by Benjamin Peirce, his father. He introduced terms "confidence" and "likelihood" (before Jerzy Neyman and Fisher). (See Stephen Stigler's historical books and Ian Hacking 1990).
Philosophy.
Peirce was a working scientist for 30 years, and arguably was a professional philosopher only during the five years he lectured at Johns Hopkins. He learned philosophy mainly by reading, each day, a few pages of Kant's "Critique of Pure Reason", in the original German, while a Harvard undergraduate. His writings bear on a wide array of disciplines, including mathematics, logic, philosophy, statistics, astronomy, metrology, geodesy, experimental psychology, economics, linguistics, and the history and philosophy of science. This work has enjoyed renewed interest and approval, a revival inspired not only by his anticipations of recent scientific developments but also by his demonstration of how philosophy can be applied effectively to human problems.
Peirce's philosophy includes (see below in related sections) a pervasive three-category system, belief that truth is immutable and is both independent from actual opinion (fallibilism) and discoverable (no radical skepticism), logic as formal semiotic on signs, on arguments, and on inquiry's ways—including philosophical pragmatism (which he founded), critical common-sensism, and scientific method—and, in metaphysics: Scholastic realism, e.g. John Duns Scotus, belief in God, freedom, and at least an attenuated immortality, objective idealism, and belief in the reality of continuity and of absolute chance, mechanical necessity, and creative love. In his work, fallibilism and pragmatism may seem to work somewhat like skepticism and positivism, respectively, in others' work. However, for Peirce, fallibilism is balanced by an anti-skepticism and is a basis for belief in the reality of absolute chance and of continuity, and pragmatism commits one to anti-nominalist belief in the reality of the general (CP 5.453–7).
For Peirce, First Philosophy, which he also called cenoscopy, is less basic than mathematics and more basic than the special sciences (of nature and mind). It studies positive phenomena in general, phenomena available to any person at any waking moment, and does not settle questions by resorting to special experiences. He divided such philosophy into (1) phenomenology (which he also called phaneroscopy or categorics), (2) normative sciences (esthetics, ethics, and logic), and (3) metaphysics; his views on them are discussed in order below.
Theory of categories.
On May 14, 1867, the 27-year-old Peirce presented a paper entitled "On a New List of Categories" to the American Academy of Arts and Sciences, which published it the following year. The paper outlined a theory of predication, involving three universal categories that Peirce developed in response to reading Aristotle, Kant, and Hegel, categories that Peirce applied throughout his work for the rest of his life. Peirce scholars generally regard the "New List" as foundational or breaking the ground for Peirce's "architectonic", his blueprint for a pragmatic philosophy. In the categories one will discern, concentrated, the pattern that one finds formed by the three grades of clearness in "" (1878 paper foundational to pragmatism), and in numerous other trichotomies in his work.
"On a New List of Categories" is cast as a Kantian deduction; it is short but dense and difficult to summarize. The following table is compiled from that and later works. In 1893, Peirce restated most of it for a less advanced audience. 
Aesthetics and ethics.
Peirce did not write extensively in aesthetics and ethics, but came by 1902 to hold that aesthetics, ethics, and logic, in that order, comprise the normative sciences. He characterized aesthetics as the study of the good (grasped as the admirable), and thus of the ends governing all conduct and thought.
Philosophy: logic, or semiotic.
Logic as philosophical.
Peirce regarded logic "per se" as a division of philosophy, as a normative science based on esthetics and ethics, as more basic than metaphysics, and as "the art of devising methods of research". More generally, as inference, "logic is rooted in the social principle", since inference depends on a standpoint that, in a sense, is unlimited. Peirce called (with no sense of deprecation) "mathematics of logic" much of the kind of thing which, in current research and applications, is called simply "logic". He was productive in both (philosophical) logic and logic's mathematics, which were connected deeply in his work and thought.
Peirce argued that logic is formal semiotic, the formal study of signs in the broadest sense, not only signs that are artificial, linguistic, or symbolic, but also signs that are semblances or are indexical such as reactions. Peirce held that "all this universe is perfused with signs, if it is not composed exclusively of signs", along with their representational and inferential relations. He argued that, since all thought takes time, all thought is in signs and sign processes ("semiosis") such as the inquiry process. He divided logic into: (1) speculative grammar, or stechiology, on how signs can be meaningful and, in relation to that, what kinds of signs there are, how they combine, and how some embody or incorporate others; (2) logical critic, or logic proper, on the modes of inference; and (3) speculative or universal rhetoric, or methodeutic, the philosophical theory of inquiry, including pragmatism.
Presuppositions of logic.
In his "F.R.L." Rule of Logic (1899), Peirce states that the first, and "in one sense, the sole", rule of reason is that, "to learn, one needs to desire to learn" and desire it without resting satisfied with that which one is inclined to think. So, the first rule is, "to wonder". Peirce proceeds to a critical theme in research practices and the shaping of theories:
Do not block the way of inquiry.
Peirce adds, that method and economy are best in research but no outright sin inheres in trying any theory in the sense that the investigation via its trial adoption can proceed unimpeded and undiscouraged, and that "the one unpardonable offence" is a philosophical barricade against truth's advance, an offense to which "metaphysicians in all ages have shown themselves the most addicted". Peirce in many writings holds that logic precedes metaphysics (ontological, religious, and physical).
Peirce goes on to list four common barriers to inquiry: (1) Assertion of absolute certainty; (2) maintaining that something is absolutely unknowable; (3) maintaining that something is absolutely inexplicable because absolutely basic or ultimate; (4) holding that perfect exactitude is possible, especially such as to quite preclude unusual and anomalous phenomena. To refuse absolute theoretical certainty is the heart of "fallibilism", which Peirce unfolds into refusals to set up any of the listed barriers. Peirce elsewhere argues (1897) that logic's presupposition of fallibilism leads at length to the view that chance and continuity are very real (tychism and synechism).
The First Rule of Logic pertains to the mind's presuppositions in undertaking reason and logic, presuppositions, for instance, that truth and the real do not depend on yours or my opinion of them but do depend on representational relation and consist in the destined end in investigation taken far enough (see below). He describes such ideas as, collectively, hopes which, in particular cases, one is unable seriously to doubt.
Four incapacities.
The "Journal of Speculative Philosophy" series (1868–69), including
Peirce argued that those incapacities imply the reality of the general and of the continuous, the validity of the modes of reasoning, and the falsity of philosophical Cartesianism (see below).
Peirce rejected the conception (usually ascribed to Kant) of the unknowable thing-in-itself and later said that to "dismiss make-believes" is a prerequisite for pragmatism.
Logic as formal semiotic.
Peirce sought, through his wide-ranging studies through the decades, formal philosophical ways to articulate thought's processes, and also to explain the workings of science. These inextricably entangled questions of a dynamics of inquiry rooted in nature and nurture led him to develop his semiotic with very broadened conceptions of signs and inference, and, as its culmination, a theory of inquiry for the task of saying 'how science works' and devising research methods. This would be logic by the medieval definition taught for centuries: art of arts, science of sciences, having the way to the principles of all methods. Influences radiate from points on parallel lines of inquiry in Aristotle's work, in such "loci" as: the basic terminology of psychology in "On the Soul"; the founding description of sign relations in "On Interpretation"; and the differentiation of inference into three modes that are commonly translated into English as "abduction", "deduction", and "induction", in the "Prior Analytics", as well as inference by analogy (called "paradeigma" by Aristotle), which Peirce regarded as involving the other three modes.
Peirce began writing on semiotic in the 1860s, around the time when he devised his system of three categories. He called it both "semiotic" and "semeiotic". Both are current in singular and plural. He based it on the conception of a triadic sign relation, and defined "semiosis" as "action, or influence, which is, or involves, a cooperation of "three" subjects, such as a sign, its object, and its interpretant, this tri-relative influence not being in any way resolvable into actions between pairs". As to signs in thought, Peirce emphasized the reverse:
Peirce held that all thought is in signs, issuing in and from interpretation, where 'sign' is the word for the broadest variety of conceivable semblances, diagrams, metaphors, symptoms, signals, designations, symbols, texts, even mental concepts and ideas, all as determinations of a mind or "quasi-mind", that which at least functions like a mind, as in the work of crystals or bees — the focus is on sign action in general rather than on psychology, linguistics, or social studies (fields which he also pursued).
Inquiry is a kind of inference process, a manner of thinking and semiosis. Global divisions of ways for phenomena to stand as signs, and the subsumption of inquiry and thinking within inference as a sign process, enable the study of inquiry on semiotics' three levels:
Peirce uses examples often from common experience, but defines and discusses such things as assertion and interpretation in terms of philosophical logic. In a formal vein, Peirce said:
Signs.
A list of noted writings by Peirce on signs and sign relations is at Semiotic elements and classes of signs (Peirce)#References and further reading.
Sign relation.
Peirce's theory of signs is known to be one of the most complex semiotic theories due to its generalistic claim. Anything is a sign — not absolutely as itself, but instead in some relation or other. The "sign relation" is the key. It defines three roles encompassing (1) the sign, (2) the sign's subject matter, called its "object", and (3) the sign's meaning or ramification as formed into a kind of effect called its "interpretant" (a further sign, for example a translation). It is an irreducible "triadic relation", according to Peirce. The roles are distinct even when the things that fill those roles are not. The roles are but three; a sign of an object leads to one or more interpretants, and, as signs, they lead to further interpretants.
"Extension × intension = information." Two traditional approaches to sign relation, necessary though insufficient, are the way of "extension" (a sign's objects, also called breadth, denotation, or application) and the way of "intension" (the objects' characteristics, qualities, attributes referenced by the sign, also called depth, comprehension, significance, or connotation). Peirce adds a third, the way of "information", including change of information, to integrate the other two approaches into a unified whole. For example, because of the equation above, if a term's total amount of information stays the same, then the more that the term 'intends' or signifies about objects, the fewer are the objects to which the term 'extends' or applies.
"Determination." A sign depends on its object in such a way as to represent its object — the object enables and, in a sense, determines the sign. A physically causal sense of this stands out when a sign consists in an indicative reaction. The interpretant depends likewise on both the sign and the object — an object determines a sign to determine an interpretant. But this determination is not a succession of dyadic events, like a row of toppling dominoes; sign determination is triadic. For example, an interpretant does not merely represent something which represented an object; instead an interpretant represents something "as" a sign representing the object. The object (be it a quality or fact or law or even fictional) determines the sign to an interpretant through one's collateral experience with the object, in which the object is found or from which it is recalled, as when a sign consists in a chance semblance of an absent object. Peirce used the word "determine" not in a strictly deterministic sense, but in a sense of "specializes," "bestimmt", involving variable amount, like an influence. Peirce came to define representation and interpretation in terms of (triadic) determination. The object determines the sign to determine another sign — the interpretant — to be related to the object "as the sign is related to the object", hence the interpretant, fulfilling its function as sign of the object, determines a further interpretant sign. The process is logically structured to perpetuate itself, and is definitive of sign, object, and interpretant in general.
Semiotic elements.
Peirce held there are exactly three basic elements in semiosis (sign action):
Some of the understanding needed by the mind depends on familiarity with the object. To know what a given sign denotes, the mind needs some experience of that sign's object, experience outside of, and collateral to, that sign or sign system. In that context Peirce speaks of collateral experience, collateral observation, collateral acquaintance, all in much the same terms.
Classes of signs.
Among Peirce's many sign typologies, three stand out, interlocked. The first typology depends on the sign itself, the second on how the sign stands for its denoted object, and the third on how the sign stands for its object to its interpretant. Also, each of the three typologies is a three-way division, a trichotomy, via Peirce's three phenomenological categories: (1) quality of feeling, (2) reaction, resistance, and (3) representation, mediation.
I. "Qualisign, sinsign, legisign" (also called" tone, token, type," and also called "potisign, actisign, famisign"): This typology classifies every sign according to the sign's own phenomenological category—the qualisign is a quality, a possibility, a "First"; the sinsign is a reaction or resistance, a singular object, an actual event or fact, a "Second"; and the legisign is a habit, a rule, a representational relation, a "Third".
II. "Icon, index, symbol": This typology, the best known one, classifies every sign according to the category of the sign's way of denoting its object—the icon (also called semblance or likeness) by a quality of its own, the index by factual connection to its object, and the symbol by a habit or rule for its interpretant.
III. "Rheme, dicisign, argument" (also called "sumisign, dicisign, suadisign," also "seme, pheme, delome," and regarded as very broadened versions of the traditional "term, proposition, argument"): This typology classifies every sign according to the category which the interpretant attributes to the sign's way of denoting its object—the rheme, for example a term, is a sign interpreted to represent its object in respect of quality; the dicisign, for example a proposition, is a sign interpreted to represent its object in respect of fact; and the argument is a sign interpreted to represent its object in respect of habit or law. This is the culminating typology of the three, where the sign is understood as a structural element of inference.
Every sign belongs to one class or another within (I) "and" within (II) "and" within (III). Thus each of the three typologies is a three-valued parameter for every sign. The three parameters are not independent of each other; many co-classifications are absent, for reasons pertaining to the lack of either habit-taking or singular reaction in a quality, and the lack of habit-taking in a singular reaction. The result is not 27 but instead ten classes of signs fully specified at this level of analysis.
Modes of inference.
Borrowing a brace of concepts from Aristotle, Peirce examined three basic modes of inference — "abduction", "deduction", and "induction" — in his "critique of arguments" or "logic proper". Peirce also called abduction "retroduction", "presumption", and, earliest of all, "hypothesis". He characterized it as guessing and as inference to an explanatory hypothesis. He sometimes expounded the modes of inference by transformations of the categorical syllogism Barbara (AAA), for example in "Deduction, Induction, and Hypothesis" (1878). He does this by rearranging the "rule" (Barbara's major premise), the "case" (Barbara's minor premise), and the "result" (Barbara's conclusion):
Deduction.
"Rule:" All the beans from this bag are white. <br>
"Case:" These beans are beans from this bag. <br>
formula_1 "Result:" These beans are white.
Induction.
"Case:" These beans are [randomly selected] from this bag. <br>
"Result:" These beans are white. <br>
formula_1 "Rule:" All the beans from this bag are white.
Hypothesis (Abduction).
"Rule:" All the beans from this bag are white. <br>
"Result:" These beans are white. <br>
formula_1 "Case:" These beans are from this bag.
Peirce 1883 in "A Theory of Probable Inference" ("Studies in Logic") equated hypothetical inference with the induction of characters of objects (as he had done in effect before). Eventually dissatisfied, by 1900 he distinguished them once and for all and also wrote that he now took the syllogistic forms and the doctrine of logical extension and comprehension as being less basic than he had thought. In 1903 he presented the following logical form for abductive inference:
The logical form does not also cover induction, since induction neither depends on surprise nor proposes a new idea for its conclusion. Induction seeks facts to test a hypothesis; abduction seeks a hypothesis to account for facts. "Deduction proves that something "must" be; Induction shows that something "actually is" operative; Abduction merely suggests that something "may be"." Peirce did not remain quite convinced that one logical form covers all abduction. In his methodeutic or theory of inquiry (see below), he portrayed abduction as an economic initiative to further inference and study, and portrayed all three modes as clarified by their coordination in essential roles in inquiry: hypothetical explanation, deductive prediction, inductive testing.
Pragmatism.
Some noted articles and lectures
As a movement, pragmatism began in the early 1870s in discussions among Peirce, William James, and others in the Metaphysical Club. James among others regarded some articles by Peirce such as "" (1877) and especially "" (1878) as foundational to pragmatism. Peirce (CP 5.11–12), like James ("", 1907), saw pragmatism as embodying familiar attitudes, in philosophy and elsewhere, elaborated into a new deliberate method for fruitful thinking about problems. Peirce differed from James and the early John Dewey, in some of their tangential enthusiasms, in being decidedly more rationalistic and realistic, in several senses of those terms, throughout the preponderance of his own philosophical moods.
In 1905 Peirce coined the new name pragmaticism "for the precise purpose of expressing the original definition", saying that "all went happily" with James's and F.C.S. Schiller's variant uses of the old name "pragmatism" and that he coined the new name because of the old name's growing use in "literary journals, where it gets abused". Yet he cited as causes, in a 1906 manuscript, his differences with James and Schiller and, in a 1908 publication, his differences with James as well as literary author Giovanni Papini's declaration of pragmatism's indefinability. Peirce in any case regarded his views that truth is immutable and infinity is real, as being opposed by the other pragmatists, but he remained allied with them on other issues.
Pragmatism begins with the idea that belief is that on which one is prepared to act. Peirce's pragmatism is a method of clarification of conceptions of objects. It equates any conception of an object to a conception of that object's effects to a general extent of the effects' conceivable implications for informed practice. It is a method of sorting out conceptual confusions occasioned, for example, by distinctions that make (sometimes needed) formal yet not practical differences. He formulated both pragmatism and statistical principles as aspects of scientific logic, in his "Illustrations of the Logic of Science" series of articles. In the second one, "", Peirce discussed three grades of clearness of conception:
By way of example of how to clarify conceptions, he addressed conceptions about truth and the real as questions of the presuppositions of reasoning in general. In clearness's second grade (the "nominal" grade), he defined truth as a sign's correspondence to its object, and the real as the object of such correspondence, such that truth and the real are independent of that which you or I or any actual, definite community of inquirers think. After that needful but confined step, next in clearness's third grade (the pragmatic, practice-oriented grade) he defined truth as that opinion which "would" be reached, sooner or later but still inevitably, by research taken far enough, such that the real does depend on that ideal final opinion—a dependence to which he appeals in theoretical arguments elsewhere, for instance for the long-run validity of the rule of induction. Peirce argued that even to argue against the independence and discoverability of truth and the real is to presuppose that there is, about that very question under argument, a truth with just such independence and discoverability.
Peirce said that a conception's meaning consists in "all general modes of rational conduct" implied by "acceptance" of the conception—that is, if one were to accept, first of all, the conception as true, then what could one conceive to be consequent general modes of rational conduct by all who accept the conception as true?—the whole of such consequent general modes is the whole meaning. His pragmatism does not equate a conception's meaning, its intellectual purport, with the conceived benefit or cost of the conception itself, like a meme (or, say, propaganda), outside the perspective of its being true, nor, since a conception is general, is its meaning equated with any definite set of actual consequences or upshots corroborating or undermining the conception or its worth. His pragmatism also bears no resemblance to "vulgar" pragmatism, which misleadingly connotes a ruthless and Machiavellian search for mercenary or political advantage. Instead the pragmatic maxim is the heart of his pragmatism as a method of experimentational mental reflection arriving at conceptions in terms of conceivable confirmatory and disconfirmatory circumstances—a method hospitable to the formation of explanatory hypotheses, and conducive to the use and improvement of verification.
Peirce's pragmatism, as method and theory of definitions and conceptual clearness, is part of his theory of inquiry, which he variously called speculative, general, formal or universal rhetoric or simply methodeutic. He applied his pragmatism as a method throughout his work.
Theory of inquiry.
Critical common-sensism.
Critical common-sensism, treated by Peirce as a consequence of his pragmatism, is his combination of Thomas Reid's common-sense philosophy with a fallibilism that recognizes that propositions of our more or less vague common sense now indubitable may later come into question, for example because of transformations of our world through science. It includes efforts to work up in tests genuine doubts for a core group of common indubitables that vary slowly if at all.
Rival methods of inquiry.
In (1877), Peirce described inquiry in general not as the pursuit of truth "per se" but as the struggle to move from irritating, inhibitory doubt born of surprise, disagreement, and the like, and to reach a secure belief, belief being that on which one is prepared to act. That let Peirce frame scientific inquiry as part of a broader spectrum and as spurred, like inquiry generally, by actual doubt, not mere verbal, quarrelsome, or hyperbolic doubt, which he held to be fruitless. Peirce sketched four methods of settling opinion, ordered from least to most successful:
Peirce held that, in practical affairs, slow and stumbling ratiocination is often dangerously inferior to instinct and traditional sentiment, and that the scientific method is best suited to theoretical research, which in turn should not be trammeled by the other methods and practical ends; reason's "first rule" is that, in order to learn, one must desire to learn and, as a corollary, must not block the way of inquiry. Scientific method excels the others finally by being deliberately designed to arrive — eventually — at the most secure beliefs, upon which the most successful practices can be based. Starting from the idea that people seek not truth "per se" but instead to subdue irritating, inhibitory doubt, Peirce showed how, through the struggle, some can come to submit to truth for the sake of belief's integrity, seek as truth the guidance of potential conduct correctly to its given goal, and wed themselves to the scientific method.
Scientific method.
Insofar as clarification by pragmatic reflection suits explanatory hypotheses and fosters predictions and testing, pragmatism points beyond the usual duo of foundational alternatives: deduction from self-evident truths, or "rationalism"; and induction from experiential phenomena, or "empiricism".
Based on his critique of three modes of argument and different from either foundationalism or coherentism, Peirce's approach seeks to justify claims by a three-phase dynamic of inquiry:
Thereby, Peirce devised an approach to inquiry far more solid than the flatter image of inductive generalization "simpliciter", which is a mere re-labeling of phenomenological patterns. Peirce's pragmatism was the first time the scientific method was proposed as an epistemology for philosophical questions.
A theory that succeeds better than its rivals in predicting and controlling our world is said to be nearer the truth. This is an operational notion of truth used by scientists.
Peirce extracted the pragmatic model or theory of inquiry from its raw materials in classical logic and refined it in parallel with the early development of symbolic logic to address problems about the nature of scientific reasoning.
Abduction, deduction, and induction make incomplete sense in isolation from one another but comprise a cycle understandable as a whole insofar as they collaborate toward the common end of inquiry. In the pragmatic way of thinking about conceivable practical implications, every thing has a purpose, and, as possible, its purpose should first be denoted. Abduction hypothesizes an explanation for deduction to clarify into implications to be tested so that induction can evaluate the hypothesis, in the struggle to move from troublesome uncertainty to more secure belief. No matter how traditional and needful it is to study the modes of inference in abstraction from one another, the integrity of inquiry strongly limits the effective modularity of its principal components.
Peirce's outline of the scientific method in §III–IV of "A Neglected Argument" is summarized below (except as otherwise noted). There he also reviewed plausibility and inductive precision (issues of critique of arguments).
1. Abductive (or retroductive) phase. Guessing, inference to explanatory hypotheses for selection of those best worth trying. From abduction, Peirce distinguishes induction as inferring, on the basis of tests, the proportion of truth in the hypothesis. Every inquiry, whether into ideas, brute facts, or norms and laws, arises from surprising observations in one or more of those realms (and for example at any stage of an inquiry already underway). All explanatory content of theories comes from abduction, which guesses a new or outside idea so as to account in a simple, economical way for a surprising or complicated phenomenon. The modicum of success in our guesses far exceeds that of random luck, and seems born of attunement to nature by developed or inherent instincts, especially insofar as best guesses are optimally plausible and simple in the sense of the "facile and natural", as by Galileo's natural light of reason and as distinct from "logical simplicity". Abduction is the most fertile but least secure mode of inference. Its general rationale is inductive: it succeeds often enough and it has no substitute in expediting us toward new truths. In 1903, Peirce called pragmatism "the logic of abduction". Coordinative method leads from abducting a plausible hypothesis to judging it for its testability and for how its trial would economize inquiry itself. The hypothesis, being insecure, needs to have practical implications leading at least to mental tests and, in science, lending themselves to scientific tests. A simple but unlikely guess, if not costly to test for falsity, may belong first in line for testing. A guess is intrinsically worth testing if it has plausibility or reasonably objective probability, while subjective likelihood, though reasoned, can be misleadingly seductive. Guesses can be selected for trial strategically, for their caution (for which Peirce gave as example the game of Twenty Questions), breadth, or incomplexity. One can discover only that which would be revealed through their sufficient experience anyway, and so the point is to expedite it; economy of research demands the leap, so to speak, of abduction and governs its art.
2. Deductive phase. Two stages:
3. Inductive phase. Evaluation of the hypothesis, inferring from observational or experimental tests of its deduced consequences. The long-run validity of the rule of induction is deducible from the principle (presuppositional to reasoning in general) that the real "is only the object of the final opinion to which sufficient investigation would lead"; in other words, anything excluding such a process would never be real. Induction involving the ongoing accumulation of evidence follows "a method which, sufficiently persisted in," will "diminish the error below any predesignate degree." Three stages:
Against Cartesianism.
Peirce drew on the methodological implications of the four incapacities — no genuine introspection, no intuition in the sense of non-inferential cognition, no thought but in signs, and no conception of the absolutely incognizable — to attack philosophical Cartesianism, of which he said that:
1. "It teaches that philosophy must begin in universal doubt" — when, instead, we start with preconceptions, "prejudices [...] which it does not occur to us "can" be questioned", though we may find reason to question them later. "Let us not pretend to doubt in philosophy what we do not doubt in our hearts."
2. "It teaches that the ultimate test of certainty is...in the individual consciousness" — when, instead, in science a theory stays on probation till agreement is reached, then it has no actual doubters left. No lone individual can reasonably hope to fulfill philosophy's multi-generational dream. When "candid and disciplined minds" continue to disagree on a theoretical issue, even the theory's author should feel doubts about it.
3. It trusts to "a single thread of inference depending often upon inconspicuous premisses" — when, instead, philosophy should, "like the successful sciences", proceed only from tangible, scrutinizable premisses and trust not to any one argument but instead to "the multitude and variety of its arguments" as forming, not a chain at least as weak as its weakest link, but "a cable whose fibers", soever "slender, are sufficiently numerous and intimately connected".
4. It renders many facts "absolutely inexplicable, unless to say that 'God makes them so' is to be regarded as an explanation" — when, instead, philosophy should avoid being "unidealistic", misbelieving that something real can defy or evade all possible ideas, and supposing, inevitably, "some absolutely inexplicable, unanalyzable ultimate", which explanatory surmise explains nothing and so is inadmissible.
Philosophy: metaphysics.
Some noted articles
Peirce divided metaphysics into (1) ontology or general metaphysics, (2) psychical or religious metaphysics, and (3) physical metaphysics.
Ontology. Peirce was a Scholastic Realist, declaring for the reality of generals as early as 1868. Regarding modalities (possibility, necessity, etc.), he came in later years to regard himself as having wavered earlier as to just how positively real the modalities are. In his 1897 "The Logic of Relatives" he wrote: Peirce retained, as useful for some purposes, the definitions in terms of information states, but insisted that the pragmaticist is committed to a strong modal realism by conceiving of objects in terms of predictive general conditional propositions about how they "would" behave under certain circumstances.
Psychical or religious metaphysics. Peirce believed in God, and characterized such belief as founded in an instinct explorable in musing over the worlds of ideas, brute facts, and evolving habits — and it is a belief in God not as an "actual" or "existent" being (in Peirce's sense of those words), but all the same as a "real" being. In "" (1908), Peirce sketches, for God's reality, an argument to a hypothesis of God as the Necessary Being, a hypothesis which he describes in terms of how it would tend to develop and become compelling in musement and inquiry by a normal person who is led, by the hypothesis, to consider as being purposed the features of the worlds of ideas, brute facts, and evolving habits (for example scientific progress), such that the thought of such purposefulness will "stand or fall with the hypothesis"; meanwhile, according to Peirce, the hypothesis, in supposing an "infinitely incomprehensible" being, starts off at odds with its own nature as a purportively true conception, and so, no matter how much the hypothesis grows, it both (A) inevitably regards itself as partly true, partly vague, and as continuing to define itself without limit, and (B) inevitably has God appearing likewise vague but growing, though God as the Necessary Being is not vague or growing; but the hypothesis will hold it to be "more" false to say the opposite, that God is purposeless. Peirce also argued that the will is free and (see Synechism) that there is at least an attenuated kind of immortality.
Physical metaphysics. Peirce held the view, which he called objective idealism, that "matter is effete mind, inveterate habits becoming physical laws". Peirce asserted the reality of (1) absolute chance (his tychist view), (2) mechanical necessity (anancist view), and (3) that which he called the law of love (agapist view), echoing his categories Firstness, Secondness, and Thirdness, respectively. He held that fortuitous variation (which he also called "sporting"), mechanical necessity, and creative love are the three modes of evolution (modes called "tychasm", "anancasm", and "agapasm") of the cosmos and its parts. He found his conception of agapasm embodied in Lamarckian evolution; the overall idea in any case is that of evolution tending toward an end or goal, and it could also be the evolution of a mind or a society; it is the kind of evolution which manifests workings of mind in some general sense. He said that overall he was a synechist, holding with reality of continuity, especially of space, time, and law.
Science of review.
Peirce outlined two fields, "Cenoscopy" and "Science of Review", both of which he called philosophy. Both included philosophy about science. In 1903 he arranged them, from more to less theoretically basic, thus:
Peirce placed, within Science of Review, the work and theory of classifying the sciences (including mathematics and philosophy). His classifications, on which he worked for many years, draw on argument and wide knowledge, and are of interest both as a map for navigating his philosophy and as an accomplished polymath's survey of research in his time.
See also.
Contemporaries associated with Peirce
External links.
Charles Sanders Peirce bibliography has external links throughout to such materials as biographical and overview articles on Peirce at encyclopedias, study sites, etc.; individual works by Peirce; and collections, bibliographies, and Peirce's definitions in the Baldwin dictionary.
Other useful sets of links:

</doc>
<doc id="6118" url="https://en.wikipedia.org/wiki?curid=6118" title="Carnot heat engine">
Carnot heat engine

A Carnot heat engine is an engine that operates on the reversible Carnot cycle. The basic model for this engine was developed by Nicolas Léonard Sadi Carnot in 1824. The Carnot engine model was graphically expanded upon by Benoît Paul Émile Clapeyron in 1834 and mathematically elaborated upon by Rudolf Clausius in 1857 from which the concept of entropy emerged.
Every thermodynamic system exists in a particular state. A thermodynamic cycle occurs when a system is taken through a series of different states, and finally returned to its initial state. In the process of going through this cycle, the system may perform work on its surroundings, thereby acting as a heat engine.
A heat engine acts by transferring energy from a warm region to a cool region of space and, in the process, converting some of that energy to mechanical work. The cycle may also be reversed. The system may be worked upon by an external force, and in the process, it can transfer thermal energy from a cooler system to a warmer one, thereby acting as a refrigerator or heat pump rather than a heat engine.
Carnot's diagram.
In the adjacent diagram, from Carnot's 1824 work, "Reflections on the Motive Power of Fire", there are "two bodies "A" and "B", kept each at a constant temperature, that of "A" being higher than that of "B". These two bodies to which we can give, or from which we can remove the heat without causing their temperatures to vary, exercise the functions of two unlimited reservoirs of caloric. We will call the first the furnace and the second the refrigerator.” Carnot then explains how we can obtain motive power, i.e., “work”, by carrying a certain quantity of heat from body "A" to body "B".
Modern diagram.
The previous image shows the original piston-and-cylinder diagram used by Carnot in discussing his ideal engines. The figure at right shows a block diagram of a generic heat engine, such as the Carnot engine. In the diagram, the “working body” (system), a term introduced by Clausius in 1850, can be any fluid or vapor body through which heat "Q" can be introduced or transmitted to produce work. Carnot had postulated that the fluid body could be any substance capable of expansion, such as vapor of water, vapor of alcohol, vapor of mercury, a permanent gas, or air, etc. Although, in these early years, engines came in a number of configurations, typically "Q"H was supplied by a boiler, wherein water was boiled over a furnace; "Q"C was typically supplied by a stream of cold flowing water in the form of a condenser located on a separate part of the engine. The output work "W" here is the movement of the piston as it is used to turn a crank-arm, which was then typically used to turn a pulley so to lift water out of flooded salt mines. Carnot defined work as “weight lifted through a height”.
Carnot cycle.
The Carnot cycle when acting as a heat engine consists of the following steps:
Carnot's theorem.
Carnot's theorem is a formal statement of this fact: "No engine operating between two heat reservoirs can be more efficient than a Carnot engine operating between the same reservoirs."
Explanation 
This maximum efficiency formula_4 is defined as above:
A corollary to Carnot's theorem states that: All reversible engines operating between the same heat reservoirs are equally efficient.
It is easily shown that the efficiency formula_9 is maximum when the entire cyclic process is a reversible process. This means the total entropy of the total system consisting of the three parts: the entropy of the hot furnace, the entropy of the "working fluid" of the Heat engine, and the entropy of the cold sink. The total entropy of the system remains constant when the "working fluid" completes one cycle and returns to its original state. (In the general case, the total entropy of this combined system would increase in a general irreversible process).
Since the "working fluid" comes back to the same state after one cycle, and entropy of the system is a state function; the change in entropy of the "working fluid" system is 0. Thus, it implies that the total entropy change of the furnace and sink is zero, for the process to be reversible and the efficiency of the engine to be maximum. This derivation is carried out in the next section.
The Coefficient of Performance (COP) of the heat engine is the reciprocal of its efficiency.
Efficiency of real heat engines.
For a real heat engine, the total thermodynamic process is generally irreversible. The working fluid is brought back to its initial state after one cycle, and thus the change of entropy of the fluid system is 0, but the sum of the entropy changes in the hot and cold reservoir in this one cyclical process is greater than 0.
The internal energy of the fluid is also a state variable, so its total change in one cycle is 0. So the total work done by the system formula_5, is equal to the heat put into the system formula_6 minus the heat taken out formula_12.
For real engines, sections 1 and 3 of the Carnot Cycle; in which heat is absorbed by the "working fluid" from the hot reservoir, and released by it to the cold reservoir, respectively; no longer remain ideally reversible, and there is a temperature differential between the temperature of the reservoir and the temperature of the fluid while heat exchange takes place.
During heat transfer from the hot reservoir at formula_14 to the fluid, the fluid would have a slightly lower temperature than formula_14, and the process for the fluid may not necessarily remain isothermal. 
Let formula_16 be the total entropy change of the fluid in the process of intake of heat. 
where the temperature of the fluid formula_18 is always slightly lesser than formula_14, in this process.
So, one would get 
Similarly, at the time of heat injection from the fluid to the cold reservoir one would have, for the magnitude of total entropy change formula_21 of the fluid in the process of expelling heat:
where, during this process of transfer of heat to the cold reservoir, the temperature of the fluid formula_18 is always slightly greater than formula_24.
We have only considered the magnitude of the entropy change here. Since the total change of entropy of the fluid system for the cyclic process is 0, we must have
The previous three equations combine to give:
Equations (2) and (7) combine to give 
Hence,
where formula_29 is the efficiency of the real engine, and formula_4 is the efficiency of the Carnot engine working between the same two reservoirs at the temperatures formula_14 and formula_24. For the Carnot engine, the entire process is 'reversible', and Equation (7) is an equality.
Hence, the efficiency of the real engine is always less than the ideal Carnot engine.
Equation (7) signifies that the total entropy of the total system(the two reservoirs + fluid) increases for the real engine, because the entropy gain of the cold reservoir as formula_33 flows into it at the fixed temperature formula_24, is greater than the entropy loss of the hot reservoir as formula_35 leaves it at its fixed temperature formula_14. The inequality in Equation (7) is essentially the statement of the Clausius theorem.
According to the second theorem, "The efficiency of the Carnot engine is independent of the nature of the working substance".

</doc>
<doc id="6119" url="https://en.wikipedia.org/wiki?curid=6119" title="Context-sensitive">
Context-sensitive

Context-sensitive is an adjective meaning "depending on context" or "depending on circumstances". It may refer to:

</doc>
<doc id="6121" url="https://en.wikipedia.org/wiki?curid=6121" title="Central America">
Central America

Central America () is the southernmost, isthmian portion of the North American continent, which connects with South America on the southeast. Central America is bordered by Mexico to the north, Colombia to the southeast, the Caribbean Sea to the east, and the Pacific Ocean to the west. Central America consists of seven countries: Belize, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and Panama. The combined population of Central America is between 41,739,000 (2009 estimate) and 42,688,190 (2012 estimate).
The Central American land mass has an area of , or almost 0.1% of the Earth's surface. It is part of the Mesoamerican biodiversity hotspot, which extends from northern Guatemala through central Panama. Due to the presence of several active geologic faults and the Central America Volcanic Arc, there is a great deal of seismic activity in the region. Volcanic eruptions and earthquakes occur frequently; these natural disasters have resulted in the loss of many lives and much property.
In the Pre-Columbian era, Central America was inhabited by the indigenous peoples of Mesoamerica to the north and west and the Isthmo-Colombian peoples to the south and east. Soon after Christopher Columbus's voyages to the Americas, the Spanish began to colonize the Americas. From 1609 until 1821, most of the territory within Central America—except for the lands that would become Belize and Panama—was governed as the Captaincy General of Guatemala. After achieving independence from Spain in 1821, the former Captaincy General was annexed to the First Mexican Empire, but soon seceded from Mexico to form the Federal Republic of Central America, which lasted from 1823 to 1838. The seven states finally became independent autonomous nations, beginning with Nicaragua, Honduras, Costa Rica, and Guatemala (1838), followed by El Salvador (1841), then Panama (1903), and finally Belize (1981).
Different definitions.
"Central America" may mean different things to various people, based upon different contexts:
History.
In the Pre-Columbian era, the northern areas of Central America were inhabited by the indigenous peoples of Mesoamerica. Most notable among these were the Mayans, who had built numerous cities throughout the region, and the Aztecs, who had created a vast empire. The pre-Columbian cultures of eastern El Salvador, eastern Honduras, Caribbean Nicaragua, most of Costa Rica and Panama were predominantly speakers of the Chibchan languages at the time of European contact and are considered by some culturally different and grouped in the Isthmo-Colombian Area.
Following Christopher Columbus's voyages to the Americas, the Spanish sent many expeditions to the region, and they began their conquest of Maya territory in 1523. Soon after the conquest of the Aztec Empire, Spanish conquistador Pedro de Alvarado commenced the conquest of northern Central America for the Spanish Empire. Beginning with his arrival in Soconusco in 1523, Alvarado's forces systematically conquered and subjugated most of the major Maya kingdoms, including the K'iche', Tz'utujil, Pipil, and the Kaqchikel. By 1528, the conquest of Guatemala was nearly complete, with only the Petén Basin remaining outside the Spanish sphere of influence. The last independent Maya kingdoms – the Ko'woj and the Itza people – were finally defeated in 1697, as part of the Spanish conquest of Petén.
In 1538, Spain established the "Audiencia Real de Panama", which had jurisdiction over all land from the Strait of Magellan to the Gulf of Fonseca. This entity was dissolved in 1543, and most of the territory within Central America then fell under the jurisdiction of the "Audiencia Real de Guatemala". This area included the current territories of Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Mexican state of Chiapas, but excluded the lands that would become Belize and Panama. The president of the Audiencia, which had its seat in Antigua Guatemala, was the governor of the entire area. In 1609 the area became a captaincy general and the governor was also granted the title of captain general. The Captaincy General of Guatemala encompassed most of Central America, with the exception of present-day Belize and Panama.
The Captaincy General of Guatemala lasted for more than two centuries, but began to fray after a rebellion in 1811 which began in the intendancy of San Salvador. The Captaincy General formally ended on 15 September 1821, with the signing of the Act of Independence of Central America. Mexican independence was achieved at virtually the same time with the signing of the Treaty of Córdoba and the Declaration of Independence of the Mexican Empire, and the entire region was finally free from Spanish authority by 28 September 1821.
From its independence from Spain in 1821 until 1823, the former Captaincy General remained intact as part of the short-lived First Mexican Empire. When the Emperor of Mexico was overthrown on 19 March 1823, Central America again became independent. On 1 July 1823, the Congress of Central America peacefully seceded from Mexico and declared absolute independence from all foreign nations, and the region formed the Federal Republic of Central America.
The Federal Republic of Central America was a representative democracy with its capital at Guatemala City. This union consisted of the provinces of Costa Rica, El Salvador, Guatemala, Honduras, Los Altos, Mosquito Coast, and Nicaragua. The lowlands of southwest Chiapas, including Soconusco, initially belonged to the Republic until 1824, when Mexico annexed most of Chiapas and began its claims to Soconusco. The Republic lasted from 1823 to 1838, when it disintegrated as a result of civil wars.
The territory that now makes up Belize was heavily contested in a dispute that continued for decades after Guatemala achieved independence. Spain, and later Guatemala, considered this land a Guatemalan department. In 1862, Britain formally declared it a British colony and named it British Honduras. It became independent as Belize in 1981.
Panama, situated in the southernmost part of Central America on the Isthmus of Panama, has for most of its history been culturally linked to South America. Panama was part of the Province of Tierra Firme from 1510 until 1538 when it came under the jurisdiction of the newly formed "Audiencia Real de Panama". Beginning in 1543, Panama was administered as part of the Viceroyalty of Peru, along with all other Spanish possessions in South America. Panama remained as part of the Viceroyalty of Peru until 1739, when it was transferred to the Viceroyalty of New Granada, the capital of which was located at Santa Fé de Bogotá. Panama remained as part of the Viceroyalty of New Granada until the disestablishment of that viceroyalty in 1819. A series of military and political struggles took place from that time until 1822, the result of which produced the republic of Gran Colombia. After the dissolution of Gran Colombia in 1830, Panama became part of a successor state, the Republic of New Granada. From 1855 until 1886, Panama existed as Panama State, first within the Republic of New Granada, then within the Granadine Confederation, and finally within the United States of Colombia. The United States of Colombia was replaced by the Republic of Colombia in 1886. As part of the Republic of Colombia, Panama State was abolished and it became the Isthmus Department. Despite the many political reorganizations, Colombia was still deeply plagued by conflict, which eventually led to the secession of Panama on 3 November 1903. Only after that time did some begin to regard Panama as a North or Central American entity.
After more than two hundred years of social unrest, violent conflict and revolution, Central America today remains in a period of political transformation. Poverty, social injustice and violence are still widespread. Nicaragua is the second poorest country in the western hemisphere (only Haiti is poorer).
Geography.
Central America is the tapering isthmus of southern North America, with unique and varied geographic features. The Pacific Ocean lies to the southwest, the Caribbean Sea lies to the northeast, and the Gulf of Mexico lies to the north. Some physiographists define the Isthmus of Tehuantepec as the northern geographic border of Central America, while others use the northwestern borders of Belize and Guatemala. From there, the Central American land mass extends southeastward to the Isthmus of Panama, where it connects to the Pacific Lowlands in northwestern South America.
Of the many mountain ranges within Central America, the longest are the Sierra Madre de Chiapas, the Cordillera Isabelia and the Cordillera de Talamanca. At , Volcán Tajumulco is the highest peak in Central America. Other high points of Central America are as listed in the table below:
High points in Central America
Between the mountain ranges lie fertile valleys that are suitable for the raising of livestock and for the production of coffee, tobacco, beans and other crops. Most of the population of Honduras, Costa Rica and Guatemala lives in valleys.
Trade winds have a significant effect upon the climate of Central America. Temperatures in Central America are highest just prior to the summer wet season, and are lowest during the winter dry season, when trade winds contribute to a cooler climate. The highest temperatures occur in April, due to higher levels of sunlight, lower cloud cover and a decrease in trade winds.
Biodiversity.
Central America is part of the Mesoamerican biodiversity hotspot, boasting 7% of the world's biodiversity. The Pacific Flyway is a major north-south flyway for migratory birds in the Americas, extending from Alaska to Tierra del Fuego. Due to the funnel-like shape of its land mass, migratory birds can be seen in very high concentrations in Central America, especially in the spring and autumn. As a bridge between North America and South America, Central America has many species from the Nearctic and the Neotropic ecozones. However the southern countries (Costa Rica and Panama) of the region have more biodiversity than the northern countries (Guatemala and Belize), meanwhile the central countries (Honduras, Nicaragua and El Salvador) have the least biodiversity. The table below shows recent statistics:
Biodiversity in Central America (number of different species of terrestrial vertebrate animals and vascular plants)
Over 300 species of the region's flora and fauna are threatened, 107 of which are classified as critically endangered. The underlying problems are deforestation, which is estimated by FAO at 1.2% per year in Central America and Mexico combined, fragmentation of rainforests and the fact that 80% of the vegetation in Central America has already been converted to agriculture.
Efforts to protect fauna and flora in the region are made by creating ecoregions and nature reserves. 36% of Belize's land territory falls under some form of official protected status, giving Belize one of the most extensive systems of terrestrial protected areas in the Americas. In addition, 13% of Belize's marine territory are also protected. A large coral reef extends from Mexico to Honduras: the Mesoamerican Barrier Reef System. The Belize Barrier Reef is part of this. The Belize Barrier Reef is home to a large diversity of plants and animals, and is one of the most diverse ecosystems of the world. It is home to 70 hard coral species, 36 soft coral species, 500 species of fish and hundreds of invertebrate species.
So far only about 10% of the species in the Belize barrier reef have been discovered.
Flora.
From 2001 to 2010, of forest were lost in the region. In 2010 Belize had 63% of remaining forest cover, Costa Rica 46%, Panama 45%, Honduras 41%, Guatemala 37%, Nicaragua 29%, and El Salvador 21%. Most of the loss occurred in the moist forest biome, with . Woody vegetation loss was partially set off by a gain in the coniferous forest biome with , and a gain in the dry forest biome at . Mangroves and deserts contributed only 1% to the loss in forest vegetation. The bulk of the deforestation was located at the Caribbean slopes of Nicaragua with a loss of of forest in the period from 2001 to 2010. The most significant regrowth of of forest was seen in the coniferous woody vegetation of Honduras.
The Central American pine-oak forests ecoregion, in the tropical and subtropical coniferous forests biome, is found in Central America and southern Mexico. The Central American pine-oak forests occupy an area of , extending along the mountainous spine of Central America, extending from the Sierra Madre de Chiapas in Mexico's Chiapas state through the highlands of Guatemala, El Salvador, and Honduras to central Nicaragua. The pine-oak forests lie between elevation, and are surrounded at lower elevations by tropical moist forests and tropical dry forests. Higher elevations above are usually covered with Central American montane forests. The Central American pine-oak forests are composed of many species characteristic of temperate North America including oak, pine, fir, and cypress.
Laurel forest is the most common type of Central American temperate evergreen cloud forest, found in almost all Central American countries, normally more than above sea level. Tree species include evergreen oaks, members of the laurel family, and species of "Weinmannia", "Drimys", and "Magnolia". The cloud forest of Sierra de las Minas, Guatemala, is the largest in Central America. In some areas of southeastern Honduras there are cloud forests, the largest located near the border with Nicaragua. In Nicaragua, cloud forests are situated near the border with Honduras, but many were cleared to grow coffee. There are still some temperate evergreen hills in the north. The only cloud forest in the Pacific coastal zone of Central America is on the Mombacho volcano in Nicaragua. In Costa Rica, there are laurel forests in the Cordillera de Tilarán and Volcán Arenal, called Monteverde, also in the Cordillera de Talamanca.
The Central American montane forests are an ecoregion of the tropical and subtropical moist broadleaf forests biome, as defined by the World Wildlife Fund. These forests are of the moist deciduous and the semi-evergreen seasonal subtype of tropical and subtropical moist broadleaf forests and receive high overall rainfall with a warm summer wet season and a cooler winter dry season. Central American montane forests consist of forest patches located at altitudes ranging from , on the summits and slopes of the highest mountains in Central America ranging from Southern Mexico, through Guatemala, El Salvador, and Honduras, to northern Nicaragua. The entire ecoregion covers an area of and has a temperate climate with relatively high precipitation levels.
Fauna.
Ecoregions are not only established to protect the forests themselves but also because they are habitat for an incomparably rich and often endemic Fauna. Almost half of the bird population of the Talamancan montane forests in Costa Rica and Panama are endemic to this region. Several birds are listed as threatened, most notably the resplendent quetzal (Pharomacrus mocinno), three-wattled bellbird (Procnias tricarunculata), bare-necked umbrellabird (Cephalopterus glabricollis), and black guan (Chamaepetes unicolor). Many of the amphibians are endemic and depend on the existence of forest. The golden toad that once inhabited a small region in the Monteverde Reserve, which is part of the Talamancan montane forests, has not been seen alive since 1989 and is listed as extinct by IUCN. The exact causes for its extincition are unknown. Global warming may have played a role, because the development of fog that is typical for this area may have been compromised. Seven small mammals are endemic to the Costa Rica-Chiriqui highlands within the Talamancan montane forest region. Jaguars, cougars, spider monkeys, as well as tapirs, and anteaters live in the woods of Central America. The Central American red brocket is a brocket deer found in Central America's tropical forest.
Geology.
Central America is geologically very active, with volcanic eruptions and earthquakes occurring frequently, and tsunamis occurring occasionally. Many thousands of people have died as a result of these natural disasters.
Most of Central America rests atop the Caribbean Plate. This tectonic plate converges with the Cocos, Nazca, and North American plates to form the Middle America Trench, a major subduction zone. The Middle America Trench is situated some off the Pacific coast of Central America and runs roughly parallel to it. Many large earthquakes have occurred as a result of seismic activity at the Middle America Trench. For example, subduction of the Cocos Plate beneath the North American Plate at the Middle America Trench is believed to have caused the 1985 Mexico City earthquake that killed as many as 40,000 people. Seismic activity at the Middle America Trench is also responsible for earthquakes in 1902, 1942, 1956, 1982, 1992, 2001, 2007, 2012, 2014, and many other earthquakes throughout Central America.
The Middle America Trench is not the only source of seismic activity in Central America. The Motagua Fault is an onshore continuation of the Cayman Trough which forms part of the tectonic boundary between the North American Plate and the Caribbean Plate. This transform fault cuts right across Guatemala and then continues offshore until it merges with the Middle America Trench along the Pacific coast of Mexico, near Acapulco. Seismic activity at the Motagua Fault has been responsible for earthquakes in 1717, 1773, 1902, 1976, 1980, and 2009.
Another onshore continuation of the Cayman Trough is the Chixoy-Polochic Fault, which runs parallel to, and roughly to the north, of the Motagua Fault. Though less active than the Motagua Fault, seismic activity at the Chixoy-Polochic Fault is still thought to be capable of producing very large earthquakes, such as the 1816 earthquake of Guatemala.
Managua, the capital of Nicaragua, was devastated by earthquakes in 1931 and 1972.
Volcanic eruptions are also common in Central America. In 1968 the Arenal Volcano, in Costa Rica, erupted killing 87 people as the 3 villages of Tabacon, Pueblo Nuevo and San Luis were buried under pyroclastic flows and debris. Fertile soils from weathered volcanic lava have made it possible to sustain dense populations in the agriculturally productive highland areas.
Demographics.
The population of Central America is estimated at 42,688,190 as of 2012. With an area of , it has a population density of .
Languages.
The official language majority in all Central American countries is Spanish, except in Belize, where the official language is English. Mayan languages constitute a language family consisting of about 26 related languages. Guatemala formally recognized 21 of these in 1996. Xinca and Garifuna are also present in Central America.
Ethnic groups.
This region of the continent is very rich in terms of ethnic groups. The majority of the population is mestizo, with sizable Mayan and White populations present, including Xinca and Garifuna minorities. The immigration of Arabs, Jews, Chinese, Europeans and others brought additional groups to the area.
Religious groups.
The predominant religion in Central America is Christianity (95.6%). Beginning with the Spanish colonization of Central America in the 16th century, Roman Catholicism became the most popular religion in the region until the first half of the 20th century. Since the 1960s, there has been an increase in other Christian groups, particularly Protestantism, as well as other religious organizations, and individuals identifying themselves as having no religion.
Politics.
Central American Integration.
Sistema de Integración Centroamericana
Central American Integration System
Motto: "Peace, Development, Liberty and Democracy"
Anthem: "La Granadera"
Central America is currently undergoing a process of political, economic and cultural transformation that started in 1907 with the creation of the Central American Court of Justice.
In 1951 the integration process continued with the signature of the San Salvador Treaty, which created the ODECA, the Organization of Central American States. However, the unity of the ODECA was limited by conflicts between several member states.
In 1991, the integration agenda was further advanced by the creation of the Central American Integration System ("Sistema para la Integración Centroamericana", or SICA). SICA provides a clear legal basis to avoid disputes between the member states. SICA membership includes the 7 nations of Central America plus the Dominican Republic, a state that is traditionally considered part of the Caribbean.
On 6 December 2008 SICA announced an agreement to pursue a common currency and common passport for the member nations. No timeline for implementation was discussed.
Central America already has several supranational institutions such as the Central American Parliament, the Central American Bank for Economic Integration and the Central American Common Market.
On 22 July 2011 President Mauricio Funes of El Salvador became the first president "pro tempore" to SICA. El Salvador also became the headquarters of SICA with the inauguration of a new building.
Foreign relations.
Until recently, all Central American countries have maintained diplomatic relations with Taiwan instead of China. President Óscar Arias of Costa Rica, however, established diplomatic relations with China in 2007, severing formal diplomatic ties with Taiwan.
Central American Parliament.
The Central American Parliament (also known as PARLACEN) is a political and parliamentary body of SICA. The parliament's beginnings started at around 1980, and its primary goal was to solve wars in Nicaragua, Guatemala, and El Salvador. Although the group was disbanded in 1986, ideas of unity of Central Americans still remained, so a treaty was signed in 1987 to create the Central American Parliament and other political bodies. Its original members were Guatemala, El Salvador, Nicaragua and Honduras. The parliament is the political organ of Central America, and is part of SICA. New members have since then joined including Panama and the Dominican Republic.
Economy.
Signed in 2004, the Central American Free Trade Agreement (CAFTA) is an agreement between the United States, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Dominican Republic. The treaty is aimed at promoting free trade among its members.
Guatemala has the largest economy in the region. Its main exports are coffee, sugar, bananas, petroleum, clothing, and cardamom. Of its 10.29 billion dollar annual exports, 40.2% go to the United States, 11.1% to neighboring El Salvador, 8% to Honduras, 5.5% to Mexico, 4.7% to Nicaragua, and 4.3% to Costa Rica.
Economic growth in Central America is projected to slow slightly in 2014–15, as country-specific domestic factors offset the positive effects from stronger economic activity in the United States.
Tourism.
Tourism in Belize has grown considerably in more recent times, and it is now the second largest industry in the nation. Belizean Prime Minister Dean Barrow has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Belize's tourism-driven economy have been significant, with the nation welcoming almost one million tourists in a calendar year for the first time in its history in 2012.
Costa Rica is the most visited nation in Central America. Tourism in Costa Rica is one of the fastest growing economic sectors of the country, having become the largest source of foreign revenue by 1995. Since 1999, tourism has earned more foreign exchange than bananas, pineapples and coffee exports combined. The tourism boom began in 1987, with the number of visitors up from 329,000 in 1988, through 1.03 million in 1999, to a historical record of 2.43 million foreign visitors and $1.92-billion in revenue in 2013. In 2012 tourism contributed with 12.5% of the country's GDP and it was responsible for 11.7% of direct and indirect employment.
Tourism in Nicaragua has grown considerably recently, and it is now the second largest industry in the nation. Nicaraguan President Daniel Ortega has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Nicaragua's tourism-driven economy have been significant, with the nation welcoming one million tourists in a calendar year for the first time in its history in 2010.
Transport.
Roads.
The Inter-American Highway is the Central American section of the Pan-American Highway, and spans between Nuevo Laredo, Mexico, and Panama City, Panama. Because of the break in the highway known as the Darién Gap, it is not possible to cross between Central America and South America in an automobile.

</doc>
<doc id="6122" url="https://en.wikipedia.org/wiki?curid=6122" title="Continuous function">
Continuous function

In mathematics, a continuous function is, roughly speaking, a function for which sufficiently small changes in the input result in arbitrarily small changes in the output. Otherwise, a function is said to be a "discontinuous" function. A continuous function with a continuous inverse function is called a homeomorphism.
Continuity of functions is one of the core concepts of topology, which is treated in full generality below. The introductory portion of this article focuses on the special case where the inputs and outputs of functions are real numbers. In addition, this article discusses the definition for the more general case of functions between two metric spaces. In order theory, especially in domain theory, one considers a notion of continuity known as Scott continuity. Other forms of continuity do exist but they are not discussed in this article.
As an example, consider the function "h"("t"), which describes the height of a growing flower at time "t". This function is continuous. By contrast, if "M"("t") denotes the amount of money in a bank account at time "t", then the function jumps whenever money is deposited or withdrawn, so the function "M"("t") is discontinuous.
History.
A form of this epsilon-delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of formula_1 as follows: an infinitely small increment formula_2 of the independent variable "x" always produces an infinitely small change formula_3 of the dependent variable "y" (see e.g., "Cours d'Analyse", p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s but the work wasn't published until the 1930s. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.
Real-valued continuous functions.
Definition.
A function from the set of real numbers to the real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve with no "holes" or "jumps". Note that this is not a rigorous definition of continuity since also the function formula_4 is continuous on its whole domain formula_5 although its graph has a “jump” at formula_6. 
A function is "continuous at a point" if it does not have a hole or jump. A “hole” or “jump” in the graph of a function occurs if the value of the function at a point "c" differs from its limiting value along points that are nearby. Such a point is called a "discontinuity". A function is then "continuous" if it has no holes or jumps: that is, if it is continuous at every point of its domain. Otherwise, a function is "discontinuous", at the points where the value of the function differs from its limiting value (if any).
There are several ways to make this definition mathematically rigorous. These definitions are equivalent to one another, so the most convenient definition can be used to determine whether a given function is continuous or not. In the definitions below,
is a function defined on a subset "I" of the set R of real numbers. This subset "I" is referred to as the domain of "f". Some possible choices include "I"=R, the whole set of real numbers, an open interval
Here, "a" and "b" are real numbers.
Definition in terms of limits of functions.
The function "f" is "continuous at some point" "c" of its domain if the limit of "f"("x") as "x" approaches "c" through the domain of "f" exists and is equal to "f"("c"). In mathematical notation, this is written as
In detail this means three conditions: first, "f" has to be defined at "c". Second, the limit on the left hand side of that equation has to exist. Third, the value of this limit must equal "f"("c").
Definition in terms of neighborhoods.
A neighborhood of a point "c" is a set that contains all points of the domain within some fixed distance of "c". Intuitively, a function is continuous at a point "c" if the range of the restriction of "f" to a neighborhood of "c" shrinks to a single point "f"("c") as the width of the neighborhood shrinks to zero. More precisely, a function "f" is continuous at a point "c" of its domain if, for any neighborhood formula_10 there is a neighborhood formula_11 such that formula_12 whenever formula_13.
This definition does only require that the domain and the codomain are topological spaces and is thus the most general definition. From it follows, that the function "f" is automatically continuous at every isolated point of its domain. As a specific example, every real valued function on the set of integers is continuous.
Definition in terms of limits of sequences.
One can instead require that for any sequence formula_14 of points in the domain which converges to "c", the corresponding sequence formula_15 converges to "f"("c"). In mathematical notation, formula_16
Weierstrass definition (epsilon–delta) of continuous functions.
Explicitly including the definition of the limit of a function, we obtain a self-contained definition:
Given a function "f" as above and an element "c" of the domain "I", "f" is said to be continuous at the point "c" if the following holds: For any number "ε" > 0, however small, there exists some number "δ" > 0 such that for all "x" in the domain of "f" with "c" − "δ" < "x" < "c" + "δ", the value of "f"("x") satisfies
Alternatively written, continuity of "f" : "I" → "R" at "c" ∈ "I" means that for every "ε" > 0 there exists a "δ" > 0 such that for all "x" ∈ "I",:
More intuitively, we can say that if we want to get all the "f"("x") values to stay in some small neighborhood around "f"("c"), we simply need to choose a small enough neighborhood for the "x" values around "c", and we can do that no matter how small the "f"("x") neighborhood is; "f" is then continuous at "c".
In modern terms, this is generalized by the definition of continuity of a function with respect to a basis for the topology, here the metric topology.
Definition using oscillation.
Continuity can also be defined in terms of oscillation: a function "f" is continuous at a point "x"0 if and only if its oscillation at that point is zero; in symbols, formula_19 A benefit of this definition is that it "quantifies" discontinuity: the oscillation gives how "much" the function is discontinuous at a point.
This definition is useful in descriptive set theory to study the set of discontinuities and continuous points – the continuous points are the intersection of the sets where the oscillation is less than "ε" (hence a Gδ set) – and gives a very quick proof of one direction of the Lebesgue integrability condition.
The oscillation is equivalent to the "ε"-"δ" definition by a simple re-arrangement, and by using a limit (lim sup, lim inf) to define oscillation: if (at a given point) for a given "ε"0 there is no "δ" that satisfies the "ε"-"δ" definition, then the oscillation is at least "ε"0, and conversely if for every "ε" there is a desired "δ," the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.
Definition using the hyperreals.
Cauchy defined continuity of a function in the following intuitive terms: an infinitesimal change in the independent variable corresponds to an infinitesimal change of the dependent variable (see "Cours d'analyse", page 34). Non-standard analysis is a way of making this mathematically rigorous. The real line is augmented by the addition of infinite and infinitesimal numbers to form the hyperreal numbers. In nonstandard analysis, continuity can be defined as follows.
(see microcontinuity). In other words, an infinitesimal increment of the independent variable always produces to an infinitesimal change of the dependent variable, giving a modern expression to Augustin-Louis Cauchy's definition of continuity.
Examples.
All polynomial functions, such as
(pictured), are continuous. This is a consequence of the fact that, given two continuous functions
defined on the same domain "I", then the sum "f" + "g" and the product "fg" of the two functions are continuous (on the same domain "I"). Moreover, the function
is continuous. (The points where "g"("x") is zero are discarded, as they are not in the domain of "f"/"g".) For example, the function (pictured)
is defined for all real numbers and is continuous at every such point. Thus it is a continuous function. The question of continuity at does not arise, since is not in the domain of "f". There is no continuous function "F": R → R that agrees with "f"("x") for all . The sinc function "g"("x") = (sin "x")/"x", defined for all "x"≠0 is continuous at these points. Thus it is a continuous function, too. However, unlike the one of the previous example, this one "can" be extended to a continuous function on all real numbers, namely
since the limit of "g"("x"), when "x" approaches 0, is 1. Therefore, the point "x"=0 is called a removable singularity of "g".
Given two continuous functions
the composition
is continuous.
Non-examples.
An example of a discontinuous function is the function "f" defined by "f"("x") = 1 if "x" > 0, "f"("x") = 0 if "x" ≤ 0. Pick for instance ε = . There is no δ-neighborhood around "x" = 0 that will force all the "f"("x") values to be within ε of "f"(0). Intuitively we can think of this type of discontinuity as a sudden jump in function values. Similarly, the signum or sign function
is discontinuous at "x" = 0 but continuous everywhere else. Yet another example: the function
is continuous everywhere apart from "x" = 0.
Thomae's function,
is continuous at all irrational numbers and discontinuous at all rational numbers. In a similar vein, Dirichlet's function
is nowhere continuous.
Properties.
Intermediate value theorem.
The intermediate value theorem is an existence theorem, based on the real number property of completeness, and states:
For example, if a child grows from 1 m to 1.5 m between the ages of two and six years, then, at some time between two and six years of age, the child's height must have been 1.25 m.
As a consequence, if "f" is continuous on ["a", "b"] and "f"("a") and "f"("b") differ in sign, then, at some point "c" in ["a", "b"], "f"("c") must equal zero.
Extreme value theorem.
The extreme value theorem states that if a function "f" is defined on a closed interval ["a","b"] (or any closed and bounded set) and is continuous there, then the function attains its maximum, i.e. there exists "c" ∈ ["a","b"] with "f"("c") ≥ "f"("x") for all "x" ∈ ["a","b"]. The same is true of the minimum of "f". These statements are not, in general, true if the function is defined on an open interval ("a","b") (or any set that is not both closed and bounded), as, for example, the continuous function "f"("x") = 1/"x", defined on the open interval (0,1), does not attain a maximum, being unbounded above.
Relation to differentiability and integrability.
Every differentiable function
is continuous, as can be shown. The converse does not hold: for example, the absolute value function
is everywhere continuous. However, it is not differentiable at "x" = 0 (but is so everywhere else). Weierstrass's function is also everywhere continuous but nowhere differentiable.
The derivative "f′"("x") of a differentiable function "f"("x") need not be continuous. If "f′"("x") is continuous, "f"("x") is said to be continuously differentiable. The set of such functions is denoted "C"1(). More generally, the set of functions
(from an open interval (or open subset of R) Ω to the reals) such that "f" is "n" times differentiable and such that the "n"-th derivative of "f" is continuous is denoted "C""n"(Ω). See differentiability class. In the field of computer graphics, these three levels are sometimes called "G"0 (continuity of position), "G"1 (continuity of tangency), and "G"2 (continuity of curvature).
Every continuous function
is integrable (for example in the sense of the Riemann integral). The converse does not hold, as the (integrable, but discontinuous) sign function shows.
Pointwise and uniform limits.
Given a sequence
of functions such that the limit
exists for all "x" in "I", the resulting function "f"("x") is referred to as the pointwise limit of the sequence of functions ("f""n")"n"∈N. The pointwise limit function need not be continuous, even if all functions "f""n" are continuous, as the animation at the right shows. However, "f" is continuous when the sequence converges uniformly, by the uniform convergence theorem. This theorem can be used to show that the exponential functions, logarithms, square root function, trigonometric functions are continuous.
Directional and semi-continuity.
Discontinuous functions may be discontinuous in a restricted way, giving rise to the concept of directional continuity (or right and left continuous functions) and semi-continuity. Roughly speaking, a function is "right-continuous" if no jump occurs when the limit point is approached from the right. Formally, "f" is said to be right-continuous at the point "c" if the following holds: For any number "ε" > 0 however small, there exists some number "δ" > 0 such that for all "x" in the domain with , the value of "f"("x") will satisfy
This is the same condition as for continuous functions, except that it is required to hold for "x" strictly larger than "c" only. Requiring it instead for all "x" with yields the notion of "left-continuous" functions. A function is continuous if and only if it is both right-continuous and left-continuous.
A function "f" is "lower semi-continuous" if, roughly, any jumps that might occur only go down, but not up. That is, for any "ε" > 0, there exists some number "δ" > 0 such that for all "x" in the domain with , the value of "f"("x") satisfies
The reverse condition is "upper semi-continuity".
Continuous functions between metric spaces.
The concept of continuous real-valued functions can be generalized to functions between metric spaces. A metric space is a set "X" equipped with a function (called metric) "d""X", that can be thought of as a measurement of the distance of any two elements in "X". Formally, the metric is a function
that satisfies a number of requirements, notably the triangle inequality. Given two metric spaces ("X", d"X") and ("Y", d"Y") and a function
then "f" is continuous at the point "c" in "X" (with respect to the given metrics) if for any positive real number ε, there exists a positive real number δ such that all "x" in "X" satisfying d"X"("x", "c") < δ will also satisfy d"Y"("f"("x"), "f"("c")) < ε. As in the case of real functions above, this is equivalent to the condition that for every sequence ("x""n") in "X" with limit lim "x""n" = "c", we have lim "f"("x""n") = "f"("c"). The latter condition can be weakened as follows: "f" is continuous at the point "c" if and only if for every convergent sequence ("x""n") in "X" with limit "c", the sequence ("f"("x""n")) is a Cauchy sequence, and "c" is in the domain of "f".
The set of points at which a function between metric spaces is continuous is a Gδ set – this follows from the ε-δ definition of continuity.
This notion of continuity is applied, for example, in functional analysis. A key statement in this area says that a linear operator
between normed vector spaces "V" and "W" (which are vector spaces equipped with a compatible norm, denoted ||"x"||)
is continuous if and only if it is bounded, that is, there is a constant "K" such that
for all "x" in "V".
Uniform, Hölder and Lipschitz continuity.
The concept of continuity for functions between metric spaces can be strengthened in various ways by limiting the way δ depends on ε and "c" in the definition above. Intuitively, a function "f" as above is uniformly continuous if the δ does
not depend on the point "c". More precisely, it is required that for every real number "ε" > 0 there exists "δ" > 0 such that for every "c", "b" ∈ "X" with "d""X"("b", "c") < "δ", we have that "d""Y"("f"("b"), "f"("c")) < "ε". Thus, any uniformly continuous function is continuous. The converse does not hold in general, but holds when the domain space "X" is compact. Uniformly continuous maps can be defined in the more general situation of uniform spaces.
A function is Hölder continuous with exponent α (a real number) if there is a constant "K" such that for all "b" and "c" in "X", the inequality
holds. Any Hölder continuous function is uniformly continuous. The particular case is referred to as Lipschitz continuity. That is, a function is Lipschitz continuous if there is a constant "K" such that the inequality
holds any "b", "c" in "X". The Lipschitz condition occurs, for example, in the Picard–Lindelöf theorem concerning the solutions of ordinary differential equations.
Continuous functions between topological spaces.
Another, more abstract, notion of continuity is continuity of functions between topological spaces in which there generally is no formal notion of distance, as there is in the case of metric spaces. A topological space is a set "X" together with a topology on "X", which is a set of subsets of "X" satisfying a few requirements with respect to their unions and intersections that generalize the properties of the open balls in metric spaces while still allowing to talk about the neighbourhoods of a given point. The elements of a topology are called open subsets of "X" (with respect to the topology).
A function
between two topological spaces "X" and "Y" is continuous if for every open set "V" ⊆ "Y", the inverse image
is an open subset of "X". That is, "f" is a function between the sets "X" and "Y" (not on the elements of the topology "TX"), but the continuity of "f" depends on the topologies used on "X" and "Y".
This is equivalent to the condition that the preimages of the closed sets (which are the complements of the open subsets) in "Y" are closed in "X".
An extreme example: if a set "X" is given the discrete topology (in which every subset is open), all functions
to any topological space "T" are continuous. On the other hand, if "X" is equipped with the indiscrete topology (in which the only open subsets are the empty set and "X") and the space "T" set is at least T0, then the only continuous functions are the constant functions. Conversely, any function whose range is indiscrete is continuous.
Alternative definitions.
Several equivalent definitions for a topological structure exist and thus there are several equivalent ways to define a continuous function.
Neighborhood definition.
Neighborhoods continuity for functions between topological spaces formula_47 and formula_48 at a point may be defined:
A function formula_49 is continuous at a point formula_50 iff for any neighborhood of its image formula_51 the preimage is again a neighborhood of that point: formula_52
According to the property that neighborhood systems being upper sets this can be restated as follows:
formula_53
formula_54
The second one being a restatement involving the image rather than the preimage.
Literally, this means no matter how small the neighborhood is chosen one can always find a neighborhood mapped into it.
Besides, there's a simplification involving only open neighborhoods. In fact, they're equivalent:
formula_55
formula_56
The second one again being a restatement using images rather than preimages.
If "X" and "Y" are metric spaces, it is equivalent to consider the neighborhood system of open balls centered at "x" and "f"("x") instead of all neighborhoods. This gives back the above δ-ε definition of continuity in the context of metric spaces. However, in general topological spaces, there is no notion of nearness or distance.
Note, however, that if the target space is Hausdorff, it is still true that "f" is continuous at "a" if and only if the limit of "f" as "x" approaches "a" is "f"("a"). At an isolated point, every function is continuous.
Sequences and nets.
In several contexts, the topology of a space is conveniently specified in terms of limit points. In many instances, this is accomplished by specifying when a point is the limit of a sequence, but for some spaces that are too large in some sense, one specifies also when a point is the limit of more general sets of points indexed by a directed set, known as nets. A function is (Heine-)continuous only if it takes limits of sequences to limits of sequences. In the former case, preservation of limits is also sufficient; in the latter, a function may preserve all limits of sequences yet still fail to be continuous, and preservation of nets is a necessary and sufficient condition.
In detail, a function "f": "X" → "Y" is sequentially continuous if whenever a sequence ("x""n") in "X" converges to a limit "x", the sequence ("f"("x""n")) converges to "f"("x"). Thus sequentially continuous functions "preserve sequential limits". Every continuous function is sequentially continuous. If "X" is a first-countable space and countable choice holds, then the converse also holds: any function preserving sequential limits is continuous. In particular, if "X" is a metric space, sequential continuity and continuity are equivalent. For non first-countable spaces, sequential continuity might be strictly weaker than continuity. (The spaces for which the two properties are equivalent are called sequential spaces.) This motivates the consideration of nets instead of sequences in general topological spaces. Continuous functions preserve limits of nets, and in fact this property characterizes continuous functions.
Closure operator definition.
Instead of specifying the open subsets of a topological space, the topology can also be determined by a closure operator (denoted cl) which assigns to any subset "A" ⊆ "X" its closure, or an interior operator (denoted int), which assigns to any subset "A" of "X" its interior. In these terms, a function
between topological spaces is continuous in the sense above if and only if for all subsets "A" of "X"
That is to say, given any element "x" of "X" that is in the closure of any subset "A", "f"("x") belongs to the closure of "f"("A"). This is equivalent to the requirement that for all subsets "A"' of "X"'
Moreover,
is continuous if and only if
for any subset "A"' of "Y".
Properties.
If "f": "X" → "Y" and "g": "Y" → "Z" are continuous, then so is the composition "g" ∘ "f": "X" → "Z". If "f": "X" → "Y" is continuous and
The possible topologies on a fixed set "X" are partially ordered: a topology τ1 is said to be coarser than another topology τ2 (notation: τ1 ⊆ τ2) if every open subset with respect to τ1 is also open with respect to τ2. Then, the identity map
is continuous if and only if τ1 ⊆ τ2 (see also comparison of topologies). More generally, a continuous function
stays continuous if the topology τ"Y" is replaced by a coarser topology and/or τ"X" is replaced by a finer topology.
Homeomorphisms.
Symmetric to the concept of a continuous map is an open map, for which "images" of open sets are open. In fact, if an open map "f" has an inverse function, that inverse is continuous, and if a continuous map "g" has an inverse, that inverse is open. Given a bijective function "f" between two topological spaces, the inverse function "f"−1 need not be continuous. A bijective continuous function with continuous inverse function is called a "homeomorphism".
If a continuous bijection has as its domain a compact space and its codomain is Hausdorff, then it is a homeomorphism.
Defining topologies via continuous functions.
Given a function
where "X" is a topological space and "S" is a set (without a specified topology), the final topology on "S" is defined by letting the open sets of "S" be those subsets "A" of "S" for which "f"−1("A") is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is coarser than the final topology on "S". Thus the final topology can be characterized as the finest topology on "S" that makes "f" continuous. If "f" is surjective, this topology is canonically identified with the quotient topology under the equivalence relation defined by "f".
Dually, for a function "f" from a set "S" to a topological space, the initial topology on "S" has as open subsets "A" of "S" those subsets for which "f"("A") is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is finer than the initial topology on "S". Thus the initial topology can be characterized as the coarsest topology on "S" that makes "f" continuous. If "f" is injective, this topology is canonically identified with the subspace topology of "S", viewed as a subset of "X".
More generally, given a set "S", specifying the set of continuous functions
into all topological spaces "X" defines a topology. Dually, a similar idea can be applied to maps
This is an instance of a universal property.
Related notions.
Various other mathematical domains use the concept of continuity in different, but related meanings. For example, in order theory, an order-preserving function "f": "X" → "Y" between particular types of partially ordered sets "X" and "Y" is continuous if for each directed subset "A" of "X", we have sup("f"("A")) = "f"(sup("A")). Here sup is the supremum with respect to the orderings in "X" and "Y", respectively. This notion of continuity is the same as topological continuity when the partially ordered sets are given the Scott topology.
In category theory, a functor
between two categories is called "continuous", if it commutes with small limits. That is to say,
for any small (i.e., indexed by a set "I", as opposed to a class) diagram of objects in formula_68.
A "continuity space" is a generalization of metric spaces and posets, which uses the concept of quantales, and that can be used to unify the notions of metric spaces and domains.

</doc>
<doc id="6123" url="https://en.wikipedia.org/wiki?curid=6123" title="Curl (mathematics)">
Curl (mathematics)

In vector calculus, the curl is a vector operator that describes the infinitesimal rotation of a 3-dimensional vector field. At every point in the field, the curl of that point is represented by a vector. The attributes of this vector (length and direction) characterize the rotation at that point.
The direction of the curl is the axis of rotation, as determined by the right-hand rule, and the magnitude of the curl is the magnitude of rotation. If the vector field represents the flow velocity of a moving fluid, then the curl is the circulation density of the fluid. A vector field whose curl is zero is called irrotational.
The curl is a form of differentiation for vector fields. The corresponding form of the fundamental theorem of calculus is Stokes' theorem, which relates the surface integral of the curl of a vector field to the line integral of the vector field around the boundary curve.
The alternative terminology "rotor" or "rotational" and alternative notations rot F and ∇ × F are often used (the former especially in many European countries, the latter, using the del operator and the cross product, is more used in other countries) for "curl" and curl F.
Unlike the gradient and divergence, curl does not generalize as simply to other dimensions; some generalizations are possible, but only in three dimensions is the geometrically defined curl of a vector field again a vector field. This is a similar phenomenon as in the 3 dimensional cross product, and the connection is reflected in the notation ∇ × for the curl.
The name "curl" was first suggested by James Clerk Maxwell in 1871 but the concept was apparently first used in the construction of an optical field theory by James MacCullagh in 1839.
Definition.
The curl of a vector field F, denoted by curl F, or ∇ × F, or rot F, at a point is defined in terms of its projection onto various lines through the point. If formula_1 is any unit vector, the projection of the curl of F onto formula_1 is defined to be the limiting value of a closed line integral in a plane orthogonal to formula_1 as the path used in the integral becomes infinitesimally close to the point, divided by the area enclosed.
As such, the curl operator maps continuously differentiable functions f : R3 → R3 to continuous functions g : R3 → R3. In fact, it maps "C"k functions in R3 to "C"k-1 functions in R3. 
Implicitly, curl is defined by:
where formula_5 is a line integral along the boundary of the area in question, and |"A"| is the magnitude of the area. If formula_6 is an outward pointing in-plane normal, whereas formula_1 is the unit vector perpendicular to the plane (see caption at right), then the orientation of C is chosen so that a tangent vector formula_8 to C is positively oriented if and only if formula_9 forms a positively oriented basis for R3 (right-hand rule).
The above formula means that the curl of a vector field is defined as the infinitesimal area density of the "circulation" of that field. To this definition fit naturally 
Note that the equation for each component, formula_13 can be obtained by exchanging each occurrence of a subscript 1, 2, 3 in cyclic permutation: 1→2, 2→3, and 3→1 (where the subscripts represent the relevant indices).
If ("x"1, "x"2, "x"3) are the Cartesian coordinates and ("u"1,"u"2,"u"3) are the orthogonal coordinates, then 
is the length of the coordinate vector corresponding to "ui". The remaining two components of curl result from cyclic permutation of indices: 3,1,2 → 1,2,3 → 2,3,1.
Intuitive interpretation.
Suppose the vector field describes the velocity field of a fluid flow (such as a large tank of liquid or gas) and a small ball is located within the fluid or gas (the centre of the ball being fixed at a certain point). If the ball has a rough surface, the fluid flowing past it will make it rotate. The rotation axis (oriented according to the right hand rule) points in the direction of the curl of the field at the centre of the ball, and the angular speed of the rotation is half the magnitude of the curl at this point.
Usage.
In practice, the above definition is rarely used because in virtually all cases, the curl operator can be applied using some set of curvilinear coordinates, for which simpler representations have been derived.
The notation ∇ × F has its origins in the similarities to the 3 dimensional cross product, and it is useful as a mnemonic in Cartesian coordinates if ∇ is taken as a vector differential operator del. Such notation involving operators is common in physics and algebra. However, in certain coordinate systems, such as polar-toroidal coordinates (common in plasma physics), using the notation ∇ × F will yield an incorrect result.
Expanded in Cartesian coordinates (see Del in cylindrical and spherical coordinates for spherical and cylindrical coordinate representations), ∇ × F is, for F composed of ["F"x, "F"y, "F"z]:
where i, j, and k are the unit vectors for the "x"-, "y"-, and "z"-axes, respectively. This expands as follows:
Although expressed in terms of coordinates, the result is invariant under proper rotations of the coordinate axes but the result inverts under reflection.
In a general coordinate system, the curl is given by
where ε denotes the Levi-Civita tensor and formula_18 the covariant derivative, the metric tensor is used to lower the index on F, and the Einstein summation convention implies that repeated indices are summed over. Equivalently,
where e"k" are the coordinate vector fields. Equivalently, using the exterior derivative, the curl can be expressed as:
Here formula_21 and formula_22 are the musical isomorphisms, and formula_23 is the Hodge dual. This formula shows how to calculate the curl of F in any coordinate system, and how to extend the curl to any oriented three-dimensional Riemannian manifold. Since this depends on a choice of orientation, curl is a chiral operation. In other words, if the orientation is reversed, then the direction of the curl is also reversed.
Examples.
A simple vector field.
Take the vector field, which depends on "x" and "y" linearly:
Its plot looks like this:
Simply by visual inspection, we can see that the field is rotating. If we place a paddle wheel anywhere, we see immediately its tendency to rotate clockwise. Using the right-hand rule, we expect the curl to be into the page. If we are to keep a right-handed coordinate system, into the page will be in the negative z direction. The lack of x and y directions is analogous to the cross product operation.
If we calculate the curl:
Which is indeed in the negative "z" direction, as expected. In this case, the curl is actually a constant, irrespective of position. The "amount" of rotation in the above vector field is the same at any point ("x", "y"). Plotting the curl of "F" is not very interesting:
A more involved example.
Suppose we now consider a slightly more complicated vector field:
Its plot:
We might not see any rotation initially, but if we closely look at the right, we see a larger field at, say, x=4 than at x=3. Intuitively, if we placed a small paddle wheel there, the larger "current" on its right side would cause the paddlewheel to rotate clockwise, which corresponds to a curl in the negative z direction. By contrast, if we look at a point on the left and placed a small paddle wheel there, the larger "current" on its left side would cause the paddlewheel to rotate counterclockwise, which corresponds to a curl in the positive z direction. Let's check out our guess by doing the math:
Indeed, the curl is in the positive z direction for negative x and in the negative z direction for positive x, as expected. Since this curl is not the same at every point, its plot is a bit more interesting:
We note that the plot of this curl has no dependence on y or z (as it shouldn't) and is in the negative z direction for positive x and in the positive z direction for negative x.
Identities.
In general curvilinear coordinates (not only in Cartesian coordinates), the curl of a cross product of vector fields v and F can be shown to be
Interchanging the vector field v and ∇ operator, we arrive at the cross product of a vector field with curl of a vector field:
using the Feynman subscript notation, ∇F, which operates only on the vector field F.
Another example is the curl of a curl of a vector field. It can be shown that in general coordinates
and this identity defines the vector Laplacian of F, symbolized as ∇2F.
The curl of the gradient of "any" scalar field φ is always the zero vector field
which follows from the antisymmetry in the definition of the curl, and the symmetry of second derivatives.
If φ is a scalar valued function and F is a vector field, then
Generalizations.
The vector calculus operations of grad, curl, and div are most easily generalized and understood in the context of differential forms, which involves a number of steps. In a nutshell, they correspond to the derivatives of 0-forms, 1-forms, and 2-forms, respectively. The geometric interpretation of curl as rotation corresponds to identifying bivectors (2-vectors) in 3 dimensions with the special orthogonal Lie algebra so(3) of infinitesimal rotations (in coordinates, skew-symmetric 3 × 3 matrices), while representing rotations by vectors corresponds to identifying 1-vectors (equivalently, 2-vectors) and so(3), these all being 3-dimensional spaces.
Differential forms.
In 3 dimensions, a differential 0-form is simply a function "f"("x", "y", "z"); a differential 1-form is the following expression: formula_33 a differential 2-form is the formal sum: formula_34 and a differential 3-form is defined by a single term: formula_35 (Here the a-coefficients are real functions; the "wedge products", e.g. formula_36 can be interpreted as some kind of oriented area elements, formula_37, etc.) The exterior derivative of a "k"-form in R3 is defined as the ("k"+1)-form from above (and in R"n" if, e.g.,
then the exterior derivative "d" leads to
The exterior derivative of a 1-form is therefore a 2-form, and that of a 2-form is a 3-form. On the other hand, because of the interchangeability of mixed derivatives, e.g. because of
the twofold application of the exterior derivative leads to 0.
Thus, denoting the space of "k"-forms by formula_41 and the exterior derivative by "d" one gets a sequence:
Here formula_43 is the space of sections of the exterior algebra formula_44 vector bundle over Rn, whose dimension is the binomial coefficient formula_45 note that formula_46 for "k" > 3 or "k" < 0. Writing only dimensions, one obtains a row of Pascal's triangle:
the 1-dimensional fibers correspond to functions, and the 3-dimensional fibers to vector fields, as described below. Note that modulo suitable identifications, the three nontrivial occurrences of the exterior derivative correspond to grad, curl, and div.
Differential forms and the differential can be defined on any Euclidean space, or indeed any manifold, without any notion of a Riemannian metric. On a Riemannian manifold, or more generally pseudo-Riemannian manifold, "k"-forms can be identified with "k"-vector fields ("k"-forms are "k"-covector fields, and a pseudo-Riemannian metric gives an isomorphism between vectors and covectors), and on an "oriented" vector space with a nondegenerate form (an isomorphism between vectors and covectors), there is an isomorphism between "k"-vectors and ("n"−"k")-vectors; in particular on (the tangent space of) an oriented pseudo-Riemannian manifold. Thus on an oriented pseudo-Riemannian manifold, one can interchange "k"-forms, "k"-vector fields, ("n"−"k")-forms, and ("n"−"k")-vector fields; this is known as Hodge duality. Concretely, on R3 this is given by:
Thus, identifying 0-forms and 3-forms with functions, and 1-forms and 2-forms with vector fields:
On the other hand, the fact that "d"2 = 0 corresponds to the identities curl grad "f" = 0 and formula_54 for any function "f" or vector field formula_55
Grad and div generalize to all oriented pseudo-Riemannian manifolds, with the same geometric interpretation, because the spaces of 0-forms and "n"-forms is always (fiberwise) 1-dimensional and can be identified with scalar functions, while the spaces of 1-forms and ("n"−1)-forms are always fiberwise "n"-dimensional and can be identified with vector fields.
Curl does not generalize in this way to 4 or more dimensions (or down to 2 or fewer dimensions); in 4 dimensions the dimensions are
so the curl of a 1-vector field (fiberwise 4-dimensional) is a "2-vector field", which is fiberwise 6-dimensional, one has
which yields a sum of six independent terms, and cannot be identified with a 1-vector field. Nor can one meaningfully go from a 1-vector field to a 2-vector field to a 3-vector field (4 → 6 → 4), as taking the differential twice yields zero ("d"2 = 0). Thus there is no curl function from vector fields to vector fields in other dimensions arising in this way.
However, one can define a curl of a vector field as a "2-vector field" in general, as described below.
Curl geometrically.
2-vectors correspond to the exterior power Λ2"V"; in the presence of an inner product, in coordinates these are the skew-symmetric matrices, which are geometrically considered as the special orthogonal Lie algebra so("V") of infinitesimal rotations. This has formula_57 dimensions, and allows one to interpret the differential of a 1-vector field as its infinitesimal rotations. Only in 3 dimensions (or trivially in 0 dimensions) is formula_58 which is the most elegant and common case. In 2 dimensions the curl of a vector field is not a vector field but a function, as 2-dimensional rotations are given by an angle (a scalar - an orientation is required to choose whether one counts clockwise or counterclockwise rotations as positive); note that this is not the div, but is rather perpendicular to it. In 3 dimensions the curl of a vector field is a vector field as is familiar (in 1 and 0 dimensions the curl of a vector field is 0, because there are no non-trivial 2-vectors), while in 4 dimensions the curl of a vector field is, geometrically, at each point an element of the 6-dimensional Lie algebra so(4).
Note also that the curl of a 3-dimensional vector field which only depends on 2 coordinates (say "x, y") is simply a vertical vector field (in the "z" direction) whose magnitude is the curl of the 2-dimensional vector field, as in the examples on this page.
Considering curl as a 2-vector field (an antisymmetric 2-tensor) has been used to generalize vector calculus and associated physics to higher dimensions.

</doc>
<doc id="6125" url="https://en.wikipedia.org/wiki?curid=6125" title="Carl Friedrich Gauss">
Carl Friedrich Gauss

Johann Carl Friedrich Gauss (; , ; ) (30 April 177723 February 1855) was a German mathematician who contributed significantly to many fields, including number theory, algebra, statistics, analysis, differential geometry, geodesy, geophysics, mechanics, electrostatics, astronomy, matrix theory, and optics.
Sometimes referred to as the "Princeps mathematicorum" (Latin, "the foremost of mathematicians") and "greatest mathematician since antiquity", Gauss had an exceptional influence in many fields of mathematics and science and is ranked as one of history's most influential mathematicians.
Early years.
Carl Friedrich Gauss was born on 30 April 1777 in Brunswick (Braunschweig), in the Duchy of Brunswick-Wolfenbüttel (now part of Lower Saxony, Germany), as the son of poor working-class parents. His mother was illiterate and never recorded the date of his birth, remembering only that he had been born on a Wednesday, eight days before the Feast of the Ascension, which itself occurs 39 days after Easter. Gauss later solved this puzzle about his birthdate in the context of finding the date of Easter, deriving methods to compute the date in both past and future years. He was christened and confirmed in a church near the school he attended as a child.
Gauss was a child prodigy. A contested story relates that, when he was eight, he figured out how to add up all the numbers from 1 to 100. There are many other anecdotes about his precocity while a toddler, and he made his first ground-breaking mathematical discoveries while still a teenager. He completed "Disquisitiones Arithmeticae", his magnum opus, in 1798 at the age of 21, though it was not published until 1801. This work was fundamental in consolidating number theory as a discipline and has shaped the field to the present day.
Gauss's intellectual abilities attracted the attention of the Duke of Brunswick, who sent him to the Collegium Carolinum (now Braunschweig University of Technology), which he attended from 1792 to 1795, and to the University of Göttingen from 1795 to 1798.
While at university, Gauss independently rediscovered several important theorems. His breakthrough occurred in 1796 when he showed that a regular polygon can be constructed by compass and straightedge if and only if the number of sides is the product of distinct Fermat primes and a power of 2. This was a major discovery in an important field of mathematics; construction problems had occupied mathematicians since the days of the Ancient Greeks, and the discovery ultimately led Gauss to choose mathematics instead of philology as a career.
Gauss was so pleased by this result that he requested that a regular heptadecagon be inscribed on his tombstone. The stonemason declined, stating that the difficult construction would essentially look like a circle.
The year 1796 was most productive for both Gauss and number theory. He discovered a construction of the heptadecagon on 30 March. He further advanced modular arithmetic, greatly simplifying manipulations in number theory. On 8 April he became the first to prove the quadratic reciprocity law. This remarkably general law allows mathematicians to determine the solvability of any quadratic equation in modular arithmetic. The prime number theorem, conjectured on 31 May, gives a good understanding of how the prime numbers are distributed among the integers.
Gauss also discovered that every positive integer is representable as a sum of at most three triangular numbers on 10 July and then jotted down in his diary the note: "ΕΥΡΗΚΑ! num = Δ + Δ + Δ". On October 1 he published a result on the number of solutions of polynomials with coefficients in finite fields, which 150 years later led to the Weil conjectures.
Middle years.
Algebra.
In his 1799 doctorate in absentia, "A new proof of the theorem that every integral rational algebraic function of one variable can be resolved into real factors of the first or second degree", Gauss proved the fundamental theorem of algebra which states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. Mathematicians including Jean le Rond d'Alembert had produced false proofs before him, and Gauss's dissertation contains a critique of d'Alembert's work. Ironically, by today's standard, Gauss's own attempt is not acceptable, owing to implicit use of the Jordan curve theorem. However, he subsequently produced three other proofs, the last one in 1849 being generally rigorous. His attempts clarified the concept of complex numbers considerably along the way.
Gauss also made important contributions to number theory with his 1801 book "Disquisitiones Arithmeticae" (Latin, Arithmetical Investigations), which, among other things, introduced the symbol ≡ for congruence and used it in a clean presentation of modular arithmetic, contained the first two proofs of the law of quadratic reciprocity, developed the theories of binary and ternary quadratic forms, stated the class number problem for them, and showed that a regular heptadecagon (17-sided polygon) can be constructed with straightedge and compass.
Astronomy.
In the same year, Italian astronomer Giuseppe Piazzi discovered the dwarf planet Ceres. Piazzi could only track Ceres for somewhat more than a month, following it for three degrees across the night sky. Then it disappeared temporarily behind the glare of the Sun. Several months later, when Ceres should have reappeared, Piazzi could not locate it: the mathematical tools of the time were not able to extrapolate a position from such a scant amount of data—three degrees represent less than 1% of the total orbit.
Gauss, who was 24 at the time, heard about the problem and tackled it. After three months of intense work, he predicted a position for Ceres in December 1801—just about a year after its first sighting—and this turned out to be accurate within a half-degree when it was rediscovered by Franz Xaver von Zach on 31 December at Gotha, and one day later by Heinrich Olbers in Bremen.
Gauss's method involved determining a conic section in space, given one focus (the Sun) and the conic's intersection with three given lines (lines of sight from the Earth, which is itself moving on an ellipse, to the planet) and given the time it takes the planet to traverse the arcs determined by these lines (from which the lengths of the arcs can be calculated by Kepler's Second Law). This problem leads to an equation of the eighth degree, of which one solution, the Earth's orbit, is known. The solution sought is then separated from the remaining six based on physical conditions. In this work Gauss used comprehensive approximation methods which he created for that purpose.
One such method was the fast Fourier transform. While this method is traditionally attributed to a 1965 paper by J. W. Cooley and J. W. Tukey, Gauss developed it as a trigonometric interpolation method. His paper, "Theoria Interpolationis Methodo Nova Tractata", was only published posthumously in Volume 3 of his collected works. This paper predates the first presentation by Joseph Fourier on the subject in 1807.
Zach noted that "without the intelligent work and calculations of Doctor Gauss we might not have found Ceres again". Though Gauss had up to that point been financially supported by his stipend from the Duke, he doubted the security of this arrangement, and also did not believe pure mathematics to be important enough to deserve support. Thus he sought a position in astronomy, and in 1807 was appointed Professor of Astronomy and Director of the astronomical observatory in Göttingen, a post he held for the remainder of his life.
The discovery of Ceres led Gauss to his work on a theory of the motion of planetoids disturbed by large planets, eventually published in 1809 as "Theoria motus corporum coelestium in sectionibus conicis solem ambientum" (Theory of motion of the celestial bodies moving in conic sections around the Sun). In the process, he so streamlined the cumbersome mathematics of 18th century orbital prediction that his work remains a cornerstone of astronomical computation. It introduced the Gaussian gravitational constant, and contained an influential treatment of the method of least squares, a procedure used in all sciences to this day to minimize the impact of measurement error.
Gauss proved the method under the assumption of normally distributed errors (see Gauss–Markov theorem; see also Gaussian). The method had been described earlier by Adrien-Marie Legendre in 1805, but Gauss claimed that he had been using it since 1794 or 1795. In the history of statistics, this disagreement is called the "priority dispute over the discovery of the method of least squares."
Geodesic survey.
In 1818 Gauss, putting his calculation skills to practical use, carried out a geodesic survey of the Kingdom of Hanover, linking up with previous Danish surveys. To aid the survey, Gauss invented the heliotrope, an instrument that uses a mirror to reflect sunlight over great distances, to measure positions.
Non-Euclidean geometries.
Gauss also claimed to have discovered the possibility of non-Euclidean geometries but never published it. This discovery was a major paradigm shift in mathematics, as it freed mathematicians from the mistaken belief that Euclid's axioms were the only way to make geometry consistent and non-contradictory.
Research on these geometries led to, among other things, Einstein's theory of general relativity, which describes the universe as non-Euclidean. His friend Farkas Wolfgang Bolyai with whom Gauss had sworn "brotherhood and the banner of truth" as a student, had tried in vain for many years to prove the parallel postulate from Euclid's other axioms of geometry.
Bolyai's son, János Bolyai, discovered non-Euclidean geometry in 1829; his work was published in 1832. After seeing it, Gauss wrote to Farkas Bolyai: ""To praise it would amount to praising myself. For the entire content of the work ... coincides almost exactly with my own meditations which have occupied my mind for the past thirty or thirty-five years.""
This unproved statement put a strain on his relationship with Bolyai who thought that Gauss was "stealing" his idea.
Letters from Gauss years before 1829 reveal him obscurely discussing the problem of parallel lines. Waldo Dunnington, a biographer of Gauss, argues in "Gauss, Titan of Science" that Gauss was in fact in full possession of non-Euclidean geometry long before it was published by Bolyai, but that he refused to publish any of it because of his fear of controversy.
Theorema Egregium.
The geodetic survey of Hanover, which required Gauss to spend summers traveling on horseback for a decade, fueled Gauss's interest in differential geometry and topology, fields of mathematics dealing with curves and surfaces. Among other things he came up with the notion of Gaussian curvature. 
This led in 1828 to an important theorem, the Theorema Egregium ("remarkable theorem"), establishing an important property of the notion of curvature. Informally, the theorem says that the curvature of a surface can be determined entirely by measuring angles and distances on the surface.
That is, curvature does not depend on how the surface might be embedded in 3-dimensional space or 2-dimensional space.
In 1821, he was made a foreign member of the Royal Swedish Academy of Sciences.
Later years and death.
In 1831 Gauss developed a fruitful collaboration with the physics professor Wilhelm Weber, leading to new knowledge in magnetism (including finding a representation for the unit of magnetism in terms of mass, charge, and time) and the discovery of Kirchhoff's circuit laws in electricity. It was during this time that he formulated his namesake law. They constructed the first electromechanical telegraph in 1833, which connected the observatory with the institute for physics in Göttingen. Gauss ordered a magnetic observatory to be built in the garden of the observatory, and with Weber founded the "Magnetischer Verein" ("magnetic club" in German), which supported measurements of Earth's magnetic field in many regions of the world. He developed a method of measuring the horizontal intensity of the magnetic field which was in use well into the second half of the 20th century, and worked out the mathematical theory for separating the inner and outer (magnetospheric) sources of Earth's magnetic field.
In 1840, Gauss published his influential "Dioptrische Untersuchungen", in which he gave the first systematic analysis on the formation of images under a paraxial approximation (Gaussian optics). Among his results, Gauss showed that under a paraxial approximation an optical system can be characterized by its cardinal points and he derived the Gaussian lens formula.
In 1845, he became associated member of the Royal Institute of the Netherlands; when that became the Royal Netherlands Academy of Arts and Sciences in 1851, he joined as a foreign member.
In 1854, Gauss selected the topic for Bernhard Riemann's Habilitationvortrag, "Über die Hypothesen, welche der Geometrie zu Grunde liegen". On the way home from Riemann's lecture, Weber reported that Gauss was full of praise and excitement.
Gauss died in Göttingen, in the Kingdom of Hanover (now part of Lower Saxony, Germany) on 23 February 1855 and is interred in the Albanifriedhof cemetery there. Two individuals gave eulogies at his funeral: Gauss's son-in-law Heinrich Ewald and Wolfgang Sartorius von Waltershausen, who was Gauss's close friend and biographer. His brain was preserved and was studied by Rudolf Wagner who found its mass to be 1,492 grams (slightly above average) and the cerebral area equal to 219,588 square millimeters (340.362 square inches). Highly developed convolutions were also found, which in the early 20th century was suggested as the explanation of his genius.
Religious views.
Gauss was a Lutheran Protestant, a member of the St. Albans Evangelical Lutheran church in Göttingen. Potential evidence that Gauss believed in God comes from his response after solving a problem that had previously stumped him: "Finally, two days ago, I succeeded— not on account of my hard efforts, but by the grace of the Lord." One of his biographers G. Waldo Dunnington describes Gauss's religious views in these terms:
For him science was the means of exposing the immortal nucleus of the human soul. In the days of his full strength it furnished him recreation and, by the prospects which it opened up to him, gave consolation. Toward the end of his life it brought him confidence. Gauss' God was not a cold and distant figment of metaphysics, nor a distorted caricature of embittered theology. To man is not vouchsafed that fullness of knowledge which would warrant his arrogantly holding that his blurred vision is the full light and that there can be none other which might report truth as does his. For Gauss, not he who mumbles his creed, but he who lives it, is accepted. He believed that a life worthily spent here on earth is the best, the only, preparation for heaven. Religion is not a question of literature, but of life. God's revelation is continuous, not contained in tablets of stone or sacred parchment. A book is inspired when it inspires. The unshakeable idea of personal continuance after death, the firm belief in a last regulator of things, in an eternal, just, omniscient, omnipotent God, formed the basis of his religious life, which harmonized completely with his scientific research.
Apart from his correspondence, there are not many known details about Gauss' personal creed. Many biographers of Gauss disagree with his religious stance, with Bühler and others considering him a deist with very unorthodox views, while Dunnington (though admitting that Gauss did not believe literally in all Christian dogmas and that it is unknown what he believed on most doctrinal and confessional questions) points out that he was, at least, a nominal Lutheran.
In connection to this, there's a record of a conversation between Rudolf Wagner and Gauss, in which they discussed William Whewell's book "Of the Plurality of Worlds". In this work, Whewell had discarded the possibility of existing life in other planets, on the basis of theological arguments, but this was a position with which both Wagner and Gauss disagreed. Later Wagner explained that he did not fully believe in the Bible, though he confessed that he "envied" those who were able to easily believe. This later led them to discuss the topic of faith, and in some other religious remarks, Gauss said that he had been more influenced by theologians like Lutheran minister Paul Gerhardt than by Moses. Other religious influences included Wilhelm Braubach, Johann Peter Süssmilch, and the New Testament.
Dunnington further elaborates on Gauss's religious views by writing: Gauss' religious consciousness was based on an insatiable thirst for truth and a deep feeling of justice extending to intellectual as well as material goods. He conceived spiritual life in the whole universe as a great system of law penetrated by eternal truth, and from this source he gained the firm confidence that death does not end all.
Gauss declared he firmly believed in the afterlife, and saw spirituality as something essentially important for human beings. He was quoted stating: ""The world would be nonsense, the whole creation an absurdity without immortality,"" and for this statement he was severely criticized by the atheist Eugen Dühring who judged him as a narrow superstitious man.
Though he was not a church-goer, Gauss strongly upheld religious tolerance, believing "that one is not justified in disturbing another's religious belief, in which they find consolation for earthly sorrows in time of trouble." When his son Eugene announced that he wanted to become a Christian missionary, Gauss approved of this, saying that regardless of the problems within religious organizations, missionary work was "a highly honorable" task.
Family.
Gauss's personal life was overshadowed by the early death of his first wife, Johanna Osthoff, in 1809, soon followed by the death of one child, Louis. Gauss plunged into a depression from which he never fully recovered. He married again, to Johanna's best friend, Friederica Wilhelmine Waldeck, commonly known as Minna. When his second wife died in 1831 after a long illness, one of his daughters, Therese, took over the household and cared for Gauss for the rest of his life. His mother lived in his house from 1817 until her death in 1839.
Gauss had six children. With Johanna (1780–1809), his children were Joseph (1806–1873), Wilhelmina (1808–1846) and Louis (1809–1810). With Minna Waldeck he also had three children: Eugene (1811–1896), Wilhelm (1813–1879) and Therese (1816–1864). Eugene shared a good measure of Gauss's talent in languages and computation. Therese kept house for Gauss until his death, after which she married.
Gauss eventually had conflicts with his sons. He did not want any of his sons to enter mathematics or science for "fear of lowering the family name", as he believed none of them would surpass his own achievements. Gauss wanted Eugene to become a lawyer, but Eugene wanted to study languages. They had an argument over a party Eugene held, which Gauss refused to pay for. The son left in anger and, in about 1832, emigrated to the United States, where he was quite successful. While working for the American Fur Company in the Midwest, he learned the Sioux language. Later, he moved to Missouri and became a successful businessman. Wilhelm also moved to America in 1837 and settled in Missouri, starting as a farmer and later becoming wealthy in the shoe business in St. Louis. It took many years for Eugene's success to counteract his reputation among Gauss's friends and colleagues. See also on 3 September 1912.
Personality.
Carl Gauss was an ardent perfectionist and a hard worker. He was never a prolific writer, refusing to publish work which he did not consider complete and above criticism. This was in keeping with his personal motto "pauca sed matura" ("few, but ripe"). His personal diaries indicate that he had made several important mathematical discoveries years or decades before his contemporaries published them. Mathematical historian Eric Temple Bell said that had Gauss published all of his discoveries in a timely manner, he would have advanced mathematics by fifty years.
Though he did take in a few students, Gauss was known to dislike teaching. It is said that he attended only a single scientific conference, which was in Berlin in 1828. However, several of his students became influential mathematicians, among them Richard Dedekind and Bernhard Riemann. 
On Gauss's recommendation, Friedrich Bessel was awarded an honorary doctor degree from Göttingen in March 1811. Around that time, the two men engaged in an epistolary correspondence. However, when they met in person in 1825, they quarrelled; the details are not known.
Before she died, Sophie Germain was recommended by Gauss to receive her honorary degree; it was eventually conferred upon her six years after she died.
Gauss usually declined to present the intuition behind his often very elegant proofs—he preferred them to appear "out of thin air" and erased all traces of how he discovered them. This is justified, if unsatisfactorily, by Gauss in his "Disquisitiones Arithmeticae", where he states that all analysis (i.e., the paths one travelled to reach the solution of a problem) must be suppressed for sake of brevity.
Gauss supported the monarchy and opposed Napoleon, whom he saw as an outgrowth of revolution.
Anecdotes.
There are several stories of his early genius. According to one, his gifts became very apparent at the age of three when he corrected, mentally and without fault in his calculations, an error his father had made on paper while calculating finances.
Another story has it that in primary school after the young Gauss misbehaved, his teacher, J.G. Büttner, gave him a task: add a list of integers in arithmetic progression; as the story is most often told, these were the numbers from 1 to 100. The young Gauss reputedly produced the correct answer within seconds, to the astonishment of his teacher and his assistant Martin Bartels.
Gauss's presumed method was to realize that pairwise addition of terms from opposite ends of the list yielded identical intermediate sums: 1 + 100 = 101, 2 + 99 = 101, 3 + 98 = 101, and so on, for a total sum of 50 × 101 = 5050.
However, the details of the story are at best uncertain (see for discussion of the original Wolfgang Sartorius von Waltershausen source and the changes in other versions); some authors, such as Joseph Rotman in his book "A first course in Abstract Algebra", question whether it ever happened.
According to Isaac Asimov, Gauss was once interrupted in the middle of a problem and told that his wife was dying. He is purported to have said, "Tell her to wait a moment till I'm done." This anecdote is briefly discussed in G. Waldo Dunnington's "Gauss, Titan of Science" where it is suggested that it is an apocryphal story.
He referred to mathematics as "the queen of sciences" and supposedly once espoused a belief in the necessity of immediately understanding Euler's identity as a benchmark pursuant to becoming a first-class mathematician.
Commemorations.
From 1989 through 2001, Gauss's portrait, a normal distribution curve and some prominent Göttingen buildings were featured on the German ten-mark banknote. The reverse featured the approach for Hanover. Germany has also issued three postage stamps honoring Gauss. One (no. 725) appeared in 1955 on the hundredth anniversary of his death; two others, nos. 1246 and 1811, in 1977, the 200th anniversary of his birth.
Daniel Kehlmann's 2005 novel "Die Vermessung der Welt", translated into English as "Measuring the World" (2006), explores Gauss's life and work through a lens of historical fiction, contrasting them with those of the German explorer Alexander von Humboldt. A film version directed by Detlev Buck was released in 2012.
In 2007 a bust of Gauss was placed in the Walhalla temple.
Things named in honor of Gauss include:
In 1929 the Polish mathematician Marian Rejewski, who helped to solve the German Enigma cipher machine in December 1932, began studying actuarial statistics at Göttingen. At the request of his Poznań University professor, Zdzisław Krygowski, on arriving at Göttingen Rejewski laid flowers on Gauss's grave.
Writings.
Gauss's collective works are online at dz-srv1.sub.uni-goettingen.de Uni-goettingen.de includes German translations of Latin texts and commentaries by various authorities.

</doc>
<doc id="6130" url="https://en.wikipedia.org/wiki?curid=6130" title="Cornish language">
Cornish language

Cornish (' or ') is a Southwestern Brittonic Celtic language historically spoken by the Cornish people. The language has undergone a revival in recent decades and is considered to be an important part of Cornish identity, culture and heritage. It is a recognised minority language of the United Kingdom, protected under the European Charter for Regional or Minority Languages, and has a growing number of speakers.
Along with Welsh and Breton, Cornish is descended directly from the Common Brittonic language spoken throughout much of Britain before the English language came to dominate. It was the main language of Cornwall for centuries until it was pushed westwards by English, maintaining close links with its sister language Brezhoneg with which it was mutually intelligible until well into the Middle Ages. Cornish continued to function as a common community language in parts of Cornwall until the late 18th century, and continued to be spoken in the home by some families into the 19th and possibly 20th centuries, overlapping the beginning of revival efforts. A process to revive the language was begun in the early 20th century, with a number of orthographical systems in use until a Standard Written Form was agreed upon in 2008. In 2010 UNESCO announced that its former classification of the language as "extinct" was "no longer accurate".
Since the revival of the language, many Cornish textbooks and works of literature have been published and an increasing number of people are studying the language. Recent developments include Cornish music, independent films, and children's books. A small number of people in Cornwall have been brought up to be bilingual native speakers, and the language is taught in many schools. The first Cornish language crèche opened in 2010.
Classification.
Cornish is one of the Brittonic languages, which constitute a branch of the Insular Celtic section of the Celtic language family. Brittonic also includes Welsh, Breton and the Cumbric language; the last is extinct. Scottish Gaelic, Irish and Manx are part of the separate Goidelic branch of Insular Celtic.
Joseph Loth viewed Cornish and Breton as being two dialects of the same language, claiming that "Middle Cornish is without doubt closer to Breton as a whole than the modern Breton dialect of Quiberon is to that of Saint-Pol-de-Léon."
History.
Cornish evolved from the Common Brittonic spoken throughout Britain south of the Firth of Forth during the British Iron Age and Roman period. As a result of westward Anglo-Saxon expansion, the Britons of the southwest were separated from those in modern-day Wales and Cumbria. Some scholars have proposed that this split took place after the Battle of Deorham in about 577. The western dialects eventually evolved into modern Welsh and the now extinct Cumbric, while Southwestern Brittonic developed into Cornish and Breton, the latter as a result of immigration to parts of the continent, known as Brittany over the following centuries.
Old Cornish.
The area controlled by the southwestern Britons was progressively reduced by the expansion of Wessex over the next few centuries. During the Old Cornish period (800–1200), the Cornish-speaking area was largely coterminous with modern-day Cornwall; the region of Devon was isolated by Wessex in 936 CE and many inhabitants fled to Cornwall or Domnonée. The earliest written record of the Cornish language comes from this period; a 9th-century gloss in a Latin manuscript of ' by Boethius, which used the words '. The phrase means ""it (the mind) hated the gloomy places"". A much more substantial survival from Old Cornish is a Cornish-Latin glossary (the Vocabularium Cornicum or Cottonian Vocabulary) containing translations of around 300 words. The manuscript was widely thought to be in Welsh until the 1700s when it was identified as Cornish. At this time there was still little difference between Welsh and Cornish, and even fewer differences between Cornish and Breton, with some scholars arguing that the terms "Old Cornish" and "Old Breton" are merely geographical terms for the same language.
Middle Cornish.
The Cornish language continued to flourish well through the Middle Cornish period (1200–1600), reaching a peak of about 39,000 speakers in the 13th century, after which the number started to decline. This period provided the bulk of traditional Cornish literature, which was used to reconstruct the language during its revival. Most important is the "Ordinalia", a cycle of three mystery plays, "Origo Mundi", "Passio Christi" and "Resurrexio Domini". Together these provide about 20,000 lines of text. Various plays were written by the canons of Glasney College, intended to educate the Cornish people about the Bible and the Celtic saints. From this period also is ' and the recently discovered '.
In the reign of Henry VIII, an account was given by Andrew Boorde in his 1542 "Boke of the Introduction of Knowledge". He states, ""
When Parliament passed the Act of Uniformity 1549, people in many areas of Cornwall did not speak or understand English. The intention of the Act was to replace worship in Latin with worship in English, which was known by the lawmakers not to be universally spoken throughout England. Instead of merely banning Latin, the Act was framed so as to enforce English. The Prayer Book Rebellion, which may also have been influenced by the retaliation of the English after the failed Cornish Rebellion of 1497, broke out, and was ruthlessly suppressed: over 4,000 people who protested against the imposition of an English prayer book were massacred by Edward VI's army. Their leaders were executed and the people suffered numerous reprisals.
The rebels' document claimed they wanted a return to the old religious services and ended, "We the Cornishmen (whereof certain of us understand no English) utterly refuse this new English spelling." Edward Seymour, Duke of Somerset, replied to the Cornishmen, inquiring as to why they should be offended by services in English when they had them in Latin, which they also did not understand.
Through many factors, including loss of life and the spread of English, the Prayer Book Rebellion proved a turning-point for the Cornish language. Indeed, some recent research has suggested that estimates of the Cornish-speaking population prior to the rebellion may have been low, making the decline even more drastic.
Peter Berresford-Ellis cites the years 1550–1650 as a century of immense damage for the language, and its decline can be traced to this period. In 1680, William Scawen wrote an essay describing 16 reasons for the decline of Cornish, among them the lack of a distinctive Cornish alphabet, the loss of contact between Cornwall and Brittany, the cessation of the miracle plays, loss of records in the Civil War, lack of a Cornish bible, and immigration to Cornwall.
Late Cornish.
By the middle of the 17th century, the language had retreated to Penwith and Kerrier, and transmission of the language to new generations had almost entirely ceased. In his "Survey of Cornwall", published in 1602, Richard Carew writes:of the inhabitants can speak no word of Cornish, but very few are ignorant of the English; and yet some so affect their own, as to a stranger they will not speak it; for if meeting them by chance, you inquire the way, or any such matter, your answer shall be, ',' 'I [will speak no Saxonage.'"
The Late Cornish period from 1578 to about 1800 has fewer sources of information on the language but they are more varied in nature. Written sources from this period are largely spelled following English spelling conventions since the majority of writers of the time had had no exposure to Middle Cornish texts or the Cornish orthography within them. In 1776, William Bodinar, who had learnt Cornish from fishermen, wrote a letter in Cornish which was probably the last prose in the language. However, the last verse was the "Cranken Rhyme", written in the late 19th century by John Davey of Boswednack.
In the 18th and 19th centuries, there was intense academic and antiquarian interest in the language, particularly in the Middle Cornish literature, and also in attempting to find the last native speaker of the Cornish language. Despite the announcements of the death of the language, this academic interest, along with the beginning of the Celtic Revival in the late 19th Century, provided the groundwork for a Cornish language revival movement.
Modern Cornish.
In 1904, the Celtic language scholar and Cornish cultural activist Henry Jenner published "A Handbook of the Cornish Language". The publication of this book is often considered to be the point at which the revival movement started.
The revival focused on reconstructing and standardising the language, including coining new words for modern concepts, and creating educational material in order to teach Cornish to others. In 1929 Robert Morton Nance published his Unified Cornish system, based on the Middle Cornish literature while extending the attested vocabulary with forms based on Celtic roots also found in Breton and Welsh, publishing a dictionary in 1938. Nance's work became the basis of revived Cornish for most of the 20th century. However, as the revival grew in strength and focus shifted from written to spoken Cornish, Nance's stiff, archaic formulation of the language seemed less suitable for a spoken revival, and academic research into the traditional literature proved that the Unified system lacked some phonological distinctions.
In the 1980s, in response to dissatisfaction with Unified Cornish, Ken George published a new system, ("Common Cornish"). Like Unified Cornish, it retained a Middle Cornish base but implemented an orthography that aspired to be as phonemic as possible. It was subsequently adopted by the Cornish Language Board as well as by many Cornish speakers, but came under fierce criticism by academic linguists for its phonological base, as well as those who found its orthography too different from traditional Cornish spelling conventions. Also during this period, Richard Gendall created his Modern Cornish system (also known as "Revived Late Cornish"), which used Late Cornish as a basis, and Nicholas Williams published a revised version of Unified; however neither of these systems gained the popularity of Unified or Kemmyn.
The revival entered a period of factionalism and public disputes, with each orthography attempting to push the others aside. By the time that Cornish was recognised by the UK government under the European Charter for Regional or Minority Languages in 2002, it had become recognised that the existence of multiple orthographies was unsustainable with regards to using the language in education and public life, as none had achieved a wide consensus. A process of unification was set about which resulted in the creation of the public-body Cornish Language Partnership in 2005 and agreement on a Standard Written Form in 2008. In 2010 UNESCO altered its classification of Cornish, recognising that its previous label of "extinct" was no longer accurate. This was seen by Cornish speakers as a milestone, turning the language from a state of undergoing revival, to having been revived.
The modern-day Cornish language is a successfully revived language with a number of speakers that is slowly increasing, and is becoming more visible in Cornwall as local government and business are encouraged to make use of the language as part of revitalisation efforts.
Geographic distribution.
Speakers of Cornish reside primarily in Cornwall. There are also some speakers living outside of Cornwall, particularly in the countries of the Cornish diaspora, as well as other Celtic nations. Estimates of the number of Cornish speakers vary according to the definition of being a speaker, and is difficult to accurately determine due to the individualised nature of language take-up. Nevertheless, there is recognition that the number of Cornish speakers is growing. One figure for the mean number of people who know a few basic words, such as knowing that "Kernow" means "Cornwall", was 300,000; the same survey gave the figure of people able to have simple conversations at 3,000. The Cornish Language Strategy project commissioned research to provide quantitative and qualitative evidence for the number of Cornish speakers: due to the success of the revival project it was estimated that 2,000 people were fluent (surveyed in spring 2008), an increase from the estimated 300 people who spoke Cornish fluently suggested in a study by Kenneth MacKinnon in 2000. In the 2011 UK census, 557 people in England and Wales declared Cornish to be their main language, 464 of whom lived in Cornwall.
Official status.
Cornish is officially recognised as a minority language by the UK government under the European Charter for Regional or Minority Languages, a status it has held since 2002. The Cornish Language Partnership is the official body for promotion and development of the language in Cornwall.
Cornwall Council's policy is to support the language. A motion passed in November 2009 approved the council's use of Cornish. The policy notes the "place of the Cornish language as a unique cultural asset" and requires the council to promote Cornish in line with the European Charter for Regional or Minority Languages. One effect of the policy is that worn out road signs are replaced by bilingual ones, but this plan has drawn some criticism.
In October 2015, Cornwall County Council announced that staff would be encouraged to use “basic words and phrases” in Cornish when dealing with the public.
In 2014 the Cornish people were recognised by the UK Government as a national minority under the Framework Convention for the Protection of National Minorities. The FCNM provides certain rights and protections to a national minority with regard to their minority language.
UNESCO's "Atlas of World Languages" classifies Cornish as "critically endangered". UNESCO has acknowledged that a previous classification of "extinct", which came under fierce criticism from Cornish speakers, "does not reflect the current situation for Cornish".
In 2016 central government funding for the Cornish language ceased, and responsibility transferred to Cornwall council. 
Phonology.
The phonology of modern Cornish is based on a number of sources. The work of the linguist Edward Lhuyd who visited Cornwall in 1700 to record the language, as well as the modern Cornish dialect and accent of English, which got much of its intonation and sounds from the Cornish language, have provided a major source of input. Analysis of the traditional literature has also been used, as the Middle Cornish plays were often written in rhyming verse, and Late Cornish texts were written phonetically following English spelling conventions.
Grammar.
The grammar of Cornish shares with other Celtic languages a number of features which, while not unique, are unusual in an Indo-European context. The grammatical features most unfamiliar to English speakers of the language are the initial consonant mutations, the verb–subject–object word order, inflected prepositions, fronting of emphasised syntactic elements, and the use of two different forms for "to be". Cornish nouns belong to one of two grammatical genders, masculine and feminine, but are not inflected for case. Cornish has a variety of different endings to indicate the plural, and some nouns have a third collective form. Verbs are conjugated for tense and mood, which can be indicated either by inflection of the main verb, or by the use of auxiliary verbs.
As in other Celtic languages, Cornish lacks a number of verbs that are commonly found in other languages. This includes modals and psych-verbs; examples 'have', 'like', 'hate', 'prefer', 'must'/'have to', 'make'='compel to'. These functions are instead fulfilled by periphrastic constructions involving a verb and various prepositional phrases.
Culture.
The Celtic Congress and Celtic League are groups that advocate cooperation amongst the Celtic Nations in order to protect and promote Celtic languages and cultures, thus working in the interests of the Cornish language.
There have been films such as "", some televised, made entirely, or significantly, in the language. Some businesses use Cornish names.
According to the sociologist Kenneth MacKinnon, Jenner wrote "There has never been a time when there has been no person in Cornwall without a knowledge of the Cornish language."
Cornish has had a significant and lasting impact on Cornwall's place names, as well as in Cornish surnames, and knowledge of the language helps the understanding of these ancient meanings. Cornish names are adopted for children, pets, houses and boats.
There is Cornish literature, in which poetry is the most important genre, particularly in oral form or as song or as traditional Cornish chants historically performed in marketplaces during religious holidays and public festivals and gatherings.
There are periodicals solely in the language such as the monthly ', ', and "". BBC Radio Cornwall has a news broadcast in Cornish, and sometimes has other programmes and features for learners and enthusiasts. Local newspapers such as the "Western Morning News" have articles in Cornish, and newspapers such as "The Packet", "The West Briton" and "The Cornishman" have also been known to have Cornish features. There is an online radio service in Cornish called , publishing a one-hour podcast each week, based on a magazine format. It includes music in Cornish as well as interviews and features.
The language has financial sponsorship from sources, including the Millennium Commission. A number of language organisations exist in Cornwall: (Our Language), the Cornish sub-group of the European Bureau for Lesser-Used Languages, , (the Cornish Language Board) and (the Cornish Language Fellowship)]. There are ceremonies, some ancient, some modern, which use the language or are entirely in the language.
Cultural events.
Cornwall has had cultural events associated with the language, including the international Celtic Media Festival, hosted in St Ives in 1997. The Old Cornwall Society has promoted the use of the language at events and meetings. Two examples of ceremonies that are performed in both the English and Cornish languages are Crying the Neck and the annual mid-summer bonfires.
Study and teaching.
Cornish is taught in some schools; it was previously taught at degree level in the University of Wales, though the only existing course in the language at University level is as part of a course in Cornish Studies at the University of Exeter. In March 2008, a course in the language was started as part of the Celtic Studies curriculum at the University of Vienna, Austria.
In 2015 a university level course aiming to encourage and support practitioners working with young children to introduce the Cornish language into their settings was launched. The "Cornish Language Practice Project (Early Years)" is a level 4 course approved by Plymouth University and run at Cornwall College. The course is not a Cornish language course, but students will be assessed on their ability to use the Cornish language constructively in their work with young children. The course will cover such topics as "Understanding Bilingualism", "Creating Resources" and "Integrating Language and Play", but the focus of the language provision will be on Cornish. A non-accredited specialist Cornish language course has been developed to run alongside the level 4 course for those who prefer tutor support to learn the language or develop their skills further for use with young children.
Cornwall's first Cornish language crèche, "", was established in 2010 at Cornwall College, Camborne. The nursery teaches children aged between two and five years alongside their parents to ensure the language is also spoken in the home.
A number of dictionaries are available in the different orthographies (a dictionary in the Standard Written Form has yet to be published), including ' by Ken George, ' by Nicholas Williams and "A Practical Dictionary of Modern Cornish" by Richard Gendall. Course books include the three-part ' series, ', ' and ', as well as the more recent ' and '.
Cornish studies.
William Scawen produced a manuscript on the declining Cornish language that continually evolved until he died in 1689, aged 89. He was the first person to realise the language was dying out and wrote detailed manuscripts which he started working on when he was 78. The only version that was ever published was a short first draft, but the final version, which he worked on until his death, is a few hundred pages long. At the same time a group of scholars, led by John Keigwin (nephew of William Scawen), of Mousehole, tried to preserve and further the Cornish language. They left behind a large number of translations of parts of the Bible, proverbs and songs. This group was contacted by the Welsh linguist Edward Lhuyd who came to Cornwall to study the language.
Early Modern Cornish was the subject of a study published by Lhuyd in 1707, and differs from the medieval language in having a considerably simpler structure and grammar. Such differences included the wide use of certain modal affixes that, although out of use by Lhuyd's time, had a considerable effect on the word-order of medieval Cornish. The medieval language also possessed two additional tenses for expressing past events and an extended set of possessive suffixes. Edward Lhuyd theorises that the language of this time was heavily inflected, possessing not just the genitive, ablative and locative cases so common in Early Modern Cornish, but also dative and accusative cases, and even a vocative case, although historical references to this are rare.
John Whitaker, the Manchester-born rector of Ruan Lanihorne, studied the decline of the Cornish language. In his 1804 work "the Ancient Cathedral of Cornwall" he concluded that: "he English Liturgy, was not desired by the Cornish, but forced upon them by the tyranny of England, at a time when the English language was yet unknown in Cornwall. This act of tyranny was at once gross barbarity to the Cornish people, and a death blow to the Cornish language.".
Robert Williams published the first comprehensive Cornish dictionary in 1865, the "Lexicon Cornu-Britannicum". As a result of the discovery of additional ancient Cornish manuscripts, 2000 new words were added to the vocabulary by Whitley Stokes in "A Cornish Glossary". William C. Borlase published "Proverbs and Rhymes in Cornish" in 1866 while "A Glossary of Cornish Place Names" was produced by John Bannister in the same year. Frederick Jago published his "English–Cornish Dictionary" in 1882.
Literature.
In 1981, the Breton library ' edited ' (Passion of our lord), a 15th-century Cornish poem. The first complete translation of the Bible into Cornish translated from English, was published in 2011. Another Bible translation project translating from original languages is underway. The New Testament and Psalms were posted on-line on YouVersion (Bible.com) and Bibles.org in July 2014 by the Bible Society.
A few small publishers produce books in Cornish which are stocked in some local bookshops, as well as in Cornish branches of Waterstones and WH Smiths, although newer publications are becoming increasingly available on the Internet. The Truro Waterstones hosts the annual "" literary awards, established by to recognise publications relating to Cornwall or in the Cornish language. In recent years, a number of Cornish translations of literature has been published, including "Alice's Adventures in Wonderland" (2009), "Around the World in Eighty Days" (2009), "Treasure Island" (2010), "The Railway Children" (2012), "Hound of the Baskervilles" (2012), "War of the Worlds" (2012), "The Wind in the Willows" (2013), "Three Men in a Boat" (2013), "Alice in Wonderland and Through the Looking-Glass" (2014), and "A Christmas Carol" (which won the 2012 award for Cornish Language books), as well as original Cornish literature such as ' ("The Lyonesse Stone") by Craig Weatherhill. Literature aimed at children is also available, such as ' ("Where's Spot?"), ' ("The Beast of Bodmin Moor"), three "Topsy and Tim" titles, and ' ("Briallen and the Alien"), which won the 2015 award for Cornish Language books for children. In 2014 "", Nicholas Williams' translation of J.R.R. Tolkien's "The Hobbit" was published.
Media.
In 1983 BBC Radio Cornwall started broadcasting around two minutes of Cornish every week. In 1987, however, they gave over 15 minutes of airtime on Sunday mornings for a programme called ' ("Holdall"), presented by John King, running until the early 1990s. It was eventually replaced with a five-minute news bulletin called ' ("The News"). The bulletin was presented every Sunday evening for many years by Rod Lyon, then Elizabeth Stewart, and currently a team presents in rotation. Pirate FM ran short bulletins on Saturday lunchtimes from 1998 to 1999. In 2006, Matthew Clarke who had presented the Pirate FM bulletin, launched a web-streamed news bulletin called ' ("Weekly News"), which in 2008 was merged into a new weekly magazine podcast ' (RanG).
Cornish television shows have included a 1982 series by Westward Television each episode containing a three-minute lesson in Cornish. ', an eight episode series produced by Television South West and broadcast between June and July 1984, later on S4C from May to July 1985, and as a schools programme in 1986. Also by Television South West were two bilingual programmes on Cornish Culture called '
Music.
English composer Peter Warlock, an enthusiast of the Celtic languages, wrote a Christmas carol in Cornish (setting words by Henry Jenner). Cornish musician Jory Bennett (born Redruth, 1963) has composed "Six Songs of Cornwall" for bass and piano, a Cornish song-cycle, settings of Cornish language poems by Nicholas Williams /trans. E. G. Retallack Hooper (f.p. Keele University, 7 May 1986). The Cornish electronic musician Richard D James has often used Cornish names for track titles, most notably on his "DrukQs" album. Gwenno Saunders is a multilingual Welsh-born musician and a Cornish speaker. Skwardya has produced four CD albums in Cornish in a modern pop/rock/blues/dance style.
Placenames and surnames.
The Cornish language has had an impact on the toponomy of Cornwall, and has historically been used in surnames for the Cornish people. The following tables present some examples of Cornish placenames and surnames, and their anglicised versions:
Samples.
From the Universal Declaration of Human Rights:
From "", the Cornish anthem:

</doc>
<doc id="6132" url="https://en.wikipedia.org/wiki?curid=6132" title="Complexity theory">
Complexity theory

Complexity theory may refer to:

</doc>
<doc id="6134" url="https://en.wikipedia.org/wiki?curid=6134" title="Charybdis">
Charybdis

Charybdis (; Greek: Χάρυβδις, , "Kharybdis") was a sea monster, later rationalised as a whirlpool and considered a shipping hazard in the Strait of Messina.
Overview.
The sea monster Charybdis was believed to live under a small rock on one side of a narrow channel. Opposite her was Scylla, another sea monster, that lived inside a much larger rock. Book XII The sides of the strait were within an arrow-shot of each other, and sailors attempting to avoid one of them would come in reach of the other. To be "between Scylla and Charybdis" therefore means to be presented with two opposite dangers, the task being to find a route that avoids both. Three times a day, Charybdis swallowed a huge amount of water, before belching it back out again, creating large whirlpools capable of dragging a ship underwater. In some variations of the story, Charybdis was simply a large whirlpool instead of a sea monster.
A later myth makes Charybdis the daughter of Poseidon and Gaia and living as a loyal servant to Poseidon. She aided him in his feud with Zeus, and as such, helped him engulf lands and islands in water. Zeus, angry for the land she stole from him, cursed her into a hideous bladder of a monster, with flippers for arms and legs, and an uncontrollable thirst for the sea. As such, she drank the water from the sea three times a day to quench it, which created whirlpools. She lingered on a rock with Scylla facing her directly on another rock, making a strait.
The theoretical size of Charybdis remains unknown, yet in order to consume Greek ships the whirlpool can be estimated to about 23 metres (75 ft) across. Charybdis has been associated with the Strait of Messina, off the coast of Sicily and opposite a rock on the mainland identified with Scylla. Were Charybdis to be located in the Strait of Messina it would in fact have the size to accommodate the whirlpool. A whirlpool does exist there, caused by currents meeting, but it is dangerous only to small craft in extreme conditions.
References in ancient literature.
Jason and The Argonauts.
The Argonauts were able to avoid both dangers because Hera ordered the sea-nymph Thetis to guide them through the perilous passage.
Aesop.
Aristotle mentions in his "Meteorologica" that Aesop once teased a ferryman by telling him a myth concerning Charybdis. With one gulp of the sea she brought the mountains to view; islands appeared after the next. The third is yet to come and will dry the sea altogether, thus depriving the ferryman of his livelihood.

</doc>
<doc id="6136" url="https://en.wikipedia.org/wiki?curid=6136" title="Carbon monoxide">
Carbon monoxide

Carbon monoxide (CO) is a colorless, odorless, and tasteless gas that is slightly less dense than air. It is toxic to hemoglobic animals (including humans) when encountered in concentrations above about 35 ppm, although it is also produced in normal animal metabolism in low quantities, and is thought to have some normal biological functions. In the atmosphere, it is spatially variable and short lived, having a role in the formation of ground-level ozone.
Carbon monoxide consists of one carbon atom and one oxygen atom, connected by a triple bond that consists of two covalent bonds as well as one dative covalent bond. It is the simplest oxocarbon and is isoelectronic with the cyanide anion, the nitrosonium cation and molecular nitrogen. In coordination complexes the carbon monoxide ligand is called carbonyl.
Carbon monoxide is produced from the partial oxidation of carbon-containing compounds; it forms when there is not enough oxygen to produce carbon dioxide (CO2), such as when operating a stove or an internal combustion engine in an enclosed space. In the presence of oxygen, including atmospheric concentrations, carbon monoxide burns with a blue flame, producing carbon dioxide. Coal gas, which was widely used before the 1960s for domestic lighting, cooking, and heating, had carbon monoxide as a significant fuel constituent. Some processes in modern technology, such as iron smelting, still produce carbon monoxide as a byproduct.
Worldwide, the largest source of carbon monoxide is natural in origin, due to photochemical reactions in the troposphere that generate about 5 kilograms per year. Other natural sources of CO include volcanoes, forest fires, and other forms of combustion.
In biology, carbon monoxide is naturally produced by the action of heme oxygenase 1 and 2 on the heme from hemoglobin breakdown. This process produces a certain amount of carboxyhemoglobin in normal persons, even if they do not breathe any carbon monoxide. Following the first report that carbon monoxide is a normal neurotransmitter in 1993, as well as one of three gases that naturally modulate inflammatory responses in the body (the other two being nitric oxide and hydrogen sulfide), carbon monoxide has received a great deal of clinical attention as a biological regulator. In many tissues, all three gases are known to act as anti-inflammatories, vasodilators, and promoters of neovascular growth. Clinical trials of small amounts of carbon monoxide as a drug are ongoing. Nonetheless, too much carbon monoxide causes carbon monoxide poisoning.
History.
Aristotle (384–322 BC) first recorded that burning coals produced toxic fumes. An ancient method of execution was to shut the criminal in a bathing room with smouldering coals. What was not known was the mechanism of death. Greek physician Galen (129–199 AD) speculated that there was a change in the composition of the air that caused harm when inhaled. In 1776, the French chemist de Lassone produced CO by heating zinc oxide with coke, but mistakenly concluded that the gaseous product was hydrogen, as it burned with a blue flame. The gas was identified as a compound containing carbon and oxygen by the Scottish chemist William Cumberland Cruikshank in the year 1800. Its toxic properties on dogs were thoroughly investigated by Claude Bernard around 1846.
During World War II, a gas mixture including carbon monoxide was used to keep motor vehicles running in parts of the world where gasoline and diesel fuel were scarce. External (with a few exceptions) charcoal or wood gas generators were fitted, and the mixture of atmospheric nitrogen, carbon monoxide, and small amounts of other gases produced by gasification was piped to a gas mixer. The gas mixture produced by this process is known as wood gas. Carbon monoxide was also used on a large scale during the Holocaust at some Nazi German extermination camps, the most notable by gas vans in Chelmno, and in the Action T4 "euthanasia" program.
Molecular properties.
Carbon monoxide has a molar mass of 28.0, which makes it slightly lighter than air, whose average molar mass is 28.8. According to the ideal gas law, CO is therefore less dense than air.
The bond length between the carbon atom and the oxygen atom is 112.8 pm. This bond length is consistent with a triple bond, as in molecular nitrogen (N2), which has a similar bond length and nearly the same molecular mass. Carbon–oxygen double bonds are significantly longer, 120.8 pm in formaldehyde, for example. The boiling point (82 K) and melting point (68 K) are very similar to those of N2 (77 K and 63 K, respectively). The bond dissociation energy of 1072 kJ/mol is stronger than that of N2 (942 kJ/mol) and represents the strongest chemical bond known.
The ground electronic state of carbon monoxide is a singlet state since there are no unpaired electrons.
Bonding and dipole moment.
Carbon and oxygen together have a total of 10 electrons in the valence shell. Following the octet rule for both carbon and oxygen, the two atoms form a triple bond, with six shared electrons in three bonding molecular orbitals, rather than the usual double bond found in organic carbonyl compounds. Since four of the shared electrons come from the oxygen atom and only two from carbon, one bonding orbital is occupied by two electrons from oxygen, forming a dative or dipolar bond. This causes a C ← O polarization of the molecule, with a small negative charge on carbon and a small positive charge on oxygen. The other two bonding orbitals are each occupied by one electron from carbon and one from oxygen, forming (polar) covalent bonds with a reverse C → O polarization, since oxygen is more electronegative than carbon. In the free carbon monoxide, a net negative charge δ- remains at the carbon end and the molecule has a small dipole moment of 0.122 D.
The molecule is therefore asymmetric: oxygen has more electron density than carbon, and is also slightly positively charged compared to carbon being negative. By contrast, the isoelectronic dinitrogen molecule has no dipole moment.
If carbon monoxide acts as a ligand, the polarity of the dipole may reverse with a net negative charge on the oxygen end, depending on the structure of the coordination complex.
See also the section ""Coordination chemistry"" below.
Bond polarity and oxidation state.
Theoretical and experimental studies show that, despite the greater electronegativity of oxygen, the dipole moment points from the more-negative carbon end to the more-positive oxygen end. The three bonds are in fact polar covalent bonds that are strongly polarized. The calculated polarization toward the oxygen atom is 71% for the σ-bond and 77% for both π-bonds.
The oxidation state of carbon in carbon monoxide is +2 in each of these structures. It is calculated by counting all the bonding electrons as belonging to the more electronegative oxygen. Only the two non-bonding electrons on carbon are assigned to carbon. In this count, carbon then has only two valence electrons in the molecule compared to four in the free atom.
Biological and physiological properties.
Toxicity.
Carbon monoxide poisoning is the most common type of fatal air poisoning in many countries. Carbon monoxide is colorless, odorless, and tasteless, but highly toxic. It combines with hemoglobin to produce carboxyhemoglobin, which usurps the space in hemoglobin that normally carries oxygen, but is ineffective for delivering oxygen to bodily tissues. Concentrations as low as 667 ppm may cause up to 50% of the body's hemoglobin to convert to carboxyhemoglobin. A level of 50% carboxyhemoglobin may result in seizure, coma, and fatality. In the United States, the OSHA limits long-term workplace exposure levels above 50 ppm. Within short time scales, carbon monoxide absorption is cumulative, since the half-life is about 5 hours in fresh air.
The most common symptoms of carbon monoxide poisoning may resemble other types of poisonings and infections, including symptoms such as headache, nausea, vomiting, dizziness, fatigue, and a feeling of weakness. Affected families often believe they are victims of food poisoning. Infants may be irritable and feed poorly. Neurological signs include confusion, disorientation, visual disturbance, syncope (fainting), and seizures.
Some descriptions of carbon monoxide poisoning include retinal hemorrhages, and an abnormal cherry-red blood hue. In most clinical diagnoses these signs are seldom noticed. One difficulty with the usefulness of this cherry-red effect is that it corrects, or masks, what would otherwise be an unhealthy appearance, since the chief effect of removing deoxygenated hemoglobin is to make an asphyxiated person appear more normal, or a dead person appear more lifelike, similar to the effect of red colorants in embalming fluid. The "false" or unphysiologic red-coloring effect in anoxic CO-poisoned tissue is related to the meat-coloring commercial use of carbon monoxide, discussed below.
Carbon monoxide also binds to other molecules such as myoglobin and mitochondrial cytochrome oxidase. Exposures to carbon monoxide may cause significant damage to the heart and central nervous system, especially to the globus pallidus, often with long-term chronic pathological conditions. Carbon monoxide may have severe adverse effects on the fetus of a pregnant woman.
Normal human physiology.
Carbon monoxide is produced naturally by the human body as a signaling molecule. Thus, carbon monoxide may have a physiological role in the body, such as a neurotransmitter or a blood vessel relaxant. Because of carbon monoxide's role in the body, abnormalities in its metabolism have been linked to a variety of diseases, including neurodegenerations, hypertension, heart failure, and inflammation.
Microbiology.
Carbon monoxide is a nutrient for methanogenic archaea, a building-block for acetyl coenzyme A. This is the theme for the emerging field of bioorganometallic chemistry. Extremophile micro-organisms can, thus, metabolise carbon monoxide in such locations as the thermal vents of volcanoes.
In bacteria, carbon monoxide is produced via the reduction of carbon dioxide by the enzyme carbon monoxide dehydrogenase, an Fe-Ni-S-containing protein.
CooA is a carbon monoxide sensor protein. The scope of its biological role is still unknown; it may be part of a signaling pathway in bacteria and archaea. Its occurrence in mammals is not established.
Occurrence.
Carbon monoxide occurs in various natural and artificial environments. Typical concentrations in parts per million are as follows:
Atmospheric presence.
Carbon monoxide is present in small amounts in the atmosphere, chiefly as a product of volcanic activity but also from natural and man-made fires (such as forest and bushfires, burning of crop residues, and sugarcane fire-cleaning). The burning of fossil fuels also contributes to carbon monoxide production. Carbon monoxide occurs dissolved in molten volcanic rock at high pressures in the Earth's mantle. Because natural sources of carbon monoxide are so variable from year to year, it is extremely difficult to accurately measure natural emissions of the gas.
Carbon monoxide is a short-lived greenhouse gas and also has an indirect radiative forcing effect by elevating concentrations of methane and tropospheric ozone through chemical reactions with other atmospheric constituents (e.g., the hydroxyl radical, OH.) that would otherwise destroy them. Through natural processes in the atmosphere, it is eventually oxidized to carbon dioxide. Carbon monoxide is both short-lived in the atmosphere (on average about two months) and spatially variable in concentration.
In the atmosphere of Venus carbon monoxide occurs as a result of the photodissociation of carbon dioxide by electromagnetic radiation of wavelengths shorter than 169 nm.
Due to its long lifetime in the mid-troposphere, carbon monoxide is also used as tracer of transport for pollutant plumes.
Urban pollution.
Carbon monoxide is a temporary atmospheric pollutant in some urban areas, chiefly from the exhaust of internal combustion engines (including vehicles, portable and back-up generators, lawn mowers, power washers, etc.), but also from incomplete combustion of various other fuels (including wood, coal, charcoal, oil, paraffin, propane, natural gas, and trash).
Large CO pollution events can be observed from space over cities.
Role in ground-level ozone formation.
Carbon monoxide is, along with aldehydes, part of the series of cycles of chemical reactions that form photochemical smog. It reacts with hydroxyl radical (•OH) to produce a radical intermediate •HOCO, which transfers rapidly its radical hydrogen to O2 to form peroxy radical (HO2•) and carbon dioxide (CO2). Peroxy radical subsequently reacts with nitrogen oxide (NO) to form nitrogen dioxide (NO2) and hydroxyl radical. NO2 gives O(3P) via photolysis, thereby forming O3 following reaction with O2.
Since hydroxyl radical is formed during the formation of NO2, the balance of the sequence of chemical reactions starting with carbon monoxide and leading to the formation of ozone is:
Although the creation of NO2 is the critical step leading to low level ozone formation, it also increases this ozone in another, somewhat mutually exclusive way, by reducing the quantity of NO that is available to react with ozone.
Indoor pollution.
In closed environments, the concentration of carbon monoxide can easily rise to lethal levels. On average, 170 people in the United States die every year from carbon monoxide produced by non-automotive consumer products. However, according to the Florida Department of Health, "every year more than 500 Americans die from accidental exposure to carbon monoxide and thousands more across the U.S. require emergency medical care for non-fatal carbon monoxide poisoning" These products include malfunctioning fuel-burning appliances such as furnaces, ranges, water heaters, and gas and kerosene room heaters; engine-powered equipment such as portable generators; fireplaces; and charcoal that is burned in homes and other enclosed areas. The American Association of Poison Control Centers (AAPCC) reported 15,769 cases of carbon monoxide poisoning resulting in 39 deaths in 2007. In 2005, the CPSC reported 94 generator-related carbon monoxide poisoning deaths. Forty-seven of these deaths were known to have occurred during power outages due to severe weather, including Hurricane Katrina. Still others die from carbon monoxide produced by non-consumer products, such as cars left running in attached garages. The Centers for Disease Control and Prevention estimates that several thousand people go to hospital emergency rooms every year to be treated for carbon monoxide poisoning.
Presence in blood.
Carbon monoxide is absorbed through breathing and enters the blood stream through gas exchange in the lungs. It is also produced in hemoglobin metabolism and enters the blood from the tissues, and thus is present in all normal tissues, even if not inhaled.
Normal circulating levels in the blood are 0% to 3%, and are higher in smokers. Carbon monoxide levels cannot be assessed through a physical exam. Laboratory testing requires a blood sample (arterial or venous) and laboratory analysis on a CO-Oximeter. Additionally, a noninvasive carboxyhemoglobin (SpCO) test method from Pulse CO-Oximetry exists and has been validated compared to invasive methods.
Astrophysics.
Outside of Earth, carbon monoxide is the second-most common molecule in the interstellar medium, after molecular hydrogen. Because of its asymmetry, the carbon monoxide molecule produces far brighter spectral lines than the hydrogen molecule, making CO much easier to detect. Interstellar CO was first detected with radio telescopes in 1970. It is now the most commonly used tracer of molecular gas in general in the interstellar medium of galaxies, as molecular hydrogen can only be detected using ultraviolet light, which requires space telescopes. Carbon monoxide observations provide much of the information about the molecular clouds in which most stars form.
Beta Pictoris, the second brightest star in the constellation Pictor, shows an excess of infrared emission compared to normal stars of its type, which is caused by large quantities of dust and gas (including carbon monoxide) near the star.
Production.
Many methods have been developed for carbon monoxide's production.
Industrial production.
A major industrial source of CO is producer gas, a mixture containing mostly carbon monoxide and nitrogen, formed by combustion of carbon in air at high temperature when there is an excess of carbon. In an oven, air is passed through a bed of coke. The initially produced CO2 equilibrates with the remaining hot carbon to give CO. The reaction of CO2 with carbon to give CO is described as the Boudouard reaction. Above 800 °C, CO is the predominant product:
Another source is "water gas", a mixture of hydrogen and carbon monoxide produced via the endothermic reaction of steam and carbon:
Other similar "synthesis gases" can be obtained from natural gas and other fuels.
Carbon monoxide is also a byproduct of the reduction of metal oxide ores with carbon, shown in a simplified form as follows:
Carbon monoxide is also produced by the direct oxidation of carbon in a limited supply of oxygen or air.
Since CO is a gas, the reduction process can be driven by heating, exploiting the positive (favorable) entropy of reaction. The Ellingham diagram shows that CO formation is favored over CO2 in high temperatures.
Laboratory preparation.
Carbon monoxide is conveniently produced in the laboratory by the dehydration of formic acid or oxalic acid, for example with concentrated sulfuric acid. Another method is heating an intimate mixture of powdered zinc metal and calcium carbonate, which releases CO and leaves behind zinc oxide and calcium oxide:
Silver nitrate and iodoform also afford carbon monoxide:
Coordination chemistry.
Most metals form coordination complexes containing covalently attached carbon monoxide. Only metals in lower oxidation states will complex with carbon monoxide ligands. This is because there must be sufficient electron density to facilitate back-donation from the metal dxz-orbital, to the π*molecular orbital from CO. The lone pair on the carbon atom in CO, also donates electron density to the dx²−y² on the metal to form a sigma bond. This electron donation is also exhibited with the cis effect, or the labilization of CO ligands in the cis position. Nickel carbonyl, for example, forms by the direct combination of carbon monoxide and nickel metal:
For this reason, nickel in any tubing or part must not come into prolonged contact with carbon monoxide. Nickel carbonyl decomposes readily back to Ni and CO upon contact with hot surfaces, and this method is used for the industrial purification of nickel in the Mond process.
In nickel carbonyl and other carbonyls, the electron pair on the carbon interacts with the metal; the carbon monoxide donates the electron pair to the metal. In these situations, carbon monoxide is called the carbonyl ligand. One of the most important metal carbonyls is iron pentacarbonyl, Fe(CO)5:
Many metal-CO complexes are prepared by decarbonylation of organic solvents, not from CO. For instance, iridium trichloride and triphenylphosphine react in boiling 2-methoxyethanol or DMF to afford IrCl(CO)(PPh3)2.
Metal carbonyls in coordination chemistry are usually studied using infrared spectroscopy.
Organic and main group chemistry.
In the presence of strong acids and water, carbon monoxide reacts with alkenes to form carboxylic acids in a process known as the Koch–Haaf reaction. In the Gattermann–Koch reaction, arenes are converted to benzaldehyde derivatives in the presence of AlCl3 and HCl. Organolithium compounds (e.g. butyl lithium) react with carbon monoxide, but these reactions have little scientific use.
Although CO reacts with carbocations and carbanions, it is relatively nonreactive toward organic compounds without the intervention of metal catalysts.
With main group reagents, CO undergoes several noteworthy reactions. Chlorination of CO is the industrial route to the important compound phosgene. With borane CO forms an adduct, H3BCO, which is isoelectronic with the acylium cation [H3CCO]+. CO reacts with sodium to give products resulting from C-C coupling such as sodium acetylenediolate 2·. It reacts with molten potassium to give a mixture of an organometallic compound, potassium acetylenediolate 2·, potassium benzenehexolate 6 , and potassium rhodizonate 2·.
The compounds cyclohexanehexone or triquinoyl (C6O6) and cyclopentanepentone or leuconic acid (C5O5), which so far have been obtained only in trace amounts, can be regarded as polymers of carbon monoxide.
At pressures of over 5 gigapascals, carbon monoxide converts into a solid polymer of carbon and oxygen. This is metastable at atmospheric pressure but is a powerful explosive.
Uses.
Chemical industry.
Carbon monoxide is an industrial gas that has many applications in bulk chemicals manufacturing. Large quantities of aldehydes are produced by the hydroformylation reaction of alkenes, carbon monoxide, and H2. Hydroformylation is coupled to the Shell higher olefin process to give precursors to detergents.
Phosgene, useful for preparing isocyanates, polycarbonates, and polyurethanes, is produced by passing purified carbon monoxide and chlorine gas through a bed of porous activated carbon, which serves as a catalyst. World production of this compound was estimated to be 2.74 million tonnes in 1989.
Methanol is produced by the hydrogenation of carbon monoxide. In a related reaction, the hydrogenation of carbon monoxide is coupled to C-C bond formation, as in the Fischer-Tropsch process where carbon monoxide is hydrogenated to liquid hydrocarbon fuels. This technology allows coal or biomass to be converted to diesel.
In the Monsanto process, carbon monoxide and methanol react in the presence of a homogeneous rhodium catalyst and hydroiodic acid to give acetic acid. This process is responsible for most of the industrial production of acetic acid.
An industrial scale use for pure carbon monoxide is purifying nickel in the Mond process.
Meat coloring.
Carbon monoxide is used in modified atmosphere packaging systems in the US, mainly with fresh meat products such as beef, pork, and fish to keep them looking fresh. The carbon monoxide combines with myoglobin to form carboxymyoglobin, a bright-cherry-red pigment. Carboxymyoglobin is more stable than the oxygenated form of myoglobin, oxymyoglobin, which can become oxidized to the brown pigment metmyoglobin. This stable red color can persist much longer than in normally packaged meat. Typical levels of carbon monoxide used in the facilities that use this process are between 0.4% to 0.5%.
The technology was first given "generally recognized as safe" (GRAS) status by the U.S. Food and Drug Administration (FDA) in 2002 for use as a secondary packaging system, and does not require labeling. In 2004, the FDA approved CO as primary packaging method, declaring that CO does not mask spoilage odor. Despite this ruling, the process remains controversial for fears that it masks spoilage. In 2007, a bill was introduced to the United States House of Representatives to label modified atmosphere carbon monoxide packaging as a color additive, but the bill died in subcommittee. The process is banned in many other countries, including Japan, Singapore, and the European Union.
Medicine.
In biology, carbon monoxide is naturally produced by the action of heme oxygenase 1 and 2 on the heme from hemoglobin breakdown. This process produces a certain amount of carboxyhemoglobin in normal persons, even if they do not breathe any carbon monoxide.
Following the first report that carbon monoxide is a normal neurotransmitter in 1993, as well as one of three gases that naturally modulate inflammatory responses in the body (the other two being nitric oxide and hydrogen sulfide), carbon monoxide has received a great deal of clinical attention as a biological regulator. In many tissues, all three gases are known to act as anti-inflammatories, vasodilators, and encouragers of neovascular growth. However, the issues are complex, as neovascular growth is not always beneficial, since it plays a role in tumor growth, and also the damage from "wet" macular degeneration, a disease for which smoking (a major source of carbon monoxide in the blood, several times more than natural production) increases the risk from 4 to 6 times.
There is a theory that, in some nerve cell synapses, when long-term memories are being laid down, the receiving cell makes carbon monoxide, which back-transmits to the transmitting cell, telling it to transmit more readily in future. Some such nerve cells have been shown to contain guanylate cyclase, an enzyme that is activated by carbon monoxide.
Studies involving carbon monoxide have been conducted in many laboratories throughout the world for its anti-inflammatory and cytoprotective properties. These properties have potential to be used to prevent the development of a series of pathological conditions including ischemia reperfusion injury, transplant rejection, atherosclerosis, severe sepsis, severe malaria, or autoimmunity. Clinical tests involving humans have been performed, however the results have not yet been released.
Lasers.
Carbon monoxide has also been used as a lasing medium in high-powered infrared lasers.
Niche uses.
Carbon monoxide has been proposed for use as a fuel on Mars. Carbon monoxide/oxygen engines have been suggested for early surface transportation use as both carbon monoxide and oxygen can be straightforwardly produced from the atmosphere of Mars by zirconia electrolysis, without using any Martian water resources to obtain hydrogen, which would be needed to make methane or any hydrogen-based fuel.

</doc>
<doc id="6138" url="https://en.wikipedia.org/wiki?curid=6138" title="Conjecture">
Conjecture

In mathematics, a conjecture is a conclusion or proposition based on incomplete information, for which no proof has been found. Conjectures such as the Riemann hypothesis (still a conjecture) or Fermat's Last Theorem (which was a conjecture until proven in 1995) have shaped much of mathematical history as new areas of mathematics are developed in order to prove them.
Important examples.
Fermat's Last Theorem.
In number theory, Fermat's Last Theorem (sometimes called Fermat's conjecture, especially in older texts) states that no three positive integers "a", "b", and "c" can satisfy the equation "a""n" + "b""n" = "c""n" for any integer value of "n" greater than two.
This theorem was first conjectured by Pierre de Fermat in 1637 in the margin of a copy of "Arithmetica" where he claimed he had a proof that was too large to fit in the margin. The first successful proof was released in 1994 by Andrew Wiles, and formally published in 1995, after 358 years of effort by mathematicians. The unsolved problem stimulated the development of algebraic number theory in the 19th century and the proof of the modularity theorem in the 20th century. It is among the most notable theorems in the history of mathematics and prior to its proof it was in the "Guinness Book of World Records" for "most difficult mathematical problems".
Four color theorem.
In mathematics, the four color theorem, or the four color map theorem, states that, given any separation of a plane into contiguous regions, producing a figure called a "map", no more than four colors are required to color the regions of the map so that no two adjacent regions have the same color. Two regions are called "adjacent" if they share a common boundary that is not a corner, where corners are the points shared by three or more regions. For example, in the map of the United States of America, Utah and Arizona are adjacent, but Utah and New Mexico, which only share a point that also belongs to Arizona and Colorado, are not.
Möbius mentioned the problem in his lectures as early as 1840. The conjecture was first proposed on October 23, 1852 when Francis Guthrie, while trying to color the map of counties of England, noticed that only four different colors were needed. The five color theorem, which has a short elementary proof, states that five colors suffice to color a map and was proven in the late 19th century ; however, proving that four colors suffice turned out to be significantly harder. A number of false proofs and false counterexamples have appeared since the first statement of the four color theorem in 1852.
The four color theorem was proven in 1976 by Kenneth Appel and Wolfgang Haken. It was the first major theorem to be proved using a computer. Appel and Haken's approach started by showing that there is a particular set of 1,936 maps, each of which cannot be part of a smallest-sized counterexample to the four color theorem. (If they did appear, you could make a smaller counter-example.) Appel and Haken used a special-purpose computer program to confirm that each of these maps had this property. Additionally, any map that could potentially be a counterexample must have a portion that looks like one of these 1,936 maps. Showing this required hundreds of pages of hand analysis. Appel and Haken concluded that no smallest counterexamples exists because any must contain, yet do not contain, one of these 1,936 maps. This contradiction means there are no counterexamples at all and that the theorem is therefore true. Initially, their proof was not accepted by all mathematicians because the computer-assisted proof was infeasible for a human to check by hand . Since then the proof has gained wider acceptance, although doubts remain .
Hauptvermutung.
The Hauptvermutung (German for main conjecture) of geometric topology is the conjecture that any two triangulations of a triangulable space have a common refinement, a single triangulation that is a subdivision of both of them. It was originally formulated in 1908, by Steinitz and Tietze.
This conjecture is now known to be false. The non-manifold version was disproved by John Milnor in 1961 using Reidemeister torsion.
The manifold version is true in dimensions . The cases were proved by Tibor Radó and Edwin E. Moise in the 1920s and 1950s, respectively.
Weil conjectures.
In mathematics, the Weil conjectures were some highly influential proposals by on the generating functions (known as local zeta-functions) derived from counting the number of points on algebraic varieties over finite fields.
A variety "V" over a finite field with "q" elements has a finite number of rational points, as well as points over every finite field with "q""k" elements containing that field. The generating function has coefficients derived from the numbers "N""k" of points over the (essentially unique) field with "q""k" elements.
Weil conjectured that such "zeta-functions" should be rational functions, should satisfy a form of functional equation, and should have their zeroes in restricted places. The last two parts were quite consciously modeled on the Riemann zeta function and Riemann hypothesis. The rationality was proved by , the functional equation by , and the analogue of the Riemann hypothesis was proved by 
Poincaré conjecture.
In mathematics, the Poincaré conjecture is a theorem about the characterization of the 3-sphere, which is the hypersphere that bounds the unit ball in four-dimensional space. The conjecture states: An equivalent form of the conjecture involves a coarser form of equivalence than homeomorphism called homotopy equivalence: if a 3-manifold is "homotopy equivalent" to the 3-sphere, then it is necessarily "homeomorphic" to it.
Originally conjectured by Henri Poincaré, the theorem concerns a space that locally looks like ordinary three-dimensional space but is connected, finite in size, and lacks any boundary (a closed 3-manifold). The Poincaré conjecture claims that if such a space has the additional property that each loop in the space can be continuously tightened to a point, then it is necessarily a three-dimensional sphere. An analogous result has been known in higher dimensions for some time.
After nearly a century of effort by mathematicians, Grigori Perelman presented a proof of the conjecture in three papers made available in 2002 and 2003 on arXiv. The proof followed on from the program of Richard Hamilton to use the Ricci flow to attempt to solve the problem. Hamilton later introduced a modification of the standard Ricci flow, called "Ricci flow with surgery" to systematically excise singular regions as they develop, in a controlled way, but was unable to prove this method "converged" in three dimensions. Perelman completed this portion of the proof. Several teams of mathematicians have verified that Perelman's proof is correct.
The Poincaré conjecture, before being proven, was one of the most important open questions in topology.
Riemann hypothesis.
In mathematics, the Riemann hypothesis, proposed by , is a conjecture that the non-trivial zeros of the Riemann zeta function all have real part 1/2. The name is also used for some closely related analogues, such as the Riemann hypothesis for curves over finite fields.
The Riemann hypothesis implies results about the distribution of prime numbers. Along with suitable generalizations, some mathematicians consider it the most important unresolved problem in pure mathematics . The Riemann hypothesis, along with the Goldbach conjecture, is part of Hilbert's eighth problem in David Hilbert's list of 23 unsolved problems; it is also one of the Clay Mathematics Institute Millennium Prize Problems.
P versus NP problem.
The P versus NP problem is a major unsolved problem in computer science. Informally, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer; it is widely conjectured that the answer is no. It was essentially first mentioned in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether a certain NP complete problem could be solved in quadratic or linear time. The precise statement of the P=NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" and is considered by many to be the most important open problem in the field. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.
Resolution of conjectures.
Proof.
Formal mathematics is based on "provable" truth. In mathematics, any number of cases supporting a conjecture, no matter how large, is insufficient for establishing the conjecture's veracity, since a single counterexample would immediately bring down the conjecture. Mathematical journals sometimes publish the minor results of research teams having extended the search for a counterexample farther than previously done. For instance, the Collatz conjecture, which concerns whether or not certain sequences of integers terminate, has been tested for all integers up to 1.2 × 1012 (over a trillion). However, the failure to find a counterexample after extensive search does not constitute a proof that no counterexample exists nor that the conjecture is true, because the conjecture might be false but with a very large minimal counterexample. 
Instead, a conjecture is considered proven only when it has been shown that it is logically impossible for it to be false. There are various methods of doing so; see Mathematical proof#Methods for details.
One method of proof, usable when there are only a finite number of cases that could lead to counterexamples, is known as "brute force": in this approach, all possible cases are considered and shown not to give counterexamples. Sometimes the number of cases is quite large, in which situation a brute-force proof may require as a practical matter the use of a computer algorithm to check all the cases: the validity of the 1976 and 1997 brute-force proofs of the four color theorem by computer was initially doubted, but was eventually confirmed in 2005 by theorem-proving software.
When a conjecture has been proven, it is no longer a conjecture but a theorem. Many important theorems were once conjectures, such as the Geometrization theorem (which resolved the Poincaré conjecture), Fermat's Last Theorem, and others.
Disproof.
Conjectures disproven through counterexample are sometimes referred to as "false conjectures" (cf. the Pólya conjecture and Euler's sum of powers conjecture). In the case of the latter, the first counterexample found involved numbers in the millions, although subsequently it has been found that the minimal counterexample is smaller than that. 
Undecidable conjectures.
Not every conjecture ends up being proven true or false. The continuum hypothesis, which tries to ascertain the relative cardinality of certain infinite sets, was eventually shown to be undecidable (or independent) from the generally accepted set of axioms of set theory. It is therefore possible to adopt this statement, or its negation, as a new axiom in a consistent manner (much as we can take Euclid's parallel postulate as either true or false).
In this case, if a proof uses this statement, researchers will often look for a new proof that "doesn't" require the hypothesis (in the same way that it is desirable that statements in Euclidean geometry be proved using only the axioms of neutral geometry, i.e. no parallel postulate.) The one major exception to this in practice is the axiom of choice—unless studying this axiom in particular, the majority of researchers do not usually worry whether a result requires the axiom of choice.
Conditional proofs.
Sometimes a conjecture is called a "hypothesis" when it is used frequently and repeatedly as an assumption in proofs of other results. For example, the Riemann hypothesis is a conjecture from number theory that (amongst other things) makes predictions about the distribution of prime numbers. Few number theorists doubt that the Riemann hypothesis is true. In anticipation of its eventual proof, some have proceeded to develop further proofs which are contingent on the truth of this conjecture. These are called "conditional proofs": the conjectures assumed appear in the hypotheses of the theorem, for the time being.
These "proofs", however, would fall apart if it turned out that the hypothesis was false, so there is considerable interest in verifying the truth or falsity of conjectures of this type.
In other sciences.
Karl Popper pioneered the use of the term "conjecture" in scientific philosophy. Conjecture is related to hypothesis, which in science refers to a testable conjecture.

</doc>
<doc id="6139" url="https://en.wikipedia.org/wiki?curid=6139" title="Christoph Ludwig Agricola">
Christoph Ludwig Agricola

Christoph Ludwig Agricola (November 5, 1667 – August 8, 1719) was a German landscape painter. He was born and died at Regensburg (Ratisbon).
He trained as a painter in his native country. He spent a great part of his life in travel, visiting England, the Netherlands and France, and residing for a considerable period at Naples.
His numerous landscapes, chiefly cabinet pictures, are remarkable for fidelity to nature, and especially for their skilful representation of varied phases of climate. In composition his style shows the influence of Nicolas Poussin, while in light and colour he imitates Claude Lorrain. He stayed for some years circa 1712 in Venice, where he painted many works for the patron Zaccaria Sagredo.
His pictures can be found in Dresden, Braunschweig, Vienna, Florence, Naples and many other towns of both Germany and Italy.

</doc>
<doc id="6140" url="https://en.wikipedia.org/wiki?curid=6140" title="Claudius">
Claudius

Claudius (; ; 1 August 10 BC – 13 October 54 AD) was Roman emperor from 41 to 54. A member of the Julio-Claudian dynasty, he was the son of Drusus and Antonia Minor. He was born at Lugdunum in Gaul, the first Roman Emperor to be born outside Italy. Because he was afflicted with a limp and slight deafness due to sickness at a young age, his family ostracized him and excluded him from public office until his consulship, shared with his nephew Caligula in 37.
Claudius' infirmity probably saved him from the fate of many other nobles during the purges of Tiberius and Caligula's reigns; potential enemies did not see him as a serious threat. His survival led to his being declared Emperor by the Praetorian Guard after Caligula's assassination, at which point he was the last man of his family.
Despite his lack of experience, Claudius proved to be an able and efficient administrator. He was also an ambitious builder, constructing many new roads, aqueducts, and canals across the Empire. During his reign the Empire began the conquest of Britain (if the earlier invasions of Britain by Caesar and Caligula's aborted attempts are not counted). Having a personal interest in law, he presided at public trials, and issued up to twenty edicts a day. He was seen as vulnerable throughout his reign, particularly by elements of the nobility. Claudius was constantly forced to shore up his position; this resulted in the deaths of many senators. These events damaged his reputation among the ancient writers, though more recent historians have revised this opinion. Many authors contend that he was murdered by his own wife. After his death in 54 AD (at age of 63), his grand-nephew and adopted son Nero succeeded him as Emperor.
He was a descendant of the Octavii Rufi (through Gaius Octavius), Julii Caesares (through Julia Atii and Julia Antonii) and the Claudii Nerones (through Nero Claudius Drusus); he was a great-nephew of Augustus through his full sister Octavia Minor, an uncle of Caligula and finally a great-uncle of Nero through Caligula's father and Nero's grandfather Germanicus.
Family and early life.
Claudius was born on 1 August 10 BC at the Sanctuary of the Three Gauls in what is now Lyon, France. He had two older siblings, Germanicus and Livilla. His mother, Antonia, may have had two other children who died young.
His maternal grandparents were Mark Antony and Octavia Minor, Augustus' sister, and he was therefore the great-great grandnephew of Gaius Julius Caesar. His paternal grandparents were Livia, Augustus' third wife, and Tiberius Claudius Nero. During his reign, Claudius revived the rumor that his father Drusus was actually the illegitimate son of Augustus, to give the appearance that Augustus was Claudius' paternal grandfather.
In 9 BC, his father Drusus unexpectedly died on campaign in Germania, possibly from illness. Claudius was then left to be raised by his mother, who never remarried. When Claudius' disability became evident, the relationship with his family turned sour. Antonia referred to him as a monster, and used him as a standard for stupidity. She seems to have passed her son off on his grandmother Livia for a number of years.
Livia was a little kinder, but nevertheless often sent him short, angry letters of reproof. He was put under the care of a "former mule-driver" to keep him disciplined, under the logic that his condition was due to laziness and a lack of will-power. However, by the time he reached his teenage years his symptoms apparently waned and his family took some notice of his scholarly interests.
In 7 AD, Livy was hired to tutor him in history, with the assistance of Sulpicius Flavus. He spent a lot of his time with the latter and the philosopher Athenodorus. Augustus, according to a letter, was surprised at the clarity of Claudius' oratory. Expectations about his future began to increase.
Public life.
His work as a budding historian damaged his prospects for advancement in public life. According to Vincent Scramuzza and others, Claudius began work on a history of the Civil Wars that was either too truthful or too critical of Octavian—then reigning as Augustus Caesar. In either case, it was far too early for such an account, and may have only served to remind Augustus that Claudius was Antony's descendant. His mother and grandmother quickly put a stop to it, and this may have convinced them that Claudius was not fit for public office. He could not be trusted to toe the existing party line.
When he returned to the narrative later in life, Claudius skipped over the wars of the second triumvirate altogether. But the damage was done, and his family pushed him to the background. When the Arch of Pavia was erected to honor the Imperial clan in 8 BC, Claudius' name (now Tiberius Claudius Nero Germanicus after his elevation to paterfamilias of Claudii Nerones on the adoption of his brother) was inscribed on the edge—past the deceased princes, Gaius and Lucius, and Germanicus' children. There is some speculation that the inscription was added by Claudius himself decades later, and that he originally did not appear at all.
When Augustus died in 14 AD, Claudius — then 23 — appealed to his uncle Tiberius to allow him to begin the "cursus honorum". Tiberius, the new Emperor, responded by granting Claudius consular ornaments. Claudius requested office once more and was snubbed. Since the new Emperor was no more generous than the old, Claudius gave up hope of public office and retired to a scholarly, private life.
Despite the disdain of the Imperial family, it seems that from very early on the general public respected Claudius. At Augustus' death, the "equites", or knights, chose Claudius to head their delegation. When his house burned down, the Senate demanded it be rebuilt at public expense. They also requested that Claudius be allowed to debate in the Senate. Tiberius turned down both motions, but the sentiment remained.
During the period immediately after the death of Tiberius' son, Drusus, Claudius was pushed by some quarters as a potential heir. This again suggests the political nature of his exclusion from public life. However, as this was also the period during which the power and terror of the commander of the Praetorian Guard, Sejanus, was at its peak, Claudius chose to downplay this possibility.
After the death of Tiberius the new emperor Caligula (the son of Claudius' brother Germanicus) recognized Claudius to be of some use. He appointed Claudius his co-consul in 37 in order to emphasize the memory of Caligula's deceased father Germanicus. Despite this, Caligula relentlessly tormented his uncle: playing practical jokes, charging him enormous sums of money, humiliating him before the Senate, and the like. According to Cassius Dio Claudius became very sickly and thin by the end of Caligula's reign, most likely due to stress. A possible surviving portrait of Claudius from this period may support this.
Assassination of Caligula (41 AD).
On 24 January 41, Caligula was assassinated in a broad-based conspiracy involving the Praetorian commander Cassius Chaerea and several senators. There is no evidence that Claudius had a direct hand in the assassination, although it has been argued that he knew about the plot — particularly since he left the scene of the crime shortly before his nephew was murdered. However, after the deaths of Caligula's wife and daughter, it became apparent that Cassius intended to go beyond the terms of the conspiracy and wipe out the Imperial family.
In the chaos following the murder, Claudius witnessed the German guard cut down several uninvolved noblemen, including many of his friends. He fled to the palace to hide. According to tradition, a Praetorian named Gratus found him hiding behind a curtain and suddenly declared him "princeps". A section of the guard may have planned in advance to seek out Claudius, perhaps with his approval. They reassured him that they were not one of the battalions looking for revenge. He was spirited away to the Praetorian camp and put under their protection.
The Senate quickly met and began debating a change of government, but this eventually devolved into an argument over which of them would be the new "princeps". When they heard of the Praetorians' claim, they demanded that Claudius be delivered to them for approval, but he refused, sensing the danger that would come with complying. Some historians, particularly Josephus, claim that Claudius was directed in his actions by the Judaean King Herod Agrippa. However, an earlier version of events by the same ancient author downplays Agrippa's role so it remains uncertain. Eventually the Senate was forced to give in and, in return, Claudius pardoned nearly all the assassins.
As Emperor.
Claudius took several steps to legitimize his rule against potential usurpers, most of them emphasizing his place within the Julio-Claudian family. He adopted the name "Caesar" as a cognomen, as the name still carried great weight with the populace. In order to do so, he dropped the cognomen "Nero" which he had adopted as "paterfamilias" of the Claudii Nerones when his brother Germanicus was adopted out.
While Claudius had never been formally adopted either by Augustus or his successors, he was nevertheless the grandson of his sister Octavia, and so he felt that he had the right of family. He also adopted the name "Augustus" as the two previous emperors had done at their accessions. He kept the honorific "Germanicus" to display the connection with his heroic brother. He deified his paternal grandmother Livia to highlight her position as wife of the divine Augustus. Claudius frequently used the term "filius Drusi" (son of Drusus) in his titles, in order to remind the people of his legendary father and lay claim to his reputation.
Since Claudius was the first Emperor proclaimed on the initiative of the Praetorian Guard instead of the Senate, his repute suffered at the hands of commentators (such as Seneca). Moreover, he was the first Emperor who resorted to bribery as a means to secure army loyalty and rewarded the soldiers of the Praetorian Guard that had elevated him with 15,000 sesterces. Tiberius and Augustus had both left gifts to the army and guard in their wills, and upon Caligula's death the same would have been expected, even if no will existed. Claudius remained grateful to the guard, however, issuing coins with tributes to the Praetorians in the early part of his reign.
Expansion of the Empire.
Under Claudius, the Empire underwent its first major expansion since the reign of Augustus. The provinces of Thrace, Noricum, Pamphylia, Lycia, and Judea were annexed (or put under direct rule) under various circumstances during his term. The annexation of Mauretania, begun under Caligula, was completed after the defeat of rebel forces, and the official division of the former client kingdom into two Imperial provinces. The most far-reaching conquest was the conquest of Britannia".
In 43 AD, Claudius sent Aulus Plautius with four legions to Britain ("Britannia") after an appeal from an ousted tribal ally. Britain was an attractive target for Rome because of its material wealth – particularly mines and slaves. It was also a haven for Gallic rebels and the like, and so could not be left alone much longer. Claudius himself travelled to the island after the completion of initial offensives, bringing with him reinforcements and elephants. The latter must have made an impression on the Britons when they were displayed in the large tribal centre of Camulodunum, modern day Colchester. The Roman "colonia" of "Colonia Claudia Victricensis" was established as the provincial capital of the newly established province of Britannia at Camulodunum, where a large Temple was dedicated in his honour.
He left after 16 days, but remained in the provinces for some time. The Senate granted him a triumph for his efforts. Only members of the Imperial family were allowed such honours, but Claudius subsequently lifted this restriction for some of his conquering generals. He was granted the honorific "Britannicus" but only accepted it on behalf of his son, never using the title himself. When the Briton general Caractacus was captured in 50 AD, Claudius granted him clemency. Caractacus lived out his days on land provided by the Roman state, an unusual end for an enemy commander.
Claudius conducted a census in 48 that found 5,984,072 Roman citizens (adult males with Roman citizenship; women, children, slaves, and free adult males without Roman citizenship were not counted), an increase of around a million since the census conducted at Augustus' death. He had helped increase this number through the foundation of Roman colonies that were granted blanket citizenship. These colonies were often made out of existing communities, especially those with elites who could rally the populace to the Roman cause. Several colonies were placed in new provinces or on the border of the Empire to secure Roman holdings as quickly as possible.
Judicial and legislative affairs.
Claudius personally judged many of the legal cases tried during his reign. Ancient historians have many complaints about this, stating that his judgments were variable and sometimes did not follow the law. He was also easily swayed. Nevertheless, Claudius paid detailed attention to the operation of the judicial system.
He extended the summer court session, as well as the winter term, by shortening the traditional breaks. Claudius also made a law requiring plaintiffs to remain in the city while their cases were pending, as defendants had previously been required to do. These measures had the effect of clearing out the docket. The minimum age for jurors was also raised to 25 in order to ensure a more experienced jury pool.
Claudius also settled disputes in the provinces. He freed the island of Rhodes from Roman rule for their good faith and exempted Troy from taxes. Early in his reign, the Greeks and Jews of Alexandria sent him two embassies at once after riots broke out between the two communities. This resulted in the famous "Letter to the Alexandrians", which reaffirmed Jewish rights in the city but also forbade them to move in more families en masse. According to Josephus, he then reaffirmed the rights and freedoms of all the Jews in the Empire.
One of Claudius's investigators discovered that many old Roman citizens based in the modern city of Trento were not in fact citizens. The Emperor issued a declaration, contained in the "Tabula clesiana", that they would be considered to hold citizenship from then on, since to strip them of their status would cause major problems. However, in individual cases, Claudius punished false assumption of citizenship harshly, making it a capital offense. Similarly, any freedmen found to be laying false claim to membership of the Roman equestrian order were sold back into slavery.
Numerous edicts were issued throughout Claudius' reign. These were on a number of topics, everything from medical advice to moral judgments. A famous medical example is one promoting yew juice as a cure for snakebite. Suetonius wrote that he is even said to have thought of an edict allowing public flatulence for good health. One of the more famous edicts concerned the status of sick slaves. Masters had been abandoning ailing slaves at the temple of Aesculapius on Tiber Island to die instead of providing them with medical assistance and care, and then reclaiming them if they lived. Claudius ruled that slaves who were thus abandoned and recovered after such treatment would be free. Furthermore, masters who chose to kill slaves rather than take care of them were liable to be charged with murder.
Public works.
Claudius embarked on many public works throughout his reign, both in the capital and in the provinces. He built two aqueducts, the Aqua Claudia, begun by Caligula, and the Anio Novus. These entered the city in 52 AD and met at the famous Porta Maggiore. He also restored a third, the Aqua Virgo.
He paid special attention to transportation. Throughout Italy and the provinces he built roads and canals. Among these was a large canal leading from the Rhine to the sea, as well as a road from Italy to Germany – both begun by his father, Drusus. Closer to Rome, he built a navigable canal on the Tiber, leading to Portus, his new port just north of Ostia. This port was constructed in a semicircle with two moles and a lighthouse at its mouth. The construction also had the effect of reducing flooding in Rome.
The port at Ostia was part of Claudius' solution to the constant grain shortages that occurred in winter, after the Roman shipping season. The other part of his solution was to insure the ships of grain merchants who were willing to risk travelling to Egypt in the off-season. He also granted their sailors special privileges, including citizenship and exemption from the Lex Papia-Poppaea, a law that regulated marriage. In addition, he repealed the taxes that Caligula had instituted on food, and further reduced taxes on communities suffering drought or famine.
The last part of Claudius' plan was to increase the amount of arable land in Italy. This was to be achieved by draining the Fucine lake, which would have the added benefit of making the nearby river navigable year-round. A tunnel was dug through the lake bed, but the plan was a failure. The tunnel was crooked and not large enough to carry the water, which caused it to back up when opened. The resultant flood washed out a large gladiatorial exhibition held to commemorate the opening, causing Claudius to run for his life along with the other spectators. The draining of the lake was revisited many times in history, including by Emperors Trajan and Hadrian, and Holy Roman Emperor Frederick II in the Middle Ages. It was finally achieved by the Prince Torlonia in the 19th century, producing over of new arable land. He expanded the Claudian tunnel to three times its original size.
Claudius and the Senate.
Because of the circumstances of his accession, Claudius took great pains to please the Senate. During regular sessions, the Emperor sat among the Senate body, speaking in turn. When introducing a law, he sat on a bench between the consuls in his position as Holder of the Power of Tribune (The Emperor could not officially serve as a Tribune of the Plebes as he was a Patrician, but it was a power taken by previous rulers). He refused to accept all his predecessors' titles (including Imperator) at the beginning of his reign, preferring to earn them in due course. He allowed the Senate to issue its own bronze coinage for the first time since Augustus. He also put the Imperial provinces of Macedonia and Achaea back under Senate control.
Claudius set about remodeling the Senate into a more efficient, representative body. He chided the senators about their reluctance to debate bills introduced by himself, as noted in the fragments of a surviving speech:
In 47 he assumed the office of "Censor" with Lucius Vitellius, which had been allowed to lapse for some time. He struck the names of many senators and equites who no longer met qualifications, but showed respect by allowing them to resign in advance. At the same time, he sought to admit eligible men from the provinces. The Lyon Tablet preserves his speech on the admittance of Gallic senators, in which he addresses the Senate with reverence but also with criticism for their disdain of these men. (He even jokes about how the Senate had admitted members from beyond Gallia Narbonensis (Lyons, France), i.e. himself). He also increased the number of Patricians by adding new families to the dwindling number of noble lines. Here he followed the precedent of Lucius Junius Brutus and Julius Caesar.
Nevertheless, many in the Senate remained hostile to Claudius, and many plots were made on his life. This hostility carried over into the historical accounts. As a result, Claudius reduced the Senate's power for the sake of efficiency. The administration of Ostia was turned over to an Imperial Procurator after construction of the port. Administration of many of the empire's financial concerns was turned over to Imperial appointees and freedmen. This led to further resentment and suggestions that these same freedmen were ruling the Emperor.
Plots and coup attempts.
Several coup attempts were made during Claudius' reign, resulting in the deaths of many senators. Appius Silanus was executed early in Claudius' reign under questionable circumstances. Shortly after, a large rebellion was undertaken by the Senator Vinicianus and Scribonianus, the governor of Dalmatia and gained quite a few senatorial supporters. It ultimately failed because of the reluctance of Scribonianus' troops, which led to the suicide of the main conspirators.
Many other senators tried different conspiracies and were condemned. Claudius' son-in-law Pompeius Magnus was executed for his part in a conspiracy with his father Crassus Frugi. Another plot involved the consulars Lusiius Saturninus, Cornelius Lupus, and Pompeius Pedo.
In 46, Asinius Gallus, the grandson of Asinius Pollio, and Titus Statilius Taurus Corvinus were exiled for a plot hatched with several of Claudius' own freedmen. Valerius Asiaticus was executed without public trial for unknown reasons. The ancient sources say the charge was adultery, and that Claudius was tricked into issuing the punishment. However, Claudius singles out Asiaticus for special damnation in his speech on the Gauls, which dates over a year later, suggesting that the charge must have been much more serious.
Asiaticus had been a claimant to the throne in the chaos following Caligula's death and a co-consul with the Titus Statilius Taurus Corvinus mentioned above. Most of these conspiracies took place before Claudius' term as Censor, and may have induced him to review the Senatorial rolls. The conspiracy of Gaius Silius in the year after his Censorship, 48, is detailed in the section discussing Claudius' third wife, Messalina. Suetonius states that a total of 35 senators and 300 knights were executed for offenses during Claudius' reign. Needless to say, the responses to these conspiracies could not have helped Senate-emperor relations.
Secretariat and centralization of powers.
Claudius was hardly the first emperor to use freedmen to help with the day-to-day running of the Empire. He was, however, forced to increase their role as the powers of the "princeps" became more centralized and the burden larger. This was partly due to the ongoing hostility of the Senate, as mentioned above, but also due to his respect for the senators. Claudius did not want free-born magistrates to have to serve under him, as if they were not peers.
The secretariat was divided into bureaus, with each being placed under the leadership of one freedman. Narcissus was the secretary of correspondence. Pallas became the secretary of the treasury. Callistus became secretary of justice. There was a fourth bureau for miscellaneous issues, which was put under Polybius until his execution for treason. The freedmen could also officially speak for the Emperor, as when Narcissus addressed the troops in Claudius' stead before the conquest of Britain.
Since these were important positions, the senators were aghast at their being placed in the hands of former slaves. If freedmen had total control of money, letters, and law, it seemed it would not be hard for them to manipulate the Emperor. This is exactly the accusation put forth by the ancient sources. However, these same sources admit that the freedmen were loyal to Claudius.
He was similarly appreciative of them and gave them due credit for policies where he had used their advice. However, if they showed treasonous inclinations, the Emperor did punish them with just force, as in the case of Polybius and Pallas' brother, Felix. There is no evidence that the character of Claudius' policies and edicts changed with the rise and fall of the various freedmen, suggesting that he was firmly in control throughout.
Regardless of the extent of their political power, the freedmen did manage to amass wealth through their positions. Pliny the Elder notes that several of them were richer than Crassus, the richest man of the Republican era.
Religious reforms.
Claudius, as the author of a treatise on Augustus' religious reforms, felt himself in a good position to institute some of his own. He had strong opinions about the proper form for state religion. He refused the request of Alexandrian Greeks to dedicate a temple to his divinity, saying that only gods may choose new gods. He restored lost days to festivals and got rid of many extraneous celebrations added by Caligula. He re-instituted old observances and archaic language.
Claudius was concerned with the spread of eastern mysteries within the city and searched for more Roman replacements. He emphasized the Eleusinian mysteries which had been practiced by so many during the Republic. He expelled foreign astrologers, and at the same time rehabilitated the old Roman soothsayers (known as haruspices) as a replacement. He was especially hard on Druidism, because of its incompatibility with the Roman state religion and its proselytizing activities.
It is also reported that at one time he expelled the Jews from Rome, probably because the Jews within the city caused continuous disturbances at the instigation of Chrestus. Claudius opposed proselytizing in any religion, even in those regions where he allowed natives to worship freely. The results of all these efforts were recognized even by Seneca, who has an ancient Latin god defend Claudius in his satire.
Public games and entertainments.
According to Suetonius, Claudius was extraordinarily fond of games. He is said to have risen with the crowd after gladiatorial matches and given unrestrained praise to the fighters. Claudius also presided over many new and original events. Soon after coming into power, Claudius instituted games to be held in honor of his father on the latter's birthday. Annual games were also held in honour of his accession, and took place at the Praetorian camp where Claudius had first been proclaimed Emperor.
Claudius organised a performance of the Secular Games, marking the 800th anniversary of the founding of Rome. Augustus had performed the same games less than a century prior. Augustus' excuse was that the interval for the games was 110 years, not 100, but his date actually did not qualify under either reasoning. Claudius also presented naval battles to mark the attempted draining of the Fucine Lake, as well as many other public games and shows.
At Ostia, in front of a crowd of spectators, Claudius fought a killer whale which was trapped in the harbour. The event was witnessed by Pliny the Elder:
Claudius also restored and adorned many of the venues around Rome. The old wooden barriers of the Circus Maximus were replaced with ones made of gold-ornamented marble. A new section of the Circus was designated for seating the senators, who previously had sat among the general public. Claudius rebuilt Pompey's Theatre after it had been destroyed by fire, organising special fights at the re-dedication which he observed from a special platform in the orchestra box.
Marriages and personal life.
Suetonius and the other ancient authors accused Claudius of being dominated by women and wives, of being uxorious, and of being a womanizer.
Claudius married four times, after two failed betrothals. The first betrothal was to his distant cousin Aemilia Lepida, but was broken for political reasons. The second was to Livia Medullina, which ended with Medullina's sudden death on their wedding day.
Plautia Urgulanilla.
Plautia Urgulanilla was the granddaughter of Livia's confidant Urgulania. During their marriage she gave birth to a son, Claudius Drusus. Drusus died of asphyxiation in his early teens, shortly after becoming engaged to Junilla, the daughter of Sejanus.
Claudius later divorced Urgulanilla for adultery and on suspicion of murdering her sister-in-law Apronia. When Urgulanilla gave birth after the divorce, Claudius repudiated the baby girl, Claudia, as the father was allegedly one of his own freedmen. This action made him later the target of criticism by his enemies.
Aelia Paetina.
Soon after (possibly in 28), Claudius married Aelia Paetina, a relative of Sejanus, if not Sejanus's adoptive sister. During their marriage, Claudius and Paetina had a daughter, Claudia Antonia. He later divorced her after the marriage became a political liability, although Leon (1948) suggests it may have been due to emotional and mental abuse by Paetina.
Valeria Messalina.
Some years after divorcing Aelia Paetina, in 38 or early 39, Claudius married Valeria Messalina, who was his first cousin once removed and closely allied with Caligula's circle. Shortly thereafter, she gave birth to a daughter Claudia Octavia. A son, first named Tiberius Claudius Germanicus, and later known as Britannicus, was born just after Claudius' accession.
This marriage ended in tragedy. The ancient historians allege that Messalina was a nymphomaniac who was regularly unfaithful to Claudius — Tacitus states she went so far as to compete with a prostitute to see who could have the most sexual partners in a night — and manipulated his policies in order to amass wealth. In 48, Messalina married her lover Gaius Silius in a public ceremony while Claudius was at Ostia.
Sources disagree as to whether or not she divorced the Emperor first, and whether the intention was to usurp the throne. Scramuzza, in his biography, suggests that Silius may have convinced Messalina that Claudius was doomed, and the union was her only hope of retaining rank and protecting her children. The historian Tacitus suggests that Claudius's ongoing term as Censor may have prevented him from noticing the affair before it reached such a critical point. Whatever the case, the result was the execution of Silius, Messalina, and most of her circle. Claudius made the Praetorians promise to kill him if he ever married again. 
Agrippina the Younger.
Claudius did marry once more. The ancient sources tell that his freedmen pushed three candidates, Caligula's third wife Lollia Paulina, Claudius's divorced second wife Aelia Paetina and Claudius's niece Agrippina the Younger. According to Suetonius, Agrippina won out through her feminine wiles.
The truth is likely more political. The attempted coup d'etat by Silius and Messalina had probably made Claudius realize the weakness of his position as a member of the Claudian but not the Julian family. This weakness was compounded by the fact that he did not have an obvious adult heir, Britannicus being just a boy.
Agrippina was one of the few remaining descendants of Augustus, and her son Lucius Domitius Ahenobarbus (the future Emperor Nero) was one of the last males of the Imperial family. Coup attempts could rally around the pair and Agrippina was already showing such ambition. It has been suggested in recent times that the Senate may have pushed for the marriage, to end the feud between the Julian and Claudian branches. This feud dated back to Agrippina's mother's actions against Tiberius after the death of her husband Germanicus (Claudius's brother), actions which Tiberius had gladly punished. In any case, Claudius accepted Agrippina and later adopted the newly mature Nero as his son.
Nero was made joint heir with the underage Britannicus, married to Octavia and promoted. This was not as unusual as it seems, to people acquainted with hereditary monarchies. Barbara Levick notes that Augustus had named his grandson Postumus Agrippa and his stepson Tiberius as joint heirs.
Tiberius named Caligula joint heir with his grandson Tiberius Gemellus. Adoption of adults or near adults was an old tradition in Rome, when a suitable natural adult heir was unavailable as was the case during Britannicus' minority. S.V. Oost suggests that Claudius had previously looked to adopt one of his sons-in-law to protect his own reign.
Faustus Cornelius Sulla Felix, married to his daughter Claudia Antonia, was only descended from Octavia and Antony on one side – not close enough to the Imperial family to prevent doubts (that did not stop others from making him the object of a coup attempt against Nero a few years later). Besides which, he was the half-brother of Valeria Messalina and at this time those wounds were still fresh. Nero was more popular with the general public as the grandson of Germanicus and the direct descendant of Augustus.
Claudius' affliction and personality.
The historian Suetonius describes the physical manifestations of Claudius' affliction in relatively good detail. His knees were weak and gave way under him and his head shook. He stammered and his speech was confused. He slobbered and his nose ran when he was excited. The Stoic Seneca states in his "Apocolocyntosis" that Claudius' voice belonged to no land animal, and that his hands were weak as well.
However, he showed no physical deformity, as Suetonius notes that when calm and seated he was a tall, well-built figure of "dignitas". When angered or stressed, his symptoms became worse. Historians agree that this condition improved upon his accession to the throne. Claudius himself claimed that he had exaggerated his ailments to save his life.
Modern assessments of his health have changed several times in the past century. Prior to World War II, infantile paralysis (or polio) was widely accepted as the cause. This is the diagnosis used in Robert Graves' Claudius novels, first published in the 1930s. Polio does not explain many of the described symptoms, however, and a more recent theory implicates cerebral palsy as the cause, as outlined by Ernestine Leon. Tourette syndrome has also been considered a possibility.
As a person, ancient historians described Claudius as generous and lowbrow, a man who sometimes lunched with the plebeians. They also paint him as bloodthirsty and cruel, overly fond of gladiatorial combat and executions, and very quick to anger; Claudius himself acknowledged the latter trait, and apologized publicly for his temper. According to the ancient historians he was also overly trusting, and easily manipulated by his wives and freedmen. But at the same time they portray him as paranoid and apathetic, dull and easily confused.
The extant works of Claudius present a different view, painting a picture of an intelligent, scholarly, well-read, and conscientious administrator with an eye to detail and justice. Thus, Claudius becomes an enigma. Since the discovery of his "Letter to the Alexandrians" in the last century, much work has been done to rehabilitate Claudius and determine where the truth lies.
Scholarly works and their impact.
Claudius wrote copiously throughout his life. Arnaldo Momigliano states that during the reign of Tiberius – which covers the peak of Claudius' literary career – it became impolitic to speak of republican Rome. The trend among the young historians was to either write about the new empire or obscure antiquarian subjects. Claudius was the rare scholar who covered both.
Besides the history of Augustus' reign that caused him so much grief, his major works included an Etruscan history and eight volumes on Carthaginian history, as well as an Etruscan dictionary and a book on dice playing. (Claudius is actually the last person known to have been able to read Etruscan.) Despite the general avoidance of the Republican era, he penned a defense of Cicero against the charges of Asinius Gallus. Modern historians have used this to determine the nature of his politics and of the aborted chapters of his civil war history.
He proposed a reform of the Latin alphabet by the addition of three new letters, two of which served the function of the modern letters "W" and "Y". He officially instituted the change during his censorship but they did not survive his reign. Claudius also tried to revive the old custom of putting dots between successive words (Classical Latin was written with no spacing). Finally, he wrote an eight-volume autobiography, that Suetonius describes as lacking in taste. Since Claudius (like most of the members of his dynasty) harshly criticized his predecessors and relatives in surviving speeches, it is not hard to imagine the nature of Suetonius' charge.
None of the works survive but live on as sources for the surviving histories of the Julio-Claudian dynasty. Suetonius quotes Claudius' autobiography once and must have used it as a source numerous times. Tacitus uses Claudius' arguments for the orthographical innovations mentioned above and may have used him for some of the more antiquarian passages in his annals. Claudius is the source for numerous passages of Pliny's "Natural History".
The influence of historical study on Claudius is obvious. In his speech on Gallic senators, he uses a version of the founding of Rome identical to that of Livy, his tutor in adolescence. The detail of his speech borders on the pedantic, a common mark of all his extant works and he goes into long digressions on related matters. This indicates a deep knowledge of a variety of historical subjects, that he could not help but share. Many of the public works instituted in his reign were based on plans first suggested by Julius Caesar. Levick believes this emulation of Caesar may have spread to all aspects of his policies.
His censorship seems to have been based on those of his ancestors, particularly Appius Claudius Caecus and he used the office to put into place many policies based on those of Republican times. This is when many of his religious reforms took effect and his building efforts greatly increased during his tenure. In fact, his assumption of the office of Censor may have been motivated by a desire to see his academic labors bear fruit. For example, he believed (as most Romans) that his ancestor Appius Claudius Caecus had used the censorship to introduce the letter "R" and so used his own term to introduce his new letters.
Death.
The consensus of ancient historians was that Claudius was murdered by poison – possibly contained in mushrooms or on a feather – and died in the early hours of 13 October 54 AD. Accounts vary greatly. Some claim Claudius was in Rome while others claim he was in Sinuessa.
Nearly all implicate his final wife, Agrippina, as the instigator. Agrippina and Claudius had become more combative in the months leading up to his death. This carried on to the point where Claudius openly lamented his bad wives, and began to comment on Britannicus' approaching manhood with an eye towards restoring his status within the imperial family. Agrippina had motive in ensuring the succession of Nero before Britannicus could gain power.
Some implicate either his taster Halotus, his doctor Xenophon, or the infamous poisoner Locusta as the administrator of the fatal substance. Some say he died after prolonged suffering following a single dose at dinner, and some have him recovering only to be poisoned again. Among contemporary sources, Seneca the younger ascribed the emperor's death to natural causes, while Josephus only spoke of rumors on his poisoning.
In modern times, some authors have cast doubt on whether Claudius was murdered or merely succumbed to illness or old age. Some modern scholars claim the near universality of the accusations in ancient texts lends credence to the crime. Claudius' ashes were interred in the Mausoleum of Augustus on 24 October 54 AD, after a funeral in the manner of Augustus.
After death.
Divine honours.
Already, while alive, he received the widespread private worship of a living Princeps and was worshipped in Britannia in his own temple in Camulodunum.
Claudius was deified by Nero and the Senate almost immediately. Those who regard this homage as cynical should note that, cynical or not, such a move would hardly have benefited those involved, had Claudius been "hated", as some commentators, both modern and historic, characterize him. Many of Claudius' less solid supporters quickly became Nero's men. Claudius' will had been changed shortly before his death to either recommend Nero and Britannicus jointly or perhaps just Britannicus, who would have been considered an adult man according to Roman law only a few months later.
Views of the new regime.
Agrippina had sent away Narcissus shortly before Claudius' death, and now murdered the freedman. The last act of this secretary of letters was to burn all of Claudius' correspondence — most likely so it could not be used against him and others in an already hostile new regime. Thus Claudius' private words about his own policies and motives were lost to history. Just as Claudius had criticized his predecessors in official edicts (see below), Nero often criticized the deceased Emperor and many of Claudius' laws and edicts were disregarded under the reasoning that he was too stupid and senile to have meant them.
Seneca's Apocolocyntosis reinforces the view of Claudius as an unpleasant fool and this remained the official view for the duration of Nero's reign. Eventually Nero stopped referring to his deified adoptive father at all, and realigned with his birth family. Claudius' temple was left unfinished after only some of the foundation had been laid down. Eventually the site was overtaken by Nero's Golden House.
Flavian and later perspectives.
The Flavians, who had risen to prominence under Claudius, took a different tack. They were in a position where they needed to shore up their legitimacy, but also justify the fall of the Julio-Claudians. They reached back to Claudius in contrast with Nero, to show that they were good associated with good. Commemorative coins were issued of Claudius and his son Britannicus, who had been a friend of the Emperor Titus (Titus was born in 39, Britannicus was born in 41). When Nero's Golden House was burned, the Temple of Claudius was finally completed on the Caelian Hill.
However, as the Flavians became established, they needed to emphasize their own credentials more, and their references to Claudius ceased. Instead, he was lumped with the other emperors of the fallen dynasty. His state cult in Rome probably continued until the abolition of all such cults of dead Emperors by Maximinus Thrax in 237–238. The "Feriale Duranum", probably identical to the festival calendars of every regular army unit, assigns him a sacrifice of a steer on his birthday, the Kalends of August. And such commemoration (and consequent feasting) probably continued until the Christianization and disintegration of the army in the late 4th century.
Views of ancient historians.
The main ancient historians Tacitus, Suetonius, and Cassius Dio all wrote after the last of the Flavians had gone. All three were senators or "equites". They took the side of the Senate in most conflicts with the Princeps, invariably viewing him as being in the wrong. This resulted in biases, both conscious and unconscious. Suetonius lost access to the official archives shortly after beginning his work. He was forced to rely on second-hand accounts when it came to Claudius (with the exception of Augustus' letters, which had been gathered earlier). Suetonius painted Claudius as a ridiculous figure, belittling many of his acts and attributing the objectively good works to his retinue.
Tacitus wrote a narrative for his fellow senators and fitted each of the emperors into a simple mold of his choosing. He wrote of Claudius as a passive pawn and an idiot in affairs relating to the palace and often in public life. During his censorship of 47-8 Tacitus allows the reader a glimpse of a Claudius who is more statesmanlike (XI.23-25), but it is a mere glimpse. Tacitus is usually held to have 'hidden' his use of Claudius' writings and to have omitted Claudius' character from his works. Even his version of Claudius' Lyons tablet speech is edited to be devoid of the Emperor's personality. Dio was less biased, but seems to have used Suetonius and Tacitus as sources. Thus the conception of Claudius as the weak fool, controlled by those he supposedly ruled, was preserved for the ages.
As time passed, Claudius was mostly forgotten outside of the historians' accounts. His books were lost first, as their antiquarian subjects became unfashionable. In the 2nd century, Pertinax, who shared his birthday, became emperor, overshadowing commemoration of Claudius.
In modern literature, film and radio.
The best known fictional representation of the Emperor Claudius were the books "I, Claudius" and "Claudius the God" (published in 1934 and 1935) by Robert Graves, both written in the first-person to give the reader the impression that they are Claudius' autobiography. Graves employed a fictive artifice to suggest that they were recently discovered, genuine translations of Claudius' writings. Claudius' extant letters, speeches, and sayings were incorporated into the text (mostly in the second book, "Claudius the God"), to add authenticity.
In 1937, director Josef von Sternberg attempted a film version of "I, Claudius", with Charles Laughton as Claudius. However, the lead actress Merle Oberon suffered a near-fatal accident and the movie was never finished. The surviving reels were featured in the BBC documentary "The Epic That Never Was" (1965). The motion picture rights for a new film eventually passed to producer Scott Rudin.
Graves's two books were the basis for a British television adaptation "I, Claudius", produced by the BBC. The series starred Derek Jacobi as Claudius and was broadcast in 1976 on BBC2. It was a substantial critical success, and won several BAFTA awards. The series was later broadcast in the United States on "Masterpiece Theatre" in 1977. The 1996 7-VHS release and the later DVD release of the television series, include the "The Epic That Never Was" documentary.
A radio adaptation of the Graves novels by Robin Brooks and directed by Jonquil Panting, was broadcast in six one-hour episodes on BBC Radio 4 beginning 4 December 2010. The cast featured Tom Goodman-Hill as Claudius, Derek Jacobi as Augustus, Harriet Walter as Livia, Tim McInnerny as Tiberius and Samuel Barnett as Caligula.
In 2011, it was announced rights for a miniseries adaptation passed to HBO and BBC2. Anne Thomopoulos and Jane Tranter, producers of the popular HBO–BBC2 "Rome" miniseries, are attached to the new "I, Claudius" project.
The 1954 film "Demetrius and the Gladiators" also portrayed him sympathetically, played by Barry Jones.
On television, Freddie Jones portrayed Claudius in the 1968 British television series "The Caesars".
The 1975 TV Special "Further Up Pompeii!" (based on the Frankie Howerd sit-com "Up Pompeii!") featured Cyril Appleton as Claudius.
In the 1979 motion picture "Caligula", where the role was performed by Giancarlo Badessi, Claudius is depicted as an idiot, in contrast to Robert Graves' portrait of Claudius as a cunning and deeply intelligent man, who is perceived by others to be an idiot.
The 1985 made-for-television miniseries "A.D." features actor Richard Kiley as Claudius. Kiley portrays him as thoughtful, but willing to cater to public opinion as well as being under the influence of Agrippina.
There is also a reference to Claudius' suppression of a coup in the movie "Gladiator", though the incident is entirely fictional.
In literature, Claudius and his contemporaries appear in the historical novel "The Roman" by Mika Waltari. Canadian-born science fiction writer A. E. van Vogt reimagined Robert Graves' Claudius story, in his two novels "Empire of the Atom" and "The Wizard of Linn".

</doc>
<doc id="6141" url="https://en.wikipedia.org/wiki?curid=6141" title="Cardinal">
Cardinal

Cardinal or The Cardinal may refer to:

</doc>
<doc id="6172" url="https://en.wikipedia.org/wiki?curid=6172" title="Cantor set">
Cantor set

In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of remarkable and deep properties. It was discovered in 1874 by Henry John Stephen Smith and introduced by German mathematician Georg Cantor in 1883.
Through consideration of this set, Cantor and others helped lay the foundations of modern point-set topology. Although Cantor himself defined the set in a general, abstract way, the most common modern construction is the Cantor ternary set, built by removing the middle thirds of a line segment. Cantor himself only mentioned the ternary construction in passing, as an example of a more general idea, that of a perfect set that is nowhere dense.
Construction and formula of the ternary set.
The Cantor ternary set formula_1 is created by deleting the open middle third from each of a set of line segments repeatedly. One starts by deleting the open middle third (, ) from the interval leaving two line segments: [0,  ∪ [, 1]. Next, the open middle third of each of these remaining segments is deleted, leaving four line segments: ∪ [,  ∪ [, ] ∪ [, 1]. This process is continued ad infinitum, where the "n"th set is
The Cantor ternary set contains all points in the interval [0, 1] that are not deleted at any step in this infinite process:
The first six steps of this process are illustrated below.
An explicit closed formula for the Cantor set is
or
This process of removing middle thirds is a simple example of a finite subdivision rule.
It is perhaps most intuitive to think about the Cantor set as the set of real numbers between zero and one whose ternary expansion in base three doesn't contain the digit 1. As the above diagram shows, the Cantor ternary set is in bijection with the set of paths in a full binary tree on countably many nodes. Such a path is completely determined by an infinite series of instructions determining at each node whether we go left or right as we traverse the diagram. This in turn describes the ternary expansion of the number. For example, such a path might begin (left, right, right, left, left...) which describes the ternary number 0.02200... In particular, the Cantor set is in bijection with the set of binary sequences.
Composition.
Since the Cantor set is defined as the set of points not excluded, the proportion (i.e., measure) of the unit interval remaining can be found by total length removed. This total is the geometric progression
So that the proportion left is 1 – 1 = 0.
This calculation shows that the Cantor set cannot contain any interval of non-zero length. In fact, it may seem surprising that there should be anything left — after all, the sum of the lengths of the removed intervals is equal to the length of the original interval. However, a closer look at the process reveals that there must be something left, since removing the "middle third" of each interval involved removing open sets (sets that do not include their endpoints). So removing the line segment (1/3, 2/3) from the original interval [0, 1] leaves behind the points 1/3 and 2/3. Subsequent steps do not remove these (or other) endpoints, since the intervals removed are always internal to the intervals remaining. So the Cantor set is not empty, and in fact contains an uncountably infinite number of points.
It may appear that "only" the endpoints are left, but that is not the case either. The number 1/4, for example, is in the bottom third, so it is not removed at the first step, and is in the top third of the bottom third, and is in the bottom third of "that", and in the "top" third of "that", and so on ad infinitum—alternating between top and bottom thirds. Since it is never in one of the middle thirds, it is never removed, and yet it is also not one of the endpoints of any middle third. The number 3/10 is also in the Cantor set and is not an endpoint.
In the sense of cardinality, "most" members of the Cantor set are not endpoints of deleted intervals. Since each step removes a finite number of intervals and the number of steps is countable, the set of endpoints is countable while the whole Cantor set is uncountable.
Properties.
Cardinality.
It can be shown that there are as many points left behind in this process as there were to begin with, and that therefore, the Cantor set is uncountable. To see this, we show that there is a function "f" from the Cantor set formula_1 to the closed interval that is surjective (i.e. "f" maps from formula_1 onto [0,1) so that the cardinality of formula_1 is no less than that of Since formula_1 is a subset of [0,1, its cardinality is also no greater, so the two cardinalities must in fact be equal, by the Cantor–Bernstein–Schroeder theorem.
To construct this function, consider the points in the [0, 1] interval in terms of base 3 (or ternary) notation. 
Recall that some points admit more than one representation in this notation, as for example 1/3, that can be written as 0.13 but also as 0.022222...3, and 2/3, that can be written as 0.23 but also as 0.12222...3.
When we remove the middle third, this contains the numbers with ternary numerals of the form 0.1xxxxx...3 where xxxxx...3 is strictly between 00000...3 and 22222...3. So the numbers remaining after the first step consist of
This can be summarized by saying that those numbers that admit a ternary representation such that the first digit after the decimal point is not 1 are the ones remaining after the first step.
The second step removes numbers of the form 0.01xxxx...3 and 0.21xxxx...3, and (with appropriate care for the endpoints) it can be concluded that the remaining numbers are those with a ternary numeral where neither of the first "two" digits is 1. Continuing in this way, for a number not to be excluded at step "n", it must have a ternary representation whose "n"th digit is not 1. For a number to be in the Cantor set, it must not be excluded at any step, it must admit a numeral representation consisting entirely of 0s and 2s. It is worth emphasising that numbers like 1, 1/3 = 0.13 and 7/9 = 0.213 are in the Cantor set, as they have ternary numerals consisting entirely of 0s and 2s: 1 = 0.2222...3, 1/3 = 0.022222...3 and 7/9 = 0.2022222...3. So while a number in formula_1 may have either a terminating or a recurring ternary numeral, one of its representations will consist entirely of 0s and 2s.
The function from formula_1 to [0,1] is defined by taking the numeral that does consist entirely of 0s and 2s, replacing all the 2s by 1s, and interpreting the sequence as a binary representation of a real number. In a formula,
For any number "y" in [0,1], its binary representation can be translated into a ternary representation of a number "x" in formula_1 by replacing all the 1s by 2s. With this, "f"("x") = "y" so that "y" is in the range of "f". For instance if "y" = 3/5 = 0.100110011001...2, we write "x" = 0.200220022002...3 = 7/10. Consequently, "f" is surjective; however, "f" is "not" injective — interestingly enough, the values for which "f"("x") coincides are those at opposing ends of one of the "middle thirds" removed. For instance, 7/9 = 0.2022222...3 and 8/9 = 0.2200000...3 so "f"(7/9) = 0.101111...2 = 0.112 = "f"(8/9).
So there are as many points in the Cantor set as there are in [0, 1], and the Cantor set is uncountable (see Cantor's diagonal argument). However, the set of endpoints of the removed intervals is countable, so there must be uncountably many numbers in the Cantor set which are not interval endpoints. As noted above, one example of such a number is ¼, which can be written as 0.02020202020...3 in ternary notation.
The Cantor set contains as many points as the interval from which it is taken, yet itself contains no interval of nonzero length. The irrational numbers have the same property, but the Cantor set has the additional property of being closed, so it is not even dense in any interval, unlike the irrational numbers which are dense in every interval.
It has been conjectured that all algebraic irrational numbers are normal. Since members of the Cantor set are not normal, this would imply that all members of the Cantor set are either rational or transcendental.
Self-similarity.
The Cantor set is the prototype of a fractal. It is self-similar, because it is equal to two copies of itself, if each copy is shrunk by a factor of 3 and translated. More precisely, there are two functions, the left and right self-similarity transformations, formula_16 and formula_17, which leave the Cantor set invariant up to homeomorphism: formula_18
Repeated iteration of formula_19 and formula_20 can be visualized as an infinite binary tree. That is, at each node of the tree, one may consider the subtree to the left or to the right. Taking the set formula_21 together with function composition forms a monoid, the dyadic monoid.
The automorphisms of the binary tree are its hyperbolic rotations, and are given by the modular group. Thus, the Cantor set is a homogeneous space in the sense that for any two points formula_22 and formula_23 in the Cantor set formula_1, there exists a homeomorphism formula_25 with formula_26. These homeomorphisms can be expressed explicitly, as Möbius transformations. 
The Hausdorff dimension of the Cantor set is equal to ln(2)/ln(3) ≈ 0.631.
Topological and analytical properties.
Although "the" Cantor set typically refers to the original, middle-thirds Cantor described above, topologists often talk about "a" Cantor set, which means any topological space that is homeomorphic (topologically equivalent) to it.
As the above summation argument shows, the Cantor set is uncountable but has Lebesgue measure 0. Since the Cantor set is the complement of a union of open sets, it itself is a closed subset of the reals, and therefore a complete metric space. Since it is also totally bounded, the Heine–Borel theorem says that it must be compact.
For any point in the Cantor set and any arbitrarily small neighborhood of the point, there is some other number with a ternary numeral of only 0s and 2s, as well as numbers whose ternary numerals contain 1s. Hence, every point in the Cantor set is an accumulation point (also called a cluster point or limit point) of the Cantor set, but none is an interior point. A closed set in which every point is an accumulation point is also called a perfect set in topology, while a closed subset of the interval with no interior points is nowhere dense in the interval.
Every point of the Cantor set is also an accumulation point of the complement of the Cantor set.
For any two points in the Cantor set, there will be some ternary digit where they differ — one will have 0 and the other 2. By splitting the Cantor set into "halves" depending on the value of this digit, one obtains a partition of the Cantor set into two closed sets that separate the original two points. In the relative topology on the Cantor set, the points have been separated by a clopen set. Consequently, the Cantor set is totally disconnected. As a compact totally disconnected Hausdorff space, the Cantor set is an example of a Stone space.
As a topological space, the Cantor set is naturally homeomorphic to the product of countably many copies of the space formula_27, where each copy carries the discrete topology. This is the space of all sequences in two digits 
which can also be identified with the set of 2-adic integers. The basis for the open sets of the product topology are cylinder sets; the homeomorphism maps these to the subspace topology that the Cantor set inherits from the natural topology on the real number line. This characterization of the Cantor space as a product of compact spaces gives a second proof that Cantor space is compact, via Tychonoff's theorem.
From the above characterization, the Cantor set is homeomorphic to the p-adic integers, and, if one point is removed from it, to the p-adic numbers.
The Cantor set is a subset of the reals, which are a metric space with respect to the ordinary distance metric; therefore the Cantor set itself is a metric space, by using that same metric. Alternatively, one can use the p-adic metric on formula_29: given two sequences formula_30, the distance between them is formula_31, where formula_32 is the smallest index such that formula_33; if there is no such index, then the two sequences are the same, and one defines the distance to be zero. These two metrics generate the same topology on the Cantor set.
We have seen above that the Cantor set is a totally disconnected perfect compact metric space. Indeed, in a sense it is the only one: every nonempty totally disconnected perfect compact metric space is homeomorphic to the Cantor set. See Cantor space for more on spaces homeomorphic to the Cantor set.
The Cantor set is sometimes regarded as "universal" in the category of compact metric spaces, since any compact metric space is a continuous image of the Cantor set; however this construction is not unique and so the Cantor set is not universal in the precise categorical sense. The "universal" property has important applications in functional analysis, where it is sometimes known as the "representation theorem for compact metric spaces".
For any integer "q" ≥ 2, the topology on the group G=Z"q"ω (the countable direct sum) is discrete. Although the Pontrjagin dual Γ is also Z"q"ω, the topology of Γ is compact. One can see that Γ is totally disconnected and perfect - thus it is homeomorphic to the Cantor set. It is easiest to write out the homeomorphism explicitly in the case "q"=2. (See Rudin 1962 p 40.)
Measure and probability.
The Cantor set can be seen as the compact group of binary sequences, and as such, it is endowed with a natural Haar measure. When normalized so that the measure of the set is 1, it is a model of an infinite sequence of coin tosses. Furthermore, one can show that the usual Lebesgue measure on the interval is an image of the Haar measure on the Cantor set, while the natural injection into the ternary set is a canonical example of a singular measure. It can also be shown that the Haar measure is an image of any probability, making the Cantor set a universal probability space in some ways.
In Lebesgue measure theory, the Cantor set is an example of a set which is uncountable and has zero measure.
Cantor numbers.
If we define a Cantor number as a member of the Cantor set, then
Variants.
Smith–Volterra–Cantor set.
Instead of repeatedly removing the middle third of every piece as in the Cantor set, we could also keep removing any other fixed percentage (other than 0% and 100%) from the middle. In the case where the middle 8/10 of the interval is removed, we get a remarkably accessible case — the set consists of all numbers in [0,1] that can be written as a decimal consisting entirely of 0s and 9s.
By removing progressively smaller percentages of the remaining pieces in every step, one can also construct sets homeomorphic to the Cantor set that have positive Lebesgue measure, while still being nowhere dense. See Smith–Volterra–Cantor set for an example.
Cantor dust.
Cantor dust is a multi-dimensional version of the Cantor set. It can be formed by taking a finite Cartesian product of the Cantor set with itself, making it a Cantor space. Like the Cantor set, Cantor dust has zero measure.
A different 2D analogue of the Cantor set is the Sierpinski carpet, where a square is divided up into nine smaller squares, and the middle one removed. The remaining squares are then further divided into nine each and the middle removed, and so on ad infinitum. The 3D analogue of this is the Menger sponge.
Historical remarks.
Cantor himself defined the set in a general, abstract way, and mentioned the ternary construction only in passing, as an example of a more general idea, that of a perfect set that is nowhere dense. The original paper provides several different constructions of the abstract concept.
This set would have been considered abstract at the time when Cantor devised it. Cantor himself was led to it by practical concerns about the set of points where a trigonometric series might fail to converge. The discovery did much to set him on the course for developing an abstract, general theory of infinite sets.
A column capital from the Ancient Egyptian site of the island of Philae carries a pattern which resembles the Cantor set. Cantor may have seen the image, as his cousin was an Egyptologist.

</doc>
<doc id="6173" url="https://en.wikipedia.org/wiki?curid=6173" title="Cardinal number">
Cardinal number

In mathematics, cardinal numbers, or cardinals for short, are a generalization of the natural numbers used to measure the cardinality (size) of sets. The cardinality of a finite set is a natural number: the number of elements in the set. The "transfinite" cardinal numbers describe the sizes of infinite sets.
Cardinality is defined in terms of bijective functions. Two sets have the same cardinality if, and only if, there is a one-to-one correspondence (bijection) between the elements of the two sets. In the case of finite sets, this agrees with the intuitive notion of size. In the case of infinite sets, the behavior is more complex. A fundamental theorem due to Georg Cantor shows that it is possible for infinite sets to have different cardinalities, and in particular the cardinality of the set of real numbers is greater than the cardinality of the set of natural numbers. It is also possible for a proper subset of an infinite set to have the same cardinality as the original set, something that cannot happen with proper subsets of finite sets.
There is a transfinite sequence of cardinal numbers:
This sequence starts with the natural numbers including zero (finite cardinals), which are followed by the aleph numbers (infinite cardinals of well-ordered sets). The aleph numbers are indexed by ordinal numbers. Under the assumption of the axiom of choice, this transfinite sequence includes every cardinal number. If one rejects that axiom, the situation is more complicated, with additional infinite cardinals that are not alephs.
Cardinality is studied for its own sake as part of set theory. It is also a tool used in branches of mathematics including model theory, combinatorics, abstract algebra, and mathematical analysis. In category theory, the cardinal numbers form a skeleton of the category of sets.
History.
The notion of cardinality, as now understood, was formulated by Georg Cantor, the originator of set theory, in 1874–1884. Cardinality can be used to compare an aspect of finite sets; e.g. the sets {1,2,3} and {4,5,6} are not "equal", but have the "same cardinality", namely three (this is established by the existence of a bijection, i.e. a one-to-one correspondence, between the two sets; e.g. {1->4, 2->5, 3->6}).
Cantor applied his concept of bijection to infinite sets; e.g. the set of natural numbers N = {0, 1, 2, 3, ...}. Thus, all sets having a bijection with N he called denumerable (countably infinite) sets and they all have the same cardinal number. This cardinal number is called formula_2, aleph-null. He called the cardinal numbers of these infinite sets transfinite cardinal numbers.
Cantor proved that any unbounded subset of N has the same cardinality as N, even though this might appear to run contrary to intuition. He also proved that the set of all ordered pairs of natural numbers is denumerable; this implies that the set of all rational numbers is also denumerable, since every rational can be represented by a pair of integers. He later proved that the set of all algebraic numbers is also denumerable. Each algebraic number "z" may be encoded as a finite sequence of integers which are the coefficients in the polynomial equation of which it is the solution, i.e. the ordered n-tuple ("a"0, "a"1, ..., "an"), "ai" ∈ Z together with a pair of rationals ("b"0, "b"1) such that "z" is the unique root of the polynomial with coefficients ("a"0, "a"1, ..., "an") that lies in the interval ("b"0, "b"1).
In his 1874 paper "On a Property of the Collection of All Real Algebraic Numbers", Cantor proved that there exist higher-order cardinal numbers by showing that the set of real numbers has cardinality greater than that of N. His proof used an argument with nested intervals, but in an 1891 paper he proved the same result using his ingenious but simpler diagonal argument. The new cardinal number of the set of real numbers is called the cardinality of the continuum and Cantor used the symbol formula_3 for it.
Cantor also developed a large portion of the general theory of cardinal numbers; he proved that there is a smallest transfinite cardinal number (formula_2, aleph-null), and that for every cardinal number there is a next-larger cardinal
His Continuum Hypothesis is the proposition that formula_3 is the same as formula_7. This hypothesis has been found to be independent of the standard axioms of mathematical set theory; it can neither be proved nor disproved from the standard assumptions.
Motivation.
In informal use, a cardinal number is what is normally referred to as a "counting number", provided that 0 is included: 0, 1, 2, ... They may be identified with the natural numbers beginning with 0. The counting numbers are exactly what can be defined formally as the finite cardinal numbers. Infinite cardinals only occur in higher-level mathematics and logic.
More formally, a non-zero number can be used for two purposes: to describe the size of a set, or to describe the position of an element in a sequence. For finite sets and sequences it is easy to see that these two notions coincide, since for every number describing a position in a sequence we can construct a set which has exactly the right size, e.g. 3 describes the position of 'c' in the sequence <'a','b','c','d'...>, and we can construct the set {a,b,c} which has 3 elements. However, when dealing with infinite sets it is essential to distinguish between the two — the two notions are in fact different for infinite sets. Considering the position aspect leads to ordinal numbers, while the size aspect is generalized by the cardinal numbers described here.
The intuition behind the formal definition of cardinal is the construction of a notion of the relative size or "bigness" of a set without reference to the kind of members which it has. For finite sets this is easy; one simply counts the number of elements a set has. In order to compare the sizes of larger sets, it is necessary to appeal to more subtle notions.
A set "Y" is at least as big as a set "X" if there is an injective mapping from the elements of "X" to the elements of "Y". An injective mapping identifies each element of the set "X" with a unique element of the set "Y". This is most easily understood by an example; suppose we have the sets "X" = {1,2,3} and "Y" = {a,b,c,d}, then using this notion of size we would observe that there is a mapping:
which is injective, and hence conclude that "Y" has cardinality greater than or equal to "X". Note the element d has no element mapping to it, but this is permitted as we only require an injective mapping, and not necessarily an injective and onto mapping. The advantage of this notion is that it can be extended to infinite sets.
We can then extend this to an equality-style relation. Two sets "X" and "Y" are said to have the same cardinality if there exists a bijection between "X" and "Y". By the Schroeder–Bernstein theorem, this is equivalent to there being "both" an injective mapping from "X" to "Y" "and" an injective mapping from "Y" to "X". We then write |"X"| = |"Y"|. The cardinal number of "X" itself is often defined as the least ordinal "a" with |"a"| = |"X"|. This is called the von Neumann cardinal assignment; for this definition to make sense, it must be proved that every set has the same cardinality as "some" ordinal; this statement is the well-ordering principle. It is however possible to discuss the relative cardinality of sets without explicitly assigning names to objects.
The classic example used is that of the infinite hotel paradox, also called Hilbert's paradox of the Grand Hotel. Suppose you are an innkeeper at a hotel with an infinite number of rooms. The hotel is full, and then a new guest arrives. It is possible to fit the extra guest in by asking the guest who was in room 1 to move to room 2, the guest in room 2 to move to room 3, and so on, leaving room 1 vacant. We can explicitly write a segment of this mapping:
In this way we can see that the set {1,2,3...} has the same cardinality as the set {2,3,4...} since a bijection between the first and the second has been shown. This motivates the definition of an infinite set being any set which has a proper subset of the same cardinality; in this case {2,3,4...} is a proper subset of {1,2,3...}.
When considering these large objects, we might also want to see if the notion of counting order coincides with that of cardinal defined above for these infinite sets. It happens that it doesn't; by considering the above example we can see that if some object "one greater than infinity" exists, then it must have the same cardinality as the infinite set we started out with. It is possible to use a different formal notion for number, called ordinals, based on the ideas of counting and considering each number in turn, and we discover that the notions of cardinality and ordinality are divergent once we move out of the finite numbers.
It can be proved that the cardinality of the real numbers is greater than that of the natural numbers just described. This can be visualized using Cantor's diagonal argument;
classic questions of cardinality (for instance the continuum hypothesis) are concerned with discovering whether there is some cardinal between some pair of other infinite cardinals. In more recent times mathematicians have been describing the properties of larger and larger cardinals.
Since cardinality is such a common concept in mathematics, a variety of names are in use. Sameness of cardinality is sometimes referred to as equipotence, equipollence, or equinumerosity. It is thus said that two sets with the same cardinality are, respectively, equipotent, equipollent, or equinumerous.
Formal definition.
Formally, assuming the axiom of choice, the cardinality of a set "X" is the least ordinal α such that there is a bijection between "X" and α. This definition is known as the von Neumann cardinal assignment. If the axiom of choice is not assumed we need to do something different. The oldest definition of the cardinality of a set "X" (implicit in Cantor and explicit in Frege and Principia Mathematica) is as the class "of all sets that are equinumerous with "X". This does not work in ZFC or other related systems of axiomatic set theory because if "X" is non-empty, this collection is too large to be a set. In fact, for "X ≠ ∅" there is an injection from the universe into "[X" by mapping a set "m" to "{m} × X" and so by the axiom of limitation of size, "" is a proper class. The definition does work however in type theory and in New Foundations and related systems. However, if we restrict from this class to those equinumerous with "X" that have the least rank, then it will work (this is a trick due to Dana Scott: it works because the collection of objects with any given rank is a set).
Formally, the order among cardinal numbers is defined as follows: |"X"| ≤ |"Y"| means that there exists an injective function from "X" to "Y". The Cantor–Bernstein–Schroeder theorem states that if |"X"| ≤ |"Y"| and |"Y"| ≤ |"X"| then |"X"| = |"Y"|. The axiom of choice is equivalent to the statement that given two sets "X" and "Y", either |"X"| ≤ |"Y"| or |"Y"| ≤ |"X"|.
A set "X" is Dedekind-infinite if there exists a proper subset "Y" of "X" with |"X"| = |"Y"|, and Dedekind-finite if such a subset doesn't exist. The finite cardinals are just the natural numbers, i.e., a set "X" is finite if and only if |"X"| = |"n"| = "n" for some natural number "n". Any other set is infinite. Assuming the axiom of choice, it can be proved that the Dedekind notions correspond to the standard ones. It can also be proved that the cardinal formula_2 (aleph null or aleph-0, where aleph is the first letter in the Hebrew alphabet, represented formula_9) of the set of natural numbers is the smallest infinite cardinal, i.e. that any infinite set has a subset of cardinality formula_10 The next larger cardinal is denoted by formula_7 and so on. For every ordinal α there is a cardinal number formula_12 and this list exhausts all infinite cardinal numbers.
Cardinal arithmetic.
We can define arithmetic operations on cardinal numbers that generalize the ordinary operations for natural numbers. It can be shown that for finite cardinals these operations coincide with the usual operations for natural numbers. Furthermore, these operations share many properties with ordinary arithmetic.
Successor cardinal.
If the axiom of choice holds, every cardinal κ has a successor κ+ > κ, and there are no cardinals between κ and its successor. (Without the axiom of choice, using Hartogs' theorem, it can be shown that, for any cardinal number κ, there is a minimal cardinal κ+, so that + ࣞ κ.-->formula_13) For finite cardinals, the successor is simply κ + 1. For infinite cardinals, the successor cardinal differs from the successor ordinal.
Cardinal addition.
If "X" and "Y" are disjoint, addition is given by the union of "X" and "Y". If the two sets are not already disjoint, then they can be replaced by disjoint sets of the same cardinality, e.g., replace "X" by "X"×{0} and "Y" by "Y"×{1}.
Zero is an additive identity "κ" + 0 = 0 + "κ" = "κ".
Addition is associative ("κ" + "μ") + "ν" = "κ" + ("μ" + "ν").
Addition is commutative "κ" + "μ" = "μ" + "κ".
Addition is non-decreasing in both arguments:
Assuming the axiom of choice, addition of infinite cardinal numbers is easy. If either κ or μ is infinite, then
Subtraction.
Assuming the axiom of choice and, given an infinite cardinal σ and a cardinal μ, there exists a cardinal κ such that μ + κ = σ if and only if μ ≤ σ. It will be unique (and equal to σ) if and only if μ < σ.
Cardinal multiplication.
The product of cardinals comes from the cartesian product.
"κ"·0 = 0·"κ" = 0.
"κ"·"μ" = 0 → ("κ" = 0 or "μ" = 0).
One is a multiplicative identity "κ"·1 = 1·"κ" = "κ".
Multiplication is associative ("κ"·"μ")·"ν" = "κ"·("μ"·"ν").
Multiplication is commutative "κ"·"μ" = "μ"·"κ".
Multiplication is non-decreasing in both arguments:
"κ" ≤ "μ" → ("κ"·"ν" ≤ "μ"·"ν" and "ν"·"κ" ≤ "ν"·"μ").
Multiplication distributes over addition:
"κ"·("μ" + "ν") = "κ"·"μ" + "κ"·"ν" and
Assuming the axiom of choice, multiplication of infinite cardinal numbers is also easy. If either "κ" or "μ" is infinite and both are non-zero, then
Division.
Assuming the axiom of choice and, given an infinite cardinal "π" and a non-zero cardinal μ, there exists a cardinal κ such that μ · κ = "π" if and only if μ ≤ "π". It will be unique (and equal to "π") if and only if μ < "π".
Cardinal exponentiation.
Exponentiation is given by
where "XY" is the set of all functions from "Y" to "X".
Exponentiation is non-decreasing in both arguments:
Note that 2|"X"| is the cardinality of the power set of the set "X" and Cantor's diagonal argument shows that 2|"X"| > |"X"| for any set "X". This proves that no largest cardinal exists (because for any cardinal "κ", we can always find a larger cardinal 2κ). In fact, the class of cardinals is a proper class. (This proof fails in some set theories, notably New Foundations.)
All the remaining propositions in this section assume the axiom of choice:
If 2 ≤ κ and 1 ≤ μ and at least one of them is infinite, then:
Using König's theorem, one can prove κ < κcf(κ) and κ < cf(2κ) for any infinite cardinal κ, where cf(κ) is the cofinality of κ.
Roots.
Assuming the axiom of choice and, given an infinite cardinal κ and a finite cardinal μ greater than 0, the cardinal ν satisfying formula_20 will be κ.
Logarithms.
Assuming the axiom of choice and, given an infinite cardinal κ and a finite cardinal μ greater than 1, there may or may not be a cardinal λ satisfying formula_21. However, if such a cardinal exists, it is infinite and less than κ, and any finite cardinality ν greater than 1 will also satisfy formula_22.
The logarithm of an infinite cardinal number κ is defined as the least cardinal number μ such that κ ≤ 2μ. Logarithms of infinite cardinals are useful in some fields of mathematics, for example in the study of cardinal invariants of topological spaces, though they lack some of the properties that logarithms of positive real numbers possess.
The continuum hypothesis.
The continuum hypothesis (CH) states that there are no cardinals strictly between formula_2 and formula_24 The latter cardinal number is also often denoted by formula_3; it is the cardinality of the continuum (the set of real numbers). In this case formula_26 The generalized continuum hypothesis (GCH) states that for every infinite set "X", there are no cardinals strictly between | "X" | and 2| "X" |. The continuum hypothesis is independent of the usual axioms of set theory, the Zermelo-Fraenkel axioms together with the axiom of choice (ZFC).
References.
Notes
Bibliography

</doc>
<doc id="6174" url="https://en.wikipedia.org/wiki?curid=6174" title="Cardinality">
Cardinality

In mathematics, the cardinality of a set is a measure of the "number of elements of the set". For example, the set A = {2, 4, 6} contains 3 elements, and therefore A has a cardinality of 3. There are two approaches to cardinality – one which compares sets directly using bijections and injections, and another which uses cardinal numbers.
The cardinality of a set is also called its size, when no confusion with other notions of size is possible.
The cardinality of a set "A" is usually denoted | "A" |, with a vertical bar on each side; this is the same notation as absolute value and the meaning depends on context. Alternatively, the cardinality of a set "A" may be denoted by n("A"), "A", card("A"), or # "A".
Comparing sets.
While the cardinality of a finite set is just the number of its elements, extending the notion to infinite sets usually starts with defining the notion of comparison of arbitrary (in particular infinite) sets.
Definition 3: | "A" | < | "B" |.
If | "A" | ≤ | "B" | and | "B" | ≤ | "A" | then | "A" | = | "B" | (Cantor–Bernstein–Schroeder theorem). The axiom of choice is equivalent to the statement that | "A" | ≤ | "B" | or | "B" | ≤ | "A" | for every "A","B".
Cardinal numbers.
Above, "cardinality" was defined functionally. That is, the "cardinality" of a set was not defined as a specific object itself. However, such an object can be defined as follows.
The relation of having the same cardinality is called equinumerosity, and this is an equivalence relation on the class of all sets. The equivalence class of a set "A" under this relation then consists of all those sets which have the same cardinality as "A". There are two ways to define the "cardinality of a set":
Assuming AC, the cardinalities of the infinite sets are denoted
For each ordinal formula_2, formula_3 is the least cardinal number greater than formula_4.
The cardinality of the natural numbers is denoted aleph-null (formula_5), while the cardinality of the real numbers is denoted by "formula_6" (a lowercase fraktur script "c"), and is also referred to as the cardinality of the continuum. Cantor showed, using the diagonal argument, that formula_7. We can show that formula_8, this also being the cardinality of the set of all subsets of the natural numbers. The continuum hypothesis says that formula_9, i.e. formula_10 is the smallest cardinal number bigger than formula_5, i.e. there is no set whose cardinality is strictly between that of the integers and that of the real numbers.
The continuum hypothesis is independent of ZFC, a standard axiomatization of set theory; that is, it is impossible to prove the continuum hypothesis or its negation from ZFC (provided ZFC is consistent). See below for more details on the cardinality of the continuum.
Finite, countable and uncountable sets.
If the axiom of choice holds, the law of trichotomy holds for cardinality. Thus we can make the following definitions:
Infinite sets.
Our intuition gained from finite sets breaks down when dealing with infinite sets. In the late nineteenth century Georg Cantor, Gottlob Frege, Richard Dedekind and others rejected the view of Galileo (which derived from Euclid) that the whole cannot be the same size as the part. One example of this is Hilbert's paradox of the Grand Hotel.
Indeed, Dedekind defined an infinite set as one that can be placed into a one-to-one correspondence with a strict subset (that is, having the same size in Cantor's sense); this notion of infinity is called Dedekind infinite. Cantor introduced the cardinal numbers, and showed that (according to his bijection-based definition of size) some infinite sets are greater than others. The smallest infinite cardinality is that of the natural numbers (formula_5).
Cardinality of the continuum.
One of Cantor's most important results was that the cardinality of the continuum (formula_15) is greater than that of the natural numbers (formula_5); that is, there are more real numbers R than whole numbers N. Namely, Cantor showed that
The continuum hypothesis states that there is no cardinal number between the cardinality of the reals and the cardinality of the natural numbers, that is,
However, this hypothesis can neither be proved nor disproved within the widely accepted ZFC axiomatic set theory, if ZFC is consistent.
Cardinal arithmetic can be used to show not only that the number of points in a real number line is equal to the number of points in any segment of that line, but that this is equal to the number of points on a plane and, indeed, in any finite-dimensional space. These results are highly counterintuitive, because they imply that there exist proper subsets and proper supersets of an infinite set "S" that have the same size as "S", although "S" contains elements that do not belong to its subsets, and the supersets of "S" contain elements that are not included in it.
The first of these results is apparent by considering, for instance, the tangent function, which provides a one-to-one correspondence between the interval (−½π, ½π) and R (see also Hilbert's paradox of the Grand Hotel).
The second result was first demonstrated by Cantor in 1878, but it became more apparent in 1890, when Giuseppe Peano introduced the space-filling curves, curved lines that twist and turn enough to fill the whole of any square, or cube, or hypercube, or finite-dimensional space. These curves are not a direct proof that a line has the same number of points as a finite-dimensional space, but they can be used to obtain such a proof.
Cantor also showed that sets with cardinality strictly greater than formula_6 exist (see his generalized diagonal argument and theorem). They include, for instance:
Both have cardinality
The cardinal equalities formula_21 formula_22 and formula_23 can be demonstrated using cardinal arithmetic:
Union and intersection.
If "A" and "B" are "disjoint" sets, then
From this, one can show that in general the cardinalities of unions and intersections are related by

</doc>
<doc id="6176" url="https://en.wikipedia.org/wiki?curid=6176" title="Cecil B. DeMille">
Cecil B. DeMille

Cecil Blount DeMille (; August 12, 1881 – January 21, 1959) was an American filmmaker. Between 1913 and 1956, he made seventy features, both silent and sound films. He is acknowledged as a founding father of the Hollywood film industry, and the most commercially successful producer-director in cinema history. His films were distinguished by their epic scale, and by his cinematic showmanship. He made silent films of every genre: social dramas, comedies, Westerns, farces, morality plays, and historical pageants.
DeMille began his career as a stage actor in 1900. He later moved to writing and directing stage productions, some with Jesse Lasky, who was then a vaudeville producer. DeMille's first film, "The Squaw Man" (1914), was also the first feature film shot in Hollywood. Its interracial love story made it a phenomenal hit and it "put Hollywood on the map." The continued success of his productions led to the founding of Paramount Pictures with Lasky and Adolph Zukor. His first biblical epic, "The Ten Commandments" (1923), was both a critical and financial success; it held the Paramount revenue record for twenty-five years.
In 1927 he directed "The King of Kings", a biography of Jesus Christ, which was acclaimed for its sensitivity and reached more than 800 million viewers. "The Sign of the Cross" (1932) was the first sound film to integrate all aspects of cinematic technique. "Cleopatra" (1934) was his first film to be nominated for the Academy Award for Best Picture. After more than thirty years in Hollywood, DeMille reached the pinnacle of his career with "Samson and Delilah" (1949), a biblical epic which did "an all-time record business." Along with biblical and historical narratives, he also directed films oriented toward "neo-naturalism," which tried to portray the laws of man fighting the forces of nature.
He went on to receive his first nomination for the Academy Award for Best Director for his circus drama "The Greatest Show on Earth" (1952), which won the Academy Award for Best Picture. His last and most famous film, "The Ten Commandments" (1956), is currently the seventh highest-grossing film of all-time adjusted for inflation. In addition to his Best Picture Award, he received an Academy Honorary Award for his film contributions, the Palme d'Or (posthumously) for "Union Pacific (film)", a DGA Award for Lifetime Achievement, and the Irving G. Thalberg Memorial Award. He was also the first recipient of the Golden Globe Cecil B. DeMille Award, which was later named in his honor.
DeMille name.
There are several variants of DeMille's surname. His family's Dutch surname was originally spelled "de Mil" and then became "de Mille". As an adult, he adopted the spelling "DeMille" for professional purposes but continued to use "de Mille" in private life. The family name "de Mille" was used by his children Cecilia, John, Richard, and Katherine. DeMille's brother William and his daughters, Margaret and Agnes, as well as DeMille's granddaughter, Cecilia de Mille Presley, also used the "de Mille" spelling.
Family, childhood, youth.
Cecil Blount DeMille was born in Ashfield, Massachusetts, while his parents were vacationing there, and grew up in Washington, North Carolina. His father, Henry Churchill de Mille (1853–1893), was a North Carolina-born dramatist and lay reader in the Episcopal Church, who had earlier begun a career as a playwright, writing his first play at age 15. His mother was Matilda Beatrice DeMille (née Samuel), whose parents were both of German Jewish heritage. She emigrated from England with her parents in 1871 when she was 18, where they settled in Brooklyn. Beatrice grew up in a middle-class English household. DeMille's mother was related to British politician Herbert Louis Samuel.
DeMille's parents met as members of a music and literary society in New York. Henry was a tall, red-headed student. Beatrice was intelligent, educated, forthright, and strong-willed. They were both born in 1853 and both loved the theater. When they married, Beatrice converted to Henry's faith. Henry worked as a playwright, administrator, and faculty member during the early years of The American Academy of Dramatic Arts, established in New York City in 1884. He built a house for his family in Wayne, New Jersey.
The family spent time in Pompton Lakes, New Jersey, operating a private school in that town and attending Christ Episcopal Church. DeMille recalled that this church was the place where he visualized the story of his 1923 version of "The Ten Commandments". Henry read to his children nightly, both from the classics and from the Bible. DeMille studied Scripture his entire life and read the Bible during lunch in the studio commissary. He was the first to admit that he did not attend church services but he did profess an unshakable belief in prayer. He stated that his films were a continuation of his father's work. "My ministry," said DeMille, "has been to make religious movies and to get more people to read the Bible than anyone else ever has."
In 1893, at the age of forty, Henry de Mille contracted typhoid fever and died suddenly, leaving Beatrice with three children, a house, and no savings. Beatrice had "enthusiastically supported" her husband's theatrical aspirations. In his eulogy, she wrote:
Within eight weeks of Henry's death, Beatrice opened an acting workshop in her home, the Henry C. De Mille School for Girls. She later became the second female play broker on Broadway. DeMille attended Pennsylvania Military College in Chester, Pennsylvania from the age of fifteen. Both DeMille (Class of 1900) and his brother William (Class of 1901) also attended and graduated from the American Academy of Dramatic Arts, which they attended on scholarship. The Academy later honored DeMille with an Alumni Achievement Award.
Career.
Broadway.
DeMille began his career as an actor on the Broadway stage in the theatrical company of Charles Frohman in 1900. His brother William was establishing himself as a playwright and sometimes invited him to collaborate. DeMille performed on stage with actors whom he would later direct in films: Charlotte Walker, Mary Pickford, and Pedro de Cordoba. DeMille also produced and directed plays. DeMille found success in the spring of 1913 producing "Reckless Age" by Lee Wilson, a play about a high society girl wrongly accused of manslaughter starring Frederick Burton and Sydney Shields. DeMille and his brother at times worked with the legendary impresario David Belasco, who had been a friend and collaborator of their father. Changes in the theater rendered DeMille's melodramas obsolete before they were produced, and true theatrical success eluded him. By 1913 he was having difficulty supporting his wife and baby daughter.
Moving pictures.
In July 1913 DeMille, Jesse Lasky, Sam Goldfish (later Samuel Goldwyn), and a group of East Coast businessmen created the Jesse L. Lasky Feature Play Company. On December 12, 1913, DeMille, his cast, and crew boarded a Southern Pacific train bound for Flagstaff via New Orleans. His tentative plan was to shoot a film in Arizona, but he disliked the quality of light he saw there. He continued to Los Angeles. Once there, he chose not to shoot in Edendale, where many studios were, but in Hollywood. He also flouted the dictum that a film should run twenty minutes. He made his first film run sixty minutes, as long as a short play. "The Squaw Man" (1914), co-directed by Oscar Apfel, was a sensation and it established the Lasky Company.
Silent era.
The first few years of the Lasky Company (soon to become Famous Players-Lasky) were spent in making films nonstop, literally writing the language of film. DeMille adapted Belasco's dramatic lighting techniques to film technology, mimicking moonlight with Hollywood's first attempts at "motivated lighting" in "The Warrens of Virginia"
After five years and thirty hit films, DeMille became Hollywood's most successful director. In the silent era, he was renowned for "Male and Female" (1919), "Manslaughter" (1921), and "The Godless Girl" (1928). DeMille's trademark scenes included bathtubs, lion attacks, and Roman orgies. A number of his films featured scenes in two-color Technicolor.
The immense popularity of DeMille's silent films enabled him to branch out into other areas. The Roaring Twenties were the boom years and DeMille took full advantage, opening the Mercury Aviation Company, one of America's first commercial airlines. He was also a real estate speculator, an underwriter of political campaigns, and a Bank of America executive, approving loans for other filmmakers. 
Sound era.
When "talking pictures" were innovated in 1928, DeMille made a successful transition, offering his own innovations to the painful process; he devised a microphone boom and a soundproof camera blimp. He also popularized the camera crane.
DeMille made stars of unknown actors: Gloria Swanson, Bebe Daniels, Rod La Rocque, William Boyd, Claudette Colbert, and Charlton Heston. He also cast established stars such as Gary Cooper, Robert Preston, Paulette Goddard and Fredric March in multiple pictures. DeMille displayed a loyalty to his performers, casting them repeatedly. They included Henry Wilcoxon, Julia Faye, Joseph Schildkraut, Ian Keith, Charles Bickford, Theodore Roberts, Akim Tamiroff and William Boyd. DeMille was credited by actor Edward G. Robinson with saving his career following his eclipse in the Hollywood blacklist.
DeMille had a reputation for autocratic behavior on the set, singling out and berating extras who were not paying attention. A number of these displays were thought to be staged, however, an exercise in discipline. He despised actors who were unwilling to take physical risks, especially when he had first demonstrated that the required stunt would not harm them. This occurred with Victor Mature in "Samson and Delilah". Mature refused to wrestle Jackie the Lion, even though DeMille had just tussled with the lion, proving that he was tame. DeMille told the actor that he was "one hundred percent yellow". Paulette Goddard's refusal to risk personal injury in a scene involving fire in "Unconquered" cost her DeMille's favor and a role in "The Greatest Show on Earth".
DeMille was adept at directing "thousands of extras", and many of his pictures include spectacular setpieces: the toppling of the pagan temple in "Samson and Delilah"; train wrecks in "The Road to Yesterday", "Union Pacific" and "The Greatest Show on Earth"; the destruction of an airship in "Madam Satan"; and the parting of the Red Sea in both versions of "The Ten Commandments".
DeMille first used three-strip Technicolor in "North West Mounted Police" (1940). Audiences liked its highly saturated color, so DeMille made no further black-and-white features.
Showmanship as director.
DeMille was one of the first directors to become a celebrity in his own right. He cultivated the image of the omnipotent director, complete with megaphone, riding crop, and jodhpurs. From 1936 to 1944, DeMille hosted "Lux Radio Theater", a weekly digest of current feature films. 
DeMille was respected by his peers, yet his individual films were sometimes criticized. "Directorially, I think his pictures were the most horrible things I've ever seen in my life", said director William Wellman. "But he put on pictures that made a fortune. In that respect, he was better than any of us." 
Producer David O. Selznick wrote: "There has appeared only one Cecil B. DeMille. He is one of the most extraordinarily able showmen of modern times. However much I may dislike some of his pictures, it would be very silly of me, as a producer of commercial motion pictures, to demean for an instant his unparalleled skill as a maker of mass entertainment."
DeMille appeared as himself in numerous films, including the M-G-M comedy "Free and Easy." He often appeared in his coming-attraction trailers and narrated many of his later films, even stepping on screen to introduce "The Ten Commandments". DeMille was immortalized in Billy Wilder's "Sunset Boulevard" when Gloria Swanson spoke the line: "All right, Mr. DeMille. I'm ready for my closeup." DeMille plays himself in the film.
In the 1940s DeMille continued to please the public. He averaged one film a year; most of them centered on historical figures or Bible stories. His first attempt at a drama set within a semi-documentary frame was "The Greatest Show on Earth", a saga of circus performers released in 1952. His experiment gained him a nomination for best director and won an Oscar for best picture.
"The Ten Commandments".
In 1954, DeMille began his last film, the production for which he is best remembered, "The Ten Commandments".
On November 7, 1954, while in Egypt filming the Exodus sequence for "The Ten Commandments", DeMille (who was seventy-three) climbed a ladder to the top of the massive Per Rameses set and suffered a serious heart attack. Ignoring his doctor's orders, DeMille was back directing the film within a week. Although DeMille completed the film, his health was diminished by several more heart attacks. This film would be his last.
Unfulfilled projects.
Because of his illness, DeMille asked his son-in-law, actor Anthony Quinn, to direct a remake of his 1938 film "The Buccaneer". DeMille served as executive producer but could not improve Quinn's style of direction. Despite a cast led by Charlton Heston and Yul Brynner, the 1958 film, "The Buccaneer" was a disappointment.
In the months prior to his death, DeMille was researching a film biography of Robert Baden-Powell, 1st Baron Baden-Powell, the founder of the Scout Movement. DeMille asked David Niven to star in the film, but it was never made. DeMille was also planning a film about the space race, as well as another Biblical epic, this one about the Book of Revelation.
Personal life.
DeMille married Constance Adams on August 16, 1902 and had one child, Cecilia. The couple also adopted an orphan child, Katherine Lester in the early 1920s; her father had been killed in World War I and her mother had died of tuberculosis. 
Katherine became an actress at Paramount Pictures, ultimately gaining his approval. In 1937 she married actor Anthony Quinn. In the 1920s the DeMilles adopted two sons, John and Richard, the latter of whom became a notable filmmaker, writer, and psychologist.
He had an older brother William. Their sister Agnes died in childhood. William later named a daughter after her. Agnes de Mille, the famed dancer-choreographer, was DeMille's niece. DeMille died of a heart ailment at age 77 in January 1959.
Politics.
DeMille was a lifelong conservative Republican activist. He greatly admired Herbert Hoover. In 1944, he was the master of ceremonies at the massive rally organized by David O. Selznick in the Los Angeles Coliseum in support of the Dewey-Bricker ticket as well as Governor Earl Warren of California, who would become Dewey's running mate in 1948 and later the Chief Justice of the United States. The gathering drew 93,000, with short speeches by Hedda Hopper and Walt Disney. Among those in attendance were Ann Sothern, Ginger Rogers, Randolph Scott, Adolphe Menjou, Gary Cooper, and Walter Pidgeon. Though the rally drew a good response, most Hollywood celebrities who took a public position sided with the Roosevelt-Truman ticket.
DeMille was a Freemason and a member of Prince of Orange Lodge #16 in New York City.
In 1954, Secretary of the Air Force Harold E. Talbott asked DeMille for help in designing the cadet uniforms at the newly established United States Air Force Academy. DeMille's designs, most notably his design of the distinctive cadet parade uniform, won praise from Air Force and Academy leadership, were ultimately adopted, and are still worn by cadets.
In the early 1950s, DeMille was recruited by Allen Dulles and Frank Wisner to serve on the board of the anti-communist National Committee for a Free Europe, the public face of the organization that oversaw the Radio Free Europe service.
Race and religion.
DeMille drew on his Jewish and Protestant heritage to convey a message of tolerance. "The Crusades" was the first film to show accord between Christians and Muslims. DeMille received more than a dozen awards from Jewish religious and cultural groups, including B’nai B’rith.
In 1954 he was seeking approval for a lavish remake of his 1923 silent film "The Ten Commandments". He went before the Paramount board of directors, which was mostly Jewish-American. The members rejected his proposal, even though his last two films, "Samson and Delilah" and "The Greatest Show on Earth", had been record-breaking hits. Adolph Zukor, the chairman of the board, rebuked the members, saying: “We have just lived through a war where our people were systematically executed. Here we have a man who made a film praising the Jewish people, that tells of Samson, one of the legends of our Scripture. Now he wants to make the life of Moses. We should get down on our knees to Cecil and say ‘Thank you!’” DeMille did not have an exact budget proposal for the project, and it promised to be the most costly in Hollywood history. Still, the members unanimously approved it.
Death.
In the early hours of January 21, 1959, DeMille died of heart failure.
DeMille's funeral was held on January 23 at St. Stephen's Episcopal Church. He was entombed at the Hollywood Memorial Cemetery (now known as Hollywood Forever).
Legacy.
DeMille received hundreds of awards, commendations, and honors in his lifetime.
Posthumous honors.
For his contribution to the motion picture and radio industry, DeMille has two stars on the Hollywood Walk of Fame. The first, for radio contributions, is located at 6240 Vine Street. The second star is located at 1725 Vine Street.
Two schools are named after him: Cecil B. DeMille Middle School, in Long Beach, California, closed and demolished in 2007 to make way for a new high school; and Cecil B. DeMille Elementary School in Midway City, California.
The former film building at Chapman University in Orange, California is named in honor of DeMille. The Lawrence and Kristina Dodge College of Film and Media Arts now resides in Marion Knotts Studios.
The Golden Globe's annual Cecil B. DeMille Award recognizes lifetime achievement in the film industry.
Filmography.
DeMille made seventy features. In spite of careful storage in his film vaults, seven films were lost to nitrate decomposition; all were early silent films. The titles are: "The Arab", "The Wild Goose Chase", "Chimmie Fadden", "The Dream Girl", "We Can't Have Everything", "The Devil Stone", and "The Squaw Man" (the 1918 remake). Roughly twenty of his silent features are available in commercial DVD format.
The sound films are in three groups:
1. The three films DeMille produced at M-G-M are now owned by Warner Bros. (through Turner Entertainment).
2. The films he made at Paramount between 1932 and 1947 were sold by that company to EMKA, Ltd. in 1957, and are available through the television division of NBCUniversal.
3. DeMille's last three films were not sold to EMKA, and at present remain with Paramount. Television distribution for those films is handled by Trifecta Entertainment & Media. "The Ten Commandments" is broadcast every Easter Sunday in the United States on the ABC Television Network.
Director.
Silent films
Sound films
External links.
Sources
Criticism and Commentary
Archival Materials
Images and Census Information

</doc>
<doc id="6181" url="https://en.wikipedia.org/wiki?curid=6181" title="Chinese Islamic cuisine">
Chinese Islamic cuisine

Chinese Islamic cuisine (, Dungan: Чиңжән каи or , Dungan: Ҳуэйзў каи) is the cuisine of the Hui (ethnic Chinese Muslims) and other Muslims living in China such as Dongxiang, Salar and Bonan as well as Dungans of Central Asia.
History.
Due to the large Muslim population in western China, many Chinese restaurants cater to, or are run by, Muslims. Northern Chinese Islamic cuisine originated in China proper. It is heavily influenced by Beijing cuisine, with nearly all cooking methods identical, and differs only in material due to religious restrictions. As a result, northern Islamic cuisine is often included in home Beijing cuisine, however seldom in east coast restaurants.
During the Yuan dynasty, Halal methods of slaughtering animals and preparing food was banned and forbidden by the Mongol Emperors, starting with Genghis Khan who banned Muslims and Jews from slaughtering their animals their own way, and making them follow the Mongol method.
Among all the alien peoples only the Hui-hui say “we do not eat Mongol food”. [Cinggis Qa’an replied: “By the aid of heaven we have pacified you; you are our slaves. Yet you do not eat our food or drink. How can this be right?” He thereupon made them eat. “If you slaughter sheep, you will be considered guilty of a crime.” He issued a regulation to that effect ... 1279/1280 under Qubilai all the Muslims say: “if someone else slaughters animal we do not eat”. Because the poor people are upset by this, from now on, Musuluman Huihui and Zhuhu [Jewish Huihui, no matter who kills animal will eat and must cease slaughtering sheep themselves, and cease the rite of circumcision.
Traditionally, there is a distinction between northern and southern Chinese Islamic cuisine despite both utilizing mutton and lamb. Northern Chinese Islamic cuisine relies heavily on beef, but rarely ducks, geese, shrimp or seafood, while southern Islamic cuisine is the reverse. The reason for this difference is due to availability of the ingredients. Oxen have been long used for farming and Chinese governments have frequently strictly prohibited the slaughter of oxen for food. However, due to the geographic proximity of the northern part of China to minority-dominated regions that were not subjected to such restrictions, beef could be easily purchased and transported to northern China. At the same time, ducks, geese, and shrimp are rare in comparison to southern China due to the arid climate of northern China.
A Chinese Islamic restaurant () can be similar to a Mandarin restaurant with the exception that there is no pork on the menu and is primarily noodle/soup based.
In most major eastern cities in China, there are very limited Islamic/Halal restaurants, which are typically run by migrants from Western China (e.g., Uyghurs), they primarily offer inexpensive noodle soups only. These restaurants are typically decorated with Islamic motifs such as pictures of Islamic rugs and Arabic writing.
Another difference is that lamb and mutton dishes are more commonly available than in other Chinese restaurants, due to the greater prevalence of these meats in the cuisine of western Chinese regions. (Refer to image 1.)
Other Muslim ethnic minorities like the Salar, Dongxiang, Bonan, and Tibetan Muslims have their own cuisines as well. Dongxiang people also operate their own restaurants serving their cuisine.
Many cafeterias (canteens) at Chinese universities have separate sections or dining areas for Muslim students (Hui or western Chinese minorities), typically labeled "qingzhen." Student ID cards sometimes indicate whether a student is Muslim, and will allow access to these dining areas, or will allow access on special occasions such as the Eid feast following Ramadan.
Several Hui restaurants serving Chinese Islamic cuisine exist in Los Angeles. San Francisco, despite its huge number of Chinese restaurants, appears to have only one whose cuisine would qualify as Halal.
Many Chinese Hui Muslims who moved from Yunnan to Burma (Myanmar) are known as Panthays operate restaurants and stalls serving Chinese Islamic cuisine such as noodles. Chinese Hui Muslims from Yunnan who moved to Thailand are known as Chin Haw and they also own restaurants and stalls serving Chinese Islamic food.
In Central Asia, Dungan people, descendants of Hui, operate restaurants serving Chinese Islamic cuisine which is respectively referred to as "Dungan cuisine" there. They cater to Chinese businessmen. Chopsticks are used by Dungans. The cuisine of the Dungan resembles northwestern Chinese cuisine.
Most Chinese regard Hui Halal food as cleaner than food made by non Muslims so their restaurants are popular in China. Hui who migrated to Northeast China (Manchuria) after the Chuang Guandong opened many new inns and restaurants to cater to travellers, which were regarded as clean.
The Hui who migrated to Taiwan also operate Qingzhen restaurants and stalls serving Chinese Islamic cuisine in Taipei and other big cities.
The Thai Department of Export Promotion claims that "China's halal food producers are small-scale entrepreneurs whose products have little value added and lack branding and technology to push their goods to international standards" to encourage Thai private sector Halal producers to market their products in China.
Famous dishes.
Lamian.
Lamian (Refer to image 2.) ( Dungan: Ламиән) is a Chinese dish of hand-made noodles, usually served in a beef or mutton-flavored soup (湯麵 даңмиән tāngmiàn), but sometimes stir-fried (炒麵 Чаомиән chǎomiàn) and served with a tomato-based sauce. Literally, 拉 ла (lā) means to pull or stretch, while 麵 миән (miàn) means noodle. The hand-making process involves taking a lump of dough and repeatedly stretching it to produce a single very long noodle.
Beef noodle soup.
Beef noodle soup (Refer to image 3.) is a noodle soup dish composed of stewed beef, beef broth, vegetables and wheat noodles. It exists in various forms throughout East Asia and Southeast Asia. The most common Vietnamese version is called Bo kho, but which uses rice noodles instead. It was created by the Hui people during the Tang Dynasty of China.
In the West, this food may be served in a small portion as a soup. In China, a large bowl of it is often taken as a whole meal with or without any side dish.
Chuanr.
Chuanr (Chinese :串儿 Чуанр, pinyin: chuànr (shortened from "chuan er"); ""kebab""), originating in the Xinjiang (新疆) province of China and in recent years has been disseminated throughout the rest of that country, most notably in Beijing. It is a product of the Chinese Islamic cuisine of the Uyghur (维吾尔) people and other Chinese Muslims. Yang rou chuan, or lamb kebabs, is particularly popular.
Suan cai.
Suan cai or Chinese Sauerkraut is a traditional Chinese cuisine vegetable dish used in a variety of ways. It consists of pickled Chinese cabbage. Suan cai is a unique form of pao cai due to the material used and the method of production. Although "suan cai" is not exclusively Chinese Islamic cuisine, it is used in Chinese Islamic cuisine to top off noodle soups, especially beef noodle soup.
Nang.
"Nang" 馕 Наң, is a type of round unleavened bread, topped with sesame. It is similar to South and Central Asia naan.

</doc>
<doc id="6182" url="https://en.wikipedia.org/wiki?curid=6182" title="Cantonese cuisine">
Cantonese cuisine

Cantonese cuisine () comes from Guangdong province and is one of the Eight Culinary Traditions of Chinese cuisine. Its prominence outside China is due to the large number of emigrants from Guangdong. Chefs trained in Cantonese cuisine are highly sought after throughout China. When Westerners speak of Chinese food, they usually refer to Cantonese cuisine.
Background.
Guangzhou, the capital of Guangdong province, has long been a trading port and many imported foods and ingredients are used in Cantonese cuisine. Besides pork, beef and chicken, Cantonese cuisine incorporates almost all edible meats, including offal, chicken feet, duck's tongue, snakes, and snails. However, lamb and goat are rarely eaten, unlike in the cuisines of northern or western China. Many cooking methods are used, with steaming and stir frying being the most favoured due to their convenience and rapidity. Other techniques include shallow frying, double steaming, braising, and deep frying.
For many traditional Cantonese cooks, the flavours of a finished dish should be well balanced and not greasy. Apart from that, spices should be used in modest amounts to avoid overwhelming the flavours of the primary ingredients, and these ingredients in turn should be at the peak of their freshness and quality. There is no widespread use of fresh herbs in Cantonese cooking, in contrast with their liberal use in other cuisines such as Sichuan, European, Thai or Vietnamese. Garlic chives and coriander leaves are notable exceptions, although the latter are usually used as mere garnish in most dishes.
Foods.
Sauces and condiments.
In Cantonese cuisine, a number of ingredients such as spring onion, sugar, salt, soy sauce, rice wine, cornstarch, vinegar, scallion oil, and sesame oil, suffice to enhance flavour, although garlic is heavily used in some dishes, especially those in which internal organs, such as entrails, may emit unpleasant odours. Ginger, chili peppers, five-spice powder, powdered black pepper, star anise and a few other spices are also used, but often sparingly.
Dried and preserved ingredients.
Although Cantonese cooks pay much attention to the freshness of their primary ingredients, Cantonese cuisine also uses a long list of preserved food items to add flavour to a dish. This may be influenced by Hakka cuisine, since the Hakkas were once a dominant group occupying imperial Hong Kong and other southern territories.
Some items gain very intense flavours during the drying / preservation / oxidation process and some foods are preserved to increase their shelf life. Some chefs combine both dried and fresh varieties of the same items in a dish. Dried items are usually soaked in water to rehydrate before cooking. These ingredients are generally not served a la carte, but rather go with vegetables or other Cantonese dishes.
Traditional dishes.
A number of dishes have been part of Cantonese cuisine since the earliest territorial establishments of Guangdong. While many of these are on the menus of typical Cantonese restaurants, some simpler ones are more commonly found in Chinese homes. Home-made Cantonese dishes are usually served with plain white rice.
Deep fried dishes.
There are a small number of deep-fried dishes in Cantonese cuisine, which can often be found as street food. They have been extensively documented in colonial Hong Kong records of the 19th and 20th centuries. A few are synonymous with Cantonese breakfast and lunch, even though these are also part of other cuisines.
Slow-cooked soup.
Slow-cooked soup, or "lou fo tong" () in the Cantonese dialect (literally meaning "old fire-cooked soup") is usually a clear broth prepared by simmering meat and other ingredients over a low heat for several hours. Chinese herbs are often used as ingredients.
Soup chain stores or delivery outlets in Cantonese-dominated cities such as Hong Kong serve this dish due to the long preparation time of slow-cooked soup.
Seafood.
Due to Guangdong's location on the southern coast of China, fresh seafood is prominent in Cantonese cuisine, and many Cantonese restaurants keep aquariums or seafood tanks on the premises. In Cantonese cuisine, as in cuisines from other parts of Asia, if seafood has a repugnant odour strong spices are added; the freshest seafood is odourless and, in Cantonese culinary arts, is best cooked by steaming. For instance, in some recipes, only a small amount of soy sauce, ginger, and spring onion is added to steamed fish. According to Cantonese cuisine, the light seasoning is used only to bring out the natural sweetness of the seafood. As a rule of thumb, the spiciness of a dish is usually inversely proportionate to the freshness of the ingredients.
Noodle dishes.
Noodles are served either in soup broth or fried. These are available as home-cooked meals, on dim sum side menus, or as street food at dai pai dongs, where they can be served with a variety of toppings such as fish balls, beef balls, or fish slices.
Siu mei.
"Siu mei" () is essentially the Chinese rotisserie style of cooking. Unlike most other Cantonese dishes, siu mei consists of meat only, with no vegetables.
Lou mei.
Lou mei () is the name given to dishes made from internal organs, entrails and other left-over parts of animals. It is widely available in southern Chinese regions.
Siu laap.
All Cantonese-style cooked meats, including siu mei, lou mei and preserved meat can be classified as siu laap (). "Siu laap" also includes dishes such as:
A typical dish may consist of offal and half an order of multiple varieties of roasted meat. The majority of siu laap is white meat.
Little Pot rice.
Little pot rice () are dishes cooked and served in a flat-bottomed pot (as opposed to a round-bottomed wok). Usually this is a saucepan or braising pan (see clay pot cooking). Such dishes are cooked by covering and steaming, making the rice and ingredients very hot and soft. Usually the ingredients are layered on top of the rice with little or no mixing in between. Many standard combinations exist.
Banquet/dinner dishes.
A number of dishes are traditionally served in Cantonese restaurants only at dinner times. Dim sum restaurants stop serving bamboo-basket dishes after the yum cha period (equivalent to afternoon tea) and begin offering an entirely different menu in the evening. Some dishes are standard while others are regional. Some are customised for special purposes such as Chinese marriages or banquets. Salt and pepper dishes are one of the few spicy dishes.
Dessert.
After the evening meal, most Cantonese restaurants offer tong sui (), a sweet soup. Many varieties of tong sui are also found in other Chinese cuisines. Some desserts are traditional, while others are recent innovations. The more expensive restaurants usually offer their specialty desserts.
Delicacies.
Certain Cantonese delicacies consist of parts taken from rare or endangered animals, which raises controversy over animal rights and environmental issues. This is often due to alleged health benefits of certain animal products. For example, the continued spreading of the idea that shark cartilage can cure cancer has led to decreased shark populations although scientific research has found no evidence to support the credibility of shark cartilage as a cancer cure.

</doc>
<doc id="6183" url="https://en.wikipedia.org/wiki?curid=6183" title="Teochew cuisine">
Teochew cuisine

Teochew cuisine, also known as Chiuchow cuisine, Chaozhou cuisine or Chaoshan cuisine, originated from the Chaoshan region in the east of Guangdong province, which includes the cities of Chaozhou, Shantou and Jieyang. Teochew cuisine bears more similarities to that of Fujian cuisine, with which it shares some dishes. This may be due to the similarity of Chaoshan's and Fujian's culture and language and to their geographic proximity. However, Teochew cuisine is also influenced by Cantonese cuisine in its style and technique.
Background.
Teochew cuisine is well known for its seafood and vegetarian dishes and is commonly regarded as being healthy. Its use of flavouring is much less heavy-handed than most other Chinese cuisines and depends much on the freshness and quality of the ingredients for taste and flavour. As a delicate cuisine, oil is not often used in large quantities and there is a relatively heavy emphasis on poaching, steaming and braising, as well as the common Chinese method of stir-frying. Chaozhou cuisine is also known for serving congee (; or "mue"), in addition to steamed rice or noodles with meals. The Teochew "mue" is rather different from the Cantonese counterpart, being very watery with the rice sitting loosely at the bottom of the bowl, while the Cantonese dish is more a thin gruel.
Authentic Teochew restaurants serve very strong oolong tea called Tieguanyin in very tiny cups before and after the meal. Presented as "Gongfu cha", the tea has a thickly bittersweet taste, colloquially known as "gam gam" ().
A condiment that is popular in Fujian and Taiwanese cuisine and commonly associated with cuisine of certain Teochew groups is shacha sauce (). It is made from soybean oil, garlic, shallots, chilies, brill fish, and dried shrimp. The paste has a savoury and slightly spicy taste.
As an ingredient, it has multiple uses:
In addition to soy sauce (widely used in all Chinese cuisines), diaspora Teochew cuisine, (mainly Teochews in Indochina) uses fish sauce. It is used as a flavouring agent in soups and sometimes as a dipping sauce, as in Vietnamese spring rolls.
Teochew chefs often use a special stock called superior broth (). This stock remains on the stove and is continuously replenished. Portrayed in popular media, some Hong Kong chefs allegedly use the same superior broth that is preserved for decades. This stock can as well be seen on Chaozhou TV's cooking programmes.
There is a notable feast in Teochew cuisine / banquet called "jiat dot" (). A myriad of dishes are often served, which include shark fin soup, bird's nest soup, lobster, steamed fish, roasted suckling pig and braised goose.
Teochew chefs take pride in their skills of vegetable carving, and carved vegetables are used as garnishes on cold dishes and on the banquet table.
Teochew cuisine is also known for a late night meal known as "meh siao" () or "daa laang" () among the Cantonese. Teochew people enjoy eating out close to midnight in restaurants or at roadside food stalls. Some dai pai dong-like restaurants stay open till dawn.
Unlike the typical menu selections of many other Chinese cuisines, Teochew restaurant menus often have a dessert section.
Many people of Chaoshan origin, also known as Teochiu or Teochew people, have settled in Southeast Asia, especially Singapore, Hong Kong, Cambodia and Thailand; influences they bring can be noted in the cuisine of Singapore and that of other settlements. A large number of Teochew people have also settled in Taiwan, evident in Taiwanese cuisine. Other notable Teochew diaspora communities are in Vietnam and France. There is also a large diaspora of Teochew people (most were from Southeast Asia) in the United States - particularly in the state of California. There is a Teochew Chinese Association in Paris called L'Amicale des Teochews en France.

</doc>
<doc id="6184" url="https://en.wikipedia.org/wiki?curid=6184" title="Co-NP">
Co-NP

In computational complexity theory, co-NP is a complexity class. A decision problem formula_1 is a member of co-NP if and only if its complement formula_2 is in the complexity class NP. In simple terms, co-NP is the class of problems for which efficiently verifiable proofs of "no" instances, sometimes called counterexamples, exist. Equivalently, co-NP is the set of decision problems where the "no" instances can be accepted in polynomial time by a non-deterministic Turing machine.
An example of an NP-complete problem is the subset sum problem: given a finite set of integers, is there a non-empty subset that sums to zero? To give a proof of a "yes" instance, one must specify a non-empty subset that does sum to zero. The complementary problem is in co-NP and asks: "given a finite set of integers, does every non-empty subset have a non-zero sum?".
Relationship to other classes.
P, the class of polynomial time solvable problems, is a subset of both NP and co-NP. P is thought to be a strict subset in both cases (and demonstrably cannot be strict in one case and not strict in the other). NP and co-NP are also thought to be unequal. If so, then no NP-complete problem can be in co-NP and no co-NP-complete problem can be in NP.
This can be shown as follows. Suppose there exists an NP-complete problem formula_1 that is in co-NP. Since all problems in NP can be reduced to formula_1, it follows that for every problem in NP we can construct a non-deterministic Turing machine that decides its complement in polynomial time, i.e., NP ⊆ co-NP. From this it follows that the set of complements of the problems in NP is a subset of the set of complements of the problems in co-NP, i.e., co-NP ⊆ NP. Thus co-NP = NP. The proof that no co-NP-complete problem can be in NP if NP ≠ co-NP is symmetrical.
If a problem can be shown to be in both NP and co-NP, that is generally accepted as strong evidence that the problem is probably not NP-complete (since otherwise NP = co-NP).
Integer factorization is closely related to the primality problem. An integer factorization algorithm can decide primality. The contrary is not true: for a primality test it is enough to show that a factor exists when checking a composite number. Both primality testing and factorization have long been known to be NP and co-NP problems. The AKS primality test, published in 2002, proves that primality testing also lies in P. Factorization may or may not have a polynomial-time algorithm.

</doc>
<doc id="6185" url="https://en.wikipedia.org/wiki?curid=6185" title="Chuck Yeager">
Chuck Yeager

Charles Elwood "Chuck" Yeager (; born , 1923) is a retired brigadier general in the United States Air Force and record-setting test pilot. In 1947, he became the first pilot confirmed to have exceeded the speed of sound in level flight.
Yeager's career began in World War II as a private in the United States Army Air Forces. After serving as an aircraft mechanic, in September 1942 he entered enlisted pilot training and upon graduation was promoted to the rank of flight officer (the World War II USAAF equivalent to warrant officer) and became a P-51 fighter pilot.
After the war, Yeager became a test pilot of many types of aircraft, including experimental rocket-powered aircraft. As the first human to officially break the sound barrier, on , 1947, he flew the experimental Bell X-1 at Mach 1 at an altitude of (). Although Scott Crossfield was the first to fly faster than Mach 2 in 1953, Yeager shortly thereafter set a new record of Mach 2.44.
Yeager later commanded fighter squadrons and wings in Germany, and in Southeast Asia during the Vietnam War, and in recognition of the outstanding performance ratings of those units he was promoted to brigadier general. Yeager's flying career spans more than 60 years and has taken him to every corner of the globe, including the Soviet Union during the height of the Cold War.
Early life.
Yeager was born , 1923, to farming parents Susie Mae and Albert Hal Yeager in Myra, West Virginia, and graduated from high school in Hamlin, West Virginia, in June 1941. He had two brothers, Roy and Hal, Jr., and two sisters, Doris Ann (accidentally killed at age 2 by 6-year-old Roy playing with a shotgun) and Pansy Lee. His first experience with the military was as a teen at the Citizens Military Training Camp at Fort Benjamin Harrison, Indianapolis, Indiana, during the summers of 1939 and 1940. On , 1945, Yeager married Glennis Dickhouse, and the couple had four children. Glennis died in 1990.
The name "Yeager" () is an Anglicized form of the German name "Jäger" or "Jaeger" (German: "hunter"). He is the cousin of former baseball catcher Steve Yeager.
Career.
World War II.
Yeager enlisted as a private in the U.S. Army Air Forces (USAAF) on , 1941, and became an aircraft mechanic at George Air Force Base, Victorville, California. At enlistment, Yeager was not eligible for flight training because of his age and educational background, but the entry of the U.S. into World War II less than three months later prompted the USAAF to alter its recruiting standards. Having unusually sharp vision (a visual acuity rated 20/10), which once enabled him to shoot a deer at , Yeager displayed natural talent as a pilot and was accepted for flight training.
He received his wings and a promotion to flight officer at Luke Field, Arizona, where he graduated from class 43C on , 1943. Assigned to the 357th Fighter Group at Tonopah, Nevada, he initially trained as a fighter pilot, flying Bell P-39 Airacobras (earning a seven-day grounding order for pruning a tree belonging to a local farmer during a training flight), and shipped overseas with the group on , 1943.
Stationed in the United Kingdom at RAF Leiston, Yeager flew P-51 Mustangs in combat with the 363d Fighter Squadron. He named his aircraft "Glamorous Glen" after his girlfriend, Glennis Faye Dickhouse, who became his wife in February 1945. Yeager had gained one victory before he was shot down over France in his 1st aircraft (P-51B-5-NA s/n 43-6763) on , 1944 during his eighth mission. He escaped to Spain on with the help of the "Maquis" (French Resistance) and returned to England on , 1944. During his stay with the "Maquis", Yeager assisted the guerrillas in duties that did not involve direct combat, although he did help to construct bombs for the group, a skill that he had learned from his father. He was awarded the Bronze Star for helping another airman, who had lost part of his leg during the escape attempt, to cross the Pyrenees.
Despite a regulation prohibiting "evaders" (escaped pilots) from flying over enemy territory again, the purpose of which was to prevent a second capture from compromising resistance groups, Yeager was reinstated to flying combat. He had joined another evader, bomber pilot Captain Fred Glover, in speaking directly to the Supreme Allied Commander, General Dwight D. Eisenhower, on , 1944. With Glover pleading their case, they argued that because the Allies had invaded France and the "Maquis" were by then openly fighting the Nazis alongside Allied troops, if Yeager or Glover were shot down again, there was little about those who had previously helped them evade capture that could be revealed to the enemy.
Eisenhower, after gaining permission from the War Department to decide the requests, concurred with Yeager and Glover. Yeager later credited his postwar success in the Air Force to this decision, saying that his test pilot career followed naturally from his having been a decorated combat pilot, along with having been an aircraft mechanic before attending pilot school. In part, because of his maintenance background, he also frequently served as a maintenance officer in his flying units.
Yeager demonstrated outstanding flying skills and combat leadership. On , 1944, he became the first pilot in his group to make "ace in a day," downing five enemy aircraft in a single mission. Two of these kills were scored without firing a single shot: when he flew into firing position against a Messerschmitt Bf 109, the pilot of the aircraft panicked, breaking to starboard and colliding with his wingman. Yeager later reported both pilots bailed out. He finished the war with 11.5 official victories, including one of the first air-to-air victories over a jet fighter (a German Messerschmitt Me 262).
Another victory, which was not officially counted for Yeager, came during the period before his combat status was reinstated. In his biography Yeager reveals an incident that occurred during a training flight in his P-51 over the North Sea when he was ordered to fly top cover for the crew of a downed Boeing B-17 Flying Fortress. He spotted a German Junkers Ju 88 at great distance flying in his general direction. Apparently, when the crew of the Ju-88 saw Yeager and his wingman, they turned and ran for the coast. Yeager abandoned his station to chase after the Ju-88, which he downed as it crossed the beach. Yeager could provide no factual evidence to support his assertion, but explained his conduct by claiming the Ju-88 must have been there to attack the men in the water, and many authors have since chosen to repeat this unsupported claim as fact. Ju-88s were often used in the daylight battles against the Allied bomber streams to keep contact with the formations and search for downed pilots at sea. Yeager says that he was chewed out for his conduct. Because he was not yet cleared for flying combat again, his gun camera film and credit for the kill were given to his wingman, Eddie Simpson. (Yeager later mistakenly recalled that the credit had given Simpson his fifth kill.)
In his 1986 memoirs, Yeager recalled with disgust that "atrocities were committed by both sides" and went on to recount going on a mission with orders from the Eighth Air Force to "strafe anything that moved." During the mission briefing, he whispered to Major Donald H. Bochkay, "If we are going to do things like this, we sure as hell better make sure we are on the winning side." Yeager further noted, "I’m certainly not proud of that particular strafing mission against civilians. But it is there, on the record and in my memory."
Yeager was commissioned a second lieutenant while at Leiston, and was promoted to captain before the end of his tour. He flew his 61st and final mission on , 1945, and returned to the United States in early February. As an evader, he received his choice of assignments and, because his new wife was pregnant, chose Wright Field to be near his home in West Virginia. His high number of flight hours and maintenance experience qualified him to become a functional test pilot of repaired aircraft, which brought him under the command of Colonel Albert Boyd, head of the Aeronautical Systems Flight Test Division.
Post-World War II.
Test pilot – breaking the sound barrier.
Yeager remained in the Air Force after the war, becoming a test pilot at Muroc Army Air Field (now Edwards Air Force Base). After Bell Aircraft test pilot "Slick" Goodlin demanded $150,000 ($1.6 million in 2015 dollars) to break the sound "barrier," the USAAF selected Yeager to fly the rocket-powered Bell XS-1 in a NACA program to research high-speed flight.
Such was the difficulty in this task that the answer to many of the inherent challenges were along the lines of "Yeager better have paid-up insurance." Two nights before the scheduled date for the flight, Yeager broke two ribs when he fell from a horse. He was worried that the injury would remove him from the mission and reported that he went to a civilian doctor in nearby Rosamond, who taped his ribs. Yeager told only his wife, as well as friend and fellow project pilot Jack Ridley, about the accident. On the day of the flight, Yeager was in such pain that he could not seal the X-1's hatch by himself. Ridley rigged up a device, using the end of a broom handle as an extra lever, to allow Yeager to seal the hatch.
Yeager broke the sound barrier on , 1947, flying the X-1 at Mach 1.07 at an altitude of (). over the Rogers Dry Lake in the Mojave Desert. Yeager was awarded the MacKay and Collier Trophies in 1948 for his mach-transcending flight, and the Harmon International Trophy in 1954. The X-1 he flew that day was later put on permanent display at the Smithsonian Institution's National Air and Space Museum.
Yeager went on to break many other speed and altitude records. He was also one of the first American pilots to fly a MiG-15, after its pilot, No Kum-sok, defected to South Korea. Returning to Muroc, during the latter half of 1953, Yeager was involved with the USAF team that was working on the X-1A, an aircraft designed to surpass Mach 2 in level flight. That year, he flew a chase aircraft for the civilian pilot Jackie Cochran, a close friend, as she became the first woman to fly faster than sound.
On , 1953, the U.S. Navy program involving the D-558-II Skyrocket and its pilot, Scott Crossfield, became the first team to reach twice the speed of sound. After they were bested, Ridley and Yeager decided to beat rival Crossfield's speed record in a series of test flights that they dubbed "Operation NACA Weep." Not only did they beat Crossfield, but they did it in time to spoil a celebration planned for the 50th anniversary of flight in which Crossfield was to be called "the fastest man alive."
The Ridley/Yeager USAF team achieved Mach 2.44 on , 1953. Shortly after reaching Mach 2.44, Yeager experienced a loss of aerodynamic control of the X-1A due to inertia coupling at approximately . With the aircraft simultaneously rolling, pitching, and yawing out of the sky, Yeager dropped in 51 seconds before regaining control of the aircraft at approximately . He was able to land the aircraft without further incident. Yeager was awarded the Distinguished Service Medal (DSM) in 1954 for this achievement. Yeager received the DSM in the Army design as the Air Force Distinguished Service Medal was not awarded until 1965.
Military command.
Yeager was foremost a fighter pilot and held several squadron and wing commands. From May 1955 to July 1957 he commanded the F-86H Sabre-equipped 417th Fighter-Bomber Squadron (50th Fighter-Bomber Wing) at Hahn AB, Germany, and Toul-Rosieres Air Base, France; and from 1957 to 1960 the F-100D Super Sabre-equipped 1st Fighter Day Squadron (later, while still under Yeager's command, re-designated the 306th Tactical Fighter Squadron) at George Air Force Base, California, and Morón Air Base, Spain.
Now a full colonel in 1962, after completion of a year's studies at the Air War College, Yeager became the first commandant of the USAF Aerospace Research Pilot School, which produced astronauts for NASA and the USAF, after its redesignation from the USAF Flight Test Pilot School. (Yeager himself had only a high school education, so was not eligible to become an astronaut like those he trained.) Between December 1963 and January 1964, Yeager completed five flights in the NASA M2-F1 lifting body. An accident during a test flight in one of the school's NF-104s put an end to his record attempts.
In 1966 Yeager took command of the 405th Tactical Fighter Wing at Clark Air Base, the Philippines, whose squadrons were deployed on rotational temporary duty (TDY) in South Vietnam and elsewhere in Southeast Asia. There he accrued another 414 hours of combat time in 127 missions, mostly in a Martin B-57 Canberra light bomber. In February 1968, Yeager was assigned command of the 4th Tactical Fighter Wing at Seymour Johnson Air Force Base, North Carolina, and led the McDonnell Douglas F-4 Phantom II wing in South Korea during the "Pueblo" crisis.
On , 1969, Yeager was promoted to brigadier general, and was assigned in July as the vice-commander of the Seventeenth Air Force.
From 1971 to 1973, at the behest of Ambassador Joe Farland, Yeager was assigned to Pakistan to advise the Pakistan Air Force.
Post-retirement career.
On , 1975, following assignments in Germany and Pakistan, Yeager retired from the Air Force at Norton Air Force Base, although he continued to occasionally fly for the USAF and NASA as a consulting test pilot at Edwards AFB.
Yeager made a cameo appearance in the movie "The Right Stuff" (1983). He played "Fred," a bartender at "Pancho's Place", which was most appropriate, as Yeager said, "if all the hours were ever totaled, I reckon I spent more time at her place than in a cockpit over those years." His own role in the movie was played by Sam Shepard.
For several years in the 1980s, Yeager was connected to General Motors, serving as the public face of AC Delco, the company's automotive parts division. In 1986 he was invited to drive the Chevrolet Corvette pace car for the 70th running of the Indianapolis 500. In 1988, Yeager was again invited to drive the pace car, this time at the wheel of an Oldsmobile Cutlass Supreme. In 1986, President Reagan appointed Yeager to the Rogers Commission that investigated the explosion of the Space Shuttle "Challenger".
In the late 1980s and early 1990s, Yeager set a number of light general aircraft performance records for speed, range, and endurance. Most notable were flights conducted on behalf of Piper Aircraft. On one such flight, Yeager performed an emergency landing as a result of fuel exhaustion. On another, he piloted Piper's turboprop Cheyenne 400LS to a time-to-height record: FL350 (35,000 feet) in 16 minutes, exceeding the climb performance of a Boeing 737 at gross weight.
Yeager is fully retired from military test flying, after having maintained that status for three decades after his official retirement from the Air Force. On , 1997, on the 50th anniversary of his historic flight past Mach 1, he flew a new "Glamorous Glennis III", an F-15D Eagle, past Mach 1. The chase plane for the flight was an F-16 Fighting Falcon piloted by Bob Hoover, a legendary air-show pilot who had been Yeager's wingman for the first supersonic flight. This was Yeager's last official flight with the U.S. Air Force. At the end of his speech to the crowd, Yeager concluded, "All that I am ... I owe to the Air Force." Later that month, he was the recipient of the "Tony Jannus Award" for his achievements.
On , 2012, on the 65th anniversary of breaking the sound barrier, Yeager did it again at the age of 89, riding in a McDonnell Douglas F-15 Eagle piloted by Captain David Vincent out of Nellis Air Force Base.
Awards and decorations.
In 1973, Yeager was inducted into the National Aviation Hall of Fame, arguably aviation's highest honor. In December 1975, the U.S. Congress awarded Yeager a silver medal "equivalent to a noncombat Medal of Honor ... for contributing immeasurably to aerospace science by risking his life in piloting the XS-1 research airplane faster than the speed of sound on , 1947." President Gerald Ford presented the medal to Yeager in a ceremony at the White House on , 1976.
Yeager, who never attended college and was often modest about his background, is considered by many, including Flying Magazine, The California Hall of Fame, the State of West Virginia, National Aviation Hall of Fame, a few U.S. presidents, and the United States Army Air Force, to be one of the greatest pilots of all time. Despite his lack of higher education, he has been honored in his home state. Marshall University has named its highest academic scholarship, the Society of Yeager Scholars, in his honor. Yeager was also the chairman of Experimental Aircraft Association's Young Eagle Program since 1994, and has been named the program's chairman emeritus.
Yeager Airport in Charleston, West Virginia, is named in his honor. The Interstate 64/Interstate 77 bridge over the Kanawha River in Charleston is named in his honor. On , 2006, the state of West Virginia also honored Yeager with a marker along Corridor G (part of U.S. 119) in his home Lincoln County, and also renamed part of the highway the "Yeager Highway".
Yeager is an honorary board member of the humanitarian organization Wings of Hope. On , 2009, Governor Schwarzenegger and Maria Shriver announced that Yeager would be one of 13 California Hall of Fame inductees in The California Museum's yearlong exhibit. The induction ceremony was on , 2009, in Sacramento, California. "Flying Magazine" ranked Yeager number 5 on its 2013 list of The 51 Heroes of Aviation; he is the highest-ranked living person on the list.
The Civil Air Patrol, the volunteer auxiliary of the USAF, awards the Charles E. "Chuck" Yeager Award to its Senior Members as part of its Aerospace Education program. The General Chuck Yeager Cadet Squadron (SER-FL-237), associated with the Florida Wing, Civil Air Patrol, and based in Brandon, Florida, is also named in his honor.
Personal life.
Yeager and Glennis moved to Grass Valley, California, after his retirement from the Air Force in 1975. The couple prospered because of Yeager's best-selling autobiography, speaking engagements and commercial ventures. Glennis Yeager died of ovarian cancer in 1990. They had four children (Susan, Don, Mickey and Sharon).
In 2000, Yeager met actress Victoria Scott D'Angelo on a hiking trail in Nevada County. The pair started dating shortly thereafter, and married in August 2003. Subsequent to the commencement of their relationship, a bitter dispute arose between Yeager, his children and D'Angelo. The children contended that D'Angelo, 41 years Yeager's junior, had married him for his fortune. Yeager and D'Angelo both denied the charge. Litigation ensued, in which his children accused D'Angelo of "undue influence" on Yeager, and Yeager accused his children of diverting hundreds of thousands of dollars from his pension fund. In August 2008, the California Court of Appeal ruled for Yeager, finding that his daughter Susan had breached her duty as trustee.
Yeager and Victoria currently reside in Penn Valley, California, the location of the General Chuck Yeager Foundation, which supports programs that "teach the ideals by which General Yeager has lived."

</doc>
<doc id="6186" url="https://en.wikipedia.org/wiki?curid=6186" title="Cajun cuisine">
Cajun cuisine

Cajun cuisine (, ) is a style of cooking named for the French-speaking Acadian people deported by the British from Acadia in Canada to the Acadiana region of Louisiana. It is what could be called a rustic cuisine; locally available ingredients predominate and preparation is simple.
An authentic Cajun meal is usually a three-pot affair, with one pot dedicated to the main dish, one dedicated to steamed rice, special made sausages, or some seafood dish, and the third containing whatever vegetable is plentiful or available. Shrimp and pork sausage are staple meats used in a variety of dishes.
The aromatic vegetables green bell pepper ("poivron"), onion, and celery are called the holy trinity by Cajun chefs in Cajun and Creole cuisines. Roughly diced and combined in cooking, the method is similar to the use of the "mirepoix" in traditional French cuisine which blends roughly diced onion, celery and carrot. Characteristic aromatics for the Creole version may also include parsley, bay leaf, green onions, dried cayenne pepper, and dried black pepper.
History.
Around 1755, Acadians were forced out of their settlements by the British, and as a result, they migrated in 1755 in what was called "le Grand Dérangement", eventually settling in Southern Louisiana. Due to the extreme change in climate, Acadians were unable to cook their original dishes. Soon, their former culinary traditions were lost, and so, these other meals developed to become what is now considered classic Cajun cuisine traditions (not to be confused with the more modern concept associated with Prudhomme's style). Up through the 20th century, the meals were not elaborate but instead, rather basic. The public's false perception of "Cajun" cuisine was based on Prudhomme's style of Cajun cooking, which was spicy, flavorful, and not true to the classic form of the cuisine. Cajun and Creole label have been mistaken to be the same, but the origins of Creole cooking began in New Orleans, and Cajun cooking came 40 years after the establishment of New Orleans down south on the bayou.
Today, most restaurants serve dishes that consist of Cajun styles, which Paul Prudhomme dubbed "Louisiana cooking". In home-cooking, these individual styles are still kept separate. However, there are fewer and fewer people cooking the classic Cajun dishes that would have been eaten by the original settlers. 
Cajun cooking methods.
Deep-frying of turkeys or oven-roasted turduckens entered southern Louisiana cuisine more recently. Also, blackening of fish or chicken and barbecuing of shrimp in the shell are excluded because they were not prepared in traditional Cajun cuisine. Blackening was actually an invention by chef Paul Prudhomme in the 1970s, becoming associated with Cajun cooking, and presented as such by him, but is not a true historical or traditional Cajun cooking process.
Ingredients.
The following is a partial list of ingredients used in Cajun cuisine and some of the staple ingredients of the Acadian food culture.
Meat and seafood.
Cajun folkways include many ways of preserving meat, some of which are waning due to the availability of refrigeration and mass-produced meat at the grocer. Smoking of meats remains a fairly common practice, but once-common preparations such as turkey or duck confit (preserved in poultry fat, with spices) are now seen even by Acadians as quaint rarities.
Game (and hunting) are still uniformly popular in Acadiana.
The recent increase of catfish farming in the Mississippi Delta has brought about an increase in its usage in Cajun cuisine in the place of the more traditional wild-caught trout (the saltwater species) and red fish.
Seafood
Also included in the seafood mix are some so-called trash fish that would not sell at market because of their high bone to meat ratio or required complicated cooking methods. These were brought home by fishermen to feed the family. Examples are garfish, black drum also called gaspergou or just "goo", croaker, and bream.
Poultry
Pork
Beef and dairy<br>
Though parts of Acadiana are well suited to cattle or dairy farming, beef is not often used in a pre-processed or uniquely Cajun form. It is usually prepared fairly simply as chops, stews, or steaks, taking a cue from Texas to the west. Ground beef is used as is traditional throughout the southern US, although seasoned differently.
Dairy farming is not as prevalent as in the past, but there are still some farms in the business. There are no unique dairy items prepared in Cajun cuisine. Traditional Cajun and New Orleans Creole-influenced desserts are common.
Other Game Meats
Individual
Thyme, sage, mint, marjoram, savory, and basil are considered sweet herbs. In Colonial times a herbes de Provence would be several sweet herbs tied up in a Muslin.
Blended
Cooking bases
Cajun Dishes.
Three popular local dishes in Acadiana are noted in the Hank Williams' song "Jambalaya", namely "Jambalaya and-a crawfish pie and filé gumbo".
Primary Favorites.
Boudin is a type of sausage made from pork, pork liver, rice, garlic, green onions and other spices. It is widely available by the link or pound from butcher shops. Boudin is usually made daily as it does not keep well for very long, even when frozen. Boudin is typically stuffed in a natural casing and has a softer consistency than other, better-known sausage varieties. It is usually served with side dishes such as rice dressing, maque choux or bread. Boudin balls are commonly served in southern Louisiana restaurants and are made by taking the boudin out of the case and frying it in spherical form.
Gumbo - High on the list of favorites of Cajun cooking are the soups called gumbos. Contrary to non-Cajun or Continental beliefs, gumbo does not mean simply "everything in the pot". Gumbo exemplifies the influence of French, Spanish, African and Native American food cultures on Cajun cuisine. The name originally meant "okra", a word brought to the region from western Africa. Okra which can be one of the principal ingredients in gumbo recipes is used as a thickening agent and for its distinct vegetable flavor. Many claim that Gumbo is a "Cajun" dish, but Gumbo was established long before the Acadian arrival. It's early existence came via the early French Creole culture In New Orleans, Louisiana, where French, Spanish and Africans frequented and also influenced by later waves of Italian, German and Irish settlers.
A filé gumbo is thickened with dried sassafras leaves after the stew has finished cooking, a practice borrowed from the Choctaw Indians. The backbone of a gumbo is roux of which there are two variations: Cajun, a golden brown roux, and Creole, a dark roux, which is made of flour, toasted until well-browned, and fat or oil. The classic gumbo is made with chicken and the Cajun sausage called andouille, pronounced {ahn-doo-wee}, but the ingredients vary according to what is available.
Jambalaya - Another classic Cajun dish is jambalaya. The only certain thing that can be said about a jambalaya is that it contains rice, some sort of meat (such as chicken or beef), seafood (such as shrimp or crawfish) or almost anything else. Usually, however, one will find green peppers, onions, celery, tomatoes and hot chili peppers. Anything else is optional. This is also a great pre-Acadian dish, established by the Spanish in Louisiana.
Rice and gravy - Rice and gravy dishes are a staple of Cajun cuisine and is usually a brown gravy based on pan drippings, which are deglazed and simmered with extra seasonings and served over steamed or boiled rice. The dish is traditionally made from cheaper cuts of meat and cooked in a cast iron pot, typically for an extended time period in order to let the tough cuts of meat become tender. Beef, pork, chicken or any of a large variety of game meats are used for its preparation. Popular local varieties include hamburger steak, smothered rabbit, turkey necks, and chicken fricassee.
Food as an event.
Crawfish boil.
The crawfish boil is a celebratory event where Cajuns boil crawfish, potatoes, onions and corn in large pots over propane cookers. Lemons and small muslin bags containing a mixture of bay leaves, mustard seeds, cayenne pepper and other spices, commonly known as "crab boil" or "crawfish boil" are added to the water for seasoning. The results are then dumped onto large, newspaper-draped tables and in some areas covered in Creole / Cajun spice blends, such as REX, Zatarain's, Louisiana Fish Fry or Tony Chachere's. Also, Cocktail sauce, mayonnaise and hot sauce are sometimes used. The seafood is scooped onto large trays or plates and eaten by hand. During times when crawfish are not abundant, shrimp and crabs are prepared and served in the same manner.
Attendees are encouraged to "suck the head" of a crawfish by separating the abdomen of the crustacean and sucking out the abdominal fat/juices.
Often, newcomers to the crawfish boil or those unfamiliar with the traditions are jokingly warned "not to eat the dead ones". This comes from the common belief that when live crawfish are boiled, their tails curl beneath themselves, but when dead crawfish are boiled, their tails are straight and limp.
Seafood boils with crabs and shrimp are also popular.
Family Boucherie.
The traditional Cajun outdoor food event hosted by a farmer in the rural areas of the Acadiana. Family and friends of the farmer gather to socialize, play games, dance, drink, and have a copious meal consisting of hog and other dishes. Men have the task of slaughtering a hog, cutting it into usable parts, and cooking the main pork dishes while women have the task of making boudin. 
Cochon de Lait.
Similar to a family boucherie, the cochon de lait is a food event that revolves around pork but does not need to be hosted by a farmer. Traditionally, a suckling pig was purchased for the event, but in modern cochon de lait's, adult pigs are used. Unlike the family boucherie, a hog is not butchered by the hosts and there are generally not as many guests or activities. The host and male guests have the task of roasting the pig (see pig roast) while female guests bring side dishes.
Rural Mardi Gras.
The traditional Cajun Mardi Gras (see: "Courir de Mardi Gras") is a Mardi Gras celebration in rural Cajun Parishes. The tradition originated in the 18th century with the Cajuns of Louisiana, but it was abandoned in the early 20th century because of unwelcome violence associated with the event. In the early 1950s the tradition was revived in Mamou in Evangeline Parish. 
The event revolves around male maskers on horseback who ride into the countryside to collect food ingredients for the party later on. They entertain householders with Cajun music, dancing, and festive antics in return for the ingredients. The preferred ingredient is a live chicken in which the householder throws the chicken to allow the maskers to chase it down (symbolizing a hunt), but other ingredients include rice, sausage, vegetables, or frozen chicken. Unlike other Cajun events, men take no part in cooking the main course for the party, and women prepare the chicken and ingredients for the gumbo. 
Once the festivities begin, the Cajun community members eat and dance to Cajun music until midnight, as the beginning of Lent. 

</doc>
