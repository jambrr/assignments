<doc id="2102" url="https://en.wikipedia.org/wiki?curid=2102" title="Arizona Cardinals">
Arizona Cardinals

The Arizona Cardinals are a professional American football franchise based in the Phoenix metropolitan area. The Cardinals compete in the National Football League as a member club of the league's National Football Conference (NFC) West division. The Cardinals were founded as the Morgan Athletic Club in 1898, and are the oldest continuously run professional football team in the United States. The Cardinals play their home games at the University of Phoenix Stadium, which is located in the northwestern suburb of Glendale, Arizona.
The team was established in Chicago in 1898 and was a charter member of the NFL in . Along with the Chicago Bears, the club is one of two NFL charter member franchises still in operation since the league's founding. (The Green Bay Packers were an independent team until they joined the NFL in 1921). The club then moved to St. Louis in and played in that city through (sometimes referred to as the "Football Cardinals" or the "Big Red" to avoid confusion with the Major League Baseball St. Louis Cardinals). Before the season, the team moved west to Tempe, Arizona, a college suburb east of Phoenix, and played their home games for the next 18 seasons at Arizona State University's Sun Devil Stadium. In , the club began playing all home games at the newly constructed University of Phoenix Stadium in Glendale, although the team's training facility is in Tempe.
The franchise has won two NFL championships, both while it was based in Chicago. The first occurred in , but is the subject of controversy, with supporters of the Pottsville Maroons believing that Pottsville should have won the title. Their second title, and the first to be won in a championship game, came in , nearly two decades before the first Super Bowl. They returned to the title game to defend in 1948, but lost the rematch 7–0 in a snowstorm in Philadelphia.
Since winning the championship in 1947, the team suffered many losing seasons, and currently holds the league's longest active championship drought, at 67 consecutive seasons. In 2012 the Cardinals became the first NFL franchise to lose 700 games since its inception. The franchise's all-time win-loss record (including regular season and playoff games) at the conclusion of the 2015 season is 542–733–39 (535–724–39 in the regular season, 7–9 in the playoffs). They have been to the playoffs ten times and have won seven playoff games, three of which were victories during their run in the 2008–09 NFL playoffs. During that season, they won their only NFC Championship Game since the 1970 AFL–NFL merger, and reached Super Bowl XLIII. The team has also won five division titles (, , , and ) since their 1947–1948 NFL championship game appearances. The Cardinals are the only NFL team who have never lost a playoff game at home, with a 5-0 record: the 1947 NFL Championship Game, two postseason victories during the aforementioned 2008–09 NFL playoffs, one during the 2009-10 playoffs, and one during the 2015-2016 NFL playoffs.
From 1988 through 2012 (except 2005, when they trained in Prescott), the Cardinals conducted their annual summer training camp at Northern Arizona University in Flagstaff. The Cardinals moved their training camp to University of Phoenix Stadium in 2013. The stadium was the site of the 2015 Pro Bowl, unlike in past years, where it was held at Aloha Stadium in Honolulu, Hawaii. The stadium also played host to Super Bowls XLII and XLIX.
Franchise history.
Chicago.
The franchise's inception dates back to 1898, when a neighborhood group gathered to play in the Chicago South Side, calling themselves Morgan Athletic Club. Chicago painting and building contractor Chris O'Brien acquired the team, which he relocated to Normal Field in Racine Avenue. The team was known as Racine Normals until 1901, when O'Brien bought used jerseys from the University of Chicago. He described the faded maroon clothing as "Cardinal red" and the team became the Racine Street Cardinals. The team eventually became in 1920 a charter member of the American Professional Football Association (APFA), which two years later was rechristened to National Football League (NFL). The team entered the league as the Racine Cardinals, however the name was changed in 1922 to Chicago Cardinals to avoid confusion with the Horlick-Racine Legion who entered the league the same year. Except for 1925, when they were awarded the championship after the Pottsville Maroons were suspended, the Cardinals experienced only minimal success on the playing field during their first 26 seasons in the league. During the post-World War II years, the team reached two straight NFL finals against the Philadelphia Eagles, winning in 1947 - eight months after the death of owner Charles Bidwill - and losing the 1948 NFL Championship Game the following year. After years of bad seasons and losing fans to the cross-town rivals Chicago Bears, by the late 1950s the Cardinals were almost bankrupt, and owner Violet Bidwill Wolfner became interested in a relocation.
St. Louis.
Due to the formation of the rival American Football League, the NFL allowed Bidwill to relocate the team to St. Louis, Missouri, where they became the St. Louis Cardinals (nicknamed "Football Cardinals" due to sharing a name with the city's baseball team). During the Cardinals' 28-year stay in St. Louis, they advanced to the playoffs just three times (1974, 1975 & 1982), never hosting or winning in any appearance. The overall mediocrity of the Cardinals, combined with a then-21 year old stadium, caused game attendance to dwindle, and owner Bill Bidwill decided to move the team to Arizona.
Phoenix, Arizona.
Not long after the 1987 NFL season, Bidwill agreed to move to the Phoenix metropolitan area on a handshake deal with state and local officials, and the team became the Phoenix Cardinals. In 1994, the franchise changed to its current name of Arizona Cardinals due to fan preference. The 1998 NFL season made the Cardinals break two long droughts, qualifying for the playoffs for the first time in 16 years, and by winning the Wild Card Playoffs, getting their first postseason win since 1947. Ten years later, the Cardinals won the NFC Championship Game to advance to the Super Bowl for the first time in franchise history. They lost Super Bowl XLIII 27-23 to the Pittsburgh Steelers in the final seconds.
Uniforms.
The team has worn cardinal red jerseys since Chris O'Brien bought them for the club in 1898. For most of their history, the Cardinals have used the same basic uniform design of white helmets, white pants with red stripes on the sides, and either red or white jerseys.
Starting in , the team had a logo of a cardinal bird perched on the stitches of a football. However, the club did not attach a logo to their helmets until they debuted a cardinal-head logo in , the year the franchise moved from Chicago to St. Louis.
During their 28 years in St. Louis, the Cardinals frequently wore white at home, especially for games vs. the Dallas Cowboys, hoping to bring out the "blue jersey jinx" which supposedly follows the Cowboys. The Cardinals wore white at home at least twice in every season since 1964 and for every home game in 1964, 1965, and 1978. They wore white for their 1982 and 1983 home games vs. Dallas, but not at all from 1984 through 1987.
The Cardinals moved to Arizona in , and the flag of Arizona was added to the sleeves the following year. In , the team began wearing red pants with their white jerseys, as new coach Joe Bugel wanted to emulate his former employer, the Washington Redskins, who at the time wore burgundy pants with their white jerseys (the Redskins later returned to their 1970s gold pants with all their jerseys).
In , the Cardinals participated in the NFL's 75th anniversary throwback uniform program. The jerseys were similar to those of the 1920s Chicago Cardinals, with an interlocking "CC" logo and three stripes on each sleeve. The uniform numbers were relocated to the right chest. The pants were khaki to simulate the color and material used in that era. The Cardinals also stripped the logos from their helmets for the two games, at Cleveland (Sept. 18) and home vs. Pittsburgh (Oct. 30).
The Cardinal head on the helmet was repeated on the white jersey from 1982 to 1995. In 1996, the state flag of Arizona was moved higher on the sleeve after the Cardinal head was eliminated, and black was removed as an accent color, instead replaced with a blue to match the predominant color of the state flag. In 2002, the Cardinals began to wear all-red and all-white combinations, and continued to do so through 2004, prior to the team's makeover.
In , the team unveiled its first major changes in a century. The cardinal-head logo was updated to look sleeker and meaner than its predecessor. Numerous fans had derisively called the previous version a "parakeet". Black again became an accent color after an eight-year absence, while trim lines were added to the outside shoulders, sleeves, and sides of the jerseys and pants. Both the red and white jerseys have the option of red or white pants.
Hoping to break a six-game losing streak, the Cardinals wore the red pants for the first time on October 29, 2006, in a game at Lambeau Field against the Green Bay Packers. The Packers won 31–14, and the Cards headed into their bye week with a 1–7 mark. Following the bye week, the Cardinals came out in an all-red combination at home against the Dallas Cowboys and lost, 27–10. Arizona did not wear the red pants for the remainder of the season and won four of their last seven games. However, the following season, in , the Cardinals again wore their red pants for their final 3 home games. They wore red pants with white jerseys in games on the road at the Cincinnati Bengals and Seattle Seahawks. They paired red pants with red jerseys, the all-red combination, for home games against the Detroit Lions, San Francisco 49ers, Cleveland Browns, and St. Louis Rams. The red pants were not worn at all in , but they were used in home games vs. Seattle, Minnesota, and St. Louis in . The red pants were paired with the white road jersey for the first time in three years during a 2010 game at Carolina, but the white jersey/red pants combination was not used in 2011.
The Cardinals' first home game in Arizona, in 1988, saw them play in red jerseys. Thereafter, for the next 18 years in Arizona, the Cardinals, like a few other NFL teams in warm climates, wore their white jerseys at home during the first half of the season—forcing opponents to suffer in their darker jerseys during Arizona autumns that frequently see temperatures over 100 °F (38 °C). However, this tradition did not continue when the Cardinals moved from Sun Devil Stadium to University of Phoenix Stadium in 2006, as early-season games (and some home games late in the season) were played with the roof closed. With the temperature inside at a comfortable 70 °F (21 °C), the team opted to wear red jerseys at home full-time. The Cardinals wore white jerseys at home for the first time in University of Phoenix Stadium on August 29, 2008, in a preseason game against the Denver Broncos.
The Cardinals wore white at home for the first time in a regular season game at University of Phoenix Stadium against the Houston Texans on October 11, . In October 2009, the NFL recognized Breast Cancer Awareness Month, and players wore pink-accented items, including gloves, wristbands, and shoes. The team thought the pink accents looked better with white uniforms than with red.
On many occasions, when hosting the Dallas Cowboys, the Cardinals would wear white in order to force the Cowboys to don their "jinxed" blue jerseys. They have not done this since moving into University of Phoenix Stadium, however.
The season saw the Cardinals debut a new, alternate black jersey. Prior to its introduction, the Cardinals were the only NFL team without an alternate jersey or throwback kit, save for the NFL's 75th anniversary program in 1994.
Single-season records.
Points Scored: 489 ()
Passing
Rushing
Receiving
Returns
Kicking
Players.
Retired numbers.
Notes:
Pro Football Hall of Famers.
"italics" = played a portion of career with the Cardinals and enshrined representing another team
Dierdorf, Smith, Wehrli and Wilson are members of the St. Louis Football Ring of Fame in the Edward Jones Dome.
Ring of Honor.
The Cardinals' Ring of Honor was started in to mark the opening of University of Phoenix Stadium. It honors former Cardinal greats from all eras of the franchise's history. Following is a list of inductees and the dates that they were inducted.
Radio and television.
The Cardinals' flagship radio station was KMVP AM, "ESPN Radio 860." KMVP assumed the broadcast rights in 2006 after many years on KSLX-FM and KDUS. Dave Pasch, Ron Wolfley, and Paul Calvisi handle the radio broadcast. Most preseason games are televised on KNXV, channel 15, the local ABC affiliate. 
On New Year's Day 2007, KMVP began a simulcast of KTAR, which switched to an all-sports format (the news/talk station became 92.3, KTAR-FM). For the 2007 season, KTAR was the official flagship station; however, some broadcasts were also heard on 92.3 FM because of conflicts with Arizona Diamondbacks baseball games on 620 AM.
In January 2014, Bonneville International, owners of KTAR and KMVP, created Arizona Sports 98.7 (KMVP-FM), a new local FM sports talk outlet. All Cardinals games in 2014 and beyond have been heard on KMVP-FM.
Spanish-language radio broadcasts are heard on the combo of KQMR/KHOV-FM "Latino Mix" under a contract with Univisión, signed in 2015. Prior to 2015, they were heard on KDVA/KVVA-FM "José FM", as well as co-owned KBMB AM 710. The Cardinals were the first NFL team to offer all 20 preseason and regular season games on Spanish-language radio, doing so in 2000. Gabriel Trujillo and Rolando Cantú are the Spanish broadcast team.
The Cardinals have the most extensive Mexican affiliate network in the NFL, with contracts with Grupo Larsa (in the state of Sonora) and Grupo Radiorama (outside Sonora) and stations in 20 cities, including Hermosillo, Guadalajara and Mexico City.
English radio affiliates.
Cardinals Radio Affiliates
Miscellaneous.
Due to Phoenix's high temperature and strong sunshine in early September, eight of the team's first 13 home openers in Arizona were held, at earliest, in week three. In 1989, 1990 and 1991, the Cardinals opened with three consecutive road games before finally coming home in week four. For the same reason, the team's home opener was a nationally-televised night game (two "Monday Night Football" games and 11 "Sunday Night Football" (ESPN) games) from 1988 to 2001. The team hosted nine straight home openers as "Sunday Night Football" games from 1990 to 1998.
In 2001, the NFL schedule and the September 11 attacks allowed the Cardinals to play their first two games at home. Since the NFL had an odd number of teams (31) from 1999 through 2001, there had to be at least one bye in every week of the season. In 2001, the Cardinals' bye was week one. They were scheduled to travel to Washington in week two, but the game was postponed due to the terrorist attacks and moved to the very end of the slate. The Cardinals' scheduled home opener, a "Sunday Night Football" game vs. Denver, became the season opener, the only time Arizona played its season opener at home when it resided at Sun Devil Stadium. Arizona also played at home the next week vs. Atlanta. 
Patrick Daniel "Pat" Tillman (November 6, 1976 – April 22, 2004) was an American football player who left his professional career while with the Arizona Cardinals and enlisted in the United States Army in June 2002 in the aftermath of the September 11 attacks. His service in Iraq and Afghanistan, and subsequent death, were the subject of much media attention.

</doc>
<doc id="2103" url="https://en.wikipedia.org/wiki?curid=2103" title="Atlanta Falcons">
Atlanta Falcons

The Atlanta Falcons are a professional American football team based in Atlanta, Georgia. They are a member of the South Division of the National Football Conference (NFC) in the National Football League (NFL).
The Falcons joined the NFL in 1965 as an expansion team, after the NFL offered then-owner Rankin Smith a franchise to keep him from joining the rival American Football League (AFL). The AFL instead granted a franchise to Miami, Florida (the Miami Dolphins). The Falcons are tied with the Dolphins (who also began play in 1966) for being the oldest NFL franchise in the Deep South, and are the oldest NFC team in that region.
In their 49 years of existence, the Falcons have compiled a record of 316–414–6, winning division championships in 1980, 1998, 2004, 2010, and 2012. Their only Super Bowl appearance was during the 1998 season in Super Bowl XXXIII.
The Falcons play their home games at the Georgia Dome in downtown Atlanta. Construction began on Mercedes-Benz Stadium in May 2014, with play projected to begin there during the 2017 season. Their headquarters and practice facilities are located at a 50-acre site in Flowery Branch, Georgia.
Franchise history.
Professional football first came to Atlanta in 1962, when the American Football League staged two preseason contests, with one featuring the Denver Broncos vs. the Houston Oilers and the second pitting the Dallas Texans against the Oakland Raiders. Two years later, the AFL held another exhibition, this time with the New York Jets taking on the San Diego Chargers.
In 1965, after the Atlanta-Fulton County Stadium was built, the city of Atlanta felt the time was right to start pursuing professional football. One independent group which had been active in NFL exhibition promotions in Atlanta applied for franchises in both the American Football League and the National Football League, acting entirely on its own with no guarantee of stadium rights. Another group reported it had deposited earnest money for a team in the AFL.
With everyone running in different directions, some local businessmen worked out a deal and were awarded an AFL franchise on June 7, 1965, contingent upon acquiring exclusive stadium rights from city officials. NFL Commissioner Pete Rozelle, who had been moving slowly in Atlanta matters, was spurred by the AFL interest and headed on the next plane down to Atlanta to block the rival league's claim on the city of Atlanta. He forced the city to make a choice between the two leagues. By June 30, the city picked Rankin Smith and the NFL.
The Atlanta Falcons franchise began on June 30, 1965, when NFL Commissioner Pete Rozelle granted ownership to 41-year-old Rankin Smith Sr.. Smith an Executive Vice President of Life Insurance Company of Georgia at the time, paid $8.5 million the highest price in NFL history at the time 1965 for an NFL franchise. Former commissioner Pete Rozelle and Smith made the deal in about five minutes and the Atlanta Falcons brought the largest and most popular sport to the city of Atlanta. The Atlanta expansion franchise became the 15th NFL franchise, and they were awarded the first pick in the 1966 NFL draft as well as the final pick in each of the first five rounds. The Falcons drafted All-American linebacker Tommy Nobis from the University of Texas with the first pick of the draft, making him the first-ever Falcon. The league also held the 1966 NFL Expansion Draft six weeks later in which the Falcons selected unprotected players from existing franchises. Although the Falcons selected many good players in those drafts, they still were not able to win right away.
The Atlanta Falcons Football Club received its nickname on August 29, 1965. Miss Julia Elliott, a school teacher from Griffin, Georgia was singled out from many people who suggested "Falcons" as the Nickname for the new Georgia NFL franchise. She wrote: "the Falcon is proud and dignified, with great courage and fight. It never drops its prey. It is deadly and has a great sporting tradition."
In February 2015, the team was investigated by the NFL for alleged use of artificial crowd noise in the Georgia Dome.
Notable seasons.
1966–1977.
The Falcons had their first season in , and their first preseason game on August 1, , losing to the Philadelphia Eagles. Under Head Coach Norb Hecker they lost their first nine regular-season games in 1966 and secured their first victory on the road against the New York Giants. The team finished the 1960s with only 12 wins. The Falcons had their first Monday Night Football game in Atlanta during the 1970 season. The 1971 season was their first with a winning record.
1978–1980.
In the 1978 season, the Falcons qualified for the playoffs for the first time and won the Wild Card game against the Philadelphia Eagles 14–13. The following week, they lost to the Dallas Cowboys 27–20 in the Divisional Playoffs.
In 1980, after a nine-game winning streak, the Falcons posted a franchise then-best record of 12–4 and captured their first NFC West division title. The next week, their dream season ended at home with a loss to the Cowboys 30–27 in the divisional playoffs. In the strike-shortened 1982 season, the Falcons made the playoffs but lost to the Minnesota Vikings, 30–24. Falcons coach Leeman Bennett was fired after the loss.
1989.
In 1989, the Falcons drafted CB Deion Sanders in the first round, who helped them for the next four years, setting many records for the franchise. "Neon Deion" (a.k.a. "Prime Time") had a flashy appeal and helped bring media attention to one of the league's most anonymous franchises. Sanders was also famous for playing on major league baseball teams (the New York Yankees and the Atlanta Braves) while simultaneously playing in the NFL.
1991–1996.
The Falcons' 1991 season ended in a divisional playoff loss to the Washington Redskins. In 1991, the Falcons drafted Brett Favre as the thirty-third overall pick. During his rookie season, he played in two games where he amassed a record of 4 passing attempts with 0 receptions and 2 interceptions. The following February, Favre was traded to the Green Bay Packers.
In 1992, the Atlanta Falcons opened a new chapter in their history moving into the newly constructed Georgia Dome, where the team has defeated all 31 other NFL teams at least once since its opening.
1997–2000: The Dan Reeves era.
In 1998, under recently acquired head coach Dan Reeves, quarterback Chris Chandler and running back Jamal Anderson the "Dirty Bird" Falcons had their greatest season to date. On November 8, they beat the New England Patriots 41–10, ending a streak of 22 losses at cold-weather sites. The team finished with a franchise-best 14–2 regular season record and the NFC West division championship. On January 17, 1999, the Falcons upset the top-seeded Vikings at Minnesota in the NFC Championship Game 30–27, in an exciting overtime victory. However, in their first-ever Super Bowl appearance, they lost 34–19 to the defending champion Denver Broncos in Super Bowl XXXIII.
In the second game of the Falcons 1999 season, running back Jamal Anderson, who had been a key player in the Falcons' 1998 success, suffered a season-ending knee injury. The Falcons finished the season with a very disappointing 5–11 regular season record. In 2000, the Falcons suffered through another horrendous season finishing 4–12 and once again missing the playoffs.
2001–2006: The Michael Vick era.
In the 2001 NFL draft, the Falcons orchestrated a trade with the San Diego Chargers, acquiring the first overall pick (which was used on quarterback Michael Vick) in exchange for wide receiver / return specialist Tim Dwight and the fifth overall pick (used on running back LaDainian Tomlinson).
The Falcons finished the 2001 season with a record of 7–9 and missed the playoffs. Jessie Tuggle retired following 14 seasons in Atlanta. On December 6, 2001, Arthur M. Blank reached a preliminary agreement with the Falcons' Taylor Smith to purchase the team. In a special meeting prior to Super Bowl XXXVI in New Orleans on February 2, 2002, NFL owners voted unanimously to approve the purchase.
The 2002 season saw the Falcons return to the playoffs with a regular season record of 9–6–1, tying the Pittsburgh Steelers in a heated contest. It was Michael Vick's first year as the starter, and the team, with newly acquired running back Warrick Dunn, delivered the Green Bay Packers their first home playoff loss ever. A 20-6 loss to the Donovan McNabb-led Philadelphia Eagles the following week, however, ended the Falcons season.
On March 19, 2003, the Falcons presented their new logo. During the 2003 preseason Michael Vick broke his leg and missed the first twelve games of the season. After losing 7 straight games, the decision was made to release head coach Dan Reeves. Wade Phillips acted as interim coach for the final 3 games. Although the Falcons won 3 of their last 4 games after the return of Michael Vick, they ended up with a dismal 5–11 record that year. In 2004, a new head coach, Jim L. Mora, was hired and Michael Vick returned for the full season. The Falcons went 11–5, winning their third division title and earning a first-round bye into the playoffs. In the divisional playoffs, the Falcons defeated the St. Louis Rams 47–17 in the Georgia Dome, advancing to the NFC Championship, which they lost to the Eagles 27–10.
The Falcons again fell short of achieving back-to-back winning seasons in , going 8–8. In , Michael Vick became the first quarterback in league history to rush for more than 1,000 yards in a season, with 1,039. After finishing the season 7–9, however, coach Jim Mora was dismissed and Bobby Petrino, the University of Louisville's football coach, replaced him. Before the 2007 season began, Vick was suspended indefinitely by the NFL after pleading guilty to charges involving dog fighting in the state of Virginia. On December 10, 2007, Vick received a 23-month prison sentence and was officially cut from the Atlanta roster.
2007.
For the 2007 season, the Falcons were forced to start Joey Harrington at quarterback. On December 11, 13 games into his first NFL season as head coach, Bobby Petrino resigned without notice to coach at the University of Arkansas, leaving the beleaguered players only a note in the locker room. Secondary Coach Emmitt Thomas was named interim coach for the final three games of the season on December 12. The Falcons ended the year with a dismal 4–12 record.
2008–2014: Mike Smith/Matt Ryan era.
After the tumultuous and disappointing 2007 season, the Falcons made a number of moves, hiring a new General Manager and head coach, drafting a new starting quarterback, and signing a starting running back.
On January 13, 2008, the Falcons named former Patriots director of college football scouting Thomas Dimitroff General Manager. On January 23, Jacksonville Jaguars defensive coach and former linebackers coach for the 2000 Super Bowl champion Baltimore Ravens Mike Smith was named the Falcons' new head coach. Chargers back-up RB Michael Turner agreed to a 6-year deal, $30 million deal on March 2. On April 26, Matt Ryan (quarterback from Boston College) was drafted third overall in the 2008 NFL draft by the Falcons.
2008.
The Falcons finished the 2008 regular season with a record of 11–5, and the #5 seat in the playoffs. On December 21, 2008, Atlanta beat the Minnesota Vikings 24–17 to clinch a wild card spot, earning a trip to the playoffs for the first time since 2004. The Falcons would go on to lose in the wild-card round of the 2008 NFL playoffs to the eventual NFC champion Arizona Cardinals, 30–24.
Matt Ryan started all 16 games in his rookie season and was named the Associated Press Offensive Rookie of the Year. First-year head coach Mike Smith was named 2008 NFL Coach of the Year.
2009.
Although they failed to make the playoffs in 2009 the team rallied to win their final three regular season games to record back-to-back winning seasons for the first time in franchise history. The Falcons defeated the Tampa Bay Buccaneers 20–10 in the final game of the season to improve their record to 9–7.
2010.
In 2010, with a regular season record of 13–3, their best regular season record since the 1998 Super Bowl season, the Falcons secured a third straight winning season, their fourth overall divisional title, and the top overall seed in the NFC playoffs; however, the Falcons were overpowered by the eventual Super Bowl XLV champion Green Bay Packers in the NFC Divisional Playoffs 48–21. The Falcons scored 414 points – third-most in franchise history in 2010. The Falcons 2010–2011 team sent an NFL-high and franchise-best nine players to the AFC-NFC Pro Bowl.
2011.
The Falcons made a surprise trade up with the Cleveland Browns in the 2011 NFL draft to select Alabama wide receiver Julio Jones sixth overall. In exchange, the Falcons gave up their first-, second- and fourth-round draft picks in 2011, and their first and fourth draft picks in 2012. Jones, along with teammates Tony Gonzalez and Roddy White, have since been dubbed Atlanta's "Big Three" (based on their total number of reception yards). On August 30, 2011, Sports Illustrated senior writer Peter King, who correctly predicted the 2011 Super Bowl, made his predictions for the 2011 season and picked the Falcons to defeat the San Diego Chargers in the 2012 Super Bowl. The Falcons finished the season at 10–6, securing the fifth seed after a Week 17 beatdown of Tampa Bay in which the Falcons pulled their starters after leading 42–0 just 23 minutes into the game.
The Falcons then went on to play the New York Giants in a 2011 NFC Wild Card Game at MetLife Stadium in East Rutherford, New Jersey. The first half was a defensive struggle, with the first points coming off of a safety by the Falcons, giving Atlanta a 2–0 lead. In the 2nd quarter, though, Eli Manning connected with Hakeem Nicks for a short touchdown pass to make it 7–2 Giants heading into the 2nd half. Then the Giants took control, as Manning threw for two more TD passes to Mario Manningham and Nicks and the defense completed its shutout of the Falcons to give the New York Giants the win, 24–2, and the Falcons their third straight playoff loss with Matt Ryan and Mike Smith. After the season Defense Coordinator Brian VanGorder accepted a coaching job at Auburn University, and the offensive coordinator Mike Mularkey took the head coaching job in Jacksonville.
2012.
Atlanta exploded out of the gate, going a franchise best 8–0 and remaining the last unbeaten team in the NFL that year. Their hopes to get an undefeated season came to an end with a 27–31 loss to the New Orleans Saints. Julio Jones had a remarkable second year, grabbing 10 touchdowns and 1,198 yards. The Falcons finished the season 13–3, and clinched the number one seed in the NFC playoffs.
The Falcons played the Seattle Seahawks in their first playoff game. Although they went down 28–27 with only 31 seconds left on the clock, Matt Ryan led the team to their first playoff victory, 30–28. It was the only playoff victory in the Mike Smith era.
The Atlanta Falcons then advanced to face the San Francisco 49ers. The Falcons seized control of the game early with a Matt Bryant field goal, a trio of Matt Ryan touchdown passes caught by Julio Jones and Tony Gonzalez coupled with outstanding defensive play. By the end of the half, the score was 24–14.The tides of the game began to shift in the second half as the 49ers rallied back with a pair of Frank Gore touchdown runs. Atlanta's offense attempted to reply but were ultimately shut down by the 49er defense. A few series later, late in the 4th quarter with little time remaining, Atlanta found themselves in a 4th and 7 situation at the 10-yard line. The Falcons needed just 10 more yards to secure victory and advance to their first Super Bowl berth in nearly 15 years. Matt Ryan fired a pass to Roddy White which was ultimately broken up by inside linebacker NaVorro Bowman, resulting in a 28–24 defeat.
2013.
Following the success of the previous season, the Falcons were an expected Super Bowl contender. However, injuries hampered the team's performance and the team finished the season 4–12. With that, the streak of consecutive winning seasons came to an end and Mike Smith had his first losing season as a head coach. Tony Gonzalez, in his final season in the NFL, was selected to the 2014 Pro Bowl as a starter representing Team Rice. Following the conclusion of the 2012 season, director of player personnel Les Snead departed the team to join the St. Louis Rams and Dave Caldwell, assistant to general manager Thomas Dimitroff, left the team to join the Jacksonville Jaguars. Scott Pioli, former GM of the New England Patriots, was announced as the Falcons' new assistant GM. Mike Smith was given a one-year extension on his contract as head coach. The Falcons had the 6th overall pick in the 2014 NFL draft with which they selected Jake Matthews, who played as offensive tackle for Texas A&M.
2014.
Despite having another rough season, the Falcons still had an opportunity to qualify for the playoffs at the end of the regular season. The Falcons hosted the Carolina Panthers in their regular season finale, with the winners clinching the NFC South division. Unfortunately, the Falcons lost in a 34–3 blowout as Matt Ryan threw two interceptions that were returned for touchdowns and got sacked six times. The Falcons finished the season 6–10, marking the second consecutive losing season for the team. The following day, Mike Smith was fired after seven seasons as head coach. The Falcons would soon hire Seattle Seahawks defensive coordinator Dan Quinn as the team's 16th head coach. The Falcons had the 8th overall pick in the 2015 NFL draft with which they selected Vic Beasley, a defensive end from Clemson University.
Dan Quinn Era (2015-present).
The Atlanta Falcons started the season 5–0, their best start since 2012. However, the Falcons would struggle throughout the rest of the season by losing 8 of their remaining 11 games. After their Week 15 win at EverBank Field against the Jacksonville Jaguars, the Falcons managed to improve their record from last season. They did, however give the Carolina Panthers their only regular season loss. The Falcons finished the 2015 season with a 8-8 record.
Mercedes-Benz Stadium.
In an effort to replace the aging Georgia Dome and potentially host a future Super Bowl, team owner Arthur Blank proposed a deal with the city of Atlanta to build a new state-of-the-art stadium not far from where the Georgia Dome is located. Blank will contribute $800 million and the city of Atlanta will contribute an additional $200 million via bonds backed by the city's hotel/motel tax towards the construction of a retractable roof stadium. Blank will contribute additional money for cost overruns if it is needed. The team will provide up to $50 million towards infrastructure costs that weren't included in the construction budget and to retire the remaining debt on the Georgia Dome. In addition, Blank's foundation and the city will each provide $15 million for development in surrounding neighborhoods. Though the total cost of the stadium was initially estimated to be around $1 billion, the total cost is now projected to be $1.5 billion according to Blank. In March 2013, the Atlanta City Council voted 11–4 in favor of building the stadium. The new stadium is scheduled to be completed in time for the 2017 NFL season.
Logo and uniforms.
When the team debuted in 1966, the Falcons wore red helmets with a black falcon crest logo. In the center of the helmet was a center black stripe surrounded by 2 gold stripes and 2 white stripes. These colors represented the two college rival schools in the state of Georgia; rival schools Georgia Tech Yellow Jackets (White and Gold) and the Georgia Bulldogs (Red and Black) Although the gold was later taken out, the white remains to this day. They wore white pants and either black or white jerseys. At first, the falcon crest logo was also put on the jersey sleeves, but it was replaced by a red and white stripe pattern four years later. They switched from black to red jerseys in 1971, and the club began to wear silver pants in 1978.
A prototype white helmet was developed for the team prior to the 1974 season but was never worn.
In 1990, the uniform design changed to black helmets, silver pants, and either black or white jerseys. The numbers on the white jerseys were black, but were changed to red in 1997. (The red numerals could be seen on the away jerseys briefly in 1990.)
Both the logo and uniforms changed in 2003. The logo was redesigned with red and silver accents to depict a more powerful, aggressive falcon, which now more closely resembles the capital letter "F". Although the Falcons still wore black helmets, the new uniforms featured jerseys and pants with red trim down the sides. The uniform design consisted of either black or white jerseys, and either black or white pants. During that same year, a red alternate jersey with black trim was also introduced. The Falcons also started wearing black cleats with these uniforms.
In 2004, the red jerseys became the primary jerseys, and the black ones became the alternate, both worn with white pants. In select road games, the Falcons wear black pants with white jerseys. The Falcons wore an all-black combination for home games against their archrivals, the New Orleans Saints, winning the first two contests (24–21 in and 36–17 in ), but losing 31–13 in . The Falcons wore the all black combination against the New Orleans Saints for 4 straight seasons starting in 2004, With the last time being in 2007, losing 34–14. They wore the combination again in 2006, against the Tampa Bay Buccaneers in Week 2. The Falcons won that game, 14–3. The Falcons also wore their all-black uniform in 2007 against the New York Giants, and in 2008 against the Carolina Panthers and against the Tampa Bay Buccaneers (for the second time).
In the 1980s, the Falcons wore their white uniforms at home most of the time because of the heat. When the Falcons started playing in a dome, the team switched to their dark uniforms for home games but have worn their white uniforms at home a few times since switching to the dome. It was announced at the 2009 state of the franchise meeting that the Falcons would wear 1966 throwback uniforms for a couple games during the 2009 season. The Atlanta Falcons wore 1966 throwback jerseys for 2 home games in 2009 – against the Carolina Panthers on September 20 and against the Tampa Bay Buccaneers on November 29. The Falcons won both of those games. They donned the throwbacks again for 2 games in 2010, against Baltimore and San Francisco, winning both of those games as well.
Statistics.
Record vs. opponents.
Includes postseason records
! Total || 330 || 432 || 6 || || || || || 7–12 ()
Players.
Pro Football Hall of Famers.
Sanders and Humphrey are the only two players in the Hall of Fame that have been inducted based substantially on their service with the Falcons; however, four inductees played briefly and one coached for the Falcons during their careers:
Ring of Honor.
The Atlanta Falcons organization does not officially retire jersey numbers, but considers certain players' jerseys worthy of being honored. The Falcons Ring of Honor, which is featured in the rafters of the Georgia Dome, honors individual players.
Coaching staff.
Head coaches.
In their history, the Atlanta Falcons have had 15 head coaches.
Radio and television.
As of 2014, the Falcons' flagship radio station is WZGC 92.9 The Game, in partnership with WQXI 790 The Zone. Wes Durham, voice of the Georgia Tech Yellow Jackets and son of longtime North Carolina Tar Heels voice Woody Durham, is the Falcons' play-by-play announcer, with former Atlanta Falcons QB and pro football veteran, Dave Archer serving as color commentator.
Also in 2014, The CW owned-and-operated station WUPA became the official television station of the Falcons, gaining rights to its preseason games, which are produced by CBS Sports.
Radio affiliates.
Atlanta Falcon radio affiliates include:
Public interest initiatives.
A delegation from the Atlanta Falcons Cheerleaders, on January 26, 2009, traveled to the Guantánamo Bay detention camps, in Cuba, to sign autographs, and enhance the troops' morale.
While there, the cheerleaders toured the detention camps' hospital, and Camp IV, Camp V, and Camp VI.

</doc>
<doc id="2104" url="https://en.wikipedia.org/wiki?curid=2104" title="Heathenry in the United States">
Heathenry in the United States

Heathenry is a modern Pagan new religious movement that has been active in the United States since at least the early 1970s. Although the term "Heathenry" is often employed to cover the entire religious movement, different Heathen groups within the United States often prefer the term "Asatru" or "Odinism" as self-designations.
Heathenry appeared in the United States during the 1960s, at the same time as the wider emergence of modern Paganism in the United States. Among the earliest American group was the Odinist Fellowship, founded by Danish migrant Else Christensen in 1969.
History.
Asatru grew steadily in the United States during the 1960s. In 1969 the Danish Odinist Else Christensen established the Odinist Fellowship from her home in Florida, U.S. Heavily influenced by Alexander Rud Mills' writings, she began publication of a magazine, "The Odinist", although this focused to a greater extent on right-wing and racialist ideas than theological ones. Stephen McNallen first founded the Viking Brotherhood in the early 1970s, before creating the Asatru Free Assembly in 1976, which broke up in 1986 amid widespread political disagreements after McNallen's repudiation of neo-Nazis within the group. In the 1990s, McNallen founded the Ásatrú Folk Assembly (AFA), an ethnically oriented Heathen group headquartered in California.
Meanwhile, Valgard Murray and his kindred in Arizona founded the Asatru Alliance (AA) in the late 1980s, which shared the AFA's perspectives on race and which published the "Vor Tru" newsletter. In 1987, Edred Thorsson and James Chisholm founded The Troth, which was incorporated in Texas. Taking an inclusive, non-racialist view, it soon grew into an international organisation.
Terminology.
In English usage, the genitive "" "of Æsir faith" is often used on its own to denote adherents (both singular and plural). This term is favoured by practitioners who focus on the deities of Scandinavia, although is problematic as many Asatruer worship deities and entities other than the Aesir, such as the Vanir, Valkyries, Elves, and Dwarves. Other practitioners term their religion "Vanuatrú", meaning "those who honour the Vanir" or "Dísitrú", meaning "those who honour the Goddesses", depending on their particular theological emphasis.
Within the community it is sometimes stated that the term "Asatru" pertains to groups which are not racially focused, while "Odinism" is the term preferred by racially oriented groups, however in practice there is no such neat division in terminology.
There are notable differences of emphasis between "Ásatrú" as practiced in the US and in Scandinavia. According to Strmiska and Sigurvinsson (2005), American Asatruar tend to prefer a more devotional form of worship and a more emotional conception of the Nordic gods than Scandinavian practitioners, reflecting the parallel tendency of highly emotional forms of Christianity prevalent in the United States.
Demographics.
Although deeming it impossible to calculate the exact size of the Heathen community in the US, sociologist Jeffrey Kaplan estimated that, in the mid-1990s, there were around 500 active practitioners in the country, with a further thousand individuals on the periphery of the movement. He noted that the overwhelming majority of individuals in the movement were white, male, and young. Most had at least an undergraduate degree, and worked in a mix of white collar and blue collar jobs. From her experience within the community, Snook concurred that the majority of American Heathens were male, adding also that most were also white and middle-aged, but believed that there had been a growth in the proportion of Heathen women in the U.S. since the mid-1990s.
The Pagan Census project led by Helen A. Berger, Evan A. Leach, and Leigh S. Shaffer gained 60 responses from Heathens in the U.S., noting that 65% were male and 35% female, which they saw as the "opposite" of the rest of the country's Pagan community. The majority had a college education, but were generally less well educated than the wider Pagan community, with a lower median income than the wider Pagan community too. 
Subsequent assessments have suggested a larger support base; 10,000 to 20,000 according to McNallen, and 7,878 according to the 2014 census.
Politics and controversies.
Ásatrú organizations have memberships which span the entire political and spiritual spectrum. There is a history of political controversy within organized US Ásatrú, mostly surrounding the question of how to deal with such adherents as place themselves in a context of the far right and white supremacy, notably resulting in the fragmentation of the "Asatru Free Assembly" in 1986.
Externally, political activity on the part of Ásatrú organizations has surrounded campaigns against alleged religious discrimination, such as the call for the introduction of an Ásatrú "emblem of belief" by the United States Department of Veterans Affairs to parallel the Wiccan pentacle granted to the widow of Patrick Stewart in 2006. In May 2013 the "Hammer of Thor" was added to the list of United States Department of Veterans Affairs emblems for headstones and markers.
Folkish Ásatrú, Universalism and racialism.
Historically, the main dispute between the national organizations has generally centered on the interpretation of "Nordic heritage" as either something cultural, or as something genetic or racial. In the internal discourse within American Ásatrú, this cultural/racial divide has long been known as "universalist" vs. "folkish" Asatru. 
The Troth takes the "universalist" position, claiming "Asatru" as a synonym for "Northern European Heathenry" taken to comprise "many variations, names, and practices, including Theodism, Irminism, Odinism, and Anglo-Saxon Heathenry". In the UK, Germanic Neopaganism is more commonly known as Odinism or as "Heathenry". This is mostly a matter of terminology, and US Asatru may be equated with UK Odinism for practical purposes, as is evident in the short-lived International Asatru-Odinic Alliance of folkish Asatru/Odinist groups.
Some groups identifying as Ásatrú have been associated with neo-Nazi and "white power" movements.
Discrimination charges.
Inmates of the "Intensive Management Unit" at Washington State Penitentiary who are adherents of Ásatrú in 2001 were deprived of their Thor's Hammer medallions.
In 2007, a federal judge confirmed that Ásatrú adherents in US prisons have the right to possess a Thor’s Hammer pendant. An inmate sued the Virginia Department of Corrections after he was denied it while members of other religions were allowed their medallions.
In the Georgacarakos v. Watts case Peter N. Georgacarakos filed a pro se civil-rights complaint in the United States District Court for the District of Colorado against 19 prison officials for "interference with the free exercise of his Ásatrú religion" and "discrimination on the basis of his being Ásatrú".

</doc>
<doc id="2106" url="https://en.wikipedia.org/wiki?curid=2106" title="Ansible">
Ansible

An ansible is a fictional machine capable of instantaneous or superluminal communication. It can send and receive messages to and from a corresponding device over any distance whatsoever with no delay. Ansibles occur as plot devices in science fiction literature.
Origin.
Ursula K. Le Guin coined the word "ansible" in her 1966 novel "Rocannon's World". Le Guin states that she derived the name from the word "answerable", as the device would allow its users to receive answers to their messages in a reasonable amount of time, even over interstellar distances. Her award-winning 1974 novel "The Dispossessed", a book in the Hainish Cycle, tells of the invention of the ansible.
In reality.
A wormhole could provide a method of faster-than-light communication that would not violate the rules of relativity in any way. And wormholes are a known solution of Einstein's equations that humanity may succeed in engineering sometime in the future. A signal sent through a wormhole (or "micro-wormhole", one possible method of creating a working ansible) would take a "short-cut" through space, allowing instantaneous communication from any place in the universe to another if they could be engineered. Wormholes wouldn't necessarily have the problem of time travel (as long as they were purposefully created not to).
Quantum nonlocality (and in particular the phenomenon of quantum entanglement) is often proposed as another mechanism for superluminal communication.
Indeed, both experiments and theory show that entangled particles at some distance exhibit statistical correlations that cannot be explained in classical terms except by some kind of instantaneous effect; that is what is meant by "quantum nonlocality". However, it is generally (but not universally) thought () that this effect cannot be used to communicate at speeds faster than light (but can only be used at distances slower than light, since scientists can "compare notes" at those distances about what they’ve seen). The problem with claiming that, in quantum field theory, causality is respected, and quantum correlations cannot be used to transfer information faster-than-light is that there is currently no "theory-of-everything" that unites relativity and quantum mechanics; we also know relatively little about the phenomenon at this time. So we cannot say for sure that quantum entanglement will never be used for superluminal communication, nor can we say it will for sure.
While ansible functionality is impossible for now, it may be possible someday for our descendants, by one of the above methods, or by another method that is currently unknown to physics.
In fiction.
The name of the device has since been borrowed by authors such as Orson Scott Card, 
Vernor Vinge, Elizabeth Moon, Jason Jones, Kim Stanley Robinson, L.A. Graf, and Dan Simmons.
Similar devices.
Similar devices are present in the works of numerous others, such as Frank Herbert and Philip Pullman, who called his a "lodestone resonator".
Anne McCaffrey's "Crystal Singer" series posited an instantaneous communication device powered by rare "Black Crystal" from the planet Ballybran. Black Crystals cut from the same mineral deposit could be "tuned" to sympathetically vibrate with each other instantly, even when separated by interstellar distances, allowing instantaneous telephone-like voice and data communication. Similarly, in Gregory Keyes' series "The Age of Unreason", "aetherschreibers" use two halves of a single "chime" to communicate, aided by scientific alchemy. While the speed of communication is important, so is the fact that the messages cannot be overheard except by listeners with a piece of the same original crystal.
Stephen R. Donaldson, in his Gap cycle, proposed a similar system, "Symbiotic Crystalline Resonance Transmission", clearly ansible-type technology but very difficult to produce and limited to text messages.
Some hard science fiction stories use small (possibly nano-sized) paired wormholes dedicated to communication by means of a laser which traverses the wormhole. In Robert L. Forward's novel "Timemaster", the wormhole is a living organism resembling a fourth-dimensional sea anemone, "stretched" to cover the distance between a spaceship and a satellite on the home planet.
Charles Stross's books "Singularity Sky" and "Iron Sunrise" make use of "causal channels" which use entangled particles for instantaneous two-way communication. The technique has drawbacks in that the entangled particles are expendable and the use of faster-than-light travel destroys the entanglement, so that one end of the channel must be transported below light speed. This makes them expensive and limits their usefulness somewhat.
In Richard K. Morgan's Takeshi Kovacs novels human colonies on distant planets maintain contact with earth and each other via "hyperspatial needlecast", a technology which moves information "...so close to instantaneously that scientists are still arguing about the terminology".
One ansible-like device which predates Le Guin's is the "Dirac communicator" that features in several of the works of James Blish, notably his 1954 short story "Beep". As alluded to in the title, any active device received the sum of all transmitted messages in universal space-time, in a single pulse, so that demultiplexing yielded information about the past, present, and future.
In the story With Folded Hands (1947), by Jack Williamson, instant communication and power transfer through interstellar space is possible with something referred to as "rhodomagnetic waves".
Isaac Asimov solved the same communication problem with the "hyper-wave relay" in the "Foundation" series. Larry Niven later used the same term for the plot device used within his Known Space series of novels and short stories, notably in the "Ringworld" and associated Fleet of Worlds series.
In Ivan Yefremov's 1957 novel "Andromeda", a device for instant transfer of information and matter is made real by using "bipolar mathematics" to explore use of anti-gravitational shadow vectors through a zero field and the antispace, which enables them to make contact with the planet of Epsilon Tucanae.
Le Guin's ansible was said to communicate "instantaneously", but other authors have adopted the name for devices capable only of finite-speed communication, although still faster than light.
The "subspace radio", best known today from Star Trek and named for the method used in the series for achieving faster-than-light travel, was the most commonly used name for such a faster-than-light communicator in the science fiction of the 1930s to the 1950s.
In the "Stargate" television series, characters are able to communicate instantaneously over long distances by transferring their consciousness into another person or being anywhere in the universe using "Ancient communication stones". It is not known how these stones operate, but the technology explained in the show usually revolves around wormholes for instant teleportation, faster-than-light, space-warping travel, and sometimes around quantum multiverses.
Jonathan Rosenberg, author and artist of the humorous science fiction webcomic "Scenes from a Multiverse", references an ansible powered by a quantum-entangled ferret in one of the comics.
In the "Avatar" continuity, superluminal communication via a subtle control over the state of entangled particles is possible, but for practical purposes extremely slow and expensive: at a transmission rate of three bits of information per hour and a cost of $7,500 per bit, it is used for only the highest priority messages.
In the "Doctor Who" episode "Nightmare in Silver" a character references a broken Solid State Subether Ansible Class Communicator.
In Cordwainer Smith's Instrumentality novels and stories, interplanetary and interstellar communication is normally relayed from planet to planet, presumably at superluminal speed for each stage (at least between solar systems) but with a cumulative delay. For urgent communication there is the "instant message", which is effectively instantaneous but very expensive.
In Ernest Cline's novel "Armada", alien invaders possess technology for instant "quantum communication" with unlimited range. Humans reverse engineer the device from captured alien technology.
In Le Guin's work.
In "The Word for World Is Forest", Le Guin explains that in order for communication to work with any pair of ansibles, at least one "must be on a large-mass body, the other can be anywhere in the cosmos."
In "The Left Hand of Darkness", the ansible 
Unlike McCaffrey's black crystal transceivers, Le Guin's ansibles are not mated pairs: it is possible for an ansible's coordinates to be set to any known location of a receiving ansible. Moreover, the ansibles Le Guin uses in her stories apparently have a very limited bandwidth which only allows for at most a few hundred characters of text to be communicated in any transaction of a dialog session. Instead of a microphone and speaker, Le Guin's ansibles are attached to a keyboard and small display to perform text messaging.
In Card's work.
Orson Scott Card's "Ender's Game" series uses the ansible as a plot device. "The official name is Philotic Parallax Instantaneous Communicator," explains Colonel Graff in "Ender's Game", "but somebody dredged the name "ansible" out of an old book somewhere."
Card's description of the ansible's functions in "Xenocide" involve a fictional subatomic particle, the philote. In the "Enderverse", the two quarks inside a pi meson can be separated by an arbitrary distance while remaining connected by "philotic rays". This concept is similar to quantum teleportation due to entanglement. However, in reality, quark confinement prevents quarks from being separated by any observable distance.
The ansible is also featured in the video game "Advent Rising", for which Card helped write the story.
In Elizabeth Moon's work.
There is a brief reference to the ansible in Elizabeth Moon's novel "Winning Colors". The ansible itself is a major plot element, nearly a MacGuffin in her Vatta's War series. Much of the story line revolves around various parties attacking or repairing ansibles, and around the internal politics of ISC (InterStellar Communications), which holds a monopoly on the ansible technology. 
There is a brief reference to ansibles in "Once A Hero" (novel), "She didn't trust even Fleet ansibles to keep such messages secure ...".

</doc>
<doc id="2108" url="https://en.wikipedia.org/wiki?curid=2108" title="Adalbert of Prague">
Adalbert of Prague

St. Adalbert of Prague (Czech: , , ; 956 23 April 997), was a Bohemian missionary and Christian saint. He was the Bishop of Prague and a missionary to the Hungarians, Poles, and Prussians, who was martyred in his efforts to convert the Baltic Prussians to Christianity. He is the composer of Bogurodzica, the oldest known Polish hymn. St. Adalbert was later declared the patron saint of Bohemia, Poland, Hungary and the former polity of Prussia.
Life.
Early Years.
Adalbert, named "Vojtěch" at birth, was born into a noble Czech family, to Prince Slavník and his wife Střezislava in Libice nad Cidlinou, Bohemia. His father was the rich and independent ruler of the Zličan principality that rivaled Prague (see Slavník's dynasty). Adalbert had five natural brothers: Soběslav (Slavnik's heir; died 1004), Spytimír, Pobraslav, Pořej, and Čáslav, and a half-brother named Radim of his father's liaison with another woman. Radim chose a clerical career as did Adalbert, and took the name Gaudentius. Having survived a grave illness in childhood, his parents decided to dedicate Vojtěch to the service of God. Adalbert was well educated, having studied for approximately ten years (970-80) in Magdeburg under the tutelage of St. Adalbert of Magdeburg. The young Vojtěch took his tutor's name "Adalbert" at his Confirmation.
Episcopacy.
In 981 St. Adalbert of Magdeburg died, and his young protege Adalbert returned to Bohemia. Later Bishop Dietmar of Prague ordained him a Roman Catholic priest. In 982, Bishop Dietmar died, and Adalbert, despite being under canonical age, was chosen to succeed him as Bishop of Prague. Amiable and somewhat worldly, he was not expected to trouble the secular powers by making excessive claims for the Church. Although Adalbert was from a wealthy family, he avoided comfort and luxury, and was noted for his charity and austerity. After six years of prayer and preaching, he had made little headway in evangelizing the Bohemians, who maintained deeply embedded pagan beliefs.
Adalbert opposed the participation of Christians in the slave trade and complained of polygamy and idolatry, which were common among the people. Once he started to propose reforms he was met with opposition from both the secular powers and the clergy. His family refused to support Duke Boleslaus in an unsuccessful war against Poland. Adalbert was no longer welcome and eventually forced into exile. In 990 he went to Rome. He lived as a hermit at the Benedictine monastery of Saint Alexis. Five years later, Boleslaus requested that the Pope send Adalbert back to Prague, in hopes of securing his family's support. Pope John XV agreed, with the understanding that Adalbert was free to leave Prague if he continued to encounter entrenched resistance. Adalbert returned as bishop of Prague, where he was initially received with demonstrations of apparent joy. and founded a monastery in Břevnov near the City, it being the first monastery in the Czech territory.
In 995, the Slavniks' former rivalry with the Přemyslids, who were allied with the powerful Bohemian clan of the Vršovcis, resulted in the storming of the Slavnik town of Libice nad Cidlinou, led by the Přemyslid Boleslaus II the Pious. During the struggle four or five of Adalbert's brothers were killed. The Zličan principality became part of the Přemyslids' estate. Adalbert unsuccessfully attempted to protect a noblewoman caught in adultery. She had fled to a convent, where she was killed. In upholding the right of sanctuary, Bishop Adalbert responded by excommunicating the murderers. Butler suggests that the incident was orchestrated by enemies of his family.
After this, Adalbert could not safely stay in Bohemia and escaped from Prague. Strachkvas was eventually appointed to be his successor. However, Strachkvas suddenly died during the liturgy at which he was to accede to his episcopal office in Prague. The cause of his death are still ambiguous. The Pope directed Adalbert to resume his see, but believing that he would not be allowed back, he requested a brief as an itinerant missionary.
Adalbert then traveled to Hungary and probably baptized Géza of Hungary and his son Stephen in Esztergom. Then he went to Poland where he was cordially welcomed by then-Duke Boleslaus I and installed as Bishop of Gniezno.
Mission and Martyrdom in Prussia.
Adalbert again relinquished his diocese, namely that of Gniezno, and set out as a missionary to preach to the inhabitants near Prussia. Bolesław I, Duke (and, later, King) of Poland, sent soldiers with Adalbert on his mission to the Prussians. The Bishop and his companions, including his half-brother Radim (Gaudentius), entered Prussian territory and traveled along the coast of the Baltic Sea to Gdańsk.
Success attended his efforts at first, but his imperious manner in commanding the people to abandon paganism irritated them, and at the instigation of one of the pagan priests he was murdered on 23 April 997 on the Baltic Sea coast east of Truso (currently the city of Elbląg) or near Tenkitten and Fischhausen. It is recorded that his body was bought back for its weight in gold by King Boleslaus I of Poland.
Veneration and Relics.
A few years after his martyrdom, Adalbert was canonized as St. Adalbert of Prague. His life was written in "Vita Sancti Adalberti Pragensis" by various authors, the earliest being traced to imperial Aachen and the Bishop of Liège, Notger von Lüttich, although it was previously assumed that the Roman monk John Canaparius wrote the first "Vita" in 999. Another famous biographer of St. Adalbert was St. Bruno of Querfurt who wrote a hagiography of him in 1001-4.
Notably, the Přemyslid rulers of Bohemia initially refused to ransom St. Adalbert's body from the Prussians who murdered him, and therefore it was purchased by Poles. This fact may be explained by the Saint belonging to the Slavniks family which was rival to the Přemyslids. Thus St. Adalbert's bones were preserved in Gniezno, which assisted Boleslaus I of Poland in increasing Polish political and diplomatic power in Europe.
According to Bohemian accounts, in 1039 the Bohemian Duke Břetislav I looted the bones of St. Adalbert from Gniezno in a raid and translated them to Prague. According to Polish accounts, however, he stole the wrong relics, namely those of St. Gaudentius, while the Poles concealed St. Adalbert's relics, and consequently remain in Gniezno. In 1127 his severed head, which was not in the original purchase according to "Roczniki Polskie", was discovered and translated to Gniezno. In 1928, one of the arms of St. Adalbert, which Bolesław I had given to Holy Roman Emperor Otto III in 1000, was added to the bones preserved in Gniezno. Therefore, today St. Adalbert has two elaborate shrines in the Prague Cathedral and Royal Cathedral of Gniezno, each of which claims to possess his relics, but which of their bones are his authentic relics is unknown. For example, pursuant to both claims the Saint has two skulls. The one in Gniezno was stolen in 1923.
The massive bronze doors of Gniezno Cathedral, dating from around 1175, are decorated with eighteen reliefs of scenes from the Saint's life. They are the only Romanesque ecclesiastical doors in Europe depicting a cycle illustrating the life of a saint and therefore are a precious relic documenting Adalbert's martyrdom.
23 April 1997 was the one thousandth anniversary of St. Adalbert's martyrdom. It was commemorated in Poland, Czech Republic, Germany, Russia, and other nations. Representatives of Roman Catholic, Greek Orthodox, and Evangelical churches traveled on a pilgrimage to the Saint's tomb located in Gniezno. Pope St. John Paul II visited the cathedral and celebrated a liturgy there in which heads of seven European nations and approximately one million faithful participated.
A ten-meter cross was erected near the village of Beregovoe (formerly Tenkitten), Kaliningrad Oblast where St. Adalbert is thought to have been martyred by the Prussians.

</doc>
<doc id="2110" url="https://en.wikipedia.org/wiki?curid=2110" title="Ælfheah of Canterbury">
Ælfheah of Canterbury

Ælfheah (, "elf-high"; c. 953 – 19 April 1012), officially remembered as Saint Alphege within some churches, and also called Elphege, Alfege, or Godwine, was an Anglo-Saxon Bishop of Winchester, later Archbishop of Canterbury. He became an anchorite before being elected abbot of Bath Abbey. His reputation for piety and sanctity led to his promotion to the episcopate, and eventually, to his becoming archbishop. Ælfheah furthered the cult of Dunstan and also encouraged learning. He was captured by Viking raiders in 1011 and killed by them the following year after refusing to allow himself to be ransomed. Ælfheah was canonised as a saint in 1078. Thomas Becket, a later Archbishop of Canterbury, prayed to him just before his own murder in Canterbury Cathedral.
Life.
Purportedly born in Weston on the outskirts of Bath, Ælfheah became a monk early in life. His birth took place around 953. He first entered the monastery of Deerhurst, but then moved to Bath, where he became an anchorite. He was noted for his piety and austerity, and rose to become abbot of Bath Abbey. The 12th century chronicler William of Malmesbury recorded that Ælfheah was a monk and prior at Glastonbury Abbey, but this is not accepted by all historians. Indications are that Ælfheah became abbot at Bath by 982, perhaps as early as around 977. He perhaps shared authority with his predecessor Æscwig after 968.
Probably due to the influence of Dunstan, the Archbishop of Canterbury (959–988), Ælfheah was elected Bishop of Winchester in 984, and was consecrated on 19 October that year. While bishop he was largely responsible for the construction of a large organ in the cathedral, audible from over a mile (1600 m) away and said to require more than 24 men to operate. He also built and enlarged the city's churches, and promoted the cult of Swithun and his own predecessor, Æthelwold of Winchester. One act promoting Æthelwold's cult was the translation of Æthelwold's body to a new tomb in the cathedral at Winchester, which Ælfheah presided over on 10 September 996.
Following a Viking raid in 994, a peace treaty was agreed with one of the raiders, Olaf Tryggvason. Besides receiving danegeld, Olaf converted to Christianity and undertook never to raid or fight the English again. Ælfheah may have played a part in the treaty negotiations, and it is certain that he confirmed Olaf in his new faith.
In 1006 Ælfheah succeeded Ælfric as Archbishop of Canterbury, taking Swithun's head with him as a relic for the new location. He went to Rome in 1007 to receive his pallium—symbol of his status as an archbishop—from Pope John XVIII, but was robbed during his journey. While at Canterbury he promoted the cult of Dunstan, ordering the writing of the second "Life of Dunstan", which Adelard of Ghent composed between 1006 and 1011. He also introduced new practices into the liturgy, and was instrumental in the Witenagemot's recognition of Wulfsige of Sherborne as a saint in about 1012.
Ælfheah sent Ælfric of Eynsham to Cerne Abbey to take charge of its monastic school. He was present at the council of May 1008 at which Wulfstan II, Archbishop of York, preached his "Sermo Lupi ad Anglos" ("The Sermon of the Wolf to the English"), castigating the English for their moral failings and blaming the latter for the tribulations afflicting the country.
In 1011 the Danes again raided England, and from 8–29 September they laid siege to Canterbury. Aided by the treachery of Ælfmaer, whose life Ælfheah had once saved, the raiders succeeded in sacking the city. Ælfheah was taken prisoner and held captive for seven months. Godwine (Bishop of Rochester), Leofrun (abbess of St Mildrith's), and the king's reeve, Ælfweard were captured also, but the abbot of St Augustine's Abbey, Ælfmaer, managed to escape. Canterbury Cathedral was plundered and burned by the Danes following Ælfheah's capture.
Death.
Ælfheah refused to allow a ransom to be paid for his freedom, and as a result was killed on 19 April 1012 at Greenwich (then in Kent, now part of London), reputedly on the site of St Alfege's Church. The account of Ælfheah's death appears in the E version of the "Anglo-Saxon Chronicle": 
Ælfheah was the first Archbishop of Canterbury to die a violent death. A contemporary report tells that Thorkell the Tall attempted to save Ælfheah from the mob about to kill him by offering them everything he owned except for his ship, in exchange for Ælfheah's life; Thorkell's presence is not mentioned in the "Anglo-Saxon Chronicle", however. Some sources record that the final blow, with the back of an axe, was delivered as an act of kindness by a Christian convert known as "Thrum." Ælfheah was buried in St Paul's Cathedral. In 1023 his body was moved by King Cnut to Canterbury, with great ceremony. Thorkell the Tall was appalled at the brutality of his fellow raiders, and switched sides to the English king Æthelred the Unready following Ælfheah's death.
Veneration.
Pope Gregory VII canonised Ælfheah in 1078, with a feast day of 19 April. Lanfranc, the first post-Conquest archbishop, was dubious about some of the saints venerated at Canterbury. He was persuaded of Ælfheah's sanctity, but Ælfheah and Augustine of Canterbury were the only pre-conquest Anglo-Saxon archbishops kept on Canterbury's calendar of saints. Ælfheah's shrine, which had become neglected, was rebuilt and expanded in the early 12th century under Anselm of Canterbury, who was instrumental in retaining Ælfheah's name in the church calendar. After the 1174 fire in Canterbury Cathedral, Ælfheah's remains together with those of Dunstan were placed around the high altar, at which Thomas Becket is said to have commended his life into Ælfheah's care shortly before his martyrdom during the Becket controversy. The new shrine was sealed in lead, and was north of the high altar, sharing the honour with Dunstan's shrine, which was located south of the high altar. A "Life of Saint Ælfheah" in prose and verse was written by a Canterbury monk named Osbern, at Lanfranc's request. The prose version has survived, but the "Life" is very much a hagiography: many of the stories it contains have obvious Biblical parallels, making them suspect as a historical record.
In the late medieval period, Ælfheah's feast day was celebrated in Scandinavia, perhaps because of the saint's connection with Cnut. Few church dedications to him are known, with most of them occurring in Kent and one each in London and Winchester; as well as St Alfege's Church in Greenwich, a nearby hospital (1931-1968) was named after him. In 1929 a new church in Bath was dedicated to Ælfheah, under the name Alphege, designed by Giles Gilbert Scott in homage to the ancient Roman church of Santa Maria in Cosmedin.

</doc>
<doc id="2112" url="https://en.wikipedia.org/wiki?curid=2112" title="Associative algebra">
Associative algebra

In mathematics, an associative algebra is an algebraic structure with compatible operations of addition, multiplication (assumed to be associative), and a scalar multiplication by elements in some field. The addition and multiplication operations together give "A" the structure of a ring; the addition and scalar multiplication operations together give "A" the structure of a vector space over "K". In this article we will also use the term "K"-algebra'" to mean an associative algebra over the field "K". A standard first example of a "K"-algebra is a ring of square matrices over a field "K", with the usual matrix multiplication. 
In this article associative algebras are assumed to have a multiplicative unit, denoted 1; they are sometimes called unital associative algebras for clarification. In some areas of mathematics this assumption is not made, and we will call such structures non-unital associative algebras. We will also assume that all rings are unital, and all ring homomorphisms are unital.
Many authors consider the more general concept of an associative algebra over a commutative ring "R", instead of a field: An "R"-algebra is an "R"-module with an associative "R"-bilinear binary operation, which also contains a multiplicative identity. For examples of this concept, if "S" is any ring with center "C", then "S" is an associative "C"-algebra.
Definition.
Let "R" be a fixed commutative ring (so "R" could be a field). An associative "R"-algebra (or more simply, an "R"-algebra) is an additive abelian group "A" which has the structure of both a ring and an "R"-module in such a way that the scalar multiplication satisfies
for all "r" ∈ "R" and "x", "y" ∈ "A". Furthermore, "A" is assumed to be unital, which is to say it contains an element 1 such that
for all "x" ∈ "A". Note that such an element 1 must be unique.
In other words, "A" is an "R"-module together with (1) an "R"-bilinear map "A" × "A" → "A", called the multiplication, and (2) the multiplicative identity, such that the multiplication is associative:
for all "x", "y", and "z" in "A". (Technical note: the multiplicative identity is a datum, while associativity is a property. By the uniqueness of the multiplicative identity, "unitarity" is often treated like a property.) If one drops the requirement for the associativity, then one obtains a non-associative algebra.
If "A" itself is commutative (as a ring) then it is called a commutative "R"-algebra.
As a monoid object in the category of modules.
The definition is equivalent to saying that a unital associative "R"-algebra is a monoid object in "R"-Mod (the monoidal category of "R"-modules). By definition, a ring is a monoid object in the category of abelian groups; thus, an associative algebra is obtained by replacing the category of abelian groups with the category of modules.
This reinterpretation of the definition is convenient for further generalization since one does not need to refer to elements of an algebra "A" explicitly. For example, the associativity can be expressed as follows. By the universal property of a tensor product of modules, the multiplication (the "R"-bilinear map) corresponds to a unique "R"-linear map
The associativity then refers to the identity:
From ring homomorphisms.
An associative algebra amounts to a ring homomorphism whose image lies in the center. Indeed, starting with a ring "A" and a ring homomorphism formula_6 whose image lies in the center of "A", we can make "A" an "R"-algebra by defining
for all "r" ∈ "R" and "x" ∈ "A". If "A" is an "R"-algebra, taking "x" = 1, the same formula in turn defines a ring homomorphism formula_6 whose image lies in the center.
If "A" is commutative then the center of "A" is equal to "A", so that a commutative "R"-algebra can be defined simply as a homomorphism formula_6 of commutative rings.
The ring homomorphism η appearing in the above is often called a structure map. In the commutative case, one can consider the category whose objects are ring homomorphisms "R" → "A"; i.e., commutative "R"-algebras and whose morphisms are ring homomorphisms "A" → "A" that are under "R"; i.e., "R" → "A" → "A" is "R" → "A" (i.e., the coslice category of the category of commutative rings under "R".) The prime spectrum functor Spec then determines an anti-equivalence of this category to the category of affine schemes over Spec "R". (How to weaken the commutativity assumption is a subject matter of noncommutative algebraic geometry and, more recently, of derived algebraic geometry.)
Algebra homomorphisms.
A homomorphism between two "R"-algebras is an "R"-linear ring homomorphism. Explicitly, formula_10 is an associative algebra homomorphism if
The class of all "R"-algebras together with algebra homomorphisms between them form a category, sometimes denoted "R"-Alg.
The subcategory of commutative "R"-algebras can be characterized as the coslice category "R"/CRing where CRing is the category of commutative rings.
Examples.
The most basic example is a ring itself; it is an algebra over its center or any subring lying in the center. In particular, any commutative ring is an algebra over any of its subrings. Other examples abound both from algebra and other fields of mathematics.
Algebra
Representation theory
Analysis
Geometry and combinatorics
Coalgebras.
An associative algebra over "K" is given by a "K"-vector space "A" endowed with a bilinear map "A"×"A"→"A" having 2 inputs (multiplicator and multiplicand) and one output (product), as well as a morphism "K"→"A" identifying the scalar multiples of the multiplicative identity. If the bilinear map "A"×"A"→"A" is reinterpreted as a linear map (i. e., morphism in the category of "K"-vector spaces) "A"⊗"A"→"A" (by the universal property of the tensor product), then we can view an associative algebra over "K" as a "K"-vector space "A" endowed with two morphisms (one of the form "A"⊗"A"→"A" and one of the form "K"→"A") satisfying certain conditions which boil down to the algebra axioms. These two morphisms can be dualized using categorial duality by reversing all arrows in the commutative diagrams which describe the algebra axioms; this defines the structure of a coalgebra.
There is also an abstract notion of F-coalgebra, where "F" is a functor. This is vaguely related to the notion of coalgebra discussed above.
Representations.
A representation of an algebra "A" is an algebra homomorphism ρ: "A" → End("V") from "A" to the endomorphism algebra of some vector space (or module) "V". The property of ρ being an algebra homomorphism means that ρ preserves the multiplicative operation (that is, ρ("xy")=ρ("x")ρ("y") for all "x" and "y" in "A"), and that ρ sends the unity of "A" to the unity of End("V") (that is, to the identity endomorphism of "V").
If "A" and "B" are two algebras, and ρ: "A" → End("V") and τ: "B" → End("W") are two representations, then there is a (canonical) representation "A formula_15 B" → End("V formula_15 W") of the tensor product algebra "A formula_15 B" on the vector space "V formula_15 W". However, there is no natural way of defining a tensor product of two representations of a single associative algebra in such a way that the result is still a representation of that same algebra (not of its tensor product with itself), without somehow imposing additional conditions. Here, by "tensor product of representations", the usual meaning is intended: the result should be a linear representation of the same algebra on the product vector space. Imposing such additional structure typically leads to the idea of a Hopf algebra or a Lie algebra, as demonstrated below.
Motivation for a Hopf algebra.
Consider, for example, two representations formula_19 and formula_20. One might try to form a tensor product representation formula_21 according to how it acts on the product vector space, so that
However, such a map would not be linear, since one would have
for "k" ∈ "K". One can rescue this attempt and restore linearity by imposing additional structure, by defining an algebra homomorphism Δ: "A" → "A" ⊗ "A", and defining the tensor product representation as
Such a homomorphism Δ is called a comultiplication if it satisfies certain axioms. The resulting structure is called a bialgebra. To be consistent with the definitions of the associative algebra, the coalgebra must be co-associative, and, if the algebra is unital, then the co-algebra must be co-unital as well. A Hopf algebra is a bialgebra with an additional piece of structure (the so-called antipode), which allows not only to define the tensor product of two representations, but also the Hom module of two representations (again, similarly to how it is done in the representation theory of groups).
Motivation for a Lie algebra.
One can try to be more clever in defining a tensor product. Consider, for example,
so that the action on the tensor product space is given by
This map is clearly linear in "x", and so it does not have the problem of the earlier definition. However, it fails to preserve multiplication:
But, in general, this does not equal
This shows that this definition of a tensor product is too naive. It can be used, however, to define the tensor product of two representations of a Lie algebra (rather than of an associative algebra).
Non-unital algebras.
Some authors use the term "associative algebra" to refer to structures with do not necessarily have a multiplicative identity, and hence consider homomorphisms which are not necessarily unital. 
An example of a non-unital associative algebra is given by the set of all functions "f": R → R whose limit as "x" nears infinity is zero.

</doc>
<doc id="2113" url="https://en.wikipedia.org/wiki?curid=2113" title="Axiom of regularity">
Axiom of regularity

In mathematics, the axiom of regularity (also known as the axiom of foundation) is an axiom of Zermelo–Fraenkel set theory that states that every non-empty set "A" contains an element that is disjoint from "A". In first-order logic, the axiom reads:
The axiom implies that no set is an element of itself, and that there is no infinite sequence ("an") such that "ai+1" is an element of "ai" for all "i". With the axiom of dependent choice (which is a weakened form of the axiom of choice), this result can be reversed: if there are no such infinite sequences, then the axiom of regularity is true. Hence, the axiom of regularity is equivalent, given the axiom of dependent choice, to the alternative axiom that there are no downward infinite membership chains.
The axiom of regularity was introduced by ; it was adopted in a formulation closer to the one found in contemporary textbooks by . Virtually all results in the branches of mathematics based on set theory hold even in the absence of regularity; see chapter 3 of . However, regularity makes some properties of ordinals easier to prove; and it not only allows induction to be done on well-ordered sets but also on proper classes that are well-founded relational structures such as the lexicographical ordering on formula_2
Given the other axioms of Zermelo–Fraenkel set theory, the axiom of regularity is equivalent to the axiom of induction. The axiom of induction tends to be used in place of the axiom of regularity in intuitionistic theories (ones that do not accept the law of the excluded middle), where the two axioms are not equivalent.
In addition to omitting the axiom of regularity, non-standard set theories have indeed postulated the existence of sets that are elements of themselves.
Elementary implications of regularity.
No set is an element of itself.
Let "A" be a set, and apply the axiom of regularity to {"A"}, which is a set by the axiom of pairing. We see that there must be an element of {"A"} which is disjoint from {"A"}. Since the only element of {"A"} is "A", it must be that "A" is disjoint from {"A"}. So, since "A" ∈ {"A"}, we cannot have "A" ∈ "A" (by the definition of disjoint).
No infinite descending sequence of sets exists.
Suppose, to the contrary, that there is a function, "f", on the natural numbers with "f"("n"+1) an element of "f"("n") for each "n". Define "S" = {"f"("n"): "n" a natural number}, the range of "f", which can be seen to be a set from the axiom schema of replacement. Applying the axiom of regularity to "S", let "B" be an element of "S" which is disjoint from "S". By the definition of "S", "B" must be "f"("k") for some natural number "k". However, we are given that "f"("k") contains "f"("k"+1) which is also an element of "S". So "f"("k"+1) is in the intersection of "f"("k") and "S". This contradicts the fact that they are disjoint sets. Since our supposition led to a contradiction, there must not be any such function, "f".
The nonexistence of a set containing itself can be seen as a special case where the sequence is infinite and constant.
Notice that this argument only applies to functions "f" that can be represented as sets as opposed to undefinable classes. The hereditarily finite sets, Vω, satisfy the axiom of regularity (and all other axioms of ZFC except the axiom of infinity). So if one forms a non-trivial ultrapower of Vω, then it will also satisfy the axiom of regularity. The resulting model will contain elements, called non-standard natural numbers, that satisfy the definition of natural numbers in that model but are not really natural numbers. They are fake natural numbers which are "larger" than any actual natural number. This model will contain infinite descending sequences of elements. For example, suppose "n" is a non-standard natural number, then formula_3 and formula_4, and so on. For any actual natural number "k", formula_5. This is an unending descending sequence of elements. But this sequence is not definable in the model and thus not a set. So no contradiction to regularity can be proved.
Simpler set-theoretic definition of the ordered pair.
The axiom of regularity enables defining the ordered pair ("a","b") as {"a",{"a","b"}}. See ordered pair for specifics. This definition eliminates one pair of braces from the canonical Kuratowski definition ("a","b") = .
Every set has an ordinal rank.
This was actually the original form of von Neumann's axiomatization.
For every two sets, only one can be an element of the other.
Let "X" and "Y" be sets. Then apply the axiom of regularity to the set {"X","Y"}. We see there must be an element of {"X","Y"} which is also disjoint from it. It must be either "X" or "Y". By the definition of disjoint then, we must have either "Y" is not an element of "X" or vice versa.
The axiom of dependent choice and no infinite descending sequence of sets implies regularity.
Let the non-empty set "S" be a counter-example to the axiom of regularity; that is, every element of "S" has a non-empty intersection with "S". We define a binary relation "R" on "S" by formula_6, which is entire by assumption. Thus, by the axiom of dependent choice, there is some sequence ("an") in "S" satisfying "anRan+1" for all "n" in N. As this is an infinite descending chain, we arrive at a contradiction and so, no such "S" exists.
Regularity and the rest of ZF(C) axioms.
Regularity was shown to be relatively consistent with the rest of ZF by and , meaning that if ZF without regularity is consistent, then ZF (with regularity) is also consistent. For his proof in modern notation see for instance.
The axiom of regularity was also shown to be independent from the other axioms of ZF(C), assuming they are consistent. The result was announced by Paul Bernays in 1941, although he did not publish a proof until 1954. The proof involves (and led to the study of) Rieger-Bernays permutation models (or method), which were used for other proofs of independence for non-well-founded systems ( and ).
Regularity and Russell's paradox.
Naive set theory (the axiom schema of unrestricted comprehension and the axiom of extensionality) is inconsistent due to Russell's paradox. Set theorists have avoided that contradiction by replacing the axiom schema of comprehension with the much weaker axiom schema of separation. However, this makes set theory too weak. So some of the power of comprehension was added back via the other existence axioms of ZF set theory (pairing, union, powerset, replacement, and infinity) which may be regarded as special cases of comprehension. So far, these axioms do not seem to lead to any contradiction. Subsequently, the axiom of choice and the axiom of regularity were added to exclude models with some undesirable properties. These two axioms are known to be relatively consistent.
In the presence of the axiom schema of separation, Russell's paradox becomes a proof that there is no set of all sets. The axiom of regularity (with the axiom of pairing) also prohibits such a universal set, however this prohibition is redundant when added to the rest of ZF. If the ZF axioms without regularity were already inconsistent, then adding regularity would not make them consistent.
The existence of Quine atoms (sets that satisfy the formula equation "x" = {"x"}, i.e. have themselves as their only elements) is consistent with the theory obtained by removing the axiom of regularity from ZFC. Various non-wellfounded set theories allow "safe" circular sets, such as Quine atoms, without becoming inconsistent by means of Russell's paradox.
Regularity, the cumulative hierarchy, and types.
In ZF it can be proven that the class formula_7 (see cumulative hierarchy) is equal to the class of all sets. This statement is even equivalent to the axiom of regularity (if we work in ZF with this axiom omitted). From any model which does not satisfy axiom of regularity, a model which satisfies it can be constructed by taking only sets in formula_7.
In the same paper, Scott shows that an axiomatic system based on the inherent properties of the cumulative hierarchy turns out to be equivalent to ZF, including regularity. 
History.
The concept of well-foundedness and rank of a set were both introduced by Dmitry Mirimanoff (1917) cf. and . Mirimanoff called a set "x" "regular" (French: "ordinaire") if every descending chain "x" ∋ "x1" ∋ "x2" ∋ ... is finite. Mirimanoff however did not consider his notion of regularity (and well-foundedness) as an axiom to be observed by all sets ; in later papers Mirimanoff also explored what are now called non-well-founded sets ("extraordinaire" in Mirimanoff's terminology) .

</doc>
<doc id="2114" url="https://en.wikipedia.org/wiki?curid=2114" title="IBM AIX">
IBM AIX

AIX (Advanced Interactive eXecutive, pronounced ) is a series of proprietary Unix operating systems developed and sold by IBM for several of its computer platforms. Originally released for the IBM 6150 RISC workstation, AIX now supports or has supported a wide variety of hardware platforms, including the IBM RS/6000 series and later POWER and PowerPC-based systems, IBM System i, System/370 mainframes, PS/2 personal computers, and the Apple Network Server.
AIX is based on UNIX System V with 4.3BSD-compatible extensions. It is one of five commercial operating systems that have versions certified to The Open Group's UNIX 03 standard (the others being Mac OS X, Solaris, Inspur K-UX and HP-UX).
The AIX family of operating systems debuted in 1986, became the standard operating system for the RS/6000 series on its launch in 1990, and is still actively developed by IBM. It is currently supported on IBM Power Systems alongside IBM i and Linux.
AIX was the first operating system to utilize journaling file systems, and IBM has continuously enhanced the software with features like processor, disk and network virtualization, dynamic hardware resource allocation (including fractional processor units), and reliability engineering ported from its mainframe designs.
History.
Unix started life at AT&T's Bell Labs research center in the early 1970s, running on DEC minicomputers. By 1976, the operating system was in use at various academic institutions, including Princeton, where Tom Lyon and others ported it to the S/370, to run as a guest OS under VM/370. This port would later grow out to become UTS, a mainframe Unix offering by IBM's competitor Amdahl Corporation.
IBM's own involvement in Unix can be dated to 1979, when it assisted Bell Labs in doing its own Unix port to the 370 (to be used as a build host for the 5ESS switch's software). In the process, IBM made modifications to the TSS/370 hypervisor to better support Unix.
It took until 1985 for IBM to offer its own Unix on the S/370 platform, IX/370, which was developed by Interactive Systems Corporation and intended by IBM to compete with Amdahl UTS. The operating system offered special facilities for interoperating with PC/IX, Interactive/IBM's version of Unix for IBM PC compatible hardware, and was licensed at $10,000 per sixteen concurrent users.
AIX Version 1, introduced in 1986 for the IBM 6150 RT workstation, was based on UNIX System V Releases 1 and 2. In developing AIX, IBM and Interactive Systems Corporation (whom IBM contracted) also incorporated source code from 4.2 and 4.3 BSD UNIX.
Among other variants, IBM later produced AIX Version 3 (also known as AIX/6000), based on System V Release 3, for their POWER-based RS/6000 platform. Since 1990, AIX has served as the primary operating system for the RS/6000 series (later renamed "IBM eServer pSeries", then "IBM System p", and now "IBM Power Systems"). AIX Version 4, introduced in 1994, added symmetric multiprocessing with the introduction of the first RS/6000 SMP servers and continued to evolve through the 1990s, culminating with AIX 4.3.3 in 1999. Version 4.1, in a slightly modified form, was also the standard operating system for the Apple Network Server systems sold by Apple Computer to complement the Macintosh line.
In the late 1990s, under Project Monterey, IBM and the Santa Cruz Operation planned to integrate AIX and UnixWare into a single 32-bit/64-bit multiplatform UNIX with particular emphasis on running on Intel IA-64 (Itanium) architecture CPUs. A beta test version of AIX 5L for IA-64 systems was released, but according to documents released in the "SCO v. IBM" lawsuit, less than forty licenses for the finished Monterey Unix were ever sold before the project was terminated in 2002. In 2003, the SCO Group alleged that (among other infractions) IBM had misappropriated licensed source code from UNIX System V Release 4 for incorporation into AIX; SCO subsequently withdrew IBM's license to develop and distribute AIX. IBM maintains that their license was irrevocable, and continued to sell and support the product until the litigation was adjudicated.
AIX was a component of the 2003 "SCO v. IBM" lawsuit, in which the SCO Group filed a lawsuit against IBM, alleging IBM contributed SCO's intellectual property to the Linux codebase. The SCO Group, who argued they were the rightful owners of the copyrights covering the Unix operating system, attempted to revoke IBM's license to sell or distribute the AIX operating system. In March 2010, a jury returned a verdict finding that Novell, not the SCO Group, owns the rights to Unix.
AIX 6 was announced in May 2007, and it ran as an open beta from June 2007 until the general availability (GA) of AIX 6.1 on November 9, 2007. Major new features in AIX 6.1 included full role-based access control, workload partitions (which enable application mobility), enhanced security (Addition of AES encryption type for NFS v3 and v4), and Live Partition Mobility on the POWER6 hardware.
AIX 7.1 was announced in April 2010, and an open beta ran until general availability of AIX 7.1 in September 2010. Several new features, including better scalability, enhanced clustering and management capabilities were added. AIX 7.1 includes a new built-in clustering capability called Cluster Aware AIX. AIX is able to organize multiple LPARs through the multipath communications channel to neighboring CPUs, enabling very high-speed communication between processors. This enables multi-terabyte memory address range and page table access to support global petabyte shared memory space for AIX POWER7 clusters so that software developers can program a cluster as if it were a single system, without using message passing (i.e. semaphore-controlled Inter-process Communication). AIX administrators can use this new capability to cluster a pool of AIX nodes. By default, AIX V7.1 pins kernel memory and includes support to allow applications to pin their kernel stack. Pinning kernel memory and the kernel stack for applications with real-time requirements can provide performance improvements by ensuring that the kernel memory and kernel stack for an application is not paged out.
AIX 7.2 was announced in October 2015, and released in December 2015. AIX 7.2 principal feature is the Live Kernel Update capability which allows OS fixes to replace the entire AIX kernel with no impact to applications. AIX 7.2 was also restructured to remove obsolete components. The networking component, bos.net.tcp.client was repackaged to allow additional installation flexibility. Unlike AIX 7.1, AIX 7.2 is only supported on systems based on POWER7 or later processors.
Supported hardware platforms.
IBM 6150 RT.
The original AIX (sometimes called AIX/RT) was developed for the IBM 6150 RT workstation by IBM in conjunction with Interactive Systems Corporation, who had previously ported UNIX System III to the IBM PC for IBM as PC/IX. According to its developers, the AIX source (for this initial version) consisted of one million lines of code. Installation media consisted of eight 1.2M floppy disks. The RT was based on the ROMP microprocessor, the first commercial RISC chip. This was based on a design pioneered at IBM Research (the IBM 801) .
One of the novel aspects of the RT design was the use of a microkernel, called Virtual Resource Manager (VRM). The keyboard, mouse, display, disk drives and network were all controlled by a microkernel. One could "hotkey" from one operating system to the next using the Alt-Tab key combination. Each OS in turn would get possession of the keyboard, mouse and display. Besides AIX v2, the PICK OS also utilized this microkernel.
Much of the AIX v2 kernel was written in the PL/8 programming language, which proved troublesome during the migration to AIX v3. AIX v2 included full TCP/IP networking, as well as SNA and two networking file systems: NFS, licensed from Sun Microsystems, and Distributed Services (DS). DS had the distinction of being built on top of SNA, and thereby being fully compatible with DS on the IBM midrange AS/400 and mainframe systems. For the graphical user interfaces, AIX v2 came with the X10R3 and later the X10R4 and X11 versions of the X Window System from MIT, together with the Athena widget set. Compilers for Fortran and C were available. One of the more popular desktop applications was the PageMaker desktop publishing software.
IBM PS/2 series.
AIX PS/2 (also known as AIX/386) was developed by Locus Computing Corporation under contract to IBM. AIX PS/2, first released in 1987, ran on IBM PS/2 personal computers with Intel 386 and compatible processors.
The product was announced in September 1988 with a baseline tag price of $595, although some utilities like uucp were included in a separate Extension package priced at $250. nroff and troff for AIX were also sold separately in a Text Formatting System package priced at $200. The TCP/IP stack for AIX PS/2 retailed for another $300. The X Window package was priced at $195, while the C and FORTRAN compilers each had a price tag of $275. Locus also made available their DOS Merge virtual machine environment for AIX, which could run MS DOS 3.3 applications inside AIX; DOS Merge was sold separately for another $250. IBM also offered a $150 AIX PS/2 DOS Server Program, which provided file server and print server services for client computers running PC DOS 3.3.
The last version of PS/2 AIX is 1.3. It was released in 1992 and announced to add support for non-IBM (non-microchannel) computers as well. Support for PS/2 AIX ended in March 1995.
IBM mainframes.
In 1988, IBM announced AIX/370, also developed by Locus Computing. AIX/370 was IBM's third attempt to offer Unix-like functionality for their mainframe line, specifically the System/370 (the prior versions were a TSS/370 based Unix system developed jointly with AT&T c.1980, and VM/IX, a VM/370 based system developed jointly with Interactive Systems Corporation c.1984). AIX/370 was released in 1990 with functional equivalence to System V Release 2 and 4.3BSD as well as IBM enhancements. With the introduction of the ESA/390 architecture, AIX/370 was replaced by AIX/ESA in 1991, which was based on OSF/1, and also ran on the System/390 platform. This development effort was made partly to allow IBM to compete with Amdahl UTS. Unlike AIX/370, AIX/ESA ran both natively as the host operating system, and as a guest under VM. AIX/ESA, while technically advanced, had little commercial success, partially because UNIX functionality was added as an option to the existing mainframe operating system, MVS, which became MVS/ESA OpenEdition in 1999.
IA-64 systems.
As part of Project Monterey, IBM released a beta test version of AIX 5L for the IA-64 (Itanium) architecture in 2001, but this never became an official product due to lack of interest.
Apple Network Servers.
The Apple Network Server systems were PowerPC-based systems designed by Apple Computer to have numerous high-end features that standard Apple hardware did not have, including swappable hard drives, redundant power supplies, and external monitoring capability. These systems were more or less based on the Power Macintosh hardware available at the time but were designed to use AIX (versions 4.1.4 or 4.1.5) as their native operating system in a specialized version specific to the ANS.
AIX was only compatible with the Network Servers and was not ported to standard Power Macintosh hardware. Not to be confused is A/UX, Apple's earlier version of Unix for 68k-based Macintoshes.
POWER/PowerPC-based systems.
The release of AIX version 3 (sometimes called AIX/6000) coincided with the announcement of the first POWER1-based IBM RS/6000 models in 1990.
AIX v3 innovated in several ways on the software side. It was the first operating system to introduce the idea of a journaling file system, JFS, which allowed for fast boot times by avoiding the need to ensure the consistency of the file systems on disks (see fsck) on every reboot. Another innovation was shared libraries which avoid the need for static linking from an application to the libraries it used. The resulting smaller binaries used less of the hardware RAM to run, and used less disk space to install. Besides improving performance, it was a boon to developers: executable binaries could be in the tens of kilobytes instead of a megabyte for an executable statically linked to the C library. AIX v3 also scrapped the microkernel of AIX v2, a contentious move that resulted in v3 containing no PL/I code and being somewhat more "pure" than v2.
Other notable subsystems included:
, AIX runs on IBM Power, System p, System i, System p5, System i5, eServer p5, eServer pSeries and eServer i5 server product lines, as well as IBM BladeCenter blades and IBM PureFlex compute nodes based on Power Architecture technology.
POWER7 AIX features.
AIX 7.1 fully exploits systems based on POWER7 processors include the Active Memory Expansion feature, which increases system flexibility where system administrators can configure logical partitions (LPARs) to use less physical memory. For example, an LPAR running AIX appears to the OS applications to be configured with 80 GB of physical memory but the hardware actually only consumes 60 GB of physical memory. Active Memory Expansion is a virtual memory compression system which employs memory compression technology to transparently compress in-memory data, allowing more data to be placed into memory and thus expanding the memory capacity of POWER7 systems. Utilizing Active Memory Expansion can improve system utilization and increase a system’s throughput. AIX 7 automatically manages the size of memory pages used to automatically use 4 KB, 64 KB or a combination of those page sizes. This self-tuning feature results in optimized performance without administrative effort.
POWER8 AIX features.
AIX 7.2 exploits POWER8 hardware features including accelerators and eight-way hardware multithreading.
User interfaces.
The default shell was Bourne shell up to AIX version 3, but was changed to Korn shell (ksh88) in version 4 in view of XPG4 and POSIX compliance.
Graphical.
The Common Desktop Environment (CDE) is AIX's default graphical user interface. As part of Linux Affinity and the free AIX Toolboxes for Linux Applications (ATLA), open-source KDE Plasma Workspaces and GNOME desktop are also available.
System Management Interface Tool.
SMIT is the System Management Interface Tool for AIX. It allows a user to navigate a menu hierarchy of commands, rather than using the command line. Invocation is typically achieved with the command codice_1. Experienced system administrators make use of the codice_2 function key which generates the command line that SMIT will invoke to complete it.
SMIT also generates a log of commands that are performed in the codice_3 file. The codice_3 file automatically records the commands with the command flags and parameters used. The codice_3 file can be used as an executable shell script to rerun system configuration tasks. SMIT also creates the codice_6 file, which contains additional detailed information that can be used by programmers in extending the SMIT system.
codice_1 and codice_8 refer to the same program, though codice_8 invokes the text-based version, while codice_1 will invoke an X Window System based interface if possible; however, if codice_1 determines that X Window System capabilities are not present, it will present the text-based version instead of failing. Determination of X Window System capabilities is typically performed by checking for the existence of the codice_12 variable.

</doc>
<doc id="2115" url="https://en.wikipedia.org/wiki?curid=2115" title="AppleTalk">
AppleTalk

AppleTalk was a proprietary suite of networking protocols developed by Apple Inc. for their Macintosh computers. AppleTalk includes a number of features that allow local area networks to be connected with no prior setup or the need for a centralized router or server of any sort. Connected AppleTalk-equipped systems automatically assign addresses, update the distributed namespace, and configure any required inter-networking routing. It is a plug-n-play system.
AppleTalk was released in 1985, and was the primary protocol used by Apple devices through the 1980s and 1990s. Versions were also released for the IBM PC and compatibles and the Apple IIGS. AppleTalk support was also available in most networked printers (especially laser printers), some file servers,and a number of routers.
The rise of TCP/IP during the 1990s led to a reimplementation of most of these types of support on that protocol, and AppleTalk became unsupported as of the release of Mac OS X v10.6 in 2009. Many of AppleTalk's more advanced autoconfiguration features have since been introduced in Bonjour, while Universal Plug and Play serves similar needs.
History.
AppleNet.
After the release of the Apple Lisa computer in January 1983, Apple invested considerable effort in the development of a local area networking (LAN) system for the machines. Known as AppleNet, it was based on the seminal Xerox XNS protocol stack but running on a custom 1 Mbit/s coaxial cable system rather than Xerox's 2.94 Mbit/s Ethernet. AppleNet was announced early in 1983 with a fall introduction at the target price of $500 for plug-in AppleNet cards for the Lisa and the Apple II.
At that time, early LAN systems were just coming to market, including Ethernet, Token Ring and ARCNET. This was a topic of major commercial effort at the time, dominating shows like the National Computer Conference (NCC) in Anaheim in May 1983. All of the systems were jockeying for position in the market, but even at this time Ethernet's widespread acceptance suggested it was to become a "de facto" standard. It was at this show that Steve Jobs asked Gursharan Sidhu a seemingly innocuous question, "Why has networking not caught on?"
Four months later, in October, AppleNet was cancelled. At the time, they announced that "Apple realized that it's not in the business to create a networking system. We built and used AppleNet in-house, but we realized that if we had shipped it, we would have seen new standards coming up." In January, Jobs announced that they would instead be supporting IBM's Token Ring, which he expected to come out in a "few months".
AppleBus.
Through this period, Apple was deep in development of the Macintosh computer. During development, engineers had made the decision to use the Zilog 8530 serial controller chip (SCC) instead of the lower cost and more common UART to provide serial port connections. The SCC cost about $5 more than a UART, but offered much higher speeds up to 250 kilobits per second (or higher with additional hardware) and internally supported a number of basic networking-like protocols like IBM's Bisync.
The SCC was chosen because it would allow multiple devices to be attached to the port. Peripherals equipped with similar SCCs could communicate using the built-in protocols, interleaving their data with other peripherals on the same bus. This would eliminate the need for more ports on the back of the machine, and allowed for the elimination of expansion slots for supporting more complex devices. The initial concept was known as AppleBus, envisioning a system controlled by the host Macintosh polling "dumb" devices in a fashion similar to the modern Universal Serial Bus.
AppleBus networking.
The Macintosh team had already begun work on what would become the LaserWriter, and had considered a number of other options of how to share these expensive machines and other resources. A series of memos from Bob Belleville clarified these concepts, outlining the Mac, LaserWriter and a file server system which would become Macintosh Office. By late 1983 it was clear that IBM's Token Ring would not be ready in time for the launch of the Mac, and might miss the launch of these other products as well. In the end, Token Ring would not ship until October 1985.
Jobs' earlier question to Sidhu had already sparked a number of ideas. When AppleNet was cancelled in October, Sidhu led an effort to develop a new networking system based on the AppleBus hardware. This new system would not have to conform to any existing preconceptions, and was designed to be worthy of the Mac - a system that was user-installable, had zero-configuration, and no fixed network addresses - in short, a true plug-and-play network. Considerable effort was needed, but by the time the Mac was released, the basic concepts had been outlined, and some of the low-level protocols were on their way to completion. Sidhu mentioned the work to Belleville only two hours after the Mac was announced.
The "new" AppleBus was announced in early 1984, allowing direct connection from the Mac or Lisa through a small box that plugged into the serial port and connected via cables to the next computer upstream and downstream. Adaptors for Apple II and Apple III were also announced. Apple also announced that AppleBus networks could be attached to, and would appear to be a single node within, a Token Ring system. Details of how this would work were sketchy.
AppleTalk.
Just prior to its release in early 1985, AppleBus was renamed AppleTalk. The system had a number of limitations, including a speed of only 230.4 kbit/s, a maximum distance of 1000 feet from end to end, and only 32 nodes per LAN. But as the basic hardware was built into the Mac, adding nodes only cost about $50 for the adaptor box. In comparison, Ethernet or Token Ring cards cost hundreds or thousands of dollars. Additionally, the entire networking stack required only about 6 kB of RAM, allowing it to run on any Mac.
The relatively slow speed of AppleTalk allowed further reductions in cost. Instead of using RS-422's balanced transmit and receive circuits, the AppleTalk Personal Network cabling used a single common electrical ground, which limited speeds to about 500 kbit/s, but allowed one conductor to be removed. This meant that common three-conductor cables could be used for wiring. Additionally, the adaptors were designed to be "self-terminating", meaning that nodes at the end of the network could simply leave their last connector unconnected. There was no need for the wires to be connected back together into a loop, nor the need for hubs or other devices.
The system was designed for future expansion; the addressing system allowed for expansion to 255 nodes in a LAN (although only 32 could be used at that time), and by using "bridges" (which came to be known as "routers", although technically not the same) one could interconnect LANs into larger collections. "Zones" allowed devices to be addressed within a bridge-connected internet. Additionally, AppleTalk was designed from the start to allow use with any potential underlying physical link.
The main advantage of AppleTalk was that it was completely maintenance-free. To join a device to a network, you simply plugged the adaptor into the machine, then connected a cable from it to any free port on any other adaptor. AppleTalk's internal protocols negotiated a working network address number, automatically gave the computer a human-readable name, and collected up a list of the names and types of other machines on the network so the user could browse the devices through the GUI-based Chooser. AppleTalk was so easy to use that ad-hoc networks tended to appear whenever multiple Macs were in the same room. Apple would later use this in an advertisement showing a network being created between two seats in an airplane.
PhoneNet and other adaptors.
A thriving 3rd party market for AppleTalk devices developed over the next few years. One particularly notable example was an alternate adaptor designed by BMUG and commercialized by Farallon as PhoneNet in 1987. This was essentially a replacement for Apple's connector that had conventional phone jacks instead of Apple's round connectors. PhoneNet allowed AppleTalk networks to be connected together using normal telephone wires, and with very little extra work, could run analog phones and AppleTalk on a single four-conductor phone cable.
Other companies took advantage of the SCC's ability to read external clocks in order to support higher transmission speeds, up to 1 Mbit/s. In these systems the external adaptor also included its own clock, and used that to signal the SCC's clock input pins. The best known such system was Centram's FlashTalk, which ran at 768 kbit/s, and was intended to be used with their TOPS networking system. A similar solution was the 850 kbit/s DaynaTalk, which used a separate box that plugged in between the computer and a normal LocalTalk/PhoneNet box. Dayna also offered a PC expansion card that ran up to 1.7 Mbit/s when talking to other Dayna PC cards. Several other systems also existed with even higher performance, but these often required special cabling that was incompatible with LocalTalk/PhoneNet, and also required patches to the networking stack that often caused problems.
EtherTalk, TokenTalk and AppleShare.
By 1987 Ethernet was clearly winning the standards battle over Token Ring, and in the middle of that year Apple introduced EtherTalk 1.0 for the newly released Macintosh II computer. The package included both a NuBus card with Ethernet ports and a new Network control panel that allowed the user to select which physical connection to use for networking (from "Built-in" or "EtherTalk"). The release's new networking stack also expanded the system to allow a full 255 nodes per LAN. With its release, AppleTalk Personal Network was renamed LocalTalk. Token Ring would eventually be supported with the similar TokenTalk product, which used the same Network control panel and underlying software. Many third party companies would introduce compatible Ethernet and Token Ring cards that used these same drivers.
The appearance of EtherTalk also led to a problem: Networks with new and old Macs needed some way to communicate between each other. This could be as simple as a network of Ethernet Macs II trying to talk to a LaserWriter. Apple had considered the problem, and AppleTalk included the possibility for a low-cost LocalTalk-to-Ethernet bridge, but they felt it would be a low-volume product and left it to third parties. A number of companies responded, both existing communications vendors like Hayes and Cisco Systems, as well as newly formed companies like Kinetics. Contrary to Apple's belief these would be low-volume, by the end of 1987, 130,000 such systems were in use. AppleTalk was at that time the most used networking system in the world, with over three times the installations of any other vendor.
1987 also marked the introduction of the AppleShare product, a dedicated file server that ran on any Mac with 512 kB of RAM or more. A common AppleShare machine was the Mac Plus with an external SCSI hard drive. AppleShare was the #3 network operating system in the late 1980s, behind Novell NetWare and Microsoft's MS-Net. AppleShare was effectively the replacement for the failed Macintosh Office efforts, which had been based on a dedicated file server device.
AppleTalk Phase II and other developments.
A significant re-design was released in 1989 as AppleTalk Phase II. In many ways, Phase II can be considered an effort to make the earlier version (never called Phase I) more generic. LANs could now support more than 255 nodes, and zones were no longer associated with physical networks, but were entirely virtual constructs used simply to organize nodes. For instance, one could now make a "Printers" zone that would list all the printers in an organization, or one might want to place that same device in the "2nd Floor" zone to indicate its physical location. Phase II also included changes to the underlying inter-networking protocols to make them less "chatty", which had previously been a serious problem on networks that bridged over wide-area networks.
By this point Apple had a wide variety of communications products under development, and many of these were announced along with AppleTalk Phase II. These included updates to EtherTalk and TokenTalk, AppleTalk software and LocalTalk hardware for the IBM PC, EtherTalk for Apple's A/UX operating system allowing it to use LaserPrinters and other network resources, and the Mac X.25 and MacX products.
Ethernet had become almost universal by 1990, and it was time to build Ethernet into Macs direct from the factory. However, the physical wiring used by these networks was not yet completely standardized. Apple solved this problem using a single port on the back of the computer into which the user could plug an adaptor for any given cabling system. This FriendlyNet system was based on the industry-standard Attachment Unit Interface or AUI, but deliberately chose a non-standard connector that was smaller and easier to use, which they called "Apple AUI", or AAUI. FriendlyNet was first introduced on the Quadra 700 and Quadra 900 computers, and used across much of the Mac line for some time. As with LocalTalk, a number of 3rd party FriendlyNet adaptors quickly appeared.
As 10-BASE-T became the de facto cabling system for Ethernet, second-generation Power Macintosh machines added a 10-BASE-T port in addition to the AAUI, and eventually dropped AAUI on Macs with the New World ROM, and 10-BASE-T was then universal.
The capital-I Internet.
In 1988 Apple had released MacTCP, a system that allowed the Mac to support TCP/IP on machines with suitable Ethernet hardware. However, this left many universities with the problem of supporting IP on their many LocalTalk-equipped Macs. Stanford University pioneered development of MacIP, which allowed IP packets to be routed over LocalTalk networks with the support of a suitable "gateway" machine. These were initially custom devices, but it was soon common to include MacIP support in LocalTalk-to-Ethernet bridges. MacTCP would not become a standard part of the Mac OS until 1994, by which time it also supported SNMP and PPP.
For some time in the early 1990s, the Mac was a primary client on the rapidly expanding Internet. Among the better known programs in wide use were Fetch, Eudora, eXodus, NewsWatcher and the NCSA packages, especially NCSA Mosaic and its offspring, Netscape Navigator. Additionally, a number of server products appeared that allowed the Mac to host Internet content. Through this period, Macs had about 2 to 3 times as many clients connected to the Internet as any other platform, despite the relatively small overall marketshare.
As the world quickly moved to IP for both LAN and WAN uses, Apple was faced with maintaining two increasingly outdated code bases on an ever-wider group of machines as well as the introduction of the PowerPC based machines. This led to the Open Transport efforts, which re-implemented both MacTCP and AppleTalk on an entirely new code base adapted from the Unix standard STREAMS. Early versions had problems and did not become stable for some time. By that point, Apple was deep in their ultimately doomed Copland efforts.
Legacy and abandonment.
With the purchase of NeXT and subsequent development of Mac OS X, AppleTalk was strictly a legacy system. Support was added to OS X in order to provide support for the large number of existing AppleTalk devices, notably laser printers and file shares, but alternate connection solutions common in this era, notably USB for printers, limited their demand. As Apple abandoned many of these product categories, and all new systems were based on IP, AppleTalk became less and less common. AppleTalk support was finally removed from the MacOS in Mac OS X v10.6 in 2009.
However, the loss of AppleTalk did not reduce the desire for networking solutions that combined its ease-of-use with IP routing. Apple has led development of many such efforts, from the introduction of the AirPort router to the development of the Zero configuration networking system and their implementation of it, Bonjour.
Design.
The AppleTalk design rigorously followed the OSI model of protocol layering. Unlike most of the early LAN systems, AppleTalk was not built using the archetypal Xerox XNS system. The intended target was not Ethernet, and it did not have 48-bit addresses to route. Nevertheless, many portions of the AppleTalk system have direct analogs in XNS.
One key differentiation for AppleTalk was it contained two protocols aimed at making the system completely self-configuring. The "AppleTalk address resolution protocol" ("AARP") allowed AppleTalk hosts to automatically generate their own network addresses, and the "Name Binding Protocol" ("NBP") was a dynamic system for mapping network addresses to user-readable names. Although systems similar to AARP existed in other systems, Banyan VINES for instance, nothing like NBP has existed until recently.
Both AARP and NBP had defined ways to allow "controller" devices to override the default mechanisms. The concept was to allow routers to provide the information or "hardwire" the system to known addresses and names. On larger networks where AARP could cause problems as new nodes searched for free addresses, the addition of a router could reduce "chattiness." Together AARP and NBP made AppleTalk an easy-to-use networking system. New machines were added to the network by plugging them and optionally giving them a name. The NBP lists were examined and displayed by a program known as the "Chooser" which would display a list of machines on the local network, divided into classes such as file-servers and printers.
Addressing.
An AppleTalk address was a 4-byte quantity. This consisted of a two-byte network number, a one-byte node number, and a one-byte socket number. Of these, only the network number required any configuration, being obtained from a router. Each node dynamically chose its own node number, according to a protocol (originally the LocalTalk Link Access Protocol LLAP and later the AppleTalk Address Resolution Protocol, AARP) which handled contention between different nodes accidentally choosing the same number. For socket numbers, a few well-known numbers were reserved for special purposes specific to the AppleTalk protocol itself. Apart from these, all application-level protocols were expected to use dynamically-assigned socket numbers at both the client and server end.
Because of this dynamism, users could not be expected to access services by specifying their address. Instead, all services had "names" which, being chosen by humans, could be expected to be meaningful to users, and also could be sufficiently long to minimize the chance of conflicts.
As NBP names translated to an address, which included a socket number as well as a node number, a name in AppleTalk mapped directly to a "service" being provided by a machine, which was entirely separate from the name of the machine itself. Thus, services could be moved to a different machine and, so long as they kept the same service name, there was no need for users to do anything different in order to continue accessing the service. And the same machine could host any number of instances of services of the same type, without any network connection conflicts.
Contrast this with "A records" in the DNS, where a name translates to a machine's address, not including the port number that might be providing a service. Thus, if people are accustomed to using a particular machine name to access a particular service, their access will break when the service is moved to a different machine. This can be mitigated somewhat by insistence on using "CNAME records" indicating service rather than actual machine names to refer to the service, but there is no way of guaranteeing that users will follow such a convention. Some newer protocols, such as Kerberos and Active Directory use DNS SRV records to identify services by name, which is much closer to the AppleTalk model.
Protocols.
AppleTalk Address Resolution Protocol.
AARP resolves AppleTalk addresses to link layer, usually MAC, addresses. It is functionally equivalent to ARP.
AARP is a fairly simple system. When powered on, an AppleTalk machine broadcasts an "AARP probe packet" asking for a network address, intending to hear back from controllers such as routers. If no address is provided, one is picked at random from the "base subnet", 0. It then broadcasts another packet saying "I am selecting this address", and then waits to see if anyone else on the network complains. If another machine has that address, it will pick another address, and keep trying until it finds a free one. On a network with many machines it may take several tries before a free address is found, so for performance purposes the successful address is "written down" in NVRAM and used as the default address in the future. This means that in most real-world setups where machines are added a few at a time, only one or two tries are needed before the address effectively become constant.
AppleTalk Data Stream Protocol.
This was a comparatively late addition to the AppleTalk protocol suite, done when it became clear that a TCP-style reliable connection-oriented transport was needed. Significant differences from TCP were:
Apple Filing Protocol.
The Apple Filing Protocol (AFP), formerly AppleTalk Filing Protocol, is the protocol for communicating with AppleShare file servers. Built on top of AppleTalk Session Protocol (for legacy AFP over DDP) or the Data Stream Interface (for AFP over TCP), it provides services for authenticating users (extensible to different authentication methods including two-way random-number exchange) and for performing operations specific to the Macintosh HFS filesystem. AFP is still in use in Mac OS X, even though most other AppleTalk protocols have been deprecated.
AppleTalk Session Protocol.
ASP was an intermediate protocol, built on top of ATP, which in turn was the foundation of AFP. It provided basic services for requesting responses to arbitrary "commands" d performing out-of-band status queries. It also allowed the server to send asynchronous "attention" messages to the client.
Datagram Delivery Protocol.
DDP was the lowest-level data-link-independent transport protocol. It provided a datagram service with no guarantees of delivery. All application-level protocols, including the infrastructure protocols NBP, RTMP and ZIP, were built on top of DDP. AppleTalk's DDP corresponds closely to the Network layer of the Open Systems Interconnection (OSI) communication model.
Name Binding Protocol.
Name Binding Protocol was a dynamic, distributed system for managing AppleTalk names. When a service started up on a machine, it registered a name for itself as chosen by a human administrator. At this point, NBP provided a system for checking that no other machine had already registered the same name. Later, when a client wanted to access that service, it used NBP to query machines to find that service. NBP provided browseability ("what are the names of all the services available?") as well as the ability to find a service with a particular name. Names were human readable, containing spaces, upper and lower case letters, and including support for searching.
AppleTalk Echo Protocol.
AEP (AppleTalk Echo Protocol) is a transport layer protocol designed to test the reachability of network nodes. AEP generates packets to be sent to the network node and is identified in the Type field of a packet as an AEP packet. The packet is first passed to the source DDP. After it is identified as an AEP packet, it is forwarded to the node where the packet is examined by the DDP at the destination. After the packet is identified as an AEP packet, the packet is then copied and a field in the packet is altered to create an AEP reply packet, and is then returned to the source node.
Printer Access Protocol.
PAP was the standard way of communicating with PostScript printers. It was built on top of ATP. When a PAP connection was opened, each end sent the other an ATP request which basically meant "send me more data". The client's response to the server was to send a block of PostScript code, while the server could respond with any diagnostic messages that might be generated as a result, after which another "send-more-data" request was sent. This use of ATP provided automatic flow control; each end could only send data to the other end if there was an outstanding ATP request to respond to.
PAP also provided for out-of-band status queries, handled by separate ATP transactions. Even while it was busy servicing a print job from one client, a PAP server could continue to respond to status requests from any number of other clients. This allowed other Macintoshes on the LAN that were waiting to print to display status messages indicating that the printer was busy, and what the job was that it was busy with.
Routing Table Maintenance Protocol.
RTMP was the protocol by which routers kept each other informed about the topology of the network. This was the only part of AppleTalk that required periodic unsolicited broadcasts: every 10 seconds, each router had to send out a list of all the network numbers it knew about and how far away it thought they were.
Zone Information Protocol.
ZIP was the protocol by which AppleTalk network numbers were associated with zone names. A "zone" was a subdivision of the network that made sense to humans (for example, "Accounting Department"); but while a network number had to be assigned to a topologically-contiguous section of the network, a zone could include several different discontiguous portions of the network.
Physical implementation.
The initial default hardware implementation for AppleTalk was a high-speed serial protocol known as "LocalTalk" that used the Macintosh's built-in RS-422 ports at 230.4 kbit/s. LocalTalk used a splitter box in the RS-422 port to provide an upstream and downstream cable from a single port. The topology was a bus: cables were daisy-chained from each connected machine to the next, up to the maximum of 32 permitted on any LocalTalk segment. The system was slow by today's standards, but at the time the additional cost and complexity of networking on PC machines was such that it was common that Macs were the only networked personal computers in an office. Other larger computers, such as UNIX or VAX workstations, would commonly be networked via Ethernet.
Other physical implementations were also available. One common replacement for LocalTalk was "PhoneNet", a 3rd party solution (from a company called Farallon, now called Netopia) that also used the RS-422 port and was indistinguishable from LocalTalk as far as Apple's LocalTalk port drivers were concerned, but ran over the two unused wires in standard four-wire phone cabling. PhoneNet was considerably less expensive to install and maintain. Ethernet and Token Ring was also supported, known as "EtherTalk" and "TokenTalk" respectively. EtherTalk in particular gradually became the dominant implementation method for AppleTalk as Ethernet became generally popular in the PC industry throughout the 1990s. Besides AppleTalk and TCP/IP, any Ethernet network could also simultaneously carry other protocols such as DECnet and IPX.
Cross-platform solutions.
When AppleTalk was first introduced, the dominant office computing platform was the PC compatible running MS-DOS. Apple introduced the AppleTalk PC Card in early 1987, allowing PCs to join AppleTalk networks and print to LaserWriter printers. A year later AppleShare PC was released, allowing PCs to access AppleShare file servers.
The "TOPS Teleconnector" MS-DOS networking system over AppleTalk system enabled MS-DOS PCs to communicate over AppleTalk network hardware; it comprised an AppleTalk interface card for the PC and a suite of networking software allowing such functions as file, drive and printer sharing. As well as allowing the construction of a PC-only AppleTalk network, it allowed communication between PCs and Macs with TOPS software installed. (Macs without TOPS installed could use the same network but only to communicate with other Apple machines.) The Mac TOPS software did not match the quality of Apple's own either in ease of use or in robustness and freedom from crashes, but the DOS software was relatively simple to use in DOS terms, and was robust.
The BSD and Linux operating systems support AppleTalk through an open source project called Netatalk, which implements the complete protocol suite and allows them to both act as native file or print servers for Macintosh computers, and print to LocalTalk printers over the network.
The Windows Server operating systems supported AppleTalk starting with Windows NT and ending after Windows Server 2003. Miramar included AppleTalk in its PC MacLAN product which was discontinued by CA in 2007. GroupLogic continues to bundle its AppleTalk protocol with its ExtremeZ-IP server software for Macintosh-Windows integration which supports Windows 2008 Server and Windows Vista as well prior versions. HELIOS Software GmbH offers a proprietary implementation of the AppleTalk protocol stack, as part of their HELIOS UB2 server. This is essentially a File and Print Server suite that runs on a whole range of different platforms.
In addition, Columbia University released the Columbia AppleTalk Package (CAP) which implemented the protocol suite for various Unix flavors including Ultrix, SunOS, *BSD and IRIX. This package is no longer actively maintained.

</doc>
<doc id="2116" url="https://en.wikipedia.org/wiki?curid=2116" title="Apple II series">
Apple II series

The Apple II series (trademarked with square brackets as "Apple ][" and rendered on later models as "Apple //") is a family of home computers, one of the first highly successful mass-produced microcomputer products, designed primarily by Steve Wozniak, manufactured by Apple Computer (now Apple Inc.) and introduced in 1977 with the original Apple II. In terms of ease of use, features and expandability, the Apple II was a major technological advancement over its predecessor, the Apple I, a limited-production bare circuit board computer for electronics hobbyists that pioneered many features that made the Apple II a commercial success. Introduced at the West Coast Computer Faire on April 16, 1977, the Apple II was among the first successful personal computers; it launched the Apple company into a successful business (and allowed several related companies to start). Throughout the years, a number of models were sold, with the most popular model remaining relatively little changed into the 1990s. While primarily an 8-bit computer, by mid-run a 16-bit model was introduced.
It was first sold on June 10, 1977. By the end of production in 1993, somewhere between five and six million Apple II series computers (including about 1.25 million Apple IIGS models) had been produced. The Apple II was one of the longest running mass-produced home computer series, with models in production just under 17 years.
The Apple II became one of several recognizable and successful computers during the 1980s and early 1990s, although this was mainly limited to the USA. It was aggressively marketed through volume discounts and manufacturing arrangements to educational institutions which made it the first computer in widespread use in American secondary schools, displacing the early leader Commodore PET. The effort to develop educational and business software for the Apple II, including the 1979 release of the popular VisiCalc spreadsheet, made the computer especially popular with business users and families.
The original Apple II operating system was in ROM along with Integer BASIC. Programs were entered, then saved and loaded on cassette tape. When the Disk II was implemented in 1978 by Steve Wozniak, a Disk Operating System or DOS was commissioned from the company Shepardson where its development was done by Paul Laughton. The final and most popular version of this software was Apple DOS 3.3. Some commercial Apple II software booted directly and did not use standard DOS formats. This discouraged the copying or modifying of the software on the disks and improved loading speed. Apple DOS was superseded by ProDOS, which supported a hierarchical filesystem and larger storage devices. With an optional third-party Z80-based expansion card the Apple II could boot into the CP/M operating system and run WordStar, dBase II, and other CP/M software. At the height of its evolution, towards the late 1980s, the platform had the graphical look of a hybrid of the Apple II and Macintosh with the introduction of the Apple IIGS. By 1992, the platform had 16-bit processing capabilities, a mouse-driven graphical user interface, and graphics and sound capabilities far beyond the original.
Despite the introduction of the Motorola 68000-based Apple Macintosh in 1984 the Apple II series still reportedly accounted for 85% of the company's sales in the first quarter of fiscal 1985, and remained the company's primary revenue source for most of the following decade. At its peak, it was a billion-dollar-a-year industry with its associated community of third-party developers and retailers. The Apple IIGS was sold until the end of 1992; the last II-series Apple in production, the IIe, was discontinued on October 15, 1993.
Design.
The Apple II was designed to look more like a home appliance than a piece of electronic equipment. The lid popped off the beige plastic case without the use of tools, allowing access to the computer's internals, including the motherboard with eight expansion slots, and an array of random access memory (RAM) sockets that could hold up to 48 kilobytes worth of memory chips.
The Apple II had color and high-resolution graphics modes, sound capabilities and one of two built-in BASIC programming languages (initially Integer BASIC, later Applesoft BASIC). The Apple II was targeted for the masses rather than just hobbyists and engineers; it also influenced most of the microcomputers that followed it. Unlike preceding home microcomputers, it was sold as a finished consumer appliance rather than as a kit (unassembled or preassembled). "VanLOVEs Apple Handbook" and "The Apple Educators Guide" by Gerald VanDiver and Rolland Love reviewed more than 1,500 software programs that the Apple II series could use. The Apple dealer network used this book to emphasize the growing software developer base in education and personal use. 
The Apple II series had a keyboard built into the motherboard shell, with the exception of the Apple IIGS which featured an external keyboard. An upgrade kit was sold later to house the motherboard of an Apple IIGS in an Apple IIe case. The Apple II case was durable enough, according to a 1981 Apple ad, to protect an Apple II from a fire started when a cat belonging to one early user knocked over a lamp.
Models.
Early II-series models were usually designated "Apple ]["; later models "Apple //", plus a letter suffix.
Apple II.
The first Apple II computers went on sale on June 10, 1977 with a MOS Technology 6502 (later Synertek) microprocessor running at 1 MHz, 4 KB of RAM, an audio cassette interface for loading programs and storing data, and the Integer BASIC programming language built into the ROMs. The video controller displayed 40 columns by 24 lines of monochrome, upper-case-only (the original character set matches ASCII characters 0x20 to 0x5F) text on the screen, with NTSC composite video output suitable for display on a TV monitor, or on a regular TV set by way of a separate RF modulator. The original retail price of the computer was US$1298(with 4 kB of RAM) and US$2638 (with the maximum 48 kB of RAM). To reflect the computer's color graphics capability, the Apple logo on the casing was represented using rainbow stripes, which remained a part of Apple's corporate logo until early 1998. The earliest Apple IIs were assembled in Silicon Valley, and later in Texas; printed circuit boards were manufactured in Ireland and Singapore.
An external 5¼-inch floppy disk drive, the Disk II, attached via a controller card that plugged into one of the computer's expansion slots (usually slot 6), was used for data storage and retrieval to replace cassettes. The Disk II interface, created by Steve Wozniak, was regarded as an engineering masterpiece for its economy of electronic components. While other controllers had dozens of chips for synchronizing data I/O with disk rotation, seeking the head to the appropriate track, and encoding the data into magnetic pulses, Wozniak's controller card had few chips; instead, the Apple DOS used software to perform these functions. The Group Code Recording used by the controller was simpler and easier to implement in software than the more common MFM. In the end, the low chip count of the controller helped make Apple's Disk II the first affordable floppy drive for personal computers. As a side effect, Wozniak's scheme made it easy for proprietary software developers to copy-protect the media on which their software shipped by changing the low-level sector format or stepping the drive's head between the tracks; inevitably, other companies eventually sold software to foil this protection. Another Wozniak optimization allowed him to omit Shugart's Track-0 sensor. When the Operating System wants to go to track 0, the controller simply moves 40 times toward the next-lower-numbered track, relying on the mechanical stop to prevent it going any further down than track 0. This process, called "recalibration", made a loud buzzing (rapid mechanical chattering) sound that often frightened Apple novices.
The approach taken in the Disk II controller was typical of Wozniak's design sensibility. The Apple II used several engineering shortcuts to save hardware and reduce costs. For example, taking advantage of the way that 6502 instructions only access memory every other clock cycle, the video generation circuitry's memory access on the otherwise unused cycles avoided memory contention issues and also eliminated the need for a separate refresh circuit for the DRAM chips. Rather than use a complex analog-to-digital circuit to read the outputs of the game controller, Wozniak used a simple timer circuit whose period was proportional to the resistance of the game controller, and used a software loop to measure the timer.
The text and graphics screens had a complex arrangement (the scanlines were not stored in sequential areas of memory) which was reputedly due to Wozniak's realization that doing it that way would save a chip; it was less expensive to have software calculate or look up the address of the required scanline than to include the extra hardware. Similarly, in the high-resolution graphics mode, color was determined by pixel position and could thus be implemented in software, saving Wozniak the chips needed to convert bit patterns to colors. This also allowed for sub-pixel font rendering since orange and blue pixels appeared half a pixel-width further to the right on the screen than green and purple pixels.
Color on the Apple II series took advantage of a quirk of the NTSC television signal standard, which made color display relatively easy and inexpensive to implement. The original NTSC television signal specification was black-and-white. Color was tacked on later by adding a 3.58-MHz subcarrier signal that was partially ignored by B&W TV sets. Color is encoded based on the "phase" of this signal in relation to a reference "color burst" signal. The result is that the position, size, and intensity of a series of pulses define color information. These pulses can translate into "pixels" on the computer screen.
The Apple II display provided two pixels per subcarrier cycle. When the color burst reference signal was turned on and the computer attached to a color display, it could display green by showing one alternating pattern of pixels, magenta with an opposite pattern of alternating pixels, and white by placing two pixels next to each other. Later, blue and orange became available by tweaking the offset of the pixels by half a pixel-width in relation to the colorburst signal. The high-resolution display offered more colors simply by compressing more, narrower pixels into each subcarrier cycle. The coarse, low-resolution graphics display mode worked differently, as it could output a short burst of high-frequency signal per pixel to offer more color options.
The epitome of the Apple II design philosophy was the Apple II sound circuitry. Rather than having a dedicated sound-synthesis chip, the Apple II had a toggle circuit that could only emit a click through a built-in speaker or a line out jack; all other sounds (including two, three and, eventually, four-voice music and playback of audio samples and speech synthesis) were generated entirely by software that clicked the speaker at just the right times. Not for nearly a decade would an Apple II be released with a dedicated sound chip (though with six expansion slots, users could add sound functionality with various sound cards). Similar techniques were used for cassette storage: the cassette output worked the same as the speaker, and the input was a simple zero-crossing detector that served as a crude (1-bit) audio digitizer. Routines in the ROM were used to encode and decode data in frequency-shift keying for the cassette. Since the Apple II mainboard had no interrupts, it was impossible to use the speaker without taking CPU time and so most games had little sound.
Wozniak's open design and the Apple II's multiple expansion slots permitted a wide variety of third-party devices, including Apple II peripheral cards such as serial controllers, display controllers, memory boards, hard disks, networking components, and realtime clocks. There were plug-in expansion cards – such as the Z-80 SoftCard – that permitted the Apple to use the Z80 processor and run a multitude of programs developed under the CP/M operating system, including the dBase II database and the WordStar word processor. There was also a third-party 6809 card that would allow OS-9 Level One to be run. Third-party sound cards greatly improved audio capabilities, allowing simple music synthesis and text-to-speech functions. Eventually, Apple II accelerator cards were created to double or quadruple the computer's speed.
Rod Holt is credited (for example in the Walter Isaacson biography of "Jobs") with the design of the Apple II's power supply. He employed a Switched-mode power supply design. This was far smaller and generated less unwanted heat than the linear power supply some other home computers used. Isaacson quotes Wozniak saying that this was not something he could have done; "I only knew vaguely what a switching power supply was."
The original Apple II was discontinued at the start of 1981, having been superseded by the II+. An estimated 40,000 machines were sold for its 4-year production run.
Apple II Plus.
The Apple II Plus, introduced in June 1979, included the Applesoft BASIC programming language in ROM. This Microsoft-authored dialect of BASIC, which was previously available as an upgrade, supported floating-point arithmetic, and became the standard BASIC dialect on the Apple II series (though it ran at a noticeably slower speed than Steve Wozniak's Integer BASIC).
Except for improved graphics and disk-booting support in the ROM, and the removal of the 2k 6502 assembler/disassembler to make room for the floating point BASIC, the II+ was otherwise identical to the original II. RAM prices fell during 1980–81 and all II+ machines came from the factory with a full 48k of memory already installed. The language card in Slot 0 added another 16k, but it had to be bank switched since the remaining CPU address space was occupied by the ROMs and I/O area. For this reason, the extra RAM in the language card was bank-switched over the machine's built-in ROM, allowing code loaded into the additional memory to be used as if it actually were ROM. Users could thus load Integer BASIC into the language card from disk and switch between the Integer and Applesoft dialects of BASIC with DOS 3.3's INT and FP commands just as if they had the BASIC ROM expansion card. The language card was also required to use the UCSD Pascal and FORTRAN 77 compilers, which were released by Apple at about the same time. These ran under the UCSD p-System operating system, which had its own disk format and emitted code for a "virtual machine" rather than the actual 6502 processor.
A TEMPEST-approved version of the Apple II Plus was created in 1980 by the Georgia Tech Research Institute for U.S. Army FORSCOM, and used as a component in the earliest versions of the Microfix system. Fielded in 1982, the Microfix system was the first tactical system using video disk (Laserdisc) map technology providing zoom and scroll over map imagery coupled with a point database of intelligence data such as order of battle, airfields, roadways, and bridges.
Apple II Europlus and J-Plus.
After the success of the first Apple II in the United States, Apple expanded its market to include Europe, Australia and the Far East in 1979, with the Apple II Europlus (Europe, Australia) and the Apple II J-Plus (Japan). In these models, Apple made the necessary hardware, software and firmware changes in order to comply to standards outside of the U.S. The power supply was modified to accept the local voltage, and in the European and Australian model the video output signal was changed from color NTSC to monochrome PAL – an extra video card was needed for color PAL graphics, since the simple tricks Wozniak had used to generate a pseudo-NTSC signal with minimal hardware did not carry over to the more complex PAL system. In the Japanese version of the international Apple, the keyboard layout was changed to allow for Katakana writing (full Kanji support was clearly beyond the capabilities of the machine), but in most other countries the international Apple was sold with an unmodified American keyboard; thus the German model still lacked the umlauts, for example. For the most part, the Apple II Europlus and J-Plus were identical to the Apple II Plus. Production of the Europlus ended in 1983.
Apple IIe.
The Apple II Plus was followed in 1983 by the Apple IIe, a cost-reduced yet more powerful machine that used newer chips to reduce the component count and add new features, such as the display of upper and lowercase letters and a standard 64 kB of RAM.
The IIe RAM was configured as if it were a 48 kB Apple II Plus with a language card; the machine had no slot 0, but instead had an auxiliary slot that for most practical purposes took the place of slot 3, the most commonly used slot for 80-column cards in the II Plus.
The auxiliary slot could accept a 1 kB memory card to enable the 80-column display. This card contained only RAM; the hardware and firmware for the 80-column display was built into the Apple IIe, remaining fairly compatible with the older Videx-style cards, even though the low-level details were very different. An "extended 80-column card" with more memory expanded the machine's RAM to 128 kB.
As with the language card, the memory in the 80-column card was bank-switched over the machine's main RAM; this made the memory better suited to data storage than to running software, and in fact the ProDOS operating system, which was introduced with the Apple IIe, would automatically configure this memory as a RAM disk upon booting.
Third-party aux-slot memory cards later allowed expansion up to 1 MB. The 80-column card also enabled one new graphics mode, Double Lo-Res (80×48 pixels). The extended 80-column card enabled two, Double Lo-Res and Double Hi-Res (560×192 pixels). Both modes doubled the horizontal resolution in comparison to the standard Lo-Res (40×48) and Hi-Res (280×192) Modes; in the case of Double Hi-Res, the number of available colors was increased as well, from 6 to 15. Apple IIes from the very first production run could not use Double Hi-Res. Neither of these modes was directly supported by the built-in BASIC, however, so the user had to resort to the use of lots of POKE and CALL commands in BASIC, or assembly language programming, or one of a number of software Toolkits to exploit these modes.
While it was possible for software to switch out the 80-column firmware, making the firmware of a card in slot 3 available with a card in the auxiliary slot, it was not a common thing to do. However, even with the 80-column firmware enabled, slot 3's I/O memory range was still usable, giving it approximately the capability of slot 0 on a II or II plus. This meant that it actually was possible to use slot 3 for things, such as coprocessor cards and language cards, that did not use slot firmware space.
Introduced with the IIe was the DuoDisk, essentially two Disk II 5.25-inch drives in a single enclosure designed to stack between the computer and the monitor, and a new controller card to run it. This controller was (by design) functionally identical to the original Disk II controller but used a different connector, allowing a single cable to control both drives in the DuoDisk. The DuoDisk was plagued by reliability problems, however, and did not catch on as well as the Apple IIe itself.
The Apple IIe was the most popular Apple II ever built and was widely considered the "workhorse" of the line. It also has the distinction of being the longest-lived Apple computer of all time – it was manufactured and sold with only minor changes for nearly 11 years. In that time, following the original, two important variations were introduced known as the Apple IIe Enhanced (four new replacement chips to give it some of the features of the later model Apple IIc, including an upgraded processor called the 65C02) and the Apple IIe Platinum (a modernized new look for the case color to match other Apple products of the era, along with the addition of a built-in numeric keypad). An Enhanced IIe with 128 kB of RAM can be considered the minimum requirement for running most Apple II software released after about 1988. //e models were distinguished from the standard IIe by having 128k of memory, DHGR graphics mode, and a 65C02 CPU.
Two and a half years before the Apple IIe, Apple produced and unsuccessfully marketed a computer called the "Apple III" for business users. Some of its features were carried over in the design of the Apple IIe. Among them was the ProDOS operating system, which was based on Apple III's Sophisticated Operating System (SOS).
Apple IIc.
Apple released the Apple IIc in April 1984, billing it as a portable Apple II, because it could be easily carried, though unlike modern portables it lacked a built-in display and battery. The IIc even sported a carrying handle that folded down to prop the machine up into a typing position. It was the first of three Apple II models to be made in the Snow White design language, and the only one that used its unique creamy off-white color. (The other Snow White computers from the Apple II series, the IIGS and the IIc Plus, were light gray, called "Platinum" by Apple.) The obsolete cassette port was omitted from the IIc.
The Apple IIc was the first Apple II to use the 65C02 low-power variant of the 6502 processor, and featured a built-in 5.25-inch floppy drive and 128 kB RAM, with a built-in disk controller that could control external drives, composite video (NTSC or PAL), serial interfaces for modem and printer, and a port usable by either a joystick or mouse. Unlike previous Apple II models, the IIc had no internal expansion slots at all, this being the means by which its compact size was attained. Third parties did eventually figure out how to wedge up to 1 MB of additional memory and a real-time clock into the machine, and a later revision of the motherboard provided an expansion slot that could accept an Apple memory card bearing up to 1 MB of RAM. The disk port, originally intended for a second 5.25-inch floppy drive, eventually was able to interface to 3½-inch disk drives and (via third parties) even hard disks.
IIc machines supported the 16 color DHGR (double hi-resolution graphics) graphics mode and from a software standpoint were identical to the //e.
To play up the portability, two different monochrome LCD displays were sold for use with the IIc's video expansion port, although both were short-lived due to high cost and poor legibility. (An Apple IIc with the smaller of these displays appeared briefly in the film "2010".) The IIc had an external power supply that converted AC power to 12 V DC, allowing third parties to offer battery packs and automobile power adapters that connected in place of the supplied AC adapter.
The Apple IIc (in its American version) was the first microcomputer to include support for the Dvorak Simplified Keyboard, which was activated using a switch above the keyboard. This feature was also later found in late-model American Apple IIe computers (though the switch was inside the computer) and in the Apple IIGS (accessible via the built-in control panel). The international models used the same mechanism to switch between the localized and the American keyboard layouts, but did not offer Dvorak.
Apple IIGS.
The next member of the line was the Apple IIGS computer, released on September 15, 1986. A radical departure from the existing Apple II line, the IIGS featured a true 16-bit microprocessor, the 65C816, operating at with 24-bit addressing, allowing expansion up to 8 MB of RAM without the bank-switching hassles of the earlier machines (RAM cards with more than 4 MB were never directly supported by Apple). It introduced two completely new graphic modes sporting higher resolutions with a palette of 4,096 colors and up to 256 colors on screen; however, only 4 (at 640×200 resolution) or 16 (at 320×200 resolution) colors could be used on a single line at a time.
In a departure from earlier Apple II graphics modes, the new modes laid out the scanlines sequentially in memory and up to 16 scanline changes could be made (i.e. 16 palettes of 16 distinct colors each, equals 256 colors) without slowing down the CPU. However, programmers in search of a graphics challenge could always turn to 3200-color mode, which involved precisely swapping in a different 16-color palette for each of the screen's 200 scanlines as the monitor's electron beam traced the screen line by line. This exotic technique did not leave many CPU cycles available for other processing, so this "mode" was best suited to displaying static images.
The Apple IIGS stood out from any previous (or future) Apple II models, evolving and advancing the platform into the next generation of computing while still maintaining near-complete backward compatibility. The secret of the Apple IIGS's compatibility was a single chip called the Mega II, which contained the functional equivalent of an entire Apple IIe computer (sans processor). This, combined with the flawless 65C02 emulation mode of the 65C816 processor, provided full support for legacy software.
The computer also included a 32-voice Ensoniq 5503 DOC 'wavetable' sample-based sound synthesizer chip with 64 kB dedicated RAM, 256 kB (or later 1.125 MB) of standard RAM, built-in peripheral ports (switchable between IIe-style card slots and IIc-style onboard controllers for disk drives, mouse, RGB video, and serial devices), built-in AppleTalk networking, and a ROM toolbox that supported a graphical user interface derived from the Macintosh toolbox. The computer could run existing 8-bit Apple II software (including software written for the very first Apple II in Integer BASIC), but also supported 16-bit software running under a new (albeit modified) OS called ProDOS 16 and later replaced by a full 16-bit OS called GS/OS. The new OS eventually included a Finder that could be used for managing disks and files and opening documents and applications, along with desk accessories – just like the Macintosh. The 16-bit operating system would automatically switch to the text display and downshift to 8-bit mode to run legacy software, while offering a consistent, Macintosh-like graphical interface for native 16-bit applications. Eventually, the IIGS gained the ability to read and write Macintosh disks and, through third-party software, even multitasking (both cooperative and preemptive, the latter in the form of a Unix-type shell), outline TrueType font support, and in one case, even real-time 3D gaming using texture mapping.
The first 50,000 Apple IIGS computers came with Steve Wozniak's ""Woz"" signature silkscreened on the front and were referred to as the ""Woz Limited Edition"". These machines are not functionally different from machines from the same time period without the signature.
Apple IIc Plus.
The final Apple II model was the Apple IIc Plus introduced in 1988. It was the same size and shape as the IIc that came before it, but the 5.25-inch floppy drive had been replaced with a 3½-inch drive, the power supply was moved inside (gone was the IIc's "brick on a leash" power supply), and the processor was a fast 65C02 processor that actually ran 8-bit Apple II software faster than the IIGS. (Third-party accelerators for other models could, however, go as fast as , and IIGS accelerators would eventually reach .) The IIc Plus's accelerator was derived from a design licensed from Zip Technologies, a third-party maker of accelerators for the Apple II, though Apple used separate chips instead of combining the processor, cache, and supporting logic on a multi-chip module as did Zip. Like later models of the original Apple IIc, the IIc Plus included a memory expansion slot that would accept a daughter-card carrying up to a megabyte of RAM. The IIc Plus also featured a new keyboard layout that matched the Platinum IIe and IIGS. Unlike the IIe, IIc and IIGS, the IIc Plus came only in one version (American) and was not officially sold anywhere outside the USA.
Many perceived the IIc Plus as Apple's attempt to compete with the Laser 128EX/2, a popular third party Apple-compatible machine that also had an accelerated processor and a built-in 3.5-inch drive. There were few other rational explanations for Apple expending resources on the continued development of a new 8-bit Apple II model rather than furthering the 16-bit Apple IIGS. However, with its 3.5-inch drive and speedy processor, it provided a compact machine for running the AppleWorks integrated productivity package, especially with the 1 MB memory upgrade.
Apple IIe Card.
Although not an extension of the Apple II line, in 1990 the Apple IIe Card, an expansion card for the LC line of Macintosh computers, was released. Essentially a miniaturized Apple IIe computer on a card (using the Mega II chip from the Apple IIGS), it allowed the Macintosh to run 8-bit Apple IIe software through hardware emulation (although video was emulated in software and was slower at times than a IIe). Many of the LC's built-in Macintosh peripherals could be "borrowed" by the card when in Apple II mode (i.e. extra RAM, 3.5-inch floppy, AppleTalk networking, hard disk). The IIe card could not, however, run software intended for the 16-bit Apple IIGS. The Macintosh LC with IIe Card was intended to replace the Apple IIGS in schools and homes and was presumably the reason a new model Apple IIGS that was confirmed by insiders to be in development at one point was cancelled and never released.
Final years.
Apple's Macintosh product line finally eclipsed the Apple II in the early 1990s. Even after the Macintosh's introduction, the Apple II had remained the company's primary revenue source for years. The computer was the first to attract a loyal user community and many outspoken Apple II fans were bitter that the company had invested its Apple II profits into the Macintosh rather than using them to further the Apple II series.
Apple continued to sell Apple II systems alongside the Macintosh until terminating the IIGS in December 1992 and the IIe in November 1993.
Advertising, marketing, and packaging.
Mike Markkula, a retired Intel marketing manager, provided the early critical funding for Apple Computer. From 1977 to 1981, Apple used the Regis McKenna agency for its advertisements and marketing. In 1981, Chiat-Day acquired Regis McKenna's advertising operations and Apple used Chiat-Day. At Regis McKenna Advertising, the team assigned to launch the Apple II consisted of Rob Janoff, art director, Chip Schafer, copywriter and Bill Kelley, account executive. Janoff came up with the Apple logo with a bite out of it. The design was originally an olive green with matching company logotype all in lower case. Steve Jobs insisted on promoting the color capability of the Apple II by putting rainbow stripes on the Apple logo. In its letterhead and business card implementation, the rounded "a" of the logotype echoed the "bite" in the logo. This logo was developed simultaneously with an advertisement and a brochure; the latter being produced for distribution initially at the first West Coast Computer Faire. Ever since the original Apple II, Apple has paid high attention to its quality of packaging, partly because of Steve Jobs' personal preferences and opinions on packaging and final product appearance. All of Apple's packaging for the Apple II series looked similar, featuring lots of clean white space and showing the Apple rainbow logo prominently. For several years up until the late 1980s, Apple used the Motter Tektura font for packaging, until changing to the Apple Garamond font.
Apple ran the first advertisement for the Apple II, a two-page spread ad titled "Introducing Apple II", in "BYTE" in July 1977. The first brochure, was entitled "Simplicity" and the copy in both the ad and brochure pioneered "demystifying" language intended to make the new idea of a home computer more "personal." The Apple II introduction ad was later run in the September 1977 issue of "Scientific American".
For the Apple IIc, Apple wanted an advertisement to demonstrate the power of the machine despite its small size; they ran a memorable television commercial featuring a high-rise office building in which they claimed with words and images that the IIc had all the power necessary to run a large building, suggesting that it had more than enough power for the home user. (This ad, along with the "1984" Macintosh ad, was featured in a Marketing telecourse run on PBS.)
Apple later aired eight television commercials for the Apple IIGS, emphasizing its benefits to education and students, along with some print ads.
Towards the end of 1982, art director Brent Thomas and Steve Hayden came up with the idea of doing an advertising campaign based on the timely tagline "Why 1984 will not be like 1984". Chiat-Day shopped it around to a number of clients, including Apple, where it was proposed to be used for a print ad in the Wall Street Journal promoting the Apple II. However, Apple did not go for it, and the idea was filed away until the spring of 1983, when they met with the Macintosh marketing team to start working on the launch, which was scheduled for January 1984. The idea eventually became the famous "1984" commercial which aired during the third quarter at Super Bowl XVIII.
Clones.
The Apple II was frequently cloned, both in the United States and abroad and similar cloning of the IBM PC later occurred. According to some sources (see below), more than 190 different models of Apple II clones were manufactured. Most could not be legally imported into the United States; United States Customs might confiscate even a clone purchased in Asia and brought into the country as luggage. Apple sued and sought criminal charges against clone makers in more than a dozen countries, and cooperated with the agency in investigations. For example, in December 1983 raids on three separate importers, customs confiscated about 400 clones of the discontinued Apple II that investigators purchased for $375–500.
Without explicitly stating that they were Apple II clones, many had fruit-related names. An example was the Pineapple, and) that a review of the ACT Apricot explained that it was not "yet another 'fruity' Apple rip-off". Apple successfully forced the "Pineapple" to change its name to "Pinecom".
Agat was a series of Apple II compatible computers produced in Soviet Union between 1984 and 1993. They were widely used in schools in 80's. First mass-produced models Agat 4 and Agat 7 had different memory layouts and video modes to Apple II, which made first Agats only partially compatible. Agats were not direct clones of Apple II, but rather uniquely designed computers based on 6502 CPU and emulated Apple II architecture. That helped developers to port Apple II software titles to Agat. Later model Agat 9 had Apple II compatibility mode out of the box. Soviet engineers and enthusiasts developed thousands of software titles for Agat, including system software, business applications and rich frameworks for education.
Bulgarian Pravetz Series 8 was Apple II clone with Cyrillic support.
Basis, a German company, created the Basis 108, a clone for the Apple II that included both a 6502 processor and the Zilog Z80, allowing it to run the CP/M operating system as well as most Apple II software. This machine was unusual in that it was housed in a heavy cast aluminum chassis. The Basis 108 was equipped with built-in Centronics (parallel) and RS232c (serial) ports, as well as the standard six Apple II compatible slots. Unlike the Apple II it came with a detached full-stroke keyboard (AZERTY/QWERTY) of 100 keys plus 15 functions keys and separate numeric and editing keypads.
Another European Apple II clone was the Pearcom Pear II, which was larger as the original as it sported not eight but fourteen expansion slots. It also had a numerical keypad. Pearcom initially used a pear shaped rainbow logo, but stopped after Apple threatened to take legal action.
A Bosnian company named IRIS Computers (subsidiary of an electric company in Bosnia and Herzegovina and Yugoslavia ENERGOINVEST) produced Apple II clones starting in the early 1980s. Their official brand name was IRIS 8. They were very expensive and hard to obtain and were produced primarily for use in early computerized digital telephone systems and for education. Their use in offices of state companies, R&D labs and in the Yugoslav army was also reported. IRIS 8 machines looked like early IBM PCs, with a separate central unit accompanied by a cooling system and two 5.25-inch disks, monitor, and keyboard. Compatibility with the original Apple II was complete. Elite high schools in Yugoslavia and especially Bosnia and Herzegovina were equipped with clusters of 8, 16, or 32 IRIS 8 computers connected in a local network administrated by an IRIS 16 PC clone. The number of IRIS 8s produced is believed to be on the order of 10 or 20 thousand.
An Australian-produced clone of the Apple II was the Medfly, named after the Mediterranean fruit fly that attacks apples. The Medfly computer featured a faster processor, more memory, detached keyboard, lower and upper case characters, and a built-in disk controller.
Until 1992 in Brazil, it was illegal to import microcomputers. Because of that, the illegal cloning industry of Apple II-based computers was strong there. In the early 1980s, there were around 20 different clones of Apple II Plus computers in that country, all of them using illegally copied software and hardware (since the Apple II and II Plus used commonly available TTL integrated circuits). Some of the names include Elppa ("Apple" spelled backwards), Maxtro, Exato MC4000 (by CCE), AP II (by Unitron), and even an "Apple II Plus" (manufactured by a company called Milmar, which was using the name illegally). There were only two clones of the Apple IIe, since it used custom IC chips that could not be copied, and therefore had to be reversed-engineered and developed in the country. These clones were the TK3000 IIe by Microdigital and Exato IIe by CCE. In addiiton, the Laser IIc was manufactured by Milmar and, despite the name, was a clone of the Apple II Plus, not of the Apple IIc, although it had a design similar to that of the Apple IIc, with an integrated floppy controller and 80-column card, but without an integrated floppy disk drive.
The Ace clones from Franklin Computer Corporation were the best known Apple II clones and had the most lasting impact, as Franklin copied Apple's ROMs and software and freely admitted to doing so. Franklin's response was that a computer's ROM was simply a pattern of switches locked into a fixed position, and one cannot copyright a pattern of switches. Apple fought Franklin in court for about five years to get its clones off the market, and was ultimately successful when a court ruled that software stored in ROM was in fact copyrightable in the U.S. (See Apple Computer, Inc. v. Franklin Computer Corp.) Franklin later released non-infringing but less-compatible clones; these could run ProDOS and AppleWorks and had an Applesoft-like BASIC, but compatibility with other software was hit-or-miss.
Apple also challenged VTech's Laser 128, an enhanced clone of the Apple IIc first released in 1984, in court. This suit proved less fruitful for Apple, because VTech had reverse-engineered the Monitor ROM rather than copying it and had licensed Applesoft BASIC from its creator, Microsoft. Apple had neglected to obtain exclusive rights to the Applesoft dialect of BASIC from Microsoft; VTech was the first cloner to license it. The Laser 128 proved popular and remained on the market for many years, both in its original form and in accelerated versions that ran faster than . Although it was not fully compatible with the Apple II, it was close, and its popularity ensured that most major developers tested their software on a Laser as well as on genuine Apple machines. Because it was frequently sold via mail order and mass-market retailers such as Sears, the Laser 128 cut into the sales of low-cost competitors such as Commodore Business Machines as much as it did Apple's.
While the first Apple II clones were generally exact copies of their Apple counterparts that competed mainly on price, many clones had extra capabilities too. A Franklin model, the Ace 1000, sported a numeric keypad and lower-case long before these features were added to the Apple II line. The Laser 128 series is sometimes credited with spurring Apple to release the Apple IIc Plus; the built-in 3½-inch drive and accelerated processor were features Laser had pioneered. The Laser 128 also had a IIe-style expansion slot on the side that could be used to add peripheral cards.
Bell & Howell, an audiovisual equipment manufacturer whose products (particularly film projectors) were ubiquitous in American schools, offered what appeared at first glance to be an Apple II Plus clone in a distinctive black plastic case. However, these were in fact real Apple II Plus units manufactured by Apple for B&H for a brief period of time. Many schools had a few of these Black Apple or Black "Darth Vader" Apples in their labs.
ITT made the ITT 2020, a licensed Apple II Plus clone, in the UK. It has the same shape as the Apple II but was matte silver (it was sometimes known as the "silver Apple") and was not an exact copy functionally. The ITT2020 produced a PAL video signal for the European market, where the domestic US market used NTSC. Software using the BIOS worked correctly on both the Apple and ITT, but software written to access the Apple's display hardware directly, bypassing the BIOS, displayed with vertical stripes on the ITT 2020. The Apple II itself was later introduced in the UK, and both the Apple II and ITT 2020 were sold for a time, the ITT at a lower price.
Syscom 2 Inc (from Carson City, NV) created the Syscom 2 Apple II+ clone. The case looked nearly identical. It had 48kb of RAM and the normal expansion capabilities. These clones also supported lower case characters, toggled with a ^O keystroke.
An unknown company produced a clone called the RX-8800. One new feature it had was a numeric keypad.
One of the best Apple II clones, SEKON, made in Taiwan, had the same color plastic case as an Apple ][, sported 48kb of RAM standard, and a lower-uppercase switch, located where the power light indicator was typically situated on Apple II's. Additionally, it featured a 5-amp power supply which supplied ample power for add-on cards. SEKON avoided shipments being confiscated by U.S. Customs, by shipping their computers without ROMS, leaving it to the dealers to populate the boards upon arrival to their private stores. Often these machines would boot up with a familiar logo of the Apple II after the dealers removed E-proms of original Apple ROMS and added them in. The reason for such activity was so that users could obtain a fully Apple-compatible clone for usually around US$600, as opposed to US$2500 from Apple.
Although not technically a clone, Quadram produced an add-in ISA card, called the Quadlink, that provided hardware emulation of an Apple II+ for the IBM PC. The card had its own 6502 CPU and dedicated 80 K RAM (64 K for applications, plus 16 K to hold a reverse-engineered Apple ROM image, loaded at boot-time), and installed "between" the PC and its floppy drive(s), color display, and speaker, in a pass-through configuration. This allowed the PC to operate in a dual-boot fashion: when booted through the Quadlink, the PC could run the majority of II software, and read and write Apple-formatted floppies through the standard PC floppy drive. Because it had a dedicated processor, rather than any form of software emulation, this system ran at nearly the same speed as an equivalent Apple machine. Another company, Diamond Computer Systems, produced a similar card called the Trackstar, that had both a 6502 and a Z80, allowing use of software for both Apple DOS and Apple CP/M. The Trackstar also had a connector allowing use of an actual Apple floppy drive, which enhanced its compatibility with software that took advantage of Apple hardware for copy-protection.
Most of the clone manufacturers chose to stop production on their own once the IBM PC became popular since it was possible to make legitimate clones of the PC which would not violate any of IBM's patents or copyrights.
General.
Data storage.
Originally the Apple II used audio cassette tapes for program and data storage. A dedicated tape recorder along the lines of the Commodore Datasette was never produced; Apple recommended using the Panasonic RQ309 in some of its early printed documentation. The uses of common consumer cassette recorders and a standard video monitor or television set (with a third party R-F modulator) made the total cost of owning an Apple II less expensive and helped contribute to the Apple II's success.
Cassette storage may have been inexpensive, but it was also slow and unreliable. The Apple II's lack of a disk drive was "a glaring weakness" in what was otherwise intended to be a polished, professional product. Recognizing that the II needed a disk drive to be taken seriously, Apple set out to develop a disk drive and a DOS to run it. Wozniak spent the 1977 Christmas holidays designing a disk controller that reduced the number of chips used by a factor of 10 compared to existing controllers. Still lacking a DOS, and with Wozniak inexperienced in operating system design, Jobs approached Shepardson Microsystems with the project. On April 10, 1978 Apple signed a contract for $13,000 with Sheperdson to develop the DOS.
Even after disk drives made the cassette input and output ports obsolete they were still used by enthusiasts as simple one-bit audio input-output ports. Ham radio operators used the cassette input to receive slow scan TV (single frame images). A commercial speech recognition Blackjack program was available, after some user-specific voice training it would recognize simple commands (Hit, stand). Bob Bishop's "Music Kaleidoscope" was a simple program which monitored the cassette input port and based on zero-crossings created color patterns on the screen, a predecessor to current audio visualization plug-ins for media players. Music Kaleidoscope was especially popular on projection TV sets in dance halls.
Apple and many third-party developers made software available on tape at first, but after the Disk II became available in 1978, tape-based Apple II software essentially disappeared from the market. The initial price of the Disk II drive and controller was US$595, although a $100 off coupon was available through the Apple newsletter "Contact". The controller could handle two drives and a second drive (without controller) retailed for $495.
The Disk II single-sided floppy drive used 5.25-inch floppy disks; double-sided disks could be used, one side at a time, by turning them over and notching a hole for the write protect sensor. The first disk operating systems for the Apple II were DOS 3.1 and DOS 3.2, which stored 113.75 kB on each disk, organized into 35 tracks of 13 256-byte sectors each. After about two years, DOS 3.3 was introduced, storing 140 kB thanks to a minor firmware change on the disk controller that allowed it to store 16 sectors per track. (This upgrade was user-installable as two PROMs on older controllers.) After the release of DOS 3.3, the user community discontinued use of DOS 3.2 except for running legacy software. Programs that required DOS 3.2 were fairly rare; however, as DOS 3.3 was not a major architectural change aside from the number of sectors per track, a program called MUFFIN was provided with DOS 3.3 to allow users to copy files from DOS 3.2 disks to DOS 3.3 disks. It was possible for software developers to create a DOS 3.2 disk which would also boot on a system with DOS 3.3 firmware.
Later, double-sided drives, with heads to read both sides of the disk, became available from third-party companies. (Apple only produced double-sided 5.25" disks for the Lisa 1 computer).
On a DOS 3.x disk, tracks 0, 1, and most of track 2 were reserved to store the operating system. (It was possible, with a special utility, to reclaim most of this space for data if a disk did not need to be bootable.) A short ROM program on the disk controller had the ability to seek to track zero – which it did without regard for the read/write head's current position, resulting in the characteristic "chattering" sound of a Disk II boot, which was the read/write head hitting the rubber stop block at the end of the rail – and read and execute code from sector 0. The code contained in there would then pull in the rest of the operating system. DOS stored the disk's directory on track 17, smack in the middle of the 35-track disks, in order to reduce the average seek time to the frequently used directory track. The directory was fixed in size and could hold a maximum of 105 files. Subdirectories were not supported.
Most game publishers did not include DOS on their floppy disks, since they needed the memory it occupied more than its capabilities; instead, they often wrote their own boot loaders and read-only file systems. This also served to discourage "crackers" from snooping around in the game's copy-protection code, since the data on the disk was not in files that could be accessed easily.
Some third-party manufacturers produced floppy drives that could write 40 tracks to most 5.25-inch disks, yielding 160 kB of storage per disk, but the format did not catch on widely, and no known commercial software was published on 40-track media. Most drives, even Disk IIs, could write 36 tracks; a two byte modification to DOS to format the extra track was common.
The Apple Disk II stored 140 kB on single-sided, "single-density" floppy disks, but it was very common for Apple II users to extend the capacity of a single-sided floppy disk to 280 kB by cutting out a second write-protect notch on the side of the disk using a "disk notcher" or hole puncher and inserting the disk flipped over. Double-sided disks, with notches on both sides, were available at a higher price, but in practice the magnetic coating on the reverse of nominally single-sided disks was usually of good enough quality to be used (both sides were coated in the same way to prevent warping, although only one side was certified for use). Early on, diskette manufacturers routinely warned that this technique would damage the read/write head of the drives or wear out the disk faster, and these warnings were frequently repeated in magazines of the day. In practice, however, this method was an inexpensive way to store twice as much data for no extra cost, and was widely used for commercially released floppies as well.
Later, Apple IIs were able to use 3.5-inch disks with a total capacity of 800 kB and hard disks. DOS 3.3 did not support these drives natively; third-party software was required, and disks larger than about 400 kB had to be split up into multiple "virtual disk volumes."
DOS 3.3 was succeeded by ProDOS, a 1983 descendent of the Apple ///'s SOS. It added the capabilities for subdirectories and larger storage capacities.
ProDOS became the Apple II operating system of choice for users with these larger disks thanks to its native support of volumes up to 32 MB in size and the fact that AppleWorks and other newer programs required it.
Renditions of the "II" name.
The "II" portion of the Apple II name was rendered in a variety of creative ways using stylized characters which resembled punctuation symbols on the front lids of the computers, and most printed material followed this lead. The II and II+ were labeled ][ and ][ plus. The IIGS and IIc Plus were rendered in small caps. The Apple III, IIc, and IIe models used slashes: ///, //c and //e.
Legacy.
Today, emulators for various Apple II models are available to run Apple II software on OS X, Linux, Microsoft Windows, homebrew enabled Nintendo DS and other operating systems. Numerous disk images of Apple II software are available free over the Internet for use with these emulators. AppleWin and MESS are among the best emulators compatible with most Apple II images. The MESS emulator supports recording and playing back of Apple II emulation sessions, as does Home Action Replay Page (a.k.a. HARP).
However, many emulators cannot run software on copy-protected media, or can run only software employing fairly simple protection schemes, unless it is "cracked" (copy restrictions removed). Breaking protection on software was widely popular in the Apple II's heyday; even Apple itself apparently engaged in the practice. Commercial cracking software such as the popular Copy II+ program were sold in stores with the purpose of creating legitimate back-ups of protected software. Although creating back-ups was legitimate under copyright law of the time, the use of such software today is of questionable legality in the U.S. (see DMCA). For those who prefer to obtain their old software legally, the Lost Classics Project has the goal of convincing copyright holders of classic Apple II software to officially allow unrestricted free distribution of their software and has "freed" a number of programs.
In addition, an active retrocomputing community of vintage Apple II collectors and users, continue to restore, maintain and develop hardware and software for daily use of these original computers. Numerous websites and support groups exist for these enthusiasts who maintain and use their machines. There is still a small annual convention, KansasFest, dedicated to the platform.
Industry impact.
The Apple II series of computers had an enormous impact on the technology industry and on everyday life. The Apple II was the first personal computer many people ever saw. Its price was within the reach of many middle-class families, and a partnership with MECC helped make the Apple II popular in schools. By the end of 1980 Apple had already sold over 100,000 Apple IIs. Its popularity bootstrapped the computer game and educational software markets and began the boom in the word processor and computer printer markets. The first microcomputer program for business was VisiCalc, the earliest spreadsheet, and it ran first on the Apple II. Many businesses bought Apple IIs just to run VisiCalc.
The Apple II series had much more business software than the rival Atari 8-bit computers. Its success caused IBM to create the IBM PC, which many businesses purchased to run spreadsheet and word processing software, at first ported from Apple II versions; later, whole new application software dynasties would be founded on the PC. The popularity of these PCs and their clones then transformed business again with LAN applications such as e-mail and later Internet applications such as Usenet and the WWW.
The first 1000 or so Apple IIs shipped with a 68-page mimeographed "Apple II Mini Manual" bound with brass paper fasteners. This was the basis for the "Apple II Reference Manual" (a/k/a Red book) which was published in January 1978. All existing customers who sent in their warranty cards were sent free copies of the Red Book.
The Apple II Reference Manual contained the complete schematic of the entire computer's circuitry and a complete source listing of the "Monitor" ROM firmware that served as the machine's BIOS.
A revised spiral bound guide released several years later with updated information had to be purchased separately, and in the case of the Apple IIGS, the full technical documentation ran to several volumes.
The Apple II's slots, allowing any peripheral card to take control of the bus and directly access memory, enabled an independent industry of card manufacturers who together created a flood of hardware products that let users build systems that were far more powerful and useful (at a lower cost) than any competing system, most of which were not nearly as expandable and were universally proprietary. The first peripheral card was a blank prototyping card intended for electronics enthusiasts who wanted to design their own peripherals for the Apple II.
Specialty peripherals kept the Apple II in use in industry and education environments for many years after Apple Computer stopped supporting the Apple II. Well into the 1990s every clean-room (the super-clean facility where spacecraft are prepared for flight) at the Kennedy Space Center used an Apple II to monitor the environment and air quality. Most planetariums used Apple IIs to control their projectors and other equipment.
Even the game port was unusually powerful and could be used for digital and analog input and output. The early manuals included instructions for how to build a circuit with only four commonly available components (one transistor and three resistors) and a software routine to drive a common Teletype Model 33 machine. One hacker (Don Lancaster) used the game I/O to drive a LaserWriter printer.

</doc>
<doc id="2117" url="https://en.wikipedia.org/wiki?curid=2117" title="Apple III">
Apple III

The Apple III (often styled as Apple ///) is a business-oriented personal computer produced and released by Apple Computer that was intended as the successor to the Apple II series, but was largely considered a failure in the market. Development work on the Apple III started in late 1978 under the guidance of Dr. Wendell Sander. It had the internal code name of "Sara", named after Sander's daughter. The machine was first announced and released on May 19, 1980, but due to serious stability issues that required a design overhaul and a recall of existing machines, it was formally reintroduced in the second half of 1981. Development stopped and the Apple III was discontinued on April 24, 1984, and its last successor—the III Plus, was dropped from the Apple product line in September 1985.
The Apple III could be viewed as an enhanced Apple II – then the newest heir to a line of 8-bit machines dating back to 1976. However, the Apple III was not part of the Apple II line, but rather a close cousin. The key features business users wanted in a personal computer were a true typewriter-style upper/lowercase keyboard (as opposed to the Apple II which was based on a Teletype keyboard) and 80-column display. In addition, the machine had to pass U.S. Federal Communications Commission (FCC) radio frequency interference (RFI) qualifications for business equipment. In 1981, International Business Machines (IBM) unveiled the IBM Personal Computer (IBM PC) – a completely new 16-bit design soon available in a wide range of inexpensive clones. The business market moved rapidly towards the PC DOS/MS-DOS platform, eventually pulling away from the Apple 8-bit computer line.
Despite numerous stability issues and a recall that included the first 14,000 units off the assembly line, Apple was eventually able to produce a reliable and dependable version of the machine. However, damage to the computer's reputation had already been done and it failed to do well commercially as a direct result. In the end, an estimated 65,000–75,000 Apple III computers were sold. The Apple III Plus brought this up to ~120,000. Apple co-founder Steve Wozniak stated that the primary reason for the Apple III's failure was that the system was designed by Apple's marketing department, unlike Apple's previous engineering-driven projects. The Apple III's failure led to Apple reevaluating their plan to phase out the Apple II, and eventual continuation of development of the older machine. As a result, later Apple II models incorporated some hardware, such as the Apple Scribe Printer, a thermal printer, and software technologies of the Apple III.
Design.
The Apple III was designed to be a business computer and an eventual successor for the Apple II. While the Apple II contributed to the inspirations of several important business products, such as VisiCalc, Multiplan and Apple Writer, the computer's hardware architecture, operating system and developer environment were limited. The Apple III addressed these weaknesses. According to Steve Wozniak, VisiCalc and Disk II had caused the Apple II's popularity, with 90% of sales going to businesses as opposed to the hobbyists that were its original market. Apple management intended to clearly establish market segmentation by designing the Apple III to appeal to the business market, leaving the Apple II to home and education users. Management believed that "once the Apple III was out, the Apple II would stop selling in six months", Wozniak said.
The Apple III was powered by a 1.8 MHz Synertek 6502A or B 8-bit CPU and, like some of the later machines in the Apple II family, used bank switching techniques to address memory beyond the 6502's traditional 64KB limit, up to 256 K in the IIIs case. Third-party vendors also produced memory upgrade kits that allowed the Apple III to reach up to 512 KB. Other Apple III built-in features included an 80-column, 24-line display with upper and lowercase characters, a numeric keypad, dual-speed (pressure-sensitive) cursor control keys, 6-bit (DAC) audio, and a built-in 140 KB 5.25" floppy disk drive. Graphics modes included 560x192 in black and white, and 280x192 with 16 colors or shades of gray. Unlike the Apple II, the Disk III controller was built into the logic board.
The Apple III was the first Apple product that allowed the user to choose both a screen font and a keyboard layout: either QWERTY or Dvorak. These choices could not be changed while programs were running, unlike the Apple IIc, which had a keyboard switch directly above the keyboard, allowing switching on the fly.
Software.
A major limitation of the Apple II and DOS 3.3 was the way it addressed resources, which made it highly desirable for peripherals to be installed in standardized locations (slot 5 and 6 reserved for storage devices, slot 2 reserved for serial communication interfaces, etc.) This forced the user to identify a peripheral by its physical location, such as PR#6, CATALOG, D1, and so on. The Apple III introduced an advanced operating system called Apple SOS, pronounced "apple sauce". Its ability to address resources by name instead of a physical location allowed the Apple III to be more scalable. Apple SOS also allowed the full capacity of a storage device to be used as a single volume, such as the Apple ProFile hard disk drive. Also, Apple SOS supported a hierarchical file system (HFS). Some of the features and code base of Apple SOS made their way into the Apple II's ProDOS and GS/OS operating systems, as well as Lisa 7/7 and Macintosh system software.
The Apple III also introduced a new BASIC interpreter called Apple III Business BASIC, and later an implementation of UCSD Pascal for more structured programming.
With a starting price between $4,340 to $7,800 US, the Apple III was more expensive than many of the CP/M-based business computers that were available at the time. Little Apple III software was available besides VisiCalc, and because Apple did not view the Apple III as suitable for hobbyists, it did not provide much of the technical software information that accompanied the Apple II. Originally intended as a direct replacement to the Apple II series, it was designed to be backwards compatible with Apple II software. However, since Apple did not want to encourage continued development of the II platform, Apple II compatibility existed only in a special "Apple II Mode" which was limited in its capabilities to the emulation of a basic 48 KB Apple II+ configuration. Special chips were intentionally added to prevent access to the III's advanced features such as its larger memory.
Early Apple III users were told that they had to use existing 40-column Apple II word processors and spreadsheet programs, which hurt sales since those programs could be used in 80-column mode on the Apple IIs with the suitable hardware installed. It was not until several months after the Apple III was introduced that native 80-column business software became available. Since many business-oriented Apple II programs started requiring at least 64 KB of RAM (i.e. an 48 KB Apple II with an added 16 KB "language card") around the time the III was released, they were incompatible with the III, preventing some users from switching over.
The Apple III had a System Utilities program, which allowed system reconfiguration and file manipulation. Another program, Selector III, was designed to integrate with the System Utilities program and launch various applications. The program was developed by ON THREE, a large Apple III user group. Another company, Quark Software, developed a competing product, Catalyst, the cruder interface of which was offset by program-switching capabilities and support for copy-protection, which enabled companies to license users to run programs from a hard disk without worrying that their software might be backed up or copied without permission. When Apple decided to bundle Catalyst with its new ProFile hard disk, Quark celebrated, but ON THREE continued to market and sell Selector III through their monthly magazine. Selector III remained commercially available and supported long after Quark discontinued its Apple III product line.
Peripherals.
The Apple III had four expansion slots, a number that "inCider" in 1986 called "miserly". Apple II cards were compatible but risked violating government RFI regulations, and required Apple III-specific device drivers; "BYTE" stated that "Apple provides virtually no information on how to write them". As with software, Apple provided little hardware technical information with the computer but Apple III-specific products became available, such as one that made the computer compatible with the Apple IIe. Several new Apple-produced peripherals were developed for the Apple III. The original Apple III came with a built-in real-time clock, which was recognized by Apple SOS. The clock was later removed from the "revised" model, and instead was made available as an add-on.
Along with the built-in floppy drive, the Apple III could also handle up to three additional external Disk III floppy disk drives. The Disk III was only officially compatible with the Apple III. The Apple III Plus required an adapter from Apple to use the Disk III with its DB-25 disk port.
With the introduction of the revised Apple III a year after launch Apple began offering the ProFile external hard disk system. Costing US$3499 for 5MB, it also required a peripheral slot for the ProFile controller card.
Revisions.
Once the logic board design flaws were discovered, a newer logic board design was produced – which included a lower power requirement, wider traces and better designed chip sockets. The $3,495 revised model also included 256 KB RAM as a standard configuration. The 14,000 units of the original Apple III sold were returned and replaced with the entirely new revised model.
Apple III Plus.
Apple discontinued the III in October 1983 because it violated Federal Communications Commission (FCC) regulations, and the FCC required the company to change the redesigned computer's name. It introduced the Apple III Plus in December 1983 at a price of US$2995. This newer version included a built-in clock, video interlacing, standardized rear port connectors, 55-watt power supply, 256K RAM as standard, and a redesigned, IIe-like keyboard.
Owners of the Apple III could purchase individual III Plus upgrades, like the clock and interlacing feature, and obtain the newer logic board as a service replacement. A keyboard upgrade kit, dubbed "Apple III Plus upgrade kit" was also made available – which included the keyboard, cover, keyboard encoder ROM and logo replacements. This upgrade had to be installed by an authorized service technician.
Design flaws.
According to Wozniak, the Apple III "had 100 percent hardware failures". Former Apple executive Taylor Pohlman recalled:
Steve Jobs insisted on the idea of no fan or air vents – in order to make the computer run quietly. Jobs would later push this same ideology onto almost all Apple models he had control of – from the Apple Lisa and Macintosh 128K to the iMac. To allow the computer to dissipate heat, the base of the Apple III was made of heavy cast aluminum, which supposedly acted as a heat sink. One undeniable advantage to the aluminum case was a reduction in RFI (Radio Frequency Interference), a problem which had plagued the Apple II series throughout its history. Unlike the Apple II series, the power supply was mounted – without its own shell – in a compartment separate from the logic board. The decision to use an aluminum shell ultimately led to engineering issues which resulted in the Apple III's reliability problems. The lead time for manufacturing the shells was high, and this had to be done before the motherboard was finalized. Later it was realized that there wasn't enough room on the motherboard for all of the components unless narrow traces were used.
Many Apple IIIs were thought to have failed due to their inability to properly dissipate heat. "inCider" stated in 1986 that "Heat has always been a formidable enemy of the Apple ///", and some users reported that their Apple IIIs became so hot that the chips started dislodging from the board, causing the screen to display garbled data or their disk to come out of the slot "melted". "BYTE" wrote, "the integrated circuits tended to wander out of their sockets". Apple advised customers to lift the Apple III off the desk until it was six inches in the air, and then drop it to reseat the chips. Other analyses blame a faulty automatic chip insertion process, not heat.
Case designer Jerry Manock denied the design flaw charges, stating that tests proved that the unit adequately dissipated the internal heat. The primary cause, he claimed, was a major logic board design problem. The logic board used "fineline" technology that was not fully mature at the time, with narrow, closely spaced traces. When chips were "stuffed" into the board and wave-soldered, solder bridges would form between traces that were not supposed to be connected. This caused numerous short circuits, which required hours of costly diagnosis and hand rework to fix. Apple designed a new circuit board, with more layers and normal-width traces. The new logic board was laid out by one designer on a huge drafting board, rather than using the costly CAD-CAM system used for the previous board, and the new design worked.
Earlier Apple III units came with a built-in real time clock. The hardware, however, would fail after prolonged use. Assuming that National Semiconductor would test all parts before shipping them, Apple did not perform this level of testing. Apple was soldering chips directly to boards, and could not easily change out a bad chip if one was found. Eventually, Apple solved this problem by removing the real-time clock from the Apple III's specification rather than shipping the Apple III with the clock pre-installed, and then sold the peripheral as a level 1 technician add-on.
Commercial failure.
Pohlman stated that Apple was only selling 500 units a month by late 1981, mostly as replacements. The company was able to raise monthly sales to 5,000, but the IBM PC's successful launch encouraged software companies to develop for it instead, causing Apple to shift focus to the Lisa and Macintosh. By early 1984 sales were only to existing III owners, Apple itself—its 4500 employees had about 3000-4500 units—and some small businesses. Despite formerly devoting the majority of its R&D to the III and so ignoring the II that for a while dealers had difficulty in obtaining the latter, Apple discontinued the Apple III series on 24 April 1984, four months after introducing the III Plus, after selling 65-75,000 computers and replacing 14,000 defective units.
Jobs stated that Apple lost "infinite, incalculable amounts" of money on the Apple III. Pohlman claimed that there was a "stigma" at the company associated with having contributed to the computer. Most employees who worked on the III reportedly left Apple.
Influence.
The filesystem and some design ideas from Apple SOS, the Apple III's operating system, were part of Apple ProDOS and Apple GS/OS, the major operating systems for the Apple II series following the demise of the Apple III, as well as the Apple Lisa, which was the de facto business-oriented successor to the Apple III. The hierarchical file system influenced the evolution of the Macintosh: while the original Macintosh File System (MFS) was a flat file system designed for a floppy disk without subdirectories, subsequent file systems were hierarchical. By comparison, the IBM PC's first file system (again designed for floppy disks) was flat; likewise, later versions (designed for hard disks) were hierarchical.
In Popular Culture.
At the start of the Walt Disney Pictures film TRON, lead character Kevin Flynn (played by Jeff Bridges) is seen hacking into the ENCOM mainframe using an Apple III.

</doc>
<doc id="2118" url="https://en.wikipedia.org/wiki?curid=2118" title="AVL tree">
AVL tree

In computer science, an AVL tree (Georgy Adelson-Velsky and Evgenii Landis' tree, named after the inventors) is a self-balancing binary search tree. It was the first such data structure to be invented. In an AVL tree, the heights of the two child subtrees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property. Lookup, insertion, and deletion all take O(log "n") time in both the average and worst cases, where "n" is the number of nodes in the tree prior to the operation. Insertions and deletions may require the tree to be rebalanced by one or more tree rotations.
The AVL tree is named after its two Soviet inventors, Georgy Adelson-Velsky and Evgenii Landis, who published it in their 1962 paper "An algorithm for the organization of information".
AVL trees are often compared with red-black trees because both support the same set of operations and take O(log "n") time for the basic operations. For lookup-intensive applications, AVL trees are faster than red-black trees because they are more rigidly balanced. Similar to red-black trees, AVL trees are height-balanced. Both are in general not weight-balanced nor μ-balanced for any formula_1; that is, sibling nodes can have hugely differing numbers of descendants.
Operations.
Basic operations of an AVL tree involve carrying out the same actions as would be carried out on an unbalanced binary search tree, but modifications are followed by zero or more operations called tree rotations, which help to restore the height balance of the subtrees.
Searching.
Searching for a key in an AVL tree can be done the same way as that of a normal unbalanced binary search tree.
Traversal.
Once a node has been found in a balanced tree, the "next" or "previous" nodes can be explored in amortized constant time. Some instances of exploring these "nearby" nodes require traversing up to log("n") links (particularly when moving from the rightmost leaf of the root's left subtree to the root or from the root to the leftmost leaf of the root's right subtree; in the example AVL tree, moving from node 14 to the "next but one" node 19 takes 4 steps). However, exploring all "n" nodes of the tree in this manner would use each link exactly twice: one traversal to enter the subtree rooted at that node, another to leave that node's subtree after having explored it. And since there are "n"−1 links in any tree, the amortized cost is found to be 2×("n"−1)/"n", or approximately 2.
Insertion.
After inserting a node, it is necessary to check each node starting with the subject node and advancing up to the root for consistency with the invariants of AVL trees: this is called "retracing". This is achieved by considering the balance factor of each node, which is defined as the difference in heights of the left and right subtrees.
Thus the balance factor of any node of an AVL tree is in the integer range [-1,+1]. This "balance factor is stored in the node", but may have to be corrected after an insertion or a deletion, which is also done during retracing. Since with a single insertion the height of an AVL subtree cannot increase by more than one, the temporarily recomputed balance factor of a node after an insertion will be in the range [−2,+2]. For each node checked, if the recomputed balance factor remains in the range [−1,+1] no rotations are necessary. However, if the recomputed balance factor becomes less than −1 or greater than +1, the subtree rooted at this node is unbalanced, and a rotation is needed.
Let us first assume the balance factor of a node P is 2 (as opposed to the other possible unbalanced value −2). This case is depicted in the left column of the illustration with P:=5. We then look at the left subtree (the higher one), N its root. If this subtree does not lean to the right - i.e. N has balance factor 1 (or, when deletion also 0) - we can rotate the tree (rooted by 5) to the right to get a balanced tree. This is labelled as the "Left Left Case" in the illustration with N:=4. If the subtree does lean to the right - i.e. N:=3 has balance factor −1 - we first rotate the subtree to the left and end up the previous case. This second case is labelled as "Left Right Case" in the illustration.
If the balance factor of the node P is −2 (this case is depicted in the right column of the illustration P:=3) we can mirror the above algorithm. I.e. if the root N of the (higher) right subtree has balance factor −1 (or, when deletion also 0) we can rotate the whole tree to the left to get a balanced tree. This is labelled as the "Right Right Case" in the illustration with N:=4. If the root N:=5 of the right subtree has balance factor 1 ("Right Left Case") we can rotate the subtree to the right to end up in the "Right Right Case".
The whole retracing loop for an insertion looks like this:
After a rotation a subtree has the same height as before, so retracing can stop.
In order to restore the balance factors of all nodes, first observe that all nodes requiring correction lie along the path used during the initial insertion. If the above procedure is applied to nodes along this path, starting from the bottom (i.e. the inserted node), then every node in the tree will again have a balance factor of −1, 0, or 1.
The time required is for lookup, plus a maximum of retracing levels on the way back to the root, so the operation can be completed in time.
Deletion.
Let node X be the node with the value we need to delete, and let node Y be a node in the tree we need to find to take node X's place, and let node Z be the actual node we take out of the tree.
Steps to consider when deleting a node in an AVL tree are the following:
Since with a single deletion the height of an AVL subtree cannot decrease by more than one, the temporary balance factor of a node will be in the range from −2 to +2.
If the balance factor becomes ±2 then the subtree is unbalanced and needs to be rotated. The various cases of rotations are depicted in section "Insertion".
The whole retracing loop for a deletion looks like this:
The retracing can stop if the balance factor becomes ±1 indicating that the height of that subtree has remained unchanged. This can also result from a rotation when the higher child tree has a balance factor of 0.
If the balance factor becomes 0 then the height of the subtree has decreased by one and the retracing needs to continue. This can also result from a rotation.
The time required is for lookup, plus a maximum of retracing levels on the way back to the root, so the operation can be completed in time.
Comparison to other structures.
Both AVL trees and red-black trees are self-balancing binary search trees and they are very similar mathematically. The operations to repair the balance of the trees are different, but both take O(1) at one level. However, with both trees, there is a certain chance ≤ 0.5 that the balancing rules will be violated at the next or next but one level higher up to the root. Thus, on the average, where the number of levels being repaired is ≈ 1 or 2, rebalancing consumes O(1), and in the worst case it is in O(log "n") when repair happens to take place at each level up to the root.
A first difference between the two is the limiting height.
For a tree of size formula_2:
As a consequence, AVL trees are more rigidly balanced than red-black trees, leading to faster retrieval but maybe slower insertion and removal. 
Performance comparisons can be found in Ben Pfaff. His results show in 79 measurement runs the similarity of AVL trees ("AVL") and red-black trees ("RB") with relations between 0.677 and 1.077, median ≈0.947, and geometric mean ≈0.910.
Another difference is pointed out by Mehlhorn (p. 165): "AVL trees do not support constant amortized update costs", whereas red-black trees do (p. 158).

</doc>
<doc id="2120" url="https://en.wikipedia.org/wiki?curid=2120" title="Aliphatic compound">
Aliphatic compound

In organic chemistry, hydrocarbons (compounds composed of carbon and hydrogen) are divided into two classes: aromatic compounds and aliphatic compounds (; G. "aleiphar", fat, oil) also known as non-aromatic compounds. Aliphatics can be cyclic, but only aromatic compounds contain an especially stable ring of atoms, such as benzene. Aliphatic compounds can be saturated, like hexane, or unsaturated, like hexene. Open-chain compounds (whether straight or branched) contain no rings of any type, and are thus aliphatic.
Structure.
Aliphatic compounds can be saturated, joined by single bonds (alkanes), or unsaturated, with double bonds (alkenes) or triple bonds (alkynes). Besides hydrogen, other elements can be bound to the carbon chain, the most common being oxygen, nitrogen, sulphur, and chlorine. 
The simplest aliphatic compound is methane (CH4). Aliphatics include alkanes, alkenes, and alkynes.
Properties.
Most aliphatic compounds are flammable, allowing the use of hydrocarbons as fuel, such as methane in Bunsen burners and as liquefied natural gas (LNG), and acetylene in welding.
Examples of aliphatic compounds / non-aromatic.
The most important aliphatic compounds are:
Important examples of low-molecular aliphatic compounds can be found in the list below (sorted by the number of carbon-atoms):
A few structures can be shown as example:
But-1-ene can be shown as
CH2=CH-CH2-CH3
Aliphatic acids.
Aliphatic acids are the acids of nonaromatic hydrocarbons, such as acetic, propionic, and butyric acids.

</doc>
<doc id="2122" url="https://en.wikipedia.org/wiki?curid=2122" title="Astrology">
Astrology

Astrology is the study of the movements and relative positions of celestial objects as a means for divining information about human affairs and terrestrial events. Astrology has been dated to at least the 2nd millennium BCE, and has its roots in calendrical systems used to predict seasonal shifts and to interpret celestial cycles as signs of divine communications. Many cultures have attached importance to astronomical events, and some – such as the Indians, Chinese, and Maya – developed elaborate systems for predicting terrestrial events from celestial observations. Western astrology, one of the oldest astrological systems still in use, can trace its roots to 19th-17th century BCE Mesopotamia, from which it spread to Ancient Greece, Rome, the Arab world and eventually Central and Western Europe. Contemporary Western astrology is often associated with systems of horoscopes that purport to explain aspects of a person's personality and predict significant events in their lives based on the positions of celestial objects; the majority of professional astrologers rely on such systems.
Throughout most of its history astrology was considered a scholarly tradition and was common in academic circles, often in close relation with astronomy, alchemy, meteorology, and medicine. It was present in political circles, and is mentioned in various works of literature, from Dante Alighieri and Geoffrey Chaucer to William Shakespeare, Lope de Vega and Calderón de la Barca.
With the onset of the scientific revolution astrology was called into question; it has been challenged successfully both on theoretical and experimental grounds, and has been shown to have no scientific validity or explanatory power. Astrology thus lost its academic and theoretical standing, and common belief in astrology has largely declined. Astrology is now recognized to be pseudoscience.
Etymology.
The word "astrology" comes from the early Latin word "astrologia", which derives from the Greek —from ἄστρον "astron" ("star") and -λογία "-logia", ("study of"—"account of the stars"). "Astrologia" later passed into meaning 'star-divination' with "astronomia" used for the scientific term.
History.
Many cultures have attached importance to astronomical events, and the Indians, Chinese, and Maya developed elaborate systems for predicting terrestrial events from celestial observations. In the West, astrology most often consists of a system of horoscopes purporting to explain aspects of a person's personality and predict future events in their life based on the positions of the sun, moon, and other celestial objects at the time of their birth. The majority of professional astrologers rely on such systems.
Astrology has been dated to at least the 2nd millennium BCE, with roots in calendrical systems used to predict seasonal shifts and to interpret celestial cycles as signs of divine communications. A form of astrology was practised in the first dynasty of Mesopotamia (1950–1651 BCE). Chinese astrology was elaborated in the Zhou dynasty (1046–256 BCE). Hellenistic astrology after 332 BCE mixed Babylonian astrology with Egyptian Decanic astrology in Alexandria, creating horoscopic astrology. Alexander the Great's conquest of Asia allowed astrology to spread to Ancient Greece and Rome. In Rome, astrology was associated with 'Chaldean wisdom'. After the conquest of Alexandria in the 7th century, astrology was taken up by Islamic scholars, and Hellenistic texts were translated into Arabic and Persian. In the 12th century, Arabic texts were imported to Europe and translated into Latin. Major astronomers including Tycho Brahe, Johannes Kepler and Galileo practised as court astrologers. Astrological references appear in literature in the works of poets such as Dante Alighieri and Geoffrey Chaucer, and of playwrights such as Christopher Marlowe and William Shakespeare.
Throughout most of its history, astrology was considered a scholarly tradition. It was accepted in political and academic contexts, and was connected with other studies, such as astronomy, alchemy, meteorology, and medicine. At the end of the 17th century, new scientific concepts in astronomy and physics (such as heliocentrism and Newtonian mechanics) called astrology into question. Astrology thus lost its academic and theoretical standing, and common belief in astrology has largely declined.
Ancient world.
Astrology, in its broadest sense, is the search for meaning in the sky. Early evidence for humans making conscious attempts to measure, record, and predict seasonal changes by reference to astronomical cycles, appears as markings on bones and cave walls, which show that lunar cycles were being noted as early as 25,000 years ago. This was a first step towards recording the Moon's influence upon tides and rivers, and towards organising a communal calendar. Farmers addressed agricultural needs with increasing knowledge of the constellations that appear in the different seasons—and used the rising of particular star-groups to herald annual floods or seasonal activities. By the 3rd millennium BCE, civilisations had sophisticated awareness of celestial cycles, and may have oriented temples in alignment with heliacal risings of the stars.
Scattered evidence suggests that the oldest known astrological references are copies of texts made in the ancient world. The Venus tablet of Ammisaduqa thought to be compiled in Babylon around 1700 BCE. A scroll documenting an early use of electional astrology is doubtfully ascribed to the reign of the Sumerian ruler Gudea of Lagash (c. 2144 – 2124 BCE). This describes how the gods revealed to him in a dream the constellations that would be most favourable for the planned construction of a temple. However, there is controversy about whether these were genuinely recorded at the time or merely ascribed to ancient rulers by posterity. The oldest undisputed evidence of the use of astrology as an integrated system of knowledge is therefore attributed to the records of the first dynasty of Mesopotamia (1950–1651 BCE). This astrology had some parallels with Hellenistic Greek (western) astrology, including the zodiac, a norming point near 9 degrees in Aries, the trine aspect, planetary exaltations, and the dodekatemoria (the twelve divisions of 30 degrees each). The Babylonians viewed celestial events as possible signs rather than as causes of physical events.
The system of Chinese astrology was elaborated during the Zhou dynasty (1046–256 BCE) and flourished during the Han Dynasty (2nd century BCE to 2nd century CE), during which all the familiar elements of traditional Chinese culture – the Yin-Yang philosophy, theory of the five elements, Heaven and Earth, Confucian morality – were brought together to formalise the philosophical principles of Chinese medicine and divination, astrology and alchemy.
Ancient objections.
Cicero stated the twins objection (that with close birth times, personal outcomes can be very different), later developed by Saint Augustine. He argued that since the other planets are much more distant from the earth than the moon, they could have only very tiny influence compared to the moon's. He also argued that if astrology explains everything about a person's fate, then it wrongly ignores the visible effect of inherited ability and parenting, changes in health worked by medicine, or the effects of the weather on people.
Plotinus argued that since the fixed stars are much more distant than the planets, it is laughable to imagine the planets' effect on mankind should depend on their position with respect to the zodiac. He also argues that the interpretation of the moon's conjunction with a planet as good when the moon is full, but bad when the moon is waning, is clearly wrong, as from the moon's point of view, half of her surface is always in sunlight; and from the planet's point of view, waning should be better, as then the planet sees some light from the moon, but when the moon is full to us, it is dark, and therefore bad, on the side facing the planet.
Favorinus argued that it was absurd to imagine that stars and planets would affect human bodies in the same way as they affect the tides, and equally absurd that small motions in the heavens cause large changes in people's fates. Sextus Empiricus argued that it was absurd to link human attributes with myths about the signs of the zodiac. Carneades argued that belief in fate denies free will and morality; that people born at different times can all die in the same accident or battle; and that contrary to uniform influences from the stars, tribes and cultures are all different.
Hellenistic Egypt.
In 525 BCE, Egypt was conquered by the Persians. The 1st century BCE Egyptian Dendera Zodiac shares two signs – the Balance and the Scorpion – with Mesopotamian astrology.
With the occupation by Alexander the Great in 332 BCE, Egypt became Hellenistic. The city of Alexandria was founded by Alexander after the conquest, becoming the place where Babylonian astrology was mixed with Egyptian Decanic astrology to create Horoscopic astrology. This contained the Babylonian zodiac with its system of planetary exaltations, the triplicities of the signs and the importance of eclipses. It used the Egyptian concept of dividing the zodiac into thirty-six decans of ten degrees each, with an emphasis on the rising decan, and the Greek system of planetary Gods, sign rulership and four elements. 2nd century BCE texts predict positions of planets in zodiac signs at the time of the rising of certain decans, particularly Sothis. The astrologer and astronomer Ptolemy lived in Alexandria. Ptolemy's work the "Tetrabiblos" formed the basis of Western astrology, and, "...enjoyed almost the authority of a Bible among the astrological writers of a thousand years or more."
Greece and Rome.
The conquest of Asia by Alexander the Great exposed the Greeks to ideas from Syria, Babylon, Persia and central Asia. Around 280 BCE, Berossus, a priest of Bel from Babylon, moved to the Greek island of Kos, teaching astrology and Babylonian culture. By the 1st century BCE, there were two varieties of astrology, one using horoscopes to describe the past, present and future; the other, theurgic, emphasising the soul's ascent to the stars. Greek influence played a crucial role in the transmission of astrological theory to Rome.
The first definite reference to astrology in Rome comes from the orator Cato, who in 160 BCE warned farm overseers against consulting with Chaldeans, who were described as Babylonian 'star-gazers'. Among both Greeks and Romans, Babylonia (also known as Chaldea) became so identified with astrology that 'Chaldean wisdom' became synonymous with divination using planets and stars. The 2nd-century Roman poet and satirist Juvenal complains about the pervasive influence of Chaldeans, saying, "Still more trusted are the Chaldaeans; every word uttered by the astrologer they will believe has come from Hammon's fountain."
One of the first astrologers to bring Hermetic astrology to Rome was Thrasyllus, astrologer to the emperor Tiberius, the first emperor to have had a court astrologer, though his predecessor Augustus had used astrology to help legitimise his Imperial rights.
Medieval world.
Hindu.
The main texts upon which classical Indian astrology is based are early medieval compilations, notably the "Bṛhat Parāśara Horāśāstra", and "Sārāvalī" by .
The "Horāshastra" is a composite work of 71 chapters, of which the first part (chapters 1–51) dates to the 7th to early 8th centuries and the second part (chapters 52–71) to the later 8th century. The "Sārāvalī" likewise dates to around 800 CE. English translations of these texts were published by N.N. Krishna Rau and V.B. Choudhari in 1963 and 1961, respectively.
Islamic.
Astrology was taken up by Islamic scholars following the collapse of Alexandria to the Arabs in the 7th century, and the founding of the Abbasid empire in the 8th. The second Abbasid caliph, Al Mansur (754–775) founded the city of Baghdad to act as a centre of learning, and included in its design a library-translation centre known as "Bayt al-Hikma" 'House of Wisdom', which continued to receive development from his heirs and was to provide a major impetus for Arabic-Persian translations of Hellenistic astrological texts. The early translators included Mashallah, who helped to elect the time for the foundation of Baghdad, and Sahl ibn Bishr, ("a.k.a." "Zael"), whose texts were directly influential upon later European astrologers such as Guido Bonatti in the 13th century, and William Lilly in the 17th century. Knowledge of Arabic texts started to become imported into Europe during the Latin translations of the 12th century.
Europe.
The first astrological book published in Europe was the "Liber Planetis et Mundi Climatibus" ("Book of the Planets and Regions of the World"), which appeared between 1010 and 1027 AD, and may have been authored by Gerbert of Aurillac. Ptolemy's second century AD "Tetrabiblos" was translated into Latin by Plato of Tivoli in 1138. The Dominican theologian Thomas Aquinas followed Aristotle in proposing that the stars ruled the imperfect 'sublunary' body, while attempting to reconcile astrology with Christianity by stating that God ruled the soul. The thirteenth century mathematician Campanus of Novara is said to have devised a system of astrological houses that divides the prime vertical into 'houses' of equal 30° arcs, though the system was used earlier in the East. The thirteenth century astronomer Guido Bonatti wrote a textbook, the "Liber Astronomicus", a copy of which King Henry VII of England owned at the end of the fifteenth century.
In "Paradiso", the final part of the "Divine Comedy", the Italian poet Dante Alighieri referred "in countless details" to the astrological planets, though he adapted traditional astrology to suit his Christian viewpoint, for example using astrological thinking in his prophecies of the reform of Christendom.
Medieval objections.
In the seventh century, Isidore of Seville argued in his "Etymologiae" that astronomy described the movements of the heavens, while astrology had two parts: one was scientific, describing the movements of the sun, the moon and the stars, while the other, making predictions, was theologically erroneous. In contrast, John Gower in the fourteenth century defined astrology as essentially limited to the making of predictions. The influence of the stars was in turn divided into natural astrology, with for example effects on tides and the growth of plants, and judicial astrology, with supposedly predictable effects on people. The fourteenth century sceptic Nicole Oresme however included astronomy as a part of astrology in his "Livre de divinacions". Oresme argued that current approaches to prediction of events such as plagues, wars, and weather were inappropriate, but that such prediction was a valid field of inquiry. However, he attacked the use of astrology to choose the timing of actions (so-called interrogation and election) as wholly false, and rejected the determination of human action by the stars on grounds of free will. The friar Laurens Pignon (c. 1368–1449) similarly rejected all forms of divination and determinism, including by the stars, in his 1411 "Contre les Devineurs". This was in opposition to the tradition carried by the Arab astronomer Albumasar (787-886) whose "Introductorium in Astronomiam" and "De Magnis Coniunctionibus" argued the view that both individual actions and larger scale history are determined by the stars.
Renaissance and Early Modern.
Renaissance scholars commonly practised astrology. Gerolamo Cardano cast the horoscope of king Edward VI of England, while John Dee was the personal astrologer to queen Elizabeth I of England. Catherine de Medici paid Michael Nostradamus in 1566 to verify the prediction of the death of her husband, king Henry II of France made by her astrologer Lucus Gauricus. Major astronomers who practised as court astrologers included Tycho Brahe in the royal court of Denmark, Johannes Kepler to the Habsburgs, Galileo Galilei to the Medici, and Giordano Bruno who was burnt at the stake for heresy in Rome in 1600. The distinction between astrology and astronomy was not entirely clear. Advances in astronomy were often motivated by the desire to improve the accuracy of astrology.
Ephemerides with complex astrological calculations, and almanacs interpreting celestial events for use in medicine and for choosing times to plant crops, were popular in Elizabethan England. In 1597, the English mathematician and physician Thomas Hood made a set of paper instruments that used revolving overlays to help students work out relationships between fixed stars or constellations, the midheaven, and the twelve astrological houses. Hood's instruments also illustrated, for pedagogical purposes, the supposed relationships between the signs of the zodiac, the planets, and the parts of the human body adherents believed were governed by the planets and signs. While Hood's presentation was innovative, his astrological information was largely standard and was taken from Gerard Mercator's astrological disc made in 1551, or a source used by Mercator.
English astrology had reached its zenith by the 17th century. Astrologers were theorists, researchers, and social engineers, as well as providing individual advice to everyone from monarchs downwards. Among other things, astrologers could advise on the best time to take a journey or harvest a crop, diagnose and prescribe for physical or mental illnesses, and predict natural disasters. This underpinned a system in which everything—people, the world, the universe—was understood to be interconnected, and astrology co-existed happily with religion, magic and science.
Enlightenment period and onwards.
During The Enlightenment, intellectual sympathy for astrology fell away, leaving only a popular following supported by cheap almanacs. One English almanac compiler, Richard Saunders, followed the spirit of the age by printing a derisive "Discourse on the Invalidity of Astrology", while in France Pierre Bayle's "Dictionnaire" of 1697 stated that the subject was puerile. The Anglo-Irish satirist Jonathan Swift ridiculed the Whig political astrologer John Partridge.
Astrology saw a popular revival starting in the 19th century, as part of a general revival of spiritualism and—later, New Age philosophy, and through the influence of mass media such as newspaper horoscopes. Early in the 20th century the psychiatrist Carl Jung developed some concepts concerning astrology, which led to the development of psychological astrology.
Principles and practice.
Advocates have defined astrology as a symbolic language, an art form, a science, and a method of divination. Though most cultural astrology systems share common roots in ancient philosophies that influenced each other, many use methods that differ from those in the West. These include Hindu astrology (also known as "Indian astrology" and in modern times referred to as "Vedic astrology") and Chinese astrology, both of which have influenced the world's cultural history.
Western.
Western astrology is a form of divination based on the construction of a horoscope for an exact moment, such as a person's birth. It uses the tropical zodiac, which is aligned to the equinoctial points.
Western astrology is founded on the movements and relative positions of celestial bodies such as the Sun, Moon and planets, which are analysed by their movement through signs of the zodiac (twelve spatial divisions of the ecliptic) and by their aspects (based on geometric angles) relative to one another. They are also considered by their placement in houses (twelve spatial divisions of the sky). Astrology's modern representation in western popular media is usually reduced to sun sign astrology, which considers only the zodiac sign of the Sun at an individual's date of birth, and represents only 1/12 of the total chart.
The horoscope visually expresses the set of relationships for the time and place of the chosen event. These relationships are between the seven 'planets', signifying tendencies such as war and love; the twelve signs of the zodiac; and the twelve houses. Each planet is in a particular sign and a particular house at the chosen time, when observed from the chosen place, creating two kinds of relationship. A third kind is the aspect of each planet to every other planet, where for example two planets 120° apart (in 'trine') are in a harmonious relationship, but two planets 90° apart ('square') are in a conflicted relationship. Together these relationships and their interpretations supposedly form "...the language of the heavens speaking to learned men."
Along with tarot divination, astrology is one of the core studies of Western esotericism, and as such has influenced systems of magical belief not only among Western esotericists and Hermeticists, but also belief systems such as Wicca that have borrowed from or been influenced by the Western esoteric tradition. Tanya Luhrmann has said that "all magicians know something about astrology," and refers to a table of correspondences in Starhawk's "The Spiral Dance", organised by planet, as an example of the astrological lore studied by magicians.
Hindu.
The earliest Vedic text on astronomy is the "Vedanga Jyotisha"; Vedic thought later came to include astrology as well.
Hindu natal astrology originated with Hellenistic astrology by the 3rd century BCE, though incorporating the Hindu lunar mansions. The names of the signs (e.g. Greek 'Krios' for Aries, Hindi 'Kriya'), the planets (e.g. Greek 'Helios' for Sun, astrological Hindi 'Heli'), and astrological terms (e.g. Greek 'apoklima' and 'sunaphe' for declination and planetary conjunction, Hindi 'apoklima' and 'sunapha' respectively) in Varaha Mihira's texts are considered conclusive evidence of a Greek origin for Hindu astrology. The Indian techniques may also have been augmented with some of the Babylonian techniques.
Chinese and East-Asian.
Chinese astrology has a close relation with Chinese philosophy (theory of the three harmonies: heaven, earth and man) and uses concepts such as yin and yang, the Five phases, the 10 Celestial stems, the 12 Earthly Branches, and shichen (時辰 a form of timekeeping used for religious purposes). The early use of Chinese astrology was mainly confined to political astrology, the observation of unusual phenomena, identification of portents and the selection of auspicious days for events and decisions.
The constellations of the Zodiac of western Asia and Europe were not used; instead the sky is divided into Three Enclosures (三垣 sān yuán), and Twenty-eight Mansions (二十八宿 èrshíbā xiù) in twelve Ci (十二次). The Chinese zodiac of twelve animal signs is said to represent twelve different types of personality. It is based on cycles of years, lunar months, and two-hour periods of the day (the shichen). The zodiac traditionally begins with the sign of the Rat, and the cycle proceeds through 11 other animals signs: the Ox, Tiger, Rabbit, Dragon, Snake, Horse, Goat, Monkey, Rooster, Dog and Pig. Complex systems of predicting fate and destiny based on one's birthday, birth season, and birth hours, such as "ziping" and Zi Wei Dou Shu () are still used regularly in modern-day Chinese astrology. They do not rely on direct observations of the stars.
The Korean zodiac is identical to the Chinese one. The Vietnamese zodiac is almost identical to Chinese zodiac except the second animal is the "Water Buffalo" instead of the "Ox", and the fourth animal is the "Cat" instead of the "Rabbit". The Japanese have since 1873 celebrated the beginning of the new year on 1 January as per the Gregorian Calendar. The Thai zodiac begins, not at Chinese New Year, but either on the first day of fifth month in the Thai lunar calendar, or during the Songkran festival (now celebrated every 13–15 April), depending on the purpose of the use.
Theological viewpoints.
Ancient.
St. Augustine (354430) believed that the determinism of astrology conflicted with the Christian doctrines of man's free will and responsibility, and God not being the cause of evil, but he also grounded his opposition philosophically, citing the failure of astrology to explain twins who behave differently although conceived at the same moment and born at approximately the same time.
Medieval.
Some of the practices of astrology were contested on theological grounds by medieval Muslim astronomers such as Al-Farabi (Alpharabius), Ibn al-Haytham (Alhazen) and Avicenna. They said that the methods of astrologers conflicted with orthodox religious views of Islamic scholars, by suggesting that the Will of God can be known and predicted in advance. For example, Avicenna's 'Refutation against astrology', "Risāla fī ibṭāl aḥkām al-nojūm", argues against the practice of astrology while supporting the principle that planets may act as agents of divine causation. Avicenna considered that the movement of the planets influenced life on earth in a deterministic way, but argued against the possibility of determining the exact influence of the stars. Essentially, Avicenna did not deny the core dogma of astrology, but denied our ability to understand it to the extent that precise and fatalistic predictions could be made from it. Ibn Qayyim Al-Jawziyya (1292–1350), in his "Miftah Dar al-SaCadah", also used physical arguments in astronomy to question the practice of judicial astrology. He recognised that the stars are much larger than the planets, and argued:
Modern.
The Catechism of the Catholic Church maintains that divination, including predictive astrology, is incompatible with modern Catholic beliefs such as free will:
Scientific analysis and criticism.
The scientific community rejects astrology as having no explanatory power for describing the universe, and consider it a pseudoscience. Scientific testing of astrology has been conducted, and no evidence has been found to support any of the premises or purported effects outlined in astrological traditions. There is no proposed mechanism of action by which the positions and motions of stars and planets could affect people and events on Earth that does not contradict well understood, basic aspects of biology and physics. Those who continue to have faith in astrology have been characterised as doing so "...in spite of the fact that there is no verified scientific basis for their beliefs, and indeed that there is strong evidence to the contrary."
It has also been shown that confirmation bias is a psychological factor that contributes to belief in astrology. Confirmation bias is a form of cognitive bias. According to available literature, astrology believers tend to selectively remember predictions that turn out to be true, and do not remember those that turn out false. Another, separate, form of confirmation bias also plays a role, where believers often fail to distinguish between messages that demonstrate special ability and those that do not. Thus there are two distinct forms of confirmation bias that are under study with respect to astrological belief.
Demarcation.
Under the criterion of falsifiability, first proposed by philosopher of science Karl Popper, astrology is a pseudoscience. Popper regarded astrology as "pseudo-empirical" in that "it appeals to observation and experiment," but "nevertheless does not come up to scientific standards." In contrast to scientific disciplines, astrology has not responded to falsification through experiment.
In contrast to Popper, the philosopher Thomas Kuhn argued that it was not lack of falsifiability that makes astrology unscientific, but rather that the process and concepts of astrology are non-empirical. Kuhn thought that, though astrologers had, historically, made predictions that categorically failed, this in itself does not make it unscientific, nor do attempts by astrologers to explain away failures by claiming that creating a horoscope is very difficult. Rather, in Kuhn's eyes, astrology is not science because it was always more akin to medieval medicine; they followed a sequence of rules and guidelines for a seemingly necessary field with known shortcomings, but they did no research because the fields are not amenable to research, and so "they had no puzzles to solve and therefore no science to practise." While an astronomer could correct for failure, an astrologer could not. An astrologer could only explain away failure but could not revise the astrological hypothesis in a meaningful way. As such, to Kuhn, even if the stars could influence the path of humans through life astrology is not scientific.
The philosopher Paul Thagard asserts that astrology cannot be regarded as falsified in this sense until it has been replaced with a successor. In the case of predicting behaviour, psychology is the alternative. To Thagard a further criterion of demarcation of science from pseudoscience is that the state-of-the-art must progress and that the community of researchers should be attempting to compare the current theory to alternatives, and not be "selective in considering confirmations and disconfirmations." Progress is defined here as explaining new phenomena and solving existing problems, yet astrology has failed to progress having only changed little in nearly 2000 years. To Thagard, astrologers are acting as though engaged in normal science believing that the foundations of astrology were well established despite the "many unsolved problems," and in the face of better alternative theories (psychology). For these reasons Thagard views astrology as pseudoscience.
For the philosopher Edward W. James, astrology is irrational not because of the numerous problems with mechanisms and falsification due to experiments, but because an analysis of the astrological literature shows that it is infused with fallacious logic and poor reasoning.
Effectiveness.
Astrology has not demonstrated its effectiveness in controlled studies and has no scientific validity. Where it has made falsifiable predictions under controlled conditions, they have been falsified. One famous experiment included 28 astrologers who were asked to match over a hundred natal charts to psychological profiles generated by the California Psychological Inventory (CPI) questionnaire. The double-blind experimental protocol used in this study was agreed upon by a group of physicists and a group of astrologers nominated by the National Council for Geocosmic Research, who advised the experimenters, helped ensure that the test was fair and helped draw the central proposition of natal astrology to be tested. They also chose 26 out of the 28 astrologers for the tests (two more volunteered afterwards). The study, published in "Nature" in 1985, found that predictions based on natal astrology were no better than chance, and that the testing "...clearly refutes the astrological hypothesis."
In 1955, astrologer and psychologist Michel Gauquelin stated that though he had failed to find evidence that supported indicators like zodiacal signs and planetary aspects in astrology, he did find positive correlations between the diurnal positions of some planets and success in professions that astrology traditionally associates with those planets. The best-known of Gauquelin's findings is based on the positions of Mars in the natal charts of successful athletes and became known as the "Mars effect". A study conducted by seven French scientists attempted to replicate the claim, but found no statistical evidence. They attributed the effect to selective bias on Gauquelin's part, accusing him of attempting to persuade them to add or delete names from their study.
Geoffrey Dean has suggested that the effect may be caused by self-reporting of birth dates by parents rather than any issue with the study by Gauquelin. The suggestion is that a small subset of the parents may have had changed birth times to be consistent with better astrological charts for a related profession. The sample group was taken from a time where belief in astrology was more common. Gauquelin had failed to find the Mars effect in more recent populations, where a nurse or doctor recorded the birth information. The number of births under astrologically undesirable conditions was also lower, indicating more evidence that parents choose dates and times to suit their beliefs.
Dean, a scientist and former astrologer, and psychologist Ivan Kelly conducted a large scale scientific test that involved more than one hundred cognitive, behavioural, physical, and other variables—but found no support for astrology. Furthermore, a meta-analysis pooled 40 studies that involved 700 astrologers and over 1,000 birth charts. Ten of the tests—which involved 300 participants—had the astrologers pick the correct chart interpretation out of a number of others that were not the astrologically correct chart interpretation (usually three to five others). When date and other obvious clues were removed, no significant results suggested there was any preferred chart.
Lack of mechanisms and consistency.
Testing the validity of astrology can be difficult, because there is no consensus amongst astrologers as to what astrology is or what it can predict. Most professional astrologers are paid to predict the future or describe a person's personality and life, but most horoscopes only make vague untestable statements that can apply to almost anyone.
Many astrologers claim that astrology is scientific,
while some have proposed conventional causal agents such as electromagnetism and gravity. Scientists reject these mechanisms as implausible since, for example, the magnetic field, when measured from earth, of a large but distant planet such as Jupiter is far smaller than that produced by ordinary household appliances.
Western astrology has taken the earth's axial precession (also called precession of the equinoxes) into account since Ptolemy's "Almagest", so the 'first point of Aries', the start of the astrological year, continually moves against the background of the stars. The tropical zodiac has no connection to the stars, and as long as no claims are made that the constellations themselves are in the associated sign, astrologers avoid the concept that precession seemingly moves the constellations. Charpak and Broch, noting this, referred to astrology based on the tropical zodiac as being "...empty boxes that have nothing to do with anything and are devoid of any consistency or correspondence with the stars." Sole use of the tropical zodiac is inconsistent with references made, by the same astrologers, to the Age of Aquarius, which depends on when the vernal point enters the constellation of Aquarius.
Astrologers usually have only a small knowledge of astronomy, and often do not take into account basic principles—such as the precession of the equinoxes, which changes the position of the sun with time. They commented on the example of Elizabeth Teissier, who claimed that, "The sun ends up in the same place in the sky on the same date each year," as the basis for claims that two people with the same birthday, but a number of years apart, should be under the same planetary influence. Charpak and Broch noted that, "There is a difference of about twenty-two thousand miles between Earth's location on any specific date in two successive years," and that thus they should not be under the same influence according to astrology. Over a 40 years period there would be a difference greater than 780,000 miles.
Cultural impact.
Western politics and society.
In the West, political leaders have sometimes consulted astrologers. Louis de Wohl worked as an astrologer for the British intelligence agency MI5, after claims surfaced that Adolf Hitler used astrology to time his actions. The War Office was "...interested to know what Hitler's own astrologers would be telling him from week to week." In fact, de Wohl's predictions were so inaccurate that he was soon labelled a "complete charlatan," and later evidence showed that Hitler considered astrology "complete nonsense." After John Hinckley's attempted assassination of US President Ronald Reagan, first lady Nancy Reagan commissioned astrologer Joan Quigley to act as the secret White House astrologer. However, Quigley's role ended in 1988 when it became public through the memoirs of former chief of staff, Donald Regan.
There was a boom in interest in astrology in the late 1960s. The sociologist Marcello Truzzi described three levels of involvement of "Astrology-believers" to account for its revived popularity in the face of scientific discrediting. He found that most astrology-believers did not claim it was a scientific explanation with predictive power. Instead, those superficially involved, knowing "next to nothing" about astrology's 'mechanics', read newspaper astrology columns, and could benefit from "tension-management of anxieties" and "a cognitive belief-system that transcends science." Those at the second level usually had their horoscopes cast and sought advice and predictions. They were much younger than those at the first level, and could benefit from knowledge of the language of astrology and the resulting ability to belong to a coherent and exclusive group. Those at the third level were highly involved and usually cast horoscopes for themselves. Astrology provided this small minority of astrology-believers with a ""meaningful" view of their universe and them an "understanding" of their place in it." This third group took astrology seriously, possibly as a "sacred canopy", whereas the other two groups took it playfully and irreverently.
In 1953, sociologist Theodor W. Adorno conducted a study of the astrology column of a Los Angeles newspaper as part of a project examining mass culture in capitalist society. Adorno believed that popular astrology, as a device, invariably leads to statements that encouraged conformity—and that astrologers who go against conformity, by discouraging performance at work etc., risk losing their jobs. Adorno concluded that astrology was a large-scale manifestation of systematic irrationalism, where individuals are subtly led—through flattery and vague generalisations—to believe that the author of the column is addressing them directly. Adorno drew a parallel with the phrase opium of the people, by Karl Marx, by commenting, "occultism is the metaphysic of the dopes."
A 2005 Gallup poll and a 2009 survey by the Pew Research Center reported that 25% of US adults believe in astrology. According to data released in the National Science Foundation's 2014 "Science and Engineering Indicators" study, "Fewer Americans rejected astrology in 2012 than in recent years." The NSF study noted that in 2012, "slightly more than half of Americans said that astrology was 'not at all scientific,' whereas nearly two-thirds gave this response in 2010. The comparable percentage has not been this low since 1983."
India and Japan.
In India, there is a long-established and widespread belief in astrology. It is commonly used for daily life, particularly in matters concerning marriage and career, and makes extensive use of electional, horary and karmic astrology. Indian politics have also been influenced by astrology. It is still considered a branch of the Vedanga. In 2001, Indian scientists and politicians debated and critiqued a proposal to use state money to fund research into astrology, resulting in permission for Indian universities to offer courses in Vedic astrology.
On February 2011, the Bombay High Court reaffirmed astrology's standing in India when it dismissed a case that challenged its status as a science.
In Japan, strong belief in astrology has led to dramatic changes in the fertility rate and the number of abortions in the years of "Fire Horse". Adherents believe that women born in "hinoeuma" years are unmarriageable and bring bad luck to their father or husband. In 1966, the number of babies born in Japan dropped by over 25% as parents tried to avoid the stigma of having a daughter born in the hinoeuma year.
Literature and music.
The fourteenth-century English poets John Gower and Geoffrey Chaucer both referred to astrology in their works, including Gower's "Confessio Amantis" and Chaucer's "The Canterbury Tales". Chaucer commented explicitly on astrology in his "Treatise on the Astrolabe", demonstrating personal knowledge of one area, judicial astrology, with an account of how to find the ascendant or rising sign.
In the fifteenth century, references to astrology, such as with similes, became "a matter of course" in English literature.
In the sixteenth century, John Lyly's 1597 play, "The Woman in the Moon", is wholly motivated by astrology, while Christopher Marlowe makes astrological references in his plays "Doctor Faustus" and "Tamburlaine" (both c. 1590), and Sir Philip Sidney refers to astrology at least four times in his romance "The Countess of Pembroke's Arcadia" (c. 1580). Edmund Spenser uses astrology both decoratively and causally in his poetry, revealing "...unmistakably an abiding interest in the art, an interest shared by a large number of his contemporaries." George Chapman's play, "Byron's Conspiracy" (1608), similarly uses astrology as a causal mechanism in the drama. William Shakespeare's attitude towards astrology is unclear, with contradictory references in plays including "King Lear", "Antony and Cleopatra", and "Richard II". Shakespeare was familiar with astrology and made use of his knowledge of astrology in nearly every play he wrote, assuming a basic familiarity with the subject in his commercial audience. Outside theatre, the physician and mystic Robert Fludd practised astrology, as did the quack doctor Simon Forman. In Elizabethan England, "The usual feeling about astrology ... that it is the most useful of the sciences."
In seventeenth century Spain, Lope de Vega, with a detailed knowledge of astronomy, wrote plays that ridicule astrology. In his pastoral romance "La Arcadia" (1598), it leads to absurdity; in his novela "Guzman el Bravo" (1624), he concludes that the stars were made for man, not man for the stars. Calderón de la Barca wrote the 1641 comedy "Astrologo Fingido" (The Pretended Astrologer); the plot was borrowed by the French playwright Thomas Corneille for his 1651 comedy "Feint Astrologue".
The most famous piece of music influenced by astrology is the orchestral suite "The Planets". Written by the British composer Gustav Holst (1874–1934), and first performed in 1918, the framework of "The Planets" is based upon the astrological symbolism of the planets. Each of the seven movements of the suite is based upon a different planet, though the movements are not in the order of the planets from the Sun. The composer Colin Matthews wrote an eighth movement entitled "Pluto, the Renewer", first performed in 2000. In 1937, another British composer, Constant Lambert, wrote a ballet on astrological themes, called "Horoscope". In 1974, the New Zealand composer Edwin Carr wrote "The Twelve Signs: An Astrological Entertainment" for orchestra without strings. Camille Paglia acknowledges astrology as an influence on her work of literary criticism "Sexual Personae" (1990).
Astrology features strongly in Eleanor Catton's "The Luminaries", recipient of the 2013 Man Booker Prize.

</doc>
<doc id="2123" url="https://en.wikipedia.org/wiki?curid=2123" title="Abyssinia">
Abyssinia

Abyssinia may refer to :
Other uses.
Television

</doc>
<doc id="2125" url="https://en.wikipedia.org/wiki?curid=2125" title="Algebraic extension">
Algebraic extension

In abstract algebra, a field extension "L"/"K" is called algebraic if every element of "L" is algebraic over "K", i.e. if every element of "L" is a root of some non-zero polynomial with coefficients in "K". Field extensions that are not algebraic, i.e. which contain transcendental elements, are called transcendental.
For example, the field extension R/Q, that is the field of real numbers as an extension of the field of rational numbers, is transcendental, while the field extensions C/R and Q(√2)/Q are algebraic, where C is the field of complex numbers.
All transcendental extensions are of infinite degree. This in turn implies that all finite extensions are algebraic. The converse is not true however: there are infinite extensions which are algebraic. For instance, the field of all algebraic numbers is an infinite algebraic extension of the rational numbers.
If "a" is algebraic over "K", then "K"["a"], the set of all polynomials in "a" with coefficients in "K", is not only a ring but a field: an algebraic extension of "K" which has finite degree over "K". The converse is true as well, if "K"["a"] is a field, then "a" is algebraic over "K". In the special case where "K" = Q is the field of rational numbers, Q["a"] is an example of an algebraic number field.
A field with no nontrivial algebraic extensions is called algebraically closed. An example is the field of complex numbers. Every field has an algebraic extension which is algebraically closed (called its algebraic closure), but proving this in general requires some form of the axiom of choice.
An extension "L"/"K" is algebraic if and only if every sub "K"-algebra of "L" is a field.
Properties.
The class of algebraic extensions forms a distinguished class of field extensions, that is, the following three properties hold:
These finitary results can be generalized using transfinite induction: 
This fact, together with Zorn's lemma (applied to an appropriately chosen poset), establishes the existence of algebraic closures.
Generalizations.
Model theory generalizes the notion of algebraic extension to arbitrary theories: an embedding of "M" into "N" is called an algebraic extension if for every "x" in "N" there is a formula "p" with parameters in "M", such that "p"("x") is true and the set
is finite. It turns out that applying this definition to the theory of fields gives the usual definition of algebraic extension. The Galois group of "N" over "M" can again be defined as the group of automorphisms, and it turns out that most of the theory of Galois groups can be developed for the general case.

</doc>
<doc id="2126" url="https://en.wikipedia.org/wiki?curid=2126" title="Ani DiFranco">
Ani DiFranco

Ani DiFranco (; born Angela Maria DiFranco; September 23, 1970) is an American singer, multi-instrumentalist, poet, songwriter and businesswoman. She has released more than 20 albums and is widely considered a feminist icon. DiFranco has received positive feedback from critics for much of her career.
Although DiFranco's music has been classified as both folk rock and alternative rock, she has reached across genres since her earliest albums incorporating first punk, then funk, hip hop, and jazz influences. She was one of the first independent musicians to create her own record label (Righteous Babe), a move that has given her significant creative freedom.
From the earliest days of her career, DiFranco has lent her voice and her name to a broad range of social movements, performing benefit concerts, appearing on benefit albums, and speaking at rallies. Through the Righteous Babe Foundation, DiFranco has backed various grassroots cultural and political organizations, supporting causes ranging from abortion rights to gay visibility.
Life and career.
DiFranco was born in Buffalo, New York, the daughter of Elizabeth (Ross) and Dante Americo DiFranco, who had met while attending MIT. Her father was of Italian descent, and her mother was from Montreal. DiFranco started playing Beatles covers at local bars and busking with her guitar teacher, Michael Meldrum, at the age of nine. By fourteen she was penning her own songs and playing her original material at bars and coffee houses throughout her teen years. DiFranco graduated from the Buffalo Academy for Visual and Performing Arts high school at the age of sixteen and began attending classes at Buffalo State College that same year. She was already living alone, having moved out of her mother's apartment after she became an emancipated minor at age 15.
In 1989 at the age of 18, DiFranco started her own record company, Righteous Babe Records. Her self-titled debut album was issued on the label in the winter of 1990, shortly after she had relocated to New York City. In New York she took poetry classes at The New School where she met poet Sekou Sundiata who was to become a friend and mentor. She toured vigorously for the next 15 years, essentially pausing briefly only to record albums. Appearances at Canadian folk festivals and increasingly larger venues in the U.S. cemented her growing presence on the North American folk and roots scene.
In September 1995, DiFranco participated in a concert at the Rock and Roll Hall of Fame in Cleveland Ohio, inaugurating the opening of the Woody Guthrie Archives in New York City. She later released a CD on Righteous Babe of the concert entitled "Til We Outnumber Em" (featuring artists such as DiFranco, Billy Bragg, Ramblin' Jack Elliott, Arlo Guthrie, Indigo Girls, Dave Pirner, Tim Robbins, and Bruce Springsteen) with 100% of proceeds going to the Woody Guthrie Foundation and Archives and the Rock and Roll Hall of Fame Museum educational department.
DiFranco toured solo throughout the early and mid 1990s and also as a duo with Canadian drummer Andy Stochansky. Bassist Sara Lee joined the touring group in 1996. Their rapport during live shows is showcased on the 1997 album "Living in Clip". DiFranco would later release Lee's solo album "Make It Beautifu"l on Righteous Babe.
In 1998, Stochansky left to pursue a solo career as a singer-songwriter. A new touring ensemble consisting of Jason Mercer on bass, Julie Wolf on keyboards, and Daren Hahn on drums, augmented at times by a horn section, accompanied DiFranco on tour between 1998 and 2002.
The 1990s were a period of heightened exposure for DiFranco, as she continued playing ever larger venues around the world and attracted international attention of the press, including cover stories in "Spin, Ms., "and" Magnet, "among others, as well as appearances on MTV and VH1. Her playfully ironic cover of the Bacharach/David song "Wishin' and Hopin appeared under the opening titles of the film "My Best Friend's Wedding".
Beginning in 1999, Righteous Babe Records began to release albums by other artists including Sekou Sundiata, Michael Meldrum, Arto Lindsay, Bitch and Animal, That One Guy, Utah Phillips, Hamell on Trial, Andrew Bird, Kurt Swinghammer, Sara Lee, Buddy Wakefield, Anais Mitchell, and Nona Hendryx.
On September 11, 2001, DiFranco was in Manhattan and later penned the poem "Self Evident" about the experience. The poem was featured in the book "It's a Free Country: Personal Freedom in America After September 11, "edited by Danny Goldberg, Victoria Goldberg, and Robert Greenwald. The poem's title also became the name of DiFranco's first book of poetry released exclusively in Italy by Minimum Fax. It was later featured in a book of her poetry published in the U.S. by Seven Stories press, entitled "Verses". DiFranco has written and performed many spoken-word pieces throughout her career and was showcased as a poet on the HBO series "Def Poetry" in 2005
Her father died early in the summer of 2004. In July 2005, DiFranco developed tendonitis and took a nine-month hiatus from touring.
On September 11, 2007, she released the first retrospective of her career, a two disc compilation entitled "Canon" and simultaneously released a retrospective collection of poetry book "Verses". "Red Letter Year" was released on September 30, 2008.
DiFranco performed a live webcast from Ex'pression College for Digital Arts on June 24, 2010. She debuted a selection of new material, including the songs "Which Side Are You On?" (a reworking of the Florence Reece song with different lyrics penned by DiFranco), "Life Boat", "Unworry", "Promiscuity", "Splinter", "Amendment", "See See..." and "Hearse".
DiFranco's touring band and recordings have featured the bass player Todd Sickafoose since her 2005 release "Knuckle Down "(co-produced by Joe Henry) and in turns other musicians such as Allison Miller, Andy Borger, Herlin Riley, and Terence Higgins on drums and Mike Dillon on percussion and vibes.
In 2009 DiFranco appeared at Pete Seeger's 90th birthday celebration at Madison Square Garden, debuting her revamped version of the 1930s labor anthem "Which Side Are You On?" in a duet with Bruce Cockburn and also duetting with Kris Kristofferson on the folk classic "There's a Hole in the Bucket".
DiFranco released an album of new material on January 17, 2012, titled "¿Which Side Are You On?". It includes collaborations with Pete Seeger, Ivan Neville, Cyril Neville, Skerik, Adam Levy, Righteous Babe recording artist Anaïs Mitchell, CC Adcock, and a host of New Orleans-based horn players known for their work in such outfits as Galactic, Bonerama, and Rebirth Brass Band.
Relationships.
DiFranco identifies herself as bisexual, and has written songs about love and sex with women and men. She addressed the controversy about her sexuality with the song "In or Out". In 1998, she married sound engineer Andrew Gilchrist in a Unitarian Universalist service in Canada. DiFranco and Gilchrist divorced five years later.
DiFranco gave birth to a daughter, Petah Lucia DiFranco Napolitano, at her Buffalo home in 2007. She married the child's father, Mike Napolitano, also her regular producer, in 2009.
In an interview on September 13, 2012, DiFranco mentioned that she was pregnant with her second child. She gave birth to a second child, a son Dante DiFranco Napolitano, in 2013.
She and her husband currently reside in the Bywater neighborhood of New Orleans.
Critical reception.
DiFranco has been a critical success for much of her career, though not a commercial one by major label standards, with a career album average of 72 on Metacritic. "Living in Clip", DiFranco's 1998 double live album, is the only one to achieve gold record status to date. DiFranco has been praised by the "Buffalo News" as the "Buffalo's leading lady of rock music".
Starting in 2003, DiFranco was nominated four consecutive times for Best Recording Package at the Grammy Awards, winning in 2004, for "Evolve".
On July 21, 2006, DiFranco received the "Woman of Courage Award" at the National Organization for Women (NOW) Conference and Young Feminist Summit in Albany, New York. Past winners have included singer and actress Barbra Streisand and Sen. Barbara Boxer, D-Calif. DiFranco is one of the first musicians to receive the award, given each year to a woman who has set herself apart by her contributions to the feminist movement.
In 2009 DiFranco became a Woody Guthrie Award recipient, as a voice of positive social change.
Music.
Style.
DiFranco's guitar playing is often characterized by a signature staccato style, rapid fingerpicking and many alternate tunings. She delivers many of her lines in a speaking style notable for its rhythmic variation. Her lyrics, which often include alliteration, metaphor, word play and a more or less gentle irony, have also received praise for their sophistication.
Although DiFranco's music has been classified as both folk rock and alternative rock, she has reached across genres since her earliest albums incorporating first punk, then funk, hiphop, and jazz influences.
While primarlly an acoustic guitarist she has used a variety of instruments and styles: brass instrumentation was prevalent in 1998's "Little Plastic Castle"; a simple walking bass in her 1997 cover of Hal David and Burt Bacharach's "Wishin' and Hopin' "; strings on the 1997 live album "Living in Clip" and 2004's "Knuckle Down"; and electronics and synthesisers in 1999's "To the Teeth" and 2006's "Reprieve".
DiFranco herself noted that "folk music is not an acoustic guitar – that's not where the heart of it is. I use the word 'folk' in reference to punk music and rap music. It's an attitude, it's an awareness of one's heritage, and it's a community. It's subcorporate music that gives voice to different communities and their struggle against authority."
Musical collaborations, cover versions, and samples.
DiFranco has also collaborated with a wide range of artists. In 1997 she appeared on Canadian songwriter Bruce Cockburn's "Charity of Night" album. In 1998 she produced fellow folksinger Dan Bern's album "Fifty Eggs".
She developed a deep association with folksinger and social activist Utah Phillips throughout the mid-1990s, sharing her stage and her audience with the older musician until his death in 2008 and resulting in two collaborative albums: "The Past Didn't Go Anywhere", 1996, and "Fellow Workers",1999 (with liner notes by Howard Zinn). "The Past" is built around Phillips's storytelling, an important part of his art that had not previously been documented on recordings; on the album, DiFranco provides musical settings for his speaking voice. The followup, "Fellow Workers", was recorded live in Daniel Lanois's Kingsway Studio in New Orleans and features Phillips fronting DiFranco's touring band for a collection of songs and stories.
Prince recorded two songs with DiFranco in 1999, "Providence" on her "To the Teeth" album, and "I Love U, But I Don't Trust U Anymore" on Prince's "Rave Un2 the Joy Fantastic" album. Funk and soul jazz musician Maceo Parker and rapper Corey Parker have both appeared on DiFranco's albums and featured appearances by her on theirs. Parker and Di Franco toured together in 1999.
She has appeared on several compilations of the songs of Pete Seeger and frequented his Hudson Clearwater Revival Festival. In 2001 she appeared on Brazilian artist Lenine's album "Falange Canibal". In 2002 her rendition of Greg Brown's "The Poet Game" appeared on "Going Driftless: An Artist’s Tribute to Greg Brown". Also in 2002 she recorded a duet with Jackie Chan of the Irving Gordon song "Unforgettable" for a record of unlikely collaborations entitled "When Pigs Fly: Songs You Never Thought You’d Hear".
In 2005 she appeared on Dar Williams' record "My Better Self", dueting on William's cover of Pink Floyd's "Comfortably Numb". She performed with Cyndi Lauper on "Sisters of Avalon" a track from Lauper's 2005 "The Body Acoustic" album. In 2006 she produced Hamell on Trial's album "Songs for Parents Who Enjoy Drugs". In 2008 she appeared on Todd Sickafoose's album "Tiny Resisters". In 2010 she co-produced a track with Margaret Cho called "Captain Cameltoe" for the comedian's "Cho Dependant" album. In 2011 she appeared on Rob Wasserman's album "Note of Hope", an exploration of the writings of Woody Guthrie with musical accompaniment, though the track in which she appeared, "Voice", was actually recorded 13 years earlier. Also in 2011 she duetted with Greg Dulli on the Twilight Singers record "Dynamite Steps".
Other artists have covered and sampled DiFranco's work throughout the years. Her spoken word poem "Self Evident" was covered by Public Enemy founder Chuck D's group called Impossebulls. Alana Davis had some commercial success with DiFranco's song 32 Flavors.
Samples from the track "Coming Up" were used by DJ Spooky in his album "Live Without Dead Time", produced for AdBusters Magazine in 2003.
Lyrics, politics and religion.
Although much of DiFranco's material is autobiographical, it is often also strongly political. Many of her songs are concerned with contemporary social issues such as racism, sexism, sexual abuse, homophobia, reproductive rights, poverty, and war. In 2008, she donated a song to Aid Still Required's CD to assist with the restoration of the devastation done to Southeast Asia from the 2004 Tsunami.
The combination of personal and political is partially responsible for DiFranco's early popularity among politically active college students, particularly those of the left wing, some of whom set up fan pages on the web to document DiFranco's career as early as 1994. DiFranco's rapid rise in popularity in the mid-1990s was fueled mostly by personal contact and word of mouth rather than mainstream media.
DiFranco has expressed political views outside of her music. During the 2000 U.S. presidential election, she actively supported and voted for Green Party candidate Ralph Nader. She supported Dennis Kucinich in the 2004 and 2008 Democratic primaries. Kucinich appeared with her at a number of concerts across the country during both primary seasons. DiFranco went on to perform at the 2008 Democratic National Convention.
DiFranco has described herself as an atheist. On the subject of religion, DiFranco has stated:
Well, I'm not a religious person myself. I'm an atheist. I think religion serves a lot of different purposes in people's lives, and I can recognize the value of that, you know, the value of ceremony, the value of community, or even just having a forum to get together and talk about ideas, about morals – that's a cool concept. But then, of course, institutional religions are so problematic.
Label independence.
Ani cites her anti-corporate ethos for the main reason she decided to start her own label. This has allowed her a considerable degree of creative freedom over the years, including, for example, providing all instrumentals and vocals and recording the album herself at her home on an analog 8-track reel to reel, and handling much of the artwork and packaging design for her 2004 album "Educated Guess". She has referenced this independence from major labels in song more than once, including "The Million You Never Made" ("Not a Pretty Girl"), which discusses the act of turning down a lucrative contract, "The Next Big Thing" ("Not So Soft"), which describes an imagined meeting with a label head-hunter who evaluates the singer based on her looks, and "Napoleon" ("Dilate"), which sympathizes sarcastically with an unnamed friend who did sign with a label.
The business grew organically starting in 1990 with the first cassette tape. Connections were made when women in colleges started duplicating and sharing tapes. Offers to play at colleges started coming in and her popularity grew largely by word of mouth and through women's groups or organizations. Zango and Goldenrod, two music distributors specializing in women's music, started carrying DiFranco's music. In general they sold music to independent music stores and women's book stores. In 1995 Righteous Babe Records signed with Koch International for DiFranco's release of "Not a Pretty Girl". Her records could then be found in large and small record stores alike.
DiFranco has occasionally joined with Prince in discussing publicly the problems associated with major record companies. Righteous Babe Records employs a number of people in her hometown of Buffalo. In a 1997 open letter to "Ms. magazine" she expressed displeasure that what she considers a way to ensure her own artistic freedom was seen by others solely in terms of its financial success.
Activism.
From the earliest days of her career, Ani DiFranco has lent her voice and her name to a broad range of social movements, performing benefit concerts, appearing on benefit albums, speaking at rallies, and offering info table space to organizations at her concerts and the virtual equivalent on her website, among other methods and actions. In 1999 she created her own not-for-profit organization; as the Buffalo News has reported,"Through the Righteous Babe Foundation, DiFranco has backed various grassroots cultural and political organizations, supporting causes ranging from abortion rights to gay visibility."
During the first Gulf War, DiFranco participated in the anti-war movement. In the early 1993 she played Pete Seeger's Clearwater Folk Festival for the first time. In 1998 she was a featured performer in the Dead Man Walking benefit concert series raising money for Sister Helen Prejean's "Not in Our Name" anti-death penalty organization. DiFranco's commitment to opposing the death penalty is longstanding; she has also been a long time supporter of the Southern Center for Human Rights.
In 2004 DiFranco visited Burma in order to learn about the Burmese resistance movement and the country's fight for democracy. During her travels she met with then-detained resistance leader Aung San Suu Kyi. Her song "In The Way" was later featured on For the Lady, a benefit CD that donated all proceeds to the United States Campaign for Burma.
On the home front, DiFranco has also been outspoken defender of democracy. During the 2004 presidential primaries, she openly and enthusiastically supported liberal, anti-war Democrat Dennis Kucinich. Congressman Kucinich appeared on stage with her at several concerts and she spoke positively about him from the stage at many more of her concerts. After the primary season ended, and Kerry was the clear Democratic candidate, DiFranco wrote an open letter of conditional support for independent candidate Ralph Nader. The same year she launched a "Vote, Dammit" tour of swing states encouraging audience members to register to vote. In 2005 she lobbied Congress against the proliferation of nuclear power in general and the placement of nuclear waste dumps on Indian land in particular. In 2008 she backed candidate Dennis Kucinich in his bid for the presidency.
In 2002 Righteous Babe Records established the "Aiding Buffalo's Children" program in conjunction with members of the local community to raise funds for Buffalo's imperiled public school system. To kick off the program, DiFranco donated "a day's pay"—the performance fee from her concert that year at Shea's Performing Arts Center— to ABC and challenged her fans to do the same. Aiding Buffalo's Children has since been folded into the Community Foundation of Greater Buffalo, contributing to a variety of charitable funds.
In 2005 when Hurricane Katrina devastated DiFranco's newly adopted home town of New Orleans she collected donations from fans around the world through The Righteous Babe Store website for the Katrina Piano Fund, helping musicians replace instruments lost in the hurricane, raising over $47,500 for the cause.
In 2010 when the BP Oil Spill crippled the Gulf she donated her talents to the "For Our Coast”benefit concert joining Marianne Faithfull, C.C. Adcock and others at the Acadiana Center for the Arts Theater in Lafayette, raising money for Gulf Aid Acadiana, and the Gulf Aid show with Lenny Kravitz, Mos Def, and many more at Mardi Gras World River City in New Orleans, both shows raising money to help protect the wetlands, clean up the coast and to assist the fishermen and their families affected by the spill.
DiFranco also sits on the board for The Roots of Music, founded by Rebirth Brass Band drummer Derrick Tabb. The organization fills a void in music education in New Orleans educational institutions by providing free Marching Band instruction to area children in addition to academic tutoring and mentoring.
DiFranco joined about 500,000 people at the March for Women's Lives in DC in April 2004 to voice her support for women's rights. As an honored guest she marched in the front row for the three-mile route, along with Margaret Cho, Janeane Garofalo, Whoopi Goldberg, Gloria Steinem and many others. Later in the day, Ani played a few songs on the main stage in front of the Capitol, including "Your Next Bold Move".
Scot Fisher, Righteous Babe label president and DiFranco's longtime manager, has been a longtime advocate of the preservation movement in Buffalo. In 1999 he and DiFranco purchased a decaying church on the verge of demolition in downtown Buffalo and began the lengthy process of restoring it. In 2006 the building opened its doors again, first briefly as "The Church" and then as "Babeville,” housing two concert venues, the record label's business office, and Hallwalls Contemporary Arts Center.
2014 Righteous Retreat.
In 2013 DiFranco was criticized on social media and faced "a great deal of outcry" after the announcement that she was hosting a three-day artists' workshop billed as the "Righteous Retreat" at Iberville Parish's Nottoway Plantation in White Castle, Louisiana. Nottoway was one of the largest plantations in the South, and features the largest antebellum mansion. Its operator and founder John Randolph owned over 155 slaves in the year 1860. The grounds are now operated as a luxury resort. Critics charged that the resort's promotional material attempts to portray the plantation owner in a positive light, to downplay the suffering of the slaves, and to "sanitize" and "romanticize" the history of slavery for commercial gain. DiFranco's choice of venue for the retreat was called "a very blatant display of racism" on a petition at change.org that collected more than 2,600 signatures.
On December 29, 2013 DiFranco issued a statement that she was cancelling the retreat, stating that "i am not unaware of the mechanism of white privilege or the fact that i need to listen more than talk when it comes to issues of race. if nottoway is simply not an acceptable place for me to go and try to do my work in the eyes of many, then let me just concede before more divisive words are spilled. ... i think many positive and life-affirming connections would have been made at this conference, in its all of its complexity of design. i do not wish to reinvent the righteous retreat at this point to eliminate the stay at the Nottoway Plantation. at this point I wish only to cancel." The singer's statements were called "remarkably unapologetic" on jezebel.com, and "a variety of excuses and justifications" on ebony.com, and a piece at theguardian.com said the announcement made "much of the idea that this was all a mistake, with no indication of remorse."
DiFranco issued an apology on January 2, 2014 following continued criticism. In it, she wrote "..i would like to say i am sincerely sorry. it is obvious to me now that you were right - all those who said we can't in good conscience go to that place and support it or look past for one moment what it deeply represents. i needed a wake up call and you gave it to me."

</doc>
<doc id="2127" url="https://en.wikipedia.org/wiki?curid=2127" title="Arene (disambiguation)">
Arene (disambiguation)

An Aromatic hydrocarbon or Arene is a hydrocarbon with alternating double and single bonds between carbon atoms forming rings.
Arene may also refer to:

</doc>
<doc id="2129" url="https://en.wikipedia.org/wiki?curid=2129" title="Arizona Diamondbacks">
Arizona Diamondbacks

The Arizona Diamondbacks (often shortened as the D-backs) are an American professional baseball franchise based in Phoenix, Arizona. The club competes in Major League Baseball (MLB) as a member of the National League (NL) West division. Since the team's inception in 1998, the franchise has played home games at Chase Field, formerly known as Bank One Ballpark. The ballpark was renamed in 2005, as a result of Bank One Corporation's merger with JPMorgan Chase & Co. The Diamondbacks have won one World Series championship (in 2001), becoming the fastest expansion team in the Major Leagues to win a championship, doing it in only the fourth season since the franchise's inception in the 1998 Major League Baseball season.
Franchise history.
On March 9, 1995, Arizona was awarded a franchise to begin play for the 1998 season. A $130 million franchise fee was paid to Major League Baseball and on January 16, 1997, the Diamondbacks were officially voted into the National League.
Since their debut, the Diamondbacks have won five National League West titles, one National League Championship pennant, and the 2001 World Series.
Logos.
The Diamondbacks' original colors were purple, black, teal and copper. Their first logo was an italicized block letter "A" with a diamond pattern, and the crossbar represented by a snake's tongue. Prior to their inaugural season, they released their baseball caps. The home cap had a cream color crown with a purple visor and button. The road cap was black and had a turquoise visor and button. Their alternate cap had a turquoise crown with a purple visor and button. Depending on the cap, the "A" logo on the front of the cap had different color variations.
In the Diamondbacks' second season, they introduced a new logo which was a copper color snake in the shape of a letter "D". It was used on a solid black cap, which in the beginning, was worn as a road cap.
The franchise unveiled new uniforms and colors of Sedona Red, Sonoran Sand and black on November 8, 2006. The red shade is named for the sandstone canyon at Red Rock State Park near Sedona, while the beige (sand) shade is named for the Sonoran Desert. A sleeve patch was added featuring a lowercase "d" and "b" configured to look like a snake's head. The team also kept the "D" logo, but was slightly altered and put on an all red cap to be used as their game cap. They also kept the "A" logo with the new colors applied to it, with a solid black cap used as the alternate cap. A similar color scheme is currently used by the Arizona Coyotes of the National Hockey League.
Media.
The primary television play-by-play voice for the team's first nine seasons of play was Thom Brennaman, who also broadcasts baseball and college football games nationally for Fox Television. Brennaman was the TV announcer for the Chicago Cubs and Cincinnati Reds (along with his father Marty Brennaman) before being hired by Diamondbacks founder Jerry Colangelo in 1996, two years before the team would begin play.
In October 2006, Brennaman left the Diamondbacks to call games with his father for the Reds beginning in 2007, signing a four-year deal (his FOX duties remained unchanged).
The English language flagship radio station is KTAR. Greg Schulte is the regular radio play-by-play voice, a 25-year veteran of sports radio in the Phoenix market, also well known for his previous work on Phoenix Suns, Arizona Cardinals and Arizona State University (ASU) broadcasts.
Jeff Munn is a backup radio play-by-play announcer; he served as the regular public address announcer at Chase Field in the early days of the franchise. He is well-known to many Phoenix area sports fans, having also served as the public address announcer for the Suns at America West Arena (now Talking Stick Resort Arena) in the 1990s. He is also the play-by-play radio voice for ASU women's basketball.
On November 1, 2006, the team announced that the TV voice of the Milwaukee Brewers since 2002, Daron Sutton, would be hired as the Diamondbacks primary TV play-by-play voice. Sutton was signed to a five-year contract with a team option for three more years. Sutton is considered one of the best of the younger generation of baseball broadcasters. His signature chants include "let's get some runs" when the D-backs trail in late innings. Sutton's father is Hall of Fame pitcher and current Atlanta Braves broadcaster Don Sutton.
Former Diamondbacks and Chicago Cubs first baseman Mark Grace and former Major League knuckleball pitcher Tom Candiotti were the Diamondbacks primary color analysts for the 2006 and 2007 seasons. Former Diamondbacks third baseman Matt Williams also did color commentary on occasion, as did former Cardinals and NBC broadcast legend Joe Garagiola, Sr., a longtime Phoenix-area resident and father of Joe Garagiola, Jr., the first GM of the Diamondbacks (as head of the Maricopa County Sports Authority in the early 1990s, Garagiola, Jr. was one of the primary people involved in Phoenix obtaining a Major League Baseball franchise).
The Diamondbacks announced in July 2007 that for the 2008 season, all regionally broadcast Diamondbacks TV games will be shown exclusively on Fox Sports Arizona, and a few could possibly be shown on the national Fox MLB telecasts. Fox Sports Arizona (or FS Arizona) is currently seen in 2.8 million households in Arizona and New Mexico. The previous flagship station, since the inaugural 1998 season, was KTVK, a popular over-the-air independent station (and former longtime ABC affiliate) in Phoenix.
From 2009 to 2012, Mark Grace and Daron Sutton were tagged as the main broadcasters of the Diamondbacks with pre-game and postgame shows on Fox Sports Arizona, being hosted by former big-league closer Joe Borowski.
On June 21, 2012, Daron Sutton was suspended indefinitely, amid rumors of insubordination. Then on August 24, the team announced that Mark Grace had requested an indefinite leave of absence after being arrested for his second DUI in less than two years (Grace was later indicted on four DUI counts). For the remainder of the 2012 season, Sutton was replaced by Greg Schulte (Jeff Munn replaced Schulte on the radio broadcast) and Grace was replaced by Luis Gonzalez. At the end of the 2012 season, the team announced that neither Sutton nor Grace would be returning for the 2013 season.
On October 18, 2012, the team announced that Bob Brenly would be returning as a broadcaster, and that he would be joined by then-ESPN personality Steve Berthiaume.
Spanish broadcasts.
The flagship Spanish language radio station is KBMB AM 710 with Miguel Quintana, Richard Saenz and Oscar Soria.
Games were televised in Spanish on KPHE-LP—with Oscar Soria and Jerry Romo as the announcers—but this arrangement ended prior to the 2009 season due to the team switching fully to Fox Sports Arizona and the lack of carriage of KHPE-LP on the Cox cable system.

</doc>
<doc id="2130" url="https://en.wikipedia.org/wiki?curid=2130" title="Aesthetics">
Aesthetics

Aesthetics, or the philosophy of art, is the study of beauty and taste. It is about interpreting works of art and art movements or theories. The term aesthetic is also used to designate a particular style, for example the "chess aesthetics", the "japanese aesthetics".
As well as being applied to art, aesthetics can also be applied to cultural objects. Aesthetic design principles include ornamentation, edge delineation, texture, flow, solemnity, symmetry, color, granularity, the interaction of sunlight and shadows, transcendence, and harmony.
The word aesthetic is also an adjective and adverb relating to cosmetology and medicine, as in aesthetic medicine.
Also spelt "æsthetics" and "esthetics", the word is derived from the Ancient Greek αἰσθητικός ("aisthetikos", meaning "esthetic, sensitive, sentient, pertaining to sense perception"), which in turn was derived from αἰσθάνομαι ("aisthanomai", meaning "I perceive, feel, sense").
History of aesthetics in western philosophy.
The idea of the aesthetic developed from the idea of taste and beauty. Before the early 1700s, thinkers developed general theories of proportion and harmony, detailed most specifically in architecture and music. An extended, philosophical reflection on aesthetics emerged with the widening of leisure activities in the eighteenth century.
In the 1700s, Edmund Burke and David Hume tried to explain aesthetic concepts such as beauty with empirical evidence, by connecting them with typical individuals' responses. They sought a basis for an objectivity of personal reactions.
In the 1800s psychologist Wilhelm Wundt showed that interest is generally related to complexity of stimulus. To arouse interest an object should be neither boringly simple nor overly complex; thus complexity could be an objective measure. It is now known, for instance, that judgments of facial beauty in humans are a matter of averageness and symmetry.
The analysis of individual experience and behavior based on experiment is a central part of experimental aesthetics, a field founded by Gustav Theodor Fechner in the 1800s.
Immanuel Kant insisted that aesthetic concepts are essentially subjective, but have some objectivity since feelings of pleasure and pain can be universal responses to certain stimuli.
Recently theorists have been interested in ways that aesthetic concepts are constructed out of social mores and practices. Evaluations of beauty may well be linked to desirability, economic, political, or moral value. One might judge a Lamborghini to be beautiful partly because it is desirable as a status symbol, or we might judge it to be repulsive partly because it signifies for us over-consumption and offends our political or moral values.
As late as 1912 it was normal in the West to assume that all art aims at beauty, and thus that anything that wasn't trying to be beautiful couldn't count as art. The cubists, dadaists, Stravinsky, and many later art movements struggled against this conception that beauty was central to the definition of art, with such success that, according to Danto, "Beauty had disappeared not only from the advanced art of the 1960s but from the advanced philosophy of art of that decade as well."
In the 1930s, Walter Benjamin, in his essay The Work of Art in the Age of Mechanical Reproduction, argued that, in the absence of any traditional, ritualistic value, art in the age of mechanical reproduction would inherently be based on the practice of politics. John Berger continued in this direction with Ways of Seeing, in which he criticizes traditional Western cultural aesthetics by raising questions about hidden ideologies in visual images.
In 1946, William K. Wimsatt and Monroe Beardsley published the essay The Intentional Fallacy, in which they argued strongly against the relevance of an author's intention, or "intended meaning" in the analysis of a literary work. For Wimsatt and Beardsley, the words on the page were all that mattered; importation of meanings from outside the text was considered irrelevant, and potentially distracting. In another essay, "The Affective Fallacy," which served as a kind of sister essay to "The Intentional Fallacy", Wimsatt and Beardsley also discounted the reader's personal/emotional reaction to a literary work as a valid means of analyzing a text. This fallacy would later be repudiated by theorists from the reader-response school of literary theory. Ironically, one of the leading theorists from this school, Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and Beardsley in his essay "Literature in the Reader" (1970).
In 1959 Frank Sibley wrote that aesthetic concepts were not rule- or condition-governed, but required a heightened form of perception, which one might call taste, sensitivity, or judgment.
Scientific analysis of aesthetics.
In the 1990s, Jürgen Schmidhuber described an algorithmic theory of beauty which takes the subjectivity of the observer into account and postulates: among several observations classified as comparable by a given subjective observer, the aesthetically most pleasing one is the one with the shortest description, given the observer's previous knowledge and his particular method for encoding the data. This is closely related to the principles of algorithmic information theory and minimum description length. For example: mathematical beauty. Another example describes an aesthetically pleasing human face whose proportions can be described with very little information, drawing inspiration from less detailed 15th century proportion studies by Leonardo da Vinci and Albrecht Dürer. Schmidhuber's theory explicitly distinguishes between what is beauty and what is interesting, stating that the latter corresponds to the first derivative of subjectively perceived beauty. The premise is that any observer continually tries to improve the predictability and compressibility of the observations by discovering regularities such as repetitions and symmetry and self-similarity.
Mathematical considerations, such as symmetry and complexity, are used for analysis in theoretical aesthetics. The fact that judgments of beauty and judgments of truth both are influenced by processing fluency has been presented as an explanation for why beauty is sometimes equated with truth. Recent research found that people use beauty as an indication for truth in mathematical pattern tasks.
Computer scientists have attempted to develop automated methods to infer aesthetic quality of images. Typically, these approaches follow a machine learning approach, where large numbers of manually rated photographs are used to teach a computer about what visual properties are of relevance to aesthetic quality. The Acquine engine, developed at Penn State University, rates natural photographs uploaded by users. There have also been relatively successful attempts with regard to chess and music.
In Evolutionary aesthetics, the basic aesthetic preferences of humans are argued to be a product of evolutionary adaptations. For example, body symmetry may be valued in physical attractiveness because it may indicate good health.
Aesthetic systems.
Japanese aesthetics.
The study of Japanese aesthetics only started a little over two hundred years ago in the West. The Japanese aesthetic is a set of ancient ideals which underpin much of Japanese cultural and aesthetic norms for what is considered tasteful or beautiful. While seen as a philosophy in Western societies, the concept of aesthetics in Japan is seen as an integral part of daily life.
Indian aesthetics.
Indian aesthetics evolved with an emphasis on inducing special spiritual or philosophical states in the audience, or with representing them as symbols.
Chess aesthetics.
Chess aesthetics, or beauty in chess is appreciated by both players and chess composers. In some tournaments there are prizes for brilliancy (not just for winning a match). There are books published featuring chess problems or puzzles that emphasize their aesthetic aspect. Factors about a game or move sequence (also referred to as a combination that might cause it to be regarded as 'brilliant' include: expediency, disguise, sacrifice, correctness, preparation, paradox, unity, and originality.
Music aesthetics.
In the pre-modern tradition, the aesthetics of music explored the mathematical and cosmological dimensions of rhythmic and harmonic organization. In the eighteenth century, focus shifted to the experience of hearing music, and thus to questions about its beauty and human enjoyment.
Mathematical beauty.
Mathematicians consider mathematical beauty to be a desirable quality in their work. Comparisons are often made with music and poetry.

</doc>
<doc id="2134" url="https://en.wikipedia.org/wiki?curid=2134" title="Ark of the Covenant">
Ark of the Covenant

The Ark of the Covenant ( "ʾĀrôn Habbərît", modern pron. "Aron haBrit"), also known as the Ark of the Testimony, was a wooden chest clad with gold containing the two stone tablets of the Ten Commandments as well as, according to various texts within the Hebrew Bible, Aaron's rod and a pot of manna.
The biblical account relates that, approximately one year after the Israelites' exodus from Egypt, the Ark was created according to the pattern given to Moses by God when the Israelites were encamped at the foot of biblical Mount Sinai. Thereafter, the gold-plated acacia chest was carried by its staves while en route by the Levites approximately 2,000 cubits (approximately ) in advance of the people when on the march or before the Israelite army, the host of fighting men. When the Ark was borne by Levites into the bed of the Jordan River, the waters parted as God had parted the waters of the Red Sea, opening a pathway for the entire host to pass. The walls of the city of Jericho were shaken to the ground with no more than a shout from the army after the Ark of the Covenant was paraded around them for seven days by Levites accompanied by seven priests sounding seven trumpets of rams' horns. When carried, the Ark was always hidden under a large veil made of skins and blue cloth, always carefully concealed, even from the eyes of the priests and the Levites who carried it. God was said to have spoken with Moses "from between the two cherubim" on the Ark's cover. When at rest the tabernacle was reared up and the holy Ark was placed under the veil of the covering the staves of it crossing the middle side bars to hold it up off the ground.
Biblical account.
Construction and description.
According to the Book of Exodus, God instructed Moses on Mount Sinai during his 40-day stay upon the mountain within the thick cloud and darkness where God was and he was shown the pattern for the tabernacle and furnishings of the Ark to be made of shittim wood to house the Tablets of Stone. Moses instructed Bezalel and Oholiab to construct the Ark. In Deuteronomy, however, the Ark is said to have been built specifically by Moses himself without reference of Bezalel or Oholiab.
The Book of Exodus gives detailed instructions on how the Ark is to be constructed. It is to be 2½ cubits in length, 1½ in breadth, and 1½ in height (approximately ). Then it is to be gilded entirely with gold, and a crown or molding of gold is to be put around it. Four rings of gold are to be attached to its four corners, two on each side—and through these rings staves of shittim-wood overlaid with gold for carrying the Ark are to be inserted; and these are not to be removed. A golden lid, the "kapporet" (traditionally "mercy seat" in Christian translations) which is covered with 2 golden cherubim, is to be placed above the Ark. Instructions missing from the biblical account include the thickness of the mercy seat, the thickness of its sides and bottom, and details concerning the cherubim. The Ark is finally to be placed under the veil of the covering.
Mobile vanguard.
The biblical account continues that, after its creation by Moses, the Ark was carried by the Israelites during their 40 years of wandering in the desert. Whenever the Israelites camped, the Ark was placed in a separate room in a sacred tent, called the Tabernacle.
When the Israelites, led by Joshua toward the Promised Land, arrived at the banks of the River Jordan, the Ark was carried in the lead preceding the people and was the signal for their advance (Joshua 3:3, 6). During the crossing, the river grew dry as soon as the feet of the priests carrying the Ark touched its waters, and remained so until the priests—with the Ark—left the river after the people had passed over (Josh. 3:15-17; 4:10, 11, 18). As memorials, twelve stones were taken from the Jordan at the place where the priests had stood (Josh. 4:1-9).
In the Battle of Jericho, the Ark was carried round the city once a day for seven days, preceded by the armed men and seven priests sounding seven trumpets of rams' horns (Josh. 6:4-15). On the seventh day, the seven priests sounding the seven trumpets of rams' horns before the Ark compassed the city seven times and, with a great shout, Jericho's wall fell down flat and the people took the city (Josh. 6:16-20). After the defeat at Ai, Joshua lamented before the Ark (Josh. 7:6-9). When Joshua read the Law to the people between Mount Gerizim and Mount Ebal, they stood on each side of the Ark. We next hear of the Ark in Bethel where it was being cared for by the priest Phineas the grandson of Aaron (Judges 20:26f, where 'Bethel' is translated 'the House of God' in the King James Version). According to this verse it was consulted by the people of Israel when they were planning to attack the Benjaminites at the battle of Gibeah. Later, however, the Ark was kept at Shiloh, another religious centre some 10 miles north of Bethel, at the time of the prophet Samuel's apprenticeship (1 Samuel 3:3), where it was cared for by Hophni and Phinehas, two sons of Eli (1 Samuel 4:3f).
Capture by the Philistines.
A few years later the elders of Israel decided to take the Ark out onto the battlefield to assist them against the Philistines, after being defeated at the battle of Eben-Ezer (1 Sam. 4:3-11). They were, however, heavily defeated with the loss of 30,000 men. The Ark was captured by the Philistines and Hophni and Phinehas were killed. The news of its capture was at once taken to Shiloh by a messenger "with his clothes rent, and with earth upon his head." The old priest, Eli, fell dead when he heard it; and his daughter-in-law, bearing a son at the time the news of the capture of the Ark was received, named him Ichabod — explained as "The glory has departed Israel" in reference to the loss of the Ark (1 Sam. 4:12-22).
The Philistines took the Ark to several places in their country, and at each place misfortune befell them (1 Sam. 5:1-6). At Ashdod it was placed in the temple of Dagon. The next morning Dagon was found prostrate, bowed down, before it; and on being restored to his place, he was on the following morning again found prostrate and broken. The people of Ashdod were smitten with hemorrhoids; a plague of mice was sent over the land (1 Sam. 6:5). The affliction of boils was also visited upon the people of Gath and of Ekron, whither the Ark was successively removed (1 Sam. 5:8-12).
After the Ark had been among them for seven months, the Philistines, on the advice of their diviners, returned it to the Israelites, accompanying its return with an offering consisting of golden images of the tumors and mice wherewith they had been afflicted. The Ark was set up in the field of Joshua the Beth-shemite, and the Beth-shemites offered sacrifices and burnt offerings (1 Sam. 6:1-15). Out of curiosity the men of Beth-shemesh gazed at the Ark; and as a punishment, seventy of them (fifty thousand and seventy in some mss.) were smitten by the Lord (1 Sam. 6:19). The Bethshemites sent to Kirjath-jearim, or Baal-Judah, to have the Ark removed (1 Sam. 6:21); and it was taken to the house of Abinadab, whose son Eleazar was sanctified to keep it. Kirjath-jearim remained the abode of the Ark for twenty years. Under Saul, the Ark was with the army before he first met the Philistines, but the king was too impatient to consult it before engaging in battle. In 1 Chronicles 13:3 it is stated that the people were not accustomed to consult the Ark in the days of Saul.
In the days of King David.
At the beginning of his reign, King David removed the Ark from Kirjath-jearim amid great rejoicing. On the way to Zion, Uzzah, one of the drivers of the cart that the Ark was carried on, put out his hand to steady the Ark, and was struck dead by God for touching it. David, in fear, carried the Ark aside into the house of Obed-edom the Gittite, instead of carrying it on to Zion, and there it stayed three months (2 Samuel 6:1-11; 1 Chronicles 13:1-13).
On hearing that God had blessed Obed-edom because of the presence of the Ark in his house, David had the Ark brought to Zion by the Levites, while he himself, "girded with a linen ephod," "danced before the Lord with all his might" and in the sight of all the public gathered in Jerusalem—a performance that caused him to be scornfully rebuked by his first wife, Saul's daughter Michal (2 Sam. 6:12-16, 20-22; 1 Chron. 15). In Zion, David put the Ark in the tabernacle he had prepared for it, offered sacrifices, distributed food, and blessed the people and his own household (2 Sam. 6:17-20; 1 Chron. 16:1-3; 2 Chron. 1:4).
The Levites were appointed to minister before the Ark (1 Chron. 16:4). David's plan of building a temple for the Ark was stopped at the advice of God (2 Sam. 7:1-17; 1 Chron. 17:1-15; 28:2, 3). The Ark was with the army during the siege of Rabbah (2 Sam. 11:11); and when David fled from Jerusalem at the time of Absalom's conspiracy, the Ark was carried along with him until he ordered Zadok the priest to return it to Jerusalem (2 Sam. 15:24-29).
In Solomon's Temple.
When Abiathar was dismissed from the priesthood by King Solomon for having taken part in Adonijah's conspiracy against David, his life was spared because he had formerly borne the Ark (1 Kings 2:26). Solomon worshipped before the Ark after his dream in which God promised him wisdom (1 Kings 3:15).
During the construction of Solomon's Temple, a special inner room, named "Kodesh Hakodashim" (Eng. Holy of Holies), was prepared to receive and house the Ark (1 Kings 6:19); and when the Temple was dedicated, the Ark—containing the original tablets of the Ten Commandments—was placed therein (1 Kings 8:6-9). When the priests emerged from the holy place after placing the Ark there, the Temple was filled with a cloud, "for the glory of the Lord had filled the house of the Lord" (1 Kings 8:10-11; 2 Chron. 5:13, 14).
When Solomon married Pharaoh's daughter, he caused her to dwell in a house outside Zion, as Zion was consecrated because of its containing the Ark (2 Chron. 8:11). King Josiah also had the Ark returned to the Temple (2 Chron. 35:3), from which it appears to have been removed by one of his predecessors (cf. 2 Chron. 33-34 and 2 Kings 21-23).
The Babylonian Conquest and aftermath.
In 587 BC, the Babylonians destroyed Jerusalem and Solomon's Temple. There is no record of what became of the Ark in the Books of Kings and Chronicles. An ancient Greek version of the biblical third Book of Ezra, 1 Esdras, suggests that Babylonians took away the vessels of the ark of God, but does not mention taking away the Ark:
In Rabbinic literature, the final disposition of the Ark is disputed. Some rabbis hold that it must have been carried off to Babylon, while others hold that it must have been hidden lest it be carried off into Babylon and never brought back. A late 2nd-century rabbinic work known as the "Tosefta" states the opinions of these rabbis that Josiah, the king of Judah, stored away the Ark, along with the jar of manna, and a jar containing the holy anointing oil, the rod of Aaron which budded and a chest given to Israel by the Philistines. This was said to have been done in order to prevent their being carried off into Babylon as had already happened to the other vessels. Rabbi Eliezer and Rabbi Shimon, in the same rabbinic work, state that the Ark was, in fact, taken into Babylon. Rabbi Yehudah, dissenting, says that the Ark was stored away in its own place, meaning, somewhere on the Temple Mount.
References in Scripture.
Tanakh.
The Ark is first mentioned in the Book of Exodus, and then numerous times in Deuteronomy, Joshua, Judges, I Samuel, II Samuel, I Kings, I Chronicles, II Chronicles, Psalms and Jeremiah.
In the Book of Jeremiah, it is referenced by Jeremiah, who, speaking in the days of Josiah (Jer. 3:16), prophesied a future time, possibly the end of days, when the Ark will no longer be talked about or be made again:
Rashi comments on this verse that "The entire people will be so imbued with the spirit of sanctity that God's Presence will rest upon them collectively, as if the congregation itself was the Ark of the Covenant."
Second Book of Maccabees.
According to Second Maccabees, at the beginning of chapter 2:
The "mountain from the top of which Moses saw God's promised land" would be Mount Nebo, located in what is now Jordan.
New Testament.
In the New Testament, the Ark is mentioned in the Letter to the Hebrews and the Revelation to St. John. states that the Ark contained "the golden pot that had manna, and Aaron's rod that budded, and the tablets of the covenant." says the prophet saw God's temple in heaven opened, "and the ark of his covenant was seen within his temple."
Roman Catholic writers connect this verse with the Woman of the Apocalypse in , which immediately follows, and say that the Blessed Virgin Mary is the "Ark of the New Covenant." Carrying the saviour of mankind within her, she herself became the Holy of Holies. This is the interpretation given in the third century by Gregory Thaumaturgus, and in the fourth century by Saint Ambrose, Saint Ephraem of Syria and Saint Augustine. The Catholic Church teaches this in the Catechism of the Catholic Church: "Mary, in whom the Lord himself has just made his dwelling, is the daughter of Zion in person, the Ark of the Covenant, the place where the glory of the Lord dwells. She is ‘the dwelling of God . . . with men"
In the Gospel of Luke, the author's accounts of the Annunciation and Visitation are constructed using eight points of literary parallelism to compare Mary to the Ark.
It is believed by Roman Catholics that Athanasius the bishop of Alexandria wrote about the connections between the Ark and the Virgin Mary: "O noble Virgin, truly you are greater than any other greatness. For who is your equal in greatness, O dwelling place of God the Word? To whom among all creatures shall I compare you, O Virgin? You are greater than them all O (Ark of the) Covenant, clothed with purity instead of gold! You are the Ark in which is found the golden vessel containing the true manna, that is, the flesh in which Divinity resides" ("Homily of the Papyrus of Turin"). However, some question the authenticity of this work and suggest it is an example of the writing of yet another Pseudo-Athanasius.
The Ark in Islamic sources.
Chapter 2 ("Sura" 2) of the Quran (Verse 248), is believed to refer to the Ark:
The Arabic word "sakīna" (variously translated 'peace of reassurance' or 'spirit of tranquillity') is related to the post-Biblical Hebrew shekhinah, meaning 'dwelling or presence of God'.
The Islamic scholar Al Baidawi mentioned that the "sakina" could be Tawrat, the Books of Moses. According to Al-Jalalan, the relics in the Ark were the fragments of the two tablets, rods, robes, shoes, mitres of Moses and the vase of manna. Al-Tha'alibi, in "Qisas Al-Anbiya" (The Stories of the Prophets), has given an earlier and later history of the Ark.
According to most Muslim scholars, the Ark of the Covenant has a religious basis in Islam, and Islam gives it special significance. A Shia sect of Muslims believe that it will be found by the Mahdi near the end of times from Lake Tiberias.
Possible locations.
Since its disappearance from the Biblical narrative, there have been a number of claims of having discovered or of having possession of the Ark, and several possible places have been suggested for its location.
Mount Nebo.
2 Maccabees 2:4-10, written around 100 BC, says that the prophet Jeremiah, "being warned by God" before the Babylonian invasion, took the Ark, the Tabernacle, and the Altar of Incense, and buried them in a cave on Mount Nebo, informing those of his followers who wished to find the place that it should remain unknown "until the time that God should gather His people again together, and receive them unto mercy."
Mount Nebo is also described in the Bible (Deuteronomy 34) as the site from which Moses views the Promised Land, and apparently also is his final burial place. Mount Nebo is approximately 29 miles (47 km) slightly south of due east from Jerusalem, near the east bank of the Jordan River.
Ethiopia.
The Ethiopian Orthodox Church claims to possess the Ark of the Covenant, or "Tabot", in Axum. The object is currently kept under guard in a treasury near the Church of Our Lady Mary of Zion. Replicas of the Axum "tabot" are kept in every Ethiopian church, each with its own dedication to a particular saint; the most popular of these include Mary, George and Michael.
The "Kebra Nagast", composed to legitimise the new dynasty ruling Ethiopia following its establishment in 1270, narrates how the real Ark of the Covenant was brought to Ethiopia by Menelik I with divine assistance, while a forgery was left in the Temple in Jerusalem. Although the "Kebra Nagast" is the best-known account of this belief, it predates the document. Abu al-Makarim, writing in the last quarter of the twelfth century, makes one early reference to this belief that they possessed the Ark. "The Abyssinians possess also the Ark of the Covenant", he wrote, and, after a description of the object, describes how the liturgy is celebrated upon the Ark four times a year, "on the feast of the great nativity, on the feast of the glorious Baptism, on the feast of the holy Resurrection, and on the feast of the illuminating Cross."
In the 1992 book "The Sign and the Seal", controversial British writer Graham Hancock suggests, contrary to the "Kebra Nagast", that the ark spent several years in Egypt before it came to Ethiopia via the Nile River, where it was kept in the islands of Lake Tana for about four hundred years and finally taken to Axum. Archaeologist John Holladay of the University of Toronto called Hancock's theory "garbage and hogwash," while Edward Ullendorff, a former Professor of Ethiopian Studies at the University of London, said he "wasted a lot of time reading it."
On 25 June 2009, the patriarch of the Orthodox Church of Ethiopia, Abune Paulos, said he would announce to the world the next day the unveiling of the Ark of the Covenant, which he said had been kept safe and secure in a church in Axum, Ethiopia. The following day, on 26 June 2009, the patriarch announced that he would not unveil the Ark after all, but that instead he could attest to its current status.
Southern Africa.
The Lemba people of South Africa and Zimbabwe have claimed that their ancestors carried the Ark south, calling it the "ngoma lungundu" or "voice of God", eventually hiding it in a deep cave in the Dumghe mountains, their spiritual home.
On 14 April 2008, in a UK Channel 4 documentary, Tudor Parfitt, taking a literalist approach to the Biblical story, described his research into this claim. He says that the object described by the Lemba has attributes similar to the Ark. It was of similar size, was carried on poles by priests, was not allowed to touch the ground, was revered as a voice of their God, and was used as a weapon of great power, sweeping enemies aside.
In his book "The Lost Ark of the Covenant" (2008), Parfitt also suggests that the Ark was taken to Arabia following the events depicted in the Second Book of Maccabees, and cites Arabic sources which maintain it was brought in distant times to Yemen. One Lemba clan, the Buba, which was supposed to have brought the Ark to Africa, have a genetic signature called the Cohen Modal Haplotype. This suggests a male Semitic link to the Levant. Lemba tradition maintains that the Ark spent some time in Sena in Yemen. Later, it was taken across the sea to East Africa and may have been taken inland at the time of the Great Zimbabwe civilization. According to their oral traditions, some time after the arrival of the Lemba with the Ark, it self-destructed. Using a core from the original, the Lemba priests constructed a new one. This replica was discovered in a cave by a Swedish German missionary named Harald von Sicard in the 1940s and eventually found its way to the Museum of Human Science in Harare. Parfitt had this artifact radio-carbon dated to about 1350, which coincided with the sudden end of the Great Zimbabwe civilization.
Europe.
Chartres Cathedral, France.
French author Louis Charpentier claimed that the Ark was taken to Chartres Cathedral by the Knights Templar.
Rennes-le-Château, then to the United States.
One author has theorised that the Ark was taken from Jerusalem to the village of Rennes-le-Château in Southern France. Karen Ralls has cited Freemason Patrick Byrne, who believes the Ark was moved from Rennes-le-Château at the outbreak of World War I to the United States.
Rome.
The Ark of the Covenant was said to have been kept in the Basilica of St. John Lateran, surviving the pillages of Rome by Genseric and Alaric I but lost when the basilica burned.
United Kingdom.
In 2003, author Graham Phillips hypothetically concluded that the Ark was taken to Mount Sinai in the Valley of Edom by the Maccabees. Phillips claims it remained there until the 1180s, when Ralph de Sudeley, the leader of the Templars found the Maccabean treasure at Jebel al-Madhbah, and returned home to his estate at Herdewyke in Warwickshire, England taking the treasure with him.
Ireland.
During the turn of the 20th century British Israelites carried out some excavations of the Hill of Tara in Ireland looking for the Ark of the Covenant—the Royal Society of Antiquaries of Ireland campaigned successfully to have them stopped before they destroyed the hill.
Egypt.
Tutankhamun's tomb.
In 1922 in the Egyptian Valley of the Kings, the tomb of Tutankhamun (KV62) was opened by Howard Carter and Lord Carnarvon. Among the artifacts was a processional ark, listed as Shrine 261, the Anubis Shrine. Almost immediately after publication of the photographs of this sensational archaeological find, some claimed that the Anubis Shrine could be the Ark of the Covenant. John M. Lundquist, author of "The Temple of Jerusalem: past, present, and future" (2008), discounts this idea. The Anubis Shrine measures long, wide, and high in the shape of a pylon. The Biblical Ark of the Covenant is approximately long, wide, and high in the shape of a rectangular chest.
He points out that Shrine 261 is not strictly analogous to the Ark of the Covenant: it can only be said that the Anubis Shrine is "ark-like", constructed of wood, gessoed and gilded, stored within a sacred tomb, "guarding" the treasury of the tomb (and not the primary focus of that environment), that it contains compartments within it that store and hold sacred objects, that it has a figure of Anubis on its lid, and that it was carried by two staves permanently inserted into rings at its base and borne by eight priests in the funerary procession to Tutankhamun's tomb. Its value is the insight it provides to the ancient culture of Egypt.
In popular culture.
The Ark of the Covenant is a plot device in Steven Spielberg's 1981 adventure film "Raiders of the Lost Ark," which depicts it as located in the Egyptian city of Tanis; it is mentioned briefly in the 1989 film "Indiana Jones and the Last Crusade" and appears in a cameo in "Indiana Jones and the Kingdom of the Crystal Skull".
In the Danish family film "The Lost Treasure of the Knights Templar" from 2006, the main part of the treasure found in the end is the Ark of the Covenant. The power of the Ark comes from charged static electricity from different metal plates like a giant battery.

</doc>
<doc id="2136" url="https://en.wikipedia.org/wiki?curid=2136" title="Angles">
Angles

The Angles () were one of the main Germanic peoples who settled in Britain in the post-Roman period. They founded several of the kingdoms of Anglo-Saxon England, and their name is the root of the name "England". The name comes from the district of Angeln, an area located on the Baltic shore of what is now Schleswig-Holstein, the most northern state of Germany.
Name.
The name of the Angles was first recorded in Latinised form, as "Anglii", in the "Germania" of Tacitus. It is thought to derive from the name of the area they originally inhabited: "Angeln" in modern German, "Angel" in Danish. This name has been hypothesised to originate from the Germanic root for "narrow" (compare German and Dutch "eng" = "narrow"), meaning "the Narrow ", i.e. the Schlei estuary; the root would be angh, "tight". Another theory is that the name meant "hook", as in angling for fish; Julius Pokorny, a major Indo-European linguist, derives it from *ang-, "bend" (see ankle).
Gregory the Great in an epistle simplified the Latinised name "Anglii" to "Angli", the latter form developing into the preferred form of the word. The country remained "Anglia" in Latin. Alfred the Great's translation of Orosius' history of the world uses "Angelcynn" (-kin) to describe England and the English people; Bede used "Angelfolc" (-folk); there are also such forms as "Engel", "Englan" (the people), "Englaland", and "Englisc", all showing i-mutation.
Greco-Roman historiography.
Tacitus.
The earliest recorded mention of the Angles may be in chapter 40 of Tacitus's "Germania". Tacitus describes the "Anglii" as one of the more remote Suebic tribes compared to the Semnones and Langobardi, who lived on the Elbe and were better known to the Romans. He grouped the Angles with several other tribes in that region, the Reudigni, Aviones, Varini, Eudoses, Suarini and Nuitones. These were all living behind ramparts of rivers and woods and therefore inaccessible to attack.
He gives no precise indication of their geographical situation but states that, together with the six other tribes, they worshiped Nerthus, or Mother Earth, whose sanctuary was located on "an island in the Ocean". The Eudoses are the Jutes, these names probably refer to localities in Jutland or on the Baltic coast. The coast contains sufficient estuaries, inlets, rivers, islands, swamps and marshes to have been then inaccessible to those not familiar with the terrain, such as the Romans, who considered it unknown, inaccessible, with a small population and of little economic interest.
The majority of scholars believe that the Anglii lived on the coasts of the Baltic Sea, probably in the southern part of the Jutish peninsula. This view is based partly on Old English and Danish traditions regarding persons and events of the 4th century, and partly on the fact that striking affinities to the cult of Nerthus as described by Tacitus are to be found in pre-Christian Scandinavian, especially Swedish and Danish, religion.
Ptolemy.
Ptolemy in his "Geography" (2.10), half a century later, describes the "Sueboi Angeilloi", Latinised to "Suevi Angili", further south, living in a stretch of land between the northern Rhine and central Elbe, but apparently not touching either river, with the Suebic Langobardi on the Rhine to their west, and the Suebic Semnones on the Elbe stretching to their east.
These Suevi Angili would have been in Lower Saxony or near it, but they are not coastal. The three Suebic peoples are separated from the coastal Chauci, (between Ems and Elbe), and Saxones, (east of the Elbe mouth), by a series of tribes including, between Weser and Elbe, the Angrivarii, "Laccobardi" (probably another reference to Langobardi, but taken by Ptolemy from another source), and Dulgubnii. South of the Saxons, and east of the Elbe, Ptolemy lists "Ouirounoi" (Latinised as Viruni, and probably the Varini) and Teutonoari, which either denotes "the Teuton men", or else it denotes people living in the area where the Teutons had previously lived (who Ptolemy places still living to the east of the Teutonoari). Ptolemy describes the coast to the east of the Saxons as inhabited by the Farodini, a name not known from any other sources.
Owing to the uncertainty of this passage, there has been much speculation regarding the original home of the Anglii. One theory is that they or part of them dwelt or moved among other coastal people perhaps confederated up to the basin of the Saale (in the neighbourhood of the ancient canton of Engilin) on the Unstrut valleys below the Kyffhäuserkreis, from which region the "Lex Angliorum et Werinorum hoc est Thuringorum" is believed by many to have come. The ethnic names of Frisians and Warines are attested in the neighbourhood names of this Saxon or Swabian lands.
A second possible solution is that these Angles of Ptolemy are not those of Schleswig at all. According to Julius Pokorny the Angri- in Angrivarii, the -angr in Hardanger and the Angl- in Anglii all come from the same root meaning "bend", but in different senses. In other words, the similarity of the names is strictly coincidental and does not reflect any ethnic unity beyond Germanic.
On the other hand, Gudmund Schütte, in his analysis of Ptolemy, believes that the Angles have simply been moved by an error coming from Ptolemy's use of imperfect sources. He points out that Angles are placed correctly just to the northeast of the Langobardi, but that these have been duplicated, so that they appear once, correctly, on the lower Elbe, and a second time, incorrectly, at the northern Rhine.
Medieval historiography.
Bede states that the Anglii, before coming to Great Britain, dwelt in a land called Angulus, "which lies between the province of the Jutes and the Saxons, and remains unpopulated to this day." Similar evidence is given by the "Historia Brittonum". King Alfred the Great and the chronicler Æthelweard identified this place with the district that is now called Angeln, in the province of Schleswig (Slesvig) (though it may then have been of greater extent), and this identification agrees with the indications given by Bede.
In the Norwegian seafarer Ohthere of Hålogaland's account of a two-day voyage from the Oslo fjord to Schleswig, he reported the lands on his starboard bow, and Alfred appended the note "on these islands dwelt the "Engle" before they came hither". Confirmation is afforded by English and Danish traditions relating to two kings named Wermund and Offa of Angel, from whom the Mercian royal family claimed descent and whose exploits are connected with Angeln, Schleswig, and Rendsburg. Danish tradition has preserved record of two governors of Schleswig, father and son, in their service, Frowinus (Freawine) and Wigo (Wig), from whom the royal family of Wessex claimed descent. During the 5th century, the Anglii invaded Great Britain, after which time their name does not recur on the continent except in the title of "Suevi Angili".
The Angles are the subject of a legend about Pope Gregory I, who happened to see a group of Angle children from Deira for sale as slaves in the Roman market. As the story would later be told by the Anglo-Saxon monk and historian Bede, Gregory was struck by the unusual appearance of the slaves and asked about their background. When told they were called ""Anglii"" (Angles), he replied with a Latin pun that translates well into English: “"Bene, nam et angelicam habent faciem, et tales angelorum in caelis decet esse coheredes"” ("It is well, for they have an angelic face, and such people ought to be co-heirs of the angels in heaven"). Supposedly, this encounter inspired the Pope to launch a mission to bring Christianity to their countrymen.
Archaeology.
The province of Schleswig has proved rich in prehistoric antiquities that date apparently from the 4th and 5th centuries. A large cremation cemetery has been found at Borgstedt, between Rendsburg and Eckernförde, and it has yielded many urns and brooches closely resembling those found in pagan graves in England. Of still greater importance are the great deposits at Thorsberg moor (in Angeln) and Nydam, which contained large quantities of arms, ornaments, articles of clothing, agricultural implements, etc., and in Nydam even ships. By the help of these discoveries, Angle culture in the age preceding the invasion of Britannia can be pieced together.
Anglian kingdoms in England.
According to sources such as the History of Bede, after the invasion of Britannia, the Angles split up and founded the kingdoms of the Northumbria, East Anglia and Mercia. H.R. Loyn has observed in this context that "a sea voyage is perilous to tribal institutions," and the apparently tribally-based kingdoms were produced in England. In early times there were two northern kingdoms (Bernicia and Deira) and two midland ones (Middle Anglia and Mercia), which had by the 7th century resolved themselves into two Angle kingdoms, viz., Northumbria and Mercia. Northumbria held suzerainty amidst the Teutonic presence in the British Isles in the 7th century, but was eclipsed by the rise in power of the Mercian Kingdom in the 8th century. Both Kingdoms fell in the great assaults of the Danish Viking armies in the 9th century, their royal houses being effectively destroyed in the fighting, the Angle populations of the two fallen Kingdoms becoming governmentally captive under the Danelaw's dominion. Having withstood the Danish assaults further south, the Saxon kings of Wessex marched north in the late 9th and early 10th centuries and liberated the Angles from the Danelaw in a succession of victorious military campaigns, and were accepted by the Angles as their kings after having united their house in marriage with the surviving residue of the Angle royal lines. This marked the passing of the old 'Anglo-Saxon' world and the dawn of the "English" as a new people. The regions of East Anglia and Northumbria are still known by their original titles. Northumbria once stretched as far north as what is now southeast Scotland, including Edinburgh, and as far south as the Humber Estuary.
The rest of that people stayed at the centre of the Angle homeland in the northeastern portion of the modern German "Bundesland" of Schleswig-Holstein, on the Jutland Peninsula. There, a small peninsular area is still called "Angeln" today and is formed as a triangle drawn roughly from modern Flensburg on the Flensburger Fjord to the City of Schleswig and then to Maasholm, on the Schlei inlet.

</doc>
<doc id="2137" url="https://en.wikipedia.org/wiki?curid=2137" title="Aster CT-80">
Aster CT-80

The Aster CT-80, an early (1982) home/personal computer developed by the small Dutch company MCP (later renamed to Aster Computers), was sold in its first incarnation as a kit for hobbyists. Later it was sold ready to use. It consisted of several Eurocard PCB's with DIN 41612 connectors, and a backplane all based on a 19-inch rack configuration. It was the first commercially available Dutch personal/home computer. The Aster computer could use the software written for the popular Tandy TRS-80 computer while fixing many of the problems of that computer, but it could also run CP/M software, with a big amount of free memory Transient Program Area, (TPA) and a full 80×25 display, and it could be used as a Videotext terminal. Although the Aster was a clone of the TRS-80 Model I it was in fact more compatible with the TRS-80 Model III, and ran all the software of these systems including games. It also had a built in speaker which was compatible with such games software.
Models.
Three models were sold. The first model (launched June 1982) looked like the later IBM PC (which came on the market years later), a rectangular base unit with two floppy drives on the front, and a monitor on top with a separate detachable keyboard. The second incarnation was a much smaller unit the width of two 5¼" floppy drives stacked on top of each other, and the third incarnation looked like a flattened Apple with a built-in keyboard.
All units ran much faster than the original TRS-80, at 4 MHz, (with a software selectable throttle to the original speed for compatibility purposes) and the display supported upper and lower case, hardware snow suppression (video ram bus arbitration logic), and an improved character font set. The floppy disk interface supported dual density, and disk capacities up to 800 KB, more than four times the capacity of the original TRS-80. A special version of NewDos/80, (an improved TRS-DOS compatible Disk operating system) was used to support these disk capacities when using the TRS-80 compatibility mode.
For the educational market a version of the first model was produced with a new plastic enclosure (the First Asters had an all-metal enclosure) that also had an opening on the top in which a cassette recorder could be placed. This model was used in a cluster with one Aster (with disk drives) for the teacher, and eight disk less versions for the pupils. The pupils could download software from the teachers computer through a network based on a fast serial connection, as well as sending back their work to the teachers computer. There was also hardware in place through which the teacher could see the display of each pupils screen on his own monitor.
Working modes.
The Aster used 64KB of RAM memory and had the unique feature of supporting two fundamentally different internal architectures: when turned on without a boot floppy or with a TRS-DOS floppy, the Aster would be fully TRS-80 compatible, with 48KB or RAM. When the boot loader detected a CP/M floppy, the Aster would reconfigure its internal memory architecture on the fly to optimally support CP/M with 60 KB free RAM for programs (TPA) and an 80 x 25 display. This dual-architecture capability only existed on one other TRS-80 clone, the LOBO Max-80.
With a special configuration tool, the CT-80 could reconfigure its floppy drivers to read and write the floppies of about 80 other CP/M systems.
A third mode was entered with a special boot floppy which turned the Aster into a Videotex terminal with a 40x25 display and a Videotex character set, The software used the built in RS232 interface of the Aster to control a modem through which it could contact a Prestel service provider.
Sales.
Most Aster CT-80's (about 10 thousand of them) were sold to schools for computer education, in a project first known as the "honderd scholen project" (one hundred schools project), but which later involved many more than just one hundred schools. MCP received this order from the Dutch government because their computer met all the technical and other demands, including the demand that the computers should be of Dutch origin and should be built in the Netherlands. Another important demand was that the computers could be used in a network (Aster developed special software and hardware for that). Later however the Government turned around and gave 50% of the order to Philips and their P2000 homecomputer even though the P2000 did not meet all the technical demands, was made in Austria and did not have network hard nor software.
The company.
Aster computers was based in the small town of Arkel near the town of Gorinchem.
Initially Aster computer b.v. was called MCP (Music print Computer Product), because it was specialized in producing computer assisted printing of sheet music. The director of the company was interested in Microprocessor technology and noticed there was a market for selling kits to computer building amateurs, so they started selling electronic kits to hobbyists, and employed four persons at that time . They also assembled kits for people without soldering skills, especially the "junior Computer" from Elektor (a copy of the KIM-1), and the ZX80 from Sinclair. Among the kits sold there were also alternative floppy disk drives for TRS-80 computers. But these needed the infamous TRS-80 expansion interface, which was very expensive, and had a very unreliable floppy disk controller because it used the WD1771 floppy disc controller chip without an external "data separator". To fix this problem MCP developed a small plugin board which could be plugged into the socket for the WD1771, and which contained a data separator, and a socket for the WD1791 to support dual-density operation. Still, the expansion interface was expensive and due to its design it was also unreliable. So they decided to also develop their own alternative in the form of an improved floppy disk controller and printer interface that could be built right into a floppy disk enclosure. The lack of RAM expansion offered by this solution was solved by a service in which the 16 KB RAM chips inside the base unit would be replaced by 64 KB RAM chips.
While this went on MCP renamed itself to "MCP CHIP" but ran into problems with the German computer magazine CHIP, and had to return to its former name. At that time MCP did also sell imported home computers like the TRS-80, the Video Genie, (another TRS-80 clone), the Luxor ABC 80 and the Apple II.
They also sold the exotic Olivetti M20, a very early 16 bit personal computer that was one of the very few systems to use a Z8000 CPU.
After designing their own fully functional replacement for the TRS-80 expansion interface (which was never commercialized) the company realized that they could do better than just re-designing the expansion interface. They observed that the TRS-80 was a great computer but it lacked in several areas. The display logic and resulting display 'snow' was irritating, as was the missing lower case support, the CPU speed could be improved, the quality and layout of the keyboard was bothersome, and the floppy disk capacity and reliability was low. Also the more interesting software offered for CP/M systems could not run well on a TRS-80. So they decided to designed a TRS-80 and CP/M software compatible computer system, which (following the lead of Apple Computer) they decided to name after a "typical Dutch flower". So they called it the Aster CT-80 (CP/M/Tandy-1980). Why they went with Aster, and not the more well known Tulip is unknown, perhaps they thought it would be to presumptuous, or perhaps the fact that "Aster" is also a Dutch girls name has something to do with it. Remarkably "Aster" was also the name given to a Dutch Supercomputer much later, in 2002.
The first version of the Aster consisted of four "Eurocard's", one Z80 CPU card with 64KB memory, one Motorola MC6845 based video card, one double density floppy disk controller card and one "keyboard/RS232/cassette interface" card. Plus a "backplane card", (which connected all the other cards) and a keyboard. And was intended for hobbyists, to be sold as a kit consisting of the parts and the PCB's for the computer and attached keyboard. After selling a few kits, MCP became convinced there was a much bigger market for an improved model sold as a completed working system. However the original kit version lacked many features that prevented its use as a serious computer system. Because the original designer had left the company another employee completely redesigned most of the system, (adding a display snow remover circuit, true 80/64 column text mode support, (with different size letters for TRS-80 and CP/M mode, so that in TRS-80 mode the full screen was also used, not just a 64x16 portion of the 80x25 screen) with an improved font set (adding "gray scale" version of the TRS-80 mozaik graphics and many special PETSCII like characters), and a more flexible and reliable floppy disk controller and keyboard interface plus many other small improvements), also an enclosure was developed for the main computer system, (in the form of a 19-inch rack for the Eurocards) and for two floppy disk drives and the power supply. A software engineer was hired to write the special "dual boot mode" BIOS and the special CP/M BIOS. The "dual boot mode" BIOS actually discovered whether a TRS-DOS, or Aster CP/M disk was placed in the drive, and would, depending on the type of disk, reorganise the internal memory architecture of the system, to either be 100% TRS-80 compatible or optimally support CP/M, with as much "workspace" as possible, and the 80x25 video mode. It also was responsible for switching to ROM BASIC when the system was turned on with the break key pressed, and later supported a primitive LAN system, using the RS232 port with modified cabling. The very first of the ready made computers were sold with the "kit" versions of the euro cards, the version with redesigned cards came a month or so later.
Soon the little shop became much too small and they moved to a much larger factory building nearby (formerly a window glass factory), and started mass-producing the Aster for a period of a few years, in which time its staff grew twentyfold.
After the Aster having been a few years on the Market Tandy released its own improved model, the TRS-80 Model III computer which solved many of the same problems that the Aster also had solved, but the model 3 still did not fully support CP/M as the Aster did. In the meantime IBM had released its original IBM PC, which incidentally looked remarkably like the Asters base with floppy drives + separate keyboard set-up.
The aster was chosen for Dutch schools by the Dutch ministry of education, in a set-up with eight disk-less Asters, and one Aster with high capacity floppy drives all connected by a LAN based on the Asters high-speed serial port hardware, and special cables that permitted that any single computer on the LAN could broadcast to all other computers. The floppy based system was operated by the teacher who could send programs from his floppy disk, and data, to the student's disk-less systems thanks to the special BIOS in those systems. The students could send programs and data back to the teacher through the same LAN, or could save to a cassette recorder built into the disk-less units. Through a special "video-switch" the teacher was also able to see a copy of each students display on his own screen. About a thousand of such systems were sold for many hundreds of Dutch schools.
Unfortunately, because of cash flow problems (resulting from growing too fast, insufficient financial backing, technical problems, and a sudden problem with Z80 processor deliveries) the company suddenly folded even before it came to full fruition.
Perhaps the Aster computer inspired another Dutch computer firm to name their computer after another typical Dutch flower — the Tulip's Tulip System-1 which appeared about the same time Aster folded.
Most of the engineers who designed the hardware and software of the Aster went on to design hardware and software for the (then new) MSX system for a company called "Micro Technology b.v.".
Unreleased add ons.
To enhance and modernize the Aster CT-80 the company also designed three alternative video display adapters to supplement or replace the TRS-80 compatible video card, (due to the modular nature of the Aster it was simply a matter of changing the video card, and/or CPU card to upgrade the system).
A hard disk interface was also in the works, which would, add a SCSI interface, and the necessary software. A working prototype was developed that added a 40MB hard disk.
On the software front, work was being done to implement the replacement for the aging "user interface" of CP/M, (the Command Console Processor CCP ) with the more modern ZCPR.
Finally a replacement for the aging Z80 processor was being developed in the form of an Intel 8086 board, and additional 512K 16 bit memory boards. Such replacements of CPU and memory system components were possible because the Aster CT-80 was designed to use a backplane that was designed to support both 8 and 16 bit processors, and used a modular Eurocard based design with slots to spare for expansion. In theory the system could support the Z80 and the 8086 simultaneously. Plans were formulated to support CP/M-86 and even MS-DOS.
Unfortunately none of these extensions to the system became available because the company folded before any of them could be released.

</doc>
<doc id="2138" url="https://en.wikipedia.org/wiki?curid=2138" title="Arthur Wellesley">
Arthur Wellesley

Arthur Wellesley may refer to:

</doc>
<doc id="2139" url="https://en.wikipedia.org/wiki?curid=2139" title="List of animated television series">
List of animated television series

These are lists of animated television series. Animated television series are television programs produced by means of animation. Animated series produced for theaters are not included in this lists; for those, see List of animated short series. These lists include compilation series of theatrical shorts such as "The Bugs Bunny Show" since they often feature some new wrap-around animation.

</doc>
<doc id="2140" url="https://en.wikipedia.org/wiki?curid=2140" title="Atlanta Braves">
Atlanta Braves

The Atlanta Braves are an American professional baseball franchise based in Atlanta, Georgia since 1966. The team originated in Boston and played for many decades there before playing in Milwaukee for a little more than a decade. The franchise is a member of the East division of the National League (NL) in Major League Baseball (MLB). The Braves have played home games at Turner Field since 1997, and play spring training games in Lake Buena Vista, Florida. In 2017, the team is to move to SunTrust Park, a new stadium complex in the Cumberland district of Cobb County just north of the I-285 bypass.
The "Braves" name, which was first used in 1912, originates from a term for an Indian warrior. They are nicknamed "the "Bravos"", and often referred to as "America's Team" in reference to the team's games being broadcast on the nationally available TBS from the 1970s until 2007, giving the team a nationwide fan base.
From 1991 to 2005 the Braves were one of the most successful franchises in baseball, winning division titles an unprecedented 14 consecutive times in that period (omitting the strike-shortened 1994 season in which there were no official division champions). The Braves won the NL West 1991–93 and the NL East 1995–2005, and they returned to the playoffs as the National League Wild Card in 2010. The Braves advanced to the World Series five times in the 1990s, winning the title in 1995. Since their debut in the National League in 1876, the franchise has won 16 divisional titles, 17 National League pennants, and three World Series championships—in 1914 as the Boston Braves, in 1957 as the Milwaukee Braves, and in 1995 in Atlanta. The Braves are the only Major League Baseball franchise to have won the World Series in three different home cities.
The club is one of the National League's two remaining charter franchises (the other being the Chicago Cubs) and was founded in Boston in 1871 as the Boston Red Stockings (not to be confused with the American League's Boston Red Sox). They are considered "the oldest continuously playing team in major North American sports." There is an argument as to which team is actually older, because, although the Cubs are a full season "older" (formed as the Chicago White Stockings in 1870), Chicago did not sponsor a White Stockings team for two seasons due to the Great Chicago Fire; therefore, the Braves have played more consecutive seasons.
After various name changes, the team eventually began operating as the Boston Braves, which lasted for most of the first half of the 20th century. Then, in 1953, the team moved to Milwaukee, Wisconsin and became the Milwaukee Braves, followed by the final move to Atlanta in 1966. The team's tenure in Atlanta is noted for Hank Aaron breaking Babe Ruth's career home run record in 1974.
History.
Boston (1871–1952).
1870–1913.
The Cincinnati Red Stockings, established in 1869 as the first openly all-professional baseball team, voted to dissolve after the 1870 season. Player-manager Harry Wright, with brother George and two other Cincinnati players, then went to Boston, Massachusetts at the invitation of Boston Red Stockings founder Ivers Whitney Adams to form the nucleus of the "Boston Red Stockings", a charter member of the National Association of Professional Base Ball Players (NAPBBP). The original Boston Red Stockings team and its successors can lay claim to being the oldest continuously playing team in American professional sports. (The only other team that has been organized as long, the Chicago Cubs, did not play for the two years following the Great Chicago Fire of 1871.) Two young players hired away from the Forest City club of Rockford, Illinois, turned out to be the biggest stars during the NAPBBP years: pitcher Al Spalding (founder of Spalding sporting goods) and second baseman Ross Barnes.
Led by the Wright brothers, Barnes, and Spalding, the Red Stockings dominated the National Association, winning four of that league's five championships. The team became one of the National League's charter franchises in 1876, sometimes called the ""Red Caps"" (as a new Cincinnati Red Stockings club was another charter member). Boston came to be called the "Beaneaters" in 1883, while retaining red as the team color.
The Boston Red Caps played in the first game in the history of the National League, on Saturday, April 22, 1876, defeating the Athletics, 6-5.
Although somewhat stripped of talent in the National League's inaugural year, Boston bounced back to win the 1877 and 1878 pennants. The Red Caps/Beaneaters were one of the league's dominant teams during the 19th century, winning a total of eight pennants. For most of that time, their manager was Frank Selee. The 1898 team finished 102–47, a club record for wins that would stand for almost a century. Stars of those 1890s Beaneater teams included the "Heavenly Twins", Hugh Duffy and Tommy McCarthy, as well as "Slidin'" Billy Hamilton.
The team was decimated when the American League's new Boston entry set up shop in 1901. Many of the Beaneaters' stars jumped to the new team, which offered contracts that the Beaneaters' owners did not even bother to match. They only managed one winning season from 1900 to 1913, and lost 100 games five times. In 1907, the Beaneaters (temporarily) eliminated the last bit of red from their stockings because their manager thought the red dye could cause wounds to become infected (as noted in "The Sporting News Baseball Guide" during the 1940s when each team's entry had a history of its nickname(s). The American League club's owner, Charles Taylor, wasted little time in adopting Red Sox as his team's first official nickname (up to that point they had been called by the generic "Americans"). Media-driven nickname changes to the "Doves" in 1907 and the "Rustlers" in 1911 did nothing to change the National League club's luck. The team became the "Braves" for the first time in 1912. Their owner, James Gaffney, was a member of New York City's political machine, Tammany Hall, which used an Indian chief as their symbol.
1914: Miracle.
Two years later, the Braves put together one of the most memorable seasons in baseball history. After a dismal 4–18 start, the Braves seemed to be on pace for a last place finish. On July 4, 1914, the Braves lost both games of a doubleheader to the Brooklyn Dodgers. The consecutive losses put their record at 26–40 and the Braves were in last place, "15 games" behind the league-leading New York Giants, who had won the previous three league pennants. After a day off, the Braves started to put together a hot streak, and from July 6 through September 5, the Braves went 41–12. On September 7 and 8, the Braves took two of three from the New York Giants and moved into first place. The Braves tore through September and early October, closing with 25 wins against six losses, while the Giants went 16–16. They were the only team, under the old eight-team league format, to win a pennant after being in last place on the Fourth of July. They were in last place as late as July 18, but were close to the pack, moving into fourth on July 21 and second place on August 12.
Despite their amazing comeback, the Braves entered the World Series as a heavy underdog to Connie Mack's Philadelphia A's. Nevertheless, the Braves swept the Athletics—the first unqualified sweep in the young history of the modern World Series (the 1907 Series had one tied game) to win the world championship. Meanwhile, Johnny Evers won the Chalmers Award.
The Braves played the World Series (as well as the last few games of the 1914 season) at Fenway Park, since their normal home, the South End Grounds, was too small. However, the Braves' success inspired owner Gaffney to build a modern park, Braves Field, which opened in August 1915. It was the largest park in the majors at the time, with 40,000 seats and a very spacious outfield. The park was novel for its time; public transportation brought fans right to the park.
1915–1953.
After contending for most of 1915 and 1916, the Braves only twice posted winning records from 1917 to 1932. The lone highlight of those years came when Judge Emil Fuchs bought the team in 1923 to bring his longtime friend, pitching great Christy Mathewson, back into the game. However, Mathewson died in 1925, leaving Fuchs in control of the team.
Fuchs was committed to building a winner, but the damage from the years prior to his arrival took some time to overcome. The Braves finally managed to be competitive in 1933 and 1934 under manager Bill McKechnie, but Fuchs' revenue was severely depleted due to the Great Depression.
Looking for a way to get more fans and more money, Fuchs worked out a deal with the New York Yankees to acquire Babe Ruth, who had started his career with the Red Sox. Fuchs made Ruth team vice president, and promised him a share of the profits. He was also granted the title of assistant manager, and was to be consulted on all of the Braves' deals. Fuchs even suggested that Ruth, who had long had his heart set on managing, could take over as manager once McKechnie stepped down—perhaps as early as 1936.
At first, it appeared that Ruth was the final piece the team needed in 1935. On opening day, he had a hand in all of the Braves' runs in a 4–2 win over the Giants. However, that proved to be the only time the Braves were over .500 all year. Events went downhill quickly. While Ruth could still hit, he could do little else. He could not run, and his fielding was so terrible that three of the Braves' pitchers threatened to go on strike if Ruth were in the lineup. It soon became obvious that he was vice president and assistant manager in name only and Fuchs' promise of a share of team profits was hot air. In fact, Ruth discovered that Fuchs expected him to invest some of "his" money in the team.
Seeing a franchise in complete disarray, Ruth retired on June 1—only six days after he clouted what turned out to be the last three home runs of his career. He had wanted to quit as early as May 12, but Fuchs wanted him to hang on so he could play in every National League park. The Braves finished 38–115, the worst season in franchise history. Their .248 winning percentage is the third-worst in baseball history, and the second-worst in National League history (behind only the 1899 Cleveland Spiders).
Fuchs lost control of the team in August 1935, and the new owners tried to change the team's image by renaming it the "Boston Bees". This did little to change the team's fortunes. After five uneven years, a new owner, construction magnate Lou Perini, changed the nickname back to the Braves. He immediately set about rebuilding the team. World War II slowed things down a little, but the team rode the pitching of Warren Spahn to impressive seasons in 1946 and 1947.
In 1948, the team won the pennant, behind the pitching of Spahn and Johnny Sain, who won 39 games between them. The remainder of the rotation was so thin that in September, "Boston Post" writer Gerald Hern wrote this poem about the pair:
The poem received such a wide audience that the sentiment, usually now paraphrased as ""Spahn and Sain and pray for rain"", entered the baseball vocabulary. However, in the 1948 season, the Braves actually had the same record in games that Spahn and Sain started that the team had overall, in terms of winning percentage.
The 1948 World Series, which the Braves lost in six games to the Indians, turned out to be the Braves' last hurrah in Boston. In 1950, Sam Jethroe became the team's first African American player, making his major league debut on April 18. Amid four mediocre seasons, attendance steadily dwindled until, on March 13, 1953, Perini, who had recently bought out his original partners, announced he was moving the team to Milwaukee, where the Braves had their top farm club, the Brewers. Milwaukee had long been a possible target for relocation. Bill Veeck had tried to return his St. Louis Browns there earlier the same year (Milwaukee was the original home of that franchise), but his proposal had been voted down by the other American League owners.
Milwaukee (1953–1965).
Milwaukee went wild over the Braves, who were welcomed as genuine heroes. The Braves finished 92–62 in their first season in Milwaukee, and drew a then-NL record 1.8 million fans. The success of the team was noted by many owners. Not coincidentally, the Philadelphia Athletics, St. Louis Browns, Brooklyn Dodgers, and New York Giants would leave their original hometowns within the next five years.
As the 1950s progressed, the reinvigorated Braves became increasingly competitive. Sluggers Eddie Mathews and Hank Aaron drove the offense (they would hit a combined 1,226 home runs as Braves, with 850 of those coming while the franchise was in Milwaukee), often aided by another power hitter, Joe Adcock, while Warren Spahn, Lew Burdette, and Bob Buhl anchored the rotation. The 1956 Braves finished second, only one game behind the Brooklyn Dodgers.
In 1957, the Braves celebrated their first pennant in nine years spearheaded by Aaron's MVP season, as he led the National League in home runs and RBI. Perhaps the most memorable of his 44 round-trippers that season came on September 23, a two-run walk-off home run that gave the Braves a 4–2 victory over the St. Louis Cardinals and clinched the League championship. The team then went on to its first World Series win in over 40 years, defeating the powerful New York Yankees of Berra, Mantle, and Ford in seven games. One-time Yankee Burdette, the Series MVP, threw three complete game victories against his former team, giving up only two earned runs.
In 1958, the Braves again won the National League pennant and jumped out to a three games to one lead in the World Series against the New York Yankees once more, thanks in part to the strength of Spahn's and Burdette's pitching. But the Yankees stormed back to take the last three games, in large part to World Series MVP Bob Turley's pitching.
The 1959 season saw the Braves finish the season in a tie with the Los Angeles Dodgers, both with 86-68 records. Many residents of Chicago and Milwaukee were hoping for a Sox-Braves Series, as the cities are only about apart, but it was not to be because Milwaukee fell in a best-of-3 playoff with two straight losses to the Dodgers. The Dodgers would go on to defeat the Chicago White Sox in the World Series.
The next six years were up-and-down for the Braves. The 1960 season featured two no-hitters by Burdette and Spahn, and Milwaukee finished seven games behind the Pittsburgh Pirates, who ultimately were to win the World Series that year, in second place, one year after the Braves were on the winning end of the 13-inning near-perfect game of Pirates pitcher Harvey Haddix. The 1961 season saw a drop in the standings for the Braves down to fourth, despite Spahn recording his 300th victory and pitching another no-hitter that year.
Aaron hit 45 home runs in 1962, a Milwaukee career high for him, but this did not translate into wins for the Braves, as they finished fifth. The next season, Aaron again hit 44 home runs and notched 130 RBI, and Spahn was once again the ace of the staff, going 23–7. However, none of the other Braves produced at that level, and the team finished in the lower half of the league, or "second division", for the first time in its short history in Milwaukee.
The Braves were somewhat mediocre as the 1960s began, but fattened up on the expansion New York Mets and Houston Colt .45s. To this day, the Milwaukee Braves are the only major league team who played more than one season and never had a losing record.
Perini sold the Braves to a Chicago-based group led by William Bartholomay in 1962. Almost immediately Bartholomay started shopping the Braves to a larger television market. Keen to attract them, the fast-growing city of Atlanta, led by Mayor
Ivan Allen, Jr. constructed a new $18 million, 52,000-seat ballpark in less than one year, Atlanta Stadium, which was officially opened in 1965 in hopes of luring an existing major league baseball and/or NFL/AFL team. After the city failed to lure the Kansas City A's to Atlanta (the A's would move to Oakland in 1968), the Braves announced their intention to move to Atlanta for the 1965 season. However, an injunction filed in Wisconsin kept the Braves in Milwaukee for one final year. In 1966, the Braves completed the move to Atlanta.
Eddie Mathews is the only Braves player to have played for the organization in all three cities that they have been based in. Mathews played with the Braves for their last season in Boston, the team's entire tenure in Milwaukee, and their first season in Atlanta.
Atlanta.
1966–1974.
The Braves were a .500 team in their first few years in Atlanta; 85–77 in 1966, 77–85 in 1967, and 81–81 in 1968. The 1967 season was the Braves' first losing season since 1952, their last year in Boston. In 1969, with the onset of divisional play, the Braves won the first-ever National League West Division title, before being swept by the "Miracle Mets" in the National League Championship Series. They would not be a factor during the next decade, posting only two winning seasons between 1970 and 1981 – in some cases, fielding teams as bad as the worst Boston teams.
In the meantime, fans had to be satisfied with the achievements of Hank Aaron. In the relatively hitter-friendly confines and higher-than-average altitude of Atlanta Stadium ("The Launching Pad"), he actually increased his offensive production. Atlanta also produced batting champions in Rico Carty (in 1970) and Ralph Garr (in 1974). In the shadow of Aaron's historical home run pursuit, was the fact that three Atlanta sluggers hit 40 or more home runs in 1973 – Darrell Evans, Davey Johnson and, of course, Aaron.
By the end of the 1973 season, Aaron had hit 713 home runs, one short of Ruth's record. Throughout the winter he received racially motivated death threats, but stood up well under the pressure. The next season, it was only a matter of time before he set a new record. On April 4, opening day, he hit No.714 in Cincinnati, and on April 8, in front of his home fans and a national television audience he finally beat Ruth's mark with a home run to left-center field off left-hander Al Downing of the Los Angeles Dodgers. Aaron spent most of his career as a Milwaukee and Atlanta Brave before asking to be traded to the Milwaukee Brewers, while Ruth finished his career as a Boston Brave. In fact, until Barry Bonds eclipsed the 714 home runs hit by Babe Ruth in 2006, the top two home run hitters in Major League history had at one time been Braves.
1976–77: Ted Turner buys the team.
In 1976, the team was purchased by media magnate Ted Turner, owner of superstation WTBS, as a means to keep the team (and one of his main programming staples) in Atlanta. The financially strapped Turner used money already paid to the team for their broadcast rights as a down-payment. It was then that Atlanta Stadium was renamed Atlanta–Fulton County Stadium. Turner quickly gained a reputation as a quirky, hands-on baseball owner. On May 11, 1977, Turner appointed himself manager, but because MLB passed a rule in the 1950s barring managers from holding a financial stake in their teams, Turner was ordered to relinquish that position after one game (the Braves lost 2–1 to the Pittsburgh Pirates to bring their losing streak to 17 games).
Turner used the Braves as a major programming draw for his fledgling cable network, making the Braves the first franchise to have a nationwide audience and fan base. WTBS marketed the team as "The Atlanta Braves: America's Team", a nickname that still sticks in some areas of the country, especially the South. Among other things, in 1976 Turner suggested the nickname "Channel" for pitcher Andy Messersmith and jersey number 17, in order to promote the television station that aired Braves games. Major League Baseball quickly nixed the idea.
1978–1990.
After three straight losing seasons, Bobby Cox was hired for his first stint as manager for the 1978 season. He promoted 22-year-old slugger Dale Murphy into the starting lineup. Murphy hit 77 home runs over the next three seasons, but he struggled on defense, unable to adeptly play either catcher or first base. In 1980, Murphy was moved to center field and demonstrated excellent range and throwing ability, while the Braves earned their first winning season since 1974. Cox was fired after the 1981 season and replaced with Joe Torre, under whose leadership the Braves attained their first divisional title since 1969. Strong performances from Bob Horner, Chris Chambliss, pitcher Phil Niekro, and short relief pitcher Gene Garber helped the Braves, but no Brave was more acclaimed than Murphy, who won both a Most Valuable Player and a Gold Glove award. Murphy also won an MVP award the following season, but the Braves began a period of decline that defined the team throughout the 1980s. Murphy, excelling in defense, hitting, and running, was consistently recognized as one of the league's best players, but the Braves averaged only 65 wins per season between 1985 and 1990. Their lowest point came in 1988, when they lost 106 games. The 1986 season saw the return of Bobby Cox as general manager. Also in 1986, the team stopped using their Indian-themed mascot, Chief Noc-A-Homa.
1991–2004: Division dominance.
1991–1994.
Cox returned to the dugout as manager in the middle of the 1990 season, replacing Russ Nixon. The Braves finished the year with the worst record in baseball, at 65–97. They traded Dale Murphy to the Philadelphia Phillies after it was clear he was becoming a less dominant player. Pitching coach Leo Mazzone began developing young pitchers Tom Glavine, Steve Avery, and John Smoltz into future stars. That same year, the Braves used the number one overall pick in the 1990 MLB draft to select Chipper Jones, who became one of the best hitters in team history. Perhaps the Braves' most important move was not on the field, but in the front office. Immediately after the season, John Schuerholz was hired away from the Kansas City Royals as general manager.
The following season, Glavine, Avery, and Smoltz would be recognized as the best young pitchers in the league, winning 52 games among them. Meanwhile, behind position players David Justice, Ron Gant and unexpected league Most Valuable Player and batting champion Terry Pendleton, the Braves overcame a 39–40 start, winning 55 of their final 83 games over the last three months of the season and edging the Los Angeles Dodgers by one game in one of baseball's more memorable playoff races. The "Worst to First" Braves, who had not won a divisional title since 1982, captivated the city of Atlanta (and the entire southeast) during their improbable run to the flag. They defeated the Pittsburgh Pirates in a very tightly contested seven-game NLCS only to lose the World Series, also in seven games, to the Minnesota Twins. The series, considered by many to be one of the greatest ever, was the first time a team that had finished last in its division one year went to the World Series the next; both the Twins and Braves accomplished the feat.
Despite the 1991 World Series loss, the Braves' success would continue. In 1992, the Braves returned to the NLCS and once again defeated the Pirates in seven games, culminating in a dramatic game seven win. Francisco Cabrera's two-out single that scored David Justice and Sid Bream capped a three-run rally in the bottom of the ninth inning that gave the Braves a 3–2 victory. It was the first time in post season history that the tying and winning runs had scored on a single play in the ninth inning. The Braves lost the World Series to the Toronto Blue Jays, however. In 1993, the Braves signed Cy Young Award winning pitcher Greg Maddux from the Chicago Cubs, leading many baseball insiders to declare the team's pitching staff the best in baseball. The 1993 team posted a franchise-best 104 wins after a dramatic pennant race with the San Francisco Giants, who won 103 games. The Braves needed a stunning 55–19 finish to edge out the Giants, who led the Braves by nine games in the standings as late as August 11. However, the Braves fell in the NLCS to the Philadelphia Phillies in six games.
In 1994, in a realignment of the National League's divisions following the 1993 expansion, the Braves moved to the Eastern Division. This realignment was the main cause of the team's heated rivalry with the New York Mets during the mid-to-late 1990s.
The player's strike cut short the 1994 season, prior to the division championships, with the Braves six games behind the Montreal Expos with 48 games left to play.
1995–2004.
The Braves returned strong the following strike-shortened (144 games instead of the customary 162) year and beat the Cleveland Indians in the 1995 World Series. This squelched claims by many Braves critics that they were the "Buffalo Bills of Baseball" (January 1996 issue of "Beckett Baseball Card Monthly"). With this World Series victory, the Braves became the first team in Major League Baseball to win world championships in three different cities. With their strong pitching as a constant, the Braves appeared in the and 1999 World Series (losing both to the New York Yankees, managed by Joe Torre, a former Braves manager), and had a streak of division titles from 1991 to 2005 (three in the Western Division and eleven in the Eastern) interrupted only in 1994 when the strike ended the season early. Pitching was not the only constant in the Braves organization —Cox was the Braves' manager, while Schuerholz remained the team's GM until after the 2007 season when he was promoted to team president. Terry Pendleton finished his playing career elsewhere, but returned to the Braves system as the hitting coach.
In October 1996, Time Warner acquired Ted Turner's Turner Broadcasting System and all of its assets, including its cable channels and the Atlanta Braves. Over the next few years, Ted Turner's presence as owner of the team would diminish.
A 95–67 record in produced a ninth consecutive division title. However, a sweep by the St. Louis Cardinals in the National League Division Series prevented the Braves from reaching the NL Championship Series.
In 2001, Atlanta won the National League East division yet again, swept the Houston Astros in the NLDS, then lost to the Arizona Diamondbacks in the National League Championship Series four games to one. One memorable game the Braves played that year came on September 21, when they played rival New York Mets in the first major professional sporting event held in New York City since 9/11.
In 2002, 2003 and 2004, the Braves won the Eastern division again, but lost in the NLDS in all three years in the same fashion: 3 games to 2 to the San Francisco Giants, Chicago Cubs, and Houston Astros.
Cy Young dominance.
Six National League Cy Young Awards in the 1990s were awarded to three Braves pitchers:
2005: A new generation.
In 2005, the Braves won the Division championship for the 14th consecutive time from 1991 to 2005. 14 consecutive division titles stands as the record for all major league baseball. The 2005 title marked the first time any MLB team made the postseason with more than 4 rookies who each had more than 100 ABs (Wilson Betemit, Brian McCann, Pete Orr, Ryan Langerhans, Jeff Francoeur). Catcher Brian McCann, right fielder Jeff Francoeur, and pitcher Kyle Davies all grew up in the suburbs of Atlanta. The large number of rookies to debut in 2005 were nicknamed the "Baby Braves" by fans and became an Atlanta-area sensation, helping to lead the club to a record of 90–72.
However, the season would end on a sour note as the Braves lost the National League Division Series to the Astros in four games. In Game 4, with the Braves leading by 5 in the eighth inning, the Astros battled back with a Lance Berkman grand slam and a two-out, ninth inning Brad Ausmus home run off of Braves closer Kyle Farnsworth. The game did not end until the 18th inning, becoming the longest game in playoff history at 5 hours 50 minutes. Chris Burke ended the marathon with a home run off of Joey Devine.
After the 2005 season, the Braves lost their long-time pitching coach Leo Mazzone, who left to go to the Baltimore Orioles. Roger McDowell took his place in the Atlanta dugout. Unable to re-sign shortstop Rafael Furcal, the Braves acquired shortstop Edgar Rentería from the Boston Red Sox.
2006: Struggles.
In 2006, the Braves did not perform at the level they had grown accustomed to. Due to an offensive slump, injuries to their starting rotation, and subpar bullpen performances, the Braves compiled a 6–21 record during June, the worst month ever in Atlanta with a winning percentage of .222; this was only better than the woeful Boston Braves in May 1935 (4–20) with a .166 winning percentage.
The Braves made their move in July, going 14–10. However, the team remained in the bottom half of the NL East and trailed the Mets by a double-digit deficit for much of the season (13 games at the All-Star Break). However, despite their struggles, the Braves entered the break down by only 6½ games to the Dodgers for the NL Wild Card slot after winning seven of their last ten games.
After the break, the Braves came out with their bats swinging, setting many franchise records. They won five straight, sweeping the Padres and taking two from the Cardinals, tallying a total of 65 runs in that span. The 65 runs in five games is the best by the franchise since 1897, when the Boston Beaneaters totaled 78, including 25 in one game and 21 in another, from May 31 – June 3; the 2006 Braves also became the first team since the 1930 New York Yankees to score ten runs or more in five straight games. The Braves had a total of 81 hits during their five-game run and 98 hits in their last six games, going back to an 8–3 victory over Cincinnati on July 9, the last game before the All-Star break. Additionally, Chipper Jones was able to maintain a 20-game hitting streak and tie Paul Waner's 69-year-old Major League record with a 14-game extra-base hit streak.
The Braves made their first trade of the season on July 20 to shore up the bullpen, sending Class A Rome catcher Max Ramirez to Cleveland for closer Bob Wickman. He served as the Braves' closer for the remainder of the season, taking over for an embattled Jorge Sosa, who was subsequently traded on the July 31 trade deadline for St. Louis minor league pitcher Rich Scalamandre.
On July 29, the Braves traded reserve third baseman/shortstop Wilson Betemit to the Los Angeles Dodgers for reliever Danys Báez and infielder Willy Aybar. The move came on the night that starting third baseman Chipper Jones went on the 15-day disabled list with a strained oblique muscle. With Betemit gone, Atlanta called up infielder Tony Peña, Jr. from AAA Richmond to supplement Pete Orr.
Before the expansion of rosters on September 1, the Braves acquired Daryle Ward from the Washington Nationals for Class A Myrtle Beach pitcher Luis Atilano, in hopes that he would be a valuable pinch-hitter in the postseason.
However, on September 18, the New York Mets' win over the Florida Marlins mathematically eliminated the Braves from winning the NL East, ending the Atlanta Braves' 11-year reign over the NL East. On September 24, the Braves' loss to the Colorado Rockies mathematically eliminated the Braves from winning the NL Wild Card, making 2006 the first year that the Braves would not compete in the postseason since 1990, not counting the strike-shortened 1994 season.
Also, a loss to the Mets on September 28 guaranteed the Braves their first losing season since 1990. Although the Braves won two of their last three games against the Astros, including rookie Chuck James besting Roger Clemens, Atlanta finished the season in third place, one game ahead of the Marlins, at 79–83.
After the season, the Atlanta coaching staff underwent a few changes. Brian Snitker became the third base coach after Fredi González left to become the manager for the Florida Marlins. Chino Cadahia replaced Pat Corrales as bench coach and former catcher Eddie Pérez became the new bullpen coach, replacing Bobby Dews.
Sale to Liberty Media.
In December 2005, team owner Time Warner, who inherited the Braves after purchasing TBS in 1996, announced it was placing the team for sale. Liberty Media began negotiations to purchase the team.
In February 2007, after more than a year of negotiations, Time Warner agreed to a deal that would sell the Braves to Liberty Media Group (a company which owned a large amount of stock in Time Warner, Inc.), pending approval by 75 percent of MLB owners and the Commissioner of Baseball, Bud Selig. The deal included the exchange of the Braves, valued in the deal at $450 million, a hobbyist magazine publishing company, and $980 million cash, for 68.5 million shares of Time Warner stock held by Liberty Media, then worth approximately $1.48 billion. Team President Terry McGuirk anticipated no change in the current front office structure, personnel, or day-to-day operations of the Braves. Liberty Media is not expected to take any type of "active" ownership in terms of day-to-day operations.
On May 16, 2007, Major League Baseball's owners approved the sale of the Braves from Time Warner to Liberty Media. The Braves are one of three Major League Baseball teams under corporate ownership (and the only NL team with this distinction); the other two franchises are the American League (AL)'s Seattle Mariners (which are owned by Nintendo of America) and the Toronto Blue Jays (which are owned by Rogers Communications).
2007: More struggles.
The Braves made their first moves by re-signing Bob Wickman to a one-year deal and picking up John Smoltz's option in September 2006. They traded starting pitcher Horacio Ramírez to the Seattle Mariners for pitcher Rafael Soriano, an American League reliever with a 2.20 ERA in 2006. They also denied arbitration to pitcher Chris Reitsma and second baseman Marcus Giles. The Braves signed utility-man Chris Woodward to fill a spot on the bench. The biggest trade in the offseason involved first baseman Adam LaRoche and a minor league player for Pittsburgh Pirates closer Mike González and a minor league infielder, Brent Lillibridge. Gonzalez, who converted 24 of 24 save opportunities in 2006, joined Soriano as a set-up man for Wickman in the bullpen. The team then signed Craig Wilson to a one-year deal to platoon with Scott Thorman. The Braves also had solid relievers in Macay McBride, Blaine Boyer, and Tyler Yates. In addition, the majority of the Braves' offense, which was second in the NL in runs scored in 2006, returned in 2007. However, Mike Hampton was sidelined for the entire 2007 season with yet another surgery. Mike González was later sidelined for the season while recovering from Tommy John surgery.
The Braves' bullpen and offense came through in the clutch early on, helping the Braves to a 7–1 start, their best start since winning the World Series in 1995. The team finished April with a 16–9 record, but struggled during May, finishing 14–14. The Braves also struggled during interleague play, finishing with an NL-worst 4–11 record. On June 24, the Braves fell to .500 for the first time in the 2007 season, but rebounded by winning the next 5 games.
On July 5, Chipper Jones surpassed Dale Murphy for the Atlanta club record of 372 home runs by belting two against the Los Angeles Dodgers. On July 31, 2007, the Braves finalized the deal to acquire slugger first baseman Mark Teixeira and LHP Ron Mahay from the Texas Rangers for catcher Jarrod Saltalamacchia, SS Elvis Andrus, and three minor-leaguers. The Braves also acquired Octavio Dotel from the Kansas City Royals for Kyle Davies and also traded LHP Wilfredo Ledezma and RHP Will Startup to the San Diego Padres for Royce Ring. On August 19, 2007 John Smoltz passed Phil Niekro for 1st place on the Braves' all-time strikeout list. Braves manager Bobby Cox broke the all-time MLB record for most career ejections by a manager in August 2007.
After struggling during the second half of the 2007 season, Atlanta finished over .500 and missed the post season again. On October 12, 2007, John Schuerholz stepped down as General Manager to take over as team president. Assistant GM Frank Wren took over as General Manager.
2008: Plagued by injuries.
In December 2007, the team announced it would not re-sign center fielder Andruw Jones (who later would sign with the Dodgers). Another major move was acquiring CF Gorkys Hernández and RHP Jair Jurrjens from the Detroit Tigers in exchange for SS Edgar Rentería and cash considerations. Next, LHP Tom Glavine was signed to a one-year contract. They also acquired LHP Will Ohman and INF Omar Infante from the Cubs in exchange for RHP José Ascanio.
The team's first new move for 2008 was acquiring OF Mark Kotsay from the A's (to replace Jones) in exchange for RHP Joey Devine, RHP Jamie Richmond and cash considerations. Days later, Wren traded Willy Aybar, outfielder Tom Lindsey, and infielder Chase Fontaine to the Rays in exchange for left-hand reliever Jeff Ridgway.
Before the trade deadline the Braves traded 1B Mark Teixeira to the Los Angeles Angels for first baseman Casey Kotchman and minor league RHP Stephen Marek. The Braves failed to make the playoffs for the third straight season.
2009: The return of solid pitching.
On December 4, 2008, the Atlanta Braves received Javier Vázquez and Boone Logan, while the Chicago White Sox received prospects catcher Tyler Flowers, shortstop Brent Lillibridge, third baseman Jon Gilmore and pitcher Santos Rodriguez. On January 13, 2009, the Braves signed Japanese pitcher Kenshin Kawakami to a three-year deal, and two days later signed free agent pitcher Derek Lowe to a four-year contract. During the course of the offseason, the Braves signed veteran pitcher and former Brave Tom Glavine, while losing long-time Brave John Smoltz to the Boston Red Sox.
On February 25, 2009, just before the start of spring training, Atlanta agreed to terms on a one-year contract with free-agent outfielder Garret Anderson. The additional outfield depth allowed the Braves to trade Josh Anderson to the Detroit Tigers for minor league pitcher Rudy Darrow on March 30, 2009.
On June 3, 2009, the Braves acquired Nate McLouth from the Pittsburgh Pirates for prospects Jeff Locke, Charlie Morton and Gorkys Hernández. They also released veteran pitcher Tom Glavine. On July 10, 2009, the Braves traded outfielder Jeff Francoeur to the New York Mets for outfielder Ryan Church. On July 31, 2009, hours before the trade deadline, the Braves and Boston Red Sox swapped 1st basemen: Atlanta dealt Casey Kotchman to Boston and reacquired Adam LaRoche, whom the Braves had traded away during the 2006–07 off-season to Pittsburgh.
The Braves made a late-season surge, coming within 2 games of the wild card leading Colorado Rockies in late September. On October 1, 2009 with the Braves four games back, Colorado beat the Milwaukee Brewers 9–2 to clinch the wild card spot and end the Braves' 2009 postseason hopes.
2010: Cox's final season.
The 2010 Atlanta Braves Season features the Braves' attempt to reclaim a postseason berth for the first time since 2005. The Braves were once again skippered by Bobby Cox, now in his 25th and final season managing the team. The Braves started the 2010 season slowly and had a nine-game losing streak in April. Then they had a nine-game winning streak from May 26 through June 3, the Braves longest since 2000 when they won 16 in a row. On May 31, the Atlanta Braves defeated the then-first place Philadelphia Phillies at Turner Field to take sole possession of first place in the National League East standings, a position they had maintained through the middle of August. The last time the Atlanta Braves led the NL East on August 1 was in 2005. On July 13, 2010 at the 2010 MLB All-Star Game in Anaheim, Braves catcher Brian McCann was awarded the All-Star Game MVP Award for his clutch two-out, three-run double in the seventh inning to give the National League its first win in the All-Star Game since 1996. He became the first Brave to win the All-Star Game MVP Award since Fred McGriff did so in 1994. The Braves made two deals before the trade deadline to acquire Álex González, Rick Ankiel and Kyle Farnsworth from the Toronto Blue Jays and Kansas City Royals, giving up shortstop Yunel Escobar, pitchers Jo-Jo Reyes and Jesse Chavez, outfielder Gregor Blanco and three minor leaguers. On August 18, 2010 they traded three pitching prospects for first baseman Derrek Lee from the Chicago Cubs. On August 22, 2010 against the Chicago Cubs, Mike Minor struck out 12 batters across 6 innings; an Atlanta Braves single game rookie strikeout record. The Braves dropped to second in the NL East in early September, but won the NL Wild Card. They lost to the San Francisco Giants in the National League Division Series in four games. Every game of the series was determined by one run. After the series-clinching victory for the Giants in Game 4, Bobby Cox was given a standing ovation by the fans, also by players and coaches of both the Braves and Giants.
2011: Fredi González takes over.
On October 13, 2010, the Atlanta Braves announced that Fredi González would replace long-time Braves manager Bobby Cox as manager of the team in 2011. The announcement came just two days after the 2010 Braves were eliminated from the postseason. It was also announced that pitching coach Roger McDowell, third-base coach Brian Snitker, and bullpen coach Eddie Pérez would retain their current positions, while former hitting coach Terry Pendleton would replace Glenn Hubbard as the first-base coach and newcomer Carlos Tosca would become the new bench coach. Hubbard and former bench coach Chino Cadahia were not offered positions on the new coaching staff. Larry Parrish was hired as hitting coach on October 29, 2010.
On November 16, 2010 in an offseason trade, the Braves acquired Dan Uggla from the Florida Marlins in exchange for left-handed reliever Mike Dunn and infielder Omar Infante. According to Elias Sports Bureau, the Braves had an all-time franchise win-loss record over .500 for the first time since 1923 after their win over the Houston Astros on June 11, 2011. The Braves franchise became the third franchise in MLB history to reach 10,000 wins with their win over the Washington Nationals on July 15, 2011. On July 31, 2011, just sixteen days after registering their 10,000th win, the Florida Marlins defeated the Braves by a score of 3-1, handing the team the 10,000th loss in franchise history. The Braves become only the second team in big league history with 10,000 losses after the Philadelphia Phillies reached the plateau in 2007.
Players from the Braves' farm system, such as Freddie Freeman and Brandon Beachy, played regularly with the big league club, while Julio Teherán, Randall Delgado, and Mike Minor were called up for spot starts. With late season injuries to starters Jair Jurrjens and Tommy Hanson, these three young pitchers made their way into the starting rotation in their absence. Eight players made their major league debuts for the team in 2011.
September collapse.
The Braves led the National League Wild Card standings for much of the 2011 season, with the division-rival Philadelphia Phillies firmly in control of first place in the National League East. The Braves entered the final month of the regular season 25 games above .500 with a record of 80–55 and an -game lead in the Wild Card standings. The nearest team trailing them, the St. Louis Cardinals, who also trailed the National League Central-leading Milwaukee Brewers by games at the time, were considered a long-shot to gain a spot in the postseason. Just days prior on August 26, the Cardinals found themselves games behind and in third place.
With 27 games to play, the Braves went 9–18 in September to finish the season with a record of 89–73. The Cardinals, meanwhile, went 18–8 to finish at 90–72. Braves closer Craig Kimbrel, who had not surrendered a single earned run in July or August, carried a 4.76 ERA in September with three blown saves. After being dominant in his role for much of the season, Braves setup man Jonny Venters posted a 5.11 September ERA. These sharp declines in both relievers led many critics to question the handling of the bullpen by Braves manager Fredi González. Veteran starter Derek Lowe posted a win-loss record of 0–5 in September with an ERA of 8.75. Shortly into the offseason, Lowe would be traded to the Cleveland Indians. The Braves starters lasted six or more innings only three times over the last 23 games. Over the last five games, all of which were losses for the Braves, the team managed to score only seven runs. Braves catcher Brian McCann, often regarded as the best offensive catcher in the Majors, hit only .183 with two home runs in September. The offense as a whole hit for only a .235 batting average and a .300 on-base percentage in September, both second-worst in the National League. The .195 RISP average by Braves hitters was second worst in the Majors. Hitting coach Larry Parrish was fired two days following the last game of the season.
2012: Chipper's last season.
In 2012, the Braves began their 138th season after an upsetting end to the 2011 season. On March 22, the Braves announced that third baseman Chipper Jones would retire following the 2012 season after 19 Major League seasons with the team. The Braves also lost many key players through trades or free agency, including pitcher Derek Lowe, shortstop Alex González, and outfielder Nate McLouth. To compensate for this, the team went on to receive many key players such as outfielder Michael Bourn, along with shortstops Tyler Pastornicky and Andrelton Simmons. To fill the void of a quality starting pitcher left by Lowe (as well as a mid-season injury to Brandon Beachy), manager Fredi González elected relief pitcher Kris Medlen to the starting pitching rotation. The Braves went on to win every game Medlen started, setting the MLB record for most consecutive wins when a single pitcher starts (total of 23). Atlanta stayed close to the Washington Nationals in the race to win the National League East title. They also stayed on top of the National League Wild Card race. Washington ended up winning their first division title in franchise history, but the Braves remained in first place of the NL wild card race. Keeping with a new MLB rule for the 2012 season, the top two wild card teams in each league must play each other in a playoff game before entering into the Division Series.
The Braves played the St. Louis Cardinals in the first ever Wild Card Game. The Braves were behind 6–3 in the bottom of the eighth inning when Andrelton Simmons hit a fly ball to left field that dropped in between the Cardinals shortstop and left fielder. Umpire Sam Holbrook called Simmons out, citing the infield fly rule. Had an infield fly not been called, Simmons would have been credited with a single and Atlanta would have had the bases loaded with one out. Fans at Turner Field began to litter the field with debris, prompting the game to be delayed for 19 minutes. The Braves lost the game 6–3, ending their season.
2013: Braves win the East.
During the offseason following a gut wrenching exit against the St. Louis Cardinals in the Wild Card Game, the Braves spent the 2012–2013 offseason revamping and retooling their offense. The Braves turned heads across baseball by acquiring B.J. Upton from the Tampa Bay Rays, signing him to a 5-year $75.25 million contract and making him their starting center fielder, and uniting him with his younger brother Justin Upton from the Arizona Diamondbacks in a seven player trade that sent fan favorite utility man Martín Prado to the Diamondbacks, they also filled a need for a new Third Baseman in Chris Johnson after the retirement of Chipper Jones the previous year. The Braves began the 2013 season with a hot start in April by going 17-9 for the month, which saw the emergence of rookie sensation Evan Gattis, while taking hold of first place in the National League East division, a lead they would never relinquish for the rest of the season. The Braves suffered many injuries to key players throughout the season, including injuries to Jason Heyward, Brian McCann, Freddie Freeman, Eric O'Flaherty, Jonny Venters, Ramiro Pena and others, but found a way to win despite these blows to the team. Leading up to the All Star break, First Baseman Freddie Freeman was voted in to play for the 2013 National League All-Star Team, in the 2013 All Star Game, which he did not play. The Braves also witnessed the emergence of rookie pitcher Julio Teherán after much hype during Spring training. From July 26 to August 10, the Braves won 14 games in a row. The winning streak was the longest of its kind since April–May 2000.
On June 28, 2013 the Atlanta Braves retired former third baseman Chipper Jones' jersey, number 10, before the game against the Arizona Diamondbacks. He was honored before 51,300 fans at Turner Field in Atlanta. He served as a staple of the Braves franchise for 19 years before announcing his retirement at the beginning of the 2012 season. Chipper Jones played his last regular season game for the Braves on September 30, 2012.
The Braves opened up a 15-game lead on the Washington Nationals in the National League East on September 3, 2013, riding that lead en route to its first division title since 2005, the last of 14 straight division titles. This was also Braves manager Fredi González's first division title since beginning his managerial career in 1990; including his first since becoming the manager of the Braves after the 2010 season. The Braves clinched the 18th division title in team history on September 22, 2013 after a Nationals loss to the Marlins in the first game of a double header; the Braves also won their game that day, beating the Chicago Cubs 5-2 at Wrigley Field.
2014: Losing season.
On November 11, 2013, the Braves announced that they would vacate Turner Field for a new stadium in Cobb County, in the northwest suburbs outside of Atlanta in 2017. The move is to follow the expiration of the Braves' 20-year lease on Turner Field in 2016. The new stadium is to be constructed in a public/private partnership. During the offseason the Braves signed few of their young talents to multi year contracts; Craig Kimbrel (4 years/$42M), Freddie Freeman (8 years/$135M), Kris Medlen (1 year/$5.8M), Jason Heyward (2 years/$13.3M), Julio Teherán (6 years/$32.4M) and Andrelton Simmons (7 years/$58M).
The Braves finished the season in a distant second place with a 79-83 record, which was their first losing season since 2008 and only their third since 1990.
2015.
Prior to the 2015 season, the Braves fired their General Manager Frank Wren, and John Hart replaced him as interim GM, choosing to only take the title of President of Baseball Operations. The Braves promptly traded Gold Glove Award winner Jason Heyward to the St. Louis Cardinals along with pitcher Jordan Walden for pitchers Shelby Miller and Tyrell Jenkins. Catcher Evan Gattis and minor league prospect James Hoyt were traded to the Houston Astros for minor leaguers Mike Foltynewicz, Rio Ruiz, and Andrew Thurman. By the beginning of the season, the Braves did 11 trades in all.
2016.
Prior to the start of the 2016 regular season, the Braves continued their off season rebuilding by trading Andrelton Simmons to the Los Angeles Angels for Erick Aybar, and pitching prospects Sean Newcomb and Chris Ellis and $2.5 million. They agreed to 1 year contracts with Kelly Johnson, Chris Withrow, and Arodys Vizcaino, and agreed to terms on a minor league contract for Carlos Torres and Jeff Francoeur. The Braves would end up purchasing the Major League contract of Francoeur. 
On April 13, 2016, Hector Olivera was arrested and charged with the assault of a woman at the team hotel when the Braves were in Washington D.C. facing the Nationals. He was placed on Administrative Leave by Major League Baseball and was placed on the Braves Restricted List until further disciplinary action is given.
The Braves began the season on a nine-game losing streak, which is the worst opening by the franchise since 1988, when they dropped the first 10 games of that season. 
World Series Championships.
Over its 138 seasons, the Braves franchise has won a total of three World Series Championships.
Radio and television.
After years of stability, the Braves have faced a period of transition in their radio and television coverage.
The 2007 season was the last for Braves baseball on the TBS Superstation. TBS showed 70 games throughout the country, then cleared the decks to make way for a new national broadcast package that began in earnest with the 2007 postseason, and expanded to Sunday afternoon games in 2008. Until his dismissal in 2009, Chip Caray, one of the Braves' current broadcasters, called play-by-play for the national package, which includes the Division Series every season and alternating coverage of the ALCS and NLCS. Caray is joined by Joe Simpson, who has provided color commentary for the Braves since 1992.
Braves baseball had been on TBS since it was WTCG in 1972 and had been a cornerstone of the national superstation since it began in 1976. WPCH-TV/Peachtree TV, formerly WTBS Atlanta, still carried Braves games after 2007, but only in parts of the Southern United States. After the transfer of the channel's operations from Time Warner to Meredith Corporation, all Peachtree TV games were simulcast on Fox Sports South outside of the Peachtree TV coverage area in 2011 and 2012. On February 27, 2013, it was announced that Fox Sports South and SportSouth (now called Fox Sports Southeast) would carry every regionally televised Braves game exclusively, ending the team's partnership with WPCH-TV after 40 years.
After the 2004 season, longtime radio flagship station 750 WSB was replaced by WGST 640AM. Due to WGST's weak signal at night, which fails to cover the entire Atlanta metropolitan area, all games began to be simulcast on FM radio when the rights were transferred. The games first appeared on 96.1 WKLS (formerly "96 Rock") in 2005, but moved to country music station 94.9 WUBL ("94.9 The Bull") in 2007 after WKLS underwent a change in format from classic rock to active rock and became Project 9–6–1. As of the 2009 season, the Braves returned to WKLS on the FM frequency but remained on WGST on AM. It was announced that for the 2010 season, the Braves will be flagshipped on WCNN 680 The Fan and in Atlanta on the AM dial and WNNX 100.5 FM.
The Atlanta Braves radio network currently serves 134 radio stations across the Southern United States, including 20 in Alabama, 4 in Florida, 68 in Georgia, 1 in Mississippi, 13 in North Carolina, 14 in South Carolina, and 14 in Tennessee.
Since 2009, the radio announcers have been former Brewers announcer Jim Powell and Don Sutton. Sutton was released after the 2006 season and called Washington Nationals games on television from 2007 to 2008, but he has since returned for the 2009 season. Longtime Braves voices Skip Caray and Pete Van Wieren were the primary play-by-play voices of Braves baseball until Skip's sudden death on August 3, 2008, and Van Wieren's retirement after the 2008 season.

</doc>
<doc id="2141" url="https://en.wikipedia.org/wiki?curid=2141" title="Atari ST">
Atari ST

The Atari ST is a line of home computers from Atari Corporation and the successor to the Atari 8-bit family. The first ST model, the 520ST, was released in June 1985. "ST" officially stands for "Sixteen/Thirty-two", which referred to the Motorola 68000's 16-bit external bus and 32-bit internals. The Atari ST is the first personal computer to come with a bit-mapped color GUI, using a version of Digital Research's GEM released in February 1985. The 1040ST, released in 1986, is the first personal computer to ship with a megabyte of RAM in the base configuration and also the first with a cost-per-kilobyte of less than US$1.
The Atari ST is part of the 16/32-bit generation of home computers, based on the Motorola 68000 CPU, typically with 512 KB or more of RAM, a graphical user interface, and 3½-inch floppy disks as storage. The ST was primarily a competitor to the Macintosh, Amiga, and, in certain markets, the Acorn Archimedes. Whereas the Amiga has custom graphics processors and sample-based synthesis audio, the ST has a basic frame buffer and a three-voice synthesizer chip but with a slightly faster CPU and a high-resolution monochrome display mode ideal for business and CAD. Its simple design allowed the ST to precede the Commodore Amiga's commercial release by almost two months.
In some markets, particularly Germany, the machine gained a strong foothold as a small business machine for CAD and Desktop publishing work.
Thanks to its built-in MIDI, the ST enjoyed success for running music-sequencer software and as a controller of musical instruments among both amateurs and well-known musicians.
The ST was later superseded by the Atari STE, Atari TT, Atari MEGA STE, and Falcon computers.
Origins.
The Atari ST was born from the rivalry between home-computer makers Atari, Inc. and Commodore International.
Amiga contract.
Jay Miner, one of the original designers for the custom chips found in the Atari 2600 and Atari 8-bit family, tried to convince Atari management to create a new chipset for a video game console and computer. When his idea was rejected, Miner left Atari to form a small think tank called Hi-Toro in 1982 and began designing the new "Lorraine" chipset. The company, which was later renamed Amiga Corporation, was pretending to sell video game controllers to deceive competition while it developed a Lorraine-based computer.
Amiga ran out of capital to complete Lorraine's development, and Atari, owned by Warner Communications, paid Amiga to continue development work. In return Atari received exclusive use of the Lorraine design for one year as a video game console. After one year Atari would have the right to add a keyboard and market the complete computer, designated the 1850XLD. As Atari was heavily involved with Disney at the time, it was later code-named "Mickey", and the 256K memory expansion board was codenamed "Minnie".
Tramel Technology.
After leaving Commodore International in January 1984, Jack Tramiel formed Tramel Technology with his sons and other ex-Commodore employees and in April began planning a new computer. The company initially considered the National Semiconductor NS320xx microprocessor but was disappointed with its performance. This started the move to the 68000.
Tramiel learned that Warner wanted to sell Atari, which in mid-1984 was losing about a million dollars per day. Interested in Atari's overseas manufacturing and worldwide distribution network for his new computer, Tramiel negotiated with Warner in May and June 1984. He secured funding and bought Atari's Consumer Division (which included the console and home computer departments) in July. As executives and engineers left Commodore to join Tramiel's new Atari Corporation, Commodore responded by filing lawsuits against four former engineers for theft of trade secrets.
The Tramiels did not purchase the employee contracts when they bought the assets of Atari Inc., so one of their first acts was to interview Atari Inc. employees to decide whom to hire at what was essentially a brand new company. This company was originally called TTL (Tramiel Technologies Limited), later renamed to Atari Corp. At the time of the purchase of Atari Inc's assets, there were roughly 900 employees remaining from a high point of 10,000. After the interviews, approximately 100 employees were hired to work at Atari Corp.
At one point a custom sound processor called AMY was a planned component for the new ST computer design, but the chip needed more time to complete, so AMY was dropped in favor of an off the shelf Yamaha sound chip.
It was during this time in late July/early August that Leonard Tramiel discovered the original Amiga contract, which required Amiga Corporation to deliver the Lorraine chipset to Atari on June 30, 1984. Amiga Corp. had sought more monetary support from investors in spring 1984 (among them Tramel Technology, which wished to replace nearly everyone at Amiga).
Commodore and Amiga.
Having heard rumors that Tramiel was negotiating to buy Atari, Amiga Corp. entered into discussions with Commodore. The discussions led to Commodore wanting to purchase Amiga Corporation outright, which Commodore believed would cancel any outstanding contracts, including Atari's. Instead of Amiga Corp. delivering Lorraine to Atari, Commodore delivered a check of $500,000 to Atari on Amiga's behalf, in effect returning the funds Atari invested into Amiga for the chipset. Tramiel countersued Amiga Corp. on August 13, 1984. He sought damages and an injunction to bar Amiga (and effectively Commodore) from producing anything with its technology.
At Commodore, the Amiga team was in limbo during the summer of 1984 because of the lawsuit. No word on the status of the chipset, the Lorraine computer, or the team's fate was known. In the fall of 1984, Commodore informed the team that the Lorraine project was active again, the chipset was to be improved, the operating system (OS) developed, and the hardware design completed. While Commodore announced the Amiga 1000 with the Lorraine chipset in July 1985, the delay gave Atari, with its many former Commodore engineers, time to deliver the first Atari ST units in June 1985. In March 1987, the two companies settled the dispute out of court in a closed decision.
Operating system.
With the hardware design nearing completion, the Atari team started looking at solutions for the operating system (OS). Soon after the Atari buyout, Microsoft approached Tramiel with the suggestion that they port Windows to the platform, but the delivery date was out by about two years, far too long for their needs. Another possibility was Digital Research, who was working on a new GUI-based system then known as Crystal, soon to become GEM. Another option was to write a new operating system in-house, but this was rejected as Atari management was unsure whether the company had the required expertise to do so.
Digital Research was fully committed to the Intel platform, so a team from Atari was sent to the Digital Research headquarters to work with the "Monterey Team" which comprised a mixture of Atari and Digital Research engineers. Atari's Leonard Tramiel was the Atari person overseeing "Project Jason" (a.k.a.  The Operating System) for the Atari ST line of computers. The name came from the original designer and developer, Jason Loveman. Tim Oren has an article describing the history of the project, from his series "Professional GEM".
GEM was initially based on CP/M-68K, essentially a direct port of CP/M to the 68000. By 1985, CP/M was becoming increasingly outdated; it did not support sub-directories, for example. Digital Research was also in the process of building a new DOS-like operating system specifically for GEM, "GEMDOS", and there was some discussion of whether or not a port of GEMDOS could be completed in time for product delivery in June. The decision was eventually taken to port it, resulting in a GEMDOS file system which became part of TOS ("The Operating System" and colloquially known as the "Tramiel Operating System"). This was beneficial as it gave the ST a fast, hierarchical file system, essential for hard drive storage disks, plus programmers had function calls similar to the IBM PC DOS. The character set is based on codepage 437. 
Besides the original TOS operating system, a number of third party OSes were developed or ported to the Atari ST. Among Unix Clones, Idris, Minix had an Atari ST port and the Mint OS was developed specifically for the Atari ST.
Debut and release.
After six months of intensive effort following Tramiel's takeover, Atari announced the 520ST at the Winter Consumer Electronics Show in Las Vegas in January 1985. "InfoWorld" described prototypes shown at computer shows as a "typical Commodore-64 style, corner-cutting, low-cost Jack Tramiel product", but Atari unexpectedly displayed the ST at Atlanta COMDEX in May. Due to its similarities to the original Apple Macintosh and Tramiel's role in its development, it was quickly nicknamed the Jackintosh. Atari's rapid development of the ST amazed many, but others were more skeptical, citing the ST's "cheap" appearance, Atari's uncertain financial health, and the poor relations the Tramiel-led Commodore had with software developers.
As early as 1981, Adam Osborne wrote that while Tramiel "deserves credit for what he has been able to accomplish", "the microcomputer industry abounds with horror stories describing the way Commodore treats its dealers and its customers." In 1984 "Ahoy!" had written that Tramiel "had never been able to establish very good relations with computer dealers ... Under his reign, computer retailers have accused Commodore of treating them as harshly as if they were suppliers or competitors". After purchasing Atari, "Computer Gaming World" stated that his poor reputation likely made computer stores reluctant to deal with the company, hurting its distribution of the ST. One retailer said, "If you can believe Lucy when she holds the football for Charlie Brown, you can believe Jack Tramiel", and another said that because of its experience with Tramiel "Our interest in Atari is zero, zilch". Neither Atari nor Commodore was able to persuade large chains like ComputerLand or BusinessLand to sell their products, but observers criticized Atari's erratic discussion of its stated plans for the new computer, quickly shifting from using mass merchandisers to specialty computer stores to both; Atari executives could not name any computer stores that would carry the ST when asked at COMDEX. One analyst stated after attending a meeting with the company, "We've seen marketing strategies changed before our eyes".
Although the more than 30 companies exhibiting ST software at Las Vegas COMDEX in November 1985—while the Amiga had almost none—surprised the industry, Tramiel's poor reputation also influenced potential developers of software for his computer. One stated that "Dealing with Commodore was like dealing with Attila the Hun. I don't know if Tramiel will be following his old habits ... I don't see a lot of people rushing to get software on the machine." Large business-software companies like Lotus, Ashton-Tate, and Microsoft did not promise software for either the ST or Amiga, and the majority of software companies were hesitant to support another platform beyond the IBM PC, Apple, and Commodore 64; "These days, if I were a consumer, I'd stick to companies and IBM I know will be around", said Philippe Kahn of Borland. "The New York Times" reported after Atlanta COMDEX that "more than 100 software titles will be available for the machine, most written by small software houses that desperately need work", and contrasted the "small, little-known companies" at Las Vegas with the larger ones like Electronic Arts and Activision which planned Amiga programs.
Trip Hawkins of Electronic Arts said "I don't think Atari understands the software business. I'm still skeptical about its resources and its credibility." Although Michael Berlyn of Infocom promised that his company would quickly publish all of its games for the new computer, he doubted that many others would soon do so. Other companies such as Spinnaker Software and Lifetree Software were more positive. Both promised to soon release ST software, with the former reporting that "Atari has a vastly improved attitude toward software developers. They are eager to give us technical support and machines", and the latter stating "we are giving Atari high priority". Some, such as Software Publishing Corporation, were unsure of whether to develop for the ST or the Amiga, while John C. Dvorak wrote that the public saw both Commodore and Atari as selling "cheap disposable" game machines.
Success.
Atari ST advertisements stated "America, We Built It For You", and quoted Atari president Sam Tramiel: "We promised. We delivered. With pride, determination, and good old ATARI know how". Although Atari was out of cash, sales of its 8-bit computers were "very, very slow" according to Jack Tramiel, and employees feared that he would shut the company down, the 520ST shipped during spring 1985 to the press, developers, and user groups, and in early July 1985 for general retail sales, saving the company. By November the company stated that it had sold more than 50,000 520 STs, "with U.S. sales alone well into five figures". The machine had gone from concept to store shelves in a little under a year. Atari had originally intended to release versions with 128 KB and 256 KB of RAM as the "130ST" and "260ST" respectively. However, with the OS loaded from floppy into RAM, there would be little or no room left over for applications to run. The 260ST did make its way into Europe on a limited basis.
The ST supports a monochrome or color monitor. The color hardware supports two different resolutions, 320 × 200 with 16 out of 512 colors, or 640 × 200 with 4 out of 512 colors. The monochrome monitor was less expensive and has a single resolution of 640 × 400. Due to its higher vertical resolution and noninterlaced operation at 70 Hz, the monochrome monitor was better suited to business applications. The attached monitor determines available resolutions, so software either supports both types of monitors or only works with one. Color is required by a majority of games. Unlike the Amiga, Commodore 64, and Atari 8-bit computers, the ST does not have hardware-supported sprites.
Early models shipped with Atari Logo and "TOS" on disk; although the operating system occupies 206K RAM, but models were designed with six ROM sockets allow easy upgrading to the future ROM-based "TOS". These became available only a few months later and were included in all new machines as well as being available to upgrade older machines. By late 1985 the machines were also upgraded with the addition of an RF modulator (for TV display), a version known as the 520STM. ST systems before the Mega ST range have no battery-backed clock.
Atari had originally intended to include GEM's GDOS (Graphical Device Operating System), which allowed programs to send GEM VDI (Virtual Device Interface) commands to drivers loaded by GDOS. This allowed developers to send VDI instructions to other devices simply by pointing to it. However, GDOS was not ready at the time the ST started shipping and was included in software packages and later ST machines. Later versions of GDOS supported vector fonts.
A limited set of GEM fonts were also included within the ROMs. These fonts also feature a standard 8x8 pixel graphical character set for the ST (the main in-ROM "font" for GEM and text-mode TOS operations in color modes) containing standard numbers, letters, symbols, accented characters, and four unusual characters (which can be placed together in a square, forming a basic but recognizable facsimile of the face of J. R. "Bob" Dobbs, the figurehead of the Church of the Subgenius).
The ST was less expensive than most machines, including the Macintosh Plus, and tended to be faster than most. Largely as a result of the price/performance factor, the ST would go on to be a fairly popular machine, notably in European markets where the foreign-exchange rates amplified prices. Indeed, the company's English advertising strapline of the era was "power without the price". In fact, an Atari ST and terminal emulation software was much cheaper than a Digital VT220 terminal, which was commonly needed by offices with central computers.
Design.
Original housing.
The original 520ST case design was created by Ira Velinsky Atari's chief Industrial Designer. The ST is basically wedge shaped, featuring bold angular lines and a series of grilles cut into the rear for airflow. The keyboard has soft tactile feedback and rhomboid-shaped function keys across the top. The 520ST is an all-in-one unit, similar to earlier home computers like the Commodore 64. By the time the 520ST reached the market, however, market and IBM compatibility concerns demanded a keyboard with cursor keys and a numeric keypad. For this reason, the 520ST ended up significantly larger than previous popular all-in-one machines like the Commodore 64.
The 520ST uses an external "brick" power supply, floppy disk, monitor, and mouse. Even basic system setups thus suffer from cable spaghetti, a problem future versions would address to one degree or another. Early 520ST owners became accustomed to the "Atari Twist" and the "Atari Drop" service procedures. The "Atari Twist" seemed to help discharge built-up static electricity (Atari soldered-down the metal shielding to fix the problem) while the "Atari Drop" appeared to help re-seat chips which may have become partially unseated over time.
Port connections.
The 520ST features a large number of ports mounted at the rear of the machine. The basic port layout would remain largely unchanged over the machine's history.
Because of its bi-directional design, the Centronics printer port can be used for joystick input, and several games make use of available adaptors that plugged into the printer socket, providing two additional 9-pin joystick ports.
Floppy drive.
Atari initially used single-sided disk drives that could store up to 360 kB. Later drives were double-sided and stored 720 kB. Some commercial software, particularly games, shipped by default on single-sided disks, even supplying two 360kB floppies instead of a single double-sided one, for fear of alienating early adopters. The problem was exacerbated by the early drive's single read/write head being on the "wrong" side of the disc that is, reading/writing the same side of the disc as a more standard 720kB drive's "second" head ("head 1") instead of its "first" ("head 0"). The boot sector and FAT was typically written to "side 0" by double-sided drives (in both STs and other marques fitted with 3.5" drives), so owners of single-sided machines could not read any useful data from a standard double-sided disc at all, not even the root directory listing, and might well mistakenly end up reformatting just one side of a seemingly "faulty" disc as a result.
ST magazines wishing to cater to the entire audience while still supplying a large amount of material on a single cover disc had to adopt innovative custom formats to work around this problem, forcing the bootsector and FAT onto "side 1", along with the disc's main feature program, and tucking supplemental programs onto "side 0" (typically falsely renamed "side B", in allusion to classic 45rpm singles), "inside" a particular file folder which would only open successfully for owners of 720kB drives. Owners of single-sided drives were encouraged, if they wished to gain access to "side B", to send the original coverdisk(s) back to the publisher with a token fee for postage and duplication, for which they would be sent a set of single-sided discs containing the full software complement. This scheme was also operated by some producers of productivity software in later years, mirroring the PC situation where software would ship by default on a particular disc format (3.5" or 5.25", double or high density) and a customer who bought the wrong type could have it replaced by mail order.
Another early sticking point with the ST's floppy drives was that, whilst double-sided drive equipped STs could happily read discs formatted under MS-DOS on IBM PCs, PCs could not themselves read Atari disks, because the initial versions of TOS could recognise, read, and write to but not themselves create discs in the same particular specification used and indeed demanded by MS-DOS (single-sided Atari drives were completely incompatible in either direction, as MS-DOS never officially supported single-sided 3.5" hardware, and still placed its filesystem information on "side 0"). Achieving successful data interchange between the two platforms using floppies thus required pre-formatting dedicated file transfer discs under MS-DOS, and copying the necessary data onto them from any unsuitable Atari formatted discs. This formatting issue was soon resolved by the emergence of third-party formatting and file copier software, MS-DOS disc imaging software capable of reading the unusual formats used by the ST and various other machines (such as the Commodore Amiga) and, a few years later, Atari's own version 1.4 (and later) TOS upgrades.
STF and STFM models.
Atari later upgraded the basic design in 1986 with the "1040STF" (also written "STF"). The machine is generally similar to the earlier 520ST, but moved the power supply and a double-sided floppy drive into the rear of the housing of the computer, as opposed to being external. This added to the size of the machine, but reduced cable clutter in the back. The joystick/mouse ports, formerly on the right side of the machine where the disk drive now sat, were moved to a niche underneath the keyboard.
The "1040ST" was the first personal computer shipped with a base RAM configuration of 1 MB. When the list price was reduced to $999 in the U.S. it appeared on the cover of "BYTE" in March 1986 as the first computer to break the $1000/megabyte price barrier; "Compute!" noted that, in fact, the "1040ST" was the first computer to break the $2500/megabyte price barrier. However, the ST remained generally the same internally over the majority of its several-year lifespan. The choice of model numbers was inherited from the model numbers of the "XE series" of the Atari 8-bit family of computers. A limited number of 1040STFs shipped with a single-sided floppy drive.
The same basic design was also used for a cut-down version, the 512 kB "520STFM", which replaced the earlier 520ST models in the market. The early 'STF' machines lack the 'M' modulator that allows a TV to be used and will only work with a monitor.
Mega models.
Initial sales were strong, especially in Europe where Atari sold 75% of its computers. Germany became Atari's strongest market, with small business users using them for desktop publishing and CAD.
To address this growing market segment, Atari came up with the "ST1". Debuted at Comdex in 1986, it was received favorably. Renamed the "Mega", this new machine includes a high-quality detached keyboard, a stronger case to support the weight of a monitor, and an internal bus expansion connector. A 20 MB hard drive called the SH204 could be purchased as an option and stacked below or above the main case of the Mega. The upcoming SLM804 laser printer would not come with a processor or memory, reducing costs. It would attach to the Mega through the ST DMA port and require the Mega computer to render the pages. As TOS was not a multitasking OS, this meant the computer could not be used while printing. Initially equipped with 2 or 4 MB (a 1 MB version, the "Mega 1" would later follow), the Mega machines would complement the Atari laser printer for a low-cost desktop publishing package, which received acclaim and was featured on the cover of Computer Shopper magazine.
A custom blitter co-processor was to be included to speed the performance of some graphics operations on the screen, but due to delays it was eventually released on the "Mega 2" and "Mega 4" machines. Developers wanting to use it had to detect for it in their programs because it was not present on all machines. However, properly written programs using the screen VDI commands can use the blitter seamlessly, since GEM API is a higher-level interface to "TOS".
Later models.
STE models.
In late 1989, Atari released the "520STE" and "1040STE" (also written "STE"), enhanced version of the ST with improvements to the multimedia hardware and operating system. It features an increased color palette of 4096 colors from the ST's 512 (though the maximum displayable palette of these without programming tricks was still limited to 16 in the lowest 320x200 resolution, and even fewer in higher resolutions), Genlock support, and a graphics co-processor chip called Blitter, which can quickly move large blocks of data (most particularly, graphics sprites) around in RAM. It also included a new 2-channel digital sound chip that could play 8-bit stereo samples in hardware at up to 50 kHz. Two enhanced joystick ports (EJP) were added (two normal joysticks can be plugged into each port with an adapter), with the new connectors placed in more easily accessed locations on the side of the case. The enhanced joystick ports were re-used in Atari's Jaguar console, and are compatible. RAM was now much more simply upgradable via SIMMs. CPU speed was unchanged and ran at 8 MHz.
The STE models initially had software and hardware conflicts resulting in some applications and video games written for the ST line being unstable or even completely unusable, primarily caused by programming direct hardware calls which bypassed the operating system. Sometimes incompatibility could be solved by expanding the RAM. Furthermore, even having a joystick plugged in would sometimes cause strange behavior with a few applications (such as the WYSIWYG word-processor application First Word Plus).
The STE was the first Atari with PCM audio, which was probably one of the most attractive features of the machine. It has the ability to play back 8-bit (signed) samples using the SDMA at the following frequencies: 6258 Hz, 12517 Hz, 25033 Hz and even 50066 Hz a sampling frequency above that of audio CDs, although at only 8-bit resolution. The channels are arranged as either a mono track or a track of LRLRLRLR... bytes.
Very little use was made of the extra features of the STE: STE-enhanced and STE-only software were rare, generally being limited to serious art, CAD, or music applications, with very few games taking advantage of the hardware, not present on most machines.
The last STE machine, the "Mega STE", is an STE in a grey Atari TT case that had a switchable 16 MHz, dual-bus design (16-bit external, 32-bit internal), optional Motorola 68881 FPU, built-in 3½-inch floppy disk drive, VME expansion slot, a network port (very similar to that used by Apple's LocalTalk) and an optional built-in 3½" hard drive. It also shipped with TOS 2.00 (better support for hard drives, enhanced desktop interface, memory test, 1.44 MB floppy support, bug fixes). It was marketed as more affordable than a TT but more powerful than an ordinary ST.
Atari TT.
In 1990, Atari released the high-end workstation-oriented "Atari TT030", based on a 32 MHz Motorola 68030 processor. The "TT" name ("Thirty-two/Thirty-two") continued the nomenclature system as the 68030 chip had full 32-bit wide buses both internally and externally. Originally planned with a 68020 CPU, the TT included improved graphics and more powerful support chips. The case was a new design with an integrated hard-drive enclosure.
Atari Falcon.
The final ST computer is the multimedia-capable "Atari Falcon030". Like the TT, this was also 68030-based, operating at 16 MHz, but with improved video modes and an on-board Motorola 56001 audio digital signal processor. The Falcon, like the Atari STE, supports sampling frequencies above 44.1 kHz; the sampling master clock is 98340 Hz, which can be divided by a number between 2 and 16 to get the actual sampling frequencies. Apart from these frequencies, it is also able to play the STE sample frequencies (up to 50066 Hz) in 8 or 16 bit, mono/stereo, all by using the same DMA interface as the STE, with a few additions. The Falcon can both play back and record samples; it has 8 mono channels / 4 stereo channels; thus this allowed musicians to use the computer for harddisk recording. Although the 68030 microprocessor is capable of using 32-bit memory, the Falcon uses a 16-bit bus which affects performance, but also served to reduce its cost. In another cost-reduction measure, Atari shipped the Falcon in an inexpensive case much like that of the STF and STE. Aftermarket upgrade kits were available that allowed the Falcon to be put in a desktop or rack-mount case, with the keyboard separate.
Released in 1992, the Falcon was discontinued by Atari the following year. In Europe, C-Lab licensed the Falcon design from Atari, and released the C-Lab Falcon Mk I (the same as Atari's Falcon except for some slight modifications to the audio circuitry), Mk II (as Mk I but with an internal 500 MB SCSI hard disk) and Mk X (as Mk II but in a desktop case).
Aftermath.
In 1993, Atari ceased development on the ST computers to focus on the Jaguar.
Following the exit of Atari from the computer market, Medusa Computer Systems manufactured some powerful 3rd-party Atari Falcon/TT-compatible machines that used 68040 and 68060 processors, based on multimedia (particularly audio, but also video), CAD, and office uses.
Despite the lack of a hardware supplier, there is a small active community dedicated to keeping the ST platform alive. There have been advancements in the operating system, software emulators (for Windows, Mac, & Linux), and some hardware developments. There are accelerator cards, such as the CT60 & CT63, which is a 68060 based accelerator card for the Falcon, and there is the Atari Coldfire Project, which aims at developing an Atari-clone based on the Coldfire processor. Milan Computer of Germany also made 68040 and 68060-based Atari clones that can run either Atari TOS 4.5 or Milan Computer's MultiTOS operating system.
Software.
As with the Atari 8-bit computers, software publishers attributed their reluctance to produce Atari ST products in part to—as "Compute!" reported in 1988—the belief in the existence of a "higher-than-normal amount of software piracy". That year WordPerfect threatened to discontinue the Atari ST version of its word processor because the company discovered that pirate bulletin board systems (BBSs) were distributing it, causing "ST-Log" to warn that "we had better put a stop to piracy "now" ... it can have harmful effects on the longevity and health of your computer". In 1989 magazines published a letter by Gilman Louie, head of Spectrum Holobyte. He stated that he had been warned by competitors that releasing a game like "Falcon" on the ST would fail because BBSs would widely disseminate it. Within 30 days of releasing the non-copy protected ST version, the game was available on BBSs with maps and code wheels. Because the ST market was smaller than that for the IBM PC it was more vulnerable to piracy which, Louie said, seemed to be better organized and more widely accepted for the ST. He reported that the Amiga version sold in six weeks twice as much as the ST version in nine weeks, and that the Mac and PC versions had four times the sales. "Computer Gaming World" stated "This is certainly the clearest exposition ... we have seen to date" of why software companies produced less software for the ST than for other computers.
Music and sound.
The ST has built-in MIDI ports, and there was plenty of MIDI-related software for use professionally in music studios, or by amateur enthusiasts. The popular Windows/Macintosh applications "Cubase" and "Logic Pro" originated on the Atari ST (the latter as "Notator Logic", preceded by "Creator", "Notator" and "Notator-SL"). Another popular and powerful ST music sequencer application, Dr. T's "KCS", contains a "Multi-Program Environment" that allows ST users to run other applications, such as the synthesizer patch editing software XoR (now known as Unisyn on the Macintosh), from within the sequencer application.
Music tracker software was popular on the ST, such as the "TCB Tracker", aiding the production of quality music from the Yamaha synthesizer ('chiptunes').
An innovative music composition program that combines the sample playing abilities of a tracker with conventional music notation (which was usually only found in MIDI software) is called "Quartet" (after its four-note polyphonic tracker, which displays one monophonic stave at a time on color screens).
Due to the ST having comparatively large amounts of memory for the time, sound sampling packages became a realistic proposition. The Microdeal Replay Professional product features a sound sampler that cleverly uses the ST cartridge port to read in parallel from the cartridge port from the ADC. For output of digital sound, it uses the on-board frequency output, sets it to 128 kHz (inaudible) and then modulates the amplitude of that.
Another program that had good success on the ST platform is "MasterTracks Pro" from Passport Designs, of Half Moon Bay, CA., that was first put out by Don Williams for the Macintosh. When the ST died, a PC version continued that one could port MIDI to using the generic .MID format. GVox bought out Passport, and continues the program for Windows and Mac OS along with the other Passport product, the notation program "Encore".
In addition to the sound-sampling functionalities, the availability of software packages with MIDI support for music composition and efficient sound analysis contributed to make the Atari ST a forerunner of later computer-based all-in-one studios.
The ST's low cost, built-in MIDI ports, and fast, low-latency response times made it a favorite with musicians:
Applications.
Also popular on the ST was professional desktop publishing software, such as "PageStream" and "Calamus"; office tools such as word processors ("WordPerfect", "Microsoft Write", "AtariWorks", "WordWriter ST", First Word with the machine and its Plus continuation, and others); spreadsheets ("3D-Calc", "LDW Power", "LDW Power 2", "LOGiSTiX Senior", "PowerLedger ST", "SwiftCalc ST", "VIP Professional", and others); turnkey programs ("Mail-Pro", "Sales-Pro 6", "Video-Pro", and others); database programs ("A-Calc Prime", "Data Manager", "Data Manager Professional", "DBMan V", "Base Two", "H&DBase", "Informer II", "DB Master One", "SBT Database Accounting Library" ("dLedger", "dInvoice", "dOrder", "dPurchases", and "dPayables)", "Superbase Personal", "Superbase Professional", "Tracker ST", and others); and various CAD and CAM tools from amateur hobbyist to professional grade (Campus CAD, DynaCADD, Leonard ST, Technobox CAD/2...): all being largely targeted at, or even limited to owners of high-resolution monochrome monitors.
Graphics programs such as "NEOchrome", Degas & Degas Elite, "Canvas", "Deluxe Paint", and "Cyber Paint" (which author Jim Kent would later evolve into "Autodesk Animator") featured advanced features such as 3D design and animation. One paint program, "Spectrum 512", uses the ST's rapid palette switching ability to expand the maximum number of colors to be displayed on-screen at once to 512 (up to 46 in each scan line the STE never had a Spectrum4096, but other more minor applications filled this speciality niche, one even going so far as to program the shifter chip to palette shift at a rate enabling a display of 19200 colors).
3D computer graphics applications (like "Cyber Studio"s "CAD-3D", which author Tom Hudson would later develop into Autodesk "3D Studio"), brought 3D modelling, sculpting, scripting, and most important, computer animation (using delta-compression) to the desktop. Video-capture and -editing applications using special video-capture 'dongles' connected using the cartridge port low frame rate, mainly silent and monochrome, but progressing to sound and basic color (in still frames) by the end of the machine's life. At the end, Spectrum 512 and CAD-3D teamed up to produce realistic 512-color textured 3D renderings, but processing was slow, and Atari's failure to deliver a machine with a math coprocessor had Hudson and Yost looking towards the PC as the future before a finished product could be delivered to the consumer.
The Atari ST was the computer upon which today's prevalent graphical touchscreen point of sale software for restaurants was originally developed. This software was created by Gene Mosher under the ViewTouch copyright and trademark. It does not feature the Atari ST's GEM graphical user interface but, instead, features an application specific graphical user interface and widget framework which he developed using, in part, the Neochrome paint program.
Software development.
The Atari ST has a wide variety of languages and tools for development. 68000 assemblers (MadMac from Atari Corp, HiSoft Systems's Devpac, TurboAss, GFA-Assembler), Pascal (OSS Personal Pascal, Maxon Pascal, PurePascal), Modula-2, C compilers (like Turbo C, Alcyon C, Lattice C, Megamax C, Mark Williams C, GNU C, Aztec C, AHCC (A Home Cooked C)), LISP, Prolog, Logo, and many others.
The initial development kit from Atari included a computer and manuals. At $5,000, this discouraged many from developing software for the ST. Later, the Atari Developer's Kit consisted of software and manuals (no hardware) for $300. Included with the kit were a resource kit, C compiler (first Alcyon C, then Mark Williams C), debugger, and 68000 assembler (plus the non-disclosure agreement).
The ST came bundled with a system disk that contained ST BASIC, the first BASIC for the ST. However, due to its poor performance, users favored other BASICs, such as HiSoft BASIC, GFA BASIC, FaST BASIC (notable for being one of the few programs to actually be supplied as a ROM cartridge instead of on disc), and the relatively famous "STOS", which then inspired and led to the creation of AMOS on the Amiga, and powerful enough that it was used (with a compiler, opposed to its usual runtime interpreter) for the production of at least two commercial titles and an innumerable host of good quality shareware and public domain games. In the late years of the Atari ST Omikron Basic was bundled with it in Germany.
Even novelty tools such as "SEUCK" were available.
Games.
The ST enjoyed success in gaming due to low cost, fast performance and colorful graphics.
Notable individuals who developed games on the ST include Peter Molyneux, Doug Bell, Jeff Minter, Éric Chahi, Jez San, and David Braben. An early real-time 3D role-playing video game, "Dungeon Master", was first developed and released on the ST, and was the best-selling software ever produced for the platform. Simulation games like "Falcon" and "Flight Simulator II" made use of the enhanced graphics found in the ST machines, as did many arcade ports. One game, MIDI Maze, uses the MIDI ports to connect up to 16 machines for interactive networked play. Games simultaneously released on the Amiga that had identical graphics and sound were often accused by video game magazines of simply being ST ports. The critically acclaimed game "Another World" was originally released for ST and Amiga in 1991 with the Polygonal engine developed on the ST and the rotoscoped animations created on the Amiga (the two games are very similar on both systems).
Garry Kasparov became the first player to register the commercial "ChessBase", a popular commercial database program produced for storing and searching records of games of chess. The first version was built for Atari ST with his collaboration in January 1987. In his autobiography "Child of Change", he regards this facility as "the most important development in chess research since printing".
Utilities.
Utility software was available to drive hardware add-ons such as video digitisers. Office Productivity and graphics software was also bundled with the ST (HyperPaint II by Dimitri Koveos, HyperDraw by David Farmborough, 3D-Calc spreadsheet by Frank Schoonjans, and several others commissioned by Bob Katz, later of Electronic Arts).
There was a thriving output of public domain and shareware software which was distributed by, in the days long before public internet access, public domain software libraries that advertised in magazines and on popular dial-up bulletin board systems.
Remarkably, a modest core fanbase for the system, supporting a dwindling number of good quality print magazines, survived to the mid-'90s and the birth of the modern, publicly accessible Internet as we know it. Despite the limited graphics, memory, and temporary hard-storage capabilities of the system, several email, FTP, telnet, IRC, and even full-blown graphical World Wide Web browser applications were available and usable on the ST.
There were also DOS emulators released in the late 1980s. "PC-Ditto" came in two versions, software-only-, and a hardware version that plugs into the cartridge slot or kludges internally. After running the PC-Ditto software, a DOS boot disk is required to load the system. Both allow users to run DOS programs in CGA mode, though much more slowly than on an IBM PC. Other options are the "PC-Speed" (NEC V30), "AT-Speed" (Intel 80286) and "ATonce-386SX" (Intel 80386sx) hardware emulator boards.
Technical specifications.
All STs are made up of both custom and commercial chips:
ST/STF/STM/STFM.
As originally released in the "520ST":
Very early machines included the OS on a floppy disk due to it not being ready to be burned to ROM (like the Amiga 1000 had). This early version of TOS was bootstrapped from a very small core boot ROM, but this was quickly replaced with (expanded capacity) ROM versions of TOS 1.0 when it was ready. (This change was also greatly welcomed as older ST machines with memory below 512 kB suffered, as GEM loaded its entire 192 kB code into RAM when booting the desktop). Having the OS loaded from disk was due to Atari trying to rush the machines to market without ironing out all the bugs in the OS. Soon after this change, most production models became STFs, with an integrated single- (520STF/512 kB RAM) or double-sided (1040STF/1024 kB RAM) double density floppy disk drive built-in, but no other changes. The next later models used an upgraded version of TOS: 1.02 (also known as TOS 1.2). Another early addition (after about 6 months) was an RF Modulator that allows the machine to be hooked to a color TV when run in its low or medium resolution (525/625 line 60/50 Hz interlace, even on RGB monitors) modes, greatly enhancing the machine's saleability and perceived value (no need to buy a prohibitively expensive, even if exceptionally crisp and clear, monitor). These models were known as the "520STM" (or "520STM"). Later "F" and "FM" models of the 520 had a built in double-sided disk drive instead of a single-sided one.
STE.
As originally released in the "520STE/1040STE":
Models.
The members of the ST family are listed below, in rough chronological order:
Related systems.
Atari ABAQ, or Atari Transputer Workstation: A standalone machine developed in conjunction with Perihelion Hardware, containing modified ST hardware and up to 17 transputers capable of massively parallel operations for tasks such as ray tracing.

</doc>
<doc id="2142" url="https://en.wikipedia.org/wiki?curid=2142" title="List of artificial intelligence projects">
List of artificial intelligence projects

The following is a list of current and past, nonclassified notable artificial intelligence projects.

</doc>
