<doc id="45599" url="https://en.wikipedia.org/wiki?curid=45599" title="Surgery">
Surgery

Surgery (from the "cheirourgikē" (composed of χείρ, "hand", and ἔργον, "work"), via , meaning "hand work") is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate and/or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas (for example, a perforated ear drum).
An act of performing surgery may be called a "surgical procedure", operation, or simply surgery. In this context, the verb operate means to perform surgery. The adjective surgical means pertaining to surgery; e.g. surgical instruments or surgical nurse. The patient or subject on which the surgery is performed can be a person or an animal. A surgeon is a person who practices surgery and a surgeon's assistant is a person who practices surgical assistance. A surgical team is made up of surgeon, surgeon's assistant, anesthesia provider, circulating nurse and surgical technologist. Surgery usually spans minutes to hours, but it is typically not an ongoing or periodic type of treatment. The term "surgery" can also refer to the place where surgery is performed, or simply the office of a physician, dentist, or veterinarian.
Definitions.
Surgery is a technology consisting of a physical intervention on tissues.
As a general rule, a procedure is considered surgical when it involves cutting of a patient's tissues or closure of a previously sustained wound. Other procedures that do not necessarily fall under this rubric, such as angioplasty or endoscopy, may be considered surgery if they involve "common" surgical procedure or settings, such as use of a sterile environment, anesthesia, antiseptic conditions, typical surgical instruments, and suturing or stapling. All forms of surgery are considered invasive procedures; so-called "noninvasive surgery" usually refers to an excision that does not penetrate the structure being excised (e.g. laser ablation of the cornea) or to a radiosurgical procedure (e.g. irradiation of a tumor).
Types of surgery.
Surgical procedures are commonly categorized by urgency, type of procedure, body system involved, degree of invasiveness, and special instrumentation.
Description of surgical procedure.
Location.
At a hospital, modern surgery is often done in an operating theater using surgical instruments, an operating table for the patient, and other equipment. Among United States hospitalizations for nonmaternal and nonneonatal conditions in 2012, more than one-fourth of stays and half of hospital costs involved stays that included operating room (OR) procedures. The environment and procedures used in surgery are governed by the principles of aseptic technique: the strict separation of "sterile" (free of microorganisms) things from "unsterile" or "contaminated" things. All surgical instruments must be sterilized, and an instrument must be replaced or re-sterilized if it becomes contaminated (i.e. handled in an unsterile manner, or allowed to touch an unsterile surface). Operating room staff must wear sterile attire (scrubs, a scrub cap, a sterile surgical gown, sterile latex or non-latex polymer gloves and a surgical mask), and they must scrub hands and arms with an approved disinfectant agent before each procedure. There is moderate-quality evidence that usage of two layers of gloves compared to single gloving during surgery reduces perforations and blood stains on the skin, indicating a decrease in percutaneous exposure incidents.
Preoperative care.
Prior to surgery, the patient is given a medical examination, receives certain pre-operative tests, and their physical status is rated according to the ASA physical status classification system. If these results are satisfactory, the patient signs a consent form and is given a surgical clearance. If the procedure is expected to result in significant blood loss, an autologous blood donation may be made some weeks prior to surgery. If the surgery involves the digestive system, the patient may be instructed to perform a bowel prep by drinking a solution of polyethylene glycol the night before the procedure. Patients are also instructed to abstain from food or drink (an NPO order after midnight on the night before the procedure), to minimize the effect of stomach contents on pre-operative medications and reduce the risk of aspiration if the patient vomits during or after the procedure.
Some medical systems have a practice of routinely performing chest x-rays before surgery. The premise behind this practice is that the physician might discover some unknown medical condition which would complicate the surgery, and that upon discovering this with the chest x-ray, the physician would adapt the surgery practice accordingly. In fact, medical specialty professional organizations recommend against routine pre-operative chest x-rays for patients who have an unremarkable medical history and presented with a physical exam which did not indicate a chest x-ray. Routine x-ray examination is more likely to result in problems like misdiagnosis, overtreatment, or other negative outcomes than it is to result in a benefit to the patient. Likewise, other tests including complete blood count, prothrombin time, partial thromboplastin time, basic metabolic panel, and urinalysis should not be done unless the results of these tests can help evaluate surgical risk.
Staging for surgery.
In the pre-operative holding area, the patient changes out of his or her street clothes and is asked to confirm the details of his or her surgery. A set of vital signs are recorded, a peripheral IV line is placed, and pre-operative medications (antibiotics, sedatives, etc.) are given. When the patient enters the operating room, the skin surface to be operated on, called the operating field, is cleaned and prepared by applying an antiseptic such as chlorhexidine gluconate or povidone-iodine to reduce the possibility of infection. If hair is present at the surgical site, it is clipped off prior to prep application. The patient is assisted by an anesthesiologist or resident to make a specific surgical position, then sterile drapes are used to cover all of the patient's body except for the head and the surgical site or at least a wide area surrounding the operating field; the drapes are clipped to a pair of poles near the head of the bed to form an "ether screen", which separates the anesthetist/anesthesiologist's working area (unsterile) from the surgical site (sterile).
Anesthesia is administered to prevent pain from incision, tissue manipulation and suturing. Based on the procedure, anesthesia may be provided locally or as general anesthesia. Spinal anesthesia may be used when the surgical site is too large or deep for a local block, but general anesthesia may not be desirable. With local and spinal anesthesia, the surgical site is anesthetized, but the patient can remain conscious or minimally sedated. In contrast, general anesthesia renders the patient unconscious and paralyzed during surgery. The patient is intubated and is placed on a mechanical ventilator, and anesthesia is produced by a combination of injected and inhaled agents.
Choice of surgical method and anaesthetic technique aims to reduce risk of complications, shorten time needed for recovery and minimise the surgical stress response.
Surgery.
An incision is made to access the surgical site. Blood vessels may be clamped or cauterized to prevent bleeding, and retractors may be used to expose the site or keep the incision open. The approach to the surgical site may involve several layers of incision and dissection, as in abdominal surgery, where the incision must traverse skin, subcutaneous tissue, three layers of muscle and then peritoneum. In certain cases, bone may be cut to further access the interior of the body; for example, cutting the skull for brain surgery or cutting the sternum for thoracic (chest) surgery to open up the rib cage. Whilst in surgery health and safety is used to prevent infection or further spreading of the disease. The surgeon will remove hair from the face and eyes, using a head hat. Hands, wrists and forearms are washed thoroughly to prevent germs getting into the operated body, then gloves are placed onto the hands. A PVC apron will be worn at all times, to stop any contamination. A yellow substance – typically an antiseptic iodine solution – is lighly coated onto the located area of the patient's body that will be performed on, this stops germs and disease infecting areas of the body, whilst the patient is being cut into.
Work to correct the problem in body then proceeds. This work may involve:
Blood or blood expanders may be administered to compensate for blood lost during surgery. Once the procedure is complete, sutures or staples are used to close the incision. Once the incision is closed, the anesthetic agents are stopped and/or reversed, and the patient is taken off ventilation and extubated (if general anesthesia was administered).
Post-operative care.
After completion of surgery, the patient is transferred to the post anesthesia care unit and closely monitored. When the patient is judged to have recovered from the anesthesia, he/she is either transferred to a surgical ward elsewhere in the hospital or discharged home. During the post-operative period, the patient's general function is assessed, the outcome of the procedure is assessed, and the surgical site is checked for signs of infection. There are several risk factors associated with postoperative complications, such as immune deficienty and obesity. Obesity has long been considered a risk factor for adverse post-surgical outcomes. It has been linked to many disorders such as obesity hypoventilation syndrome, atelectasis and pulmonary embolism, adverse cardiovascular effects, and wound healing complications. If removable skin closures are used, they are removed after 7 to 10 days post-operatively, or after healing of the incision is well under way.
It is not uncommon for surgical drains (see Drain (surgery)) to be required to remove blood or fluid from the surgical wound during recovery. Mostly these drains stay in until the volume tapers off, then they are removed. These drains can become clogged, leading to retained blood complications or abscess.
Postoperative therapy may include adjuvant treatment such as chemotherapy, radiation therapy, or administration of medication such as anti-rejection medication for transplants. Other follow-up studies or rehabilitation may be prescribed during and after the recovery period.
The use of topical antibiotics on surgical wounds does not reduce infection rates in comparison with non-antibiotic ointment or no ointment at all. Antibiotic ointments will irritate the skin, slow healing, and greatly increase risk of developing contact dermatitis and antibiotic resistance. Because of this, they should only be used when a person shows signs of infection and not as a preventative.
Through a retrospective analysis of national administrative data, the association between mortality and day of elective surgical procedure suggests a higher risk in procedures carried out later in the working week and on weekends. The odds of death were 44% and 82% higher respectively when comparing procedures on a Friday to a weekend procedure. This “weekday effect” has been postulated to be from several factors including poorer availability of services on a weekend, and also, decrease number and level of experience over a weekend.
Epidemiology.
Of the 38.6 million hospital stays that occurred in U.S. hospitals in 2011, 29% included at least one operating room procedure. These stays accounted for 48% of the total $387 billion in hospital costs.
In total, there were over 15 million operating room procedures performed in U.S. hospitals in 2011. The overall number of procedures remained stable from 2001-2011.
A study of data from 2003-2011 showed that U.S. hospital costs were highest for the surgical service line; the surgical service line costs were $17,600 in 2003 and projected to be $22,500 in 2013. For hospital stays in 2012 in the United States, private insurance had the highest percentage of surgical expenditure. Mean hospital costs in the United States in 2012 were highest for surgical stays.
In special populations.
Elderly people.
Older adults have widely varying physical health. Frail elderly people are at significant risk of post-surgical complications and the need for extended care. Assessment of older patients before elective surgery can accurately predict the patients' recovery trajectories. One frailty scale uses five items: unintentional weight loss, muscle weakness, exhaustion, low physical activity, and slowed walking speed. A healthy person scores 0; a very frail person scores 5. Compared to non-frail elderly people, people with intermediate frailty scores (2 or 3) are twice as likely to have post-surgical complications, spend 50% more time in the hospital, and are three times as likely to be discharged to a skilled nursing facility instead of to their own homes. Frail elderly patients (score of 4 or 5) have even worse outcomes, with the risk of being discharged to a nursing home rising to twenty times the rate for non-frail elderly people.
Other populations.
Surgery on children requires considerations which are not common in adult surgery. Children and adolescents are still developing physically and mentally making it difficult for them to make informed decisions and give consent for surgical treatments. Bariatric surgery in youth is among the controversial topics related to surgery in children.
A person with a debilitating medical condition may have special needs during a surgery which a typical patient would not.
Doctors perform surgery with the consent of the patient. Some patients are able to give better informed consent than others. Populations such as incarcerated persons, the mentally incompetent, persons subject to coercion, and other people who are not able to make decisions with the same authority as a typical patient have special needs when making decisions about their personal healthcare, including surgery.
In Low and Middle Income Countries.
In 2014 the Lancet Commission on Global Surgery was launched to examine the case for surgery as an integral component of global health care and to provide recommendations regarding the delivery of surgical and anesthesia services in low and middle income countries. The primary conclusions of the study were as follows:
History.
Ancient Egypt.
Surgical treatments date back to the prehistoric era. The oldest for which there is evidence is trepanation, in which a hole is drilled or scraped into the skull, thus exposing the dura mater in order to treat health problems related to intra cranial pressure and other diseases. Prehistoric surgical techniques are seen in Ancient Egypt, where a mandible dated to approximately 2650 BCE shows two perforations just below the root of the first molar, indicating the draining of an abscessed tooth. Surgical texts from ancient Egypt date back about 3500 years ago. Surgical operations were performed by priests, specialized in medical treatments similar to today., and used sutures to close wounds. Infections were treated with honey.
India and China.
Remains from the early Harappan periods of the Indus Valley Civilization (c. 3300 BCE) show evidence of teeth having been drilled dating back 9,000 years. Susruta was an ancient Indian surgeon commonly credited as the author of the treatise Sushruta Samhita. He is dubbed as the "founding father of surgery" and his period is usually placed between the period of 1200 BC - 600 BC. One of the earliest known mention of the name is from the "Bower Manuscript" where Sushruta is listed as one of the ten sages residing in the Himalayas. Texts also suggest that he learned surgery at Kasi from Lord Dhanvantari, the god of medicine in Hindu mythology. It is one of the oldest known surgical texts and it describes in detail the examination, diagnosis, treatment, and prognosis of numerous ailments, as well as procedures on performing various forms of cosmetic surgery, plastic surgery and rhinoplasty.
Instruments resembling surgical tools have also been found in the archaeological sites of Bronze Age China dating from the Shang Dynasty, along with seeds likely used for herbalism.
Ancient Greece.
In ancient Greece, temples dedicated to the healer-god Asclepius, known as "Asclepieia" (, sing. "Asclepieion" "Ασκληπιείον"), functioned as centers of medical advice, prognosis, and healing. In the Asclepieion of Epidaurus, some of the surgical cures listed, such as the opening of an abdominal abscess or the removal of traumatic foreign material, are realistic enough to have taken place. The Greek Galen was one of the greatest surgeons of the ancient world and performed many audacious operations—including brain and eye surgery—that were not tried again for almost two millennia.
In the Middle East, surgery was developed to a high degree in the Islamic world. Abulcasis (Abu al-Qasim Khalaf ibn al-Abbas Al-Zahrawi), an Andalusian-Arab physician and scientist who practised in the Zahra suburb of Córdoba, wrote medical texts that influenced European surgical procedures.
Early Modern Europe.
In Europe, the demand grew for surgeons to formally study for many years before practicing; universities such as Montpellier, Padua and Bologna were particularly renowned. In the 15th century, Rogerius Salernitanus composed his "Chirurgia", laying the foundation for modern Western surgical manuals. Barber-surgeons generally had a bad reputation that was not to improve until the development of academic surgery as a specialty of medicine, rather than an accessory field. Basic surgical principles for asepsis etc., are known as Halsteads principles.
There were some important advances to the art of surgery during this period. The professor of anatomy at the University of Padua, Andreas Vesalius, was a pivotal figure in the Renaissance transition from classical medicine and anatomy based on the works of Galen, to an empirical approach of 'hands-on' dissection. In his anatomic treatis, "De humani corporis fabrica", he exposed the many anatomical errors in Galen and advocated that all surgeons should train by engaging in practical dissections themselves.
The second figure of importance in this era was Ambroise Paré (sometimes spelled "Ambrose"), a French army surgeon from the 1530s until his death in 1590. The practice for cauterizing gunshot wounds on the battlefield had been to use boiling oil; an extremely dangerous and painful procedure. Paré began to employ a less irritating emollient, made of egg yolk, rose oil and turpentine. He also described more efficient techniques for the effective ligation of the blood vessels during an amputation.
Modern surgery.
The discipline of surgery was put on a sound, scientific footing during the Age of Enlightenment in Europe. An important figure in this regard was the English surgical scientist, John Hunter, generally regarded as the father of modern scientific surgery. He brought an empirical and experimental approach to the science and was renowned around Europe for the quality of his research and his written works. Hunter reconstructed surgical knowledge from scratch; refusing to rely on the testimonies of others, he conducted his own surgical experiments to determine the truth of the matter. To aid comparative analysis, he built up a collection of over 13,000 specimens of separate organ systems, from the simplest plants and animals to humans.
He greatly advanced knowledge of venereal disease and introduced many new techniques of surgery, including new methods for repairing damage to the Achilles tendon and a more effective method for applying ligature of the arteries in case of an aneurysm. He was also one of the first to understand the importance of pathology, the danger of the spread of infection and how the problem of inflammation of the wound, bone lesions and even tuberculosis often undid any benefit that was gained from the intervention. He consequently adopted the position that all surgical procedures should be used only as a last resort.
Other important 18th and early 19th century surgeons included Percival Pott (1713 -1788) who described tuberculosis on the spine and first demonstrated that a cancer may be caused by an environmental carcinogen - (he noticed a connection between chimney sweep's exposure to soot and their high incidence of scrotal cancer). Astley Paston Cooper (1768-1841) first performed a successful ligation of the abdominal aorta, and James Syme (1799-1870) pioneered the Symes Amputation for the ankle joint and successfully carried out the first hip disarticulation.
Modern pain control through anesthesia was discovered in the mid-19th century. Before the advent of anesthesia, surgery was a traumatically painful procedure and surgeons were encouraged to be as swift as possible to minimize patient suffering. This also meant that operations were largely restricted to amputations and external growth removals. Beginning in the 1840s, surgery began to change dramatically in character with the discovery of effective and practical anaesthetic chemicals such as ether, first used by the American surgeon Crawford Long, and chloroform, discovered by James Young Simpson and later pioneered by John Snow, physician to Queen Victoria. In addition to relieving patient suffering, anaesthesia allowed more intricate operations in the internal regions of the human body. In addition, the discovery of muscle relaxants such as curare allowed for safer applications.
Infection and antisepsis.
Unfortunately, the introduction of anesthetics encouraged more surgery, which inadvertently caused more dangerous patient post-operative infections. The concept of infection was unknown until relatively modern times. The first progress in combating infection was made in 1847 by the Hungarian doctor Ignaz Semmelweis who noticed that medical students fresh from the dissecting room were causing excess maternal death compared to midwives. Semmelweis, despite ridicule and opposition, introduced compulsory handwashing for everyone entering the maternal wards and was rewarded with a plunge in maternal and fetal deaths, however the Royal Society dismissed his advice.
Until the pioneering work of British surgeon Joseph Lister in the 1860s, most medical men believed that chemical damage from exposures to bad air (see "miasma") was responsible for infections in wounds, and facilities for washing hands or a patient's wounds were not available. Lister became aware of the work of French chemist Louis Pasteur, who showed that rotting and fermentation could occur under anaerobic conditions if micro-organisms were present. Pasteur suggested three methods to eliminate the micro-organisms responsible for gangrene: filtration, exposure to heat, or exposure to chemical solutions. Lister confirmed Pasteur's conclusions with his own experiments and decided to use his findings to develop antiseptic techniques for wounds. As the first two methods suggested by Pasteur were inappropriate for the treatment of human tissue, Lister experimented with the third, spraying carbolic acid on his instruments. He found that this remarkably reduced the incidence of gangrene and he published his results in "The Lancet".
Lister continued to develop improved methods of antisepsis and asepsis when he realised that infection could be better avoided by preventing bacteria from getting into wounds in the first place. This led to the rise of sterile surgery. Lister introduced the Steam Steriliser to sterilize equipment, instituted rigorous hand washing and later implemented the wearing of rubber gloves. These three crucial advances – the adoption of a scientific methodology toward surgical operations, the use of anaesthetic and the introduction of sterilised equipment – laid the groundwork for the modern invasive surgical techniques of today.
The use of X-rays as an important medical diagnostic tool began with their discovery in 1895 by German physicist Wilhelm Röntgen. He noticed that these rays could penetrate the skin, allowing the skeletal structure to be captured on a specially treated photographic plate.

</doc>
<doc id="45600" url="https://en.wikipedia.org/wiki?curid=45600" title="Reed–Solomon error correction">
Reed–Solomon error correction

Reed–Solomon codes are an important group of error-correcting codes that were introduced by Irving S. Reed and Gustave Solomon in 1960.
They have many important applications, the most prominent of which include consumer technologies such as CDs, DVDs, Blu-ray Discs, QR Codes, data transmission technologies such as DSL and WiMAX, broadcast systems such as DVB and ATSC, and storage systems such as RAID 6. They are also used in satellite communication.
In coding theory, the Reed–Solomon code belongs to the class of non-binary cyclic error-correcting codes. The Reed–Solomon code is based on univariate polynomials over finite fields.
It is able to detect and correct multiple symbol errors. By adding check symbols to the data, a Reed–Solomon code can detect any combination of up to erroneous symbols, or correct up to symbols. As an erasure code, it can correct up to known erasures, or it can detect and correct combinations of errors and erasures. 
Furthermore, Reed–Solomon codes are suitable as multiple-burst bit-error correcting codes, since a sequence of consecutive bit errors can affect at most two symbols of size . The choice of is up to the designer of the code, and may be selected within wide limits.
History.
Reed–Solomon codes were developed in 1960 by Irving S. Reed and Gustave Solomon, who were then staff members of MIT Lincoln Laboratory. Their seminal article was titled "Polynomial Codes over Certain Finite Fields.". The original encoding scheme described in the Reed Solomon article used a variable polynomial based on the message to be encoded, which made decoding impractical for all but the simplest of cases. This was resolved by changing the encoding scheme to use a fixed polynomial known to both encoder and decoder. A practical decoder developed by Daniel Gorenstein and Neal Zierler was described in a MIT Lincoln Laboratory report by Zierler in January 1960 and later in a paper in June 1961. During the same period, work was also being done on BCH codes and Reed-Solomon codes were considered as a special class of BCH codes at the time. The Gorenstein-Zierler decoder and the related work on BCH codes are described in a book Error Correcting Codes by W. Wesley Peterson (1961).
An improved decoder was developed in 1969 by Elwyn Berlekamp and James Massey, and is since known as the Berlekamp–Massey decoding algorithm. Another improved decoder was developed in 1975 by Yasuo Sugiyama, based on the extended Euclidean algorithm.
In 1977, Reed–Solomon codes were implemented in the Voyager program in the form of concatenated error correction codes. The first commercial application in mass-produced consumer products appeared in 1982 with the compact disc, where two interleaved Reed–Solomon codes are used. Today, Reed–Solomon codes are widely implemented in digital storage devices and digital communication standards, though they are being slowly replaced by more modern low-density parity-check (LDPC) codes or turbo codes. For example, Reed–Solomon codes are used in the Digital Video Broadcasting (DVB) standard DVB-S, but LDPC codes are used in its successor, DVB-S2.
Applications.
Data storage.
Reed–Solomon coding is very widely used in mass storage systems to correct
the burst errors associated with media defects.
Reed–Solomon coding is a key component of the compact disc. It was the first use of strong error correction coding in a mass-produced consumer product, and DAT and DVD use similar schemes. In the CD, two layers of Reed–Solomon coding separated by a 28-way convolutional interleaver yields a scheme called Cross-Interleaved Reed–Solomon Coding (CIRC). The first element of a CIRC decoder is a relatively weak inner (32,28) Reed–Solomon code, shortened from a (255,251) code with 8-bit symbols. This code can correct up to 2 byte errors per 32-byte block. More importantly, it flags as erasures any uncorrectable blocks, i.e., blocks with more than 2 byte errors. The decoded 28-byte blocks, with erasure indications, are then spread by the deinterleaver to different blocks of the (28,24) outer code. Thanks to the deinterleaving, an erased 28-byte block from the inner code becomes a single erased byte in each of 28 outer code blocks. The outer code easily corrects this, since it can handle up to 4 such erasures per block.
The result is a CIRC that can completely correct error bursts up to 4000 bits, or about 2.5 mm on the disc surface. This code is so strong that most CD playback errors are almost certainly caused by tracking errors that cause the laser to jump track, not by uncorrectable error bursts.
DVDs use a similar scheme, but with much larger blocks, a (208,192) inner code, and a (182,172) outer code.
Reed–Solomon error correction is also used in parchive files which are commonly posted accompanying multimedia files on USENET. The Distributed online storage service Wuala also makes use of Reed–Solomon when breaking up files.
Bar code.
Almost all two-dimensional bar codes such as PDF-417, MaxiCode, Datamatrix, QR Code, and Aztec Code use Reed–Solomon error correction to allow correct reading even if a portion of the bar code is damaged. When the bar code scanner cannot recognize a bar code symbol, it will treat it as an erasure.
Reed–Solomon coding is less common in one-dimensional bar codes, but is used by the PostBar symbology.
Data transmission.
Specialized forms of Reed–Solomon codes, specifically Cauchy-RS and Vandermonde-RS, can be used to overcome the unreliable nature of data transmission over erasure channels. The encoding process assumes a code of RS("N", "K") which results in "N" codewords of length "N" symbols each storing "K" symbols of data, being generated, that are then sent over an erasure channel.
Any combination of "K" codewords received at the other end is enough to reconstruct all of the "N" codewords. The code rate is generally set to 1/2 unless the channel's erasure likelihood can be adequately modelled and is seen to be less. In conclusion, "N" is usually 2"K", meaning that at least half of all the codewords sent must be received in order to reconstruct all of the codewords sent.
Reed–Solomon codes are also used in xDSL systems and CCSDS's Space Communications Protocol Specifications as a form of forward error correction.
Space transmission.
One significant application of Reed–Solomon coding was to encode the digital pictures sent back by the Voyager space probe.
Voyager introduced Reed–Solomon coding concatenated with convolutional codes, a practice that has since become very widespread in deep space and satellite (e.g., direct digital broadcasting) communications.
Viterbi decoders tend to produce errors in short bursts. Correcting these burst errors is a job best done by short or simplified Reed–Solomon codes.
Modern versions of concatenated Reed–Solomon/Viterbi-decoded convolutional coding were and are used on the Mars Pathfinder, Galileo, Mars Exploration Rover and Cassini missions, where they perform within about 1–1.5 dB of the ultimate limit, being the Shannon capacity.
These concatenated codes are now being replaced by more powerful turbo codes.
Constructions.
The Reed–Solomon code is actually a family of codes:
For every choice of the three parameters "k" < "n" ≤ "q", there is a Reed–Solomon code that has an alphabet of size "q", a block length "n", and a message length "k".
Moreover, the alphabet is interpreted as the finite field of order "q", and thus, "q" has to be a prime power.
In the most useful parameterizations of the Reed–Solomon code, the block length is usually some constant multiple of the message length, that is, the rate is some constant, and furthermore, the block length is equal to or one less than the alphabet size, that is, or .
Reed & Solomon's original view: The codeword as a sequence of values.
There are different encoding procedures for the Reed–Solomon code, and thus, there are different ways to describe the set of all codewords.
In the original view of , every codeword of the Reed–Solomon code is a sequence of function values of a polynomial of degree less than "k". One issue with this view is that decoding and checking for errors is not practical except for the simplest of cases. In order to obtain a codeword of the Reed–Solomon code, the message is interpreted as the description of a polynomial "p" of degree less than "k" over the finite field "F" with "q" elements.
In turn, the polynomial "p" is evaluated at "n" distinct points formula_1 of the field "F", and the sequence of values is the corresponding codeword.
Formally, the set formula_2 of codewords of the Reed–Solomon code is defined as follows:
Since any two "distinct" polynomials of degree less than formula_4 agree in at most formula_5 points, this means that any two codewords of the Reed–Solomon code disagree in at least formula_6 positions.
Furthermore, there are two polynomials that do agree in formula_5 points but are not equal, and thus, the distance of the Reed–Solomon code is exactly formula_8.
Then the relative distance is formula_9, where formula_10 is the rate.
This trade-off between the relative distance and the rate is asymptotically optimal since, by the Singleton bound, "every" code satisfies formula_11.
Being a code that achieves this optimal trade-off, the Reed–Solomon code belongs to the class of maximum distance separable codes.
While the number of different polynomials of degree less than "k" and the number of different messages are both equal to formula_12, and thus every message can be uniquely mapped to such a polynomial, there are different ways of doing this encoding.
The original construction of interprets the message "x" as the "coefficients" of the polynomial "p", whereas subsequent constructions interpret the message as the "values" of the polynomial at the first "k" points formula_13 and obtain the polynomial "p" by interpolating these values with a polynomial of degree less than "k".
The latter encoding procedure, while being slightly less efficient, has the advantage that it gives rise to a systematic code, that is, the original message is always contained as a subsequence of the codeword.
In many contexts it is convenient to choose the sequence formula_1 of evaluation points so that they exhibit some additional structure.
In particular, it is useful to choose the sequence of successive powers of a primitive root formula_15 of the field formula_16, that is, formula_15 is generator of the finite field's multiplicative group and the sequence is defined as formula_18 for all formula_19.
This sequence contains all elements of formula_16 except for formula_21, so in this setting, the block length is formula_22.
Then it follows that, whenever formula_23 is a polynomial over formula_16, then the function formula_25 is also a polynomial of the same degree, which gives rise to a codeword that is a cyclic left-shift of the codeword derived from formula_23; thus, this construction of Reed–Solomon codes gives rise to a cyclic code.
Simple encoding procedure: The message as a sequence of coefficients.
In the original construction of , the message formula_27 is mapped to the polynomial formula_28 with
As described above, the codeword is then obtained by evaluating formula_30 at formula_31 different points formula_1 of the field formula_16.
Thus the classical encoding function formula_34 for the Reed–Solomon code is defined as follows: 
This function formula_36 is a linear mapping, that is, it satisfies formula_37 for the following formula_38-matrix formula_39 with elements from formula_16:
This matrix is the transpose of a Vandermonde matrix over formula_16.
In other words, the Reed–Solomon code is a linear code, and in the classical encoding procedure, its generator matrix is formula_39.
Systematic encoding procedure: The message as an initial sequence of values.
As mentioned above, there is an alternative way to map codewords formula_44 to polynomials formula_28.
In this alternative encoding procedure, the polynomial formula_28 is the unique polynomial of degree less than formula_4 such that
To compute this polynomial formula_28 from formula_44, one can use Lagrange interpolation.
Once it has been found, it is evaluated at the other points formula_52 of the field.
The alternative encoding function formula_34 for the Reed–Solomon code is then again just the sequence of values: 
This time, however, the first formula_4 entries of the codeword are exactly equal to formula_44, so this encoding procedure gives rise to a systematic code.
It can be checked that the alternative encoding function is a linear mapping as well.
The BCH view: The codeword as a sequence of coefficients.
In this view, the sender again maps the message formula_44 to a polynomial formula_28, and for this, any of the two mappings above can be used (where the message is either interpreted as the coefficients of formula_28 or as the initial sequence of values of formula_28).
Once the sender has constructed the polynomial formula_28 in some way, however, instead of sending the "values" of formula_28 at all points, the sender computes some related polynomial formula_67 of degree at most formula_68 for formula_22 and sends the formula_31 "coefficients" of that polynomial.
The polynomial formula_71 is constructed by multiplying the message polynomial formula_72, which has degree at most formula_5, with a generator polynomial formula_74 of degree formula_75 that is known to both the sender and the receiver. The generator polynomial formula_76 is defined as the polynomial whose roots are exactly formula_77, i.e.,
The transmitter sends the formula_22 coefficients of formula_80.
Thus, in the BCH view of Reed Solomon codes, the set formula_81 of codewords is defined for formula_22 as follows:
With this definition of the codewords, it can be immediately seen that a Reed–Solomon code is a polynomial code, and in particular a BCH code. The generator polynomial formula_74 is the minimal polynomial with roots formula_85 as defined above, and the codewords are exactly the polynomials that are divisible by formula_74.
Since Reed–Solomon codes are a special case of BCH codes and the Berlekamp–Massey algorithm has been designed for the decoding of such codes, it is applicable to Reed–Solomon codes:
The receiver interprets the received word as the coefficients of a polynomial formula_87.
If no error has occurred during the transmission, that is, if formula_88, then the receiver can use polynomial division to determine the message polynomial formula_89.
In general, the receiver can use polynomial division to construct the unique polynomials formula_23 and formula_91, such that formula_91 has degree less than the degree of formula_74 and
If the remainder polynomial formula_91 is not identically zero, then an error has occurred during the transmission.
The receiver can evaluate formula_87 at the roots of formula_74 and build a system of equations that eliminates formula_71 and identifies which coefficients of formula_87 are in error, and the magnitude of each coefficient's error ( and ).
If the system of equations can be solved, then the receiver knows how to modify the received word formula_87 to get the most likely codeword formula_71 that was sent.
Systematic encoding procedure.
The above encoding procedure for the BCH view of Reed–Solomon codes is classical, but does not give rise to a systematic encoding procedure, i.e., the codewords do not necessarily contain the message as a subsequence.
To remedy this fact, instead of sending formula_102, the encoder constructs the transmitted polynomial formula_103 such that the coefficients of the formula_4 largest monomials are equal to the corresponding coefficients of formula_105, and the lower-order coefficients of formula_103 are chosen exactly in such a way that formula_103 becomes divisible by formula_76.
Then the coefficients of formula_105 are a subsequence of the coefficients of formula_103.
To get a code that is overall systematic, we construct the message polynomial formula_105 by interpreting the message as the sequence of its coefficients.
Formally, the construction is done by multiplying formula_105 by formula_113 to make room for the formula_114 check symbols, dividing that product by formula_76 to find the remainder, and then compensating for that remainder by subtracting it.
The formula_116 check symbols are created by computing the remainder formula_117:
Note that the remainder has degree at most formula_119, whereas the coefficients of formula_120 in the polynomial formula_121 are zero. Therefore, the following definition of the codeword formula_103 has the property that the first formula_4 coefficients are identical to the coefficients of formula_105:
As a result, the codewords formula_103 are indeed elements of formula_81, that is, they are divisible by the generator polynomial formula_76:
Duality of the two views - discrete Fourier transform.
At first sight, the two views of Reed–Solomon codes above seem very different. In the first definition, codewords in the set formula_2 are "values" of polynomials, whereas in the second set formula_81, they are "coefficients". Moreover, the generator polynomials in the first definition are of degree less than formula_4, are variable, and unknown to the decoder, whereas those in the second definition are of degree formula_75, are required to have specific roots, and are known to both encoder and decoder. Although the codewords as produced by the above encoder schemes are not the same, there is a duality between the coefficients of polynomials and their values that would allow the same codeword to be considered as a set of coefficients or a set of values.
The equivalence of the two definitions can be proved using the discrete Fourier transform. This transform, which exists in all finite fields as well as the complex numbers, establishes a duality between the coefficients of polynomials and their values. This duality can be approximately summarized as follows: Let formula_105 and formula_135 be two polynomials of degree less than formula_31. If the "values" of formula_105 are the "coefficients" of formula_135, then (up to a scalar factor and reordering), the "values" of formula_135 are the "coefficients" of formula_105. For this to make sense, the values must be taken at locations formula_141, for formula_142, where formula_15 is a primitive formula_31th root of unity.
To be more precise, let
and assume formula_105 and formula_135 are related by the discrete Fourier transform. Then the coefficients and values of formula_105 and formula_135 are related as follows: for all formula_142, formula_152 and formula_153 or in the case of a binary field where addition is effectively xor, formula_154.
Using these facts, we have: formula_155 is a code word of the Reed–Solomon code according to the first definition
This shows that the two definitions are equivalent. However, the practical decoders described below require a generator polynomial known to the decoder, and view a codeword as a set of coefficients.
Remarks.
Designers are not required to use the "natural" sizes of Reed–Solomon code blocks. A technique known as "shortening" can produce a smaller code of any desired size from a larger code. For example, the widely used (255,223) code can be converted to a (160,128) code by padding the unused portion of the source block with 95 binary zeroes and not transmitting them. At the decoder, the same portion of the block is loaded locally with binary zeroes. The Delsarte-Goethals-Seidel theorem illustrates an example of an application of shortened Reed–Solomon codes. In parallel to shortening, a technique known as puncturing allows omitting some of the encoded parity symbols.
Properties.
The Reed–Solomon code is a ["n", "k", "n" − "k" + 1] code; in other words, it is a linear block code of length "n" (over "F") with dimension "k" and minimum Hamming distance "n" − "k" + 1. The Reed–Solomon code is optimal in the sense that the minimum distance has the maximum value possible for a linear code of size ("n", "k"); this is known as the Singleton bound. Such a code is also called a maximum distance separable (MDS) code.
The error-correcting ability of a Reed–Solomon code is determined by its minimum distance, or equivalently, by formula_167, the measure of redundancy in the block. If the locations of the error symbols are not known in advance, then a Reed–Solomon code can correct up to formula_168 erroneous symbols, i.e., it can correct half as many errors as there are redundant symbols added to the block. Sometimes error locations are known in advance (e.g., "side information" in demodulator signal-to-noise ratios)—these are called erasures. A Reed–Solomon code (like any MDS code) is able to correct twice as many erasures as errors, and any combination of errors and erasures can be corrected as long as the relation 2"E" + "S" ≤ "n" − "k" is satisfied, where formula_169 is the number of errors and formula_170 is the number of erasures in the block.
For practical uses of Reed–Solomon codes, it is common to use a finite field formula_16 with formula_172 elements. In this case, each symbol can be represented as an formula_173-bit value. 
The sender sends the data points as encoded blocks, and the number of symbols in the encoded block is formula_174. Thus a Reed–Solomon code operating on 8-bit symbols has formula_175 symbols per block. (This is a very popular value because of the prevalence of byte-oriented computer systems.) The number formula_4, with formula_177, of "data" symbols in the block is a design parameter. A commonly used code encodes formula_178 eight-bit data symbols plus 32 eight-bit parity symbols in an formula_179-symbol block; this is denoted as a formula_180 code, and is capable of correcting up to 16 symbol errors per block.
The Reed–Solomon code properties discussed above make them especially well-suited to applications where errors occur in bursts. This is because it does not matter to the code how many bits in a symbol are in error — if multiple bits in a symbol are corrupted it only counts as a single error. Conversely, if a data stream is not characterized by error bursts or drop-outs but by random single bit errors, a Reed–Solomon code is usually a poor choice compared to a binary code.
The Reed–Solomon code, like the convolutional code, is a transparent code. This means that if the channel symbols have been inverted somewhere along the line, the decoders will still operate. The result will be the inversion of the original data. However, the Reed–Solomon code loses its transparency when the code is shortened. The "missing" bits in a shortened code need to be filled by either zeros or ones, depending on whether the data is complemented or not. (To put it another way, if the symbols are inverted, then the zero-fill needs to be inverted to a one-fill.) For this reason it is mandatory that the sense of the data (i.e., true or complemented) be resolved before Reed–Solomon decoding.
Error correction algorithms.
The decoders described below use the .
Peterson–Gorenstein–Zierler decoder.
Daniel Gorenstein and Neal Zierler developed a practical decoder that was described in a MIT Lincoln Laboratory report by Zierler in January 1960 and later in a paper in June 1961. The Gorenstein-Zierler decoder and the related work on BCH codes are described in a book Error Correcting Codes by W. Wesley Peterson (1961).
Syndrome decoding.
The transmitted message is viewed as the coefficients of a polynomial "s"("x") that is divisible by a generator polynomial "g"("x").
where "α" is a primitive root.
Since "s"("x") is divisible by generator "g"("x"), it follows that
The transmitted polynomial is corrupted in transit by an error polynomial "e"("x") to produce the received polynomial "r"("x").
where "ei" is the coefficient for the "i"-th power of "x". Coefficient "ei" will be zero if there is no error at that power of "x" and nonzero if there is an error. If there are "ν" errors at distinct powers "ik" of "x", then
The goal of the decoder is to find the number of errors ("ν"), the positions of the errors ("ik"), and the error values at those positions ("eik"). From those, e(x) can be calculated and subtracted from r(x) to get the original message s(x).
The syndromes "S""j" are defined as
The advantage of looking at the syndromes is that the message polynomial drops out. Another possible way of calculating e(x) is using polynomial interpolation to find the only polynomial that passes through the points formula_188 (Because formula_189), however, this is not used widely because polynomial interpolation is not always feasible in the fields used in Reed–Solomon error correction. For example, it is feasible over the integers (of course), but it is infeasible over the integers modulo a prime.
Error locators and error values.
For convenience, define the error locators "Xk" and error values "Yk" as:
Then the syndromes can be written in terms of the error locators and error values as
The syndromes give a system of "n" − "k" ≥ 2"ν" equations in 2"ν" unknowns, but that system of equations is nonlinear in the "Xk" and does not have an obvious solution. However, if the "Xk" were known (see below), then the syndrome equations provide a linear system of equations that can easily be solved for the "Yk" error values.
Consequently, the problem is finding the "Xk", because then the leftmost matrix would be known, and both sides of the equation could be multiplied by its inverse, yielding Y"k"
Error locator polynomial.
There is a linear recurrence relation that gives rise to a system of linear equations. Solving those equations identifies the error locations.
Define the error locator polynomial Λ("x") as
The zeros of Λ("x") are the reciprocals formula_194:
Multiply both sides by formula_197 and it will still be zero. j is any number such that 1≤j≤v.
Sum for "k" = 1 to "ν"
This reduces to
This yields a system of linear equations that can be solved for the coefficients Λ"i" of the error location polynomial:
The above assumes the decoder knows the number of errors "ν", but that number has not been determined yet. The PGZ decoder does not determine "ν" directly but rather searches for it by trying successive values. The decoder first assumes the largest value for a trial "ν" and sets up the linear system for that value. If the equations can be solved (i.e., the matrix determinant is nonzero), then that trial value is the number of errors. If the linear system cannot be solved, then the trial "ν" is reduced by one and the next smaller system is examined. 
Obtain the error locators from the error locator polynomial.
Use the coefficients Λ"i" found in the last step to build the error location polynomial. The roots of the error location polynomial can be found by exhaustive search. The error locators are the reciprocals of those roots. Chien search is an efficient implementation of this step.
Calculate the error locations.
Calculate ik by taking the log base a of "Xk". This is generally done using a precomputed lookup table.
Calculate the error values.
Once the error locators are known, the error values can be determined. This can be done by direct solution for "Yk" in the error equations given above, or using the Forney algorithm.
Fix the errors.
Finally, e(x) is generated from ik and eik and then is subtracted from r(x) to get the sent message s(x).
Berlekamp–Massey decoder.
The Berlekamp–Massey algorithm is an alternate iterative procedure for finding the error locator polynomial. During each iteration, it calculates a discrepancy based on a current instance of Λ(x) with an assumed number of errors "e":
and then adjusts Λ(x) and "e" so that a recalculated Δ would be zero. The article Berlekamp–Massey algorithm has a detailed description of the procedure. In the following example, C(x) is used to represent Λ(x).
Example.
Consider the Reed–Solomon code defined in with and (this is used in PDF417 barcodes). The generator polynomial is
If the message polynomial is , then the codeword is calculated as follows.
Errors in transmission might cause this to be received instead.
The syndromes are calculated by evaluating "r" at powers of "α".
To correct the errors, first use the Berlekamp–Massey algorithm to calculate the error locator polynomial.
The final value of "C" is the error locator polynomial, Λ("x"). The zeros can be found by trial substitution. They are "x"1 = 757 = 3−3 and "x"2 = 562 = 3−4, corresponding to the error locations. To calculate the error values, apply the Forney algorithm.
Subtracting "e"1"x"3 and "e"2"x"4 from the received polynomial "r" reproduces the original codeword "s".
Euclidean decoder.
Another iterative method for calculating both the error locator polynomial and the error value polynomial is based on Sugiyama's adaptation of the Extended Euclidean algorithm .
Define S(x) , Λ(x) , and Ω(x) for "t" syndromes and "e" errors:
The key equation is:
For "t" = 6 and "e" = 3:
The middle terms are zero due to the relationship between Λ and syndromes.
The extended Euclidean algorithm can find a series of polynomials of the form
Ai(x) S(x) + Bi(x) xt = Ri(x)
where the degree of R decreases as i increases. Once the degree of Ri(x) < t/2, then
Ai(x) = Λ(x)
Bi(x) = -Q(x)
Ri(x) = Ω(x).
B(x) and Q(x) don't need to be saved, so the algorithm becomes:
to set low order term of Λ(x) to 1, divide Λ(x) and Ω(x) by Ai(0):
Ai(0) is the constant (low order) term of Ai.
Example.
Using the same data as the Berlekamp Massey example above:
Decoder using discrete Fourier transform.
A discrete Fourier transform can be used for decoding. To avoid conflict with syndrome names, let c(x) = s(x) the encoded codeword. r(x) and e(x) are the same as above. Define C(x), E(x), and R(x) as the discrete Fourier transforms of c(x), e(x), and r(x). Since r(x) = c(x) + e(x), and since a discrete Fourier transform is a linear operator, R(x) = C(x) + E(x).
Transform r(x) to R(x) using discrete Fourier transform. Due to the relationship between a polynomial and it's discrete Fourier transform as explained in the duality of the two views, the syndromes and t coefficients of R(x) and E(x) are the same:
Use formula_221 through formula_222 as syndromes (they're the same) and generate the error locator polynomial using the methods from any of the above decoders.
Let v = number of errors. Generate E(x) using the known coefficients formula_223 to formula_224, the error locator polynomial, and these formulas
Then calculate C(x) = R(x) - E(x) and take the inverse transform of C(x) to produce c(x).
Decoding beyond the error-correction bound.
The Singleton bound states that the minimum distance "d" of a linear block code of size ("n","k") is upper-bounded by "n" − "k" + 1. The distance "d" was usually understood to limit the error-correction capability to ⌊"d"/2⌋. The Reed–Solomon code achieves this bound with equality, and can thus correct up to ⌊("n" − "k" + 1)/2⌋ errors. However, this error-correction bound is not exact.
In 1999, Madhu Sudan and Venkatesan Guruswami at MIT published "Improved Decoding of Reed–Solomon and Algebraic-Geometry Codes" introducing an algorithm that allowed for the correction of errors beyond half the minimum distance of the code. It applies to Reed–Solomon codes and more generally to algebraic geometric codes. This algorithm produces a list of codewords (it is a list-decoding algorithm) and is based on interpolation and factorization of polynomials over formula_228 and its extensions.
Soft-decoding.
The algebraic decoding methods described above are hard-decision methods, which means that for every symbol a hard decision is made about its value. For example, a decoder could associate with each symbol an additional value corresponding to the channel demodulator's confidence in the correctness of the symbol. The advent of LDPC and turbo codes, which employ iterated soft-decision belief propagation decoding methods to achieve error-correction performance close to the theoretical limit, has spurred interest in applying soft-decision decoding to conventional algebraic codes. In 2003, Ralf Koetter and Alexander Vardy presented a polynomial-time soft-decision algebraic list-decoding algorithm for Reed–Solomon codes, which was based upon the work by Sudan and Guruswami.
Matlab Example.
Encoder.
Here we present a simple Matlab implementation for an encoder.
Decoder.
Now the decoding part:

</doc>
<doc id="45606" url="https://en.wikipedia.org/wiki?curid=45606" title="Zorba the Greek (film)">
Zorba the Greek (film)

Zorba the Greek (, "Alexis Zorba(s)") is a 1964 British-Greek drama film directed by Cypriot Michael Cacoyannis and starring Anthony Quinn as the title character. It is based on the novel "Zorba the Greek" by Nikos Kazantzakis. The supporting cast includes Alan Bates, Lila Kedrova, Irene Papas and Sotiris Moustakas.
Plot.
Basil (Alan Bates) is a half-English, half-Greek writer raised in Britain who bears the hallmarks of an uptight, middle-class Englishman. He is waiting at the Athens port of Piraeus on mainland Greece to catch a boat to Crete when he meets a gruff, yet enthusiastic peasant and musician named Zorba (Anthony Quinn). Basil explains to Zorba that he is traveling to a rural Cretan village where his father owns some land, with the intention of reopening a lignite mine and perhaps curing his writer's block. Zorba relates his experience with mining and convinces Basil to take him along.
When they arrive at Crete, they take a car to the village where they are greeted enthusiastically by the town's impoverished peasant community. They stay with an old French war widow and courtesan named Madame Hortense (Lila Kedrova) in her self-styled "Hotel Ritz". The audacious Zorba tries to persuade Basil into making a move on the much older Madame Hortense, but when he is understandably reluctant, Zorba seizes the opportunity, and they form a relationship.
Over the next few days, Basil and Zorba attempt to work the old lignite mine, but find it unsafe and shut it down. Zorba then has an idea to use the forest in the nearby mountains for logging (although his specific plan is left ambiguous), however the land is owned by a powerful monastery, so Zorba visits and befriends the monks, getting them drunk. Afterwards, he comes home to Basil and begins to dance in a way that mesmerizes Basil.
Meanwhile, Basil and Zorba get their first introduction to "the Widow" (Irene Papas), a young and attractive widowed woman, who is incessantly teased by the townspeople for not remarrying, especially to a young, local boy who is madly in love with her, but whom she has spurned repeatedly. One rainy afternoon, Basil offers her his umbrella, which she reluctantly takes. Zorba suggests that she is attracted to him, but Basil, ever shy, denies this and refuses to pursue the widow.
Basil hands Zorba some money, and sends him off to the large town of Chania, where Zorba is to buy cable and other supplies for the implementation of his grand plan. Zorba says goodbye to Basil and Madame Hortense, who is by now madly in love with him. In Chania, Zorba entertains himself at a cabaret and strikes up a brief romance with a much younger dancer. In a letter to Basil, he details his exploits and indicates that he has found love. Angered by Zorba's apparent irresponsibility and the squandering of his money, Basil untruthfully tells Madame Hortense that Zorba has declared his love to her and intends to marry her upon his return – to which she is ecstatic to the point of tears. Meanwhile, the Widow returns Basil's umbrella by way of Mimithos (Sotiris Moustakas), the village idiot.
When Zorba eventually returns with supplies and gifts, he is surprised and angered to hear of Basil's lie to Madame Hortense. He also asks Basil about his whereabouts the night before. That night, Basil had gone to the Widow's house, made love to her and spent the night. The brief encounter comes at great cost. A villager catches sight of them, and word spreads, and the young, local boy who is in love with the Widow is taunted mercilessly about it. The next morning, the villagers find his body by the sea, where he has drowned himself out of shame.
The boy's father holds a funeral which the villagers attend. The widow attempts to come inconspicuously, but is blocked from entering the church. She is eventually trapped in the courtyard, then beaten and stoned by the villagers, who hold her responsible for the boy's suicide. Basil, meek and fearful of intervening, tells Mimithos to quickly fetch Zorba. Zorba arrives just as a villager, a friend of the boy, tries to pull a knife and kill the widow. Zorba overpowers the much younger man and disarms him. Thinking that the situation is under control, Zorba asks the Widow to follow him and turns his back. At that moment, the dead boy's father pulls his knife and cuts the widow's throat. She dies at once, as the villagers shuffle away apathetically, whisking the father away. Only Basil, Zorba and Mimithos show any emotion over her murder. Basil proclaims his inability to intervene whereupon Zorba laments the futility of death.
On a rainy day, Basil and Zorba come home and find Madame Hortense waiting. She expresses anger at Zorba for making no progress on the wedding. Zorba conjures up a story that he had ordered a white satin wedding dress, lined with pearls and adorned with real gold. Madame Hortense presents two golden rings she had made and proposes their immediate engagement. Zorba tries to stall, but eventually agrees with gusto, to Basil's surprise.
Some time later, Madame Hortense has contracted pneumonia, and is seen on her deathbed. Zorba stays by her side, along with Basil. Meanwhile, word has spread that "the foreigner" is dying, and since she has no heirs, the State will take her possessions and money. The desperately poor villagers crowd around her hotel, impatiently waiting for her demise so they can steal her belongings. As two old ladies enter her room and gaze expectantly at her, other women try to enter, but Zorba manages to fight them off. At the instant of her death, the women re-enter Madame Hortense's bedroom "en masse" to steal her valued possessions. Zorba leaves with a sigh, as the hotel is ransacked and stripped bare by the shrieking and excited villagers. When Zorba returns to Madame Hortense's bedroom, the room is barren apart from her bed (where she lies) and the bird in her cage. Zorba takes the birdcage with him.
Finally, Zorba's elaborate contraption to transport timber down the hill is complete. A festive ceremony, including lamb on a spit is held, and all the villagers turned out. After a blessing from the priests, Zorba signals the start by firing a rifle in the air. A log comes hurtling down the zip line at a worrying pace, destroying the log itself and slightly damaging part of the contraption. Zorba remains unconcerned and gives orders for a second log. This one also speeds down and shoots straight into the sea. By now the villagers and priests have grown fearful and head for cover. Zorba remains unfazed and orders a third log, which accelerates downhill with such violence that it dislodges the entire contraption, destroying everything. The villagers flee, leaving Basil and Zorba behind.
Basil and Zorba sit by the shore to eat roasted lamb for lunch. Zorba pretends to tell the future from the lamb shank, saying that he foresees a great journey to a big city. He then asks Basil directly when he plans to leave, and Basil replies that he will leave in a few days. Zorba declares his sadness about Basil's imminent departure to England and tells Basil that he is missing madness. Basil asks Zorba to teach him to dance. Zorba teaches him the sirtaki and Basil begins to laugh hysterically at the catastrophic outcome. The story ends with both men enthusiastically dancing the sirtaki on the beach.
Production.
Simone Signoret began filming the role of Madame Hortense; Lila Kedrova replaced her early in the production.
The film was shot on location on the Greek island of Crete. Specific locations featured include the town of Chania, the Apokoronas region and the Akrotiri peninsula. The famed scene in which Quinn's character dances the Sirtaki was filmed on the beach of the village of Stavros.
Reception.
The film was a smash-hit. Produced on a budget of only $783,000, it grossed $9 million at the U.S. box office, earning $4.4 million in U.S. theatrical rentals. At the worldwide box office, the film earned $9.4 million in rentals, placing the worldwide gross between $18.8 million to $23.5 million. It was the 19th highest grossing film of 1964.
The film won three Academy Awards.
The film has an 83% rating at Rotten Tomatoes. On both sides of the Atlantic, the film was applauded and Anthony Quinn came in for the 
best reviews. He was loved as Zorba, along with the other stars, including Greek-born Irene Papas, who worked with Quinn on "The Guns of Navarone".
Cultural influence.
The dance at the end of the film, choreographed by Giorgos Provias, formerly known as "Zorba's dance" and later called Sirtaki, has become a popular cliché of Greek dance.
"Zorba the Greek" was adapted into a 1968 Broadway musical named "Zorba". The play starred Herschel Bernardi: then, the show was revived in 1983, with Anthony Quinn and Lila Kedrova reprising their film roles. It opened to big box office receipts and good reviews, plus 362 performances, more than the original stage production.
The film's music by Mikis Theodorakis, especially the main song, "Zorbas", is well known in popular culture. For example, the song has been used at Yankee Stadium for years to incite crowd participation during a potential rally by the home team. A remake of "Zorbas" by John Murphy and David Hughes was used during the climax shootout-scene in the 1998 Guy Richie film, "Lock Stock and Two Smoking Barrels".
A short film made in Scotland in 1999, "Billy and Zorba", is about a man who believes he is Zorba the Greek.
The film has been referenced in two of actress Nia Vardalos' films. In "My Big Fat Greek Wedding", the family-owned restaurant her character works at is called "Dancing Zorba's"; this is also seen in the short-lived 2003 show "My Big Fat Greek Life". In "My Life In Ruins", Vardalos' character Georgia expresses contempt for the film because of the Greek's love of dancing and Anthony Quinn.
A web browser flash game akin to Dance Dance Revolution was created by Pippin Barr, wherein the player competes with Zorba by taking turns performing Zorba's dance, trying to out-dance each other.

</doc>
<doc id="45607" url="https://en.wikipedia.org/wiki?curid=45607" title="Biosecurity protocol">
Biosecurity protocol

Biosecurity protocol refers to several politically controversial attempts to unify global biosecurity measures and responses, in a similar manner to a biosafety protocol. Although some propose a "Biosecurity Protocol" to extend the Biosafety Protocol to organisms considered weapons (already controlled by UN arms proliferation treaties), others argue this is an inappropriate response to military threats, and argue for a broad biodefense instead. 
As of 2002, the latter view was prevalent in military and scientific circles, the former in NGOs, some United Nations agencies, and Green Parties. Most cooperation was restricted to attempts to define "biosecurity" itself. 
A major issue is whether to accept the Precautionary Principle, or by extension, any restrictions on militarily useful research by major powers. Compromises, e.g. the 2002 US government request to scientists to delete procedural details of experiments on dangerous organisms, are strongly resisted by most American scientists. Extreme positions, e.g. Bill Joy's argument for relinquishment of nanotechnology and artificial intelligence, are considered a legitimate part of the debate, but have yet to achieve any serious political support, even among Green Parties.
Whether these negotiations and compromises will yield a comprehensive biosecurity protocol is doubtful. It seems that basic political differences drive the debate which are unlikely to easily resolve, and that military alliances will influence tax, trade, and tariff systems and import/export restrictions more than any diplomatic or scientific protocol.

</doc>
<doc id="45609" url="https://en.wikipedia.org/wiki?curid=45609" title="Cheetah">
Cheetah

The cheetah () ("Acinonyx jubatus"), also known as the hunting leopard, is a big cat that occurs mainly in eastern and southern Africa and a few parts of Iran. The only extant member of the genus "Acinonyx", it is placed in the subfamily Felinae. The cheetah is characterised by a slender body, deep chest, spotted pelage, a small rounded head, black tear-like streaks on the face, long thin legs and a long spotted tail. Its lightly built, thin form is in sharp contrast with the robust build of the other big cats. The cheetah reaches nearly at the shoulder, and weighs . While it is taller than the leopard, it is notably smaller than the lion. Basically yellowish tan or rufous to greyish white, the coat of the cheetah is uniformly covered with nearly 2,000 black, solid spots.
Cheetah are active mainly during the day; hunting is the major activity. Adult males are sociable despite their territoriality, forming groups called "coalitions". Females are not territorial; they may be solitary or live with their offspring in their home ranges. Carnivores, cheetah mainly prey upon antelopes and gazelles. They will stalk their prey to within , charge towards it and kill it by tripping it during the chase and biting its throat to suffocate it to death. The cheetah's body is specialised for speed; it is the fastest land mammal. Its thin and light body makes it well-suited to short, explosive bursts of speed, rapid acceleration and an ability to execute extreme changes in direction during a sprint. The speed of a hunting cheetah averages during a sprint; the chase is interspersed with a few short bursts of speed, when the animal can clock . Induced ovulators, breeding in cheetah occurs throughout the year. Females, maturing at 21–22 months, have an oestrus lasting one to three days every 12 days. The dominant male approaches and mates with the female without any courtship. Gestation is nearly three months long, resulting in a litter of typically three to five cubs (the number can vary from one to eight). Weaning occurs at six months; siblings tend to stay together for some time. Cheetah cubs face higher mortality than most other mammals, especially in the Serengeti region. Cheetah inhabit a variety of habitats: dry forests, scrub forests, savannahs and grasslands.
Classified as Vulnerable by the IUCN, the cheetah has suffered a substantial decline in its historic range due to rampant hunting in the 20th century. Several African countries have taken steps to improve the standards of cheetah conservation. Thanks to its prowess at hunting, the cheetah was tamed and used to kill game at hunts in the past. The animal has been widely depicted in art, literature, advertising and animation.
Etymology.
The vernacular name "cheetah" () is derived from the Hindi word चीता ("cītā"), which in turn comes from the Sanskrit word चित्रकायः ("") meaning "bright" or "variegated". The first recorded use of this word was in 1610. An alternative name for the cheetah is "hunting leopard".
The scientific name of the cheetah is "Acinonyx jubatus". The generic name "Acinonyx" could have originated from the combination of three Greek words: "a" means "not", "kaina" means thorn, and "onus" means claw. A rough translation of the word would be "non-moving claws", a reference to the limited retractability (capability of being drawn inside) of the claws of the cheetah. The specific name "jubatus" means "maned" in Latin, referring to the dorsal crest of this animal.
Taxonomy and phylogeny.
The cheetah is the only extant species of the genus "Acinonyx". It is classified under the subfamily Felinae and family Felidae, the family that also includes large cats such as lion, tiger and leopard. The species was first described by German naturalist Johann Christian Daniel von Schreber in his 1775 publication "Die Säugethiere in Abbildungen nach der Natur mit Beschreibungen".
The cheetah has a particularly close relationship with the cougar ("Puma concolor") and the jaguarundi ("P. yagouaroundi") in comparison to other felids. These three species together form the "Puma" lineage, one of the eight lineages of Felidae. In fact, the jaguarundi is more closely related to the cougar and the cheetah than to any other felid. The cheetah is also close to "Felis", which comprises smaller cats.
Although the cheetah is an African cat, molecular evidence indicates that all the three species of the "Puma" lineage evolved in North America two to three million years ago, where they possibly had a common ancestor during the Miocene. They possibly diverged from this ancestor 8.25 million years ago. The cheetah diverged from the puma and the jaguarundi around 6.7 million years ago. A genome study concluded that cheetahs originated in North America and spread to Asia and Africa around 100,000 years ago during the late Pleistocene. The result of this first migration also caused the first genetic bottleneck in their population when cheetah became extinct in North America at the end of the last ice age. This was followed by a second bottleneck between 10,000 and 20,000 years ago, further lowering their genetic variability.
Cheetah fossils found in the lower beds of the Olduvai Gorge site in northern Tanzania date back to the Pleistocene. The extinct species of "Acinonyx" are older than the cheetah, with the oldest known from the late Pliocene; these fossils are about three million years old. These species include "Acinonyx pardinensis" (Pliocene epoch), notably larger than the modern cheetah, and "A. intermedius" (mid-Pleistocene period). While the range of "A. intermedius" stretched from Europe to China, "A. pardinensis" spanned over Eurasia as well as eastern and southern Asia. These two species were contemporaries of the cheetah nearly 10,000 years ago, when it occurred throughout Asia, Africa and North America. A variety of larger cheetah believed to have existed in Europe fell to extinction around 0.5 million years ago.
Extinct North American cats resembling the cheetah had historically been assigned to "Felis", "Pumas" or "Acinonyx". However, a phylogenetic analysis in 1990 placed these species under the genus "Miracinonyx". "Miracinonyx" exhibited a high degree of similarity with the cheetah. However, in 1998, a DNA analysis showed that "Miracinonyx inexpectatus", "M. studeri", and "M. trumani" (early to late Pleistocene epoch), found in North America, are not true cheetahs; in fact, they are close relatives of the cougar.
Subspecies.
The five recognised subspecies of the cheetah are:
Genetics.
The diploid number of chromosomes in the cheetah is 38, the same as in any other felid, save for the ocelot and the margay, in whose case the number is 36. A remarkable feature of the cheetah is its unusually low genetic variability in comparison to other felids. Consequently, individuals show considerable genetic similarity to one another, as illustrated by skin grafts, electrophoretic evidence and reproductive surveys. A prolonged period of inbreeding, following a genetic bottleneck during the last ice age, is believed to be the reason behind this anomaly. The consequences of such genetic uniformity might include a low sperm count, motility, deformed flagella, difficulty in captive breeding and susceptibility to disease.
King cheetah.
The king cheetah is a variety of cheetah with a rare mutation for cream-coloured fur marked with large, blotchy spots and three dark, wide stripes extending from their neck to the tail. In 1926, Major A. Cooper wrote about an animal he had shot near Salisbury (modern-day Harare) in southern Rhodesia (modern-day Zimbabwe). Describing the animal, he noted its remarkable similarity to the cheetah, but the body of this individual was covered with fur as thick as that of a snow leopard and the spots merged to form stripes. He suggested that it could be a cross between a leopard and a cheetah. After further similar animals were discovered, it was established they were similar to the cheetah in having non-retractable claws – a characteristic feature of the cheetah.
English zoologist Reginald Innes Pocock described it as a new species by the name of "Acinonyx rex" ("rex" being Latin for "king", the name translated to "king cheetah"); However, he reverted from this in 1939. English hunter-naturalist Abel Chapman considered it to be a colour morph of the spotted cheetah. Since 1927, the king cheetah was reported five more times in the wild; an individual was photographed in 1975.
In May 1981, two spotted sisters gave birth at the De Wildt Cheetah and Wildlife Centre (South Africa) and each litter contained one king cheetah. Each sister had mated with a wild male from the Transvaal region (where king cheetahs had been recorded). Further king cheetahs were later born at the Centre. It has been known to exist in Zimbabwe, Botswana and northern Transvaal. In 2012, the cause of this alternative coat pattern was found to be a mutation in the gene for transmembrane aminopeptidase Q (Taqpep), the same gene responsible for the striped "mackerel" versus blotchy "classic" patterning seen in tabby cats. Hence genetically the king cheetah is simply a variety of the common cheetah and not a separate species. This case is similar to that of the black panthers. The mutation is recessive, a reason behind the rareness of the mutation. As a result, if two mating cheetah have the same gene, then a quarter of their offspring can be expected to be king cheetah.
Characteristics.
The cheetah is a big cat with several distinctive features – a slender body, deep chest, spotted pelage, a small rounded head, black tear-like streaks on the face, long thin legs and a long spotted tail. Its lightly built, thin form is in sharp contrast with the robust build of the other big cats. The head-and-body length ranges from . The cheetah reaches nearly at the shoulder, and weighs . Thus it is clearly taller than the leopard, that stands nearly at the shoulder. The weight ranges of the cheetah overlaps extensively with that of the leopard, that weighs from . On the other hand, the cheetah is significantly shorter than the lion, whose average height is nearly . Moreover, it is much lighter than the lion, among which females weigh and the males are much heavier, . Based on measurements, the smallest cheetah have been reported from the Sahara, northeastern Africa and Iran. A sexually dimorphic species, male cheetah are generally larger than the females.
The head is small and streamlined, adding to the agility of the cheetah. Saharan cheetah are observed to have narrow canine faces. Small, short and rounded, the ears are marked by black patches on the back; the edges and base of the ears are tawny. The high-set eyes have round pupils. The whiskers, shorter and fewer than those of other felids, are fine and inconspicuous. The pronounced tear streaks are unique to the cheetah. These streaks originate from the corner of the eyes and run down the nose till the mouth. Their role is obscure – they may be serving as a shield for the eyes against the sun's glare, a helpful feature as the cheetah is a diurnal hunter; another purpose could be to define facial expressions.
Basically yellowish tan or rufous to greyish white, the coat of the cheetah is uniformly covered with nearly 2,000 black, solid spots. The upper parts are in stark contrast to the underbelly, that is completely white. Each spot measures nearly across. Every cheetah has a unique pattern of spots on its coat; hence this serves as a distinct identity for each individual. Cheetah fur is short and often coarse. Fluffy fur covers the chest and the ventral side. Several colour morphs of the cheetah have been identified, including melanistic and white forms. Black cheetah have been observed in Kenya and Zambia. In 1877–1878, English zoologist Philip Sclater described two partially albino specimens from South Africa. A ticked (tabby) cheetah was photographed in Kenya in 2012. Juveniles are typically dark with long, loose blue to grey hair. A short mane, about long, on the neck and the shoulders, is all that remains of the cape in adults. The exceptionally long and muscular tail measures , and ends in a bushy white tuft. While the first two-thirds of the tail are covered in spots, the final part is marked with four to six dark rings or stripes. The arrangement of the terminal stripes of the tail differs among individuals, but the stripe patterns of siblings are very similar. In fact, the tail of an individual will typically resemble its sibling's to a greater extent than it resembles its mother's or any other individual's.
The cheetah is often confused with the leopard and the cougar. However, the leopard is marked with rosettes while the cheetah with spots; added to this the former lacks the tear streaks of the cheetah. Moreover, the leopard has rose-like spots instead of the small round ones of the cheetah. The cougar possesses neither the tear streaks nor the spotted coat pattern of the cheetah. The serval has a very similar form as the cheetah, but is significantly smaller. Moreover, it has a shorter tail and spots that fuse to form stripes on the back.
Anatomy.
The cheetah differs notably from the other big cats in terms of morphology. The face and the jaw are unusually shortened and the sagittal crest is poorly developed, possibly to reduce weight and enhance speed. In fact, the skull resembles that of the smaller cats. Another point of similarity to the small cats is the long and flexible spine, in contrast with the stiff and short one of other large felids. A 2001 study of felid morphology stated that the relatively earlier truncation of the development of the middle phalanx bone in cheetah in comparison to other felids could be a major reason for the peculiar morphology of the cheetah. In the "Puma" lineage, the cheetah has similar skull morphology as the puma – both have short, wide skulls – while that of jaguarundi is different.
The cheetah has a total of 30 teeth; the dental formula is . The deciduous dentition is . The sharp, narrow cheek teeth help in tearing flesh, whereas the small and flat canine teeth bite the throat of the prey to suffocate it. Males have slightly bigger heads with wider incisors and longer mandibles than females. The muscles between the skull and jaw are short, and thus do not allow the cheetah to open its mouth as much as other cats. Digitigrade animals, the cheetah have tough foot pads that make it convenient to run on firm ground. The hindlegs are longer than the forelegs. The relatively longer metacarpals, metatarsals (of lower leg), radius, ulna, tibia and fibula increase the length of each jump. The straightening of the flexible vertebral column also adds to the length.
Cheetah have a high concentration of nerve cells, arranged in a band in the centre of the eyes. This arrangement is called a "visual streak", that significantly enhances the sharpness of the vision. The visual streak is most concentrated and efficient in the cheetah among most of the felids. The nasal passages are short and large; the smallness of the canines helps to accommodate the large nostrils. The cheetah is unable to roar due to the presence of a sharp-edged vocal fold with a sharp edge in the larynx.
The paws of the cheetah are narrower than those of other felids. The slightly curved claws lack a protective sheath, and are weakly retractable (semi-retractable). This is a major point of difference between the cheetah and the other big cats, that have fully retractable claws. The limited retraction of claws adds a canine quality to this felid. The aforementioned 2001 study showed that the claws of cheetah have features intermediate between those of felids and the wolf. This peculiar similarity between the cheetah and the wolf was attributed to convergent evolution. Additionally, the claws of cheetah are shorter as well as straighter than those of other cats. Absence of protection makes the claws blunt. However, the large and strongly curved dewclaw has remarkable sharpness.
Ecology and behaviour.
Cheetah are diurnal (active mainly during the day), whereas the leopard, tiger and lion are nocturnal (active mainly at night); this diurnality allows better observation and monitoring of the animal. Hunting is the major activity throughout the day; peaks are observed during dawn and dusk indicating crepuscular tendencies. Groups rest in grassy clearings after dusk, though males and juveniles often roam around at night. The cheetah is an alert animal; individuals often inspect their vicinity at observation points such as elevations. Even while resting, they take turns at keeping a lookout.
Social organisation.
Apart from the lion, the cheetah is the only cat that is gregarious; however, female cheetahs tend to remain solitary. Tim Caro, of the University of California, Davis, identified the various social classes and their longevity. Pregnant and nursing females, a few adolescents and males who have not joined any groups are typically solitary. Non-lactating females, their cubs, adolescent siblings and several males will form their own groups. A loose association between the opposite sexes can be observed during the breeding season. These social groups typically keep away from one another.
Males.
Adult males are typically gregarious despite their territoriality, and may group together for life and form "coalitions". These groups collectively defend their territories. In most cases, a coalition will comprise brothers born in the same litter, who stayed together after weaning. However, if a cub is the only male in the litter then two or three lone males may form a small group, or a lone male may join an existing group. Males in coalitions establish territories that ensure maximum access to females. Solitary males may or may not be territorial. Some males alternate between solitude and coalitions, whichever ensures encounters with a greater number of females. Although a coalition, due to its larger membership, demands greater amount of resources than do the solitary males or their groups, the coalition has a greater chance of encountering and acquiring females for mating.
Females and juveniles.
Females are not territorial, and live alone or with their offspring. Juveniles form mixed-sex groups after weaning, but most of the young females stay back with their mother, with whom they do not show any significant interaction. Males eventually mature and try to acquire territories.
Home ranges and territories.
Males.
Males in coalitions establish territories in locations that ensure maximum access to females. Males exhibit marking behaviour – territories, termite mounds, trees, common tracks and junctions and trees are marked by urine, faeces and claw scratches. The sizes can be location specific. For example, territories range from in the Serengeti, while in the Phinda Private Game Reserve, the size can be . Territorial solitary males establish considerably larger territories, as large as in the Serengeti or in central Namibia. A 1987 study of the social organisation in males showed that territoriality depends on the size and age of the males and the membership of the coalition. It concluded that solitary as well as grouped males have nearly equal chance of coming across females, but the males in coalitions are notably healthier and have better chances of survival than their solitary counterparts. In the Serengeti, only 4% of the solitary males hold territories, while those who joined coalitions were far more successful. The average period for which territories are held for four months for singletons, seven-and-a-half months for pairs and 22 months for trios.
Males exhibit pronounced marking behaviour – territories, termite mounds, trees, common tracks and junctions and trees are marked by urine, faeces and claw scratches. Males marking their territory by urination stand less than a meter away from a tree or rock surface with the tail raised, pointing the penis either horizontally backward or 60° upward. Territorial clashes can take place between two coalitions, or coalitions and solitary males; fights, however, are rarely gruesome. Another major reason for fights is to acquire dominance in the breeding season. These can even involve cannibalism.
Females.
Unlike male and other felines, female cheetahs do not establish territories. Instead, they live in unguarded areas, known as "home range"s. Home ranges often overlap; there is, however, hardly any interaction between the females. Females are regular visitors to male territories. The size of a home range depends mainly on the availability of prey. The greater the density of prey animals in an area, the smaller the home range of a female cheetah there. In areas with nomadic prey animals (such as the Thomson's gazelle in Serengeti and the springbok in Kalahari Desert), the home ranges cover hundreds of square kilometres. On the contrary, home ranges are merely large where sedentary prey, such as the impala in the Kruger National Park, is available.
Communication.
Vocalisations.
The cheetah is a prominently vocal felid. While the cheetah can not roar but the other big cats can, the latter can not purr but the cheetah can. A wide variety of vocalisations of the cheetah have been identified by several terms, but most of these lack a detailed acoustic description, which makes it difficult to reliably assess which term denotes which sound. In 2010, Robert Eklund (of the University of Göteborg, Sweden) and colleagues published a detailed report on the purring of the cheetah and compared it with that observed in other felids. The cheetah purrs when content, or to greet known individuals. A characteristic of purring is that it is realised on both egressive and ingressive airstream. Other vocalisations Eklund identified include:
In a 1991 book, biologist R. D. Estes had enlisted, in addition to the aforementioned vocalisations, some other sounds made by the cheetah:
Other methods.
Scent plays a significant role in olfactory communication. Cheetah often investigate urine-marked places (territories or common landmarks) for a long time by crouching on their forelegs and carefully smelling the place. Then the male cheetah will itself urinate there and sniff at its own scent before leaving. Other observing individuals will repeat the ritual. Females may also show marking behaviour but less prominently than the males. Females in oestrus will show maximum urine-marking, and her excrement can attract males from far-off.
Social meetings are marked by mutual sniffing in oral and genital areas, grooming one another, rubbing the cheeks and face-licking. Further physical contact has not been observed.
The tear streaks are a means of visual communication. The tear streaks combined with the black lips and the contrasting white fur give the face a striking appearance and form clear expressions when viewed from a close range. The ears and the face are obscure from a distance, and so are the expressions. On the other hand, the tail is quite conspicuous and probably used by mothers to direct juveniles to follow them.
Display behaviour.
Cheetah engage in several displays during fights, hunting or self-defence. Prior to a sprint, the cheetah will hold its head down, with aggression on its face, and approach the target in a stiff gait. The aggressive expression is maintained during the run. To defend itself or its prey, a cheetah will hold its body low to the ground, and produce a snarl with its mouth wide open, the eyes staring threateningly ahead and the ears folded backward. This may be accompanied by moans, hisses and growls. In more severe cases the ground is hit with the paws. Fights are characterised by biting, tearing out the fur and attempts at strangling on both sides.
Diet and hunting.
The cheetah is a carnivore that prefers medium-sized prey with a body mass ranging from . Blesbok, duiker, Grant's gazelle, impala, reedbuck, springbok and Thomson's gazelle are some of the common targets of the cheetah. Other prey animals include the bat-eared fox, bushbuck, kudu, hartebeest, nyala, oribi, roan antelope, steenbok, sable antelope and waterbuck; they prey less frequently on African buffalo, gemsbok, giraffe, ostrich, warthog, wildebeest and zebra. A study showed that a major proportion of the diet of Asiatic cheetah consists of livestock; local species such as chinkara, desert hare, goitered gazelle, ibex, rodents and wild sheep are also hunted. Normally only groups of cheetah will attempt to kill large animals such as hartebeest, although mothers with young cubs will attempt to secure a large prey all by themselves. There are no records of cheetah killing human beings. The diet of a cheetah depends on the area in which it lives. For example, on the East African plains, its preferred prey is the Thomson's gazelle, somewhat smaller than the cheetah. In contrast, in Kwa-Zulu Natal, the preferred prey is the significantly larger nyala, males of which can weigh up to . They do, however, opt for young and adolescent targets, which make up about 50% of the cheetah diet despite constituting only a small portion of the prey population.
Cheetah hunt primarily throughout the day, but geographical variations exist. For instance, cheetah in the Sahara and the Masai Mara hunt after sunset to escape the high temperatures of the day. In Serengeti they hunt when the lions and hyenas are inactive. A study in Nairobi National Park (Kenya) showed that the success of the hunt depends on the species, age, sex and habitat of the prey, and the size of the hunting herd or the efficiency of the hunting individual. Cheetahs hunt by vision rather than by scent. Prey is located from observation points or while roaming. Animals toward the edges of the herd are preferred. The cheetah will stalk their prey to within ; it will try to approach it as closely as possible while concealing itself in cover, sometimes even up to of the prey. The cheetah will crouch and move slowly while stalking, occasionally becoming motionless. The chase usually lasts less than a minute; if the cheetah fails to make a kill quickly, it will give up. Cheetahs have an average hunting success rate of 40 to 50%.
Cheetahs kill their prey by tripping it during the chase; the cheetah can use its strong dewclaw to knock the prey off its balance. To kill medium- to large-sized prey, the cheetah bites the prey's throat to suffocate it to death. A bite on the back of the neck or the snout is enough to kill smaller prey. The prey is then taken to a shaded place; the cheetah, highly exhausted after the chase, rests beside the kill and pants heavily for nearly five to 55 minutes. Groups of cheetah devour the kill peacefully, though minor growling may be observed. Cheetah not involved in hunting will immediately start eating. Cheetah can consume large quantities of food. In a study at the Etosha National Park (Namibia), the cheetah consumed as much as within two hours and stayed close to the remains for 11 hours. Cheetah move their head from side to side so that the sharp carnassial teeth effectively tear the flesh, which can then be swallowed without chewing. They typically begin with the hindquarters, and then progress toward the abdomen and the spine. Rib bones are chewed on at the ends, and the limbs are not generally torn apart while eating.
Competitors.
The cheetah, especially mothers with young cubs, are highly vigilant; they need to remain on a lookout for large carnivores who might steal the prey or harm the cubs, and for any potential prey. The cheetah will surrender its kill to sturdier carnivores such as lions, leopards, spotted hyena, brown hyena and wild dogs. Cheetahs lose around 10 to 15% of their kills to other predators; the percentage was found to be as high as 50% in a 1986 study. Cheetah have been rarely observed to feed on the kills of other carnivores; this may be due to vultures and spotted hyena, that adroitly capture and consume heavy carcasses within a short time.
Speed and acceleration.
Adaptations.
The cheetah's body is specialised for speed and it is the fastest land mammal. Estes describes the cheetah as the "felid version of the greyhound", as both have similar morphology and the ability to reach tremendous speeds in a shorter time compared to other mammals. The thin and light body of the cheetah makes it well-suited to short, explosive bursts of speed, rapid acceleration and an ability to execute extreme changes in direction while moving at speed. These adaptations account for much of the cheetah's ability to catch fast-moving prey.
The large nasal passages ensure fast flow of sufficient air, and the enlarged heart and lungs allow the enrichment of blood with oxygen in a short time. This allows cheetahs to rapidly regain their stamina after a chase. During a typical chase, their respiratory rate increases from 60 to 150 breaths per minute. While running, in addition to having good traction due to their semi-retractable claws, cheetahs use their tail as a rudder-like means of steering that enables them to make sharp turns, necessary to outflank antelopes that often change direction to escape during a chase.
The protracted claws increase grip over the ground, while foot pads make the sprint more convenient over tough ground. The tight binding of the tibia and the fibula restrict rotation about the lower leg, thus stabilising the animal throughout the sprint; the demerit, however, is that this reduces climbing efficiency. The pendulum-like motion of the scapula increases the stride length and assists in shock absorption. The extension of the vertebral column can add as much as to the length of a stride. During more than half of the time of the sprint, the animal has all the four limbs in the air; this contributes to the stride length.
In the course of a sprint, the heat production in cheetah exceeds more than 50% of the normal. The cheetah retains as much as 90% of the heat generated in its body during the chase, which is considerably larger than the 20% in the case of the domestic dog. The cheetah does not indulge in long distance chases, lest it should develop dangerous temperatures, nearly . The cheetah will run no more than at the tremendous speeds of . This is very rare as most chases are within 
Recorded values.
In general, the speed of a hunting cheetah averages during a chase, interspersed with a few short bursts when the speed may vary between ; the most reliable measurement of the typical speed during a short chase is . As this is an averaged value, a cheetah's maximum speed may be still higher; the value of the maximum speed is, however, disputed. The speeds attained by the cheetah are only slightly greater than those achieved by the pronghorn and the springbok . Yet the cheetah has a greater probability of succeeding in the chase due to its exceptional acceleration – it can attain a speed of in just two seconds. One stride or jump of a galloping cheetah averages . Similarly, the ability to rapidly change direction is pivotal in ensuring hunting success. Cheetah typically walk at .
Speed and acceleration values for the hunting cheetah may be different from those for the non-hunting because the cheetah is more likely to be twisting and turning to capture the prey and may be running through vegetation. In 2012, an 11-year-old cheetah from Cincinnati Zoo, named Sarah, made a world record by running in 5.95 seconds over a set run, during which she ran a recorded maximum speed of . A study of five wild cheetah (three females, two males) during hunting reported a maximum speed of , with an average of . Speed can be increased by almost in a single stride. The average chase is and the maximum ranges from .
Reproduction.
Cheetah breed throughout the year; they are induced ovulators. Females become sexually mature at 21 to 22 months of age. Females are polyoestrus – they have an oestrus ("heat") cycle every 12 days (this can vary from 10 to 20 days). Each oestrus lasting one to three days. A female can give birth again after 17 to 20 months; however, on the loss of a whole litter mothers can mate again. Urine-marking in males becomes more pronounced when a female in their vicinity comes into oestrus. Males fight among one another to secure access to the female; even males in a coalition may show some aggression toward one another on approaching a female. One male eventually wins dominance over the others. Mating, observed mainly at night, begins with the male approaching the female, who lies down on the ground. No courtship behaviour is observed; the male immediately secures hold of the female's nape and copulation takes place. The pair then ignore each other and part ways. However, they meet and copulate a few more times within the next few days. Polyandrous, females can mate with several males. The mean number of motile sperm in a single ejaculation is nearly 25.3 million.
Gestation is nearly three months long. The number of cubs born can vary from one to eight, though the common number is three to five. Birth takes place in a sheltered place, such as thick vegetation. Each cub weighs nearly at birth; the eyes, shut at birth, open in four to 11 days. Newborn cubs can crawl and spit; they can start walking by two weeks. Their nape, shoulders and back is thickly covered with long bluish grey hair. This downy underlying fur, called a "mantle", gives them a Mohawk-type appearance; this fur is shed as the cheetah grows older. A study noted that this mane gives a cheetah cub the appearance of the honey badger; this could act as a camouflage in both animals. Cheetah cubs are highly vulnerable during the first few weeks of their life; mothers keep their cubs hidden in dense vegetation for the first month.
Cubs start following their mothers at six weeks. The mother frequently shifts the cubs to new locations. A study of play behaviour of cheetah cubs showed that cubs tend to play after nursing or while they were on the move with their mothers. Play involves plenty of agility; attacks are seldom lethal. Playing cubs stay near their mothers. The study further revealed that while the cubs showed improvement in catching each other as they grew up, the ability to crouch and hide did not develop remarkably. Thus it was suggested that play helps develop only certain aspects of predator defence. Weaning occurs at three to six months of age. The mother brings kills to her cubs; the cubs might be purr as the mother licks them clean after the meal. Cubs as young as six months try to capture small prey like hares and juvenile gazelles. However, they may have to wait till as long as 15 months to make a successful kill on their own.
The offspring may stay with the mother for 13 to 20 months, associating with one another and feeding on kills together. After weaning, juveniles may form mixed-sex herds; young females may stay back with their mother, but there is hardly any interaction between the mother and daughters. The females in the mixed-sex herd gradually move out as they near sexual maturity. In the Serengeti, average age of independence of 70 observed litters was 17.1 months. Young females had their first litters at the age of about 2.4 years and subsequent litters about 20 months later. The lifespan of wild cheetah is 14 to 15 years for females, though their reproductive cycle typically ends by 12 years of age. Males generally live as long as 10 years.
Mortality.
High mortality rates have been recorded in the Serengeti. In a 1994 study, nearly 77% of litters died before eight weeks of birth, and nearly 83 percent of those alive could not make it to adolescence (14 weeks). Lions emerged as the major predator of juveniles, accounting for nearly 78 percent of the deaths. The study concluded that the survival rate of cubs till weaning was a mere 4.8%. This was attributed to the open terrain of the region, which does not allow cheetah to conceal themselves. Cheetah cubs face higher mortality than most other mammals.
It has been suggested that the significant lack of genetic diversity in cheetah is a cause of poor quality and production of sperm, and birth defects such as cramped teeth, kinked tails, and bent limbs. Consequently, cheetah are found to have low fertility rates. Moreover, as cheetah expert Laurie Marker points out, the high level of genetic uniformity would mean that if an infectious disease surfaced in a population, no cheetah would be able to survive as all of them will necessarily have the same level of immunity. As such, large populations might get wiped out; in 1982, 60% of the cheetah population in the Wildlife Safari (Oregon, USA) died due to a peritonitis epidemic.
Distribution and habitat.
The cheetah inhabits a variety of habitats; in Africa it has been observed in dry forests, scrub forests, savannahs and grasslands. However, the distribution of the prey may influence habitat preferences; in a study in the Kruger National Park, female cheetah were found to spend a significant amount of time in woodlands, where impala occurred. It was suggested that though the forested area was unsuitable for hunting, the females preferred woodlands to encounter more impala. Male coalitions, on the other hand, shunned dense habitats and spent most of the time in open savannahs. An explanation given for this was that the coalitions prefer larger prey than impala. Though they do not prefer montane regions, cheetah can occur at elevations as high as . An open area with some cover, such as diffused bushes, is probably ideal for the cheetah because it needs to stalk and pursue its prey over a distance, exploiting its speed. This also minimises the risk of encountering larger carnivores. Complete lack of cover, however, can be a cause of prey loss and mortality.
In the prehistoric times, the cheetah was distributed throughout Asia, Africa, Europe and North America. Gradually it vanished from Europe and North America. Nearly 500 years ago, the cheetah was still common throughout Africa, though it avoided deserts and tropical forests. Afghanistan, Iran, Iraq, Palestine, Syria and the Ganga and Indus river valleys sheltered large numbers of cheetah. However, today the cheetah has been exterminated from the majority of its earlier range. The IUCN estimates that the total expanse of the range of the cheetah in earlier times was approximately ; the range (as of 2015) has since then reduced to , a substantial decline of 89%.
In Africa, the cheetah occurs mainly in eastern and southern Africa; the range across the continent has declined to a mere 10 percent of the historic expanse. The range in eastern Africa has reduced to six percent of its original range, so that presently it is distributed in an area of . In the Horn of Africa, the cheetah occurs in Ethiopia, Kenya, South Sudan, Tanzania and Uganda. The range has not reduced as much in the southern part of the continent, where it occurs in an area of , 22% of its original range. Though cheetah do not occur in Malawi any more, significant populations thrive in south-western Angola, Botswana, south-western Mozambique, Namibia, northern South Africa, southern Zambia and Zimbabwe. Very few, isolated populations occur in the Sahara; the population density in this region is as low as two to three individuals per . They occur in very low numbers in northern and western Africa. In the past, the cheetah ranged across vast stretches of Asia: from the Mediterranean and the Arabian Peninsula in the west to the Indian subcontinent in the east, and as far north as the Caspian and Aral Seas. However, the cheetah has disappeared from the majority of its historic range save for Iran, and possibly a few areas in Afghanistan, the Indian subcontinent and Turkmenistan.
Status and threats.
The cheetah has been classified as Vulnerable by the IUCN; it is listed under Appendix I of the Convention on the Conservation of Migratory Species of Wild Animals (CMS) and Appendix I of CITES (Convention on International Trade in Endangered Species). In 2014, the CITES Standing Committee recognised cheetahs as a "species of priority' in their strategies in northeastern Africa to counter wildlife trafficking. As of 2015, the IUCN gives the total number of surviving individuals as nearly 6,700. Regional estimates have been given as: 1,960 in eastern Africa (as of 2007); 4,190 in southern Africa (as of 2007); and 440 in western, central and northern Africa (as of 2012). The southern half of the continent, therefore, is shelter to the largest number of cheetah. 29 sub-populations have been identified, of which most consist of no more than 500 individuals. A small population of 60 to 100 individuals was reported from Iran in 2007. Populations are feared to be declining, especially those of adults.
The cheetah is threatened by habitat loss through agricultural and industrial expansion; moreover, the animal apparently requires a large area to live in as indicated by its low population densities. The cheetah appears to be less capable than the leopard in coexisting with humans. As such, human interference can disturb the activities, such as hunting and feeding, of cheetah. With 76% of their range consisting of unprotected land, the cheetah are often targeted by farmers and pastoralists who attempt to protect their livestock. However, cheetah typically do not prefer livestock for prey. Game hunters may also try to harm cheetah as these carnivores can deprive them of valuable game. Roadkill can be another threat, especially in areas where roads have been constructed near the natural habitat or protected areas. Cases of roadkill involving cheetah have been reported from Kalmand, Tūrān and Bafq. Minor threat is posed by infectious diseases, given the low population densities and hence the minimal chance of infection.
Conservation measures.
The IUCN has recommended co-operation between countries across the cheetah's range to minimise the conflict between cheetah and human beings. A 2016 study showed that ecotourism can have a significantly positive impact on the conservation of the cheetah. Although the requirement of space for the habitat would have to be compromised with in most cases, establishment of private reserves for cheetah and ensuring the absence of predators and poachers could be a successful conservation measure. Additionally, the financial benefits accrued and the awareness generated can further aid the cause of the cheetah. At the same time it needs to be ensured that the animals are not unnecessarily handled or disturbed, as cheetah are particularly sensitive to human interference.
In Africa.
The Range Wide Conservation Program for Cheetah and African Wild Dogs (RWCP), the brainchild of Sarah Durant and Rosie Woodroffe (of the Zoological Society of London), was started in 2007 with the primary aim of ensuring better conservation measures for the cheetah and the wild dog – two species with very low population densities. A joint initiative by the ZSL, the Wildlife Conservation Society and the IUCN Cat Specialist Group, the major goals of this program include a review of the conservation policies adopted by the South African countries, and study and action on illegal hunting and trade of the cheetah. In a 2007 publication, Durant emphasised the role of land management and improvement in connectivity across the range in cheetah conservation, in the lack of which the populations might face severe fragmentation.
The following African countries have formulated action plans for the conservation of the cheetah as well as the wild dog (the years in which the workshops were held are given in brackets): Benin (2014), Botswana (2007), Chad (2015), Ethiopia (2010), Kenya (2007), Mozambique (2010), Namibia (2013), Niger (2012), South Africa (2009), South Sudan (2009), Tanzania (2013), Zambia (2009) and Zimbabwe (2009).
Reintroduction attempts in India.
In the 20th century, the populations of cheetah in India saw a drastic fall. The last physical evidence of the cheetah in India was three individuals, all shot by the Maharajah of Surguja in 1947 in eastern Madhya Pradesh, a man also noted for holding a record for shooting 1,360 tigers. During the early 2000s, scientists from the Centre for Cellular and Molecular Biology (CCMB), Hyderabad, proposed a plan to clone Asiatic cheetahs obtained from Iran. India requested Iran to transport one live pair to India, or, if that was not possible, allow them to collect sperm and of the cheetah pair in Iran itself. However, Iran refused to both proposals.
In September 2009, the then Minister of Environment and Forests, Jairam Ramesh, assigned the Wildlife Trust of India and the Wildlife Institute of India with the task of examining the potential of cheetah reintroduction in the nation. The report, submitted in 2010, showed that the Kuno Wildlife Sanctuary and Nauradehi Wildlife Sanctuary in Madhya Pradesh, and Shahgarh Landscape and Desert National Park in Rajasthan have high potential to support reintroduced cheetah populations. These areas were found to be spacious; of these four areas the Kuno Wildlife Sanctuary had the largest available area, . Moreover, these were rich in prey availability. The Sanjay National Park, though comprising an area of and having supported cheetah populations before the independence of India in 1947, is no more suitable for the cheetah due to low prey density and risks of poaching.
Interaction with human beings.
Taming.
The cheetah in general shows no hostility toward human beings, probably due to its sociable nature. This might be a reason why the cheetah can be easily tamed, as it has been since antiquity. Reliefs in the Deir el-Bahari temple complex tell of an expedition by Egyptians to the Land of Punt during the reign of the pharaoh Hatshepsut (1507–1458 BC) that fetched, among other things, animals called "panther"s for Egypt. Two types of "panther"s were depicted in these sculptures: leashed cheetah, referred to as "panthers of the north", and sturdy leopards, referred to as "panthers of the south". During the New Kingdom (16th to 11th centuries BC), cheetah were common pet animals for the royalty, who decorated the animals with beautiful collars and leashes. The Egyptians would use their dogs to bring the concealed prey out in the open, after which a cheetah would be set upon it to kill it. A Sumerian seal dating back to nearly 3000 BC, featuring a leashed animal resembling a cheetah, has fuelled speculation that the cheetah might have been first domesticated and used for hunting in Sumer (Mesopotamia). However, Thomas T. Allsen (of The College of New Jersey) argues that the depicted animal might not be a cheetah given the largely dog-like features of the former; moreover, the background gives an impression of a montane area, which the cheetah does not typically inhabit.
Mainly two kinds of theories have been put forth to explain the subsequent expansion of the cheetah into Asia, Europe and the rest of Africa. Historians who accept the Sumerian origin of the domesticated cheetah – such as Heinz F. Friederichs and Burchard Brentjes – hold that the animal gradually spread out to central and northern Africa, from where it reached India. On the other hand, historians such as Frederick E. Zeuner, accept the Egyptian origin and state that the cheetah gradually spread into central Asia, Iran and India. In the third century AD, Roman author Claudius Aelianus wrote of tame panthers in India and "smaller lions" which would be used for tracking and hunting; the account can not be very reliable as Roman, as well as Greek, literature is not generally clear in its references to different types of cats.
Hunting with cheetahs became more prominent toward the seventh century AD. In the Middle East, the cheetah would accompany the nobility to hunts in special seats behind saddles. Cheetah continued to be associated with royalty and elegance in western Asia till as late as the 19th century. The first phase of taming would take several weeks, in which the cheetah would be kept tethered and made to get accustomed to human beings. Next, the cheetah would be tempted with food and trained to mount horses. Finally its hunting instincts would be aroused by slaughtering animals before it. The whole process could take as long as a year to complete. In eastern Asia, the records are confusing as regional names for the leopard and the cheetah may be used interchangeably. The earliest depiction of cheetah from eastern Asia dates back to the Tang dynasty (7th to 10th centuries AD); paintings depict tethered cheetah as well as cheetah mounted on horses. Chinese emperors would use cheetah, as well as caracals, as gifts. In the 13th and the 14th centuries, the Yuan rulers bought numerous caracals, cheetah and tigers from the western parts of the empire and Muslim merchants in return for gold, silver, cash and silk. According to the "Ming Shilu", the subsequent Ming dynasty (14th to 17th centuries) continued this practice. The cheetah gradually entered Eurasia toward the 14th century, though they never became a popular as they had in the Middle East. The Mughal ruler Akbar the Great (1556–1605) is said to have kept as many as 1,000 cheetahs. However, his son Jahangir wrote in his memoirs, "Tuzk-e-Jahangiri", that only one of them gave birth to cubs. Mughal rulers trained cheetah as well as caracals in a similar way as the West Asians, and used them to hunt game – especially blackbuck. The rampant hunting severely affected the populations of wild animals.
In captivity.
Mortality under captivity is generally high; reasons include stillbirths, birth defects, cannibalism, hypothermia, neglect of cubs by mothers and infectious diseases. A study comparing the health of captive and wild cheetah noted that despite having similar genetic make-up, the wild cheetah are far more healthier than their captive counterparts. The study identified possible stress factors such as restricted habitat and interaction with human beings and other carnivores, and recommended private and spacious areas for captive cheetah. A study of diseases suffered by captive cheetah in the period 1989–92 in several North American zoos showed that hepatic veno-occlusive disease, a disease of the liver, had affected 82% of the deceased cheetah, caused nine deaths and occurred in 51% alive females. Chronic gastritis was detected in 91% of the population. Glomerulosclerosis, a disease of the kidneys, emerged as another significant disease, affecting 84% of the cheetah; another renal disease, nephrosclerosis, affected 39% of the cheetah. Feline infectious peritonitis caused two deaths. Pneumonia was a major cause for juvenile deaths. Another study concluded that excess of vitamin A in diets and the liver could result in veno-occlusive disease.
Moreover, cheetah are poor breeders in captivity, while wild individuals are far more successful. In a 1992 study, females in Serengeti were found to have 95% success rate in breeding. In contrast, only 20% of the North American captive cheetah bred successfully in 1991. Studies have shown that in-vitro fertilisation in cheetah poses more difficulties than are faced in the case of other cats.
In popular culture.
The cheetah has been widely portrayed in a variety of artistic works. In "Bacchus and Ariadne", an oil painting by the 16th century Italian painter Titian, the chariot of the Greek god Bacchus (Dionysus) is depicted as being drawn by two cheetah. The cheetah in the painting were previously considered to be leopards. In 1764, English painter George Stubbs commemorated the gifting of a cheetah to George III by the English Governor of Madras, Sir George Pigot in his painting "Cheetah with Two Indian Attendants and a Stag". The painting depicts a cheetah, that was hooded and collared by two Indian servants, along with a stag it was supposed to prey upon. 1896 painting "The Caress", by the 19th century Belgian symbolist painter Fernand Khnopff, is a representation of the myth of Oedipus and the Sphinx. It portrays a creature with a woman's head and a cheetah's body (often misidentified as a leopard's).
A variety of literature mentions the cheetah. In 1969, author Joy Adamson, of "Born Free" fame, wrote "The Spotted Sphinx", a biography of her pet cheetah Pippa. "Hussein, An Entertainment", a novel by Patrick O'Brian set in the British Raj period in India, illustrates the practice of royalty keeping and training cheetah to hunt antelopes. The book "How It Was with Dooms" tells the true story of a family raising an orphaned cheetah cub named Dooms in Kenya. The 2005 film "Duma" was loosely based on this book.
The cheetah has often been featured in marketing and animation. In 1986, Frito-Lay introduced the Chester Cheetah, an anthropomorphic cheetah, as the mascot for their Cheetos. The first release of Apple Inc.'s Mac OS X, the Mac OS X 10.0, was code-named "Cheetah"; the subsequent releases have been named after big cats. The animated series "ThunderCats" had a character named "Cheetara", an anthropomorphic cheetah, voiced by Lynne Lipton. Comic book superheroine Wonder Woman's chief adversary is Dr. Barbara Ann Minerva, alias The Cheetah.

</doc>
<doc id="45610" url="https://en.wikipedia.org/wiki?curid=45610" title="Mata Hari">
Mata Hari

Margaretha Geertruida "Margreet" MacLeod (née Zelle; 7 August 187615 October 1917), better known by the stage name Mata Hari, was a Dutch Frisian exotic dancer and courtesan who was convicted of being a spy and executed by firing squad in France under charges of espionage for Germany during World War I.
Early life.
Margaretha Zelle was born in Leeuwarden, the Netherlands. She was the eldest of four children of Adam Zelle (2 October 1840 – 13 March 1910) and his first wife Antje van der Meulen (21 April 1842 – 9 May 1891). She had three brothers. Her father owned a hat shop, made successful investments in the oil industry, and became affluent enough to give Margaretha a lavish early childhood that included exclusive schools until the age of 13.
Soon after Margaretha's father went bankrupt in 1889, her parents divorced, and then her mother died in 1891. Her father remarried in Amsterdam on 9 February 1893 to Susanna Catharina ten Hoove (11 March 1844 – 1 December 1913), by whom he had no children. The family fell apart, and Margaretha moved to live with her godfather, Mr. Visser, in Sneek. In Leiden, she studied to be a kindergarten teacher, but when the headmaster began to flirt with her conspicuously, she was removed from the institution by her offended godfather. A few months later, she fled to her uncle's home in The Hague.
Dutch East Indies.
At 18, Zelle answered an advertisement in a Dutch newspaper placed by Dutch Colonial Army Captain Rudolf MacLeod (1 March 18569 January 1928), who was living in what was then the Dutch East Indies (now Indonesia) and was looking for a wife. Zelle married MacLeod in Amsterdam on 11 July 1895. He was the son of Captain John Brienen MacLeod (a descendant of the Gesto branch of the MacLeods of Skye, hence his Scottish name) and Dina Louisa, Baroness Sweerts de Landas. The marriage enabled her to move into the Dutch upper class, and her finances were placed on a sound footing. They moved to Malang on the east side of the island of Java, traveling out on in May 1897, and had two children, Norman-John MacLeod (30 January 1897 – 27 June 1899) and Louise Jeanne MacLeod (2 May 1898 – 10 August 1919).
The marriage was an overall disappointment. MacLeod appears to have been an alcoholic who would take out his frustrations on his wife, who was twenty years younger and whom he blamed for his lack of promotion. He also openly kept a concubine, a socially accepted practice in the Dutch East Indies at that time. The disenchanted Zelle abandoned him temporarily, moving in with Van Rheedes, another Dutch officer. For months, she studied the Indonesian traditions intensively, joining a local dance company. In 1897, she revealed her artistic name of "Mata Hari," Malay ("Indonesian as a standardized register did not exist in 1897") for "sun" (literally, "eye of the day"), in correspondence to her relatives in the Netherlands.
At MacLeod's urging, Zelle returned to him, but his aggressive demeanour did not change. She escaped her circumstances by studying the local culture. In 1899, their children fell violently ill from complications relating to the treatment of syphilis contracted from their parents, though the family claimed they were poisoned by an irate servant. Jeanne survived, but Norman died. Some sources maintain that one of MacLeod's enemies may have poisoned a supper to kill both of their children. After moving back to the Netherlands, the couple officially separated on 30 August 1902. The divorce became final in 1906. Zelle was awarded custody of Jeanne. MacLeod was legally required to pay support, which he never did, making life very difficult for Zelle and her daughter. During a visit of Jeanne with her father, MacLeod decided not to return Jeanne to her mother. Zelle was forced to accept the situation, not having the resources to fight it, in the knowledge that whatever kind of husband MacLeod had been to her, he had always been a good father. Jeanne later died at the age of 21, also possibly from complications relating to syphilis.
Paris.
In 1903, Zelle moved to Paris, where she performed as a circus horse rider using the name Lady MacLeod, much to the disapproval of the Dutch MacLeods. Struggling to earn a living, she also posed as an artist's model.
By 1905, Mata Hari began to win fame as an exotic dancer. She was a contemporary of dancers Isadora Duncan and Ruth St. Denis, leaders in the early modern dance movement, which around the turn of the 20th century looked to Asia and Egypt for artistic inspiration. Critics would later write about this and other such movements within the context of Orientalism. Gabriel Astruc became her personal booking agent.
Promiscuous, flirtatious, and openly flaunting her body, Mata Hari captivated her audiences and was an overnight success from the debut of her act at the Musée Guimet on 13 March 1905. She became the long-time mistress of the millionaire Lyon industrialist Émile Étienne Guimet, who had founded the Musée. She posed as a Javanese princess of priestly Hindu birth, pretending to have been immersed in the art of sacred Indian dance since childhood. She was photographed numerous times during this period, nude or nearly so. Some of these pictures were obtained by MacLeod and strengthened his case in keeping custody of their daughter.
Mata Hari brought a carefree provocative style to the stage in her act, which garnered wide acclaim. The most celebrated segment of her act was her progressive shedding of clothing until she wore just a jeweled bra and some ornaments upon her arms and head. She was seldom seen without a bra as she was self-conscious about being small-breasted. She wore a bodystocking for her performances that was similar in color to her own skin.
Although Mata Hari's claims about her origins were fictitious, it was very common for entertainers of her era to invent colorful stories about their origins as part of the show. Her act was successful because it elevated exotic dance to a more respectable status and so broke new ground in a style of entertainment for which Paris was later to become world famous. Her style and free-willed attitude made her a popular woman, as did her eagerness to perform in exotic and revealing clothing. She posed for provocative photos and mingled in wealthy circles. Since most Europeans at the time were unfamiliar with the Dutch East Indies, Mata Hari was thought of as exotic, and it was assumed her claims were genuine.
By about 1910, a myriad imitators had arisen. Critics began to opine that the success and dazzling features of the popular Mata Hari were due to cheap exhibitionism and lacked artistic merit. Although she continued to schedule important social events throughout Europe, she was held in disdain by serious cultural institutions as a dancer who did not know how to dance.
Mata Hari's career went into decline after 1912. On 13 March 1915, she performed in what would be the last show of her career. She had begun her career relatively late for a dancer, and had started putting on weight. However, by this time she had become a successful courtesan, known more for her sensuality and eroticism than for her beauty. She had relationships with high-ranking military officers, politicians, and others in influential positions in many countries. Her relationships and liaisons with powerful men frequently took her across international borders. Prior to World War I, she was generally viewed as an artist and a free-spirited bohemian, but as war approached, she began to be seen by some as a wanton and promiscuous woman, and perhaps a dangerous seductress.
"Double agent".
During World War I, the Netherlands remained neutral. As a Dutch subject, Zelle was thus able to cross national borders freely. To avoid the battlefields, she travelled between France and the Netherlands via Spain and Britain, and her movements inevitably attracted attention. In 1916, she was travelling by steamer from Spain when her ship called at the English port of Falmouth. There she was arrested and brought to London where she was interrogated at length by Sir Basil Thomson, Assistant Commissioner at New Scotland Yard in charge of counter-espionage. He gave an account of this in his 1922 book "Queer People," saying that she eventually admitted to working for French intelligence. Initially detained in Cannon Street police station, she was then released and stayed at the Savoy Hotel. A full transcript of the interview is in Britain's National Archives and was broadcast, with Mata Hari played by Eleanor Bron, on the independent station London Broadcasting in 1980.
It is unclear if she lied on this occasion, believing the story made her sound more intriguing, or if French authorities were using her in such a way but would not acknowledge her due to the embarrassment and international backlash it could cause.
In January 1917, the German military attaché in Madrid transmitted radio messages to Berlin describing the helpful activities of a German spy code-named H-21. French intelligence agents intercepted the messages and, from the information it contained, identified H-21 as Mata Hari. The messages were in a code that some claimed that German intelligence knew had already been broken by the French (in fact it had been broken not by the French, but by the British "Room 40" team), leaving some to claim that the messages were contrived. However, this same code, which the Germans were convinced was unbreakable was used to transmit the Zimmermann Telegram.
Trial and execution.
On 13 February 1917, Mata Hari was arrested in her room at the Hotel Elysée Palace on the Champs Elysées in Paris. She was put on trial on 24 July, accused of spying for Germany, and consequently causing the deaths of at least 50,000 soldiers. Although the French and British intelligence suspected her of spying for Germany, neither could produce definite evidence against her. Supposedly secret ink was found in her room, which was incriminating evidence in that period. She contended that it was part of her makeup. She wrote several letters to the Dutch Consul in Paris, claiming her innocence. "My international connections are due of my work as a dancer, nothing else ... Because I really did not spy, it is terrible that I cannot defend myself". Her defence attorney, veteran international lawyer Edouard Clunet, faced impossible odds; he was denied permission either to cross-examine the prosecution's witnesses or to examine his own witnesses directly. Under the circumstances, her conviction was a foregone conclusion.
German documents unsealed in the 1970s proved that Mata Hari truly had been a German agent. In the autumn of 1915, she had entered the German secret service, and on orders of section III B-Chief Walter Nicolai, had been instructed about her duties by Major Roepell during a stay in Cologne. Her reports were to be sent to the Kriegsnachrichtenstelle West (War News Post West) in Düsseldorf under Roepell as well as to the Agent mission in the German embassy in Madrid under Major Arnold Kalle, with her direct handler being Captain Hoffmann, who also gave her the code name H-21. It is contended by some historians, however, that Mata Hari may have merely accepted money from the Germans without actually carrying out any spy duties.
In December 1916, the French Second Bureau of the French War Ministry let Mata Hari obtain the names of six Belgian agents. Five were suspected of submitting fake material and working for the Germans, while the sixth was suspected of being a double agent for Germany and France. Two weeks after Mata Hari had left Paris for a trip to Madrid, the double agent was executed by the Germans, while the five others continued their operations. This development served as proof to the Second Bureau that the names of the six spies had been communicated by Mata Hari to the Germans.
She was executed by firing squad on 15 October 1917, at the age of 41.
Disappearance and rumours.
Mata Hari's body was not claimed by any family members and was accordingly used for medical study. Her head was embalmed and kept in the Museum of Anatomy in Paris, but in 2000, archivists discovered that the head had disappeared, possibly as early as 1954, when the museum had been relocated. Records dated from 1918 show that the museum also received the rest of the body, but none of the remains could later be accounted for.
A 1934 "New Yorker" article reported that at her execution she wore "a neat Amazonian tailored suit, especially made for the occasion, and a pair of new white gloves" though another account indicates she wore the same suit, low-cut blouse and tricorn hat ensemble which had been picked out by her accusers for her to wear at trial, and which was still the only full, clean outfit which she had in prison. Neither description matches photographic evidence. According to an eyewitness account by British reporter Henry Wales, she was not bound and refused a blindfold. Wales records her death, saying that after the volley of shots rang out, "Slowly, inertly, she settled to her knees, her head up always, and without the slightest change of expression on her face. For the fraction of a second it seemed she tottered there, on her knees, gazing directly at those who had taken her life. Then she fell backward, bending at the waist, with her legs doubled up beneath her." A non-commissioned officer then walked up to her body, pulled out his revolver, and shot her in the head to make sure she was dead.
Museum.
The Fries Museum in Leeuwarden, the Netherlands, contains a "Mata Hari Room". Included in the exhibit are two of her personal scrapbooks and an oriental rug embroidered with the footsteps of her fan dance. Located in Mata Hari's native town, the museum is well known for research into the life and career of Leeuwarden's world-famous citizen.
Legend and popular culture.
The idea of an exotic dancer working as a lethal double agent using her powers of seduction to extract military secrets from her many lovers made Mata Hari an enduring archetype of the femme fatale. Her life inspired a number of films, including "Mata Hari", a 1927 German production; "Mata Hari" (1931) starring Greta Garbo; "Mata Hari, Agent H21" (1964) and "Mata Hari" (1985); and three stage musicals: the first in 1967, starring Pernell Roberts and Marisa Mell, and the second by Lene Lovich, Judge Smith, and Les Chappell, which premiered in 1982 at the Lyric Theatre, Hammersmith. A third, by Frank Wildhorn, will debut in Seoul, South Korea on March 2016. The Dutch Royal Ballet debuted a ballet based on her life on 6 February 2016.
The historical Mata Hari featured as the fictional Indy's first sexual encounter in "The Adventures of Young Indiana Jones" episode "Demons of Deception", an episode filmed in a different, slightly surreal style (it flashes between present time, and Mata's execution for supposed espionage by the French). The actress who played Mata was a slender redhead whereas the historical figure was a slightly plump brunette.
In theatre the monologue "Mata Hari: A Dawn's Sentence" by Jorge Arroyo has been staged in Costa Rica (1987) and Brazil (2002-2003).

</doc>
<doc id="45611" url="https://en.wikipedia.org/wiki?curid=45611" title="Dr. Feelgood (band)">
Dr. Feelgood (band)

Dr. Feelgood are a British pub rock band formed in 1971. Hailing from Canvey Island, Essex, they are best known for early singles like "She Does It Right", "Roxette", and "Back in the Night". The group's original distinctively British R&B sound was centred on Wilko Johnson's choppy guitar style. Along with Johnson, the original band line-up included singer Lee Brilleaux and the rhythm section of John B. Sparks, known as "Sparko", on bass guitar and John Martin, known as "The Big Figure", on drums. Although their most commercially productive years were the early to mid-1970s, and in spite of Brilleaux's death in 1994 of lymphoma, a version of the band (featuring none of the original members) continues to tour and record to this day.
Career.
Early years.
The band was formed in Canvey Island in 1971 by Johnson, Brilleaux and Sparks, who had all been members of existing R&B bands, and soon added drummer John Martin. They took their name from a 1962 record by the American blues pianist and singer Willie Perryman (also known as "Piano Red") called "Dr. Feel-Good", which Perryman recorded under the name of Dr. Feelgood & The Interns. The song was covered by several British beat groups in the 1960s, including Johnny Kidd & The Pirates. The term is also a slang term for heroin or for a doctor who is willing to overprescribe drugs.
By late 1973, the band's driving R&B had made them one of the most popular bands on the growing London pub rock circuit, and they recorded their debut album, "Down by the Jetty", for United Artists in 1974. Like many pub rock acts, Dr Feelgood were known primarily for their high energy live performances honed through constant touring and regular performances, although their studio albums like "Down by the Jetty" and "Malpractice" (1975) were also popular.
Their breakthrough 1976 live album, "Stupidity", reached number one in the UK Albums Chart (their only chart-topper). But after the 1977 follow-up "Sneakin' Suspicion", Johnson left the group because of conflicts with Lee Brilleaux. He was replaced by John 'Gypie' Mayo. With Mayo, the band was never as popular as with Johnson, but still enjoyed their only Top Ten hit single in 1979, with "Milk and Alcohol". Johnson never achieved any great success outside of the band, apart from a brief spell with Ian Dury and The Blockheads from 1980. Fans always speculated about a return by Johnson that never occurred.
Later years.
Despite Mayo's departure in 1981, and various subsequent line-up changes which left Brilleaux the only remaining original member, Dr Feelgood continued touring and recording through the 1980s. However, the band then suffered an almost career-finishing blow when Brilleaux died of cancer on 7 April 1994.
As Brilleaux had insisted prior to his death, Dr Feelgood reunited in May 1995, initially with vocalist Pete Gage (not to be confused with guitarist Pete Gage of Geno Washington and Vinegar Joe), and recommenced touring in 1996. Though the band contained no original members at this point, the musicians backing Gage had all previously played as members of Dr. Feelgood for at least five years, and in some cases for over a decade. In 1999 Gage was replaced by Robert Kane, formerly of The Animals II and The Alligators, who celebrated his 1,000th gig as the frontman of Dr. Feelgood in April 2007.
Every year since Brilleaux's death, a special concert known as the Lee Brilleaux Birthday Memorial has been held on Canvey Island, where former and current Feelgoods celebrate the music of Dr Feelgood, and raise money for The Fair Havens Hospice in Westcliff-on-Sea. Fans attend from all over the globe, and the 17th event was held on 7 May 2010. Still based in the UK, Dr Feelgood continue to play across the world, with concerts in 2010 in Austria, Bahrain, Belgium, Finland, France, the Netherlands, Italy, Spain and Switzerland.
Band manager Chris Fenwick organises an annual walk around Canvey to commemorate Brilleaux's life, as well as additional walking tours during which he points out landmarks from the band's career. These include the jetty featured in the photograph on the band's first album cover, and venues where they played early in their career, such as The Lobster Smack inn, The Monico Nightclub and The Canvey Club (disguised as 'The Alibi Club' on the sleeve of the album "Sneakin' Suspicion").
A film by Julien Temple about the early days of the band, "Oil City Confidential", premiered at the London Film Festival on 22 October 2009, and received a standing ovation. Guest of honour was Lee Brilleaux's mother Joan Collinson, along with his widow Shirley and children Kelly and Nick. All the surviving members of the original band were present along with manager Chris Fenwick, former tour manager and Stiff Records boss Jake Riviera and other friends and colleagues of the band. The film has its own Facebook page.
Reviewing the film for "The Independent", Nick Hasted concluded: "Feelgood are remembered in rock history, if at all, as John the Baptists to punk's messiahs". On general release from 1 February 2010, the film was critically well received, with Peter Bradshaw of "The Guardian" describing it as "...a vivid study of period, music and place". The film was first broadcast on BBC Four in April 2010.
A major exhibition of memorabilia celebrating the band's career ran at The Canvey Club between May and July 2013, having been extended several times.

</doc>
<doc id="45619" url="https://en.wikipedia.org/wiki?curid=45619" title="Lagged Fibonacci generator">
Lagged Fibonacci generator

A Lagged Fibonacci generator (LFG or sometimes LFib) is an example of a pseudorandom number generator. This class of random number generator is aimed at being an improvement on the 'standard' linear congruential generator. These are based on a generalisation of the Fibonacci sequence.
The Fibonacci sequence may be described by the recurrence relation:
Hence, the new term is the sum of the last two terms in the sequence. This can be generalised to the sequence:
In which case, the new term is some combination of any two previous terms. m is usually a power of 2 (m = 2M), often 232 or 264. The formula_3 operator denotes a general binary operation. This may be either addition, subtraction, multiplication, or the bitwise arithmetic exclusive-or operator (XOR). The theory of this type of generator is rather complex, and it may not be sufficient simply to choose random values for j and k. These generators also tend to be very sensitive to initialisation.
Generators of this type employ k words of state (they 'remember' the last k values).
If the operation used is addition, then the generator is described as an "Additive Lagged Fibonacci Generator" or ALFG, if multiplication is used, it is a "Multiplicative Lagged Fibonacci Generator" or MLFG, and if the XOR operation is used, it is called a "Two-tap generalised feedback shift register" or GFSR. The Mersenne twister algorithm is a variation on a GFSR. The GFSR is also related to the linear feedback shift register, or LFSR.
Properties of lagged Fibonacci generators.
Lagged Fibonacci generators have a maximum period of (2k - 1)*2M-1 if addition or subtraction is used, and (2k-1)*k if exclusive-or operations are used to combine the previous values. If, on the other hand, multiplication is used, the maximum period is (2k - 1)*2M-3, or 1/4 of period of the additive case.
For the generator to achieve this maximum period, the polynomial:
must be primitive over the integers mod 2. Values of j and k satisfying this constraint have been published in the literature. Popular pairs are:
Another list of possible values for "j" and "k" is on page 29 of volume 2 of "The Art of Computer Programming":
Note that the smaller number have short periods (only a few "random" numbers are generated before the first "random" number is repeated and the sequence restarts).
If addition is used, it is required that at least one of the first k values chosen to initialise the generator be odd; if multiplication is used, instead, it is required that all the first k values be odd.
It has been suggested that good ratios between j and k are approximately the golden ratio.
Problems with LFGs.
In a paper on four-tap shift registers, Robert M. Ziff, referring to LFGs that use the XOR operator, states that "It is now widely known that such generators, in particular with the two-tap rules such as R(103, 250), have serious deficiencies. Marsaglia observed very poor behavior with R(24,55) and smaller generators, and advised against using generators of this type altogether. ... The basic problem of two-tap generators R(a, b) is that they have a built-in three-point correlation between formula_4, formula_5, and formula_6, simply given by the generator itself ... While these correlations are spread over the size formula_7 of the generator itself, they can evidently still lead to significant errors.". This only refers to the standard LFG where each new number in the sequence depends on two previous numbers. A three-tap LFG has been shown to eliminate some statistical problems such as failing the Birthday Spacings and Generalized Triple tests.
The initialization of LFGs is a very complex problem. The output of LFGs is very sensitive to initial conditions, and statistical defects may appear initially but also periodically in the output sequence unless extreme care is taken . Another potential problem with LFGs is that the mathematical theory behind them is incomplete, making it necessary to rely on statistical tests rather than theoretical performance.

</doc>
<doc id="45621" url="https://en.wikipedia.org/wiki?curid=45621" title="Psychopharmacology">
Psychopharmacology

Psychopharmacology (from Greek , "psȳkhē", "breath, life, soul"; , "pharmakon", "drug"; and , "-logia") is the scientific study of the effects drugs have on mood, sensation, thinking, and behavior. It is distinguished from neuropsychopharmacology, which emphasizes the correlation between drug-induced changes in the functioning of cells in the nervous system and changes in consciousness and behavior. 
The field of psychopharmacology studies a wide range of substances with various types of psychoactive properties, focusing primarily on the chemical interactions with the brain.
Psychoactive drugs interact with particular target sites or receptors found in the nervous system to induce widespread changes in physiological or psychological functions. The specific interaction between drugs and their receptors is referred to as "drug action", and the widespread changes in physiological or psychological function is referred to as "drug effect". These drugs may originate from natural sources such as plants and animals, or from artificial sources such as chemical synthesis in the laboratory.
Historical overview.
Early psychopharmacology.
Not often mentioned or included in the field of psychopharmacology today, are psychoactive substances not identified as useful in modern mental health settings or references. These substances are naturally occurring, but nonetheless psychoactive, and are compounds identified through the work of ethnobotanists and ethnomycologists (and others who study the native use of naturally occurring psychoactive drugs). However, although these substances have been used throughout history by various cultures, and have a profound effect on mentality and brain function, they have not always attained the degree of scrutinous evaluation that lab-made compounds have. Nevertheless, some, such as psilocybin and mescaline, have provided a basis of study for the compounds that are used and examined in the field today. Hunter-gatherer societies tended to favor psychedelics, dissociatives and deliriants, and today their use can still be observed in many surviving tribal cultures. The exact drug used depends on what the particular ecosystem a given tribe lives in can support, and are typically found growing wild. Such drugs include various psychedelic mushrooms containing psilocybin, muscimol, and muscarine (to name a few), and cacti containing mescaline and other chemicals, along with myriad other psychoactive-chemical-containing plants. These societies generally attach spiritual significance to such drug use, and often incorporate it into their religious practices. With the dawn of the Neolithic and the proliferation of agriculture, new psychoactives came into use as a natural by-product of farming. Among them were opium, cannabis, and alcohol derived from the fermentation of cereals and fruits. Most societies began developing herblores, lists of herbs which were good for treating various physical and mental ailments. For example, St. John's Wort was traditionally prescribed in parts of Europe for depression (in addition to use as a general-purpose tea), and Chinese medicine developed elaborate lists of herbs and preparations. These and various other substances that have an effect on the brain are still used as remedies in many cultures.
Modern psychopharmacology.
The dawn of contemporary psychopharmacology marked the beginning of the use of psychiatric drugs to treat psychological illnesses. It brought with it the use of opiates and barbiturates for the management of acute behavioral issues in patients. In the early stages, psychopharmacology was primarily used for sedation. Then with the 1950s came the establishment of chlorpromazine for psychoses, lithium carbonate for mania, and then in rapid succession, the development of tricyclic antidepressants, monoamine oxidase inhibitors, benzodiazepines, among other antipsychotics and antidepressants. A defining feature of this era includes an evolution of research methods, with the establishment of placebo-controlled, double blind studies, and the development of methods for analyzing blood levels with respect to clinical outcome and increased sophistication in clinical trials. The early 1960s revealed a revolutionary model by Julius Axelrod describing nerve signals and synaptic transmission, which was followed by a drastic increase of biochemical brain research into the effects of psychotropic agents on brain chemistry. After the 1960s, the field of psychiatry shifted to incorporate the indications for and efficacy of pharmacological treatments, and began to focus on the use and toxicities of these medications. The 1970s and 1980s were further marked by a better understanding of the synaptic aspects of the action mechanisms of drugs. However, the model has its critics, too – notably Joanna Moncrieff and the Critical Psychiatry Network.
Chemical signaling.
Neurotransmitters.
Psychoactive drugs exert their sensory and behavioral effects almost entirely by acting on neurotransmitters and by modifying one or more aspects of synaptic transmission. Neurotransmitters can be viewed as chemicals through which neurons primarily communicate; psychoactive drugs affect the mind by altering this communication. Drugs may act by 1) serving as a precursor for the neurotransmitter; 2) inhibiting neurotransmitter synthesis; 3) preventing storage of neurotransmitter in the presynaptic vesicle; 4) stimulating or inhibiting neurotransmitter release; 5) stimulating or blocking post-synaptic receptors; 6) stimulating autoreceptors, inhibiting neurotransmitter release; 7) blocking autoreceptors, increasing neurotransmitter release; 8) inhibiting neurotransmission breakdown; or 9) blocking neurotransmitter reuptake by the presynaptic neuron.
Hormones.
The other central method through which drugs act is by affecting communications between cells through hormones. Neurotransmitters can usually only travel a microscopic distance before reaching their target at the other side of the synaptic cleft, while hormones can travel long distances before reaching target cells anywhere in the body. Thus, the endocrine system is a critical focus of psychopharmacology because 1) drugs can alter the secretion of many hormones; 2) hormones may alter the behavioral responses to drugs; 3) hormones themselves sometimes have psychoactive properties; and 4) the secretion of some hormones, especially those dependent on the pituitary gland, is controlled by neurotransmitter systems in the brain.
Psychopharmacological substances.
Alcohol.
Alcohol is a depressant, the effects of which may vary according to dosage amount, frequency, and chronicity. As a member of the sedative-hypnotic class, at the lowest doses, the individual feels relaxed and less anxious. In quiet settings, the user may feel drowsy, but in settings with increased sensory stimulation, individuals may feel uninhibited and more confident. High doses of alcohol rapidly consumed may produce amnesia for the events that occur during intoxication. Other effects include reduced coordination, which leads to slurred speech, impaired fine-motor skills, and delayed reaction time. The effects of alcohol on the body’s neurochemistry are more difficult to examine than some other drugs. This is because the chemical nature of the substance makes it easy to penetrate into the brain, and it also influences the phospholipid bilayer of neurons. This allows alcohol to have a widespread impact on many normal cell functions and modifies the actions of several neurotransmitter systems. Alcohol inhibits glutamate (a major excitatory neurotransmitter in the nervous system) neurotransmission by reducing the effectiveness at the NMDA receptor, which is related to memory loss associated with intoxication. It also modulates the function of GABA, a major inhibitory amino acid neurotransmitter. The reinforcing qualities of alcohol leading to repeated use – and thus also the mechanisms of withdrawal from chronic alcohol use – are partially due to the substance’s action on the dopamine system. This is also due to alcohol’s effect on the opioid systems, or endorphins, that have opiate-like effects, such as modulating pain, mood, feeding, reinforcement, and response to stress.
Antidepressants.
Antidepressants reduce symptoms of mood disorders primarily through the regulation of norepinephrine and serotonin (particularly the 5-HT receptors). After chronic use, neurons adapt to the change in biochemistry, resulting in a change in pre- and postsynaptic receptor density and second messenger function.
Monoamine oxidase inhibitors (MAOIs) are the oldest class of antidepressants. They inhibit monoamine oxidase, the enzyme that metabolizes the monoamine neurotransmitters in the presynaptic terminals that are not contained in protective synaptic vesicles. The inhibition of the enzyme increases the amount of neurotransmitter available for release. It increases norepinephrine, dopamine, and 5-HT and thus increases the action of the transmitters at their receptors. MAOIs have been somewhat disfavored because of their reputation for more serious side effects.
Tricyclic antidepressants (TCAs) work through binding to the presynaptic transporter proteins and blocking the reuptake of norepinephrine or 5-HT into the presynaptic terminal, prolonging the duration of transmitter action at the synapse.
Selective serotonin reuptake inhibitors (SSRIs) selectively block the reuptake of serotonin (5-HT) through their inhibiting effects on the sodium/potassium ATP-dependent serotonin transporter in presynaptic neurons. This increases the availability of 5-HT in the synaptic cleft. The main parameters to consider in choosing an antidepressant are side effects and safety. Most SSRIs are available generically and are relatively inexpensive. Older antidepressants, such as the TCAs and MAOIs usually require more visits and monitoring, and this may offset the low expense of the drugs. The SSRIs are relatively safe in overdose and better tolerated than the TCAs and MAOIs for most patients.
Antipsychotics.
All antipsychotic substances, except clozapine, are relatively potent postsynaptic dopamine receptor blockers (dopamine antagonists). All of the effective antipsychotics, except clozapine, act on the nigrostriatal system. For an antipsychotic to be effective, it generally requires a dopamine antagonism of 60%-80% of dopamine D2 receptors.
First generation (typical) antipsychotics: Traditional neuroleptics modify several neurotransmitter systems, but their clinical effectiveness is most likely due to their ability to antagonize dopamine transmission by competitively blocking the receptors or by inhibiting dopamine release. The most serious and troublesome side effects of these classical antipsychotics are movement disorders that resemble the symptoms of Parkinson's disease, because the neuroleptics antagonize dopamine receptors broadly, also reducing the normal dopamine-mediated inhibition of cholinergic cells in the striatum.
Second-generation (atypical) antipsychotics: The concept of “atypicality” is from the finding that the second generation antipsychotics (SGAs) had a greater serotonin/dopamine ratio than did earlier drugs, and might be associated with improved efficacy (particularly for the negative symptoms of psychosis) and reduced extrapyramidal side effects. Some of the efficacy of atypical antipsychotics may be due to 5-HT2 antagonism or the blockade of other dopamine receptors. Agents that purely block 5-HT2 or dopamine receptors other than D2 have often failed as effective antipsychotics.
Benzodiazepines.
Benzodiazepines are often used to reduce anxiety symptoms, muscle tension, seizure disorders, insomnia, symptoms of alcohol withdrawal, and panic attack symptoms. Their action is primarily on specific benzodiazepine sites on the GABAA receptor. This receptor complex is thought to mediate the anxiolytic, sedative, and anticonvulsant actions of the benzodiazepines. Use of benzodiazepines carries the risk of tolerance (necessitating increased dosage), dependence, and abuse. Taking these drugs for a long period of time can lead to withdrawal symptoms upon abrupt discontinuation.
Hallucinogens.
Hallucinogens cause perceptual and cognitive distortions without delirium. The state of intoxication is often called a “trip”. Onset is the first stage after an individual ingests (LSD, psilocybin, or mescaline) or smokes (dimethyltryptamine) the substance. This stage may consist of visual effects, with an intensification of colors and the appearance of geometric patterns that can be seen with one’s eyes closed. This is followed by a plateau phase, where the subjective sense of time begins to slow and the visual effects increase in intensity. The user may experience synesthesia, a crossing-over of sensations (for example, one may “see” sounds and “hear” colors). In addition to the sensory-perceptual effects, hallucinogenic substances may induce feelings of depersonalization, emotional shifts to a euphoric or anxious/fearful state, and a disruption of logical thought. Hallucinogens are classified chemically as either indoleamines (specifically tryptamines), sharing a common structure with serotonin, or as phenethylamines, which share a common structure with norepinephrine. Both classes of these drugs are agonists at the 5-HT2 receptors; this is thought to be the central component of their hallucinogenic properties. Activation of 5-HT2A may be particularly important for hallucinogenic activity. However, repeated exposure to hallucinogens leads to rapid tolerance, likely through down-regulation of these receptors in specific target cells.
Hypnotics.
Hypnotics are often used to treat the symptoms of insomnia, or other sleep disorders. Benzodiazepines are still among the most widely prescribed sedative-hypnotics in the United States today. Certain non-benzodiazepine drugs are used as hypnotics as well. Although they lack the chemical structure of the benzodiazepines, their sedative effect is similarly through action on the GABAA receptor. They also have a reputation of being less addictive than benzodiazepines. Melatonin, a naturally-occurring hormone, is often used over the counter (OTC) to treat insomnia and jet lag. This hormone appears to be excreted by the pineal gland early during the sleep cycle and may contribute to human circadian rhythms. Because OTC melatonin supplements are not subject to careful and consistent manufacturing, more specific melatonin agonists are sometimes preferred. They are used for their action on melatonin receptors in the suprachiasmatic nucleus, responsible for sleep-wake cycles. Many barbiturates have or had an FDA-approved indication for use as sedative-hypnotics, but have become less widely used because of their limited safety margin in overdose, their potential for dependence, and the degree of central nervous system depression they induce. The amino-acid L-tryptophan is also available OTC, and seems to be free of dependence or abuse liability. However, it is not as powerful as the traditional hypnotics. Because of the possible role of serotonin in sleep patterns, a new generation of 5-HT2 antagonists are in current development as hypnotics.
Cannabis and the cannabinoids.
Cannabis consumption produces a dose-dependent state of intoxication in humans. There is commonly increased blood flow to the skin, which leads to sensations of warmth or flushing, and heart rate is also increased. It also frequently induces increased hunger. Iversen (2000) categorized the subjective and behavioral effects often associated with cannabis into four stages. The first is the "buzz," a brief period of initial responding, where the main effects are lightheadedness or slight dizziness, in addition to possible tingling sensations in the extremities or other parts of the body. The "high" is characterized by feelings of euphoria and exhilaration characterized by mild psychedelia, as well as a sense of disinhibition. If the individual has taken a sufficiently large dose of cannabis, the level of intoxication progresses to the stage of being “stoned,” and the user may feel calm, relaxed, and possibly in a dreamlike state. Sensory reactions may include the feeling of floating, enhanced visual and auditory perception, visual illusions, or the perception of the slowing of time passage, which are somewhat psychedelic in nature.
There exist two primary CNS cannabinoid receptors, on which marijuana and the cannabinoids act. Both the CB1 receptor and CB2 receptor are found in the brain. The CB2 receptor is also found in the immune system. CB1 is expressed at high densities in the basal ganglia, cerebellum, hippocampus, and cerebral cortex. Receptor activation can inhibit cAMP formation, inhibit voltage-sensitive calcium ion channels, and activate potassium ion channels. Many CB1 receptors are located on axon terminals, where they act to inhibit the release of various neurotransmitters. In combination, these drug actions work to alter various functions of the central nervous system including the motor system, memory, and various cognitive processes.
Opiates.
The opiate drugs, which include drugs like heroin, morphine, and oxycodone, belong to the class of narcotic analgesics, which reduce pain without producing unconsciousness, but do produce a sense of relaxation and sleep, and at high doses, may result in coma and death. The ability of opiates (both endogenous and exogenous) to relieve pain depends on a complex set of neuronal pathways at the spinal cord level, as well as various locations above the spinal cord. Small endorphin neurons in the spinal cord act on receptors to decrease the conduction of pain signals from the spinal cord to higher brain centers. Descending neurons originating in the periaqueductal gray give rise to two pathways that further block pain signals in the spinal cord. The pathways begin in the locus coeruleus (noradrenaline) and the nucleus of raphe (serotonin). Similar to other abused substances, opiate drugs increase dopamine release in the nucleus accumbens. Opiates are more likely to produce physical dependence than any other class of psychoactive drugs, and can lead to painful withdrawal symptoms if discontinued abruptly after regular use.
Stimulants.
Cocaine is one of the more common stimulants, and is a complex drug that interacts with various neurotransmitter systems. It commonly cause heightened alertness, increased confidence, feelings of exhilaration, reduced fatigue, and a generalized sense of well-being. The effects of cocaine are similar to those of the amphetamines, though cocaine tends to have a shorter duration of effect. In high doses and/or with prolonged use, cocaine can result in a number of negative effects as well, including irritability, anxiety, exhaustion, total insomnia, and even psychotic symptomatology. Most of the behavioral and physiological actions of cocaine can be explained by its ability to block the reuptake of the two catecholamines, dopamine and norepinephrine, as well as serotonin. Cocaine binds to transporters that normally clear these transmitters from the synaptic cleft, inhibiting their function. This leads to increased levels of neurotransmitter in the cleft and transmission at the synapses. Based on in-vitro studies using rat brain tissue, cocaine binds most strongly to the serotonin transporter, followed by the dopamine transporter, and then the norepinephrine transporter.
Amphetamines tend to cause the same behavioral and subjective effects of cocaine. Various forms of amphetamine are commonly used to treat the symptoms of attention deficit hyperactivity disorder (ADHD) and narcolepsy, or are used recreationally. Amphetamine and methamphetamine are indirect agonists of the catecholaminergic systems. They block catecholamine reuptake, in addition to releasing catecholamines from nerve terminals. There is evidence that dopamine receptors play a central role in the behavioral responses of animals to cocaine, amphetamines, and other psychostimulant drugs. One action causes the dopamine molecules to be released from inside the vesicles into the cytoplasm of the nerve terminal, which are then transported outside by the mesolimbic dopamine pathway to the nucleus accumbens. This plays a key role in the rewarding and reinforcing effects of cocaine and amphetamine in animals, and is the primary mechanism for amphetamine dependence.
Psychopharmacological research.
In psychopharmacology, researchers are interested in any substance that crosses the blood–brain barrier and thus has an effect on behavior, mood or cognition. Drugs are researched for their physiochemical properties, physical side effects, and psychological side effects. Researchers in psychopharmacology study a variety of different psychoactive substances that include alcohol, cannabinoids, club drugs, psychedelics, opiates, nicotine, caffeine, psychomotor stimulants, inhalants, and anabolic-androgenic steroids. They also study drugs used in the treatment of affective and anxiety disorders, as well as schizophrenia.
Clinical studies are often very specific, typically beginning with animal testing, and ending with human testing. In the human testing phase, there is often a group of subjects, one group is given a placebo, and the other is administered a carefully measured therapeutic dose of the drug in question. After all of the testing is completed, the drug is proposed to the concerned regulatory authority (e.g. the U.S. FDA), and is either commercially introduced to the public via prescription, or deemed safe enough for over the counter sale.
Though particular drugs are prescribed for specific symptoms or syndromes, they are usually not specific to the treatment of any single mental disorder. Because of their ability to modify the behavior of even the most disturbed patients, the antipsychotic, antianxiety, and antidepressant agents have greatly affected the management of the hospitalized mentally ill, enabling hospital staff to devote more of their attention to therapeutic efforts and enabling many patients to lead relatively normal lives outside of the hospital.
A somewhat controversial application of psychopharmacology is "cosmetic psychiatry": persons who do not meet criteria for any psychiatric disorder are nevertheless prescribed psychotropic medication. The antidepressant bupropion is then prescribed to increase perceived energy levels and assertiveness while diminishing the need for sleep. The antihypertensive compound propranolol is sometimes chosen to eliminate the discomfort of day-to-day anxiety. Fluoxetine in nondepressed people can produce a feeling of generalized well-being. Pramipexole, a treatment for restless leg syndrome, can dramatically increase libido in women. These and other off-label lifestyle applications of medications are not uncommon. Although occasionally reported in the medical literature no guidelines for such usage have been developed. There is also a potential for the misuse of prescription psychoactive drugs by elderly persons, who may have multiple drug prescriptions.

</doc>
<doc id="45622" url="https://en.wikipedia.org/wiki?curid=45622" title="Iranian Green Movement">
Iranian Green Movement

The Iranian Green Movement refers to a political movement that arose after the 2009 Iranian presidential election, in which protesters demanded the removal of Mahmoud Ahmadinejad from office. Green was initially used as the symbol of Mir Hossein Mousavi's campaign, but after the election it became the symbol of unity and hope for those asking for annulment of what they regarded as a fraudulent election. Mir Hossein Mousavi and Mehdi Karroubi are recognized as political leaders of the Green Movement. Hossein-Ali Montazeri was also mentioned as spiritual leader of the movement.
The Green Movement protests were a major event in Iran's modern political history and observers claimed that protests were the largest since the Iranian Revolution of 1978-1979.
Outcome of 2009-2010 Iranian election protests.
The election was held on 12 June 2009. The official results showed Ahmadinejad winning by a landslide, though Mousavi and others believed the results were fraudulent. They suggested that the Interior Minister, Sadegh Mahsouli, an ally of Ahmadinejad, had interfered with the election and distorted the votes to keep Ahmadinejad in power. Mousavi then claimed victory, and called for his supporters to celebrate it which led to the 2009–2010 Iranian election protests.
Protests.
Clashes broke out between police and groups protesting the election results from early morning on Saturday onward. Initially, the protests were largely peaceful. However, as time passed, they became increasingly violent. In a stand-off that later took place in north Tehran between supporters of Ahmadinejad and Mousavi, an angry throng of people broke into shops, started fires, and tore down signs. Civil unrest took place as riot police on motorbikes used batons to disperse Mousavi supporters who staged a sit-in near the interior ministry, where the results were announced. Up to 2,000 Mousavi supporters erected barricades of burning tyres and chanted "Mousavi take back our vote!".
The demonstrations grew bigger and more heated than the 1999 student protests. Al Jazeera English described the 13 June situation as the "biggest unrest since the 1979 revolution." It also reported that protests seemed spontaneous without any formal organization. Two hundred people protested outside Iran's embassy in London on 13 June. Ynet has stated that "tens of thousands" protested on 13 June. Demonstrators are chanting phrases such as "Down with the dictator", "Death to the dictator", and "Give us our votes back". Mousavi has urged for calm and asked that his supporters refrain from acts of violence.
Ynet reported on 14 June that two people had died in the rioting so far. That day, protests had been organized in front of the Iranian embassies in Turkey, Dubai, Paris, Berlin, London, Rome, Sydney, Vienna and The Hague. In response to the reformist protests, tens of thousands of people rallied in Tehran on 14 June to support the victory of Ahmadinejad.
On 15 June, Mousavi rallied, with anywhere from hundreds of thousands to three million, of his supporters in Tehran, despite being warned by state officials that any such rally would be illegal. The demonstration, the largest in the Islamic Republic of Iran's 30-year history, was Mousavi's first public appearance after the election. Protests focused around Azadi Tower, around which lines of people stretched for more than nine kilometers met. Gunshots were reported to have been fired at the rally, where Mousavi had spoken to his supporters saying, "The vote of the people is more important than Mousavi or any other person." All three opposition candidates appeared.
Competing rallies for Mousavi and for Ahmadinejad took place on 16 June. The pro-Ahmadinejad protesters, chanting the phrases "Death to America!" and "Death to Israel!", outnumbered their opponents, but they did not match the numbers of opponents who had protested the day before. Reports from the state media and elsewhere stated on 16 June that seven people have died in all of the protests so far. However, Times Online quoted a Rasoul Akram Hospital nurse that day who asserted that 28 people have suffered from "bullet wounds" and eight have died so far. Over half a million reformist Iranians marched silently from Haft-e-Tir Square to Vali Asr Square on 17 June. Huffington Post reported that day that 32 people had died protesting so far.
On 14 February 2011, the largest Green demonstrations in Iran in more than a year broke out. In response pro-government MPs called for the death of opposition leaders Mir Hussein Moussavi and Mehdi Karroubi.
Government actions.
Arrests.
On the weekend of 13 and 14 June, in a series of raids across Tehran, the government arrested over 170 people, according to police officials. Among them were prominent reformist politicians, including Mojahedin of the Islamic Revolution Organization (MIRO) founder Behzad Nabavi, Islamic Iran Participation Front (IIPF) leader Mohsen Mirdamadi, and former president Mohammad Khatami's brother Mohammad-Reza Khatami, who was later released. Also arrested were Mostafa Tajzadeh and Mohsen Aminzadeh, whom the IRNA said were involved in orchestrating protests on 13 June. Anonymous sources said that the police stormed the headquarters of the IIPF and arrested a number of people. Iranian journalist Mashallah Shamsolvaezin claimed that presidential candidate Mir-Hossein Mousavi was put under house arrest, although officials denied this. An estimated 200 people were detained after clashes with students at Tehran university, although many were later released.
Acting Police Chief Ahmad-Reza Radan stated via the state press service on the 14th that "in the interrogation of related rebels, we intend to find the link between the plotters and foreign media". A judiciary spokesman said they had not been arrested but that they were summoned, "warned not to increase tension," and later released. Intelligence minister Gholam Hossein Mohseni-Ejehei linked some arrests to terrorism supported from outside Iran, stating that "more than 20 explosive consignments were discovered". Others, he said, were "counter-revolutionary groups" who had "penetrated election headquarters" of the election candidates.
On 16 June, Reuters reported that former vice-president Mohammad-Ali Abtahi and former presidential advisor Saeed Hajjarian had been arrested. Human rights lawyer Abdolfattah Soltani, who had been demanding a recount of all votes, was also arrested on the Tuesday according to Shirin Ebadi, who said that security officials had posed as clients. Over 100 students were arrested after security forces fired tear gas at protesters at Shiraz University on the same day. Reporters Without Borders reported that 5 of 11 arrested journalists were still detention as of 16 June, and that a further 10 journalists were unaccounted for and may have been arrested.
On 17 June, former foreign minister and secretary-general of the Freedom Movement of Iran, Ebrahim Yazdi, was arrested while undergoing tests at Pars hospital in Tehran. He was held overnight in Evin Prison before being released and returning to hospital, where according to Human Rights Watch he remained under guard. In Tabriz, other Freedom Movement activists and eight members of the IIPF were arrested, with reports of at least 100 civic figures' arrests. The total number of arrests across Iran since the election was reported as 500.
Aaron Rhodes, a spokesman for the International Campaign for Human Rights in Iran, stated that "Iranian intelligence and security forces are using the public protests to engage in what appears to be a major purge of reform-oriented individuals whose situations in detention could be life-threatening". In Isfahan Province, prosecutor-general Mohammadreza Habibi warned that dissidents could face execution under Islamic law.
The Green Path of Hope.
Mousavi and other reformist leaders are now working in peaceful and legal methods to widen the influence of their reforms. They have set up a new coalition named "The Green Path of Hope". Iranian political parties and movements need to be authorized by the Interior Ministry. Mousavi neither recognizes the current government as legitimate nor is likely to receive permission; so, the movement was named a "path" in order to bypass this law.
The Green Path of Hope claims it seeks to continue protests against Ahmadinejad's presidency following lawful and peaceful methods, and the full execution of the constitution, as Mousavi says:
According to organization officials, the movement functions encompasses numerous political parties, NGO's and social networks. Mousavi emphasized that existent, autonomous social networks in the community are part of this movement:
The "Green Path" has six main members of the central council, who are connected to reformist parties, NGOs, and social networks. The main body will be ordinary protesters. The strategy is to connect existent pressures and issues in society in a social network, and to therefore lead protests in a lawful manner.
Where is my vote?
"Where is my vote?" ( "ra'y-e-man kojāst?") is a motto which was used during the protests. The Iranian government, headed by President Mahmoud Ahmadinejad, released results claiming a two-thirds majority. However, Mousavi had already claimed victory before the vote count was done and supporters of Mousavi and Karroubi accused the government of rigging the votes.
In the aftermath of the election, protests were widened and several massive protests were held around the country by the people. The government arrested a large number of the protesters and several were killed by the police and governmental militia forces.
Although the Iranian government prohibited any form of gathering by opposition-supporters in Tehran and across the country, significantly slowed down internet access and censored any form of media agreeing with the opposition, hundreds of thousands of Iranians chanted this motto, defying the law and challenging the Islamic Republic.
Legal ways.
Mousavi and the reformists later attempted to implement reforms though legal processes and set up a new coalition, named The Green Path of Hope, to support this.
Iran national football team.
During the Iran's final game of the 2010 FIFA World Cup qualifiers against South Korea in Seoul on 17 June 2009, seven members of the team, Javad Nekounam, Ali Karimi, Hossein Kaebi, Masoud Shojaei, Mohammad Nosrati, Vahid Hashemian, and captain Mehdi Mahdavikia wore green wristbands in support of the Iranian Green Movement during the 2009 Iranian election protests. Initial reports were that all seven players were banned for life by the Iranian Football Federation, however, state-run media claimed that all seven had "retired". On 24 June 2009, FIFA wrote to Iran's Football Federation asking for clarification on the situation. The Iranian Football Federation replied that no disciplinary action has been taken against any player. As of 2014 FIFA World Cup qualification, several of the above players have played again for the national team, notably Javad Nekounam, Masoud Shojaei, and Mehdi Mahdavikia.

</doc>
<doc id="45623" url="https://en.wikipedia.org/wiki?curid=45623" title="Informer (disambiguation)">
Informer (disambiguation)

An informer, or informant, is a person who provides privileged information to an agency.
Informer may also refer to:

</doc>
<doc id="45627" url="https://en.wikipedia.org/wiki?curid=45627" title="IIRC">
IIRC

IIRC may refer to:

</doc>
<doc id="45630" url="https://en.wikipedia.org/wiki?curid=45630" title="Peter III">
Peter III

Peter III may refer to:

</doc>
<doc id="45631" url="https://en.wikipedia.org/wiki?curid=45631" title="Telephony Application Programming Interface">
Telephony Application Programming Interface

The Telephony Application Programming Interface (TAPI) is a Microsoft Windows API, which provides computer telephony integration and enables PCs running Microsoft Windows to use telephone services. Different versions of TAPI are available on different versions of Windows. TAPI allows applications to control telephony functions between a computer and telephone network for data, fax, and voice calls. It includes basic functions, such as dialing, answering, and hanging up a call. It also supports supplementary functions, such as hold, transfer, conference, and call park found in PBX, ISDN, and other telephone systems. 
TAPI is used primarily to control either modems or, more recently, to control business telephone system (PBX) handsets. When controlling a PBX handset, the driver is provided by the manufacturer of the telephone system. Some manufacturers provide drivers that allow the control of multiple handsets. This is traditionally called "third-party control". Other manufacturers provide drivers that allow the control of a single handset. This is called "first-party control". Third-party drivers are designed to allow applications to see and/or control multiple extensions at the same time. Some telephone systems only permit one third-party connection at a time. First-party drivers are designed to allow applications to monitor and/or control one extension at a time. Telephone systems naturally permit many of these connections simultaneously. Modem connections are by nature first-party.
TAPI can also be used to control voice-enabled telephony devices, including voice modems and dedicated hardware such as Dialogic cards.
History.
TAPI was introduced in 1993 as the result of joint development by Microsoft and Intel. The first publicly available version of TAPI was version 1.3, which was released as a patch on top of Microsoft Windows 3.1. Version 1.3 drivers were 16-bit only. Version 1.3 is no longer supported, although some MSDN development library CDs still contain the files and patches.
With Microsoft Windows 95, TAPI was integrated into the operating system. The first version on Windows 95 was TAPI 1.4. TAPI 1.4 had support for 32-bit applications.
The TAPI standard supports both connections from individual computers and LAN connections serving any number of computers.
TAPI 2.0 was introduced with Windows NT 4.0. Version 2.0 was the first version on the Windows NT platform. It made a significant step forward by supporting ACD and PBX-specific functionality.
In 1997, Microsoft released TAPI version 2.1. This version of TAPI was available as a downloadable update and was the first version to be supported on both the Microsoft Windows 95 and Windows NT/2000 platforms.
TAPI 3.0 was released in 1999 together with Windows 2000. This version enables IP telephony (VoIP) by providing simple and generic methods for making connections between two (using H.323) or more (using IP Multicast) computers and now also offers the ability to access any media streams involved in the connection.
Windows XP included both TAPI 3.1 and TAPI 2.2. TAPI 3.1 supports the Microsoft Component Object Model and provides a set of COM objects to application programmers. This version uses File Terminals which allow applications to record streaming data to a file and play this recorded data back to a stream. A USB Phone TSP (Telephony Service Provider) was also included which allows an application to control a USB phone and use it as a streaming endpoint. TAPI 3.0 or TAPI 3.1 are not available on operating systems earlier than Windows 2000 and Windows XP respectively.
The Telephony Server Application Programming Interface (TSAPI) is a similar standard developed by Novell for NetWare servers.
TAPI 2.x vs TAPI 3.x.
It is a common misconception that TAPI 3.0 (or TAPI 3.1) replaces TAPI 2.x.
TAPI 2.x and earlier versions were written in C; the API uses pointers to structures. Consequently, TAPI 2.x is easy to access from C or C++ applications, but it can be awkward to use from many other programming languages. 
TAPI 3.x was designed with a Component Object Model (COM) interface. This was done with the intent of making it accessible to higher level applications such as developed in VB or other environments that provide easy access to COM but don't deal with C-style pointers. 
TAPI 3.x has a slightly different set of functionality than TAPI 2.x. The addition of integrated media control was the most significant addition. But TAPI 3.x doesn't include all functionality that TAPI 2.x does, like support for the Phone class.
One very notable issue with TAPI 3.x is the lack of support for managed code (.NET environment). As documented in Microsoft KB Article 841712, Microsoft currently has no plans to support TAPI 3.x directly from .Net programming languages. However, Mark Smith has provided a Managed C++ library called ITAPI3 and other developers such as Mondago provide .Net libraries to work indirectly with TAPI enabled PBXs.
One often overlooked reason an application developer might choose between TAPI 2.x and TAPI 3.x should be the hardware vendors recommendation. Even though TAPI provides an abstract model of phone lines, telephony applications are still heavily impacted by the specific behavior of the underlying hardware. Troubleshooting behavior issues usually requires both software and hardware vendors to collaborate. Because there is almost a 1:1 relationship between the TAPI Service Provider (TSP) interface and the TAPI 2.x interface, collaboration is often easier if the application is designed using TAPI 2.x. Experience with TAPI 3.x varies significantly between hardware vendors.
TAPI compliant hardware.
Telephony hardware that supports TAPI includes most voice modems and some telephony cards such as Dialogic cards.
The following telephone systems provide Tapi drivers. Often these are only available for 32 bit operating systems. Many of these drivers are licensed and thus incur a charge to use. In other cases, alternative drivers are available for separate purchase from iQ NetSolutions, C4B Com For Business, Estos and Mondago:

</doc>
<doc id="45633" url="https://en.wikipedia.org/wiki?curid=45633" title="Economic history">
Economic history

Economic history is the study of economies or economic phenomena of the past. Analysis in economic history is undertaken using a combination of historical methods, statistical methods and the application of economic theory to historical situations and institutions. The topic includes and business history and overlaps with areas of social history such as demographic and labor history. The quantitative – in this case, econometric – study of economic history is also known as cliometrics.
Development as a separate field.
In Germany in the late 19th century, scholars in a number of universities, led by Gustav von Schmoller, developed the historical school of economic history. It ignored quantitative and mathematical approaches. Historical approach dominated German and French scholarship for most of the 20th century. The approach was spread to Great Britain by William Ashley, 1860-1927, and dominated British economic history for much of the 20th century. In France, economic history was heavily influenced by the Annales School from the early 20th century to the present. It exerts a worldwide influence through its Journal "Annales. Histoire, Sciences Sociales."
Treating economic history as a discrete academic discipline has been a contentious issue for many years. Academics at the London School of Economics and the University of Cambridge had numerous disputes over the separation of economics and economic history in the interwar era. Cambridge economists believed that pure economics involved a component of economic history and that the two were inseparably entangled. Those at the LSE believed that economic history warranted its own courses, research agenda and academic chair separated from mainstream economics.
In the initial period of the subject's development, the LSE position of separating economic history from economics won out. Many universities in the UK developed independent programmes in economic history rooted in the LSE model. Indeed, the Economic History Society had its inauguration at LSE in 1926 and the University of Cambridge eventually established its own economic history programme. However, the past twenty years have witnessed the widespread closure of these separate programmes in the UK and the integration of the discipline into either history or economics departments. Only the LSE retains a separate economic history department and stand-alone undergraduate and graduate programme in economic history. Cambridge, Glasgow, the LSE and Oxford together train the vast majority of economic historians coming through the British higher education system today.
United States.
Meanwhile, in the US, the field of economic history has in recent decades been largely subsumed into other fields of economics and is seen as a form of applied economics. As a consequence, there are no specialist economic history graduate programs at any universities anywhere in the country. Economic history remains as a special field component of regular economics or history PhD programs in universities including at University of California, Berkeley, Harvard University, Northwestern University and Yale University.
Economic history and economics.
Yale University economist Irving Fisher wrote in 1933 on the relationship between economics and economic history in his "Debt-Deflation Theory of Great Depressions" ("Econometrica", Vol. 1, No. 4: 337–338):
The study of dis-equilibrium may proceed in either of two ways. We may take as our unit for study an actual historical case of great dis-equilibrium, such as, say, the panic of 1873; or we may take as our unit for study any constituent tendency, such as, say, deflation, and discover its general laws, relations to, and combinations with, other tendencies. The former study revolves around events, or facts; the latter, around tendencies. The former is primarily economic history; the latter is primarily economic science. Both sorts of studies are proper and important. Each helps the other. The panic of 1873 can only be understood in light of the various tendencies involved—deflation and other; and deflation can only be understood in the light of various historical manifestations—1873 and other.
There is a school of thought among economic historians that splits economic history—the study of how economic phenomena evolved in the past—from historical economics—testing the generality of economic theory using historical episodes. US economic historian Charles P. Kindleberger explained this position in his 1990 book "Historical Economics: Art or Science?".
The new economic history, also known as cliometrics, refers to the systematic use of economic theory and/or econometric techniques to the study of economic history. The term cliometrics was originally coined by Jonathan R. T. Hughes and Stanley Reiter in 1960 and refers to Clio, who was the muse of history and heroic poetry in Greek mythology. Cliometricians argue their approach is necessary because the application of theory is crucial in writing solid economic history, while historians generally oppose this view warning against the risk of generating anachronisms. Early cliometrics was a type of counterfactual history. However, counterfactualism is no longer its distinctive feature. Some have argued that cliometrics had its heyday in the 1960s and 1970s and that it is now neglected by economists and historians.
In recent decades economic historians, following Douglass North, have tended to move away from narrowly quantitative studies toward institutional, social, and cultural history affecting the evolution of economies.   • E. Aerts and H. Van der Wee, 2002. "Economic History," "International Encyclopedia of the Social & Behavioral Sciences" pp. 4102-410. Abstract.</ref> However, this trend has been criticized, most forcefully by Francesco Boldizzoni, as a form of economic imperialism "extending the neoclassical explanatory model to the realm of social relations." Conversely, economists in other specializations have started to write on topics concerning economic history.
Economic history and the history of capitalism.
A new field calling itself the "History of Capitalism" has emerged in US history departments since about the year 2000. It includes many topics traditionally associated with the field of economic history, such as insurance, banking and regulation, the political dimension of business, and the impact of capitalism on the middle classes, the poor and women and minorities. The field utilizes the existing research of business history, but has sought to make it more relevant to the concerns of history departments in the United States, including by having limited or no discussion of individual business enterprises.

</doc>
<doc id="45634" url="https://en.wikipedia.org/wiki?curid=45634" title="Thread safety">
Thread safety

Thread safety is a computer programming concept applicable in the context of multi-threaded programs. A piece of code is thread-safe if it only manipulates shared data structures in a manner that guarantees safe execution by multiple threads at the same time. There are various strategies for making thread-safe data structures.
A program may execute code in several threads simultaneously in a shared address space where each of those threads has access to virtually all of the memory of every other thread. Thread safety is a property that allows code to run in multi-threaded environments by re-establishing some of the correspondences between the actual flow of control and the text of the program, by means of synchronization.
Levels of thread safety.
Software libraries can provide certain thread-safety guarantees. For example, concurrent reads might be guaranteed to be thread-safe, but concurrent writes might not be. Whether or not a program using such a library is thread-safe depends on whether it uses the library in a manner consistent with those guarantees.
Different vendors use slightly different terminology for thread-safety:
Thread safety guarantees usually also include design steps to prevent or limit the risk of different forms of deadlocks, as well as optimizations to maximize concurrent performance. However, deadlock-free guarantees can not always be given, since deadlocks can be caused by callbacks and violation of architectural layering independent of the library itself.
Implementation approaches.
Below we discuss two approaches for avoiding race conditions to achieve thread safety.
The first class of approaches focuses on avoiding shared state, and includes:
The second class of approaches are synchronization-related, and are used in situations where shared state cannot be avoided:
Examples.
In the following piece of Java code, the function is thread-safe:
<syntaxhighlight lang="java">
class Counter {
</syntaxhighlight>
In the following piece of C code, the function is thread-safe, but not reentrant:
<syntaxhighlight lang="c">
int increment_counter ()
</syntaxhighlight>
In the above, codice_1 can be called by different threads without any problem since a mutex is used to synchronize all access to the shared codice_2 variable. But if the function is used in a reentrant interrupt handler and a second interrupt arises inside the function, the second routine will hang forever. As interrupt servicing can disable other interrupts, the whole system could suffer.
The same function can be implemented to be both thread-safe and reentrant using the lock-free atomics in C++11:
<syntaxhighlight lang="cpp">
int increment_counter ()
</syntaxhighlight>

</doc>
<doc id="45635" url="https://en.wikipedia.org/wiki?curid=45635" title="Top-down and bottom-up design">
Top-down and bottom-up design

Top-down and bottom-up are both strategies of information processing and knowledge ordering, used in a variety of fields including software, humanistic and scientific theories (see systemics), and management and organization. In practice, they can be seen as a style of thinking, teaching, or leadership.
A top-down approach (also known as "stepwise design" and in some cases used as a synonym of "decomposition") is essentially the breaking down of a system to gain insight into its compositional sub-systems in a reverse engineering fashion. In a top-down approach an overview of the system is formulated, specifying but not detailing any first-level subsystems. Each subsystem is then refined in yet greater detail, sometimes in many additional subsystem levels, until the entire specification is reduced to base elements. A top-down model is often specified with the assistance of "black boxes", these make it easier to manipulate. However, black boxes may fail to elucidate elementary mechanisms or be detailed enough to realistically validate the model. Top down approach starts with the big picture. It breaks down from there into smaller segments.
A bottom-up approach is the piecing together of systems to give rise to more complex systems, thus making the original systems sub-systems of the emergent system. Bottom-up processing is a type of information processing based on incoming data from the environment to form a perception. From a Cognitive Psychology perspective, information enters the eyes in one direction (sensory input, or the "bottom"), and is then turned into an image by the brain that can be interpreted and recognized as a perception (output that is "built up" from processing to final cognition). In a bottom-up approach the individual base elements of the system are first specified in great detail. These elements are then linked together to form larger subsystems, which then in turn are linked, sometimes in many levels, until a complete top-level system is formed. This strategy often resembles a "seed" model, by which the beginnings are small but eventually grow in complexity and completeness. However, "organic strategies" may result in a tangle of elements and subsystems, developed in isolation and subject to local optimization as opposed to meeting a global purpose.
Product design and development.
During the design and development of new products, designers and engineers rely on both a bottom-up and top-down approach. The bottom-up approach is being utilized when off-the-shelf or existing components are selected and integrated into the product. An example would include selecting a particular fastener, such as a bolt, and designing the receiving components such that the fastener will fit properly. In a top-down approach, a custom fastener would be designed such that it would fit properly in the receiving components.
For perspective, for a product with more restrictive requirements (such as weight, geometry, safety, environment, etc.), such as a space-suit, a more top-down approach is taken and almost everything is custom designed. However, when it's more important to minimize cost and increase component availability, such as with manufacturing equipment, a more bottom-up approach would be taken, and as many off-the-shelf components (bolts, gears, bearings, etc.) would be selected as possible. In the latter case, the receiving housings would be designed around the selected components.
Computer science.
Software development.
In the software development process, the top-down and bottom-up approaches play a key role.
Top-down approaches emphasize planning and a complete understanding of the system. It is inherent that no coding can begin until a sufficient level of detail has been reached in the design of at least some part of the system. Top-down approaches are implemented by attaching the stubs in place of the module. This, however, delays testing of the ultimate functional units of a system until significant design is complete. Bottom-up emphasizes coding and early testing, which can begin as soon as the first module has been specified. This approach, however, runs the risk that modules may be coded without having a clear idea of how they link to other parts of the system, and that such linking may not be as easy as first thought. Re-usability of code is one of the main benefits of the bottom-up approach.
Top-down design was promoted in the 1970s by IBM researchers Harlan Mills and Niklaus Wirth. Mills developed structured programming concepts for practical use and tested them in a 1969 project to automate the "New York Times" morgue index. The engineering and management success of this project led to the spread of the top-down approach through IBM and the rest of the computer industry. Among other achievements, Niklaus Wirth, the developer of Pascal programming language, wrote the influential paper "Program Development by Stepwise Refinement". Since Niklaus Wirth went on to develop languages such as Modula and Oberon (where one could define a module before knowing about the entire program specification), one can infer that top-down programming was not strictly what he promoted. Top-down methods were favored in software engineering until the late 1980s, and object-oriented programming assisted in demonstrating the idea that both aspects of top-down and bottom-up programming could be utilized.
Modern software design approaches usually combine both top-down and bottom-up approaches. Although an understanding of the complete system is usually considered necessary for good design, leading theoretically to a top-down approach, most software projects attempt to make use of existing code to some degree. Pre-existing modules give designs a bottom-up flavor. Some design approaches also use an approach where a partially functional system is designed and coded to completion, and this system is then expanded to fulfill all the requirements for the project
Programming.
Top-down is a programming style, the mainstay of traditional procedural languages, in which design begins by specifying complex pieces and then dividing them into successively smaller pieces. The technique for writing a program using top–down methods is to write a main procedure that names all the major functions it will need. Later, the programming team looks at the requirements of each of those functions and the process is repeated. These compartmentalized sub-routines eventually will perform actions so simple they can be easily and concisely coded. When all the various sub-routines have been coded the program is ready for testing. By defining how the application comes together at a high level, lower level work can be self-contained. By defining how the lower level abstractions are expected to integrate into higher level ones, interfaces become clearly defined.
In a bottom-up approach, the individual base elements of the system are first specified in great detail. These elements are then linked together to form larger subsystems, which then in turn are linked, sometimes in many levels, until a complete top-level system is formed. This strategy often resembles a "seed" model, by which the beginnings are small, but eventually grow in complexity and completeness. Object-oriented programming (OOP) is a paradigm that uses "objects" to design applications and computer programs. In mechanical engineering with software programs such as Pro/ENGINEER, Solidworks, and Autodesk Inventor users can design products as pieces not part of the whole and later add those pieces together to form assemblies like building with LEGO. Engineers call this piece part design.
This bottom-up approach has one weakness. Good intuition is necessary to decide the functionality that is to be provided by the module. If a system is to be built from existing system, this approach is more suitable as it starts from some existing modules.
Parsing.
Parsing is the process of analyzing an input sequence (such as that read from a file or a keyboard) in order to determine its grammatical structure. This method is used in the analysis of both natural languages and computer languages, as in a compiler.
Bottom-up parsing is a strategy for analyzing unknown data relationships that attempts to identify the most fundamental units first, and then to infer higher-order structures from them. Top-down parsers, on the other hand, hypothesize general parse tree structures and then consider whether the known fundamental structures are compatible with the hypothesis. See Top-down parsing and Bottom-up parsing.
Nanotechnology.
Top-down and bottom-up are two approaches for the manufacture of products. These terms were first applied to the field of nanotechnology by the Foresight Institute in 1989 in order to distinguish between molecular manufacturing (to mass-produce large atomically precise objects) and conventional manufacturing (which can mass-produce large objects that are not atomically precise). Bottom-up approaches seek to have smaller (usually molecular) components built up into more complex assemblies, while top-down approaches seek to create nanoscale devices by using larger, externally controlled ones to direct their assembly.
The top-down approach often uses the traditional workshop or microfabrication methods where externally controlled tools are used to cut, mill, and shape materials into the desired shape and order. Micropatterning techniques, such as photolithography and inkjet printing belong to this category.
Bottom-up approaches, in contrast, use the chemical properties of single molecules to cause single-molecule components to (a) self-organize or self-assemble into some useful conformation, or (b) rely on positional assembly. These approaches utilize the concepts of molecular self-assembly and/or molecular recognition. See also Supramolecular chemistry. Such bottom-up approaches should, broadly speaking, be able to produce devices in parallel and much cheaper than top-down methods, but could potentially be overwhelmed as the size and complexity of the desired assembly increases.
Neuroscience and psychology.
These terms are also employed in neuroscience, cognitive neuroscience and cognitive psychology to discuss the flow of information in processing. Typically sensory input is considered "bottom-up", and higher cognitive processes, which have more information from other sources, are considered "top-down". A bottom-up process is characterized by an absence of higher level direction in sensory processing, whereas a top-down process is characterized by a high level of direction of sensory processing by more cognition, such as goals or targets (Beiderman, 19).
According to Psychology notes written by Dr. Charles Ramskov, a Psychology professor at De Anza College, Rock, Neiser, and Gregory claim that top-down approach involves perception that is an active and constructive process. Additionally, it is an approach not directly given by stimulus input, but is the result of stimulus, internal hypotheses, and expectation interactions. According to Theoretical Synthesis, "when a stimulus is presented short and clarity is uncertain that gives a vague stimulus, perception becomes a top-down approach."
Conversely, Psychology defines bottom-up processing as an approach wherein there is a progression from the individual elements to the whole. According to Ramskov, one proponent of bottom-up approach, Gibson, claims that it is a process that includes visual perception that needs information available from proximal stimulus produced by the distal stimulus. Theoretical Synthesis also claims that bottom-up processing occurs "when a stimulus is presented long and clearly enough."
Cognitively speaking, certain cognitive processes, such as fast reactions or quick visual identification, are considered bottom-up processes because they rely primarily on sensory information, whereas processes such as motor control and directed attention are considered top-down because they are goal directed. Neurologically speaking, some areas of the brain, such as area V1 mostly have bottom-up connections. Other areas, such as the fusiform gyrus have inputs from higher brain areas and are considered to have top-down influence.
The study of visual attention provides an example. If your attention is drawn to a flower in a field, it may be because the color or shape of the flower are visually salient. The information that caused you to attend to the flower came to you in a bottom-up fashion—your attention was not contingent upon knowledge of the flower; the outside stimulus was sufficient on its own. Contrast this situation with one in which you are looking for a flower. You have a representation of what you are looking for. When you see the object you are looking for, it is salient. This is an example of the use of top-down information.
In cognitive terms, two thinking approaches are distinguished. "Top-down" (or "big chunk") is stereotypically the visionary, or the person who sees the larger picture and overview. Such people focus on the big picture and from that derive the details to support it. "Bottom-up" (or "small chunk") cognition is akin to focusing on the detail primarily, rather than the landscape. The expression "seeing the wood for the trees" references the two styles of cognition.
Management and organization.
In the fields of management and organization, the terms "top-down" and "bottom-up" are used to describe how decisions are made and/or how change is implemented. 
A ""top-down"" approach is where an executive decision maker or other top person makes the decisions of how something should be done. This approach is disseminated under their authority to lower levels in the hierarchy, who are, to a greater or lesser extent, bound by them. For example, when wanting to make an improvement in a hospital, a hospital administrator might decide that a major change (such as implementing a new program) is needed, and then the leader uses a planned approach to drive the changes down to the frontline staff (Stewart, Manges, Ward, 2015). 
A ""bottom-up"" approach to changes one that works from the grassroots—from a large number of people working together, causing a decision to arise from their joint involvement. A decision by a number of activists, students, or victims of some incident to take action is a "bottom-up" decision. A bottom-up approach can be though of as "an incremental change approach that represents an emergent process cultivated and upheld primarily by frontline workers" (Stewart, Manges, Ward, 2015, p. 241). 
Positive aspects of top-down approaches include their efficiency and superb overview of higher levels. Also, external effects can be internalized. On the negative side, if reforms are perceived to be imposed ‘from above’, it can be difficult for lower levels to accept them (e.g. Bresser Pereira, Maravall, and Przeworski 1993). Evidence suggests this to be true regardless of the content of reforms (e.g. Dubois 2002). A bottom-up approach allows for more experimentation and a better feeling for what is needed at the bottom. Other evidence suggests that there is a third combination approach to change (see Stewart, Manges, Ward, 2015). 
State organization.
Both approaches can be found in the organization of states, this involving political decisions.
In bottom-up organized organizations, e.g. ministries and their subordinate entities, decisions are prepared by experts in their fields, which define, out of their expertise, the policy they deem necessary. If they cannot agree, even on a compromise, they "escalate" the problem to the next higher hierarchy level, where a decision would be sought. Finally, the highest common principal might have to take the decision. Information is in the debt of the inferior to the superior, which means that the inferior owes information to the superior. In the effect, as soon as inferiors agree, the head of the organization only provides his or her “face″ for the decision which their inferiors have agreed upon.
Among several countries, the German political system provides one of the purest forms of a bottom-up approach. The German Federal Act on the Public Service provides that any inferior has to consult and support any superiors, that he or she – only – has to follow “general guidelines" of the superiors, and that he or she would have to be fully responsible for any own act in office, and would have to follow a specific, formal complaint procedure if in doubt of the legality of an order. Frequently, German politicians had to leave office on the allegation that they took wrong decisions because of their resistance to inferior experts' opinions (this commonly being called to be “beratungsresistent", or resistant to consultation, in German). The historical foundation of this approach lies with the fact that, in the 19th century, many politicians used to be noblemen without appropriate education, who more and more became forced to rely on consultation of educated experts, which (in particular after the Prussian reforms of Stein and Hardenberg) enjoyed the status of financially and personally independent, indismissable, and neutral experts as "Beamte" (public servants under public law).
The experience of two dictatorships in the country and, after the end of such regimes, emerging calls for the legal responsibility of the “aidees of the aidees" ("Helfershelfer") of such regimes also furnished calls for the principle of personal responsibility of any expert for any decision made, this leading to a strengthening of the bottom-up approach, which requires maximum responsibility of the superiors. A similar approach can be found in British police laws, where entitlements of police constables are vested in the constable in person and not in the police as an administrative agency, this leading to the single constable being fully responsible for his or her own acts in office, in particular their legality.
In the opposite, the French administration is based on a top-down approach, where regular public servants enjoy no other task than simply to execute decisions made by their superiors. As those superiors also require consultation, this consultation is provided by members of a "cabinet", which is distinctive from the regular ministry staff in terms of staff and organization. Those members who are not members of the "cabinet" are not entitled to make any suggestions or to take any decisions of political dimension.
The advantage of the bottom-up approach is the level of expertise provided, combined with the motivating experience of any member of the administration to be responsible and finally the independent “engine" of progress in that field of personal responsibility. A disadvantage is the lack of democratic control and transparency, this leading, from a democratic viewpoint, to the deferment of actual power of policy-making to faceless, if even known, public servants. Even the fact that certain politicians might “provide their face" to the actual decisions of their inferiors might not mitigate this effect, but rather strong parliamentary rights of control and influence in legislative procedures (as they do exist in the example of Germany).
The advantage of the top-down principle is that political and administrative responsibilities are clearly distinguished from each other, and that responsibility for political failures can be clearly identified with the relevant office holder. Disadvantages are that the system triggers demotivation of inferiors, who know that their ideas to innovative approaches might not be welcome just because of their position, and that the decision-makers cannot make use of the full range of expertise which their inferiors will have collected.
Administrations in "dictatorships" traditionally work according to a strict top-down approach. As civil servants below the level of the political leadership are discouraged from making suggestions, they use to suffer from the lack of expertise which could be provided by the inferiors, which regularly leads to a breakdown of the system after a few decades. Modern communist states, which the People's Republic of China forms an example of, therefore prefer to define a framework of permissible, or even encouraged, criticism and self-determination by inferiors, which would not affect the major state doctrine, but allows the use of professional and expertise-driven knowledge and the use of it for the decision-making persons in office.
Public health.
Both top-down and bottom-up approaches exist in public health. There are many examples of top-down programs, often run by governments or large inter-governmental organizations (IGOs); many of these are disease-specific or issue-specific, such as HIV control or Smallpox Eradication. Examples of bottom-up programs include many small NGOs set up to improve local access to healthcare. However, a lot of programs seek to combine both approaches; for instance, guinea worm eradication, a single-disease international program currently run by the Carter Center has involved the training of many local volunteers, boosting bottom-up capacity, as have international programs for hygiene, sanitation, and access to primary health-care.
Architecture.
Often, the École des Beaux-Arts school of design is said to have primarily promoted top-down design because it taught that an architectural design should begin with a parti, a basic plan drawing of the overall project.
By contrast, the Bauhaus focused on bottom-up design. This method manifested itself in the study of translating small-scale organizational systems to a larger, more architectural scale (as with the woodpanel carving and furniture design).
Ecology.
In ecology, top-down control refers to when a top predator controls the structure or population dynamics of the ecosystem. The classic example is of kelp forest ecosystems. In such ecosystems, sea otters are a keystone predator. They prey on urchins which in turn eat kelp. When otters are removed, urchin populations grow and reduce the kelp forest creating urchin barrens. In other words, such ecosystems are not controlled by productivity of the kelp but rather a top predator.
Bottom up control in ecosystems refers to ecosystems in which the nutrient supply and productivity and type of primary producers (plants and phytoplankton) control the ecosystem structure. An example would be how plankton populations are controlled by the availability of nutrients. Plankton populations tend to be higher and more complex in areas where upwelling brings nutrients to the surface.
There are many different examples of these concepts. It is common for populations to be influenced by both types of control.

</doc>
<doc id="45636" url="https://en.wikipedia.org/wiki?curid=45636" title="Borland Turbo C">
Borland Turbo C

Turbo C is a discontinued Integrated Development Environment and compiler for the C programming language from Borland. First introduced in 1987, it was noted for its integrated development environment, small size, fast compile speed, comprehensive manuals and low price.
In May 1990, Borland replaced Turbo C with Turbo C++. In 2006, Borland reintroduced the Turbo moniker.
Early history.
In the early 1980s, Borland enjoyed considerable success with their Turbo Pascal product and it became a popular choice when developing applications for the PC. Borland followed up that success by releasing Turbo Basic, Turbo Prolog and Turbo C. Turbo C had the same properties as Turbo Pascal: an integrated development environment, a fast compiler (though not near the speed of Turbo Pascal), a good editor, and a competitive price.
Turbo C was not as successful as the Pascal-sister product. First, C was a language for professional programming and systems development rather than a school language. Turbo C competed with other professional programming tools (Microsoft C, Lattice C, Watcom C, etc.). Turbo C did, however, have advantages in speed of compiled code, large project support and price. It is developed in C.
Version history.
Version 1.0 (May 13, 1987) offered the first integrated development environment for C on IBM PCs. Like many Borland products of the time, the software was bought from another company (in this case Wizard C by Bob Jervis), and branded with the "Turbo" name. It ran in of memory. It allowed inline assembly with full access to C symbolic names and structures, supported all memory models, and offered optimizations for speed, size, constant folding, and jump elimination.
Version 1.5 (January 1988) was an incremental improvement over version 1.0. It included more sample programs, improved manuals and bug fixes. It was shipped on five 360 KB diskettes of uncompressed files, and came with sample C programs, including a stripped down spreadsheet called mcalc. This version introduced the <conio.h> header file (which provided fast, PC-specific console I/O routines).
Version 2.0 (late 1988) featured the first "blue screen" version, which would be typical of all future Borland releases for MS-DOS. The American release did not have Turbo Assembler or a separate debugger. (These were sold separately as Turbo Assembler.) Turbo C, Asm, and Debugger were sold together as a suite. This seems to describe another release: Featured Turbo Debugger, Turbo Assembler, and an extensive graphics library. This version of Turbo C was also released (in Germany only) for the Atari ST; the program was not maintained by Borland, but sold and renamed PureC.
With the release of Turbo C++ 1.0 (in 1990), the two products were folded into one and the name "Turbo C" was discontinued. The C++ compiler was developed under contract by a company in San Diego, and was one of the first "true" compilers for C++ (until then, it was common to use pre-compilers that generated C code, ref. Cfront).
Freeware release.
In 2006, Borland's successor, Embarcadero Technologies, re-released Turbo C and the MS-DOS versions of the Turbo C++ compilers as freeware.

</doc>
<doc id="45638" url="https://en.wikipedia.org/wiki?curid=45638" title="Undocumented feature">
Undocumented feature

Undocumented features are frequently found in software releases. Sometimes the documentation is omitted through simple oversight, but undocumented features are often elements of the software not intended for use by end users, but left available for use by the vendor for software support and development.
Since the suppliers of the software usually consider the software documentation to constitute a contract for the behavior of the software, undocumented features are generally left unsupported, and may be removed or changed at will and without notice to the users. 
Sometimes such a feature (for example, the ability to change the switch character in MS-DOS, usually to a hyphen) is included for compatibility (in this case with Unix utilities) or future-expansion reasons, but if the software provider changes their mind or goes out of business, the absence of documentation makes it easier to justify the feature's removal.
New versions of software might omit mention of old (possibly superseded) features in documentation but keep them implemented for users who've grown accustomed to them.
In other cases, software bugs are referred to jokingly as undocumented features. (""It's not a bug; it's an undocumented feature!"") This usage may have been popularised in some of Microsoft's responses to bug reports for its first Word for Windows product, but doesn't originate there. The oldest surviving reference on Usenet dates to 5 March 1984. Between 1969 and 1972, Sandy Mathes, a systems programmer for PDP-8 software at Digital Equipment Corporation (DEC) in Maynard, MA, used the terms "bug" and "feature" in her reporting of test results to distinguish between undocumented actions of delivered software products that were "unacceptable" and "tolerable", respectively. This usage may have been perpetuated.
Ironically, undocumented features themselves have become a major feature of computer games. Developers often include various cheats and other special features ("easter eggs") that are not explained in the packaged material, but have become part of the "buzz" about the game on the Internet and among gamers. The undocumented features of foreign games are often elements that were not localized from their native language.
Closed source APIs can also have undocumented functions that are not generally known. These are sometimes used to gain a commercial advantage over third-party software by providing additional information or better performance to the application provider.

</doc>
<doc id="45639" url="https://en.wikipedia.org/wiki?curid=45639" title="Bal Gangadhar Tilak">
Bal Gangadhar Tilak

Tilak was one of the first and strongest advocates of "Swaraj" (self-rule) and a strong radical in Indian consciousness. He is known for his quote in Marathi, "स्वराज्य हा माझा जन्मसिद्ध हक्क आहे आणि तो मी मिळवणारच" ("Swarajya is my birthright and I shall have it!") in India. He formed a close alliance with many Indian National Congress leaders including Bipin Chandra Pal, Lala Lajpat Rai, Aurobindo Ghose, V. O. Chidambaram Pillai and Muhammad Ali Jinnah. As a strong advocate of Swaraj, he was against Gandhi's policy of Total-ahimsa (non-violence), satyagraha and advocated the use of force where necessary.
Early life.
Tilak was born in a Marathi Chitpavan Brahmin family in Ratnagiri, headquarters of the eponymous district of present-day Maharashtra (then British India) on 23 July 1856. His ancestral village was Chikhali. His father, Gangadhar Tilak was a school teacher and a Sanskrit scholar who died when Tilak was sixteen. Tilak graduated from Deccan College, Pune in 1877. Tilak was amongst one of the first generation of Indians to receive a college education. In 1871 Tilak was married to Tapibai (a women belonging to Bal family) when he was sixteen before few months of his father's death. After marriage, her name was changed to Satyabhamabai. He obtained his matriculation in 1872. He obtained his Bachelor of Arts in first class in Mathematics from Deccan College of Pune in 1877. In 1879 he obtained his LL.B degree from Government Law College . He had left M.A. midway to join the L.L.B course instead.
After graduating, Tilak started teaching mathematics at a private school in Pune. Later due to ideological differences with the colleagues in the new school, he withdrew and became a journalist later. Tilak actively participated in public affairs. He stated:
""Religion and practical life are not different. To take Sanyasa (renunciation) is not to abandon life. The real spirit is to make the country your family work together instead of working only for your own. The step beyond is to serve humanity and the next step is to serve God.""
He organised the Deccan Education Society with a few of his college friends, including Gopal Ganesh Agarkar, Mahadev Ballal Namjoshi and Vishnushastri Chiplunkar. Their goal was to improve the quality of education for India's youth. The Deccan Education Society was set up to create a new system that taught young Indians nationalist ideas through an emphasis on Indian culture. The Society established the New English School for secondary education and Fergusson College in 1885 for post-secondary studies. Tilak taught mathematics at Fergusson College. He began a mass movement towards independence by an emphasis on a religious and cultural revival.
Political career.
Tilak had a long political career agitating for Indian autonomy from the British rule. Before Gandhi, he was the most widely known Indian political leader. Unlike his fellow Maharashtrian contemporary, Gokhale, Tilak was considered a radical leader and was imprisoned on a number of occasions that included a long stint at Mandalay. At one stage in his political life he was called "the father of Indian unrest" by the British authorities. Towards the end of his life, Tilak became more moderate and campaigned for Indian Home rule with leaders like Jinnah and Annie Beasant.
Indian National Congress.
Tilak joined the Indian National Congress in 1890. He opposed its moderate attitude, especially towards the fight for self-government. He was one of the most-eminent radicals at the time.
Despite being personally opposed to early marriage, Tilak was against the 1891 Age of Consent bill, seeing it as interference with Hinduism and a dangerous precedent. The act raised the age at which a girl could get married from 10 to 12 years.
During late 1896, a Bubonic plague spread from Bombay to Pune, and by January 1897, it reached epidemic proportions. British troops were brought in to deal with the emergency and harsh measures were employed including forced entry into private houses, examination of occupants, evacuation to hospitals and segregation camps, removing and destroying personal possessions, and preventing patients from entering or leaving the city. By the end of May, the epidemic was under control. Though the British authorities' measures were well-meant, they were widely regarded as acts of tyranny and oppression. Tilak took up this issue by publishing inflammatory articles in his paper "Kesari" ("Kesari" was written in Marathi, and "Mahratta" was written in English), quoting the Hindu scripture, the Bhagavad Gita, to say that no blame could be attached to anyone who killed an oppressor without any thought of reward. Following this, on 22 June 1897, Commissioner Rand and another British officer, Lt. Ayerst were shot and killed by the Chapekar brothers and their other associates. According to Barbara and Thomas R. Metcalf, Tilak "almost surely concealed the identities of the perpetrators". Tilak was charged with incitement to murder and sentenced to 18 months imprisonment. When he emerged from prison in present-day Mumbai, he was revered as a martyr and a national hero. He adopted a new slogan coined by his associate Kaka Baptista, "Swaraj (self-rule) is my birthright and I shall have it."
Following the Partition of Bengal, which was a strategy set out by Lord Curzon to weaken the nationalist movement, Tilak encouraged the Swadeshi movement and the Boycott movement.
The movement consisted of the boycott of foreign goods and also the social boycott of any Indian who used foreign goods. The Swadeshi movement consisted of the usage of natively produced goods. Once foreign goods were boycotted, there was a gap which had to be filled by the production of those goods in India itself. Tilak said that the Swadeshi and Boycott movements are two sides of the same coin.
Tilak opposed the moderate views of Gopal Krishna Gokhale, and was supported by fellow Indian nationalists Bipin Chandra Pal in Bengal and Lala Lajpat Rai in Punjab. They were referred to as the "Lal-Bal-Pal triumvirate". In 1907, the annual session of the Congress Party was held at Surat, Gujarat. Trouble broke out over the selection of the new president of the Congress between the moderate and the radical sections of the party . The party split into the radicals faction, led by Tilak, Pal and Lajpat Rai, and the moderate faction. Nationalists like Aurobindo Ghose, V. O. Chidambaram Pillai were Tilak supporters..
Sedition Charges.
During his life time among other political cases, Bala Gangadhar Tilak had been tried for Sedition Charges in three times by British India Government. Firstly in 1897, Secondly in 1909 
Thirdly in 1916 
Imprisonment in Mandalay.
On 30 April 1908, two Bengali youths, Prafulla Chaki and Khudiram Bose, threw a bomb on a carriage at Muzzafarpur, to kill the Chief Presidency Magistrate Douglas Kingsford of Calcutta fame, but erroneously killed two women travelling in it. While Chaki committed suicide when caught, Bose was hanged. Tilak, in his paper "Kesari", defended the revolutionaries and called for immediate Swaraj or self-rule. The Government swiftly arrested him for sedition. But a special jury convicted him, and the judge Dinshaw D. Davar gave him the controversial sentence of six years' transportation and a fine of Rs 1,000. The jury by a majority of 7:2 convicted him. On being asked by the judge whether he had anything to say, Tilak said: All that I wish to say is that, in spite of the verdict of the jury, I still maintain that I am innocent. There are higher powers that rule the destinies of men and nations; and I think, it may be the will of Providence that the cause I represent may be benefited more by my suffering than by my pen and tongue.
In passing sentence, the judge indulged in some scathing strictures against Tilak's conduct. He threw off the judicial restraint which, to some extent, was observable in his charge to the jury. He condemned the articles as "seething with sedition", as preaching violence, speaking of murders with approval. "You hail the advent of the bomb in India as if something had come to India for its good. I say, such journalism is a curse to the country".
Tilak was sent to Mandalay, Burma from 1908 to 1914. While imprisoned, he continued to read and write, further developing his ideas on the Indian nationalist movement. While in the prison he wrote the "Gita Rahasya". Many copies of which were sold, and the money was donated for the Indian Independence movement..
Life after Mandalay.
Tilak developed diabetes during his sentence in Mandalay prison. This and the general ordeal of prison life had mellowed him at his release on 16 June 1914. When World War I started in August of that year, Tilak cabled the King-Emperor George V of his support and turned his oratory to find new recruits for war efforts. He welcomed The Indian Councils Act, popularly known as Minto-Morley Reforms, which had been passed by British Parliament in May 1909, terming it as "a marked increase of confidence between the Rulers and the Ruled". It was his conviction that acts of violence actually diminished, rather than hastening, the pace of political reforms. He was eager for reconciliation with Congress and had abandoned his demand for direct action and settled for agitations "strictly by constitutional means" – a line advocated by his rival Gokhale.
Tilak tried to convince Mohandas Gandhi to leave the idea of Total non-violence ("Total Ahimsa") and try to get Selfrule ("Swarajya") by all means. Gandhi, though he respected Tilak as his "guru", did not change his mind.
All India Home Rule League.
Later, Tilak re-united with his fellow nationalists and re-joined the Indian National Congress in 1916. He also helped found the All India Home Rule League in 1916–18, with G. S. Khaparde and Muhammad Ali Jinnah and Annie Besant. After years of trying to reunite the moderate and radical factions, he gave up and focused on the Home Rule League, which sought self-rule. Tilak travelled from village to village for support from farmers and locals to join the movement towards self-rule. Tilak was impressed by the Russian Revolution, and expressed his admiration for Vladimir Lenin. There were total of 1400 members in April 1916 and in 1917 there were approximately of about 32,000 members in the league. Tilak started his Home Rule League in Maharashtra, Central Provinces, and Karnataka and Berar region. Besant's League was active in the rest part of India.
Tilak, who started his political life as a Maratha propagandist, progressed into a prominent nationalist after his close association with Indian nationalists following the partition of Bengal. When asked in Calcutta whether he envisioned a Maratha-type of government for independent India, Tilak replied that the Maratha-dominated governments of 17th and 18th centuries were outmoded in the 20th century, and he wanted a genuine federal system for Free India where every religion and race was an equal partner. He added that only such a form of government would be able to safeguard India's freedom. He was the first Congress leader to suggest that Hindi written in the Devanagari script be accepted as the sole national language of India.
Social contributions and legacy.
Tilak started two weeklies, "Kesari" ("The Lion") in Marathi and "Mahratta" in English in 1880–81 with Gopal Ganesh Agarkar as the first editor. By this he was recognized as 'awakener of India'. As Kesari later became a daily and continues publication to this day.
In 1894, Tilak transformed the household worshipping of Ganesha into a grand public event (Sarvajanik Ganeshotsav). The celebrations consisted of several days of processions, music and food. They were organized by the means of subscriptions by neighbourhood, caste, or occupation. Students often would celebrate Hindu and national glory and address political issues; including patronage of "Swadeshi" goods.
In 1895, Tilak founded the Shri Shivaji Fund Committee for celebration of "Shiv Jayanti", the birth anniversary of Chhatrapati Shivaji, the founder of the Maratha Empire. The project also had the objective of funding the reconstruction of the tomb (Samadhi) of Shivaji at Raigad Fort. For this second objective, Tilak established the Shri Shivaji Raigad Smarak Mandal along with Senapati Khanderao Dabhade II of Talegaon Dabhade, who became the founder President of the Mandal.
The events like the Ganapati festival and Shiv Jayanti were used by Tilak to build a national spirit beyond the circle of educated elite in opposition to colonial rule. But it also exacerbated Hindu-Muslim differences. The festival organizers would urge Hindus to protect cows and boycott the Muharram celebrations organized by Shi'a Muslims, in which Hindus had formerly often participated. Thus, although the celebrations were meant to be a way to oppose colonial rule, they also contributed to religious tensions. Contemporary Marathi Hindu nationalist parties like the Shivsena took up his reverence for Shivaji.
The Deccan Education Society that Tilak founded with others in the 1880s still runs Institutions in Pune like the Fergusson College.
The Swadeshi movement started by Tilak at the beginning of the 20th century became part of the Independence movement until that goal was achieved in 1947. One can even say Swadeshi remained part of Indian Government policy until the 1990s when the Congress Government liberalised the economy.
Tilak Smarak Ranga Mandir, a theatre auditorium in Pune is dedicated to him. In 2007, the Government of India released a coin to commemorate the 150th birth anniversary of Tilak.
Tilak said, "I regard India as my Motherland and my Goddess, the people in India are my kith and kin, and loyal and steadfast work for their political and social emancipation is my highest religion and duty".
Swami Vivekananda reached Pune by train during September 1892. Tilak happened to be his fellow passenger. Vivekananda stayed in his house "Vinchurkar Wada" in Pune.

</doc>
<doc id="45641" url="https://en.wikipedia.org/wiki?curid=45641" title="UPS">
UPS

UPS may refer to:

</doc>
<doc id="45642" url="https://en.wikipedia.org/wiki?curid=45642" title="Demography">
Demography

Demography (from prefix "demo-" from Ancient Greek δῆμος "dēmos", meaning "the people", and "-graphy" from γράφω "graphō", implies "writing, description or measurement") is the statistical study of populations, especially human beings. As a very general science, it can analyze any kind of dynamic living population, i.e., one that changes over time or space (see population dynamics). Demography encompasses the study of the size, structure, and distribution of these populations, and spatial or temporal changes in them in response to birth, migration, ageing, and death. Based on the demographic research of the earth, earth's population up to the year 2050 and 2100 can be estimated by demographers. Demographics are quantifiable characteristics of a given population.
Demographic analysis can cover whole societies, or groups defined by criteria such as education, nationality, religion and ethnicity. Educational institutions usually treat demography as a field of sociology, though there are a number of independent demography departments.
Formal demography limits its object of study to the measurement of population processes, while the broader field of social demography or population studies also analyzes the relationships between economic, social, cultural and biological processes influencing a population.
History.
Demographic thoughts can be traced back to antiquity, and are present in many civilisations and cultures, like Ancient Greece, Ancient Rome, India and China. In ancient Greece, this can be found in the writings of Herodotus, Thucidides, Hippocrates, Epicurus, Protagoras, Polus, Plato and Aristotle. In Rome, writers and philosophers like Cicero, Seneca, Pliny the elder, Marcus Aurelius, Epictetus, Cato, and Collumella also expressed important ideas on this ground.
In the Middle ages, Christian thinkers devoted much time in refuting the Classical ideas on demography. Important contributors to the field were William of Conches, Bartholomew of Lucca, William of Auvergne, William of Pagula, and Ibn Khaldun.
One of the earliest demographic studies in the modern period was "Natural and Political Observations Made upon the Bills of Mortality" (1662) by John Graunt, which contains a primitive form of life table. Among the study's findings were that one third of the children in London died before their sixteenth birthday. Mathematicians, such as Edmond Halley, developed the life table as the basis for life insurance mathematics. Richard Price was credited with the first textbook on life contingencies published in 1771, followed later by Augustus de Morgan, ‘On the Application of Probabilities to Life Contingencies’ (1838).
At the end of the 18th century, Thomas Malthus concluded that, if unchecked, populations would be subject to exponential growth. He feared that population growth would tend to outstrip growth in food production, leading to ever-increasing famine and poverty (see Malthusian catastrophe). He is seen as the intellectual father of ideas of overpopulation and the limits to growth. Later, more sophisticated and realistic models were presented by Benjamin Gompertz and Verhulst.
The period 1860-1910 can be characterized as a period of transition wherein demography emerged from statistics as a separate field of interest. This period included a panoply of international ‘great demographers’ like Adolphe Quételet (1796–1874), William Farr (1807–1883), Louis-Adolphe Bertillon (1821–1883) and his son Jacques (1851–1922), Joseph Körösi (1844–1906), Anders Nicolas Kaier (1838–1919), Richard Böckh (1824–1907), Émile Durkheim (1858-1917), Wilhelm Lexis (1837–1914) and Luigi Bodio (1840–1920) contributed to the development of demography and to the toolkit of methods and techniques of demographic analysis.
Methods.
There are two types of data collection—direct and indirect—with several different methods of each type.
Direct methods.
Direct data comes from vital statistics registries that track all births and deaths as well as certain changes in legal status such as marriage, divorce, and migration (registration of place of residence). In developed countries with good registration systems (such as the United States and much of Europe), registry statistics are the best method for estimating the number of births and deaths.
A census is the other common direct method of collecting demographic data. A census is usually conducted by a national government and attempts to enumerate every person in a country. However, in contrast to vital statistics data, which are typically collected continuously and summarized on an annual basis, censuses typically occur only every 10 years or so, and thus are not usually the best source of data on births and deaths. Analyses are conducted after a census to estimate how much over or undercounting took place. These compare the sex ratios from the census data to those estimated from natural values and mortality data.
Censuses do more than just count people. They typically collect information about families or households in addition to individual characteristics such as age, sex, marital status, literacy/education, employment status, and occupation, and geographical location. They may also collect data on migration (or place of birth or of previous residence), language, religion, nationality (or ethnicity or race), and citizenship. In countries in which the vital registration system may be incomplete, the censuses are also used as a direct source of information about fertility and mortality; for example the censuses of the People's Republic of China gather information on births and deaths that occurred in the 18 months immediately preceding the census.
Indirect methods.
Indirect methods of collecting data are required in countries and periods where full data are not available, such as is the case in much of the developing world, and most of historical demography. One of these techniques in contemporary demography is the sister method, where survey researchers ask women how many of their sisters have died or had children and at what age. With these surveys, researchers can then indirectly estimate birth or death rates for the entire population. Other indirect methods in contemporary demography include asking people about siblings, parents, and children. Other indirect methods are necessary in historical demography.
There are a variety of demographic methods for modeling population processes. They include models of mortality (including the life table, Gompertz models, hazards models, Cox proportional hazards models, multiple decrement life tables, Brass relational logits), fertility (Hernes model, Coale-Trussell models, parity progression ratios), marriage (Singulate Mean at Marriage, Page model), disability (Sullivan's method, multistate life tables), population projections (Lee Carter, the Leslie Matrix), and population momentum (Keyfitz).
The United Kingdom has a series of four national birth cohort studies, the first three spaced apart by 12 years: the 1946 National Survey of Health and Development, the 1958 National Child Development Study, the 1970 British Cohort Study, and the Millennium Cohort Study, begun much more recently in 2000. These have followed the lives of samples of people (typically beginning with around 17,000 in each study) for many years, and are still continuing. As the samples have been drawn in a nationally representative way, inferences can be drawn from these studies about the differences between four distinct generations of British people in terms of their health, education, attitudes, childbearing and employment patterns.
Common Rates and Ratios.
A stable population does not necessarily remain fixed in size. It can be expanding or shrinking.
Note that the crude death rate as defined above and applied to a whole population can give a misleading impression. For example, the number of deaths per 1,000 people can be higher for developed nations than in less-developed countries, despite standards of health being better in developed countries. This is because developed countries have proportionally more older people, who are more likely to die in a given year, so that the overall mortality rate can be higher even if the mortality rate at any given age is lower. A more complete picture of mortality is given by a life table which summarises mortality separately at each age. A life table is necessary to give a good estimate of life expectancy.
Basic equation.
Suppose that a country (or other entity) contains "Populationt" persons at time "t".
What is the size of the population at time "t" + 1 ?
Natural increase from time "t" to "t" + 1:
Net migration from time "t" to "t" + 1:
This basic equation can also be applied to subpopulations. For example, the population size of ethnic groups or nationalities within a given society or country is subject to the same sources of change. However, when dealing with ethnic groups, "net migration" might have to be subdivided into physical migration and ethnic reidentification (assimilation). Individuals who change their ethnic self-labels or whose ethnic classification in government statistics changes over time may be thought of as migrating or moving from one population subcategory to another.
More generally, while the basic demographic equation holds true by definition, in practice the recording and counting of events (births, deaths, immigration, emigration) and the enumeration of the total population size are subject to error. So allowance needs to be made for error in the underlying statistics when any accounting of population size or change is made.
The figure in this section shows the latest (2004) UN projections of world population out to the year 2150 (red = high, orange = medium, green = low). The UN "medium" projection shows world population reaching an approximate equilibrium at 9 billion by 2075. Working independently, demographers at the International Institute for Applied Systems Analysis in Austria expect world population to peak at 9 billion by 2070. Throughout the 21st century, the average age of the population is likely to continue to rise.
Science of population.
Populations can change through three processes: fertility, mortality, and migration. Fertility involves the number of children that women have and is to be contrasted with fecundity (a woman's childbearing potential). Mortality is the study of the causes, consequences, and measurement of processes affecting death to members of the population. Demographers most commonly study mortality using the Life Table, a statistical device which provides information about the mortality conditions (most notably the life expectancy) in the population.
Migration refers to the movement of persons from a locality of origin to a destination place across some pre-defined, political boundary. Migration researchers do not designate movements 'migrations' unless they are somewhat permanent. Thus demographers do not consider tourists and travelers to be migrating. While demographers who study migration typically do so through census data on place of residence, indirect sources of data including tax forms and labor force surveys are also important.
Demography is today widely taught in many universities across the world, attracting students with initial training in social sciences, statistics or health studies. Being at the crossroads of several disciplines such as sociology, economics, epidemiology, geography, anthropology and history, demography offers tools to approach a large range of population issues by combining a more technical quantitative approach that represents the core of the discipline with many other methods borrowed from social or other sciences. Demographic research is conducted in universities, in research institutes as well as in statistical departments and in several international agencies. Population institutions are part of the Cicred (International Committee for Coordination of Demographic Research) network while most individual scientists engaged in demographic research are members of the International Union for the Scientific Study of Population, or a national association such as the Population Association of America in the United States, or affiliates of the Federation of Canadian Demographers in Canada.
See also.
Social surveys:
Organizations:
Scientific journals:

</doc>
<doc id="45645" url="https://en.wikipedia.org/wiki?curid=45645" title="Krishna Chandra Bhattacharya">
Krishna Chandra Bhattacharya

Krishna Chandra Bhattacharya (12 May 1875 – 11 December 1949) was a philosopher at the University of Calcutta who studied one of the central questions of Hindu philosophy, which is how mind, life or consciousness creates an apparently material universe.
Early life.
Krishna Chandra Bhattacharya was born on 12 May 1875 at Serampore in a Brahmin family of Sanskrit scholars. Krishnachandra took his school education in a local school.After passing matriculation examination in 1891 he went to the Presidency College, then affiliated with the University of Calcutta.

</doc>
<doc id="45648" url="https://en.wikipedia.org/wiki?curid=45648" title="Nightjar">
Nightjar

Nightjars are medium-sized nocturnal or crepuscular birds in the family Caprimulgidae, characterized by long wings, short legs and very short bills. They are sometimes called goatsuckers, due to the ancient folk tale that they sucked the milk from goats (the Latin for goatsucker is "Caprimulgus"). Some New World species are called nighthawks. Nightjars usually nest on the ground.
The English word 'nightjar' originally referred to the European nightjar.
Nightjars are found around the world. They are mostly active in the late evening and early morning or at night, and feed predominantly on moths and other large flying insects. 
Most have small feet, of little use for walking, and long pointed wings. Their soft plumage is cryptically coloured to resemble bark or leaves. Some species, unusual for birds, perch along a branch, rather than across it. This helps to conceal them during the day. Bracken is their preferred habitat.
The common poorwill, "Phalaenoptilus nuttallii" is unique as a bird that undergoes a form of hibernation, becoming torpid and with a much reduced body temperature for weeks or months, although other nightjars can enter a state of torpor for shorter periods.
Nightjars lay one or two patterned eggs directly onto bare ground. It has been suggested that nightjars will move their eggs and chicks from the nesting site in the event of danger by carrying them in their mouths. This suggestion has been repeated many times in ornithology books, but while this may accidentally happen, surveys of nightjar research have found very little evidence to support this idea.
Conservation challenge.
Working out conservation strategies for some species of nightjar presents a particular challenge common to other hard-to-see families of birds; in a few cases, humans do not have enough data on whether a bird is rare or not. This has nothing to do with any lack of effort. It reflects, rather, the difficulty in locating and identifying a small number of those species of birds among the 10,000 or so that exist in the world, given the limitations of human beings. A perfect example is the Vaurie's nightjar in China's south-western Xinjiang. It has been seen for certain only once, in 1929, a specimen that was held in the hand. Surveys in the 1970s and 1990s failed to find it. It is perfectly possible that it has evolved as a species that can really be identified in the wild only by other Vaurie's nightjars, rather than by humans. As a result, scientists do not know whether it is extinct, endangered, or even locally common.
Systematics.
Traditionally, nightjars have been divided into two subfamilies: the Caprimulginae, or typical nightjars with about 80 species, and the Chordeilinae, or nighthawks of the New World with about 19 species. The two groups are similar in most respects, but the typical nightjars have rictal bristles, longer bills, and softer plumage. In their pioneering DNA-DNA hybridisation work, Sibley and Ahlquist found that the genetic difference between the eared-nightjars and the typical nightjars was, in fact, greater than that between the typical nightjars and the nighthawks of the New World. Accordingly, they placed the eared-nightjars in a separate family: Eurostopodidae. 
Subsequent work, both morphological and genetic, has provided support for the separation of the typical and the eared-nightjars, and some authorities have adopted this Sibley-Ahlquist recommendation, and also the more far-reaching one to group all the owls (traditionally Strigiformes) together in the Caprimulgiformes. The listing below retains a more orthodox arrangement, but recognises the eared-nightjars as a separate group. For more detail and an alternative classification scheme, see Caprimulgiformes and Sibley-Ahlquist taxonomy.
Subfamily Chordeilinae (nighthawks) 
Subfamily Caprimulginae — (typical nightjars) 
Also see a list of nightjars, sortable by common and binomial names.

</doc>
<doc id="45651" url="https://en.wikipedia.org/wiki?curid=45651" title="Sarvepalli Radhakrishnan">
Sarvepalli Radhakrishnan

Sarvepalli Radhakrishnan (5 September 1888 – 17 April 1975) was an Indian philosopher and statesman who was the first Vice President of India (1952–1962) and the second President of India from 1962 to 1967.
One of India's most distinguished twentieth-century scholars of comparative religion and philosophy, his academic appointments included the King George V Chair of Mental and Moral Science at the University of Calcutta (1921–1932) and Spalding Professor of Eastern Religion and Ethics at University of Oxford (1936–1952).
His philosophy was grounded in Advaita Vedanta, reinterpreting this tradition for a contemporary understanding. He defended Hinduism against "uninformed Western criticism", contributing to the formation of contemporary Hindu identity. He has been influential in shaping the understanding of Hinduism, in both India and the west, and earned a reputation as a bridge-builder between India and the West.
Radhakrishnan was awarded several high awards during his life, including a knighthood in 1931, the Bharat Ratna, the highest civilian award in India, in 1954, and honorary membership of the British Royal Order of Merit in 1963. Radhakrishnan believed that "teachers should be the best minds in the country". Since 1962, his birthday is celebrated in India as Teachers' Day on 5 September.
Biography.
Early life.
Sarvepalli Radhakrishnan was born in a Telugu Brahmin family in a village near Thiruttani India, in the erstwhile Madras Presidency near the border of Andhra Pradesh and Tamil Nadu states. His father's name was Sarvepalli Veeraswami and his mother's was Sitamma. His early years were spent in Thiruttani and Tirupati. His father was a subordinate revenue official in the service of a local zamindar (landlord). His primary education was at K.V High School at Thiruttani. In 1896 he moved to the Hermansburg Evangelical Lutheran Mission School in Tirupati.
Education.
Radhakrishnan was awarded scholarships throughout his academic life. He joined Voorhees College in Vellore but switched to the Madras Christian College at the age of 17. He graduated from there in 1906 with a master's degree in Philosophy, being one of its most distinguished alumni.
Radhakrishnan studied philosophy by chance rather than choice. Being a financially constrained student, when a cousin who graduated from the same college passed on his philosophy textbooks in to Radhakrishnan, it automatically decided his academic course.
Radhakrishnan wrote his thesis for the M.A. degree on "The Ethics of the Vedanta and its Metaphysical Presuppositions". It "was intended to be a reply to the charge that the Vedanta system had no room for ethics." He was afraid that this M.A. thesis would offend his philosophy professor, Dr. Alfred George Hogg. Instead, Hogg commended Radhakrishnan on having done most excellent work. Radhakrishnan's thesis was published when he was only twenty. According to Radhakrishnan himself, the criticism of Hogg and other Christian teachers of Indian culture "disturbed my faith and shook the traditional props on which I leaned." Radhakrishnan himself describes how, as a student,
This led him to his critical study of Indian philosophy and religion and a lifelong defence of Hinduism against "uninformed Western criticism".
Marriage and family.
I was married to Sivakamu, a distant cousin, at the age of 16. As per tradition the marriage was arranged by the family. The couple had five daughters and a son, Sarvepalli Gopal. Sarvepalli Gopal went on to a notable career as a historian. Sivakamu died in 1956. They were married for over 51 years.
Former Indian Test Cricketer VVS Laxman is his great grand nephew.
Academic career.
In April 1909, Sarvepalli Radhakrishnan was appointed to the Department of Philosophy at the Madras Presidency College. Thereafter, in 1918, he was selected as Professor of Philosophy by the University of Mysore, where he taught at its Maharaja's College, Mysore. By that time he had written many articles for journals of repute like "The Quest", "Journal of Philosophy" and the "International Journal of Ethics". He also completed his first book, "The Philosophy of Rabindranath Tagore". He believed Tagore's philosophy to be the "genuine manifestation of the Indian spirit". His second book, "The Reign of Religion in Contemporary Philosophy" was published in 1920.
In 1921 he was appointed as a professor in philosophy to occupy the King George V Chair of Mental and Moral Science at the University of Calcutta. He represented the University of Calcutta at the Congress of the Universities of the British Empire in June 1926 and the International Congress of Philosophy at Harvard University in September 1926. Another important academic event during this period was the invitation to deliver the Hibbert Lecture on the ideals of life which he delivered at Harris Manchester College, Oxford in 1929 and which was subsequently published in book form as "An Idealist View of Life".
In 1929 Radhakrishnan was invited to take the post vacated by Principal J. Estlin Carpenter at Harris Manchester College. This gave him the opportunity to lecture to the students of the University of Oxford on Comparative Religion. For his services to education he was knighted by George V in the June 1931 Birthday Honours, and formally invested with his honour by the Governor-General of India, the Earl of Willingdon, in April 1932. However, he ceased to use the title after Indian independence, preferring instead his academic title of 'Doctor'.
He was the Vice-Chancellor of Andhra University from 1931 to 1936. In 1936 Radhakrishnan was named Spalding Professor of Eastern Religions and Ethics at the University of Oxford, and was elected a Fellow of All Souls College. That same year, and again in 1937, he was nominated for the Nobel Prize in Literature (although this nomination process, for all laureates, was not public at the time. Further nominations for the award would continue steadily into the 1960s.) In 1939 Pt. Madan Mohan Malaviya invited him to succeed him as the Vice-Chancellor of Banaras Hindu University (BHU). He served as its Vice-Chancellor till January 1948.
Political career.
Radhakrishnan started his political career "rather late in life", after his successful academic career. His international authority preceded his political career. In 1931 he was nominated to the "League of Nations Committee for International Cooperation", where after "in Western eyes he was the recognized Hindu authority on Indian ideas and a persuasive interpreter of the role of Eastern institutions in contemporary society." When India became independent in 1947, Radhakrishnan represented India at UNESCO (1946–52) and was later Ambassador of India to the Soviet Union, from 1949 to 1952. He was also elected to the Constituent Assembly of India. Radhakrishnan was elected as the first Vice-President of India in 1952, and elected as the second President of India (1962–1967).
Radhakrishnan did not have a background in the Congress Party, nor was he active in the struggle against British rule. His motivation lay in his pride of Hindu culture, and the defence of Hinduism against "uninformed Western criticism". According to Brown,
Teachers' Day.
When he became the President of India, some of his students and friends requested him to allow them to celebrate his birthday, 5 September. He replied, "Instead of celebrating my birthday, it would be my proud privilege if 5 September is observed as Teachers' Day." His birthday has since been celebrated as Teachers' Day in India.
Charity.
Along with Ghanshyam Das Birla and some other social workers in the pre-independence era, Radhakrishnan formed the Krishnarpan Charity Trust.
Philosophy.
Radhakrishnan tried to bridge eastern and western thought, defending Hinduism against "uninformed Western criticism", but also incorporating Western philosophical and religious thought.
Advaita Vedanta.
Radhakrishnan was one of the most prominent spokesmen of Neo-Vedanta. His metaphysics was grounded in Advaita Vedanta, but he reinterpreted Advaita Vedanta for a contemporary understanding. He acknowledged the reality and diversity of the world of experience, which he saw as grounded in and supported by the absolute or Brahman. Radhakrishnan also reinterpreted Shankara's notion of "maya". According to Radhakrishnan, maya is not a strict absolute idealism, but "a subjective misperception of the world as ultimately real."
Intuition and religious experience.
"Intuition", or "anubhava", synonymously called "religious experience", has a central place in Radhakrishnan's philosophy as a source of knowledge which is not mediated by conscious thought. His specific interest in experience can be traced back to the works of William James (1842–1910), Francis Herbert Bradley (1846–1924), Henri Bergson (1859–1941), and Friedrich von Hügel (1852–1925), and to Vivekananda, who had a strong influence on Radhakrisnan's thought. According to Radhakrishnan, intuition is of a self-certifying character ("svatassiddha"), self-evidencing ("svāsaṃvedya"), and self-luminous ("svayam-prakāsa"). In his book "An Idealist View of Life", he made a powerful case for the importance of intuitive thinking as opposed to purely intellectual forms of thought.
According to Radhakrishnan, "intuition" plays a specific role in all kinds of experience. Radhakrishnan discernes five sorts of experience:
Classification of religions.
For Radhakrishnan, theology and creeds are intellectual formulations, and symbols of religious experience or "religious intuitions". Radhakrishnan qualified the variety of religions hierarchically according to their apprehension of "religious experience", giving Advaita Vedanta the highest place:
Radhakrishnan saw Hinduism as a scientific religion based on facts, apprehended via intuition or religious experience. According to Radhakrishnan, "f philosophy of religion is to become scientific, it must become empirical and found itself on religious experience". He saw this empiricism exemplified in the Vedas:
To Radhakrishnan, Advaita Vedanta was the best representative of Hinduism, as being grounded in intuition, in contrast to the "intellectually mediated interpretations" of other religions. He objected against charges of "quietism" and "world denial", instead stressing the need and ethic of social service, giving a modern interpretation of classical terms as "tat-tvam-asi". According to Radhakrishnan, Vedanta offers the most direct intuitive experience and inner realisation, which makes it the highest form of religion:
Radhakrishnan saw other religions, "including what Radhakrishnan understands as lower forms of Hinduism," as interpretations of Advaita Vedanta, thereby Hindusizing all religions.
Although Radhakrishnan was well-acquainted with western culture and philosophy, he was also critical of them. He stated that Western philosophers, despite all claims to objectivity, were influenced by theological influences of their own culture.
Influence.
Radhakrishnan was one of India's best and most influential twentieth-century scholars of comparative religion and philosophy,
Radhakrishnan's defence of the Hindu traditions has been highly influential, both in India and the western world. In India, Radhakrishnan's ideas contributed to the formation of India as a nation-state. Radhakrishnan's writings contributed to the hegemonic status of Vedanta as "the essential worldview of Hinduism". In the western world, Radhakrishnan's interpretations of the Hindu tradition, and his emphasis on "spiritual experience", made Hinduism more readily accessible for a western audience, and contributed to the influence Hinduism has on modern spirituality:
Appraisal.
Radhakrishnan has been highly appraised. According to Paul Artur Schillp:
And according to Hawley:
Criticism and context.
Radhakrishnan's ideas have also received criticism and challenges, for their perennialist and universalist claims, and the use of an East-West dichotomy.
Perennialism.
According to Radhakrishnan, there is not only an underlying "divine unity" from the seers of the Upanishads up to modern Hindus like Tagore and Gandhi, but also "an essential commonality between philosophical and religious traditions from widely disparate cultures." This is also a major theme in the works of Rene Guenon, the Theosophical Society, and the contemporary popularity of eastern religions in modern spirituality. Since the 1970s, the Perennialist position has been criticised for its essentialism. Social-constructionists give an alternative approach to religious experience, in which such "experiences" are seen as being determined and mediated by cultural determants: As Michaels notes:
Rinehart also points out that "perennialist claims notwithstanding, modern Hindu thought is a product of history", which "has been worked out and expressed in a variety of historical contexts over the preceding two hundreds years." This is also true for Radhakrishan, who was educated by missionaries and, like other neo-Vedantins used the prevalent western understanding of India and its culture to present an alternative to the western critique.
Universalism, communalism and Hindu nationalism.
According to Richard King, the elevation of Vedanta as the essence of Hinduism, and Advaita Vedanta as the "paradigmatic example of the mystical nature of the Hindu religion" by colonial Indologists but also neo-Vedantins served well for the Hindu nationalists, who further popularised this notion of Advaita Vedanta as the pinnacle of Indian religions. It
This "opportunity" has been criticised. According to Sucheta Mazumdar and Vasant Kaiwar,
Rinehart also criticises the inclusivism of Radhakrishnan's approach, since it provides "a theological scheme for subsuming religious difference under the aegis of Vedantic truth." According to Rinehart, the consequence of this line of reasoning is communalism, the idea that "all people belonging to one religion have common economic, social and political interests and these interests are contrary to the interests of those belonging to another religion." Rinehart notes that Hindu religiosity plays an important role in the nationalist movement, and that "the neo-Hindu discource is the unintended consequence of the initial moves made by thinkers like Rammohan Roy and Vivekananda." Yet Rinehart also points out that it is
Post-colonialism.
Colonialism left deep traces in the hearts and minds of the Indian people, influencing the way they understood and represented themselves. The influences of "colonialist forms of knowledge" can also be found in the works of Radhakrishnan. According to Hawley, Radhakirshnan's division between East and West, the East being spiritual and mystical, and the West being rational and dogmatical,
Since the 1990s, the colonial influences on the 'construction' and 'representation' of Hinduism have been the topic of debate among scholars of Hinduism Western Indologists are trying to come to more neutral and better-informed representations of India and its culture, while Indian scholars are trying to establish forms of knowledge and understanding which are grounded in and informed by Indian traditions, instead of being dominated by western forms of knowledge and understanding.
Bibliography.
Biographies and monographs on Radhakrishnan.
Several books have been published on Sarvepalli Radhakrishnan:

</doc>
<doc id="45652" url="https://en.wikipedia.org/wiki?curid=45652" title="Ram Mohan Roy">
Ram Mohan Roy

Raja Ram Mohan Roy, also known as Rammohan Roy or Rammohun Roy, (22 May 1772 – 27 September, 1833) was the founder of the "Brahmo Sabha" movement in 1828, which engendered the Brahmo Samaj, an influential Bengali socio-religious reform movement against Brahminsm. His influence was apparent in the fields of politics, public administration and education as well as religion. He is best known for his efforts to establish the abolishment of the practice of sati, the Hindu funeral practice in which the widow was compelled to sacrifice herself in her husband’s funeral pyre in some parts of Bengal. What is not so well known is that Roy protested against the East India Company's decision to support vernacular education and insisted that English replace Sanskrit and Persian in India. It was he who first introduced the word "Hinduism" into the English language in 1816. For his diverse activities and contributions to society, Raja Ram Mohan Roy is regarded as one of the most important and contentious figures in the Bengali renaissance. His efforts to protect Hinduism and Indian rights and his closeness with the British government earned him the title "The Father of the Indian Renaissance". The British government has named a street in memory of Ram Mohan Roy as "Raja Rammohan Way".
Early life and education (1772–1796).
Ram Mohan Roy was born in Radhanagar, Arambagh subdivision, Hooghly District, Bengal Presidency, in 1772, into the Rarhi Brahmin caste. His family background displayed religious diversity — his father Ramkanta was a Vaishnavite, while his mother Tarinidevi was from a Shivaite family. This was unusual, for Vaishanavites commonly did not marry Shaivites at the time.
Ram Mohan Roy was married three times, which fell in the strict framework of his polygamous and caste customs. His first wife died early in his childhood. He conceived two sons, Radhaprasad in 1800 and Ramaprasad in 1812 with his second wife, who died in 1824. Roy's third wife outlived him.
Ram Mohan Roy's early education was controversial. The common version is "Ram Mohan started his formal education in the village "pathshala" where he learned Bengali and some Sanskrit and Persian. Later he is said to have studied Persian and Arabic in a "madrasa" in Patna and after that he was sent to Benares (Kashi) for learning the intricacies of Sanskrit and Hindu scripture, including the Vedas and Upanishads. The dates of his sojourn in both these places is uncertain. However, the commonly held belief is that he was sent to Patna when he was nine years old and two years later to Benares."
Impact.
Ram Mohan Roy's impact on modern Indian history was a revival of the pure and ethical principles of the Vedanta school of philosophy as found in the Upanishads. He preached the unity of God, made early translations of Vedic scriptures into English, co-founded the Calcutta Unitarian Society and founded the Brahma Samaj. The Brahma Samaj played a major role in reforming and modernising the Indian society. He successfully campaigned against sati, the practice of burning widows. He sought to integrate Western culture with the best features of his own country's traditions. He established a number of schools to popularize a modern system (effectively replacing Sanskrit based education with English based education) of education in India. He promoted a rational, ethical, non-authoritarian, this-worldly, and social-reform Hinduism. His writings also sparked interest among British and American Unitarians.
Christianity and the early rule of the East India Company (1795–1828).
During these overlapping periods, Ram Mohan Roy acted as a political agitator and agent, representing Christian missionaries whilst employed by the East India Company and simultaneously pursuing his vocation as a Pandit. To understand fully this complex period in his life leading up to his eventual Brahmoism needs reference to his peers.
In 1792 the British Baptist shoemaker William Carey published his influential missionary tract, "An Enquiry of the obligations of Christians to use means for the conversion of heathens".
In 1793 William Carey landed in India to settle. His objective was to translate, publish and distribute the Bible in Indian languages and propagate Christianity to the Indian peoples. He realized the "mobile" (i.e. service classes) Brahmins and Pundits were most able to help him in this endeavor, and he began gathering them. He learnt the Buddhist and Jain religious works to better argue the case for Christianity in the cultural context.
In 1795 Carey made contact with a Sanskrit scholar, the Tantric Hariharananda Vidyabagish, who later introduced him to Ram Mohan Roy, who wished to learn English.
Between 1796 and 1797 the trio of Carey, Vidyavagish and Roy fabricated a spurious religious work known as the "Maha Nirvana Tantra" (or "Book of the Great Liberation") and passed it off as an ancient religious text to "the One True God", actually the Holy Spirit of Christianity masquerading as Brahma. Carey's involvement is not recorded in his very detailed records and he reports only learning to read Sanskrit in 1796 and only completed a grammar in 1797, the same year he translated part of The Bible from Joshua to Job, a massive task. (The explanation later given by Ram Mohan Roy to his family concerning his whereabouts during this period is that he went to "Tibet", then as far away as "Timbuktoo"). For the next two decades this document was regularly augmented. Its judicial sections were used in the law courts of the English Settlement in Bengal as Hindu Law for adjudicating upon property disputes of the zamindari. However, a few British magistrates and collectors began to suspect it as a forgery and its usage (as well as the reliance on pundits as sources of Hindu Law) was quickly deprecated. Vidyavagish had a brief falling out with Carey and separated from the group, but maintained ties to Ram Mohan Roy. (The Maha Nirvana Tantra's significance for Brahmoism lay in the wealth that accumulated to Ram Mohan Roy and Dwarkanath Tagore by its judicial use, and not due to any religious wisdom within, although it does contain an entire chapter devoted to "the One True God" and his worship.)
In 1797, Ram Mohan reached Calcutta and became a "banian" (moneylender), mainly to impoverished Englishmen of the Company living beyond their means. Ram Mohan also continued his vocation as pundit in the English courts and started to make a living for himself. He began learning Greek and Latin.
In 1799, Carey was joined by missionary Joshua Marshman and the printer William Ward at the Danish settlement of Serampore.
From 1803 till 1815, Ram Mohan served the East India Company's "Writing Service", commencing as private clerk "munshi" to Thomas Woodroffe, Registrar of the Appellate Court at Murshidabad (whose distant nephew, John Woodroffe — also a Magistrate — and later made a rich living off the spurious Maha Nirvana Tantra under the pseudonym Arthur Avalon). Roy resigned from Woodroffe's service due to allegations of corruption. Later he secured employment with John Digby, a Company collector, and Ram Mohan spent many years at Rangpur and elsewhere with Digby, where he renewed his contacts with Hariharananda. William Carey had by this time settled at Serampore and the old trio renewed their profitable association. William Carey was also aligned now with the English Company, then headquartered at Fort William, and his religious and political ambitions were increasingly intertwined.
The East India Company was draining money from India at a rate of three million pounds a year in 1838. Ram Mohan Roy was one of the first to try to estimate how much money was being driven out of India and to where it was disappearing. He estimated that around one-half of all total revenue collected in India was sent out to England, leaving India, with a considerably larger population, to use the remaining money to maintain social wellbeing. Ram Mohan Roy saw this and believed that the unrestricted settlement of Europeans in India governing under free trade would help ease the economic drain crisis.
At the turn of the 19th century the Muslims, although considerably vanquished after the battles of Plassey and Buxar, still posed a formidable political threat to the Company. Ram Mohan was now chosen by Carey to be the agitator among them.
Under Carey's secret tutelage in the next two decades, Ram Mohan launched his attack against the bastions of Hinduism of Bengal, namely his own Kulin Brahmin priestly clan (then in control of the many temples of Bengal) and their priestly excesses. The social and theological issues Carey chose for Ram Mohan were calculated to weaken the hold of the dominant Kulin class (especially their younger disinherited sons forced into service who constituted the mobile gentry or "bhadralok" of Bengal) from the Mughal zamindari system and align them to their new overlords of Company. The Kulin excesses targeted include sati (the concremation of widows), polygamy, idolatory, child marriage and dowry. All causes were equally dear to Carey's ideals.
Roy's contemporary biographer records:
Middle "Brahmo" period (1820–1830).
This was Ram Mohan's most controversial period. Commenting on his published works Sivanath Sastri writes:-
"The period between 1820 and 1830 was also eventful from a literary point of view, as will be manifest from the following list of his publications during that period
Life in England (1831–1833).
He publicly declared that he would emigrate from British empire if parliament failed to pass the Reform Bill.
In 1830 Ram Mohan Roy travelled to the United Kingdom as an ambassador of the Mughal Empire to ensure that the Lord Bentick's regulation banning the practice of Sati was not overturned. He also visited France.
He died at Stapleton, then a village to the north east of Bristol (now a suburb), on the 27th September 1833 of meningitis and was buried in Arnos Vale Cemetery in southern Bristol.
Religious reforms.
The religious reforms of Roy contained in some beliefs of the Brahmo Samaj expounded by Rajnarayan Basu are:-
Social reforms.
Roy’s political background fit influenced his social and religious to reforms of Hinduism. He writes,
"The present system of Hindus is not well calculated to promote their political interests…. It is necessary that some change should take place in their religion, at least for the sake of their political advantage and social comfort."
Ram Mohan Roy’s experience working with the British government taught him that Hindu traditions were often not credible or respected by western standards and this no doubt affected his religious reforms. He wanted to legitimize Hindu traditions to his European acquaintances by proving that "superstitious practices which deform the Hindu religion have nothing to do with the pure spirit of its dictates!" The "superstitious practices" Ram Mohan Roy objected included sati, caste rigidity, polygamy and child marriages. These practices were often the reasons British officials claimed moral superiority over the Indian nation. Ram Mohan Roy’s ideas of religion actively sought to create a fair and just society by implementing humanitarian practices similar to Christian ideals and thus legitimize Hinduism in the modern world.
Mausoleum at Arnos Vale.
Ram Mohan Roy was originally buried on 18 October 1833, in the grounds of Stapleton Grove where he had died of meningitis on 27 September 1833. Nine and a half years later he was reburied on 29 May 1843 in a grave at the new Arnos Vale Cemetery, in Brislington, East Bristol. A large plot on The Ceremonial Way there, had been bought by William Carr and William Prinsep, and the body in its lac and lead coffin was placed later in a deep brick-built vault, over seven feet underground. Two years after this Dwarkanath Tagore helped pay for the chattri raised above this vault, although there is no record of his ever visiting Bristol. The chattri was designed by the artist William Prinsep, who had known Ram Mohan in Calcutta. The Raja's remains are still there, despite a misleading story first suggested by the Adi Brahmo Samaj Press, and unfortunately repeated later by one (or more) historians, without proper evidence or citation. The coffin has been seen in situ by the Trustee in charge of the 2006/7 repairs to the chattri, which were funded by Aditya Poddar of Singapore.
The original brief epitaph,"Rammohun Roy, died Stapleton 27th. Sept. 1833", was suggested by Dwarkanath Tagore, but this plaque was removed to the rear of the tomb by Rev. Rohini Chaterji (sic), who was descended from Radha Prasad Roy. His new and more expansive epitaph was placed at the front. The epitaph reads:
The Indian High Commission often come to the annual Commemoration of the Raja in September, whilst Bristol's Lord Mayor is always in attendance. The Commemoration is a joint Brahmo-Unitarian service for about 100 people. Brahmo and Unitarian prayers and hymns are sung before the tomb, flowers are laid, and the life of the Raja celebrated in a service. In 2013 a recently discovered ivory bust of Ram Mohan was displayed, in 2014 his original death mask at Edinburgh was filmed and its history discussed.
In September 2008 representatives from the Indian High Commission came to Bristol to mark the 175th anniversary of Ram Mohan Roy's death. During the ceremony Brahmo and Unitarian prayers were recited and songs of Ram Mohan and other Brahmosangeet were performed.
Following on from this visit the Mayor of Kolkata, Bikash Ranjan Bhattacharya (who was amongst the representatives from the India High Commission) decided to raise funds to restore the mausoleum.
Bristol honours Ram Mohan Roy.
In 1983 a full scale Exhibition on Ram Mohan Roy was held in Bristol's Museum and Art Gallery. His enormous 1831 portrait by Henry Perronet Briggs still hangs there, and was the subject of a talk by Sir Max Muller in 1873. At Bristol's Centre, on College Green, is a full size bronze statue of the Raja by the modern Kolkata sculptor, Niranjan Pradhan. Another bust by Pradhan, gifted to Bristol by Joyti Basu, sits inside the main foyer of Bristol's City Hall. A pedestrian path at Stapleton has been named "Rajah Rammohun Walk". There is a 1933 Brahmo plaque on the outside west wall of Stapleton Grove, and his first burial place in the garden is marked by railings and a granite memorial stone. His tomb and chattri at Arnos Vale are listed Grade II* by English Heritage, and attract many admiring visitors today.

</doc>
<doc id="45654" url="https://en.wikipedia.org/wiki?curid=45654" title="Dayananda Saraswati">
Dayananda Saraswati

Dayanand Saraswati born (12 February 1824 – 30 October 1883) was a Hindu religious leader who founded the Arya Samaj, a Hindu reform movement of the Vedic tradition. He was a profound scholar of the Vedic lore and Sanskrit language. He was the first to give the call for "Swarajya" as "India for Indians" – in 1876, later taken up by Lokmanya Tilak. Denouncing the idolatry and ritualistic worship prevalent in Hinduism at the time, he worked towards reviving Vedic ideologies. Subsequently the philosopher and President of India, S. Radhakrishnan, called him one of the "makers of Modern India," as did Sri Aurobindo.
Those who were influenced by and followed Dayananda included Madam Cama, Pandit Lekh Ram, Swami Shradhanand, Pandit Guru Dutt Vidyarthi, Shyam Krishan Verma (who established India House in England for Freedom fighters) Vinayak Damodar Savarkar, Lala Hardayal, Madan Lal Dhingra, Ram Prasad Bismil, Mahadev Govind Ranade Swami Shraddhanand, Mahatma Hansraj, Lala Lajpat Rai and others. One of his most influential works is the book "Satyarth Prakash", which contributed to the Indian independence movement. He was a sanyasi (ascetic) from boyhood, and a scholar, who believed in the infallible authority of the Vedas.
Maharshi Dayananda advocated the doctrine of Karma (Karmasiddhanta in Hinduism) and Reincarnation (Punarjanma in Hinduism). He emphasized the Vedic ideals of brahmacharya (celibacy) and devotion to God. The Theosophical Society and the Arya Samaj were united from 1878 to 1882, becoming the Theosophical Society of the Arya Samaj. Among Maharshi Dayananda's contributions are his promoting of the equal rights for women, such as the right to education and reading of Indian scriptures, and his intuitive commentary on the Vedas from Vedic Sanskrit in Sanskrit as well as Hindi so that the common man might be able to read them. Dayanand was the first to give the word of Swadeshi and Harijan to the dalits and Pariahs (Outcastes) long before Mahatma Gandhi.
Early life.
Dayananda Saraswati was born on 12 February in 1824 in a Hindu family in Tankara, near Morbi in the Kathiawad region (now Rajkot district of Gujarat). His original name was Mool Shankar because he was born in Dhanu Rashi and Mool Nakshatra. His birthday is celebrated in Falguna Krishna Dashami tithi (the 10th day of waning moon in the month of Purnimanta Falguna). He belonged to Mool Nakshatra and his birth tithi was Purnimanta Falguna Krishna Dashami then his birth date should be Tuesday, 24 February 1824 according to astrological calculations. His father's name was Karshanji Lalji Tiwari and mother's name was Yashodabai. A tax collector, his father was a rich, prosperous and influential person. He was the head of an eminent Hindu family of the village. When Mool Shankar was eight years old, Yajnopavita Sanskara, or the investiture with thread of the "twice-born" were performed. His father was a follower of Shiva and taught Dayananda Saraswati the ways to impress the Lord. Dayananda was also told the importance of keeping fasts. On the occasion of Shivratri, Dayananda had to sit awake the whole night in obedience to Lord Shiva. One such night, he saw a mouse eating the offerings to the God and running over the idol's body. After seeing this, he questioned himself, if the God could not defend himself against a little mouse then how could he be the savior of the massive world.
Since he was born under Mula Nakshatra, he was named "Moolshankar", and led a comfortable early life, studying Sanskrit, the Vedas and other religious texts to prepare himself for a future as a teacher.
The deaths of his younger sister and his uncle from cholera caused Dayananda to ponder the meaning of life and death and he started asking questions which worried his parents. He was to be married in his early teens, as was common in nineteenth-century India, but he decided marriage was not for him and in 1846 ran away from home.
Dayananda Saraswati spent nearly twenty-five years, from 1845 to 1869, as a wandering ascetic, searching for religious truth. An ascetic is someone who gives up material goods and lives a life of self-denial, devoted to spiritual matters. He lived in jungles, in retreats in the Himalayan Mountains, and at a number of pilgrimage sites in northern India. During these years Dayananda Sarasvati practiced various forms of yoga. He became a disciple, or follower, of a well-known religious teacher, Virajanand Dandeesha (sometimes spelled Birajananda). Virajanand believed that Hinduism had strayed from its historical roots and that many of its practices had become impure. Dayananda Sarasvati promised Virajanand that he would devote his life to restoring the rightful place of the Vedas in the Hindu faith.
Dayanand's mission.
Dayanand's mission was not to start or set up any new religion but to ask humankind for Universal Brotherhood through nobility as spelt out in Vedas. For that mission he founded Arya Samaj enunciating the Ten Universal Principles as a code for Universalism "Krinvanto Vishwaryam" meaning the whole world be an abode for Nobles (Aryas). His next step was to take up the difficult task of reforming Hinduism with dedication despite multiple repeated attempts on his personal life. He traveled the country challenging religious scholars and priests to discussions and won repeatedly on the strength of his arguments based on his knowledge of Sanskrit and Vedas. He believed that Hinduism had been corrupted by divergence from the founding principles of the Vedas and that Hindus had been misled by the priesthood for the priests' self-aggrandizement. Hindu priests discouraged the laity from reading Vedic scriptures and encouraged rituals, such as bathing in the Ganges River and feeding of priests on anniversaries, which Dayananda pronounced as superstitions or self-serving practices. By exhorting the nation to reject such superstitious notions, his aim was to educate the nation to "Go back to the Vedas". He wanted the people who followed Hinduism to go back to its roots and to follow the Vedic life, which he pointed out. He exhorted the Hindu nation to accept social reforms, including the importance of Cows for national prosperity as well as the adoption of Hindi as the national language for national integration. Through his daily life and practice of yoga and asanas, teachings, preaching, sermons and writings, he inspired the Hindu nation to aspire to "Swarajya" (self governance), nationalism, and spiritualism. He advocated the equal rights and respects to women and advocated the education of a girl child like the males.
Swami Dayanand did logical, scientific and critical analyses of faiths i.e. Christianity & Islam as well as of other Indian faiths like Jainism, Buddhism and Sikhism. In addition to discouraging idolatry in Hinduism, as may be seen in his book "Satyarth Prakash". He was against what he considered to be the corruption of the true and pure faith in his own country. Unlike many other reform movements of his times within Hinduism, the Arya Samaj's appeal was addressed not only to the educated few in India, but to the world as a whole as evidenced in the sixth principle of the Arya Samaj. In fact his teachings professed universalism for the all living beings and not for any particular sect, faith, community or nation.
Arya Samaj allows and encourages converts to Hinduism. Dayananda’s concept of dharma is stated in the "Beliefs and Disbeliefs" section of "Satyartha Prakash". He said:
Dayananda's Vedic message was to emphasize respect and reverence for other human beings, supported by the Vedic notion of the divine nature of the individual–divine because the body was the temple where the human essence (soul or "atma") had the possibility to interface with the creator ("Paramatma"). In the ten principles of the Arya Samaj, he enshrined the idea that "All actions should be performed with the prime objective of benefiting mankind", as opposed to following dogmatic rituals or revering idols and symbols. The first five principles speak of Truth and the other five of a society with nobility, civics, co-living and disciplined life. In his own life, he interpreted moksha to be a lower calling (due to its benefit to one individual) than the calling to emancipate others.
Dayananda's "back to the Vedas" message influenced many thinkers and philosophers the world over.
Activities.
Dayanand is noted to have been active since he was 14, by this time he was able to recite religious verses and teach about them. He is highly applauded for taking parts in religious debates. His debates were attended by relatively high amount of public.
One of the remarkable debate occurred on 22 October 1869 in Varanasi, where he had won a debate against 27 scholars and about 12 expert pandits. The debate was attended by over 50,000 people. The main topic was "Do the Vedas uphold deity worship?"
Arya Samaj.
Swami Dayananda's creations, the Arya Samaj, unequivocally condemns practices of different religions and communities that are noted to be prevalent, such as idol worship, animal sacrifice, pilgrimages, priest craft, offerings made in temples, the castes, child marriages, meat eating and discrimination against women on the grounds that all these lacked Hinduism of that time.
The Arya Samaj discourages dogma and symbolism and encourages skepticism in beliefs that run contrary to common sense and logic.
Views on Superstitions.
He severely criticized the practice of superstitions like sorcery, astrology which are prevalent in India.
here are some quotes from his famous book Sathyarth Prakash,
On Astrology, he wrote,
He makes a clear distinction between jyotisha shaastra and astrology and calls astrology as fraud.
Views on Other Religions.
Dayanand Saraswati is noted to have thoroughly studied about religions other than Hinduism, such as Islam, Buddhism, Jainism, Christianity, Sikhism, and others. He has described these religions in the chapters of his book Satyarth Prakash. However his analysis seemed critical to some, in its nature, while to some he presented perfect understanding.
Islam.
He viewed Islam to be waging wars and immorality. He doubted if Islam has to do anything with the God, as he questioned that why a God would be hating every non-believer, allowing slaughter of animals, non-merciful and command Muhammad to slaughter innocent people, animals.
He further described Muhammad as "imposter", and one who held out "a bait to men and women, in the name of God, to compass his own selfish needs." He regarded Quran as "Not the Word of God. It is a human work. Hence it cannot be believed in."
Christianity.
He described Christianity as a "good religion". His analysis of Bible is based on the comparison with scientific evidences, morality, and other properties. He included that Bible contains many stories and precepts that are immoral, praising cruelty, deceit and encouraging sin.
He opposed the perpetual virginity of Mary, he added that such doctrines are simply against the nature of law, and that God will never break his own law because God is Omniscient and infallible.
Regarding Jesus, he wrote:
All Christian missionaries say that Jesus was a very calm and peace loving person. But in reality he was a hot-tempered persons destitute of knowledge and who behaved like a wild savage. This shows that Jesus was neither the son of God, nor had he any miraculous powers. He did not possess the power to forgive sins. The righteous people do not stand in need of any mediator like Jesus. Jesus came to spread discord which is going on everywhere in the world. Therefore, it is evident that the hoax of Christ’s being the Son of God, the knower of the past and the future, the forgiver of sin, has been set up falsely by his disciples. In reality, he was a very ordinary ignorant man, neither learned nor a yogi.
He asserted that Jesus wasn't an enlightened man either. Dayanand further states that if Jesus was a son of God, God would have saved him at the time of his death, and he wouldn't have suffered from mental severe physical pain at last moments.
He noted that Bible writes that women held the feet of Jesus and worshiped him, he questions:
Was it the same body which had been buried? Now that body had been buried for three days, we should like to know why did it not decompose?
Sikhism.
He regarded Guru Nanak as "not much literate", who was quite ignorant about the Vedas, Sanskrit, the Shashtras- otherwise, according to Swami Dayanand Saraswati, Guru Nanak wouldn't be mistaken with words. A Sikh wrote a response, to which Dayanand Saraswati answered that his opinion had undergone a change after having visited the Punjab, and the remarks about Sikhism would be deleted in the subsequent edition of his work. However, these remarks were never removed after the untimely death of Dayanand Saraswati, and later editions of Satyarth Prakash were even more critical of Sikhism.
He further pointed that followers of Sikhism are to be blamed for making up stories that Guru Nanak possessed miraculous powers and met Gods. He slammed Guru Gobind Singh, and other Gurus to have been "invented fictitious stories", although he also recognized Guru Gobind Singh to be "indeed a very brave man."
Jainism.
He regarded Jainism as "a most dreadful religion", he writes that Jains were intolerant and hostile towards the non-Jains.
Buddhism.
Dayanand described Buddhism as "anti-vedic" and "atheistic." He noted that the type of "salvation" Buddhism prescribes to, is attainable even to dogs and donkeys. He further criticized the Cosmogony of Buddhism, that earth was not created.
Assassination attempts.
Dayananda was subjected to many unsuccessful attempts on his life.
According to his supporters, he was poisoned on few occasions, but due to his regular practice of Hatha Yoga he would succeed to throw out the poison. One story tells that he was once attacked by some proponents of Islam, and tried to drown him to river. Although Dayanand would drag these attackers into river instead and release when they would be near to fully drowned.
Death.
In 1883,Dayananda was invited by the Maharaja of Jodhpur to stay at his palace. The Maharaja was eager to become his disciple and learn his teachings. One day Dayananda went to the Maharaja's rest room and saw him with a dance-girl named Nanhi Jaan. Dayananda boldly asked the Maharaja to forsake the girl and all unethical acts and follow dharma like a true Aryan. Dayananda's suggestion offended the dance-girl and she decided to take revenge. She bribed Dayananda's cook and asked him to mix pieces of glasses in his milk and give it to Dayanand. On 29 September 1883 while he still was the royal guest of Jaswant Singh II, the cook brought him a glass of milk containing pieces of glasses at bedtime. Dayananda drank the milk and went to sleep and as he drank the milk he knew that it had been mixed with glasses. He immediately realized that his nerves and veins were cut. Dayananda was bedridden and suffered excruciating pain. Maharaja quickly arranged doctor's services for him. However, by the time doctors arrived, his condition got worse and had bleeding sores. On seeing Dayananda's suffering the cook overcame with unbearable guilt and remorse. He confessed his crime to Dayananda. On his deathbed, Dayananda forgave him and gave him a bag of money and told him to flee the kingdom lest he be found out and executed by the Maharaja's men.
Later Maharaja arranged for Swamiji to be sent to Mount Abu upon advice of Residency, however, after staying some time in Abu, Swamji was sent to Ajmer for better medical care on 26 October 1883. There was no improvement in his health and he died on the morning of 30 October 1883 at 6:00 am, chanting mantras. The day coincided with Hindu festival of Diwali.
Legacy.
Notable for influencing the freedom movement of India, his views and writings have been used by different writers. Shyamji Krishna Varma, who founded India House in London and guided other revolutionaries was influenced by him. Others who were influenced by him included Subhas Chandra Bose, Lala Lajpat Rai, Madam Cama, Vinayak Damodar Savarkar, Lala Hardayal, Madan Lal Dhingra, Ram Prasad Bismil, Mahadev Govind Ranade, Swami Shraddhanand, S. Satyamurti, Pandit Lekh Ram, Mahatma Hansraj, Rajiv Dixit and others.
He had notable influence on Bhagat Singh. Singh, after finishing his primary schools, he had joined the Dayanand Anglo Vedic Middle school, of Mohan Lal road, in Lahore.
Sarvapalli Radhakrishnan, on Shivratri day, on 24 February 1964, said about him:-
Industrialist Nanji Kalidas Mehta built the Maharshi Dayanand Science College and donated it to the Education Society of Porbandar and named it after Swami Dayanand Saraswati, to keep people alive of memory of great saint of India.
It has been noted, that he had branches across the country within his period. The places Dayanand had visited in his life were remarked to have been culturally changed. Jodhpur had adopted Hindi as main language, and later the present day Rajasthan adopted the as same.
Other admirers included Swami Vivekananda, Ramakrishna, Bipin Chandra Pal, Vallabhbhai Patel, Syama Prasad Mookerjee, Romain Rolland, regarded him as one of the remarkable and unique figure.
American Spiritualist Andrew Jackson Davis described Dayanand's influence on him, he called Dayanand a "Son of God", and applauded him for restoring the status of the Nation.
Sten Konow, a Swedish scholar noted that Dayanand Saraswati revived the historicity of India, and discovered the very less known about the Indian society.
Others who were notably influenced by him, includes Ninian Smart, Benjamin Walker among others.
Works.
Dayananda Saraswati wrote more than 60 works in all, including a 16 volume explanation of the six Vedangas, an incomplete commentary on the Ashtadhyayi (Panini's grammar), several small tracts on ethics and morality, Vedic rituals and sacraments and on analysis of rival doctrines (such as Advaita Vedanta, Islam and Christianity). Some of his major works are Satyarth Prakash, Sanskarvidhi, RigvedadiBhashyaBhumika, Rigved Bhashyam (up to 7/61/2)and Yajurved Bhashyam. The Paropakarini Sabha located in the Indian city of Ajmer was founded by the Swami himself to publish and preach his works and Vedic texts.

</doc>
<doc id="45660" url="https://en.wikipedia.org/wiki?curid=45660" title="Swami Vivekananda">
Swami Vivekananda

Swami Vivekananda , "Shāmi Bibekānondo"; 12 January 1863 – 4 July 1902), born Narendranath Datta (), was an Indian Hindu monk, a chief disciple of the 19th-century Indian mystic Ramakrishna. He was a key figure in the introduction of the Indian philosophies of Vedanta and Yoga to the Western world and is credited with raising interfaith awareness, bringing Hinduism to the status of a major world religion during the late 19th century. He was a major force in the revival of Hinduism in India, and contributed to the concept of nationalism in colonial India. Vivekananda founded the Ramakrishna Math and the Ramakrishna Mission. He is perhaps best known for his speech which began, "Sisters and brothers of America ...," in which he introduced Hinduism at the Parliament of the World's Religions in Chicago in 1893.
Born into an aristocratic Bengali family of Calcutta, Vivekananda was inclined towards spirituality. He was influenced by his Guru, Ramakrishna Deva, from whom he learnt that all living beings were an embodiment of the divine self; therefore, service to God could be rendered by service to mankind. After Ramakrishna's death, Vivekananda toured the Indian subcontinent extensively and acquired first-hand knowledge of the conditions prevailing in British India. He later travelled to the United States, representing India at the 1893 Parliament of the World Religions. Vivekananda conducted hundreds of public and private lectures and classes, disseminating tenets of Hindu philosophy in the United States, England and Europe. In India, Vivekananda is regarded as a patriotic saint and his birthday is celebrated there as National Youth Day.
Early life (1863–88).
Birth and childhood.
Vivekananda was born Narendranath Datta (shortened to Narendra or Naren) at his ancestral home at 3 Gourmohan Mukherjee Street in Calcutta, the capital of British India, on 12 January 1863 during the Makar Sankranti festival. He belonged to a traditional Bengali Kayastha family and was one of nine siblings. His father, Vishwanath Datta, was an attorney at the Calcutta High Court. Durgacharan Datta, Narendra's grandfather was a Sanskrit and Persian scholar who left his family and became a monk at age twenty-five. His mother, Bhubaneswari Devi, was a devout housewife. The progressive, rational attitude of Narendra's father and the religious temperament of his mother helped shape his thinking and personality.
Narendranath was interested spiritually from a young age, and used to meditate before the images of deities such as Shiva, Rama, Sita, and Mahavir Hanuman. He was fascinated by wandering ascetics and monks. Naren was naughty and restless as a child, and his parents often had difficulty controlling him. His mother said, "I prayed to Shiva for a son and he has sent me one of his ghosts".
Education.
In 1871, at the age of eight, Narendranath enrolled at Ishwar Chandra Vidyasagar's Metropolitan Institution, where he went to school until his family moved to Raipur in 1877. In 1879, after his family's return to Calcutta, he was the only student to receive first-division marks in the Presidency College entrance examination. He was an avid reader in a wide range of subjects, including philosophy, religion, history, social science, art and literature. He was also interested in Hindu scriptures, including the Vedas, the Upanishads, the Bhagavad Gita, the "Ramayana", the "Mahabharata" and the Puranas. Narendra was trained in Indian classical music, and regularly participated in physical exercise, sports and organised activities. Narendra studied Western logic, Western philosophy and European history at the General Assembly's Institution (now known as the Scottish Church College). In 1881 he passed the Fine Arts examination, and completed a Bachelor of Arts degree in 1884. Narendra studied the works of David Hume, Immanuel Kant, Johann Gottlieb Fichte, Baruch Spinoza, Georg W. F. Hegel, Arthur Schopenhauer, Auguste Comte, John Stuart Mill and Charles Darwin. He became fascinated with the evolutionism of Herbert Spencer and corresponded with him, translating Spencer's book "Education" (1861) into Bengali. While studying Western philosophers, he also learned Sanskrit scriptures and Bengali literature. William Hastie (principal of General Assembly's Institution) wrote, "Narendra is really a genius. I have travelled far and wide but I have never come across a lad of his talents and possibilities, even in German universities, among philosophical students' Some accounts have called Narendra a "shrutidhara" (a person with a prodigious memory)
Spiritual apprenticeship - influence of Brahmo Samaj.
In 1880 Narendra joined Keshab Chandra Sen's "Nava Vidhan", which was established by Sen after meeting Ramakrishna and reconverting from Christianity to Hinduism. Narendra became a member of a Freemasonry lodge "at some point before 1884" and of the Sadharan Brahmo Samaj in his twenties, a breakaway faction of the Brahmo Samaj led by Keshab Chandra Sen and Debendranath Tagore. From 1881 to 1884 he was also active in Sen's Band of Hope, which tried to discourage the youth from smoking and drinking.
It was in this cultic milieu that Narendra became acquainted with western esotericism. His initial beliefs were shaped by Brahmo concepts, which included belief in a formless God and the deprecation of idolatry, and a "streamlined, rationalized, monotheistic theology strongly coloured by a selective and modernistic reading of the "Upanisads" and of the Vedanta." Rammohan Roy, the founder of the Brahmo Samaj who was strongly influenced by Unitarianism, strived toward an universalistic interpretation of Hinduism. His ideas were "altered [...] considerably" by Debendranath Tagore, who had a Romantic approach to the development of these new doctrines, and questioned central Hindu beliefs like reincarnation and karma, and rejected the authority of the "Vedas". Tagore also brought this "neo-Hinduism" closer in line with western esotericism, a development which was furthered by Keshubchandra Sen. Sen was influenced by Transcendentalism, an American philosophical-religious movement stringly connected with Unitarianism, which emphasized personal religious experience over mere reasoning and theology. Sen strived to "an accessible, non-renunciatory, everyman type of spirituality," introducing "lay systems of spiritual practice" which can be regarded as proto-types of the kind of Yoga-exercises which Vivekananda populurized in the west.
The same search for direct intuition and understanding can be seen with Vivekananda. Not satisfied with his knowledge of philosophy, Narendra came to "the question which marked the real beginning of his intellectual quest for God." He asked several prominent Calcutta residents if they had come "face to face with God", but none of their answers satisfied him. At this time, Narendra met Debendranath Tagore (the leader of Brahmo Samaj) and asked if he had seen God. Instead of answering his question, Tagore said "My boy, you have the "Yogi"s eyes." According to Banhatti, it was Ramakrishna who really answered Narendra's question, by saying "Yes, I see Him as I see you, only in an infinitely intenser sense." Nevertheless, Vivekananda was more influenced by the Brahmo Samaj's and its new ideas, than by Ramakrishna. It was Sen's influence who brought Vivekananda fully into contact with western esotericism, and it was also via Sen that he met Ramakrishna.
With Ramakrishna.
In 1881 Narendra first met Ramakrishna, who became his spiritual focus after his own father had died in 1884.
Narendra's first introduction to Ramakrishna occurred in a literature class at General Assembly's Institution when he heard Professor William Hastie lecturing on William Wordsworth's poem, "The Excursion". While explaining the word "trance" in the poem, Hastie suggested that his students visit Ramakrishna of Dakshineswar to understand the true meaning of trance. This prompted some of his students (including Narendra) to visit Ramakrishna.
They probably first met personally in November 1881, though Narendra did not consider this their first meeting, and neither man mentioned this meeting later. At this time Narendra was preparing for his upcoming F. A. examination, when Ram Chandra Datta accompanied him to Surendra Nath Mitra's, house where Ramakrishna was invited to deliver a lecture. According to Paranjape, at this meeting Ramakrishna asked young Narendra to sing. Impressed by his singing talent, he asked Narendra to come to Dakshineshwar.
In late 1881 or early 1882, Narendra went to Dakshineswar with two friends and met Ramakrishna. This meeting proved to be a turning point in his life. Although he did not initially accept Ramakrishna as his teacher and rebelled against his ideas, he was attracted by his personality and began to frequently visit him at Dakshineswar. He initially saw Ramakrishna's ecstasies and visions as "mere figments of imagination" and "hallucinations". As a member of Brahmo Samaj, he opposed idol worship, polytheism and Ramakrishna's worship of Kali. He even rejected the Advaita Vedanta of "identity with the absolute" as blasphemy and madness, and often ridiculed the idea. Narendra tested Ramakrishna, who faced his arguments patiently: "Try to see the truth from all angles", he replied.
Narendra's father's sudden death in 1884 left the family bankrupt; creditors began demanding the repayment of loans, and relatives threatened to evict the family from their ancestral home. Narendra, once a son of a well-to-do family, became one of the poorest students in his college. He unsuccessfully tried to find work and questioned God's existence, but found solace in Ramakrishna and his visits to Dakshineswar increased.
One day Narendra requested Ramakrishna to pray to goddess Kali for their family's financial welfare. Ramakrishna suggested him to go to the temple himself and pray. Following Ramakrishna's suggestion, he went to the temple thrice, but failed to pray for any kind of worldly necessities and ultimately prayed for true knowledge and devotion from the goddess. Narendra gradually grew ready to renounce everything for the sake of realising God, and accepted Ramakrishna as his Guru.
In 1885, Ramakrishna developed throat cancer, and was transferred to Calcutta and (later) to a garden house in Cossipore. Narendra and Ramakrishna's other disciples took care of him during his last days, and Narendra's spiritual education continued. At Cossipore, he experienced "Nirvikalpa samadhi". Narendra and several other disciples received ochre robes from Ramakrishna, forming his first monastic order. He was taught that service to men was the most effective worship of God. Ramakrishna asked him to care for the other monastic disciples, and in turn asked them to see Narendra as their leader. Ramakrishna died in the early-morning hours of 16 August 1886 in Cossipore.
Founding of first Ramakrishna Math at Baranagar.
After Ramakrishna's death, his devotees and admirers stopped supporting his disciples. Unpaid rent accumulated, and Narendra and the other disciples had to find a new place to live. Many returned home, adopting a "Grihastha" (family-oriented) way of life. Narendra decided to convert a dilapidated house at Baranagar into a new "math" (monastery) for the remaining disciples. Rent for the Baranagar Math was low, raised by "holy begging" ("mādhukarī"). The math became the first building of the Ramakrishna Math: the monastery of the monastic order of Ramakrishna. Narendra and other disciples used to spend many hours in practising meditation and religious austerities every day. Narendra later reminisced about the early days of the monastery:
In 1887, Narendra compiled a Bengali song anthology named "Sangeet Kalpataru" with Vaishnav Charan Basak. Narendra collected and arranged most of the songs of this compilation, but could not finish the work of the book for unfavourable circumstances.
Monastic vows.
In December 1886, the mother of Baburam invited Narendra and his other brother monks to Antpur village. Narendra and the other aspiring monks accepted the invitation and went to Antpur to spend few days. In Antpur, in the Christmas Eve of 1886, Narendra and eight other disciples took formal monastic vows. They decided to live their lives as their master lived. Narendranath took the name "Swami Vivekananda".
Travels in India (1888–93).
In 1888, Narendra left the monastery as a "Parivrâjaka"— the Hindu religious life of a wandering monk, "without fixed abode, without ties, independent and strangers wherever they go". His sole possessions were a kamandalu (water pot), staff and his two favourite books: the "Bhagavad Gita" and "The Imitation of Christ". Narendra travelled extensively in India for five years, visiting centres of learning and acquainting himself with diverse religious traditions and social patterns. He developed sympathy for the suffering and poverty of the people, and resolved to uplift the nation. Living primarily on bhiksha (alms), Narendra travelled on foot and by railway (with tickets bought by admirers). During his travels he met, and stayed with Indians from all religions and walks of life: scholars, "dewans", rajas, Hindus, Muslims, Christians, "paraiyars" (low-caste workers) and government officials. Narendra left Bombay for Chicago on 31 May 1893 with the name "Vivekananda", as suggested by Ajit Singh of Khetri, which means "the bliss of discerning wisdom".
First visit to the West (1893–97).
Vivekananda started his journey to the West on 31 May 1893 and visited several cities in Japan (including Nagasaki, Kobe, Yokohama, Osaka, Kyoto and Tokyo), China and Canada en route to the United States, reaching Chicago on 30 July 1893, where the "Parliament of Religions" took place in September 1893. The Congress was an initiative of the Swedenborgian layman, and judge of the Illinois Supreme Court, Charles C. Bonney, to gather all the religions of the world, and show "the substantial unity of many religions in the good deeds of the religious life." It was one of the more than 200 adjunct gatherings and congresses of the Chicago's World's Fair, and was "an avant-garde intellectual manifestation of [...] cultic milieus, East and West," with the Brahmo Samaj and the Theosophical Society being invited as being representative of Hinduism.
Vivekananda wanted to join, but was disappointed to learn that no one without credentials from a "bona fide" organisation would be accepted as a delegate. Vivekananda contacted Professor John Henry Wright of Harvard University, who invited him to speak at Harvard. Vivekananda wrote of the professor, "He urged upon me the necessity of going to the Parliament of Religions, which he thought would give an introduction to the nation". Vivekananda submitted an application, "introducing himself as a monk 'of the oldest order of "sannyāsis" ... founded by Sankara,'" supported by the Brahmo Samaj representative Protapchandra Mozoombar, who was also a member of the Parliament's selection committee, "classifying the Swami as a representative of the Hindu monastic order."
Parliament of the World's Religions.
The Parliament of the World's Religions opened on 11 September 1893 at the Art Institute of Chicago as part of the World's Columbian Exposition. On this day, Vivekananda gave a brief speech representing India and Hinduism. He was initially nervous, bowed to Saraswati (the Hindu goddess of learning) and began his with "Sisters and brothers of America!". At these words, Vivekananda received a two-minute standing ovation from the crowd of seven thousand. According to Sailendra Nath Dhar, when silence was restored he began his address, greeting the youngest of the nations on behalf of "the most ancient order of monks in the world, the Vedic order of sannyasins, a religion which has taught the world both tolerance, of and universal acceptance". Vivekananda quoted two illustrative passages from the "Shiva mahima strotam": "As the different streams having their sources in different places all mingle their water in the sea, so, O Lord, the different paths which men take, through different tendencies, various though they appear, crooked or straight, all lead to Thee!" and "Whosoever comes to Me, through whatsoever form, I reach him; all men are struggling through paths that in the end lead to Me." According to Sailendra Nath Dhar, "t was only a short
speech, but it voiced the spirit of the Parliament."
Parliament President John Henry Barrows said, "India, the Mother of religions was represented by Swami Vivekananda, the Orange-monk who exercised the most wonderful influence over his auditors". Vivekananda attracted widespread attention in the press, which called him the "cyclonic monk from India". The "New York Critique" wrote, "He is an orator by divine right, and his strong, intelligent face in its picturesque setting of yellow and orange was hardly less interesting than those earnest words, and the rich, rhythmical utterance he gave them". The "New York Herald" noted, "Vivekananda is undoubtedly the greatest figure in the Parliament of Religions. After hearing him we feel how foolish it is to send missionaries to this learned nation". American newspapers reported Vivekananda as "the greatest figure in the parliament of religions" and "the most popular and influential man in the parliament".
The "Boston Evening Transcript" reported that Vivekananda was "a great favourite at the parliament... if he merely crosses the platform, he is applauded". He spoke "at receptions, the scientific section, and private homes" on topics related to Hinduism, Buddhism and harmony among religions until the parliament ended on 27 September 1893. Vivekananda's speeches at the Parliament had the common theme of universality, emphasising religious tolerance. He soon became known as a "handsome oriental" and made a huge impression as an orator.
Lecture tours in the UK and US.
After the Parliament of Religions, he toured many parts of the US as a guest. His popularity opened up new views for expanding on "life and religion to thousands". During a question-answer session at Brooklyn Ethical Society, he remarked, "I have a message to the West as Buddha had a message to the East."
Vivekananda spent nearly two years lecturing in the eastern and central United States, primarily in Chicago, Detroit, Boston, and New York. He founded the Vedanta Society of New York in 1894. By spring 1895 his busy, tiring schedule had affected his health. He ended his lecture tours and began giving free, private classes in Vedanta and yoga. Beginning in June 1895, Vivekananda gave private lectures to a dozen of his disciples at Thousand Island Park in New York for two months.
During his first visit to the West he travelled to the UK twice, in 1895 and 1896, lecturing successfully there. In November 1895 he met Margaret Elizabeth Noble an Irish woman who would become Sister Nivedita. During his second visit to the UK in May 1896 Vivekananda met Max Müller, a noted Indologist from Oxford University who wrote Ramakrishna's first biography in the West. From the UK, Vivekananda visited other European countries. In Germany he met Paul Deussen, another Indologist. Vivekananda was offered academic positions in two American universities (one the chair in Eastern Philosophy at Harvard University and a similar position at Columbia University); he declined both, since his duties would conflict with his commitment as a monk.
His success led to a change in mission, namely the establishment of Vedanta centres in the West. Vivekananda adapted traditional Hindu ideas and religiosity to suit the needs and understandings of his western audiences, who were especially attracted by and familiar with western esoteric traditions and movements like Transcendentalism and New thought. An important element in his adaptation of Hindu religiosity was the introduction of his four yoga's model, which includes Raja yoga, his interpretation of Patanjali's Yoga sutras, which offered a practical means to realize the divine force within which is central to modern western esotericism. In 1896 his book "Raja Yoga" was published, which became an instant success and was highly influential in the western understanding of Yoga.
Vivekananda attracted followers and admirers in the U.S. and Europe, including Josephine MacLeod, William James, Josiah Royce, Robert G. Ingersoll, Nikola Tesla, Lord Kelvin, Harriet Monroe, Ella Wheeler Wilcox, Sarah Bernhardt, Emma Calvé and Hermann Ludwig Ferdinand von Helmholtz. He initiated several followers : Marie Louise (a French woman) became Swami Abhayananda, and Leon Landsberg became Swami Kripananda, so that they could continue the work of the mission of the Vedanta Society. This society even to this day is filled with foreign nationals and is also located in Los Angeles. During his stay in America, Vivekananda was given land in the mountains to the Southeast of San Jose, CA to establish an asrama (retreat) for Vedanta students. He called it Peace retreat or "Shanti Asrama". The largest American center is the Vedanta Society of Southern California in Hollywood, CA (one of the twelve main centers). There is also a Vedanta Press in Hollywood which publishes books about Vedanta and translations of Hindu scriptures and texts in English. Christina Greenstidel of Detroit was also initiated by Vivekananda with a mantra and she became Sister Christine, and they established a close father–daughter relationship.
From the West, Vivekananda revived his work in India. He regularly corresponded with his followers and brother monks, offering advice and financial support. His letters from this period reflect his campaign of social service, and were strongly worded. He wrote to Swami Akhandananda, "Go from door to door amongst the poor and lower classes of the town of Khetri and teach them religion. Also, let them have oral lessons on geography and such other subjects. No good will come of sitting idle and having princely dishes, and saying "Ramakrishna, O Lord!"—unless you can do some good to the poor". In 1895, Vivekananda founded the periodical "Brahmavadin" to teach the Vedanta. Later, Vivekananda's translation of the first six chapters of "The Imitation of Christ" was published in "Brahmavadin" in 1889. Vivekananda left for India on 16 December 1896 from England with his disciples, Captain and Mrs. Sevier and J.J. Goodwin. On the way they visited France and Italy, and set sail for India from Naples on 30 December 1896. He was later followed to India by Sister Nivedita, who devoted the rest of her life to the education of Indian women and India's independence.
Back in India (1897–99).
The ship from Europe arrived in Colombo, British Ceylon (now Sri Lanka) on 15 January 1897, and Vivekananda received a warm welcome. In Colombo he gave his first public speech in the East, "". From there on, his journey to Calcutta was triumphant. Vivekananda travelled from Colombo to Pamban, Rameswaram, Ramnad, Madurai, Kumbakonam and Madras, delivering lectures. Common people and rajas gave him an enthusiastic reception. During his train travels, people often sat on the rails to force the train to stop so they could hear him. From Madras, he continued his journey to Calcutta and Almora. While in the West, Vivekananda spoke about India's great spiritual heritage; in India, he repeatedly addressed social issues: uplifting the people, eliminating the caste system, promoting science and industrialisation, addressing widespread poverty and ending colonial rule. These lectures, published as "Lectures from Colombo to Almora", demonstrate his nationalistic fervour and spiritual ideology.
On 1 May 1897 in Calcutta, Vivekananda founded the Ramakrishna Mission for social service. Its ideals are based on "", and its governing body consists of the trustees of the Ramakrishna Math (which conducts religious work). Both Ramakrishna Math and Ramakrishna Mission have their headquarters at Belur Math. Vivekananda founded two other monasteries: one in Mayavati in the Himalayas (near Almora), the "Advaita Ashrama" and another in Madras. Two journals were founded: "Prabuddha Bharata" in English and "Udbhodan" in Bengali. That year, famine-relief work was begun by Swami Akhandananda in the Murshidabad district.
Vivekananda earlier inspired Jamshedji Tata to set up a research and educational institution when they travelled together from Yokohama to Chicago on Vivekananda's first visit to the West in 1893. Tata now asked him to head his Research Institute of Science; Vivekananda declined the offer, citing a conflict with his "spiritual interests". He visited Punjab, attempting to mediate an ideological conflict between Arya Samaj (a reformist Hindu movement) and "sanatan" (orthodox Hindus). After brief visits to Lahore, Delhi and Khetri, Vivekananda returned to Calcutta in January 1898. He consolidated the work of the math and trained disciples for several months. Vivekananda composed "Khandana Bhava–Bandhana", a prayer song dedicated to Ramakrishna, in 1898.
Second visit to the West and final years (1899–1902).
Despite declining health, Vivekananda left for the West for a second time in June 1899 accompanied by Sister Nivedita and Swami Turiyananda. Following a brief stay in England, he went to the United States. During this visit, Vivekananda established Vedanta Societies in San Francisco and New York and founded a "shanti ashrama" (peace retreat) in California. He then went to Paris for the Congress of Religions in 1900. His lectures in Paris concerned the worship of the "lingam" and the authenticity of the Bhagavad Gita. Vivekananda then visited Brittany, Vienna, Istanbul, Athens and Egypt. The French philosopher Jules Bois was his host for most of this period, until he returned to Calcutta on 9 December 1900.
After a brief visit to the Advaita Ashrama in Mayavati Vivekananda settled at Belur Math, where he continued co-ordinating the works of Ramakrishna Mission, the math and the work in England and the U.S. He had many visitors, including royalty and politicians. Although Vivekananda was unable to attend the Congress of Religions in 1901 in Japan due to deteriorating health, he made pilgrimages to Bodhgaya and Varanasi. Declining health (including asthma, diabetes and chronic insomnia) restricted his activity.
Death.
On 4 July 1902 (the day of his death) Vivekananda awoke early, went to the chapel at Belur Math and meditated for three hours. He taught "Shukla-Yajur-Veda", Sanskrit grammar and the philosophy of yoga to pupils, later discussing with colleagues a planned Vedic college in the Ramakrishna Math. At 7:00 p.m. Vivekananda went to his room, asking not to be disturbed; he died at 9:10 p.m. while meditating. According to his disciples, Vivekananda attained mahasamādhi; the rupture of a blood vessel in his brain was reported as a possible cause of death. His disciples believed that the rupture was due to his "brahmarandhra" (an opening in the crown of his head) being pierced when he attained "mahasamādhi". Vivekananda fulfilled his prophecy that he would not live forty years. He was cremated on a sandalwood funeral pyre on the bank of the Ganga in Belur, opposite where Ramakrishna was cremated sixteen years earlier.
Teachings and philosophy.
Vivekananda propagated that the essence of Hinduism was best expressed in Adi Shankara's Advaita Vedanta philosophy. Nevertheless, following Ramakrishna, and in contrast to Advaita Vedanta, Vivekananda believed that the Absolute is both immanent and transcendent. According to Anil Sooklal, Vivekananda's neo-Advaita "reconciles Dvaita or dualism and Advaita or non-dualism". Vivekananda summarised the Vedanta as follows, giving it a modern and Universalistic interpretation:
Nationalism was a prominent theme in Vivekananda's thought. He believed that a country's future depends on its people, and his teachings focused on human development. He wanted "to set in motion a machinery which will bring noblest ideas to the doorstep of even the poorest and the meanest".
Vivekananda linked morality with control of the mind, seeing truth, purity and unselfishness as traits which strengthened it. He advised his followers to be holy, unselfish and to have "śraddhā" (faith). Vivekananda supported "brahmacharya" (celibacy), believing it the source of his physical and mental stamina and eloquence. He emphasised that success was an outcome of focused thought and action; in his lectures on Raja Yoga he said, "Take up one idea. Make that one idea your life – think of it, dream of it, live on that idea. Let the brain, muscles, nerves, every part of your body, be full of that idea, and just leave every other idea alone. This is the way to success, that is the way great spiritual giants are produced".
Influence and legacy.
Vivekananda was one of the main representatives of Neo-Vedanta, a modern interpretation of selected aspects of Hinduism in line with western esoteric traditions, especially Transcendentalism, New Thought and Theosophy. His reinterpretation was, and is, very successful, creating a new understanding and appreciation of Hinduism within and outside India, and was the principal reason for the enthusiastic reception of yoga, transcendental meditation and other forms of Indian spiritual self-improvement in the West. Agehananda Bharati explained, "...modern Hindus derive their knowledge of Hinduism from Vivekananda, directly or indirectly". Vivekananda espoused the idea that all sects within Hinduism (and all religions) are different paths to the same goal. However, this view has been criticised as an oversimplification of Hinduism.
In the background of emerging nationalism in British-ruled India, Vivekananda crystallised the nationalistic ideal. In the words of social reformer Charles Freer Andrews, "The Swami's intrepid patriotism gave a new colour to the national movement throughout India. More than any other single individual of that period Vivekananda had made his contribution to the new awakening of India". Vivekananda drew attention to the extent of poverty in the country, and maintained that addressing such poverty was a prerequisite for national awakening. His nationalistic ideas influenced many Indian thinkers and leaders. Sri Aurobindo regarded Vivekananda as the one who awakened India spiritually. Mahatma Gandhi counted him among the few Hindu reformers "who have maintained this Hindu religion in a state of splendor by cutting down the dead wood of tradition".
The first governor-general of independent India, Chakravarti Rajagopalachari, said "Vivekananda saved Hinduism, saved India". According to Subhas Chandra Bose, a proponent of armed struggle for Indian independence, Vivekananda was "the maker of modern India"; for Gandhi, Vivekananda's influence increased Gandhi's "love for his country a thousandfold". Vivekananda influenced India's independence movement; his writings inspired independence activists such as Netaji Subhas Chandra Bose, Aurobindo Ghose, Bal Gangadhar Tilak and Bagha Jatin and intellectuals such as Aldous Huxley, Christopher Isherwood, Romain Rolland. Many years after Vivekananda's death Rabindranath Tagore told French Nobel laureate Romain Rolland, "If you want to know India, study Vivekananda. In him everything is positive and nothing negative". Rolland wrote, "His words are great music, phrases in the style of Beethoven, stirring rhythms like the march of Händel choruses. I cannot touch these sayings of his, scattered as they are through the pages of books, at thirty years' distance, without receiving a thrill through my body like an electric shock. And what shocks, what transports, must have been produced when in burning words they issued from the lips of the hero!"
Jamshedji Tata was inspired by Vivekananda to establish the Indian Institute of Science, one of India's best-known research universities. Abroad, Vivekananda communicated with orientalist Max Müller, and scientist Nikola Tesla was one of those influenced by his Vedic teachings. While National Youth Day in India is observed on his birthday, 12 January, the day he delivered his masterful speech at the Parliament of Religions, 11 September 1893 is "World Brotherhood Day". In September 2010, India's Finance Ministry highlighted the relevance of Vivekananda's teachings and values to the modern economic environment. The then Union Finance Minister Pranab Mukherjee, the current President of India, approved in principle the Swami Vivekananda Values Education Project at a cost of , with objectives including involving youth with competitions, essays, discussions and study circles and publishing Vivekananda's works in a number of languages. In 2011, the West Bengal Police Training College was renamed the Swami Vivekananda State Police Academy, West Bengal.
The state technical university in Chhattisgarh has been named the Chhattisgarh Swami Vivekananda Technical University. In 2012, the Raipur airport was renamed Swami Vivekananda Airport.
The 150th birth anniversary of Swami Vivekananda was celebrated in India and abroad. The Ministry of Youth Affairs and Sports in India officially observed 2013 as the occasion in a declaration. Year-long events and programs were organised by branches of the Ramakrishna Math, the Ramakrishna Mission, the central and state governments in India, educational institutions and youth groups. Bengali film director Tutu (Utpal) Sinha made a film, "" as a tribute for his 150th birth anniversary.
Works.
Lectures.
Although Vivekananda was a powerful orator and writer in English and Bengali, he was not a thorough scholar, and most of his published works were compiled from lectures given around the world which were "mainly delivered [...] impromptu and with little preparation". His main work, "Raja Yoga", consists of talks he delivered in New York.
Literary works.
According to Banhatti, " singer, a painter, a wonderful master of language and a poet, Vivekananda was a complete artist", composing many songs and poems, including his favourite, "Kali the Mother". Vivekananda blended humour with his teachings, and his language was lucid. His Bengali writings testify to his belief that words (spoken or written) should clarify ideas, rather than demonstrating the speaker (or writer's) knowledge.
"Bartaman Bharat" meaning "Present Day India" is an erudite Bengali language essay written by him, which was first published in the March 1899 issue of Udbodhan, the only Bengali language magazine of Ramakrishna Math and Ramakrishna Mission. The essay was reprinted as a book in 1905 and later compiled into the fourth volume of The Complete Works of Swami Vivekananda. In this essay his refrain to the readers was to honour and treat every Indian as a brother irrespective of whether he was born poor or in lower caste.
Publications.
Here a list of selected books by Vivekananda that were published after his death (1902)

</doc>
<doc id="45667" url="https://en.wikipedia.org/wiki?curid=45667" title="A. C. Bhaktivedanta Swami Prabhupada">
A. C. Bhaktivedanta Swami Prabhupada

Abhay Charanaravinda Bhaktivedanta Swami Prabhupada (Bengali: "Abhoy Charonarobindo Bhoktibedanto Swamy Probhupad"; অভয়চরণারবিন্দ ভক্তিবেদান্ত স্বামী প্রভুপাদ, Sanskrit: , IAST: '; 1 September 1896 – 14 November 1977) was a Gaudiya Vaishnava spiritual teacher (guru) and the founder preceptor (acharya) of the International Society for Krishna Consciousness (ISKCON), commonly known as the "Hare Krishna Movement". His mission was to propagate Gaudiya Vaishnavism, a school of Vaishnavite Hinduism that had been taught to him by his guru, Bhaktisiddhanta Sarasvati, throughout the world. Born Abhay Charan De in Calcutta, he was educated at the prestigious local Scottish Church College. Before adopting the life of a pious renunciant (vanaprastha) in 1950, he was married with children and owned a small pharmaceutical business.
In 1959 he took a vow of renunciation (sannyasa) and started writing commentaries on Vaishnava scriptures. In his later years, as a traveling Vaishnava monk, he became an influential communicator of Gaudiya Vaishnava theology to India and specifically to the West through his leadership of ISKCON, founded in 1966. As the founder of ISKCON, he "emerged as a major figure of the Western counterculture, initiating thousands of young Americans." Despite attacks from anti-cult groups, he received a favorable welcome from many religious scholars, such as J. Stillson Judah, Harvey Cox, Larry Shinn and Thomas Hopkins, who praised Bhaktivedanta Swami's translations and defended the group against distorted media images and misinterpretations. In respect to his achievements, religious leaders from other Gaudiya Vaishnava movements have also given him credit.
He has been described as a charismatic leader, in the sense used by sociologist Max Weber, as he was successful in acquiring followers in the United States, Europe, India and elsewhere. After his death in 1977, ISKCON, the society he founded based on a type of Hindu Krishnaism using the "Bhagavata Purana" as a central scripture, continued to grow and is respected in India, though there have been disputes about leadership among his followers. In February 2014, ISKCON's news agency reported to have reached a milestone of distributing over half a billion books authored by Bhaktivedanta Swami Prabhupada, since 1965.
Biography.
Early life.
Born on 1 September 1896, the day after Janmastami, one of the most important Vaishnava holidays, in a humble house in the Tollygunge suburb of Calcutta, he was named Abhay Charan, ""one who is fearless", "having taken shelter at Lord Krishna's feet"." Since he was born on the day of Nandotsava ("the celebration of Nanda," Krishna's father, a traditional festival in honor of Krishna's birth) he was also called Nandulal. His parents, Sriman Gour Mohan De and Srimati Rajani De, were devout Vaishnavas (devotees of Vishnu). In accordance with Bengali tradition, his mother had gone to the home of her parents for the delivery, and only a few days later Abhay returned with parents to his home at 151 Harrison Road in Calcutta, where he was brought up and educated.
He received a European led education in the Scottish Church College. This school was well reputed among Bengalis; many Vaishnava families sent their sons there. The professors, most of whom were Europeans, were known as sober, moral men, and it is believed that the students received a good education. The college was located in north Calcutta, not far from Harrison Road where Abhay's family lived. During his years in the college, Abhay Charan De (অভয় চরণ দে) was a member of the English Society as well as that of the Sanskrit Society, and it has been suggested that his education provided him a foundation for his future leadership. He graduated in 1920 with majors in English, philosophy and economics. However he rejected his diploma in response to Gandhi's independence movement. 
Religious career.
In 1922, when he first met his spiritual master, Bhaktisiddhanta Sarasvati Thakura, he was requested to spread the message of Chaitanya Mahaprabhu in the English language. In 1933 he became a formally initiated disciple of Bhaktisiddhanta. In 1944, (from his front room at Sita Kanta Banerjee, Calcutta), he started the publication called "Back to Godhead", for which he acted as writer, designer, publisher, editor, copy editor and distributor. He personally designed the logo, an effulgent figure of Caitanya Mahaprabhu in the upper left corner, with the motto: ""Godhead is Light, Nescience is darkness"" greeting the readers. In his first magazine he wrote:
In 1947, the Gaudiya Vaishnava Society recognised his scholarship with the title "Bhaktivedanta," ("") meaning "one who has realised that devotional service to the Supreme Lord is the end of all knowledge" (with the words Bhakti, indicating devotion and Vedanta indicating conclusive knowledge).
His later well known name, ', is a Sanskrit title, literally meaning "he who has taken the shelter of the lotus feet of the Lord" where" " denotes "Lord", and ' means "taking shelter." Also, ""at whose feet masters sit"". This name was used as a respectful form of address by his disciples from late 1967 early 1968 onwards. Previous to this, as with his early disciples, followers used to call him "Swamiji".
From 1950 onwards, he lived at the medieval Radha-Damodar mandir in the holy town of Vrindavan, where he began his commentary and translation work of the Sanskrit work Bhagavata Purana. Of all notable Vrindavana's temples, the Radha-Damodara mandir had at the time the largest collection of various copies of the original writings of the Six Gosvamis and their followers – more than two thousand separate manuscripts, many of them three hundred, some even four hundred years old. His guru, Bhaktisiddhanta Sarasvati, had always encouraged him that "If you ever get money, print books", referring to the need of literary presentation of the Vaishnava culture.
Renunciation.
Keshavaji Gaudiya Matha was the place where Bhaktivedanta used to live, he had written and studied in the library of this building, here he edited the "" magazine and this is the place where he donated the murti of Lord Chaitanya who stands on the altar beside the Deities of Radha Krishna (named "Śrī Śrī Rādhā Vinodavihārījī"). During his visit in September 1959 he entered the doors of this "matha" dressed in white, as Abhoy Babu, but would be leaving dressed in saffron, a sannyasi. He received the sannyasa name "Swami" (स्वामी Svāmi), not to be confused with the title Swami. In this "matha", in Mathura Vrndavana, Abhoy Charan Bhaktivedanta took Vaishnava renunciate vows,"sannyasa", from his friend and godbrother Bhakti Prajnana Keshava, and following this he single-handedly published the first three volumes covering seventeen chapters of the first book of "Bhagavata Purana", filling three volumes of four hundred pages each with a detailed commentary. Introduction to the first volume was a biographical sketch of Caitanya Mahāprabhu. He then left India, obtaining free passage on a freight ship called the "Jaladuta", with the aim and a hope of fulfilling his spiritual master's instruction to spread the message of Caitanya Mahaprabhu around the world. In his possession were a suitcase, an umbrella, a supply of dry cereal, about eight dollars worth of Indian currency, and several boxes of books.
Mission to the West.
When he sailed to the United States in 1965, his trip was not sponsored by any religious organization, nor was he met upon arrival by a group of loyal followers. As the Indian freighter "Jaladuta" neared his destination, the magnitude of his intended task weighed on him. On 13 September he wrote in his diary, "Today I have disclosed my mind to my companion, Lord Sri Krishna." On this occasion and on a number of others, he called on Krishna for help in his native Bengali. Examining these compositions, academics regard them as "intimate records of his prayerful preparation for what lay ahead" and a view on "how Bhaktivedanta Swami understood his own identity and mission."
By journeying to USA, he was attempting to fulfill the wish of his guru, possible only by the grace of "his dear Lord Krishna". It is in July 1966 "global missionary Vaishnavism" was brought to the West by Bhaktivedanta Swami, "the soul agent", founding the International Society for Krishna Consciousness in New York City. Bhaktivedanta Swami spent much of the last decade of his life setting up the institution of ISKCON. Since he was the Society's leader, his personality and management were responsible for much of ISKCON's growth and the reach of his mission.
When it was suggested to him at the time of founding the ISKCON in 1966 that a broader term "God Consciousness" would be preferable to "Krishna Consciousness" in the title, he rejected this recommendation, suggesting that the name "Krishna" includes all other forms and concepts of God.
After a group of devotees and a temple had been established in New York another center was started in San Francisco in 1967. From there he traveled throughout America with his disciples, popularizing the movement through street chanting ("sankirtana"), book distribution and public speeches.
Once ISKCON was more established in the USA a small number of devotees from the San Francisco temple were sent to London, England. After a short time in London they came into contact with The Beatles, of whom George Harrison took the greatest interest, spending a significant time speaking with Bhaktivedanta Swami and producing a record with members of the later London Radha Krsna Temple. Over the following years his continuing leadership role took him around the world some several times setting up temples and communities in all of the major continents. By the time of his death in Vrindavan in 1977, ISKCON had become an internationally known expression of Vaishnavism.
In the twelve years from his arrival in New York until his final days, he:
Through his mission, he followed and communicated the teachings of Chaitanya Mahaprabhu and introduced bhakti yoga to an international audience. Within Gaudiya Vaishnavism this was viewed as the fulfillment of a long time mission to introduce Caitanya Mahaprabhu's teachings to the world.
In his discussion with historian Arnold J. Toynbee in London, he is quoted as saying: "I have started this Krishna Conscious Movement among the Indians and Americans and for the next ten thousand years it will increase."
Books and publishing.
It is believed that Bhaktivedanta Swami's most significant contribution are his books. Within the final twenty years of his life Bhaktivedanta Swami translated over sixty volumes of classic Vedic scriptures (such as the "Bhagavad Gita" and the "Srimad Bhagavatam") into the English language. For their authority, depth, and clarity, his books have won praise from professors at colleges and universities like Harvard, Oxford, Cornell, Columbia, Syracuse, Oberlin, and Edinburgh, and his "Bhagavad-Gītā As It Is" was published by Macmillan Publishers, in 1968 and unabridged edition in 1972, and is now available in over sixty languages around the world and some other books by Bhaktivedanta Swami are available in over eighty different languages. In February 2014, ISKCON's news agency reported to have reached a milestone of distributing over half a billion books authored by Bhaktivedanta Swami Prabhupada, since 1965.
The Bhaktivedanta Book Trust was established in 1972 to publish his works, and it has also published his multi-volume biography, "Srila Prabhupada-lilamrta", that according to Larry Shinn will "certainly be one of the most complete records of the life and work of any modern religious figure". Prabhupada reminded his devotees before his death that he would live forever in his books, and through them would remain present as a spiritual master or guru. Bhaktivedanta Swami had instilled in his followers an understanding of the importance of writing and publishing not only with regard to his works, but also their own initiatives. His early disciples felt Prabhupada had given them "Back To Godhead" for their own writings from the very start.
A prominent Gaudiya Vaishnava figure, Shrivatsa Goswami, who as a young man had met Bhaktivedanta Swami in 1972, affirmed the significance of book publishing and distribution in spreading the message of Caitanya in an interview with Steven Gelberg:
Views on other religious traditions.
Bhaktivedanta Swami considered Moses, Jesus, and Mohamed to be empowered representatives of God, describing them within his writings as pioneers of the same essential message of dedication to God with love and devotion.
Other typical expressions present a different perspective, where he would point out that "today I may be a Hindu, but tomorrow I may become a Christian or Muslim. In this way faiths can be changed, but dharma" is a natural sequence, a natural occupation or a connection and it can not be changed, because it is permanent, according to him. While the ISKCON theology of personal god is close to Christian theology, both personal and monotheistic, being a preacher of bhakti and a missionary he sometimes would add, that "already many Christians have tasted the nectar of divine love of the holy name and are dancing with "karatalas" (hand-cymbals) and "mridangas" (drums)."
His approach to modern knowledge is also seen in sectarian Orthodox Judaism, where the skills and technical knowledge of modernity are encouraged, but the values rejected. Bhaktivedanta Swami stated "devotees should not be lazy, idle...we are not afraid to work. Whatever our engagement is, by offering the result to Krishna we become Krishna conscious". Some of his representations are believed to affect women adversely and are male-centred, others are tender and celebratory. Bhaktivedanta Swami himself taught a dualism of body and soul and that of the genders. Similar to many traditional religions he considered sexuality and spirituality as conflicting opposites. Among some liberal male followers there is a positive recognition of his example in applying the spirit of the law according to time, place, person and circumstance, rather than literal tracing of the tradition.
Within India.
Beginning his public preaching mission in India, he founded the League of Devotees in Jhansi in 1953.
Following the establishment of temples and centres in the United States and Europe, he returned to India in 1971, holding many public programs which were well attended. From 1971 onwards, the movement became increasingly popular and spread throughout India. He was particularly eager to see the progress at "the impressive temple project in" Mumbai which he and his disciples had fought very hard to establish, with large temples in Mayapur and Vrindavan to follow in the mid-1970s. To promote the vedic education system within the modern Indian education structure, he introduced a chain of Gurukul in various part of India. The Bhaktivedanta Gurukula and International School is one of the most successful schools in the list.
In 1996, the Government of India recognized his accomplishments by issuing a commemorative stamp in his honour as a part of Prabhupada Centennial celebrations.
Speaking at the inauguration of ISKCON's cultural center in New Delhi on 5 April on the occasion of Ramnavmi in 1998, Atal Bihari Vajpayee, then India's prime minister, said:
Monuments.
A number of memorial samadhis or shrines to Bhaktivedanta Swami were constructed by the members of ISKCON in his remembrance, the largest of which are in Mayapur, Vrindavan and at the larger sized temples in America. Prabhupada's Palace of Gold was designed and constructed by devotees of the New Vrindavan community and dedicated on 2 September 1979. Back in 1972 it was intended to be simply a residence for Bhaktivedanta Swami, but over time the plans evolved into an ornate marble and gold palace which is now visited by thousands of Hindu pilgrims each year, visiting this centerpiece of the community strongly relying upon tourist trade.

</doc>
<doc id="45675" url="https://en.wikipedia.org/wiki?curid=45675" title="Primary Chronicle">
Primary Chronicle

The Tale of Bygone Years (, "Pověstĭ Vremęnĭnyhŭ Lětŭ", , "Povest’ vremennyh let") or Primary Chronicle is a history of Kievan Rus' from about 850 to 1110, originally compiled in Kiev about 1113. The work is considered to be a fundamental source in the interpretation of the history of the Eastern Slavs.
Three editions.
Primary edition.
Tradition long regarded the original compilation as the work of a monk named Nestor (c. 1056 – c. 1114); hence scholars spoke of "Nestor's Chronicle" or of "Nestor's manuscript". His compilation has not survived. Nestor's many sources included earlier (now-lost) Slavonic chronicles, the Byzantine annals of John Malalas and of George Hamartolus, native legends and Norse sagas, several Greek religious texts, Rus'–Byzantine treaties, and oral accounts of Yan Vyshatich and of other military leaders. Nestor worked at the court of Sviatopolk II of Kiev (ruled 1093–1113) and probably shared Sviatopolk's pro-Scandinavian policies.
The early part of the "Chronicle" features many anecdotal stories, among them those of the arrival of the three Varangian brothers, the founding of Kiev, the murder of Askold and Dir (ca. 882), the death (912) of Oleg (fatally bitten by a serpent concealed in the skeleton of his horse), and the vengeance taken by Olga, the wife of Igor, on the Drevlians, who had murdered her husband. The account of the labors of Saints Cyril and Methodius among the Slavic peoples also makes a very interesting tale, and to Nestor we owe the story of the summary way in which Vladimir the Great (rules 980 to 1015) suppressed the worship of Perun and other traditional gods at Kiev.
Second edition.
In the year 1116, Nestor's text was extensively edited by hegumen Sylvester who appended his name at the end of the chronicle. As Vladimir Monomakh was the patron of the village of Vydubychi where his monastery is situated, the new edition glorified that prince and made him the central figure of later narrative. This second version of Nestor's work is preserved in the Laurentian codex (see below).
Third edition.
A third edition followed two years later and centered on the person of Vladimir's son and heir, Mstislav the Great. The author of this revision could have been Greek, for he corrected and updated much data on Byzantine affairs. This latest revision of Nestor's work is preserved in the Hypatian codex (see below).
Two manuscripts.
Because the original of the chronicle as well as the earliest known copies are lost, it is difficult to establish the original content of the chronicle. The two main sources for the chronicle's text as it is known presently are the Laurentian codex and the Hypatian codex.
The Laurentian codex was compiled in what are today Russian lands by the Nizhegorod monk Laurentius for the Prince Dmitry Konstantinovich in 1377. The original text he used was a lost codex compiled for the Grand Duke Mikhail of Tver in 1305. The account continues until 1305, but the years 898–922, 1263–83 and 1288–94 are missing for reasons unknown. The manuscript was acquired by the famous Count Musin-Pushkin in 1792 and subsequently presented to the National Library of Russia in Saint Petersburg.
The Hypatian Codex dates to the 15th century. It was written in what are today Ukrainian lands and incorporates much information from the lost 12th-century Kievan and 13th-century Halychian chronicles. The language of this work is the East Slavic version of Church Slavonic language with many additional irregular east-slavisms (like other east-Slavic codices of the time). Whereas the Laurentian (Muscovite) text traces the Kievan legacy through to the Muscovite princes, the Hypatian text traces the Kievan legacy through the rulers of the Halych principality.The Hypatian codex was rediscovered in Kiev in the 1620s and copy was made for Prince Kostiantyn Ostrozhsky. A copy was found in Russia in the 18th century at the Ipatiev Monastery of Kostroma by the Russian historian Nikolai Karamzin.
Numerous monographs and published versions of the chronicle have been made, the earliest known being in 1767. Aleksey Shakhmatov published a pioneering textological analysis of the narrative in 1908. Dmitry Likhachev and other Soviet scholars partly revisited his findings. Their versions attempted to reconstruct the pre-Nestorian chronicle, compiled at the court of Yaroslav the Wise in the mid-11th century.
Assessment.
Unlike many other medieval chronicles written by European monks, the "Tale of Bygone Years" is unique as the only written testimony on the earliest history of East Slavic people. Its comprehensive account of the history of Rus' is unmatched in other sources, although important correctives are provided by the Novgorod First Chronicle. It is also valuable as a prime example of the Old East Slavonic literature.

</doc>
<doc id="45678" url="https://en.wikipedia.org/wiki?curid=45678" title="Atonality">
Atonality

Atonality in its broadest sense is music that lacks a tonal center, or key. "Atonality", in this sense, usually describes compositions written from about 1908 to the present day where a hierarchy of pitches focusing on a single, central tone is not used, and the notes of the chromatic scale function independently of one another . More narrowly, the term "atonality" describes music that does not conform to the system of tonal hierarchies that characterized classical European music between the seventeenth and nineteenth centuries . "The repertory of atonal music is characterized by the occurrence of pitches in novel combinations, as well as by the occurrence of familiar pitch combinations in unfamiliar environments" .
More narrowly still, the term is sometimes used to describe music that is neither tonal nor serial, especially the pre-twelve-tone music of the Second Viennese School, principally Alban Berg, Arnold Schoenberg, and Anton Webern . However, "a categorical label, 'atonal' generally means only that the piece is in the Western tradition and is not 'tonal , although there are longer periods, e.g., medieval, renaissance, and modern modal musics to which this definition does not apply. "[Serialism arose partly as a means of organizing more coherently the relations used in the preserial 'free atonal' music. ... Thus many useful and crucial insights about even strictly serial music depend only on such basic atonal theory" .
Late 19th- and early 20th-century composers such as Alexander Scriabin, Claude Debussy, Béla Bartók, Paul Hindemith, Sergei Prokofiev, Igor Stravinsky, and Edgard Varèse have written music that has been described, in full or in part, as atonal (; ; ; ; ; ; ; ; ; ; ; ).
History.
While music without a tonal center had been written previously, for example Franz Liszt's "Bagatelle sans tonalité" of 1885, it is with the twentieth century that the term "atonality" began to be applied to pieces, particularly those written by Arnold Schoenberg and The Second Viennese School.
The term "atonality" was coined in 1907 by Joseph Marx in a scholarly study of tonality, which was later expanded into his doctoral thesis .
Their music arose from what was described as the "crisis of tonality" between the late nineteenth century and early twentieth century in classical music. This situation had come about historically through the increasing use over the course of the nineteenth century of
ambiguous chords, less probable harmonic inflections, and the more unusual melodic and rhythmic inflections possible within the style of tonal music. The distinction between the exceptional and the normal became more and more blurred; and, as a result, there was a concomitant loosening of the syntactical bonds through which tones and harmonies had been related to one another. The connections between harmonies were uncertain even on the lowest—chord-to-chord—level. On higher levels, long-range harmonic relationships and implications became so tenuous that they hardly functioned at all. At best, the felt probabilities of the style system had become obscure; at worst, they were approaching a uniformity which provided few guides for either composition or listening. 
The first phase, known as "free atonality" or "free chromaticism", involved a conscious attempt to avoid traditional diatonic harmony. Works of this period include the opera "Wozzeck" (1917–1922) by Alban Berg and "Pierrot Lunaire" (1912) by Schoenberg.
The second phase, begun after World War I, was exemplified by attempts to create a systematic means of composing without tonality, most famously the method of composing with 12 tones or the twelve-tone technique. This period included Berg's "Lulu" and "Lyric Suite", Schoenberg's "Piano Concerto", his oratorio "Die Jakobsleiter" and numerous smaller pieces, as well as his last two string quartets. Schoenberg was the major innovator of the system, but his student, Anton Webern, is anecdotally claimed to have begun linking dynamics and tone color to the primary row, making rows not only of pitches but of other aspects of music as well . However, actual analysis of Webern's twelve-tone works has so far failed to demonstrate the truth of this assertion. One analyst concluded, following a minute examination of the Piano Variations, op. 27, that while the texture of this music may superficially resemble that of some serial music ... its structure does not. None of the patterns within separate nonpitch characteristics makes audible (or even numerical) sense "in itself". The point is that these characteristics are still playing their traditional role of differentiation. Twelve-tone technique, combined with the parametrization (separate organization of four aspects of music: pitch, attack character, intensity, and duration) of Olivier Messiaen, would be taken as the inspiration for serialism .
Atonality emerged as a pejorative term to condemn music in which chords were organized seemingly with no apparent coherence. In Nazi Germany, atonal music was attacked as "Bolshevik" and labeled as degenerate ("Entartete Musik") along with other music produced by enemies of the Nazi regime. Many composers had their works banned by the regime, not to be played until after its collapse after World War II.
After Schoenberg's death, Igor Stravinsky used the twelve-tone technique . Iannis Xenakis generated pitch sets from mathematical formulae, and also saw the expansion of tonal possibilities as part of a synthesis between the hierarchical principle and the theory of numbers, principles which have dominated music since at least the time of Parmenides .
Free atonality.
The twelve-tone technique was preceded by Schoenberg's freely atonal pieces of 1908–1923, which, though free, often have as an "integrative element...a minute intervallic cell" that in addition to expansion may be transformed as with a tone row, and in which individual notes may "function as pivotal elements, to permit overlapping statements of a basic cell or the linking of two or more basic cells" .
The twelve-tone technique was also preceded by nondodecaphonic serial composition used independently in the works of Alexander Scriabin, Igor Stravinsky, Béla Bartók, Carl Ruggles, and others . "Essentially, Schoenberg and Hauer systematized and defined for their own dodecaphonic purposes a pervasive technical feature of 'modern' musical practice, the ostinato" 
Composing atonal music.
Setting out to compose atonal music may seem complicated because of both the vagueness and generality of the term. Additionally George Perle explains that, "the 'free' atonality that preceded dodecaphony precludes by definition the possibility of self-consistent, generally applicable compositional procedures" . However, he provides one example as a way to compose atonal pieces, a pre-twelve-tone technique piece by Anton Webern, which rigorously avoids anything that suggests tonality, to choose pitches that do not imply tonality. In other words, reverse the rules of the common practice period so that what was not allowed is required and what was required is not allowed. This is what was done by Charles Seeger in his explanation of dissonant counterpoint, which is a way to write atonal counterpoint .
Kostka and Payne list four procedures as operational in the atonal music of Schoenberg, all of which may be taken as negative rules. Avoidance of melodic or harmonic octaves, avoidance of traditional pitch collections such as major or minor triads, avoidance of more than three successive pitches from the same diatonic scale, and use of disjunct melodies (avoidance of conjunct melodies) .
Further, Perle agrees with and that, "the abandonment of the concept of a root-generator of the individual chord is a radical development that renders futile any attempt at a systematic formulation of chord structure and progression in atonal music along the lines of traditional harmonic theory" . Atonal compositional techniques and results "are not reducible to a set of foundational assumptions in terms of which the compositions that are collectively designated by the expression 'atonal music' can be said to represent 'a system' of composition" . Equal-interval chords are often of indeterminate root, mixed-interval chords are often best characterized by their interval content, while both lend themselves to atonal contexts .
Perle also points out that structural coherence is most often achieved through operations on intervallic cells. A cell "may operate as a kind of microcosmic set of fixed intervallic content, statable either as a chord or as a melodic figure or as a combination of both. Its components may be fixed with regard to order, in which event it may be employed, like the twelve-tone set, in its literal transformations. … Individual tones may function as pivotal elements, to permit overlapping statements of a basic cell or the linking of two or more basic cells" .
Regarding the post-tonal music of Perle, one theorist wrote: "While ... montages of discrete-seeming elements tend to accumulate global rhythms other than those of tonal progressions and their rhythms, there is a similarity between the two sorts of accumulates spatial and temporal relationships: a similarity consisting of generalized arching tone-centers linked together by shared background referential materials" .
Another approach of composition techniques for atonal music is given by Allen Forte who developed the theory behind atonal music Forte describes two main operations: transposition an inversion. Transposition can be seen as a rotation of "t" either clockwise or anti-clockwise on a circle, where each note of the chord is rotated equally. For example, if "t" = 2 and the chord is 3 6, transposition (clockwise) will be 5 8. Inversion can be seen as a symmetry with respect to the axis formed by 0 and 6. If we carry on with our example 3 6 becomes 9 6.
An important characteristic are the invariants which are the notes which stay identical after a transformation. It should be noted that no difference is made between the octave in which the note is played so that, for example, all Cs are equivalent, no matter the octave in which they actually occur. This is why the 12-note scale is represented by a circle. This leads us to the definition of the similarity between two chords which considers the subsets and the interval content of each chord .
Reception.
Controversy over the term itself.
The term "atonality" itself has been controversial. Arnold Schoenberg, whose music is generally used to define the term, was vehemently opposed to it, arguing that "The word 'atonal' could only signify something entirely inconsistent with the nature of tone... to call any relation of tones atonal is just as farfetched as it would be to designate a relation of colors aspectral or acomplementary. There is no such antithesis" .
Composer and theorist Milton Babbitt also disparaged the term, saying "The works that followed, many of them now familiar, include the Five Pieces for Orchestra, Erwartung, Pierrot Lunaire, and they and a few yet to follow soon were termed 'atonal,' by I know not whom, and I prefer not to know, for in no sense does the term make sense. Not only does the music employ 'tones,' but it employs precisely the same 'tones,' the same physical materials, that music had employed for some two centuries. In all generosity, 'atonal' may have been intended as a mildly analytically derived term to suggest 'atonic' or to signify 'a-triadic tonality,' but, even so there were infinitely many things the music was not" .
"Atonal" developed a certain vagueness in meaning as a result of its use to describe a wide variety of compositional approaches that deviated from traditional chords and chord progressions. Attempts to solve these problems by using terms such as "pan-tonal", "non-tonal", "multi-tonal", "free-tonal" and "without tonal center" instead of "atonal" have not gained broad acceptance.
Criticism of the concept of atonality.
Composer Anton Webern held that "new laws asserted themselves that made it impossible to designate a piece as being in one key or another" . Composer Walter Piston, on the other hand, said that, out of long habit, whenever performers "play any little phrase they will hear it in some key—it may not be the right one, but the point is they will play it with a tonal sense. ... he more I feel I know Schoenberg's music the more I believe he thought that way himself. ... And it isn't only the players; it's also the listeners. They will hear tonality in everything" .
Donald Jay Grout similarly doubted whether atonality is really possible, because "any combination of sounds can be referred to a fundamental root". He defined it as a fundamentally subjective category: "atonal music is music in which the person who is using the word cannot hear tonal centers" .
One difficulty is that even an otherwise "atonal" work, tonality "by assertion" is normally heard on the thematic or linear level. That is, centricity may be established through the repetition of a central pitch or from emphasis by means of instrumentation, register, rhythmic elongation, or metric accent .
Criticism of atonal music.
Swiss conductor, composer, and musical philosopher Ernest Ansermet, a critic of atonal music, wrote extensively on this in the book "Les fondements de la musique dans la conscience humaine" () ), where he argued that the classical musical language was a precondition for musical expression with its clear, harmonious structures. Ansermet argued that a tone system can only lead to a uniform perception of music if it is deduced from just a single interval. For Ansermet this interval is the fifth .

</doc>
<doc id="45705" url="https://en.wikipedia.org/wiki?curid=45705" title="Inverse transform sampling">
Inverse transform sampling

Inverse transform sampling (also known as inversion sampling, the inverse probability integral transform, the inverse transformation method, Smirnov transform, golden rule,) is a basic method for pseudo-random number sampling, i.e. for generating sample numbers at random from any probability distribution given its cumulative distribution function. 
Inverse transformation sampling takes uniform samples of a number formula_1 between 0 and 1, interpreted as a probability, and then return the largest number formula_2 from the domain of the distribution formula_3 such that formula_4. For example, imagine that formula_3 is the standard normal distribution with mean zero and standard deviation one. The table below shows samples taken from the uniform distribution and their representation on the standard normal distribution. 
We are randomly choosing a proportion of the area under the curve and returning the number in the domain such that exactly this proportion of the area occurs to the left of that number. Intuitively, we are unlikely to choose a number in the far end of tails because there is very little area in them which would require choosing a number very close to zero or one.
Computationally, this method involves computing the quantile function of the distribution — in other words, computing the cumulative distribution function (CDF) of the distribution (which maps a number in the domain to a probability between 0 and 1) and then inverting that function. This is the source of the term "inverse" or "inversion" in most of the names for this method. Note that for a discrete distribution, computing the CDF is not in general too difficult: We simply add up the individual probabilities for the various points of the distribution. For a continuous distribution, however, we need to integrate the probability density function (PDF) of the distribution, which is impossible to do analytically for most distributions (including the normal distribution). As a result, this method may be computationally inefficient for many distributions and other methods are preferred; however, it is a useful method for building more generally applicable samplers such as those based on rejection sampling.
For the normal distribution, the lack of an analytical expression for the corresponding quantile function means that other methods (e.g. the Box–Muller transform) may be preferred computationally. It is often the case that, even for simple distributions, the inverse transform sampling method can be improved on: see, for example, the ziggurat algorithm and rejection sampling. On the other hand, it is possible to approximate the quantile function of the normal distribution extremely accurately using moderate-degree polynomials, and in fact the method of doing this is fast enough that inversion sampling is now the default method for sampling from a normal distribution in the statistical package R.
Definition.
The probability integral transform states that if formula_6 is a continuous random variable with cumulative distribution function formula_7, then the random variable formula_8 has a uniform distribution on The inverse probability integral transform is just the inverse of this: specifically, if formula_9 has a uniform distribution on [0, 1 and if formula_6 has a cumulative distribution formula_7, then the random variable formula_12 has the same distribution as formula_6 .
The method.
The problem that the inverse transform sampling method solves is as follows:
The inverse transform sampling method works as follows:
Expressed differently, given a continuous uniform variable "U" in 1 and an invertible cumulative distribution function "F", the random variable "X" = "F" −1("U") has distribution "F" (or, "X" is distributed "F").
A treatment of such inverse functions as objects satisfying differential equations can be given. Some such differential equations admit explicit power series solutions, despite their non-linearity.
As an example, suppose we have a random variable formula_14 and a cumulative distribution function
In order to perform an inversion we want to solve for formula_16
From here we would perform steps one, two and three
Proof of correctness.
Let "F" be a continuous cumulative distribution function, and let "F"−1 be its inverse function (using the infimum because CDFs are weakly monotonic and right-continuous):
"Proof:"
Reduction of the number of inversions.
In order to obtain a large number (lets say M) of samples one needs to perform the same number of inversions formula_20 of the distribution formula_7. 
One possible way to reduce the number of inversions to only a few while obtaining a large number of samples is the application of the so-called the Stochastic Collocation Monte Carlo sampler (SCMC sampler), within a polynomial chaos expansion framework, allows us the generation of any number of Monte Carlo samples based on only a few inversions of the original distribution and independent samples from a variable for which the inversions are analytically available, like for example the standard normal variable.

</doc>
<doc id="45707" url="https://en.wikipedia.org/wiki?curid=45707" title="Nevi'im">
Nevi'im

Nevi'im (; "Nəḇî'îm", lit. "spokespersons", "Prophets") is the second main division of the Hebrew Bible (the "Tanakh"), between the Torah (instruction) and Ketuvim (writings). It contains two sub-groups, the Former Prophets ( "Nevi'im Rishonim", the narrative books of Joshua, Judges, Samuel and Kings) and the Latter Prophets ( "Nevi'im Aharonim", the books of Isaiah, Jeremiah and Ezekiel and The Twelve minor prophets).
Many of the writings of the Latter Prophets are thought by scholars to be older than the narratives of the Former Prophets which precede them in the canon, and were profoundly influential on the direction and development of Hebrew religion. The Latter Prophets have also had a wide influence on literature and on political and social activism in cultures outside of Judaism.
Synopsis.
In Judaism, "Samuel" and "Kings" are each counted as one book. In addition, twelve relatively short prophetic books are counted as one in a single collection called "Trei Asar" or "The Twelve Minor Prophets". The Jewish tradition thus counts a total of eight books in "Nevi'im" out of a total of 24 books in the entire Tanakh. In the Jewish liturgy, selections from the books of "Nevi'im" known as the "Haftarah" are read publicly in the synagogue after the reading of the Torah on each Shabbat, as well as on Jewish festivals and fast days. The Book of Daniel is part of the Writings, or "Ketuvim", in the Tanakh.
Former Prophets.
The Former Prophets are the books Joshua, Judges, 1st & 2nd Samuel, 1st & 2nd Kings. They contain historical narratives that begin immediately after the death of Moses with the divine appointment of Joshua as his successor, who then leads the people of Israel into the Promised Land, and end with the release from imprisonment of the last king of Judah. Treating Samuel and Kings as single books, they cover:
Joshua.
The Book of Joshua ("Yehoshua" יהושע) contains a history of the Israelites from the death of Moses to that of Joshua. After Moses' death, Joshua, by virtue of his previous appointment as Moses' successor, receives from God the command to cross the Jordan. In execution of this order Joshua issues the requisite instructions to the stewards of the people for the crossing of the Jordan; and he reminds the Reubenites, Gadites, and the half of Manasseh of their pledge given to Moses to help their brethren.
The book essentially consists of three parts:
Judges.
The Book of Judges ("Shoftim" שופטים) consists of three distinct parts:
Samuel.
The Books of Samuel ("Shmu'el" שמואל) consists of five parts:
A conclusion of sorts appears at 1 Kings 1-2, concerning Solomon enacting a final revenge on those who did what David perceived as wrongdoing, and having a similar narrative style. While the subject matter in the Book(s) of Samuel is also covered by the narrative in Chronicles, it is noticeable that the section (2 Sam. 11:2–12:29) containing an account of the matter of Bathsheba is omitted in the corresponding passage in 1 Chr. 20.
Kings.
The Books of Kings ("Melakhim" מלכים) contains accounts of the kings of the ancient Kingdom of Israel and the Kingdom of Judah, and the annals of the Jewish commonwealth from the accession of Solomon until the subjugation of the kingdom by Nebuchadnezzar and the Babylonians.
Latter Prophets.
The Latter Prophets are divided into two groups, the Major prophets (Isaiah, Jeremiah and Ezekiel) and the Twelve Minor Prophets (Hosea, Joel, Amos, Obadiah, Jonah, Micah, Nahum, Habakkuk, Zephaniah, Haggai, Zechariah and Malachi) collected into a single book.
Isaiah.
The 66 chapters of Isaiah ("Yeshayahu" [ישעיהו]) consist primarily of prophecies of the judgments awaiting nations that are persecuting Judah. These nations include Babylon, Assyria, Philistia, Moab, Syria, Israel (the northern kingdom), Ethiopia, Egypt, Arabia, and Phoenicia. The prophecies concerning them can be summarized as saying that God is the God of the whole earth, and that nations which think of themselves as secure in their own power might well be conquered by other nations, at God's command.
Chapter 6 describes Isaiah's call to be a prophet of God. Chapters 36–39 provide historical material about King Hezekiah and his triumph of faith in God. Chapters 24–35, while too complex to characterize easily, are primarily concerned with prophecies of a Messiah, a person anointed or given power by God, and of the Messiah's kingdom, where justice and righteousness will reign. This section is seen by Jews as describing an actual king, a descendant of their great king, David, who will make Judah a great kingdom and Jerusalem a truly holy city.
The prophecy continues with what some scholars have called "The Book of Comfort" which begins in chapter 40 and completes the writing. In the first eight chapters of this book of comfort, Isaiah prophesies the deliverance of the Jews from the hands of the Babylonians and restoration of Israel as a unified nation in the land promised to them by God. Isaiah reaffirms that the Jews are indeed the chosen people of God in chapter 44 and that Hashem is the only God for the Jews (and only the God of the Jews) as he will show his power over the gods of Babylon in due time in chapter 46. In chapter 45:1 the Persian ruler Cyrus is named as the messiah who will overthrow the Babylonians and allow the return of Israel to their original land. The remaining chapters of the book contain prophecies of the future glory of Zion under the rule of a righteous servant (52 & 54). Chapter 53 contains a very poetic prophecy about this servant which is generally considered by Christians to refer to the crucifixion of Jesus, though Jews generally interpret it as a reference to God's people. Although there is still the mention of judgment of false worshippers and idolaters (65 & 66), the book ends with a message of hope of a righteous ruler who extends salvation to his righteous subjects living in the Lord's kingdom on earth.
Jeremiah.
The Book of Jeremiah ("Yirmiyahu" [ירמיהו]) can be divided into twenty-three subsections, and its contents organized into five sub-sections or 'books'.
In Egypt, after an interval, Jeremiah is supposed to have added three sections, viz., ch. 37–39; 40–43; and 44. The main Messianic prophecies are found in 23:1–8; 31:31–40; and 33:14–26.
Jeremiah's prophecies are noted for the frequent repetitions found in them of the same words, phrases, and imagery. They cover the period of about 30 years. They are not in chronological order. Modern scholars do not believe they have reliable theories as to when, where, and how the text was edited into its present form.
Ezekiel.
The Book of Ezekiel ("Yehezq'el" [יחזקאל]) contains three distinct sections.
The Twelve.
The Twelve are:
Liturgical use.
The Haftarah is a text selected from the books of "Nevi'im" that is read publicly in the synagogue after the reading of the Torah on each Shabbat, as well as on Jewish festivals and fast days.
Cantillation.
There is a special cantillation melody for the haftarah, distinct from that of the Torah portion. In some earlier authorities there are references to a tune for the "prophets" generally, distinct from that for the haftarah: this may have been a simplified melody for learning purposes.
Certain cantillation marks and combinations appear in Nevi'im but not within any of the Haftarah selections, and most communities therefore do not have a musical tradition for those marks. J.L. Neeman suggested that "those who recite Nevi'im privately with the cantillation melody may read the words accented by those rare notes by using a "metaphor" based on the melody of those notes in the five books of the Torah, while adhering to the musical scale of the melody for Nevi'im." Neeman includes a reconstruction of the musical scale for the lost melodies of the rare cantillation notes. In the Ashkenazi tradition, the resemblance between the Torah and Haftarah melodies is obvious and it is easy to transpose motifs between the two as suggested by Neeman. In the Sephardi traditions the haftarah melody is considerably more florid than the Torah melody, and usually in a different musical mode, and there are only isolated points of contact between the two.
Extraliturgical public reading.
In some Near and Middle Eastern Jewish traditions, the whole of Nevi'im (as well as the rest of the Tanakh and the Mishnah) is read each year on a weekly rota, usually on Shabbat afternoons. These reading sessions often take place in the synagogue courtyard but are not considered to be synagogue services.
Aramaic translation.
A "targum" is an Aramaic translation of the Hebrew Scriptures that was compiled or written in the Land of Israel or in Babylonia from the Second Temple period until the early Middle Ages (late first millennium). According to the Talmud, the targum on Nevi'im was composed by Jonathan ben Uzziel. Like Targum Onkelos on the Torah, Targum Jonathan is an eastern (Babylonian) targum with early origins in the west (Land of Israel).
Like the targum to the Torah, Targum Jonathan to Nevi'im served a formal liturgical purpose: it was read alternately, verse by verse, or in blocks of up to three verses, in the public reading of the Haftarah and in the study of Nevi'im. Yemenite Jews continue the above tradition to this day, and have thus preserved a living tradition of the Babylonian vocalization for the Targum to Nevi'im.

</doc>
<doc id="45708" url="https://en.wikipedia.org/wiki?curid=45708" title="Dipolar bond">
Dipolar bond

A dipolar bond, also known as a dative covalent bond or coordinate bond is a kind of 2-center, 2-electron covalent bond in which the two electrons derive from the same atom.
Examples.
The term dipolar bond is used in organic chemistry for compounds such as amine oxides for which the electronic structure can be described in terms of the basic amine donating two electrons to an oxygen atom.
The arrow → indicates that both electrons in the bond originate from the amine moiety. In a standard covalent bond each atom contributes one electron. Therefore, an alternative description is that the amine gives away one electron to the oxygen atom, which is then used, with the remaining unpaired electron on the nitrogen atom, to form a standard covalent bond. The process of transferring the electron from nitrogen to oxygen creates formal charges, so the electronic structure may also be depicted as
This electronic structure has an electric dipole, hence the name di-polar bond. In reality, the atoms carry fractional charges; the more electronegative atom of the two involved in the bond will usually carry a fractional negative charge. One exception to this is carbon monoxide. In this case, the carbon atom carries the fractional negative charge despite its being less electronegative than oxygen.
An example of a dative covalent bond is provided by the interaction between a molecule of ammonia, a Lewis base with a lone pair of electrons on the nitrogen atom, and boron trifluoride, a Lewis acid by virtue of the boron atom having an incomplete octet of electrons. In forming the adduct, the boron atom attains an octet configuration.
The electronic structure of a coordination complex can be described in terms of the set of ligands each donating a pair of electrons to a metal centre. For example, in Hexaamminecobalt(III) chloride, each ammonia ligand donates its lone pair of electrons to the cobalt(III) ion. In this case, the bonds formed are described as coordinate bonds.
In all cases the bond is a covalent bond. The prefix dipolar, dative or coordinate merely serves to indicate the origin of the electrons used in creating the bond.

</doc>
<doc id="45710" url="https://en.wikipedia.org/wiki?curid=45710" title="Forensic science">
Forensic science

Forensic science is the application of science to criminal and civil laws. Forensic scientists collect, preserve, and analyse scientific evidence during the course of an investigation. While some forensic scientists travel to the scene to collect the evidence themselves, others occupy a purely laboratory role, performing analysis on objects brought to them by other individuals. In addition to their laboratory role, forensic scientists testify as expert witnesses in both criminal and civil cases and can work for either the prosecution or the defense. While any field could technically be "forensic", certain sections have developed over time to encompass the majority of forensically related cases.
Etymology.
The word "forensic" comes from the Latin term "forēnsis", meaning "of or before the forum." The history of the term originates from Roman times, during which a criminal charge meant presenting the case before a group of public individuals in the forum. Both the person accused of the crime and the accuser would give speeches based on their sides of the story. The case would be decided in favor of the individual with the best argument and delivery. This origin is the source of the two modern usages of the word "forensic" – as a form of legal evidence and as a category of public presentation. In modern use, the term "forensics" in the place of "forensic science" can be considered correct, as the term "forensic" is effectively a synonym for "legal" or "related to courts". However, the term is now so closely associated with the scientific field that many dictionaries include the meaning that equates the word "forensics" with "forensic science".
History.
Early methods.
The ancient world lacked standardized forensic practices, which aided criminals in escaping punishment. Criminal investigations and trials heavily relied on forced confessions and witness testimony. However, ancient sources do contain several accounts of techniques that foreshadow concepts in forensic science that were developed centuries later.
For instance, Archimedes (287–212 BC) invented a method for determining the volume of an object with an irregular shape. According to Vitruvius, a votive crown for a temple had been made for King Hiero II, who had supplied the pure gold to be used, and Archimedes was asked to determine whether some silver had been substituted by the dishonest goldsmith. Archimedes had to solve the problem without damaging the crown, so he could not melt it down into a regularly shaped body in order to calculate its density. Instead he used the law of displacement to prove that the goldsmith had taken some of the gold and substituted silver instead.
The first written account of using medicine and entomology to solve criminal cases is attributed to the book of "Xi Yuan Lu" (translated as "Washing Away of Wrongs"), written in China by Song Ci (宋慈, 1186–1249) in 1248, during the Song Dynasty. In one of the accounts, the case of a person murdered with a sickle was solved by an investigator who instructed everyone to bring his sickle to one location. (He realized it was a sickle by testing various blades on an animal carcass and comparing the wound.) Flies, attracted by the smell of blood, eventually gathered on a single sickle. In light of this, the murderer confessed. The book also offered advice on how to distinguish between a drowning (water in the lungs) and strangulation (broken neck cartilage), along with other evidence from examining corpses on determining if a death was caused by murder, suicide or an accident.
Methods from around the world involved saliva and examination of the mouth and tongue to determine innocence or guilt, as a precursor to the Polygraph test. In ancient India, some suspects were made to fill their mouths with dried rice and spit it back out. Similarly, in Ancient China, those accused of a crime would have rice powder placed in their mouths. In ancient middle-eastern cultures, the accused were made to lick hot metal rods briefly. It is thought that these tests had some validity since a guilty person would produce less saliva and thus have a drier mouth; the accused would be considered guilty if rice was sticking to their mouths in abundance or if their tongues were severely burned due to lack of shielding from saliva.
Origins of forensic science.
In 16th-century Europe, medical practitioners in army and university settings began to gather information on the cause and manner of death. Ambroise Paré, a French army surgeon, systematically studied the effects of violent death on internal organs. Two Italian surgeons, Fortunato Fidelis and Paolo Zacchia, laid the foundation of modern pathology by studying changes that occurred in the structure of the body as the result of disease. In the late 18th century, writings on these topics began to appear. These included "A Treatise on Forensic Medicine and Public Health" by the French physician Francois Immanuele Fodéré and "The Complete System of Police Medicine" by the German medical expert Johann Peter Frank.
As the rational values of the Enlightenment era increasingly permeated society in the 18th century, criminal investigation became a more evidence-based, rational procedure − the use of torture to force confessions was curtailed, and belief in witchcraft and other powers of the occult largely ceased to influence the court's decisions. Two examples of English forensic science in individual legal proceedings demonstrate the increasing use of logic and procedure in criminal investigations at the time. In 1784, in Lancaster, John Toms was tried and convicted for murdering Edward Culshaw with a pistol. When the dead body of Culshaw was examined, a pistol wad (crushed paper used to secure powder and balls in the muzzle) found in his head wound matched perfectly with a torn newspaper found in Toms's pocket, leading to the conviction.
In Warwick in 1816, a farm labourer was tried and convicted of the murder of a young maidservant. She had been drowned in a shallow pool and bore the marks of violent assault. The police found footprints and an impression from corduroy cloth with a sewn patch in the damp earth near the pool. There were also scattered grains of wheat and chaff. The breeches of a farm labourer who had been threshing wheat nearby were examined and corresponded exactly to the impression in the earth near the pool.
Toxicology and ballistics.
A method for detecting arsenious oxide, simple arsenic, in corpses was devised in 1773 by the Swedish chemist Carl Wilhelm Scheele. His work was expanded, in 1806, by German chemist Valentin Ross, who learned to detect the poison in the walls of a victim's stomach.
James Marsh was the first to apply this new science to the art of forensics. He was called by the prosecution in a murder trial to give evidence as a chemist in 1832. The defendant, John Bodle, was accused of poisoning his grandfather with arsenic-laced coffee. Marsh performed the standard test by mixing a suspected sample with hydrogen sulfide and hydrochloric acid. While he was able to detect arsenic as yellow arsenic trisulfide, when it was shown to the jury it had deteriorated, allowing the suspect to be acquitted due to reasonable doubt.
Annoyed by this, Marsh developed a much better test. He combined a sample containing arsenic with sulfuric acid and arsenic-free zinc, resulting in arsine gas. The gas was ignited, and it decomposed to pure metallic arsenic, which, when passed to a cold surface, would appear as a silvery-black deposit. So sensitive was the test, known formally as the Marsh test, that it could detect as little as one-fiftieth of a milligram of arsenic. He first described this test in "The Edinburgh Philosophical Journal" in 1836.
Henry Goddard at Scotland Yard pioneered the use of bullet comparison in 1835. He noticed a flaw in the bullet that killed the victim and was able to trace this back to the mold that was used in the manufacturing process.
Anthropometry.
The French police officer Alphonse Bertillon was the first to apply the anthropological technique of anthropometry to law enforcement, thereby creating an identification system based on physical measurements. Before that time, criminals could only be identified by name or photograph. Dissatisfied with the "ad hoc" methods used to identify captured criminals in France in the 1870s, he began his work on developing a reliable system of anthropometrics for human classification.
Bertillon created many other forensics techniques, including forensic document examination, the use of galvanoplastic compounds to preserve footprints, ballistics, and the dynamometer, used to determine the degree of force used in breaking and entering. Although his central methods were soon to be supplanted by fingerprinting, "his other contributions like the mug shot and the systematization of crime-scene photography remain in place to this day."
Fingerprints.
Sir William Herschel was one of the first to advocate the use of fingerprinting in the identification of criminal suspects. While working for the Indian Civil Service, he began to use thumbprints on documents as a security measure to prevent the then-rampant repudiation of signatures in 1858.
In 1877 at Hooghly (near Calcutta), Herschel instituted the use of fingerprints on contracts and deeds, and he registered government pensioners' fingerprints to prevent the collection of money by relatives after a pensioner's death.
In 1880, Dr. Henry Faulds, a Scottish surgeon in a Tokyo hospital, published his first paper on the subject in the scientific journal "Nature", discussing the usefulness of fingerprints for identification and proposing a method to record them with printing ink. He established their first classification and was also the first to identify fingerprints left on a vial. Returning to the UK in 1886, he offered the concept to the Metropolitan Police in London, but it was dismissed at that time.
Faulds wrote to Charles Darwin with a description of his method, but, too old and ill to work on it, Darwin gave the information to his cousin, Francis Galton, who was interested in anthropology. Having been thus inspired to study fingerprints for ten years, Galton published a detailed statistical model of fingerprint analysis and identification and encouraged its use in forensic science in his book "Finger Prints". He had calculated that the chance of a "false positive" (two different individuals having the same fingerprints) was about 1 in 64 billion.
Juan Vucetich, an Argentine chief police officer, created the first method of recording the fingerprints of individuals on file. In 1892, after studying Galton's pattern types, Vucetich set up the world's first fingerprint bureau. In that same year, Francisca Rojas of Necochea was found in a house with neck injuries whilst her two sons were found dead with their throats cut. Rojas accused a neighbour, but despite brutal interrogation, this neighbour would not confess to the crimes. Inspector Alvarez, a colleague of Vucetich, went to the scene and found a bloody thumb mark on a door. When it was compared with Rojas' prints, it was found to be identical with her right thumb. She then confessed to the murder of her sons.
A Fingerprint Bureau was established in Calcutta (Kolkata), India, in 1897, after the Council of the Governor General approved a committee report that fingerprints should be used for the classification of criminal records. Working in the Calcutta Anthropometric Bureau, before it became the Fingerprint Bureau, were Azizul Haque and Hem Chandra Bose. Haque and Bose were Indian fingerprint experts who have been credited with the primary development of a fingerprint classification system eventually named after their supervisor, Sir Edward Richard Henry. The Henry Classification System, co-devised by Haque and Bose, was accepted in England and Wales when the first United Kingdom Fingerprint Bureau was founded in Scotland Yard, the Metropolitan Police headquarters, London, in 1901. Sir Edward Richard Henry subsequently achieved improvements in dactyloscopy.
In the United States, Dr. Henry P. DeForrest used fingerprinting in the New York Civil Service in 1902, and by December 1905, New York City Police Department Deputy Commissioner Joseph A. Faurot, an expert in the Bertillon system and a fingerprint advocate at Police Headquarters, introduced the fingerprinting of criminals to the United States.
DNA.
DNA fingerprinting was first used in 1984. It was discovered by Sir Alec Jefferys who realized that variation in the genetic code could be used to identify individuals and to tell individuals apart from one another. The first application of DNA profiles was used by Jefferys in a double murder mystery in a small England town called Narborough, Leicestershire in 1983. A 15-year-old school girl by the name of Lynda Mann was raped and murdered in Carlton Hayes psychiatric hospital. The police did not find a suspect but were able to obtain a semen sample.
In 1986, Dawn Ashworth, 15 years old, was also raped and strangled in a nearby village of Enderby. Forensic evidence showed that both killers had the same blood type. Richard Buckland became the suspect because he worked at Carlton Hayes psychiatric hospital, had been spotted near Dawn Ashworth's murder scene and knew unreleased details about the body. He later confessed to Dawn's murder but not Lynda's.
Sir Alec Jefferys was brought into case to analyze the semen samples. He concluded that there was no match between the samples and Buckland, who became the first person to be exonerated using DNA. Jefferys confirmed that the DNA profiles were identical for the two murder semen samples. To find the perpetrator, DNA from entire male population, more than 4,000 aged from 17 to 34, in town was collected. They all were compared to semen samples from the crime.
A friend of Colin Pitchfork was heard saying that he had given his sample to the police claiming to be Colin. Colin Pitchfork was arrested in 1987 and it was found that his DNA profile matched the semen samples from the murder.
Because of this case, DNA databases came into being. There is the national (FBI) and international databases as well as the European countries (ENFSI). These searchable databases are used to match crime scene DNA profiles to those already in database.
Maturation.
By the turn of the 20th century, the science of forensics had become largely established in the sphere of criminal investigation. Scientific and surgical investigation was widely employed by the Metropolitan Police during their pursuit of the mysterious Jack the Ripper, who had killed a series of prostitutes in the 1880s. This case is a watershed in the application of forensic science. Large teams of policemen conducted house-to-house inquiries throughout Whitechapel. Forensic material was collected and examined. Suspects were identified, traced and either examined more closely or eliminated from the inquiry. Police work follows the same pattern today. Over 2000 people were interviewed, "upwards of 300" people were investigated, and 80 people were detained.
The investigation was initially conducted by the Criminal Investigation Department (CID), headed by Detective Inspector Edmund Reid. Later, Detective Inspectors Frederick Abberline, Henry Moore, and Walter Andrews were sent from Central Office at Scotland Yard to assist. Initially, butchers, surgeons and physicians were suspected because of the manner of the mutilations. The alibis of local butchers and slaughterers were investigated, with the result that they were eliminated from the inquiry. Some contemporary figures thought the pattern of the murders indicated that the culprit was a butcher or cattle drover on one of the cattle boats that plied between London and mainland Europe. Whitechapel was close to the London Docks, and usually such boats docked on Thursday or Friday and departed on Saturday or Sunday. The cattle boats were examined, but the dates of the murders did not coincide with a single boat's movements, and the transfer of a crewman between boats was also ruled out.
At the end of October, Robert Anderson asked police surgeon Thomas Bond to give his opinion on the extent of the murderer's surgical skill and knowledge. The opinion offered by Bond on the character of the "Whitechapel murderer" is the earliest surviving offender profile. Bond's assessment was based on his own examination of the most extensively mutilated victim and the post mortem notes from the four previous canonical murders. In his opinion the killer must have been a man of solitary habits, subject to "periodical attacks of homicidal and erotic mania", with the character of the mutilations possibly indicating "satyriasis". Bond also stated that "the homicidal impulse may have developed from a revengeful or brooding condition of the mind, or that religious mania may have been the original disease but I do not think either hypothesis is likely".
"Handbook for Coroners, police officials, military policemen" was written by the Austrian criminal jurist Hans Gross in 1893, and is generally acknowledged as the birth of the field of criminalistics. The work combined in one system fields of knowledge that had not been previously integrated, such as psychology and physical science, and which could be successfully used against crime. Gross adapted some fields to the needs of criminal investigation, such as crime scene photography. He went on to found the Institute of Criminalistics in 1912, as part of the University of Graz' Law School. This Institute was followed by many similar institutes all over the world.
In 1909, Archibald Reiss founded the "Institut de police scientifique" of the University of Lausanne (UNIL), the first school of forensic science in the world. Dr. Edmond Locard, became known as the "Sherlock Holmes of France". He formulated the basic principle of forensic science: "Every contact leaves a trace", which became known as Locard's exchange principle. In 1910, he founded what may have been the first criminal laboratory in the world, after persuading the Police Department of Lyon (France) to give him two attic rooms and two assistants.
Symbolic of the new found prestige of forensics and the use of reasoning in detective work was the popularity of the fictional character Sherlock Holmes, written by Arthur Conan Doyle in the late 19th century. He remains a great inspiration for forensic science, especially for the way his acute study of a crime scene yielded small clues as to the precise sequence of events. He made great use of trace evidence such as shoe and tire impressions, as well as fingerprints, ballistics and handwriting analysis, now known as questioned document examination. Such evidence is used to test theories conceived by the police, for example, or by the investigator himself. All of the techniques advocated by Holmes later became reality, but were generally in their infancy at the time Conan Doyle was writing. In many of his reported cases, Holmes frequently complains of the way the crime scene has been contaminated by others, especially by the police, emphasising the critical importance of maintaining its integrity, a now well-known feature of crime scene examination. He used analytical chemistry for blood residue analysis as well as toxicology examination and determination for poisons. He used ballistics by measuring bullet calibres and matching them with a suspected murder weapon.
Late 19th-Early 20th Centuries Figures.
Hans Gross applied scientific methods to crime scenes and was responsible for the birth of criminalistics.
Edmond Locard expanded on Gross' work with Locard's Exchange Principle which stated "whenever two objects come into contact with one another, materials are exchanged between them". This means that every contact by a criminal leaves a trace. Locard was also known as the "Sherlock Holmes of France".
Alexander Lacassagne, who taught Locard, produced autopsy standards on actual forensic cases.
Alphonse Bertillon was a French criminologist and founder of Anthropometry (scientific study of measurements and proportions of the human body). He used anthropometry for identification, saying each individual is unique and by measuring aspect of physical difference, there could be a personal identification system. He created the Bertillon System around 1879, which was a way to identify criminals and citizens by measuring 20 parts of the body. In 1884, there was over 240 repeat offenders caught through the Bertillon system. Fingerprinting became more reliable than the Bertillon system.
20th century.
Later in the 20th century several British pathologists, Mikey Rochman, Francis Camps, Sydney Smith and Keith Simpson pioneered new forensic science methods. Alec Jeffreys pioneered the use of DNA profiling in forensic science in 1984. He realized the scope of DNA fingerprinting, which uses variations in the genetic code to identify individuals. The method has since become important in forensic science to assist police detective work, and it has also proved useful in resolving paternity and immigration disputes. DNA fingerprinting was first used as a police forensic test to identify the rapist and killer of two teenagers, Lynda Mann and Dawn Ashworth, who were both murdered in Narborough, Leicestershire, in 1983 and 1986 respectively. Colin Pitchfork was identified and convicted of murder after samples taken from him matched semen samples taken from the two dead girls.
Forensic science has been fostered by a number of national forensic science learned bodies including the American Academy of Forensic Sciences (founded 1948), publishers of the "Journal of Forensic Sciences"; the Canadian Society of Forensic Science (founded 1953), publishers of the "Journal of the Canadian Society of Forensic Science"; the British Academy of Forensic Sciences (founded 1960), publishers of "Medicine, science and the law", and the Australian Academy of Forensic Sciences (founded 1967), publishers of the "Australian Journal of Forensic Sciences".
Questionable techniques.
Some forensic techniques, believed to be scientifically sound at the time they were used, have turned out later to have much less scientific merit or none. Some such techniques include:
Litigation science.
Litigation science describes analysis or data developed or produced "expressly" for use in a trial versus those produced in the course of independent research. This distinction was made by the US 9th Circuit Court of Appeals when evaluating the admissibility of experts.
This uses demonstrative evidence, which is evidence created in preparation of trial by attorneys or paralegals.
International demographics.
In the United States there are over 14,400 forensic science technicians, as of 2014.
Examples in popular culture.
The Argentinean writer Jorge Luis Borges claims that the police novel genre is inaugurated with Edgar Allan Poe's short story, "The Murders in the Rue Morgue". But it was Sherlock Holmes, the fictional character created by Sir Arthur Conan Doyle in works produced from 1887 to 1915, who first used forensic science as one of his investigating methods. Conan Doyle credited the inspiration for Holmes on his teacher at the medical school of the University of Edinburgh, the gifted surgeon and forensic detective Joseph Bell.
Agatha Christie's Hercule Poirot and Miss Marple, in books, films, and television series, use similar methods.
The comic strip "Dick Tracy" also featured a detective using a considerable number of forensic methods, although sometimes the methods were more fanciful than actually possible.
In comic books published by DC Comics, Barry Allen (alter ego of The Flash) is a forensic scientist for the Central City police department.
Defense attorney Perry Mason occasionally used forensic techniques, both in the novels and television series.
One of the earliest television series to focus on the scientific analysis of evidence was "Quincy, M.E." (1976–83, and based loosely on an even earlier Canadian series titled "Wojeck"), with the title character, a medical examiner working in Los Angeles solving crimes through careful study. The opening theme of each episode featured a clip of the title character, played by Jack Klugman, beginning a lecture to a group of police officers with "Gentlemen, you are about to enter the most fascinating sphere of police work, the world of forensic medicine." Later series with similar premises include "Dexter", "The Mentalist", "", "Hawaii Five-0", "Cold Case", "Bones", "Law & Order", "Body of Proof", "NCIS", "Criminal Minds", "Silent Witness", "Detective Conan", "Midsomer Murders" and "Waking the Dead", depict glamorized versions of the activities of 21st-century forensic scientists. Some claim these TV shows have changed individuals' expectations of forensic science, an influence termed the "CSI effect".
Non-fiction TV shows such as "Forensic Files", "The New Detectives", "American Justice", and Dayle Hinman's "" have also popularized forensic science.
The Ace Attorney series features forensic science, mainly in ' and the DS-only case in '.
Controversies.
Questions about certain areas of forensic science, such as fingerprint evidence and the assumptions behind these disciplines have been brought to light in some publications including the "New York Post". The article stated that "No one has proved even the basic assumption: That everyone's fingerprint is unique." The article also stated that "Now such assumptions are being questioned - and with it may come a radical change in how forensic science is used by police departments and prosecutors." Law professor Jessica Gabel said on NOVA that forensic science "lacks the rigors, the standards, the quality controls and procedures that we find, usually, in science."
In America, on 25 June 2009, the Supreme Court issued a 5-to-4 decision in "Melendez-Diaz v. Massachusetts" stating that crime laboratory reports may not be used against criminal defendants at trial unless the analysts responsible for creating them give testimony and subject themselves to cross-examination. The Supreme Court cited the National Academies report "Strengthening Forensic Science in the United States" in their decision. Writing for the majority, Justice Antonin Scalia referred to the National Research Council report in his assertion that "Forensic evidence is not uniquely immune from the risk of manipulation."
In 2009, scientists indicated that it is possible to fabricate DNA evidence, therefore suggesting it is possible to falsely accuse or acquit a person or persons using forged evidence.
In America, another area of forensic science that has come under question in recent years is the lack of laws requiring the accreditation of forensic labs. Some states require accreditation, but some states do not. Because of this, many labs have been caught performing very poor work resulting in false convictions or acquittals. For example, it was discovered after an audit of the Houston Police Department in 2002 that the lab had fabricated evidence which led George Rodriguez being convicted of raping a fourteen-year-old girl. The former director of the lab, when asked, said that the total number of cases that could have been contaminated by improper work could be in the range of 5,000 to 10,000. This could have been avoided if the lab had been accredited by organizations such as ASCLD/Lab, which require crime labs to undergo rigorous assessments to show that they are able to perform multiple tests accurately. Once they become accredited, they are periodically re-evaluated to ensure that the lab is still functioning at its best. Periodic evaluations of a lab's performance by an independent organization will help to prevent scandals from occurring in forensic science laboratories.
Although forensic science has greatly enhanced the investigator's ability to solve crimes, it has limitations and must be scrutinized in and out of the courtroom to avoid the occurrence of wrongful convictions.
Forensic science and humanitarian work.
The International Committee of the Red Cross (ICRC) uses forensic science for humanitarian purposes to clarify the fate of missing persons after armed conflict, disasters or migration, and is one of the services related to Restoring Family Links and Missing Persons. Knowing what has happened to a missing relative can often make it easier to proceed with the grieving process and move on with life for families of missing persons.
Forensic science is used by various other organizations to clarify the fate and whereabouts of persons who have gone missing. Examples include the NGO Argentine Forensic Anthropology Team, working to clarify the fate of people who disappeared during the period of the 1976–1983 military dictatorship. The International Commission on Missing Persons (ICMP) uses forensic science to find missing persons, for example after the conflicts in the Balkans.

</doc>
<doc id="45712" url="https://en.wikipedia.org/wiki?curid=45712" title="Eggplant">
Eggplant

Eggplant ("Solanum melongena") or aubergine is a species of nightshade grown for its edible fruit.
"Eggplant" is the common name in North American and Australian English but British English uses "aubergine". It is known in South Asia, Southeast Asia and South Africa as brinjal. Other common names are melongene, garden egg, or guinea squash.
The fruit is widely used in cooking. As a member of the genus "Solanum", it is related to both the tomato and the potato. It was originally domesticated from the wild nightshade species, the thorn or bitter apple, "S. incanum", probably with two independent domestications, one in the region of South Asia, and one in East Asia.
Description.
The eggplant is a delicate, tropical perennial often cultivated as a tender or half-hardy annual in temperate climates. It grows tall, with large, coarsely lobed leaves that are long and broad. Semiwild types can grow much larger, to with large leaves over long and broad. The stem is often spiny. The flower is white to purple, with a five-lobed corolla and yellow stamens. The egg-shaped glossy purple fruit has white flesh with a meaty texture. The cut surface of the flesh rapidly turns brown when the fruit is cut open. On wild plants, the fruit is less than in diameter, but very much larger in cultivated forms, reaching or more in length.
Botanically classified as a berry, the fruit contains numerous small, soft seeds which, though edible, taste bitter because, the plant being related to tobacco, they contain nicotinoid alkaloids.
Etymology and regional names.
The plant and vegetable have a profusion of English names: "eggplant" (North America, Australia), "aubergine" (Britain), "brinjal" (South Asia, South Africa, Malaysia, Singapore, and West Indies), "baingan" and " baigan" (South Asia, Trinidad), "melongene" (Caribbean), and formerly "melongena" and "mad-apple". 
The word "eggplant" was first recorded in 1767, and was originally applied to white varieties; some 18th-century European cultivars were small, round, yellow or white, resembling goose or hen's eggs.
The other names, even "mad-apple", all ultimately derive from a Dravidian word with reflexes in modern Malayalam "vaṟutina" and Tamil "vaṟutuṇai", transmitted through Sanskrit "vātigama", Prakrit "vāiṃaṇa", Persian بادنجان "bādingān", and Arabic "bāḏinjān" باذنجان.
The Arabic name is the common source of all the European names for this plant, but through two distinct paths of transmission, with the "melongene" family coming through the eastern Mediterranean, and the "aubergine" family through the western Mediterranean.
In the western Mediterranean, the Arabic "(al)-bāḏinjān" was borrowed as Spanish "alberengena" and "berenjena", Catalan "albergínia", and Portuguese "beringela", whence the modern French "aubergine" (and the earlier "albergine", "albergaine", "albergame", "belingèle"), the source of the British English "aubergine".
In the eastern Mediterranean, "bāḏinjān" was borrowed into Byzantine Greek first as ματιζάνιον, then modified to μελιτζάνα "melitzána" and "melanzana", influenced by Greek μελανο- 'black'. This came into Italian as "melongiana" and "melanzana", and into Medieval Latin as "melongena". The Latin name was later used by Tournefort as a genus name, then by Linnaeus as a species name. These forms came into English; though "melongene" has become obsolete, as have the French "merangène", "melongène/melanjan", it persists in the Caribbean English "melongene" or "meloongen". In Italian, "melanzana" was interpreted as "mela insana" 'crazy apple', this was translated into English as "mad apple".
The Anglo-Indian name "brinjal" or "brinjaul" comes from the Portuguese "bringella", "bringiela", or "beringela", whereas the name "baingan" or "baigan", also sometimes used in English in South Asia as well as in Trinidad, appears to be reborrowed from the Persian.
History.
The plant species originated in cultivation. It has been cultivated in southern and eastern Asia since prehistory. The first known written record of the plant is found in "Qimin Yaoshu" , an ancient Chinese agricultural treatise completed in 544. The numerous Arabic and North African names for it, along with the lack of the ancient Greek and Roman names, indicate it was introduced throughout the Mediterranean area by the Arabs in the early Middle Ages. A book on agriculture by Ibn Al-Awwam in 12th century Arabic Spain described how to grow aubergines. There are records from later medieval Catalan and Spanish.
The aubergine is unrecorded in England until the 16th century. An English botany book in 1597 stated:
Because of the plant's relationship with the Solanaceae (nightshade) family, the fruit was at one time believed to be extremely poisonous. The flowers and leaves can be poisonous if consumed in large quantities due to the presence of solanine.
Cultivated varieties.
Different varieties of the plant produce fruit of different size, shape, and color, though typically purple. The most widely cultivated varieties (cultivars) in Europe and North America today are elongated ovoid, 12–25 cm long ( to 9 in) and 6–9 cm broad (2 to 4 in) in a dark purple skin.
A much wider range of shapes, sizes and colors is grown in India and elsewhere in Asia. Larger varieties weighing up to a kilogram (2.2 pounds) grow in the region between the Ganges and Yamuna rivers, while smaller varieties are found elsewhere. Colors vary from white to yellow or green, as well as reddish-purple and dark purple. Some cultivars have a color gradient, from white at the stem to bright pink to deep purple or even black. Green or purple cultivars in white striping also exist. Chinese varieties are commonly shaped like a narrower, slightly pendulous cucumber, and are sometimes called Japanese eggplants in North America.
Oval or elongated oval-shaped and black-skinned cultivars include 'Harris Special Hibush', 'Burpee Hybrid', 'Bringal Bloom', 'Black Magic', 'Classic', 'Dusky', and 'Black Beauty'. Slim cultivars in purple-black skin include 'Little Fingers', 'Ichiban', 'Pingtung Long', and 'Tycoon'; in green skin, 'Louisiana Long Green' and 'Thai (Long) Green'; in white skin, 'Dourga'. Traditional, white-skinned, egg-shaped cultivars include 'Casper' and 'Easter Egg'. Bicolored cultivars with color gradient include 'Rosa Bianca', 'Violetta di Firenze', 'Bianca Smufata di Rosa' (heirloom), and 'Prosperosa' (heirloom). Bicolored cultivars with striping include 'Listada de Gandia' and 'Udumalapet'. In some parts of India, miniature varieties (most commonly called "vengan") are popular.
Cooking.
The raw fruit can have a somewhat bitter taste, but becomes tender when cooked and develops a rich, complex flavor. Many recipes advise salting, rinsing and draining of the sliced fruit (known as "degorging"), to soften it and to reduce the amount of fat absorbed during cooking, but mainly to remove the bitterness of the earlier cultivars. Some modern varieties—including large, purple varieties commonly imported into western Europe—do not need this treatment. The fruit is capable of absorbing large amounts of cooking fats and sauces, making for very rich dishes, but salting reduces the amount of oil absorbed. Eggplant, due to its texture and bulk, is sometimes used as a meat substitute in vegan and vegetarian cuisine.
The fruit flesh is smooth, as in the related tomato. The numerous seeds are soft and edible along with the rest of the fruit. The thin skin is also edible.
Eggplant is used in the cuisine of many countries. Eggplant is widely used in its native Indian cuisine, for example in "sambhar", "dalma" (a "dal" preparation with vegetables, native to Odisha), chutney, curry, and "achaar". Owing to its versatile nature and wide use in both everyday and festive Indian food, it is often described (under the name "baingan" or "brinjal") as the "king of vegetables". Roasted, skinned, mashed, mixed with onions, tomatoes and spices and then slow cooked gives the South Asian dish "baingan bharta" or "gojju", similar to "salată de vinete" in Romania. Another version of the dish, "begun-pora" (eggplant charred or burnt), is very popular in Bangladesh and the east Indian states of Odisha and West Bengal where the pulp of the vegetable is mixed with raw chopped shallot, green chilies, salt, fresh coriander and mustard oil. Sometimes fried tomatoes and deep-fried potatoes are also added, creating a dish called "begun bhorta". In a dish called "bharli vangi", brinjal is stuffed with ground coconut, peanuts, and masala, and then cooked in oil.
It is often stewed, as in the French ratatouille, or deep fried as in the Italian "parmigiana di melanzane", the Turkish "karnıyarık" or Turkish and Greek "musakka/moussaka", and Middle-Eastern and South Asian dishes. Eggplants can also be battered before deep-frying and served with a sauce made of tahini and tamarind. In Iranian cuisine, it is blended with whey as "kashk e-bademjan", tomatoes as "mirza ghasemi" or made into stew as "khoresh-e-bademjan". It can be sliced and deep-fried, then served with plain yogurt, (optionally) topped with a tomato and garlic sauce, such as in the Turkish dish "patlıcan kızartması" (meaning fried aubergines) or without yogurt as in "patlıcan şakşuka". Perhaps the best-known Turkish eggplant dishes are "imam bayıldı" (vegetarian) and "karnıyarık" (with minced meat).
It may also be roasted in its skin until charred, so the pulp can be removed and blended with other ingredients, such as lemon, tahini, and garlic, as in the Arab "baba ghanoush" and the similar Greek "melitzanosalata". A mix of roasted eggplant, roasted red peppers, chopped onions, tomatoes, mushrooms, carrots, celery and spices is called "zacuscă" in Romania , and "ajvar" or "pinjur" in the Balkans. A Spanish dish called "escalivada" in Catalonia calls for strips of roasted aubergine, sweet pepper, onion and tomato. In Andalusia, eggplant is mostly cooked thinly sliced, deep fried in olive oil and served hot with honey ("Berenjenas a la Cordobesa"). In the La Mancha region of central Spain a small eggplant is pickled in vinegar, paprika, olive oil and red peppers. The result is berenjena de Almagro, Ciudad Real. A Levantine specialty is Makdous, another pickling of eggplants, stuffed with red peppers and walnuts in olive oil.
Eggplant can be hollowed out and stuffed with meat, rice, or other fillings, and then baked. In the Caucasus, for example, it is fried and stuffed with walnut paste to make "nigvziani badrijani".
Cultivation.
In tropical and subtropical climates, eggplant can be sown directly into the garden. Eggplant grown in temperate climates fares better when transplanted into the garden after all danger of frost is passed. Seeds are typically started eight to ten weeks prior to the anticipated frost-free date.
Many of the pests and diseases that afflict other Solanaceous plants, such as tomato, pepper (capsicum), and potato, are also troublesome to eggplants. For this reason, it should generally not be planted in areas previously occupied by its close relatives. However, since eggplants can be particularly susceptible to pests such as white flies, they are sometimes grown with slightly less susceptible plants, such as pepper, as a sacrificial trap crop. 
Common North American pests include the potato beetles, flea beetles, aphids, white flies and spider mites. (Adults can be removed by hand, though flea beetles can be especially difficult to control.) A commonly used herbicide for eggplant is dimethyl tetrachloroterephthalate. Good sanitation and crop rotation practices are extremely important for controlling fungal disease, the most serious of which is "Verticillium". Four years should separate successive crops of eggplants to reduce pest pressure.
Spacing should be between plants, depending on cultivar, and between rows, depending on the type of cultivation equipment being used. Mulching helps conserve moisture and prevent weeds and fungal diseases. The flowers are relatively unattractive to bees and the first blossoms often do not set fruit. Hand pollination improves the set of the first blossoms. Growers typically cut fruits from the vine just above the calyx owing to the somewhat woody stems. Flowers are complete, containing both female and male structures, and may be self-pollinated or cross-pollinated.
"Solanum melongena" is included in the Tasmanian Fire Service's list of low flammability plants, indicating that it is suitable for growing within a building protection zone.
Production.
In 2013, global production of eggplants was 49.4 million tonnes, with 57% of output coming from China alone. India (27% of world total), Iran, Egypt and Turkey were also major producers which, when combined with other Asian countries, constituted 94% of world production. More than are devoted to the cultivation of eggplants in the world. 
Nutrition.
Nutritionally, raw eggplant is low in fat, protein, dietary fiber and carbohydrates (table). It also provides low amounts of essential nutrients, with only manganese having a moderate percentage (11%) of the Daily Value (table).
Minor changes in nutrient composition occur with season and environment (open field or greenhouse) of cultivation and genotype.
One of the compounds in eggplant thought to be beneficial to human health is chlorogenic acid. However, cooking at higher temperatures does somewhat alter the amount of chlorogenic acid in eggplant. 
Chemistry.
Color of purple skin varieties is due to an anthocyanin (nasunin or delphinidin-3-(p-coumaroylrutinoside)-5-glucoside).
Browning of eggplant flesh results from the oxidation of polyphenols, such as the most abundant phenolic compound in the fruit, chlorogenic acid.
Allergies.
Case reports of itchy skin or mouth, mild headache, and stomach upset after handling or eating eggplant have been reported anecdotally and published in medical journals (see also oral allergy syndrome). A 2008 study of a sample of 741 people in India, where eggplant is commonly consumed, found nearly 10% reported some allergic symptoms after consuming eggplant, with 1.4% showing symptoms within less than two hours.
Contact dermatitis from eggplant leaves and allergy to eggplant flower pollen have also been reported. Individuals who are atopic (genetically predisposed to developing certain allergic hypersensitivity reactions) are more likely to have a reaction to eggplant, which may be because eggplant is high in histamines. A few proteins and at least one secondary metabolite have been identified as potential allergens. Cooking eggplant thoroughly seems to preclude reactions in some individuals, but at least one of the allergenic proteins survives the cooking process.
Varieties.
Genetically engineered variety.
Bt brinjal is a transgenic eggplant that contains a gene from the soil bacterium "Bacillus thuringiensis". This variety was designed to give the plant resistance to lepidopteran insects like the brinjal fruit and shoot borer ("Leucinodes orbonalis") and fruit borer ("Helicoverpa armigera").
On 9 February 2010, the Environment Ministry of India imposed a moratorium on the cultivation of Bt brinjal after protests against regulatory approval of cultivated Bt brinjal in 2009, stating the moratorium would last "for as long as it is needed to establish public trust and confidence". This decision was deemed controversial, as it deviated from previous science-based, objective successes of other genetically modified crops in India.
Synonyms.
The eggplant is quite often featured in the older scientific literature under the junior synonyms "S. ovigerum" and "S. trongum". Several other now-invalid names have been uniquely applied to it:
A number of subspecies and varieties have been named, mainly by Dikii, Dunal, and (invalidly) by Sweet. Names for various eggplant types, such as "agreste, album, divaricatum, esculentum, giganteum, globosi, inerme, insanum, leucoum, luteum, multifidum, oblongo-cylindricum, ovigera, racemiflorum, racemosum, ruber, rumphii, sinuatorepandum, stenoleucum, subrepandum, tongdongense, variegatum, violaceum" and "viride", are not considered to refer to anything more than cultivar groups at best. On the other hand, "Solanum incanum" and cockroach berry ("S. capsicoides"), other eggplant-like nightshades described by Linnaeus and Allioni, respectively, were occasionally considered eggplant varieties, but this is not correct.
The eggplant has a long history of taxonomic confusion with the scarlet and Ethiopian eggplants, known as "gilo" and "nakati", and described by Linnaeus as "S. aethiopicum". The eggplant was sometimes considered a variety "violaceum" of that species. "S. violaceum" of de Candolle applies to Linnaeus' "S. aethiopicum". There is an actual "S. violaceum", an unrelated plant described by Ortega, which used to include Dunal's "S. amblymerum" and was often confused with the same author's "S. brownii".
Like the potato and "Solanum lichtensteinii", but unlike the tomato, which then was generally put in a different genus, the eggplant was also described as "S. esculentum", in this case once more in the course of Dunal's work. He also recognized varieties "aculeatum", "inerme" and "subinerme" at that time. Similarly, H.C.F. Schuhmacher and Peter Thonning named the eggplant as "S. edule", which is also a junior synonym of sticky nightshade ("S. sisymbriifolium"). Scopoli's "S. zeylanicum" refers to the eggplant, and that of Blanco to "S. lasiocarpum".
Folklore.
A 13th century Italian tradition says that the eggplant can cause insanity.
In 19th century Egypt, it was said that insanity was "more common and more violent" when the eggplant is in season, that is, in the summer.

</doc>
<doc id="45714" url="https://en.wikipedia.org/wiki?curid=45714" title="Horseradish">
Horseradish

Horseradish ("Armoracia rusticana", syn. "Cochlearia armoracia") is a perennial plant of the Brassicaceae family (which also includes mustard, wasabi, broccoli, and cabbage). It is a root vegetable used as a spice.
The plant is probably native to southeastern Europe and western Asia. It is now popular around the world. It grows up to tall, and is cultivated primarily for its large, white, tapered root.
The intact horseradish root has hardly any aroma. When cut or grated, however, enzymes from the now-broken plant cells break down sinigrin (a glucosinolate) to produce allyl isothiocyanate (mustard oil), which irritates the mucous membranes of the sinuses and eyes. Grated mash should be used immediately or preserved in vinegar for best flavor. Once exposed to air or heat it will begin to lose its pungency, darken in color, and become unpleasantly bitter tasting over time.
History.
Horseradish is probably indigenous to temperate Eastern Europe, where its Slavic name "chren" seemed to Augustin Pyramus de Candolle more primitive than any Western synonym. Horseradish has been cultivated since antiquity. According to Greek mythology, the Delphic Oracle told Apollo that the horseradish was worth its weight in gold. Horseradish was known in Egypt in 1500 BC. Dioscorides listed horseradish equally as "Persicon sinapi" ("Diosc." 2.186) or "Sinapi persicum" ("Diosc." 2.168), which Pliny's Natural History reported as "Persicon napy"; Cato discusses the plant in his treatises on agriculture, and a mural in Pompeii shows the plant. Horseradish is probably the plant mentioned by Pliny the Elder in his "Natural History" under the name of "Amoracia", and recommended by him for its medicinal qualities, and possibly the Wild Radish, or "raphanos agrios" of the Greeks. The early Renaissance herbalists Pietro Andrea Mattioli and John Gerard showed it under "Raphanus". Though its modern Linnaean genus "Armoracia" was first applied to it by Heinrich Bernhard Ruppius, in his "Flora Jenensis", 1745, Linnaeus called it "Coclearia armoracia".
Both root and leaves were used as a medicine during the Middle Ages and the root was used as a condiment on meats in Germany, Scandinavia, and Britain. It was introduced to North America during European colonialization; both George Washington and Thomas Jefferson mention horseradish in garden accounts.
William Turner mentions horseradish as "Red Cole" in his "Herbal" (1551–1568), but not as a condiment. In "The Herball, or Generall Historie of Plantes" (1597), John Gerard describes it under the name of "raphanus rusticanus", stating that it occurs wild in several parts of England. After referring to its medicinal uses, he says:
The word "horseradish" is attested in English from the 1590s. It combines the word "horse" (formerly used in a figurative sense to mean strong or coarse) and the word "radish".
Cultivation.
Horseradish is perennial in hardiness zones 2–9 and can be grown as an annual in other zones, although not as successfully as in zones with both a long growing season and winter temperatures cold enough to ensure plant dormancy. After the first frost in the autumn kills the leaves, the root is dug and divided. The main root is harvested and one or more large offshoots of the main root are replanted to produce next year's crop. Horseradish left undisturbed in the garden spreads via underground shoots and can become invasive. Older roots left in the ground become woody, after which they are no longer culinarily useful, although older plants can be dug and re-divided to start new plants. The early season leaves can be distinctively different, asymmetric spiky, before the mature typical flat broad leaves start to be developed.
Pests and diseases.
Widely introduced by accident, "cabbageworms", the larvae of "Pieris rapae", the Small White butterfly, are a common caterpillar pest in horseradish. The adults are white butterflies with black spots on the forewings that are commonly seen flying around plants during the day. The caterpillars are velvety green with faint yellow stripes running lengthwise down the back and sides. Full grown caterpillars are about in length. They move sluggishly when prodded. They overwinter in green pupal cases. Adults start appearing in gardens after the last frost and are a problem through the remainder of the growing season. There are three to five overlapping generations a year. Mature caterpillars chew large, ragged holes in the leaves leaving the large veins intact. Handpicking is an effective control strategy in home gardens.
Culinary uses.
The distinctive pungent taste of horseradish is from the compound allyl isothiocyanate. Upon crushing the flesh of horseradish, the enzyme myrosinase is released and acts on the glucosinolates sinigrin and gluconasturtiin, which are precursors to the allyl isothiocyanate. The allyl isothiocyanate serves the plant as a natural defense against herbivores. Since allyl isothiocyanate is harmful to the plant itself, it is stored in the harmless form of the glucosinolate, separate from the myrosinase enzyme. When an animal chews the plant, the allyl isothiocyanate is released, repelling the animal. Allyl isothiocyanate is an unstable compound, degrading over the course of days at 37 °C. Because of this instability, horseradish sauces lack the pungency of the freshly crushed roots.
Cooks use the terms "horseradish" or "prepared horseradish" to refer to the grated root of the horseradish plant mixed with vinegar. Prepared horseradish is white to creamy-beige in color. It will keep for months refrigerated but eventually will darken, indicating it is losing flavour and should be replaced. The leaves of the plant, while edible, are not commonly eaten, and are referred to as "horseradish greens", which have a flavor similar to that of the roots.
Horseradish sauce.
Horseradish sauce made from grated horseradish root and vinegar is a popular condiment in the United Kingdom and in Poland. In the UK, it is usually served with roast beef, often as part of a traditional Sunday roast; but can be used in a number of other dishes also, including sandwiches or salads. A variation of horseradish sauce, which in some cases may substitute the vinegar with other products like lemon juice or citric acid, is known in Germany as "Tafelmeerrettich". Also popular in the UK is Tewkesbury mustard, a blend of mustard and grated horseradish originating in medieval times and mentioned by Shakespeare (Falstaff says: "his wit's as thick as Tewkesbury Mustard" in Henry IV Part II). A very similar mustard, called "Krensenf" or "Meerrettichsenf", is popular in Austria and parts of Eastern Germany. In France, "sauce au raifort" is popular in Alsatian cuisine.
In the U.S., the term "horseradish sauce" refers to grated horseradish combined with mayonnaise or salad dressing. Prepared horseradish is a common ingredient in Bloody Mary cocktails and in cocktail sauce, and is used as a sauce or sandwich spread. Horseradish cream is a mixture of horseradish and sour cream and is served alongside au jus for a prime rib dinner.
Vegetable.
In Central and Eastern Europe horseradish is called "khren" (in various spellings like "kren") in many Slavic languages, in Austria, in parts of Germany (where the other German name "Meerrettich" isn't used), in North-East Italy, and in Yiddish ("כריין" transliterated as "khreyn").
There are two varieties of khreyn. "Red" khreyn is mixed with red beet (beetroot) and "white" khreyn contains no beet. It is popular in Ukraine (under the name of , "khrin"), in Belarus (under the name of , "chren"), in Poland (under the name of ), in the Czech Republic (), in Russia (, "khren"), in Hungary (), in Romania (), in Lithuania (), in Bulgaria (, "khryan"), and in Slovakia (under the name of ). Having this on the table is a part of Christian Easter and Jewish Passover tradition in Eastern and Central Europe.
Relation to wasabi.
The Japanese condiment wasabi, although traditionally prepared from the wasabi plant, is now usually made with horseradish due to the scarcity of the wasabi plant. The Japanese botanical name for horseradish is , or "Western wasabi". Both plants are members of the family Brassicaceae.
Nutritional content.
In a 100 gram amount, prepared horseradish provides 48 calories and has high content of vitamin C with moderate content of sodium, folate and dietary fiber, while other essential nutrients are negligible in content. In a typical serving of one tablespoon (15 grams), horseradish supplies no significant nutrient content.
Horseradish contains volatile oils, notably mustard oil, and allyl isothiocyanate.
Biomedical uses.
The enzyme horseradish peroxidase (HRP), found in the plant, is used extensively in molecular biology and biochemistry.

</doc>
<doc id="45715" url="https://en.wikipedia.org/wiki?curid=45715" title="Arecaceae">
Arecaceae

The Arecaceae are a botanical family of perennial lianas, shrubs, and trees commonly known as palm trees. (Owing to historical usage, the family is alternatively called Palmae.) They are flowering plants, the only family in the monocot order Arecales. Roughly 200 genera with around 2600 species are currently known, most of them restricted to tropical, subtropical, and warm temperate climates. Most palms are distinguished by their large, compound, evergreen leaves arranged at the top of an unbranched stem. However, palms exhibit an enormous diversity in physical characteristics and inhabit nearly every type of habitat within their range, from rainforests to deserts.
Palms are among the best known and most extensively cultivated plant families. They have been important to humans throughout much of history. Many common products and foods are derived from palms, and palms are also widely used in landscaping, making them one of the most economically important plants. In many historical cultures, palms were symbols for such ideas as victory, peace, and fertility. For inhabitants of cooler climates today, palms symbolize the tropics and vacations.
Morphology.
Whether as shrubs, trees, or vines, palms have two methods of growth: solitary or clustered. The common representation is that of a solitary shoot ending in a crown of leaves. This monopodial character may be exhibited by prostrate, trunkless, and trunk-forming members. Some common palms restricted to solitary growth include "Washingtonia" and "Roystonea". Palms may instead grow in sparse though dense clusters. The trunk develops an axillary bud at a leaf node, usually near the base, from which a new shoot emerges. The new shoot, in turn, produces an axillary bud and a clustering habit results. Exclusively sympodial genera include many of the rattans, "Guihaia", and "Rhapis". Several palm genera have both solitary and clustering members. Palms which are usually solitary may grow in clusters, and "vice versa". These aberrations suggest the habit operates on a single gene.
Palms have large, evergreen leaves that are either palmately ('fan-leaved') or pinnately ('feather-leaved') compound and spirally arranged at the top of the stem. The leaves have a tubular sheath at the base that usually splits open on one side at maturity. The inflorescence is a spadix or spike surrounded by one or more bracts or spathes that become woody at maturity. The flowers are generally small and white, radially symmetric, and can be either uni- or bisexual. The sepals and petals usually number three each, and may be distinct or joined at the base. The stamens generally number six, with filaments that may be separate, attached to each other, or attached to the pistil at the base. The fruit is usually a single-seeded drupe (sometimes berry-like) but some genera (e.g. "Salacca") may contain two or more seeds in each fruit.
The Arecaceae are notable among monocots for their height and for the size of their seeds, leaves, and inflorescences. "Ceroxylon quindiuense", Colombia's national tree, is the tallest monocot in the world, reaching up to 60 m tall. The "coco de mer" ("Lodoicea maldivica") has the largest seeds of any plant, 40–50 cm in diameter and weighing 15–30 kg each. Raffia palms ("Raphia" spp.) have the largest leaves of any plant, up to 25 m long and 3 m wide. The "Corypha" species have the largest inflorescence of any plant, up to 7.5 m tall and containing millions of small flowers. "Calamus" stems can reach 200 m in length.
Range and habitat.
Most palms grow in the tropics. They are abundant throughout the tropics, and thrive in almost every habitat they are in. Their diversity is highest in wet, lowland tropical forests, especially in ecological "hotspots" such as Madagascar, which has more endemic palms than all of Africa. Colombia may have the highest number of palm species in one country. Palms are most commonly seen throughout Africa, South America, the Arabian peninsula, South and Southeast Asia, northern Australia, the islands of tropical and subtropical parts of the Pacific Ocean, Mexico, Puerto Rico, and some U.S. states including California, Florida, and Hawaii.
Only about 130 palm species grow naturally beyond the tropics, mostly in the subtropics. The northernmost native palm is "Chamaerops humilis", which reaches 44°N latitude in southern France. The southernmost palm is the "Rhopalostylis sapida", which reaches 44°S on the Chatham Islands where an oceanic climate prevails. Some palms, such as the "Trachycarpus fortunei", grow well under cultivation in temperate climates, some as far north as 50°N in oceanic climates (Ireland, Scotland, England, Long Island and the Pacific Northwest, from Oregon to Vancouver).
Palms inhabit a variety of ecosystems. More than two-thirds of palm species live in tropical forests, where some species grow tall enough to form part of the canopy and shorter ones form part of the understory. Some species form pure stands in areas with poor drainage or regular flooding, including "Raphia hookeri" which is common in coastal freshwater swamps in West Africa. Other palms live in tropical mountain habitats above 1000 m, such as those in the genus "Ceroxylon" native to the Andes. Palms may also live in grasslands and scrublands, usually associated with a water source, and in desert oases such as the date palm. A few palms are adapted to extremely basic lime soils, while others are similarly adapted to extreme potassium deficiency and toxicity of heavy metals in serpentine soils.
Palms are a monophyletic group of plants, meaning the group consists of a common ancestor and all its descendants. Extensive taxonomic research on palms began with botanist H.E. Moore, who organized palms into 15 major groups based mostly on general morphological characteristics. The following classification, proposed by N.W. Uhl and J. Dransfield in 1987, is a revision of Moore's classification that organizes palms into six subfamilies.
A few general traits of each subfamily are listed below.
The Coryphoideae are the most diverse subfamily, and are a paraphyletic group, meaning all members of the group share a common ancestor, but the group does not include all the ancestor's descendants. Most palms in this subfamily have palmately lobed leaves and solitary flowers with three, or sometimes four carpels. The fruit normally develops from only one carpel.
Subfamily Calamoideae includes the climbing palms, such as rattans. The leaves are usually pinnate; derived characters (synapomorphies) include spines on various organs, organs specialized for climbing, an extension of the main stem of the leaf-bearing reflexed spines, and overlapping scales covering the fruit and ovary.
Subfamily Nypoideae contains only one species, "Nypa fruticans", which has large, pinnate leaves. The fruit is unusual in that it floats, and the stem is dichotomously branched, also unusual in palms.
Subfamily Ceroxyloideae has small to medium-sized flowers, spirally arranged, with a gynoecium of three joined carpels.
The Arecoideae are the largest subfamily, with six diverse tribes (Areceae, Caryoteae, Cocoeae, Geonomeae, Iriarteeae, and Podococceae) containing over 100 genera. All tribes have pinnate or bipinnate leaves and flowers arranged in groups of three, with a central pistillate and two staminate flowers.
The Phytelephantoideae are a monoecious subfamily. Members of this group have distinct monopodial flower clusters. Other distinct features include a gynoecium with five to 10 joined carpels, and flowers with more than three parts per whorl. Fruits are multiple-seeded and have multiple parts.
Currently, few extensive phylogenetic studies of the Arecaceae exist. In 1997, Baker" et al." explored subfamily and tribe relationships using chloroplast DNA from 60 genera from all subfamilies and tribes. The results strongly showed the Calamoideae are monophyletic, and Ceroxyloideae and Coryphoideae are paraphyletic. The relationships of Arecoideae are uncertain, but they are possibly related to the Ceroxyloideae and Phytelephantoideae. Studies have suggested the lack of a fully resolved hypothesis for the relationships within the family is due to a variety of factors, including difficulties in selecting appropriate outgroups, homoplasy in morphological character states, slow rates of molecular evolution important for the use of standard DNA markers, and character polarization. However, hybridization has been observed among "Orbignya" and "Phoenix" species, and using chloroplast DNA in cladistic studies may produce inaccurate results due to maternal inheritance of the chloroplast DNA. Chemical and molecular data from non-organelle DNA, for example, could be more effective for studying palm phylogeny.
Selected genera.
See list of Arecaceae genera arranged by taxonomic groups or by alphabetical order for a complete listing of genera.
Evolution.
The Arecaceae are the first modern family of monocots appearing in the fossil record around 80 million years ago (Mya), during the late Cretaceous period. The first modern species, such as "Nypa fruticans" and "Acrocomia aculeata", appeared 94 Mya, confirmed by fossil "Nypa" pollen dated to 94 Mya. Palms appear to have undergone an early period of adaptive radiation. By 60 Mya, many of the modern, specialized genera of palms appeared and became widespread and common, much more widespread than their range today. Because palms separated from the monocots earlier than other families, they developed more intrafamilial specialization and diversity. By tracing back these diverse characteristics of palms to the basic structures of monocots, palms may be valuable in studying monocot evolution. Several species of palms have been identified from flowers preserved in amber, including "Palaeoraphe dominicana" and "Roystonea palaea". Evidence can also be found in samples of petrified palmwood.
Uses.
Human use of palms is as old or older than human civilization itself, starting with the cultivation of the date palm by Mesopotamians and other Middle Eastern peoples 5000 years or more ago. Date wood, pits for storing dates, and other remains of the date palm have been found in Mesopotamian sites. The date palm had a tremendous effect on the history of the Middle East. W.H. Barreveld wrote:
An indication of the importance of palms in ancient times is that they are mentioned more than 30 times in the Bible, and at least 22 times in the Quran.
Arecaceae have great economic importance, including coconut products, oils, dates, palm syrup, ivory nuts, carnauba wax, rattan cane, raffia, and palm wood.
Along with dates mentioned above, members of the palm family with human uses are numerous.
The southeastern U.S. state of South Carolina is nicknamed the Palmetto State after the sabal palmetto (cabbage palmetto), logs from which were used to build the fort at Fort Moultrie. During the American Revolutionary War, they were invaluable to those defending the fort, because their spongy wood absorbed or deflected the British cannonballs. The sabal palmetto is also the state tree of Florida.
Some palms can be grown as far north as the United States' Mid-Atlantic, such as the National Arboretum in Washington, DC, southern Midwest, and even north along the Pacific coast to Oregon, Washington, and British Columbia, where ocean winds have a warming effect. Species of transplanted palms have even been known to have survived as far north as Devon. The Chinese "Trachycarpus fortunei" is being grown experimentally on the Faroe Islands at 62°N, with young plants doing well so far.
Endangered species.
Like many other plants, palms have been threatened by human intervention and exploitation. The greatest risk to palms is destruction of habitat, especially in the tropical forests, due to urbanization, wood-chipping, mining, and conversion to farmland. Palms rarely reproduce after such great changes in the habitat, and those with small habitat ranges are most vulnerable to them. The harvesting of heart of palm, a delicacy in salads, also poses a threat because it is derived from the palm's apical meristem, a vital part of the palm that cannot be regrown. The use of rattan palms in furniture has caused a major population decrease in these species that has negatively affected local and international markets, as well as biodiversity in the area. The sale of seeds to nurseries and collectors is another threat, as the seeds of popular palms are sometimes harvested directly from the wild. At least 100 palm species are currently endangered, and nine species have reportedly recently become extinct.
However, several factors make palm conservation more difficult. Palms live in almost every type of warm habitat and have tremendous morphological diversity. Most palm seeds lose viability quickly, and they cannot be preserved in low temperatures because the cold kills the embryo. Using botanical gardens for conservation also presents problems, since they can only house a few plants of any species or truly imitate the natural setting. Also, the risk of cross-pollination can lead to hybrid species.
The Palm Specialist Group of the World Conservation Union (IUCN) began in 1984, and has performed a series of three studies to find basic information on the status of palms in the wild, use of wild palms, and palms under cultivation. Two projects on palm conservation and use supported by the World Wildlife Fund took place from 1985 to 1990 and 1986–1991, in the American tropics and southeast Asia, respectively. Both studies produced copious new data and publications on palms. Preparation of a global action plan for palm conservation began in 1991, supported by the IUCN, and was published in 1996.
The rarest palm known is "Hyophorbe amaricaulis". The only living individual remains at the Botanic Gardens of Curepipe in Mauritius.
Pest species.
Pests that attack a variety of species of palm trees include:
Symbolism.
The palm branch was a symbol of triumph and victory in pre-Christian times. The Romans rewarded champions of the games and celebrated military successes with palm branches. Early Christians used the palm branch to symbolize the victory of the faithful over enemies of the soul, as in the Palm Sunday festival celebrating the triumphal entry of Jesus into Jerusalem. In Judaism, the palm represents peace and plenty, and is one of the Four Species of Sukkot; the palm may also symbolize the Tree of Life in Kabbalah.
Panaiveriyamman was an ancient Tamil tree deity related to fertility. Named after "panai", the Tamil name for the Palmyra palm, she was also known as Taalavaasini, a name that further related her to all types of palms.
Today, the palm, especially the coconut palm, remains a symbol of the tropical island paradise.
Palms appear on the flags and seals of several places where they are native, including those of Haiti, Guam, Saudi Arabia, Florida, and South Carolina.
Other plants.
Some species commonly called palms, though they are not true palms, include:

</doc>
<doc id="45716" url="https://en.wikipedia.org/wiki?curid=45716" title="Transporter (Star Trek)">
Transporter (Star Trek)

A transporter is a fictional teleportation machine used in the "Star Trek" universe. Transporters convert a person or object into an energy pattern (a process called "dematerialization"), then "beam" it to a target, where it is reconverted into matter ("rematerialization"). The term "transporter accident" is a catch-all term for when a person or object does not rematerialize correctly.
According to "The Making of Star Trek", "Star Trek" creator Gene Roddenberry's original plan did not include transporters, instead calling for characters to land the starship itself. However, this would have required unfeasible and unaffordable sets and model filming, as well as episode running time spent while landing, taking off, etc. The shuttlecraft was the next idea, but when filming began, the full-sized shooting model was not ready. Transporters were devised as a less expensive alternative, achieved by a simple fade-out/fade-in of the subject. Transporters first appear in the original pilot episode "". The transporter special effect, before being done using computer animation, was created by turning a slow-motion camera upside down and photographing some backlit shiny grains of aluminium powder that were dropped between the camera and a black background.
Gene Roddenberry in 1964 had not seen "The Fly" upon his first draft of "The Cage", but it was brought to his attention, and this is how the transporter was considered. The later "Doctor Who" series 'The Seeds of Death' in 1969 also had teleport device called "T-Mat" for a Teleport Matter transfer.
According to the "", the three touch-sensitive light-up bars on the Enterprise-D's transporter console were an homage to the three sliders used on the duotronic transporter console on the original Enterprise in The Original Series.
In August 2008, physicist Michio Kaku predicted in "Discovery Channel Magazine" that a teleportation device similar to those in Star Trek would be invented within 100 years.
Depiction.
History.
According to dialogue in the ' ("ENT") episode "Daedalus", the transporter was invented in the early 22nd century by Dr. Emory Erickson, who also became the first human to be successfully transported. Although the "Enterprise" (NX-01) has a transporter, the crew does not routinely use it for moving biological organisms. (Captain Jonathan Archer once said that he wouldn't even put his dog through it.) Instead, they generally prefer using shuttlepods or other means of transportation unless no other means of transportation are possible or feasible. The capability is rare; in "The Andorian Incident", the Andorians, technologically far superior to Starfleet in many regards, are explicitly stated not to possess the technology, and in "Chosen Realm", a group of alien religious extremists who hijack the ship is unaware of it to the point that when Archer, choosing himself after their leader insists on sacrificing a crew member, claims that the device disintegrates matter rather than teleporting it, he is unhesitatingly taken at his word. The crew aboard the 23rd century USS "Enterprise" frequently use the transporter. By the 24th century, transporter travel was reliable and "the safest way to travel" according to dialogue in the ' ("TNG") episode "Realm of Fear".
According to the "" episode "Homefront", Starfleet Academy cadets receive transporter rations, and the Sisko family once used a transporter to move furniture into a new home.
Despite its frequent use, characters such as Leonard McCoy and Katherine Pulaski are reluctant to use the transporter, as the characters express in the "Next Generation" episodes "Encounter at Farpoint" and "", respectively. Reginald Barclay expresses his outright fear of transporting in "Realm of Fear".
Capabilities and limitations.
The television series and films do not go into great detail about transporter technology. The "" claims that the devices transport objects in real time, accurate to the quantum level. The episode "Realm of Fear" specifies the length of a transport under unusual circumstances would last "... four or five seconds; about twice the normal time". This calculates the length of a typical transport as between 2 and 2.5 seconds and possibly less. Heisenberg compensators remove uncertainty from the subatomic measurements, making transporter travel feasible. Further technology involved in transportation include a computer pattern buffer to enable a degree of leeway in the process. When asked "How does the Heisenberg compensator work?" by "Time" magazine, "Star Trek" technical adviser Michael Okuda responded: "It works very well, thank you."
According to "The Original Series" ("TOS") writers' guide, the effective range of a transporter is 40,000 kilometers, although thick layers of rock can reduce this range ("TNG": ""). The "TOS" episode "" however, appears to indicate that the transporters' maximum range, during that time period in "Star Trek" history, is actually around 30,000 kilometers. Transporter operations have been disrupted or prevented by dense metals ("TNG": ""), solar flares ("TNG": ""), and other forms of radiation, including electromagnetic ("TNG": ""; "TNG": "") and nucleonic ("TNG": ""), and affected by ion storms ("TOS": ""). Transporting, in progress, has also been stopped by telekinetic powers ("TNG": "") and by brute strength ("TNG": ""). The "TNG" episode "" features a dangerous and experimental "subspace transporter" capable of interstellar distances and the Dominion had the ability to transport over great distances ("DS9": ""). The 40,000-kilometer limit is also referenced in "ENT": "".
Starfleet transporters from the "TNG" era onward include a device that can detect and disable an active weapon ("TNG": ""), and a bio-filter to remove contagious microbes or viruses from an individual in transport ("TNG": ""). The transporter can also serve a tactical purpose, such as beaming a photon grenade or photon torpedo to detonate at remote locations ("TNG": "", "": ""), or to outright destroy objects ("TNG": "Captain's Holiday"). The "TOS" episode "A Taste of Armageddon" mentions Vendikar materializing fusion bombs over targets of enemy planet Eminiar VII in the course of theoretical computer warfare.
Whenever a person or object is transported, the machine creates a memory file of the pattern. This has been used at least once in every "Star Trek" series to revert people adversely affected by a transport to their original state.
Various episodes of "Deep Space Nine" ("DS9") and "Voyager" ("VOY") have introduced two anti-transporter devices: transport inhibitors and transporter scramblers. Inhibitors prevent a transporter beam from "locking on" to whatever the device is attached. Scramblers distort the pattern that is in transit, literally scrambling the atoms upon rematerialization, resulting in the destruction of inanimate objects and killing living beings by rematerializing them as masses of random tissue; this was gruesomely demonstrated in the "DS9" episode "".
Transporter operations can also be curtailed when either the point of origin and/or the intended target site is moving at warp velocities. In the "TNG" episode, "", a "long-range" or "near-warp" transport was required as a transporter beam cannot penetrate a warp field. (In the 2009 "Star Trek" film Kirk and Scotty beam aboard while the "Enterprise" is traveling at warp, however, the movie takes place in an alternate continuity, thus not affecting the Prime Continuity used in all previous media and the Star Trek Online computer game.) To deposit an away team on the planet Gravesworld while at the same time responding to a distress signal, the "Enterprise" would only drop out of warp drive just long enough to energize the transporter beam. Geordi La Forge personally performed the delicate operation, which involved compensating for the ship's relativistic motion. After materializing, Deanna Troi commented that for a moment she thought she was trapped in a nearby wall, to which Worf replied, "For a moment, you were." In later stories ("" and ""), it was confirmed that the transporter would work at warp only if the sending and receiving sites were moving at equal velocities.
In his book, "The Physics of Star Trek", after explaining the difference between transporting information and transporting the actual atoms, Krauss notes that "The "Star Trek" writers seem never to have got it exactly clear what they want the transporter to do. Does the transporter send the atoms and the bits, or just the bits?" He notes that according to the canon definition of the transporter the former seems to be the case, but that that definition is inconsistent with a number of applications, particularly incidents, involving the transporter, which appear to involve only a transport of information, for example the way in which it splits Kirk into two version in the episode "" or the way in which Riker is similarly split in the episode "". Krauss elaborates that: "If the transporter carries both the matter stream and the information signal, this splitting phenomenon is impossible. The number of atoms you end up with has to be the same as the number you began 
with. There is no possible way to replicate people in this manner. On the other hand, if only the information were beamed up, one could imagine combining it with atoms that might be stored aboard a starship and making as many copies as you wanted of an individual."
Transporter accidents.
Aside from external influences causing disruptions in the normal operations of transporters, the technology itself has been known to fail on occasion, causing serious injury or usually death to those being transported. This was demonstrated in "" when a malfunction in the transporter sensor circuits resulted in insufficient signal being present at the "Enterprise" end to successfully rematerialize the two subjects, and Starfleet was unable to pull them back to where they had dematerialized from. The transporter system attempted to rematerialize what little signal was available, and despite the efforts of Kirk and Scotty, the system failed and both subjects vanished from the transporter pad. Kirk, visibly shaken by what he had witnessed asked, "Starfleet, do you have them?", to which the response was made ""Enterprise", what we got back didn't live long, fortunately".
By the time of "", transporter technology has advanced considerably, meaning that accidents are now remote, if not near impossible. In fact, in the episode "Realm of Fear", Geordi La Forge states that there have been no more than 2 or 3 transporter accidents in the preceding 10 years. Reference is also made to the advancement of transporter technology in the same episode, where Chief O'Brien states that each individual transporter pad has four redundant scanners whereby in the event a scanner fails the other three will take over, and that he has never lost anyone having been a transporter operator for over twenty years.
In "Rascals", several adult Enterprise crew members were beamed off a shuttle and re materialized as children still in their adult sized clothing, the incoming "matter stream" had a commensurate drop in mass, the operator had initially thought the reduction in mass meant "we may have lost one". 
In the "" episode "Tuvix", a transporter accident combines both the physical and behavioral aspects of Lt. Tuvok and Neelix into a single being wearing a melange of each other's clothing. Notably, Tuvix was of equal mass of both Tuvok and Neelix combined. When they were later separated, Neelix and Tuvok were both wearing Starfleet uniforms.
Technological and Scientific Restrictions.
While several characters have asserted that transporters cannot transport through a ship's shields or planetary defense shields, there are instances of this "rule" being broken through a technobabble solution ("TNG": "", "DS9": "Trials and Tribble-ations") or disregarded by the show's writers ("Voyager": "").
In ', Vice Admiral James T. Kirk and Lieutenant Saavik carry on a conversation during rematerialization. In ', Dr. Gillian Taylor jumps into Kirk's transporter beam during dematerialization, and rematerializes without any apparent ill effects. This is probably due to the "annular confinement beam", a component of the transporter mentioned in the various television episodes which serves to keep patterns separate from one another. In the same film, Mr. Spock is beamed into a cloaked ship while walking.
According to the "TNG Technical Manual", the transporter cannot move antimatter, but in the "Voyager" episode "Dark Frontier" "Voyager" transported a live photon torpedo equipped with antimatter onto a Borg ship. Also in "TOS" episode "" Kirk and a fellow crewman beam down to the surface of a planet with an antimatter 'bomb'. The "TAS" episode "One of Our Planets Is Missing" has the Enterprise beaming a chunk of antimatter into a stasis box.
In the original series, beaming to and from the transporter chamber was a necessity. This is explained in the "TOS" episode "Day of the Dove". Spock and Scotty had said that doing a site-to-site transport, as they are referred to on the show, on board the ship could be risky. They could beam into a deck or other inanimate object and get stuck there. However, there are apparently safeguards in place to prevent people from being beamed into hostile environments such as under water and into lava pits, although it is possible to override this safety feature; for example, in the "TOS" episode "And the Children Shall Lead", two security guards are beamed into open space. In the following series, however, the transporter room seems to become mostly obsolete, the actual equipment notwithstanding. Characters are shown activating the transporter from ordinary consoles and beaming from place to place without apparent trouble. The main operator can likewise send those in transport anywhere with ease (for example, in the "Voyager" episode "", a medical console is used to transport a body from the morgue to the surgical bay). A possible explanation for this is put forward in the "", where such site-to-site transports would probably use twice as much energy as would be required for transport to or from the transporter room itself, since the subject would have to be beamed to the transporter, stored, then shunted to their destination. In addition, the six circles on the platform are generally used as targets for the subjects to stand on, but they do not appear to represent any limitation of the hardware to six or fewer people. People have been transported carrying others, in a coffin style transport, as well as animals, hay, and various inanimate objects.
Dialogue in "Deep Space Nine" indicates the existence of portable transporters, but these are never seen. The "Next Generation" episode "" features emergency transporter armbands, although these may have served only to activate a remote transporter. To confuse things more, "" featured the prototype "emergency transport unit". Tom Paris uses a portable transporter in the "Voyager" episode "". However, in "Star Trek: Into Darkness", Khan Noonien Singh uses a portable transporter to beam from a helicopter to the Klingon home world.
For special effects reasons, in "TOS", people generally appear immobilized during transport, with the exception of Kirk in the episode "That Which Survives". However, by "TNG", characters can move within the confines of the transporter beam while being transported, although this is rarely shown. Persons being transported are at least sometimes able to perceive the functioning of the transporter while they are in transit. In the "TOS" episode "", the "Enterprise" transporter malfunctions while transporting Scotty from the disabled USS "Constellation" to the "Enterprise" due to a power drain, and Scotty's pattern is nearly lost in transit. As soon as he successfully materializes, Scotty asks the transporter operator with concern, "What's the matter with that thing?" and orders the transporter to be taken off-line for emergency repair. This incident does not necessarily suggest that such malfunctions would have had strong effects on the person being transported, however, for Scotty's expertise might have allowed him to perceive and diagnose subtle effects during transit that most people would not.
Some species do not use transporter technology for a variety of reasons. In the first appearance of Trill in the "TNG" episode "", Trill were unable to be transported, once joined with a symbiont. It seems that was due to the symbiont being detected and removed by the transporter technology as an infestation in the host. Odan, the Trill host in this episode, is reluctant to say why he will not travel this way, and it only becomes apparent that he is carrying a symbiont when he is later injured. All the crew of the "Enterprise" react as if they have had no contact with this species before. It later becomes apparent that joined Trill have been working in the Federation for some time.
When Trill became a regularly used race in later series, the inability to use transporter technology was dropped. No explanation of the change is ever given in any series where they appear, but according to an article on startrek.com, Trill are actually more than one host race.
In popular culture.
The famous catchphrase "Beam me up, Scotty" refers to the transporter device, which was often operated by chief engineer Montgomery Scott during the original series. The phrase was never uttered by anyone in the original series, although the lines "Scotty, beam us up" and "Beam me up" were spoken by Captain Kirk in that series. "Scotty, beam me up" was spoken by Admiral Kirk in "Star Trek IV: The Voyage Home". On the special edition DVD of "Star Trek IV", the text commentary provided by Michael and Denise Okuda (co-authors of "The Star Trek Encyclopedia" and "The Star Trek Chronology: The History of the Future") indicates that this was the closest anyone came to using that catchphrase in an official "Star Trek" production.

</doc>
<doc id="45720" url="https://en.wikipedia.org/wiki?curid=45720" title="Schleswig, Schleswig-Holstein">
Schleswig, Schleswig-Holstein

Schleswig (; ; South Jutlandic: "Sljasvig"; archaic English: "Sleswick"; ) is a town in the northeastern part of Schleswig-Holstein, Germany. It is the capital of the "Kreis" (district) Schleswig-Flensburg. It has a population of about 27,000, the main industries being leather and food processing. It takes its name from the Schlei, an inlet of the Baltic sea at the end of which it sits, and "vik" or "vig" which means bay in Old Norse and Danish. Schleswig or Slesvig therefore means "bay of the Schlei".
Geography.
The city lies at the western end of the Schlei Förde, which separates the two peninsulas of Angeln and Schwansen and is on the western edge of the Schleswig-Holstein Uplands on the transition to the Geest country. The urban area ranges from 0 to 20 m above sea level. Brautsee (lake) is in the town.
The nearest major cities are Flensburg, Husum and Kiel. Autobahn 7 runs immediately west of the city. Highways 76 and 77 end in Schleswig and B 201 runs to the north of the town. Schleswig station is a stop for InterCity and Intercity-Express trains and is on the Hamburg–Neumünster–Flensburg and Husum–Kiel lines.
Climate.
The climate is humid and maritime. The annual mean temperature is 8 °C and precipitation averages 925 mm.
History.
The Viking settlement of Hedeby, located south of the modern town, was first mentioned in 804. It was a powerful settlement in the Baltic region, dominating the area for more than 200 years. In 1050, following several destructions, the population was moved to the opposite shore of the Schlei, becoming the city of Schleswig. In 1066 Hedeby was finally destroyed, and Schleswig remained as a part of the Danish kingdom.
In 1544 Gottorf Castle became the residence of the local rulers. The dukes of Gottorf were vassals of the Danish kings and ruled over much of present day Schleswig-Holstein. In 1721, when the Great Northern War ended, the dukes of Gottorf lost their power and their land became Danish crown land. After the Second Schleswig War (1864), Schleswig was annexed by the Kingdom of Prussia.

</doc>
