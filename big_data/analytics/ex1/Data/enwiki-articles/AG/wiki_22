<doc id="40897" url="https://en.wikipedia.org/wiki?curid=40897" title="Collinear antenna array">
Collinear antenna array

In telecommunications, a collinear antenna array is an array of dipole antennas mounted in such a manner that the corresponding elements of each antenna are parallel and collinear, that is they are located along a common line or axis. 
Collinear arrays of dipoles are high gain omnidirectional antennas. A dipole has an omnidirectional radiation pattern when in free space and not influenced by any other conductors in that it radiates equal radio power in all azimuthal directions perpendicular to the antenna, with the signal strength dropping to zero on the antenna axis. The purpose of stacking multiple dipoles in a vertical collinear array is to increase the power radiated in horizontal directions and reduce the power radiated into the sky or down toward the earth, where it is wasted. They radiate vertically polarized radio waves. Theoretically, when stacking idealised lossless dipole antennas in such a fashion, doubling their number will produce double the gain, with an increase of 3.01 dB. In practice, the gain realized will be below this due to imperfect radiation spread and losses.
Collinear dipole arrays are often used as the antennas for base stations for land mobile radio systems that communicate with mobile two-way radios in vehicles, such as police, fire, ambulance, and taxi dispatchers. They are also sometimes used for broadcasting.
Multiple directional antennas mounted vertically separated are referred to as "stacked" and if alongside each other as "bayed".
References.
Chris Burks

</doc>
<doc id="40898" url="https://en.wikipedia.org/wiki?curid=40898" title="Collision">
Collision

A collision is an event in which two or more bodies exert forces on each other for a relatively short time. Although the most common colloquial use of the word "collision" refers to incidents in which two or more objects collide, the scientific use of the word "collision" implies nothing about the magnitude of the force.
Some examples of physical interactions that scientists would consider collisions:
Some colloquial uses of the word collision are:
Overview.
Collision is short-duration interaction between two bodies or more than two bodies simultaneously causing change in motion of bodies involved due to internal forces acted between them during this. Collisions involve forces (there is a change in velocity). The magnitude of the velocity difference at impact is called the closing speed. All collisions conserve momentum. What distinguishes different types of collisions is whether they also conserve kinetic energy. Line of impact – It is the line which is common normal for surfaces are closest or in contact during impact. This is the line along which internal force of collision acts during impact and Newton's coefficient of restitution is defined only along this line.
Specifically, collisions can either be "elastic," meaning they conserve both momentum and kinetic energy, or "inelastic," meaning they conserve momentum but not kinetic energy. An inelastic collision is sometimes also called a "plastic collision."
A “perfectly inelastic” collision (also called a "perfectly plastic" collision) is a limiting case of inelastic collision in which the two bodies stick together after impact.
The degree to which a collision is elastic or inelastic is quantified by the coefficient of restitution, a value that generally ranges between zero and one. A perfectly elastic collision has a coefficient of restitution of one; a perfectly inelastic collision has a coefficient of restitution of zero.
Types of collisions.
There are two types of collisions between two bodies - 1) Head on collisions or one-dimensional collisions - where the velocity of each body just before impact is along the line of impact, and 2) Non-head on collisions, oblique collisions or two-dimensional collisions - where the velocity of each body just before impact is not along the line of impact.
According to the coefficient of restitution, there are two special cases of any collision as written below:
Allision.
In maritime law, it is occasionally desirable to distinguish between the situation of a vessel striking a moving object, and that of it striking a stationary object. The word "allision" is then used to mean the striking of a stationary object, while "collision" is used to mean the striking of a moving object.
Analytical vs. numerical approaches towards resolving collisions.
Relatively few problems involving collisions can be solved analytically; the remainder require numerical methods. An important problem in simulating collisions is determining whether two objects have in fact collided. This problem is called collision detection.
Examples of collisions that can be solved analytically.
Billiards.
Collisions play an important role in cue sports. Because the collisions between billiard balls are nearly elastic, and the balls roll on a surface that produces low rolling friction, their behavior is often used to illustrate Newton's laws of motion. After a zero-friction collision of a moving ball with a stationary one of equal mass, the angle between the directions of the two balls is 90 degrees. This is an important fact that professional billiards players take into account, although it assumes the ball is moving frictionlessly across the table rather than rolling with friction.
Consider an elastic collision in 2 dimensions of any 2 masses m1 and m2, with respective initial velocities u1 and u2 where u2 = 0, and final velocities V1 and V2.
Conservation of momentum gives m1u1 = m1V1+ m2V2.
Conservation of energy for an elastic collision gives (1/2)m1|u1|2 = (1/2)m1|V1|2 + (1/2)m2|V2|2.
Now consider the case m1 = m2: we obtain u1=V1+V2 and |u1|2 = |V1|2+|V2|2.
Taking the dot product of each side of the former equation with itself, |u1|2 = u1•u1 = |V1|2+|V2|2+2V1•V2. Comparing this with the latter equation gives V1•V2 = 0, so they are perpendicular unless V1 is the zero vector (which occurs if and only if the collision is head-on).
Perfectly inelastic collision.
In a perfectly inelastic collision, i.e., a zero coefficient of restitution, the colliding particles stick together. It is necessary to consider conservation of momentum:
where v is the final velocity, which is hence given by
The reduction of total kinetic energy is equal to the total kinetic energy before the collision in a center of momentum frame with respect to the system of two particles, because in such a frame the kinetic energy after the collision is zero. In this frame most of the kinetic energy before the collision is that of the particle with the smaller mass. In another frame, in addition to the reduction of kinetic energy there may be a transfer of kinetic energy from one particle to the other; the fact that this depends on the frame shows how relative this is.
With time reversed we have the situation of two objects pushed away from each other, e.g. shooting a projectile, or a rocket applying thrust (compare the derivation of the Tsiolkovsky rocket equation).
Examples of collisions analyzed numerically.
Animal locomotion.
Collisions of an animal's foot or paw with the underlying substrate are generally termed ground reaction forces. These collisions are inelastic, as kinetic energy is not conserved. An important research topic in prosthetics is quantifying the forces generated during the foot-ground collisions associated with both disabled and non-disabled gait. This quantification typically requires subjects to walk across a force platform (sometimes called a "force plate") as well as detailed kinematic and dynamic (sometimes termed kinetic) analysis.
Collisions used as an experimental tool.
Collisions can be used as an experimental technique to study material properties of objects and other physical phenomena.
Space exploration.
An object may deliberately be made to crash-land on another celestial body, to do measurements and send them to Earth before being destroyed, or to allow instruments elsewhere to observe the effect. See e.g.:
Mathematical description of molecular collisions.
Let the linear, angular and internal momenta of a molecule be given by the set of "r" variables { "p"i }. The state of a molecule may then be described by the range "δw"i = δ"p"1δ"p"2δ"p"3 ... δ"p"r. There are many such ranges corresponding to different states; a specific state may be denoted by the index "i". Two molecules undergoing a collision can thus be denoted by ("i", "j") (Such an ordered pair is sometimes known as a "constellation".)
It is convenient to suppose that two molecules exert a negligible effect on each other unless their centre of gravities approach within a critical distance "b". A collision therefore begins when the respective centres of gravity arrive at this critical distance, and is completed when they again reach this critical distance on their way apart. Under this model, a collision is completely described by the matrix formula_3, which refers to the constellation ("i", "j") before the collision, and the (in general different) constellation ("k", "l") after the collision.
This notation is convenient in proving Boltzmann's H-theorem of statistical mechanics.
Attack by means of a deliberate collision.
Types of attack by means of a deliberate collision include:
An attacking collision with a distant object can be achieved by throwing or launching a projectile.

</doc>
<doc id="40899" url="https://en.wikipedia.org/wiki?curid=40899" title="Combat-net radio">
Combat-net radio

In telecommunication, a combat-net radio (CNR) is a radio operating in a network that (a) provides a half-duplex circuit and (b) uses either a single radio frequency or a discrete set of radio frequencies when in a frequency hopping mode.
CNRs are primarily used for push-to-talk-operated radio nets for command and control of combat, combat support, and combat service support operations among military ground, sea, and air forces.
In the United States, two military standards govern the use of combat net radios and the host applications that communicate over the network: MIL-STD-188-220 and MIL-STD-2045-47001. In addition to IETF RFCs governing UDP, TCP, and IPv4/IPv6, all seven layers of the OSI communications architecture are addressed. MIL-STD-2045-47001 covers layer 7 (application), while MIL-STD-188-220 covers layers 1 through 3 (physical, data link, and network).

</doc>
<doc id="40900" url="https://en.wikipedia.org/wiki?curid=40900" title="Combined distribution frame">
Combined distribution frame

In telecommunication, a combined distribution frame (CDF) is a distribution frame that combines the functions of main and intermediate distribution frames and contains both vertical and horizontal terminating blocks. 
The vertical blocks are used to terminate the permanent outside lines entering the station. Horizontal blocks are used to terminate inside plant equipment. This arrangement permits the association of any outside line with any desired terminal equipment. These connections are made either with twisted pair wire, normally referred to as jumper wire, or with optical fiber cables, normally referred to as jumper cables. 
In technical control facilities, the vertical side may be used to terminate equipment as well as outside lines. The horizontal side is then used for jackfields and battery terminations.

</doc>
<doc id="40901" url="https://en.wikipedia.org/wiki?curid=40901" title="Comma-free code">
Comma-free code

A comma-free code is block code in which no concatenation of two code words contains a valid code word that overlaps both.
Comma-free codes are also known as self-synchronizing block codes because no synchronization is required to find the beginning of a code word.

</doc>
<doc id="40906" url="https://en.wikipedia.org/wiki?curid=40906" title="Commercial refile">
Commercial refile

Commercial refile: In military communications systems, the processing of a message from (a) a given military network, such as a tape relay network, a point-to-point telegraph network, a radio-telegraph network, or the DSN to (b) a commercial communications network. 
Commercial refiling of a message will usually require a reformatting of the message, particularly the heading.

</doc>
<doc id="40908" url="https://en.wikipedia.org/wiki?curid=40908" title="Common battery">
Common battery

In telecommunication, a common battery is a single electrical power source used to energize more than one circuit, electronic component, equipment, or system. 
A common battery is usually an electrolytic device and is usually centrally located to the equipment that it serves. In many telecommunications applications, the common battery is at a nominal −48 VDC. A central office common battery in the battery room supplies power to operate all directly connected instruments. "Common battery" may include one or more power conversion devices to transform commercial power to direct current, with an electrolytic battery floating across the output. Common battery operation largely replaced local batteries in each telephone in the early 20th century. 

</doc>
<doc id="40909" url="https://en.wikipedia.org/wiki?curid=40909" title="Booting">
Booting

In computing, booting (or booting up) is the initialization of a computerized system. The system can be a computer or a computer appliance. The booting process can be "hard", after electrical power to the CPU is switched from off to on (in order to diagnose particular hardware errors), or "soft", when those power-on self-tests (POST) can be avoided. Soft booting can be initiated by hardware such as a button press, or by software command. Booting is complete when the normal, operative, runtime environment is attained.
A boot loader is a computer program that loads an operating system or some other system software for the computer after completion of the power-on self-tests; it is the loader for the operating system itself. Within the hard reboot process, it runs after completion of the self-tests, then loads and runs the software. A boot loader is loaded into main memory from persistent memory, such as a hard disk drive or, in some older computers, from a medium such as punched cards, punched tape, or magnetic tape. The boot loader then loads and executes the processes that finalize the boot. Like POST processes, the boot loader code comes from a "hard-wired" and persistent location; if that location is too limited for some reason, that primary boot loader calls a second-stage boot loader or a secondary program loader.
On modern general purpose computers, the boot up process can take tens of seconds, and typically involves performing a power-on self-test, locating and initializing peripheral devices, and then finding, loading and starting an operating system. The process of hibernating or sleeping does not involve booting. Minimally, some embedded systems do not require a noticeable boot sequence to begin functioning and when turned on may simply run operational programs that are stored in ROM. All computing systems are state machines, and a reboot may be the only method to return to a designated zero-state from an unintended, locked state.
"Boot" is short for "bootstrap" or "bootstrap load" and derives from the phrase "to pull oneself up by one's bootstraps". The usage calls attention to the requirement that, if most software is loaded onto a computer by other software already running on the computer, some mechanism must exist to load the initial software onto the computer. Early computers used a variety of ad-hoc methods to get a small program into memory to solve this problem. The invention of read-only memory (ROM) of various types solved this paradox by allowing computers to be shipped with a start up program that could not be erased. Growth in the capacity of ROM has allowed ever more elaborate start up procedures to be implemented.
History.
There are many different methods available to load a short initial program into a computer. These methods reach from simple, physical input to removable media that can hold more complex programs.
Pre integrated-circuit-ROM examples.
Early computers.
Early computers in the 1940s and 1950s were one-of-a-kind engineering efforts that could take weeks to program and program loading was one of many problems that had to be solved. An early computer, ENIAC, had no "program" stored in memory, but was set up for each problem by a configuration of interconnecting cables. Bootstrapping did not apply to ENIAC, whose hardware configuration was ready for solving problems as soon as power was applied.
In 1960, the Ballistic Missile Early Warning System Display Information Processor (DIP) in Colorado Springsbefore the NORAD facility was built in the underground Cheyenne Mountain Complexran only one program, which carried its own startup code. The program was stored as a bit image on a continuously running magnetic drum, and loaded in a fraction of a second. Core memory was probably cleared manually via the maintenance console, and startup from when power was fully up was very fast, only a few seconds. In its general design, the DIP compared roughly with a DEC PDP-8. Thus, it was not the kind of single-button-pressure bootstrap that came later, nor a read-only memory (ROM) in strict terms, since the magnetic drum involved could be written to.
First commercial computers.
The first programmable computers for commercial sale, such as the UNIVAC I and the IBM 701 included features to make their operation simpler. They typically included instructions that performed a complete input or output operation. The same hardware logic could be used to load the contents of a punch card (the most typical ones) or other input media, such as a magnetic drum or magnetic tape, that contained a bootstrap program by pressing a single button. This booting concept was called a variety of names for IBM computers of the 1950s and early 1960s, but IBM used the term "Initial Program Load" with the IBM 7030 Stretch and later used it for their mainframe lines, starting with the System/360 in 1964. A punch card was not a ROM in strictly technical terms, since it was not a device built using semiconductors.
The IBM 701 computer (1952–1956) had a "Load" button that initiated reading of the first 36-bit word into main memory from a punched card in a card reader, a magnetic tape in a tape drive, or a magnetic drum unit, depending on the position of the Load Selector switch. The left 18-bit half-word was then executed as an instruction, which usually read additional words into memory. The loaded boot program was then executed, which, in turn, loaded a larger program from that medium into memory without further help from the human operator. The term "boot" has been used in this sense since at least 1958.
Other IBM computers of that era had similar features. For example, the IBM 1401 system (c. 1958) used a card reader to load a program from a punched card. The 80 characters stored in the punched card were read into memory locations 001 to 080, then the computer would branch to memory location 001 to read its first stored instruction. This instruction was always the same: move the information in these first 80 memory locations to an assembly area where the information in punched cards 2, 3, 4, and so on, could be combined to form the stored program. Once this information was moved to the assembly area, the machine would branch to an instruction in location 080 (read a card) and the next card would be read and its information processed.
Another example was the IBM 650 (1953), a decimal machine, which had a group of ten 10-position switches on its operator panel which were addressable as a memory word (address 8000) and could be executed as an instruction. Thus setting the switches to 7004000400 and pressing the appropriate button would read the first card in the card reader into memory (op code 70), starting at address 400 and then jump to 400 to begin executing the program on that card.
IBM's competitors also offered single button program load.
A noteworthy variation of this is found on the Burroughs B1700 where there is neither a bootstrap ROM nor a hardwired IPL operation. Instead, after the system is reset it reads and executes opcodes sequentially from a tape drive mounted on the front panel; this sets up a boot loader in RAM which is then executed. However, since this makes few assumptions about the system it can equally well be used to load diagnostic (Maintenance Test Routine) tapes which display an intelligible code on the front panel even in cases of gross CPU failure.
IBM System/360 and successors.
In the IBM System/360 and its successors, including the current z/Architecture machines, the boot process is known as "Initial Program Load" (IPL).
IBM coined this term for the 7030 (Stretch), revived it for the design of the System/360, and continues to use it in those environments today. In the System/360 processors, an IPL is initiated by the computer operator by selecting the three hexadecimal digit device address (CUU; C=I/O Channel address, UU=Control unit and Device address) followed by pressing the "LOAD" button. On most System/370 and some later systems, the functions of the switches and the LOAD button are simulated using selectable areas on the screen of a graphics console, often an IBM 2250-like device or an IBM 3270-like device. For example, on the System/370 Model 158, the keyboard sequence 0-7-X (zero, seven and X, in that order) results in an IPL from the device address which was keyed into the input area. Amdahl 470V/6 and related CPUs supported four hexadecimal digits on those CPUs which had the optional second channel unit installed, for a total of 32 channels. Later, IBM would also support more than 16 channels.
The IPL function in the System/360 and its successors, and its compatibles such as Amdahl's, reads 24 bytes from an operator-specified device into main storage starting at real address zero. The second and third groups of eight bytes are treated as Channel Command Words (CCWs) to continue loading the startup program (the first CCW is always simulated by the CPU and consists of a Read IPL command, 02h, with command chaining and suppress incorrect length indication being enforced). When the I/O channel commands are complete, the first group of eight bytes is then loaded into the processor's Program Status Word (PSW) and the startup program begins execution at the location designated by that PSW. The IPL device is usually a disk drive, hence the special significance of the 02h read-type command, but exactly the same procedure is also used to IPL from other input-type devices, such as tape drives, or even card readers, in a device-independent manner, allowing, for example, the installation of an operating system on a brand-new computer from an OS initial distribution magnetic tape. For disk controllers, the 02h command also causes the selected device to seek to cylinder 0000h, head 0000h, simulating a Seek cylinder and head command, 07h, and to search for record 01h, simulating a Search ID Equal command, 31h; seeks and searches are not simulated by tape and card controllers, as for these device classes an 02h command is simply a sequential read command, not a Read IPL command.
The disk, tape or card deck must contain a special program to load the actual operating system into main storage, and for this specific purpose "IPL Text" is placed on the disk by the stand-alone DASDI (Direct Access Storage Device Initialization) program or an equivalent program running under an operating system, e.g., ICKDSF, but IPL-able tapes and card decks are usually distributed with this "IPL Text" already present.
Minicomputers.
Minicomputers, starting with the Digital Equipment Corporation (DEC) PDP-5 and PDP-8 (1965) simplified design by using the CPU to assist input and output operations. This saved cost but made booting more complicated than pressing a single button. Minicomputers typically had some way to "toggle in" short programs by manipulating an array of switches on the front panel. Since the early minicomputers used magnetic core memory, which did not lose its information when power was off, these bootstrap loaders would remain in place unless they were erased. Erasure sometimes happened accidentally when a program bug caused a loop that overwrote all of memory.
Other minicomputers with such simple form of booting include Hewlett-Packard's HP 2100 series (mid-1960s), the original Data General Nova (1969), and DEC's PDP-11 (1970).
DEC later added an optional diode matrix read-only memory for the PDP-11 that stored a bootstrap program of up to 32 words (64 bytes). It consisted of a printed circuit card, the M792, that plugged into the Unibus and held a 32 by 16 array of semiconductor diodes. With all 512 diodes in place, the memory contained all "one" bits; the card was programmed by cutting off each diode whose bit was to be "zero". DEC also sold versions of the card, the BM792-Yx series, pre-programmed for many standard input devices by simply omitting the unneeded diodes.
Following the older approach, the earlier PDP-1 has a hardware loader, such that an operator need only push the "load" switch to instruct the paper tape reader to load a program directly into core memory. The Data General Supernova used front panel switches to cause the computer to automatically load instructions into memory from a device specified by the front panel's data switches, and then jump to loaded code; the Nova 800 and 1200 had a switch that loaded a program into main memory from a special read-only memory and jumped to it.
Early minicomputer boot loader examples.
In a minicomputer with a paper tape reader, the first program to run in the boot process, the boot loader, would read into core memory either the second-stage boot loader (often called a "Binary Loader") that could read paper tape with checksum or the operating system from an outside storage medium. Pseudocode for the boot loader might be as simple as the following eight instructions:
A related example is based on a loader for a Nicolet Instrument Corporation minicomputer of the 1970s, using the paper tape reader-punch unit on a Teletype Model 33 ASR teleprinter. The bytes of its second-stage loader are read from paper tape in reverse order.
The length of the second stage loader is such that the final byte overwrites location 7. After the instruction in location 6 executes, location 7 starts the second stage loader executing. The second stage loader then waits for the much longer tape containing the operating system to be placed in the tape reader. The difference between the boot loader and second stage loader is the addition of checking code to trap paper tape read errors, a frequent occurrence with relatively low-cost, "part-time-duty" hardware, such as the Teletype Model 33 ASR. (Friden Flexowriters were far more reliable, but also comparatively costly.)
Booting the first microcomputers.
The earliest microcomputers, such as the Altair 8800 and an even earlier, similar machine (based on the Intel 8008 CPU) had no bootstrapping hardware as such. When started, the CPU would see memory that would contain executable code containing only binary zeros—memory was cleared by resetting when powering up. The front panels of these machines carried toggle switches, one switch per bit of the computer memory word. Simple additions to the hardware permitted one memory location at a time to be loaded from those switches to store bootstrap code. Meanwhile, the CPU was kept from attempting to execute memory content. Once correctly loaded, the CPU was enabled to execute the bootstrapping code. This process was tedious and had to be error-free.
Integrated circuit read-only memory era.
The boot process was revolutionized by the introduction of integrated circuit read-only memory (ROM), with its many variants, including mask-programmed ROMs, programmable ROMs (PROM), erasable programmable ROMs (EPROM), and flash memory. These allowed firmware boot programs to be shipped installed on the computer. The introduction of an (external) ROM was in an Italian telephone switching elaborator, called "Gruppi Speciali", patented in 1975 by Alberto Ciaramella, a researcher at CSELT. Gruppi Speciali was, starting from 1975, a fully single-button machine booting into the operating system from a ROM memory composed from semiconductors, not from ferrite cores. Although the ROM was not natively integrated, due to the design of the machine, it also allowed the single-button ROM booting in machines not designed for that, e.g. the PDP-11.
Typically, every microprocessor will, after a reset or power-on condition, perform a start-up process that usually takes the form of "begin execution of the code that is found starting at a specific address" or "look for a multibyte code at a specific address and jump to the indicated location to begin execution". A system built using that microprocessor will have the permanent ROM occupying these special locations so that the system always begins operating without operator assistance. For example, Intel x86 processors always start by running the instructions beginning at FFFF:FFF0, while for the MOS 6502 processor, initialization begins by reading a two-byte vector address at $FFFD (MS byte) and $FFFC (LS byte) and jumping to that location to run the bootstrap code.
Apple Inc.'s first computer, the Apple 1 introduced in 1976, featured PROM chips that eliminated the need for a front panel for the boot process in a commercial computer. According to Apple's ad announcing it "No More Switches, No More Lights ... the firmware in PROMS enables you to enter, display and debug programs (all in hex) from the keyboard."
Due to the expense of read-only memory at the time, the Apple II series booted its disk operating systems using a series of very small incremental steps, each passing control onward to the next phase of the gradually more complex boot process. (See Apple DOS: Boot loader). Because so little of the disk operating system relied on ROM, the hardware was also extremely flexible and supported a wide range of customized disk copy protection mechanisms. (See Software Cracking: History.)
Some operating systems, most notably pre-1995 Macintosh systems from Apple, are so closely interwoven with their hardware that it is impossible to natively boot an operating system other than the standard one. This is the opposite extreme of the scenario using switches mentioned above; it is highly inflexible but relatively error-proof and foolproof as long as all hardware is working normally. A common solution in such situations is to design a boot loader that works as a program belonging to the standard OS that hijacks the system and loads the alternative OS. This technique was used by Apple for its A/UX Unix implementation and copied by various freeware operating systems and BeOS Personal Edition 5.
Some machines, like the Atari ST microcomputer, were "instant-on", with the operating system executing from a ROM. Retrieval of the OS from secondary or tertiary store was thus eliminated as one of the characteristic operations for bootstrapping. To allow system customizations, accessories, and other support software to be loaded automatically, the Atari's floppy drive was read for additional components during the boot process. There was a timeout delay that provided time to manually insert a floppy as the system searched for the extra components. This could be avoided by inserting a blank disk. The Atari ST hardware was also designed so the cartridge slot could provide native program execution for gaming purposes as a holdover from Atari's legacy making electronic games; by inserting the Spectre GCR cartridge with the Macintosh system ROM in the game slot and turning the Atari on, it could "natively boot" the Macintosh operating system rather than Atari's own TOS system.
The IBM Personal Computer included ROM-based firmware called the BIOS; one of the functions of that firmware was to perform a power-on self test when the machine was powered up, and then to read software from a boot device and execute it. Firmware compatible with the BIOS on the IBM Personal Computer is used in IBM PC compatible computers. The Extensible Firmware Interface was developed by Intel, originally for Itanium-based machines, and later also used as an alternative to the BIOS in x86-based machines, including Apple Macs using Intel processors.
Unix workstations originally had vendor-specific ROM-based firmware. Sun Microsystems later developed OpenBoot, later known as Open Firmware, which incorporated a Forth interpreter, with much of the firmware being written in Forth. It was standardized by the IEEE as IEEE standard 1275-1994; firmware that implements that standard was used in PowerPC-based Macs and some other PowerPC-based machines, as well as Sun's own SPARC-based computers. The Advanced RISC Computing specification defined another firmware standard, which was implemented on some MIPS-based and Alpha-based machines and the SGI Visual Workstation x86-based workstations.
Modern boot loaders.
When a computer is turned off, its softwareincluding operating systems, application code, and dataremains stored on nonvolatile data storage devices such as hard disk drives, CDs, DVDs, flash memory cards (SD cards, for example), USB flash drives, and floppy disks. When the computer is powered on, it typically does not have an operating system or its loader in random access memory (RAM). The computer first executes a relatively small program stored in read-only memory (ROM) along with a small amount of needed data, to access the nonvolatile device or devices from which the operating system programs and data can be loaded into RAM.
The small program that starts this sequence is known as a "bootstrap loader", "bootstrap" or "boot loader". This small program's only job is to load other data and programs which are then executed from RAM. Often, multiple-stage boot loaders are used, during which several programs of increasing complexity load one after the other in a process of chain loading.
Some computer systems, upon receiving a boot signal from a human operator or a peripheral device, may load a very small number of fixed instructions into memory at a specific location, initialize at least one CPU, and then point the CPU to the instructions and start their execution. These instructions typically start an input operation from some peripheral device (which may be switch-selectable by the operator). Other systems may send hardware commands directly to peripheral devices or I/O controllers that cause an extremely simple input operation (such as "read sector zero of the system device into memory starting at location 1000") to be carried out, effectively loading a small number of boot loader instructions into memory; a completion signal from the I/O device may then be used to start execution of the instructions by the CPU.
Smaller computers often use less flexible but more automatic boot loader mechanisms to ensure that the computer starts quickly and with a predetermined software configuration. In many desktop computers, for example, the bootstrapping process begins with the CPU executing software contained in ROM (for example, the BIOS of an IBM PC) at a predefined address (some CPUs, including the Intel x86 series are designed to execute this software after reset without outside help). This software contains rudimentary functionality to search for devices eligible to participate in booting, and load a small program from a special section (most commonly the boot sector) of the most promising device, typically starting at a fixed entry point such as the start of the sector.
Boot loaders may face peculiar constraints, especially in size; for instance, on the IBM PC and compatibles, a boot sector should typically work in only 32 KB (later relaxed to 64 KB) of system memory and not use instructions not supported by the original 8088/8086 processors. The first stage of boot loaders (FSBL, first-stage boot loader) located on fixed disks and removable drives must fit into the first 446 bytes of the Master Boot Record in order to leave room for the default 64-byte partition table with four partition entries and the two-byte boot signature, which the BIOS requires for a proper boot loader — or even less, when additional features like more than four partition entries (up to 16 with 16 bytes each), a disk signature (6 bytes), a disk timestamp (6 bytes), an Advanced Active Partition (18 bytes) or special multi-boot loaders have to be supported as well in some environments. In floppy and superfloppy Volume Boot Records, up to 59 bytes are occupied for the Extended BIOS Parameter Block on FAT12 and FAT16 volumes since DOS 4.0, whereas the FAT32 EBPB introduced with DOS 7.1 requires even 71 bytes, leaving only 441 bytes for the boot loader when assuming a sector size of 512 bytes. Microsoft boot sectors therefore traditionally imposed certain restrictions on the boot process, for example, the boot file had to be located at a fixed position in the root directory of the file system and stored as consecutive sectors, conditions taken care of by the codice_1 command and slightly relaxed in later versions of DOS. The boot loader was then able to load the first three sectors of the file into memory, which happened to contain another embedded boot loader able to load the remainder of the file into memory. When they added LBA and FAT32 support, they even switched to a two-sector boot loader using 386 instructions. At the same time other vendors managed to squeeze much more functionality into a single boot sector without relaxing the original constraints on the only minimal available memory and processor support. For example, DR-DOS boot sectors are able to locate the boot file in the FAT12, FAT16 and FAT32 file system, and load it into memory as a whole via CHS or LBA, even if the file is not stored in a fixed location and in consecutive sectors.
Second-stage boot loader.
Second-stage boot loaders, such as GNU GRUB, BOOTMGR, Syslinux, NTLDR or BootX, are not themselves operating systems, but are able to load an operating system properly and transfer execution to it; the operating system subsequently initializes itself and may load extra device drivers. The second-stage boot loader does not need drivers for its own operation, but may instead use generic storage access methods provided by system firmware such as the BIOS or Open Firmware, though typically with restricted hardware functionality and lower performance.
Many boot loaders (like GNU GRUB, Windows's BOOTMGR, and Windows NT/2000/XP's NTLDR) can be configured to give the user multiple booting choices. These choices can include different operating systems (for dual or multi-booting from different partitions or drives), different versions of the same operating system (in case a new version has unexpected problems), different operating system loading options (e.g., booting into a rescue or safe mode), and some standalone programs that can function without an operating system, such as memory testers (e.g., memtest86+), a basic shell (as in GNU GRUB), or even games (see List of PC Booter games). Some boot loaders can also load other boot loaders; for example, GRUB loads BOOTMGR instead of loading Windows directly. Usually a default choice is preselected with a time delay during which a user can press a key to change the choice; after this delay, the default choice is automatically run so normal booting can occur without interaction.
The boot process can be considered complete when the computer is ready to interact with the user, or the operating system is capable of running system programs or application programs. Typical modern personal computers boot in about one minute, of which about 15 seconds are taken by a power-on self-test (POST) and a preliminary boot loader, and the rest by loading the operating system and other software. Time spent after the operating system loading can be considerably shortened to as little as 3 seconds by bringing the system up with all cores at once, as with coreboot. Large servers may take several minutes to boot and start all their services.
Many embedded systems must boot immediately. For example, waiting a minute for a digital television or a GPS navigation device to start is generally unacceptable. Therefore, such devices have software systems in ROM or flash memory so the device can begin functioning immediately; little or no loading is necessary, because the loading can be precomputed and stored on the ROM when the device is made.
Large and complex systems may have boot procedures that proceed in multiple phases until finally the operating system and other programs are loaded and ready to execute. Because operating systems are designed as if they never start or stop, a boot loader might load the operating system, configure itself as a mere process within that system, and then irrevocably transfer control to the operating system. The boot loader then terminates normally as any other process would.
Network booting.
Most computers are also capable of booting over a computer network. In this scenario, the operating system is stored on the disk of a server, and certain parts of it are transferred to the client using a simple protocol such as the Trivial File Transfer Protocol (TFTP). After these parts have been transferred, the operating system takes over the control of the booting process.
As with the second-stage boot loader, network booting begins by using generic network access methods provided by the network interface's boot ROM, which typically contains a Preboot Execution Environment (PXE) image. No drivers are required, but the system functionality is limited until the operating system kernel and drivers are transferred and started. As a result, once the ROM-based booting has completed it is entirely possible to network boot into an operating system that itself does not have the ability to use the network interface.
Personal computers (PC).
Boot devices.
The boot device is the device from which the operating system is loaded. A modern PC BIOS supports booting from various devices, typically a local hard disk drive via the Master Boot Record (MBR) (and of several MS-DOS partitions on such a disk, or GPT through GRUB 2), an optical disc drive (using El Torito), a USB mass storage device (FTL-based flash drive, SD card, or multi-media card slot; hard disk drive, optical disc drive, etc.), or a network interface card (using PXE). Older, less common BIOS-bootable devices include floppy disk drives, SCSI devices, Zip drives, and LS-120 drives.
Typically, the BIOS will allow the user to configure a "boot order". If the boot order is set to "first, the DVD drive; second, the hard disk drive", then the BIOS will try to boot from the DVD drive, and if this fails (e.g. because there is no DVD in the drive), it will try to boot from the local hard drive.
For example, on a PC with Windows XP installed on the hard drive, the user could set the boot order to the one given above, and then insert a Linux Live CD in order to try out Linux without having to install an operating system onto the hard drive. This is an example of dual booting, in which the user chooses which operating system to start after the computer has performed its Power-on self-test (POST). In this example of dual booting, the user chooses by inserting or removing the CD from the computer, but it is more common to choose which operating system to boot by selecting from a BIOS or UEFI boot menu, by using the computer keyboard; the boot menu is typically entered by pressing or keys during the POST.
Several devices are available that enable the user to "quick-boot" into what is usually a variant of Linux for various simple tasks such as Internet access; examples are Splashtop and Latitude ON.
Boot sequence.
Upon starting, an IBM-compatible personal computer's x86 CPU executes, in real mode, the instruction located at reset vector (the physical memory address FFFF0h on 16-bit x86 processors and FFFFFFF0h on 32-bit and 64-bit x86 processors), usually pointing to the BIOS entry point inside the ROM. This memory location typically contains a jump instruction that transfers execution to the location of the BIOS start-up program. This program runs a power-on self-test (POST) to check and initialize required devices such as DRAM and the PCI bus (including running embedded ROMs). The most complicated step is setting up DRAM over SPI, made more difficult by the fact that at this point memory is very limited.
After initializing required hardware, the BIOS goes through a pre-configured list of non-volatile storage devices ("boot device sequence") until it finds one that is bootable. A bootable device is defined as one that can be read from, and where the last two bytes of the first sector contain the little-endian word AA55h, found as byte sequence 55h, AAh on disk (also known as the MBR boot signature), or where it is otherwise established that the code inside the sector is executable on x86 PCs.
Coreboot splits the initialization and boot services into distinct parts, supporting "payloads" such as SeaBIOS, Tianocore, GRUB, and Linux directly (from flash).
Once the BIOS has found a bootable device it loads the boot sector to linear address 7C00h (usually segment:offset 0000h:7C00h, but some BIOSes erroneously use 07C0h:0000h) and transfers execution to the boot code. In the case of a hard disk, this is referred to as the Master Boot Record (MBR) and is by definition not operating-system specific. The conventional MBR code checks the MBR's partition table for a partition set as "bootable" (the one with "active" flag set). If an active partition is found, the MBR code loads the boot sector code from that partition, known as Volume Boot Record (VBR), and executes it.
The VBR is often operating-system specific; however, in most operating systems its main function is to load and execute the operating system kernel, which continues startup.
If there is no active partition, or the active partition's boot sector is invalid, the MBR may load a secondary boot loader which will select a partition (often via user input) and load its boot sector, which usually loads the corresponding operating system kernel. In some cases, the MBR may also attempt to load secondary boot loaders before trying to boot the active partition. If all else fails, it should issue an INT 18h BIOS interrupt call (followed by an INT 19h just in case INT 18h would return) in order to give back control to the BIOS, which would then attempt to boot off other devices, attempt a remote boot via network or invoke ROM BASIC.
Some systems (particularly newer Macintoshes and new editions of Microsoft Windows) use Intel's EFI. Also coreboot allows a computer to boot without having the firmware/BIOS constantly running in system management mode. 16-bit BIOS interfaces are required by certain x86 operating systems, such as DOS and Windows 3.1/95/98 (and all when not booted via UEFI). However, most boot loaders retain 16-bit BIOS call support.
Other kinds of boot sequences.
Some modern CPUs and microcontrollers (for example, TI OMAP) or sometimes even DSPs may have boot ROM with boot code integrated directly into their silicon, so such a processor could perform quite a sophisticated boot sequence on its own and load boot programs from various sources like NAND flash, SD or MMC card and so on. It is difficult to hardwire all the required logic for handling such devices, so an integrated boot ROM is used instead in such scenarios. Boot ROM usage enables more flexible boot sequences than hardwired logic could provide. For example, the boot ROM could try to perform boot from multiple boot sources. Also, a boot ROM is often able to load a boot loader or diagnostic program via serial interfaces like UART, SPI, USB and so on. This feature is often used for system recovery purposes when for some reasons usual boot software in non-volatile memory got erased, and it could also be used for initial non-volatile memory programming when there is clean non-volatile memory installed and hence no software available in the system yet.
Some embedded system designs may also include an intermediary boot sequence step in form of additional code that gets loaded into system RAM by the integrated boot ROM. Additional code loaded that way usually serves as a way for overcoming platform limitations, such as small amounts of RAM, so a dedicated primary boot loader, such as Das U-Boot, can be loaded as the next step in system's boot sequence. The additional code and boot sequence step are usually referred to as "secondary program loader" (SPL).
It is also possible to take control of a system by using a hardware debug interface such as JTAG. Such an interface may be used to write the boot loader program into bootable non-volatile memory (e.g. flash) by instructing the processor core to perform the necessary actions to program non-volatile memory. Alternatively, the debug interface may be used to upload some diagnostic or boot code into RAM, and then to start the processor core and instruct it to execute the uploaded code. This allows, for example, the recovery of embedded systems where no software remains on any supported boot device, and where the processor does not have any integrated boot ROM. JTAG is a standard and popular interface; many CPUs, microcontrollers and other devices are manufactured with JTAG interfaces (as of 2009).
Some microcontrollers provide special hardware interfaces which cannot be used to take arbitrary control of a system or directly run code, but instead they allow the insertion of boot code into bootable non-volatile memory (like flash memory) via simple protocols. Then at the manufacturing phase, such interfaces are used to inject boot code (and possibly other code) into non-volatile memory. After system reset, the microcontroller begins to execute code programmed into its non-volatile memory, just like usual processors are using ROMs for booting. Most notably this technique is used by Atmel AVR microcontrollers, and by others as well. In many cases such interfaces are implemented by hardwired logic. In other cases such interfaces could be created by software running in integrated on-chip boot ROM from GPIO pins.
Most digital signal processors have a serial mode boot, and a parallel mode boot, such as the host port interface (HPI boot)
In case of DSPs there is often a second microprocessor or microcontroller present in the system design, and this is responsible for overall system behavior, interrupt handling, dealing with external events, user interface, etc. while the DSP is dedicated to signal processing tasks only. In such systems the DSP could be booted by another processor which is sometimes referred as the "host processor" (giving name to a Host Port). Such a processor is also sometimes referred as the "master", since it usually boots first from its own memories and then controls overall system behavior, including booting of the DSP, and then further controlling the DSP's behavior. The DSP often lacks its own boot memories and relies on the host processor to supply the required code instead. The most notable systems with such a design are cell phones, modems, audio and video players and so on, where a DSP and a CPU/microcontroller are co-existing.
Many FPGA chips load their configuration from an external serial EEPROM ("configuration ROM") on power-up.

</doc>
<doc id="40910" url="https://en.wikipedia.org/wiki?curid=40910" title="Common carrier">
Common carrier

A common carrier in common law countries (corresponding to a public carrier in civil law systems, usually called simply a carrier) is a person or company that transports goods or people for any person or company and that is responsible for any possible loss of the goods during transport. A common carrier offers its services to the general public under license or authority provided by a regulatory body. The regulatory body has usually been granted "ministerial authority" by the legislation that created it. The regulatory body may create, interpret, and enforce its regulations upon the common carrier (subject to judicial review) with independence and finality, as long as it acts within the bounds of the enabling legislation.
A common carrier is distinguished from a contract carrier (also called a "public carrier" in UK English), which is a carrier that transports goods for only a certain number of clients and that can refuse to transport goods for anyone else, and from a private carrier. A common carrier holds itself out to provide service to the general public without discrimination (to meet the needs of the regulator's quasi judicial role of impartiality toward the public's interest) for the "public convenience and necessity". A common carrier must further demonstrate to the regulator that it is "fit, willing, and able" to provide those services for which it is granted authority. Common carriers typically transport persons or goods according to defined and published routes, time schedules, and rate tables upon the approval of regulators. Public airlines, railroads, bus lines, taxicab companies, cruise ships, motor carriers (i.e., trucking companies), and other freight companies generally operate as common carriers. Under US law, an ocean freight forwarder cannot act as a common carrier.
The term "common carrier" is a common law term, seldom used in continental Europe because it has no exact equivalent in civil-law systems. In continental Europe, the functional equivalent of a common carrier is referred to as a "public carrier" (or simply as a "carrier"). (However, "public carrier" in continental Europe is different from "public carrier" in British English, where it is a synonym for "contract carrier".)
General.
Although common carriers generally transport people or goods, in the United States the term may also refer to telecommunications service providers and public utilities. In certain U.S. states, amusement parks that operate roller coasters and comparable rides have been found to be common carriers; a famous example is Disneyland.
Regulatory bodies may also grant carriers the authority to operate under contract with their customers instead of under common carrier authority, rates, schedules and rules. These regulated carriers, known as contract carriers, must demonstrate that they are "fit, willing and able" to provide service, according to standards enforced by the regulator. However, contract carriers are specifically not required to demonstrate that they will operate for the "public convenience and necessity". A contract carrier may be authorized to provide service over either fixed routes and schedules, i.e., as regular route carrier or on an "ad hoc" basis as an irregular route carrier.
It should be mentioned that the carrier refers only to the person (legal or physical) that enters into a contract of carriage with the shipper. The carrier does not necessarily have to own or even be in the possession of a means of transport. Unless otherwise agreed upon in the contract, the carrier may use whatever means of transport approved in its operating authority, as long as it is the most favourable from the cargo interests' point of view. The carriers' duty is to get the goods to the agreed destination within the agreed time or within reasonable time. 
The person that is physically transporting the goods on a means of transport is referred to as the "actual carrier". When a carrier subcontracts with another provider, such as an independent contractor or a third-party carrier, the common carrier is said to be providing "substituted service". The same person may hold both common carrier and contract carrier authority. In the case of a rail line in the US, the owner of the property is said to retain a "residual common carrier obligation", unless otherwise transferred (such as in the case of a commuter rail system, where the authority operating passenger trains may acquire the property but not this obligation from the former owner), and must operate the line if service is terminated. 
In contrast, private carriers are not licensed to offer a service to the public. Private carriers generally provide transport on an irregular or "ad hoc" basis for their owners.
Carriers were very common in rural areas prior to motorised transport. Regular services by horse-drawn vehicles would ply to local towns, taking goods to market or bringing back purchases for the village. If space permitted, passengers could also travel.
Telecommunications.
In the United States, telecommunications carriers are regulated by the Federal Communications Commission under title II of the Communications Act of 1934.
The Telecommunications Act of 1996 made extensive revisions to the "Title II" provisions regarding common carriers and repealed the judicial 1982 AT&T consent decree (often referred to as the "modification of final judgment" or "MFJ") that effectuated the breakup of AT&T's Bell System. Further, the Act gives telephone companies the option of providing video programming on a common carrier basis or as a conventional cable television operator. If it chooses the former, the telephone company will face less regulation but will also have to comply with FCC regulations requiring what the Act refers to as "open video systems". The Act generally bars, with certain exceptions including most rural areas, acquisitions by telephone companies of more than a 10 percent interest in cable operators (and vice versa) and joint ventures between telephone companies and cable systems serving the same areas.
The FCC classified Internet Service Providers as common carriers, effective June 12, 2015, for the purpose of enforcing net neutrality. Before that time, the Good Samaritan provision of the Communications Decency Act established immunity from liability for third party content on grounds of libel or slander, and the DMCA established that ISPs that comply with the DMCA would not be liable for the copyright violations of third parties on their network.
Pipelines.
In the United States, many oil, gas and CO2 pipelines are common carriers. The Federal Energy Regulatory Commission (FERC) regulates rates charged and other tariff terms imposed by interstate common carrier pipelines. Intrastate common carrier pipeline tariffs are often regulated by state agencies. The US and many states have delegated the power of eminent domain to common carrier gas pipelines.
Legal implications.
Common carriers are subject to special laws and regulations that differ depending on the means of transport used, e.g. sea carriers are often governed by quite different rules from road carriers or railway carriers. In common law jurisdictions as well as under international law, a common carrier is absolutely liable for goods carried by it, with four exceptions:
A sea carrier may also, according to the Hague-Visby Rules, escape liability on other grounds than the above-mentioned, e.g. a sea carrier is not liable for damages to the goods if the damage is the result of a fire on board the ship or the result of a navigational error committed by the ship's master or other crewmember.
Carriers typically incorporate further exceptions into a contract of carriage, often specifically claiming not to be a common carrier.
An important legal requirement for common carrier as public provider is that it cannot "discriminate", that is refuse the service unless there is some compelling reason. As of 2007, the status of Internet service providers as common carriers and their rights and responsibilities is widely debated (network neutrality).
It is also important to remember that the term common carrier does not exist in continental Europe but is distinctive to common law systems, particularly law systems in the US.
In "Ludditt v Ginger Coote Airways" the Privy Council (Lord Macmillan, Lord Wright, Lord Porter and Lord Simonds) held the liability of a public or common carrier of passengers is only to carry with due care. This is more limited than that of a common carrier of goods. The complete freedom of a carrier of passengers at common law to make such contracts as he thinks fit was not curtailed by the Railway and Canal Traffic Act 1854, and a specific contract that enlarges, diminishes or excludes his duty to take care (e.g., by a condition that the passenger travels "at his own risk against all casualties") cannot be pronounced to be unreasonable if the law authorises it. There was nothing in the provisions of the Canadian Transport Act 1938 section 25 that would invalidate a provision excluding liability. "Grand Trunk Railway Co of Canada v Robinson" A.C. 740 was followed and "Peek v North Staffordshire Railway" 11 E.R. 1109 was distinguished.

</doc>
<doc id="40911" url="https://en.wikipedia.org/wiki?curid=40911" title="Common control">
Common control

In telecommunication, a common control is an automatic telephone exchange arrangement in which the control equipment necessary for the establishment of connections is shared by being associated with a given call only during the period required to accomplish the control function for the given call. The first examples deployed on a major scale were the Director telephone system in London and the panel switch in the Bell System. Direct control telephone exchanges became rare in the 1960s, leaving only common control ones.
Systems which have control subsystem as an integral part of the switching network itself were known as direct control switching systems. Systems in which the control subsytem is outside the switching network are known as Common control systems. Strowger exchanges are usually direct control systems, whereas crossbar, electronic exchanges including all stored program control systems are common control systems. Common control is also known as indirect control or register control.
During the 1970s, common control exchanges became stored program control exchanges, using in the 1980s common-channel signaling in which the channels that are used for signaling are not used for message traffic.

</doc>
<doc id="40912" url="https://en.wikipedia.org/wiki?curid=40912" title="Common Management Information Service">
Common Management Information Service

The Common Management Information Service (CMIS) is the service interface specified in ITU-T Recommendation X.710, ISO/IEC International Standard 9595 that is employed by OSI network elements for network management. It defines the service interface that is implemented by the Common Management Information Protocol (CMIP) as specified in ITU-T Recommendation X.711, ISO/IEC International Standard 9596-1. CMIS is part of the Open Systems Interconnection (OSI) body of international network standards.
Note the term CMIP is sometimes used erroneously when CMIS is intended. CMIS/CMIP is most often used in telecommunication applications, in other areas SNMP has become more popular.
Services.
The following services are made available by the Common Management Information Service Element (CMISE) to allow management of network elements:
Management association services.
To transfer management information between open systems using CMIS/CMIP, peer connections, "i.e.," associations, must be established. This requires the establishment of an Application layer association, a Session layer connection, a Transport layer connection, and, depending on supporting communications technology, Network layer and Link layer connections.
CMIS initially defined management association services but it was later decided these services could be provided by ACSE and these services were removed. Below is a list of these services which were subsequently removed from ISO 9595:

</doc>
<doc id="40913" url="https://en.wikipedia.org/wiki?curid=40913" title="Common-mode interference">
Common-mode interference

In telecommunication, the term common-mode interference has the following meanings: 
Techniques for dealing with common-mode interference.
Common mode noise may be isolated from the desired signal by various means:

</doc>
<doc id="40915" url="https://en.wikipedia.org/wiki?curid=40915" title="Communications blackout">
Communications blackout

In telecommunications, communications blackouts are
Technical failures.
Uptime being a key goal of most communications networks, uninterruptible power supplies and backup generators are typically used to ensure high-reliability power.
Wireless networks may be subject to radio jamming; wired networks can be physically severed. Network design can also play a role in maintaining communications reliability; depending on the constraints in building a fiber-optic network, a self-healing ring topology may be used.
Spacecraft reentry.
The communications blackouts that affect spacecraft re-entering the Earth's atmosphere, which are also known as radio blackouts, ionization blackouts, or reentry blackouts, are caused by an envelope of ionized air around the craft, created by the heat from the compression of the atmosphere by the craft. The ionized air interferes with radio signals. For the Mercury, Gemini, and Apollo spacecraft, such communications blackouts lasted for several minutes. Gemini 2, for example, endured such a blackout for four minutes, beginning at 9 minutes 5 seconds into the flight.
For Apollo missions, the communications blackout was approximately three minutes long. For Apollo 16, for example, pre-advisory data (PAD) for re-entry listed the expected times for re-entry communications blackout to be from 0 minutes 16 seconds after entry interface to 3 minutes 33 seconds after entry interface (a total of 3 minutes 17 seconds). For the Apollo 13 mission, the blackout was much longer than normal because the flight path of the spacecraft was unexpectedly at a much shallower angle than normal. According to the mission log maintained by Gene Kranz, the Apollo 13 re-entry blackout lasted around 6 minutes, beginning at 142:39 and ending at 142:45, and was 1 minute 27 seconds longer than had been predicted.
Communications blackouts for re-entry are not solely confined to entry into Earth's atmosphere. They apply to entry into any atmosphere where such ionization occurs around a craft. The Mars Pathfinder endured a 30-second communications blackout as it entered Mars' atmosphere, for example. The Huygens probe endured a communications blackout as it entered the atmosphere of Titan.
Until the creation of the Tracking and Data Relay Satellite System (TDRSS), the Space Shuttle endured a 30-minute blackout. The TDRSS allowed the Shuttle to communicate by relay with a Tracking and Data Relay Satellite during re-entry, through a "hole" in the ionized air envelope at the tail end of the craft, created by the Shuttle's shape.
Space weather.
Radio blackouts on Earth caused by space weather are measured by the National Oceanic and Atmospheric Administration on a scale that goes from 1 (minor) to 5 (extreme).
Solar position.
Communications can also be lost when the Sun is blocking or behind one station in the same line of sight; Sun outages periodically interrupt communications with geosynchronous satellites. It is also a common problem for interplanetary space missions.

</doc>
<doc id="40916" url="https://en.wikipedia.org/wiki?curid=40916" title="Communications center">
Communications center

In telecommunication, the term communications center has the following meanings: 

</doc>
<doc id="40918" url="https://en.wikipedia.org/wiki?curid=40918" title="Communications deception">
Communications deception

In telecommunication, the term communications deception has the following meanings:

</doc>
<doc id="40919" url="https://en.wikipedia.org/wiki?curid=40919" title="Communications-electronics">
Communications-electronics

In telecommunication, communications-electronics (C-E) is the specialized field concerned with the use of electronic devices and systems for the acquisition or acceptance, processing, storage, display, analysis, protection, disposition, and transfer of information. 
C-E includes the wide range of responsibilities and actions relating to:
Electronic Communications Equipment.
Communication electronics radio equipment has been a rapidly growing industry for more than a century. Homeland Security in the USA is one of the reasons for the fast growth. Since the invention of the “solid state” transistor in the 1950s and the TTL (transistor-transistor logic) that led to the development of the IC (integrated circuit) in the 1960s the growth in the field of electronics has been phenomenal. As now witnessed in the “radio communications” field. The latest trend is to send conventional LMR (land-mobile-radio) signals over the Internet (Internet Protocol) this is called RoIP (Radio over Internet Protocol), which is just like VoIP (Voice over Internet Protocol) but uses the radio. By sending signals over the Internet it allows radios to be connected together all over the world. Hence: the “Communications Revolution”.

</doc>
<doc id="40921" url="https://en.wikipedia.org/wiki?curid=40921" title="Communications protection">
Communications protection

In telecommunications, communications protection is the application of communications security (COMSEC) measures to telecommunications systems in order to: (a) deny unauthorized access to sensitive unclassified information of value, (b) prevent disruption of telecommunications services, or (c) ensure the authenticity of information handled by telecommunications systems.

</doc>
<doc id="40922" url="https://en.wikipedia.org/wiki?curid=40922" title="Communications security">
Communications security

Communications security is the discipline of preventing unauthorized interceptors from accessing telecommunications in an intelligible form, while still delivering content to the intended recipients. In the United States Department of Defense culture, it is often referred to by the abbreviation COMSEC. The field includes cryptosecurity, transmission security, and physical security of COMSEC equipment.
COMSEC is used to protect both classified and unclassified traffic on military communications networks, including voice, video, and data. It is used for both analog and digital applications, and both wired and wireless links.
Voice over secure internet protocol VOSIP has become the de facto standard for securing voice communication, replacing the need for Secure Terminal Equipment (STE) in much of the U.S. Department of Defense. USCENTCOM moved entirely to VOSIP in 2008.
Related terms.
Types of COMSEC equipment:
DoD key management system.
The EKMS is DoD key management, COMSEC material distribution, and logistics support system. The NSA established the EKMS program to supply electronic key to COMSEC devices in securely and timely manner, and to provide COMSEC managers with an automated system capable of ordering, generation, production, distribution, storage, security accounting, and access control.
The Army's platform in the four-tiered EKMS, AKMS, automates frequency management and COMSEC management operations. It eliminates paper keying material, hardcopy SOI, and associated time and resource-intensive courier distribution. It has 4 components:

</doc>
<doc id="40924" url="https://en.wikipedia.org/wiki?curid=40924" title="Communications survivability">
Communications survivability

In telecommunication, communications survivability is the ability of communications systems to continue to operate effectively under adverse conditions, though portions of the system may be damaged or destroyed. 
Various methods may be used to maintain communications services, such as using alternate routing, different transmission media or methods, redundant equipment, and sites and equipment that are radiation hardened.

</doc>
<doc id="40925" url="https://en.wikipedia.org/wiki?curid=40925" title="Communications system">
Communications system

In telecommunication, a communications system is a collection of individual communications networks, transmission systems, relay stations, tributary stations, and data terminal equipment (DTE) usually capable of interconnection and interoperation to form an integrated whole. The components of a communications system serve a common purpose, are technically compatible, use common procedures, respond to controls, and operate in union. Telecommunications is a method of communication (e.g., for sports broadcasting, mass media, journalism, etc.). A communications subsystem is a functional unit or operational assembly that is smaller than the larger assembly under consideration...
Types.
By media.
An optical communication system is any form of telecommunication that uses light as the transmission medium. Equipment consists of a transmitter, which encodes a "message" into an optical "signal", a "channel", which carries the signal to its destination, and a receiver, which reproduces the message from the received optical signal. Fiber-optic communication systems transmit information from one place to another by sending light through an optical fiber. The light forms a carrier signal that is modulated to carry information.
A radio communication system is composed of several communications subsystems that give exterior communications capabilities. A radio communication system comprises a transmitting conductor in which electrical oscillations or currents are produced and which is arranged to cause such currents or oscillations to be propagated through the free space medium from one point to another remote therefrom and a receiving conductor at such distant point adapted to be excited by the oscillations or currents propagated from the transmitter.
Power line communication systems operate by impressing a modulated carrier signal on power wires. Different types of powerline communications use different frequency bands, depending on the signal transmission characteristics of the power wiring used. Since the power wiring system was originally intended for transmission of AC power, the power wire circuits have only a limited ability to carry higher frequencies. The propagation problem is a limiting factor for each type of power line communications.
By Technology.
A duplex communication system is a system composed of two connected parties or devices which can communicate with one another in both directions. The term "duplex" is used when describing communication between two parties or devices. Duplex systems are employed in nearly all communications networks, either to allow for a communication "two-way street" between two connected parties or to provide a "reverse path" for the monitoring and remote adjustment of equipment in the field.
An Antenna is basically a small length of a qwert conductor that is used to radiate or receive electromagnetic waves.
It acts as a conversion device.At the transmitting end it converts high frequency current into electromagnetic waves.At the receiving end it transforms electromagnetic waves into electrical signals that is fed into the input of the receiver. several types of antenna are used in communication.
Examples of communications subsystems include the Defense Communications System (DCS).
By Application area.
A tactical communications system is a communications system that 
(a) is used within, or in direct support of tactical forces
(b) is designed to meet the requirements of changing tactical situations and varying environmental conditions, 
(c) provides securable communications, such as voice, data, and video, among mobile users to facilitate command and control within, and in support of, tactical forces, and 
(d) usually requires extremely short installation times, usually on the order of hours, in order to meet the requirements of frequent relocation.
An Emergency communication system is any system (typically computer based) that is organized for the primary purpose of supporting the two way communication of emergency messages between both individuals and groups of individuals. These systems are commonly designed to integrate the cross-communication of messages between are variety of communication technologies.
An Automatic call distributor (ACD) is a communication system that automatically queues, assigns and connects callers to handlers. This is used often in customer service (such as for product or service complaints), ordering by telephone (such as in a ticket office), or coordination services (such as in air traffic control).
A Voice Communication Control System (VCCS) is essentially an ACD with characteristics that make it more adapted to use in critical situations (no waiting for dialtone, or lengthy recorded announcements, radio and telephone lines equally easily connected to, individual lines immediately accessible etc..)
See also.
Automatic call distributor

</doc>
<doc id="40927" url="https://en.wikipedia.org/wiki?curid=40927" title="Companding">
Companding

In telecommunication and signal processing companding (occasionally called compansion) is a method of mitigating the detrimental effects of a channel with limited dynamic range. The name is a combination of the words compressing and expanding. The use of companding allows signals with a large dynamic range to be transmitted over facilities that have a smaller dynamic range capability. Companding is employed in telephony and other audio applications such as professional wireless microphones and analog recording.
How it works.
While the dynamic range compression used in audio recording and the like depends on a variable-gain amplifier, and so is a locally linear process (linear for short regions, but not globally), companding is non-linear and takes place in the same way at all points in time. The dynamic range of a signal is compressed before transmission and is expanded to the original value at the receiver.
The electronic circuit that does this is called a compander and works by compressing or expanding the dynamic range of an analog electronic signal such as sound recorded by a microphone. One variety is a triplet of amplifiers: a logarithmic amplifier, followed by a variable-gain linear amplifier and an exponential amplifier. Such a triplet has the property that its output voltage is proportional to the input voltage raised to an adjustable power.
Companded quantization is the combination of three functional building blocks – namely, a (continuous-domain) signal dynamic range "compressor", a limited-range uniform quantizer, and a (continuous-domain) signal dynamic range "expander" that inverts the compressor function. This type of quantization is frequently used in telephony systems. 
In practice, companders are designed to operate according to relatively simple dynamic range compressor functions that are designed to be suitable for implementation using simple analog electronic circuits. The two most popular compander functions used for telecommunications are the A-law and μ-law functions.
Applications.
Companding is used in digital telephony systems, compressing before input to an analog-to-digital converter, and then expanding after a digital-to-analog converter. This is equivalent to using a non-linear ADC as in a T-carrier telephone system that implements A-law or μ-law companding. This method is also used in digital file formats for better signal-to-noise ratio (SNR) at lower bit rates. For example, a linearly encoded 16-bit PCM signal can be converted to an 8-bit WAV or AU file while maintaining a decent SNR by compressing before the transition to 8-bit and expanding after a conversion back to 16-bit. This is effectively a form of lossy audio data compression.
Professional wireless microphones do this since the dynamic range of the microphone audio signal itself is larger than the dynamic range provided by radio transmission. Companding also reduces the noise and crosstalk levels at the receiver.
Companders are used in concert audio systems and in some noise reduction schemes such as dbx and Dolby NR (all versions).
History.
The use of companding in an analog picture transmission system was patented by A. B. Clark of AT&T in 1928 (filed in 1925):
In 1942, Clark and his team completed the SIGSALY secure voice transmission system that included the first use of companding in a PCM (digital) system.
In 1953, B. Smith showed that a nonlinear DAC could be complemented by the inverse nonlinearity in a successive-approximation ADC configuration, simplifying the design of digital companding systems.
In 1970, H. Kaneko developed the uniform description of segment (piecewise linear) companding laws that had by then been adopted in digital telephony.
In the 1980s (and '90s), many of the music equipment manufacturers (Roland, Yamaha, Korg) used companding when compressing the library waveform data in their digital synthesizers. This dates back to the late '80s when memory chips were often one of the most costly components in the instrument. Manufacturers usually quoted the amount of memory in its compressed form: i.e. 24MB of physical waveform ROM in a Korg Trinity is actually 48MB when uncompressed. Similarly, Roland SR-JV expansion boards were usually advertised as 8MB boards with '16MB-equivalent content'. Careless copying of this technical information, omitting the "equivalence" reference, can often cause confusion.

</doc>
<doc id="40928" url="https://en.wikipedia.org/wiki?curid=40928" title="Comparably efficient interconnection">
Comparably efficient interconnection

In telecommunication, a comparably efficient interconnection (CEI) is an equal-access concept developed by the FCC stating that, ". . . if a carrier offers an enhanced service, it should be required to offer network interconnection (or collocation) opportunities to others that are comparably efficient to the interconnection that its enhanced service enjoys. Accordingly, a carrier would be required to implement CEI only as it introduces new enhanced services." "Report and Order" June 16, 1986

</doc>
<doc id="40929" url="https://en.wikipedia.org/wiki?curid=40929" title="Comparator">
Comparator

In electronics, a comparator is a device that compares two voltages or currents and outputs a digital signal indicating which is larger. It has two analog input terminals formula_1 and formula_2 and one binary digital output formula_3. The output is ideally 
A comparator consists of a specialized high-gain differential amplifier. They are commonly used in devices that measure and digitize analog signals, such as analog-to-digital converters (ADCs), as well as relaxation oscillators.
Differential voltage.
The differential voltages must stay within the limits specified by the manufacturer. Early integrated comparators, like the LM111 family, and certain high-speed comparators like the LM119 family, require differential voltage ranges substantially lower than the power supply voltages (±15 V vs. 36 V). "Rail-to-rail" comparators allow any differential voltages within the power supply range. When powered from a bipolar (dual rail) supply, 
or, when powered from a unipolar TTL/CMOS power supply:
Specific rail-to-rail comparators with p-n-p input transistors, like the LM139 family, allow input potential to drop 0.3 volts "below" the negative supply rail, but do not allow it to rise above the positive rail. Specific ultra-fast comparators, like the LMH7322, allow input signal to swing below the negative rail "and" above the positive rail, although by a narrow margin of only 0.2 V. Differential input voltage (the voltage between two inputs) of a modern rail-to-rail comparator is usually limited only by the full swing of power supply.
Op-amp voltage comparator.
An operational amplifier (op-amp) has a well balanced difference input and a very high gain. This parallels the characteristics of comparators and can be substituted in applications with low-performance requirements.
In theory, a standard op-amp operating in open-loop configuration (without negative feedback) may be used as a low-performance comparator. When the non-inverting input (V+) is at a higher voltage than the inverting input (V-), the high gain of the op-amp causes the output to saturate at the highest positive voltage it can output. When the non-inverting input (V+) drops below the inverting input (V-), the output saturates at the most negative voltage it can output. The op-amp's output voltage is limited by the supply voltage. An op-amp operating in a linear mode with negative feedback, using a balanced, split-voltage power supply, (powered by ± VS) has its transfer function typically written as: formula_7. However, this equation may not be applicable to a comparator circuit which is non-linear and operates open-loop (no negative feedback)
In practice, using an operational amplifier as a comparator presents several disadvantages as compared to using a dedicated comparator:
Working.
A dedicated voltage comparator will generally be faster than a general-purpose operational amplifier pressed into service as a comparator. A dedicated voltage comparator may also contain additional features such as an accurate, internal voltage reference, an adjustable hysteresis and a clock gated input.
A dedicated voltage comparator chip such as LM339 is designed to interface with a digital logic interface (to a TTL or a CMOS). The output is a binary state often used to interface real world signals to digital circuitry (see analog to digital converter). If there is a fixed voltage source from, for example, a DC adjustable device in the signal path, a comparator is just the equivalent of a cascade of amplifiers. When the voltages are nearly equal, the output voltage will not fall into one of the logic levels, thus analog signals will enter the digital domain with unpredictable results. To make this range as small as possible, the amplifier cascade is high gain. The circuit consists of mainly Bipolar transistors. For very high frequencies, the input impedance of the stages is low. This reduces the saturation of the slow, large P-N junction bipolar transistors that would otherwise lead to long recovery times. Fast small Schottky diodes, like those found in binary logic designs, improve the performance significantly though the performance still lags that of circuits with amplifiers using analog signals. Slew rate has no meaning for these devices. For applications in flash ADCs the distributed signal across eight ports matches the voltage and current gain after each amplifier, and resistors then behave as level-shifters.
The LM339 accomplishes this with an open collector output. When the inverting input is at a higher voltage than the non inverting input, the output of the comparator connects to the negative power supply. When the non inverting input is higher than the inverting input, the output is 'floating' (has a very high impedance to ground).
The gain of op amp as comparator is given by this equation
V(out)=V(in)
Key specifications.
While it is easy to understand the basic task of a comparator, that is, comparing two voltages or currents, several parameters must be considered while selecting a suitable comparator:
Speed and power.
While in general comparators are "fast," their circuits are not immune to the classic speed-power tradeoff. High speed comparators use transistors with larger aspect ratios and hence also consume more power. Depending on the application, select either a comparator with high speed or one that saves power. For example, nano-powered comparators in space-saving chip-scale packages (UCSP), DFN or SC70 packages such as MAX9027, LTC1540, LPV7215, MAX9060 and MCP6541 are ideal for ultra-low-power, portable applications. Likewise if a comparator is needed to implement a relaxation oscillator circuit to create a high speed clock signal then comparators having few nano seconds of propagation delay may be suitable. ADCMP572 (CML output), LMH7220 (LVDS Output), MAX999 (CMOS output / TTL output), LT1719 (CMOS output / TTL output), MAX9010 (TTL output), and MAX9601 (PECL output) are examples of some good high speed comparators.
Hysteresis.
A comparator normally changes its output state when the voltage between its inputs crosses through approximately zero volts. Small voltage fluctuations due to noise, always present on the inputs, can cause undesirable rapid changes between the two output states when the input voltage difference is near zero volts. To prevent this output oscillation, a small hysteresis of a few millivolts is integrated into many modern comparators. 
For example, the LTC6702, MAX9021 and MAX9031 have internal hysteresis desensitizing them from input noise. In place of one switching point, hysteresis introduces two: one for rising voltages, and one for falling voltages. The difference between the higher-level trip value (VTRIP+) and the lower-level trip value (VTRIP-) equals the hysteresis voltage (VHYST).
If the comparator does not have internal hysteresis or if the input noise is greater than the internal hysteresis then an external hysteresis network can be built using positive feedback from the output to the non-inverting input of the comparator. The resulting Schmitt trigger circuit gives additional noise immunity and a cleaner output signal. Some comparators such as LMP7300, LTC1540, MAX931, MAX971 and ADCMP341 also provide the hysteresis control through a separate hysteresis pin. These comparators make it possible to add a programmable hysteresis without feedback or complicated equations. Using a dedicated hysteresis pin is also convenient if the source impedance is high since the inputs are isolated from the hysteresis network. When hysteresis is added then a comparator cannot resolve signals within the hysteresis band.
Output type.
Because comparators have only two output states, their outputs are near zero or near the supply voltage. Bipolar rail-to-rail comparators have a common-emitter output that produces a small voltage drop between the output and each rail. That drop is equal to the collector-to-emitter voltage of a saturated transistor. When output currents are light, output voltages of CMOS rail-to-rail comparators, which rely on a saturated MOSFET, range closer to the rails than their bipolar counterparts.
On the basis of outputs, comparators can also be classified as open drain or push–pull. Comparators with an open-drain output stage use an external pull up resistor to a positive supply that defines the logic high level. Open drain comparators are more suitable for mixed-voltage system design. Since the output is high impedance for logic level high, open drain comparators can also be used to connect multiple comparators on to a single bus. Push pull output does not need a pull up resistor and can also source current unlike an open drain output.
Internal reference.
The most frequent application for comparators is the comparison between a voltage and a stable reference. Most comparator manufacturers also offer comparators in which a reference voltage is integrated on to the chip. Combining the reference and comparator in one chip not only saves space, but also draws less supply current than a comparator with an external reference. ICs with wide range of references are available such as MAX9062 (200 mV reference), LT6700 (400 mV reference), ADCMP350 (600 mV reference), MAX9025 (1.236 V reference), MAX9040 (2.048 V reference), TLV3012 (1.24 V reference) and TSM109 (2.5 V reference).
Continuous versus clocked.
A continuous comparator will output either a "1" or a "0" any time a high or low signal is applied to its input and will change quickly when the inputs are updated. However, many applications only require comparator outputs at certain instances, such as in A/D converters and memory. By only strobing a comparator at certain intervals, higher accuracy and lower power can be achieved with a clocked (or dynamic) comparator structure, also called a latched comparator. Often latched comparators employ strong positive feedback for a "regeneration phase" when a clock is high, and have a "reset phase" when the clock is low. 
This is in contrast to a continuous comparator, which can only employ weak positive feedback since there is no reset period.
Applications.
Null detectors.
A null detector is one that functions to identify when a given value is zero. Comparators can be a type of amplifier distinctively for null comparison measurements. It is the equivalent to a very high gain amplifier with well-balanced inputs and controlled output limits. The circuit compares the two input voltages, determining the larger. The inputs are an unknown voltage and a reference voltage, usually referred to as vu and vr. A reference voltage is generally on the non-inverting input (+), while vu is usually on the inverting input (−). (A circuit diagram would display the inputs according to their sign with respect to the output when a particular input is greater than the other.) The output is either positive or negative, for example ±12 V. In this case, the idea is to detect when there is no difference between in the input voltages. This gives the identity of the unknown voltage since the reference voltage is known.
When using a comparator as a null detector, there are limits as to the accuracy of the zero value measurable. Zero output is given when the magnitude of the difference in the voltages multiplied by the gain of the amplifier is less than the voltage limits. For example, if the gain of the amplifier is 106, and the voltage limits are ±6 V, then no output will be given if the difference in the voltages is less than 6 μV. One could refer to this as a sort of uncertainty in the measurement.
Zero-crossing detectors.
For this type of detector, a comparator detects each time an ac pulse changes polarity. The output of the comparator changes state each time the pulse changes its polarity, that is the output is HI (high) for a positive pulse and LO (low) for a negative pulse squares the input signal.
Relaxation oscillator.
A comparator can be used to build a relaxation oscillator. It uses both positive and negative feedback. The positive feedback is a Schmitt trigger configuration. Alone, the trigger is a bistable multivibrator. However, the slow negative feedback added to the trigger by the RC circuit causes the circuit to oscillate automatically. That is, the addition of the RC circuit turns the hysteretic bistable multivibrator into an astable multivibrator.
Level shifter.
This circuit requires only a single comparator with an open-drain output as in the LM393, TLV3011 or MAX9028. The circuit provides great flexibility in choosing the voltages to be translated by using a suitable pull up voltage. It also allows the translation of bipolar ±5 V logic to unipolar 3 V logic by using a comparator like the MAX972.
Analog-to-digital converters.
When a comparator performs the function of telling if an input voltage is above or below a given threshold, it is essentially performing a 1-bit quantization. This function is used in nearly all analog to digital converters (such as flash, pipeline, successive approximation, delta-sigma modulation, folding, interpolating, dual-slope and others) in combination with other devices to achieve a multi-bit quantization.
Window detectors.
Comparators can also be used as window detectors. In a window detector, a comparator is used to compare two voltages and determine whether a given input voltage is under voltage or over voltage.

</doc>
<doc id="40930" url="https://en.wikipedia.org/wiki?curid=40930" title="Compatibility">
Compatibility

Compatibility may refer to:

</doc>
<doc id="40931" url="https://en.wikipedia.org/wiki?curid=40931" title="Compatible sideband transmission">
Compatible sideband transmission

A Compatible sideband transmission, also known as amplitude modulation equivalent (AME) or Single sideband-reduced carrier (SSB-RC), is a type of single sideband RF modulation in which the carrier is deliberately reinserted at a lower level after its normal suppression to permit reception by conventional AM receivers. 
The benefits of AME over conventional AM are increased spectral efficiency due to a reduction in bandwidth of 50% as well as an increase in signal efficiency. Conventional AM transmitters waste 66% of the transmitter RF power due to AM's carrier and redundant sideband. By using AME, less RF power is required at the transmitter to transmit the same quality of signal the same distance. 
AME is currently most popular in high frequency military communications.

</doc>
<doc id="40933" url="https://en.wikipedia.org/wiki?curid=40933" title="Complementary network service">
Complementary network service

In telecommunication, a complementary network service (CNS) is a means for an enhanced-service provider customer to connect to a network and to the enhanced service provider. 
Complementary network services usually consist of the customer local service, such as a business or residence, and several associated service features, such as a call-forwarding service.

</doc>
<doc id="40934" url="https://en.wikipedia.org/wiki?curid=40934" title="Component">
Component

Component may refer to:

</doc>
<doc id="40936" url="https://en.wikipedia.org/wiki?curid=40936" title="Compromise">
Compromise

To compromise is to make a deal between different parties where each party gives up part of their demand. In arguments, compromise is a concept of finding agreement through communication, through a mutual acceptance of terms—often involving variations from an original goal or desires.
Extremism is often considered as antonym to compromise, which, depending on context, may be associated with concepts of balance and tolerance. In the negative connotation, compromise may be referred to as capitulation, referring to a "surrender" of objectives, principles, or material, in the process of negotiating an agreement. In human relationships, "compromise" is frequently said to be an agreement with which no party is happy because the parties involved often feel that they either gave away too much or that they received too little.
Political compromise.
In international politics, the compromises most often discussed are usually regarded as nefarious deals with dictators, such as Neville Chamberlain's appeasement of Adolf Hitler. Margalit calls these "rotten compromises."
In democratic politics, great challenges of contemporary democracy and has become more difficult in the era of the permanent campaign, as Gutmann and Thompson show. The problem of political compromise in general is an important subject in political ethics.
Studies in compromise.
Defining and finding the best possible compromise is an important problem in fields like game theory and the voting system.
Research has indicated that suboptimal compromises are often the result of negotiators failing to realize when they have interests that are completely compatible with those of the other party and settle for suboptimal agreements. Mutually better outcomes can often be found by careful investigation of both parties' interests, especially if done early in negotiations.
The compromise solution of a multicriteria decision making or multi-criteria decision analysis problem that is the closest to the ideal could be determined by the VIKOR method, which provides a maximum utility of the majority, and a minimum individual regret of the opponent.

</doc>
<doc id="40937" url="https://en.wikipedia.org/wiki?curid=40937" title="Computer conferencing">
Computer conferencing

Computer conferencing may refer to:

</doc>
<doc id="40940" url="https://en.wikipedia.org/wiki?curid=40940" title="Concentrator">
Concentrator

In the evolution of modern telecommunications systems there was a requirement to connect large numbers of low-speed access devices with large telephone company 'central office' switches over common paths. During the first generations of digital networks, analog signals were digitized on line cards attached to the telephone exchange switches. In an effort to reduce local loop costs, it was decided to push this conversion closer to the customer premises by deploying small conversion devices in customer neighborhoods. These devices would combine multiple digital signals on a single link to a larger telephone switch, which would provide service to the customer. These devices were initially called remote concentrators or simply remotes.
In fibre-optic distribution systems which offer triple-play services (voice, television, internet) the digitization has arrived at the customer premises and signals are digitized at the source and combined using customer edge routers. This traffic enters the distribution network at an Optical Network Termination and is carried to the central office using Wavelength division multiplexing and Passive optical networking. 
In telecommunication, the term concentrator has the following meanings:

</doc>
<doc id="40941" url="https://en.wikipedia.org/wiki?curid=40941" title="Concentricity error">
Concentricity error

The concentricity error of an optical fiber is the distance between the center of the two concentric circles that specify the cladding diameter and the center of the two concentric circles that specify the core diameter. 
The concentricity error is used in conjunction with tolerance fields to specify or characterize optical fiber core and cladding geometry.

</doc>
<doc id="40942" url="https://en.wikipedia.org/wiki?curid=40942" title="Conditioning equipment">
Conditioning equipment

In telecommunication, the term conditioning equipment has the following meanings: 

</doc>
<doc id="40943" url="https://en.wikipedia.org/wiki?curid=40943" title="Conducted interference">
Conducted interference


</doc>
<doc id="40946" url="https://en.wikipedia.org/wiki?curid=40946" title="Conference operation">
Conference operation

In a communications network, a conference operation is an operation that allows a call to be established among three or more stations in such a manner that each of the stations is able to communicate directly with all the other stations. In radio systems, the stations may receive simultaneously, but must transmit one at a time. The common operational modes are "push-to-talk" for telephone operation and "push-to-type" for telegraph and data transmission.

</doc>
<doc id="40948" url="https://en.wikipedia.org/wiki?curid=40948" title="Configuration management">
Configuration management

Configuration management (CM) is a systems engineering process for establishing and maintaining consistency of a product's performance, functional, and physical attributes with its requirements, design, and operational information throughout its life. 
The CM process is widely used by military engineering organizations to manage changes throughout the system lifecycle of complex systems, such as weapon systems, military vehicles, and information systems. Outside the military, the CM process is also used with IT service management as defined by ITIL, and with other domain models in the civil engineering and other industrial engineering segments such as roads, bridges, canals, dams, and buildings.
Introduction.
CM, when applied over the life cycle of a system, provides visibility and control of its performance, functional, and physical attributes. CM verifies that a system performs as intended, and is identified and documented in sufficient detail to support its projected life cycle. The CM process facilitates orderly management of system information and system changes for such beneficial purposes as to revise capability; improve performance, reliability, or maintainability; extend life; reduce cost; reduce risk and liability; or correct defects. The relatively minimal cost of implementing CM is returned many fold in cost avoidance. The lack of CM, or its ineffectual implementation, can be very expensive and sometimes can have such catastrophic consequences such as failure of equipment or loss of life.
CM emphasizes the functional relation between parts, subsystems, and systems for effectively controlling system change. It helps to verify that proposed changes are systematically considered to minimize adverse effects. Changes to the system are proposed, evaluated, and implemented using a standardized, systematic approach that ensures consistency, and proposed changes are evaluated in terms of their anticipated impact on the entire system. CM verifies that changes are carried out as prescribed and that documentation of items and systems reflects their true configuration. A complete CM program includes provisions for the storing, tracking, and updating of all system information on a component, subsystem, and system basis.
A structured CM program ensures that documentation (e.g., requirements, design, test, and acceptance documentation) for items is accurate and consistent with the actual physical design of the item. In many cases, without CM, the documentation exists but is not consistent with the item itself. For this reason, engineers, contractors, and management are frequently forced to develop documentation reflecting the actual status of the item before they can proceed with a change. This reverse engineering process is wasteful in terms of human and other resources and can be minimized or eliminated using CM.
History.
Configuration Management originates in the United States Department of Defense in the 1950s as a technical management discipline for hardware material items—and it is now a standard practice in virtually every industry. The CM process became its own technical discipline sometime in the late 1960s when the DoD developed a series of military standards called the "480 series" (i.e., MIL-STD-480, MIL-STD-481 and MIL-STD-483) that were subsequently issued in the 1970s. In 1991, the "480 series" was consolidated into a single standard known as the MIL–STD–973 that was then replaced by MIL–HDBK–61 pursuant to a general DoD goal that reduced the number of military standards in favor of industry technical standards supported by standards developing organizations (SDO). This marked the beginning of what has now evolved into the most widely distributed and accepted standard on CM, ANSI–EIA–649–1998. Now widely adopted by numerous organizations and agencies, the CM discipline's concepts include systems engineering (SE), integrated logistics support (ILS), Capability Maturity Model Integration (CMMI), ISO 9000, Prince2 project management method, COBIT, Information Technology Infrastructure Library (ITIL), product lifecycle management, and application lifecycle management. Many of these functions and models have redefined CM from its traditional holistic approach to technical management. Some treat CM as being similar to a librarian activity, and break out change control or change management as a separate or stand alone discipline.
Overview.
CM is the practice of handling changes systematically so that a system maintains its integrity over time. CM implements the policies, procedures,
techniques, and tools that are required to manage, evaluate proposed changes, track the status of changes, and to maintain an inventory of system and support documents as the system changes. CM programs and plans provide technical and administrative direction to the development and implementation of the procedures, functions, services, tools, processes, and resources required to successfully develop and support a complex system. During system development, CM allows program management to track requirements throughout the life cycle through acceptance and operations and maintenance. As changes are inevitably made to the requirements and design, they must be approved and documented, creating an accurate record of the system status. Ideally the CM process is applied throughout the system lifecycle.
The CM process for both hardware and software configuration items comprises five distinct disciplines as established in the MIL–HDBK–61A and ANSI/EIA-649. These disciplines are carried out as policies and procedures for establishing baselines and performing a standard change management process.
Software.
The traditional software configuration management (SCM) process is looked upon by practitioners as the best solution to handling changes in software projects. It identifies the functional and physical attributes of software at various points in time, and performs systematic control of changes to the identified attributes for the purpose of maintaining software integrity and traceability throughout the software development life cycle.
The SCM process further defines the need to trace changes, and the ability to verify that the final delivered software has all of the planned enhancements that are supposed to be included in the release. It identifies four procedures that must be defined for each software project to ensure that a sound SCM process is implemented. They are:
These terms and definitions change from standard to standard, but are essentially the same.
Configuration management database.
The Information Technology Infrastructure Library, also known as ITIL, specifies the use of a Configuration management system (CMS) / Configuration management database (CMDB) as a means of achieving industry best practices for Configuration Management. CMDBs are used to track Configuration Items (CIs) and the dependencies between them, where CIs represent the things in an enterprise that are worth tracking and managing, such as but not limited to computers, software, software licenses, racks, network devices, storage, and even the components within such items.
The benefits of a CMS/CMDB includes being able to perform functions like root cause analysis, impact analysis, change management, and current state assessment for future state strategy development.
Information assurance.
For information assurance, CM can be defined as the management of security features and assurances through control of changes made to hardware, software, firmware, documentation, test, test fixtures, and test documentation throughout the life cycle of an information system. CM for information assurance, sometimes referred to as Secure Configuration Management, relies upon performance, functional, and physical attributes of IT platforms and products and their environments to determine the appropriate security features and assurances that are used to measure a system configuration state. For example, configuration requirements may be different for a network firewall that functions as part of an organization's Internet boundary versus one that functions as an internal local network firewall.
Maintenance systems.
Configuration management is used to maintain an understanding of the status of complex assets with a view to maintaining the highest level of serviceability for the lowest cost. Specifically, it aims to ensure that operations are not disrupted due to the asset (or parts of the asset) overrunning limits of planned lifespan or below quality levels.
In the military, this type of activity is often classed as "mission readiness", and seeks to define which assets are available and for which type of mission; a classic example is whether aircraft on board an aircraft carrier are equipped with bombs for ground support or missiles for defense.
Operating System configuration management.
Configuration management can be used to maintain OS configuration files. Example systems include Quattor, CFEngine, Bcfg2, Puppet, SaltStack, Ansible, Vagrant and Chef.
A theory of configuration maintenance was worked out by Mark Burgess, with a practical implementation on present day computer systems in the software CFEngine able to perform real time repair as well as preventive maintenance.
Preventive maintenance.
Understanding the "as is" state of an asset and its major components is an essential element in preventive maintenance as used in maintenance, repair, and overhaul and enterprise asset management systems.
Complex assets such as aircraft, ships, industrial machinery etc. depend on many different components being serviceable. This serviceability is often defined in terms of the amount of usage the component has had since it was new, since fitted, since repaired, the amount of use it has had over its life and several other limiting factors. Understanding how near the end of their life each of these components is has been a major undertaking involving labor-intensive record keeping until recent developments in software.
Predictive maintenance.
Many types of component use electronic sensors to capture data which provides live condition monitoring. This data is analyzed on board or at a remote location by computer to evaluate its current serviceability and increasingly its likely future state using algorithms which predict potential future failures based on previous examples of failure through field experience and modeling. This is the basis for "predictive maintenance".
Availability of accurate and timely data is essential in order for CM to provide operational value and a lack of this can often be a limiting factor. Capturing and disseminating the operating data to the various support organizations is becoming an industry in itself.
The consumers of this data have grown more numerous and complex with the growth of programs offered by original equipment manufacturers (OEMs). These are designed to offer operators guaranteed availability and make the picture more complex with the operator managing the asset but the OEM taking on the liability to ensure its serviceability. In such a situation, individual components within an asset may communicate directly to an analysis center provided by the OEM or an independent analyst.
Standards.
A number of standards support or include configuration management, including:
Construction.
More recently configuration management has been applied to large construction projects which can often be very complex and have a huge amount of details and changes that need to be documented. Construction agencies such as the Federal Highway Administration have used configuration management for their infrastructure projects. There are construction-based configuration management tools that aim to document change orders and RFIs in order to ensure a project stays on schedule and on budget. These programs can also store information to aid in the maintenance and modification of the infrastructure when it is completed. One such application, ccsNet, was tested in a case study funded by the Federal Transportation Administration (FTA) in which the efficacy of configuration management was measured through comparing the approximately 80% complete construction of the Los Angeles County Metropolitan Transit Agency (LACMTA) 1st and 2nd segments of the Red Line, a $5.3 billion rail construction project. This study yielded results indicating a benefit to using configuration management on projects of this nature.
Certification.
Formal training and certification is available for configuration managers.

</doc>
<doc id="40949" url="https://en.wikipedia.org/wiki?curid=40949" title="Congestion">
Congestion

Congestion may refer to:

</doc>
<doc id="40950" url="https://en.wikipedia.org/wiki?curid=40950" title="Connectionless communication">
Connectionless communication

Connectionless communication, often referred to as CL-mode communication, is a data transmission method used in packet switching networks by which each data unit is individually addressed and routed based on information carried in each unit, rather than in the setup information of a prearranged, fixed data channel as in connection-oriented communication.
Under connectionless communication between two network end points, a message can be sent from one end point to another without prior arrangement. The device at one end of the communication transmits data addressed to the other, without first ensuring that the recipient is available and ready to receive the data. Some protocols allow for error correction by requested retransmission. Internet Protocol (IP) and User Datagram Protocol (UDP) are connectionless protocols.
A packet transmitted in a connectionless mode is frequently called a datagram.
Connectionless protocols are usually described as stateless protocols because the end points have no protocol-defined way to remember where they are in a "conversation" of message exchanges.
In connection-oriented communication the communicating peers must first establish a logical or physical data channel or "connection" in a dialog preceding the exchange of user data.
The connectionless communications has the advantage over connection-oriented communications in that it has low overhead. It also allows for multicast and broadcast operations in which the same data are transmitted to several recipients in a single transmission.
In connectionless transmissions the service provider usually cannot guarantee that there will be no loss, error insertion, misdelivery, duplication, or out-of-sequence delivery of the packet. However, the effect of errors may be reduced by implementing error correction within an application protocol.
In connectionless mode no optimizations are possible when sending several data units between the same two peers. By establishing a connection at the beginning of such a data exchange the components (routers, bridges) along the network path would be able to pre-compute (and hence cache) routing-related information, avoiding re-computation for every packet. Network components could also reserve capacity for the transfer of the subsequent data units of a video download, for example.
Distinction between connectionless and connection-oriented transmission may take place at several layers of the OSI Reference Model:

</doc>
<doc id="40951" url="https://en.wikipedia.org/wiki?curid=40951" title="Connections per circuit hour">
Connections per circuit hour

In telecommunication, the term connections per circuit hour (CCH) has the following meanings: 
The magnitude of the CCH is an instantaneous value subject to change as a function of time (i.e. from moment to moment), and is subject to study including load curve and busy hour as other measures of traffic are.
See also.
Busy Hour Call Attempts
Source: from Federal Standard 1037C and from MIL-STD-188

</doc>
<doc id="40952" url="https://en.wikipedia.org/wiki?curid=40952" title="Connectivity exchange">
Connectivity exchange

Connectivity exchange (CONEX): In an adaptive or manually operated high-frequency (HF) radio network, the automatic or manual exchange of information concerning routes to stations that are not directly reachable by the exchange originator. 
The purpose of the exchange is to identify indirect paths and/or possible relay stations to those stations that are not directly reachable.

</doc>
<doc id="40954" url="https://en.wikipedia.org/wiki?curid=40954" title="Contention">
Contention

Contention may refer to:
Contention may also refer to:

</doc>
<doc id="40955" url="https://en.wikipedia.org/wiki?curid=40955" title="Continuous operation">
Continuous operation

In telecommunication, continuous operation is an operation in which certain components, such as nodes, facilities, circuits, or equipment, are in an operational state at all times. Continuous operation usually requires that there be fully redundant configuration, or at least a sufficient "X" out of "Y" degree of redundancy for compatible equipment, where "X" is the number of spare components and "Y" is the number of operational components. 

</doc>
<doc id="40956" url="https://en.wikipedia.org/wiki?curid=40956" title="Contrast">
Contrast

Contrast may refer to:

</doc>
<doc id="40957" url="https://en.wikipedia.org/wiki?curid=40957" title="Control communications">
Control communications

In telecommunication, control communications is the branch of technology devoted to the design, development, and application of communications facilities used specifically for control purposes, such as for controlling (a) industrial processes, (b) movement of resources, (c) electric power generation, distribution, and utilization, (d) communications networks, and (e) transportation systems.

</doc>
<doc id="40958" url="https://en.wikipedia.org/wiki?curid=40958" title="Controlled area">
Controlled area

In telecommunication, a controlled area is an area in which uncontrolled movement will not result in compromise of classified information, that is designed to provide administrative control and safety, or that serves as a buffer for controlling access to limited-access areas. It can also refer to an area to which security controls have been applied to protect an information-processing system's equipment and wirelines, equivalent to that required for the information transmitted through the system.

</doc>
<doc id="40961" url="https://en.wikipedia.org/wiki?curid=40961" title="Control operation">
Control operation

In telecommunication, a control operation (control function) is an operation that affects the recording, processing, transmission, or interpretation of data. 
Examples of control operations a font change, or a rewind; and transmitting an end-of-transmission (EOT) control character.

</doc>
<doc id="40962" url="https://en.wikipedia.org/wiki?curid=40962" title="Convolutional code">
Convolutional code

In telecommunication, a convolutional code is a type of error-correcting code that generates parity symbols via the sliding application of a boolean polynomial function to a data stream. The sliding application represents the 'convolution' of the encoder over the data, which gives rise to the term 'convolutional coding.' The sliding nature of the convolutional codes facilitates trellis decoding using a time-invariant trellis. Time invariant trellis decoding allows convolutional codes to be maximum-likelihood soft-decision decoded with reasonable complexity.
The ability to perform economical maximum likelihood soft decision decoding is one of the major benefits of convolutional codes. This is in contrast to classic block codes, which are generally represented by a time-variant trellis and therefore are typically hard-decision decoded. Convolutional codes are often characterized by the base code rate and the depth (or memory) of the encoder [n,k,K]. The base code rate is typically given as n/k, where n is the input data rate and k is the output symbol rate. The depth is often called the "constraint length" 'K', where the output is a function of the previous K-1 inputs. The depth may also be given as the number of memory elements 'v' in the polynomial or the maximum possible number of states of the encoder (typically 2^v).
Convolutional codes are often described as continuous. However, it may also be said that convolutional codes have arbitrary block length, rather than being continuous, since most real-world convolutional encoding is performed on blocks of data. Convolutionally encoded block codes typically employ termination. The arbitrary block length of convolutional codes can also be contrasted to classic block codes, which generally have fixed block lengths that are determined by algebraic properties.
The code rate of a convolutional code is commonly modified via symbol puncturing. For example, a convolutional code with a 'mother' code rate n/k=1/2 may be punctured to a higher rate of, for example, 7/8 simply by not transmitting a portion of code symbols. The performance of a punctured convolutional code generally scales well with the amount of parity transmitted. The ability to perform economical soft decision decoding on convolutional codes, as well as the block length and code rate flexibility of convolutional codes, makes them very popular for digital communications.
History.
Convolutional codes were introduced in 1955 by Peter Elias. It was thought that convolutional codes could be decoded with arbitrary quality at the expense of computation and delay. In 1967 Andrew Viterbi determined that convolutional codes could be maximum-likelihood decoded with reasonable complexity using time invariant trellis based decoders — the Viterbi algorithm. Other trellis-based decoder algorithms were later developed, including the BCJR decoding algorithm.
Recursive systematic convolutional codes were invented by Claude Berrou around 1991. These codes proved especially useful for iterative processing including the processing of concatenated codes such as turbo codes.
Using the "convolutional" terminology, a classic convolutional code might be considered a Finite impulse response (FIR) filter, while a recursive convolutional code might be considered an Infinite impulse response (IIR) filter.
Where convolutional codes are used.
Convolutional codes are used extensively to achieve reliable data transfer in numerous applications, such as digital video, radio, mobile communications and satellite communications. These codes are often implemented in concatenation with a hard-decision code, particularly Reed Solomon. Prior to turbo codes such constructions were the most efficient, coming closest to the Shannon limit.
Convolutional encoding.
To convolutionally encode data, start with "k" memory registers, each holding 1 input bit. Unless otherwise specified, all memory registers start with a value of 0. The encoder has "n" modulo-2 adders (a modulo 2 adder can be implemented with a single Boolean XOR gate, where the logic is: , , , ), and "n" generator polynomials — one for each adder (see figure below). An input bit "m"1 is fed into the leftmost register. Using the generator polynomials and the existing values in the remaining registers, the encoder outputs "n" symbols. These symbols may be transmitted or punctured depending on the desired code rate. Now bit shift all register values to the right ("m"1 moves to "m"0, "m"0 moves to "m"-1) and wait for the next input bit. If there are no remaining input bits, the encoder continues shifting until all registers have returned to the zero state (flush bit termination).
The figure below is a rate () encoder with constraint length ("k") of 3. Generator polynomials are , and . Therefore, output bits are calculated (modulo 2) as follows:
Recursive and non-recursive codes.
The encoder on the picture above is a "non-recursive" encoder. Here's an example of a recursive one and as such it admits a feedback structure:
The example encoder is "systematic" because the input data is also used in the output symbols (Output 2). Codes with output symbols that do not include the input data are called "non-systematic."
Recursive codes are typically systematic and, conversely, non-recursive codes are typically non-systematic. It isn't a strict requirement, but a common practice.
The example encoder in Img. 2. is an 8-state encoder because the 3 registers will create 8 possible encoder states (23). A corresponding decoder trellis will typically use 8 states as well.
Recursive systematic convolutional (RSC) codes have become more popular due to their use in Turbo Codes. Recursive systematic codes are also referred to as pseudo-systematic codes.
Other RSC codes and example applications include:
Useful for LDPC code implementation and as inner constituent code for serial concatenated convolutional codes (SCCC's).
Useful for SCCC's and multidimensional turbo codes.
Useful as constituent code in low error rate turbo codes for applications such as satellite links. Also suitable as SCCC outer code.
Impulse response, transfer function, and constraint length.
A convolutional encoder is called so because it performs a "convolution" of the input stream with the encoder's "impulse responses":
where formula_2 is an input sequence, formula_3j --> is a sequence from output formula_4 and formula_5"j" --> is an impulse response for output formula_4.
A convolutional encoder is a discrete linear time-invariant system. Every output of an encoder can be described by its own transfer function, which is closely related to the generator polynomial. An impulse response is connected with a transfer function through Z-transform.
Transfer functions for the first (non-recursive) encoder are:
Transfer functions for the second (recursive) encoder are:
Define formula_12 by
where, for any rational function formula_14,
Then formula_12 is the maximum of the polynomial degrees of the 
formula_17, and the "constraint length" is defined as formula_18. For instance, in the first example the constraint length is 3, and in the second the constraint length is 4.
Trellis diagram.
A convolutional encoder is a finite state machine. An encoder with "n" binary cells will have 2"n" states.
Imagine that the encoder (shown on Img.1, above) has '1' in the left memory cell ("m"0), and '0' in the right one ("m"-1). ("m"1 is not really a memory cell because it represents a current value). We will designate such a state as "10". According to an input bit the encoder at the next turn can convert either to the "01" state or the "11" state. One can see that not all transitions are possible for (e.g., a decoder can't convert from "10" state to "00" or even stay in "10" state).
All possible transitions can be shown as below:
An actual encoded sequence can be represented as a path on this graph. One valid path is shown in red as an example.
This diagram gives us an idea about "decoding": if a received sequence doesn't fit this graph, then it was received with errors, and we must choose the nearest "correct" (fitting the graph) sequence. The real decoding algorithms exploit this idea.
Free distance and error distribution.
The free distance ("d") is the minimal Hamming distance between different encoded sequences. The "correcting capability" ("t") of a convolutional code is the number of errors that can be corrected by the code. It can be calculated as
Since a convolutional code doesn't use blocks, processing instead a continuous bitstream, the value of "t" applies to a quantity of errors located relatively near to each other. That is, multiple groups of "t" errors can usually be fixed when they are relatively far apart.
Free distance can be interpreted as the minimal length of an erroneous "burst" at the output of a convolutional decoder. The fact that errors appear as "bursts" should be accounted for when designing a concatenated code with an inner convolutional code. The popular solution for this problem is to interleave data before convolutional encoding, so that the outer block (usually Reed-Solomon) code can correct most of the errors.
Decoding convolutional codes.
Several algorithms exist for decoding convolutional codes. For relatively small values of "k", the Viterbi algorithm is universally used as it provides maximum likelihood performance and is highly parallelizable. Viterbi decoders are thus easy to implement in VLSI hardware and in software on CPUs with SIMD instruction sets.
Longer constraint length codes are more practically decoded with any of several sequential decoding algorithms, of which the Fano algorithm is the best known. Unlike Viterbi decoding, sequential decoding is not maximum likelihood but its complexity increases only slightly with constraint length, allowing the use of strong, long-constraint-length codes. Such codes were used in the Pioneer program of the early 1970s to Jupiter and Saturn, but gave way to shorter, Viterbi-decoded codes, usually concatenated with large Reed-Solomon error correction codes that steepen the overall bit-error-rate curve and produce extremely low residual undetected error rates.
Both Viterbi and sequential decoding algorithms return hard decisions: the bits that form the most likely codeword. An approximate confidence measure can be added to each bit by use of the Soft output Viterbi algorithm. Maximum a posteriori (MAP) soft decisions for each bit can be obtained by use of the BCJR algorithm.
Popular convolutional codes.
An especially popular Viterbi-decoded convolutional code, used at least since the Voyager program has a constraint length "k" of 7 and a rate "r" of 1/2.
Punctured convolutional codes.
Puncturing is a technique used to make a "m"/"n" rate code from a "basic" low-rate (e.g., 1/"n") code. It is reached by deletion of some bits in the encoder output. Bits are deleted according to a "puncturing matrix". The following puncturing matrices are the most frequently used:
For example, if we want to make a code with rate 2/3 using the appropriate matrix from the above table, we should take a basic encoder output and transmit every first bit from the first branch and every bit from the second one. The specific order of transmission is defined by the respective communication standard.
Punctured convolutional codes are widely used in the satellite communications, for example, in INTELSAT systems and Digital Video Broadcasting.
Punctured convolutional codes are also called "perforated".
Turbo codes: replacing convolutional codes.
Simple Viterbi-decoded convolutional codes are now giving way to turbo codes, a new class of iterated short convolutional codes that closely approach the theoretical limits imposed by Shannon's theorem with much less decoding complexity than the Viterbi algorithm on the long convolutional codes that would be required for the same performance. Concatenation with an outer algebraic code (e.g., Reed-Solomon) addresses the issue of error floors inherent to turbo code designs.
MATLAB implementation.
MATLAB's Communications System Toolbox supports convolutional codes.
For example the encoder shown on Img. 1 can be implemented as follows:
The bits of the first output stream are at positions 1,4,7...,3k+1... in output vector "codedWord",
respectively second stream at positions 2,5...,3k+2... and the third 3,6...,3k...
Initial state is by default initialized by all zeros.
Convolution code can also be implemented using Verilog HDL language,by making use of corresponding state diagrams and state tables.

</doc>
<doc id="40964" url="https://en.wikipedia.org/wiki?curid=40964" title="Cooperation factor">
Cooperation factor

In facsimile systems, the cooperation factor is the product of the total image scanning length and the scanning density, given by "CF" = "L" σ, where "L" is the scanning line length and σ is the scanning line density, both in compatible units. 
For example, a 20 cm line and a line density of 6 scanning pitches per centimeter would yield a cooperation factor of 120.

</doc>
<doc id="40965" url="https://en.wikipedia.org/wiki?curid=40965" title="Copy">
Copy

Copy may refer to: to copy a word from a book to a paper or laptop or computer

</doc>
<doc id="40966" url="https://en.wikipedia.org/wiki?curid=40966" title="Cord circuit">
Cord circuit

In telecommunication, a cord circuit is a switchboard circuit in which a plug-terminated cord is used to establish connections manually between user lines or between trunks and user lines. A number of cord circuits are furnished as part of the switchboard position equipment. The cords may be referred to as front cord and rear cord or trunk cord and station cord. In modern cordless switchboards, the cord-circuit function is switch operated and may be programmable.
In early and middle 20th century telephone exchanges this task was done by a supervisory relay set known variously as junctor circuit or district junctor. Later designs made it a function of the trunk circuit or absorbed it into software.

</doc>
<doc id="40967" url="https://en.wikipedia.org/wiki?curid=40967" title="Core">
Core

Core may refer to:

</doc>
<doc id="40968" url="https://en.wikipedia.org/wiki?curid=40968" title="Corner reflector">
Corner reflector

A corner reflector is a retroreflector consisting of three mutually perpendicular, intersecting flat surfaces, which reflects waves back directly towards the source, but translated. The three intersecting surfaces often have square shapes. Radar corner reflectors made of metal are used to reflect radio waves from radar sets. Optical corner reflectors, called corner cubes, made of three-sided glass prisms, are used in surveying and laser rangefinding.
The corner reflector should not be confused with the corner reflector antenna, which consists of two flat metal surfaces at a right angle, with a dipole antenna in front of them.
How it works.
The incoming ray is reflected three times, once by each surface, which results in a reversal of direction. To see this, the three corresponding normal vectors of the corner's perpendicular sides can be considered to form a basis (a rectangular coordinate system) ("x", "y", "z") in which to represent the direction of an arbitrary incoming ray, ["a", "b", "c"]. When the ray reflects from the first side, say "x", the ray's "x" component, "a", is reversed to −"a" while the "y" and "z" components are unchanged, resulting in a direction of [−"a", "b", "c"]. Similarly, when reflected from side "y" and finally from side "z", the "b" and "c" components are reversed. So the ray direction goes from ["a", "b", "c"] to [−"a", "b", "c"] to [−"a", −"b", "c"] to [−"a", −"b", −"c"] and it leaves the corner reflector with all three components of direction exactly reversed. The distance travelled, relative to a plane normal to the direction of the rays, is also equal for any ray entering the reflector, regardless of the location where it first reflects.
In diagram 1 the green ray is shown as reflecting from only one surface. This is a special case where the incoming ray is exactly normal (perpendicular) to one of the reflective faces. In the same diagram the orange and red rays are shown reflecting off of two surfaces. This is again a special case, the requirement being that the incoming ray is parallel to one of the reflecting planes.
Radar corner reflectors.
Radar corner reflectors are designed to reflect the microwave radio waves emitted by radar sets back toward the radar antenna. This causes them to show a strong "return" on radar screens. A simple corner reflector consists of three conducting sheet metal or screen surfaces at 90° angles to each other, attached to one another at the edges, forming a "corner". These reflect radio waves coming from in front of them back parallel to the incoming beam. To create a corner reflector that will reflect radar waves coming from any direction, 8 corner reflectors are placed back-to-back in an octahedron (diamond) shape. The reflecting surfaces must be larger than several wavelengths of the radio waves to function.
In maritime navigation they are placed on bridge abutments, buoys, ships and, especially, lifeboats, to ensure that these show up strongly on ship radar screens. Corner reflectors are placed on the vessel's masts at a height of at least 4.6 meters (15 feet) above sea level (giving them an approximate minimum horizon distance of 8 kilometers or 4.5 nautical miles). Marine radar uses X-band microwaves with wavelengths of 2.5 - 3.75 cm, so small reflectors less than 30 cm across are used. In aircraft navigation, corner reflectors are installed on rural runways, to make them show up on aircraft radar.
Optical corner reflectors.
In optics, corner reflectors typically consist of three mirrors or reflective prism faces which return an incident light beam in the opposite direction. In surveying, retroreflector prisms are commonly used as targets for long-range electronic distance measurement using a total station.
NASA has put several optical corner reflectors made of quartz, known as the Lunar Laser Ranging Experiment, on the Moon for use in laser time-of-flight measurement to measure the Moon’s orbit more precisely than was possible before.
Automobile and bicycle tail lights are molded with arrays of small corner reflectors, with different sections oriented for viewing from different angles. Reflective paint for visibility at night usually contains retroreflective spherical beads.
Thin plastic with microscopic corner reflector structures can be used as tape, on signs, or sewn or molded onto clothing.
Other examples.
Corner reflectors can also occur accidentally. Tower blocks with balconies are often accidental corner reflectors for sound and return a distinctive echo to an observer making a sharp noise, such as a hand clap, nearby. Similarly, in radar interpretation, an object that has multiple reflections from smooth surfaces produces a radar return of greater magnitude than might be expected from the physical size of the object. This effect was put to use on the ADM-20 Quail, a small missile which had the same radar cross section as a B-52.

</doc>
<doc id="40969" url="https://en.wikipedia.org/wiki?curid=40969" title="Cosmic noise">
Cosmic noise

Cosmic noise and galactic radio noise is random noise that originates outside the Earth's atmosphere. It can be detected and heard on radio receivers.
Elaboration.
Cosmic noise characteristics are similar to those of thermal noise. Cosmic noise is experienced at frequencies above about 15 MHz when highly directional antennas are pointed toward the sun or to certain other regions of the sky such as the center of the Milky Way Galaxy. Celestial objects like Quasars, super dense objects that lie far from Earth, emit electromagnetic waves in its full spectrum including radio waves. We can also hear the fall of a meteorite in a radio receiver; as the falling object burns from friction with the Earth's atmosphere, ionizing surrounding gases, thereby producing radio waves. Cosmic Microwave Background Radiation (CMBR) from outer space, discovered by Arno Penzias and Robert Wilson, who later won the Nobel Prize for this discovery, is also a form of cosmic noise. CMBR is thought to be a relic of the Big Bang, and pervades the space almost homogeneously over the entire celestial sphere. The bandwidth of the CMBR is wide, though the peak is in the microwave range.

</doc>
<doc id="40970" url="https://en.wikipedia.org/wiki?curid=40970" title="Costas loop">
Costas loop

A Costas loop is a phase-locked loop (PLL) based circuit which is used for carrier frequency recovery from suppressed-carrier modulation signals (e.g. double-sideband suppressed carrier signals) and phase modulation signals (e.g. BPSK, QPSK). It was invented by John P. Costas at General Electric in the 1950s
. Its invention was described as having had "a profound effect on modern digital communications".
The primary application of Costas loops is in wireless receivers. Its advantage over the PLL-based detectors is that at small deviations the Costas loop error voltage is formula_1 as compared to formula_2. This translates to double the sensitivity and also makes the Costas loop uniquely suited for tracking Doppler-shifted carriers especially in OFDM and GPS receivers.
Classical implementation.
In the classical implementation of a Costas loop, a local voltage-controlled oscillator (VCO) provides quadrature outputs, one to each of two phase detectors, "e.g.", product detectors. The same phase of the input signal is also applied to both phase detectors and the output of each phase detector is passed through a low-pass filter. The outputs of these low-pass filters are inputs to another phase detector, the output of which passes through noise-reduction filter before being used to control the voltage-controlled oscillator. The overall loop response is controlled by the two individual low-pass filters that precede the third phase detector while the third low-pass filter serves a trivial role in terms of gain and phase margin.
Mathematical models.
In the time domain.
In the simplest case formula_3. Therefore, formula_3 does not affect the input of noise-reduction filter.
Carrier and voltage-controlled oscillator (VCO) signals are periodic oscillations formula_5 with high-frequencies formula_6.
Block formula_7 shifts phase of VCO signal by formula_8.
Block formula_9 is an analog multiplier.
From the mathematical point of view, a linear filter can be described by a system of linear differential equations
Here, formula_11 is a constant matrix, formula_12 is a state vector of filter, formula_13 and formula_14 are constant vectors.
The model of a VCO is usually assumed to be linear
where formula_16 is a free-running frequency of voltage-controlled oscillator and formula_17 is an oscillator gain. Similarly, it is possible to consider various nonlinear models of VCO.
Suppose that the frequency of master generator is constant
formula_18
Equation of VCO and equation of filter yield
The system is non-autonomous and rather difficult for investigation.
In phase-frequency domain.
In the simplest case, when
the standard engineering assumption is that the filter removes the upper sideband
with frequency from the input but leaves the lower sideband without change.
Thus it is assumed that VCO input is formula_21
This makes a Costas loop equivalent to a phase-locked loop with phase detector characteristic formula_22 corresponding to the particular waveforms formula_23 and formula_24 of input and VCO signals. It can be proved that inputs formula_25 and formula_26 of VCO for phase-frequency domain and time domain models are almost equal.
Thus it is possible
to study more simple autonomous system of differential equations
The Krylov–Bogoliubov averaging method allows one to prove that solutions of non-autonomous and autonomous equations are close under some assumptions.
Thus the block-scheme of Costas Loop in the time space can be asymptotically changed to the block-scheme on the level of phase-frequency relations.
The passage to analysis of autonomous dynamical model of Costas loop (in place of the non-autonomous one) allows one to overcome the difficulties, related with modeling Costas loop in time domain where one has to simultaneously observe very fast time scale of the input signals and slow time scale of signal's phase.

</doc>
<doc id="40972" url="https://en.wikipedia.org/wiki?curid=40972" title="Coupling">
Coupling

A coupling is a device used to connect two shafts together at their ends for the purpose of transmitting power. Couplings do not normally allow disconnection of shafts during operation, however there are torque limiting couplings which can slip or disconnect when some torque limit is exceeded.
The primary purpose of couplings is to join two pieces of rotating equipment while permitting some degree of misalignment or end movement or both. By careful selection, installation and maintenance of couplings, substantial savings can be made in reduced maintenance costs and downtime.
Uses.
Shaft couplings are used in machinery for several purposes. 
The most common of which are the following.
Types.
Clamped or compression rigid couplings come in two parts and fit together around the shafts to form a sleeve. They offer more flexibility than sleeved models, and can be used on shafts that are fixed in place. They generally are large enough so that screws can pass all the way through the coupling and into the second half to ensure a secure hold.Flanged rigid couplings are designed for heavy loads or industrial equipment. They consist of short sleeves surrounded by a perpendicular flange. One coupling is placed on each shaft so the two flanges line up face to face. A series of screws or bolts can then be installed in the flanges to hold them together. Because of their size and durability, flanged units can be used to bring shafts into alignment before they are joined together.
Rigid couplings are used when precise shaft alignment is required; shaft misalignment will affect the coupling's performance as well as its life. Examples:
Sleeve coupling.
A sleeve coupling consists of a pipe whose bore is finished to the required tolerance based on the shaft size. Based on the usage of the coupling a keyway is made in the bore in order to transmit the torque by means of the key. Two threaded holes are provided in order to lock the coupling in position.
Sleeve couplings are also known as Box Couplings. In this case shaft ends are coupled together and abutted against each other which are enveloped by "muff" or "sleeve". A gib head sunk keys hold the two shafts and sleeve together.
in other words,
this is the simplest type of the coupling. It is made from the cast iron and very simple to design and manufacture. It consists of a hollow pipe whose inner diameter is same as diameter of the shafts.
The hollow pipe is fitted over a two or more ends of the shafts with the help of the taper sunk key.a key and sleeve are useful to transmit power from one shaft to another shaft.
Clamp or split-muff coupling.
In this coupling, the muff or sleeve is made into two halves parts of the cast iron and they are joined together by means of mild steel studs or bolts. The advantages of this coupling is that assembling or disassembling of the coupling is possible without changing the position of the shaft. This coupling is used for heavy power transmission at moderate speed.
Tapered shaft lock.
A tapered lock is a form of keyless shaft locking device that does not require any material to be removed from the shaft. The basic idea is similar to a clamp coupling but the moment of rotation is closer to the center of the shaft. An alternative coupling device to the traditional parallel key, the tapered lock removes the possibility of play due to worn keyways. It is more robust than using a key because maintenance only requires one tool and the self-centering balanced rotation means it lasts longer than a keyed joint would, but the downside is that it costs more.
Hirth.
Hirth joints use tapered teeth on two shaft ends meshed together to transmit torque.
Flexible.
Flexible couplings are used to transmit torque from one shaft to another when the two shafts are slightly misaligned. Flexible couplings can accommodate varying degrees of misalignment up to 3° and some parallel misalignment. In addition, they can also be used for vibration damping or noise reduction.This coupling is used to protect the driving and driven shaft members against harmful effects produce due to misalignment of the shafts, sudden shock loads, shaft expansion or vibrations etc.
Bush pin Type flange coupling.
This is used for slightly imperfect alignment of the two shafts.
This is modified form of the protected type flange coupling. This type of coupling has pins and it works with coupling bolts. The rubber or leather bushes are used over the pins. The coupling has two halves dissimilar in construction. The pins are rigidly fastened by nuts to one of the flange and kept loose on the other flange. This coupling is used to connect of shafts which having a small parallel misalignment, angular misalignment or axial misalignment. In this coupling the rubber bushing absorbs shocks and vibration during its operations. This type of coupling is mostly used to couple electric motors and machines.
Beam.
A "beam" coupling, also known as "helical" coupling, is a flexible coupling for transmitting torque between two shafts while allowing for angular misalignment, parallel offset and even axial motion, of one shaft relative to the other. This design utilizes a single piece of material and becomes flexible by removal of material along a spiral path resulting in a curved flexible beam of helical shape. Since it is made from a single piece of material, the Beam Style coupling does not exhibit the backlash found in some multi-piece couplings. Another advantage of being an all machined coupling is the possibility to incorporate features into the final product while still keep the single piece integrity.
Changes to the lead of the helical beam provide changes to misalignment capabilities as well as other performance characteristics such as torque capacity and torsional stiffness. It is even possible to have multiple starts within the same helix.
The material used to manufacture the beam coupling also affects its performance and suitability for specific applications such as food, medical and aerospace. Materials are typically aluminum alloy and stainless steel, but they can also be made in acetal, maraging steel and titanium. The most common applications are attaching encoders to shafts and motion control for robotics.
Constant velocity.
There are various types of constant-velocity (CV) couplings: Rzeppa joint, Double cardan joint, and Thompson coupling.
Diaphragm.
Diaphragm couplings transmit torque from the outside diameter of a flexible plate to the inside diameter, across the spool or spacer piece, and then from inside to outside diameter. The deforming of a plate or series of plates from I.D. to O.D accomplishes the misalignment.
Disc.
Disc couplings transmit torque from a driving to a driven bolt tangentially on a common bolt circle. Torque is transmitted between the bolts through a series of thin, stainless steel discs assembled in a pack. Misalignment is accomplished by deforming of the material between the bolts.
Gear.
A "gear coupling" is a mechanical device for transmitting torque between two shafts that are not collinear. It consists of a flexible joint fixed to each shaft. The two joints are connected by a third shaft, called the spindle.
Each joint consists of a 1:1 gear ratio internal/external gear pair. The tooth flanks and outer diameter of the external gear are crowned to allow for angular displacement between the two gears. Mechanically, the gears are equivalent to rotating splines with modified profiles. They are called gears because of the relatively large size of the teeth.
Gear couplings and universal joints are used in similar applications. Gear couplings have higher torque densities than universal joints designed to fit a given space while universal joints induce lower vibrations. The limit on torque density in universal joints is due to the limited cross sections of the cross and yoke. The gear teeth in a gear coupling have high backlash to allow for angular misalignment. The excess backlash can contribute to vibration.
Gear couplings are generally limited to angular misalignments, i.e., the angle of the spindle relative to the axes of the connected shafts, of 4-5°. Universal joints are capable of higher misalignments.
Single joint gear couplings are also used to connected two nominally coaxial shafts. In this application the device is called a gear-type flexible, or flexible coupling. The single joint allows for minor misalignments such as installation errors and changes in shaft alignment due to operating conditions. These types of gear couplings are generally limited to angular misalignments of 1/4-1/2°.
Grid.
A "grid coupling" is composed of two shaft hubs, a metallic grid spring, and a split cover kit. Torque is transmitted between the two coupling shaft hubs through the metallic grid spring element.
Like metallic gear and disc couplings, grid couplings have a high torque density. A benefit of grid couplings, over either gear or disc couplings, is the ability their grid coupling spring elements have to absorb and spread peak load impact energy over time. This reduces the magnitude of peak loads and offers some vibration dampening capability. A negative of the grid coupling design is that it generally is very limited in its ability to accommodate misalignment.
Oldham.
An "Oldham coupling" has three discs, one coupled to the input, one coupled to the output, and a middle disc that is joined to the first two by tongue and groove. The tongue and groove on one side is perpendicular to the tongue and groove on the other. The middle disc rotates around its center at the same speed as the input and output shafts. Its center traces a circular orbit, twice per rotation, around the midpoint between input and output shafts. Often springs are used to reduce backlash of the mechanism. An advantage to this type of coupling, as compared to two universal joints, is its compact size. The coupler is named for John Oldham who invented it in Ireland, in 1821, to solve a problem in a paddle steamer design.
Rag joint.
Rag joints are commonly used on automotive steering linkages and drive trains. When used on a drive train they are sometimes known as giubos.
Magnetic Coupling.
A magnetic coupling uses magnetic forces to transmit the power from one shaft to the other without any contact, this allows for full medium separation.
Coupling maintenance and failure.
Coupling maintenance is generally a simple matter, requiring a regularly scheduled inspection of each coupling. It consists of:
Even with proper maintenance, however, couplings can fail. Underlying reasons for failure, other than maintenance, include:
The only way to improve coupling life is to understand what caused the failure and to correct it prior to installing a new coupling.
Some external signs that indicate potential coupling failure include:
Checking the coupling balance.
Couplings are normally balanced at the factory prior to being shipped, but they occasionally go out of balance in operation. Balancing can be difficult and expensive, and is normally done only when operating tolerances are such that the effort and the expense are justified. The amount of coupling unbalance that can be tolerated by any system is dictated by the characteristics of the specific connected machines and can be determined by detailed analysis or experience.

</doc>
<doc id="40973" url="https://en.wikipedia.org/wiki?curid=40973" title="Cover">
Cover

Cover or covers may refer to:

</doc>
<doc id="40974" url="https://en.wikipedia.org/wiki?curid=40974" title="Critical angle">
Critical angle

Critical angle can refer to:

</doc>
<doc id="40975" url="https://en.wikipedia.org/wiki?curid=40975" title="Critical frequency">
Critical frequency

In telecommunication, the term critical frequency has the following meanings: 
Critical Frequency changes with time of day, atmospheric conditions and angle of fire of the radio waves by antenna.
The existence of the critical frequency is the result of electron limitation, "i.e.," the inadequacy of the existing number of free electrons to support reflection at higher frequencies.
In signal processing the "critical frequency" it is also another name for the Nyquist frequency.
Critical frequency is the highest magnitude of frequency above which the waves penetrates the ionosphere and below which the waves are reflected back from the ionosphere.
It is denoted by "fc".
Its value is not fixed and it depends upon electron density of ionosphere.
It is given by:
fc=9√Nmax
Nmax is maximum electron density.

</doc>
<doc id="40976" url="https://en.wikipedia.org/wiki?curid=40976" title="Crosstalk (disambiguation)">
Crosstalk (disambiguation)

Crosstalk refers to any signal or circuit unintentionally affecting another signal or circuit.
Crosstalk may also mean:

</doc>
<doc id="40977" url="https://en.wikipedia.org/wiki?curid=40977" title="International Cryptology Conference">
International Cryptology Conference

CRYPTO, the International Cryptology Conference, is one of the largest academic conferences in cryptography and cryptanalysis. It is organized by the International Association for Cryptologic Research (IACR), and it is held yearly in August in Santa Barbara, California at the University of California, Santa Barbara.
The first CRYPTO was held in 1981. It was the first major conference on cryptology, and was all the more important because relations between government, industry and academia were rather tense. Encryption was considered a very sensitive subject and the coming together of delegates from different countries was unheard-of at the time. The initiative for the formation of the IACR came during CRYPTO '82, and CRYPTO '83 was the first IACR sponsored conference.

</doc>
<doc id="40978" url="https://en.wikipedia.org/wiki?curid=40978" title="Cryptochannel">
Cryptochannel

In telecommunication, a cryptochannel is a complete system of crypto-communications between two or more holders. The basic unit for naval cryptographic communication. It includes: (a) the cryptographic aids prescribed; (b) the holders thereof; (c) the indicators or other means of identification; (d) the area or areas in which effective; (e) the special purpose, if any, for which provided; and (f) pertinent notes as to distribution, usage, "etc." A cryptochannel is analogous to a radio circuit. 

</doc>
<doc id="40979" url="https://en.wikipedia.org/wiki?curid=40979" title="Crystal oscillator">
Crystal oscillator

A crystal oscillator is an electronic oscillator circuit that uses the mechanical resonance of a vibrating crystal of piezoelectric material to create an electrical signal with a precise frequency. This frequency is commonly used to keep track of time, as in quartz wristwatches, to provide a stable clock signal for digital integrated circuits, and to stabilize frequencies for radio transmitters and receivers. The most common type of piezoelectric resonator used is the quartz crystal, so oscillator circuits incorporating them became known as crystal oscillators, but other piezoelectric materials including polycrystalline ceramics are used in similar circuits.
Quartz crystals are manufactured for frequencies from a few tens of kilohertz to hundreds of megahertz. More than two billion crystals are manufactured annually. Most are used for consumer devices such as wristwatches, clocks, radios, computers, and cellphones. Quartz crystals are also found inside test and measurement equipment, such as counters, signal generators, and oscilloscopes.
Terminology.
A crystal oscillator is an electronic oscillator circuit that uses a piezoelectric resonator, a crystal, as its frequency-determining element. "Crystal" is the common term used in electronics for the frequency-determining component, a wafer of quartz crystal or ceramic with electrodes connected to it. A more accurate term for it is "piezoelectric resonator". Crystals are also used in other types of electronic circuits, such as crystal filters.
Piezoelectric resonators, crystals are sold as separate components for use in crystal oscillator circuits, an example is shown in the picture. They are also often incorporated in a single package with the crystal oscillator circuit, shown on the righthand side.
History.
Piezoelectricity was discovered by Jacques and Pierre Curie in 1880. Paul Langevin first investigated quartz resonators for use in sonar during World War I. The first crystal-controlled oscillator, using a crystal of Rochelle salt, was built in 1917 and patented in 1918 by Alexander M. Nicholson at Bell Telephone Laboratories, although his priority was disputed by Walter Guyton Cady. Cady built the first quartz crystal oscillator in 1921.
Other early innovators in quartz crystal oscillators include G. W. Pierce and Louis Essen.
Quartz crystal oscillators were developed for high-stability frequency references during the 1920s and 1930s. Prior to crystals, radio stations controlled their frequency with tuned circuits, which could easily drift off frequency by 3–4 kHz. Since broadcast stations were assigned frequencies only 10 kHz apart, interference between adjacent stations due to frequency drift was a common problem. In 1925 Westinghouse installed a crystal oscillator in its flagship station KDKA, and by 1926 quartz crystals were used to control the frequency of many broadcasting stations and were popular with amateur radio operators. In 1928, Warren Marrison of Bell Telephone Laboratories developed the first quartz crystal clock. With accuracies of up to 1 sec in 30 years (30 ms/year or 10−7), quartz clocks replaced precision pendulum clocks as the world's most accurate timekeepers until atomic clocks were developed in the 1950s. Using the early work at Bell Labs, AT&T eventually established their Frequency Control Products division, later spun off and known today as Vectron International.
A number of firms started producing quartz crystals for electronic use during this time. Using what are now considered primitive methods, about 100,000 crystal units were produced in the United States during 1939. Through World War II crystals were made from natural quartz crystal, virtually all from Brazil. Shortages of crystals during the war caused by the demand for accurate frequency control of military and naval radios and radars spurred postwar research into culturing synthetic quartz, and by 1950 a hydrothermal process for growing quartz crystals on a commercial scale was developed at Bell Laboratories. By the 1970s virtually all crystals used in electronics were synthetic.
In 1968, Juergen Staudte invented a photolithographic process for manufacturing quartz crystal oscillators while working at North American Aviation (now Rockwell) that allowed them to be made small enough for portable products like watches.
Although crystal oscillators still most commonly use quartz crystals, devices using other materials are becoming more common, such as ceramic resonators.
Operation.
A crystal is a solid in which the constituent atoms, molecules, or ions are packed in a regularly ordered, repeating pattern extending in all three spatial dimensions.
Almost any object made of an elastic material could be used like a crystal, with appropriate transducers, since all objects have natural resonant frequencies of vibration. For example, steel is very elastic and has a high speed of sound. It was often used in mechanical filters before quartz. The resonant frequency depends on size, shape, elasticity, and the speed of sound in the material. High-frequency crystals are typically cut in the shape of a simple, rectangular plate. Low-frequency crystals, such as those used in digital watches, are typically cut in the shape of a tuning fork. For applications not needing very precise timing, a low-cost ceramic resonator is often used in place of a quartz crystal.
When a crystal of quartz is properly cut and mounted, it can be made to distort in an electric field by applying a voltage to an electrode near or on the crystal. This property is known as electrostriction or inverse piezoelectricity. When the field is removed, the quartz generates an electric field as it returns to its previous shape, and this can generate a voltage. The result is that a quartz crystal behaves like an RLC circuit, composed of an inductor, capacitor and resistor, with a precise resonant frequency.
Quartz has the further advantage that its elastic constants and its size change in such a way that the frequency dependence on temperature can be very low. The specific characteristics depend on the mode of vibration and the angle at which the quartz is cut (relative to its crystallographic axes). Therefore, the resonant frequency of the plate, which depends on its size, does not change much. This means that a quartz clock, filter or oscillator remains accurate. For critical applications the quartz oscillator is mounted in a temperature-controlled container, called a crystal oven, and can also be mounted on shock absorbers to prevent perturbation by external mechanical vibrations.
Modeling.
Electrical model.
A quartz crystal can be modeled as an electrical network with a low-impedance (series) and a high-impedance (parallel) resonance points spaced closely together. Mathematically (using the Laplace transform), the impedance of this network can be written as:
or
where "s" is the complex frequency (formula_4), formula_5 is the series resonant angular frequency, and formula_6 is the parallel resonant angular frequency.
Adding capacitance across a crystal causes the (parallel) resonance frequency to decrease. Adding inductance across a crystal causes the (parallel) resonance frequency to increase. These effects can be used to adjust the frequency at which a crystal oscillates. Crystal manufacturers normally cut and trim their crystals to have a specified resonance frequency with a known "load" capacitance added to the crystal. For example, a crystal intended for a 6 pF load has its specified parallel resonance frequency when a 6.0 pF capacitor is placed across it. Without the load capacitance, the resonance frequency is higher.
Resonance modes.
A quartz crystal provides both series and parallel resonance. The series resonance is a few kilohertz lower than the parallel one. Crystals below 30 MHz are generally operated between series and parallel resonance, which means that the crystal appears as an inductive reactance in operation, this inductance forming a parallel resonant circuit with externally connected parallel capacitance. Any small additional capacitance in parallel with the crystal pulls the frequency lower. Moreover, the effective inductive reactance of the crystal can be reduced by adding a capacitor in series with the crystal. This latter technique can provide a useful method of trimming the oscillatory frequency within a narrow range; in this case inserting a capacitor in series with the crystal raises the frequency of oscillation. For a crystal to operate at its specified frequency, the electronic circuit has to be exactly that specified by the crystal manufacturer. Note that these points imply a subtlety concerning crystal oscillators in this frequency range: the crystal does not usually oscillate at precisely either of its resonant frequencies.
Crystals above 30 MHz (up to >200 MHz) are generally operated at series resonance where the impedance appears at its minimum and equal to the series resistance. For these crystals the series resistance is specified (<100 Ω) instead of the parallel capacitance. To reach higher frequencies, a crystal can be made to vibrate at one of its overtone modes, which occur near multiples of the fundamental resonant frequency. Only odd numbered overtones are used. Such a crystal is referred to as a 3rd, 5th, or even 7th overtone crystal. To accomplish this, the oscillator circuit usually includes additional LC circuits to select the desired overtone.
Temperature effects.
A crystal's frequency characteristic depends on the shape or 'cut' of the crystal. A tuning fork crystal is usually cut such that its frequency over temperature is a parabolic curve centered around 25 °C. This means that a tuning fork crystal oscillator resonates close to its target frequency at room temperature, but slows when the temperature either increases or decreases from room temperature. A common parabolic coefficient for a 32 kHz tuning fork crystal is −0.04 ppm/°C².
In a real application, this means that a clock built using a regular 32 kHz tuning fork crystal keeps good time at room temperature, but loses 2 minutes per year at 10 °C above or below room temperature and loses 8 minutes per year at 20 °C above or below room temperature due to the quartz crystal.
Crystal oscillator circuits.
The crystal oscillator circuit sustains oscillation by taking a voltage signal from the quartz resonator, amplifying it, and feeding it back to the resonator. The rate of expansion and contraction of the quartz is the resonant frequency, and is determined by the cut and size of the crystal. When the energy of the generated output frequencies matches the losses in the circuit, an oscillation can be sustained.
An oscillator crystal has two electrically conductive plates, with a slice or tuning fork of quartz crystal sandwiched between them. During startup, the controlling circuit places the crystal into an unstable equilibrium, and due to the positive feedback in the system, any tiny fraction of noise is amplified, ramping up the oscillation. The crystal resonator can also be seen as a highly frequency-selective filter in this system: it only passes a very narrow subband of frequencies around the resonant one, attenuating everything else. Eventually, only the resonant frequency is active. As the oscillator amplifies the signals coming out of the crystal, the signals in the crystal's frequency band becomes stronger, eventually dominating the output of the oscillator. The narrow resonance band of the quartz crystal filters out all the unwanted frequencies.
The output frequency of a quartz oscillator can be either that of the fundamental resonance or of a multiple of that resonance, called a harmonic frequency. Harmonics are an exact integer multiple of the fundamental frequency. But, like many other mechanical resonators, crystals exhibit several modes of oscillation, usually at approximately odd integer multiples of the fundamental frequency. These are termed "overtone modes", and oscillator circuits can be designed to excite them. The overtone modes are at frequencies which are approximate, but not exact odd integer multiples of that of the fundamental mode, and overtone frequencies are therefore not exact harmonics of the fundamental.
High frequency crystals are often designed to operate at third, fifth, or seventh overtones. Manufacturers have difficulty producing crystals thin enough to produce fundamental frequencies over 30 MHz. To produce higher frequencies, manufacturers make overtone crystals tuned to put the 3rd, 5th, or 7th overtone at the desired frequency, because they are thicker and therefore easier to manufacture than a fundamental crystal that would produce the same frequency—although exciting the desired overtone frequency requires a slightly more complicated oscillator circuit.
A fundamental crystal oscillator circuit is simpler and more efficient and has more pullability than a third overtone circuit.
Depending on the manufacturer, the highest available fundamental frequency may be 25 MHz to 66 MHz.
A major reason for the wide use of crystal oscillators is their high Q factor. A typical "Q" value for a quartz oscillator ranges from 104 to 106, compared to perhaps 102 for an LC oscillator. The maximum "Q" for a high stability quartz oscillator can be estimated as "Q" = 1.6 × 107/"f", where "f" is the resonance frequency in megahertz.
One of the most important traits of quartz crystal oscillators is that they can exhibit very low phase noise.
In many oscillators, any spectral energy at the resonant frequency is amplified by the oscillator, resulting in a collection of tones at different phases.
In a crystal oscillator, the crystal mostly vibrates in one axis, therefore only one phase is dominant.
This property of low phase noise makes them particularly useful in telecommunications where stable signals are needed, and in scientific equipment where very precise time references are needed.
Environmental changes of temperature, humidity, pressure, and vibration can change the resonant frequency of a quartz crystal, but there are several designs that reduce these environmental effects. These include the TCXO, MCXO, and OCXO which are defined below. These designs, particularly the OCXO, often produce devices with excellent short-term stability. The limitations in short-term stability are due mainly to noise from electronic components in the oscillator circuits. Long-term stability is limited by aging of the crystal.
Due to aging and environmental factors (such as temperature and vibration), it is difficult to keep even the best quartz oscillators within one part in 1010 of their nominal frequency without constant adjustment. For this reason, atomic oscillators are used for applications requiring better long-term stability and accuracy.
Spurious frequencies.
For crystals operated at series resonance or pulled away from the main mode by the inclusion of a series inductor or capacitor, significant (and temperature-dependent) spurious responses may be experienced. Though most spurious modes are typically some tens of kilohertz above the wanted series resonance their temperature coefficient is different from the main mode and the spurious response may move through the main mode at certain temperatures. Even if the series resistances at the spurious resonances appear higher than the one at wanted frequency a rapid change in the main mode series resistance can occur at specific temperatures when the two frequencies are coincidental.
A consequence of these activity dips is that the oscillator may lock at a spurious frequency at specific temperatures. This is generally minimized by ensuring that the maintaining circuit has insufficient gain to activate unwanted modes.
Spurious frequencies are also generated by subjecting the crystal to vibration. This modulates the resonance frequency to a small degree by the frequency of the vibrations. SC-cut crystals are designed to minimize the frequency effect of mounting stress and they are therefore less sensitive to vibration. Acceleration effects including gravity are also reduced with SC-cut crystals as is frequency change with time due to long term mounting stress variation.
There are disadvantages with SC-cut shear mode crystals, such as the need for the maintaining oscillator to discriminate against other closely related unwanted modes and increased frequency change due to temperature when subject to a full ambient range. SC-cut crystals are most advantageous where temperature control at their temperature of zero temperature coefficient (turnover) is possible, under these circumstances an overall stability performance from premium units can approach the stability of Rubidium frequency standards.
Commonly used crystal frequencies.
Crystals can be manufactured for oscillation over a wide range of frequencies, from a few kilohertz up to several hundred megahertz. Many applications call for a crystal oscillator frequency conveniently related to some other desired frequency, so hundreds of standard crystal frequencies are made in large quantities and stocked by electronics distributors. For example, many non-television applications use 3.579545 MHz crystals since they are made in large quantities for NTSC color television receivers. Using frequency dividers, frequency multipliers and phase locked loop circuits, it is practical to derive a wide range of frequencies from one reference frequency.
Crystal structures and materials.
The most common material for oscillator crystals is quartz. At the beginning of the technology, natural quartz crystals were used but now synthetic crystalline quartz grown by hydrothermal synthesis is predominant due to higher purity, lower cost and more convenient handling. One of the few remaining uses of natural crystals is for pressure transducers in deep wells. During World War II and for some time afterwards, natural quartz was considered a strategic material by the USA. Large crystals were imported from Brazil. Raw "lascas", the source material quartz for hydrothermal synthesis, are imported to USA or mined locally by Coleman Quartz. The average value of as-grown synthetic quartz in 1994 was 
Two types of quartz crystals exist: left-handed and right-handed. The two differ in their optical rotation but they are identical in other physical properties. Both left and right-handed crystals can be used for oscillators, if the cut angle is correct. In manufacture, right-handed quartz is generally used. The SiO4 tetrahedrons form parallel helices; the direction of twist of the helix determines the left- or right-hand orientation. The helixes are aligned along the z-axis and merged, sharing atoms. The mass of the helixes forms a mesh of small and large channels parallel to the z-axis. The large ones are large enough to allow some mobility of smaller ions and molecules through the crystal.
Quartz exists in several phases. At 573 °C at 1 atmosphere (and at higher temperatures and higher pressures) the α-quartz undergoes quartz inversion, transforms reversibly to β-quartz. The reverse process however is not entirely homogeneous and crystal twinning occurs. Care must be taken during manufacturing and processing to avoid phase transformation. Other phases, e.g. the higher-temperature phases tridymite and cristobalite, are not significant for oscillators. All quartz oscillator crystals are the α-quartz type.
Infrared spectrophotometry is used as one of the methods for measuring the quality of the grown crystals. The wavenumbers 3585, 3500, and 3410 cm−1 are commonly used. The measured value is based on the absorption bands of the OH radical and the infrared Q value is calculated. The electronic grade crystals, grade C, have Q of 1.8 million or above; the premium grade B crystals have Q of 2.2 million, and special premium grade A crystals have Q of 3.0 million. The Q value is calculated only for the z region; crystals containing other regions can be adversely affected. Another quality indicator is the etch channel density; when the crystal is etched, tubular channels are created along linear defects. For processing involving etching, e.g. the wristwatch tuning fork crystals, low etch channel density is desirable. The etch channel density for swept quartz is about 10–100 and significantly more for unswept quartz. Presence of etch channels and etch pits degrades the resonator's Q and introduces nonlinearities.
Quartz crystals can be grown for specific purposes.
Crystals for AT-cut are the most common in mass production of oscillator materials; the shape and dimensions are optimized for high yield of the required wafers. High-purity quartz crystals are grown with especially low content of aluminium, alkali metal and other impurities and minimal defects; the low amount of alkali metals provides increased resistance to ionizing radiation. Crystals for wrist watches, for cutting the tuning fork 32768 Hz crystals, are grown with very low etch channel density.
Crystals for SAW devices are grown as flat, with large X-size seed with low etch channel density.
Special high-Q crystals, for use in highly stable oscillators, are grown at constant slow speed and have constant low infrared absorption along the entire Z axis. Crystals can be grown as Y-bar, with a seed crystal in bar shape and elongated along the Y axis, or as Z-plate, grown from a plate seed with Y-axis direction length and X-axis width. The region around the seed crystal contains a large number of crystal defects and should not be used for the wafers.
Crystals grow anisotropically; the growth along the Z axis is up to 3 times faster than along the X axis. The growth direction and rate also influences the rate of uptake of impurities. Y-bar crystals, or Z-plate crystals with long Y axis, have four growth regions usually called +X, -X, Z, and S. The distribution of impurities during growth is uneven; different growth areas contain different levels of contaminants. The Z regions are the purest, the small occasionally present S regions are less pure, the +X region is yet less pure, and the -X region has the highest level of impurities. The impurities have a negative impact on radiation hardness, susceptibility to twinning, filter loss, and long and short term stability of the crystals. Different-cut seeds in different orientations may provide other kinds of growth regions. The growth speed of the -X direction is slowest due to the effect of adsorption of water molecules on the crystal surface; aluminium impurities suppress growth in two other directions. The content of aluminium is lowest in Z region, higher in +X, yet higher in -X, and highest in S; the size of S regions also grows with increased amount of aluminium present. The content of hydrogen is lowest in Z region, higher in +X region, yet higher in S region, and highest in -X. Aluminium inclusions transform into color centers with gamma ray irradiation, causing a darkening of the crystal proportional to the dose and level of impurities; the presence of regions with different darkness reveals the different growth regions.
The dominant type of defect of concern in quartz crystals is the substitution of an Al(III) for a Si(IV) atom in the crystal lattice. The aluminium ion has an associated interstitial charge compensator present nearby, which can be a H+ ion (attached to the nearby oxygen and forming a hydroxyl group, called Al-OH defect), Li+ ion, Na+ ion, K+ ion (less common), or an electron hole trapped in a nearby oxygen atom orbital. The composition of the growth solution, whether it is based on lithium or sodium alkali compounds, determines the charge compensating ions for the aluminium defects. The ion impurities are of concern as they are not firmly bound and can migrate through the crystal, altering the local lattice elasticity and the resonant frequency of the crystal. Other common impurities of concern are e.g. iron(III) (interstitial), fluorine, boron(III), phosphorus(V) (substitution), titanium(IV) (substitution, universally present in magmatic quartz, less common in hydrothermal quartz), and germanium(IV) (substitution). Sodium and iron ions can cause inclusions of acnite and elemeusite crystals. Inclusions of water may be present in fast-grown crystals; interstitial water molecules are abundant near the crystal seed. Another defect of importance is the hydrogen containing growth defect, when instead of a Si-O-Si structure, a pair of Si-OH HO-Si groups is formed; essentially a hydrolyzed bond. Fast-grown crystals contain more hydrogen defects than slow-grown ones. These growth defects source as supply of hydrogen ions for radiation-induced processes and forming Al-OH defects. Germanium impurities tend to trap electrons created during irradiation; the alkali metal cations then migrate towards the negatively charged center and form a stabilizing complex. Matrix defects can also be present; oxygen vacancies, silicon vacancies (usually compensated by 4 hydrogens or 3 hydrogens and a hole), peroxy groups, etc. Some of the defects produce localized levels in the forbidden band, serving as charge traps; Al(III) and B(III) typically serve as hole traps while electron vacancies, titanium, germanium, and phosphorus atoms serve as electron traps. The trapped charge carriers can be released by heating; their recombination is the cause of thermoluminescence.
The mobility of interstitial ions depends strongly on temperature. Hydrogen ions are mobile down to 10 K, but alkali metal ions become mobile only at temperatures around and above 200 K.
The hydroxyl defects can be measured by near-infrared spectroscopy. The trapped holes can be measured by electron spin resonance. The Al-Na+ defects show as an acoustic loss peak due to their stress-induced motion; the Al-Li+ defects do not form a potential well so are not detectable this way. Some of the radiation-induced defects during their thermal annealing produce thermoluminescence; defects related to aluminium, titanium, and germanium can be distinguished.
Swept crystals are crystals that have undergone a solid-state electrodiffusion purification process. Sweeping involves heating the crystal above 500 °C in a hydrogen-free atmosphere, with a voltage gradient of at least 1 kV/cm, for several hours (usually over 12). The migration of impurities and the gradual replacement of alkali metal ions with hydrogen (when swept in air) or electron holes (when swept in vacuum) causes a weak electric current through the crystal; decay of this current to a constant value signals the end of the process. The crystal is then left to cool, while the electric field is maintained. The impurities are concentrated at the cathode region of the crystal, which is cut off afterwards and discarded. Swept crystals have increased resistance to radiation, as the dose effects are dependent on the level of alkali metal impurities; they are suitable for use in devices exposed to ionizing radiation, e.g. for nuclear and space technology. Sweeping under vacuum at higher temperatures and higher field strengths yields yet more radiation-hard crystals. The level and character of impurities can be measured by infrared spectroscopy. Quartz can be swept in both α and β phase; sweeping in β phase is faster, but the phase transition may induce twinning. Twinning can be mitigated by subjecting the crystal to compression stress in the X direction, or an AC or DC electric field along the X axis while the crystal cools through the phase transformation temperature region.
Sweeping can also be used to introduce one kind of an impurity into the crystal. Lithium, sodium, and hydrogen swept crystals are used for, e.g., studying quartz behavior.
Very small crystals for high fundamental mode frequencies can be manufactured by photolithography.
Crystals can be adjusted to exact frequencies by laser trimming. A technique used in the world of amateur radio for slight decrease of the crystal frequency may be achieved by exposing crystals with silver electrodes to vapors of iodine, which causes a slight mass increase on the surface by forming a thin layer of silver iodide; such crystals however had problematic long-term stability. Another method commonly used is electrochemical increase or decrease of silver electrode thickness by submerging a resonator in lapis lazuli dissolved in water, citric acid in water, or water with salt, and using the resonator as one electrode, and a small silver electrode as the other.
By choosing the direction of current one can either increase or decrease the mass of the electrodes.
Details were published in "Radio" magazine (3/1978) by UB5LEV.
Raising frequency by scratching off parts of the electrodes is not advised as this may damage the crystal and lower its Q factor. Capacitor trimmers can be also used for frequency adjustment of the oscillator circuit.
Some other piezoelectric materials than quartz can be employed. These include single crystals of lithium tantalate, lithium niobate, lithium borate, berlinite, gallium arsenide, lithium tetraborate, aluminium phosphate, bismuth germanium oxide, polycrystalline zirconium titanate ceramics, high-alumina ceramics, silicon-zinc oxide composite, or dipotassium tartrate. Some materials may be more suitable for specific applications. An oscillator crystal can be also manufactured by depositing the resonator material on the silicon chip surface. Crystals of gallium phosphate, langasite, langanite and langanate are about 10 times more pullable than the corresponding quartz crystals, and are used in some VCXO oscillators.
Stability and aging.
The frequency stability is determined by the crystal's Q. It is inversely dependent on the frequency, and on the constant that is dependent on the particular cut. Other factors influencing Q are the overtone used, the temperature, the level of driving of the crystal, the quality of the surface finish, the mechanical stresses imposed on the crystal by bonding and mounting, the geometry of the crystal and the attached electrodes, the material purity and defects in the crystal, type and pressure of the gas in the enclosure, interfering modes, and presence and absorbed dose of ionizing and neutron radiation.
Temperature influences the operating frequency; various forms of compensation are used, from analog compensation (TCXO) and microcontroller compensation (MCXO) to stabilization of the temperature with a crystal oven (OCXO). The crystals possess temperature hysteresis; the frequency at a given temperature achieved by increasing the temperature is not equal to the frequency on the same temperature achieved by decreasing the temperature. The temperature sensitivity depends primarily on the cut; the temperature compensated cuts are chosen as to minimize frequency/temperature dependence. Special cuts can be made with linear temperature characteristics; the LC cut is used in quartz thermometers. Other influencing factors are the overtone used, the mounting and electrodes, impurities in the crystal, mechanical strain, crystal geometry, rate of temperature change, thermal history (due to hysteresis), ionizing radiation, and drive level.
Crystals tend to suffer anomalies in their frequency/temperature and resistance/temperature characteristics, known as activity dips. These are small downward frequency or upward resistance excursions localized at certain temperatures, with their temperature position dependent on the value of the load capacitors.
Mechanical stresses also influence the frequency. The stresses can be induced by mounting, bonding, and application of the electrodes, by differential thermal expansion of the mounting, electrodes, and the crystal itself, by differential thermal stresses when there is a temperature gradient present, by expansion or shrinkage of the bonding materials during curing, by the air pressure that is transferred to the ambient pressure within the crystal enclosure, by the stresses of the crystal lattice itself (nonuniform growth, impurities, dislocations), by the surface imperfections and damage caused during manufacture, and by the action of gravity on the mass of the crystal; the frequency can therefore be influenced by position of the crystal. Other dynamic stress inducing factors are shocks, vibrations, and acoustic noise. Some cuts are less sensitive to stresses; the SC (Stress Compensated) cut is an example. Atmospheric pressure changes can also introduce deformations to the housing, influencing the frequency by changing stray capacitances.
Atmospheric humidity influences the thermal transfer properties of air, and can change electrical properties of plastics by diffusion of water molecules into their structure, altering the dielectric constants and electrical conductivity.
Other factors influencing the frequency are the power supply voltage, load impedance, magnetic fields, electric fields (in case of cuts that are sensitive to them, e.g., SC cuts), the presence and absorbed dose of γ-particles and ionizing radiation, and the age of the crystal.
Crystals undergo slow gradual change of frequency with time, known as aging. There are many mechanisms involved. The mounting and contacts may undergo relief of the built-in stresses. Molecules of contamination either from the residual atmosphere, outgassed from the crystal, electrodes or packaging materials, or introduced during sealing the housing can be adsorbed on the crystal surface, changing its mass; this effect is exploited in quartz crystal microbalances. The composition of the crystal can be gradually altered by outgassing, diffusion of atoms of impurities or migrating from the electrodes, or the lattice can be damaged by radiation. Slow chemical reactions may occur on or in the crystal, or on the inner surfaces of the enclosure. Electrode material, e.g. chromium or aluminium, can react with the crystal, creating layers of metal oxide and silicon; these interface layers can undergo changes in time. The pressure in the enclosure can change due to varying atmospheric pressure, temperature, leaks, or outgassing of the materials inside. Factors outside of the crystal itself are e.g. aging of the oscillator circuitry (and e.g. change of capacitances), and drift of parameters of the crystal oven. External atmosphere composition can also influence the aging; hydrogen can diffuse through nickel housing. Helium can cause similar issues when it diffuses through glass enclosures of rubidium standards.
Gold is a favored electrode material for low-aging resonators; its adhesion to quartz is strong enough to maintain contact even at strong mechanical shocks, but weak enough to not support significant strain gradients (unlike chromium, aluminium, and nickel). Gold also does not form oxides; it adsorbs organic contaminants from the air, but these are easy to remove. However, gold alone can undergo delamination; a layer of chromium is therefore sometimes used for improved binding strength. Silver and aluminium are often used as electrodes; however both form oxide layers with time that increases the crystal mass and lowers frequency. Silver can be passivated by exposition to iodine vapors, forming a layer of silver iodide. Aluminium oxidizes readily but slowly, until about 5 nm thickness is reached; increased temperature during artificial aging does not significantly increase the oxide forming speed; a thick oxide layer can be formed during manufacture by anodizing. Exposition of silver-plated crystal to iodine vapors can also be used in amateur conditions for lowering the crystal frequency slightly; the frequency can also be increased by scratching off parts of the electrodes, but that carries risk of damage to the crystal and loss of Q.
A DC voltage bias between the electrodes can accelerate the initial aging, probably by induced diffusion of impurities through the crystal. Placing a capacitor in series with the crystal and a several-megaohm resistor in parallel can minimize such voltages.
Crystals suffer from minor short-term frequency fluctuations as well. The main causes of such noise are e.g. thermal noise (which limits the noise floor), phonon scattering (influenced by lattice defects), adsorption/desorption of molecules on the surface of the crystal, noise of the oscillator circuits, mechanical shocks and vibrations, acceleration and orientation changes, temperature fluctuations, and relief of mechanical stresses. The short-term stability is measured by four main parameters: Allan variance (the most common one specified in oscillator data sheets), phase noise, spectral density of phase deviations, and spectral density of fractional frequency deviations. The effects of acceleration and vibration tend to dominate the other noise sources; surface acoustic wave devices tend to be more sensitive than bulk acoustic wave (BAW) ones, and the stress-compensated cuts are even less sensitive. The relative orientation of the acceleration vector to the crystal dramatically influences the crystal's vibration sensitivity. Mechanical vibration isolation mountings can be used for high-stability crystals.
Crystals are sensitive to shock. The mechanical stress causes a short-term change in the oscillator frequency due to the stress-sensitivity of the crystal, and can introduce a permanent change of frequency due to shock-induced changes of mounting and internal stresses (if the elastic limits of the mechanical parts are exceeded), desorption of contamination from the crystal surfaces, or change in parameters of the oscillator circuit. High magnitudes of shocks may tear the crystals off their mountings (especially in the case of large low-frequency crystals suspended on thin wires), or cause cracking of the crystal. Crystals free of surface imperfections are highly shock-resistant; chemical polishing can produce crystals able to survive tens of thousands of g.
Phase noise plays a significant role in frequency synthesis systems using frequency multiplication; a multiplication of a frequency by N increases the phase noise power by N2. A frequency multiplication by 10 times multiplies the magnitude of the phase error by 10 times. This can be disastrous for systems employing PLL or FSK technologies.
Crystals are somewhat sensitive to radiation damage. Natural quartz is much more sensitive than artificially grown crystals, and sensitivity can be further reduced by sweeping the crystal – heating the crystal to at least 400 °C in a hydrogen-free atmosphere in an electric field of at least 500 V/cm for at least 12 hours. Such swept crystals have a very low response to steady ionizing radiation. Some Si(IV) atoms are replaced with Al(III) impurities, each having a compensating Li+ or Na+ cation nearby. Ionization produces electron-hole pairs; the holes are trapped in the lattice near the Al atom, the resulting Li and Na atoms are loosely trapped along the Z axis; the change of the lattice near the Al atom and the corresponding elastic constant then causes a corresponding change in frequency. Sweeping removes the Li+ and Na+ ions from the lattice, reducing this effect. The Al3+ site can also trap hydrogen atoms. All crystals have a transient negative frequency shift after exposure to an X-ray pulse; the frequency then shifts gradually back; natural quartz reaches stable frequency after 10–1000 seconds, with a negative offset to pre-irradiation frequency, artificial crystals return to a frequency slightly lower or higher than pre-irradiation, swept crystals anneal virtually back to original frequency. The annealing is faster at higher temperatures. Sweeping under vacuum at higher temperatures and field strength can further reduce the crystal's response to X-ray pulses. Series resistance of unswept crystals increases after an X-ray dose, and anneals back to a somewhat higher value for a natural quartz (requiring a corresponding gain reserve in the circuit) and back to pre-irradiation value for synthetic crystals. Series resistance of swept crystals is unaffected. Increase of series resistance degrades Q; too high increase can stop the oscillations. Neutron radiation induces frequency changes by introducing dislocations into the lattice by knocking out atoms, a single fast neutron can produce many defects; the SC and AT cut frequency increases roughly linearly with absorbed neutron dose, while the frequency of the BT cuts decreases. Neutrons also alter the temperature-frequency characteristics. Frequency change at low ionizing radiation doses is proportionally higher than for higher doses. High-intensity radiation can stop the oscillator by inducing photoconductivity in the crystal and transistors; with a swept crystal and properly designed circuit the oscillations can restart within 15 microseconds after the radiation burst. Quartz crystals with high levels of alkali metal impurities lose Q with irradiation; Q of swept artificial crystals is unaffected. Irradiation with higher doses (over 105 rad) lowers sensitivity to subsequent doses. Very low radiation doses (below 300 rad) have disproportionately higher effect, but this nonlinearity saturates at higher doses. At very high doses, the radiation response of the crystal saturates as well, due to the finite number of impurity sites that can be affected.
Magnetic fields have little effect on the crystal itself, as quartz is diamagnetic; eddy currents or AC voltages can however be induced into the circuits, and magnetic parts of the mounting and housing may be influenced.
After the power-up, the crystals take several seconds to minutes to "warm up" and stabilize their frequency. The oven-controlled OCXOs require usually 3–10 minutes for heating up to reach thermal equilibrium; the oven-less oscillators stabilize in several seconds as the few milliwatts dissipated in the crystal cause a small but noticeable level of internal heating.
Crystals have no inherent failure mechanisms; some have operated in devices for decades. Failures may be, however, introduced by faults in bonding, leaky enclosures, corrosion, frequency shift by aging, breaking the crystal by too high mechanical shock, or radiation-induced damage when nonswept quartz is used. Crystals can be also damaged by overdriving.
The crystals have to be driven at the appropriate drive level. While AT cuts tend to be fairly forgiving, with only their electrical parameters, stability and aging characteristics being degraded when overdriven, low-frequency crystals, especially flexural-mode ones, may fracture at too high drive levels. The drive level is specified as the amount of power dissipated in the crystal. The appropriate drive levels are about 5 μW for flexural modes up to 100 kHz, 1 μW for fundamental modes at 1–4 MHz, 0.5 μW for fundamental modes 4–20 MHz and 0.5 μW for overtone modes at 20–200 MHz. Too low drive level may cause problems with starting the oscillator. Low drive levels are better for higher stability and lower power consumption of the oscillator. Higher drive levels, in turn, reduce the impact of noise by increasing the signal-to-noise ratio.
The stability of AT cut crystals decreases with increasing frequency. For more accurate higher frequencies it is better to use a crystal with lower fundamental frequency, operating at an overtone.
Aging decreases logarithmically with time, the largest changes occurring shortly after manufacture. Artificially aging a crystal by prolonged storage at 85 to 125 °C can increase its long-term stability.
A badly designed oscillator circuit may suddenly begin oscillating on an overtone. In 1972, a train in Fremont, California crashed due to a faulty oscillator. An inappropriate value of the tank capacitor caused the crystal in a control board to be overdriven, jumping to an overtone, and causing the train to speed up instead of slowing down.
Crystal cuts.
The resonator plate can be cut from the source crystal in many different ways. The orientation of the cut influences the crystal's aging characteristics, frequency stability, thermal characteristics, and other parameters. These cuts operate at bulk acoustic wave (BAW); for higher frequencies, surface acoustic wave (SAW) devices are employed.
Image of several crystal cuts
The T in the cut name marks a temperature-compensated cut, a cut oriented in a way that the temperature coefficients of the lattice are minimal; the FC and SC cuts are also temperature-compensated.
The high frequency cuts are mounted by their edges, usually on springs; the stiffness of the spring has to be optimal, as if it is too stiff, mechanical shocks could be transferred to the crystal and cause it to break, and too little stiffness may allow the crystal to collide with the inside of the package when subjected to a mechanical shock, and break. Strip resonators, usually AT cuts, are smaller and therefore less sensitive to mechanical shocks. At the same frequency and overtone, the strip has less pullability, higher resistance, and higher temperature coefficient.
The low frequency cuts are mounted at the nodes where they are virtually motionless; thin wires are attached at such points on each side between the crystal and the leads. The large mass of the crystal suspended on the thin wires makes the assembly sensitive to mechanical shocks and vibrations.
The crystals are usually mounted in hermetically sealed glass or metal cases, filled with a dry and inert atmosphere, usually vacuum, nitrogen, or helium. Plastic housings can be used as well, but those are not hermetic and another secondary sealing has to be built around the crystal.
Several resonator configurations are possible, in addition to the classical way of directly attaching leads to the crystal. E.g. the BVA resonator (Boîtier à Vieillissement Amélioré, Enclosure with Improved Aging), developed in 1976; the parts that influence the vibrations are machined from a single crystal (which reduces the mounting stress), and the electrodes are deposited not on the resonator itself but on the inner sides of two condenser discs made of adjacent slices of the quartz from the same bar, forming a three-layer sandwich with no stress between the electrodes and the vibrating element. The gap between the electrodes and the resonator act as two small series capacitors, making the crystal less sensitive to circuit influences. The architecture eliminates the effects of the surface contacts between the electrodes, the constraints in the mounting connections, and the issues related to ion migration from the electrodes into the lattice of the vibrating element. The resulting configuration is rugged, resistant to shock and vibration, resistant to acceleration and ionizing radiation, and has improved aging characteristics. AT cut is usually used, though SC cut variants exist as well. BVA resonators are often used in spacecraft applications.
In the 1930s to 1950s, it was fairly common for people to adjust the frequency of the crystals by manual grinding. The crystals were ground using a fine abrasive slurry, or even a toothpaste, to increase their frequency. A slight decrease by 1–2 kHz when the crystal was overground was possible by marking the crystal face with a pencil lead, at the cost of a lowered Q.
The frequency of the crystal is slightly adjustable ("pullable") by modifying the attached capacitances. A varactor, a diode with capacitance depending on applied voltage, is often used in voltage-controlled crystal oscillators, VCXO. The crystal cuts are usually AT or rarely SC, and operate in fundamental mode; the amount of available frequency deviation is inversely proportional to the square of the overtone number, so a third overtone has only one-ninth of the pullability of the fundamental mode. SC cuts, while more stable, are significantly less pullable.
Circuit notations and abbreviations.
On electrical schematic diagrams, "crystals" are designated with the class letter "Y" (Y1, Y2, etc.). Oscillators, whether they are crystal oscillators or others, are designated with the class letter "G" (G1, G2, etc.). Crystals may also be designated on a schematic with "X" or "XTAL", or a crystal oscillator with "XO".
Crystal oscillator types and their abbreviations:

</doc>
<doc id="40980" url="https://en.wikipedia.org/wiki?curid=40980" title="Curve-fitting compaction">
Curve-fitting compaction

Curve-fitting compaction is data compaction accomplished by replacing data to be stored or transmitted with an analytical expression.
Examples of curve-fitting compaction consisting of discretization and then interpolation are:

</doc>
<doc id="40981" url="https://en.wikipedia.org/wiki?curid=40981" title="Customer office terminal">
Customer office terminal

In telecommunications, the term customer office terminal has the following meanings:
"Note:" An example of a customer office terminal is a stand-alone multiplexer located on the customer premises. 
"Note:" This function may be integrated into the ET.

</doc>
<doc id="40982" url="https://en.wikipedia.org/wiki?curid=40982" title="Customer-premises equipment">
Customer-premises equipment

Customer-premises equipment or customer-provided equipment (CPE) is any terminal and associated equipment located at a subscriber's premises and connected with a carrier's telecommunication channel at the demarcation point ("demarc"). The demarc is a point established in a building or complex to separate customer equipment from the equipment located in either the distribution infrastructure or central office of the communications service provider.
CPE generally refers to devices such as telephones, routers, switches, residential gateways (RG), set-top boxes, fixed mobile convergence products, home networking adapters and Internet access gateways that enable consumers to access communications service providers' services and distribute them around their house via a local area network (LAN).
A CPE can be an active equipment, as the ones mentioned above or a passive equipment such as analogue-telephone-adapters or xDSL-splitters. 
Included are key telephone systems and most private branch exchanges. Excluded from CPE are overvoltage protection equipment and pay telephones. Other types of materials that are necessary for the delivery of the telecommunication service, but are not defined as equipment, such as manuals and cable packages, and cable adapters are instead referred to as CPE-peripherals.
CPE can refer to devices purchased by the subscriber, or to those provided by the operator or service provider.
History.
The two phrases, "customer-"premises" equipment" and "customer-"provided" equipment", reflect the history of this equipment.
Under the Bell System monopoly in the United States (post Communications Act of 1934), the Bell System owned the phones, and one could not attach one's own devices to the network, or even attach anything to the phones. Thus phones were property of the Bell System, located on customers' premises - hence, customer-"premises" equipment. In the U.S. Federal Communications Commission (FCC) proceeding the Second Computer Inquiry, the FCC ruled that telecommunications carriers could no longer bundle CPE with telecommunications service, uncoupling the market power of the telecommunications service monopoly from the CPE market, and creating a competitive CPE market.
With the gradual breakup of the Bell monopoly, starting with Hush-A-Phone v. United States , which allowed some non-Bell owned equipment to be connected to the network (a process called interconnection), equipment on customers' premises became increasingly owned by customers, not the telco. Indeed, one eventually became able to purchase one's own phone - hence, customer-"provided" equipment.
In the Pay TV industry many operators and service providers offer subscribers a set-top box with which to receive video services, in return for a monthly fee. As offerings have evolved to include multiple services and data operators have increasingly given consumers the opportunity to rent or buy additional devices like access modems, internet gateways and video extenders that enable them to access multiple services, and distribute them to a range of Consumer Electronics devices around the home.
Technology evolution.
Hybrid devices.
The growth of multiple-service operators, offering triple or quad-play services, required the development of hybrid CPE to make it easy for subscribers to access voice, video and data services. The development of this technology was led by Pay TV operators looking for a way to deliver video services via both traditional broadcast and broadband IP networks. Spain’s Telefonica was the first operator to launch a hybrid broadcast and broadband TV service in 2003 with its Movistar TV DTT/IPTV offering, while Polish satellite operator 'n' was the first to offer its subscribers a Three-way hybrid (or Tri-brid) broadcast and broadband TV service, which launched in 2009
Set-back box.
The term set-back box is used in the digital TV industry to describe a piece of consumer hardware that enables them to access both linear broadcast and internet-based video content, plus a range of interactive services like Electronic Programme Guides (EPG), Pay Per View (PPV) and Video on Demand (VOD) as well as internet browsing, and view them on a large screen television set. Unlike standard set-top boxes, which sit on top of or below the TV, a set-back box has a smaller form factor to enable it to be mounted to the rear of the display panel flat panel TV, hiding it from view.
Home Gateway.
A residential gateway is a home networking device used to connect devices in the home to the Internet or other WAN.
It is an umbrella term, used to cover multi-function networking appliances used in homes, which may combine a DSL modem or cable modem, a network switch, a consumer-grade router, and a wireless access point. In the past, such functions were provided by separate devices, but in recent years technological convergence has enabled multiple functions to merged into a single device.
One of the first home gateway devices to be launched was selected by Telecom Italia to enable the operator to offer triple play services in 2002 . Along with a SIP VoIP handset for making voice calls, it enabled subscribers to access voice, video and data services over a 10MB symmetrical ADSL fiber connection.
Virtual gateway.
The virtual gateway concept enables consumers to access video and data services and distribute them around their homes using software rather than hardware. The first virtual gateway was introduced in 2010 by Advanced Digital Broadcast at the IBC exhibition in Amsterdam. The ADB Virtual Gateway uses software that resides within the middleware and is based on open standards, including DLNA home networking and the DTCP-IP standard, to ensure that all content, including paid-for encrypted content like Pay TV services, can only be accessed by secure CE devices.
Broadband.
A subscriber unit, or SU is a broadband radio that is installed at a business or residential location to connect to an access point to send/receive high speed data wired or wirelessly. Devices commonly referred to as a subscriber unit include cable modems, access gateways, home networking adapters and mobile phones.
WAN.
The terms "customer-premises equipment", "Customer-provided Equipment", or "CPE" may also refer to any devices that terminate a WAN circuit, such as an ISDN, E-carrier/T-carrier, DSL, or metro Ethernet. This includes any customer-owned hardware at the customer's site: routers, firewalls, switches, PBXs, VoIP gateways, sometimes CSU/DSU and modems.
Application Areas

</doc>
<doc id="40983" url="https://en.wikipedia.org/wiki?curid=40983" title="Customer service unit">
Customer service unit

In telecommunication, a customer service unit (CSU) is a device that provides an accessing arrangement at a user location to either switched or point-to-point, data-conditioned circuits at a specifically established data signaling rate. 
A CSU provides local loop equalization, transient protection, isolation, and central office loop-back testing capability.

</doc>
<doc id="40985" url="https://en.wikipedia.org/wiki?curid=40985" title="Cutback technique">
Cutback technique

In telecommunications, a cutback technique is a destructive technique for determining certain optical fiber transmission characteristics, such as attenuation and bandwidth.
Procedure.
The measurement technique consists of:
The cut should be made to retain 1 meter or more of the fiber, in order to establish equilibrium mode distribution conditions for the second measurement. In a multimode fiber, the lack of an equilibrium mode distribution could introduce errors in the measurement due to output coupling effects. In a single-mode fiber, measuring a shorter cutback fiber could result in significant transmission of cladding modes (light carried in the cladding rather than the core of the optical fiber), distorting the measurement. The errors introduced will result in conservative results ("i.e.", higher transmission losses and lower bandwidths) than would be realized under equilibrium conditions. 
Benefits.
The benefit of this technique is that it allows measurement of the fiber characteristics without introducing errors due to variation in the launch conditions. For example, the coupling efficiency of the light source is kept consistent between the initial and the cutback measurements.
Several characteristics may be determined using the same test fiber. 
Attenuation measurement.
Since the attenuation is defined as proportional to the logarithm of the ratio between formula_1 and formula_2, where formula_3 is the power at point formula_4 and formula_5 respectively. Using the cutback technique, the power transmitted through a fiber of known length is measured and compared with the same measurement for the same fiber cut to a length of formula_6 approximately.
Related techniques.
A variation of the cutback technique is the substitution method, in which measurements are made on a full length of fiber, and then on a short length of fiber having the same characteristics (core size, numerical aperture), with the results from the short length being subtracted to give the results for the full length.

</doc>
<doc id="40986" url="https://en.wikipedia.org/wiki?curid=40986" title="Cutoff frequency">
Cutoff frequency

In physics and electrical engineering, a cutoff frequency, corner frequency, or break frequency is a boundary in a system's frequency response at which energy flowing through the system begins to be reduced (attenuated or reflected) rather than passing through.
Typically in electronic systems such as filters and communication channels, cutoff frequency applies to an edge in a lowpass, highpass, bandpass, or band-stop characteristic – a frequency characterizing a boundary between a passband and a stopband. It is sometimes taken to be the point in the filter response where a transition band and passband meet, for example, as defined by a 3 dB corner (a frequency for which the output of the circuit is −3 dB of the nominal passband value). Alternatively, a stopband corner frequency may be specified as a point where a transition band and a stopband meet: a frequency for which the attenuation is larger than the required stopband attenuation, which for example may be 30 dB or 100 dB.
In the case of a waveguide or an antenna, the cutoff frequencies correspond to the lower and upper cutoff wavelengths.
Electronics.
In electronics, cutoff frequency or corner frequency is the frequency either above or below which the power output of a circuit, such as a line, amplifier, or electronic filter has fallen to a given proportion of the power in the passband. Most frequently this proportion is one half the passband power, also referred to as the 3 dB point since a fall of 3 dB corresponds approximately to half power. As a voltage ratio this is a fall to formula_1 of the passband voltage. Other ratios besides the 3 dB point may also be relevant, for example see Chebyshev Filters below.
Single-pole transfer function example.
The simplest low-pass filter transfer function,
has a single pole at . The magnitude of this function in the plane is
At cutoff
Hence, the cutoff frequency is given by
Where is the s-plane variable, is angular frequency and is the imaginary unit.
Chebyshev filters.
Sometimes other ratios are more convenient than the 3 dB point. For instance, in the case of the Chebyshev filter it is usual to define the cutoff frequency as the point after the last peak in the frequency response at which the level has fallen to the design value of the passband ripple. The amount of ripple in this class of filter can be set by the designer to any desired value, hence the ratio used could be any value.
Communications.
In communications, the term cutoff frequency can mean the frequency below which a radio wave fails to penetrate a layer of the ionosphere at the incidence angle required for transmission between two specified points by reflection from the layer.
Waveguides.
The cutoff frequency of an electromagnetic waveguide is the lowest frequency for which a mode will propagate in it. In fiber optics, it is more common to consider the cutoff wavelength, the maximum wavelength that will propagate in an optical fiber or waveguide. The cutoff frequency is found with the characteristic equation of the Helmholtz equation for electromagnetic waves, which is derived from the electromagnetic wave equation by setting the longitudinal wave number equal to zero and solving for the frequency. Thus, any exciting frequency lower than the cutoff frequency will attenuate, rather than propagate. The following derivation assumes lossless walls. The value of c, the speed of light, should be taken to be the group velocity of light in whatever material fills the waveguide.
For a rectangular waveguide, the cutoff frequency is
where the integers formula_7 are the mode numbers, and "a" and "b" the lengths of the sides of the rectangle. For TE modes, formula_8 (but formula_9 is not allowed), while for TM modes formula_10.
The cutoff frequency of the TM01 mode (next higher from dominant mode TE11) in a waveguide of circular cross-section (the transverse-magnetic mode with no angular dependence and lowest radial dependence) is given by 
where formula_12 is the radius of the waveguide, and formula_13 is the first root of formula_14, the bessel function of the first kind of order 1.
The dominant mode TE11 cutoff frequency is given by
For a single-mode optical fiber, the cutoff wavelength is the wavelength at which the normalized frequency is approximately equal to 2.405.
Mathematical analysis.
The starting point is the wave equation (which is derived from the Maxwell equations),
which becomes a Helmholtz equation by considering only functions of the form 
Substituting and evaluating the time derivative gives
The function formula_19 here refers to whichever field (the electric field or the magnetic field) has no vector component in the longitudinal direction - the "transverse" field. It is a property of all the eigenmodes of the electromagnetic waveguide that at least one of the two fields is transverse. The "z" axis is defined to be along the axis of the waveguide.
The "longitudinal" derivative in the Laplacian can further be reduced by considering only functions of the form 
where formula_21 is the longitudinal wavenumber, resulting in
where subscript T indicates a 2-dimensional transverse Laplacian. The final step depends on the geometry of the waveguide. The easiest geometry to solve is the rectangular waveguide. In that case the remainder of the Laplacian can be evaluated to its characteristic equation by considering solutions of the form 
Thus for the rectangular guide the Laplacian is evaluated, and we arrive at
The transverse wavenumbers can be specified from the standing wave boundary conditions for a rectangular geometry crossection with dimensions "a" and "b":
where "n" and "m" are the two integers representing a specific eigenmode. Performing the final substitution, we obtain
which is the dispersion relation in the rectangular waveguide. The cutoff frequency formula_28 is the critical frequency between propagation and attenuation, which corresponds to the frequency at which the longitudinal wavenumber formula_29 is zero. It is given by
The wave equations are also valid below the cutoff frequency, where the longitudinal wave number is imaginary. In this case, the field decays exponentially along the waveguide axis and the wave is thus evanescent.

</doc>
<doc id="40989" url="https://en.wikipedia.org/wiki?curid=40989" title="Data access arrangement">
Data access arrangement

The term data access arrangement (DAA) has the following meanings: 
Data access arrangements are an integral part of all modems built for the public telephone network. In view of mixed voice and data access, DAAs are more generally referred to as direct access arrangements.

</doc>
<doc id="40990" url="https://en.wikipedia.org/wiki?curid=40990" title="Data bank">
Data bank

In telecommunications, a data bank is a repository of information on one or more subjects that is organized in a way that facilitates local or remote information retrieval. A data bank may be either centralized or decentralized.
In computers the data bank is the same as in telecommunication (i.e. it is the repository of data. The data in the data bank can be things such as credit card transactions or it can be any data base of a company where large quantities of queries are being processed on daily bases). 
Data bank may also refer to an organization primarily concerned with the construction and maintenance of a database.

</doc>
<doc id="40991" url="https://en.wikipedia.org/wiki?curid=40991" title="Data compaction">
Data compaction

In telecommunication, data compaction is the reduction of the number of data elements, bandwidth, cost, and time for the generation, transmission, and storage of data without loss of information by eliminating unnecessary redundancy, removing irrelevancy, or using special coding. 
Examples of data compaction methods are the use of fixed-tolerance bands, variable-tolerance bands, slope-keypoints, sample changes, curve patterns, curve fitting, variable-precision coding, frequency analysis, and probability analysis. 
Simply squeezing noncompacted data into a smaller space, for example by increasing packing density or by transferring data on punched cards onto magnetic tape, is not data compaction. 
Data compaction reduces the amount of data used to represent a given amount of information, whereas data compression does not.
Everyday examples.
The use of acronyms in texting is an everyday example. The number of bits required to transmit and store "WYSIWYG" is reduced from its expanded equivalent (7 characters vs 28). The representation of Mersenne primes is another example. The largest known is over 17 million digits long but it is represented as "M"57885161 in a much more compacted form.

</doc>
<doc id="40992" url="https://en.wikipedia.org/wiki?curid=40992" title="Data element">
Data element

In metadata, the term data element is an atomic unit of data that has precise meaning or precise semantics. A data element has:
Data elements usage can be discovered by inspection of software applications or application data files through a process of manual or automated Application Discovery and Understanding. Once data elements are discovered they can be registered in a metadata registry. 
In telecommunication, the term data element has the following components: 
In the areas of databases and data systems more generally a data element is a concept forming part of a data model. As an element of data representation, a collection of data elements forms a data structure.
In Practice.
In practice, data elements (fields, columns, attributes, etc.) are sometimes "over loaded", meaning a given data element will have multiple potential meanings. While a known bad practice, over loading is nevertheless a very real factor or barrier to understanding what a system is doing.

</doc>
<doc id="40993" url="https://en.wikipedia.org/wiki?curid=40993" title="Data forwarder">
Data forwarder

In telecommunications, a data forwarder is a device that 
and 

</doc>
<doc id="40994" url="https://en.wikipedia.org/wiki?curid=40994" title="Datagram">
Datagram

A datagram is a basic transfer unit associated with a packet-switched network. The delivery, arrival time, and order of arrival need not be guaranteed by the network.
History.
The term "datagram" appeared first within the project CYCLADES, a packet-switched network created in the early 1970s, and was coined by Louis Pouzin by combining the words "data" and "telegram". CYCLADES was the first network to make the hosts responsible for the reliable delivery of data, rather than the network itself, using unreliable datagrams and associated end-to-end protocol mechanisms.
These concepts were later adopted for the creation of the Internet Protocol (IP) and other network protocols.
Definition.
RFC 1594 defines the term Datagram as follows:
A datagram needs to be self-contained without reliance on earlier exchanges because there is no connection of fixed duration between the two communicating points as there is, for example, in most voice telephone conversations.
Datagram service is often compared to a mail delivery service, the user only provides the destination address, but receives no guarantee of delivery, and no confirmation upon successful delivery. Datagram service is therefore considered unreliable. Datagram service routes datagrams without first creating a predetermined path. Datagram service is therefore considered connectionless. There is also no consideration given to the order in which it and other datagrams are sent or received. In fact, many datagrams in the same group can travel along different paths before reaching the same destination.
Structure.
Each datagram has two components, a header and a data payload. The header contains all the information sufficient for routing from the originating equipment to the destination without relying on prior exchanges between the equipment and the network. Headers may include source and destination addresses as well as a type field. The payload is the data to be transported. This process of nesting data payloads in a tagged header is called encapsulation.
Examples.
Internet Protocol.
The Internet Protocol (IP) defines standards for several types of datagrams.
The internet layer is a datagram service provided by an IP. For example, UDP is run by a datagram service in the internet layer. IP is an entirely connectionless, best effort, unreliable, message delivery service. TCP is a higher level protocol running on top of IP that can provide the addition of a connection-oriented service.
The term "datagram" is often considered synonymous to "packet" but there are some nuances. The term "datagram" is generally reserved for packets of an unreliable service, which cannot notify the sender if delivery fails, while the term "packet" applies to any packet, reliable or not. Datagrams are the IP packets that provide a quick and unreliable service like UDP, and all IP packets are datagrams;
however, at the TCP layer what is termed a TCP "segment" is the sometimes necessary IP fragmentation of a datagram, but those are referred to as "packets".

</doc>
<doc id="40995" url="https://en.wikipedia.org/wiki?curid=40995" title="Data integrity">
Data integrity

Data integrity refers to maintaining and assuring the accuracy and consistency of data over its entire life-cycle, and is a critical aspect to the design, implementation and usage of any system which stores, processes, or retrieves data. The term data integrity is broad in scope and may have widely different meanings depending on the specific context even under the same general umbrella of computing. This article provides only a broad overview of some of the different types and concerns of data integrity.
Data integrity is the opposite of data corruption, which is a form of data loss. The overall intent of any data integrity technique is the same: ensure data is recorded exactly as intended (such as a database correctly rejecting mutually exclusive possibilities,) and upon later retrieval, ensure the data is the same as it was when it was originally recorded. In short, data integrity aims to prevent unintentional changes to information. Data integrity is not to be confused with data security, the discipline of protecting data from unauthorized parties.
Any unintended changes to data as the result of a storage, retrieval or processing operation, including malicious intent, unexpected hardware failure, and human error, is failure of data integrity. If the changes are the result of unauthorized access, it may also be a failure of data security. Depending on the data involved this could manifest itself as benign as a single pixel in an image appearing a different color than was originally recorded, to the loss of vacation pictures or a business-critical database, to even catastrophic loss of human life in a life-critical system.
Integrity types.
Physical integrity.
Physical integrity deals with challenges associated with correctly storing and fetching the data itself. Challenges with physical integrity may include electromechanical faults, design flaws, material fatigue, corrosion, power outages, natural disasters, acts of war and terrorism, and other special environmental hazards such as ionizing radiation, extreme temperatures, pressures and g-forces. Ensuring physical integrity includes methods such as redundant hardware, an uninterruptible power supply, certain types of RAID arrays, radiation hardened chips, error-correcting memory, use of a clustered file system, using file systems that employ block level checksums such as ZFS, storage arrays that compute parity calculations such as exclusive or or use a cryptographic hash function and even having a watchdog timer on critical subsystems.
Physical integrity often makes extensive use of error detecting algorithms known as error-correcting codes. Human-induced data integrity errors are often detected through the use of simpler checks and algorithms, such as the Damm algorithm or Luhn algorithm. These are used to maintain data integrity after manual transcription from one computer system to another by a human intermediary (e.g. credit card or bank routing numbers). Computer-induced transcription errors can be detected through hash functions.
In production systems these techniques are used together to ensure various degrees of data integrity. For example, a computer file system may be configured on a fault-tolerant RAID array, but might not provide block-level checksums to detect and prevent silent data corruption. As another example, a database management system might be compliant with the ACID properties, but the RAID controller or hard disk drive's internal write cache might not be.
Logical integrity.
This type of integrity is concerned with the correctness or rationality of a piece of data, given a particular context. This includes topics such as referential integrity and entity integrity in a relational database or correctly ignoring impossible sensor data in robotic systems. These concerns involve ensuring that the data "makes sense" given its environment. Challenges include software bugs, design flaws, and human errors. Common methods of ensuring logical integrity include things such as a check constraints, foreign key constraints, program assertions, and other run-time sanity checks.
Both physical and logical integrity often share many common challenges such as human errors and design flaws, and both must appropriately deal with concurrent requests to record and retrieve data, the latter of which is entirely a subject on its own.
Databases.
Data integrity contains guidelines for data retention, specifying or guaranteeing the length of time data can be retained in a particular database. It specifies what can be done with data values when their validity or usefulness expires. In order to achieve data integrity, these rules are consistently and routinely applied to all data entering the system, and any relaxation of enforcement could cause errors in the data. Implementing checks on the data as close as possible to the source of input (such as human data entry), causes less erroneous data to enter the system. Strict enforcement of data integrity rules causes the error rates to be lower, resulting in time saved troubleshooting and tracing erroneous data and the errors it causes algorithms.
Data integrity also includes rules defining the relations a piece of data can have, to other pieces of data, such as a "Customer" record being allowed to link to purchased "Products", but not to unrelated data such as "Corporate Assets". Data integrity often includes checks and correction for invalid data, based on a fixed schema or a predefined set of rules. An example being textual data entered where a date-time value is required. Rules for data derivation are also applicable, specifying how a data value is derived based on algorithm, contributors and conditions. It also specifies the conditions on how the data value could be re-derived.
Types of integrity constraints.
Data integrity is normally enforced in a database system by a series of integrity constraints or rules. Three types of integrity constraints are an inherent part of the relational data model: entity integrity, referential integrity and domain integrity:
If a database supports these features it is the responsibility of the database to ensure data integrity as well as the consistency model for the data storage and retrieval. If a database does not support these features it is the responsibility of the applications to ensure data integrity while the database supports the consistency model for the data storage and retrieval.
Having a single, well-controlled, and well-defined data-integrity system increases
, since all modern databases support these features (see Comparison of relational database management systems), it has become the de facto responsibility of the database to ensure data integrity. Out-dated and legacy systems that use file systems (text, spreadsheets, ISAM, flat files, etc.) for their consistency model lack any kind of data-integrity model. This requires organizations to invest a large amount of time, money and personnel in building data-integrity systems on a per-application basis that needlessly duplicate the existing data integrity systems found in modern databases. Many companies, and indeed many database systems themselves, offer products and services to migrate out-dated and legacy systems to modern databases to provide these data-integrity features. This offers organizations substantial savings in time, money and resources because they do not have to develop per-application data-integrity systems that must be refactored each time the business requirements change.
Examples.
An example of a data-integrity mechanism is the parent-and-child relationship of related records. If a parent record owns one or more related child records all of the referential integrity processes are handled by the database itself, which automatically ensures the accuracy and integrity of the data so that no child record can exist without a parent (also called being orphaned) and that no parent loses their child records. It also ensures that no parent record can be deleted while the parent record owns any child records. All of this is handled at the database level and does not require coding integrity checks into each applications.
File systems.
Various research results show that neither widespread filesystems (including UFS, Ext, XFS, JFS and NTFS) nor hardware RAID solutions provide sufficient protection against data integrity problems.
Some filesystems (including Btrfs and ZFS) provide internal data and metadata checksumming, what is used for detecting silent data corruption and improving data integrity. If a corruption is detected that way and internal RAID mechanisms provided by those filesystems are also used, such filesystems can additionally reconstruct corrupted data in a transparent way. This approach allows improved data integrity protection covering the entire data paths, which is usually known as end-to-end data protection.
Data storage.
Apart from data in databases, standards exist to address the integrity of data on storage devices.

</doc>
<doc id="40996" url="https://en.wikipedia.org/wiki?curid=40996" title="Data link">
Data link

In telecommunication a data link is the means of connecting one location to another for the purpose of transmitting and receiving digital information. It can also refer to a set of electronics assemblies, consisting of a transmitter and a receiver (two pieces of data terminal equipment) and the interconnecting data telecommunication circuit. These are governed by a link protocol enabling digital data to be transferred from a data source to a data sink.
There are at least three types of basic data-link configurations that can be conceived of and used:
In civil aviation, a data-link system (known as Controller Pilot Data Link Communications) is used to send information between aircraft and air traffic controllers when an aircraft is too far from the ATC to make voice radio communication and radar observations possible. Such systems are used for aircraft crossing the Atlantic and Pacific oceans. One such system, used by Nav Canada and NATS over the North Atlantic, uses a five-digit data link sequence number confirmed between air traffic control and the pilots of the aircraft before the aircraft proceeds to cross the ocean. This system uses the aircraft's flight management computer to send location, speed and altitude information about the aircraft to the ATC. ATC can then send messages to the aircraft regarding any necessary change of course. 
In unmanned aircraft, land vehicles, boats, and spacecraft, a two-way (full-duplex or half-duplex) data-link is used to send control signals, and to receive telemetry.

</doc>
<doc id="40997" url="https://en.wikipedia.org/wiki?curid=40997" title="Data service unit">
Data service unit

A data service unit, sometimes called a digital service unit, is a piece of telecommunications circuit terminating equipment that transforms digital data between telephone company lines and local equipment. The device converts bipolar digital signals coming ultimately from a digital circuit and directly from a Channel service unit (CSU), into a format (e.g. RS- 530) compatible with the piece of data terminal equipment (DTE) (e.g. a router) to which the data is sent. The DSU also performs a similar process in reverse for data heading from the DTE toward the circuit. The telecommunications service a DSU supports can be a point-to-point or multipoint operation in a digital data network.
A DSU is a two or more port device; one port is called the WAN (Wide Area Network) port and the other is called a DTE port. The purpose of the DSU is to transfer serial data synchronously between the WAN port and the DTE ports. If more than one DTE port is used, the DSU assigns the DTE data according to time slots (channels) on the WAN side.
On the WAN side, the DSU, via a CSU, interfaces with a digital carrier such as DS1 or DS3 or a low speed Digital Data Service. On the DTE side, the DSU provides control lines, timing lines and appropriate physical and electrical interface. To maintain the synchronous relationship between the ports, the DSU manages timing by slaving ports to the bit rate of another or to its internal clock. Typically, the DTE port provides timing to the data terminal equipment while the WAN port dictates the rate.
DSUs usually include some maintenance capabilities. At minimum, they can loop data back at either the WAN or DTE ports, or at both. When only one port is looped back, the data received at that port is simultaneously sent back toward the port and passed in normal fashion to the other port. Most DSUs also allow various data patterns to be generated and monitored to measure error rate of the communication link. A DSU may be a separate piece of equipment, or may be combined in a CSU/DSU.

</doc>
<doc id="40998" url="https://en.wikipedia.org/wiki?curid=40998" title="Data signaling rate">
Data signaling rate

In telecommunication, data signaling rate (DSR), also known as gross bit rate, is the aggregate rate at which data pass a point in the transmission path of a data transmission system.
Notes:
Maximum rate.
The "maximum user signaling rate", synonymous to gross bitrate or data signaling rate, is the maximum rate, in bits per second, at which binary information can be transferred in a given direction between users over the telecommunications system facilities dedicated to a particular information transfer transaction, under conditions of continuous transmission and no overhead information. 
For a single channel, the signaling rate is given by , where "SCSR" is the single-channel signaling rate in bits per second, "T" is the minimum time interval in seconds for which each level must be maintained, and n is the number of significant conditions of modulation of the channel. 
In the case where an individual end-to-end telecommunications service is provided by parallel channels, the parallel-channel signaling rate is given by , where "PCSR" is the total signaling rate for "m" channels, "m" is the number of parallel channels, "Ti" is the minimum interval between significant instants for the "I"-th channel, and "ni" is the number of significant conditions of modulation for the "I"-th channel. 
In the case where an end-to-end telecommunications service is provided by tandem channels, the end-to-end signaling rate is the lowest signaling rate among the component channels.

</doc>
<doc id="40999" url="https://en.wikipedia.org/wiki?curid=40999" title="Data transmission circuit">
Data transmission circuit

In telecommunication, a data transmission circuit is the transmission media and the intervening equipment used for the data transfer between data terminal equipments (DTEs). 
"Note 1:" A data transmission circuit includes any required signal conversion equipment. 
"Note 2:" A data transmission circuit may transfer information in (a) one direction only, (b) either direction but one way at a time, or (c) both directions simultaneously. See duplex (telecommunications).

</doc>
<doc id="41000" url="https://en.wikipedia.org/wiki?curid=41000" title="Date-time group">
Date-time group

In communications messages, a date-time group (DTG) is a set of characters, usually in a prescribed format, used to express the year, the month, the day of the month, the hour of the day, the minute of the hour, and the time zone, if different from Coordinated Universal Time (UTC). The order in which these elements are presented may vary. The DTG is usually placed in the header of the message. One example is " (UTC)".
The DTG may indicate either the date and time a message was dispatched by a transmitting station or the date and time it was handed into a transmission facility by a user or originator for dispatch.
The DTG may be used as a message identifier if it is unique for each message. 
The DTG is used in message traffic. EXAMPLE: 091630Z JUL 11 represents 1630 GMT on 9 July 2011.

</doc>
<doc id="41001" url="https://en.wikipedia.org/wiki?curid=41001" title="DB (car)">
DB (car)

DB (until 1947 known as Deutsch-Bonnet) was a French automobile maker between 1938 and 1961, based in Champigny-sur-Marne near Paris. The firm was founded by Charles Deutsch and René Bonnet, an offshoot of the Deutsch family's existing coachbuilding shop which had been taken over by Bonnet in 1932. Immediately before the war the partners concentrated on making light-weight racing cars, but a few years after the war, starting with the presentation of a Panhard based cabriolet at the 1950 Paris Motor Show, the company also began to produce small road-going sports cars. By 1952 the company no longer had its own stand at the Paris motorshow, but one of their cars appeared as a star attraction on the large Panhard stand, reflecting the level of cooperation between the two businesses.
The company was defunct by 1961, as Deutsch and Bonnet's differing design philosophies hamstrung further cooperation. The number of DB's built is not certain; estimates of up to 2,000 cars are mentioned but more conservative numbers are closer to one thousand.
Light-weight engineering.
The business produced light sports cars, originally in steel or aluminium but subsequently with fibreglass bodies mainly powered by Panhard flat-twin engines, most commonly of 610, 744, or 848 cc. Deutsch was a "theoretical engineer who had a natural instinct for aerodynamics," while Bonnet was a more "pragmatic mechanical engineer".
The fibreglass bodies covered a tubular central beam chassis made from steel, with front wheel drive and four wheel independent suspension directly lifted from the Panhard donors. Until 1952 all DBs had been intended for competition purposes only.
Racing origins.
Bonnet had been promised a works drive in an Amilcar Pégase in the 1936 French Grand Prix for sports cars, but when this failed to materialise they set about building their own racer. The 1938 alloy-bodied DB1 roadster was a special, built using the remains of a Citroën Traction Avant 11CV. The construction took seventeen months. A series of numbered successors followed. The close-roofed 1.5-litre DB2's career was hindered by the war and was sold later, without Deutsch ever using it. The DB3 was a monocoque project developed during the war, but was never built, as the improved pontoon-bodied DB4 took preference. With a central beam chassis with a forked cradle for the 1.5 litre Traction 7A-based engine (originally intended for the DB2) it was finished in July 1945, with most of the work having been carried out in secret during the occupation. The very similar 2-litre DB5 was finished soon thereafter. Their two specials both placed in the first postwar race in France, in Paris in 1945, being the only post-war cars entered. An open-wheeled DB7 appeared in 1947 (preceded by the heavy and large DB6 which saw very little action), after which the "Automobiles Deutsch & Bonnet" was officially formed.
Neither single-seater DB was at all successful, but they did show Deutsch - who had hitherto preferred dependable standard units - that a tuned engine would become necessary. DB thus moved into the performance parts market, developing and offering a four-speed conversion for Citroëns and an overhead camshaft head - developed with the aid of engine specialists Maurice Sainturat and Dante Giacosa. The DB8 appeared in 1948, and won two "concours d'élegances" before partaking in any competitions. Their early cars were all built using Citroën parts, but supply was troublesome and DB soon moved on to using Panhard technology. This relationship came about as Deutsch was an officer of independent racer's club AGACI. When this organization decided to begin a "Mouvement Racer 500", modelled on the British Formula 3, Deutsch offered club members the design of a racing car using a Panhard 500 engine. One member asked to have DB build such a car, and after it made a star appearance at the 1949 Paris Salon Panhard was happy to support the construction of about fifteen more. The formula expired in 1951, with the DB Panhard 500 never competitive abroad.
DB was very active in competition, especially in Le Mans 24 Hours and other long distance racing. Nearly all DBs, even the road cars, were designed with competition foremost in mind. In 1952, a DB Speedster was entered in the 12 Hours of Sebring and won its class handsomely, beginning its career in the United States market. Steve Lansing and Ward Morehouse were the drivers.
At the 1954 Le Mans DB entered five cars and were also involved with Panhards "Monopole" racers. René Bonnet himself, together with racing legend Élie Bayol, finished tenth overall and best of the DBs. The other Panhard-engined also finished (in 16th), while three Renault-engined central-seater DB designs all failed to complete the race. The Renault-engined designs had been created as a concession to pressure from DB's customers, but they did very badly in the race, in part because of a shortage of preparation time for what was an unknown entity to Deutsch and Bonnet. In either case, DB proceeded to focus on Panhard designs exclusively.
Road cars.
The 1949 DB8 was bodied by Antem of Belgium and shown at the 1949 Paris Salon. While a handsome (winning two concours d'élegances) and modern design, Citroën refused to allow the provision of parts for series production. After DB began to depend on Panhard for engines, Antem was again commissioned to make a cabriolet with the intent to build a small series of street cars. long, the car weighed and used the Dyna's 750 cc flat-two and much of the suspension and drivetrain. As with most DBs, it had a central frame with two outliers. An 850 cc version was also offered, a model which could reach 140 rather than the 125-130 km/h of the smaller one. Naturally, Panhard developed a racing "barquette" version (called the Tank) of the Antem cabriolet. These competed at Le Mans 1951 as well as several other races. About twenty Antem cabriolets were built in 1951, but DB chose to let it die in favor of a coupé version of the same ("Coach" in French). A few DB-Antem Coach were built, mostly for competition. These had bodywork designed by Deutsch, and again mainly relied on Dyna underpinnings and a central steel-tube frame.
The steel-bodied, Frua-designed 1952 "Mille Miles" (celebrating class victories at the Mille Miglia) was a mini-GT with a 65 hp Panhard two-cylinder. It was somewhat expensive, and at the 1953 Paris Salon a Chausson-designed DB Coach in fibreglass, although it did not enter production until 1954. The HBR 4/5 model (1954–1959) was the partners' most successful project to date, with several hundred of the little cars produced between 1954 and 1959. This was followed by the Le Mans convertible and hardtop, which was shown in 1959 and built by DB until 1962, and continued until 1964 by René Bonnet. About 660 of the Mille Miles/Coach/HBR were built, and 232 DB Le Mans (not including the Bonnet-built cars). Later versions could be equipped with engines of 1 and 1.3 litres, and superchargers were also available. No two cars may have been alike, as they were built according to customer specifications from a wide range of options.
More racing success.
Deutsch's very efficient and influential aerodynamic designs allowed DB race cars to reach impressive top speeds despite the small Panhard flat-twin engine. DB's received class victories at Le Mans (three times), Sebring (twice), and Mille Miglia (four times). DB even managed an outright win in the handicapped 1954 Tourist Trophy sports car race, with Laureau and Armagnac driving. DB always showed strongly in the "Index of Performance", a category especially suitable for DB's small-engined, aerodynamic little racers. The Index of Performance is perhaps best known at the Le Mans 24 hours competition, but the category also existed at many French automobile races of the era, such as the Tour de France. DBs were also successful in American SCCA racing, where they racked up an impressive number of victories in the H-sports category.
Disagreement and the end of the partnership.
Deutsch and Bonnet disagreed whether they should build cars of front-wheel drive or mid-engined design. There was also disagreement on which engines to use. Charles Deutsch, wanting to stick to Panhard engines, left DB in 1961 to found his own firm (CD). Bonnet founded "Automobiles René Bonnet", producing cars powered by Renault engines: this business was later to become part of Matra Automobiles. Deutsch ended up an engineering consultant.

</doc>
<doc id="41002" url="https://en.wikipedia.org/wiki?curid=41002" title="Weighting filter">
Weighting filter

A weighting filter is used to emphasize or suppress some aspects of a phenomenon compared to others, for measurement or other purposes.
Audio applications.
In each field of audio measurement, special units are used to indicate a weighted measurement as opposed to a basic physical measurement of energy level. For sound, the unit is the phon (1 kHz equivalent level).
Loudness measurements.
In the measurement of loudness, for example, an A-weighting filter is commonly used to emphasize frequencies around 3–6 kHz where the human ear is most sensitive, while attenuating very high and very low frequencies to which the ear is insensitive. The aim is to ensure that measured loudness corresponds well with subjectively perceived loudness.
A-weighting is only really valid for relatively quiet sounds and for pure tones as it is based on the 40-phon Fletcher–Munson equal-loudness contour. The B and C curves were intended for louder sounds (though they are less used) while the D curve is used in assessing loud aircraft noise (IEC 537).
Telecommunications.
In the field of telecommunications, weighting filters are widely used in the measurement of electrical noise on telephone circuits, and in the assessment of noise as perceived through the acoustic response of different types of instrument (handset). Other noise-weighting curves have existed, e.g. DIN standards. The term "psophometric weighting", though referring in principle to any weighting curve intended for noise measurement, is often used to refer to a particular weighting curve, used in telephony for narrow-bandwidth voiceband speech circuits.
Environmental noise measurement.
A-weighted decibels are abbreviated dB(A) or dBA. When acoustic (calibrated microphone) measurements are being referred to, then the units used will be dB SPL (sound pressure level) referenced to 20 micropascals = 0 dB SPL. dBrn adjusted is a synonym for dBA.
The A-weighting curve has been widely adopted for environmental noise measurement, and is standard in many sound level meters (see ITU-R 468 weighting for a further explanation).
A-weighting is also in common use for assessing potential hearing damage caused by loud noise, though this seems to be based on the widespread availability of sound level meters incorporating A-Weighting rather than on any good experimental evidence to suggest that such use is valid. The distance of the measuring microphone from a sound source is often "forgotten", when SPL measurements are quoted, making the data useless. In the case of environmental or aircraft noise, distance need not be quoted as it is the level at the point of measurement that is needed, but when measuring refrigerators and similar appliances the distance should be stated; where not stated it is usually one metre (1 m). An extra complication here is the effect of a reverberant room, and so noise measurement on appliances should state "at 1 m in an open field" or "at 1 m in anechoic chamber". Measurements made outdoors will approximate well to anechoic conditions.
A-weighted SPL measurements of noise level are increasingly to be found on sales literature for domestic appliances such as refrigerators and freezers, and computer fans. Although the threshold of hearing is typically around 0 dB SPL, this is in fact very quiet indeed, and appliances are more likely to have noise levels of 30 to 40 dB SPL.
Audio reproduction and broadcasting equipment.
Human sensitivity to noise in the region of 6 kHz became particularly apparent in the late 1960s with the introduction of compact cassette recorders and Dolby-B noise reduction. A-weighted noise measurements were found to give misleading results because they did not give sufficient prominence to the 6 kHz region where the noise reduction was having greatest effect, and sometimes one piece of equipment would even measure worse than another and yet sound better, because of differing spectral content.
ITU-R 468 noise weighting was therefore developed to more accurately reflect the subjective loudness of all types of noise, as opposed to tones. This curve, which came out of work done by the BBC Research Department, and was standardised by the CCIR and later adopted by many other standards bodies (IEC, BSI/) and, , is maintained by the ITU. Noise measurements using this weighting typically also use a quasi-peak detector law rather than slow averaging. This also helps to quantify the audibility of bursty noise, ticks and pops that might go undetected with a slow rms measurement.
ITU-R 468 noise weighting with quasi-peak detection is widely used in Europe, especially in telecommunications, and in broadcasting particularly after it was adopted by the Dolby corporation who realised its superior validity for their purposes. Its advantages over A-weighting seem to be less well appreciated in the USA and in consumer electronics, where the use of A-weighting predominates—probably because A-weighting produces a 9 to 12 dB "better" specification, see specsmanship. It is commonly used by broadcasters in Britain, Europe, and former countries of the British Empire such as Australia and South Africa.
Though the noise level of 16-bit audio systems (such as CD players) is commonly quoted (on the basis of calculations that take no account of subjective effect) as −96 dB relative to FS (full scale), the best 468-weighted results are in the region of −68 dB relative to Alignment Level (commonly defined as 18 dB below FS) i.e. −86 dB relative to FS.
The use of weighting curves is in no way to be regarded as 'cheating', provided that the proper curve is used. Nothing of relevance is being 'hidden', and even when, for example, hum is present at 50 or 100 Hz at a level above the quoted (weighted) noise floor this is of no importance because our ears are very insensitive to low frequencies at low levels, so it will not be heard. A-weighting is often used to compare and qualify ADCs, for instance, because it more accurately represents the way noise shaping hides dither noise in the ultrasonic range.
Other applications of weighting.
In the measurement of gamma rays or other ionising radiation, a radiation monitor or dosimeter will commonly use a filter to attenuate those energy levels or wavelengths that cause the least damage to the human body, while letting through those that do the most damage, so that any source of radiation may be measured in terms of its true danger rather than just its 'strength'. The sievert is a unit of weighted radiation dose for ionising radiation, which supersedes the older unit the REM (roentgen equivalent man).
Weighting is also applied to the measurement of sunlight when assessing the risk of skin damage through sunburn, since different wavelengths have different biological effects. Common examples are the SPF of sunscreen, and the UV index.
Another use of weighting is in television, where the red, green and blue components of the signal are weighted according to their perceived brightness. This ensures compatibility with black and white receivers, and also benefits noise performance and allows separation into meaningful luminance and chrominance signals for transmission.

</doc>
<doc id="41003" url="https://en.wikipedia.org/wiki?curid=41003" title="DBm">
DBm

dBm (sometimes dBmW or decibel-milliwatts) is an abbreviation for the power ratio in decibels (dB) of the measured power referenced to one milliwatt (mW). It is used in radio, microwave and fiber optic networks as a convenient measure of absolute power because of its capability to express both very large and very small values in a short form. Compare dBW, which is referenced to one watt (1000 mW).
Since it is referenced to the watt, it is an absolute unit, used when measuring absolute power. By comparison, the decibel (dB) is a dimensionless unit, used for quantifying the ratio between two values, such as signal-to-noise ratio.
In audio and telephony, dBm is typically referenced relative to a 600 ohm impedance, while in radio frequency work dBm is typically referenced relative to a 50 ohm impedance.
Unit conversions.
A power level of 0 dBm corresponds to a power of 1 milliwatt. A 3 dB increase in level is approximately equivalent to doubling the power, which means that a level of 3 dBm corresponds roughly to a power of 2 mW. For each 3 dB decrease in level, the power is reduced by about one half, making −3 dBm correspond to a power of about 0.5 mW.
To express an arbitrary power "P" in mW as "x" in dBm, or vice versa, the following equivalent expressions may be used:
idem with "P" in watts
where "P" is the power in W and "x" is the power level in dBm. Below is a table summarizing useful cases:
The signal intensity (power per unit area) can be converted to received signal power by multiplying by the square of the wavelength and dividing by 4π (see Free-space path loss).
In United States Department of Defense practice, unweighted measurement is normally understood, applicable to a certain bandwidth, which must be stated or implied.
In European practice, psophometric weighting may be, as indicated by context, equivalent to dBm0p, which is preferred.
In audio, 0 dBm often corresponds to approximately 0.775 volts, since 0.775 volts dissipates 1 mW in a 600 Ω load. dBu measures against this reference voltage without the 600 Ω restriction. Conversely, for RF situations with a 50 Ω load, 0 dBm corresponds to approximately 0.224 volts since 0.224 volts dissipates 1 mW in a 50 Ω load. 
The dBm is not a part of the International System of Units and therefore is discouraged from use in documents or systems that adhere to SI units (the corresponding SI unit is the watt). However the straight decibel (dB), being a unitless ratio of two numbers, is perfectly acceptable.
Expression in dBm is typically used for optical and electrical power measurements, not for other types of power (such as thermal). A listing by power levels in watts is available that includes a variety of examples not necessarily related to electrical or optical power.
The dBm was first proposed as an industry standard in the paper "A New Standard Volume Indicator and Reference Level".

</doc>
<doc id="41004" url="https://en.wikipedia.org/wiki?curid=41004" title="DBrn">
DBrn

The symbol dBrn or dB(rn) is an abbreviation for decibels above reference noise. 
Weighted noise power in dB is referred to 1.0 picowatt. Thus, 0 dBrn = -90 dBm. Use of 144 line, 144-receiver, or C-message weighting, or flat weighting, can be indicated in parentheses. 
With C-message weighting, a one-milliwatt, 1000 Hz tone will read +90 dBrn, but the same power as white noise, randomly distributed over a 3 kHz band will read approximately +88.5 dBrn, because of the frequency weighting. 
With 144 weightings, a one milliwatt, 1000 Hz white noise tone will also read +90 dBrn, but the same 3 kHz power will only read +82 dBrn, because of the different frequency weighting.

</doc>
<doc id="41005" url="https://en.wikipedia.org/wiki?curid=41005" title="Data circuit-terminating equipment">
Data circuit-terminating equipment

A data circuit-terminating equipment (DCE) is a device that sits between the data terminal equipment (DTE) and a data transmission circuit. It is also called data communication(s) equipment and data carrier equipment. Usually, the DTE device is the terminal (or computer), and the DCE is a modem.
In a data station, the DCE performs functions such as signal conversion, coding, and line clocking and may be a part of the DTE or intermediate equipment. Interfacing equipment may be required to couple the data terminal equipment (DTE) into a transmission circuit or channel and from a transmission circuit or channel into the DTE.
Although the terms are most commonly used with RS-232, several data communications standards define different types of interfaces between a DCE and a DTE. The DCE is a device that communicates with a DTE device in these standards. Standards that use this nomenclature include:
A general rule is that DCE devices provide the clock signal (internal clocking) and the DTE device synchronizes on the provided clock (external clocking). D-sub connectors follow another rule for pin assignment. DTE devices usually transmit on pin connector number 2 and receive on pin connector number 3. DCE devices are just the opposite: pin connector number 2 receives and pin connector number 3 transmits the signals.
When two devices, that are both DTE or both DCE, must be connected together without a modem or a similar media translator between them, a crossover cable must be used, e.g. a null modem for RS-232 or an Ethernet crossover cable.

</doc>
<doc id="41008" url="https://en.wikipedia.org/wiki?curid=41008" title="Degradation">
Degradation

Degradation may refer to:

</doc>
<doc id="41009" url="https://en.wikipedia.org/wiki?curid=41009" title="Degree of isochronous distortion">
Degree of isochronous distortion

The degree of isochronous distortion, in data transmission, is the ratio of the absolute value of the maximum measured difference between the actual and the theoretical intervals separating any two significant instants of modulation (or demodulation), to the unit interval. These instants are not necessarily consecutive. This value is usually expressed as a percentage.
The result of the measurement should be qualified by an indication if the period, usually limited, of the observation. For a prolonged modulation (or demodulation), it will be appropriate to consider the probability that an assigned value of the degree of distortion will be exceeded.

</doc>
<doc id="41010" url="https://en.wikipedia.org/wiki?curid=41010" title="Degree of start-stop distortion">
Degree of start-stop distortion

In telecommunication, the term degree of start-stop distortion has the following meanings: 
The degree of distortion of a start-stop modulation (or demodulation) is usually expressed as a percentage. Distinction can be made between the degree of late (positive) distortion and the degree of early (negative) distortion.

</doc>
<doc id="41012" url="https://en.wikipedia.org/wiki?curid=41012" title="Delay">
Delay

Delay may refer to:

</doc>
<doc id="41013" url="https://en.wikipedia.org/wiki?curid=41013" title="Delay encoding">
Delay encoding

In telecommunications, delay encoding is the encoding of binary data to form a two-level signal where (a) a "0" causes no change of signal level unless it is followed by another "0" in which case a transition to the other level takes place at the end of the first bit period; and (b) a "1" causes a transition from one level to the other in the middle of the bit period. 
Delay encoding is used primarily for encoding radio signals because the frequency spectrum of the encoded signal contains less low-frequency energy than a conventional non-return-to-zero (NRZ) signal and less high-frequency energy than a biphase signal.
Delay encoding is an encoding using only half the bandwidth for biphase encoding but features all the advantages of biphase encoding:
"To be rewritten: It is guaranteed to have transitions every other bit, meaning that decoding systems can adjust their clock/DC threshold continuously".
One drawback is human readability (e.g. on an oscilloscope).
Delay encoding is also known as Miller encoding (named after Armin Miller, its inventor). <US Pat. # 3,108,261>
Some RFID cards, in particular EPC UHF Gen 2 RF cards, use a variant called "Miller sub-carrier coding".
In this system, 2, 4 or 8 cycles of a subcarrier square wave are transmitted for each bit time. The Miller encoding transitions are indicated by 180° phase shifts in the subcarrier, i.e. the subcarrier pauses for 1/2 of a cycle at each transition. (The resultant binary subcarrier is itself either ASK or PSK modulated on another carrier.)

</doc>
<doc id="41014" url="https://en.wikipedia.org/wiki?curid=41014" title="Delay line">
Delay line

Delay line may refer to:

</doc>
<doc id="41015" url="https://en.wikipedia.org/wiki?curid=41015" title="Delta modulation">
Delta modulation

A delta modulation (DM or Δ-modulation) is an analog-to-digital and digital-to-analog signal conversion technique used for transmission of voice information where quality is not of primary importance. DM is the simplest form of differential pulse-code modulation (DPCM) where the difference between successive samples are encoded into n-bit data streams. In delta modulation, the transmitted data are reduced to a 1-bit data stream. Its main features are:
To achieve high signal-to-noise ratio, delta modulation must use oversampling techniques, that is, the analog signal is sampled at a rate several times higher than the Nyquist rate.
Derived forms of delta modulation are continuously variable slope delta modulation, delta-sigma modulation, and differential modulation. Differential pulse-code modulation is the superset of DM.
Principle.
Rather than quantizing the absolute value of the input analog waveform, delta modulation quantizes the difference between the current and the previous step, as shown in the block diagram in Fig. 1.
The modulator is made by a quantizer which converts the difference between the input signal and the average of the previous steps. In its simplest form, the quantizer can be realized with a comparator referenced to 0 (two levels quantizer), whose output is "1" or "0" if the input signal is positive or negative. It is also a bit-quantizer as it quantizes only a bit at a time. The demodulator is simply an integrator (like the one in the feedback loop) whose output rises or falls with each 1 or 0 received. The integrator itself constitutes a low-pass filter.
Transfer characteristics.
The transfer characteristics of a delta modulated system follows a signum function, as it quantizes only two levels and also one-bit at a time.
The two sources of noise in delta modulation are "slope overload", when steps are too small to track the original waveform, and "granularity", when steps are too large.
But a 1971 study shows that slope overload is less objectionable compared to granularity than one might expect based solely on SNR measures.
Output signal power.
In delta modulation there is a restriction on the amplitude of the input signal, because if the transmitted signal has a large derivative (abrupt changes) then modulated signal can not follow the input signal and slope overload occurs. Lets say if the input signal is
formula_1
Modulated Signal (derivative of the input signal) which is transmitted by the modulator
formula_2
Whereas the condition to avoid slope overload is
formula_3
So maximum amplitude of input signal can be
formula_4
Where fs is the sampling frequency and ω is the frequency of the input signal and σ is step size in quantization. So Amax is the maximum amplitude that DM can transmit without causing the slope overload and the power of transmitted signal depends on the maximum amplitude.
Bit-rate.
If the communication channel is of limited bandwidth, there is the possibility of interference in either DM or PCM. Hence, 'DM' and 'PCM' operate at same bit-rate which is equal to N times the sampling frequency.
Adaptive delta modulation.
Adaptive delta modulation (ADM) was first published by Dr. John E. Abate (AT&T Bell Laboratories Fellow) in his doctorial thesis at NJ Institute Of Technology in 1968. ADM was later selected as the standard for all NASA communications between mission control and space-craft.
Adaptive delta modulation or variable slope delta modulation (CVSD) is a modification of DM in which the step size is not fixed. Rather, when several consecutive bits have the same direction value, the encoder and decoder assume that slope overload is occurring, and the step size becomes progressively larger.
Otherwise, the step size becomes gradually smaller over time. ADM reduces slope error, at the expense of increasing quantizing error.This error can be reduced by using a low-pass filter. ADM provides robust performance in the presence of bit errors meaning error detection and correction are not typically used in an ADM radio design, this allows for a reduction in host processor workload (allowing a low-cost processor to be used).
Applications.
Contemporary applications of Delta Modulation includes, but is not limited to, recreating legacy synthesizer waveforms. With the increasing availability of FPGAs and game-related ASICs, sample rates are easily controlled so as to avoid slope overload and granularity issues. For example, the C64DTV used a 32 MHz sample rate, providing ample dynamic range to recreate the SID output to acceptable levels.
SBS Application 24 kbps delta modulation.
Delta Modulation was used by Satellite Business Systems or SBS for its voice ports to provide long distance phone service to large domestic corporations with a significant inter-corporation communications need (such as IBM). This system was in service throughout the 1980s. The voice ports used digitally implemented 24 kbit/s delta modulation with Voice Activity Compression (VAC) and echo suppressors to control the half second echo path through the satellite. They performed formal listening tests to verify the 24 kbit/s delta modulator achieved full voice quality with no discernible degradation as compared to a high quality phone line or the standard 64 kbit/s µ-law companded PCM. This provided an eight to three improvement in satellite channel capacity. IBM developed the Satellite Communications Controller and the voice port functions.
The original proposal in 1974, used a state-of-the-art 24 kbit/s delta modulator with a single integrator and a Shindler Compander modified for gain error recovery. This proved to have less than full phone line speech quality. In 1977, one engineer with two assistants in the IBM Research Triangle Park, NC laboratory was assigned to improve the quality.
The final implementation replaced the integrator with a Predictor implemented with a two pole complex pair low-pass filter designed to approximate the long term average speech spectrum. The theory was that ideally the integrator should be a predictor designed to match the signal spectrum. A nearly perfect Shindler Compander replaced the modified version. It was found the modified compander resulted in a less than perfect step size at most signal levels and the fast gain error recovery increased the noise as determined by actual listening tests as compared to simple signal to noise measurements. The final compander achieved a very mild gain error recovery due to the natural truncation rounding error caused by twelve bit arithmetic.
The complete function of delta modulation, VAC and Echo Control for six ports was implemented in a single digital integrated circuit chip with twelve bit arithmetic. A single digital-to-analog converter (DAC) was shared by all six ports providing voltage compare functions for the modulators and feeding sample and hold circuits for the demodulator outputs. A single card held the chip, DAC and all the analog circuits for the phone line interface including transformers.

</doc>
<doc id="41016" url="https://en.wikipedia.org/wiki?curid=41016" title="Demand assignment">
Demand assignment

In telecommunication, a demand assignment is a method which several users share access to a communications channel on a real-time basis, "i.e.", a user needing to communicate with another user on the same network requests the required circuit, uses it, and when the call is finished, the circuit is released, making the circuit available to other users. 
Demand assignment is similar to conventional telephone switching, in which common trunks are provided for many users, on a demand basis, through a limited-size trunk group.

</doc>
<doc id="41017" url="https://en.wikipedia.org/wiki?curid=41017" title="Demand factor">
Demand factor

In telecommunication, electronics and the electrical power industry, the term demand factor is used to refer to the fractional amount of some quantity being used relative to the maximum amount that could be used by the same system. The demand factor is always less than or equal to one. As the amount of demand is a time dependent quantity so is the demand factor.
formula_1
The demand factor is often implicitly averaged over time when the time period of demand is understood by the context.
Electrical engineering.
In electrical engineering the demand factor is taken as a time independent quantity where the numerator is taken as the maximum demand in the specified time period instead of the averaged or instantaneous demand. the possible 
formula_2
This is the peak in the load profile divided by the full load of the device.
Example: 
If a residence has equipment which would draw 6,000 W when all equipment was drawing a full load draw a maximum of 3,000 W in a specified time, then the demand factor = 3,000 W / 6,000 W = 0.5
This quantity is relevant when trying to establish the amount of load a system should be rated for. In the above example it would be unlikely that the system would be rated to 6,000 W even though there may be a slight possibility that this amount of power can be drawn. This is closely related to the load factor which is the average load divided by the peak load in a specified time period.
formula_3

</doc>
<doc id="41018" url="https://en.wikipedia.org/wiki?curid=41018" title="Demand load">
Demand load

In telecommunication, the term demand load can have the following meanings: 

</doc>
<doc id="41019" url="https://en.wikipedia.org/wiki?curid=41019" title="Desensitation">
Desensitation

In telecommunication, desensitation is the reduction of desired signal gain as a result of receiver reaction to an undesired signal. 
The gain reduction is generally due to overload of some portion of the receiver (e.g., the automatic gain control circuitry) resulting in suppression of the desired signal because the receiver will no longer respond linearly to incremental changes in input voltage.

</doc>
<doc id="41020" url="https://en.wikipedia.org/wiki?curid=41020" title="Design objective">
Design objective

Design objective (DO): In communications systems, a desired performance characteristic for communications circuits and equipment that is based on engineering analyses, but (a) is not considered feasible to mandate in a standard, or (b) has not been tested. 
DOs are used because applicable systems standards are not in existence. 
Examples of reasons for designating a performance characteristic as a DO rather than as a standard are (a) it may be bordering on an advancement in the state of the art, (b) the requirement may not have been fully confirmed by measurement or experience with operating circuits, and (c) it may not have been demonstrated that the requirement can be met considering other constraints, such as cost and size. 
A DO is sometimes established in a standard for developmental consideration. A DO may also specify a performance characteristic used in the preparation of specifications for development or procurement of new equipment or systems.

</doc>
<doc id="41021" url="https://en.wikipedia.org/wiki?curid=41021" title="Detector (disambiguation)">
Detector (disambiguation)

A detector is a device capable of registering a specific substance or physical phenomenon.
Detector may also refer to:

</doc>
<doc id="41022" url="https://en.wikipedia.org/wiki?curid=41022" title="Deterministic routing">
Deterministic routing

In telecommunications, deterministic routing is the advance determination of the routes between given pairs of nodes. Examples:

</doc>
<doc id="41024" url="https://en.wikipedia.org/wiki?curid=41024" title="Pulse dialing">
Pulse dialing

Pulse dialling is a signaling technology in telecommunications in which a direct current local loop circuit is interrupted according to a defined coding system for each signal transmitted, usually a digit. This lends the method the often used name loop disconnect dialing. In the most common variant of pulse dialing, decadic dialing, each of the ten arabic numerals are encoded in a sequence of up to ten pulses. The most common version decodes the digits 1 through 9, as one to nine pulses, respectively, and the digit 0 as ten pulses. Historically, the most common device to produce such pulse trains is the rotary dial of the telephone, lending the technology another name, rotary dialing.
The pulse repetition rate was historically determined based on the response time needed for electromechanical switching systems to operate reliably. Most telephone systems used the nominal rate of ten pulses per second, but operator dialing within and between central offices often used pulse rates up to twenty per second.
Early automatic exchanges.
Automatic telephone exchange systems were developed in the late 19th and early 20th century. For identification, telephone subscribers were assigned a telephone number unique to each circuit. Various methods evolved to signal the desired destination telephone number for a telephone call directly dialed by the subscriber. An automatic switch-hook was designed by Hilborne Roosevelt.
The first commercial automatic telephone exchange, designed by Almon Brown Strowger, opened in La Porte, Indiana on 3 November 1892, and used two telegraph-type keys on the telephone, which had to be operated the correct number of times to control the vertical and horizontal relay magnets in the exchange. But the use of separate keys with separate conductors to the exchange was not practical. The most common signaling system became a system of using direct-current pulse trains generated in the telephone sets of subscribers by interrupting the single-pair wire loop of the telephone circuit.
Rotary dial.
Strowger also filed the first patent for a rotary dial in 1891. The first dials worked by direct, forward action. The pulses were sent as the user rotated the dial to the finger stop starting at a different position for each digit transmitted. Operating the dial error-free required smooth rotary motion of the finger wheel by the user, but was found as too unreliable. This mechanism was soon refined to include a recoil spring and a centrifugal governor to control the recoil speed. The user selected a digit to be dialed by inserting a finger into the corresponding hole and rotated the dial to the finger stop. When released from this position, the dial pulsing contacts were opened and closed repeatedly, thus interrupting the loop current in a pattern on the return to the home position. The exchange switch decoded the pattern for each digit thus transmitted by stepping relays or by accumulation in digit registers.
Pulse rate and coding.
When electromechanical switching system were still in use, the current pulses generated by the rotary dial on the local loop operated electrical relays in the switches at the central office. The mechanical nature of these relays and the loop capacitance, affecting pulse shape, generally limited the speed of operation, the pulsing rate, to ten pulses per second.
The specifications of the Bell System in the US required service personnel to adjust dials in customer stations to a precision of 9.5 to 10.5 pulses per second (pps), but the tolerance of the switching equipment was generally between 8 and 11 pps. The British (BPO, later Post Office Telecommunications) standard for Strowger exchanges was 10 impulses per second (allowable range 7 to 12) and a 66% break ratio (allowable range 63% to 72%)
In most countries one pulse is used for the digit 1, two pulses for 2, and so on, with ten pulses for the digit 0; this makes the code unary, excepting the digit 0. Exceptions to this are: Sweden (example dial), with one click for 0, two clicks for 1, and so on; and New Zealand with ten clicks for 0, nine clicks for 1, etc. Oslo, the capital city of Norway, used the New Zealand system, but the rest of the country did not. Systems that used this encoding of the 10 digits in a sequence of up to 10 pulses, are sometimes known as decadic dialing systems.
Some later switching systems used digit registers which doubled the allowable pulse rate to 20 pulses per second, and the inter-digital pause could be reduced as the switch selection did not have to be completed during the pause. These included some Crossbar systems, the later version (7A2) of the Rotary system, and the earlier 1970s stored program control exchanges.
In some telephones, the pulses may be heard in the receiver as clicking sounds. However, in general, such effects were undesirable and telephone designers suppressed them by mechanical means with off-normal switches on the dial, or greatly attenuated them by electrical means with a varistor connected across the receiver.
Switch-hook dialing.
As pulse dialing is achieved by interruption of the local loop, it was in principle possible to dial a telephone number by rapidly tapping, i.e. depressing, the switch hook the corresponding number of times for each digit at approximately ten taps per second. However, many telephone makers implemented a slow switch hook release to prevent rapid switching.
In the United Kingdom, it used to be possible to make calls from coin-box phones (payphones) by tapping the switch hook without depositing coins. A person caught tapping could be charged with 'abstracting electricity' from the General Post Office and several cases were prosecuted under this offence.
In popular culture, tapping was used in the film "Red Dragon" as a way for prisoner Hannibal Lecter to dial out on a phone with no dialing mechanism. This method was also used by the character 'Phantom Phreak' to call 'Acid Burn' when taken to prison in the film "Hackers".
Successors.
It was recognized as early as the 1940s that faster, more accurate dialing could be done with push buttons, but this was too unreliable in customer trials until transistors transformed the industry. In 1963, the Bell System introduced to the public its dual-tone multi-frequency (DTMF) technology under the name Touch-Tone, which was a trademark in the U.S. until 1984. The Touch-Tone system used push-button telephones. In the decades after 1963, pulse dialing was gradually phased out as the primary dialing method to the central office, but many systems still support rotary telephones today. Some keypad telephones have a switch for the selection of tone or pulse dialing.
Mobile telephones and most voice-over-IP systems use out-of-band signaling and do not send any digits until the entire number has been keyed by the user. Many VoIP systems are based on the Session Initiation Protocol (SIP), which uses a form of Uniform Resource Identifiers (URI) for addressing, instead of digits alone.

</doc>
<doc id="41026" url="https://en.wikipedia.org/wiki?curid=41026" title="Dielectric">
Dielectric

A dielectric material (dielectric for short) is an electrical insulator that can be polarized by an applied electric field. When a dielectric is placed in an electric field, electric charges do not flow through the material as they do in a conductor, but only slightly shift from their average equilibrium positions causing dielectric polarization. Because of dielectric polarization, positive charges are displaced toward the field and negative charges shift in the opposite direction. This creates an internal electric field that reduces the overall field within the dielectric itself. If a dielectric is composed of weakly bonded molecules, those molecules not only become polarized, but also reorient so that their symmetry axes align to the field.
The study of dielectric properties concerns storage and dissipation of electric and magnetic energy in materials. Dielectrics are important for explaining various phenomena in electronics, optics, and solid-state physics.
Terminology.
While the term "insulator" implies low electrical conduction, "dielectric" typically means materials with a high polarizability. The latter is expressed by a number called the relative permittivity (also known in older texts as dielectric constant). The term insulator is generally used to indicate electrical obstruction while the term dielectric is used to indicate the energy storing capacity of the material (by means of polarization). A common example of a dielectric is the electrically insulating material between the metallic plates of a capacitor. The polarization of the dielectric by the applied electric field increases the capacitor's surface charge for the given electric field strength.
The term "dielectric" was coined by William Whewell (from "dia-electric") in response to a request from Michael Faraday. A "perfect dielectric" is a material with zero electrical conductivity (cf. perfect conductor), thus exhibiting only a displacement current; therefore it stores and returns electrical energy as if it were an ideal capacitor.
Electric susceptibility.
The electric susceptibility "χe" of a dielectric material is a measure of how easily it polarizes in response to an electric field. This, in turn, determines the electric permittivity of the material and thus influences many other phenomena in that medium, from the capacitance of capacitors to the speed of light.
It is defined as the constant of proportionality (which may be a tensor) relating an electric field E to the induced dielectric polarization density P such that
where "ε"0 is the electric permittivity of free space.
The susceptibility of a medium is related to its relative permittivity "εr" by
So in the case of a vacuum,
The electric displacement D is related to the polarization density P by
Dispersion and causality.
In general, a material cannot polarize instantaneously in response to an applied field. The more general formulation as a function of time is
That is, the polarization is a convolution of the electric field at previous times with time-dependent susceptibility given by "χe"(Δ"t"). The upper limit of this integral can be extended to infinity as well if one defines for . An instantaneous response corresponds to Dirac delta function susceptibility .
It is more convenient in a linear system to take the Fourier transform and write this relationship as a function of frequency. Due to the convolution theorem, the integral becomes a simple product,
Note the simple frequency dependence of the susceptibility, or equivalently the permittivity. The shape of the susceptibility with respect to frequency characterizes the dispersion properties of the material.
Moreover, the fact that the polarization can only depend on the electric field at previous times (i.e., for , a consequence of causality, imposes Kramers–Kronig constraints on the real and imaginary parts of the susceptibility "χe"("ω").
Dielectric polarization.
Basic atomic model.
In the classical approach to the dielectric model, a material is made up of atoms. Each atom consists of a cloud of negative charge (electrons) bound to and surrounding a positive point charge at its center. In the presence of an electric field the charge cloud is distorted, as shown in the top right of the figure.
This can be reduced to a simple dipole using the superposition principle. A dipole is characterized by its dipole moment, a vector quantity shown in the figure as the blue arrow labeled "M". It is the relationship between the electric field and the dipole moment that gives rise to the behavior of the dielectric. (Note that the dipole moment points in the same direction as the electric field in the figure. This isn't always the case, and is a major simplification, but is true for many materials.)
When the electric field is removed the atom returns to its original state. The time required to do so is the so-called relaxation time; an exponential decay.
This is the essence of the model in physics. The behavior of the dielectric now depends on the situation. The more complicated the situation, the richer the model must be to accurately describe the behavior. Important questions are:
The relationship between the electric field E and the dipole moment M gives rise to the behavior of the dielectric, which, for a given material, can be characterized by the function F defined by the equation:
When both the type of electric field and the type of material have been defined, one then chooses the simplest function "F" that correctly predicts the phenomena of interest. Examples of phenomena that can be so modeled include:
Dipolar polarization.
Dipolar polarization is a polarization that is either inherent to polar molecules (orientation polarization), or can be induced in any molecule in which the asymmetric distortion of the nuclei is possible (distortion polarization). Orientation polarization results from a permanent dipole, e.g., that arising from the 104.45° angle between the asymmetric bonds between oxygen and hydrogen atoms in the water molecule, which retains polarization in the absence of an external electric field. The assembly of these dipoles forms a macroscopic polarization.
When an external electric field is applied, the distance between charges within each permanent dipole, which is related to chemical bonding, remains constant in orientation polarization; however, the direction of polarization itself rotates. This rotation occurs on a timescale that depends on the torque and surrounding local viscosity of the molecules. Because the rotation is not instantaneous, dipolar polarizations lose the response to electric fields at the highest frequencies. A molecule rotates about 1 radian per picosecond in a fluid, thus this loss occurs at about 1011 Hz (in the microwave region). The delay of the response to the change of the electric field causes friction and heat.
When an external electric field is applied at infrared frequencies or less, the molecules are bent and stretched by the field and the molecular dipole moment changes. The molecular vibration frequency is roughly the inverse of the time it takes for the molecules to bend, and this distortion polarization disappears above the infrared.
Ionic polarization.
Ionic polarization is polarization caused by relative displacements between positive and negative ions in ionic crystals (for example, NaCl).
If a crystal or molecule consists of atoms of more than one kind, the distribution of charges around an atom in the crystal or molecule leans to positive or negative. As a result, when lattice vibrations or molecular vibrations induce relative displacements of the atoms, the centers of positive and negative charges are also displaced. The locations of these centers are affected by the symmetry of the displacements. When the centers don't correspond, polarizations arise in molecules or crystals. This polarization is called ionic polarization.
Ionic polarization causes the ferroelectric effect as well as dipolar polarization. The ferroelectric transition, which is caused by the lining up of the orientations of permanent dipoles along a particular direction, is called an order-disorder phase transition. The transition caused by ionic polarizations in crystals is called a displacive phase transition.
Dielectric dispersion.
In physics, dielectric dispersion is the dependence of the permittivity of a dielectric material on the frequency of an applied electric field. Because there is a lag between changes in polarization and changes in the electric field, the permittivity of the dielectric is a complicated function of frequency of the electric field. Dielectric dispersion is very important for the applications of dielectric materials and for the analysis of polarization systems.
This is one instance of a general phenomenon known as material dispersion: a frequency-dependent response of a medium for wave propagation.
When the frequency becomes higher:
In the frequency region above ultraviolet, permittivity approaches the constant "ε"0 in every substance, where "ε"0 is the permittivity of the free space. Because permittivity indicates the strength of the relation between an electric field and polarization, if a polarization process loses its response, permittivity decreases.
Dielectric relaxation.
Dielectric relaxation is the momentary delay (or lag) in the dielectric constant of a material. This is usually caused by the delay in molecular polarization with respect to a changing electric field in a dielectric medium (e.g., inside capacitors or between two large conducting surfaces). Dielectric relaxation in changing electric fields could be considered analogous to hysteresis in changing magnetic fields (for inductors or transformers). Relaxation in general is a delay or lag in the response of a linear system, and therefore dielectric relaxation is measured relative to the expected linear steady state (equilibrium) dielectric values. The time lag between electrical field and polarization implies an irreversible degradation of Gibbs free energy.
In physics, dielectric relaxation refers to the relaxation response of a dielectric medium to an external, oscillating electric field. This relaxation is often described in terms of permittivity as a function of frequency, which can, for ideal systems, be described by the Debye equation. On the other hand, the distortion related to ionic and electronic polarization shows behavior of the resonance or oscillator type. The character of the distortion process depends on the structure, composition, and surroundings of the sample.
Debye relaxation.
Debye relaxation is the dielectric relaxation response of an ideal, noninteracting population of dipoles to an alternating external electric field. It is usually expressed in the complex permittivity "ε" of a medium as a function of the field's frequency "ω":
where "ε∞" is the permittivity at the high frequency limit, where "εs" is the static, low frequency permittivity, and "τ" is the characteristic relaxation time of the medium.
This relaxation model was introduced by and named after the physicist Peter Debye (1913).
Variants of the Debye equation.
This equation is used when the dielectric loss peak shows symmetric broadening
This equation is used when the dielectric loss peak shows asymmetric broadening
This equation considers both symmetric and asymmetric broadening 
Paraelectricity.
Paraelectricity is the ability of many materials (specifically ceramics) to become polarized under an applied electric field. Unlike ferroelectricity, this can happen even if there is no permanent electric dipole that exists in the material, and removal of the fields results in the polarization in the material returning to zero. The mechanisms that cause paraelectric behaviour are the distortion of individual ions (displacement of the electron cloud from the nucleus) and polarization of molecules or combinations of ions or defects.
Paraelectricity can occur in crystal phases where electric dipoles are unaligned and thus have the potential to align in an external electric field and weaken it.
An example of a paraelectric material of high dielectric constant is strontium titanate.
The LiNbO3 crystal is ferroelectric below 1430 K, and above this temperature it transforms into a disordered paraelectric phase. Similarly, other perovskites also exhibit paraelectricity at high temperatures.
Paraelectricity has been explored as a possible refrigeration mechanism; polarizing a paraelectric by applying an electric field under adiabatic process conditions raises the temperature, while removing the field lowers the temperature. A heat pump that operates by polarizing the paraelectric, allowing it to return to ambient temperature (by dissipating the extra heat), bringing it into contact with the object to be cooled, and finally depolarizing it, would result in refrigeration.
Tunability.
"Tunable dielectrics" are insulators whose ability to store electrical charge changes when a voltage is applied.
Generally, strontium titanate () is used for devices operating at low temperatures, while barium strontium titanate () substitutes for room temperature devices. Other potential materials include microwave dielectrics and carbon nanotube (CNT) composites.
In 2013 multi-sheet layers of strontium titanate interleaved with single layers of strontium oxide produced a dielectric capable of operating at up to 125 GHz. The material was created via molecular beam epitaxy. The two have mismatched crystal spacing that produces strain within the strontium titanate layer that makes it less stable and tunable.
Systems such as have a paraelectric–ferroelectric transition just below ambient temperature, providing high tunability. Such films suffer significant losses arising from defects.
Applications.
Capacitors.
Commercially manufactured capacitors typically use a solid dielectric material with high permittivity as the intervening medium between the stored positive and negative charges. This material is often referred to in technical contexts as the "capacitor dielectric".
The most obvious advantage to using such a dielectric material is that it prevents the conducting plates, on which the charges are stored, from coming into direct electrical contact. More significantly, however, a high permittivity allows a greater stored charge at a given voltage. This can be seen by treating the case of a linear dielectric with permittivity "ε" and thickness "d" between two conducting plates with uniform charge density "σε". In this case the charge density is given by
and the capacitance per unit area by
From this, it can easily be seen that a larger "ε" leads to greater charge stored and thus greater capacitance.
Dielectric materials used for capacitors are also chosen such that they are resistant to ionization. This allows the capacitor to operate at higher voltages before the insulating dielectric ionizes and begins to allow undesirable current.
Dielectric resonator.
A "dielectric resonator oscillator" (DRO) is an electronic component that exhibits resonance of the polarization response for a narrow range of frequencies, generally in the microwave band. It consists of a "puck" of ceramic that has a large dielectric constant and a low dissipation factor. Such resonators are often used to provide a frequency reference in an oscillator circuit. An unshielded dielectric resonator can be used as a Dielectric Resonator Antenna (DRA).
Some practical dielectrics.
Dielectric materials can be solids, liquids, or gases. In addition, a high vacuum can also be a useful, nearly lossless dielectric even though its relative dielectric constant is only unity.
Solid dielectrics are perhaps the most commonly used dielectrics in electrical engineering, and many solids are very good insulators. Some examples include porcelain, glass, and most plastics. Air, nitrogen and sulfur hexafluoride are the three most commonly used gaseous dielectrics.

</doc>
<doc id="41027" url="https://en.wikipedia.org/wiki?curid=41027" title="Dielectric strength">
Dielectric strength

In physics, the term dielectric strength has the following meanings:
The theoretical dielectric strength of a material is an intrinsic property of the bulk material and is independent of the configuration of the material or the electrodes with which the field is applied. This "intrinsic dielectric strength" corresponds to what would be measured using pure materials under ideal laboratory conditions. At breakdown, the electric field frees bound electrons. If the applied electric field is sufficiently high, free electrons from background radiation may become accelerated to velocities that can liberate additional electrons during collisions with neutral atoms or molecules in a process called avalanche breakdown. Breakdown occurs quite abruptly (typically in nanoseconds), resulting in the formation of an electrically conductive path and a disruptive discharge through the material. For solid materials, a breakdown event severely degrades, or even destroys, its insulating capability.
Factors affecting apparent dielectric strength
Breakdown field strength.
The field strength at which breakdown occurs depends on the respective geometries of the dielectric (insulator) and the electrodes with which the electric field is applied, as well as the rate of increase at which the electric field is applied. Because dielectric materials usually contain minute defects, the practical dielectric strength will be a fraction of the intrinsic dielectric strength of an ideal, defect-free, material. Dielectric films tend to exhibit greater dielectric strength than thicker samples of the same material. For instance, the dielectric strength of silicon dioxide films of a few hundred nm to a few μm thick is approximately 0.5GV/m. However very thin layers (below, say, ) become partially conductive because of electron tunneling. Multiple layers of thin dielectric films are used where maximum practical dielectric strength is required, such as high voltage capacitors and pulse transformers. Since the dielectric strength of gases varies depending on the shape and configuration of the electrodes, it is usually measured as a fraction of the dielectric strength of Nitrogen gas.
Dielectric strength (in MV/m, or 106 Volt/meter) of various common materials:
Units.
In SI, the unit of dielectric strength is volts per meter (V/m). It is also common to see related units such as volts per centimeter (V/cm), megavolts per meter (MV/m), and so on.
In United States customary units, dielectric strength is often specified in volts per mil (a mil is 1/1000 inch). The conversion is:

</doc>
<doc id="41030" url="https://en.wikipedia.org/wiki?curid=41030" title="Differential Manchester encoding">
Differential Manchester encoding

Differential Manchester encoding Scheme is a line code in which data and clock signals are combined to form a single 2-level self-synchronizing data stream. It is a differential encoding, using the presence or absence of transitions to indicate logical value. It is not necessary to know the polarity of the sent signal since the information is not kept in the actual values of the voltage but in their change: in other words it does not matter whether a logical 1 or 0 is received, but only whether the polarity is the same or different from the previous value; this makes synchronization easier.
Differential Manchester encoding is not to be confused with biphase mark code (BMC) or FM1, biphase space coding, and biphase level coding since these four lines codes are each unique.
Differential Manchester encoding has the following advantages over some other line codes:
These positive features are achieved at the expense of doubling clock frequency - the symbol rate is twice the bitrate of the original signal.
Each bit period is divided into two half-periods: clock and data.
The clock half-period always begins with a transition from low to high or from high to low.
The data half-period makes a transition for one value and no transition for the other value.
One version of the code makes a transition for 0 and no transition for 1 in the data half-period; the other makes a transition for 1 and no transition for 0.
Thus, if a "1" is represented by one transition, then a "0" is represented by two transitions and vice versa, making Differential Manchester a form of frequency shift keying.
Either code can be interpreted with the clock half-period either before or after the data half-period.
Biphase mark coding transitions on every positive edge of the clock signal (when the clock goes from 0 to 1) and also transitions on the negative edge of the clock signal when the data is a 1. 
Differential Manchester is specified in the IEEE 802.5 standard for token ring LANs, and is used for many other applications, including magnetic and optical storage.
Biphase Mark Code (BMC) is used as the encoding method in AES3 and S/PDIF. Many magnetic stripe cards also use BMC encoding, often called F2F (frequency/double frequency) or Aiken Biphase. That standard is described in ISO/IEC 7811. SMPTE time code also uses BMC.
BMC is also the original "frequency modulation" used on single-density floppy disks, before being replaced by "double-density" modified frequency modulation.

</doc>
<doc id="41031" url="https://en.wikipedia.org/wiki?curid=41031" title="Diffraction grating">
Diffraction grating

In optics, a diffraction grating is an optical component with a periodic structure, which splits and diffracts light into several beams travelling in different directions. The emerging coloration is a form of structural coloration. The directions of these beams depend on the spacing of the grating and the wavelength of the light so that the grating acts as the dispersive element. Because of this, gratings are commonly used in monochromators and spectrometers.
For practical applications, gratings generally have ridges or "rulings" on their surface rather than dark lines. Such gratings can be either transmissive or reflective. Gratings which modulate the phase rather than the amplitude of the incident light are also produced, frequently using holography.
The principles of diffraction gratings were discovered by James Gregory, about a year after Newton's prism experiments, initially with items such as bird feathers. The first man-made diffraction grating was made around 1785 by Philadelphia inventor David Rittenhouse, who strung hairs between two finely threaded screws. This was similar to notable German physicist Joseph von Fraunhofer's wire diffraction grating in 1821.
Diffraction can create "rainbow" colors when illuminated by a wide spectrum (e.g., continuous) light source. The sparkling effects from the closely spaced narrow tracks on optical storage disks such as CD's or DVDs are an example, while the similar rainbow effects caused by thin layers of oil (or gasoline, etc.) on water are not caused by a grating, but rather by interference effects in reflections from the closely spaced transmissive layers (see Examples, below). A grating has parallel lines, while a CD has a spiral of finely-spaced data tracks. Diffraction colors also appear when one looks at a bright point source through a translucent fine-pitch umbrella-fabric covering. Decorative patterned plastic films based on reflective grating patches are very inexpensive, and are commonplace.
Theory of operation.
According to the Huygens–Fresnel principle, each point on the wavefront of a propagating wave can be considered to act as a point source, and the wavefront at any subsequent point can be found by adding together the contributions from each of these individual point sources.
Gratings may be of the 'reflective' or 'transmissive' type, analogous to a mirror or lens respectively. A grating has a 'zero-order mode' (where "m" = 0), in which there is no diffraction and a ray of light behaves according to the laws of reflection and refraction the same as with a mirror or lens respectively.
An idealised grating is considered here which is made up of a set of slits of spacing "d", that must be wider than the wavelength of interest to cause diffraction. Assuming a plane wave of monochromatic light of wavelength "λ" with normal incidence (perpendicular to the grating), each slit in the grating acts as a quasi point-source from which light propagates in all directions (although this is typically limited to a hemisphere). After light interacts with the grating, the diffracted light is composed of the sum of interfering wave components emanating from each slit in the grating. At any given point in space through which diffracted light may pass, the path length to each slit in the grating will vary. Since the path length varies, generally, so will the phases of the waves at that point from each of the slits, and thus will add or subtract from one another to create peaks and valleys, through the phenomenon of additive and destructive interference. When the path difference between the light from adjacent slits is equal to half the wavelength, , the waves will all be out of phase, and thus will cancel each other to create points of minimum intensity. Similarly, when the path difference is "λ", the phases will add together and maxima will occur. The maxima occur at angles "θ"m, which satisfy the relationship = | "m" |, where "θ"m is the angle between the diffracted ray and the grating's normal vector, and "d" is the distance from the center of one slit to the center of the adjacent slit, and "m" is an integer representing the propagation-mode of interest.
Thus, when light is normally incident on the grating, the diffracted light will have maxima at angles "θ"m given by:
It is straightforward to show that if a plane wave is incident at any arbitrary angle "θ"i, the grating equation becomes:
When solved for the diffracted angle maxima, the equation is:
Please note that these equations assume that both sides of the grating are in contact with the same medium (e.g. air).
The light that corresponds to direct transmission (or specular reflection in the case of a reflection grating) is called the zero order, and is denoted "m" = 0. The other maxima occur at angles which are represented by non-zero integers "m". Note that "m" can be positive or negative, resulting in diffracted orders on both sides of the zero order beam.
This derivation of the grating equation is based on an idealised grating. However, the relationship between the angles of the diffracted beams, the grating spacing and the wavelength of the light apply to any regular structure of the same spacing, because the phase relationship between light scattered from adjacent elements of the grating remains the same. The detailed distribution of the diffracted light depends on the detailed structure of the grating elements as well as on the number of elements in the grating, but it will always give maxima in the directions given by the grating equation.
Gratings can be made in which various properties of the incident light are modulated in a periodic pattern; these include
The grating equation applies in all these cases.
Quantum electrodynamics.
Quantum electrodynamics (QED) offers another derivation of the properties of a diffraction grating in terms of photons as particles (at some level). QED can be described intuitively with the path integral formulation of quantum mechanics. As such it can model photons as potentially following all paths from a source to a final point, each path with a certain probability amplitude. These probability amplitudes can be represented as a complex number or equivalent vector—or, as Richard Feynman simply calls them in his book on QED, "arrows".
For the probability that a certain event will happen, one sums the probability amplitudes for all of the possible ways in which the event can occur, and then takes the square of the length of the result. The probability amplitude for a photon from a monochromatic source to arrive at a certain final point at a given time, in this case, can be modeled as an arrow that spins rapidly until it is evaluated when the photon reaches its final point. For example, for the probability that a photon will reflect off of a mirror and be observed at a given point a given amount of time later, one sets the photon's probability amplitude spinning as it leaves the source, follows it to the mirror, and then to its final point, even for paths that do not involve bouncing off of the mirror at equal angles. One can then evaluate the probability amplitude at the photon's final point; next, one can integrate over all of these arrows (see vector sum), and square the length of the result to obtain the probability that this photon will reflect off of the mirror in the pertinent fashion. The times these paths take are what determine the angle of the probability amplitude arrow, as they can be said to "spin" at a constant rate (which is related to the frequency of the photon).
The times of the paths near the classical reflection site of the mirror will be nearly the same, so as a result the probability amplitudes will point in nearly the same direction—thus, they will have a sizable sum. Examining the paths towards the edges of the mirror reveals that the times of nearby paths are quite different from each other, and thus we wind up summing vectors that cancel out quickly. So, there is a higher probability that light will follow a near-classical reflection path than a path further out. However, a diffraction grating can be made out of this mirror, by scraping away areas near the edge of the mirror that usually cancel nearby amplitudes out—but now, since the photons would not reflect from the scraped-off portions, the probability amplitudes which would all wind up pointing, for instance, at forty-five degrees can have a sizable sum. Thus, this would let light of the right frequency to make this happen sum to a larger probability amplitude, and as such possess a larger probability of reaching the appropriate final point.
This particular description involves many simplifications: a point source, a "surface" that light can reflect off of (thus neglecting the interactions with electrons) and so forth. The biggest simplification is perhaps in the fact that the "spinning" of the probability amplitude arrows is actually more accurately explained as a "spinning" of the source, as the probability amplitudes of photons do not "spin" while they are in transit. We obtain the same variation in probability amplitudes by allowing the time at which the photon left the source to be indeterminate, and the time of the path now tells us when the photon would have left the source, and thus what the angle of its "arrow" would be. However, this model and approximation is a reasonable one to illustrate a diffraction grating conceptually. Light of a different frequency may also reflect off of the same diffraction grating, but with a different final point.
Gratings as dispersive elements.
The wavelength dependence in the grating equation shows that the grating separates an incident polychromatic beam into its constituent wavelength components, i.e., it is dispersive. Each wavelength of input beam spectrum is sent into a different direction, producing a rainbow of colors under white light illumination. This is visually similar to the operation of a prism, although the mechanism is very different.
The diffracted beams corresponding to consecutive orders may overlap, depending on the spectral content of the incident beam and the grating density. The higher the spectral order, the greater the overlap into the next order.
The grating equation shows that the angles of the diffracted orders only depend on the grooves' period, and not on their shape. By controlling the cross-sectional profile of the grooves, it is possible to concentrate most of the diffracted energy in a particular order for a given wavelength. A triangular profile is commonly used. This technique is called "blazing." The incident angle and wavelength for which the diffraction is most efficient are often called "blazing angle" and "blazing wavelength." The efficiency of a grating may also depend on the polarization of the incident light. Gratings are usually designated by their "groove density", the number of grooves per unit length, usually expressed in grooves per millimeter (g/mm), also equal to the inverse of the groove period. The groove period must be on the order of the wavelength of interest; the spectral range covered by a grating is dependent on groove spacing and is the same for ruled and holographic gratings with the same grating constant. The maximum wavelength that a grating can diffract is equal to twice the grating period, in which case the incident and diffracted light will be at ninety degrees to the grating normal. To obtain frequency dispersion over a wider frequency one must use a prism. In the optical regime, in which the use of gratings is most common, this corresponds to wavelengths between 100 nm and 10 µm. In that case, the groove density can vary from a few tens of grooves per millimeter, as in "echelle gratings", to a few thousands of grooves per millimeter.
When groove spacing is less than half the wavelength of light, the only present order is the "m" = 0 order. Gratings with such small periodicity are called subwavelength gratings and exhibit special optical properties. Made on an isotropic material the subwavelength gratings give rise to form birefringence, in which the material behaves as if it were birefringent.
Fabrication.
Originally, high-resolution gratings were ruled using high-quality "ruling engines" whose construction was a large undertaking. Henry Joseph Grayson designed a machine to make diffraction gratings, succeeding with one of 120,000 lines to the inch (approx. 4,724 lines per mm) in 1899. Later, photolithographic techniques allowed gratings to be created from a holographic interference pattern. Holographic gratings have sinusoidal grooves and may not be as efficient as ruled gratings, but are often preferred in monochromators because they lead to much less stray light. A copying technique allows high quality replicas to be made from master gratings of either type, thereby lowering fabrication costs.
Another method for manufacturing diffraction gratings uses a photosensitive gel sandwiched between two substrates. A holographic interference pattern exposes the gel which is later developed. These gratings, called "volume phase holography diffraction gratings" (or VPH diffraction gratings) have no physical grooves, but instead a periodic modulation of the refractive index within the gel. This removes much of the surface scattering effects typically seen in other types of gratings. These gratings also tend to have higher efficiencies, and allow for the inclusion of complicated patterns into a single grating. In older versions of such gratings, environmental susceptibility was a trade-off, as the gel had to be contained at low temperature and humidity. Typically, the photosensitive substances are sealed between two substrates which make them resistant to humidity, thermal and mechanical stresses. VPH diffraction gratings are not destroyed by accidental touches and are more scratch resistant than typical relief gratings.
Semiconductor technology today is also utilized to etch holographically patterned gratings into robust materials such as fused silica. In this way, low stray-light holography is combined with the high efficiency of deep, etched transmission gratings, and can be incorporated into high volume, low cost semiconductor manufacturing technology.
A new technology for grating insertion into integrated photonic lightwave circuits is digital planar holography (DPH). DPH gratings are generated in computer and fabricated on one or several interfaces of an optical waveguide planar with standard micro-lithography or nano-imprinting methods, compatible with mass-production. Light propagates inside the DPH gratings, confined by the refractive index gradient, which provides longer interaction path and greater flexibility in light steering.
Examples.
Diffraction gratings are often used in monochromators, spectrometers, lasers, wavelength division multiplexing devices, optical pulse compressing devices, and many other optical instruments.
Ordinary pressed CD and DVD media are every-day examples of diffraction gratings and can be used to demonstrate the effect by reflecting sunlight off them onto a white wall. This is a side effect of their manufacture, as one surface of a CD has many small pits in the plastic, arranged in a spiral; that surface has a thin layer of metal applied to make the pits more visible. The structure of a DVD is optically similar, although it may have more than one pitted surface, and all pitted surfaces are inside the disc.
In a standard pressed vinyl record when viewed from a low angle perpendicular to the grooves, a similar but less defined effect to that in a CD/DVD is seen. This is due to viewing angle (less than the critical angle of reflection of the black vinyl) and the path of the light being reflected due to this being changed by the grooves, leaving a rainbow relief pattern behind.
Diffraction gratings are also used to distribute evenly the frontlight of e-readers such as the Nook Simple Touch with GlowLight.
Natural gratings.
Striated muscle is the most commonly found natural diffraction grating and, this has helped physiologists in determining the structure of such muscle. Aside from this, the chemical structure of crystals can be thought of as diffraction gratings for types of electromagnetic radiation other than visible light, this is the basis for techniques such as X-ray crystallography.
Most commonly confused with diffraction gratings are the iridescent colors of peacock feathers, mother-of-pearl, and butterfly wings. Iridescence in birds, fish and insects is often caused by thin-film interference rather than a diffraction grating. Diffraction will produce the entire spectrum of colors as the viewing angle changes, whereas thin-film interference usually produces a much narrower range. The surfaces of flowers can also create a diffraction, but the cell structures in plants are usually too irregular to produce the fine slit geometry necessary for a diffraction grating. The iridescence signal of flowers is thus only appreciable very locally and hence not visible to man and flower visiting insects. However, natural gratings do occur in some invertebrate marine animals, like the antennae of seed shrimp, and have even been discovered in Burgess Shale fossils.
Diffraction grating effects are sometimes seen in meteorology. Diffraction coronas are colorful rings surrounding a source of light, such as the sun. These are usually observed much closer to the light source than halos, and are caused by very fine particles, like water droplets, ice crystals, or smoke particles in a hazy sky. When the particles are all nearly the same size they diffract the incoming light at very specific angles. The exact angle depends on the size of the particles. Diffraction coronas are commonly observed around light sources, like candle flames or street lights, in the fog. Cloud iridescence is caused by diffraction, occurring along coronal rings when the particles in the clouds are all uniform in size.

</doc>
<doc id="41033" url="https://en.wikipedia.org/wiki?curid=41033" title="Digital filter">
Digital filter

In signal processing, a digital filter is a system that performs mathematical operations on a sampled, discrete-time signal to reduce or enhance certain aspects of that signal. This is in contrast to the other major type of electronic filter, the analog filter, which is an electronic circuit operating on continuous-time analog signals.
A digital filter system usually consists of an analog-to-digital converter to sample the input signal, followed by a microprocessor and some peripheral components such as memory to store data and filter coefficients etc. Finally a digital-to-analog converter to complete the output stage. Program Instructions (software) running on the microprocessor implement the digital filter by performing the necessary mathematical operations on the numbers received from the ADC. In some high performance applications, an FPGA or ASIC is used instead of a general purpose microprocessor, or a specialized DSP with specific paralleled architecture for expediting operations such as filtering.
Digital filters may be more expensive than an equivalent analog filter due to their increased complexity, but they make practical many designs that are impractical or impossible as analog filters. When used in the context of real-time analog systems, digital filters sometimes have problematic latency (the difference in time between the input and the response) due to the associated analog-to-digital and digital-to-analog conversions and anti-aliasing filters, or due to other delays in their implementation.
Digital filters are commonplace and an essential element of everyday electronics such as radios, cellphones, and AV receivers.
Characterization.
A digital filter is characterized by its transfer function, or equivalently, its difference equation. Mathematical analysis of the transfer function can describe how it will respond to any input. As such, designing a filter consists of developing specifications appropriate to the problem (for example, a second-order low pass filter with a specific cut-off frequency), and then producing a transfer function which meets the specifications.
The transfer function for a linear, time-invariant, digital filter can be expressed as a transfer function in the "Z"-domain; if it is causal, then it has the form:
where the order of the filter is the greater of "N" or "M".
See "Z"-transform's LCCD equation for further discussion of this transfer function.
This is the form for a recursive filter with both the inputs (Numerator) and outputs (Denominator), which typically leads to an IIR infinite impulse response behaviour, but if the denominator is made equal to unity i.e. no feedback, then this becomes an FIR or finite impulse response filter.
Analysis techniques.
A variety of mathematical techniques may be employed to analyze the behaviour of a given digital filter. Many of these analysis techniques may also be employed in designs, and often form the basis of a filter specification.
Typically, one characterizes filters by calculating how they will respond to a simple input such as an impulse. One can then extend this information to compute the filter's response to more complex signals.
Impulse response.
The impulse response, often denoted formula_2 or formula_3, is a measurement of how a filter will respond to the Kronecker delta function. For example, given a difference equation, one would set formula_4 and formula_5 for formula_6 and evaluate. The impulse response is a characterization of the filter's behaviour. Digital filters are typically considered in two categories: infinite impulse response (IIR) and finite impulse response (FIR).
In the case of linear time-invariant FIR filters, the impulse response is exactly equal to the sequence of filter coefficients:
IIR filters on the other hand are recursive, with the output depending on both current and previous inputs as well as previous outputs. The general form of an IIR filter is thus:
Plotting the impulse response will reveal how a filter will respond to a sudden, momentary disturbance.
Difference equation.
In discrete-time systems, the digital filter is often implemented by converting the transfer function to a linear constant-coefficient difference equation (LCCD) via the Z-transform. The discrete frequency-domain transfer function is written as the ratio of two polynomials. For example:
This is expanded:
and to make the corresponding filter causal, the numerator and denominator are divided by the highest order of formula_11:
The coefficients of the denominator, formula_13, are the 'feed-backward' coefficients and the coefficients of the numerator are the 'feed-forward' coefficients, formula_14. The resultant linear difference equation is:
or, for the example above:
rearranging terms:
then by taking the inverse "z"-transform:
and finally, by solving for formula_19:
This equation shows how to compute the next output sample, formula_21, the present input, formula_22. Applying the filter to an input in this form is equivalent to a Direct Form I or II realization, depending on the exact order of evaluation.
Filter design.
The design of digital filters is a deceptively complex topic. Although filters are easily understood and calculated, the practical challenges of their design and implementation are significant and are the subject of much advanced research.
There are two categories of digital filter: the recursive filter and the nonrecursive filter. These are often referred to as infinite impulse response (IIR) filters and finite impulse response (FIR) filters, respectively.
Filter realization.
After a filter is designed, it must be "realized" by developing a signal flow diagram that describes the filter in terms of operations on sample sequences.
A given transfer function may be realized in many ways. Consider how a simple expression such as formula_23 could be evaluated – one could also compute the equivalent formula_24. In the same way, all realizations may be seen as "factorizations" of the same transfer function, but different realizations will have different numerical properties. Specifically, some realizations are more efficient in terms of the number of operations or storage elements required for their implementation, and others provide advantages such as improved numerical stability and reduced round-off error. Some structures are better for fixed-point arithmetic and others may be better for floating-point arithmetic.
Direct Form I.
A straightforward approach for IIR filter realization is Direct Form I, where the difference equation is evaluated directly. This form is practical for small filters, but may be inefficient and impractical (numerically unstable) for complex designs. In general, this form requires 2N delay elements (for both input and output signals) for a filter of order N.
Direct Form II.
The alternate Direct Form II only needs "N" delay units, where "N" is the order of the filter – potentially half as much as Direct Form I. This structure is obtained by reversing the order of the numerator and denominator sections of Direct Form I, since they are in fact two linear systems, and the commutativity property applies. Then, one will notice that there are two columns of delays (formula_25) that tap off the center net, and these can be combined since they are redundant, yielding the implementation as shown below.
The disadvantage is that Direct Form II increases the possibility of arithmetic overflow for filters of high Q or resonance. It has been shown that as Q increases, the round-off noise of both direct form topologies increases without bounds. This is because, conceptually, the signal is first passed through an all-pole filter (which normally boosts gain at the resonant frequencies) before the result of that is saturated, then passed through an all-zero filter (which often attenuates much of what the all-pole half amplifies).
Cascaded second-order sections.
A common strategy is to realize a higher-order (greater than 2) digital filter as a cascaded series of second-order "biquadratric" (or "biquad") sections (see digital biquad filter). The advantage of this strategy is that the coefficient range is limited. Cascading direct form II sections results in N delay elements for filters of order N. Cascading direct form I sections results in N+2 delay elements since the delay elements of the input of any section (except the first section) are redundant with the delay elements of the output of the preceding section.
Other forms.
Other forms include:
Comparison of analog and digital filters.
Digital filters are not subject to the component non-linearities that greatly complicate the design of analog filters. Analog filters consist of imperfect electronic components, whose values are specified to a limit tolerance (e.g. resistor values often have a tolerance of ±5%) and which may also change with temperature and drift with time. As the order of an analog filter increases, and thus its component count, the effect of variable component errors is greatly magnified. In digital filters, the coefficient values are stored in computer memory, making them far more stable and predictable.
Because the coefficients of digital filters are definite, they can be used to achieve much more complex and selective designs – specifically with digital filters, one can achieve a lower passband ripple, faster transition, and higher stopband attenuation than is practical with analog filters. Even if the design could be achieved using analog filters, the engineering cost of designing an equivalent digital filter would likely be much lower. Furthermore, one can readily modify the coefficients of a digital filter to make an adaptive filter or a user-controllable parametric filter. While these techniques are possible in an analog filter, they are again considerably more difficult.
Digital filters can be used in the design of finite impulse response filters. Analog filters do not have the same capability, because finite impulse response filters require delay elements.
Digital filters rely less on analog circuitry, potentially allowing for a better signal-to-noise ratio. A digital filter will introduce noise to a signal during analog low pass filtering, analog to digital conversion, digital to analog conversion and may introduce digital noise due to quantization. With analog filters, every component is a source of thermal noise (such as Johnson noise), so as the filter complexity grows, so does the noise.
However, digital filters do introduce a higher fundamental latency to the system. In an analog filter, latency is often negligible; strictly speaking it is the time for an electrical signal to propagate through the filter circuit. In digital systems, latency is introduced by delay elements in the digital signal path, and by analog-to-digital and digital-to-analog converters that enable the system to process analog signals.
In very simple cases, it is more cost effective to use an analog filter. Introducing a digital filter requires considerable overhead circuitry, as previously discussed, including two low pass analog filters.
Another argument for analog filters is low power consumption. Analog filters require substantially less power and are therefore the only solution when power requirements are tight.
When making an electrical circuit on a PCB it is generally easier to use a digital solution, because the processing units are highly optimized over the years. Making the same circuit with analog components would take up a lot more space when using discrete components. Two alternatives are FPAA's and ASIC's, but they are expensive for low quantities.
Types of digital filters.
Many digital filters are based on the fast Fourier transform, a mathematical algorithm that quickly extracts the frequency spectrum of a signal, allowing the spectrum to be manipulated (such as to create band-pass filters) before converting the modified spectrum back into a time-series signal.
Another form of a digital filter is that of a state-space model.
A well used state-space filter is the Kalman filter published by Rudolf Kalman in 1960.
Traditional linear filters are usually based on attenuation. Alternatively nonlinear filters can be designed, including energy transfer filters which allow the user to move energy in a designed way. So that unwanted noise or effects can be moved to new frequency bands either lower or higher in frequency, spread over a range of frequencies, split, or focused. Energy transfer filters complement traditional filter designs and introduce many more degrees of freedom in filter design. Digital energy transfer filters are relatively easy to design and to implement and exploit nonlinear dynamics.

</doc>
<doc id="41035" url="https://en.wikipedia.org/wiki?curid=41035" title="Digital milliwatt">
Digital milliwatt

In digital telephony, the digital milliwatt is a standard test signal that serves as a reference for analog signal levels in the telecommunications network.
When decoding the digital milliwatt, a PCM decoder produces a sinusoidal signal with a frequency of 1000 Hz with one milliwatt in power.
The digital milliwatt signal is encoded by eight 8-bit words corresponding to one pulse-code modulated cycle of the signal. it is typically stored in read-only memory (ROM) in the telecommunication equipment.
The digital milliwatt signal is generated in instruments in place of separate test equipment. It has the advantage of being tied in frequency and amplitude to the relatively stable digital clock signal and power (voltage) supply, respectively, that are used by the digital channel bank. 

</doc>
<doc id="41036" url="https://en.wikipedia.org/wiki?curid=41036" title="Digital multiplex hierarchy">
Digital multiplex hierarchy

In telecommunications, a digital multiplex hierarchy is a hierarchy consisting of an ordered repetition of tandem digital multiplexers that produce signals of successively higher data rates at each level of the hierarchy. 
Digital multiplexing hierarchies may be implemented in many different configurations depending on; (a) the number of channels desired, (b) the signaling system to be used, and (c) the bit rate allowed by the communications media. 
Some currently available digital multiplexers have been designated as Dl-, DS-, or M-series, all of which operate at T-carrier rates. 
In the design of digital multiplex hierarchies, care must be exercised to ensure interoperability of the multiplexers used in the hierarchy.

</doc>
<doc id="41037" url="https://en.wikipedia.org/wiki?curid=41037" title="Digital Signal 0">
Digital Signal 0

Digital Signal 0 (DS0) is a basic digital signaling rate of 64 kilobits per second (kbit/s), corresponding to the capacity of one analog voice-frequency-equivalent channel. The DS0 rate, and its equivalents E0 and T0, form the basis for the digital multiplex transmission hierarchy in telecommunications systems used in North America, Europe, Japan, and the rest of the world, for both the early plesiochronous systems such as T-carrier and for modern synchronous systems such as SDH/SONET.
The DS0 rate was introduced to carry a single digitized voice call. For a typical phone call, the audio sound is digitized at an 8 kHz sample rate, or 8000 samples per second, using 8-bit pulse-code modulation for each of the samples. This results in a data rate of 64 kbit/s.
Because of its fundamental role in carrying a single phone call, the DS0 rate forms the basis for the digital multiplex transmission hierarchy in telecommunications systems used in North America. To limit the number of wires required between two involved in exchanging voice calls, a system was built in which multiple DS0s are multiplexed together on higher capacity circuits. In this system, twenty-four (24) DS0s are multiplexed into a DS1 signal. Twenty-eight (28) DS1s are multiplexed into a DS3. When carried over copper wire, this is the well-known T-carrier system, with T1 and T3 corresponding to DS1 and DS3, respectively. 
Besides its use for voice communications, the DS0 rate may support twenty 2.4 kbit/s channels, ten 4.8 kbit/s channels, five 9.67 kbit/s channels, one 56 kbit/s channel, or one 64 kbit/s clear channel.
E0 (standardized as ITU G.703) is the European equivalent of the North American DS0 for carrying . However, there are some subtle differences in implementation. Voice signals are encoded for carriage over E0 according to ITU G.711. Note that when a T-carrier system is used as in North America, robbed bit signaling can mean that a DS0 channel carried over that system is not an error-free bit-stream. The out-of-band signaling used in the European E-carrier system avoids this.

</doc>
<doc id="41038" url="https://en.wikipedia.org/wiki?curid=41038" title="Digital subscriber line">
Digital subscriber line

Digital subscriber line (DSL; originally digital subscriber loop) is a family of technologies that are used to transmit digital data over telephone lines. In telecommunications marketing, the term DSL is widely understood to mean asymmetric digital subscriber line (ADSL), the most commonly installed DSL technology, for Internet access. DSL service can be delivered simultaneously with wired telephone service on the same telephone line. This is possible because DSL uses higher frequency bands for data. On the customer premises, a DSL filter on each non-DSL outlet blocks any high-frequency interference to enable simultaneous use of the voice and DSL services.
The bit rate of consumer DSL services typically ranges from 256 kbit/s to over 100 Mbit/s in the direction to the customer (downstream), depending on DSL technology, line conditions, and service-level implementation. Bit rates of 1 Gbit/s have been reached in trials, but most homes are likely to be limited to 500-800 Mbit/s. In ADSL, the data throughput in the upstream direction (the direction to the service provider) is lower, hence the designation of "asymmetric" service. In symmetric digital subscriber line (SDSL) services, the downstream and upstream data rates are equal. Researchers at Bell Labs have reached speeds of 10 Gbit/s, while delivering 1 Gbit/s symmetrical broadband access services using traditional copper telephone lines. These higher speeds are lab results, however. A 2012 survey found that "DSL continues to be the dominant technology for broadband access" with 364.1 million subscribers worldwide.
History.
For a long time it was thought that it was not possible to operate a conventional phone-line beyond low-speed limits (typically under 9600 bit/s). In the 1950s, ordinary twisted-pair telephone-cable often carried four megahertz (MHz) television signals between studios, suggesting that such lines would allow transmitting many megabits per second. One such circuit in the UK ran some ten miles (16 km) between the BBC studios in Newcastle-upon-Tyne and the Pontop Pike transmitting station. It was able to give the studios a low quality cue feed but not one suitable for transmission. However, these cables had other impairments besides Gaussian noise, preventing such rates from becoming practical in the field.
The 1980s saw the development of techniques for broadband communications that allowed the limit to be greatly extended. A patent was filed in 1979 for the use of existing telephone wires for both telephones and data terminals that were connected to a remote computer via a digital data carrier system. The motivation for digital subscriber line technology was the Integrated Services Digital Network (ISDN) specification proposed in 1984 by the CCITT (now ITU-T) as part of Recommendation I.120, later reused as ISDN Digital Subscriber Line (IDSL). Employees at Bellcore (now Telcordia Technologies) developed Asymmetric Digital Subscriber Line (ADSL) by placing wide-band digital signals above the existing baseband analog voice signal carried between telephone company telephone exchanges and customers on conventional twisted pair cabling facilities, and filed a patent in 1988.
Joseph W. Lechleider's contribution to DSL was his insight that an asymmetric arrangement offered more than double the bandwidth capacity of symmetric DSL. This allowed Internet service providers to offer efficient service to consumers, who benefited greatly from the ability to download large amounts of data but rarely needed to upload comparable amounts. ADSL supports two modes of transport—fast channel and interleaved channel. Fast channel is preferred for streaming multimedia, where an occasional "dropped bit" is acceptable, but lags are less so. Interleaved channel works better for file transfers, where the delivered data must be error-free but latency (time delay) incurred by the retransmission of error-containing packets is acceptable.
Consumer-oriented ADSL was designed to operate on existing lines already conditioned for Basic Rate Interface ISDN services, which itself is a digital circuit switching service (non-IP), though most incumbent local exchange carriers (ILECs) provision Rate-Adaptive Digital Subscriber Line (RADSL) to work on virtually any available copper pair facility, whether conditioned for BRI or not.
Engineers developed high speed DSL facilities such as High bit rate Digital Subscriber Line (HDSL) and Symmetric Digital Subscriber Line (SDSL) to provision traditional Digital Signal 1 (DS1) services over standard copper pair facilities.
Older ADSL standards delivered 8 Mbit/s to the customer over about of unshielded twisted-pair copper wire. Newer variants improved these rates. Distances greater than significantly reduce the bandwidth usable on the wires, thus reducing the data rate. But ADSL loop extenders increase these distances by repeating the signal, allowing the LEC to deliver DSL speeds to any distance.
Until the late 1990s, the cost of digital signal processors for DSL was prohibitive. All types of DSL employ highly complex digital signal processing algorithms to overcome the inherent limitations of the existing twisted pair wires. Due to the advancements of very-large-scale integration (VLSI) technology, the cost of the equipment associated with a DSL deployment lowered significantly. The two main pieces of equipment are a digital subscriber line access multiplexer (DSLAM) at one end and a DSL modem at the other end.
A DSL connection can be deployed over existing cable. Such deployment, even including equipment, is much cheaper than installing a new, high-bandwidth fiber-optic cable over the same route and distance. This is true both for ADSL and SDSL variations. The commercial success of DSL and similar technologies largely reflects the advances made in electronics over the decades that have increased performance and reduced costs even while digging trenches in the ground for new cables (copper or fiber optic) remains expensive.
In the case of ADSL, competition in Internet access caused subscription fees to drop significantly over the years, thus making ADSL more economical than dial up access. Telephone companies were pressured into moving to ADSL largely due to competition from cable companies, which use DOCSIS cable modem technology to achieve similar speeds. Demand for high bandwidth applications, such as video and file sharing, also contributed to popularize ADSL technology.
Early DSL service required a dedicated dry loop, but when the U.S. Federal Communications Commission (FCC) required ILECs to lease their lines to competing DSL service providers, shared-line DSL became available. Also known as DSL over Unbundled Network Element, this unbundling of services allows a single subscriber to receive two separate services from two separate providers on one cable pair. The DSL service provider's equipment is co-located in the same central office (telephone exchange) as that of the ILEC supplying the customer's pre-existing voice service. The subscriber's circuit is rewired to interface with hardware supplied by the ILEC which combines a DSL frequency and POTS signals on a single copper pair facility.
By 2012 some carriers in the United States reported that DSL remote terminals with fiber backhaul are replacing older ADSL systems.
Operation.
Telephones are connected to the telephone exchange via a local loop, which is a physical pair of wires. The local loop was originally intended mostly for the transmission of speech, encompassing an audio frequency range of 300 to 3400 hertz (voiceband or commercial bandwidth). However, as long-distance trunks were gradually converted from analog to digital operation, the idea of being able to pass data through the local loop (by utilizing frequencies above the voiceband) took hold, ultimately leading to DSL.
The local loop connecting the telephone exchange to most subscribers has the capability of carrying frequencies well beyond the 3.4 kHz upper limit of POTS. Depending on the length and quality of the loop, the upper limit can be tens of megahertz. DSL takes advantage of this unused bandwidth of the local loop by creating 4312.5 Hz wide channels starting between 10 and 100 kHz, depending on how the system is configured. Allocation of channels continues at higher and higher frequencies (up to 1.1 MHz for ADSL) until new channels are deemed unusable. Each channel is evaluated for usability in much the same way an analog modem would on a POTS connection. More usable channels equates to more available bandwidth, which is why distance and line quality are a factor (the higher frequencies used by DSL travel only short distances). The pool of usable channels is then split into two different frequency bands for upstream and downstream traffic, based on a preconfigured ratio. This segregation reduces interference. Once the channel groups have been established, the individual channels are bonded into a pair of virtual circuits, one in each direction. Like analog modems, DSL transceivers constantly monitor the quality of each channel and will add or remove them from service depending on whether they are usable. Once upstream and downstream circuits are established, a subscriber can connect to a service such as an Internet service provider or other network services, like a corporate MPLS network.
The underlying technology of transport across DSL facilities uses high-frequency sinusoidal carrier wave modulation, which is an analog signal transmission. A DSL circuit terminates at each end in a modem which modulates patterns of bits into certain high-frequency impulses for transmission to the opposing modem. Signals received from the far-end modem are demodulated to yield a corresponding bit pattern that the modem retransmits, in digital form, to its interfaced equipment, such as a computer, router, switch, etc.
Unlike traditional dial-up modems, which modulate bits into signals in the 300–3400 Hz baseband (voice service), DSL modems modulate frequencies from 4000 Hz to as high as 4 MHz. This frequency band separation enables DSL service and plain old telephone service (POTS) to coexist on the same copper pair facility. On the subscriber's end of the circuit, inline low-pass DSL filters (splitters) are installed on each telephone to filter the high-frequency signals that would otherwise be heard as hiss, but pass voice frequencies. Conversely, high-pass filters already incorporated in the circuitry of DSL modems filter out voice frequencies. Although ADSL and RADSL modulations do not use the voice-frequency band, nonlinear elements in the phone could otherwise generate audible intermodulation and may impair the operation of the data modem in the absence of high-pass filters.
Because DSL operates above the 3.4 kHz voice limit, it cannot pass through a load coil, which is an inductive coil that is designed to counteract loss caused by shunt capacitance (capacitance between the two wires of the twisted pair). Load coils are commonly set at regular intervals in lines placed only for POTS. A DSL signal cannot pass through a properly installed and working load coil, while voice service cannot be maintained past a certain distance without such coils. Therefore, some areas that are within range for DSL service are disqualified from eligibility because of load coil placement. Because of this, phone companies endeavor to remove load coils on copper loops that can operate without them, and by conditioning other lines to avoid them through the use of fiber to the neighborhood or node (FTTN).
Most residential and small-office DSL implementations reserve low frequencies for POTS, so that (with suitable filters and/or splitters) the existing voice service continues to operate independent of the DSL service. Thus POTS-based communications, including fax machines and analog modems, can share the wires with DSL. Only one DSL modem can use the subscriber line at a time. The standard way to let multiple computers share a DSL connection uses a router that establishes a connection between the DSL modem and a local Ethernet, Powerline, or Wi-Fi network on the customer's premises.
The theoretical foundations of DSL, like much of communication technology, can be traced back to Claude Shannon's seminal 1948 paper: "A Mathematical Theory of Communication". Generally, higher bit rate transmissions require a wider frequency band, though the ratio of bit rate to symbol rate and thus to bandwidth are not linear due to significant innovations in digital signal processing and digital modulation methods.
Naked DSL.
A naked DSL (also known as standalone or dry loop DSL) is a way of providing DSL services without a PSTN (analogue telephony) service. It is useful when the customer does not need the traditional telephony voice service because voice service is received either on top of the DSL services (usually VoIP) or through another network (mobile telephony).
It is also commonly called a "UNE" (for Unbundled Network Element) in the United States; in Australia it is known as a "ULL" (Unconditioned Local Loop)., in Belgium it is known as "Raw Copper" and in Turkey it's known as "Yalın Internet" It started making a comeback in the United States in 2004 when Qwest started offering it, closely followed by Speakeasy. As a result of AT&T's merger with SBC, and Verizon's merger with MCI, those telephone companies have an obligation to offer naked DSL to consumers.
In Turkey, since 2011, telephone companies are obliged to offer naked DSL as a result of consumer pressure to the regulatory bodies, however companies can incur additional fees under various label, such as circuit preparation service (devre hazırlama ücreti) or an additional naked DSL fee (yalın adsl ücreti). Although circuit preparation service fee is one-time, the latter is recurring and can constitute as much as 20% of the monthly bill.
Even without the regulatory mandate, however, many ILECs offered naked DSL to consumers. The number of telephone landlines in the United States dropped from 188 million in 2000 to 115 million in 2010, while the number of cellular subscribers has grown to 277 million (as of 2010). This lack of demand for landline voice services has resulted in the expansion of naked DSL availability.
Naked DSL products are also marketed in some other countries e.g., Australia, New Zealand, and Canada.
Typical setup.
On the customer side, the DSL Transceiver, or ATU-R, or more commonly known as a DSL modem, is hooked up to a phone line. The telephone company connects the other end of the line to a DSLAM, which concentrates a large number of individual DSL connections into a single box. The location of the DSLAM depends on the telco, but it cannot be located too far from the user because of attenuation between the DSLAM and the user's DSL modem. It is common for a few residential blocks to be connected to one DSLAM.
The accompanying figure is a schematic of a simple DSL connection (in blue). The right side shows a DSLAM residing in the telephone company's central office. The left side shows the customer premises equipment with an optional router. This router manages a local area network (LAN) off of which are connected some number of PCs. With many service providers, the customer may opt for a modem which contains a wireless router. This option (within the dashed bubble) often simplifies the connection.
Exchange equipment.
At the exchange, a digital subscriber line access multiplexer (DSLAM) terminates the DSL circuits and aggregates them, where they are handed off to other networking transports. In the case of ADSL, the voice component is also separated at this step, either by a filter integrated in the DSLAM or by a specialized filtering equipment installed before it. The DSLAM terminates all connections and recovers the original digital information.
Customer equipment.
The customer end of the connection consists of a terminal adaptor or "DSL modem". This converts data between the digital signals used by computers and the voltage signal of a suitable frequency range which is then applied to the phone line.
In some DSL variations (for example, HDSL), the terminal adapter connects directly to the computer via a serial interface, using protocols such as ethernet or V.35. In other cases (particularly ADSL), it is common for the customer equipment to be integrated with higher level functionality, such as routing, firewalling, or other application-specific hardware and software. In this case, the equipment is referred to as a "gateway".
Most DSL technologies require installation of appropriate filters to separate, or "split", the DSL signal from the low-frequency voice signal. The separation can take place either at the demarcation point, or with filters installed at the telephone outlets inside the customer premises. Each way has its practical and economic limitations.
When the DSL modem powers up it goes through a series of steps to establish connections. The actual process varies from modem to modem but generally involves the following steps:
Modern DSL gateways have more functionality and usually go through an initialization procedure very similar to a PC boot up. The system image is loaded from the flash memory; the system boots, synchronizes the DSL connection and establishes the IP connection between the local network and the service provider, using protocols such as DHCP or PPPoE. (According to a 2007 book, the PPPoE method far outweighed DHCP in terms of deployment on DSL lines, and PAP was the predominant form of subscriber authentication used in such circumstances.) The system image can usually be updated to correct bugs, or to add new functionality.
Protocols and configurations.
Many DSL technologies implement an Asynchronous Transfer Mode (ATM) layer over the low-level bitstream layer to enable the adaptation of a number of different technologies over the same link.
DSL implementations may create bridged or routed networks. In a bridged configuration, the group of subscriber computers effectively connect into a single subnet. The earliest implementations used DHCP to provide network details such as the IP address to the subscriber equipment, with authentication via MAC address or an assigned host name. Later implementations often use Point-to-Point Protocol (PPP) to authenticate with a user ID and password, and to provide network details (Point-to-Point Protocol over Ethernet (PPPoE) or Point-to-Point Protocol over ATM (PPPoA)).
Transmission methods.
Transmission methods vary by market, region, carrier, and equipment.
DSL technologies.
DSL technologies (sometimes summarized as xDSL) include:
The line-length limitations from telephone exchange to subscriber impose severe limits on data transmission rates. Technologies such as VDSL provide very high-speed but short-range links. VDSL is used as a method of delivering "triple play" services (typically implemented in fiber to the curb network architectures).

</doc>
<doc id="41040" url="https://en.wikipedia.org/wiki?curid=41040" title="Digital transmission group">
Digital transmission group

In telecommunication, a digital transmission group is a group of digitized voice or data channels or both with bit streams that are combined into a single digital bit stream for transmission over communications media. 
Digital transmission groups usually are categorized by their maximum capacity, not by a specific number of channels. However, the maximum digital transmission group capacity must be equal to or greater than the sum of the individual multiplexer input channel capacities.

</doc>
<doc id="41043" url="https://en.wikipedia.org/wiki?curid=41043" title="Digroup">
Digroup

Digroup is an abbreviation for digital group. In telephony, a basic digital multiplexing group. 
In the North American and Japanese T-carrier digital hierarchies, each digroup supports 12 PCM voice channels or their equivalent in other services. The DS1 line rate (2 digroups plus overhead bits) is 1.544 Mbit/s, supporting 24 voice channels or their equivalent in other services. 
In the E-carrier European hierarchy, each digroup supports 15 PCM channels or their equivalent in other services. The DS1 line rate (2 digroups plus overhead bits) is 2.048 Mbit/s, supporting 30 voice channels or their equivalent in other services.

</doc>
<doc id="41044" url="https://en.wikipedia.org/wiki?curid=41044" title="Direct access">
Direct access

Direct access may refer to:

</doc>
<doc id="41045" url="https://en.wikipedia.org/wiki?curid=41045" title="Direct connect">
Direct connect

Direct connect may refer to:

</doc>
<doc id="41046" url="https://en.wikipedia.org/wiki?curid=41046" title="Direct distance dialing">
Direct distance dialing

Direct distance dialing (DDD) is telecommunication service feature in which a caller may, without operator assistance, call any other user outside the local calling area. Direct dialing by subscribers typically requires extra digits to be dialed as prefixes than for dialing within the local area or within an area code. DDD also extends beyond the boundaries of national public telephone network, in which case it is called international direct dialing or international direct distance dialing (IDDD).
DDD was the term used when the North American Numbering Plan was implemented in the 1950s. In the United Kingdom and other parts of the Commonwealth of Nations, the equivalent terms are or were "STD", for subscriber trunk dialing, and "ISD" for international subscriber trunk dialing.
History.
The first direct-dialed long-distance telephone calls were possible in the New Jersey communities of Englewood and Teaneck starting on November 10, 1951. Customers of the ENglewood 3, ENglewood 4 and TEaneck 7 exchanges, who could already dial New York City and area, were able to dial 11 cities across the United States, simply by dialing the three-digit area code and the seven-digit number, which at the time consisted of the first two letters of the central office name and five digits.
The eleven destinations at that time were:
Many other cities could not yet be included as they did not yet have the necessary toll switching equipment to handle incoming calls automatically on their circuits. Other cities still had either a mixture of local number lengths or were all still six-digit numbers; Montreal and Toronto, Canada, for example, had a mix of six- and seven-digit numbers from 1951 to 1957, and did not have DDD until 1958. Whitehorse, Yukon, had seven-digit numbers from 1965, but the necessary switching equipment was not in place locally until 1972.
Hardware.
The No. 4 Crossbar switching system had been introduced in the 1940s to switch four-wire circuits and replace the incoming operator. With semiautomatic operation analogous to the early days of the panel switch, the operator in the originating city used a multifrequency keypad to dial an access code to connect to the correct city and to send the seven digit number to incoming equipment at the terminating city. This design was further refined to serve DDD.
The card sorter of the 4A/CTS (Number 4A Crossbar / Card Translator System) allowed six digit translation of the central office code number dialed by the customer. This determined the proper trunk circuits to use, where separate circuit groups were used for different cities in the same area code, as in the case of Oakland and San Francisco. The new device used metal cards similar in principle to computer punched cards, and they were rapidly scanned as they fell past a light beam. On busy days, it sounded like a machine gun firing. CTS machines were called 4A (Advanced) if the translator was included in the original installation, and 4M (Modified) if it was added later. A 1970s version of 4XB, the 4A/ETS, used a computer to translate. For international dialing, Traffic Service Position System (TSPS) provided the extra computer power.
The reach of DDD was limited due to the inefficiency and expense of switching equipment, and the limited ability to process records of completed calls. One obstacle was that the majority of switching gear did not provide Automatic Number Identification (ANI). Common control switches such as 1XB switch were fairly quickly retrofitted to provide ANI, and most 5XB switches were initially installed with ANI services. Panel switch were eventually retrofitted, as were some step-by-step that were not scheduled for immediate replacement. Even if a switch had ANI, it could not identify callers on party lines. This was only partly overcome by Tip Party Identification. As the cost of subscriber line carrier declined, party lines were gradually phased out.
As this and other improved technologies became available, as well as Automatic Message Accounting (AMA) computers to process the long distance records into customer bills, the reach of DDD was slow in the 1950s, but quickened in the early 1960s. Electronic switching systems with stored-program capability allowed electronic processing of the dialed digits, referring to electronic memories to determine call routing, and this has reached the state of the art, with digital telephone exchanges which are basically specialized computers that route voice traffic from one "peripheral" to another as digital data. Call routing can now be done based on the area code, central office code and even the first two digits of the line number, although routing based on digits past the central office code is usually limited to cases of competitive local exchange carriers, number pooling and number portability.
IDDD.
In the 1960s, with the domestic conversion still underway, plans were laid to extend Direct Dialing beyond North America and its nearby islands. With so much new equipment already working that could only handle ten digit phone numbers, a system was devised by which most toll offices did not have to store and forward the whole international phone number. Gateway offices were set up in New York, London and Paris, connected to the ordinary automatic toll network. The New York gateway was at 32 Avenue of the Americas. The new LT1 5XB switch on the tenth floor of 435 West 50th Street received new Originating Registers and Outgoing Senders able to handle 15 digit telephone numbers, with appropriate modifications to Completing Markers and other equipment. Other 5XB in the next few years were installed with IDDD as original equipment, and in the 1970s ESS offices also provided the service.
The key to the new system was two-stage multi-frequency pulsing. The outgoing sender sent its Class 4 toll center an off-hook signal as usual, received a wink as usual as a "proceed to send" signal, and outpulsed only a special 3-digit (later 6-digit) access code. The toll center picked a trunk through the long distance network to the gateway office, which sent a second wink to the originating office, which then sent the whole dialed number. Thus the toll switching system needed no modification except at the gateway. The international trunks used Signaling System No. 5, a "North Atlantic" version of the North American multi-frequency signaling system, with minor modifications including slightly higher digit rate. European MF systems of the time used compelled signalling, which would slow down too much on a long transoceanic connection.
In the 1970s, toll centers were modified by adding TSPS. With these new computers in place, digit storage in the toll system was no longer a problem. End offices were less extensively modified, and sent all their digits in a single stream. TSPS handled the gateway codes and other complexities of toll connections to the gateway office.

</doc>
<doc id="41049" url="https://en.wikipedia.org/wiki?curid=41049" title="Direct-sequence spread spectrum">
Direct-sequence spread spectrum

In the telecommunications, direct-sequence spread spectrum (DSSS) is a spread spectrum modulation technique. Spread spectrum systems are such that they transmit the message bearing signals using a bandwidth that is in excess of the bandwidth that is actually needed by the message signal. This spreading of the transmitted signal over a large bandwidth make the resulting wideband signal appear as a noise signal which allows greater resistance to intentional and unintentional interference with the transmitted signal.
One of the methods of achieving this spreading of the message signal is provided by DSSS modulation. In DSSS the message signal is used to modulate a bit sequence known as the Pseudo Noise (PN) code; this PN code consists of pulses of a much shorter duration (larger bandwidth) than the pulse duration of the message signal, therefore the modulation by the message signal has the effect of chopping up the pulses of the message signal and thereby resulting in a signal which has a bandwidth nearly as large as that of the PN sequence. In this context the duration of the pulse of the PN code is referred to as the chip duration and the smaller this value, the larger the bandwidth of the resultant DSSS signal and the more immune to interference the resultant signal becomes.
Some of the uses of DSSS include the Code Division Multiple Access (CDMA) channel access method and the IEEE 802.11b specification used in Wi-Fi networks.
Transmission method.
Direct-sequence spread-spectrum transmissions multiply the data being transmitted by a "noise" signal. This noise signal is a pseudorandom sequence of codice_1 and codice_2 values, at a frequency much higher than that of the original signal.
The resulting signal resembles white noise, like an audio recording of "static". However, this noise-like signal is used to exactly reconstruct the original data at the receiving end, by multiplying it by the same pseudorandom sequence (because 1 × 1 = 1, and −1 × −1 = 1). This process, known as "de-spreading", mathematically constitutes a correlation of the transmitted PN sequence with the PN sequence that the receiver already knows the transmitter is using.
The resulting effect of enhancing signal to noise ratio on the channel is called "process gain". This effect can be made larger by employing a longer PN sequence and more chips per bit, but physical devices used to generate the PN sequence impose practical limits on attainable processing gain.
If an undesired transmitter transmits on the same channel but with a different PN sequence (or no sequence at all), the de-spreading process has reduced processing gain for that signal. This effect is the basis for the code division multiple access (CDMA) property of DSSS, which allows multiple transmitters to share the same channel within the limits of the cross-correlation properties of their PN sequences.
As this description suggests, a plot of the transmitted waveform has a roughly bell-shaped envelope centered on the carrier frequency, just like a normal AM transmission, except that the added noise causes the distribution to be much wider than that of an AM transmission.
In contrast, frequency-hopping spread spectrum pseudo-randomly re-tunes the carrier, instead of adding pseudo-random noise to the data, the latter process results in a uniform frequency distribution whose width is determined by the output range of the pseudorandom number generator.

</doc>
<doc id="41050" url="https://en.wikipedia.org/wiki?curid=41050" title="Disengagement originator">
Disengagement originator

In telecommunication, a disengagement originator is the user or execution unit that initiates a disengagement attempt. The disengagement originator may be the originating user, the destination user, or the communications system. The communications system may deliberately originate the disengagement because of preemption, or inadvertently due to system malfunction.

</doc>
<doc id="41051" url="https://en.wikipedia.org/wiki?curid=41051" title="Dispersion-limited operation">
Dispersion-limited operation

A dispersion-limited operation is an operation of a communications link in which signal waveform degradation attributable to the dispersive effects of the communications medium is the dominant mechanism that limits link performance. The dispersion is the filter-like effect that a link has on the signal, due to the different propagation speeds of the eigenmodes of the link. Practically, this means that the waveform at the input will be different from the waveform at the output of the link.
Note that the amount of allowable degradation is dependent on the quality of the receiver. Note also that in fiber optic communications, "dispersion-limited operation" is often confused with "distortion-limited operation".

</doc>
<doc id="41052" url="https://en.wikipedia.org/wiki?curid=41052" title="Distortion">
Distortion

Distortion is the alteration of the original shape (or other characteristic) of something, such as an object, image, sound or waveform. Distortion is usually unwanted, and so engineers strive to eliminate distortion, or minimize it. In some situations, however, distortion may be desirable. The important signal processing operation of heterodyning is based on nonlinear mixing of signals to cause intermodulation. Distortion is also used as a musical effect, particularly with electric guitars.
The addition of noise or other outside signals (hum, interference) is not deemed distortion, though the effects of quantization distortion are sometimes deemed noise. A quality measure that explicitly reflects both the noise and the distortion is the Signal-to-noise-and-distortion (SINAD) ratio.
Electronic signals.
In telecommunication and signal processing, a noise-free system can be characterised by a transfer function, such that the output formula_1 can be written as a function of the input formula_2 as
When the transfer function comprises only a perfect gain constant "A" and perfect delay "T"
the output is undistorted. Distortion occurs when the transfer function "F" is more complicated than this. If "F" is a linear function, for instance a filter whose gain and/or delay varies with frequency, the signal suffers linear distortion. Linear distortion does not introduce new frequency components to a signal but does alter the balance of existing ones.
This diagram shows the behaviour of a signal (made up of a square wave followed by a sine wave) as it is passed through various distorting functions.
The transfer function of an ideal amplifier, with perfect gain and delay, is only an approximation. The true behavior of the system is usually different. Nonlinearities in the transfer function of an active device (such as vacuum tubes, transistors, and operational amplifiers) are a common source of non-linear distortion; in passive components (such as a coaxial cable or optical fiber), linear distortion can be caused by inhomogeneities, reflections, and so on in the propagation path.
Amplitude distortion.
Amplitude distortion is distortion occurring in a system, subsystem, or device when the output amplitude is not a linear function of the input amplitude under specified conditions.
Harmonic distortion.
Harmonic distortion adds overtones that are whole number multiples of a sound wave's frequencies. Nonlinearities that give rise to amplitude distortion in audio systems are most often measured in terms of the harmonics (overtones) added to a pure sinewave fed to the system. Harmonic distortion may be expressed in terms of the relative strength of individual components, in decibels, or the root mean square of all harmonic components: Total harmonic distortion (THD), as a percentage. The level at which harmonic distortion becomes audible depends on the exact nature of the distortion. Different types of distortion (like crossover distortion) are more audible than others (like soft clipping) even if the THD measurements are identical. Harmonic distortion in radio frequency applications is rarely expressed as THD.
Frequency response distortion.
Non-flat frequency response is a form of distortion that occurs when different frequencies are amplified by different amounts in a filter. For example, the non-uniform frequency response curve of AC-coupled cascade amplifier is an example of frequency distortion. In the audio case, this is mainly caused by room acoustics, poor loudspeakers and microphones, long loudspeaker cables in combination with frequency dependent loudspeaker impedance, etc.
Phase distortion.
This form of distortion mostly occurs due to electrical reactance. Here, all the components of the input signal are not amplified with the same phase shift, hence making some parts of the output signal out of phase with the rest of the output.
Group delay distortion.
Can be found only in dispersive media. In a waveguide, phase velocity varies with frequency. In a filter, group delay tends to peak near the cut-off frequency, resulting in pulse distortion. When analog long distance trunks were commonplace, for example in 12 channel carrier, group delay distortion had to be corrected in repeaters.
Correction of distortion.
As the system output is given by y(t) = F(x(t)), then if the inverse function F−1 can be found, and used intentionally to distort either the input or the output of the system, then the distortion is corrected.
An example of a similar correction is where LP/vinyl recordings or FM audio transmissions are deliberately pre-emphasised by a linear filter, the reproducing system applies an inverse filter to make the overall system undistorted.
Correction is not possible if the inverse does not exist—for instance if the transfer function has flat spots (the inverse would map multiple input points to a single output point). This produces an uncorrectable loss of information. Such a situation can occur when an amplifier is overdriven—causing clipping or slew rate distortion when, for a moment, the amplifier characteristics alone and not the input signal determine the output.
Cancellation of even-order harmonic distortion.
Many symmetrical electronic circuits reduce the magnitude of even harmonics generated by the non-linearities of the amplifier's components, by combining two signals from opposite halves of the circuit where distortion components that are roughly the same magnitude but out of phase. Examples include push-pull amplifiers and long-tailed pairs.
Teletypewriter or modem signaling.
In binary signaling such as FSK, distortion is the shifting of the significant instants of the signal pulses from their proper positions relative to the beginning of the start pulse. The magnitude of the distortion is expressed in percent of an ideal unit pulse length. This is sometimes called 'bias' distortion.
Telegraphic distortion is a similar older problem, distorting the ratio between "mark" and "space" intervals. [http://www.freepatentsonline.com/3725787.html]
Distortion in art.
In the art world, a distortion is any change made by an artist to the size, shape or visual character of a form to express an idea, convey a feeling or enhance visual impact. Often referred to as "abstraction," examples of distortion include "The Weeping Woman" by Picasso and "The Adoration of the Shepherds" by El Greco.
Audio distortion.
In this context, distortion refers to any kind of deformation of an output waveform compared to its input, usually clipping, harmonic distortion, or intermodulation distortion (mixing phenomena) caused by non-linear behavior of electronic components and power supply limitations. Terms for specific types of nonlinear audio distortion include: crossover distortion, slew-Induced Distortion (SID) and transient intermodulation (TIM).
Distortion in music is often intentionally used as an effect when applied to an electric guitar signal in styles of rock music such as heavy metal and punk rock (see also overdrive and distortion synthesis). Other forms of audio distortion that may be referred to are non-flat frequency response, compression, modulation, aliasing, quantization noise, wow and flutter from analog media such as vinyl records and magnetic tape. The human ear cannot hear phase distortion, except that it may affect the stereo imaging. (See also: Audio system measurements.)
In most fields, distortion is characterized as unwanted change to a signal.
Optics.
In optics, image/optical distortion is a divergence from rectilinear projection caused by a change in magnification with increasing distance from the optical axis of an optical system.
Map projections.
In cartography, a distortion is the misrepresentation of the area or shape of a feature. The Mercator projection, for example, distorts by exaggerating the size of regions at high latitude.

</doc>
<doc id="41053" url="https://en.wikipedia.org/wiki?curid=41053" title="Distortion-limited operation">
Distortion-limited operation

In telecommunication, distortion-limited operation is the condition prevailing when distortion of a received signal, rather than its attenuated amplitude (or power), limits performance under stated operational conditions and limits. 
"Note:" Distortion-limited operation is reached when the system distorts the shape of the waveform beyond specified limits. For linear systems, distortion-limited operation is equivalent to bandwidth-limited operation.

</doc>
<doc id="41054" url="https://en.wikipedia.org/wiki?curid=41054" title="Distributed database">
Distributed database

A distributed database is a database in which storage devices are not all attached to a common processing unit such as the CPU, and which is controlled by a distributed database management system (together sometimes called a distributed database system). It may be stored in multiple computers, located in the same physical location; or may be dispersed over a network of interconnected computers. Unlike parallel systems, in which the processors are tightly coupled and constitute a single database system, a distributed database system consists of loosely coupled sites that share no physical components.
System administrators can distribute collections of data (e.g. in a database) across multiple physical locations. A distributed database can reside on network servers on the Internet, on corporate intranets or extranets, or on other company networks. Because they store data across multiple computers, distributed databases can improve performance at end-user worksites by allowing transactions to be processed on many machines, instead of being limited to one.
Two processes ensure that the distributed databases remain up-to-date and current: replication and duplication.
Both replication and duplication can keep the data current in all distributive locations.
Besides distributed database replication and fragmentation, there are many other distributed database design technologies. For example, local autonomy, synchronous and asynchronous distributed database technologies. These technologies' implementations can and do depend on the needs of the business and the sensitivity/confidentiality of the data stored in the database, and hence the price the business is willing to spend on ensuring data security, consistency and integrity.
When discussing access to distributed databases, Microsoft favors the term distributed query, which it defines in protocol-specific manner as "ny SELECT, INSERT, UPDATE, or DELETE statement that references tables and rowsets from one or more external OLE DB data sources".
Oracle provides a more language-centric view in which distributed queries and distributed transactions form part of distributed SQL.
Today the distributed DBMS market is evolving dramatically, with new, innovative entrants and incumbents supporting the growing use of unstructured data and NoSQL DBMS engines, as well as XML databases and NewSQL databases. These databases are increasingly supporting distributed database architecture that provides high availability and fault tolerance through replication and scale out ability. Some examples are Aerospike, Cassandra, Clusterpoint, ClustrixDB, Couchbase, Druid (open-source data store), FoundationDB, NuoDB, Riak and OrientDB. The block chain technology popularised by bitcoin is an implementation of a distributed database.
Architecture.
A database user accesses the distributed database through:
A homogeneous distributed database has identical software and hardware running all databases instances, and may appear through a single interface as if it were a single database. A heterogeneous distributed database may have different hardware, operating systems, database management systems, and even data models for different databases.
Homogeneous Distributed Databases Management System.
In homogeneous distributed database all sites have identical software and are aware of each other and agree to cooperate in processing user requests. Each site surrenders part of its autonomy in terms of right to change schema or software. A homogeneous DBMS appears to the user as a single system. The homogeneous system is much easier to design and manage. The following conditions must be satisfied for homogeneous database:
Heterogeneous DDBMS.
In a heterogeneous distributed database, different sites may use different schema and software. Difference in schema is a major problem for query processing and transaction processing. Sites may not be aware of each other and may provide only limited facilities for cooperation in transaction processing. In heterogeneous systems, different nodes may have different hardware & software and data structures at various nodes or locations are also incompatible. Different computers and operating systems, database applications or data models may be used at each of the locations. For example, one location may have the latest relational database management technology, while another location may store data using conventional files or old version of database management system. Similarly, one location may have the Windows NT operating system, while another may have UNIX. Heterogeneous systems are usually used when individual sites use their own hardware and software. On heterogeneous system, translations are required to allow communication between different sites (or DBMS). In this system, the users must be able to make requests in a database language at their local sites. Usually the SQL database language is used for this purpose. If the hardware is different, then the translation is straightforward, in which computer codes and word-length is changed. The heterogeneous system is often not technically or economically feasible. In this system, a user at one location may be able to read but not update the data at another location.
Important considerations.
Care with a distributed database must be taken to ensure the following:
There are two principal approaches to store a relation r in a distributed database system:
A) Replication: In replication, the system maintains several identical replicas of the same relation r in different sites.
B) Fragmentation: The relation r is fragmented into several relations r1, r2, r3...rn in such a way that the actual relation could be reconstructed from the fragments and then the fragments are scattered to different locations. There are basically two schemes of fragmentation:
A distributed database can be run by independent or even competing parties as, for example, in bitcoin or Hasq.
Advantages.
The Merge Replication Method is popularly used to consolidate the data between databases.

</doc>
<doc id="41055" url="https://en.wikipedia.org/wiki?curid=41055" title="Distributed-queue dual-bus">
Distributed-queue dual-bus

In telecommunication, a distributed-queue dual-bus network (DQDB) is a distributed multi-access network that (a) supports integrated communications using a dual bus and distributed queuing, (b) provides access to local or metropolitan area networks, and (c) supports connectionless data transfer, connection-oriented data transfer, and isochronous communications, such as voice communications.
IEEE 802.6 is an example of a network providing DQDB access methods.
Concept of operation.
The DQDB Medium Access Control (MAC) algorithm is generally credited to Robert Newman who developed this algorithm in his PhD thesis in the 1980s at the University of Western Australia. To appreciate the innovative value of the DQDB MAC algorithm, it must be seen against the background of LAN protocols at that time, which were based on broadcast (such as ethernet IEEE 802.3) or a ring (like token ring IEEE 802.5 and FDDI). The DQDB may be thought of as two token rings, one carrying data in each direction around the ring. This improves reliability which is important in Metropolitan Area Networks (MAN), where repairs may take longer than in a LAN and Wi-Fi because the damage may be inaccessible.
The DQDB standard IEEE 802.6 was developed while ATM (Broadband ISDN) was still in early development, but there was strong interaction between the two standards. ATM cells and DQDB frames were harmonized. They both settled on essentially a 48-byte data frame with a 5-byte header. In the DQDB algorithm, a distributed queue was implemented by communicating queue state information via the header. Each node in a DQDB network maintains a pair of state variables which represent its position in the distributed queue and the size of the queue. The headers on the reverse bus communicated requests to be inserted in the distributed queue so that upstream nodes would know that they should allow DQDB cells to pass unused on the forward bus. The algorithm was remarkable for its extreme simplicity.
Currently DQDB systems are being installed by many carriers in entire cities, with lengths that reach up to with speeds of a DS3 line (44.736 Mbit/s). Other implementations use optical fiber for a length of up to 100 km and speeds around 150 Mbit/s

</doc>
<doc id="41056" url="https://en.wikipedia.org/wiki?curid=41056" title="Distributed switching">
Distributed switching

Distributed switching is an architecture in which multiple processor-controlled switching units are distributed. There is often a hierarchy of switching elements, with a centralized host switch and with remote switches located close to concentrations of users.
Use in telephony networks.
Distributed switching is often used in telephone networks, though it is often called "host-remote switching".
In rural areas, population centers tend to be too small for economical deployment of a full-featured dedicated telephone exchange, and distances between these centers make transmission costs relatively high. Normal telephone traffic patterns show that most calling is done between people in a community of interest, in this case a geographical one: the population center. Use of distributed switching allows for the majority of calls that are local to that population center to be switched there without needing to be transported to and from the host switch.
The host switch provides connectivity between the remote switches and to the larger network, and the host may also directly handle some rare and complex call types (conference calling, for example) that the remote itself is not equipped to handle. Host switches also perform OAM&P (Operation, Administration, Maintenance, and Provisioning) functions, including billing, for the entire cluster of the host and its remote switches.
A key capability of a remote switch is the ability to act in emergency standalone (ESA) mode, wherein local calls can still be placed even in the event that the connection between that remote and the host has been lost. In this mode, only local calling is available anyway, so the billing capability of the host switch is not required. ESA is increasingly available on digital loop carrier platforms as well as on purpose-built remote switches in order to improve the scope of their utility.
Use within telecommunications equipment platforms.
Many data-centric telecommunications platforms such as routers and Ethernet switches utilize distributed switching on separate cards within an equipment chassis. Even when this is used, it is common to have a centralized switching fabric to interconnect the distributed switches. This architecture has become less common as backplane bus speeds and centralized switch fabric capacities have increased.

</doc>
<doc id="41057" url="https://en.wikipedia.org/wiki?curid=41057" title="Disturbance voltage">
Disturbance voltage

In telecommunication, a disturbance voltage is an unwanted voltage induced in a system by natural or man-made sources.
In telecommunications systems, the disturbance voltage creates currents that limit or interfere with the interchange of information. An example of a disturbance voltage is a voltage that produces (a) false signals in a telephone, (b) Noise (radio) in a radio receiver, or (c) distortion in a received signal.

</doc>
<doc id="41058" url="https://en.wikipedia.org/wiki?curid=41058" title="Diurnal phase shift">
Diurnal phase shift

In telecommunication, diurnal phase shift is the phase shift of electromagnetic signals associated with daily changes in the ionosphere. The major changes usually occur during the period of time when sunrise or sunset is present at critical points along the path. Significant phase shifts may occur on paths wherein a reflection area of the path is subject to a large tidal range. In cable systems, significant phase shifts can be occasioned by diurnal temperature variance.

</doc>
<doc id="41061" url="https://en.wikipedia.org/wiki?curid=41061" title="Department of Defense master clock">
Department of Defense master clock

The Department of Defense master clock is the master clock to which time and frequency measurements for the United States Department of Defense are referenced. 
The U.S. Naval Observatory master clock is designated as the DOD Master Clock. The U.S. Naval Observatory master clock is one of the two standard time and frequency references for the U.S. Government in accordance with Federal Standard 1002-A. The other standard time and frequency reference for the U.S. Government is the National Institute of Standards and Technology (NIST) master clock.

</doc>
<doc id="41062" url="https://en.wikipedia.org/wiki?curid=41062" title="Double-ended synchronization">
Double-ended synchronization

For two connected exchanges in a communications network, a double-ended synchronization (also called double-ended control) is a synchronization control scheme in which the phase error signals used to control the clock at one telephone exchange are derived by comparison with the phase of the incoming digital signal and the phase of the internal clocks at both exchanges.

</doc>
<doc id="41063" url="https://en.wikipedia.org/wiki?curid=41063" title="Double-sideband reduced-carrier transmission">
Double-sideband reduced-carrier transmission

Double-sideband reduced carrier transmission (DSB-RC): transmission in which (a) the frequencies produced by amplitude modulation are symmetrically spaced above and below the carrier and (b) the carrier level is reduced for transmission at a fixed level below that which is provided to the modulator. 
"Note:" In DSB-RC transmission, the carrier is usually transmitted at a level suitable for use as a reference by the receiver, except for the case in which it is reduced to the minimum practical level, i.e. the carrier is suppressed.

</doc>
<doc id="41064" url="https://en.wikipedia.org/wiki?curid=41064" title="Double-sideband suppressed-carrier transmission">
Double-sideband suppressed-carrier transmission

Double-sideband suppressed-carrier transmission (DSB-SC) is transmission in which frequencies produced by amplitude modulation (AM) are symmetrically spaced above and below the carrier frequency and the carrier level is reduced to the lowest practical level, ideally being completely suppressed. 
In the DSB-SC modulation, unlike in AM, the wave carrier is not transmitted; thus, much of the power is distributed between the sidebands, which implies an increase of the cover in DSB-SC, compared to AM, for the same power used.
DSB-SC transmission is a special case of double-sideband reduced carrier transmission. It is used for radio data systems.
Spectrum.
DSB-SC is basically an amplitude modulation wave without the carrier, therefore reducing power waste, giving it a 100% efficiency. This is an increase compared to normal AM transmission (DSB), which has a maximum efficiency of 33.333%, since 2/3 of the power is in the carrier which carries no intelligence, and each sideband carries the same information. Single Side Band (SSB) Suppressed Carrier is 100% efficient.
Spectrum plot of a DSB-SC signal:
Generation.
DSB-SC is generated by a mixer. This consists of a message signal multiplied by a carrier signal. The mathematical representation of this process is shown below, where the product-to-sum trigonometric identity is used.
formula_1
Demodulation.
Demodulation is done by multiplying the DSB-SC signal with the carrier signal just like the modulation process. This resultant signal is then passed through a low pass filter to produce a scaled version of original message signal. DSB-SC can be demodulated by a simple envelope detector, like AM, if the modulation index is less than unity. Full depth modulation requires carrier re-insertion.
The equation above shows that by multiplying the modulated signal by the carrier signal, the result is a scaled version of the original message signal plus a second term. Since formula_4, this second term is much higher in frequency than the original message. Once this signal passes through a low pass filter, the higher frequency component is removed, leaving just the original message.
Distortion and attenuation.
For demodulation, the demodulation oscillator's frequency and phase must be exactly the same as modulation oscillator's, otherwise, distortion and/or attenuation will occur. 
To see this effect, take the following conditions:
The resultant signal can then be given by
The formula_11 terms results in distortion and attenuation of the original message signal. In particular, if the frequencies are correct, but the phase is wrong, contribution from formula_12 is a constant attenuation factor, also formula_13 represents a cyclic inversion of the recovered signal, which is a serious form of distortion.
How it works.
This is best shown graphically. Below is a message signal that one may wish to modulate onto a carrier, consisting of a couple of sinusoidal components.
The equation for this message signal is formula_14.
The carrier, in this case, is a plain 5 kHz (formula_15) sinusoid—pictured below.
The modulation is performed by multiplication in the time domain, which yields a 5 kHz carrier signal, whose amplitude varies in the same manner as the message signal.
formula_16
The name "suppressed carrier" comes about because the carrier signal component is suppressed—it does not appear in the output signal. This is apparent when the spectrum of the output signal is viewed:

</doc>
<doc id="41067" url="https://en.wikipedia.org/wiki?curid=41067" title="Drift">
Drift


</doc>
<doc id="41068" url="https://en.wikipedia.org/wiki?curid=41068" title="Drop (liquid)">
Drop (liquid)

A drop or droplet is a small column of liquid, bounded completely or almost completely by free surfaces. A drop may form when liquid accumulates at the lower end of a tube or other surface boundary, producing a hanging drop called a pendant drop. Drops may also be formed by the condensation of a vapor or by atomization of a larger mass of liquid.
Surface tension.
Liquid forms drops because the liquid exhibits surface tension.
A simple way to form a drop is to allow liquid to flow slowly from the lower end of a vertical tube of small diameter. The surface tension of the liquid causes the liquid to hang from the tube, forming a pendant. When the drop exceeds a certain size it is no longer stable and detaches itself. The falling liquid is also a drop held together by surface tension.
Pendant drop test.
In the pendant drop test, a drop of liquid is suspended from the end of a tube by surface tension. The force due to surface tension is proportional to the length of the boundary between the liquid and the tube, with the proportionality constant usually denoted formula_1. Since the length of this boundary is the circumference of the tube, the force due to surface tension is given by
where "d" is the tube diameter.
The mass "m" of the drop hanging from the end of the tube can be found by equating the force due to gravity (formula_3) with the component of the surface tension in the vertical direction (formula_4) giving the formula
where α is the angle of contact with the tube, and "g" is the acceleration due to gravity.
The limit of this formula, as α goes to 90°, gives the maximum weight of a pendant drop for a liquid with a given surface tension, formula_1.
This relationship is the basis of a convenient method of measuring surface tension, commonly used in the petroleum industry. More sophisticated methods are available to take account of the developing shape of the pendant as the drop grows. These methods are used if the surface tension is unknown.
In medicine, droppers have a standardized diameter, in such a way that 1 millilitre is equivalent to 20 drops. And, for the cases when smaller amounts are necessary, microdroppers are used, in which, 1 millilitre = 60 microdrops.
Drop adhesion to a solid.
The drop adhesion to a solid can be divided to two categories: lateral adhesion and normal adhesion. Lateral adhesion resembles friction (though tribologically lateral adhesion is a more accurate term) and refers to the force required to slide a drop on the surface, namely the force to detach the drop from its position on the surface only to translate it to another position on the surface. Normal adhesion is the adhesion required to detach a drop from the surface in the normal direction, namely the force to cause the drop to fly off from the surface. The measurement of both adhesion forms can be done with the Centrifugal Adhesion Balance (CAB). The CAB uses a combination of centrifugal and gravitational forces to obtain any ratio of lateral and normal forces. For example, it can apply a normal force at zero lateral force for the drop to fly off away from the surface in the normal direction or it can induce a lateral force at zero normal force (simulating zero gravity).
Droplet.
The term droplet is a diminutive form of 'drop' - and as a guide is typically used for liquid particles of less than 500 µm diameter. In spray application, droplets are usually described by their perceived size (i.e., diameter) whereas the dose (or number of infective particles in the case of biopesticides) is a function of their volume. This increases by a cubic function relative to diameter3/6000 to convert µm into picolitres)-->; thus a 50 µm droplet represents a dose in 65 pl and a 500 µm drop represents a dose in 65 nanolitres.
Speed.
A droplet with a diameter of 3 mm has a terminal velocity of approximately 8 m/s.
Drops smaller than in diameter will attain 95% of their terminal velocity within . But above this size the distance to get to terminal velocity increases sharply. An example is a drop with a diameter of that may achieve this at .
Optics.
Due to the different refractive index of water and air, refraction and reflection occur on the surfaces of raindrops, leading to rainbow formation.
Sound.
The major source of sound when a droplet hits a liquid surface is the resonance of excited bubbles trapped underwater. These oscillating bubbles are responsible for most liquid sounds, such as running water or splashes, as they actually consist of many drop-liquid collisions.
Shape.
The classic shape associated with a drop (with a pointy end in its upper side) comes from the observation of a droplet clinging to a surface. The shape of a drop falling through a gas is actually more or less spherical for drops less than 2mm in diameter. Larger drops tend to be flatter on the bottom part due to the pressure of the gas they move through. As a result, as drops get larger, a concave depression forms which leads to the eventual breakup of the drop.
Size.
Raindrop sizes typically range from 0.5 mm to 4 mm, with size distributions quickly decreasing past diameters larger than 2-2.5 mm.
Scientists traditionally thought that the variation in the size of raindrops was due to collisions on the way down to the ground. In 2009 French researchers succeeded in showing that the distribution of sizes is due to the drops' interaction with air, which deforms larger drops and causes them to fragment into smaller drops, effectively limiting the largest raindrops to about 6 mm diameter. However, drops up to 10 mm (equivalent in volume to a sphere of radius 4.5 mm) are theoretically stable and could be levitated in a wind tunnel.
The largest recorded raindrop was 8.8 mm in diameter, located at the base of a cumulus congestus cloud in the vicinity of Kwajalein Atoll in July 1999. A raindrop of identical size was detected over northern Brazil in September 1995.

</doc>
<doc id="41069" url="https://en.wikipedia.org/wiki?curid=41069" title="Drop and insert">
Drop and insert

In a multichannel transmission system, a drop and insert is a process that diverts (drops) a portion of the multiplexed aggregate signal at an intermediate point, and introduces (inserts) a different signal for subsequent transmission in the same position, "e.g.", time slot or frequency band, previously occupied by the diverted signal. 
The diverted signal may be demodulated or reinserted into another transmission system in the same or another time slot or frequency band. 
The time slot or frequency band vacated by the diverted signal need not necessarily be reoccupied by another signal. Likewise, a previously unoccupied time slot or frequency band may be occupied by a signal inserted at the drop-and-insert point.
Signals not of interest at the drop-and-insert point are not diverted.

</doc>
<doc id="41070" url="https://en.wikipedia.org/wiki?curid=41070" title="Dropout">
Dropout

Dropout may refer to:

</doc>
<doc id="41071" url="https://en.wikipedia.org/wiki?curid=41071" title="DTE">
DTE

DTE may refer to:

</doc>
<doc id="41072" url="https://en.wikipedia.org/wiki?curid=41072" title="Dual access">
Dual access

In telecommunication, the term dual access has the following meanings: 
Also, network hardware company D-Link has named technology which allows two simultaneous connections over one cable, for example 1) Internet and 2) provider's local FTP or game servers or IPTV data flow.

</doc>
<doc id="41073" url="https://en.wikipedia.org/wiki?curid=41073" title="Dual in-line package">
Dual in-line package

In microelectronics, a dual in-line package (DIP or DIL), or dual in-line pin package (DIPP) is an electronic component package with a rectangular housing and two parallel rows of electrical connecting pins. The package may be through-hole mounted to a printed circuit board or inserted in a socket. The dual-inline format was invented by Don Forbes, Rex Rice and Bryant Rogers at Fairchild R&D in 1964, when the restricted number of leads available on circular transistor-style packages became a limitation in the use of integrated circuits. Increasingly complex circuits required more signal and power supply leads (as observed in Rent's rule); eventually microprocessors and similar complex devices required more leads than could be put on a DIP package, leading to development of higher-density packages. Furthermore, square and rectangular packages made it easier to route printed-circuit traces beneath the packages.
A DIP is usually referred to as a DIP"n", where "n" is the total number of pins. For example, a microcircuit package with two rows of seven vertical leads would be a DIP14. The photograph at the upper right shows three DIP14 ICs. Common packages have as few as four and as many as 64 leads. Many analog and digital integrated circuit types are available in DIP packages, as are arrays of transistors, switches, light emitting diodes, and resistors. DIP plugs for ribbon cables can be used with standard IC sockets.
DIP packages are usually made from an opaque molded epoxy plastic pressed around a tin-, silver-, or gold-plated lead frame that supports the device die and provides connection pins. Some types of IC are made in ceramic DIP packages, where high temperature or high reliability is required, or where the device has an optical window to the interior of the package. Most DIP packages are secured to a printed circuit board by inserting the pins through holes in the board and soldering them in place. Where replacement of the parts is necessary, such as in test fixtures or where programmable devices must be removed for changes, a DIP socket is used. Some sockets include a zero insertion force mechanism.
Variations of the DIP package include those with only a single row of pins, possibly including a heat sink tab in place of the second row of pins, and types with four rows of pins, two rows, staggered, on each side of the package. DIP packages have been mostly displaced by surface-mount package types, which avoid the expense of drilling holes in a printed circuit board and which allow higher density of interconnections.
Applications.
Types of devices.
DIPs are commonly used for integrated circuits (ICs). Other devices in DIP packages include resistor networks, DIP switches, LED segmented and bargraph displays, and electromechanical relays.
DIP connector plugs for ribbon cables are common in computers and other electronic equipment.
Dallas Semiconductor manufactured integrated DIP real-time clock (RTC) modules which contained an IC chip and a non-replaceable 10-year lithium battery.
DIP header blocks on to which discrete components could be soldered were used where groups of components needed to be easily removed, for configuration changes, optional features or calibration.
Uses.
The original dual-in-line package was invented by Bryant "Buck" Rogers in 1964 while working for Fairchild Semiconductor. The first devices had 14 pins and looked much like they do today. The rectangular shape allowed integrated circuits to be packaged more densely than previous round packages. The package was well-suited to automated assembly equipment; a printed circuit board could be populated with scores or hundreds of ICs, then all the components on the circuit board could be soldered at one time on a wave soldering machine and passed on to automated testing machines, with very little human labor required. DIP packages were still large with respect to the integrated circuits within them. By the end of the 20th century, surface-mount packages allowed further reduction in the size and weight of systems. DIP chips are still popular for circuit prototyping on a breadboard because of how easily they can be inserted and utilized there.
DIPs were the mainstream of the microelectronics industry in the 1970s and 80s. Their use has declined in the first decade of the 21st century due to the emerging new surface-mount technology (SMT) packages such as plastic leaded chip carrier (PLCC) and small-outline integrated circuit (SOIC), though DIPs continued in extensive use through the 1990s, and still continue to be used substantially as the year 2011 passes. Because some modern chips are available only in surface-mount package types, a number of companies sell various prototyping adapters to allow those SMT devices to be used like DIP devices with through-hole breadboards and soldered prototyping boards (such as stripboard and perfboard). (SMT can pose quite a problem, at least an inconvenience, for prototyping in general; most of the characteristics of SMT that are advantages for mass production are difficulties for prototyping.)
For programmable devices like EPROMs and GALs, DIPs remained popular for many years due to their easy handling with external programming circuitry (i.e., the DIP devices could be simply plugged into a socket on the programming device.) However, with In-System Programming (ISP) technology now state of the art, this advantage of DIPs is rapidly losing importance as well.
Through the 1990s, devices with fewer than 20 leads were manufactured in a DIP format in addition to the newer formats. Since about 2000, newer devices are often unavailable in the DIP format.
Mounting.
DIPs can be mounted either by through-hole soldering or in sockets. Sockets allow easy replacement of a device and eliminates the risk of damage from overheating during soldering. Generally sockets were used for high-value or large ICs, which cost much more than the socket. Where devices would be frequently inserted and removed, such as in test equipment or EPROM programmers, a zero insertion force socket would be used.
DIPs are also used with breadboards, a temporary mounting arrangement for education, design development or device testing. Some hobbyists, for one-off construction or permanent prototyping, use point-to-point wiring with DIPs, and their appearance when physically inverted as part of this method inspires the informal term "dead bug style" for the method.
Construction.
The body (housing) of a DIP containing an IC chip is usually made from molded plastic or ceramic. The hermetic nature of a ceramic housing is preferred for extremely high reliability devices. However, the vast majority of DIPs are manufactured via a thermoset molding process in which an epoxy mold compound is heated and transferred under pressure to encapsulate the device. Typical cure cycles for the resins are less than 2 minutes and a single cycle may produce hundreds of devices.
The leads emerge from the longer sides of the package along the seam, parallel to the top and bottom planes of the package, and are bent downward approximately 90 degrees (or slightly less, leaving them angled slightly outward from the centerline of the package body.) (The SOIC, the SMT package that most resembles a typical DIP, appears essentially the same, notwithstanding size scale, except that after being bent down the leads are bent upward again by an equal angle to become parallel with the bottom plane of the package.) In ceramic (CERDIP) packages, an epoxy or grout is used to hermetically seal the two halves together, providing an air and moisture tight seal to protect the IC die inside. Plastic DIP (PDIP) packages are usually sealed by fusing or cementing the plastic halves around the leads, but a high degree of hermeticity is not achieved because the plastic itself is usually somewhat porous to moisture and the process cannot ensure a good microscopic seal between the leads and the plastic at all points around the perimeter. However, contaminants are usually still kept out well enough that the device can operate reliably for decades with reasonable care in a controlled environment.
Inside the package, the lower half has the leads embedded, and at the center of the package is a rectangular space, chamber, or void into which the IC die is cemented. The leads of the package extend diagonally inside the package from their positions of emergence along the periphery to points along a rectangular perimeter surrounding the die, tapering as they go to become fine contacts at the die. Ultra-fine bond wires (barely visible to the naked human eye) are welded between these die periphery contacts and bond pads on the die itself, connecting one lead to each bond pad, and making the final connection between the microcircuits and the external DIP leads. The bond wires are not usually taut but loop upward slightly to allow slack for thermal expansion and contraction of the materials; if a single bond wire breaks or detaches, the entire IC may become useless. The top of the package covers all of this delicate assemblage without crushing the bond wires, protecting it from contamination by foreign materials.
Usually, a company logo, alphanumeric codes and sometimes words are printed on top of the package to identify its manufacturer and type, when it was made (usually as a year and a week number), sometimes where it was made, and other proprietary information (perhaps revision numbers, manufacturing plant codes, or stepping ID codes.)
The necessity of laying out all of the leads in a basically radial pattern in a single plane from the die perimeter to two rows on the periphery of the package is the main reason that DIP packages with higher lead counts must have wider spacing between the lead rows, and it effectively limits the number of leads which a practical DIP package may have. Even for a very small die with many bond pads (e.g. a chip with 15 inverters, requiring 32 leads), a wider DIP would still be required to accommodate the radiating leads internally. This is one of the reasons that four-sided and multiple rowed packages, such as PGAs, were introduced (around the early 1980s.)
A large DIP package (such as the DIP64 used for the Motorola 68000 CPU) has long leads inside the package between pins and the die, making such a package unsuitable for high speed devices.
Some other types of DIP devices are built very differently. Most of these have molded plastic housings and straight leads or leads that extend directly out of the bottom of the package. For some, LED displays particularly, the housing is usually a hollow plastic box with the bottom/back open, filled (around the contained electronic components) with a hard translucent epoxy material from which the leads emerge. Others, such as DIP switches, are composed of two (or more) plastic housing parts snapped, welded, or glued together around a set of contacts and tiny mechanical parts, with the leads emerging through molded-in holes or notches in the plastic.
Variants.
Several DIP variants for ICs exist, mostly distinguished by packaging material:
EPROMs were sold in ceramic DIPs manufactured with a circular window of clear quartz over the chip die to allow the part to be erased by ultraviolet light. Often, the same chips were also sold in less expensive windowless PDIP or CERDIP packages as one-time programmable (OTP) versions. Windowed and windowless packages were also used for microcontrollers, and other devices, containing EPROM memory. Windowed CERDIP-packaged EPROMs were used for the BIOS ROM of many early IBM PC clones with an adhesive label covering the window to prevent inadvertent erasure through exposure to ambient light.
Molded plastic DIPs are much lower in cost than ceramic packages; one 1979 study showed that a plastic 14 pin DIP cost around US 63 cents, and a ceramic package cost 82 cents.
Single in-line.
A single in-line (pin) package (SIP or SIPP) has one row of connecting pins. It is not as popular as the DIP, but has been used for packaging RAM chips and multiple resistors with a common pin. SIPs group RAM chips together on a small board either by the DIP process or surface mounting SMD process. The board itself has a single row of pin-leads that resembles a comb extending from its bottom edge, which plug into a special socket on a system or system-expansion board. SIPs are commonly found in memory modules. As compared to DIPs with a typical maximum I/O count of 64, SIPs have a typical maximum I/O count of 24 with lower package costs.
One variant of the single in-line package uses part of the lead frame for a heat sink tab. This multi-leaded power package is useful for such applications as audio power amplifiers, for example.
Quad in-line.
Rockwell used a quad in-line package with 42 leads formed into staggered rows for their PPS-4 microprocessor family introduced in 1973,
and other microprocessors and microcontrollers, some with higher lead counts, through the early 1990s.
The QIP, sometimes called a QIL package, has the same dimensions as a DIL package, but the leads on each side are bent into an alternating zigzag configuration so as to fit 4 lines of solder pads (instead of 2 with a DIL). The QIL design increased the spacing between solder pads without increasing package size, for two reasons:
Some QIL packaged ICs had added heatsinking tabs, such as the HA1306.
Intel and 3M developed the ceramic leadless quad in-line package (QUIP), introduced in 1979, to boost microprocessor density and economy. The ceramic leadless QUIP is not designed for surface-mount use, and requires a socket. It was used by Intel for the iAPX 432 microprocessor chip set, and by Zilog for the Z8-02 external-ROM prototyping version of the Z8 microcontroller.
Lead count and spacing.
Commonly found DIP packages that conform to JEDEC standards use an inter-lead spacing (lead pitch) of 0.1 inch (2.54 mm). Row spacing varies depending on lead counts, with 0.3 in. (7.62 mm)(JEDEC MS-001) or 0.6 inch (15.24 mm)(JEDEC MS-011) the most common. Less common standardized row spacings include 0.4 inch (10.16 mm)(JEDEC MS-010) and 0.9 inch (22.86 mm), as well as a row spacing of 0.3 inch, 0.6 inch or 0.75 inch with a 0.07 inch (1.778 mm) lead pitch.
The former Soviet Union and Eastern bloc countries used similar packages, but with a metric inter-lead spacing of 2.5 mm rather than 2.54 mm (0.1 inch).
The number of leads is always even. For 0.3 inch spacing, typical lead counts are 8, 14, 16, 18, and 28; less common are 4, 6, 20, and 24 lead counts. For 0.6 inch spacing, typical lead counts are 24, 28, 32, and 40; less common are 36, 48, 52, and 64 lead counts. Some microprocessors, such as the Motorola 68000 and Zilog Z180, used lead counts as high as 64; this is typically the maximum number of leads for a DIP package.
Orientation and lead numbering.
As shown in the diagram, leads are numbered consecutively from Pin 1. When the identifying notch in the package is at the top, Pin 1 is the top left corner of the device. Sometimes Pin 1 is identified with an indent or paint dot mark.
For example, for a 14-lead DIP, with the notch at the top, the left leads are numbered from 1 to 7 (top to bottom) and the right row of leads are numbered 8 to 14 (bottom to top).
Some DIP devices, such as segmented LED displays, or those that replace leads with a heat sink fin, skip some leads; the remaining leads are numbered as if all positions had leads.
In addition to providing for human visual identification of the orientation of the package, the notch allows automated chip-insertion machinery to confirm correct orientation of the chip by mechanical sensing.
Descendants.
The SOIC (Small Outline IC), a surface-mount package which is currently very popular, particularly in consumer electronics and personal computers, is essentially a shrunk version of the standard IC PDIP, the fundamental difference which makes it an SMT device being a second bend in the leads to flatten them parallel to the bottom plane of the plastic housing. The SOJ (Small Outline J-lead) and other SMT packages with "SOP" (for "Small Outline Package") in their names can be considered further relatives of the DIP, their original ancestor. SOIC packages tend to have half the pitch of DIP, and SOP are half that, a fourth of DIP. (0.1"/2.54mm, 0.05"/1.27mm, and 0.025"/0.635mm, respectively)
Pin grid array (PGA) packages may be considered to have evolved from the DIP. PGAs with the same 0.1 inch pin centers as most DIPs were popular for microprocessors from the early to mid-1980s through the 1990s. Owners of personal computers containing Intel 80286 through P5 Pentium processors may be most familiar with these PGA packages, which were often inserted into ZIF sockets on motherboards. The similarity is such that a PGA socket may be physically compatible with some DIP devices, though the converse is rarely true.

</doc>
<doc id="41075" url="https://en.wikipedia.org/wiki?curid=41075" title="Duct">
Duct

A duct may refer to:

</doc>
<doc id="41077" url="https://en.wikipedia.org/wiki?curid=41077" title="Duplexer">
Duplexer

A duplexer is an electronic device that allows bi-directional (duplex) communication over a single path. In radar and radio communications systems, it isolates the receiver from the transmitter while permitting them to share a common antenna. Most radio repeater systems include a duplexer. Duplexers can be based on frequency (often a waveguide filter), polarization (such as an orthomode transducer), or timing (as is typical in radar).
Types.
Transmit-receive switch.
In radar, a transmit/receive (TR) switch alternately connects the transmitter and receiver to a shared antenna. In the simplest arrangement, the switch consists of a gas-discharge tube across the input terminals of the receiver. When the transmitter is active, the resulting high voltage causes the tube to conduct, shorting together the receiver terminals to protect it, while its complementary, the anti-transmit/receive (ATR) switch, is a similar discharge tube which decouples the transmitter from the antenna while not operating, to prevent it from wasting received energy.
Frequency domain.
In radio communications (as opposed to radar), the transmitted and received signals can occupy different frequency bands, and so may be separated by frequency-selective filters. See diplexer.
"Note 1:" A duplexer must be designed for operation in the frequency band used by the receiver and transmitter, and must be capable of handling the output power of the transmitter.
"Note 2:" A duplexer must provide adequate rejection of transmitter noise occurring at the receive frequency, and must be designed to operate at, or less than, the frequency separation between the transmitter and receiver.
"Note 3:" A duplexer must provide sufficient isolation to prevent receiver desensitization.
Source: from Federal Standard 1037C

</doc>
<doc id="41078" url="https://en.wikipedia.org/wiki?curid=41078" title="Duty cycle">
Duty cycle

A duty cycle is the percentage of one period in which a signal or system is active. A period is the time it takes for a signal to complete an on-and-off cycle. As a formula, a duty cycle may be expressed as:
where formula_2 is the duty cycle, formula_3 is the time the signal is active, and formula_4 is the total period of the signal. Thus, a 60% duty cycle means the signal is on 60% of the time but off 40% of the time. The "on time" for a 60% duty cycle could be a fraction of a second, a day, or even a week, depending on the length of the period.
Duty cycles can be used to describe the percent time of an active signal in an electrical device such as the power switch in a switching power supply or the firing of action potentials by a living system such as a neuron.
The duty factor for periodic signal expresses the same notion, but is usually scaled to a maximum of one rather than 100%.
Applications.
Electrical devices.
Electrical motors typically use less than a 100% duty cycle. For example, if a motor runs for one out of 100 seconds, or 1/100 of the time, then, its duty cycle is 1/100, or 1 percent. 
Pulse-width modulation (PWM) is used in a variety of electronic situations, such as power delivery and voltage regulation. 
In electronic music, music synthesizers vary the duty cycle of their audio-frequency oscillators to obtain a subtle effect on the tone colors. This technique is known as pulse-width modulation.
In the printer / copier industry, the duty cycle specification refers to the rated throughput (that is, printed pages) of a device per month.
In a welding power supply, the maximum duty cycle is defined as the percentage of time in a 10-minute period that it can be operated continuously before overheating.
Biological systems.
The concept of duty cycles is also used to describe the activity of neurons and muscle fibers. In a neural network for example, a duty cycle specifically refers to the proportion of a cycle period in which a neuron remains active. 
Generation.
One way to generate fairly accurate square wave signals with 1/"n" duty factor, where "n" is an integer, is to vary the duty cycle until the "n"th-harmonic is significantly suppressed. For audio-band signals, this can even be done "by ear"; for example, a -40dB reduction in the 3rd harmonic corresponds to setting the duty factor to 1/3 with a precision of 1% and -60dB reduction corresponds to a precision of 0.1%.

</doc>
<doc id="41079" url="https://en.wikipedia.org/wiki?curid=41079" title="Dynamic range">
Dynamic range

Dynamic range, abbreviated DR or DNR, is the ratio between the largest and smallest values of a changeable quantity, such as in signals like sound and light.
Definition.
Dynamic range is the difference between the smallest and largest usable signal through a transmission or processing chain or storage medium. It is measured as a ratio, or as a base-10 (decibel) or base-2 (doublings, bits or stops) logarithmic value.
Dynamic range and human perception.
The human senses of sight and hearing have a very high dynamic range. A human is capable of hearing (and usefully discerning) anything from a quiet murmur in a soundproofed room to the sound of the loudest heavy metal concert. Such a difference can exceed 100 dB which represents a factor of 100,000 in amplitude and a factor 10,000,000,000 in power. A human can see objects in starlight (although colour differentiation is reduced at low light levels) or in bright sunlight, even though on a moonless night objects receive 1/1,000,000,000 of the illumination they would on a bright sunny day: that is a dynamic range of 90 dB.
A human cannot perform these feats of perception at both extremes of the scale at the same time. The eyes take time to adjust to different light levels, and the dynamic range of the human eye in a given scene is actually quite limited due to optical glare. The instantaneous dynamic range of human audio perception is similarly subject to masking so that, for example, a whisper cannot be heard in loud surroundings.
In practice, it is difficult to achieve the full dynamic range experienced by humans using electronic equipment. Electronically reproduced audio and video often uses some trickery to fit original material with a wide dynamic range into a narrower recorded dynamic range that can more easily be stored and reproduced; these techniques are called dynamic range compression. For example, a good quality LCD display has a dynamic range of around 1000:1 (commercially the dynamic range is often called the "contrast ratio" meaning the full-on/full-off luminance ratio), and some of the latest CMOS image sensors now have measured dynamic ranges of about 23,000:1 (reported as 14.5 stops, or doublings, equivalent to binary bits). Paper reflectance can achieve a dynamic range of about 100:1. A professional ENG camcorder such as the Sony Digital Betacam achieves a dynamic range of greater than 90dB in audio recording.
When showing a movie or a game, a display is able to show both shadowy nighttime scenes and bright outdoor sunlit scenes, but in fact the level of light coming from the display is much the same for both types of scene (perhaps different by a factor of 10). Knowing that the display does not have a huge dynamic range, the program makers do not attempt to make the nighttime scenes millions of times less bright than the daytime scenes, but instead use other cues to suggest night or day. A nighttime scene will usually contain duller colours and will often be lit with blue lighting, which reflects the way that the human eye sees colours at low light levels.
Examples of usage.
Audio.
Audio engineers often use "dynamic range" to describe the ratio of the amplitude of the loudest possible undistorted sine wave to the root mean square (rms) noise amplitude, say of a microphone or loudspeaker.
The dynamic range of human hearing is roughly 140 dB, varying with frequency, from the threshold of hearing (around −9 dB SPL at 3 kHz) to the threshold of pain (from 120–140 dB SPL). This wide dynamic range cannot be perceived all at once, however; the tensor tympani, stapedius muscle, and outer hair cells all act as mechanical dynamic range compressors to adjust the sensitivity of the ear to different ambient levels.
The dynamic range of music as normally perceived in a concert hall doesn't exceed 80 dB, and human speech is normally perceived over a range of about 40 dB.
The dynamic range differs from the ratio of the maximum to minimum amplitude a given device can record, as a properly dithered recording device can record signals well below the noise RMS amplitude (noise floor).
For example, if the ceiling of a device is 5V (rms) and the noise floor is 10µV (rms) then the dynamic range is 500000:1, or 114 dB:
In digital audio theory the dynamic range is limited by quantization error. The maximum achievable dynamic range for a digital audio system with "Q"-bit uniform quantization is calculated as the ratio of the largest sine-wave rms to rms noise is:
The maximum achievable signal-to-noise ratio (SNR) for a digital audio system with "Q"-bit uniform quantization is
The 16-bit compact disc has a theoretical undithered dynamic range of about 96 dB, however, the "perceived" dynamic range of 16-bit audio can be 120 dB or more with noise-shaped dither, taking advantage of the frequency response of the human ear.
Digital audio with undithered 20-bit digitization is theoretically capable of 120 dB dynamic range. 24-bit digital audio calculates to 144 dB dynamic range. Most Digital audio workstations process audio with 32-bit floating-point representation which affords even higher dynamic range and so loss of dynamic range is no longer a concern in terms of digital audio processing. Low dynamic range audio mixes typically result from improper gain staging, imperfections in the analog-to-digital and digital-to-analog conversions, recording technique including ambient noise and intentional application of dynamic range compression.
Dynamic range in analog audio is the difference between low-level thermal noise in the electronic circuitry and high-level signal saturation resulting in increased distortion and, if pushed higher, clipping. Multiple noise processes determine the noise floor of a system. Noise can be picked up from microphone self-noise, preamp noise, wiring and interconnection noise, media noise, etc.
Early 78 rpm phonograph discs had a dynamic range of up to 40 dB, soon reduced to 30 dB and worse due to wear from repeated play. Vinyl microgroove phonograph records typically yield 55-65 dB, though the first play of the higher-fidelity outer rings can achieve a dynamic range of 70 dB.
German magnetic tape in 1941 was reported to have had a dynamic range of 60 dB, though modern day restoration experts of such tapes note 45-50 dB as the observed dynamic range. Ampex tape recorders in the 1950s achieved 60 dB in practical usage, though tape formulations such as Scotch 111 boasted 68 dB dynamic range. In the 1960s, improvements in tape formulation processes resulted in 7 dB greater range, and Ray Dolby developed the Dolby A-Type noise reduction system that increased low- and mid-frequency dynamic range on magnetic tape by 10 dB, and high-frequency by 15 dB, using companding (compression and expansion) of four frequency bands. The peak of professional analog magnetic recording tape technology reached 90 dB dynamic range in the midband frequencies at 3% distortion, or about 80 dB in practical broadband applications. The Dolby SR noise reduction system gave a 20 dB further increased range resulting in 110 dB in the midband frequencies at 3% distortion. Compact Cassette tape performance ranges from 50 to 56 dB depending on tape formulation, with Metal Type IV tapes giving the greatest dynamic range, and systems such as XDR, dbx and Dolby noise reduction system increasing it further. Specialized bias and record head improvements by Nakamichi and Tandberg combined with Dolby C noise reduction yielded 72 dB dynamic range for the cassette.
The rugged elements of moving-coil microphones can have a dynamic range of up to 140 dB (at increased distortion), while condenser microphones are limited by the overloading of their associated electronic circuitry. Practical considerations of acceptable distortion levels in microphones combined with typical practices in a recording studio result in a useful operating range of 125 dB.
In 1981, researchers at Ampex determined that a dynamic range of 118 dB on a dithered digital audio stream was necessary for subjective noise-free playback of music in quiet listening environments.
Since the early 1990s, it has been recommended by several authorities, including the Audio Engineering Society, that measurements of dynamic range be made with an audio signal present, which is then filtered out to get the noise floor. This avoids questionable measurements based on the use of blank media, or muting circuits.
Electronics.
Electronics engineers apply the term to: 
Metrology.
In metrology, such as when performed in support of science, engineering or manufacturing objectives, dynamic range refers to the range of values that can be measured by a sensor or metrology instrument. Often this dynamic range of measurement is limited at one end of the range by saturation of a sensing signal sensor or by physical limits that exist on the motion or other response capability of a mechanical indicator. The other end of the dynamic range of measurement is often limited by one or more sources of random noise or uncertainty in signal levels that may be described as the defining the sensitivity of the sensor or metrology device. When digital sensors or sensor signal converters are a component of the sensor or metrology device, the dynamic range of measurement will be also related to the number of binary digits (bits) used in a digital numeric representation in which the measured value is linearly related to the digital number. For example, a 12-bit digital sensor or converter can provide a dynamic range in which the ratio of the maximum measured value to the minimum measured value is up to 212 = 4096. With gamma correction, this limitation can be relaxed somewhat; for example, the 8-bit encoding used in sRGB image encoding represents a maximum to minimum ratio of about 3000.
Metrology systems and devices may use several basic methods to increase their basic dynamic range. These methods include averaging and other forms of filtering, repetition of measurements, nonlinear transformations to avoid saturation, etc. In more advance forms of metrology, such as multiwavelength digital holography, interferometry measurements made at different scales (different wavelengths) can be combined to retain the same low-end resolution while extending the upper end of the dynamic range of measurement by orders of magnitude.
Music.
In music, "dynamic range" is the difference between the quietest and loudest volume of an instrument, part or piece of music. In modern recording, this range is often limited through dynamic range compression, which allows for louder volume, but can make the recording sound less exciting or live.
The term "dynamic range" may be confusing in music because it has two conflicting definitions, particularly in the understanding of the loudness war phenomenon. "Dynamic range" may refer to micro-dynamics, related to crest factor, whereas the European Broadcasting Union, in EBU3342 Loudness Range, defines "dynamic range" as the difference between the quietest and loudest volume, a matter of macro-dynamics.
Photography.
Photographers use "dynamic range" for the luminance range of a scene being photographed, or the limits of luminance range that a given digital camera or film can capture,
Graduated neutral density filters are used to decrease the dynamic range of scene luminance that can be captured on photographic film (or on the image sensor of a digital camera): The filter is positioned in front of the lens at the time the exposure is made; the top half is dark and the bottom half is clear. The dark area is placed over a scene's high-intensity region, such as the sky. The result is more even exposure in the focal plane, with increased detail in the shadows and low-light areas. Though this doesn't increase the fixed dynamic range available at the film or sensor, it stretches usable dynamic range in practice.
The dynamic range of sensors used in digital photography is many times less than that of the human eye and generally not as wide as that of chemical photographic media. In the domain of digital imaging, algorithms have been developed to map the image differently in shadow and in highlight in order to better distribute the lighting range across the image. These techniques are known as local tone mapping, and usually involves overcoming the limited dynamic range of the sensor array by selectively combining multiple exposures of the same scene in order to retain detail in light and dark areas. The same approach has been used in chemical photography to capture an extremely wide dynamic range: A three-layer film with each underlying layer at 1/100 the sensitivity of the next higher one has, for example, been used to record nuclear-weapons tests.
The most severe dynamic-range limitation in photography may not involve encoding, but rather reproduction to, say, a paper print or computer screen. In that case, not only local tone mapping, but also "dynamic range adjustment" can be effective in revealing detail throughout light and dark areas: The principle is the same as that of dodging and burning (using different lengths of exposures in different areas when making a photographic print) in the chemical darkroom. The principle is also similar to gain riding or automatic level control in audio work, which serves to keep a signal audible in a noisy listening environment and to avoid peak levels which overload the reproducing equipment, or which are unnaturally or uncomfortably loud.

</doc>
<doc id="41081" url="https://en.wikipedia.org/wiki?curid=41081" title="Echo (mythology)">
Echo (mythology)

In Greek mythology, Echo (; , "Ēkhō", "echo", from ἦχος ("ēchos"), "sound") was an Oread who resided on Mount Cithaeron. Zeus loved consorting with beautiful nymphs and often visited them on Earth. Eventually, Zeus's wife, Hera, became suspicious, and came from Mt. Olympus in an attempt to catch Zeus with the nymphs. Echo, by trying to protect Zeus, endured Hera's wrath, and Hera made her only able to speak the last few words spoken to her. So when Echo met Narcissus and fell in love with him, she was unable to tell him how she felt and was forced to watch him as he fell in love with himself.
Classical Depiction.
Metamorphoses.
In Metamorphoses, the poet Ovid tells of Juno (Hera in Greek mythology) and the jealousy she felt towards her husband Jupiter (Zeus in Greek mythology) for his many affairs. Though vigilant, whenever she was about to catch him, Echo distracted her with lengthy conversations. When at last Juno realized the truth, she cursed Echo. From that moment on, the once loquacious nymph could only repeat the most recently spoken words of another person.
Sometime after being cursed, Echo spied a young man, Narcissus, while he was out hunting deer with his companions. She immediately fell in love with him and, infatuated, followed quietly. The more she looked at the young man, the more she longed for him. Though she wished with all her heart to call out to Narcissus, Juno's curse prevented her.
During the hunt, Narcissus became separated from his companions and called out, ‘is anyone there’ only for Echo to repeat his words. Startled Narcissus answered the voice, ‘come here’, only to be told the same. When Narcissus saw that nobody had emerged from the glade he concluded that the owner of the voice must be running away from him and called out again. Finally he shouted, "This way, we must come together." Taking this to be a reciprocation of her love, Echo concurred ecstatically, "We must come together!"
In her delight, Echo rushed to Narcissus ready to throw her arms around her beloved. Narcissus, however, was appalled and, spurning her, exclaimed, ‘Hands off! May I die before you enjoy my body.’ All Echo could whisper in reply was, ‘enjoy my body’ and having done so she fled, scorned, humiliated, and shamed.
Despite the harshness of her rejection, Echo’s love for Narcissus only grew. When Narcissus died, wasting away before his own reflection, consumed by a love that could not be, Echo mourned over his body. When Narcissus, looking one last time into the pool uttered, "Oh marvellous boy, I loved you in vain, farewell", Echo too chorused, "Farewell."
Eventually, Echo, too, began to waste away. Her beauty faded, her skin shrivelled, and her bones turned to stone. Today, all that remains of Echo is the sound of her voice.
Daphnis and Chloe.
The tale of Daphnis and Chloe is a 2nd-century romance by Greek author Longus. At one point in the novel, Daphnis and Chloe are staring out at the boats gliding across the sea. Chloe, having never heard an echo before, is confused on hearing the fisherman’s song repeated in a nearby valley. Daphnis promises to tell her the story of Echo in exchange for ten more kisses.
Daphnis’ rendition differs radically from Ovid’s account. According to Daphnis, Echo was raised among the Nymphæ because her mother was a nymph. Her father, however, was merely a man and hence Echo was not herself a nymph but mortal. Echo spent her days dancing with the Nymphæ and singing with the Muses who taught her all manner of musical instruments. Pan then grew angry with her, envious of her musical virtuosity and covetous of her virginity, which she would yield neither to men nor gods. Pan drove the men of the fields mad, and, like wild animals, they tore Echo apart and scattered the still singing fragments of her body across the earth.
Showing favour to the Nymphæ, Gaia hid the shreds of Echo within herself providing shelter for her music, and, at the Muses’ command, Echo’s body will still sing, imitating with perfect likeness the sound of any earthly thing. Daphnis recounts that Pan himself oft hears his very own pipes and, giving chase across the mountains, looks in vain for the secret student he can never find.
Other.
Both the Homeric and Orphic Hymns to Pan reiterate Longus’ tale of Pan chasing Echo’s secret voice across the mountains.
Codex 190 of Photius' Bibliotheca states that Pan's unrequited love for Echo was placed there by Aphrodite, angry at his verdict in a beauty contest.
Nonnus’ Dionysiaca contains a number of references to Echo. In Nonnus’ account, though Pan frequently chased Echo, he never won her affection. Book VI also makes reference to Echo in the context of the Great Deluge. Nonnus states that the waters rose so far that even high on the hills Echo was forced to swim. Having escaped the advances of Pan, she feared now the lust of Poseidon.
Whereas Nonnus is adamant that Pan never wins Echo, in Apuleius' The Golden Ass Pan is described with Echo in his arms, teaching the nymph to repeat all manner of songs. Similarly in the Suda Echo is described as bearing Pan a child, Lynx. Other fragments mention a second daughter, Lambe.
Medieval Depiction.
The Lay of Narcissus.
The Lay of Narcissus, one of many titles by which the work is known, is Norman-French verse narrative written towards the end of the 12th century. In the four manuscripts that remain, an unknown author borrows from the Echo and Narcissus of Ovid to create a story better suited to the needs of his time.
This medieval account alters the characters of both Echo and Narcissus. In Ovid’s account Echo is a beautiful nymph residing with the Muses, and Narcissus is a haughty prince. In the Lay of Narcissus, Echo is replaced by the princess Dané. Conversely, Narcissus loses the royal status he bore in Ovid's account: in this rendition he is no more than a commoner, a vassal of Dané’s father, the King.
In the Lay, Dané is pierced by the arrows of Amor and falls madly in love with Narcissus. Though aware that she should first consult her father Dané, she nonetheless shares her feelings with Narcissus. Despite her emphasising her royal lineage, Narcissus spurns her just as he spurns and flees from all women.
Humiliated, Dané calls out to Amor, and, in response, the god curses Narcissus. In a classic example of poetic justice, Narcissus is forced to suffer the same pain he inflicted on others, namely the pain of unrequited love. The vehicle of this justice is a pool of water in which Narcissus falls in love with his own reflection, which he at first mistakes for a woman. Deranged by lust, Dané searches for Narcissus, naked but for a cloak, and finds him at the point of death. Devastated, Dané repents ever calling to Amor. Dané expresses her love for the last time, pulls close to her beloved and dies in his arms. The poet warns men and women alike not to disdain suitors lest they suffer a similar fate.
While Ovid’s story is still recognisable, many of the details have changed considerably. Almost all references to pagan deities are gone, save Amor who is little more than a personification of love. Narcissus is demoted to the status of a commoner while Echo is elevated to the status of princess. Allusions to Narcissus’ homosexuality are expunged. While Ovid talks of Narcissus' disdain for both male and female suitors, the Lay only mentions his hatred of women. Similarly, in the Lay, Narcissus mistakes his reflection for that of a woman, whereas no mention is made of this in Ovid’s account. Finally, the tale is overtly moralized with messages about courtly love. Such exhortations were entirely absent from the Metamorphoses rendition.
The Romance of the Rose.
The Romance of the Rose is a medieval French poem, the first section of which was written by Guillaume de Lorris in around 1230 C.E. The poem was completed by Jean de Meun in around 1275 C.E. Part of a much larger narrative, the tale of Echo and Narcissus is relayed when the central figure stumbles across the pool wherein Narcissus first glimpsed his own reflection.
In this rendition, Echo is not a nymph, or a princess, but a noble lady. She fell madly in love with Narcissus, so much so that she declared that she would die should he fail to love her in turn. Narcissus refuses, not because he despises all women, but merely because he is haughty and excessively proud of his own beauty.
Guillaume relays that on hearing Narcissus’ rejection, Echo’s grief and anger were so great that she died at once. However, in a similar vein to the Lay of Narcissus, just before she dies, Echo calls out to Deus. She asks that Narcissus might one day be tormented by unrequited love as she had been, and, in so doing, understand how the spurned suffer.
As in the classical myth, Narcissus comes across a pool following a hunt. Though Echo prayed to Deus, and the tale notes that he answered her prayer, it is Amor who waits for Narcissus by the water. Amor causes Narcissus his fall for his own reflection, leading quickly to his death. The tale makes clear that this is not merely justice for Echo, but also punishment for Narcissus’ slight against love itself.
The tale concludes with an exhortation to all women warning them that, should they scorn their lovers, God will repay the offence.
Guillaume’s rendition builds on the themes of courtly love emphasised in the Lay and moves further away from Ovid’s initial account. The curse of Athena is absent entirely, and the tale is overtly moralised. Unlike in the Lay, however, this moral message is aimed solely at women; this despite the fact that the offending behaviour is perpetrated by Narcissus not Echo.

</doc>
<doc id="41082" url="https://en.wikipedia.org/wiki?curid=41082" title="Effective data transfer rate">
Effective data transfer rate

In telecommunication, effective data transfer rate is the average number of units of data, such as bits, characters, blocks, or frames, transferred per unit time from a source and accepted as valid by a sink.
"Note:" The effective data transfer rate is usually expressed in bits, characters, blocks, or frames per second. The effective data transfer rate may be averaged over a period of seconds, minutes, or hours.

</doc>
<doc id="41084" url="https://en.wikipedia.org/wiki?curid=41084" title="Effective height">
Effective height

In telecommunication, the effective height of an antenna is the height of the antenna's center of radiation above the ground. It is defined as the ratio of the induced voltage to the incident field .
In low-frequency applications involving loaded or nonloaded vertical antennas, the effective height is the moment of the current distribution in the vertical section, divided by the input current. For an antenna with a symmetrical current distribution, the center of radiation is the center of the distribution. For an antenna with asymmetrical current distribution, the center of radiation is the center of current moments when viewed from points near the direction of maximum radiation.

</doc>
<doc id="41085" url="https://en.wikipedia.org/wiki?curid=41085" title="Effective input noise temperature">
Effective input noise temperature

In telecommunications, effective input noise temperature is the source noise temperature in a two-port network or amplifier that will result in the same output noise power, when connected to a noise-free network or amplifier, as that of the actual network or amplifier connected to a noise-free source. If "F" is the noise figure numeric and 290 K the standard noise temperature, then the effective noise temperature is given by "T" n = 290("F"-1).

</doc>
<doc id="41086" url="https://en.wikipedia.org/wiki?curid=41086" title="Effective mode volume">
Effective mode volume

For an optical fiber, the effective mode volume is the square of the product of the diameter of the near-field pattern and the sine of the radiation angle of the far-field pattern. The diameter of the near-field radiation pattern is defined here as the full width at half maximum and the radiation angle at half maximum radiant intensity. Effective mode volume is proportional to the breadth of the relative distribution of power amongst the modes in a multimode fiber. It is not truly a spatial volume but rather an ""optical volume"" equal to the product of area and solid angle. The power divided by the effective mode volume is proportional to the radiance of the light emitted by the fiber.

</doc>
<doc id="41088" url="https://en.wikipedia.org/wiki?curid=41088" title="Effective transmission rate">
Effective transmission rate

In telecommunications, effective transmission rate (average rate of transmission, effective speed of transmission) is the rate at which information is processed by a transmission facility. 

</doc>
<doc id="41089" url="https://en.wikipedia.org/wiki?curid=41089" title="Efficiency factor">
Efficiency factor

Efficiency factor is a ratio of some measure of performance to an expected value.
Data communication.
In data communications, the factor is the ratio of the time to transmit a text automatically at a specified modulation rate to the time actually required to receive the same text at a specified maximum error rate. All of the communication facilities are assumed to be in the normal condition of adjustment and operation. The practical conditions of measurement should be specified, especially the duration of the measurement.
Telegraph communications may have different temporal efficiency factors for the two directions of transmission.
Industrial engineering.
In industrial engineering, the efficiency factor is the relationship between the allowance time and the time taken, in the form of percentage.
Efficiency factors are used in performance rating and remuneration calculation exercises. The efficiency factor is an extremely simple to use and readily comprehensible index, the prerequisite being exact time management for maintaining the allowed times.

</doc>
<doc id="41091" url="https://en.wikipedia.org/wiki?curid=41091" title="Electrical length">
Electrical length

In telecommunications and electrical engineering, electrical length (or phase length)
refers to the length of an electrical conductor in terms of the phase shift introduced by transmission over that conductor at some frequency.
Usage of the term.
Depending on the specific usage, the term "electrical length" is used rather than simple physical length to incorporate one or more of the following three concepts:
Phase length.
The first usage of the term "electrical length" assumes a sine wave of some frequency, or at least a narrowband waveform centered around some frequency "f". The sine wave will repeat with a period of "T" = 1/"f". The frequency "f" will correspond to a particular wavelength λ along a particular conductor. For conductors (such as bare wire or air-filled coax) which transmit signals at the speed of light "c", the wavelength is given by λ="c"/"f". A distance "L" along that conductor corresponds to "N" wavelengths where "N"= "L" / λ.
In the figure at the right, the wave shown is seen to be "N"=1.5 wavelengths long. A wave crest at the beginning of the graph, moving towards the right, will arrive at the end after a time 1.5"T". The "electrical length" of that segment is said to be "1.5 wavelengths" or, expressed as a phase angle, "540°" (or 3π radians) where "N" wavelengths corresponds to φ = 360°•"N" (or φ = 2π•"N" radians). In radio frequency applications, when a delay is introduced due to a transmission line, it is often the phase shift φ that is of importance, so specifying a design in terms of the phase or electrical length allows one to adapt that design to an arbitrary frequency by employing the wavelength λ applying to that frequency.
Velocity factor.
In a transmission line, a signal travels at a rate controlled by the effective capacitance and inductance per unit of length of the transmission line. Some transmission lines consist only of bare conductors, in which case their signals propagate at the speed of light, "c". More often the signal travels at a reduced velocity κ"c", where κ is the "velocity factor", a number less than 1 representing the ratio of that velocity to the speed of light.
Most transmission lines contain a dielectric material (insulator) filling some or all of the space in between the conductors. The relative permittivity or "dielectric constant" of that material increases the distributed capacitance in the cable, which reduces the velocity factor below unity. It is also possible for κ to be reduced due to a relative permeability of that material which increases the distributed inductance, but this is almost never the case. Now, if one fills a space with a dielectric of relative permittivity formula_1, then the velocity of an electromagnetic plane wave is reduced by the velocity factor:
This reduced velocity factor would also apply to propagation of signals along wires immersed in a large space filled with that dielectric. However with only part of the space around the conductors filled with that dielectric, there is less reduction of the wave velocity. Part of the electromagnetic wave surrounding each conductor "feels" the effect of the dielectric, and part is in free space. Then it is possible to define an "effective relative permittivity" formula_3 which then predicts the velocity factor according to
formula_3 is computed as a weighted average of the relative permittivity of free space (1) and that of the dielectric:
where the "fill factor" F expresses the effective proportion of space so affected by the dielectric.
In the case of coaxial cable, where all of the volume in between the inner conductor and the shield is filled with a dielectric, the fill factor is unity, since the electromagnetic wave is confined to that region. In other types of cable, such as twin lead, the fill factor can be much smaller. Regardless, any cable intended for radio frequencies will have its velocity factor (as well as its characteristic impedance) specified by the manufacturer. In the case of coaxial cable, where F=1, the velocity factor is solely determined by the sort of dielectric used as specified here.
For example, a typical velocity factor for coaxial cable is .66, corresponding to a dielectric constant of 2.25. Suppose we wish to send a 30 MHz signal down a short section of such a cable, and delay it by a quarter wave (90°). In free space, this frequency corresponds to a wavelength of λ0=10m, so a delay of .25λ would require an "electrical length" of 2.5 m. Applying the velocity factor of .66, this results in a "physical" length of cable 1.67 m long.
The velocity factor likewise applies to antennas in cases where the antenna conductors are (partly) surrounded by a dieletric. This particularly applies to microstrip antennas such as the patch antenna. Waves on microstrip are affected by the dielectric of the circuit board beneath them, but not the air above them. Their velocity factors thus depend not directly on the permittivity of the circuit board material but on the "effective" permittivity formula_3 which is often specified for a circuit board material (or can be calculated). Note that the fill factor and therefore formula_3 are somewhat dependent on the width of the trace compared to the thickness of the board.
Antennas.
While there are certain wideband antenna designs, many antennas are classified as resonant and perform according to design around a particular frequency. This applies especially to broadcasting stations and communication systems which are confined to one frequency or narrow frequency band. This includes the dipole and monopole antennas and all of the designs based on them (Yagi, dipole or monopole arrays, folded dipole, etc.). In addition to the directive gain in beam antennas suffering away from the design frequency, the antenna feedpoint impedance is very sensitive to frequency offsets. Especially for transmitting, the antenna is often intended to operate at the resonant frequency. At the resonant frequency, by definition, that impedance is a pure resistance which matches the characteristic impedance of the transmission line and the output (or input) impedance of the transmitter (or receiver). At frequencies away from the resonant frequency, the impedance includes some reactance (capacitance or inductance). It is possible for an antenna tuner to be used to cancel that reactance (and to change the resistance to match the transmission line), however that is often avoided as an extra complication (and needs to be controlled at the antenna side of the transmission line).
The condition for resonance in a monopole antenna is for the element to be an odd multiple of a quarter-wavelength, "λ"/4. In a dipole antenna both driven conductors must be that long, for a total dipole length of "(2N+1)λ"/2.
The electrical length of an antenna element is, in general, different from its physical length
For example, increasing the diameter of the conductor, or the presence of nearby metal objects, will decrease the velocity of the waves in the element, increasing the electrical length.
An antenna which is shorter than its resonant length is described as ""electrically short"", and exhibits capacitive reactance. Similarly, an antenna which is longer than its resonant length is described as ""electrically long"" and exhibits inductive reactance.
Changing electrical length by loading.
An antenna's effective electrical length can be changed without changing its physical length by adding reactance, (inductance or capacitance) in series with it. This is called "lumped-impedance matching" or "loading".
For example, a monopole antenna such as a metal rod fed at one end, will be resonant when its electrical length is equal to a quarter wavelength, "λ"/4, of the frequency used. If the antenna is shorter than a quarter wavelength, the feedpoint impedance will include capacitive reactance; this causes reflections on the feedline and a mismatch at the transmitter or receiver, even if the resistive component of the impedance is correct. To cancel the capacitive reactance, an inductance, called a loading coil, is inserted in between the feedline and the antenna terminal. Selecting an inductance with the same reactance as the (negative) capacitative reactance seen at the antenna terminal, cancels that capacitance, and the "antenna system" (antenna and coil) will again be resonant. The feedline sees a purely resistive impedance. Since an antenna which had been too short now appears as if it were resonant, the addition of the loading coil is sometimes referred to as "electrically lengthening" the antenna.
Similarly, the feedpoint impedance of a monopole antenna longer than "λ"/4 (or a dipole with arms longer than "λ"/4) will include inductive reactance. A capacitor in series with the antenna can cancel this reactance to make it resonant, which can be referred to as "electrically shortening" the antenna.
Inductive loading is widely used to reduce the length of whip antennas on portable radios such as walkie-talkies and short wave antennas on cars, to meet physical requirements.
Advantages.
The electrical lengthening allows the construction of shorter aerials. It is applied in particular for aerials for VLF, longwave and medium-wave transmitters. Because those radio waves are several hundred meters to many kilometers long, mast radiators of the necessary height cannot be realised economically. It is also used widely for whip antennas on portable devices such as walkie-talkies to allow antennas much shorter than the standard quarter-wavelength to be used. The most widely used example is the rubber ducky antenna.
Disadvantages.
The electrical lengthening reduces the bandwidth of the antenna if other phase control measures are not undertaken. An electrically extended aerial is less efficient than a non-extended antenna.
Technical realization.
There are two possibilities for the realisation of the electric lengthening.
Often both measures are combined. The coils switched in series must sometimes be placed in the middle of the aerial construction. The cabin installed at a height of 150-metres on the Blosenbergturm in Beromünster is such a construction, in which a lengthening coil is installed for the supply of the upper tower part (the Blosenbergturm has in addition a ring-shaped roof capacitor on its top)
Application.
Transmission aerials of transmitters working at frequencies below the longwave broadcasting band always apply electric lengthening. Broadcasting aerials of longwave broadcasting stations apply it often. However, for transmission aerials of NDBs electrical lengthening is extensively applied, because these use antennas which are considerably less tall than a quarter of the radiated wavelength.

</doc>
<doc id="41092" url="https://en.wikipedia.org/wiki?curid=41092" title="Electric field">
Electric field

An electric field is a vector field that associates to each point in space the Coulomb force experienced by a unit electric charge. Electric fields converge and diverge at electric charges and they can be induced by time-varying magnetic fields. The electric field combines with the magnetic field to form the electromagnetic field.
Definition.
The electric field formula_1 at a given point is defined as the (vectorial) force formula_2 that would be exerted on a stationary test particle of unit charge by electromagnetic forces (i.e. the Lorentz force). A particle of charge formula_3 would be subject to a force formula_4.
Its SI units are newtons per coulomb (N⋅C−1) or, equivalently, volts per metre (V⋅m−1), which in terms of SI base units are kg⋅m⋅s−3⋅A−1.
Sources of electric field.
Causes and description.
Electric fields are caused by electric charges or varying magnetic fields. The former effect is described by Gauss's law, the latter by Faraday's law of induction, which together are enough to define the behavior of the electric field as a function of charge repartition and magnetic field. However, since the magnetic field is described as a function of electric field, the equations of both fields are coupled and together form Maxwell's equations that describe both fields as a function of charges and currents.
In the special case of a steady state (stationary charges and currents), the Maxwell-Faraday inductive effect disappears. The resulting two equations (Gauss's law formula_5 and Faraday's law with no induction term formula_6), taken together, are equivalent to Coulomb's law, written as formula_7 for a charge density
formula_8 (formula_9 denotes the position in space). Notice that formula_10, the permittivity of vacuum, must be substituted if charges are considered in non-empty media.
Continuous vs. discrete charge repartition.
The equations of electromagnetism are best described in a continuous description. However, charges are sometimes best described as discrete points; for example, some models may describe electrons as punctual sources where charge density is infinite on an infinitesimal section of space.
A charge formula_3 located in formula_12 can be described mathematically as a charge density formula_13, where the Dirac delta function (in three dimensions) is used. Conversely, a charge distribution can be approximated by many small punctual charge.
Superposition principle.
Electric fields satisfy the superposition principle, because Maxwell's equations are linear. As a result, if formula_14 and formula_15 are the electric fields resulting from distribution of charges formula_16 and formula_17, a distribution of charges formula_18 will create an electric field formula_19; for instance, Coulomb's law is linear in charge density as well.
This principle is useful to calculate the field created by multiple point charges. If charges formula_20 are stationary in space at formula_21, in the absence of currents, the superposition principle proves that the resulting field is the sum of fields generated by each particle as described by Coulomb's law:
This suggests similarities between the electric field E and the gravitational field g, or their associated potentials. Mass is sometimes called "gravitational charge" because of that similarity.
Electrostatic and gravitational forces both are central, conservative and obey an inverse-square law.
Uniform fields.
A uniform field is one in which the electric field is constant at every point. It can be approximated by placing two conducting plates parallel to each other and maintaining a voltage (potential difference) between them; it is only an approximation because of boundary effects (near the edge of the planes, electric field is distorted because the plane does not continue). Assuming infinite planes, the magnitude of the electric field "E" is:
where Δ"ϕ" is the potential difference between the plates and "d" is the distance separating the plates. The negative sign arises as positive charges repel, so a positive charge will experience a force away from the positively charged plate, in the opposite direction to that in which the voltage increases. In micro- and nanoapplications, for instance in relation to semiconductors, a typical magnitude of an electric field is in the order of , achieved by applying a voltage of the order of 1 volt between conductors spaced 1 µm apart.
Electrodynamic fields.
Electrodynamic fields are E-fields which do change with time, for instance when charges are in motion.
The electric field cannot be described independently of the magnetic field in that case. If A is the magnetic vector potential, defined so that formula_24, one can still define an electric potential formula_25 such that:
One can recover Faraday's law of induction by taking the curl of that equation
which justifies, a posteriori, the previous form for E.
Energy in the electric field.
If the magnetic field B is nonzero,
The total energy per unit volume stored by the electromagnetic field is
where "ε" is the permittivity of the medium in which the field exists, formula_29 its magnetic permeability, and E and B are the electric and magnetic field vectors.
As E and B fields are coupled, it would be misleading to split this expression into "electric" and "magnetic" contributions. However, in the steady-state case, the fields are no longer coupled (see Maxwell's equations). It makes sense in that case to compute the electrostatic energy per unit volume:
The total energy "U" stored in the electric field in a given volume "V" is therefore
Further extensions.
Definitive equation of vector fields.
In the presence of matter, it is helpful in electromagnetism to extend the notion of the electric field into three vector fields, rather than just one:
where P is the electric polarization – the volume density of electric dipole moments, and D is the electric displacement field. Since E and P are defined separately, this equation can be used to define D. The physical interpretation of D is not as clear as E (effectively the field applied to the material) or P (induced field due to the dipoles in the material), but still serves as a convenient mathematical simplification, since Maxwell's equations can be simplified in terms of free charges and currents.
Constitutive relation.
The E and D fields are related by the permittivity of the material, "ε".
For linear, homogeneous, isotropic materials E and D are proportional and constant throughout the region, there is no position dependence: For inhomogeneous materials, there is a position dependence throughout the material:
For anisotropic materials the E and D fields are not parallel, and so E and D are related by the permittivity tensor (a 2nd order tensor field), in component form:
For non-linear media, E and D are not proportional. Materials can have varying extents of linearity, homogeneity and isotropy.

</doc>
<doc id="41093" url="https://en.wikipedia.org/wiki?curid=41093" title="Electromagnetic compatibility">
Electromagnetic compatibility

Electromagnetic compatibility (EMC) is the branch of electrical engineering concerned with the unintentional generation, propagation and reception of electromagnetic energy which may cause unwanted effects such as electromagnetic interference (EMI) or even physical damage in operational equipment. The goal of EMC is the correct operation of different equipment in a common electromagnetic environment.
EMC pursues two main classes of issue. Emission is the generation of electromagnetic energy, whether deliberate or accidental, by some source and its release into the environment. EMC studies the unwanted emissions and the countermeasures which may be taken in order to reduce unwanted emissions. The second class, susceptibility is the tendency of electrical equipment, referred to as the victim, to malfunction or break down in the presence of unwanted emissions, which are known as Radio frequency interference (RFI). Immunity is the opposite of susceptibility, being the ability of equipment to function correctly in the presence of RFI, with the discipline of "hardening" equipment being known equally as susceptibility or immunity. A third class studied is coupling, which is the mechanism by which emitted interference reaches the victim.
Interference mitigation and hence electromagnetic compatibility may be achieved by addressing any or all of these issues, i.e., quieting the sources of interference, inhibiting coupling paths and/or hardening the potential victims. In practice, many of the engineering techniques used, such as grounding and shielding, apply to all three issues.
Introduction.
While electromagnetic interference (EMI) is a "phenomenon" - the radiation emitted and its effects - electromagnetic compatibility (EMC) is an equipment "characteristic" or "property" - not to behave unacceptably in the EMI environment.
EMC ensures the correct operation, in the same electromagnetic environment, of different equipment items which use or respond to electromagnetic phenomena, and the avoidance of any interference effects. Another way of saying this is that EMC is the control of EMI so that unwanted effects are prevented.
Besides understanding the phenomena in themselves, EMC also addresses the countermeasures, such as control regimes, design and measurement, which should be taken in order to prevent emissions from causing any adverse effect.
Types of interference.
Electromagnetic interference divides into several categories according to the source and signal characteristics.
The origin of interference, often called "noise" in this context, can be man-made (artificial) or natural.
Continuous interference.
Continuous, or Continuous Wave (CW), interference arises where the source continuously emits at a given range of frequencies. This type is naturally divided into sub-categories according to frequency range, and as a whole is sometimes referred to as "DC to daylight".
Pulse or transient interference.
An electromagnetic pulse (EMP), sometimes called a transient disturbance, arises where the source emits a short-duration pulse of energy. The energy is usually broadband by nature, although it often excites a relatively narrow-band "damped sine wave" response in the victim.
Sources divide broadly into isolated and repetitive events.
Coupling mechanisms.
Some of the technical words employed can be used with differing meanings. These terms are used here in a widely accepted way, which is consistent with other articles in the encyclopedia.
The basic arrangement of noise source, coupling path and victim, receptor or sink is shown in the figure below. Source and victim are usually electronic hardware devices, though the source may be a natural phenomenon such as a lightning strike, electrostatic discharge (ESD) or, in one famous case, the Big Bang at the origin of the Universe.
There are four basic coupling mechanisms: conductive, capacitive, magnetic or inductive, and radiative. Any coupling path can be broken down into one or more of these coupling mechanisms working together. For example the lower path in the diagram involves inductive, conductive and capacitive modes.
Conductive coupling.
Conductive coupling occurs when the coupling path between the source and the receptor is formed by direct electrical contact with a conducting body, for example a transmission line, wire, cable, PCB trace or metal enclosure.
Conducted noise is also characterised by the way it appears on different conductors:
Inductive coupling.
Inductive coupling occurs where the source and receiver are separated by a short distance (typically less than a wavelength). Strictly, "Inductive coupling" can be of two kinds, electrical induction and magnetic induction. It is common to refer to electrical induction as "capacitive coupling", and to magnetic induction as "inductive coupling".
Capacitive coupling.
Capacitive coupling occurs when a varying electrical field exists between two adjacent conductors typically less than a wavelength apart, inducing a change in voltage across the gap.
Magnetic coupling.
Inductive coupling or magnetic coupling (MC) occurs when a varying magnetic field exists between two parallel conductors typically less than a wavelength apart, inducing a change in voltage along the receiving conductor.
Radiative coupling.
Radiative coupling or electromagnetic coupling occurs when source and victim are separated by a large distance, typically more than a wavelength. Source and victim act as radio antennas: the source emits or radiates an electromagnetic wave which propagates across the open space in between and is picked up or received by the victim.
EMC control.
The damaging effects of electromagnetic interference pose unacceptable risks in many areas of technology, and it is necessary to control such interference and reduce the risks to acceptable levels.
The control of electromagnetic interference (EMI) and assurance of EMC comprises a series of related disciplines:
For a complex or novel piece of equipment, this may require the production of a dedicated "EMC control plan" summarizing the application of the above and specifying additional documents required.
Characterising the threat.
Characterisation of the problem requires understanding of:
The risk posed by the threat is usually statistical in nature, so much of the work in threat characterisation and standards setting is based on reducing the probability of disruptive EMI to an acceptable level, rather than its assured elimination.
Laws and regulators.
Regulatory and standards bodies.
Several organizations, both national and international, work to promote international co-operation on standardization (harmonization), including publishing various EMC standards. Where possible, a standard developed by one organization may be adopted with little or no change by others. This helps for example to harmonize national standards across Europe.
International standards organizations include:
Among the main national organizations are:
Laws.
Compliance with national or international standards is usually laid down by laws passed by individual nations. Different nations can require compliance with different standards.
In European law, manufacturers of electronic devices are advised to run EMC tests in order to comply with compulsory CE-labeling. EU directive 2004/108/EC (previously 89/336/EEC) on EMC defines the rules for the distribution of electric devices within the European Union. More are given in the list of EMC directives.
EMC design.
Electromagnetic noise is produced in the source due to rapid current and voltage changes, and spread via the coupling mechanisms described earlier.
Since breaking a coupling path is equally effective at either the start or the end of the path, many aspects of good EMC design practice apply equally to potential emitters and to potential victims. Further, a circuit which easily couples energy to the outside world will equally easily couple energy in and will be susceptible. A single design improvement often reduces both emissions and susceptibility.
Grounding and shielding.
Grounding and shielding aim to reduce emissions or divert EMI away from the victim by providing an alternative, low-impedance path. Techniques include:
Emissions suppression.
Additional measures to reduce emissions include:
Susceptibility hardening.
Additional measures to reduce susceptibility include:
EMC testing.
Testing is required to confirm that a particular device meets the required standards. It divides broadly into emissions testing and susceptibility testing.
Open-air test sites, or OATS, are the reference sites in most standards. They are especially useful for emissions testing of large equipment systems.
However RF testing of a physical prototype is most often carried out indoors, in a specialised EMC test chamber. Types of chamber include anechoic, reverberation and the Gigahertz Transverse Electromagnetic cell (GTEM cell).
Sometimes computational electromagnetics simulations are used to test virtual models.
Like all compliance testing, it is important that the test equipment, including the test chamber or site and any software used, be properly calibrated and maintained.
Typically, a given run of tests for a particular piece of equipment will require an "EMC test plan" and follow-up "Test report". The full test program may require the production of several such documents.
Emissions testing.
Emissions are typically measured for radiated field strength and where appropriate for conducted emissions along cables and wiring. Inductive (magnetic) and capacitive (electric) field strengths are near-field effects, and are only important if the device under test (DUT) is designed for location close to other electrical equipment.
Typically a spectrum analyzer is used to measure the emission levels of the DUT across a wide band of frequencies (frequency domain). Specialized spectrum analyzers for EMC testing are available, called EMI Test Receivers or EMI Analyzers. These incorporate bandwidths and detectors as specified by international EMC standards. EMI Receivers along with specified transducers can often be used for both conducted and radiated emissions. Pre-selector filters may also be used to reduce the effect of strong out-of-band signals on the front-end of the receiver.
For conducted emissions, typical transducers include the LISN (Line Impedance Stabilisation Network) or AMN (Artificial Mains Network) and the RF current clamp.
For radiated emission measurement, antennas are used as transducers. Typical antennas specified include dipole, biconical, log-periodic, double ridged guide and conical log-spiral designs. Radiated emissions must be measured in all directions around the DUT.
Some pulse emissions are more usefully characterized using an oscilloscope to capture the pulse waveform in the time domain.
Susceptibility testing.
Radiated field susceptibility testing typically involves a high-powered source of RF or EM pulse energy and a radiating antenna to direct the energy at the potential victim or device under test (DUT).
Conducted voltage and current susceptibility testing typically involves a high-powered signal or pulse generator, and a current clamp or other type of transformer to inject the test signal.
Transient immunity is used to test the immunity of the DUT against powerline disturbances including surges, lightning strikes and switching noise. In motor vehicles, similar tests are performed on battery and signal lines.
Electrostatic discharge testing is typically performed with a piezo spark generator called an "ESD pistol". Higher energy pulses, such as lightning or nuclear EMP simulations, can require a large current clamp or a large antenna which completely surrounds the DUT. Some antennas are so large that they are located outdoors, and care must be taken not to cause an EMP hazard to the surrounding environment.
History.
The earliest EMC issue was lightning strike (lightning electromagnetic pulse, or LEMP) on buildings. Lightning rods or lightning conductors began to appear in the mid-18th century. With the advent of widespread electricity generation and power supply lines from the late 19th century on, problems also arose with equipment short-circuit failure affecting the power supply, and with local fire and shock hazard when the power line was struck by lightning. Power stations were provided with output circuit breakers. Buildings and appliances would soon be provided with input fuses, and later in the 20th century miniature circuit breakers (MCB) would come into use.
As radio communications developed in the first half of the 20th century, interference between broadcast radio signals began to occur and an international regulatory framework was set up to ensure interference-free communications.
As switching devices became commonplace, typically in petrol powered cars and motorcycles but also in domestic appliances such as thermostats and refrigerators, transient interference with domestic radio and (after World War II) TV reception became problematic, and in due course laws were passed requiring the suppression of such interference sources.
ESD problems first arose with accidental electric spark discharges in hazardous environments such as coal mines and when refuelling aircraft or motor cars. Safe working practices had to be developed.
After World War II the military became increasingly concerned with the effects of nuclear electromagnetic pulse (NEMP), lightning strike, and even high-powered radar beams, on vehicle and mobile equipment of all kinds, and especially aircraft electrical systems.
When high RF emission levels from other sources became a potential problem (such as with the advent of microwave ovens), certain frequency bands were designated for Industrial, Scientific and Medical (ISM) use, allowing unlimited emissions. A variety of issues such as sideband and harmonic emissions, broadband sources, and the increasing popularity of electrical switching devices and their victims, resulted in a steady development of standards and laws.
From the 1970s, the popularity of modern digital circuitry rapidly grew. As the technology developed, with faster switching speeds (increasing emissions) and lower circuit voltages (increasing susceptibility), EMC increasingly became a source of concern. Many more nations became aware of EMC as a growing problem and issued directives to the manufacturers of digital electronic equipment, which set out the essential manufacturer requirements before their equipment could be marketed or sold. Organizations in individual nations, across Europe and worldwide, were set up to maintain these directives and associated standards. This regulatory environment led to a sharp growth in the EMC industry supplying specialist devices and equipment, analysis and design software, and testing and certification services.
Low-voltage digital circuits, especially CMOS transistors, became more susceptible to ESD damage as they were miniaturised, and a new ESD regulatory regime had to be developed.
From the 1980s, the ever-increasing use of mobile communications and broadcast media channels has put huge pressure on the available airspace. Regulatory authorities are squeezing band allocations closer and closer together, relying on increasingly sophisticated EMC control methods, especially in the digital communications arena, to keep cross-channel interference to acceptable levels. Digital systems are inherently less susceptible than analog systems, and also offer far easier ways (such as software) to implement highly sophisticated protection measures.
Most recently, even the ISM bands are being used for low-power mobile digital communications such as Wi-Fi and remotely-operated car door keys. This approach relies on the intermittent nature of ISM interference and use of sophisticated error-correction methods to ensure lossless reception during the quiet gaps between bursts of interference.

</doc>
<doc id="41094" url="https://en.wikipedia.org/wiki?curid=41094" title="Electromagnetic environment">
Electromagnetic environment

In telecommunication, the term electromagnetic environment (EME) has the following meanings: 

</doc>
<doc id="41096" url="https://en.wikipedia.org/wiki?curid=41096" title="Electromagnetic interference control">
Electromagnetic interference control

In telecommunication, electromagnetic interference control (EMI) is the control of radiated and conducted energy such that emissions that are unnecessary for system, subsystem, or equipment operation are reduced, minimized, or eliminated. 
"Note:" Electromagnetic radiated and conducted emissions are controlled regardless of their origin within the system, subsystem, or equipment. Successful EMI control with effective susceptibility control leads to electromagnetic compatibility.

</doc>
