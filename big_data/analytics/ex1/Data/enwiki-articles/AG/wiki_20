<doc id="40570" url="https://en.wikipedia.org/wiki?curid=40570" title="United States presidential election, 1980">
United States presidential election, 1980

The United States presidential election of 1980 was the 49th quadrennial presidential election. It was held on Tuesday, November 4, 1980. The contest was between incumbent Democratic President Jimmy Carter and his Republican opponent, former California Governor Ronald Reagan, as well as Republican Congressman John B. Anderson, who ran as an independent. Reagan, aided by the Iran hostage crisis and a worsening economy at home marked by high unemployment and inflation, won the election in a landslide, receiving the highest number of electoral votes ever won by a non-incumbent presidential candidate.
Carter, after defeating Edward M. Kennedy for the Democratic nomination, attacked Reagan as a dangerous right-wing radical. For his part, Reagan pledged to uplift the pessimistic mood of the nation, and won a decisive victory; in the simultaneous Congressional elections, Republicans won control of the United States Senate for the first time in 28 years. This election marked the beginning of what is called the "Reagan Revolution" or Reagan Era, and signified a conservative realignment in national politics.
Background.
Throughout the 1970s, the United States underwent a wrenching period of low economic growth, high inflation and interest rates, and intermittent energy crises. By October 1978, Iran, a major oil supplier to the United States at the time, was experiencing a major uprising that severely damaged its oil infrastructure and greatly weakened its capability to produce oil. In January 1979, shortly after Iran's leader Shah Mohammad Reza Pahlavi fled the country, Iranian opposition figure Ayatollah Ruhollah Khomeini ended his 14-year exile in France and returned to Iran to establish an Islamic Republic, largely hostile to American interests and influence in the country. In the spring and summer of 1979 inflation was on the rise and various parts of the United States were experiencing energy shortages.
With the return of the long gas lines that were last seen just after the 1973 Yom Kippur War, Carter was widely blamed and planned on delivering his fifth major speech on energy; however, he felt that the American people were no longer listening. Carter left for the presidential retreat of Camp David. "For more than a week, a veil of secrecy enveloped the proceedings. Dozens of prominent Democratic Party leaders—members of Congress, governors, labor leaders, academics and clergy—were summoned to the mountaintop retreat to confer with the beleaguered president." His pollster, Pat Caddell, told him that the American people simply faced a crisis of confidence because of the assassinations of John F. Kennedy, Robert F. Kennedy and Martin Luther King, Jr.; the Vietnam War; and Watergate. On July 15, 1979, Carter gave a nationally-televised address in which he identified what he believed to be a "crisis of confidence" among the American people. This came to be known as his "malaise" speech, although Carter never used the word in the speech.
Many expected Senator Ted Kennedy to successfully challenge Carter in the upcoming Democratic Primary. Kennedy's official announcement was scheduled for early November. A television interview with Roger Mudd of CBS a few days before the announcement went badly, however. Kennedy gave an "incoherent and repetitive" answer to the question of why he was running, and the polls, which showed him leading the President by 58-25 in August now had him ahead 49-39.
Meanwhile, an opportunity for political redemption came for Carter as the Khomeini regime again gained public attention and allowed the taking of 52 American hostages by a group of Islamist students and militants at the U.S. embassy in Tehran on November 4, 1979. Carter's calm approach towards handling this crisis resulted in his approval ratings jump in the 60-percent range in some polls, due to a "rally round the flag" effect. By the beginning of the election season, the prolonged Iran hostage crisis had sharpened public perceptions of a national crisis. On April 25, 1980, Carter's ability to use the hostage crisis to regain public acceptance eroded when his attempt to rescue the hostages ended in disaster and drew further skepticism towards his leadership skills.
Following the failed rescue attempt, Jimmy Carter was overwhelmingly blamed for the Iran hostage crisis, in which the followers of the Ayatollah Khomeini burned American flags and chanted anti-American slogans, paraded the captured American hostages in public, and burned effigies of Carter. Carter's critics saw him as an inept leader who had failed to solve the worsening economic problems at home. His supporters defended the president as a decent, well-intentioned man being unfairly criticized for problems that had been building for years.
Nominations.
Democratic Party.
Democratic candidates:
Candidates gallery.
The three major Democratic candidates in early 1980 were incumbent President Jimmy Carter, Senator Ted Kennedy of Massachusetts, and Governor Jerry Brown of California. Brown withdrew on April 2. Carter and Kennedy faced off in 34 primaries. This was the most tumultuous primary race that an elected incumbent president had encountered since President Taft, during the highly contentious election of 1912.
During the summer of 1980, there was a short-lived "Draft Muskie" movement; Secretary of State Edmund Muskie was seen as a favorable alternative to a deadlocked convention. One poll showed that Muskie would be a more popular alternative to Carter than Kennedy, implying that the attraction was not so much to Kennedy as to the fact that he was not Carter. Muskie was polling even with Ronald Reagan at the time, while Carter was seven points behind. Although the underground "Draft Muskie" campaign failed, it became a political legend.
After defeating Kennedy in 24 of 34 primaries, Carter entered the party's convention in New York in August with 60 percent of the delegates pledged to him on the first ballot. Still, Kennedy refused to drop out. At the convention, after a futile last-ditch attempt by Kennedy to alter the rules to free delegates from their first-ballot pledges, Carter was renominated with 2,129 votes to 1,146 for Kennedy. Vice President Walter Mondale was also renominated. In his acceptance speech, Carter warned that Reagan's conservatism posed a threat to world peace and progressive social welfare programs from the New Deal to the Great Society.
Republican Party.
Republican candidates
Former Governor Ronald Reagan was the odds-on favorite to win his party's nomination for president after nearly beating incumbent President Gerald Ford just four years earlier. He won the nomination on the first round at the 1980 Republican National Convention in Detroit, Michigan, in July, then chose George H. W. Bush, his top rival, as his running mate.
Other candidates.
John Anderson, after being defeated in the Republican primaries, entered the general election as an independent candidate, campaigning as a moderate Republican alternative to Reagan's conservatism. However, his campaign appealed primarily to frustrated anti-Carter voters. His support progressively evaporated through the campaign season as his supporters were pulled away by Carter and Reagan. His running mate was Patrick Lucey, a Democratic former Governor of Wisconsin and then Ambassador to Mexico, appointed by President Carter.
The Libertarian Party nominated Ed Clark for President and David H. Koch for Vice President. They received almost one million votes and were on the ballot in all 50 states plus Washington, D.C. Koch, a co-owner of Koch Industries, pledged part of his personal fortune to the campaign.
The Clark-Koch ticket received 921,128 votes (1.06% of the total nationwide). This is the highest percentage of popular votes a Libertarian Party candidate has ever received in a presidential race to date, and remained the highest overall number of votes earned by a Libertarian candidate until the 2012 election, when Gary Johnson and James P. Gray became the first Libertarian ticket to earn more than a million votes, albeit with a lower overall vote percentage than Clark-Koch. His strongest support was in Alaska, where he came in third place with 11.66% of the vote, finishing ahead of independent candidate John Anderson and receiving almost half as many votes as Jimmy Carter.
The Socialist Party USA nominated David McReynolds for President and Sister Diane Drufenbrock for Vice President, making McReynolds the first openly gay man to run for President and Drufenbrock the first nun to be a candidate for national office in the U.S.
The Citizens Party ran Biologist Barry Commoner for President and Comanche Native American activist La Donna Harris for Vice President. The Commoner/Harris ticket was on the ballot in twenty-nine states and in the District of Columbia.
The Communist Party USA ran Gus Hall for President and Angela Davis for Vice President.
The American Party nominated Percy L. Greaves, Jr. for President and Frank L. Varnum for Vice President.
Rock star Joe Walsh ran a mock campaign as a write-in candidate, promising to make his song "Life's Been Good" the new national anthem if he won, and running on a platform of "Free Gas For Everyone." Though the 33-year-old Walsh was not old enough to actually assume the office, he wanted to raise public awareness of the election.
General election.
Campaign.
Under federal election laws, Carter and Reagan received $29.4 million each, and Anderson was given a limit of $18.5 million with private fund-raising allowed for him only. They were not allowed to spend any other money. Carter and Reagan each spent about $15 million on television advertising, and Anderson under $2 million. Reagan ended up spending $29.2 million in total, Carter $29.4 million, and Anderson spent $17.6 million— partially because he (Anderson) didn't get Federal Election Commission money until after the election.
The 1980 election is considered by some to be a realigning election, reaching a climate of confrontation practically not seen since 1932. Reagan's supporters praise him for running a campaign of upbeat optimism. David Frum says Carter ran an attack-based campaign based on "despair and pessimism" which "cost him the election." Carter emphasized his record as a peacemaker, and said Reagan's election would threaten civil rights and social programs that stretched back to the New Deal. Reagan's platform also emphasized the importance of peace, as well as a prepared self-defense.
Immediately after the conclusion of the primaries, a Gallup poll held that Reagan was ahead, with 58% of voters upset by Carter's handling of the Presidency. One analysis of the election has suggested that "Both Carter and Reagan were perceived negatively by a majority of the electorate." While the three leading candidates (Reagan, Anderson and Carter) were religious Christians, Carter had the most support of evangelical Christians according to a Gallup poll. However, in the end, Jerry Falwell's Moral Majority lobbying group is credited with giving Reagan two-thirds of the white evangelical vote. According to Carter: "that autumn a group headed by Jerry Falwell purchased $10 million in commercials on southern radio and TV to brand me as a traitor to the South and no longer a Christian."
The election of 1980 was a key turning point in American politics. It signaled the new electoral power of the suburbs and the Sun Belt. Reagan's success as a conservative would initiate a realigning of the parties, as liberal Republicans and conservative Democrats would either leave politics or change party affiliations through the 1980s and 1990s to leave the parties much more ideologically polarized. While during Barry Goldwater's 1964 campaign, many voters saw his warnings about a too-powerful government as hyperbolic and only 30% of the electorate agreed that government was too powerful, by 1980 a majority of Americans believed that government held too much power.
Promises.
Reagan promised a restoration of the nation's military strength, at the same time 60% of Americans polled felt defense spending was too low. Reagan also promised an end to "'trust me' government" and to restore economic health by implementing a supply-side economic policy. Reagan promised a balanced budget within three years (which he said would be "the beginning of the end of inflation"), accompanied by a 30% reduction in tax rates over those same years. With respect to the economy, Reagan famously said, "A recession is when your neighbor loses his job. A depression is when you lose yours. And recovery is when Jimmy Carter loses his." Reagan also criticized the "windfall profit tax" that Carter and Congress enacted that year in regards to domestic oil production and promised to attempt to repeal it as president. The tax was not a tax on profits, but on the difference between the price control-mandated price and the market price.
On the issue of women's rights there was much division, with many feminists frustrated with Carter, the only candidate who supported the Equal Rights Amendment. After a bitter Convention fight between Republican feminists and antifeminists the Republican Party dropped their forty-year endorsement of the ERA. Reagan, however, announced his dedication to women's rights and his intention to, if elected, appoint women to his cabinet and the first female justice to the Supreme Court. He also pledged to work with all 50 state governors to combat discrimination against women and to equalize federal laws as an alternative to the ERA. Reagan was convinced to give an endorsement of women's rights in his nomination acceptance speech.
Carter was criticized by his own aides for not having a "grand plan" for the recovery of the economy, nor did he ever make any campaign promises; he often criticized Reagan's economic recovery plan, but did not create one of his own in response.
Events.
In August, after the Republican National Convention, Ronald Reagan gave a campaign speech at the annual Neshoba County Fair on the outskirts of Philadelphia, Mississippi, where three civil rights workers were murdered in 1964. He was the first presidential candidate ever to campaign at the fair. Reagan famously announced, "Programs like education and others should be turned back to the states and local communities with the tax sources to fund them. I believe in states' rights. I believe in people doing as much as they can at the community level and the private level." Reagan also stated, "I believe we have distorted the balance of our government today by giving powers that were never intended to be given in the Constitution to that federal establishment." He went on to promise to "restore to states and local governments the power that properly belongs to them." President Carter criticized Reagan for injecting "hate and racism" by the "rebirth of code words like 'states' rights'".
Two days later, Reagan appeared at the Urban League convention in New York, where he said, "I am committed to the protection and enforcement of the civil rights of black Americans. This commitment is interwoven into every phase of the plans I will propose." He then said that he would develop "enterprise zones" to help with urban renewal.
Reagan made some gaffes during the campaign. When Carter appeared in a small Alabama town, Tuscumbia, Reagan incorrectly claimed the town had been the birthplace of the Ku Klux Klan—it was actually the home of the KKK's national headquarters. Reagan was widely ridiculed by Democrats for saying that trees caused pollution; he later said that he meant only certain types of pollution and his remarks had been misquoted.
Meanwhile, Carter was burdened by a continued weak economy and the Iran hostage crisis. Inflation, high interest rates, and unemployment continued through the course of the campaign, and the ongoing hostage crisis in Iran became, according to David Frum in " How We Got Here: The '70s", a symbol of American impotence during the Carter years. John Anderson's independent candidacy, aimed at eliciting support from liberals, was also seen as hurting Carter more than Reagan, especially in such reliably Democratic states such as Massachusetts and New York.
Debates.
An important event in the 1980 presidential campaign was the lone presidential debate, which was held one week to the day before the election (October 28). Going into the debate, average poll data indicated that Reagan had a two to three point lead over Carter. After the debate, Reagan was able to increase his lead dramatically against the president to win a comfortable Republican victory.
The League of Women Voters, which had sponsored the 1976 Ford/Carter debate series, announced that it would do so again for the next cycle in the spring of 1979. However, Carter was not eager to participate with any debate. He had repeatedly refused to a debate with Senator Edward M. Kennedy during the primary season, and had given ambivalent signals as to his participation in the fall.
The League of Women Voters had announced a schedule of debates similar to 1976, three presidential and one vice presidential. No one had much of a problem with this until it was announced that Rep. John Anderson might be invited to participate along with Carter and Reagan. Carter steadfastly refused to participate with Anderson included, and Reagan refused to debate without him. It took months of negotiations for the League of Women Voters to finally put it together. It was held on September 21, 1980 in the Baltimore Convention Center. Reagan said of Carter's refusal to debate: "He knows that he couldn't win a debate even if it were held in the Rose Garden before an audience of Administration officials with the questions being asked by Jody Powell." The League of Women Voters promised the Reagan campaign that the debate stage would feature an empty chair to represent the missing president. Carter was very upset about the planned chair stunt, and at the last minute convinced the League to take it out. The debate was moderated by Bill Moyers. Anderson, who many thought would handily dispatch the former Governor, managed only a draw, according to many in the media at that time. The Illinois congressman, who had been as high as 20% in some polls, and at the time of the debate was over 10%, dropped to about 5% soon after. Anderson failed to substantively engage Reagan, instead he started off by criticizing Carter: "Governor Reagan is not responsible for what has happened over the last four years, nor am I. The man who should be here tonight to respond to those charges chose not to attend," to which Reagan added: "It's a shame now that there are only two of us here debating, because the two that are here are in more agreement than disagreement." In one moment in the debate, Reagan commented on a rumor that Anderson had invited Senator Ted Kennedy to be his running mate by asking the candidate directly, "John, would you really prefer Teddy Kennedy to me?"
As September turned into October, the situation remained essentially the same. Governor Reagan insisted Anderson be allowed to participate, and the President remained steadfastly opposed to this. As the standoff continued, the second round was canceled, as was the vice presidential debate.
With two weeks to go to the election, the Reagan campaign decided that the best thing to do at that moment was to accede to all of President Carter's demands, and LWV agreed to exclude Congressman Anderson from the final debate, which was rescheduled for October 28 in Cleveland, Ohio.
Moderated by Howard K. Smith and presented by the League of Women Voters, the presidential debate between President Carter and Governor Reagan ranked among the highest ratings of any television show in the previous decade. Debate topics included the Iranian hostage crisis, and nuclear arms treaties and proliferation. Carter's campaign sought to portray Reagan as a reckless "war hawk," as well as a "dangerous right-wing radical". But it was President Carter's reference to his consultation with 12-year-old daughter Amy concerning nuclear weapons policy that became the focus of post-debate analysis and fodder for late-night television jokes. President Carter said he had asked Amy what the most important issue in that election was and she said, "the control of nuclear arms." A famous political cartoon, published the day after Reagan's landslide victory, showed Amy Carter sitting in Jimmy's lap with her shoulders shrugged asking "the economy? the hostage crisis?"
When President Carter criticized Reagan's record, which included voting against Medicare and Social Security benefits, Governor Reagan audibly sighed and replied: "There you go again".
In describing the national debt that was approaching $1 trillion, Reagan stated "a billion is a thousand millions, and a trillion is a thousand billions." When Carter would criticize the content of Reagan's campaign speeches, Reagan began his counter with words: "Well... I don't know that I said that. I really don't."
In his closing remarks, Reagan asked viewers: "Are you better off now than you were four years ago? Is it easier for you to go and buy things in the stores than it was four years ago? Is there more or less unemployment in the country than there was four years ago? Is America as respected throughout the world as it was? Do you feel that our security is as safe, that we're as strong as we were four years ago? And if you answer all of those questions 'yes', why then, I think your choice is very obvious as to whom you will vote for. If you don't agree, if you don't think that this course that we've been on for the last four years is what you would like to see us follow for the next four, then I could suggest another choice that you have."
Endorsements.
In September 1980, former Watergate scandal prosecutor Leon Jaworski accepted a position as honorary chairman of Democrats for Reagan. Five months earlier, Jaworski had harshly criticized Reagan as an "extremist"; he said after accepting the chairmanship, "I would rather have a competent extremist than an incompetent moderate."
Former Democratic Senator Eugene McCarthy of Minnesota (who in 1968 had challenged Lyndon Johnson from the left, causing the then-President to all but abdicate) endorsed Reagan.
Three days before the November 4 voting in the election, the National Rifle Association endorsed a presidential candidate for the first time in its history, backing Reagan. Reagan had received the California Rifle and Pistol Association's Outstanding Public Service Award. Carter had appointed Abner J. Mikva, a fervent proponent of gun control, to a federal judgeship and had supported the Alaska Lands Bill, closing to hunting.
Results.
The election was held on November 4, 1980.
Ronald Reagan with running mate George H.W. Bush beat Carter by almost 10 percentage points in the popular vote. Republicans also gained control of the Senate for the first time in twenty-five years on Reagan's coattails. The electoral college vote was a landslide, with 489 votes (representing 44 states) for Reagan and 49 votes for Carter (representing 6 states and the District of Columbia).
NBC News projected Reagan as the winner at 8:15 pm EST (5:15 PST), before voting was finished in the West, based on exit polls. (It was the first time a broadcast network used exit polling to project a winner, and took the other broadcast networks by surprise.) Carter conceded defeat at 9:50 pm EST. Carter's loss was the worst performing of an incumbent President since Herbert Hoover lost to Franklin D. Roosevelt in 1932 by a margin of 18%. Carter's defeat was the most lopsided defeat for any incumbent president in an election where only two candidates won electoral votes. Also, Jimmy Carter was the first incumbent Democrat to serve only one full term since James Buchanan and fail to secure re-election since Andrew Johnson (Grover Cleveland served two non-consecutive terms while Harry Truman and Lyndon B. Johnson served one full term in addition to taking over after the deaths of Franklin D. Roosevelt and John F. Kennedy respectively).
Carter carried only Georgia, Maryland, Minnesota, Hawaii, West Virginia, the District of Columbia and Rhode Island.
John Anderson won 6.6% of the popular vote and failed to win any state outright. He found the most support in New England, fueled by liberal Republicans who felt Reagan was too far to the right; his best showing was in Massachusetts, where he won 15% of the popular vote. Conversely, Anderson performed worst in the South. Anderson failed to achieve the spoiler effect, due to Reagan's strong showing and the fact that he arguably attracted at least as many Democrats to his ticket as Republicans.
Libertarian Party candidate Ed Clark received 921,299 popular votes (1.06%). The Libertarians succeeded in getting Clark on the ballot in all 50 states and the District of Columbia. Clark's best showing was in Alaska, where he received 11.66% of the vote. The 921,299 votes achieved by the Clark-Koch ticket was the best performance by a Libertarian presidential candidate until 2012 when the Johnson-Gray ticket received 1,273,667 votes.
Reagan won 53% of the vote in reliably Democratic South Boston.
Reagan's electoral college victory of 489 electoral votes (90.9% of the electoral vote) was the most lopsided electoral college victory for a non-incumbent President.
This is the most recent election in which an incumbent president was defeated in two elections in a row. The only other time this happened was in 1892.
Statistics.
Source (Popular Vote): 
Source (Electoral Vote): 
Close states.
Margin of victory less than 5% (165 electoral votes):
Margin of victory more than 5%, but less than 10% (113 electoral votes):
Voter demographics.
Source: CBS News/ New York Times interviews with 12,782 voters as they left the polls, as reported in the New York Times, November 9, 1980, p. 28, and in further analysis. The 1976 data are from CBS News interviews.

</doc>
<doc id="40571" url="https://en.wikipedia.org/wiki?curid=40571" title="United States presidential election, 1984">
United States presidential election, 1984

The United States presidential election of 1984 was the 50th quadrennial presidential election. It was held on Tuesday, November 6, 1984. The contest was between the incumbent President Ronald Reagan, the Republican candidate, and former Vice President Walter Mondale, the Democratic candidate.
Reagan carried 49 of the 50 states, becoming one of only two candidates to do so (the other was Richard Nixon in the 1972 presidential election). Reagan touted a strong economic recovery from 1970s stagflation and the 1981–82 recession, as well as the widespread perception that his presidency had overseen a revival of national confidence and prestige.
Although Mondale received 40.6% of the popular vote, electoral votes are awarded on a winner-take-all basis in each state, resulting in a lopsided electoral vote count. Mondale's only electoral votes came from the District of Columbia, which has never given its electoral votes to a Republican candidate, and his home state of Minnesota, which he won by a mere 3,761 votes. 
Reagan's 525 electoral votes (out of 538) is the highest total ever received by a presidential candidate. His showing ranks fourth by percent electoral votes received (97.58%) out of total available electoral votes, just shy of the 523 out of 531 (98.49%) received by Franklin D. Roosevelt in 1936. Mondale's 13 electoral votes is also the second-fewest ever received by a second-place candidate, second only to Alf Landon's 8 in 1936. In the national popular vote, Reagan received 58.8% to Mondale's 40.6% and his percent margin of victory ranks 7th of all presidential elections. No candidate since then has managed to equal or surpass Reagan's 1984 electoral result. Also, no post-1984 Republican candidate has managed to match Reagan's electoral performance in the Northeastern United States and in the West Coast states. At 73, Reagan was also the oldest president to win a presidential election.
Nominations.
Primaries.
Ronald Reagan—the incumbent president—was the assured nominee for the Republican Party, with only token opposition. The popular vote from the Republican primaries was as follows:
Reagan was renominated by a vote of 2,233 (two delegates abstained). For the only time in American history, the vice presidential roll call was taken concurrently with the presidential roll call. Vice President George H. W. Bush was overwhelmingly renominated. This was the last time in the 20th century that the Vice Presidential candidate of either major party was nominated by roll call vote.
Primaries.
Only three Democratic candidates won any state primaries: Mondale, Hart, and Jackson. Initially, Massachusetts Senator Ted Kennedy, after a failed bid to win the 1980 Democratic nomination for president, was considered the de facto front-runner of the 1984 primary. But, after Kennedy ultimately declined to run, former Vice-President Mondale was then viewed as the favorite to win the Democratic nomination. Mondale had the largest number of party leaders supporting him, and he had raised more money than any other candidate. However, both Jackson and Hart emerged as surprising, and troublesome, opponents.
South Carolina Senator Ernest Hollings's wit and experience, as well as his call for a budget freeze, won him some positive attention, but his relatively conservative record alienated liberal Democrats, and he was never really noticed in a field dominated by Walter Mondale, John Glenn, and Gary Hart. Hollings dropped out two days after losing badly in New Hampshire, and endorsed Hart a week later. His disdain for his competitors sometimes showed. He notably referred to Mondale as a "lapdog," and to former astronaut Glenn as "Sky King" who was "confused in his capsule."
California Senator Alan Cranston hoped to galvanize supporters of the nuclear freeze movement that had called on the United States to halt the deployment of existing nuclear weapons and the development of new ones.
Glenn and Askew hoped to capture the support of moderate and conservative Democrats. None of them possessed the fundraising ability of Mondale or the grassroots support of Hart and Jackson, and none won any primaries.
Jackson was the second African-American (after Shirley Chisholm) to mount a nationwide campaign for the presidency, and he was the first African-American candidate to be a serious contender. He got 3.5 million votes during the primaries, third behind Hart and Mondale. He won the primaries in Virginia, South Carolina, and Louisiana, and split Mississippi, where there were two separate contests for Democratic delegates. Through the primaries, Jackson helped confirm the black electorate's importance to the Democratic Party in the South at the time. During the campaign, however, Jackson made an off-the-cuff reference to Jews as "Hymies" and New York City as "Hymietown," for which he later apologized. Nonetheless, the remark was widely publicized, and derailed his campaign for the nomination. Jackson ended up winning 21% of the national primary vote but received only 8% of the delegates to the national convention, and he initially charged that his campaign was hurt by the same party rules that allowed Mondale to win. He also poured scorn on Mondale, saying that Hubert Humphrey was the "last significant politician out of the St. Paul-Minneapolis" area.
Hart of Colorado was a more serious threat to Mondale, and after winning several early primaries it looked as if he might take the nomination away from Mondale. Hart finished a surprising second in the Iowa caucuses, with 16.5% of the vote. This established him as the main rival to Mondale, effectively eliminating John Glenn, Ernest Hollings and Alan Cranston as alternatives. Hart criticized Mondale as an "old-fashioned" New Deal Democrat who symbolized "failed policies" of the past. Hart positioned himself (just as Bill Clinton would eight years later) as a younger, fresher, and more moderate Democrat who could appeal to younger voters. He emerged as a formidable candidate, winning the key New Hampshire, Ohio, and California primaries as well as several others, especially in the West. However, Hart could not overcome Mondale's financial and organizational advantages, especially among labor union leaders in the Midwest and industrial Northeast.
Hart was also badly hurt in a televised debate with Mondale during the primaries, when the former vice president used a popular television commercial slogan to ridicule Hart's vague "New Ideas" platform. Turning to Hart on camera, Mondale told Hart that whenever he heard Hart talk about his "New Ideas," he was reminded of the Wendy's fast-food slogan "Where's the beef?" The remark drew loud laughter and applause from the viewing audience and caught Hart off-guard. Hart never fully recovered from Mondale's charge that his "New Ideas" were shallow and lacking in specifics.
At a roundtable debate between the three remaining Democratic candidates moderated by Phil Donahue, Mondale and Hart got in such a heated argument over the issue of U.S. policy in Central America that Jackson had to tap his water glass on the table to help get them to stop.
Mondale gradually pulled away from Hart in the delegate count, but, as "Time" reported in late May, "Mondale ... has a wide lead in total delegates (1,564 to 941) ... because of his victories in the big industrial states, his support from the Democratic Establishment and the arcane provisions of delegate-selection rules that his vanguard helped draft two years ago." After the final primary in California, on June 5, which Hart won, Mondale was about 40 delegates short of the total he needed for the nomination. However, at the Democratic National Convention in San Francisco on July 16, Mondale received the overwhelming support of the unelected superdelegates from the party establishment to win the nomination.
This race for the nomination was the closest in two generations, and it has been the most recent occasion that a major party presidential nomination has gone all the way to the convention.
Endorsements.
Note: These are only those endorsements which occurred during or before the Primary Race.
Convention.
These were the convention's nomination tally:
When he made his acceptance speech at the Democratic Convention, Mondale said: "Let's tell the truth. Mr. Reagan will raise taxes, and so will I. He won't tell you. I just did." Although Mondale intended to expose Reagan as hypocritical and position himself as the honest candidate, the choice of taxes as a discussion point likely damaged his electoral chances.
Vice-Presidential nominee.
Mondale chose U.S. Rep. Geraldine A. Ferraro of New York as his running mate, making her the first woman nominated for that position by a major party, and the second Italian American on a major party ticket. Mondale wanted to establish a precedent with his vice presidential candidate, although Tonie Nathan of the Libertarian Party was already the first woman to receive an electoral vote in the 1972 election. Another reason for the nominee to "go for broke" instead of balancing the ticket was Reagan's lead in the polls; Mondale hoped to appeal to women, by 1980 the majority of voters, by choosing Ferraro. In a "much criticized parade of possible Veep candidates" to his home in Minnesota, Mondale considered San Francisco Mayor Dianne Feinstein and Kentucky Governor Martha Layne Collins, also female; Los Angeles Mayor Tom Bradley, an African American; and San Antonio Mayor Henry Cisneros, a Hispanic, as other finalists for the nomination, and chose Ferraro because he hoped that she would attract ethnic voters with her personal background. Unsuccessful nomination candidate Jackson derided Mondale's vice-presidential screening process as a "P.R. parade of personalities," but praised Mondale for his choice, having himself pledged to name a woman to the ticket in the event he was nominated.
Mondale had wanted to choose Governor of New York Mario Cuomo as his running mate, but Cuomo declined and recommended Ferraro, his protégée. The nominee would likely have named Governor of Massachusetts Michael Dukakis as his running mate had he made a "safe" choice". Others preferred Senator Lloyd Bentsen because he would appeal to more conservative Southern voters. Nomination rival Gary Hart stated before Ferraro's selection that he would accept an invitation to run with Mondale; Hart's supporters claimed he would do better than Mondale against President Reagan, an argument undercut by a June 1984 Gallup poll that showed both men nine points behind the president.
Other parties.
National Unity Party Nomination.
The National Unity Party was an outgrowth of John Anderson's presidential campaign from the 1980 presidential election. Anderson hoped that the party would be able to challenge the "two old parties", which he viewed as being tied to various special interest groups and incapable of responsible fiscal reform. The intention was to organize the new party in California, Oregon, Washington, Illinois, the New England states, and others where his previous candidacy had proven to have experienced the most success. The party was also eligible for $5.8 million in Federal election funds, but its qualification depended on it being on the ballot in at least ten states; however, it remained unclear if National Unity could actually obtain the funds, or if it needed to be Anderson himself.
Anderson initially was against running, hoping that another notable politico would take the party into the 1984 election, and feared that his own candidacy might result in the party being labeled a "personality cult". However no candidate came forward resulting in Anderson becoming the nominee in waiting. While Anderson had managed to find equal support from the Republicans and Democrats in the 1980 election, the grand majority of the former had since switched back, resulting in the new party being supported principally by those who normally would vote Democratic, which it was feared might make him a spoiler candidate. In light of this, in addition to difficulties in getting on the ballot in his targeted states "(Utah and Kentucky were the only two, neither among those he intended to prominently campaign in)", Anderson ultimately declined to run. Later he would endorse the Democratic nominee, Walter Mondale.
Anderson had hoped that the party would continue to grow and later field a candidate in 1988 "(which he declared would not be him)", but it floundered and ultimately dissolved.
Libertarian Party Nomination.
Burns was the initial frontrunner for the nomination, but withdrew citing concerns that the party would not be able to properly finance a campaign. The remaining candidates were: Bergland; Ravenal, who had worked in the Department of Defense under Robert McNamara and Clark Clifford; and Ruwart. Bergland narrowly won the presidential nomination over Ravenal. His running mate was James A. Lewis. The ticket appeared on 39 state ballots.
Citizens Party Nomination.
Sonia Johnson ran in the 1984 presidential election, as the presidential candidate of the Citizens Party, Pennsylvania's Consumer Party and California's Peace and Freedom Party. Johnson received 72,161 votes (0.08%) finishing fifth. Her running mate for the Citizens Party was Richard Walton and for the Peace and Freedom Party Emma Wong Mar. One of her campaign managers, Mark Dunlea, later wrote a novel about a first female president, "Madame President".
Communist Party Nomination.
The Communist Party USA ran Gus Hall for President and Angela Davis for Vice President.
General election.
Campaign.
Mondale ran a liberal campaign, supporting a nuclear freeze and the Equal Rights Amendment (ERA). He spoke against what he considered to be unfairness in Reagan's economic policies and the need to reduce federal budget deficits.
While Ferraro's choice was popular among Democratic activists, polls immediately after the announcement showed that only 22% of women were excited about her selection, versus 18% who agreed that it was a "bad idea". 60% of all voters thought that pressure from women's groups had led to Mondale's decision, versus 22% who believed that he had chosen the best available candidate. Some members of the hierarchy of the Roman Catholic Church criticized the Catholic Ferraro for being pro-choice on abortion. Already fighting an uphill battle with voters, Ferraro also faced a slew of allegations, mid-campaign, directed toward her husband, John Zaccaro. These allegations included Zaccaro's possible past involvement in organized crime, pornography distribution, and campaign contribution violations. Ferraro responded to these allegations against her husband by releasing her family tax-returns to the media on August 21, 1984. However, the damage to the campaign was already done.
At a campaign stop in Hammonton, New Jersey, Reagan said, "America's future rests in a thousand dreams inside your hearts. It rests in the message of hope in songs of a man so many young Americans admire, New Jersey's Bruce Springsteen." The Reagan campaign briefly used "Born in the U.S.A.", a song criticizing the treatment of Vietnam War veterans (which they mistakenly thought was devoid of anti-war content), as a campaign song, without permission, until Springsteen, a lifelong Democrat, insisted that they stop.
The Reagan campaign was very skilled at producing effective television advertising. Two of the more memorable ads it produced were commonly known as "Bear in the woods" and "Morning in America".
Reagan was the oldest president to have ever served (he was by this point 73), and there were many questions about his capacity to endure the grueling demands of the presidency, particularly after Reagan had a poor showing in his first debate with Mondale on October 7. He referred to having started going to church "here in Washington", although the debate was in Louisville, Kentucky, referred to military uniforms as "wardrobe," and admitted to being "confused," among other mistakes. In the next debate on October 21, however, Reagan joked "I will not make age an issue of this campaign. I am not going to exploit, for political purposes, my opponent's youth and inexperience." Mondale himself laughed at the joke, and later admitted that Reagan had effectively neutralized the age issue:
Results.
Reagan was re-elected in the November 6 election in an electoral and popular vote landslide, winning 49 states. Reagan won a record 525 electoral votes total (of 538 possible), and received 58.8 percent of the popular vote; despite Ferraro's selection, 55% of women who voted did so for Reagan, and his 54 to 61% of the Catholic vote was the highest for a Republican candidate in history. Mondale's 13 electoral college votes (from his home state of Minnesota—which he won by 0.18%—and the District of Columbia) marked the lowest total of any major Presidential candidate since Alf Landon's 1936 loss to Franklin D. Roosevelt. Mondale's defeat was also the worst for any Democratic Party candidate in American history in the Electoral College (and his 13 electoral votes the fewest any Democrat has won since Stephen A. Douglas claimed 12 in the 1860 election, when the Democratic vote was divided), though others, including Alton B. Parker, James M. Cox, John W. Davis, and George S. McGovern, did worse in the popular vote.
Psephologists attributed the Republican victory to "Reagan Democrats", millions of Democrats who voted for Reagan, as in 1980. They characterized such Reagan Democrats as southern whites and northern blue collar workers who voted for Reagan because they credited him with the economic recovery, saw Reagan as strong on national security issues, and perceived the Democrats as supporting the poor and minorities at the expense of the middle class. The Democratic National Committee commissioned a study after the election that came to these conclusions, but suppressed the report afraid that it would offend its key voters.
When Reagan was asked in December 1984 what he wanted for Christmas he joked, "Well, Minnesota would have been nice". Reagan lost Minnesota in both this election and in 1980, making it the only state he failed to win in either election, and also making him the first two-term president not to carry Minnesota since Woodrow Wilson. This is the last election where the Republican candidate achieved any of the following: Win every state in the Northeastern and Pacific regions of the United States; win at least one county in every state; and win any of the following states: Hawaii, Massachusetts, New York, Oregon, Rhode Island, Washington, and Wisconsin. This was also the last election in which the winning candidate won by a double-digit margin in the percentage of the popular vote, and the last election where the winning candidate won by an eight-digit margin in total popular votes (10 million or more).
Statistics.
Source for the popular vote: 
Source for the electoral vote: 
Close states.
Margin of victory less than 5% (27 electoral votes) 
Margin of victory more than 5%, but less than 10% (90 electoral votes) 
Aftermath.
After Mondale's loss to Reagan in the general election, Hart quickly emerged as the front-runner for the Democratic Party's 1988 presidential nomination. He maintained that lead until a sex scandal derailed his candidacy in 1987.

</doc>
<doc id="40573" url="https://en.wikipedia.org/wiki?curid=40573" title="NLP">
NLP

NLP may refer to:

</doc>
<doc id="40575" url="https://en.wikipedia.org/wiki?curid=40575" title="Vladimir the Great">
Vladimir the Great

Vladimir Sviatoslavich the Great (, "Volodiměrъ Svętoslavičь", Old Norse as "Valdamarr Sveinaldsson", , "Volodymyr", , "Vladimir", , "Uladzimir"; c. 958 – 15 July 1015, Berestove) was a prince of Novgorod, grand prince of Kiev, and ruler of Kievan Rus' from 980 to 1015.
Vladimir's father was prince Sviatoslav of the Rurik dynasty. After the death of his father in 972, Vladimir, who was then prince of Novgorod, was forced to flee to Scandinavia in 976 after his brother Yaropolk had murdered his other brother Oleg and conquered Rus'. In Sweden, with the help from his relative Ladejarl Håkon Sigurdsson, ruler of Norway, he assembled a Varangian army and reconquered Novgorod from Yaropolk. By 980 Vladimir had consolidated the Kievan realm from modern-day Ukraine to the Baltic Sea and had solidified the frontiers against incursions of Bulgarian, Baltic, and Eastern nomads. Originally a follower of Slavic paganism, Vladimir converted to Christianity in 988 and Christianized the Kievan Rus'.
Rise to the throne.
Born in 958, Vladimir was the natural son and youngest son of Sviatoslav I of Kiev by his housekeeper Malusha. Malusha is described in the Norse sagas as a prophetess who lived to the age of 100 and was brought from her cave to the palace to predict the future. Malusha's brother Dobrynya was Vladimir's tutor and most trusted advisor. Hagiographic tradition of dubious authenticity also connects his childhood with the name of his grandmother, Olga Prekrasa, who was Christian and governed the capital during Sviatoslav's frequent military campaigns. His place of birth is identified by different authors either as Budyatychi (modern Volyn Oblast, Ukraine) or Budnik (:ru:Будник (деревня); modern Pskov Oblast, Russia).
Transferring his capital to Pereyaslavets in 969, Sviatoslav designated Vladimir ruler of Novgorod the Great but gave Kiev to his legitimate son Yaropolk. After Sviatoslav's death in 972, a fratricidal war erupted in 976 between Yaropolk and his younger brother Oleg, ruler of the Drevlians. In 977 Vladimir fled to his kinsman Haakon Sigurdsson, ruler of Norway, collecting as many Norse warriors as he could to assist him to recover Novgorod. On his return the next year, he marched against Yaropolk. On his way to Kiev he sent ambassadors to Rogvolod (Norse: Ragnvald), prince of Polotsk, to sue for the hand of his daughter Rogneda (Norse: Ragnhild). The high-born princess refused to affiance herself to the son of a bondswoman, so Vladimir attacked Polotsk, slew Rogvolod, and took Ragnhild by force. Polotsk was a key fortress on the way to Kiev, and capturing Polotsk and Smolensk facilitated the taking of Kiev in 978, where he slew Yaropolk by treachery and was proclaimed knyaz of all Kievan Rus.
Years of pagan rule.
Vladimir continued to expand his territories beyond his father's extensive domain. In 981, he seized the Cherven towns from the Poles; in 981-982 he suppressed a Vyatichi rebellion; in 983, he subdued the Yatvingians; in 984, he conquered the Radimichs; and in 985, he conducted a military campaign against the Volga Bulgars, planting numerous fortresses and colonies on his way.
Although Christianity spread in the region under Oleg's rule, Vladimir had remained a thoroughgoing pagan, taking eight hundred concubines (along with numerous wives) and erecting pagan statues and shrines to gods. He may have attempted to reform Slavic paganism by establishing the thunder-god, Perun, as a supreme deity.
Open abuse of the deities that most people in Rus' revered triggered widespread indignation. A mob killed the Christian Fyodor and his son Ioann (later, after the overall christening of Kievan Rus, people came to regard these two as the first Christian martyrs in Rus', and the Orthodox Church set a day to commemorate them, July 25). Immediately after the murder of Fyodor and Ioann, early medieval Rus' saw persecutions against Christians, many of whom escaped or concealed their belief.
However, Prince Vladimir mused over the incident long after, and not least for political considerations. According to the early Slavic chronicle called Tale of Bygone Years, which describes life in Kyivan Rus' up to the year 1110, he sent his envoys throughout the civilized world to judge first hand the major religions of the time, Islam, Roman Catholicism, Judaism, and Byzantine Orthodoxy. They were most impressed with their visit to Constantinople, saying, "We knew not whether we were in Heaven or on Earth… We only know that God dwells there among the people, and their service is fairer than the ceremonies of other nations."
Christianization of the Kievan Rus'.
The Primary Chronicle reports that in the year 987, after consultation with his boyars, Vladimir the Great sent envoys to study the religions of the various neighboring nations whose representatives had been urging him to embrace their respective faiths. The result is described by the chronicler Nestor. Of the Muslim Bulgarians of the Volga the envoys reported there is no gladness among them, only sorrow and a great stench. He also reported that Islam was undesirable due to its taboo against alcoholic beverages and pork. Vladimir remarked on the occasion: "Drinking is the joy of all Rus'. We cannot exist without that pleasure." Ukrainian and Russian sources also describe Vladimir consulting with Jewish envoys and questioning them about their religion, but ultimately rejecting it as well, saying that their loss of Jerusalem was evidence that they had been abandoned by God. His emissaries also visited Roman Catholic and Orthodox missionaries. Ultimately Vladimir settled on Eastern Orthodox Christianity. In the churches of the Germans his emissaries saw no beauty; but at Constantinople, where the full festival ritual of the Byzantine Church was set in motion to impress them, they found their ideal: ""We no longer knew whether we were in heaven or on earth,"" they reported, describing a majestic Divine Liturgy in Hagia Sophia, ""nor such beauty, and we know not how to tell of it."" If Vladimir was impressed by this account of his envoys, he was even more attracted by the political gains of the Byzantine alliance.
In 988, having taken the town of Chersonesos in Crimea, he boldly negotiated for the hand of emperor Basil II's sister, Anna. Never before had a Byzantine imperial princess, and one "born in the purple" at that, married a barbarian, as matrimonial offers of French kings and German emperors had been peremptorily rejected. In short, to marry the 27-year-old princess to a pagan Slav seemed impossible. Vladimir was baptized at Chersonesos, however, taking the Christian name of Basil out of compliment to his imperial brother-in-law; the sacrament was followed by his wedding to Anna. Returning to Kiev in triumph, he destroyed pagan monuments and established many churches, starting with a church dedicated to St. Basil, and the Church of the Tithes (989).
Arab sources, both Muslim and Christian, present a different story of Vladimir's conversion. Yahya of Antioch, al-Rudhrawari, al-Makin, Al-Dimashqi, and ibn al-Athir all give essentially the same account. In 987, Bardas Sclerus and Bardas Phocas revolted against the Byzantine emperor Basil II. Both rebels briefly joined forces, but then Bardas Phocas proclaimed himself emperor on 14 September 987. Basil II turned to the Kievan Rus' for assistance, even though they were considered enemies at that time. Vladimir agreed, in exchange for a marital tie; he also agreed to accept Christianity as his religion and to Christianize his people. When the wedding arrangements were settled, Vladimir dispatched 6,000 troops to the Byzantine Empire, and they helped to put down the revolt.
Christian reign.
Vladimir then formed a great council out of his boyars and set his twelve sons over his subject principalities. According to the Primary Chronicle, he founded the city of Belgorod in 991. In 992 he went on a campaign against the Croats, most likely the White Croats that lived on the border of modern Ukraine. This campaign was cut short by the attacks of the Pechenegs on and around Kiev.
In his later years he lived in a relative peace with his other neighbors: Boleslav I of Poland, Stephen I of Hungary, and Andrikh the Czech (questionable character mentioned in A Tale of the Bygone Years). After Anna's death, he married again, likely to a granddaughter of Otto the Great.
In 1014 his son Yaroslav the Wise stopped paying tribute. Vladimir decided to chastise the insolence of his son and began gathering troops against him. Vladimir fell ill, however, most likely of old age, and died at Berestovo, near Kiev. The various parts of his dismembered body were distributed among his numerous sacred foundations and were venerated as relics.
Family.
The fate of all Vladimir's daughters, whose number is around nine, is uncertain.
Significance and legacy.
The Roman Catholic and Eastern Orthodox churches celebrate the feast day of St. Vladimir on 15 July.
The town Volodymyr-Volynskyi in north-western Ukraine was founded by Vladimir and is named after him. The foundation of another town, Vladimir in Russia, is usually attributed to Vladimir Monomakh. However some researchers argue that it was also founded by Vladimir the Great.
St Volodymyr's Cathedral, one of the largest cathedrals in Kiev, is dedicated to Vladimir the Great, as was originally the University of Kiev. The Imperial Russian Order of St. Vladimir and Saint Vladimir's Orthodox Theological Seminary in the United States are also named after him.
The memory of Vladimir was also kept alive by innumerable Russian folk ballads and legends, which refer to him as "Krasno Solnyshko" (the "Fair Sun"). The Varangian period of Eastern Slavic history ceases with Vladimir, and the Christian period begins.
The appropriation of Kievan Rus' as part of national history has also been a topic of contention in Ukrainophile vs. Russophile schools of historiography since the Soviet era.

</doc>
<doc id="40577" url="https://en.wikipedia.org/wiki?curid=40577" title="Christus Dominus">
Christus Dominus

Christus Dominus is the Second Vatican Council's Decree on the Pastoral Office of Bishops. It was approved by a vote of 2,319 to 2 of the assembled bishops and was promulgated by Pope Paul VI on 28 October 1965. The title in Latin means "Christ the Lord," and is from the first line of the decree, as is customary for Roman Catholic documents. (The full text in English is available from the Holy See's website.)
Apostolic College.
The role of the bishops of the Church was brought into renewed prominence, especially when seen collectively, as a college that has succeeded to that of the apostles in teaching and governing the Church. This college does not exist without its head, the successor of St. Peter.
In these days especially bishops frequently are unable to fulfill their office effectively and fruitfully unless they develop a common effort involving constant growth in harmony and closeness of ties with other bishops. Episcopal conferences already established in many nations-have furnished outstanding proofs of a more fruitful apostolate. Therefore, this sacred synod considers it to be supremely fitting that everywhere bishops belonging to the same nation or region form an association which would meet at fixed times. Thus, when the insights of prudence and experience have been shared and views exchanged, there will emerge a holy union of energies in the service of the common good of the churches. ("CD" 37)
Preliminary Note.
Accordingly, claims made by some, that the Council gave the Church two separate earthly heads, the College of Bishops and the Pope, were countered by the "Preliminary Explanatory Note" added to the Dogmatic Constitution on the Church "Lumen Gentium" and printed at the end of the text.
This Note states:
There is no such thing as the college without its head ... and in the college the head preserves intact his function as Vicar of Christ and pastor of the universal Church. In other words it is not a distinction between the Roman Pontiff and the bishops taken together, but between the Roman Pontiff by himself and the Roman Pontiff along with the bishops.
Episcopal conferences.
In many countries, bishops already held regular conferences to discuss common matters. The Council required the setting up of such episcopal conferences, entrusting to them responsibility for the necessary adaptation to local conditions of general norms. Certain decisions of the conferences have binding force for individual bishops and their dioceses, but only if adopted by a two-thirds majority and confirmed by the Holy See.
Regional conferences, such as the CELAM, exist to assist in promoting common action on a regional or continental level, but do not have even that level of legislative power.
Controversy.
After the publication of "Humanae vitae" in 1968, several problems emerged with the notion of collegiality promoted in the document. The fact that several episcopal conferences would openly rebel against the Pope had been unthinkable during the papacy of Pius XII. Prominent members in the Roman Curia deplored the fact that conference leaders appeared to behave as if they were regional popes. This complaint is notably found in the 1985 Ratzinger Report, a series of interviews where Cardinal Joseph Ratzinger deplores the lack of structure, organization and coordination between Rome and the local assemblies of Catholic bishops.

</doc>
<doc id="40579" url="https://en.wikipedia.org/wiki?curid=40579" title="Gill">
Gill

A gill () is a respiratory organ found in many aquatic organisms that extracts dissolved oxygen from water and excretes carbon dioxide. The gills of some species, such as hermit crabs, have adapted to allow respiration on land provided they are kept moist. The microscopic structure of a gill presents a large surface area to the external environment.
Many microscopic aquatic animals, and some larger but inactive ones, can absorb adequate oxygen through the entire surface of their bodies, and so can respire adequately without a gill. However, more complex or more active aquatic organisms usually require a gill or gills.
Gills usually consist of thin filaments of tissue, branches, or slender, tufted processes that have a highly folded surface to increase surface area. A high surface area is crucial to the gas exchange of aquatic organisms, as water contains only a small fraction of the dissolved oxygen that air does. A cubic meter of air contains about 250 grams of oxygen at STP. The concentration of oxygen in water is lower than air and it diffuses more slowly. In fresh water, the dissolved oxygen content is approximately 8 cm3/L compared to that of air which is 210 cm3/L. Water is 777 times more dense than air and is 100 times more viscous. Oxygen has a diffusion rate in air 10,000 times greater than in water. The use of sac-like lungs to remove oxygen from water would not be efficient enough to sustain life. Rather than using lungs, "aseous exchange takes place across the surface of highly vascularised gills over which a one-way current of water is kept flowing by a specialised pumping mechanism. The density of the water prevents the gills from collapsing and lying on top of each other, which is what happens when a fish is taken out of water."
With the exception of some aquatic insects, the filaments and lamellae (folds) contain blood or coelomic fluid, from which gases are exchanged through the thin walls. The blood carries oxygen to other parts of the body. Carbon dioxide passes from the blood through the thin gill tissue into the water. Gills or gill-like organs, located in different parts of the body, are found in various groups of aquatic animals, including mollusks, crustaceans, insects, fish, and amphibians.
Vertebrate gills.
The gills of vertebrates typically develop in the walls of the pharynx, along a series of gill slits opening to the exterior. Most species employ a countercurrent exchange system to enhance the diffusion of substances in and out of the gill, with blood and water flowing in opposite directions to each other. The gills are composed of comb-like filaments, the gill lamellae, which help increase their surface area for oxygen exchange.
When a fish breathes, it draws in a mouthful of water at regular intervals. Then it draws the sides of its throat together, forcing the water through the gill openings, so it passes over the gills to the outside. Fish gill slits may be the evolutionary ancestors of the tonsils, thymus glands, and Eustachian tubes, as well as many other structures derived from the embryonic branchial pouches.
Fish.
Cartilaginous fish.
Sharks and rays typically have five pairs of gill slits that open directly to the outside of the body, though some more primitive sharks have six pairs. Adjacent slits are separated by a cartilaginous gill arch from which projects a cartilaginous gill ray. This gill ray is the support for the sheet-like interbranchial septum, which the individual lamellae of the gills lie on either side of. The base of the arch may also support gill rakers, projections into the pharyngeal cavity that help to prevent large pieces of debris from damaging the delicate gills.
A smaller opening, the spiracle, lies in the back of the first gill slit. This bears a small pseudobranch that resembles a gill in structure, but only receives blood already oxygenated by the true gills. The spiracle is thought to be homologous to the ear opening in higher vertebrates.
Most sharks rely on ram ventilation, forcing water into the mouth and over the gills by rapidly swimming forward. In slow-moving or bottom-dwelling species, especially among skates and rays, the spiracle may be enlarged, and the fish breathes by sucking water through this opening, instead of through the mouth.
Chimaeras differ from other cartilagenous fish, having lost both the spiracle and the fifth gill slit. The remaining slits are covered by an operculum, developed from the septum of the gill arch in front of the first gill.
Bony fish.
In bony fish, the gills lie in a branchial chamber covered by a bony operculum. The great majority of bony fish species have five pairs of gills, although a few have lost some over the course of evolution. The operculum can be important in adjusting the pressure of water inside of the pharynx to allow proper ventilation of the gills, so bony fish do not have to rely on ram ventilation (and hence near constant motion) to breathe. Valves inside the mouth keep the water from escaping.
The gill arches of bony fish typically have no septum, so the gills alone project from the arch, supported by individual gill rays. Some species retain gill rakers. Though all but the most primitive bony fish lack spiracles, the pseudobranch associated with them often remains, being located at the base of the operculum. This is, however, often greatly reduced, consisting of a small mass of cells without any remaining gill-like structure.
Marine teleosts also use gills to excrete electrolytes. The gills' large surface area tends to create a problem for fish that seek to regulate the osmolarity of their internal fluids. Salt water is less dilute than these internal fluids, so saltwater fish lose large quantities of water osmotically through their gills. To regain the water, they drink large amounts of sea water and excrete the salt. Fresh water is more dilute than the internal fluids of fish, however, so freshwater fish gain water osmotically through their gills.
Other vertebrates.
Lampreys and hagfish do not have gill slits as such. Instead, the gills are contained in spherical pouches, with a circular opening to the outside. Like the gill slits of higher fish, each pouch contains two gills. In some cases, the openings may be fused together, effectively forming an operculum. Lampreys have seven pairs of pouches, while hagfishes may have six to fourteen, depending on the species. In the hagfish, the pouches connect with the pharynx internally and a separate tube which has no respiratory tissue (the pharyngocutaneous duct) develops beneath the pharynx proper, expelling ingested debris by closing a valve at its anterior end.
Tadpoles of amphibians have from three to five gill slits that do not contain actual gills. Usually no spiracle or true operculum is present, though many species have operculum-like structures. Instead of internal gills, they develop three feathery external gills that grow from the outer surface of the gill arches. Sometimes, adults retain these, but they usually disappear at metamorphosis. Lungfish larvae also have external gills, as does the primitive ray-finned fish "Polypterus", though the latter has a structure different from amphibians. Some salamanders, such as the olm, and the mudpuppy, retain their external gills upon reaching adulthood.
Branchia.
Branchia (pl. branchiae) is the naturalists' name for gills. Galen observed that fish had multitudes of openings ("foramina"), big enough to admit gases, but too fine to give passage to water. Pliny the Elder held that fish respired by their gills, but observed that Aristotle was of another opinion. The word "branchia" comes from the Greek , "gills", plural of (in singular, meaning a fin).
Invertebrate gills.
Respiration in the Echinodermata (includes starfish and sea urchins) is carried out using a very primitive version of gills called papulae. These thin protuberances on the surface of the body contain diverticula of the water vascular system. Crustaceans, molluscs, and some aquatic insects have tufted gills or plate-like structures on the surfaces of their bodies.
The gills of aquatic insects are tracheal, but the air tubes are sealed, commonly connected to thin external plates or tufted structures that allow diffusion. The oxygen in these tubes is renewed through the gills. In the larval dragon fly, the wall of the caudal end of the alimentary tract (rectum) is richly supplied with tracheae as a rectal gill, and water pumped into and out of the rectum provides oxygen to the closed tracheae.
Plastron.
A plastron is a type of structural adaptation occurring among some aquatic arthropods (primarily insects), a form of physical gill which holds a thin film of atmospheric oxygen in an area with small openings called spiracles that connect to the tracheal system. The plastron typically consists of dense patches of hydrophobic setae on the body, which prevent water entry into the spiracles, but may also involve scales or microscopic ridges projecting from the cuticle. The physical properties of the interface between the trapped air film and surrounding water allow gas exchange through the spiracles, almost as if the insect were in atmospheric air. Carbon dioxide diffuses into the surrounding water due to its high solubility, while oxygen diffuses into the film as the concentration within the film has been reduced by respiration, and nitrogen also diffuses out as its tension has been increased. Oxygen diffuses into the air film at a higher rate than nitrogen diffuses out. However, water surrounding the insect can become oxygen-depleted if there is no water movement, so many such insects in still water actively direct a flow of water over their bodies.
The physical gill mechanism allows aquatic insects with plastrons to remain constantly submerged. Examples include many beetles in the family Elmidae, aquatic weevils, and true bugs in the family Aphelocheiridae, as well as at least one species of ricinuleid arachnid. A somewhat similar mechanism is used by the diving bell spider, which maintains an underwater bubble that exchanges gas like a plastron. Other diving insects (such as backswimmers, and hydrophilid beetles) may carry trapped air bubbles, but deplete the oxygen more quickly, and thus need constant replenishment.

</doc>
<doc id="40582" url="https://en.wikipedia.org/wiki?curid=40582" title="Polish United Workers' Party">
Polish United Workers' Party

The Polish United Workers' Party (PUWP; , PZPR) was the Communist party which governed the People's Republic of Poland from 1948 to 1989. Ideologically it was based on the theories of Marxism-Leninism.
Program and goals.
Until 1989, the PUWP held dictatorial powers (the amendment to the constitution of 1976 mentioned "a leading national force"), and controlled an unwieldy bureaucracy, the military, the secret police, and the economy.
Its main goal was to create a Communist society and help to propagate Communism all over the world. On paper, the party was organised on the basis of democratic centralism, which assumed a democratic appointment of authorities, making decisions, and managing its activity. Yet in fact, the key roles were played by the Central Committee, its Politburo and Secretariat, which were subject to the strict control of the authorities of the Soviet Union. These authorities decided about the policy and composition of the main organs; although, according to the statute, it was a responsibility of the members of the congress, which was held every five or six years. Between sessions, party conferences of the regional, county, district and work committees were taking place. The smallest organizational unit of the PUWP was the Fundamental Party Organization (FPO), which functioned in work places, schools, cultural institutions, etc.
The main part in the PUWP was played by professional politicians, or the so-called "party's hard core", formed by people who were recommended to manage the main state institutions, social organizations, and trade unions. In the crowning time of the PUWP's development (the end of the 1970s) it consisted of over 3.5 million members. The Political Office of the Central Committee, Secretariat and regional committees appointed the key posts not only within the party, but also in all organizations having ‘state’ in its name – from central offices to even small state and cooperative companies. It was called the nomenklatura system of the state and economy management. In certain areas of the economy, e.g., in agriculture, the nomenklatura system was controlled with an approval of the PUWP and by its allied parties, the United People's Party (agriculture and food production), and the Democratic Party (trade community, small enterprise, some cooperatives). After martial law began, the Patriotic Movement for National Rebirth was founded to organize these and other parties.
History.
Establishment and Sovietisation period.
This was one of the many communist parties that ruled in several countries of East Europe of that time. The Polish United Workers' Party was established at the unification congress of the CommunistPolish Workers' Party (PPR) and Polish Socialist Party (PPS) during meetings held from 15 to 21 December 1948. The unification was possible because the PPS activists who opposed unification (or rather absorption by Communists) had been forced out of the party. Similarly, the members of the PPR who were accused of "rightist – nationalistic deviation" were expelled. Thus, for all intents and purposes, the PZPR was the PPR under a new name. 
"Rightist-nationalist deviation" (Polish: odchylenie prawicowo-nacjonalistyczne) was a political propaganda term used by the Polish Stalinists against prominent activists, such as Władysław Gomułka and Marian Spychalski who opposed Soviet involvement in the Polish interior affairs, as well as internationalism displayed by the creation of the Cominform and the subsequent merger that created the PZPR. It is believed that it was Joseph Stalin who put pressure on Bolesław Bierut and Jakub Berman to remove Gomułka and Spychalski as well as their followers from power in 1948. It is estimated that over 25% of socialists were removed from power or expelled from political life.
Bolesław Bierut, an NKVD agent, and a hard Stalinist served as first Secretary General of the ruling PUWP from 1948 to 1956, playing a leading role in the Sovietisation of Poland and the installation of her most repressive regime. He had served as President since 1944 (though on a provisional basis until 1947). After a new constitution abolished the presidency, Bierut took over as Prime Minister. until his death in 1956.
Bierut oversaw the trials of many Polish wartime military leaders, such as General Stanisław Tatar and Brig. General Emil August Fieldorf, as well as 40 members of the Wolność i Niezawisłość (Freedom and Independence) organisation, various Church officials and many other opponents of the new regime including the "hero of Auschwitz", Witold Pilecki, condemned to death during secret trials. Bierut signed many of those death sentences.
Bierut's death in Moscow in 1956 (shortly after attending the 20th Congress of the Communist Party of the Soviet Union) gave rise to much speculation about poisoning or a suicide, and symbolically marked the end of the era of Stalinism in Poland.
Gomułka's autarchic communism.
In 1956, shortly after the 20th Congress of the Communist Party of the Soviet Union, the PUWP leadership split in two factions, dubbed "Natolinians" and "Puławians". The Natolin faction - named after the place where its meetings took place, in a government villa in Natolin - were against the post-Stalinist liberalization programs ("Gomułka thaw") and they proclaimed simple nationalist and antisemitic slogans as part of a strategy to gain power. The most well known members included Franciszek Jóźwiak, Wiktor Kłosiewicz, Zenon Nowak, Aleksander Zawadzki, Władysław Dworakowski, Hilary Chełchowski.
The Puławian faction - the name comes from the Puławska Street in Warsaw, on which many of the members lived - sought great liberalization of socialism in Poland. After the events of Poznań June, they successfully backed the candidature of Władysław Gomułka for First Secretary of party, thus imposing a major setback upon Natolinians. Among the most prominent members were Roman Zambrowski and Leon Kasman. Both factions disappeared towards the end of the 1950s.
Initially very popular for his reforms and seeking a "Polish way to socialism", and beginning an era known as "Gomułka's thaw", he came under Soviet pressure. In the 1960s he supported persecution of the Roman Catholic Church and intellectuals (notably Leszek Kołakowski who was forced into exile). He participated in the Warsaw Pact intervention in Czechoslovakia in 1968. At that time he was also responsible for persecuting students as well as toughening censorship of the media. In 1968 he incited an anti-Zionist propaganda campaign, as a result of Soviet bloc opposition to the Six-Day War.
In December 1970, a bloody clash with shipyard workers in which several dozen workers were fatally shot forced his resignation (officially for health reasons; he had in fact suffered a stroke). A dynamic younger man, Edward Gierek, took over the Party leadership and tensions eased.
Gierek's economic opening.
In the late 1960s, Edward Gierek had created a personal power base and become the recognized leader of the young technocrat faction of the party. When rioting over economic conditions broke out in late 1970, Gierek replaced Władysław Gomułka as party first secretary. Gierek promised economic reform and instituted a program to modernize industry and increase the availability of consumer goods, doing so mostly through foreign loans. His good relations with Western politicians, especially France's Valéry Giscard d'Estaing and West Germany's Helmut Schmidt, were a catalyst for his receiving western aid and loans.
The standard of living increased markedly in the Poland of the 1970s, and for a time he was hailed a miracle-worker. The economy, however, began to falter during the 1973 oil crisis, and by 1976 price increases became necessary. New riots broke out in June 1976, and although they were forcibly suppressed, the planned price increases were canceled. High foreign debts, food shortages, and an outmoded industrial base compelled a new round of economic reforms in 1980. Once again, price increases set off protests across the country, especially in the Gdańsk and Szczecin shipyards. Gierek was forced to grant legal status to Solidarity and to concede the right to strike. (Gdańsk Agreement).
Shortly thereafter, in early September 1980, Gierek was replaced as by Stanisław Kania as General Secretary of the party by the Central Committee, amidst much social and economic unrest.
Kania admitted that the party had made many economic mistakes, and advocated working with Catholic and trade unionist opposition groups. He met with Solidarity Union leader Lech Wałęsa, and other critics of the party. Though Kania agreed with his predecessors that the Communist Party must maintain control of Poland, he never assured the Soviets that Poland would not pursue actions independent of the Soviet Union. On October 18, 1981, the Central Committee of the Party withdrew confidence on him, and Kania was replaced by Prime Minister (and Minister of Defence) Gen. Wojciech Jaruzelski.
Jaruzelski's autocratic rule.
On 11 February 1981, Jaruzelski was elected Prime Minister of Poland and became the first secretary of the Polish United Workers' Party on October 18 the same year. Before initiating the plan, he presented it to Soviet Premier Nikolai Tikhonov. On 13 December 1981, Jaruzelski imposed martial law in Poland
In 1982 Jaruzelski revitalized the Front of National Unity, the organization the Communists used to manage their satellite parties, as the Patriotic Movement for National Rebirth.
In 1985, Jaruzelski resigned as prime minister and defence minister and became chairman of the Polish Council of State, a post equivalent to that of president or a dictator, with his power centered on and firmly entrenched in his coterie of "LWP" generals and lower ranks officers of the Polish People's Army.
Breakdown of autocracy.
The attempt to impose a naked military dictatorship, notwithstanding, the policies of Mikhail Gorbachev stimulated political reform in Poland. By the close of the tenth plenary session in December 1988, the Polish United Workers Party was forced, after strikes, to approach leaders of Solidarity for talks.
From 6 February to 15 April 1989, negotiations were held between 13 working groups during 94 sessions of the roundtable talks.
These negotiations resulted in an agreement which stated that a great degree of political power would be given to a newly created bicameral legislature. It also created a new post of president to act as head of state and chief executive. Solidarity was also declared a legal organization. During the following Polish elections the Communists won 65 percent of the seats in the Sejm, though the seats won were guaranteed and the Communists were unable to gain a majority, while 99 out of the 100 seats in the Senate freely contested were won by Solidarity-backed candidates. Jaruzelski won the presidential ballot by one vote.
Jaruzelski was unsuccessful in convincing Wałęsa to include Solidarity in a "grand coalition" with the Communists, and resigned his position of general secretary of the Polish United Workers Party. The PZPR' two allied parties broke their long-standing alliance, forcing Jaruzelski to appoint Solidarity's Tadeusz Mazowiecki as the country's first non-Stalinist prime minister since 1948. Jaruzelski resigned as Poland's President in 1990, being succeeded by Wałęsa in December.
Dissolution of the PUWP.
Starting from January 1990, the collapse of the PUWP became inevitable. All over the country, public occupations of the party buildings started in order to prevent stealing the party's possessions and destroying or taking the archives. On 29 January 1990, XI Congress was held, which was supposed to recreate the party. Finally, the PUWP dissolved, and some of its members decided to establish two new social-democratic parties. They get over $1 million from the Communist Party of the Soviet Union known as the Moscow loan.
The former activists of the PUWP established the Social Democracy of the Republic of Poland (in Polish: Socjaldemokracja Rzeczpospolitej Polskiej, SdRP), of which the main organizers were Leszek Miller and Mieczysław Rakowski. The SdRP was supposed (among other things) to take over all rights and duties of the PUWP, and help to divide out the property of the former PUWP. Up to the end of the 1980s, it had considerable incomes mainly from managed properties and from the RSW company ‘Press- Book-Traffic’, which in turn had special tax concessions. During this period, the income from membership fees constituted only 30% of the PUWP's revenues. After the dissolution of the PUWP and the establishment of the SdRP, the rest of the activists formed the Social Democratic Union of the Republic of Poland (USdRP), which changed its name to the Polish Social Democratic Union, and The 8th July Movement.
At the end of 1990, there was an intense debate in the Sejm on the takeover of the wealth that belonged to the former PUWP. Over 3000 buildings and premises were included in the wealth and almost half of it was used without legal basis. Supporters of the acquisition argued that the wealth was built on the basis of plunder and the Treasury grant collected by the whole society. Opponents of SdRP claimed that the wealth was created from membership fees; therefore, they demanded wealth inheritance for SdPR which at that time administered the wealth. Personal property and the accounts of the former PUWP were not subject to control of a parliamentary committee.
On 9 November 1990, the Sejm passed "The resolution about the acquisition of the wealth that belonged to the former PUWP". This resolution was supposed to result in a final takeover of the PUWP real estate by the Treasury. As a result, only a part of the real estate was taken over mainly for a local government by 1992, whereas a legal dispute over the other party carried on till 2000. Personal property and finances of the former PUWP practically disappeared. According to the declaration of SdRP Members of Parliament, 90-95% of the party's wealth was allocated for gratuity or was donated for a social assistance.
The Polish Communist Party (2002) claims to be the successor of the party.
Building.
The Central Committee had its seat in the "Party's House", a building erected by obligatory subscription from 1948 to 1952 and colloquially called "White House" or the "House of Sheep". Since 1991 the Bank-Financial Center "New World" is located in this building. From 1991-2000 the Warsaw Stock Exchange also had its seat there.
Party leaders.
By the year 1954 the head of the party was the Chair of Central Committee:

</doc>
<doc id="40583" url="https://en.wikipedia.org/wiki?curid=40583" title="Peritoneum">
Peritoneum

The peritoneum is the serous membrane that forms the lining of the abdominal cavity or coelom in amniotes and some invertebrates, such as annelids. It covers most of the intra-abdominal (or coelomic) organs, and is composed of a layer of mesothelium supported by a thin layer of connective tissue. The peritoneum supports the abdominal organs and serves as a conduit for their blood vessels, lymph vessels, and nerves.
The abdominal cavity (the space bounded by the vertebrae, abdominal muscles, diaphragm, and pelvic floor) should not be confused with the intraperitoneal space (located within the abdominal cavity, but wrapped in peritoneum). The structures within the intraperitoneal space are called "intraperitoneal" (e.g. the stomach), the structures in the abdominal cavity that are located behind the intraperitoneal space are called "retroperitoneal" (e.g. the kidneys), and those structures below the intraperitoneal space are called "subperitoneal" or "infraperitoneal" (e.g. the bladder).
Structure.
Types.
Although they ultimately form one continuous sheet, two types or layers of peritoneum and a potential space between them are referenced:
Subdivisions.
Peritoneal folds are omenta, mesenteries and ligaments; they connect organs to each other or to the abdominal wall. There are two main regions of the peritoneal cavity, connected by the epiploic foramen (also known as the "omental foramen" or "foramen of winslow"):
The mesentery is the part of the peritoneum through which most abdominal organs are attached to the abdominal wall and supplied with blood and lymph vessels and nerves.
Other ligaments and folds.
In addition, in the pelvic cavity there are several structures that are usually named not for the peritoneum, but for the areas defined by the peritoneal folds:
Classification of abdominal structures.
The structures in the abdomen are classified as intraperitoneal, retroperitoneal or infraperitoneal depending on whether they are covered with visceral peritoneum and whether they are attached by mesenteries (mensentery, mesocolon).
Structures that are "intraperitoneal" are generally mobile, while those that are "retroperitoneal" are relatively fixed in their location.
Some structures, such as the kidneys, are "primarily retroperitoneal", while others such as the majority of the duodenum, are "secondarily retroperitoneal", meaning that structure developed intraperitoneally but lost its mesentery and thus became retroperitoneal.
Development.
The peritoneum develops ultimately from the mesoderm of the trilaminar embryo. As the mesoderm differentiates, one region known as the lateral plate mesoderm splits to form two layers separated by an intraembryonic coelom. These two layers develop later into the visceral and parietal layers found in all serous cavities, including the peritoneum.
As an embryo develops, the various abdominal organs grow into the abdominal cavity from structures in the abdominal wall. In this process they become enveloped in a layer of peritoneum. The growing organs "take their blood vessels with them" from the abdominal wall, and these blood vessels become covered by peritoneum, forming a mesentery.
Peritoneal folds develop from the ventral and dorsal mesentery of the embryo.
Clinical significance.
Peritoneal dialysis.
In one form of dialysis, called peritoneal dialysis, a glucose solution is sent through a tube into the peritoneal cavity. The fluid is left there for a prescribed amount of time to absorb waste products, and then removed through the tube. The reason for this effect is the high number of arteries and veins in the peritoneal cavity. Through the mechanism of diffusion, waste products are removed from the blood.
Peritonitis.
Peritonitis is the inflammation of the peritoneum. It is more commonly associated to infection from a punctured organ of the abdominal cavity. It can also be provoked by the presence of fluids that produce chemical irritation, such as gastric acid or pancreatic juice. Peritonitis causes fever, tenderness, and pain in the abdominal area, which can be localized or diffuse. The treatment involves rehydration, administration of antibiotics, and surgical correction of the underlying cause. Mortality is higher in the elderly and if present for a prolonged time.
Primary peritoneal carcinoma.
Primary peritoneal cancer is a cancer of the cells lining the peritoneum.
History.
Etymology.
"Peritoneum" is derived from Greek via Latin. "Peri-" means "around", while "-ton-" refers to stretching. Thus, peritoneum means "stretched around" or "stretched over".

</doc>
<doc id="40584" url="https://en.wikipedia.org/wiki?curid=40584" title="Pistachio">
Pistachio

The pistachio (, ; "Pistacia vera"), a member of the cashew family, is a small tree originating from Central Asia and the Middle East. The tree produces seeds that are widely consumed as food.
"Pistacia vera" often is confused with other species in the genus "Pistacia" that are also known as pistachio. These other species can be distinguished by their geographic distributions (in the wild) and their seeds which are much smaller and have a soft shell.
History.
Archaeology shows that pistachio seeds were a common food as early as 6750 BC. Pliny the Elder writes in his "Natural History" that "pistacia", "well known among us", was one of the trees unique to Syria, and that the seed was introduced into Italy by the Roman Proconsul in Syria, Lucius Vitellius the Elder (in office in 35 AD) and into Hispania at the same time by Flaccus Pompeius. The early sixth-century manuscript "De observatione ciborum" ("On the observance of foods") by Anthimus implies that "pistacia" remained well known in Europe in Late Antiquity. Archaeologists have found evidence from excavations at Jarmo in northeastern Iraq for the consumption of atlantic pistachio. The Hanging Gardens of Babylon were said to have contained pistachio trees during the reign of King Merodach-Baladan about 700 BC. 
The modern pistachio "P. vera" was first cultivated in Bronze Age Central Asia, where the earliest example is from Djarkutan, modern Uzbekistan. It appears in Dioscurides as "pistakia" πιστάκια, recognizable as "P. vera" by its comparison to pine nuts.
Additionally, remains of the Atlantic pistachio and pistachio seed along with nut-cracking tools were discovered by archaeologists at the Gesher Benot Ya'aqov site in Israel's Hula Valley, dated to 78,000 years ago.
More recently, the pistachio has been cultivated commercially in many parts of the English-speaking world, in Australia, and in New Mexico David Fairchild of the United States Department of Agriculture introduced hardier cultivars collected in China to California in 1904 and 1905, but it was not promoted as a commercial crop until 1929. Walter T. Swingle’s pistachios from Syria had already fruited well at Niles by 1917.
The earliest records of pistachio in English are around roughly year 1400, with the spellings "pistace" and "pistacia". The word pistachio comes from medieval Italian "pistacchio", which is from classical Latin "pistacium", which is from ancient Greek "pistákion" and "pistákē", which is generally believed to be from Middle Persian, although unattested in Middle Persian. Later in Persian, the word is attested as "pesteh". As mentioned, the tree came to the ancient Greeks from Western Asia.
Botany.
Habitat.
Pistachio is a desert plant, and is highly tolerant of saline soil. It has been reported to grow well when irrigated with water having 3,000–4,000 ppm of soluble salts. Pistachio trees are fairly hardy in the right conditions, and can survive temperatures ranging between in winter and in summer. They need a sunny position and well-drained soil. Pistachio trees do poorly in conditions of high humidity, and are susceptible to root rot in winter if they get too much water and the soil is not sufficiently free-draining. Long, hot summers are required for proper ripening of the fruit. They have been known to thrive in warm moist environments.
The Jylgyndy Forest Reserve, a preserve protecting the native habitat of "Pistacia vera" groves, is located in the Nooken District of Jalal-Abad Province of Kyrgyzstan.
Characteristics.
The bush grows up to tall. It has deciduous pinnate leaves 10–20 centimeters (4–8 inches) long. The plants are dioecious, with separate male and female trees. The flowers are apetalous and unisexual, and borne in panicles.
The fruit is a drupe, containing an elongated seed, which is the edible portion. The seed, commonly thought of as a nut, is a culinary nut, not a botanical nut. The fruit has a hard, creamish exterior shell. The seed has a mauvish skin and light green flesh, with a distinctive flavor. When the fruit ripens, the shell changes from green to an autumnal yellow/red, and abruptly splits part way open (see photo). This is known as dehiscence, and happens with an audible pop. The splitting open is a trait that has been selected by humans. Commercial cultivars vary in how consistently they split open.
Each pistachio tree averages around of seeds, or around 50,000, every two years.
The shell of the pistachio is naturally a beige color, but it is sometimes dyed red or green in commercial pistachios. Originally, dye was applied by importers to hide stains on the shells caused when the seeds were picked by hand. Most pistachios are now picked by machine and the shells remain unstained, making dyeing unnecessary except to meet ingrained consumer expectations. Roasted pistachio seeds can be artificially turned red if they are marinated prior to roasting in a salt and strawberry marinade, or salt and citrus salts.
Like other members of the Anacardiaceae family (which includes poison ivy, sumac, mango, and cashew), pistachios contain urushiol, an irritant that can cause allergic reactions.
Production and cultivation.
Iran, the United States and Turkey are the major producers of pistachios, together accounting for 83% of the world production in 2013 (table). 
Cultivation.
The trees are planted in orchards, and take approximately seven to ten years to reach significant production. Production is alternate-bearing or biennial-bearing, meaning the harvest is heavier in alternate years. Peak production is reached around 20 years. Trees are usually pruned to size to make the harvest easier. One male tree produces enough pollen for eight to 12 drupe-bearing females. Harvesting in the United States and in Greece is often accomplished using equipment to shake the drupes off the tree. After hulling and drying, pistachios are sorted according to open-mouth and closed-mouth shells. Sun-drying has been found to be the best method of drying, then they are roasted or processed by special machines to produce pistachio kernels.
Pistachio trees are vulnerable to a wide variety of diseases. Among these is infection by the fungus "Botryosphaeria", which causes panicle and shoot blight (symptoms include death of the flowers and young shoots), and can damage entire pistachio orchards.
In Greece, the cultivated type of pistachios has an almost-white shell, sweet taste, a red-green kernel and a closed-mouth shell relative to the 'Kerman' variety. Most of the production in Greece comes from the island of Aegina and the region of Thessaly-Almyros.
In California, almost all female pistachio trees are the cultivar 'Kerman'. A scion from a mature female 'Kerman' is grafted onto a one-year-old rootstock.
Bulk container shipments of pistachio kernels are prone to self-heating and spontaneous combustion because of their high fat and low water contents.
Consumption.
The kernels are often eaten whole, either fresh or roasted and salted, and are also used in pistachio ice cream, kulfi, spumoni, historically in Neapolitan ice cream, pistachio butter, pistachio paste and confections such as baklava, pistachio chocolate, pistachio halva, pistachio lokum or biscotti and cold cuts such as mortadella. Americans make pistachio salad, which includes fresh pistachios or pistachio pudding, whipped cream, and canned fruit.
In July 2003, the Food and Drug Administration (FDA) approved the first qualified health claim specific to seeds lowering the risk of heart disease: "Scientific evidence suggests but does not prove that eating per day of most nuts, such as pistachios, as part of a diet low in saturated fat and cholesterol may reduce the risk of heart disease".
China is the top pistachio consumer worldwide, with annual consumption of 80,000 tons, while the United States consumes 45,000 tons.
Nutritional information.
Pistachio is a nutritionally dense food. In a 100 gram serving, pistachios provide 562 calories and are a rich source (> 19% of the Daily Value or DV) of protein, dietary fiber, several dietary minerals and the B vitamins, thiamin and vitamin B6 (table). Pistachios are a good source (10-19% DV) of calcium, vitamin B5 and vitamin E (table).
The fat profile of raw pistachios consists of saturated fats, monounsaturated fats and polyunsaturated fats. Saturated fatty acids include palmitic acid (10% of total) and stearic acid (2%). Oleic acid is the most common monounsaturated fatty acid (51% of total fat) and linoleic acid, a polyunsaturated fatty acid (18% of total).
Toxin and safety concerns.
As with other tree seeds, aflatoxin is found in poorly harvested or processed pistachios. Aflatoxins are potent carcinogenic chemicals produced by molds such as "Aspergillus flavus" and "Aspergillus parasiticus". The mold contamination may occur from soil, poor storage, and spread by pests. High levels of mold growth typically appear as gray to black filament-like growth. It is unsafe to eat mold-infected and aflatoxin-contaminated pistachios. Aflatoxin contamination is a frequent risk, particularly in warmer and humid environments. Food contaminated with aflatoxins has been found as the cause of frequent outbreaks of acute illnesses in parts of the world. In some cases, such as Kenya, this has led to several deaths.
Pistachio shells typically split naturally prior to harvest, with a hull covering the intact seeds. The hull protects the kernel from invasion by molds and insects, but this hull protection can be damaged in the orchard by poor orchard management practices, by birds, or after harvest, which makes it much easier for pistachios to be exposed to contamination. Some pistachios undergo so-called "early split", wherein both the hull and the shell split. Damage or early splits can lead to aflatoxin contamination. In some cases, a harvest may be treated to keep contamination below strict food safety thresholds; in other cases, an entire batch of pistachios must be destroyed because of aflatoxin contamination. In September 1997, the European Union placed its first ban on pistachio imports from Iran due to high levels of aflatoxin. The ban was lifted in December 1997 after Iran introduced and improved food safety inspections and product quality.
Pistachio shells may be helpful in cleaning up pollution created by mercury emissions.

</doc>
<doc id="40586" url="https://en.wikipedia.org/wiki?curid=40586" title="Dorididae">
Dorididae

Sea lemon is a loosely applied common name for a group of medium-sized to large shell-less colorful sea slugs or nudibranchs, specifically dorid nudibranchs in the taxonomic family Dorididae and other closely related families. These are marine gastropod mollusks. 
The Monterey sea lemon is "Doris montereyensis" and the mottled pale sea lemon is "Diaulula lentiginosa".
The common name sea lemon probably comes from these animal's visual similarity to a lemon based on such qualities as the roughened skin, the oval form when seen from above, and the common but not inevitable orange to pale yellow coloration.
Description.
These dorid nudibranchs can be large (up to 20 cm), rather flattened, and oval in shape when seen from above. They have two hornlike projections (rhinophores) on the head, and a rosette-like tuft of gills on the back of the animal. The mantle is sometimes sprinkled with black dots, and it is covered in small bumps, which are called tubercles.
Life habits.
Sea lemons feed on sponges and other sessile animals or even on dead organic matter. They lay ribbons of white or yellow eggs. 
Taxonomically the Dorididae is a family of several genera, the "dorids" named after the mythological ancient Greek sea nymph Doris. (See Ovidius, "Metamorphoses" 2.6)
Genera.
Genera within the family Dorididae include:

</doc>
<doc id="40589" url="https://en.wikipedia.org/wiki?curid=40589" title="Thomas Joannes Stieltjes">
Thomas Joannes Stieltjes

Thomas Joannes Stieltjes (, 29 December 1856 – 31 December 1894) was a Dutch mathematician. He was born in Zwolle and died in Toulouse, France. He was a pioneer in the field of moment problems and contributed to the study of continued fractions.
The Thomas Stieltjes Institute for Mathematics at the University of Leiden is named after him, as is the Riemann–Stieltjes integral.
Biography.
Stieltjes was born in Zwolle on 29 December 1856. His father (who had the same first names) was a civil engineer and politician. Stieltjes Sr. was responsible for the construction of various harbours around Rotterdam, and also seated in the Dutch parliament. Stieltjes Jr. went to university at the Polytechnical School in Delft in 1873. Instead of attending lectures, he spent his student years reading the works of Gauss and Jacobi — the consequence of this being he failed his examinations. There were 2 further failures (in 1875 and 1876), and his father despaired. His father was friends with H. G. van de Sande Bakhuyzen (who was the director of Leiden University), and Stieltjes Jr. was able to get a job as an assistant at Leiden Observatory.
Soon afterwards, Stieltjes began a correspondence with Charles Hermite which lasted for the rest of his life. Stieltjes originally wrote to Hermite concerning celestial mechanics, but the subject quickly turned to mathematics and he began to devote his spare time to mathematical research.
The director of Leiden Observatory, van de Sande-Bakhuyzen, responded quickly to Stieltjes' request on 1 January 1883 to stop his observational work to allow him to work more on mathematical topics. In 1883, he also married Elizabeth Intveld in May. She also encouraged him to move from astronomy to mathematics. And in September, Stieltjes was asked to substitute at University of Delft for F J van den Berg. From then until December of that year, he lectured on analytical geometry and on descriptive geometry. He resigned his post at the observatory at the end of that year.
In 1884, Stieltjes applied for a chair in Groningen. He was initially accepted, but in the end turned down by the Department of Education, since he lacked the required diplomas. In 1884, Hermite and professor David Bierens de Haan arranged for an honorary doctorate to be granted to Stieltjes by Leiden University, enabling him to become a professor. In 1885, he was appointed as member of the Royal Dutch Academy of Sciences (Koninklijke Nederlandse Akademie van Wetenschappen, KNAW), the next year he became foreign member. In 1889, he was appointed professor of differential and integral calculus at Toulouse University.
Research.
Stieltjes worked on almost all branches of analysis, continued fractions and number theory, and for his work, he is sometimes called ""the father of the analytic theory of continued fractions"".
His work is also seen as important as a first step towards the theory of Hilbert spaces. Other important contributions to mathematics that he made involved discontinuous functions and divergent series, differential equations, interpolation, the gamma function and elliptic functions.
Awards.
Stieltjes' work on continued fractions earned him the Ormoy Prize of the Académie des Sciences.

</doc>
<doc id="40590" url="https://en.wikipedia.org/wiki?curid=40590" title="Vladimir of Novgorod">
Vladimir of Novgorod

Vladimir Yaroslavich () (1020 – October 4, 1052) reigned as prince of Novgorod from 1036 until his death. He was the eldest son of Yaroslav I the Wise of Kiev by Ingigerd, daughter of king Olof Skötkonung of Sweden. 
In the state affairs he was assisted by the voivode Vyshata and the bishop Luka Zhidiata. In 1042, Vladimir may have been in conflict with Finns, according to some interpretations even making a military campaign in Finland. In the next year he led the Russian armies together with Harald III of Norway against the Byzantine emperor Constantine IX. He predeceased his father by two years and was buried by him in St Sophia Cathedral he had built in Novgorod. His sarcophagus is in a niche on the south side of the main body of the cathedral overlooking the Martirievskii Porch. He is depicted in an early twentieth-century fresco above the sarcophagus and on a new ephigial icon on top of the sarcophagus. The details of his death is unknown, however his son Rostislav and his descendants were in unfriendly relationship with the descendants of the Yaroslaviches triumvirate (Iziaslav, Sviatoslav, and Vsevolod). Three of Vladimir's younger brothers Izyaslav I, Svyatoslav II and Vsevolod I all reigned in Kiev, while other two (Igor and Vyacheslav) died in their early twenties after which their lands were split between the Yaroslaviches triumvirate. Coincidentally, the Vyshata of Novgorod pledged his support to Rostislav in the struggle against the triumvirate.
Vladimir's only son, Rostislav Vladimirovich, was a landless prince who usurped power in Tmutarakan. His descendants were dispossessed by their uncles and were proclaimed as izgoi (outcast), but gradually managed to establish themselves in Halychyna, ruling the land until 1199, when their line became extinct. In order to downplay their claims to Kiev, the records of Vladimir's military campaigns seem to have been obliterated from Kievan chronicles. As a result, medieval historians often confuse him with two more famous namesakes — Vladimir the Great and Vladimir Monomakh. The name of Vladimir's consort is uncertain either. According to Nikolai Baumgarten, Vladimir was married to the daughter of count Leopold of Staden, Ode. Others (Aleksandr Nazarenko) disregard that assumption or claim a different person.
Vladimir's memory was better preserved in foreign sources. In Norse sagas he frequently figures as Valdemar Holti (that is, "the Nimble"). George Cedrenus noticed Vladimir's arrogance in dealing with the Byzantines.

</doc>
<doc id="40591" url="https://en.wikipedia.org/wiki?curid=40591" title="Johann Mühlegg">
Johann Mühlegg

Johann Mühlegg (born 8 November 1970 in Ostallgäu, Germany) is a former top level cross-country skier who competed in international competitions first representing Germany and then Spain, after becoming a Spanish citizen in 1999. He was excluded and disqualified from the 2002 Winter Olympics in Salt Lake City for doping.
Early career.
Mühlegg participated for Germany in the 1992, 1994 and 1998 Winter Olympics, even though he began having trouble with Germany's ski federation in 1993. From the beginning, Mühlegg singled himself out, at one point accusing German head coach Georg Zipfel for "damaging him spiritually" (the so-called "Spiritistenaffäre"). He was thrown off the team in 1995, but was reinstated later. But from that moment on, the ever eccentric Mühlegg insisted on taking a flask of holy water with him at all times, and trusting only his Portuguese cleaning woman/chaperone Justina Agostino. In the end, Mühlegg was branded as a team cancer and was thrown out.
Competing for Spain.
After being ejected from the national team after the 1998 Nagano Games, his good relations with members of the Spanish cross-country skiing team, in particular Juan Jesús Gutiérrez Cuevas and Haritz Zunzunegui, opened the door for Mühlegg to obtain Spanish citizenship.
In late 1999, competing for Spain, he won a World Cup race for the first time. At the 2001 FIS Nordic World Ski Championships in Lahti, he won two medals with a silver in the 10 km + 10 km combined pursuit (stepping up when the original medalist Jari Isometsä was disqualified for hemohes use), and a gold in the 50 km freestyle race.
In the 2002 Winter Olympics in Salt Lake City, Mühlegg won gold medals in the 30 km freestyle and the 10 km + 10 km pursuit races, the successes gaining him congratulations from King Juan Carlos of Spain.
Mühlegg finished first in the 50 km classical race held on the final Saturday of the Salt Lake City Winter Olympic Games on 23 February 2002 but was disqualified from that race and was expelled from the Games the next day, after testing positive for darbepoetin¹ (a medicine which boosts red blood cell count; the substance was not banned at the time since it had only recently been developed).
Doping controversy.
Following the darbepoetin scandal, the International Olympic Committee (IOC) initially let Mühlegg keep his gold medals from the first two races. But in December 2003 a ruling by the Court of Arbitration for Sport (CAS) found that these medals should also be withdrawn. The CAS remitted this case as well as similar ones involving Olga Danilova and Larisa Lazutina (both from Russia) to the IOC Executive Board, which confirmed the rulings in February 2004.

</doc>
<doc id="40592" url="https://en.wikipedia.org/wiki?curid=40592" title="Darbepoetin alfa">
Darbepoetin alfa

Darbepoetin alfa (rINN) is a synthetic form of erythropoietin. It stimulates erythropoiesis (increases red blood cell levels) and is used to treat anemia, commonly associated with chronic renal failure and cancer chemotherapy. Darbepoetin is marketed by Amgen under the trade name Aranesp.
The drug was approved in September 2001 by the Food and Drug Administration for treatment of anemia in patients with chronic renal failure by intravenous or subcutaneous injection. In June 2001, it had been approved by the European Medicines Agency for this indication as well as the treatment of anemia in cancer patients undergoing chemotherapy.
Dr. Reddy's Laboratories launched darbepoetin alfa in India under the brand name ‘Cresp’ in August 2010. This is the world’s first generic darbepoetin alfa. Cresp has been approved in India.
Darbepoetin is produced by recombinant DNA technology in modified Chinese hamster ovary cells. It differs from endogenous erythropoietin (EPO) by containing two more N-linked oligosaccharide chains. It is an erythropoiesis-stimulating 165-amino acid protein.
Contraindications.
Use of darbepoetin alfa is contraindicated in patients with hypersensitivity to the drug, pre-existing uncontrolled hypertension, and pure red cell aplasia.
Adverse effects.
Darbepoetin alfa has black box warnings in the United States for increased risk of death, myocardial infarction, stroke, venous thromboembolism, thrombosis of vascular access, and tumor progression or recurrence. To avoid side effects, it is recommended for patients with chronic renal failure or cancer to use the lowest possible dose needed to avoid red blood cell (RBC) transfusions.
In addition to those listed in the black box warning, use of darbepoetin alfa also increases the risk of cardiovascular problems, including cardiac arrest, arrhythmia, hypertension and congestive heart failure, and edema. A recent study has extended these findings to treatment of patients exhibiting cancer-related anemia (distinct from anemia resulting from chemotherapy). Other reported adverse reactions include increased risk of seizure, hypotension, and chest pain.
Pregnancy and lactation.
Darbepoetin alfa is a Pregnancy Category C drug in the United States. Pregnant women who are taking darbepoetin alfa may enroll in Amgen’s Pregnancy Surveillance Program (800-772-6436).
It is not known if darbepoetin alfa is excreted in breast milk. Mothers who choose to breast-feed are advised to use caution.
Mechanism of action.
Darbepoetin alfa binds to the erythropoietin receptor on erythroid progenitor cells, stimulating RBC production and differentiation.
Safety advisories in anemic cancer patients.
Amgen sent a "dear doctor" letter in January, 2007, that highlighted results from a recent anemia of cancer trial, and warned doctors to consider use in that off-label indication with caution.
Amgen advised the U.S. Food and Drug Administration (FDA) as to the results of the DAHANCA 10 clinical trial. The DAHANCA 10 data monitoring committee found that 3-year loco-regional control in subjects treated with Aranesp was significantly worse than for those not receiving Aranesp (p=0.01).
In response to these advisories, the FDA released a Public Health Advisory
on March 9, 2007, and a clinical alert for doctors on February 16, 2007, about the use of erythropoeisis-stimulating agents (ESAs) such as epoetin alfa (marketed as Epogen) and darbepoetin alfa. The advisory recommended caution in using these agents in cancer patients receiving chemotherapy or off chemotherapy, and indicated a lack of clinical evidence to support improvements in quality of life or transfusion requirements in these settings.
According to the 2010 update to clinical practice guidelines from the American Society of Clinical Oncology (ASCO) and the American Society of Hematology (ASH), use of ESAs such as darbepoetin alfa in cancer patients is appropriate when following stipulations outlined in FDA-approved labeling.
Society and culture.
Like EPO, darbepoetin alfa has the potential to be abused by athletes seeking a competitive advantage. Its use during the 2002 Winter Olympic Games to improve performance led to the disqualification of cross-country skiers Larisa Lazutina and Olga Danilova of Russia and Johann Mühlegg of Spain from their final races.
Economics.
Epogen and Aranesp had more than $6 billion in combined sales in 2006. Procrit sales were about $3.2 billion in 2006.

</doc>
<doc id="40594" url="https://en.wikipedia.org/wiki?curid=40594" title="Pseudonym">
Pseudonym

A pseudonym ( and ) or alias is a name that a person or group assumes for a particular purpose, which can differ from their original or true name (orthonym). Pseudonyms include stage names and user names (both called "screen names"), ring names, pen names, nicknames, aliases, superhero identities and code names, gamer identifications, and regnal names of emperors, popes, and other monarchs. Historically, they have often taken the form of anagrams, Graecisms, and Latinisations, although there are many other methods of choosing a pseudonym.
Pseudonyms are most usually adopted to hide an individual's real identity, as with writers' pen names, graffiti artists' tags, resistance fighters' or terrorists' "noms de guerre", and computer hackers' handles. Actors, musicians, and other performers sometimes use stage names, for example, to mask their ethnic backgrounds.
In some cases, pseudonyms are adopted because they are part of a cultural or organisational tradition: for example devotional names used by members of some religious institutes, and "cadre names" used by Communist party leaders such as Trotsky and Lenin.
A pseudonym may also be used for personal reasons: for example, an individual may prefer to be called or known by a name that differs from their given or legal name, but is not ready to take the numerous steps to get their name legally changed; or an individual may simply feel that the context and content of an exchange offer no reason, legal or otherwise, to provide their given or legal name.
A "collective name" or "collective pseudonym" is one shared by two or more persons, for example the co-authors of a work, such as Ellery Queen, or Nicolas Bourbaki.
Etymology.
The term is derived from the Greek ("pseudṓnymon"), literally "false name", from ("pseûdos"), "lie, falsehood" and ("ónoma"), "name". A pseudonym is distinct from an "allonym", which is the (real) name of another person, assumed by the author of a work of art. This may occur when someone is ghostwriting a book or play, or in parody, or when using a "front" name, such as by screenwriters blacklisted in Hollywood in the 1950s and 1960s. See also pseudepigraph, for "falsely" attributed authorship.
Concealment of identity.
Literary pen names.
A pen name (or ""nom de plume"") is a pseudonym (sometimes a particular form of the real name) adopted by an author (or on the author's behalf by their publishers). Many pen names are used to conceal the author's identity. One famous example of this is Samuel Clemens' writing under the pen name Mark Twain. A pen name may be used if a writer's real name is likely to be confused with the name of another writer or notable individual, or if their real name is deemed to be unsuitable. Authors who write both fiction and non-fiction, or in different genres, may use different pen names to avoid confusing their readers, as in the case of mathematician Charles Dodgson, who wrote fantasy novels under the pen name Lewis Carroll and mathematical treatises under his own name. Some authors, such as Harold Robbins, use several literary pseudonyms.
The Brontë family used pen names for their early work, so as not to reveal their gender (see below) and so that local residents would not know that the books related to people of the neighbourhood. The Brontës used their neighbours as inspiration for characters in many of their books. Anne Brontë published "The Tenant of Wildfell Hall" under the name Acton Bell. Charlotte Brontë published "Shirley" and "Jane Eyre" under the name Currer Bell. Emily Brontë published "Wuthering Heights" as Ellis Bell.
Some female authors used male pen names, in particular in the 19th century, when writing was a male-dominated profession. In contrast, some twentieth and twenty first century male romance novelists have used female pen names. A well-known example of the former is Mary Ann Evans, who wrote as George Eliot. Another example is Amandine Aurore Lucile Dupin, a 19th-century French writer who used the pen name George Sand. Jane Austen used the pseudonym "A Lady" as the author of her first novel "Sense and Sensibility". A few examples of male authors using female pseudonyms include Brindle Chase, Peter O'Donnell (wrote as Madeline Brent) and Christopher Wood (wrote as Penny Sutton and Rosie Dixon).
Some pen names are not strictly pseudonyms, as they are simply variants of the authors' actual names. The authors C. L. Moore and S. E. Hinton were female authors who used the initialised forms of their full names. C. L. Moore was Catherine Lucille Moore, who wrote in the 1930s male-dominated science fiction genre, and S. E. Hinton, (author of "The Outsiders") is Susan Eloise Hinton. "Star Trek" writer D. C. Fontana (Dorothy Catherine) wrote using her abbreviated own name and also under the pen names Michael Richards and J. Michael Bingham. Author V.C. Andrews intended to publish under her given name of Virginia Andrews, but was told that, due to a production error, her first novel was being released under the name of "V.C. Andrews"; later she learned that her publisher had in fact done this deliberately. Joanne Kathleen Rowling published the "Harry Potter" series under the shortened name J. K. Rowling. Rowling also published a detective novel The Cuckoo's Calling under the pseudonym "Robert Galbraith".
Winston Churchill wrote under the pen name Winston S. Churchill (from his full surname "Spencer-Churchill" which he did not otherwise use) in an attempt to avoid confusion with the American novelist of the same name. In this case, the attempt was not entirely successful – and the two are still sometimes confused by booksellers.
A pen name may be used specifically to hide the identity of the author, as in the case of exposé books about espionage or crime, or explicit erotic fiction. Some prolific authors adopt a pseudonym to disguise the extent of their published output, e.g. Stephen King writing as Richard Bachman. Co-authors may choose to publish under a collective pseudonym, e.g., P. J. Tracy and Perri O'Shaughnessy. Frederic Dannay and Manfred Lee used the name Ellery Queen as both a pen name for their collaborative works and as the name of their main character.
A famous case in French literature was Romain Gary. Already a well-known and highly acclaimed writer, he started publishing books under the pen name Émile Ajar. He wanted to test whether his new books would be well received on their own merits and without the aid of his established reputation, and they were: Émile Ajar, like Romain Gary before him, was awarded the prestigious Prix Goncourt by a jury unaware that both were the same person. Similarly, Ronnie Barker submitted comedy material under the name of Gerald Wiley.
A collective pseudonym may represent an entire publishing house, or any contributor to a long-running series, especially with juvenile literature. Examples include Watty Piper, Victor Appleton, Erin Hunter, and Kamiru M. Xhan.
Another use of a pseudonym in literature is to present a story as being written by the fictional characters in the story. The series of novels known as A Series Of Unfortunate Events are written by Daniel Handler under the pen name of Lemony Snicket, a character in the series.
An anonymity pseudonym or multiple-use name is a name used by many different people to protect anonymity. It is a strategy that has been adopted by many unconnected radical groups and by cultural groups, where the construct of personal identity has been criticised. This has led to the idea of the "open pop star".
Aliases, fictitious business names, and dummy corporations in criminal activity.
Criminals may use aliases, fictitious business names, and dummy corporations (corporate shells) to hide their identity, or to impersonate other persons or entities in order to commit fraud. Aliases and fictitious business names used for dummy corporations may become so complex that, in the words of the "Washington Post", "getting to the truth requires a walk down a bizarre labyrinth" and multiple government agencies may become involved to uncover the truth.
While governor of Alaska, Sarah Palin used a private Yahoo! e-mail account to skirt government transparency laws. While director of the EPA, Lisa Jackson set up a false identity named Richard Windsor in order to use an official epa.gov email account that was not linked to her office. "Richard Windsor" was awarded certificates for completing training in ethical behaviour and e-mail management.
Noms de guerre.
In Ancien Régime France, a "nom de guerre" ("war name") would be adopted by each new recruit (or assigned to him by the captain of his company) as he enlisted in the French army. These pseudonyms had an official character and were the predecessor of identification numbers: soldiers were identified by their first names, their family names, and their "noms de guerre" (e.g. "Jean Amarault dit Lafidélité"). These pseudonyms were usually related to the soldier's place of origin (e.g. "Jean Deslandes dit Champigny", for a soldier coming from a town named Champigny), or to a particular physical or personal trait (e.g. "Antoine Bonnet dit Prettaboire", for a soldier "prêt à boire", ready to drink). In 1716, a "nom de guerre" was mandatory for every soldier; officers did not adopt "noms de guerre" as they considered them derogatory. In daily life, these aliases could replace the real family name.
"Noms de guerre" were adopted for security reasons by members of the World War II French resistance and Polish resistance. Such pseudonyms are often adopted by military special forces soldiers, such as members of the SAS and other similar units, resistance fighters, terrorists, and guerrillas. This practice hides their identities and may protect their families from reprisals; it may also be a form of dissociation from domestic life. Some well-known men who adopted "noms de guerre" include Carlos, for Ilich Ramírez Sánchez; Willy Brandt, Chancellor of West Germany; and Subcomandante Marcos, the spokesman of the Zapatista Army of National Liberation (EZLN). During Lehi's underground fight against the British in Mandatory Palestine, the organization's commander Yitzchak Shamir (later Prime Minister of Israel) adopted the "nom de guerre" "Michael", in honor of Ireland's Michael Collins. Revolutionaries and resistance leaders, such as Lenin, Trotsky, Golda Meir, Philippe Leclerc de Hauteclocque, and Josip Broz Tito, often adopted their "noms de guerre" as their proper names after the struggle. George Grivas, the Greek-Cypriot EOKA militant, adopted the "nom de guerre" Digenis (Διγενής). In the French Foreign Legion, recruits can adopt a pseudonym to break with their past lives. Mercenaries have long used "noms de guerre", even sometimes multiple identities depending on country, conflict and circumstance.
Computer users.
Individuals using a computer online may adopt or be required to use a form of pseudonym known as a "handle" (a term deriving from CB slang), "user name", "login name", "avatar", or, sometimes, "screen name" or "nickname". On the Internet, pseudonymous remailers utilise cryptography that achieves persistent pseudonymity, so that two-way communication can be achieved, and reputations can be established, without linking physical identities to their respective pseudonyms. Aliasing is the use of multiple names for the same data location.
More sophisticated cryptographic systems, such as anonymous digital credentials, enable users to communicate pseudonymously (i.e., by identifying themselves by means of pseudonyms). In well-defined abuse cases, a designated authority may be able to revoke the pseudonyms and reveal the individuals' real identity.
Use of pseudonyms is common among professional eSports players, despite the fact that most professional games are played offline.
Business sales.
People of ethnic minorities in some areas of the world are sometimes told by an employer to use a pseudonym that is common or acceptable in that part of the world when conducting business, as some people might prefer a person of similar ethnic origin or similar background to people of foreign background or foreign ethnicity.
Privacy.
People seeking privacy often use pseudonyms to make appointments and reservations. Those writing to advice columns in newspapers and magazines may use pseudonyms. Steve Wozniak used a pseudonym when attending the University of California, Berkeley after cofounding Apple Computer because, he said, "I knew I wouldn't have time enough to be an A+ student."
Establishment of identity.
The practice of assigning patrilineal and matrilineal names to offspring for the purpose of tracing ancestry or determining inheritance and other relationships may be giving way to a 21st-century preference for self-assigned or quality-assigned names as replacements for birth given names. A common practice of many indigenous peoples was to assign a clan or shamanic name to members in puberty and post-puberty rituals. It is becoming more common for modern authors and others to elect to take names better suited to their own tastes, characters, or other aspects of personal description or preference. "In most legal systems, a name assumed for a non-fraudulent purpose is a legal name and usable as the person's true name...". This is distinct from, though not exclusive of, employing a pseudonym for the purpose of concealment.
Stage names.
When used by an actor, musician, radio disc jockey, model, or other performer or "show business" personality a pseudonym is called a "stage name", or, occasionally, a "professional name", or "screen name".
Film, theatre, and related activities.
Members of a marginalized ethnic or religious group have often adopted stage names, typically changing their surname or entire name to mask their original background. The film-making team of Joel and Ethan Coen, for instance, share credit for editing under the alias Roderick Jaynes.
Stage names are also used to create a more marketable name, as in the case of Creighton Tull Chaney, who adopted the pseudonym Lon Chaney, Jr., a reference to his famous father Lon Chaney, Sr. Conversely, Nicolas Cage adopted this stage name instead of his real name, Nicolas Kim Coppola, in order to conceal the appearance of nepotism as the nephew of famous director Francis Ford Coppola. Chris Curtis of Deep Purple fame was christened as Christopher Crummey. In this and similar cases a stage name is adopted simply to avoid an unfortunate pun.
Pseudonyms are also used to comply with the rules of performing arts guilds (Screen Actors Guild (SAG), Writers Guild of America, East (WGA), AFTRA, etc.), which do not allow performers to use an existing name, in order to avoid confusion. For example, these rules required film and television actor Michael Fox to add a middle initial and become Michael J. Fox, to avoid being confused with another actor named Michael Fox. This was also true of author and actress Fannie Flagg, who chose this pseudonym; her real name, Patricia Neal, being the name of another well-known actress; and British actor Stewart Granger, whose real name was James Stewart. Even Dick Van Dyke was called "Navckid Keyd" at the end of the credits in the 1964 film Mary Poppins, although this was just an anagram that rearranges itself to spell "Dick Van Dyke" after a few seconds, revealing that the actor played two roles.
Some stage names are used to conceal a person's identity, such as the pseudonym Alan Smithee, which is used by directors in the Directors Guild of America (DGA) to remove their name from a film they feel was edited or modified beyond their artistic satisfaction. Actors and actresses in pornographic films use ""noms de porn"" to conceal their identity as well as to make it more outrageous and memorable (e.g., Dick Nasty). In theatre, the pseudonyms George or Georgina Spelvin, and Walter Plinge are used to hide the identity of a performer, usually when he or she is "doubling" (playing more than one role in the same play).
David Agnew was a name used by the BBC to conceal the identity of a scriptwriter, such as for the Doctor Who serial City of Death, which had 3 writers, including Douglas Adams, who was at the time of writing the show's Script Editor. In another Doctor Who serial, The Brain of Morbius, writer Terrence Dicks demanded the removal of his name from the credits saying it could go out under a "bland pseudonym". This ended up being the name "Robin Bland".
Music.
Musicians and singers can use pseudonyms to allow artists to collaborate with artists on other labels while avoiding the need to gain permission from their own labels, such as the artist Jerry Samuels, who made songs under Napoleon XIV. Rock singer-guitarist George Harrison, for example, played guitar on Cream's song "Badge" using a pseudonym. In classical music, some record companies issued recordings under a "nom de disque" in the 1950s and 1960s to avoid paying royalties. A number of popular budget LPs of piano music were released under the pseudonym Paul Procopolis. Pseudonyms are also used as stage names in heavy metal bands, such as Tracii Guns in LA Guns, Axl Rose and Slash in Guns N' Roses, Mick Mars in Mötley Crüe, or C.C. Deville in Poison. Some of these names have additional meanings, like that of Brian Hugh Warner, more commonly known as Marilyn Manson: Marilyn coming from Marilyn Monroe and Manson from convicted serial killer Charles Manson. Jacoby Shaddix of Papa Roach went under the name "Coby Dick" during the "Infest" era. He changed back to his birth name when "lovehatetragedy" was released.
Elton John (whose given name was Reginald Kenneth Dwight, until it was legally changed in 1972) is known for his use of aliases under various writing and production credits throughout his career. Amongst the many are: Ann Orson; Lord Choc Ice; William A. Bong (a pun on "bill-a-bong", an Australian term for "pond"); Reggae Dwight, and Frank N. Stein.
Ross Bagdasarian, Sr., creator of Alvin and the Chipmunks, wrote original songs, arranged, and produced the records under his real name, but performed on them as David Seville. He also wrote songs using the name Skipper Adams. Danish pop pianist Bent Fabric, whose full name is Bent Fabricius-Bjerre, wrote his biggest instrumental hit "Alley Cat" under the name Frank Bjorn.
For a time, the musician Prince used an unpronounceable "Love Symbol" as a pseudonym ("Prince" is his actual first name rather than a stage name). He wrote the song "Sugar Walls" for Sheena Easton under the alias "Alexander Nevermind" and "Manic Monday" for The Bangles as "Christopher Tracy" (he also produced albums early in his career as "Jamie Starr").
Many Italian-American singers have used stage names as their birth names were difficult to pronounce, or considered too ethnic for American tastes. Singers changing their names included Dean Martin (born Dino Paul Crocetti), Connie Francis (born Concetta Franconero), Frankie Valli (born Francesco Castelluccio), Tony Bennett (born Anthony Benedetto), and Lady Gaga (born Stefani Germanotta)
In 2009, British rock band Feeder briefly changed their name to Renegades so they could play a whole show featuring a setlist in which 95 percent of the songs played were from their forthcoming new album of the same name, with none of their singles included. Frontman Grant Nicholas felt that if they played as Feeder, there would be an uproar that they did not play any of the singles, so used the pseudonym as a hint. A series of small shows were played in 2010, at 250- to 1,000-capacity venues with the plan not to say who the band really are and just announce the shows as if they are a new band, Grant later hinted it was really Feeder to the fans on their website, which caused a series of rumours that suggested the band changed their name permanently, although "Some people got it straight away", but as intended got people talking.
In many cases, hip-hop and Rap artist prefer to use pseudonyms that represents some variation of their name, personality, or interests. Prime examples include Iggy Azalea (her name comes from her dog name, Iggy, and her home street in Mullumbimby, Azalea street) Ol' Dirty Bastard (who was known under at least six aliases), Diddy (previously known at various times as Puffy, P. Diddy, and Puff Daddy), Ludacris, Flo Rida (his name is a tribute to his home state, Florida), LL Cool J, and Chingy. Black metal artists also adopt pseudonyms, usually symbolizing dark values, such as Nocturno Culto, Gaahl, Abbath, and Silenoz. In punk and hardcore punk, singers and band members often replace their real names with "tougher"-sounding stage names, such as Sid Vicious (real name John Simon Ritchie) of the late 1970s band Sex Pistols and "Rat" of the early 1980s band The Varukers and the 2000s re-formation of Discharge. Sid Vicious did not take his name to seem tough but rather because he was anything but Vicious (several sources have indicated that Sid himself hated this nickname). Punk rock band The Ramones also had every member take the last name of Ramone. Rob Crow of the rock band Goblin Cock chose to go by the name "Lord Phallus" during the release of the band's albums. A similar practice occurred in hardcore with musicians taking the names of their bands, like Kevin Seconds of 7 Seconds and Ray Cappo of Youth of Today who, for a while, billed himself as Ray of Today. The Norwegian electronic duo Röyksopp's pseudonym for their "Back to Mine" album was Emmanuel Splice. The Australian country musician born Robert Lane changed his name to Tex Morton in order to sound more like a cowboy.
Cultural or organizational traditions.
Age.
In many cultures, people go by several different nicknames over the course of their lives, to reflect important parts of their lives. In some cases, a rite of passage or puberty marks the transition from a "milk name" to an adult name. Enrollment in school is another occasion where a child's formal or legal name would begin to be used.
Monarchies.
In many monarchies, the sovereign is allowed to choose a regnal name. This official name may differ from their first name and may not even be one of their given names.
A sovereign may choose not to use their first name for many reasons. Some, such as George VI of the United Kingdom (born Albert Frederick Arthur George), may wish to make a connection between their reign and that of a previous sovereign (in his case, his father, George V). Others, such as Queen Victoria (born Alexandrina Victoria of Kent), may never have been known by their original first name.
In Japan, the Emperor's personal name is never used as a regnal name: he is referred to by the name of his regnal era, and after his death his name is officially changed to that of the era. It is a severe breach of etiquette in Japan to refer to the current Emperor's personal name either in speech or in writing unless absolutely required by law. This does not apply to those outside Japan, which explains why Japanese and non-Japanese use different names for the Emperor. For instance, Emperor Hirohito was known within Japan as Emperor Shōwa.
Religion.
In the tradition of various Roman Catholic religious institutes, members abandon their birth name to assume a new, often unrelated, devotional name, often referring to an admired saint. For women, for example in the Society of the Helpers of the Holy Souls, this reflects the mystical marriage as bride of Christ. Newly elected popes assume a papal name. Most popes choose a name commemorating an admired saint (Benedict XVI, for example) or a predecessor or predecessors (John Paul I), or even a family member (John XXIII).
In Eastern Orthodoxy, a monk or a nun is given a saint's name by their bishop or abbot at the time of their tonsure as the new monk's or nun's first act of monastic obedience. In addition, Orthodox monks and nuns never use their last names, except for legal reasons or for disambiguation. This may also have changed to indicate their brotherhood e.g. a monk at Kykkos Monastery in Cyprus may be known as "Κυκκότης".
In Judaism, a convert adopts a Hebrew name.
In Buddhism, a Dharma name is given during the traditional refuge ceremony.
In Islam, new converts often accept Islamic names. Examples include Muhammad Ali, formerly Cassius Clay; Ivan Aguéli, who became Abd al-Hadi Aqhili; Cat Stevens, who became Yusuf Islam; and Yousuf Youhana, who became Mohammad Yousef. Malcolm X (born Malcolm Little) adopted the Arabic name El-Hajj Malik El-Shabazz when he converted to Islam in 1964.
In Sikhism, adherents adopt the last name Singh for males or Kaur for females.
It is a long-standing tradition in the Western Occult tradition to assume a pseudonym or motto. For instance, Alphonse Louis Constant wrote under the name Eliphas Levi, William Wynn Westcott wrote under Frater Sapere Aude, and Aleister Crowley wrote under the name Frater Perdurabo.
Some practitioners of Wicca adopt a "craft name" or "witch name" upon initiation for use within their community. This may be to create a name of their own choosing as opposed to their given name, or to provide anonymity to those who are in the "broom closet." Often a craft name will reflect their personality, interests or feelings.
Sexual minorities.
Members of sexual minority groups have often assumed different names to protect their identity, or to represent a different persona. Sex workers frequently adopt new names to protect themselves or their clientele, to sound more exotic or enticing, or both. "Scene names" are still common within the BDSM community, and the use of the Internet for social networking and information exchange among kinky and polyamorous people means that many are often known more by their computer "handles" than their legal names.
Cadre names.
Within Communist parties and Trotskyist organisations, noms de guerre are usually known as "party names" or "cadre names". While the practice originated during the revolutionary years after World War I, to conceal the identity of leaders, by the 1950s and 1960s, the practice was more of a tradition than an identity-concealment strategy. Some famous Communist Party names include Lenin (Vladimir Il'ich Ulyanov); Stalin (Yosif Vissarionovich Dzhugashvili); Trotsky (Lev Davidovich Bronshtein); Max (Yakov Sverdlov); Nahuel Moreno (Hugo Miguel Bressano) and Hua Guofeng (Su Zhu).
Political articles.
From the late-18th to early-19th centuries, it was established practice for political articles to be signed with pseudonyms. A well-known American was the pen name "Publius", used by Alexander Hamilton, James Madison, and John Jay, in writing "The Federalist" Papers. In his youth, Benjamin Franklin wrote a number of letters to his brother's newspaper posing as a widow under the pen name "Silence Dogood". The British political writer "Junius" was never identified but is probably Sir Philip Francis.
Other types.
Pseudonyms are also adopted for other reasons. Criminals often took on (or were given) pseudonyms, such as famed con man Jefferson R. Smith, who was known as Soapy Smith.
Comedians and others performing hoaxes often adopt aliases for their performance role. A notable instance is provided by the comedian and hoaxer Rodney Marks, who in public performances as a corporate comedian has used over one hundred different aliases indicative of the hoax features.
Mervyn's founder Mervin G. Morris was advised by an architect to spell the name of his store chain with a Y instead of an I because the signs would be more pleasing to the eye.
It is not uncommon for a pseudonym to be adopted by a racing car driver. Reasons for this may include keeping their parents or family unaware of their participation in such activities, so members of royalty (who may be otherwise prohibited from such a dangerous activity as racing) can participate, or as a way to remain in relative anonymity. Three-time F1 champion Jackie Stewart's son Paul used a pseudonym when he joined a British racing school for just this reason. Of the many instances of racing drivers assuming false names, two more are Louis Krages, who raced under the name "John Winter" to keep his mother from finding out about his "habit", and former F1 driver Jean Alesi. Alesi, born in France but of Italian descent, went by his real given name of Giovanni until teasing from classmates led him to adopting a more French first name. Other notable examples include Nelson Piquet, who used his mother's maiden name as his father (Estácio Gonçalves Souto Maior, a prominent Brazilian politician) disapproved of motor racing, and rallycross driver Hervé Lemonnier, who originally used the pseudonym "Knapick" - a manufacturer of French trailers - to hide his identity from the customers of his machinery business.
Famous pseudonyms of people who were neither authors nor actors include the architect Le Corbusier (né Charles Édouard Jeanneret), and the statistician Student (né William Sealey Gosset), discoverer of Student's t-distribution in statistics (Gosset's employer prohibited publication by employees to prevent trade secrets being revealed).
When used by a radio operator, a pseudonym is called a "handle", especially in Citizens' Band radio; on the Appalachian Trail it is common to adopt or, more usually, be given by others a "trail name".
Pseudonyms should not be confused with new names that replace old ones. Some Jewish politicians adopted Hebrew family names upon making aliyah to Israel, dropping Westernized surnames that may have been in the family for generations. David Ben-Gurion, for example, was born David Grün in Poland. He adopted his Hebrew name in 1910, when he published his first article in a Zionist journal in Jerusalem. In the 1960s, black civil rights campaigner Malcolm X (né Malcolm Little) took the "X" to represent his unknown African ancestral name that was lost when his ancestors were brought to North America as slaves, and then changed his name again to Malik El-Shabazz when he converted to Islam.

</doc>
<doc id="40597" url="https://en.wikipedia.org/wiki?curid=40597" title="Alexander Hamilton">
Alexander Hamilton

Alexander Hamilton (January 11, 1755 or 1757July 12, 1804) was a Founding Father of the United States, chief staff aide to General George Washington, one of the most influential interpreters and promoters of the U.S. Constitution, the founder of the nation's financial system, the founder of the Federalist Party, the world's first voter-based political party, the Father of the United States Coast Guard, and the founder of "The New York Post". As the first Secretary of the Treasury, Hamilton was the primary author of the economic policies of the George Washington administration. Hamilton took the lead in the funding of the states' debts by the Federal government, the establishment of a national bank, a system of tariffs, and friendly trade relations with Britain. He led the Federalist Party, created largely in support of his views; he was opposed by the Democratic-Republican Party, led by Thomas Jefferson and James Madison, which despised Britain and feared that Hamilton's policies of a strong central government would weaken the American commitment to Republicanism.
Born out of wedlock, raised in the West Indies, and orphaned as a child, Hamilton pursued a college education through the help of local wealthy men. Recognized for his abilities and talent, he was sent to King's College (now Columbia University) in New York City. Hamilton played a major role in the American Revolutionary War. At the start of the war in 1775, he joined a militia company. In early 1776, he raised a provincial artillery company, to which he was appointed captain. He soon became the senior aide to General Washington, the American forces' commander-in-chief. Washington sent him on numerous important missions to tell generals what Washington wanted. After the war, Hamilton was elected to the Congress of the Confederation from New York. He resigned, to practice law, and founded the Bank of New York. Hamilton was among those dissatisfied with the weak national government. He led the Annapolis Convention, which successfully influenced Congress to issue a call for the Philadelphia Convention, in order to create a new constitution. He was an active participant at Philadelphia; and he helped achieve ratification by writing 51 of the 85 installments of "The Federalist" Papers, which to this day are the single most important reference for Constitutional interpretation.
Hamilton became the leading cabinet member in the new government under President Washington. Hamilton was a nationalist, who emphasized strong central government and successfully argued that the implied powers of the Constitution provided the legal authority to fund the national debt, assume states' debts, and create the government-backed Bank of the United States. These programs were funded primarily by a tariff on imports, and later also by a highly controversial tax on whiskey. Facing well-organized opposition from Jefferson and Madison, Hamilton mobilized a nationwide network of friends of the government, especially bankers and businessmen. It became the Federalist Party. A major issue splitting the parties was the Jay Treaty, largely designed by Hamilton in 1794. It established friendly economic relations with Britain to the chagrin of France and the supporters of the French Revolution. Hamilton played a central role in the Federalist party, which dominated national and state politics until it lost the election of 1800 to Jefferson's Democratic Republicans.
In 1795, he returned to the practice of law in New York. He tried to control the policies of President Adams (1797–1801). In 1798 and 99, Hamilton called for mobilization against France after the XYZ Affair and became commander of a new army, which he readied for war. However, the Quasi-War, while hard-fought at sea, was never officially declared and did not involve army action. In the end, Adams found a diplomatic solution which avoided a war with France. Hamilton's opposition to Adams' re-election helped cause his defeat in the 1800 election. When Jefferson and Aaron Burr tied for the presidency in the electoral college in 1801, Hamilton helped to defeat Burr, whom he found unprincipled, and to elect Jefferson despite philosophical differences. Hamilton continued his legal and business activities in New York City, but lost much of his national prominence within the Federalist party. When Vice President Burr ran for governor of New York state in 1804, Hamilton crusaded against him as unworthy. Taking offense at some of Hamilton's comments, Burr challenged him to a duel in 1804 and mortally wounded Hamilton, who died the next day.
Childhood in the Caribbean.
Alexander Hamilton was born in and spent part of his childhood in Charlestown, the capital of the island of Nevis, in the Leeward Islands; Nevis was one of the British West Indies. Hamilton was born out of wedlock to Rachel Faucette, a married woman of partial British and partial French Huguenot descent, and James A. Hamilton, the fourth son of the Scottish laird Alexander Hamilton of Grange, Ayrshire.
His mother moved with the young Hamilton to St. Croix in the Virgin Islands, then ruled by Denmark. It is not certain whether the year of Hamilton's birth was 1757 or 1755; most historical evidence after Hamilton's arrival in North America supports the idea that he was born in 1757, and many historians had accepted this birth date. But, Hamilton's early life in the Caribbean was recorded in documents which were first published in Danish in 1930; this evidence has caused historians since then to favor a birth year of 1755. Hamilton listed his birth year as 1757 when he first arrived in the Thirteen Colonies. He celebrated his birthday on January 11. In later life, he tended to give his age only in round figures. Probate papers from St. Croix in 1768, after the death of Hamilton's mother, list him as then 13 years old, a date that would support a birth year of 1755. Historians have posited reasons for the different dates of birth being used: If 1755 is correct, Hamilton may have been trying to appear younger than his college classmates or perhaps wished to avoid standing out as older; if 1757 is correct, the probate document indicating a birth year of 1755 may have been in error, or Hamilton may have been attempting to pass as 13, in order to be more employable after his mother's death.
Hamilton's mother had been married previously to Johann Michael Lavien of St. Croix. Rachel left her husband and first son, Peter, traveling to St. Kitts in 1750, where she met James Hamilton. Hamilton and Rachel moved together to Rachel's birthplace, Nevis, where she had inherited property from her father. The couple's two sons were James Jr. and Alexander. Because Alexander Hamilton's parents were not legally married, the Church of England denied him membership and education in the church school. Hamilton received "individual tutoring" and classes in a private school led by a Jewish headmistress. Hamilton supplemented his education with a family library of 34 books.
James Hamilton abandoned Rachel and their sons, allegedly to "spar[Rachel a charge of bigamy ... after finding out that her first husband intend to divorce her under Danish law on grounds of adultery and desertion." Thereafter, Rachel supported her children in St. Croix, keeping a small store in Christiansted. She contracted a severe fever and died on February 19, 1768, 1:02 am, leaving Hamilton orphaned. This may have had severe emotional consequences for him, even by the standards of an 18th-century childhood. In probate court, Rachel's "first husband seized her estate" and obtained the few valuables Rachel had owned, including some household silver. Many items were auctioned off, but a friend purchased the family's books and returned them to the young Hamilton.
Hamilton became a clerk at a local import-export firm, Beekman and Cruger, which traded with New England; he was left in charge of the firm for five months in 1771, while the owner was at sea. He and his older brother James Jr. were adopted briefly by a cousin, Peter Lytton; but when Lytton committed suicide, the brothers were separated. James apprenticed with a local carpenter, while Alexander was adopted by a Nevis merchant, Thomas Stevens. According to the writer Ron Chernow, some evidence suggests that Stevens may have been Alexander Hamilton's biological father; his son, Edward Stevens, became a close friend of Hamilton. The two boys were described as looking much alike, were both fluent in French, and shared similar interests.
Hamilton continued clerking, but he remained an avid reader, later developing an interest in writing, and began to desire a life outside the small island where he lived. He wrote an essay published in the "Royal Danish-American Gazette", a detailed account of a hurricane which had devastated Christiansted on August 30, 1772. His biographer says that, "Hamilton's famous letter about the storm astounds the reader for two reasons: for all its bombastic excesses, it does seem wondrous the 17-year-old self-educated clerk could write with such verve and gusto. Clearly, Hamilton was highly literate and already had considerable fund of verbal riches." The essay impressed community leaders, who collected a fund to send the young Hamilton to the North American colonies for his education.
Education.
In the autumn of 1772, Hamilton arrived at Elizabethtown Academy, a grammar school in Elizabethtown, New Jersey. In 1773 he studied with Francis Barber at Elizabethtown in preparation for college work. He came under the influence of William Livingston, a leading intellectual and revolutionary, with whom he lived for a time at his Liberty Hall. Hamilton entered King's College in New York City (now Columbia University) in the autumn of 1773 "as a private student" and officially matriculated in May 1774. In what is credited as his first public appearance, on July 6, 1774 at the liberty pole at King's College, Hamilton's friend Robert Troup spoke glowingly of Hamilton's ability to clearly and concisely explain the rights and reasons the patriots have in their case against the British. Hamilton, Troup and four other undergraduates formed an unnamed literary society that is regarded as a precursor of the Philolexian Society.
When the Church of England clergyman Samuel Seabury published a series of pamphlets promoting the Loyalist cause in 1774, Hamilton responded anonymously with his first political writings, "A Full Vindication of the Measures of Congress" and "The Farmer Refuted". Seabury essentially tried to provoke fear into the colonies and his main objective was to stopgap the potential of a union among the colonies. Hamilton published two additional pieces attacking the Quebec Act and may have also authored the fifteen anonymous installments of "The Monitor" for Holt's "New York Journal". Although Hamilton was a supporter of the Revolutionary cause at this prewar stage, he did not approve of mob reprisals against Loyalists. On May 10, 1775, Hamilton won credit for saving his college president Myles Cooper, a Loyalist, from an angry mob by speaking to the crowd long enough for Cooper to escape.
During the Revolutionary War.
Early military career.
In 1775, after the first engagement of American troops with the British at Lexington and Concord, Hamilton and other King's College students joined a New York volunteer militia company called the Corsicans, later renamed or reformed as the Hearts of Oak. He drilled with the company, before classes, in the graveyard of nearby St. George's Chapel. Hamilton studied military history and tactics on his own and was soon recommended for promotion. Under fire from HMS "Asia", he led a successful raid for British cannons in the Battery, the capture of which resulted in the Hearts of Oak becoming an artillery company thereafter. Through his connections with influential New York patriots such as Alexander McDougall and John Jay, he raised the New York Provincial Company of Artillery of sixty men in 1776, and was elected captain. It took part in the campaign of 1776 around New York City, particularly at the Battle of White Plains; at the Battle of Trenton, it was stationed at the high point of town, the meeting of the present Warren and Broad Streets, to keep the Hessians pinned in the Trenton Barracks.
George Washington's staff.
Hamilton was invited to become an aide to William Alexander, Lord Stirling and one other general, perhaps Nathanael Greene or Alexander McDougall. He declined these invitations, believing his best chance for improving his station in life was glory on the battlefield. Hamilton eventually received an invitation he felt he could not refuse: to serve as Washington's aide, with the rank of Lieutenant Colonel. Washington felt, "Aides de camp are persons in whom entire confidence must be placed and it requires men of abilities to execute the duties with propriety and dispatch." Hamilton served for four years as Washington's chief staff aide. He handled letters to Congress, state governors, and the most powerful generals in the Continental Army; he drafted many of Washington's orders and letters at the latter's direction; he eventually issued orders from Washington over Hamilton's own signature. Hamilton was involved in a wide variety of high-level duties, including intelligence, diplomacy, and negotiation with senior army officers as Washington's emissary.
During the war, Hamilton became close friends with several fellow officers. His letters to the Marquis de Lafayette and to John Laurens, employing the sentimental literary conventions of the late eighteenth century and alluding to Greek history and mythology, have been read by Jonathan Katz as revealing a homosocial or perhaps homosexual relationship, but few historians agree.
While on Washington's staff, Hamilton long sought command and a return to active combat. As the war drew nearer to an end, he knew that opportunities for military glory were diminishing. In February 1781, Hamilton was mildly reprimanded by Washington and used this as an excuse to resign his staff position. He asked Washington and others for a field command. This continued until early July 1781, when Hamilton submitted a letter to Washington with his commission enclosed, "thus tacitly threatening to resign if he didn't get his desired command."
On July 31, 1781, Washington relented and assigned Hamilton as commander of a New York light infantry battalion. In the planning for the assault on Yorktown, Hamilton was given command of three battalions, which were to fight in conjunction with the allied French troops in taking Redoubts No. 9 and No. 10 of the British fortifications at Yorktown. Hamilton and his battalions fought bravely and took Redoubt No. 10 with bayonets in a nighttime action, as planned. The French also fought bravely, suffered heavy casualties, and took Redoubt No. 9. These actions forced the British surrender of an entire army at Yorktown, Virginia, effectively ending their major British military operations in North America.
Congress of the Confederation.
After the Battle of Yorktown, Hamilton resigned his commission. He was appointed in July 1782 to the Congress of the Confederation as a New York representative for the term beginning in November 1782. Before his appointment to Congress in 1782, Hamilton was already sharing his criticisms of Congress. He expressed these criticisms in his letter to James Duane dated September 3, 1780. In this letter he wrote, "The fundamental defect is a want of power in Congress…the confederation itself is defective and requires to be altered; it is neither fit for war, nor peace." While on Washington's staff, Hamilton had become frustrated with the decentralized nature of the wartime Continental Congress, particularly its dependence upon the states for voluntary financial support. Under the Articles of Confederation, Congress had no power to collect taxes or to demand money from the states. This lack of a stable source of funding had made it difficult for the Continental Army both to obtain its necessary provisions and to pay its soldiers. During the war, and for some time after, Congress obtained what funds it could from subsidies from the King of France, from aid requested from the several states (which were often unable or unwilling to contribute), and from European loans.
An amendment to the Articles had been proposed by Thomas Burke, in February 1781, to give Congress the power to collect a 5% impost, or duty on all imports, but this required ratification by all states; securing its passage as law proved impossible after it was rejected by Rhode Island in November 1782. Madison joined Hamilton in persuading Congress to send a delegation to persuade Rhode Island to change its mind. Their report recommending the delegation argued the federal government needed not just some level of financial autonomy, but also the ability to make laws that superseded those of the individual states. Hamilton transmitted a letter arguing that Congress already had the power to tax, since it had the power to fix the sums due from the several states; but Virginia's rescission of its own ratification ended the Rhode Island negotiations.
Congress and the army.
While Hamilton was in Congress, discontented soldiers began to pose a danger to the young United States. Most of the army was then posted at Newburgh, New York. Those in the army were paying for much of their own supplies, and they had not been paid in eight months. Furthermore, the Continental officers had been promised, in May 1778, after Valley Forge, a pension of half their pay when they were discharged. By the early 1780s, due to the structure of the government under the Articles of Confederation, it had no power to tax to either raise revenue or pay its soldiers. In 1782 after several months without pay, a group of officers organized to send a delegation to lobby Congress, led by Capt. Alexander MacDougall. The officers had three demands: the Army's pay, their own pensions, and commutation of those pensions into a lump-sum payment if Congress were unable to afford the half-salary pensions for life. Congress rejected the proposal.
Several Congressmen, including Hamilton, Robert Morris and Gouverneur Morris, attempted to use this Newburgh Conspiracy as leverage to secure support from the states and in Congress for funding of the national government. They encouraged MacDougall to continue his aggressive approach, threatening unknown consequences if their demands were not met, and defeated proposals that would have resolved the crisis without establishing general federal taxation: that the states assume the debt to the army, or that an impost be established dedicated to the sole purpose of paying that debt. Hamilton suggested using the Army's claims to prevail upon the states for the proposed national funding system. The Morrises and Hamilton contacted Knox to suggest he and the officers defy civil authority, at least by not disbanding if the army were not satisfied; Hamilton wrote Washington to suggest that Hamilton covertly "take direction" of the officers' efforts to secure redress, to secure continental funding but keep the army within the limits of moderation. Washington wrote Hamilton back, declining to introduce the army; after the crisis had ended, he warned of the dangers of using the army as leverage to gain support for the national funding plan.
On March 15, Washington defused the Newburgh situation by giving a speech to the officers. Congress ordered the Army officially disbanded in April 1783. In the same month, Congress passed a new measure for a twenty-five-year impost—which Hamilton voted against—that again required the consent of all the states; it also approved a commutation of the officers' pensions to five years of full pay. Rhode Island again opposed these provisions, and Hamilton's robust assertions of national prerogatives in his previous letter were widely held to be excessive.
In June 1783, a different group of disgruntled soldiers from Lancaster, Pennsylvania, sent Congress a petition demanding their back pay. When they began to march toward Philadelphia, Congress charged Hamilton and two others with intercepting the mob. Hamilton requested militia from Pennsylvania's Supreme Executive Council, but was turned down. Hamilton instructed Assistant Secretary of War William Jackson to intercept the men. Jackson was unsuccessful. The mob arrived in Philadelphia, and the soldiers proceeded to harangue Congress for their pay. The President of Congress, John Dickinson, feared that the Pennsylvania state militia was unreliable, and refused its help. Hamilton argued that Congress ought to adjourn to Princeton, New Jersey. Congress agreed, and relocated there.
Frustrated with the weakness of the central government, Hamilton while in Princeton drafted a call to revise the Articles of Confederation. This resolution contained many features of the future U.S. Constitution, including a strong federal government with the ability to collect taxes and raise an army. It also included the separation of powers into the Executive, Legislative, and Judicial branches.
Return to New York.
Hamilton resigned from Congress, and in July 1783 was authorized to practice law in New York after several months of self-directed education. He practiced law in New York City in partnership with Richard Harison. He specialized in defending Tories and British subjects, as in "Rutgers v. Waddington", in which he defeated a claim for damages done to a brewery by the Englishmen who held it during the military occupation of New York. He pleaded for the Mayor's Court to interpret state law consistent with the 1783 Treaty of Paris which had ended the Revolutionary War.
In 1784, he founded the Bank of New York, now the oldest ongoing bank in the United States. Hamilton was one of the men who restored King's College, which had been suspended since 1776 and severely damaged during the War, as Columbia College. Long dissatisfied with the weak Articles of Confederation, he played a major leadership role at the Annapolis Convention in 1786. He drafted its resolution for a constitutional convention, and in doing so brought his longtime desire to have a more powerful, more financially independent federal government one step closer to reality.
Constitution and "The Federalist" Papers.
Constitutional Convention and ratification of the Constitution.
In 1787, Hamilton served as assemblyman from New York County in the New York State Legislature and was chosen as a delegate for the Constitutional Convention by his father-in-law Philip Schuyler. Even though Hamilton had been a leader in calling for a new Constitutional Convention, his direct influence at the Convention itself was quite limited. Governor George Clinton's faction in the New York legislature had chosen New York's other two delegates, John Lansing, Jr. and Robert Yates, and both of them opposed Hamilton's goal of a strong national government. Thus, whenever the other two members of the New York delegation were present, they decided New York's vote, to ensure that there was no major alterations to the Articles of Confederation.
Early in the Convention he made a speech proposing a President-for-Life; it had no effect upon the deliberations of the convention. He proposed to have an elected President and elected Senators who would serve for life, contingent upon "good behavior" and subject to removal for corruption or abuse; this idea contributed later to the hostile view of Hamilton as a monarchist sympathizer, held by James Madison. According to Madison's notes, Hamilton said in regards to the executive, "The English model was the only good one on this subject. The hereditary interest of the king was so interwoven with that of the nation, and his personal emoluments so great, that he was placed above the danger of being corrupted from abroad…Let one executive be appointed for life who dares execute his powers." Hamilton argued, "And let me observe that an executive is less dangerous to the liberties of the people when in office during life than for seven years. It may be said this constitutes as an elective monarchy…But by making the executive subject to impeachment, the term 'monarchy' cannot apply…" During the convention, Hamilton constructed a draft for the Constitution based on the convention debates, but he never presented it. This draft had most of the features of the actual Constitution. In this draft, the Senate was to be elected in proportion to the population, being two-fifths the size of the House, and the President and Senators were to be elected through complex multistage elections, in which chosen electors would elect smaller bodies of electors; they would hold office for life, but were removable for misconduct. The President would have an absolute veto. The Supreme Court was to have immediate jurisdiction over all law suits involving the United States, and state governors were to be appointed by the federal government.
At the end of the Convention, Hamilton was still not content with the final form of the Constitution, but signed it anyway as a vast improvement over the Articles of Confederation, and urged his fellow delegates to do so also. Since the other two members of the New York delegation, Lansing and Yates, had already withdrawn, Hamilton was the only New York signer to the United States Constitution. He then took a highly active part in the successful campaign for the document's ratification in New York in 1788, which was a crucial step in its national ratification. He first used the popularity of the Constitution by the masses to compel George Clinton to sign, but was unsuccessful. The state convention in Poughkeepsie in June 1788 pitted Hamilton, Jay, James Duane, Robert Livingston, and Richard Morris against the Clintonian faction led by Melancton Smith, Lansing, Yates, and Gilbert Livingston. Hamilton's faction were against any conditional ratification, under the impression that New York would not be accepted into the Union, while Clinton's faction wanted to amend the Constitution, while maintaining the state's right to secede if their attempts failed. During the state convention, New Hampshire and Virginia becoming the ninth and tenth states to ratify the Constitution, respectively, had ensured any adjournment would not happen and a compromise would have to be reached. Hamilton's arguments used for the ratifications were largely iterations of work from "The Federalist" Papers, and Smith eventually went for ratification, though it was more out of necessity than Hamilton's rhetoric. The vote in the state constitution was ratified 30 to 27, on July 26, 1788.
In 1788, Hamilton served yet another term in what proved to be the last session of the Continental Congress under the Articles of Confederation. When the term of Philip Schuyler was up in 1791, elected in his place was the attorney general of New York, one Aaron Burr. Hamilton blamed Burr for this result, and ill characterizations of Burr appear in his correspondence thereafter. The two men did work together from time to time thereafter on various projects, including Hamilton's army of 1798 and the Manhattan Water Company.
"The Federalist" Papers.
Hamilton recruited John Jay and James Madison to write a series of essays defending the proposed Constitution, now known as "The Federalist" Papers, and made the largest contribution to that effort, writing 51 of 85 essays published (Madison wrote 29, Jay only five). Hamilton supervised the entire project, enlisted the participants, wrote the majority of the essays, and oversaw the publication. During the project each person was responsible for their areas of expertise; Jay covered foreign relations, Madison covered the history of republics and confederacies, along with the anatomy of the new government and Hamilton covered the branches of government most pertinent to him: the executive and judicial branches, with some aspects of the Senate, as well as covering military matters and taxation. The papers first appeared in "The Independent Journal" in October 27, 1787.
Hamilton wrote the first paper signed as Publius, and all of the subsequent papers were signed under the name. Jay wrote the next four papers to elaborate on the confederation's weakness and the need for unity against foreign aggression and against splitting into rival confederacies, and, except for Number 64, was not further involved. Hamilton's highlights included discussion that although republics have been culpable for disorders in the past, advances in the "science of politics" had fostered principles that ensured that those abuses could be prevented, such as the division of powers, legislative checks and balances, an independent judiciary, and legislators that were represented by electors (Numbers 7–9). Hamilton also wrote an extensive defense of the constitution (No. 23–36), and discussed the Senate and executive and judicial branches in Numbers 65–85. Hamilton and Madison worked to describe the anarchic state of the confederation in numbers 15–22, and have been described as not being entirely different in thought during this time period in contrast to their stark opposition later in life. Subtle differences appeared with the two when discussing the necessity of standing armies.
Reconciliation between New York and Vermont.
In 1764 King George III had ruled in favor of New York in a dispute between New York and New Hampshire over the region that later became the state of Vermont. New York refused to recognize claims to property derived from grants by New Hampshire governor Benning Wentworth during the preceding 15 years when the territory had been governed as a de facto part of New Hampshire. Consequently, the people of the disputed territory, called the New Hampshire Grants, resisted the enforcement of New York's laws within the Grants. Indeed, Ethan Allen's militia called the Green Mountain Boys, noted for successes in the war against the British in 1775, was originally formed for the purpose of resisting the colonial government of New York. In 1777 the statesmen of the Grants declared it a separate state to be called Vermont, and by early 1778 had erected a state government. During 1777–1785, Vermont was repeatedly denied representation in the Continental Congress, largely because New York insisted that Vermont was legally a part of New York. Vermont took the position that because the denial its petitions for admission to the Union, it was not a part of the United States, not subject to Congress, and at liberty to negotiate separately with the British. The latter Haldimand negotiations led to some exchanges of prisoners of war. The peace treaty of 1783 that ended the war included Vermont within the boundaries of the United States.
By 1787 the government of New York had almost entirely given up plans to subjugate Vermont, but still claimed jurisdiction. As a member of the legislature of New York, Hamilton argued forcefully and at length in favor of a bill to recognize the sovereignty of the State of Vermont, against numerous objections to its constitutionality and policy. Consideration of the bill was deferred to a later date. In 1788 and 1789 extensive negotiations were carried out between Hamilton and Nathaniel Chipman, a lawyer representing Vermont. Among the topics were the location of the border between Vermont and New York, and financial compensation of New York land-grantees whose grants Vermont refused to recognize because they conflicted with earlier grants from New Hampshire. In 1788 the new Constitution of the United States went into effect, with its plan to replace the unicameral Continental Congress with a new Congress consisting of a Senate and a House of Representatives. Hamilton wrote: One of the first subjects of deliberation with the new Congress will be the independence of Kentucky that time still a part of Virginia, for which the southern states will be anxious. The northern will be glad to find a counterpoise in Vermont.
In 1790 the legislature of New York agreed to give up that state's claim to jurisdiction in Vermont on condition that Congress would admit Vermont state to the Union.
Secretary of the Treasury.
President George Washington appointed Hamilton as the first United States Secretary of the Treasury on September 11, 1789. He left office on the last day of January 1795. Much of the structure of the government of the United States was worked out in those five years, beginning with the structure and function of the cabinet itself. Biographer Forrest McDonald argues that Hamilton saw his office, like that of the British First Lord of the Treasury, as the equivalent of a Prime Minister; Hamilton would oversee his colleagues under the elective reign of George Washington. Washington did request Hamilton's advice and assistance on matters outside the purview of the Treasury Department. In 1791, while Secretary, Hamilton was elected a Fellow of the American Academy of Arts and Sciences. Hamilton submitted various financial reports to Congress. Among these are the First Report on the Public Credit, Operations of the Act Laying Duties on Imports, Report on a National Bank, On the Establishment of a Mint, Report on Manufactures, and the Report on a Plan for the Further Support of Public Credit. So, the great enterprise in Hamilton's project of an administrative republic is the establishment of stability.
Report on Public Credit.
Before the adjournment of the House in September 1789, they requested Hamilton to make a report on suggestions to improve the public credit by January 1790. Hamilton had written to Robert Morris as early as 1781 that fixing the public credit will win their objective of independence. The sources that Hamilton used ranged from Frenchmen such as Jacques Necker and Montesquieu to British writers such as Hume, Hobbes, and Malachy Postlethwayt. While writing the report he also sought out suggestions from contemporaries such as John Knox Witherspoon, and Madison. Although they agreed on additional taxes such as distilleries and duties on imported liquors and land taxes, Madison feared that the securities from the government debt would fall in foreign hands.
In the report, Hamilton felt that the debt that the United States had accrued during the Revolutionary War was the price it paid for its liberty. He argued that liberty and property security were inseparable and that the government should honor the contracts, as they formed the basis of public and private morality. To Hamilton, the proper handling of the government debt would also allow America to borrow at affordable interest rates and would also be a stimulant to the economy. Hamilton divided the debt into national and state, and further divided the national debt into foreign and domestic debt. While there was agreement on how to handle the foreign debt (especially with France), there was not with regards to the national debt held by domestic creditors. During the Revolutionary War, affluent citizens had invested in bonds, and war veterans had been paid with promissory notes and IOUs that plummeted in price during the Confederation. In response, the war veterans sold the securities to speculators for as little as fifteen to twenty cents on the dollar. Hamilton felt the money from the bonds should not go to the soldiers, but the speculators that had bought the bonds from the soldiers, as they had little faith in the country's future. The process of attempting to track down the original bond holders along with the government showing discrimination among the classes of holders if the war veterans were to be compensated also weighed in as factors for Hamilton. As for the state debts, Hamilton suggested to consolidate it with the national debt and label it as federal debt, for the sake of efficiency on a national scale. The last portion of the report dealt with eliminating the debt by utilizing a sinking fund that would retire five percent of the debt annually until it was paid off. Due to the bonds being traded well below their face value, the purchases would benefit the government as the securities rose in price.
When the report was submitted to the House of Representatives, detractors soon began to speak against it. The notion of programs that resembled British practice were wicked along with the power of balance being shifted away from the Representatives to the executive branch were some of the prejudices that resided within the House. William Maclay suspected that that several congressmen were involved in government securities, saw Congress in an unholy league with New York speculators. Congressman James Jackson also spoke against New York with allegations of speculators attempting to swindle those who had yet heard about Hamilton's report. The involvement of those in Hamilton's circle such as Schuyler, William Duer, James Duane, Gouverneur Morris, and Rufus King as speculators was not favorable to those against the report, either, though Hamilton personally did not own or deal a share in the debt. Madison eventually spoke against it by February 1790. Although he was not against current holders of government debt to profit, he wanted the windfall to go to the original holders. Madison did not feel that the original holders had lost faith in the government, but sold their securities out of desperation. The compromise was seen as egregious to both Hamiltonians and their dissidents such as Maclay, and Madison's vote was defeated 36 votes to 13 on February 22.
The fight for the national government to assume state debt was a longer issue, and lasted over four months. During the period, the resources that Hamilton was to apply to the payment of state debts was requested by Alexander White, and was rejected due to Hamilton's not being able to prepare information by March 3, and was even postponed by his own supporters in spite of configuring a report the next day (which consisted of a series of additional duties to meet the interest on the state debts). Some of the other issues involving Hamilton were bypassing the rising issue of slavery in Congress after Quakers petitioned for its abolition (though he returned to the issue the following year), having Duer resign as Assistant Secretary of the Treasury, and the vote of assumption being voted down 31 votes to 29 on April 12. The temporary location of the capital from New York City also played a role, as Tench Coxe was sent to speak to Maclay to bargain about the capital being temporarily located to Philadelphia, as a single vote in the Senate was needed and five in the House for the bill to pass. The bill passed in the Senate on July 21 and in the House 34 votes to 28 on July 26, 1790.
Report on a National Bank.
Hamilton's Report on a National Bank was a projection from the first Report on the Public Credit. Although Hamilton had been forming ideas of a national bank as early as 1779, he gathered ideas in various ways over the past eleven years. These included theories from Adam Smith, extensive studies on the Bank of England, the blunders of the Bank of North America and his experience in establishing the Bank of New York. He also used American records from James Wilson, Pelatiah Webster, Gouverneur Morris, and from his assistant Treasury secretary Tench Coxe.
Hamilton suggested that Congress should charter the National Bank with a capitalization of $10 million, one-fifth of which would be handled by the Government. Since the Government did not have the money, it would borrow the money from the bank itself, and repay the loan in ten even annual installments. The rest was to be available to individual investors. The bank was to be governed by a twenty-five member board of directors that was to represent a large majority of the private shareholders, which Hamilton considered essential for his being under a private direction. Hamilton's bank model had many similarities to that of the Bank of England, except Hamilton wanted to exclude the Government from being involved in public debt, but provide a large, firm, and elastic money supply for the functioning of normal businesses and usual economic development, among other differences. For tax revenue to ignite the bank, it was the same as he had previously proposed; increases on imported spirits: rum, liquor, and whiskey.
The bill passed through the Senate practically without a problem, but objections of the proposal increased by the time it reached the House of Representatives. It was generally held by critics that Hamilton was serving the interests of the Northeast by means of the bank, and those of the agrarian lifestyle would not benefit from it. Among those critics was James Jackson of Georgia, who also attempted to refute the report by quoting from "The Federalist" Papers. Madison and Jefferson also opposed the bank bill; however, the potential of the capital not being moved to the Potomac if the bank was to have a firm establishment in Philadelphia (the current capital of the United States) was a more significant reason, and actions that Pennsylvania members of Congress took to keep the capital there made both men anxious. Madison warned the Pennsylvania congress members that he would attack the bill as unconstitutional in the House, and followed up on his threat. Madison argued his case of where the power of a bank could be established within the Constitution, but he failed to sway members of the House, and his authority on the constitution was questioned by a few members. The bill eventually passed in an overwhelming fashion 39 to 20, on February 8, 1791.
Washington hesitated to sign the bill, as he received suggestions from Attorney-General Edmund Randolph and Thomas Jefferson. Jefferson dismissed the 'necessary and proper' clause as reasoning for the creation of a national bank, stating that the enumerated powers "can all be carried into execution without a bank." Along with Randolph and Jefferson's objections, Washington's involvement in the movement of the capital from Philadelphia is also thought to be a reason for his hesitation. In response to the objection of the 'necessary and proper' clause, Hamilton stated that "Necessary often means no more than needful, requisite, incidental, useful, or conductive to", and the bank was a "convenient species of medium in which they (taxes) are to be paid.". Washington would eventually sign the bill into law.
Establishing the U.S. Mint.
In 1791, Hamilton submitted Report on the Establishment of a Mint to the House of Representatives. Most of Hamilton's ideas for this report were from European economists, resolutions from Continental Congress meetings from 1785 and 1786, and from people such as Gouverneur Morris and Thomas Jefferson. Due to the Spanish coin being the most circulated coin in the United States at the time, Alexander Hamilton proposed that the minting of the United States dollar weighing almost as much as the Spanish peso would be the simplest way to introduce a national currency. Hamilton wanted the U.S. dollar system to be set for decimals rather than the eights like the Spanish mint. In spite of preferring a monometallic gold standard, he issued a bimetallic currency at ratio that was to be similar to most European countries. What was different from the European currencies was his desire to overprice the gold on the grounds that the United States would always receive an influx of silver from the West Indies. Hamilton desired the minting of small value coins such as silver ten-cent, copper, and half-cent pieces, for reducing the cost of living for the poor. One of his main objectives was for the general public to become accustomed to handling money on a frequent basis.
By 1792, Hamilton's principles were adopted by Congress, resulting in the Coinage Act of 1792, and the creation of the United States Mint. There was to be a ten dollar Gold Eagle coin, a silver dollar, and fractional money ranging from one-half to fifty cents. The coining of silver and gold was issued by 1795.
Revenue Cutter Service.
Smuggling off American coasts was an issue before the Revolutionary War, and after the Revolution it was more problematic. Along with smuggling, lack of shipping control, pirating, and a revenue unbalance were also major problems. In response, Hamilton proposed to Congress to enact a naval police force called revenue cutters in order to patrol the waters and assist the custom collectors with confiscating contraband. This idea was also proposed to assist in tariff controlling, boosting the American economy, and promote the merchant marine. It is thought that his experience obtained during his apprenticeship with Nicholas Kruger was influential in his decision-making.
Concerning some of the details of the "System of Cutters", Hamilton wanted the first ten cutters in different areas in the United States, from New England to Georgia. Hamilton also wanted those cutters to be armed with ten muskets and bayonets, twenty pistols, two chisels, one broad-ax and two lanterns. Hamilton also wanted the fabric of the sails to be domestically manufactured. Hamilton was also concerned of the employees' food supply and etiquette when boarding ships, and made provisions for each. Congress established the Revenue Cutter Service on August 4, 1790, which is viewed as the birth of the United States Coast Guard.
Whiskey as tax revenue.
One of the principal sources of revenue Hamilton prevailed upon Congress to approve was an excise tax on whiskey. In his first Tariff Bill in January of 1790, Hamilton proposed to raise the three million dollars needed to pay for government operating expenses and interest on domestic and foreign debts by means of an increase on duties on imported wines, distilled spirits, tea, coffee, and domestic spirits. It failed, with Congress complying with most recommendations excluding the excise tax on Whiskey (Madison's tariff of the same year was a modification of Hamilton's that involved only imported duties and was passed in September).
In response of diversifying revenues, as three-fourths of revenue gathered was from commerce with Great Britain, Hamilton attempted once again during his "Report on Public Credit" when presenting it in 1790 to implement an excise tax both imported and domestic spirits. The taxation rate was graduated in proportion to the whiskey proof, and Hamilton intended to equalize the tax burden on imported spirits with imported and domestic liquor. In lieu of the excise on production citizens could pay 60 cents by the gallon of dispensing capacity, along with an exemption on small stills used exclusively for domestic consumption. He realized the loathing that the tax would receive in rural areas, but thought of the taxing of spirits more reasonable than land taxes.
Opposition initially came from Pennsylvania's House of Representatives protesting the tax. William Maclay had noted that not even the Pennsylvanian legislators had been able to enforce excise taxes in the western regions of the state. Hamilton was aware of the potential difficulties and proposed inspectors the ability to search buildings that distillers were designated to store their spirits, and would be able to search suspected illegal storage facilities to confiscate contraband with a warrant. Although the inspectors were not allowed to search houses and warehouses, they were to visit twice a day and file weekly reports in extensive detail. Hamilton cautioned against expedited judicial means, and favored a jury trial with potential offenders. As soon as 1791 locals began to shun or threaten inspectors, as they felt the inspection methods were intrusive. Inspectors were also tarred and feathered, blindfolded, and whipped. Hamilton had attempted to appease the opposition with lowered tax rates, but it did not suffice.
Strong opposition to the whiskey tax by cottage producers in remote, rural regions erupted into the Whiskey Rebellion in 1794; in Western Pennsylvania and western Virginia, whiskey was the basic export product and was fundamental to the local economy. In response to the rebellion, believing compliance with the laws was vital to the establishment of federal authority, Hamilton accompanied to the rebellion's site President Washington, General Henry "Light Horse Harry" Lee, and more federal troops than were ever assembled in one place during the Revolution. This overwhelming display of force intimidated the leaders of the insurrection, ending the rebellion virtually without bloodshed.
Manufacturing and industry.
Hamilton's next report was his "Report on Manufactures". Although he was requested by Congress on January 15, 1790 for a report for manufacturing that would expand the United States' independence, the report was not submitted until December 5, 1791. In the report, Hamilton quoted from "Wealth of Nations" and used the French physiocrats as an example for rejecting agrarianism and the physiocratic theory; respectively. Hamilton also refuted Smith's ideas of government noninterference, as it would have been detrimental for trade with other countries. Hamilton also thought of the United States being a primarily agrarian country would be a disadvantage in dealing with Europe. In response to the agrarian detractors, Hamilton stated that the agriculturists' interest would be advanced by manufactures, and that agriculture was just as productive as manufacturing.
Among the ways that the government could assist in manufacturing, Hamilton mentioned levying protective duties on imported foreign goods that were also manufactured in the United States, to withdraw duties levied on raw materials needed for domestic manufacturing, pecuniary boundaries, and encouraging immigration for people to better themselves in similar employment opportunities. Congress shelved the report without much debate (except for Madison's objection to Hamilton's formulation of the General Welfare clause, which Hamilton construed liberally as a legal basis for his extensive programs).
Subsequently in 1791, with his ideas for manufacturing being a major influence, Hamilton, along with Coxe and several entrepreneurs from New York and Philadelphia helped form the Society for the Establishment of Useful Manufactures, a private industrial corporation. The location at Great Falls of the Passaic River in New Jersey was selected due to access to raw materials, it being densely inhabited, and having access to water power from the falls of the Passaic. The factory town was named Paterson after New Jersey's Governor William Paterson, who signed the charter. The profits were to derive from specific corporates rather than the benefits to be conferred to the nation and the citizens, which was unlike the report. Hamilton also suggested the first stock to be offered at $500,000 and to eventually increase to $1 million, and welcomed state and national government subscriptions alike. The company was never successful: numerous shareholders reneged on stock payments, some members soon went bankrupt, and William Duer, the governor of the program, was sent to debtors' prison. In spite of Hamilton's efforts to mend the disaster, the company would expire by 1796.
Emergence of parties.
During Hamilton's tenure as Treasury Secretary, political factions began to emerge. A Congressional caucus, led by James Madison and William Branch Giles, began as an opposition group to Hamilton's financial programs, and Thomas Jefferson joined this group when he returned from France. Hamilton and his allies began to call themselves "Federalists". The opposition group, now called the Democratic-Republican Party by political scientists, was at the time known as "Republicans".
Hamilton assembled a nationwide coalition to garner support for the Administration, including the expansive financial programs Hamilton had made Administration policy and especially the president's policy of neutrality in the European war between Britain and France. Hamilton's public relations campaign attacked the French minister Edmond-Charles Genêt (he called himself "Citizen Genêt") who tried to appeal to voters directly, which Federalists denounced as foreign interference in American affairs. If Hamilton's administrative republic was to succeed, Americans had to see themselves as nation citizens, and experience an administration that proved firm and demonstrated the concepts found within the United States Constitution. The Federalists did impose some internal direct taxes but they departed from the most implications of the Hamilton administrative republic as risky.
The Jeffersonian Republicans opposed banks and cities, and favored France. They built their own national coalition to oppose the Federalists. Both sides gained the support of local political factions; each side developed its own partisan newspapers. Noah Webster, John Fenno, and William Cobbett were energetic editors for the Federalists; Benjamin Franklin Bache and Philip Freneau were fiery Republican editors. All the newspapers were characterized by intense personal attacks, major exaggerations and invented claims. In 1801, Hamilton established a daily newspaper, the "New York Evening Post" and brought in William Coleman as editor. It is still publishing (as the "New York Post").
The quarrel between Hamilton and Jefferson is the best known and historically the most important in American political history. Hamilton's and Jefferson's incompatibility was heightened by the unavowed wish of each to be Washington's principal and most trusted advisor.
Jay Treaty and Britain.
When France and Britain went to war in early 1793, all four members of the Cabinet were consulted on what to do. They and Washington unanimously agreed to remain neutral, and to send Genêt home. However, in 1794 policy toward Britain became a major point of contention between the two parties. Hamilton and the Federalists wished for more trade with Britain, the new nation's largest trading partner. The Republicans saw Britain as the main threat to republicanism and proposed instead a trade war.
To avoid war, Washington sent Chief Justice John Jay to negotiate with the British; Hamilton largely wrote Jay's instructions. The result was Jay's Treaty. It was denounced by the Republicans but Hamilton mobilized support up and down the land. The Jay Treaty passed the Senate in 1795 by exactly the required two-thirds majority. The Treaty resolved issues remaining from the Revolution, averted war, and made possible ten years of peaceful trade between the United States and Britain. Historian George Herring notes the "remarkable and fortuitous economic and diplomatic gains" produced by the Treaty.
Several European nations had formed a League of Armed Neutrality against incursions on their neutral rights; the Cabinet was also consulted on whether the United States should join it, and decided not to. It kept that decision secret, but Hamilton revealed it in private to George Hammond, the British Minister to the United States, without telling Jay or anyone else. (His act remained unknown until Hammond's dispatches were read in the 1920s). This "amazing revelation" may have had limited effect on the negotiations; Jay did threaten to join the League at one point, but the British had other reasons not to view the League as a serious threat.
Second Report on Public Credit.
Before leaving his post in 1795, Hamilton submitted "Report on a Plan for the Further Support of Public Credit" to Congress to curb the debt problem. Hamilton grew dissatisfied with what he viewed as a lack of a comprehensive plan to fix the public debt. He wished to have new taxes passed with older ones made permanent and stated that any surplus from the excise tax on liquor would be pledged to lower public debt. His proposals were included into a bill by Congress within slightly over a month after his departure as treasury secretary.
Post-Secretary years.
The Reynolds affair.
In 1791, Hamilton became involved in an affair with Maria Reynolds over a nine-month period that would be revealed to the public several years afterward. Reynolds appeared to Hamilton as a woman who had been abandoned by her husband, James, at New York and wished to return to there. Hamilton did not have any money on his person, so he retrieved her address in order to deliver the funds in person. After the brief dialogue in Reynolds' bedroom, he had frequent meetings with her. Hamilton then received two letters on December 15, 1791, one from both Mr. and Mrs. Reynolds. The first letter was Maria warning of her husband's knowledge and of James attempting to blackmail Hamilton. By this point Hamilton contemplated ending the relationship, and briefly ceased to visit, but both apparently were involved in the blackmailing scheme as both sent letters, and at one point James Reynolds requested to 'befriend' her. By May of 1792, James Reynolds had requested for Hamilton to no longer see his wife, but not before receiving fifty and two hundred dollars out of over $1300 in blackmail. Hamilton possibly was aware of both Reynolds' being involved before the blackmailing incident.
When under suspicion of illegal actions while Secretary of Treasury by associating with William Duer from John J. Beckley and Jacob Clingman, the latter also had alleged evidence of James Reynolds being an agent of Hamilton's, with accompanying letters gathered from Maria Reynolds that were from Hamilton. This information was relayed to James Monroe, who consulted with Congressmen Muhlenberg and Venable on what actions to take. When it was suggested by Clingman that James Reynolds had evidence that would incriminate Hamilton, after both were arrested for counterfeiting and Clingman was released, Monroe and the Congressmen soon confronted Hamilton on 15 December 1792. After Hamilton discussed the affair, the trio were to keep the documents privately with the utmost confidence.
In 1797, however, when "notoriously scurrilous journalist" James T. Callender published "A History of the United States for the Year 1796", it contained accusations of James Reynolds being an agent of Hamilton using documents from the confrontation on December 15, 1792. On July 5, 1797, Hamilton wrote to all three men to confirm that there was nothing that would damage the perception of his integrity while Secretary of Treasury. All complied but Monroe, and after several rounds of argument, the two almost resorted to a duel. When Hamilton did not obtain an explicit response from Monroe, he published a pamphlet in order to preserve his public reputation, and discussed the affair in exquisite detail. His wife forgave him, but not Monroe. Though he faced ridicule from the Democratic-Republican faction, he maintained his availability for public service.
1796 presidential election.
Hamilton's resignation as Secretary of the Treasury in 1795 did not remove him from public life. With the resumption of his law practice, he remained close to Washington as an advisor and friend. Hamilton influenced Washington in the composition of his Farewell Address by writing drafts for Washington to compare with the latter's draft, although when Washington contemplated retirement in 1792, he had consulted James Madison for a draft that was used in a similar manner to Hamilton's.
In the election of 1796, under the Constitution as it stood then, each of the presidential electors had two votes, which they were to cast for different men. The one who received most votes would become President, the second-most, Vice President. This system was not designed with the operation of parties in mind, as they had been thought disreputable and factious. The Federalists planned to deal with this by having all their Electors vote for John Adams, the Vice President, and all but a few for Thomas Pinckney of South Carolina.
Adams resented Hamilton's influence with Washington and considered him overambitious and scandalous in his private life; Hamilton compared Adams unfavorably with Washington and thought him too emotionally unstable to be President. Hamilton took the election as an opportunity: he urged all the northern electors to vote for Adams and Pinckney, lest Jefferson get in; but he cooperated with Edward Rutledge to have South Carolina's electors vote for Jefferson and Pinckney. If all this worked, Pinckney would have more votes than Adams, Pinckney would become President, and Adams would remain Vice President, but it did not work. The Federalists found out about it (even the French minister to the United States knew), and northern Federalists voted for Adams but "not" for Pinckney, in sufficient numbers that Pinckney came in third and Jefferson became Vice President. Adams resented the intrigue since he felt his service to the nation was much more extensive than Pinckney's.
Quasi-War.
During the Quasi-War of 1798–1800, and with Washington's strong endorsement, Adams reluctantly appointed Hamilton a major general of the army; at Washington's insistence, Hamilton was made the senior major general, prompting Henry Knox to decline appointment to serve as Hamilton's junior (Knox had been a major general in the Continental Army and thought it would be degrading to serve beneath him). Hamilton served as inspector general of the United States Army from July 18, 1798, to June 15, 1800; because Washington was unwilling to leave Mount Vernon unless it were to command an army in the field, Hamilton was the "de facto" head of the army, to Adams's considerable displeasure. If full-scale war broke out with France, Hamilton argued that the army should conquer the North American colonies of France's ally, Spain, bordering the United States.
To fund this army, Hamilton wrote regularly to Oliver Wolcott, Jr., his successor at the Treasury; William Loughton Smith, of the House Ways and Means Committee; and Senator Theodore Sedgwick of Massachusetts. He directed them to pass a direct tax to fund the war. Smith resigned in July 1797, as Hamilton scolded him for slowness, and told Wolcott to tax houses instead of land.
The eventual program included a Stamp Act like that of the British before the Revolution and other taxes on land, houses, and slaves, calculated at different rates in different states, and requiring difficult and intricate assessment of houses. This provoked resistance in southeastern Pennsylvania, led primarily by men such as John Fries who had marched with Washington against the Whiskey Rebellion.
Hamilton aided in all areas of the army's development, and after Washington's death he was by default the Senior Officer of the United States Army from December 14, 1799, to June 15, 1800. The army was to guard against invasion from France. Adams, however, derailed all plans for war by opening negotiations with France. Adams had held it proper to retain the members of Washington's cabinet, except for cause; he found, in 1800 (after Washington's death), that they were obeying Hamilton rather than himself, and fired several of them.
1800 presidential election.
In the 1800 election, Hamilton worked to defeat not only the rival Democratic-Republican candidates, but also his party's own nominee, John Adams. In November 1799, the Alien and Sedition Acts had left one Democratic-Republican newspaper functioning in New York City; when the last, the "New Daily Advertiser", reprinted an article saying that Hamilton had attempted to purchase the Philadelphia "Aurora" and close it down, Hamilton had the publisher prosecuted for seditious libel, and the prosecution compelled the owner to close the paper.
Aaron Burr had won New York for Jefferson in May; now Hamilton proposed a rerun of the election under different rules—with carefully drawn districts and each choosing an elector—such that the Federalists would split the electoral vote of New York. (John Jay, a Federalist who had given up the Supreme Court to be Governor of New York, wrote on the back of the letter the words, "Proposing a measure for party purposes which it would not become me to adopt," and declined to reply.)
John Adams was running this time with Charles Cotesworth Pinckney of South Carolina (the elder brother of candidate Thomas Pinckney from the 1796 election). Hamilton now toured New England, again urging northern electors to hold firm for Pinckney in the renewed hope of making Pinckney president; and he again intrigued in South Carolina. Hamilton's ideas involved coaxing middle-state Federalists to assert their non-support for Adams if there was no support for Pinckney and writing to more of the modest supports of Adams concerning his supposed misconduct while president. Hamilton expected to see southern states such as the Carolinas cast their votes for Pinckney and Jefferson, and would result in the former being ahead of both Adams and Jefferson.
In accordance with the second of the aforementioned plans, and a recent personal rift with Adams, Hamilton wrote a pamphlet called "Letter from Alexander Hamilton, Concerning the Public Conduct and Character of John Adams, Esq. President of the United States" that was highly critical of him, though it closed with a tepid endorsement. He mailed this to two hundred leading Federalists; when a copy fell into the Democratic-Republicans' hands, they printed it. This hurt Adams's 1800 reelection campaign and split the Federalist Party, virtually assuring the victory of the Democratic-Republican Party, led by Jefferson, in the election of 1800; it destroyed Hamilton's position among the Federalists.
Jefferson had beaten Adams, but both he and his running mate, Aaron Burr, had received 73 votes in the Electoral College (Adams finished in third place, Pinckney in fourth, and Jay received one vote). With Jefferson and Burr tied, the United States House of Representatives had to choose between the two men. Several Federalists who opposed Jefferson supported Burr, and for the first 35 ballots, Jefferson was denied a majority. Before the 36th ballot, Hamilton threw his weight behind Jefferson, supporting the arrangement reached by James A. Bayard of Delaware, in which five Federalist Representatives from Maryland and Vermont abstained from voting, allowing those states' delegations to go for Jefferson, ending the impasse and electing Jefferson President rather than Burr. Even though Hamilton did not like Jefferson and disagreed with him on many issues, he viewed Jefferson as the lesser of two evils. Hamilton spoke of Jefferson as being "by far not so a dangerous man", and that Burr was a "mischievous enemy" to the principle measure of the past administration. There is strong circumstantial evidence, however, that what Hamilton really feared was Burr's appeal to the members of the Federalist Party and loss of his control over them. Many Federalists viewed Burr as a moderate who was willing to dialogue with them. It was for that reason, along with the fact that Burr was a northerner and not a Virginian, that many Federalist Representatives voted for him. Hamilton wrote an exceeding number of letters to friends in Congress to convince the members to see otherwise. However, the Federalists rejected Hamilton's diatribe as reasons to not vote for Burr. Nevertheless, Burr would become Vice President of the United States. When it became clear that Jefferson had developed his own concerns about Burr and would not support his return to the Vice Presidency, Burr sought the New York governorship in 1804 with Federalist support, against the Jeffersonian Morgan Lewis, but was defeated by forces including Hamilton.
Burr–Hamilton duel and untimely death.
Soon after the 1804 gubernatorial election in New York—in which Morgan Lewis, greatly assisted by Hamilton, defeated Aaron Burr—the "Albany Register" published Charles D. Cooper's letters, citing Hamilton's opposition to Burr and alleging that Hamilton had expressed "a still more despicable opinion" of the Vice President at an upstate New York dinner party. Cooper claimed that the letter was intercepted after relaying the information, but stated he was 'unusually cautious' in recollecting the information from the dinner. Burr, sensing an attack on his honor, and recovering from his defeat, demanded an apology in letter form. Hamilton wrote a letter in response and ultimately refused because he could not recall the instance of insulting Burr; also, Hamilton would have been accused of recanting Cooper's letter out of cowardice. After a series of attempts to reconcile were to no avail, the duel was accepted through liaisons on June 27, 1804.
The night before the duel, Hamilton wrote a defense of his decision to duel. Hamilton viewed his roles of being a father and husband, putting his creditors at risk, placing his family's welfare in jeopardy and his moral and religious stances as reasons not to duel, but he felt it impossible to avoid due to making attacks on Burr and unable to recant, and because of Burr's behavior prior to the duel. He attempted to reconcile his moral and religious reasons and the codes of honor and politics. He intended to accept the duel and throw his fire in order to satisfy his morals and political codes, respectively. His desire to be available for future political matters also played a factor.
The duel began at dawn on July 11, 1804, along the west bank of the Hudson River on a rocky ledge in Weehawken, New Jersey. After the seconds measured the paces, Hamilton, according to both William P. Van Ness and Burr, raised his pistol "as if to try the light" and had to wear his spectacles to prevent his vision from being obscured. Hamilton also refused the hairspring set of dueling pistols (that would make the pulling of the trigger lighter) when offered by Nathaniel Pendleton. Vice President Burr shot Hamilton, delivering what proved to be a fatal wound. Hamilton's shot broke a tree branch directly above Burr's head. Neither of the seconds, Pendleton nor Van Ness, could determine who fired first, as each claimed that the other man had fired first. Soon after, they measured and triangulated the shooting, but could not determine from which angle Hamilton fired. Burr's shot, however, hit Hamilton in the lower abdomen above the right hip. The bullet ricocheted off Hamilton's second or third false rib, fracturing it and causing considerable damage to his internal organs, particularly his liver and diaphragm, before becoming lodged in his first or second lumbar vertebra. Biographer Ron Chernow considered the circumstances to indicate that, after taking deliberate aim, Burr fired second, while biographer James Earnest Cooke suggested that Burr took careful aim and only after the bullet struck Hamilton that the latter fired his shot while falling.
The paralyzed Hamilton, who knew himself to be mortally wounded, was ferried to the Greenwich Village home of his friend William Bayard Jr., who had been waiting on the dock. After final visits from his family and friends and considerable suffering, Hamilton died on the following afternoon, July 12, 1804, at Bayard's home at what is now 80–82 Jane Street. Gouverneur Morris gave the eulogy at his funeral and secretly established a fund to support his widow and children. Hamilton was buried in the Trinity Churchyard Cemetery in Manhattan.
Personal life.
Family.
While Hamilton was stationed in Morristown, New Jersey, in the winter of 1779 and 1780, he met Elizabeth Schuyler, a daughter of Philip Schuyler and Catherine Van Rensselaer. The two were married on December 14, 1780, at the Schuyler Mansion in Albany, New York. He and Elizabeth had eight children, including two named Philip. The elder Philip, Hamilton's first child (born January 22, 1782), was killed in 1801 in a duel with George I. Eacker, whom he had publicly insulted in a Manhattan theater. The second Philip, Hamilton's last child, was born on June 2, 1802, after the first Philip was killed. Their other children were Angelica, born September 25, 1784; Alexander, born May 16, 1786; James Alexander (April 14, 1788 – September 1878); John Church, born August 22, 1792; William Stephen, born August 4, 1797; and Eliza, born November 26, 1799.
Hamilton was also close to Elizabeth's older sister, Angelica, who eloped with John Barker Church, an Englishman who made a fortune in North America during the Revolution. She returned with Church to London after the war, where she later became a joint friend of Maria Cosway and Thomas Jefferson.
Hamilton's religion.
Hamilton, as a youth in the West Indies, was an orthodox and conventional Presbyterian of the "New Light" evangelical type (as opposed to the "Old Light" Calvinists); he was being taught by a student of John Witherspoon, a moderate of the New School. He wrote two or three hymns, which were published in the local newspaper. Robert Troup, his college roommate, noted that Hamilton was "in the habit of praying on his knees night and morning."
Gordon Wood says that Hamilton dropped his youthful religiosity during the Revolution and became, "a conventional liberal with theistic inclinations who was an irregular churchgoer at best"; however, he returned to religion in his last years. Chernow says he was nominally an Episcopalian but:
Hamilton made jokes about God at the Constitutional Convention. During the French Revolution, he displayed an "opportunistic religiosity", using Christianity for political ends and insisting that Christianity and Jefferson's democracy were incompatible. After 1801, Hamilton further asserted the truth of Christianity; he proposed a Christian Constitutional Society in 1802, to take hold of "some strong feeling of the mind" to elect ""fit" men" to office, and he wrote of "Christian welfare societies" for the poor. He was not a member of any denomination. After being shot, Hamilton spoke of his belief in God's mercy, and of his desire to renounce dueling; Bishop Moore administered communion to Hamilton.
Hamilton had always had respect for Jews. His birthplace of Charlestown had a large Jewish population with whom Hamilton came into contact on a regular basis. As a boy, he had learned Hebrew and could recite the Ten Commandments in its original language. He believed that Jewish achievement was a result of divine providence and warned that those who discredit the Jews "destroy the Christian religion."
Legacy.
Hamilton's interpretations of the Constitution set forth in the "Federalist Papers" remain highly influential, as seen in scholarly studies and court decisions.
Though the Constitution was ambiguous as to the exact balance of power between national and state governments, Hamilton consistently took the side of greater federal power at the expense of the states. As Secretary of the Treasury, he established—against the intense opposition of Secretary of State Jefferson—the country's first national bank. Hamilton justified the creation of this bank, and other increased federal powers, under Congress's constitutional powers to issue currency, to regulate interstate commerce, and to do anything else that would be "necessary and proper" to enact the provisions of the Constitution. Jefferson, on the other hand, took a stricter view of the Constitution: parsing the text carefully, he found no specific authorization for a national bank. This controversy was eventually settled by the Supreme Court of the United States in "McCulloch v. Maryland", which in essence adopted Hamilton's view, granting the federal government broad freedom to select the best means to execute its constitutionally enumerated powers, specifically the doctrine of implied powers. Nevertheless, the American Civil War and the Progressive Era demonstrated the sorts of crises and politics Hamilton's administrative republic sought to avoid.
Hamilton's policies as Secretary of the Treasury greatly affected the United States government and still continue to influence it. His constitutional interpretation, specifically of the Necessary and Proper Clause, set precedents for federal authority that are still used by the courts and are considered an authority on constitutional interpretation. The prominent French diplomat Charles Maurice de Talleyrand, who spent 1794 in the United States, wrote, "I consider Napoleon, Fox, and Hamilton the three greatest men of our epoch, and if I were forced to decide between the three, I would give without hesitation the first place to Hamilton", adding that Hamilton had intuited the problems of European conservatives.
Opinions of Hamilton have run the gamut: both John Adams and Thomas Jefferson viewed him as unprincipled and dangerously aristocratic. Hamilton's reputation was mostly negative in the eras of Jeffersonian democracy and Jacksonian democracy. However, by the Progressive era, Herbert Croly, Henry Cabot Lodge, and Theodore Roosevelt praised his leadership of a strong government. Several nineteenth- and twentieth-century Republicans entered politics by writing laudatory biographies of Hamilton.
Historians have generally taken one of two main views of Hamilton. Wilentz says:
The older Jeffersonian view attacks him as a centralizer, to the point sometimes of advocating monarchy.
Monuments and memorials.
Since the beginning of the American Civil War, Hamilton has been depicted on more denominations of US currency than anyone else. He has appeared on the $2, $5, $10, $20, $50, and $1,000. His likeness also began to appear on US postage in 1870. His portrait has continued to appear on US postage and currency, and most notably appears on the modern $10 bill, though it was announced on 18 June 2015 that his portrait would be replaced by that of a woman, to reflect the changing nature of American democracy and society (it was later decided his portrait would remain). Hamilton also appears on the $500 Series EE Savings Bond. The source of the face on the $10 bill is John Trumbull's 1805 portrait of Hamilton, in the portrait collection of New York City Hall.
The first postage stamp to honor Hamilton was issued by the U.S. Post Office in 1870. The portrayals on the 1870 and 1888 issues are from the same engraved die, which was modeled after a bust of Hamilton by Italian sculptor Giuseppe Ceracchi The Hamilton 1870 issue was the first US Postage stamp to honor a Secretary of the Treasury. The three-cent red commemorative issue, which was released on the 200th anniversary of Hamilton's birth in 1957, includes a rendition of the Federal Hall building, located in New York City. On March 19, 1956, the United States Postal Service issued the $5 Liberty Issue postage stamp honoring Hamilton.
The only home Hamilton ever owned was a Federal style mansion designed by John McComb Jr., which he built on his 32-acre country estate in Hamilton Heights in upper Manhattan. He named the house, which was completed in 1802, the "Grange" after his grandfather Alexander's estate in Ayrshire, Scotland. The house remained in the family until 1833 when his widow sold it to Thomas E. Davis, a British born real estate developer, for $25,000. Part of the proceeds were used by Eliza to purchase a new townhouse from Davis (Hamilton-Holly House) in Greenwich Village with her son Alexander. The Grange, first moved from its original location in 1889, was moved again in 2008 to a spot in St. Nicholas Park on land that was once part of the Hamilton estate, in Hamilton Heights, a neighborhood in upper Manhattan. The historic structure was restored to its original 1802 appearance in 2011, and is maintained by the National Park service as Hamilton Grange National Memorial.
Alexander Hamilton served as one of the first trustees of the Hamilton-Oneida Academy in New York state. Later the Academy received a college charter in 1812, and the school was formally renamed Hamilton College. Columbia University, Hamilton's alma mater, has official memorials to Hamilton on its campus in New York City. The college's main classroom building for the humanities is Hamilton Hall, and a large statue of Hamilton stands in front of it. The university press has published his complete works in a multivolume letterpress edition. Columbia University's student group for ROTC cadets and Marine officer candidates is named the Alexander Hamilton Society.
The main administration building of the Coast Guard Academy in New London, Connecticut, is named Hamilton Hall to commemorate Hamilton's creation of the United States Revenue Cutter Service, one of the predecessor services of the United States Coast Guard. The U.S. Army's Fort Hamilton in Brooklyn is named after Hamilton.
In 1990, the U.S. Custom House in New York City was renamed after Hamilton.
In 1880, his son John Church Hamilton commissioned Carl Conrads to sculpt a granite statue, now located in Central Park, New York City.
One statue honoring Alexander Hamilton in Chicago was mired in controversy, at least concerning the surrounding architecture. Kate Sturges Buckingham (1858–1937), of the Buckingham Fountain family, commissioned the monument. Its impetus was that Treasury Secretary Hamilton "secured the nation's financial future" and made it possible for her own family to make its fortune in grain elevators and banking. Consequently, John Angel was hired to model a figurative sculpture and the Finnish architect Eliel Saarinen was to create a "colossal architectural setting" for it. The proposed 80-foot tall columned shelter was poorly received. By Ms. Buckingham's death in 1937, the sculpture's setting, location, and design were uncertain. Conspiracy allegations surfaced, and the matter became mired in litigation. After the courts ordered the construction to be completed by 1953, the trustees hired architect Samuel A. Marx. The structure was completed, had structural problems, and was eventually demolished in 1993. The statue was gilded, and is still on display.
A statue, by James Earle Fraser, was dedicated on May 17, 1923, on the south terrace of the Treasury Building, in Washington.
On slavery.
Until recently the prevailing scholarly view was that Hamilton, like the Founders generally, lacked a deep concern about slavery. John Patrick Diggins traced this animus of historians against Hamilton to Vernon L. Parrington, who, writing in the 1920s to praise Jefferson and the Enlightenment, denounced a reactionary and unenlightened Hamilton as greedy and evil. Sean Wilentz contends that the consensus has changed sharply in Hamilton's favor in recent years. For example, Michael D. Chan argues that the first U.S. Treasury Secretary was committed to ending slavery, Chernow calls him "a fervent abolitionist", David O. Stewart states he was a "lifelong opponent of slavery", and Braun says he "was a leading anti-slavery advocate". Historian Manning Marable says Hamilton "vigorously opposed the slave trade and slavery's expansion."
Hamilton's first polemic against King George's ministers contains a paragraph that speaks of the evils that "slavery" to the British would bring upon the Americans. McDonald sees this as an attack on the institution of slavery. David Hackett Fischer believes the term is used in a symbolic way at that time.
During the Revolutionary War, Hamilton took the lead in proposals to arm slaves, free them, and compensate their masters. In 1779, Hamilton worked closely with his friend John Laurens of South Carolina to propose that such a unit be formed, under Laurens' command. Hamilton proposed to the Continental Congress that it create up to four battalions of slaves for combat duty, and free them. Congress recommended that South Carolina (and Georgia) acquire up to three thousand slaves for service, if they saw fit. Although the South Carolina governor and Congressional delegation had supported the plan in Philadelphia, they did not implement it. 
Hamilton believed that the natural faculties of blacks were probably as good as those of free whites, and he warned that the British would arm the slaves if the patriots did not. In his 21st-century biography, Chernow cites this incident as evidence that Hamilton and Laurens saw the Revolution and the struggle against slavery as inseparable. Hamilton attacked his political opponents as demanding freedom for themselves and refusing to allow it to blacks.
In January 1785, Hamilton attended the second meeting of the New York Manumission Society (NYMS). John Jay was president and Hamilton was the first secretary and later became president. Chernow notes how the membership soon included many of Hamilton's friends and associates. Hamilton was a member of the committee of the society that petitioned the legislature to end the slave trade, and that succeeded in passing legislation banning the export of slaves from New York. In the same period, Hamilton felt bound by the rule of law of the time and his law practice facilitated the return of a fugitive slave to Henry Laurens of South Carolina. He opposed the compromise at the 1787 Constitutional Convention by which the federal government could not abolish the slave trade for 20 years, and was disappointed when he lost that argument.
Hamilton never supported forced emigration for freed slaves. Horton has argued from this that he would be comfortable with a multiracial society, and that this distinguished him from his contemporaries. In international affairs, he supported Toussaint L'Ouverture's black government in Haiti after the revolt that overthrew French control, as he had supported aid to the slaveowners in 1791—both measures hurt France. Scant evidence has been interpreted by a few to indicate Hamilton may have owned household slaves, as did many wealthy New Yorkers (the evidence for this is indirect; McDonald interprets it as referring to paid employees).
On economics.
Hamilton has been portrayed as the "patron saint" of the American School of economic philosophy that, according to one historian, dominated economic policy after 1861. He firmly supported government intervention in favor of business, after the manner of Jean-Baptiste Colbert, as early as the fall of 1781. Hamilton opposed the British ideas of free trade, which he believed skewed benefits to colonial and imperial powers, in favor of protectionism, which he believed would help develop the fledgling nation's emerging economy. Henry C. Carey was inspired by his writings. Hamilton influenced the ideas and work of the German Friedrich List. In Hamilton's view, a strong executive, linked to the support of the people, could become the linchpin of an administrative republic. The dominance of executive leadership in the formulation and carrying out of policy was essential to resist the deterioration of republican government. Ian Patrick Austin has explored the similarities between Hamiltonian recommendations and the development of Meiji Japan after 1860.
In popular culture.
Apart from the $10 bill and an obscure 1931 film, Hamilton did not attract much attention in American popular culture until the advent of the 2015 hit Broadway musical "Hamilton". The musical, which features music, lyrics, and a book by Lin-Manuel Miranda, is based on a biography by Ron Chernow. "The New Yorker" called the show "an achievement of historical and cultural reimagining. In Miranda's telling, the headlong rise of one self-made immigrant becomes the story of America." The review in "The New York Times" concluded:
The off-Broadway production of "Hamilton" won the 2015 Drama Desk Award for Outstanding Musical as well as seven other Drama Desk Awards. In 2016, "Hamilton" received the Pulitzer Prize for Drama.
Hamilton has also appeared as a significant figure in popular works focusing on other American political figures of his time. He is a major character in Gore Vidal's 1973 historical novel "Burr" and in episodes of the 1976 PBS miniseries "The Adams Chronicles".

</doc>
<doc id="40598" url="https://en.wikipedia.org/wiki?curid=40598" title="Carl Woese">
Carl Woese

Carl Richard Woese (; July 15, 1928 – December 30, 2012) was an American microbiologist and biophysicist. Woese is famous for defining the Archaea (a new domain or kingdom of life) in 1977 by phylogenetic taxonomy of 16S ribosomal RNA, a technique pioneered by Woese which revolutionized the discipline of microbiology. He was also the originator of the RNA world hypothesis in 1967, although not by that name. He held the Stanley O. Ikenberry Chair and was professor of microbiology at the University of Illinois at Urbana–Champaign.
Life and education.
Woese attended Deerfield Academy in Massachusetts. He received a bachelor's degree in mathematics and physics from Amherst College in 1950. During his time at Amherst, Woese took only one biology course (Biochemistry, in his senior year) and had "no scientific interest in plants and animals" until advised by William M. Fairbank, then an assistant professor of physics at Amherst, to pursue biophysics at Yale.
In 1953, he completed a Ph.D. in biophysics at Yale University, where his doctoral research focused on the inactivation of viruses by heat and ionizing radiation. He studied medicine at the University of Rochester for two years, quitting two days into a pediatrics rotation. Then he became a postdoctoral researcher in biophysics at Yale University investigating bacterial spores. From 1960–63, he worked as a biophysicist at the General Electric Research Laboratory in Schenectady, New York. In 1964, Woese joined the microbiology faculty of the University of Illinois at Urbana–Champaign, where he focused on Archaea, genomics, and molecular evolution as his areas of expertise. He became a professor at the University of Illinois at Urbana–Champaign's Carl R. Woese Institute for Genomic Biology, which was renamed in his honor in 2015, after his death.
Woese died on December 30, 2012, following complications from pancreatic cancer.
Work and discoveries.
Early work on the genetic code.
Woese turned his attention to the genetic code while setting up his lab at General Electric's Knolls Laboratory in the fall of 1960. Interest among physicists and molecular biologists had begun to coalesce around deciphering the correspondence between the twenty amino acids and the four letter alphabet of nucleic acid bases in the decade following James D. Watson and Francis Crick's discovery of the structure of DNA in 1953. Woese published a series of papers on the topic. In one, he deduced a correspondence table between what was then known as "soluble RNA" and DNA based upon their respective base pair ratios. He then re-evaluated experimental data associated with the hypothesis that viruses used one base, rather than a triplet, to encode each amino acid, and suggested 18 codons, correctly predicting one for proline. Other work established the mechanistic basis of protein translation, but in Woese's view, largely overlooked the genetic code's evolutionary origins as an afterthought.
In 1962 Woese spent several months as a visiting researcher the Pasteur Institute in Paris, a locus of intense activity on the molecular biology of gene expression and gene regulation. While in Paris, he met Sol Spiegelman, who invited Woese to visit the University of Illinois after hearing his research goals; at this visit Spiegelman offered Woese a position with immediate tenure beginning in the fall of 1964. With the freedom to patiently pursue more speculative threads of inquiry outside the mainstream of biological research, Woese began to consider the genetic code in evolutionary terms, asking how the codon assignments and their translation into an amino acid sequence might have evolved.
Discovery of the third kingdom.
For much of the 20th century, prokaryotes were regarded as a single group of organisms and classified based on their biochemistry, morphology and metabolism. In a highly influential 1962 paper, Roger Stanier and C. B. van Niel first established the division of cellular organization into prokaryotes and eukaryotes, negatively defining prokaryotes as those organisms lacking a cell nucleus. Adapted from Édouard Chatton's generalization, Stanier and Van Niel's concept was quickly accepted as the most important distinction among organisms; yet they were nevertheless skeptical of microbiologists' attempts to construct a natural phylogenetic classification of bacteria. However, it became generally assumed that all life shared a common prokaryotic (implied by the Greek root πρό (pro-), before, in front of) ancestor.
In 1977, Carl Woese and George E. Fox experimentally disproved this universally held hypothesis about the basic structure of the tree of life. Woese and Fox discovered a kind of microbial life which they called the “archaebacteria” (Archaea). They reported that the archaebacteria comprised "a third kingdom" of life as distinct from bacteria as plants and animals. Having defined Archaea as a new "urkingdom" (later domain) which were neither bacteria nor eukaryotes, Woese redrew the taxonomic tree. His three-domain system, based on phylogenetic relationships rather than obvious morphological similarities, divided life into 23 main divisions, incorporated within three domains: Bacteria, Archaea, and Eucarya.
Acceptance of the validity of Woese's phylogenetically valid classification was a slow process. Prominent biologists including Salvador Luria and Ernst Mayr objected to his division of the prokaryotes. Not all criticism of him was restricted to the scientific level. A decade of labor-intensive oligonucleotide cataloging left him with a reputation as "a crank," and Woese would go on to be dubbed as "Microbiology's Scarred Revolutionary" by a news article printed in the journal "Science". The growing amount of supporting data led the scientific community to accept the Archaea by the mid-1980s. Today, few scientists cling to the idea of a unified Prokarya.
Woese's work on Archaea is also significant in its implications for the search for life on other planets. Before the discovery by Woese and Fox, scientists thought that Archaea were extreme organisms that evolved from the organisms more familiar to us. Now, most believe they are ancient, and may have robust evolutionary connections to the first organisms on Earth. Organisms similar to those archaea that exist in extreme environments may have developed on other planets, some of which harbor conditions conducive to extremophile life.
Notably, Woese's elucidation of the tree of life shows the overwhelming diversity of microbial lineages; single-celled organisms represent the vast majority of the biosphere's genetic, metabolic, and ecologic niche diversity. As microbes are crucial for many biogeochemical cycles and to the continued function of the biosphere, Woese's efforts to clarify the evolution and diversity of microbes provided an invaluable service to ecologists and conservationists. It was a major contribution to the theory of evolution and to our knowledge of the history of life.
-->
Evolution of primary cell types.
Woese also speculated about an era of rapid evolution in which considerable horizontal gene transfer occurred between organisms. First described by Woese and Fox in a 1977 paper, these organisms, or "progenotes", were protocells that exhibited a far lower level of complexity due to their error-prone translation apparatus ("noisy genetic transmission channel") that produced high mutation rates which constrained the specificity of cellular interaction and limited genome size. This early translation apparatus would have produced a group of similar, yet functionally equivalent, proteins, rather than a single protein. Furthermore, because of this reduced specificity, all cellular components were susceptible to HGT, and rapid evolution occurred at the level of the ecosystem.
The transition to modern cells (the "Darwinian Threshold") occurred when organisms evolved translation mechanisms with modern levels of fidelity; improved performance allowed cellular organization to reach a level of complexity and connectedness that made genes from other organisms much less able to displace an individual's own genes. Horizontal gene transfer during this era was responsible for the fast early evolution of complex biological structures.
In later years, Woese's work concentrated on genomic analysis to elucidate the significance of horizontal gene transfer (HGT) for evolution. He worked on detailed analyses of the phylogenies of the aminoacyl-tRNA synthetases and on the effect of horizontal gene transfer on how those key enzymes are distributed among organisms. The goal of the research was to explain how the primary cell types (the archaeal, eubacterial, and eukaryotic) evolved, from some ancestral state in the RNA world.
Perspectives on Biology.
Woese shared his thoughts on the past, present, and future of biology in "Current Biology":
The "important questions" that 21st century biology faces all stem from a single question, the nature and generation of biological organization. . . . Yes, Darwin is back, but in the company of . . . scientists who can see much further into the depths of biology than was possible heretofore. It is no longer a "10,000 species of birds" view of evolution—evolution seen as a procession of forms. The concern is now with the process of evolution itself.
I see the question of biological organization taking two prominent directions today. The first is the evolution of (proteinaceous) cellular organization, which includes sub-questions such as the evolution of the translation apparatus and the genetic code, and the origin and nature of the hierarchies of control that fine-tune and precisely interrelate the panoply of cellular processes that constitute cells. It also includes the question of the number of different basic cell types that exist on earth today: did all modern cells come from a single ancestral cellular organization?
The second major direction involves the nature of the global ecosystem. . . . Bacteria are the major organisms on this planet—in numbers, in total mass, in importance to the global balances. Thus, it is microbial ecology that . . . is most in need of development, both in terms of facts needed to understand it, and in terms of the framework in which to interpret them.
Woese considered biology to have an "all-important" role in society. In his view, biology should serve a broader purpose than the pursuit of "an engineered environment":
What was formally recognized in physics needs now to be recognized in biology: science serves a dual function. On the one hand it is society's servant, attacking the applied problems posed by society. On the other hand, it functions as society's teacher, helping the latter to understand its world and itself. It is the latter function that is effectively missing today.
Honors and scientific legacy.
Woese was a MacArthur Fellow in 1984, was made a member of the National Academy of Sciences in 1988, received the Leeuwenhoek Medal (microbiology's highest honor) in 1992, the Selman A. Waksman Award in Microbiology in 1995 from the National Academy of Sciences, and was a National Medal of Science recipient in 2000. In 2003, he received the Crafoord Prize from the Royal Swedish Academy of Sciences "for his discovery of a third domain of life". In 2006, he was made a foreign member of the Royal Society.
Many microbial species, such as "Pyrococcus woesei", "Methanobrevibacter woesei", and "Conexibacter woesei", are named in his honor.
Microbiologist Justin Sonnenburg of Stanford University said "The 1977 paper is one of the most influential in microbiology and arguably, all of biology. It ranks with the works of Watson and Crick and Darwin, providing an evolutionary framework for the incredible diversity of the microbial world".
With regard to Woese's work on horizontal gene transfer as a primary evolutionary process, Professor Norman R. Pace of the University of Colorado at Boulder said, "I think Woese has done more for biology than any biologist in history, including Darwin... There's a lot more to learn, and he's been interpreting the emerging story brilliantly".

</doc>
<doc id="40599" url="https://en.wikipedia.org/wiki?curid=40599" title="Otto II, Holy Roman Emperor">
Otto II, Holy Roman Emperor

Otto II (955 – December 7, 983), called the Red ("Rufus"), was Holy Roman Emperor from 973 until his death in 983. A member of the Ottonian dynasty, Otto II was the youngest and sole surviving son of Otto the Great and Adelaide of Italy.
Otto II was made joint-ruler of Germany in 961, at an early age, and his father named him co-Emperor in 967 to secure his succession to the throne. His father also arranged for Otto II to marry the Byzantine Princess Theophanu, who would be his wife until his death. When his father died after a 37-year reign, the eighteen-year-old Otto II became absolute ruler of the Holy Roman Empire in a peaceful succession. Otto II spent his reign continuing his father's policy of strengthening Imperial rule in Germany and extending the borders of the Empire deeper into southern Italy. Otto II also continued the work of Otto I in subordinating the Catholic Church to Imperial control.
Early in his reign, Otto II defeated a major revolt against his rule from other members of the Ottonian dynasty who claimed the throne for themselves. His victory allowed him to exclude the Bavarian line of Ottonians from the line of Imperial succession. This strengthened his authority as Emperor and secured the succession of his own son to the Imperial throne.
With domestic affairs settled, Otto II would focus his attention from 980 onward to annexing the whole of Italy into the Empire. His conquests brought him into conflict with the Byzantine Empire and with the Muslims of the Fatimid Caliphate, who both held territories in southern Italy. After initial successes in unifying the southern Lombard principalities under his authority and in conquering Byzantine-controlled territory, Otto II's campaigns in southern Italy ended in 982 following a disastrous defeat by the Muslims. While he was preparing to counterattack Muslim forces, a major uprising by the Slavs broke out in 983, forcing the Empire to abandon its major territorial holdings east of the Elbe river.
Otto II died suddenly in 983 at the age of 28 after a ten-year reign. He was succeeded as Emperor by his three-year-old son Otto III, plunging the Empire into a political crisis.
Early years.
Birth and youth.
Otto II was born in 955, the third son of the King of Germany Otto I and his second wife Adelaide of Italy. By 957, Otto II's older brothers Henry (born 952) and Bruno (born 953) had died, as well as Otto I's son from his first wife Eadgyth, the Crown Prince Liudolf, Duke of Swabia. With his older brothers dead, the two-year-old Otto II's became the Kingdom's crown prince and Otto I's heir apparent. Otto I entrusted his illegitimate son, Archbishop William of Mainz, with Otto II's literary and cultural education. Margrave Odo, commander of the Eastern March, taught the young crown prince the art of war and the kingdom's legal customs.
Needing to put his affairs in order prior to his descent into Italy, Otto I summoned a Diet at Worms and had Otto II elected, at the age of six, co-regent in May 961. Otto II was later crowned by his uncle Bruno the Great, Archbishop of Cologne, at Aachen Cathedral on May 26, 961. While Otto I had secured succession of the throne, he had violated the Kingdom's unwritten law that succession rights could only be granted to a child who has reached the age of majority. He was likely motivated by the high-risk associated with his expedition into Italy to claim the Imperial title from the Pope. Otto I crossed the Alps into Italy, while Otto II remained in Germany, and the two Archbishops, Bruno and William, were appointed as his regents. After three and a half year absence in Italy, Otto I returned to Germany early in 965 as Holy Roman Emperor. In order to give the hope of dynastic continuity after his death, Otto I again confirmed Otto II as his heir on February 2, 965, the third anniversary of Otto I's coronation as Emperor.
Heir apparent.
Though Otto I was crowned Emperor in 962 and returned to Germany in 965, the political situation in Italy remained unstable. After almost two years in Germany, Otto I made a third expedition to Italy in 966. Bruno was again appointed regent over the eleven-year-old Otto II during Otto I's absence.
With his power over northern and central Italy secured, Otto I sought to clarify his relationship with the Byzantine Empire in the East. The Byzantine Emperor objected to Otto's use of the title "Emperor". The situation between East and West was finally resolved to share sovereignty over southern Italy. Otto I sought a marriage alliance between his Imperial house and the Eastern Macedonian dynasty. A prerequisite for the marriage alliance was the coronation of Otto II as Co-Emperor. Otto I then sent word for Otto II to join him in Italy. In October 967, father and son met in Verona and together marched through Ravenna to Rome. On December 25, 967, Otto II was crowned Co-Emperor by Pope John XIII, securing Otto II's succession to the Imperial crown following his father's death.
Otto II's coronation allowed marriage negotiations to begin with the East. Only in 972, six years later, under the new Byzantine Emperor John I Tzimiskes, was a marriage and peace agreement concluded, however. Though Otto I preferred Byzantine Princess Anna Porphyrogenita, daughter of former Byzantine Emperor Romanos II, as she was born in the purple, her age (then only five years old) prevented serious consideration by the East. The choice of Emperor John I Tzimisces was his niece Theophanu, who was the soldier-emperor's niece by marriage. On April 14, 972, the sixteen-year-old Otto II was married to the twelve-year-old Eastern princess, and Theophanu was crowned empress by the Pope.
Even after his coronation, Otto II remained in the shadow of his overbearing father. Though the nominal co-ruler of the Empire, he was denied any role in its administration. Unlike his earlier son Liudolf, whom Otto I named Duke of Swabia in 950, Otto II was granted no area of responsibility. Otto II was confined primarily to northern Italy during his father's time south of the Alps. After five years away, the Imperial family returned to Saxony in August 972.
On May 7, 973, Otto died of fever, and Otto II succeeded his father as sole Emperor without meeting any opposition. Otto II spent his reign continuing his father's policy of strengthening Imperial rule in Germany and extending it deeper into Italy.
Reign as emperor.
Coronation and domestic strife.
When Otto the Great died, the smooth succession to the imperial throne of Otto II had long been guaranteed. Otto II had been king of Germany for twelve years and Emperor for five at the time of Otto the Great's death. Unlike his father, Otto II did not have any brothers to contest his claims to the throne. On May 8, the nobles of the Empire assembled before Otto II and, according to the Saxon Chronicler Widukind of Corvey, "elected" Otto II as his father's successor. One of Otto II's first acts was to confirm the rights and possessions of the Archbishop of Magdeburg. Although Otto II had succeeded peacefully to the throne, internal divisions of power still remained unaddressed. During his first seven years as Emperor, he was constantly occupied with maintaining Imperial power against internal rivals and external enemies.
The domestic problems Otto the Great faced between 963 and 972 had not been resolved by his death. The Saxon nobility continued to resist the Archdiocese of Magdeburg located along the Empire's eastern border. Though established by Otto I, the exact details of the diocese's boundaries were left to Otto II and his aides. Otto II's marriage to the Byzantine Princess Theophanu proved to be to his disadvantage because the Saxon nobles felt it distanced the Emperor from their interests. Among Otto II's chief advisors, only the Saxon Bishop Dietrich I of Metz had close connections with the old Saxon nobility. His other advisers lacked support from the Empire's various Dukes. The Archbishop of Mainz Willigis, appointed in 975, who had been with Otto II's advisor since Otto the Great's second expedition into Italy in the 960s, had not been born from a noble family. Hildebald of Worms, who had been appointed as Otto II's Chancellor in 977 and then as Bishop of Worms in 979, was also not from a noble family.
Otto the Great also failed to clarify affairs in Italy prior to his death. Otto died soon after the appointment of Pope Benedict VI in 973. In 974 Benedict was imprisoned in the Castel Sant'Angelo, the stronghold of the Crescentii family. When Otto II sent an imperial representative, Count Sicco, to secure his release, Crescentius I and Cardinal-Deacon Franco Ferrucci, who would subsequently become Boniface VII, an antipope, had Benedict murdered while still in prison.
Following his coronation, a rift developed between Otto II and his mother, the Dowager Empress Adelaide of Italy. From the death of Otto the Great until Easter 974, Adelaide accompanied the Emperor at all times, traveling throughout the Empire with him. However, Otto II's mother and his wife Theophano each distrusted the influence the other held over the Emperor, causing friction within the Imperial household. A final meeting between Otto II and Adelaide was arranged shortly before Pentecost in 978, but a peaceful outcome was not achieved, forcing Adelaide to retire to Burgundy and to the protection of her brother King Conrad of Burgundy.
Conflict with Henry II.
Otto II sought continued peace between himself and the descendants of his uncle Henry I, Duke of Bavaria. To ensure domestic tranquillity, Otto II, on June 27, 973, granted his cousin, Henry II, Duke of Bavaria, control over the imperial castles in Bamberg and Stegaurach. This was not enough for the young Bavarian Duke, who wished to extend his influence in the Duchy of Swabia as his father had under Otto the Great. The death of Bishop Ulrich of Augsburg on July 4, 973, brought the conflict between the cousins to a head. Without consulting Otto II, Henry II named his cousin Henry as the new Bishop of Augsburg. Augsburg was located on the western side of the Swabian-Bavarian border, the territory of Henry II's brother-in-law Burchard III, Duke of Swabia. Henry's actions in naming a bishop in a duchy not his own and without Imperial direction brought him into conflict with both Otto II and Burchard III. Not desiring civil war, Otto II, on September 22, 973, invested Henry as bishop.
On November 12, 973, Burchard III died with no heir: his union to Hadwing, sister of Henry II, had produced no children. With no clear successor, Henry II demanded that Otto II name him as the new Duke of Swabia. The Emperor sensed the far-reaching ambitions of his cousin and denied his request. Instead, Otto II named as Duke his nephew Otto, son of his half-brother Liudolf, Duke of Swabia. Prior to his appointment, Otto had been a long-time opponent of Henry II's expanding influence in Swabia. By naming a descendant of his half-brother instead of his cousin, Otto II reinforced his father's policy of appointing close family members to key posts throughout the Empire. This appointment elevated the descendants of Otto the Great above those of Henry I in the selection process, further dividing Otto II and Henry II.
The appointment of Otto as Duke of Swabia was taken by Henry II as an assault on his claim to the Imperial throne and a slight to his honor. He and his advisor, Bishop Abraham of Freising, conspired with the Duke of Poland Mieszko I and the Duke of Bohemia Boleslaus II against Otto II in 974. While the historical sources do not describe the goals of the conspirators, Henry II likely intended to restore his honor and to ensure his position as the second most influential man in the Empire. Upon hearing of the conspiracy, Poppo, the Bishop of Würzburg, demanded Henry II and his followers to submit to Otto II or face excommunication. Otto the Great's efforts to consolidate the Church under Imperial control had made this type of action normal. Henry II and his followers complied and submitted to Otto II before armed conflict broke out. Otto II, however, severely punished this conspirators: Henry II was imprisoned at Ingelheim and Bishop Abraham at Corvey.
By 976, Henry II returned to Bavaria. Whether Otto II released him from prison or if he escape is not known for certain. Upon his return, Henry came into open rebellion against Otto II, claiming rulership over the Empire for himself. Henry II mobilized the Saxon nobility against Otto II. In particular, Henry II had strong connections to Margrave Gunther of Merseburg, Count Egbert the One-Eyed, and Dietrich I of Wettin, who were all displeased with Otto II's lack of adherence to Saxon tradition. In response to the rebellion, Otto II stripped Henry II of his Duchy and had him excommunicated. Otto II then marched his army south to Bavaria and laid siege to Regensburg, Henry II's stronghold. Otto II's army eventually broke through the city's defenses, forcing Henry II to flee to Bohemia.
With Henry II deposed, in July 976 Otto II issued far-reaching edicts on the reorganization of the southern German duchies. Otto II reduced the Duchy of Bavaria in territorial size by almost a third. From the confiscated Bavarian territory, Otto II established the Duchy of Carinthia in southern Germany. By depriving Bavaria of the March of Verona, Otto II considerably reduced the influence of the Bavarian Dukes in northern Italy and in general Imperial policy regarding Italy. Otto II gave the newly diminished Duchy of Bavaria to his relative Otto, the Duke of Swabia, and appointed Henry III, son of the former Bavarian Duke Berthold, as Duke of Carinthia. These appointments continued his policy of appointing of individuals who had no political links to Otto the Great, including those who had even rebelled against him.
With matters in southern Germany settled, Otto II turned his attention to defeating and capturing Henry II. After a failed first invasion into Bohemia, Otto II marched to Bohemia a second time in August 977. While in Bohemia, a revolt broke out in Bavaria. Henry I, Bishop of Augsburg, and the newly appointed Carinthian Duke Henry III joined Henry II in rebellion, forcing Otto II to return from Bohemia. The Emperor, aided by the Duke of Swabia and Bavaria, met the rebels at Passau and, after a long siege, forced them into submission. Otto II then brought the rebels before the Imperial Diet in Quedlinburg on March 31, 978. Boleslaus II was treated with honors and swore loyalty to Otto II. Mieszko I of Poland also submitted to Otto II's overlordship. Henry II, however, was not so fortunate: Otto II imprisoned him under the custody of the Bishop of Utrecht where he would remain until Otto II's death in 983.
While Otto the Great had pardoned rebellious family members for their crimes, Otto II followed a different policy. Instead, Otto II hoped to subordinate the Bavarian line of Ottonians to his Imperial authority. Henry II's four-year-old son, also named Henry, was sent to Hildesheim to study for an ecclesiastical career. It appears Otto II intended to end the Bavarian Ottonians' secular control of Bavaria. Under a new Duke, Bavaria would remain a remote area of the Empire. Otto II would only visit the Duchy three times during his reign, in all cases accompanied by the military.
War with Denmark.
In 950, Otto the Great had subdued the Kingdom of Denmark and forced the Danish King Gorm the Old to accept him as his overlord. Otto the Great also forced the king and his heir apparent Harald Bluetooth to convert to Christianity. Under the reign of Otto the Great, Denmark fulfilled all its obligations and regularly paid tribute to the Germans. When Harald became king in 958, he expanded the control of his kingdom into Norway, becoming king there in 970. With his newly obtained power, the young ruler was no longer willing to accept German supremacy over his kingdom. In summer 974, Harald rebelled against Otto II. With the support of Norwegian troops, Harald was able to cross the Danish border into Germany, defeating the German forces stationed in the north. Otto II attacked Harald's forces, but the joint Danish-Norwegian army repelled the German army. In autumn, however, when the Norwegian allies sailed north to return to Norway, Otto II was able to counter Harald's advances at the Danevirke. As a result of this victory, Otto II officially annexed Denmark into the Empire and exiled Harald to Norway.
War against France.
Before Henry II's civil war in southern Germany erupted, Otto II was faced with disputes in western Germany. The brothers Reginar IV, Count of Mons, and Lambert I, Count of Louvain, demanded that the Emperor restore their confiscated inheritance in the Duchy of Lorraine. Years earlier in 958, Otto the Great banished their father Reginar III, Count of Hainaut, to Bohemia after he attempted a failed revolt. In 973, Otto II granted their request. With both Otto the Great and Count Reginar III dead, it appears Otto II desired a fresh start with the two sons. Lambert I and Reginar IV returned to Lorraine in 973 to reclaim their land by force. After an initial failure, the brother attempted again in 976, this time with the support of King Lothar of France. To help calm the situation in the west, Otto II appointed Charles, his cousin and brother of Lothar, as Duke of Lower Lorraine. The same year, Otto II appointed Egbert as his Imperial Chancellor.
Otto II's support of Charles, however, infuriated the French king, who claimed the Duchy as his own territory. Charles and Lothair were also feuding, with Charles being exiled from France over infidelity allegation concerning Lothair's wife. Charles fled to Otto II's court and paid homage to Otto II. In return, Otto II appointed Charles as Duke and promised to support him in claiming the French throne. Soon after Otto II crushed Henry II's revolt in the south, the Emperor and his wife Theophanu returned to the old capital of Aachen in Lorraine. With the Imperial family near the French border, Lothair invaded Lorraine and marched on Aachen. With the French army in sight, Otto II and Theophano fled to Cologne and then to the Duchy of Saxony. Upon hearing of the French invasion, Otto II’s mother Adelaide of Italy, who was Lothair's mother-in-law, sided with Lothair over her own son and moved to the court of her brother King Conrad of Burgundy. After occupying Aachen for five days, Lothair returned to France after symbolically disgracing the city.
Otto II convened the Imperial Diet in mid-July at Dortmund. There, Otto II declared war against France and prepared his army to march west. In September 978, Otto II retaliated against Lothair by invading France with the aid of Charles. He met with little resistance on French territory, devastating the land around Rheims, Soissons, and Laon. Otto II then had Charles crowned as King of France by Theodoric I, Bishop of Metz. Lothair then fled to the French capital of Paris and was there besieged by Otto II and Charles. Sickness among his troops brought on by winter and a French relief army under Hugh Capet forced Otto II and Charles to lift the siege on November 30, and to return to Germany. On the journey back to Germany, Otto's rearguard was attacked and destroyed by French forces, with their supplies being captured. Despite neither side obtaining a clear victory, Otto II felt his honor was sufficiently restored and opened peace negotiations with the French King. Peace was finally concluded between Otto II and Lothair in 980: in return for renouncing his claims on Lorraine, Otto II would recognize Lothair's son Louis V as the rightful heir to the French throne.
With peace concluded, Otto II returned to Aachen to celebrate Pentecost, and then moved towards Nijmegen. During the journey, in late June or early July 980, the Empress Theophanu gave birth to the Imperial couple's only son: Otto III.
Reign in Italy.
Papal politics.
With his rule north of the Alps secured and with the birth of his heir, Otto II shifted his focus to Italy. The situation south of the Alps was chaotic. Pope Benedict VI, who had been appointed by Otto I, had been imprisoned by the Romans in Castel Sant'Angelo. When Otto II sent an imperial representative, Count Sicco, to secure his release, Crescentius I and Cardinal Franco Ferrucci had Benedict VI murdered while still in prison in 974. Cardinal Franco Ferrucci then crowned himself as Benedict VI's successor, becoming Antipope Boniface VII. A popular revolt, however, forced Boniface VII to flee to Constantinople, taking a vast treasure with him. In October 974, under the direction of Count Sicco, the bishop of Sutri was elected Pope as Pope Benedict VII. Boniface VII was then summarily excommunicated for his unsuccessful attempt to take the papacy.
In 979 Benedict VII's position as ruler of Rome was threatened, forcing the Pope to withdraw from and seek the aid of the Emperor. Accepting the Pope's call for aid, Otto II and Theophano, along with their infant son Otto III, prepared for a march south across the Alps. Otto II appointed Willigis, the Archbishop of Mainz, to serve as his regent over Germany.
In October 980 the Imperial court arrived in Chiavenna and received its first Italian delegations. Otto II arrived in Italy at Pavia on December 5, 980. In Pavia, Otto II and his mother, the dowager empress Adelaide of Italy, were reconciled after years of being apart. Before the imperial family celebrated Christmas together in Ravenna, Otto II received the Iron Crown of Lombardy as the King of Italy. Following the New Year, Otto II led his Imperial court to Rome, reaching the city on February 9, 981, where the Emperor restored Pope Benedict VII to his papal throne without difficulty. In Rome, Otto II held a magnificent court ceremony to mark Easter. The imperial family was joined by Otto II's sister Matilda, Abbess of Quedlinburg, King Conrad of Burgundy and his wife Matilda of France, Duke Hugh Capet of France, Duke Otto of Swabia and Bavaria, and other high secular and religious officials from Germany, Italy and France.
Otto II proceeded to hold court in Rome, making the city his Imperial capital, where he received princes and nobles from all parts of western Europe.
Venetian affairs.
The relationship between the Empire and the Republic of Venice was readdressed during Otto II's reign. In 966, The Doge of Venice Peitro IV married a relative of Otto I. The marriage brought the Empire and Venice into close relationship, with Otto I, in 967, granting a series of commercial agreements to Venice in general and to Pietro IV's family in particular. These agreements strengthened Venice's tie to the Western Empire, which greatly angered the Byzantine Emperor John I Tzimisces as Venice controlled all sea trade between Western Europe and the Byzantine Levant in the East.
Otto I's military protection of Pietro IV ensured his hold over power in Venice despite his autocratic tendencies over the republican city. In 973, however, Otto I died. With Otto II busy suppressing revolts in Germany, the Venetians opposed to Pietro IV found their opportunity to depose him. Imprisoning the Doge within his palace, the Venetians nobles set fire to the building. However, the fire soon spread to Saint Mark's Basilica, resulting in the greater part of the city being burnt. The Doge and his son, also named Pietro, were killed in the blaze, but their bodies were later recovered and respectfully buried. Pietro IV's younger son, Vitale Candiano, survived however, and fled to Otto II's court in Saxony with plans to depose the new pro-Byzantine Doge, Pietro I Orseolo.
Pietro I's conciliating policy towards the Empire was ineffective. After having ruled Venice for four years, Pietro I voluntarily abdicated to become a monk, allowing the pro-Ottonian Vitale to return to Venice as Doge in 977, restoring the city's friendly relationship with the Empire. However, Vitale's reign was short (less than two years) and he too voluntarily abdicated to become a monk. With the position vacant, the pro-Byzantine Tribuno Memmo became the new Doge in 979. With the change in leadership, Otto II was reluctant to renew the city's commercial agreements which his father had previously granted to the city. It was only after the intervention of Otto II's mother, the dowager empress Adelaide of Italy, did the Emperor renew the agreements.
Violence erupted in Venice during 980 when tensions between pro-Ottonian Coloprini family and the pro-Byzantine Morosini family. The Coloprini pleaded with the Emperor for support. Seeing an opportunity to fully incorporate Venice into the Empire, Otto II agreed. Upon arriving in Italy in 981, Otto II immediately imposed a trade embargo against the island republic. While the initial embargo showed little effect on Venice, Otto II imposed a second embargo in 983 which dealt considerable damage to the Venetian economy. The effects were disastrous enough to cause the ruling Venetian families to surrender to Otto II, but Otto II's untimely death that year prevented such action.
Religious policy.
Otto II followed the policy of his father in expanding the importance of the Church in his Empire, in particular the importance of monasticism and monasteries. The Church and its organs served as supporting and stabilizing factor in the Empire's structure. To fulfill these tasks, Otto II strengthened the legal integrity and economic independence of the bishops from the secular nobility. The Ottonians had particular religious interest in Memleben as both Otto II's father Otto I and grandfather Henry I had died there. Otto II and his wife Theophanu enhanced the spiritual importance of the city by establishing a Benedictine Imperial abbey there: the Memleben Abbey. Within a short time, the Memleben Abbey had become one of the richest and most influential of the Imperial abbeys. These measures and the unusual size of the abbey perhaps suggest that Memleben may have been intended as an Imperial Mausoleum for the Ottonians.
Following the suppression of Henry II's rebellion, Otto II used the Empire's monasteries as the location for the treason trials. While his father had founded only one monastery (Otto I later replaced the abbey with the Cathedral of Magdeburg) during his 37 years of reign. Otto II, however, established at least four monasteries: Memleben, Tegernsee, Bergen, and Arneburg. Monasticism became a key part of Otto II's Imperial policy, entrusting the Abbots with key political functions.
Otto II employed monks among his top political advisers, including Ekkehard I and Majolus of Cluny. One of the most important such monks was John Philagathus (the future Antipope John XVI). Of Greek descent, John was the personal chaplain of Otto II's wife Theophanu, accompanying her when she traveled from Constantinople to marry Otto II. Otto II appointed him as his Imperial Chancellor from 980 to 982, as well as the Abbot of the Nonantola Abbey. Following Otto II's death in 983, Theophanu, as her son Otto III's regent, would name John as Otto III's tutor. She would later appoint John as the bishop of Piacenza, and would send him to Constantinople to arrange for a marriage between Otto III and a Byzantine princess.
Southern expansion.
In regard to his Italian policy, Otto II went beyond the goals of his father. Not satisfied with the territorial gains made under Otto I, Otto II wanted more. His policy was based not only on securing his power in Rome, or to cooperate with the Papacy, but also to gain absolute dominion over the whole of Italy. Influenced by his wife, who was hostile to the return of the Macedonian Dynasty in the shape of Byzantine Emperor Basil II after the assassination of John I Tzimisces, Otto II was persuaded to annex the Byzantine controlled southern Italy. However, this policy necessarily meant war with not only the Byzantine Empire but the Muslim Fatimid Caliphate as well, who claimed southern Italy as within their sphere influence.
The Ottonians' chief lieutenant in central and southern Italy had long been the Lombard leader Pandulf Ironhead. Originally appointed by Otto I as Prince of Benevento and Capua in 961, Pandulf waged war against the Byzantines and expanded Ottonian control to include the Duchy of Spoleto in 967. Under Otto II, Pandulf added the Principality of Salerno in 978 to the Empire. His campaigns under Otto I and Otto II incorporated all three of the southern Lombard principalities - Benevento, Capua, and Salerno - into the Holy Roman Empire. As vassal of Otto II, Pandulf ruled a large bloc of territories that stretched as far north as Tuscany and as far south as the Gulf of Taranto.
Pandulf's death in 981 deprived Otto II of one of his primary lieutenants. Pandulf's lands were partitioned among his sons, though further quarrels between the local Lombard princes soon followed. Pandulf's older son Landulf IV received Capua and Benevento while his younger son Pandulf II received Salerno. Upon hearing of Pandulf's death, Otto II, ruling from Rome, traveled south to install Thrasimund IV as Duke of Spoleto. Then, Pandulf's nephew Pandulf II was given Benevento when Otto II partitioned Landulf IV's territory, with Landulf IV keeping Capua. Finally, Duke Manso I of Amalfi deposed Pandulf II of his rule in Salerno in 982.
By 982 the entire area once ruled by Pandulf had collapsed, weakening Otto II's position against the Byzantines. The Byzantines still claimed sovereignty over the Lombard principalities and the lack of singular leader to prevent their advances into Lombard territory allowed the Byzantines to make inroads further north. Otto II attempted on several occasions to reunify the Lombard principalities politically and ecclesiastically into his Empire after Pandulf's death. Though he unsuccessfully besieged Manso I in Salerno, Otto II ultimately obtained the recognition of his authority from all the Lombard principalities.
With his authority reestablished over the Lombard princes, Otto II turned his attention towards the threat from Muslim Sicily. Since 960s the island had been under Muslim rule as the Emirate of Sicily, a state of the Fatimid Caliphate. The ruling Kalbid dynasty had conducted raids against Imperial territories in southern Italy. The death of Pandulf in 981 allowed the Sicilian Emir Abu al-Qasim to increase his raids, hitting targets in Apulia and Calabria. As early as 980 Otto II demanded a fleet from the city of Pisa to help him carry out his war in southern Italy, and in September 981 he marched into southern Italy. Needing allies in his campaign against the Muslims and the Byzantine Empire, Otto II reconciled with Amalfian Duke Manso I, granting Imperial recognition of his rule over Salerno.
Otto II's troops marched on Byzantine-controlled Apulia in January 982 with the purpose of annexing the territory into his Empire. Otto II's march caused the Byzantine Empire to seek an alliance with Muslim Sicily in order to hold onto their southern Italian possessions. The Emperor's army besieged and captured the Byzantine city of Taranto, the administrative center of Apulia, in March 982. After celebrating Easter in Taranto, Otto II moved his army westward, defeating a Muslim army in early July. Emir Abu al-Qasim, who had declared a Holy War ("jihad") against the Empire, retreated when he noticed the unexpected strength of Otto II's troops when the Emperor was not far from Rossano Calabro. Informed of the Muslim retreat, Otto II left his wife Theophanu and young son Otto III (along with the Imperial treasury) in the city and marched his army to pursue the Muslim force.
Unable to flee back to his stronghold in Sicily due an Imperial naval blockade, al-Qasim faced the Imperial army in a pitched battle south of Crotone at Cape Colonna on July 14, 982. After a violent clash, a corps of Otto II's heavy cavalry destroyed the Muslim center and pushed towards al-Qasim's guards, with the Emir killed during the charge. Despite the Emir's death, the Muslim troops did not flee the battlefield. The Muslims regrouped and managed to surround the Imperial soldiers, slaughtering many of them and inflicting a severe defeat upon the Emperor. According to the historian Muslim Ibn al-Athir, Imperial casualties numbered around 4,000. The Lombard Princes Landulf IV of Benevento and Pandulf II of Salerno, German Bishop Henry I of Augsburg, German Margrave Gunther of Merseburg, the Abbot of Fulda, and numerous other Imperial officials were among the battle's casualties.
The Imperial defeat shocked the political makeup of Southern Italy. With two Lombard princes dead, the Principalities of Capua and the Benevento passed to younger branches of the Landulfid family. Though the Muslim troops were forced to retreat to Sicily after their victory, the Muslims remained a presence in southern Italy, harassing the Byzantines and Lombards. The Ottonian defeat, the worst in the history of the Empire at the time, greatly weakened Imperial power in southern Italy. The Byzantines joined forces with the Muslims and regained possession of Apulia from Ottonian forces.
Imperial crisis.
Succession issues.
The defeat at Stilo forced Otto II to flee north to Rome. He then held an Imperial Diet at Verona on Pentecost, 983. He sent his nephew Otto I, Duke of Swabia and Bavaria, back to Germany with the news of the defeat and to call the German nobles to the assembly, but he died "en route" on November 1, 982, in Lucca. News of the battle did cross the Alps, however, reaching as far as Wessex in Britain, signifying the magnitude of the defeat. Duke Bernard I of Saxony was heading south for the assembly when Danish Viking raids forced him to return to face the threat.
At the assembly, Otto II appointed Conrad (a distant relative of Otto II) and Henry III as the new Dukes of Swabia and Bavaria respectively. Henry III had previously been exiled by Otto II following his defeat as part of a two-year revolt against Otto II's rule. The defeat at Stilo cost the Empire many nobles, forcing Otto II to lift the banishment of Henry III in order to stabilize domestic affairs in Germany while he campaigned against the Muslim and Byzantines in southern Italy. Also, the appointment of Conrad I allowed the House of the Conradines to return to power in Swabia for the first time since Emperor Otto I in 948. Otto II and the assembled nobles agreed on a strategy of naval blockade and economic warfare until reinforcement from Germany could arrive. Otto II then prepared for a new campaign against the Muslims and obtained a settlement with the Republic of Venice, whose assistance he needed following the destruction of his army at Stilo. However, the death of Otto II the next year and the resulting civil war prevented the Empire from appropriately responding to the defeat.
The most important action taken by Otto II at the assembly, however, was to secure the "election" of his son Otto III, who was then only three years old, as King of Germany and heir apparent to the Imperial throne. Otto III thus became the only German king elected south of the Alps. The exact reason for this unusual procedure has been lost to history. It is possible that the conditions in southern Italy following the defeat required Otto II to act quickly in designating an Imperial heir to ensure connivance in the Empire's future. It is also conceivable, however, that holding the election in Italy was a deliberate choice on the part of Otto II in order to demonstrate that Italy was an equal part of the Empire on the same level as Germany. His election secured, Otto III and his mother, the Empress Theophanu, traveled north across the Alps heading for Aachen, the traditional coronation site for the Ottonians, in order for Otto III to be officially crowned as king. Otto II stayed in Italy to further address his military campaigns.
Great Slav uprising.
Around the year 982, Imperial authority in Slavic territory extended as far east as the Lusatian Neisse River and as far south as the Ore Mountains. Following the defeat of Otto II at Stilo in 983, the Lutici Federation of Polabian Slavs revolted against their German overlords, sparking a great revolt known as the Great Slav Rising ("Slawenaufstand"). The Polabian Slavs destroyed the bishoprics of Havelberg and Brandenburg. According to the German chronicler Bishop Thietmar of Merseburg, the decades-long, forced Germanization and Christianization of the Slavs associated with these two churches was the reason for their destruction. Thietmar blames the uprising on maltreatment of the Slavs by the Germans: "Warriors, who used to be our servants, now free as a consequence of our injustices." In the Obotrite territories along the Elbe River, the Luticians initiated a revolt aimed at the abolition of feudal rule and Christianity, drawing upon considerable support by the Obodrite populace and their leader Mstivoj. In part, the Obrodite revolt was successful: The princely family, though in part remaining Christian, dissolved Christian institutions.
Soldiers from the Northern March, the March of Meissen, the March of Lusatia, as well as from the Bishop of Halberstadt and the Archbishop of Magdeburg, joined forces to defeat the Slavs near Stendal. Nevertheless, the Empire was forced to withdraw to the western banks of the Elbe river. The successes of the Empire's Christianization policy towards the Slavs were nullified, and political control over the Billung March and the Northern March (territories east of the Elbe) was lost. In the decade since his death, Otto I's life work of converting the Slavs was undone. The Slavic territories east of the Elbe would remain pagan for over a century before further missionary work resumed: it would not be until the 12th century that the churches of Havelberg and Brandenburg would be reestablished.
The Danes took advantage of the Slavic revolt and invaded the March of Schleswig along the Empire's northern border while the Sorb Slavs invaded and conquered the March of Zeitz from Saxon control.
Sudden death and political turmoil.
In July 983, Pope Benedict VII, a longtime Ottonian supporter, died of natural causes after having reigned for almost ten years. Otto II returned to Rome in September to name a new Pope, selecting the Bishop of Pavia Pietro Canepanova (who reigned as Pope John XIV) in November or early December. While Otto II was in Rome overseeing the election of a new pope, a malaria outbreak in central Italy prevented the resumption of military activity in southern Italy. The outbreak ultimately led to the death of the Emperor himself: he died in his palace in Rome at the age of 28 on December 7, 983, after having reigned for just over a decade. Otto II's money and possessions were divided among the Catholic Church, the poor of the Empire, his mother Adelaide and sister Matilda, and those nobles loyal to him. Otto II was then buried in the atrium of St. Peter's Basilica, becoming the only German ruler to be buried in a foreign country instead of in Germany.
Otto II's three-year-old son Otto III was crowned as King of Germany in Aachen on Christmas Day in 983, three weeks after his father's death. Otto III was crowned by Willigis, the Archbishop of Mainz, and John, the Archbishop of Ravenna. News of Otto II's death first reached Germany after Otto III's coronation. The unresolved problems in southern Italy and the Slavic uprising on the Empire's eastern border made the Empire's political situation extremely unstable. The arrival of a minor on the Imperial throne threw the Empire into confusion, allowing Otto III's mother, the Byzantine Princess Theophanu, to reign as his regent.
In 976, Otto II had deposed Henry II as Duke of Bavaria and imprisoned him. In early 984, Henry II escaped from his imprisonment by the Bishop of Utrecht. Free from his confinement, he seized the infant Otto III and, as a member of the ruling Ottonian dynasty, claimed the regency of the Empire for himself. Henry II eventually went so far as to claim the German throne outright, obtaining the allegiance of Mieszko I of Poland and Boleslaus II, Duke of Bohemia. Henry II's claims were supported by Archbishop Egbert of Trier, Archbishop Gisilher of Magdeburg, and Bishop Dietrich I of Metz. Otto III's right to the throne, however, was supported by Archbishop Willigis of Mainz and the Dukes of Saxony, Bavaria, and Swabia. The threat of war from Willigis and Conrad I, Duke of Swabia forced Henry II to relinquish Otto III on June 29, 984 and to respect the regency of Theophanu.
The early death of Otto II and the ensuing events proved to be a serious test for Empire. Despite having a child under the regency of his mother as a ruler, the structure established by Emperor Otto the Great remained strong as most of the Empire's most powerful officials stayed loyal to the Imperial system.
Character.
Otto was a man of small stature, by nature brave and impulsive, and by training an accomplished knight. He was generous to the church and aided the spread of Christianity in many ways. According to one of the chroniclers of the time, he was given the epithet of the "Red" when in 981 he invited the most troublesome of the Roman families to a banquet, and proceeded to butcher them at dinner. More sympathetic chroniclers said that it was due to his reddish complexion.
Family and children.
Otto II was a member of the Ottonian dynasty of rulers of Germany (and later the Holy Roman Empire) from 919 to 1024. In relation to the other members of his dynasty, Otto II was the grandson of Henry I, son of Otto I, father of Otto III, and a first-cousin once removed to Henry II.
Otto II had only one known wife. On April 14, 972, Otto II married Theophanu, a Byzantine princess of the Phokas family who was the cousin of reigning Byzantine Emperor John I Tzimiskes. The two had at least five children:

</doc>
<doc id="40604" url="https://en.wikipedia.org/wiki?curid=40604" title="Caprera">
Caprera

Caprera is a small island off the coast of Sardinia, Italy, located in the Maddalena archipelago.
In the area of La Maddalena island in the Strait of Bonifacio, it is a tourist destination and is famous as the place to which Giuseppe Garibaldi retired from 1854 until his death in 1882.
This island has been declared a natural reserve for the particular species of seabirds living on it (royal seagull, cormorant and peregrine falcon). The island's name is linked to that of Giuseppe Garibaldi, an Italian patriot and fighter who lived in the 19th century and was one of the fathers of the Italian independence. He bought the island in 1855 and died there in 1882. His house is now a museum and a memorial chapel and the island itself is a national monument. Caprera is linked to La Maddalena island by a 600 metre long causeway.
The island was probably given its name because of the numerous wild goats living on it ("capra" means "goat" in Italian).
It is the second largest island in the archipelago and has a surface of and of coastline. Monte Tejalone is the highest point (212 m). On the south-western side there is a very important sailing centre and the many coves and anchorages which can be found along the coastline make the landing easy.
Many remains of Roman cargo ships as well as of the boat of Garibaldi were found there. After the Roman occupation, Caprera remained deserted for centuries before being inhabited by groups of shepherds. Later in 1855 Garibaldi decided to settle there and planted the first trees of the blooming pinewood which covers the island today. A century after Garibaldi's death the island was freed from the numerous existing military restrictions and is now completely open to the public.
Sailing.
Caprera's Porto Palma gulf is home to the Centro Velico Caprera school since 1967.

</doc>
<doc id="40606" url="https://en.wikipedia.org/wiki?curid=40606" title="Sviatoslav I of Kiev">
Sviatoslav I of Kiev

His decade-long reign over the Kievan Rus' was marked by rapid expansion into the Volga River valley, the Pontic steppe, and the Balkans. By the end of his short life, Sviatoslav carved out for himself the largest state in Europe, eventually moving his capital in 969 from Kiev (modern-day Ukraine) to Pereyaslavets (identified as the modern village of Nufăru, Romania) on the Danube. In contrast with his mother's conversion to Christianity, Sviatoslav remained a staunch pagan all of his life. Due to his abrupt death in ambush, his conquests, for the most part, were not consolidated into a functioning empire, while his failure to establish a stable succession led to a fratricidal feud among his sons, resulting in two of his three sons being killed.
Name.
Sviatoslav is the first ruler of the Kievan Rus' recorded in the Primary Chronicle with a name of Slavic origin (as opposed to his predecessors, whose names derived from Old Norse). This name, however, is not recorded in other medieval Slavic countries. Nevertheless, Sveinald is the Old East Norse cognate with the Slavic form as attested in the patronymic Old East Norse name of Vladimir: Valdamarr Sveinaldsson. This patronymic naming convention, continues namely in Icelandic and in East Slavic languages. Even in Rus', it was attested only among the members of the house of Rurik, as were the names of Sviatoslav's immediate successors: Vladimir, Yaroslav, and Mstislav. This is questionable, however, as these names follow conventions well established in other Slavic lands, and it ignores Vladimir of Bulgaria, who ruled between 889-893. Some scholars speculate that the name of Sviatoslav, composed of the Slavic roots for "holy" and "glory", was an artificial derivation combining those of his predecessors Oleg and Rurik (they mean "holy" and "glorious" in Old Norse, respectively). On the other hand, such a compound structure name was already known from Great Moravia, as in the rulers named Svatopluk. Clearly Sviatoslav's name belongs to this tradition, as he had a son by the name of Yaropolk, of much the same form, and a grandson by the same name, Sviatopolk.
Early life and personality.
Virtually nothing is known about Sviatoslav's childhood and youth, which he spent reigning in Novgorod. Sviatoslav's father, Igor, was killed by the Drevlians around 945, and his mother, Olga, ruled as regent in Kiev until Sviatoslav reached maturity (ca. 963). Sviatoslav was tutored by a Varangian named Asmud. The tradition of employing Varangian tutors for the sons of ruling princes survived well into the 11th century. Sviatoslav appears to have had little patience for administration. His life was spent with his "druzhina" (roughly, "company") in permanent warfare against neighboring states. According to the Primary Chronicle, he carried on his expeditions neither wagons nor kettles, and he boiled no meat, rather cutting off small strips of horseflesh, game, or beef to eat after roasting it on the coals. Nor did he have a tent, rather spreading out a horse-blanket under him and setting his saddle under his head, and all his retinue did likewise.
Sviatoslav's appearance has been described very clearly by Leo the Deacon, who himself attended the meeting of Sviatoslav with John I Tzimiskes. Following Deacon's memories, Sviatoslav was a blue-eyed male of average height but of stalwart build, much more sturdy than Tzimiskes. He shaved his blond head and his beard but wore a bushy mustache and a sidelock as a sign of his nobility. He preferred to dress in white, and it was noted that his garments were much cleaner than those of his men, although he had a lot in common with his warriors. He wore a single large gold earring bearing a carbuncle and two pearls.
Religious beliefs.
Sviatoslav's mother, Olga, converted to Eastern Orthodox Christianity at the court of Byzantine Emperor Constantine Porphyrogenitus in 957. However, Sviatoslav remained a pagan all of his life. In the treaty of 971 between Sviatoslav and the Byzantine emperor John I Tzimiskes, the Rus' are swearing by Perun and Veles. According to the Primary Chronicle, he believed that his warriors (druzhina) would lose respect for him and mock him if he became a Christian. The allegiance of his warriors was of paramount importance in his conquest of an empire that stretched from the Volga to the Danube.
Family.
Very little is known of Sviatoslav's family life. It is possible that he was not the only (or the eldest) son of his parents. The Russo-Byzantine treaty of 945 mentions a certain Predslava, Volodislav's wife, as the noblest of the Rus' women after Olga. The fact that Predslava was Oleg's mother is presented by Vasily Tatishchev. He also speculated that Predslava was of a Hungarian nobility. George Vernadsky was among many historians to speculate that Volodislav was Igor's eldest son and heir who died at some point during Olga's regency. Another chronicle told that Oleg (? - 944?) was the eldest son of Igor. At the time of Igor's death, Sviatoslav was still a child, and he was raised by his mother or under her instructions. Her influence, however, did not extend to his religious observance.
Sviatoslav had several children, but the origin of his wives is not specified in the chronicle. By his wives, he had Yaropolk and Oleg. By Malusha, a woman of indeterminate origins, Sviatoslav had Vladimir, who would ultimately break with his father's paganism and convert Rus' to Christianity. John Skylitzes reported that Vladimir had a brother named Sfengus; whether this Sfengus was a son of Sviatoslav, a son of Malusha by a prior or subsequent husband, or an unrelated Rus' nobleman is unclear.
Eastern campaigns.
Shortly after his accession to the throne, Sviatoslav began campaigning to expand Rus' control over the Volga valley and the Pontic steppe region. His greatest success was the conquest of Khazaria, which for centuries had been one of the strongest states of Eastern Europe. The sources are not clear about the roots of the conflict between Khazaria and Rus', so several possibilities have been suggested. The Rus' had an interest in removing the Khazar hold on the Volga trade route because the Khazars collected duties from the goods transported by the Volga. Historians have suggested that the Byzantine Empire may have incited the Rus' against the Khazars, who fell out with the Byzantines after the persecutions of the Jews in the reign of Romanus I Lecapenus.
Sviatoslav began by rallying the East Slavic vassal tribes of the Khazars to his cause. Those who would not join him, such as the Vyatichs, were attacked and forced to pay tribute to the Kievan Rus' rather than to the Khazars. According to a legend recorded in the Primary Chronicle, Sviatoslav sent a message to the Vyatich rulers, consisting of a single phrase: "I want to come at you!" (Old East Slavic: "хощю на вы ити") This phrase is used in modern Russian (usually misquoted as "Иду на вы") and in modern Ukrainian ("Іду на ви") to denote an unequivocal declaration of one's intentions. Proceeding by the Oka and Volga rivers, he attacked Volga Bulgaria. He employed Oghuz and Pecheneg mercenaries in this campaign, perhaps to counter the superior cavalry of the Khazars and Bulgars.
Sviatoslav destroyed the Khazar city of Sarkel around 965, possibly sacking (but not occupying) the Khazar city of Kerch on the Crimea as well. At Sarkel he established a Rus' settlement called Belaya Vyezha ("the white tower" or "the white fortress", the East Slavic translation for "Sarkel"). He subsequently destroyed the Khazar capital of Atil. A visitor to Atil wrote soon after Sviatoslav's campaign: "The Rus' attacked, and no grape or raisin remained, not a leaf on a branch." The exact chronology of his Khazar campaign is uncertain and disputed; for example, Mikhail Artamonov and David Christian proposed that the sack of Sarkel came after the destruction of Atil.
Although Ibn Haukal reports the sack of Samandar by Sviatoslav, the Rus' leader did not bother to occupy the Khazar heartlands north of the Caucasus Mountains permanently. On his way back to Kiev, Sviatoslav chose to strike against the Ossetians and force them into subservience. Therefore, Khazar successor statelets continued their precarious existence in the region. The destruction of Khazar imperial power paved the way for Kievan Rus' to dominate north-south trade routes through the steppe and across the Black Sea, routes that formerly had been a major source of revenue for the Khazars. Moreover, Sviatoslav's campaigns led to increased Slavic settlement in the region of the Saltovo-Mayaki culture, greatly changing the demographics and culture of the transitional area between the forest and the steppe.
Campaigns in the Balkans.
The annihilation of Khazaria was undertaken against the background of the Rus'-Byzantine alliance, concluded in the wake of Igor's Byzantine campaign in 944. Close military ties between the Rus' and Byzantium are illustrated by the fact, reported by John Skylitzes, that a Rus' detachment accompanied Byzantine Emperor Nikephoros Phokas in his victorious naval expedition to Crete.
In 967 or 968, Nikephoros sent to Sviatoslav his agent, Kalokyros, with the task of talking Sviatoslav into assisting him in a war against Bulgaria. Sviatoslav was paid 15,000 pounds of gold and set sail with an army of 60,000 men, including thousands of Pecheneg mercenaries.
Sviatoslav defeated the Bulgarian ruler Boris II and proceeded to occupy the whole of northern Bulgaria. Meanwhile, the Byzantines bribed the Pechenegs to attack and besiege Kiev, where Olga stayed with Sviatoslav's son Vladimir. The siege was relieved by the "druzhina" of Pretich, and immediately following the Pecheneg retreat, Olga sent a reproachful letter to Sviatoslav. He promptly returned and defeated the Pechenegs, who continued to threaten Kiev.
Sviatoslav refused to turn his Balkan conquests over to the Byzantines, and the parties fell out as a result. To the chagrin of his boyars and his mother (who died within three days after learning about his decision), Sviatoslav decided to move his capital to Pereyaslavets in the mouth of the Danube due to the great potential of that location as a commercial hub. In the Primary Chronicle record for 969, Sviatoslav explains that it is to Pereyaslavets, the centre of his lands, "all the riches flow: gold, silks, wine, and various fruits from Greece, silver and horses from Hungary and Bohemia, and from Rus' furs, wax, honey, and slaves".
In summer 969, Sviatoslav left Rus' again, dividing his dominion into three parts, each under a nominal rule of one of his sons. At the head of an army that included Pecheneg and Magyar auxiliary troops, he invaded Bulgaria again, devastating Thrace, capturing the city of Philippopolis, and massacring its inhabitants. Nikephoros responded by repairing the defenses of Constantinople and raising new squadrons of armored cavalry. In the midst of his preparations, Nikephoros was overthrown and killed by John Tzimiskes, who thus became the new Byzantine emperor.
John Tzimiskes first attempted to persuade Sviatoslav into leaving Bulgaria, but he was unsuccessful. Challenging the Byzantine authority, Sviatoslav crossed the Danube and laid siege to Adrianople, causing panic on the streets of Constantinople in summer 970. Later that year, the Byzantines launched a counteroffensive. Being occupied with suppressing a revolt of Bardas Phokas in Asia Minor, John Tzimiskes sent his commander-in-chief, Bardas Skleros, who defeated the coalition of Rus', Pechenegs, Magyars, and Bulgarians in the Battle of Arcadiopolis. Meanwhile, John, having quelled the revolt of Bardas Phokas, came to the Balkans with a large army and promoting himself as the liberator of Bulgaria from Sviatoslav, penetrated the impracticable mountain passes and shortly thereafter captured Marcianopolis, where the Rus' were holding a number of Bulgar princes hostage.
Sviatoslav retreated to Dorostolon, which the Byzantine armies besieged for sixty-five days. Cut off and surrounded, Sviatoslav came to terms with John and agreed to abandon the Balkans, renounce his claims to the southern Crimea, and return west of the Dnieper River. In return, the Byzantine emperor supplied the Rus' with food and safe passage home. Sviatoslav and his men set sail and landed on Berezan Island at the mouth of the Dnieper, where they made camp for the winter. Several months later, their camp was devastated by famine, so that even a horse's head could not be bought for less than a half-grivna, reports the Kievan chronicler of the Primary Chronicle. While Sviatoslav's campaign brought no tangible results for the Rus', it weakened the Bulgarian statehood and left it vulnerable to the attacks of Basil the Bulgar-Slayer four decades later.
Death and aftermath.
Fearing that the peace with Sviatoslav would not endure, the Byzantine emperor induced the Pecheneg khan Kurya to kill Sviatoslav before he reached Kiev. This was in line with the policy outlined by Constantine VII Porphyrogenitus in "De Administrando Imperio" of fomenting strife between the Rus' and the Pechenegs. According to the Slavic chronicle, Sveneld attempted to warn Sviatoslav to avoid the Dnieper rapids, but the prince slighted his wise advice and was ambushed and slain by the Pechenegs when he tried to cross the cataracts near Khortitsa early in 972. The Primary Chronicle reports that his skull was made into a chalice by the Pecheneg khan.
Following Sviatoslav's death, tensions between his sons grew. A war broke out between his legitimate sons, Oleg and Yaropolk, in 976, at the conclusion of which Oleg was killed. In 977 Vladimir fled Novgorod to escape Oleg's fate and went to Scandinavia, where he raised an army of Varangians and returned in 980. Yaropolk was killed, and Vladimir became the sole ruler of Kievan Rus'.
Art and literature.
Sviatoslav has long been a hero of Belarusian, Russian, and Ukrainian patriots due to his great military successes. His figure first attracted attention of Russian artists and poets during the Russo-Turkish War (1768–1774), which provided obvious parallels with Sviatoslav's push towards Constantinople. Russia's southward expansion and the imperialistic ventures of Catherine II in the Balkans seemed to have been legitimized by Sviatoslav's campaigns eight centuries earlier.
Among the works created during the war was Yakov Knyazhnin's tragedy "Olga" (1772). The Russian playwright chose to introduce Sviatoslav as his protagonist, although his active participation in the events following Igor's death is out of sync with the traditional chronology. Knyazhnin's rival Nikolai Nikolev (1758–1815) also wrote a play on the subject of Sviatoslav's life. Ivan Akimov's painting "Sviatoslav's Return from the Danube to Kiev" (1773) explores the conflict between military honour and family attachment. It is a vivid example of Poussinesque rendering of early medieval subject matter.
Interest in Sviatoslav's career increased in the 19th century. Klavdiy Lebedev depicted an episode of Sviatoslav's meeting with Emperor John in his well-known painting, while Eugene Lanceray sculpted an equestrian statue of Sviatoslav in the early 20th century. Sviatoslav appears in the 1913 poem of Velimir Khlebnikov "Written before the war" (#70. Написанное до войны) as an epitome of militant Slavdom:
Sviatoslav is the villain of the novel "The Lost Kingdom, or the Passing of the Khazars", by Samuel Gordon, a fictionalized account of the destruction of Khazaria by the Rus'. The Slavic warrior figures in a more positive context in the story "Chernye Strely Vyaticha" by Vadim Viktorovich Kargalov; the story is included in his book "Istoricheskie povesti".
In 2005, reports circulated that a village in the Belgorod region had erected a monument to Sviatoslav's victory over the Khazars by the Russian sculptor Vyacheslav Klykov. The reports described the 13-meter tall statue as depicting a Rus' cavalryman trampling a supine Khazar bearing a Star of David and Kolovrat. This created an outcry within the Jewish community of Russia. The controversy was further exacerbated by Klykov's connections with Pamyat and other anti-Semitic organizations, as well as by his involvement in the "letter of 500", a controversial appeal to the Prosecutor General to review all Jewish organizations in Russia for extremism. The Press Center of the Belgorod Regional Administration responded by stating that a planned monument to Sviatoslav had not yet been constructed but would show "respect towards representatives of all nationalities and religions." When the statue was unveiled, the shield bore a twelve-pointed star.
Svyatoslav is the main character of the books "Knyaz" ("Князь") and "The Hero" ("Герой"), written by Russian writer Alexander Mazin.
On 7 November 2011 Ukrainian fisherman Sergei Pjankow fished up a one metre long frankish sword from the waters of the Dnieper not far from the spot where Svyatoslav is believed to have been killed in 972. The handle is made out of four different metals including gold and silver, and it is very possible that it belonged to Sviatoslav himself.

</doc>
<doc id="40608" url="https://en.wikipedia.org/wiki?curid=40608" title="William Jennings Bryan">
William Jennings Bryan

William Jennings Bryan (March 19, 1860 – July 26, 1925) was an American orator and politician from Nebraska, and a dominant force in the populist wing of the Democratic Party, standing three times as the Party's candidate for President of the United States (1896, 1900 and 1908). He served two terms as a member of the United States House of Representatives from Nebraska and was United States Secretary of State under President Woodrow Wilson (1913–1915). He resigned because of his pacifist position on World War I. Bryan was a devout Presbyterian, a strong advocate of popular democracy, and an enemy of the banks and the gold standard. He demanded "Free Silver" because he believed it undermined the evil "Money Power" and put more cash in the hands of the common people. He was a peace advocate, a supporter of Prohibition, and an opponent of Darwinism on religious and humanitarian grounds. With his deep, commanding voice and wide travels, he was perhaps the best-known orator and lecturer of the era. Because of his faith in the wisdom of the common people, he was called "The Great Commoner."
In the intensely fought 1896 and 1900 elections, he was defeated by William McKinley but retained control of the Democratic Party. With over 500 speeches in 1896, Bryan invented the national stumping tour in an era when other presidential candidates stayed home. In his three presidential bids, he promoted Free Silver in 1896, anti-imperialism in 1900, and trust-busting in 1908, calling on Democrats to fight the trusts (big corporations) and big banks, and embrace anti-elitist ideals of republicanism. President Wilson appointed him Secretary of State in 1913. After the "Lusitania" was torpedoed in 1915, Wilson made strong demands on Germany that Bryan disagreed with, resigning in protest as a pacifist. After 1920 he supported Prohibition and attacked Darwinism and evolution, most famously at the Scopes Trial in 1925 in Tennessee. Five days after the conclusion of the Scopes case, Bryan died in his sleep.
Background and early career: 1860–1896.
William Jennings Bryan was born in Salem, Illinois on March 19, 1860, to Silas Lillard Bryan and Mariah Elizabeth (Jennings) Bryan. Bryan's mother was of English heritage. Mary Bryan joined the Salem Baptists in 1872, so Bryan attended Methodist services on Sunday morning with his father, and in the afternoon, Baptist services with his mother. At this point, William began spending his Sunday afternoons at the Cumberland Presbyterian Church. At age 14, Bryan attended a revival, was baptized, and joined the Cumberland Presbyterian Church. In later life, Bryan said the day of his baptism was the most important day in his life, but at the time it caused little change in his daily routine. He later left the Cumberland Presbyterian Church and joined the larger Presbyterian Church in the United States of America.
His father, Silas Bryan, of Scots-Irish and English ancestry, was an avid Jacksonian Democrat. Silas won election to the Illinois State Senate, but was defeated for re-election in 1860. He won election as a state circuit judge, and in 1866 moved his family to a farm north of Salem, living in a ten-room house that was the envy of Marion County.
Until age ten, Bryan was home-schooled, as many children were. The Bible and McGuffey Readers shaped his views that gambling and liquor were evil and sinful. To attend Whipple Academy, which was attached to Illinois College, Bryan was sent to Jacksonville, Illinois in 1874.
Following high school, he entered Illinois College, graduating as valedictorian in 1881. During his time at Illinois College, Bryan was a member of the Sigma Pi literary society. He studied law at Union Law College in Chicago (which later became Northwestern University School of Law). While preparing for the bar exam, he taught high school and met Mary Elizabeth Baird, a cousin of William Sherman Jennings; the latter was also his own first-cousin. Bryan and Mary Elizabeth Baird married on October 1, 1884, and they settled in Jacksonville, which at the time had a population of two thousand.
Mary also became a lawyer, and collaborated with Bryan on all his speeches and writings. He practiced law in Jacksonville from 1883 to 1887, then moved to the boom city of Lincoln, Nebraska. In Lincoln, Bryan met James Dahlman and they became lifelong friends. As chairman of the Nebraska Democratic Party, Dahlman would help carry Nebraska for Bryan in two presidential campaigns. Even when Dahlman became closely associated with Omaha's vice elements, including the breweries, as the city's eight-term mayor, he and Bryan maintained a collegial relationship.
In the Democratic landslide of 1890, Bryan was elected to the U.S. House of Representatives from Nebraska's First Congressional District. The growing prohibitionist movement had entered the election of 1890 with its own slate of candidates. In the three-way race in the First Congressional District, Bryan received 6,713 more votes than his nearest opponent. This was a plurality of the vote and was 8,000 votes short of a majority. Bryan was elected, only the second Democrat to be elected to Congress in the history of Nebraska. In 1892, Bryan was re-elected by a 140-vote majority in a two-person race. He ran for the Senate in 1894, but a Republican landslide led to the state Legislature's choice of a Republican for the Senate seat. (At that time, state legislatures elected their representatives to the US Senate.)
First campaign for the White House: 1896.
Bryan had an innate talent in oratory. He gave speeches, organized meetings, and adopted resounding resolutions that eventually culminated in the founding of the American Bimetallic League, which then evolved into the National Bimetallic Union, and finally the National Silver Committee. At the time many farmers' groups believed that by increasing the amount of currency in circulation, commodities would receive higher prices. They were opposed by banks and bond holders who feared the effects of inflation. The ultimate goal of the league was to garner support on a national level for the reinstatement of the coinage of silver. With others, Bryan ensured that the Democratic platform reflected the now strengthening spirit of Midwestern populism.
With his support, Charles H. Jones of the "St. Louis Post-Dispatch" was put on the platform committee and Bryan's "sixteen-to-one" plank for free silver was adopted and silently added to the platform for the 1896 Democratic National Convention in Chicago, in order to avoid controversy. As a minority member of the resolutions committee, Bryan was able to push the Democratic Party from its laissez-faire and small-government roots toward its modern, liberal character. Through these measures, the public and influential Democrats became convinced of his capacity to lead and bring change, resulting in his being mentioned as a possible chairman for the Chicago convention.
In 1893, the repeal of the Sherman Silver Purchase Act had resulted in the collapse of the silver market. Bryan delivered speeches across the country for free silver from 1894 to 1896, building a grass-roots reputation as a powerful champion of the cause.
At the 1896 Democratic National Convention, Bryan lambasted Eastern moneyed classes for supporting the gold standard at the expense of the average worker. His "Cross of Gold" speech, delivered on July 9, 1896, instantly made him the sensational new face in the Democratic Party. That same year he became the first presidential candidate to campaign in a car (a donated Mueller) in Decatur, Illinois.
The Bourbon Democrats who supported incumbent Democratic President Grover Cleveland were defeated, and the party's agrarian and silver factions voted for Bryan, giving him the nomination of the Democratic Party. At the age of 36, Bryan became (and still remains) the youngest presidential nominee of a major party in American history.
Disappointed with the direction of their party, Gold Democrats invited Cleveland to run as a third-party candidate, but he declined. Cleveland did, however, support John M. Palmer, nominee of the Gold Democrats, rather than Bryan.
Bryan also formally received the nominations of the Populist Party and the Silver Republican Party. With the three nominations, voters from any party could vote for Bryan without crossing party lines. In 1896, the Populists rejected Bryan's Democratic running mate, Maine banker Arthur Sewall, and named as his running mate Georgia Populist Thomas E. Watson. People could vote for Bryan and Sewall (on the Democratic or Silver Republican lines), or for Bryan and Watson (on the People's Party line).
The Republicans nominated William McKinley on a platform calling for prosperity for everyone through industrial growth, high tariffs, and "sound money" (gold). Republicans ridiculed Bryan as a Populist. However, "Bryan's reform program was not based on the Populists--for example, the Populists Free Silver took Free Silver from Bryan's Democrats, not vice versa--but he used the same crusading rhetoric against railroads, banks, insurance companies and businesses that has often been mistaken for Populism. Bryan remained a staunch Democrat throughout his career." The popular political economist and social reformer Henry George influenced Bryan's thinking and campaigned on his behalf.
Bryan demanded Bimetallism and "Free Silver" at a ratio of 16:1. Most leading Democratic newspapers rejected his candidacy. Despite this rejection by the newspapers, Bryan won the Democratic vote.
Republicans discovered in August that Bryan was solidly ahead in the South and West, but far behind in the Northeast. He appeared to be ahead in the Midwest, so the Republicans concentrated their efforts there. They said Bryan was a madman, a religious fanatic surrounded by anarchists, who would wreck the economy. By late September, the Republicans felt they were ahead in the decisive Midwest and began emphasizing that McKinley would bring prosperity to all Americans. McKinley scored solid gains among the middle classes, factory and railroad workers, prosperous farmers, and the German Americans who rejected free silver. Bryan gave 500 speeches in 27 states. McKinley won by a margin of 271 to 176 in the electoral college, but the popular vote was much closer and in some key states, McKinley's margin of victory was narrow.
War and peace: 1898–1900.
With the outbreak of the Spanish–American War in 1898, Bryan was forced to consider his party's stance on foreign policy. On one hand, Bryan was critical of militarism. Yet Spain's suppression of Cuban and Filipino self-government movements went against his view of his country's “Global Mission.” He envisioned the United States spreading democracy to the rest of the world. With this idealism in mind, Bryan enthusiastically supported President McKinley's declaration of war against Spain. According to historian William Leuchtenburg, "few political figures exceeded the enthusiasm of William Jennings Bryan for the Spanish war."
Bryan argued that "universal peace cannot come until justice is enthroned throughout the world. Until the right has triumphed in every land and love reigns in every heart, government must, as a last resort, appeal to force." He volunteered for duty and became colonel of a Nebraska militia regiment. He contracted typhoid fever in Florida and stayed there to recuperate, never seeing combat.
Bryan surprised many of his fellow party members by supporting the ratification of the Treaty of Paris, which resulted from the United States' defeat of Spain. The treaty granted the United States control of Puerto Rico, Guam, Cuba, the Philippines, and parts of the West Indies. Many of Bryan's supporters were opposed to what they perceived as Republican aspirations of turning the country into an imperial power and criticized Bryan for hypocritically supporting the ratification of the treaty. Bryan justified supporting the treaty by arguing that the issue of imperialism should be decided upon by the American people at the ballot boxes and not in Congress. However, when the Bacon Resolution (a proposed supplement to the Treaty of Paris which would allow the Filipinos a “stable and independent government") failed to pass, Bryan began publicly speaking out against the Republicans's imperial aspirations.
Bryan gave a speech at the Democratic National Convention in 1900 simply titled "Imperialism." In this speech he discusses his views against the annexation of the Philippines, questioning the United States' right to overpower people of another country just to gain a military base. He mentions, at the beginning of the speech, that the United States should not try to emulate the imperialism of Great Britain and other European countries, who were in this period extending their power in Asia and Africa.
Presidential election of 1900.
In 1900 Bryan ran as an anti-imperialist, finding himself in alliance with industrialist Andrew Carnegie, as well as others who had fought against silver. Republicans mocked Bryan as indecisive, or a coward, a point which L. Frank Baum satirized viciously in the Bryan-like Cowardly Lion in "The Wonderful Wizard of Oz", his novel published in the spring of 1900.
Bryan combined anti-imperialism with free silver, saying:
"The nation is of age and it can do what it pleases; it can spurn the traditions of the past; it can repudiate the principles upon which the nation rests; it can employ force instead of reason; it can substitute might for right; it can conquer weaker people; it can exploit their lands, appropriate their property and kill their people; but it cannot repeal the moral law or escape the punishment decreed for the violation of human rights."
In a typical day he gave four hour-long speeches and shorter talks that added up to six hours of speaking. At an average rate of 175 words a minute, he turned out 63,000 words a day, enough to fill 52 columns of a newspaper. In Wisconsin, he once made 12 speeches in 15 hours.
Despite Bryan's tremendous energy, McKinley and the Republicans were too strong to defeat. The GOP invested ten times as much money into the campaign as did Bryan's Democratic Party. While Bryan declared “Imperialism to be the paramount issue,” he had difficulty differentiating his platform from that of the Republican party. While he argued for the US to take on the role of a protectorate to the Philippines, the Republicans argued that annexation of the Philippines would eventually lead to independence. With the issue of imperialism being defined in these vaguely similar terms, the Republicans' “full pale” platform of a strong American industrial economy proved to be more important to voters than questions of the morality of annexing the Philippines. Bryan held his base in the South, a one-party Democratic region where virtually only white men voted, since the effective disenfranchisement of most blacks at the turn of the century, but lost part of the West; McKinley retained the populous Northeast and Midwest and rolled up a comfortable margin of victory. McKinley won the electoral college with a count of 292 votes compared to Bryan's 155. Bryan's hold on his party was weakened, while his erstwhile allies the Populists had virtually disappeared from the arena.
Presidential election of 1908.
The 1908 election was Bryan’s third attempt to gain the presidency. The Democrats nominated Bryan by a wide margin at the Democratic convention held in Denver and decided on John Kern, a politician from Indiana, as his running mate. Bryan ran against the Republicans and Theodore Roosevelt’s hand-picked nominee William Howard Taft.
Bryan launched a special message to Congress, suggesting income and inheritance taxes, publicity on campaign contributions, and opposing the use of the navy for the collection of private debts. He campaigned against corporate domination, urging that all corporation contributions be made public before election day, and that failure to cooperate be made a penal offense.
The GOP ran its campaign on the benefits of the Roosevelt administration, creation of a postal service, continuation of "Sound Currency", citizenship for Puerto Rico inhabitants, regulation of big business, and tariff revision in protectionist mode.
Bryan and the Democrats’ platform denounced the wrongs done by the Republican party: Congress spent too much money; Roosevelt hand picked Taft in undemocratic fashion; Republicans wanted centralization; Republicans favored monopolies. In response, Bryan publicized the slogan, "Shall the People Rule?" In a time of peace and prosperity, and Republican trust-busting, Bryan fared poorly among the voters. He lost the electoral college 321 to 162, his worst defeat yet, and did not carry any of the states in the Northeast.
In his three presidential election bids, Bryan received a total of 493 electoral votes - the most of any candidate in American history who never won the presidency.
Chautauqua circuit: 1900–1912.
Following his defeat in the election of 1900, Bryan needed money, and his powerful voice and 100% name recognition were assets that could be capitalized. For the next 25 years, Bryan was the most popular speaker on the Chautauqua circuit, delivering thousands of paid speeches on current events in hundreds of towns and cities across the country, even while serving as Secretary of State. He usually charged $500 per speech in addition to a percentage of the profits. He mostly spoke about Christianity, but covered a wide variety of topics. His most popular lecture (and his personal favorite) was a lecture entitled "The Prince of Peace", which stressed that Christian theology was the solid foundation of morality, and individual and group morality was the foundation for peace and equality. Another famous lecture from this period, "The Value of an Ideal", was a stirring call to public service.
In a 1905 speech, Bryan warned that "the Darwinian theory represents man reaching his present perfection by the operation of the law of hate, the merciless law by which the strong crowd out and kill off the weak. If this is the law of our development then, if there is any logic that can bind the human mind, we shall turn backward to the beast in proportion as we substitute the law of love. I choose to believe that love rather than hatred is the law of development."
Bryan threw himself into the work of the Social Gospel. He served in organizations with numerous theological liberals—he sat on the temperance committee of the Federal Council of Churches, and on the general committee of the short-lived Inter-church World Movement.
In 1899 Bryan founded a weekly magazine, "The Commoner", calling on Democrats to dissolve the trusts, regulate the railroads more tightly, and support the Progressive Movement. He regarded prohibition as a "local" issue and did not endorse a constitutional amendment until 1910. In London in 1906, he presented a plan to the Inter-Parliamentary Peace Conference for arbitration of disputes that he hoped would avert warfare. He tentatively called for nationalization of the railroads, then backtracked and called only for more regulation. His party nominated Bourbon Democrat Alton B. Parker in 1904, who lost to Roosevelt. For two years following this defeat, Bryan would pursue his public speaking ventures on an international stage. From 1904 to 1906, Bryan traveled globally, preaching, sightseeing with his wife Mary, lecturing, and all while escaping the political upheaval in Washington. Bryan crusaded as well for legislation to support introduction of the initiative and referendum as a means of giving voters a direct voice, making a whistle-stop campaign tour of Arkansas in 1910. Bryan's speech to the students of Washington and Lee University began the Washington and Lee Mock Convention.
Bryan owned land in Nebraska and a ranch in Texas; he paid for both with his strong earnings from speeches and "The Commoner."
Secretary of State: 1913–1915.
For supporting Woodrow Wilson for the presidency in 1912, Bryan was appointed Secretary of State, the top cabinet position. For all his enormous influence in the Democratic Party, his two years as Secretary of State was the only time he served in a powerful office. Historian Richard Hofstadter comments:
Wilson took his measure and only nominally consulted him, making all the major foreign policy decisions from the White House. In the civil war in Mexico in 1914, Bryan supported American military intervention.
Bryan kept busy in 1913-1915, negotiating 28 treaties that promised arbitration of disputes before war broke out between the signatory countries and the United States. He made several attempts to negotiate a treaty with Germany, but ultimately could not succeed. The agreements, known officially as "Treaties for the Advancement of Peace," set up procedures for conciliation rather than for arbitration. In September 1914 Bryan wrote President Wilson urging mediation in the World War that had just begun in Europe, with the U.S. as the largest neutral:
Bryan tried to yoke the American credit to the Entente, saying "money is the worst of all contrabands because it commands everything else," but eventually yielded. He also pointed out that by traveling on British vessels, which were at risk of attack, "an American citizen can, by putting his own business above his regard for this country, assume for his own advantage unnecessary risks and thus involve his country in international complications" Wilson's demands from Germany for "strict accountability for any infringement of rights, intentional or incidental" after the sinking of the "Lusitania" troubled Bryan, who counseled an “evenhanded policy.” Bryan resigned in June 1915, protesting “… why be so shocked by the drowning of a few people, if there is to be no objection to starving a nation.”
Despite their differences, Bryan campaigned as a private citizen for Wilson's reelection in 1916. When war was declared in April 1917, Bryan wrote Wilson, "Believing it to be the duty of the citizen to bear his part of the burden of war and his share of the peril, I hereby tender my services to the Government. Please enroll me as a private whenever I am needed and assign me to any work that I can do." Wilson, however, did not allow the 57-year-old Bryan to rejoin the military, and did not offer him any wartime role.
Prohibition battles: 1916–1925.
Bryan campaigned for the Constitutional amendments on prohibition and women's suffrage. Partly to avoid Nebraska ethnics such as the German Americans who were "wet" and opposed to prohibition, Bryan moved to Coconut Grove in Miami, Florida in 1913. He called his home on Brickell Avenue "Villa Serena". Later, in 1925, he moved to a new home further south in Coconut Grove on Main Highway called "Marymont". Bryan filled lucrative speaking engagements, including playing the part of spokesman for George E. Merrick's new planned community Coral Gables, addressing large crowds across a Venetian pool, for an annual salary of over $100,000. He was also extremely active in Christian organizations. Bryan refused to support the 1920 Democratic presidential nominee, James M. Cox, because he deemed Cox not dry enough. As one biographer explains,
Bryan epitomized the prohibitionist viewpoint: Protestant and nativist, hostile to the corporation and the evils of urban civilization, devoted to personal regeneration and the social gospel, he sincerely believed that prohibition would contribute to the physical health and moral improvement of the individual, stimulate civic progress, and end the notorious abuses connected with the liquor traffic. Hence he became interested when its devotees in Nebraska viewed direct legislation as a means of obtaining anti-saloon laws.
Bryan's national campaigning helped Congress pass the 18th Amendment in 1918, which shut down all saloons as of 1920. But while prohibition was in effect, Bryan did not work to secure better enforcement. He opposed a highly controversial resolution at the 1924 Democratic National Convention condemning the Ku Klux Klan, expecting the organization would soon fold. Bryan disliked the Klan but never publicly attacked it. For the nomination in 1924, he opposed the wet Al Smith; Bryan's younger brother, Nebraska Governor Charles W. Bryan, was put on the ticket with John W. Davis as candidate for vice president to keep the Bryanites in line. Bryan was very close to his brother and endorsed him for the vice presidency.
Bryan was the chief proponent of the Harrison Narcotics Tax Act, the precursor to the modern War on Drugs. However, he argued for the act's passage more as an international obligation than on moral grounds.
After his resignation as Secretary of State, until his death, Bryan became an active promoter of Florida real estate, and lived in the Miami area during the colder months. His promotions (in print, speeches and even radio talks) may have contributed to the 1920s Florida real estate boom. "The Great Commoner" Bryan became rich from his real estate investments. The Florida boom collapsed within months after Bryan's death in 1925.
Anti-evolution activism: 1918–1925.
Before World War I, Bryan believed moral progress could achieve equality at home and, in the international field, peace among all the world's nations.
Bryan opposed the Darwinian theory of evolution for two reasons. First, he believed that what he considered a materialistic account of the descent of man through evolution undermined the Bible. Second, he considered Darwinism as applied to society to be a great evil force in the world, promoting hatred and conflicts, especially the World War.
In his famous Chautauqua lecture, "The Prince of Peace," (1909) Bryan warned that the theory of evolution could undermine the foundations of morality. He concluded, "while I do not accept the Darwinian theory I shall not quarrel with you about it." Evoking, the design argument, he said "I have a right to assume, and I prefer to assume, a Designer back of the design— a Creator back of the creation."
One book Bryan read at this time convinced him that Darwinism emphasizing the struggle of races had undermined morality in Germany. Bryan was deeply influenced by Vernon Kellogg's 1917 book, "Headquarters Nights: A Record of Conversations and Experiences at the Headquarters of the German Army in Belgium and France", which asserted (on the basis of a conversation with a reserve officer he called "Professor von Flussen") that German intellectuals were totally committed to might-makes-right due to "whole-hearted acceptance of the worst of Neo-Darwinism, the "Allmacht" of natural selection applied to human life and society and "Kultur"."
Bryan also read "The Science of Power" (1918) by British social theorist Benjamin Kidd, which credited the philosophy of Friedrich Nietzsche with German nationalism, materialism, and militarism. He described this as the working out of the social Darwinian hypothesis.
In 1920, Bryan told the World Brotherhood Congress that the theory of evolution was "the most paralyzing influence with which civilization has had to deal in the last century" and that Nietzsche, in carrying the theory of evolution to its logical conclusion, "promulgated a philosophy that condemned democracy... denounced Christianity... denied the existence of God, overturned all concepts of morality... and endeavored to substitute the worship of the superhuman for the worship of Jehovah."
By 1921, Bryan considered Darwinism as a major internal threat to the US. He was affected by James H. Leuba's major study, "The Belief in God and Immortality, a Psychological, Anthropological and Statistical Study" (1916). In this study, Leuba shows that during four years of college a considerable number of college students lost their faith. Bryan was horrified that the next generation of American leaders might have the degraded sense of morality which he believed had prevailed in Germany and caused the Great War. Bryan launched an anti-evolution campaign.
The campaign kicked off in October 1921, when the Union Theological Seminary in Richmond, Virginia invited Bryan to deliver the James Sprunt Lectures. In his lecture entitled "The Origin of Man", Bryan asked, "what is the role of man in the universe and what is the purpose of man?" For Bryan, the Bible was absolutely central to answering this question, and moral responsibility and the spirit of brotherhood could rest only on belief in God.
The Sprunt lectures were published as "In His Image", and sold over 100,000 copies, while "The Origin of Man" was published separately as "The Menace of the theory of evolution" and also sold very well.
Bryan was worried that the theory of evolution was making grounds not only in the universities, but also within the church. Many colleges were still church-affiliated. The developments of 19th century liberal theology, and higher criticism in particular, had allowed many clergymen to be willing to embrace the theory of evolution and claim that it was not contradictory with their being Christians. Determined to put an end to this, Bryan, who had long served as a Presbyterian elder, decided to run for the position of Moderator of the General Assembly of the Presbyterian Church in the USA, which was at the time embroiled in the Fundamentalist-Modernist Controversy. (Under Presbyterian church governance, clergy and laymen are equally represented in the General Assembly, and the post of Moderator is open to any member of the General Assembly.) Bryan's main competition in the race was the Rev. Charles F. Wishart, president of the College of Wooster in Ohio, who had loudly endorsed the teaching of the theory of evolution in the college. Bryan lost to Wishart by a vote of 451-427. Bryan failed in gaining approval for a proposal to cut off funds to schools where the theory of evolution was taught. Instead, the General Assembly announced disapproval of materialistic (as opposed to theistic) evolution.
In his efforts to publicize his cause, Bryan joined the American Association for the Advancement of Science in 1924 and attended the annual meeting. A featured session at the meeting was a debate on biological evolution between Bryan and Edward Loranus Rice, a developmental biologist from the Methodist-associated Ohio Wesleyan University.
According to historian Ronald L. Numbers, Bryan was not nearly as much a fundamentalist as many modern-day creationists of the 21st century. Instead he is more accurately described as a "day-age creationist". Numbers says Bryan, "not only read the Mosaic "days" as geological "ages" but allowed for the possibility of organic evolution—so long as it did not impinge on the supernatural origin of Adam and Eve."
Scopes trial: 1925.
Bryan actively lobbied for state laws banning public schools from teaching evolution. The legislatures of several Southern states proved more receptive to his anti-evolution message than the Presbyterian Church had been, and passed such laws after Bryan addressed them. A prominent example was the Butler Act of 1925, which made it unlawful in Tennessee to teach that mankind evolved from lower life forms.
Bryan's participation in the highly publicized 1925 Scopes Trial served as a capstone to his career. He was asked by William Bell Riley to represent the World Christian Fundamentals Association as counsel at the trial. During the trial, Bryan took the stand and was questioned by defense lawyer Clarence Darrow about his views on the Bible. "Asked when the Flood occurred, Bryan consulted "Ussher's Bible Concordance", and gave the date as 2348 B.C., or 4273 years ago. Did not Bryan know, asked Darrow, that Chinese civilization had been traced back at least 7000 years?" Bryan conceded that he did not. When he was asked if the records of any other religion made mention of a flood at the time he cited, Bryan replied: "The Christian religion has always been good enough for me - I never found it necessary to study any competing religion."
The national media reported the trial in great detail, with H. L. Mencken ridiculing Bryan as a symbol of Southern ignorance (despite his not being from the South) and anti-intellectualism. In a more humorous vein, satirist Richard Armour stated in "It All Started With Columbus" that Darrow had "made a monkey out of" Bryan due to Bryan's ignorance of the Bible.
After the judge retroactively expunged all of Bryan's answers to Darrow's questions, both sides closed without summation. The jury quickly returned a guilty verdict with the defense's encouragement, and Bryan won the case. However, the state Supreme Court reversed the verdict on a technicality.
Bryan linked Darwinism to what he considered to be the might-makes-right philosophy of Friedrich Nietzsche. Bryan believed that such thinking served not so much as an explanation for injustice but more as an excuse for injustice, particularly in the areas of harming the weak and waging war. In contrast, Bryan was influenced by the social philosophy of Leo Tolstoy, Christian humanitarian and pacifist.
Death.
In the days following the Scopes trial Bryan traveled hundreds of miles, delivering speeches in multiple towns. On Sunday, July 26, 1925, he returned from Chattanooga, Tennessee to his home in Dayton. After attending church services he ate a large meal, then died during a nap that afternoon, five days after the trial's conclusion. When someone remarked to Darrow that Bryan died from a "broken heart", Darrow responded, "Broken heart, hell, he died of a busted belly!" Journalist H. L. Mencken, who disliked Bryan intensely, reportedly boasted to Darrow that "we killed the son of a bitch".
Bryan is buried in Arlington National Cemetery. His headstone reads, "Statesman. Yet Friend To Truth! Of Soul Sincere. In Action Faithful. And In Honor Clear". He was survived by his daughter, Congresswoman Ruth Bryan Owen, and her four children: John Bryan Leavitt and Ruth Leavitt, by her first husband, Newport, Rhode Island artist William Homer Leavitt; and two children by her second husband, British Royal Engineers officer Reginald A. Owen.
Ruth's eldest son John Bryan Leavitt, who had been adopted by his grandfather after his parents' divorce, became a poet and an actor, working professionally as John Bryan.
Bryan College, a Christian-oriented institution, opened in 1930 in Dayton as a lasting memorial to Bryan.
Popular image.
L. Frank Baum satirized Bryan as the Cowardly Lion in "The Wonderful Wizard of Oz", published in 1900. Baum had been a Republican activist in 1896 and wrote on McKinley's behalf.
"Inherit the Wind", a 1955 play by Jerome Lawrence and Robert Edwin Lee, is a highly fictionalized account of the Scopes Trial written in response to McCarthyism. A populist thrice-defeated Presidential candidate from Nebraska named Matthew Harrison Brady comes to a small town named Hillsboro in Tennessee to help prosecute a young teacher for teaching evolution to his schoolchildren. He is opposed by a famous trial lawyer, Henry Drummond (based on Darrow), and mocked by a cynical newspaperman (based on H.L. Mencken) as the trial assumes a national profile. "Inherit the Wind" is also a 1960 Hollywood film adaptation of the play of the same name, written by Jerome Lawrence and Robert Edwin Lee, directed by Stanley Kramer. It stars Spencer Tracy as lawyer Henry Drummond and Fredric March as his friend and rival Matthew Harrison Brady.
Bryan also appears as a character in Douglas Moore's 1956 opera "The Ballad of Baby Doe" and is briefly mentioned in John Steinbeck's "East of Eden". In addition, he is a (very) minor character in Thomas Wolfe's "Look Homeward, Angel". His death is referred to in Ernest Hemingway's "The Sun Also Rises". In Robert A. Heinlein's "", Bryan's unsuccessful or successful runs for the presidency are seen as the "splitting off" events of the alternate histories through which the protagonists travel.
He also has a biographical part in "The 42nd Parallel" in John Dos Passos' "USA Trilogy".
In political cartoons.
The sheer volume of political propaganda cartoons featuring Bryan is a testament to the amusement and fear he caused among conservatives. Bryan campaigned tirelessly, championing the ideas of the farmers and workers, using his skills as a famed orator to ultimately reshape the Democratic Party into a more progressive one. These political cartoons attacked just about every facet of Bryan’s character and policy. They mocked his religious fervor, his campaign slogans, and even his ability to unify parties for a common cause. As Keen puts it, "The art of propaganda is to create a portrait that incarnates the idea of what we wish to destroy so we will react rather than think, and automatically focus our free-floating hostility, indistinct frustrations, and unnamed fears". Bryan embodied these fears of the Republican Party of the time, which is clearly evident in the lengths they went to deface his character in these cartoons.
The most notable cartoons are of Bryan illustrated as a snake, representing Populism, swallowing a donkey, symbolizing the Democratic Party. Another notable Bryan cartoon is one where he is standing atop a Bible, marketing the sales of a "crown of thorns" and a "cross of gold" both referencing "The Cross of Gold," his most popular speech.
Nicknames.
Bryan had an unusually high number of nicknames given to him in his lifetime; most of these were given by his loyal admirers in the Democratic Party. In addition to his best-known nickname, "The Great Commoner", he was also called "The Silver Knight of the West" (due to his support of the free silver issue) and the "Boy Orator of the Platte" (a reference to his oratorical skills and his home near the Platte River in Nebraska). A derisive nickname given by journalist H.L. Mencken, a prominent Bryan critic, was "The Fundamentalist Pope", a reference to Bryan's devout religious views. He is called "Adam-and-Eve" Bryan in "O Russet Witch!, Tales of the Jazz Age" by F. Scott Fitzgerald. William Jennings Bryan has been seen as America's "Biggest Loser" since losing elections and other things.
Legacy.
Michael Kazin considers Bryan the first of the 20th century "celebrity politicians", better known for their personalities and communications skills than their political views. Bryan was never comfortable with the black community, and attacked Roosevelt in 1904 for inviting Booker T. Washington to the White House to further the social equality between the races; he supported disfranchisement of southern blacks. Form and content mix uneasily in Bryan's politics. The content of his speeches leads in a direct line to the progressive reforms adopted by 20th century Democrats. But the form his actions took was a romantic invocation of the American past, a populist insistence on the wisdom of ordinary folk, and a faith-based insistence on sincerity and character.
In his book "They Also Ran", Irving Stone criticizes Bryan as an egocentric who never admitted being wrong. Stone argues that because Bryan led a privileged life, he could not feel the suffering of the common man. He asserts that Bryan only acted as a champion of common men in order to get their votes. Stone claims that none of Bryan's ideas were original, and that he did not have the brains to be an effective president. He calls Bryan one of the nation's worst Secretaries of State. He believes that, as President, Bryan would have supported many blue laws. In Stone's opinion, Bryan had one of the least disciplined minds of the 19th century, and McKinley, Roosevelt and Taft all made better Presidents than Bryan would have been. His biographer Paolo Coletta reports that Bryan relied solely on his own judgments, and did not try to consult experts. He was suspicious not only of the plutocracy but of the intelligentsia, ridiculing them as the "aristocracy of learning" and "the scientific soviet."
Many prominent Democrats have praised Bryan and his legacy. In 1962, former President Harry Truman said Bryan "was a great one—one of the greatest." Truman also claimed: "If it wasn't for old Bill Bryan, there wouldn't be any liberalism at all in the country now. Bryan kept liberalism alive, he kept it going." In 1900, Truman, aged 16, was a page at the Democratic National Convention in Kansas City. He heard Bryan speak and was deeply impressed. In 1900 Truman and his father "declared themselves thorough 'Bryan men'... Bryan remained an idol for Harry, as the voice of the common man." Tom L. Johnson, the progressive mayor of Cleveland, Ohio, referred to Bryan's campaign in 1896 as "the first great struggle of the masses in our country against the privileged classes." In a 1934 speech dedicating a memorial to Bryan, President Franklin D. Roosevelt said "I think that we would choose the word 'sincerity' as fitting him most of all...it was that sincerity that served him so well in his life-long fight against sham and privilege and wrong. It was that sincerity which made him a force for good in his own generation and kept alive many of the ancient faiths on which we are building today. We...can well agree that he fought the good fight; that he finished the course; and that he kept the faith."
Bryan was one of the best known orators of his time. He was a fixture in the Democratic Party, and a hero to the common man. Starting with his Cross of Gold speech, Bryan brought the Populists into the Democratic Party, and with his common man message he would inevitably draw the African-American and feminist vote into the party. A strong believer in the power of government to improve people’s lives, Bryan expressed his belief to John Reed in 1916 that the government “may properly impose a minimum wage, regulate hours of labor, pass usury laws, and enforce inspection of food, sanitation and housing conditions.” Bryan became the bridge that brought different factions into the party, and paved the way for liberal Democrats such as Franklin D. Roosevelt with his New Deal legislation. As noted by Bryan's biographer Michael Kazin:
Kazin, however, also emphasizes the limits of Bryan's influence in the progressive mindset:
Honors.
Bryan County, Oklahoma is named after him.
Bryan Medical Center (formerly BryanLGH Medical Center and Bryan Memorial Hospital) in Lincoln, Nebraska, Bryan College of Health Science, connected with the hospital in Lincoln, and Bryan College, located in Dayton, Tennessee, are also named for William Jennings Bryan. The William Jennings Bryan House in Nebraska was named a U.S. National Historic Landmark in 1963. A $4,000 scholarship for Creighton University students participating in Speech and Debate at the university is named after William Jennings Bryan. The Bryan Home Museum is a by-appointment only museum at his birthplace in Salem, Illinois. Salem is also home to Bryan Park and a large statue of Bryan. Omaha Bryan High School and Bryan Middle School in Bellevue, Nebraska are named for him. He is also honored by having an elementary school in Mission, Texas named after him, Bryan Elementary School on a street named after him, Bryan Street. His home at Asheville, North Carolina from 1917 to 1920, the William Jennings Bryan House, was listed on the National Register of Historic Places in 1983.
A statue of Bryan represents the state of Nebraska at the National Statuary Hall in the United States Capitol. Bryan was named to the Nebraska Hall of Fame in 1971. A bust of him was dedicated as part of the Hall of Fame in 1974 which currently resides, like other members of the hall of fame, in the Nebraska State Capitol.
He has been honored by the United States Postal Service with a $2 Great Americans series postage stamp.
The actor Ainslie Pryor played Bryan in a 1956 episode of the CBS anthology series, "You Are There" which focuses on the Cross of Gold speech.
In 2013, Bryan was inducted into the Gennett Records Walk of Fame to commemorate his recording of the Cross of Gold speech.

</doc>
<doc id="40609" url="https://en.wikipedia.org/wiki?curid=40609" title="Watergate (disambiguation)">
Watergate (disambiguation)

Watergate is the Watergate scandal, a 1972 break-in at the Watergate Hotel by members of President Richard Nixon's administration and the resulting cover-up.
Watergate may also refer to:

</doc>
<doc id="40612" url="https://en.wikipedia.org/wiki?curid=40612" title="Unitatis Redintegratio">
Unitatis Redintegratio

Unitatis Redintegratio is the Second Vatican Council's Decree on Ecumenism. It was passed by a vote of 2,137 to 11 of the bishops assembled and was promulgated by Pope Paul VI on 21 November 1964. The title in Latin means "Restoration of Unity" and is from the first line of the decree, as is customary with major Catholic documents (see incipit).
Contents.
"The numbers given correspond to the section numbers within the text."
Policy on the Eastern Orthodox and Oriental Orthodox.
"Unitatis Redintegratio" calls for the reunion of Christendom and so it is not terribly different from previous calls for unity by Pope Leo XIII in the 1894 encyclical "Praeclara gratulationis publicae". However, the document articulates a different kind of ecclesiology than "Praeclara", focusing on the unity of the people of God and on separate Christian brethren instead of a classical call for schismatics to return to the fold under the unity of the Vicar of Christ.
Reformation communities.
The document acknowledges that there are serious problems facing prospects of reunion with Reformation communities that make no attempt to claim apostolic succession such as the Anglican communion does. Ecclesial communities that adhere to Calvinism are a particular case because they often have important doctrinal differences on key issues such as ecclesiology, liturgy and mariology. Other communities have insoluble doctrinal differences with Catholic Christianity because their theology of the Holy Trinity is manifestly incompatible with the doctrine of the council of Nicea in the early Church. That these serious problems are a barrier to salvation is clarified in the 2004 Vatican document, "The Decree on Ecumenism, Read Anew after Forty Years".
Separated brethren.
The concept and wording was published as late as 1793, in a discourse which examined two papal briefs to the Bishop of Chiusi-Pienza. Frank Flinn wrote, in "Encyclopedia of Catholicism", that in 1959 Pope John XXIII "addressed Protestants as separated brethren," in "Ad Petri cathedram" (APC), which Flinn saw as "an important step toward recognizing Protestants as legitimate partners in a future dialogue." But Pope Leo XIII "was the first to speak of 'separated brothers according to John Norman Davidson Kelly's "A Dictionary of Popes". Edward Farrugia, in "Gregorianum", describes the development from Pope Leo XIII's "Orientalium dignitas" (OD) to "Orientalium Ecclesiarum" (OE) to "Unitatis Redintegratio" (UR). "Yet if builds on , differences remain. Whereas " 186 "speaks of 'dissident bretheren' ('), 28 speaks of 'separated bretheren' ('), although it does not go as far as 14, where there is an inchoative use of the language of 'sister Churches' ("")." Farrugia noted Austin Flannery's translations in "Vatican Council II", " 29 speaks of the 'separated Churches' and 25 of 'any separated Eastern Christians', and 29 of 'Eastern separated brethren'." J. M. R. Tillard goes into detail, in "New Catholic Encyclopedia", about "the development of a carefully nuanced vocabulary, consistent with Vatican II Ecclesiology," which evolved from "the idea of membership in favor of that of incorporation" and has its categorization found in the dogmatic constitution "" (LG) which Tillard describes:
"Every shade of difference in meaning among these terms is important," emphasizes Tillard. "But the terms acquire their full force only in the light of the most authoritative commentaries on them," and "Nostra aetate" (NA). "Then, supposing the nuances indicated, the richness of such expressions as the following becomes clear: 'Churches and ecclesial communities'; 'separated brethren'; 'separated Churches and ecclesial communities'; 'full communion'—'imperfect communion'."
"But thanks to its ecclesiology," wrote Tillard, "Vatican II was able to affirm at the same time that Churches or ecclesial communities separated from the Catholic Church are part of the single Church, and that nevertheless incorporation in Christ and His Church possesses within the Catholic Church the fullness that it does not have elsewhere."
In 2007, the Congregation for the Doctrine of the Faith (CDF) clarified "the authentic meaning" of the ecclesiological expression "Church" which "according to Catholic doctrine," the texts of the Second Vatican Council and those of the Magisterium since the Second Vatican Council do not call Christian Communities born out of the Reformation of the 16th century as "Churches" because "these Communities do not enjoy apostolic succession in the sacrament of Orders, and are, therefore, deprived of a constitutive element of the Church." William Whalen wrote, in "Separated Brethren", that separated brethren' refers to Christians united by baptism and committed to Jesus Christ but divided by theological beliefs." Whalen explained, that Protestant Reformation Christians broke "the bond of common faith" and "they became separated brethren."
"All Christians who are baptized and believe in Christ but are not professed Catholics" are separated brethren, according to John Hardon in "Modern Catholic Dictionary". "More commonly the term is applied to Protestants." Likewise, "separated brethren" according to Catholic Answers, in "This Rock", "refers to those who, though separated from full communion with the Catholic Church, have been justified through baptism and are thus brethren in Christ." "teaches that 'all who have been justified by faith in baptism are members of Christ's body, and have a right to be called Christian, and so are correctly accepted as brothers by the children of the Catholic Church'." J. A. Jungmann and K. Stasiak wrote, in "New Catholic Encyclopedia", that "the Second Vatican Council's call for a greater spirit of ecumenism among churches and ecclesial communities reflects the understanding that Baptism is the effecting and the sign of the fundamental unity of all Christians."
"Because Mormonism is polytheistic and rejects the Trinity," Catholic Answers points out that, "Mormon baptism is not valid, and Mormons are not considered separated brethren." Cardinal Urbano Navarrete Cortés clarified, in "L'Osservatore Romano", "that in all of the effects of the pastoral, administrative and juridical practices of the Church the Mormons are not to be considered as belonging to an 'ecclesial community not in full communion with the Catholic Church', but simply as non-baptized." Baptism conferred by The Christian Community, founded by Rudolf Steiner; The New Church, founded by Emanuel Swedenborg; conferred with the formula "I baptize you in the name of the Creator, and of the Redeemer, and of the Sanctifier"; or, conferred with the formula "I baptize you in the name of the Creator, and of the Liberator, and of the Sustainer" are also deemed not valid.
"Separated brethren" is a term sometimes used by the Roman Catholic Church and its clergy and members to refer to baptized members of other Christian traditions.
The phrase is a translation of the Latin phrase "fratres seiuncti".
Before the Second Vatican Council, per the pronouncements of the Council of Trent, the Roman Catholic Church officially referred to Protestants and other non-Roman Catholic Christians as "heretics" likely not having hope of salvation outside of the "Church of Rome". However, Biblical passages like Romans 2:12-16 point to the importance of conscience in Catholic soteriology, which the Church has always recognized.
In preparation work for draft texts of Second Vatican Council documents, a "report urged respectful use of the terms dissidents or separated brethren, in place of heretics and schismatics."
After the Second Vatican Council, however, "that habit of unthinkingly hurling accusations of heresy at Protestants pretty much died out". Since at least the mid-1990s, the term has often been replaced by Roman Catholic officials with phrases such as "other Christians".
At least one Roman Catholic writer does not consider Mormons and members of some other religious groups to be separated brethren. Among the groups not considered to be separated brethren are "Jews, Mormons, Christian Scientists, Muslims, Buddhists, and other groups." By the 21st century, within the Roman Catholic faith, Jews are described as and considered elder brothers in the faith.

</doc>
<doc id="40613" url="https://en.wikipedia.org/wiki?curid=40613" title="Logic analyzer">
Logic analyzer

A logic analyzer is an electronic instrument that captures and displays multiple signals from a digital system or digital circuit. A logic analyzer may convert the captured data into timing diagrams, protocol decodes, state machine traces, assembly language, or may correlate assembly with source-level software. Logic Analyzers have advanced triggering capabilities, and are useful when a user needs to see the timing relationships between many signals in a digital system. 
Overview.
Presently, there are three distinct categories of logic analyzers available on the market:
Operation.
A logic analyzer can be triggered on a complicated sequence of digital events, then capture a large amount of digital data from the system under test (SUT).
When logic analyzers first came into use, it was common to attach several hundred "clips" to a digital system. Later, specialized connectors came into use. The evolution of logic analyzer probes has led to a common footprint that multiple vendors support, which provides added freedom to end users. Introduced in April, 2002, connectorless technology (identified by several vendor-specific trade names: Compression Probing; Soft Touch; D-Max) has become popular. These probes provide a durable, reliable mechanical and electrical connection between the probe and the circuit board with less than 0.5 to 0.7 pF loading per signal.
Once the probes are connected, the user programs the analyzer with the names of each signal, and can group several signals together for easier manipulation. Next, a capture mode is chosen, either "timing" mode, where the input signals are sampled at regular intervals based on an internal or external clock source, or "state" mode, where one or more of the signals are defined as "clocks", and data are taken on the rising or falling edges of these clocks, optionally using other signals to qualify these clocks.
After the mode is chosen, a "trigger condition" must be set. A trigger condition can range from simple (such as triggering on a rising or falling edge of a single signal) to the very complex (such as configuring the analyzer to decode the higher levels of the TCP/IP stack and triggering on a certain HTTP packet).
At this point, the user sets the analyzer to "run" mode, either triggering once, or repeatedly triggering.
Once the data are captured, they can be displayed several ways, from the simple (showing waveforms or state listings) to the complex (showing decoded Ethernet protocol traffic). Some analyzers can also operate in a "compare" mode, where they compare each captured data set to a previously recorded data set, and halt capture or visually notify the operator when this data set is either matched or not. This is useful for long-term empirical testing. Recent analyzers can even be set to email a copy of the test data to the engineer on a successful trigger.
Uses.
Many digital designs, including those of ICs, are simulated to detect defects before the unit is constructed. The simulation usually provides logic analysis displays. Often, complex discrete logic is verified by simulating inputs and testing outputs using boundary scan. Logic analyzers can uncover hardware defects that are not found in simulation. These problems are typically too difficult to model in simulation, or too time consuming to simulate and often cross multiple clock domains.
Field-programmable gate arrays have become a common measurement point for logic analyzers and are also used to debug the logic circuit.
History.
As digital computing and integrated circuits emerged in the 1960s, new and difficult problems began to arise, problems that oscilloscopes had trouble handling. For the first time in computing history, it became essential to simultaneously view large numbers of signals. Early solutions attempted to combine hardware from multiple oscilloscopes into one package, but screen clutter, a lack of definite data interpretation, as well as probing constraints made this solution only marginally usable.
The HP 5000A Logic Analyzer, introduced in the October 1973 issue of the Hewlett Packard Journal, was probably the first commercially available instrument to be called a "Logic Analyzer". However, the HP 5000A was limited to two channels and presented information by means of two rows of 32 LEDs. The first truly parallel instrument was the twelve channel HP 1601L, it was a plug-in for the HP 180 series oscilloscope mainframes and used the oscilloscope screen to present 16 rows of 12 bit words as 1s and 0s. It was introduced in the January 1974 Hewlett Packard Journal.
Mixed-signal oscilloscopes.
Mixed-signal oscilloscopes combine the functionality of a digital storage oscilloscope with a logic analyzer. The several benefits of these include the ability to view analog and digital signals together in time, and to trigger on either digital or analog signals and capture on the other. A few limitations of mixed signal oscilloscopes are that they do not capture state-mode data, they have a limited channel count, and do not provide the analytical depth and insight of a logic analyzer.

</doc>
<doc id="40614" url="https://en.wikipedia.org/wiki?curid=40614" title="Network switch">
Network switch

A network switch (also called switching hub, bridging hub, officially MAC bridge) is a computer networking device that connects devices together on a computer network, by using packet switching to receive, process and forward data to the destination device. Unlike less advanced network hubs, a network switch forwards data only to one or multiple devices that need to receive it, rather than broadcasting the same data out of each of its ports.
A network switch is a multiport network bridge that uses hardware addresses to process and forward data at the data link layer (layer 2) of the OSI model. Switches can also process data at the network layer (layer 3) by additionally incorporating routing functionality that most commonly uses IP addresses to perform packet forwarding; such switches are commonly known as layer-3 switches or multilayer switches. Beside most commonly used Ethernet switches, they exist for various types of networks, including Fibre Channel, Asynchronous Transfer Mode, and InfiniBand. The first Ethernet switch was introduced by Kalpana in 1990.
Overview.
A switch is a device in a computer network that electrically and logically connects together other devices. Multiple data cables are plugged into a switch to enable communication between different networked devices. Switches manage the flow of data across a network by transmitting a received message only to the one or more devices for which the message was intended. Each networked device connected to a switch can be identified using a MAC address, allowing the switch to regulate the flow of traffic. This maximizes the security and efficiency of the network.
Essentially, when replacing a repeater hub with an Ethernet switch, the single large collision domain is split up into smaller ones, reducing the probability and scope of collisions and, as a result, increasing the potential throughput. Because broadcasts are still being forwarded to all connected devices, the newly formed network segment continues to be a broadcast domain.
Due to these features, a switch may be seen as more "intelligent" than a repeater hub, which simply retransmits messages out of every port of the hub but the receiving one, unable to distinguish different recipients, and greatly degrading the overall efficiency of the network.
Network design.
An Ethernet switch operates at the data link layer (layer 2) of the OSI model to create a separate collision domain for each switch port. Each device connected to a switch port can transfer data to any of the other ones at a time, and the transmissions will not interfere with the limitation that, in half duplex mode, each switch port can only "either" receive from "or" transmit to its connected device at a certain time. In full duplex mode, each switch port can simultaneously transmit "and" receive, assuming the connected device also supports full duplex mode.
In the case of using a repeater hub, only a single transmission could take place at a time for all ports combined, so they would all share the bandwidth and run in half duplex. Necessary arbitration would also result in collisions, requiring retransmissions.
Applications.
The network switch plays an integral role in most modern Ethernet local area networks (LANs). Mid-to-large sized LANs contain a number of linked managed switches. Small office/home office (SOHO) applications typically use a single switch, or an all-purpose converged device such as a residential gateway to access small office/home broadband services such as DSL or cable Internet. In most of these cases, the end-user device contains a router and components that interface to the particular physical broadband technology. User devices may also include a telephone interface for Voice over IP (VoIP) protocol.
Microsegmentation.
Segmentation involves the use of a bridge or a switch (or a router) to split a larger collision domain into smaller ones in order to reduce collision probability, and to improve overall network throughput. In the extreme case (i.e. microsegmentation), each device is located on a dedicated switch port. In contrast to an Ethernet hub, there is a separate collision domain on each of the switch ports. This allows computers to have dedicated bandwidth on point-to-point connections to the network and also to run in full-duplex without collisions. Full-duplex mode has only one transmitter and one receiver per "collision domain", making collisions impossible.
Role of switches in a network.
Switches may operate at one or more layers of the OSI model, including the data link and network layers. A device that operates simultaneously at more than one of these layers is known as a "multilayer switch".
In switches intended for commercial use, built-in or modular interfaces make it possible to connect different types of networks, including Ethernet, Fibre Channel, RapidIO, ATM, ITU-T G.hn and 802.11. This connectivity can be at any of the layers mentioned. While the layer-2 functionality is adequate for bandwidth-shifting within one technology, interconnecting technologies such as Ethernet and token ring is performed easier at layer 3 or via routing. Devices that interconnect at the layer 3 are traditionally called routers, so layer 3 switches can also be regarded as relatively primitive and specialized routers.
Where there is a need for a great deal of analysis of network performance and security, switches may be connected between WAN routers as places for analytic modules. Some vendors provide firewall, network intrusion detection, and performance analysis modules that can plug into switch ports. Some of these functions may be on combined modules.
In other cases, the switch is used to create a mirror image of data that can go to an external device. Since most switch port mirroring provides only one mirrored stream, network hubs can be useful for fanning out data to several read-only analyzers, such as intrusion detection systems and packet sniffers.
Layer-specific functionality.
While switches may learn about topologies at many layers, and forward at one or more layers, they do tend to have common features. Other than for high-performance applications, modern commercial switches use primarily Ethernet interfaces.
At any layer, a modern switch may implement power over Ethernet (PoE), which avoids the need for attached devices, such as a VoIP phone or wireless access point, to have a separate power supply. Since switches can have redundant power circuits connected to uninterruptible power supplies, the connected device can continue operating even when regular office power fails.
Layer 1 (hubs vs. higher-layer switches).
A network hub, or a repeater, is a simple network device that does not manage any of the traffic coming through it. Any packet entering a port is flooded out or "repeated" on every other port, except for the port of entry. Since every packet is repeated on every other port, packet collisions affect the entire network, limiting its overall capacity.
A network switch creates the layer 1 end-to-end connection only virtually, while originally it was mandatory. The bridging function of a switch uses information taken from layer 2 to select for each packet the particular port(s) it has to be forwarded to, removing the requirement that every node is presented with all traffic. As a result, the connection lines are not "switched" literally, instead they only appear that way on the packet level.
There are specialized applications in which a network hub can be useful, such as copying traffic to multiple network sensors. High-end network switches usually have a feature called port mirroring that provides the same functionality.
By the early 2000s, there was little price difference between a hub and a low-end switch.
Layer 2.
A network bridge, operating at the data link layer, may interconnect a small number of devices in a home or the office. This is a trivial case of bridging, in which the bridge learns the MAC address of each connected device.
Single bridges also can provide extremely high performance in specialized applications such as storage area networks.
Classic bridges may also interconnect using a spanning tree protocol that disables links so that the resulting local area network is a tree without loops. In contrast to routers, spanning tree bridges must have topologies with only one active path between two points. The older IEEE 802.1D spanning tree protocol could be quite slow, with forwarding stopping for 30 seconds while the spanning tree reconverged. A Rapid Spanning Tree Protocol was introduced as IEEE 802.1w. The newest standard Shortest path bridging (IEEE 802.1aq) is the next logical progression and incorporates all the older Spanning Tree Protocols (IEEE 802.1D STP, IEEE 802.1w RSTP, IEEE 802.1s MSTP) that blocked traffic on all but one alternative path. IEEE 802.1aq (Shortest Path Bridging SPB) allows all paths to be active with multiple equal cost paths, provides much larger layer 2 topologies (up to 16 million compared to the 4096 VLANs limit), faster convergence, and improves the use of the mesh topologies through increased bandwidth and redundancy between all devices by allowing traffic to load share across all paths of a mesh network.
While "layer 2 switch" remains more of a marketing term than a technical term, the products that were introduced as "switches" tended to use microsegmentation and full duplex to prevent collisions among devices connected to Ethernet. By using an internal forwarding plane much faster than any interface, they give the impression of simultaneous paths among multiple devices. 'Non-blocking' devices use a forwarding plane or equivalent method fast enough to allow full duplex traffic for each port simultaneously.
Once a bridge learns the addresses of its connected nodes, it forwards data link layer frames using a layer 2 forwarding method. There are four forwarding methods a bridge can use, of which the second through fourth method were performance-increasing methods when used on "switch" products with the same input and output port bandwidths:
While there are specialized applications, such as storage area networks, where the input and output interfaces are the same bandwidth, this is not always the case in general LAN applications. In LANs, a switch used for end user access typically concentrates lower bandwidth and uplinks into a higher bandwidth.
Layer 3.
Within the confines of the Ethernet physical layer, a layer-3 switch can perform some or all of the functions normally performed by a router.
The most common layer-3 capability is awareness of IP multicast through IGMP snooping. With this awareness, a layer-3 switch can increase efficiency by delivering the traffic of a multicast group only to ports where the attached device has signaled that it wants to listen to that group.
Layer 4.
While the exact meaning of the term "layer-4 switch" is vendor-dependent, it almost always starts with a capability for network address translation, but then adds some type of load distribution based on TCP sessions.
The device may include a stateful firewall, a VPN concentrator, or be an IPSec security gateway.
Layer 7.
Layer-7 switches may distribute the load based on uniform resource locators (URLs), or by using some installation-specific technique to recognize application-level transactions. A layer-7 switch may include a web cache and participate in a content delivery network (CDN).
Traffic monitoring on a switched network.
Unless port mirroring or other methods such as RMON, SMON or sFlow are implemented in a switch, it is difficult to monitor traffic that is bridged using a switch because only the sending and receiving ports can see the traffic. These monitoring features are rarely present on consumer-grade switches.
Two popular methods that are specifically designed to allow a network analyst to monitor traffic are:
Another method to monitor may be to connect a layer-1 hub between the monitored device and its switch port. This will induce minor delay, but will provide multiple interfaces that can be used to monitor the individual switch port.

</doc>
<doc id="40616" url="https://en.wikipedia.org/wiki?curid=40616" title="Pigeon sport">
Pigeon sport

There are at least four main types of competitive pigeon sport:
Though not quite a sport, fancy breeds of pigeons are also bred to standards and judged in a competitive fashion. Levi in his book "The Pigeon" describes all aspects of pigeon keeping. For exhibition purposes sport pigeons are sometimes grouped as Flying/Sporting Pigeons.

</doc>
<doc id="40622" url="https://en.wikipedia.org/wiki?curid=40622" title="Ohmmeter">
Ohmmeter

An ohmmeter is an electrical instrument that measures electrical resistance, the opposition to an electric current. Micro-ohmmeters (microhmmeter or microohmmeter) make low resistance measurements. Megohmmeters (also a trademarked device Megger) measure large values of resistance. The unit of measurement for resistance is ohms (Ω).
The first ohmmeters were based on a type of meter movement known as a 'ratiometer'. These were similar to the galvanometer type movement encountered in later instruments, but instead of hairsprings to supply a restoring force they used conducting 'ligaments' instead. These provided no net rotational force to the movement. Also, the movement was wound with two coils. One was connected via a series resistor to the battery supply. The second was connected to the same battery supply via a second resistor and the resistor under test. The indication on the meter was proportional to the ratio of the currents through the two coils. This ratio was determined by the magnitude of the resistor under test. The advantages of this arrangement were twofold. First, the indication of the resistance was completely independent of the battery voltage (as long as it actually produced some voltage) and no zero adjustment was required. Second, although the resistance scale was non linear, the scale remained correct over the full deflection range. By interchanging the two coils a second range was provided. This scale was reversed compared to the first. A feature of this type of instrument was that it would continue to indicate a random resistance value once the test leads were disconnected (the action of which disconnected the battery from the movement). Ohmmeters of this type only ever measured resistance as they could not easily be incorporated into a multimeter design. Insulation testers that relied on a hand cranked generator operated on the same principle. This ensured that the indication was wholly independent of the voltage actually produced.
Subsequent designs of ohmmeter provided a small battery to apply a voltage to a resistance via a galvanometer to measure the current through the resistance. The scale of the galvanometer was marked in ohms, because the fixed voltage from the battery assured that as resistance is decreased, the current through the meter would increase. Ohmmeters form circuits by themselves, therefore they cannot be used within an assembled circuit. This design is much simpler and cheaper than the former design, and was simple to integrate into a multimeter design and consequently was by far the most common form of analogue ohmmeter. This type of ohmmeter suffers two inherent disadvantages. First, the meter needs to be zeroed by shorting the measurement points together and performing an adjustment for zero ohms indication prior to each measurement. This is because as the battery voltage decreases with age, the series resistance in the meter needs to be reduced to maintain the zero indication at full deflection. Second, and consequent on the first, the actual deflection for any given resistor under test changes as the internal resistance is altered. It remains correct at the centre of the scale only, which is why such ohmmeter designs always quote the accuracy "at centre scale only".
A more accurate type of ohmmeter has an electronic circuit that passes a constant current (I) through the resistance, and another circuit that measures the voltage (V) across the resistance. According to the following equation, derived from Ohm's Law, the value of the resistance (R) is given by:
For high-precision measurements the above types of meter are inadequate. This is because the meter's reading is the sum of the resistance of the measuring leads, the contact resistances and the resistance being measured. To reduce this effect, a precision ohmmeter has four terminals, called Kelvin contacts. Two terminals carry the current from the meter, while the other two allow the meter to measure the voltage across the resistor. With this type of meter, any voltage drop due to the resistance of the first pair of leads and their contact resistances is ignored by the meter. This four terminal measurement technique is called Kelvin sensing, after William Thomson, Lord Kelvin, who invented the Kelvin bridge in 1861 to measure very low resistances. The Four-terminal sensing method can also be utilized to conduct accurate measurements of low resistances.

</doc>
<doc id="40623" url="https://en.wikipedia.org/wiki?curid=40623" title="Multimeter">
Multimeter

A multimeter or a multitester, also known as a VOM (Volt-Ohm meter or Volt-Ohm-milliammeter ), is an electronic measuring instrument that combines several measurement functions in one unit. A typical multimeter can measure voltage, current, and resistance. Analog multimeters use a microammeter with a moving pointer to display readings. Digital multimeters (DMM, DVOM) have a numeric display, and may also show a graphical bar representing the measured value. Digital multimeters are now far more common but analog multimeters are still preferable in some cases, for example when monitoring a rapidly varying value.
A multimeter can be a hand-held device useful for basic fault finding and field service work, or a bench instrument which can measure to a very high degree of accuracy. They can be used to troubleshoot electrical problems in a wide array of industrial and household devices such as electronic equipment, motor controls, domestic appliances, power supplies, and wiring systems.
Multimeters are available in a wide range of features and prices. Cheap multimeters can cost less than US$10, while laboratory-grade models with certified calibration can cost more than US$5,000.
History.
The first moving-pointer current-detecting device was the galvanometer in 1820. These were used to measure resistance and voltage by using a Wheatstone bridge, and comparing the unknown quantity to a reference voltage or resistance. While useful in the lab, the devices were very slow and impractical in the field. These galvanometers were bulky and delicate.
The D'Arsonval/Weston meter movement uses a moving coil which carries a pointer and rotates on pivots or a taught band ligament. The coil rotates in a permanent magnetic field and is restrained by fine spiral springs which also serve to carry current into the moving coil. It gives proportional measurement rather than just detection, and deflection is independent of the orientation of the meter. Instead of balancing a bridge, values could be directly read off the instrument's scale, which made measurement quick and easy.
The basic moving coil meter is suitable only for direct current measurements, usually in the range of 10 microamperes to 100mA. It is easily adapted to read heavier currents by using shunts (resistances in parallel with the basic movement) or to read voltage using series resistances known as multipliers. To read alternating currents or voltages, a rectifier is needed. One of the earliest suitable rectifiers was the copper oxide rectifier developed and manufactured by Union Switch & Signal Company, Swissvale, Pennsylvania, later part of Westinghouse Brake and Signal Company, from 1927.
Multimeters were invented in the early 1920s as radio receivers and other vacuum tube electronic devices became more common. The invention of the first multimeter is attributed to British Post Office engineer, Donald Macadie, who became dissatisfied with the need to carry many separate instruments required for maintenance of telecommunications circuits. Macadie invented an instrument which could measure amperes (amps), volts and ohms, so the multifunctional meter was then named Avometer. The meter comprised a moving coil meter, voltage and precision resistors, and switches and sockets to select the range.
The Automatic Coil Winder and Electrical Equipment Company was set up to manufacture the Avometer and a coil winding machine also designed and patented by D. MacAdie. Although a shareholder of ACWEECO, Mr MacAdie continued to work for the Post Office until his retirement in 1933. His son, Hugh S. MacAdie, joined ACWEECO in 1927 and became Technical Director.Automatic Coil Winder and Electrical Equipment Company (ACWEEC, founded in ~1923). The first AVO was put on sale in 1923, and many of its features remained almost unaltered through to the last Model 8.
Any meter will load the circuit under test to some extent. For example,a multimeter using a moving coil movement with full-scale deflection (fsd) current of 50 microamps, the highest sensitivity commonly available, must draw at least 50 microamps from the circuit under test for fsd. This may load a high-impedance circuit so much as to affect the circuit, and to give a low reading. The full-scale deflection current may also be expressed in terms of "ohms per volt" the reciprocal of the fsd current. The ohms per volt figure is often called the "sensitivity" of the instrument although the term is not universally accepted as correct. Thus a meter with a 50 microampere will have a "sensitivity" of 20,000 ohms per volt.
The first Avometer had a sensitivity of 60 ohms per volt, 3 direct current ranges (12mA, 1.2A & 12A), three direct voltage ranges (12, 120 & 600V or optionally 1200V)and a 10,000 ohm resistance range. An improved version of 1927 increased this to 13-ranges and 166.6 ohms per volt (6 mA) movement. A "Universal" version having additional alternating current and alternating voltage ranges was offered from 1933 and in 1936 the dual sensitivity Avometer Model 7 offered 500/100 ohms per volt. Between the mid 1930s until the 1950s, 1000 ohms per volt became a de facto standard of sensitivity for radio work and this figure was often quoted on service sheets. However, some manufacturers such as Simpson, Triplett and Weston, all in the USA, produced 20,000 ohm per volt VOMs before the Second World War and some of these were exported. After 1945/6, 20,000 ohms per volt became the expected standard for electronics but some maker offered even more sensitive instruments. For industrial and other "heavy-current" use low sensitivity multimeters continued to be produced and these were considered more robust than the more sensitive types.
High quality analog (analogue) multimeters are still made by several manufacturers including Chauvin Arnaux (France), Gossen Metrawatt (Germany) and Simpson and Triplett (USA).
Pocket watch style meters were in widespread use in the 1920s, at much lower cost than Avometers. The metal case was normally connected to the negative connection, an arrangement that caused numerous electric shocks. The technical specifications of these devices were often crude, for example the one illustrated has a resistance of just 33 ohms per volt, a non-linear scale and no zero adjustment.
"Vacuum Tube Voltmeters" or valve voltmeters (VTVM, VVM) were used for voltage measurements in electronic circuits where high impedance was necessary. The VTVM had a fixed input impedance of typically 1 megohm or more, usually through use of a cathode follower input circuit, and thus did not significantly load the circuit being tested. VTVMs were used before the introduction of digital electronic high-impedance analog transistor and field effect transistor (FET) voltmeters. Modern digital meters and some modern analog meters use electronic input circuitry to achieve high-input impedance—their voltage ranges are functionally equivalent to VTVMs.
Additional scales such as decibels, and measurement functions such as capacitance, transistor gain, frequency, duty cycle, display hold, and buzzers which sound when the measured resistance is small have been included on many multimeters. While multimeters may be supplemented by more specialized equipment in a technician's toolkit, some multimeters include additional functions for specialized applications (temperature with a thermocouple probe, inductance, connectivity to a computer, speaking measured value, etc.).
Operation.
A multimeter is a combination of a multirange DC voltmeter, multirange AC voltmeter, multirange ammeter, and multirange ohmmeter. An un-amplified analog multimeter combines a meter movement, range resistors and switches.
For an analog meter movement, DC voltage is measured with a series resistor connected between the meter movement and the circuit under test. A set of switches allows greater resistance to be inserted for higher voltage ranges. The product of the basic full-scale deflection current of the movement, and the sum of the series resistance and the movement's own resistance, gives the full-scale voltage of the range. As an example, a meter movement that required 1 milliampere for full scale deflection, with an internal resistance of 500 ohms, would, on a 10-volt range of the multimeter, have 9,500 ohms of series resistance.
For analog current ranges, low-resistance shunts are connected in parallel with the meter movement to divert most of the current around the coil. Again for the case of a hypothetical 1-mA, 500-ohm movement on a 1-Ampere range, the shunt resistance would be just over 0.5 ohms.
Moving coil instruments respond only to the average value of the current through them. To measure alternating current, a rectifier diode is inserted in the circuit so that the average value of current is non-zero. Since the rectified average value and the root-mean-square value of a waveform need not be the same, simple rectifier-type circuits may only be calibrated for sinusoidal waveforms. Other wave shapes require a different calibration factor to relate RMS and average value. Since practical rectifiers have non-zero voltage drop, accuracy and sensitivity is poor at low values.
To measure resistance, a small battery within the instrument passes a current through the device under test and the meter coil. Since the current available depends on the state of charge of the battery, a multimeter usually has an adjustment for the ohms scale to zero it. In the usual circuit found in analog multimeters, the meter deflection is inversely proportional to the resistance; so full-scale is 0 ohms, and high resistance corresponds to smaller deflections. The ohms scale is compressed, so resolution is better at lower resistance values.
Amplified instruments simplify the design of the series and shunt resistor networks. The internal resistance of the coil is decoupled from the selection of the series and shunt range resistors; the series network becomes a voltage divider. Where AC measurements are required, the rectifier can be placed after the amplifier stage, improving precision at low range.
Digital instruments, which necessarily incorporate amplifiers, use the same principles as analog instruments for range resistors. For resistance measurements, usually a small constant current is passed through the device under test and the digital multimeter reads the resultant voltage drop; this eliminates the scale compression found in analog meters, but requires a source of significant current. An autoranging digital multimeter can automatically adjust the scaling network so that the measurement uses the full precision of the A/D converter.
In all types of multimeters, the quality of the switching elements is critical to stable and accurate measurements. Stability of the resistors is a limiting factor in the long-term accuracy and precision of the instrument.
Quantities measured.
Contemporary multimeters can measure many quantities. The common ones are:
Additionally, some multimeters measure:
Digital multimeters may also include circuits for:
Various sensors can be attached to multimeters to take measurements such as:
Resolution.
Resolution and accuracy.
The resolution of a multimeter is the smallest part of the scale which can be shown, which is scale dependent. On some digital multimeters it can be configured, with higher resolution measurements taking longer to complete. For example, a multimeter that has a 1 mV resolution on a 10 V scale can show changes in measurements in 1mV increments.
Absolute accuracy is the error of the measurement compared to a perfect measurement. Relative accuracy is the error of the measurement compared to the device used to calibrate the multimeter. Most multimeter datasheets provide relative accuracy. To compute the absolute accuracy from the relative accuracy of a multimeter add the absolute accuracy of the device used to calibrate the multimeter to the relative accuracy of the multimeter.
Digital.
The resolution of a multimeter is often specified in the number of decimal digits resolved and displayed. If the most significant digit cannot take all values from 0 to 9 is often termed a fractional digit. For example, a multimeter which can read up to 19999 (plus an embedded decimal point) is said to read 4½ digits.
By convention, if the most significant digit can be either 0 or 1, it is termed a half-digit; if it can take higher values without reaching 9 (often 3 or 5), it may be called three-quarters of a digit. A 5½ digit multimeter would display one "half digit" that could only display 0 or 1, followed by five digits taking all values from 0 to 9. Such a meter could show positive or negative values from 0 to 199,999. A 3¾ digit meter can display a quantity from 0 to 3,999 or 5,999, depending on the manufacturer.
While a digital display can easily be extended in precision, the extra digits are of no value if not accompanied by care in the design and calibration of the analog portions of the multimeter. Meaningful high-resolution measurements require a good understanding of the instrument specifications, good control of the measurement conditions, and traceability of the calibration of the instrument. However, even if its resolution exceeds the accuracy, a meter can be useful for comparing measurements. For example, a meter reading 5½ stable digits may indicate that one nominally 100,000 ohm resistor is about 7 ohms greater than another, although the error of each measurement is 0.2% of reading plus 0.05% of full-scale value.
Specifying "display counts" is another way to specify the resolution. Display counts give the largest number, or the largest number plus one (so the count number looks nicer) the multimeter's display can show, ignoring a decimal separator. For example, a 5½ digit multimeter can also be specified as a 199999 display count or 200000 display count multimeter. Often the display count is just called the count in multimeter specifications.
The accuracy of a digital multimeter may be stated in a two-term form, such as "±1% of reading +2 counts", reflecting the different sources of error in the instrument.
Analog.
Analog meters are older and still preferred by many engineers. One reason for this is that analog meters are more sensitive to changes in the circuit that is being measured. A digital multimeter samples the quantity being measured and then displays it. Analog multimeters continuously read the test value. If there are slight changes in readings, the needle of an analog multimeter will track them while digital multimeters may miss them or be difficult to read. This continuous tracking feature becomes important when testing capacitors or coils. A properly functioning capacitor should allow current to flow when voltage is applied, then the current slowly decreases to zero and this "signature" is easy to see on an analog multimeter but not on a digital multimeter. This is similar when testing a coil, except the current starts low and increases.
Resistance measurements on an analog meter, in particular, are of low precision due to the typical resistance measurement circuit which compresses the scale heavily at the higher resistance values. Inexpensive analog meters may have only a single resistance scale, seriously restricting the range of precise measurements. Typically an analog meter will have a panel adjustment to set the zero-ohms calibration of the meter, to compensate for the varying voltage of the meter battery.
Accuracy.
Digital multimeters generally take measurements with accuracy superior to their analog counterparts. Standard analog multimeters measure with typically ±3% accuracy, though instruments of higher accuracy are made. Standard portable digital multimeters are specified to have an accuracy of typically ±0.5% on the DC voltage ranges. Mainstream bench-top multimeters are available with specified accuracy of better than ±0.01%. Laboratory grade instruments can have accuracies of a few parts per million.
Accuracy figures need to be interpreted with care. The accuracy of an analog instrument usually refers to full-scale deflection; a measurement of 30 V on the 100 V scale of a 3% meter is subject to an error of 3 V, 10% of the reading. Digital meters usually specify accuracy as a percentage of reading plus a percentage of full-scale value, sometimes expressed in counts rather than percentage terms.
Quoted accuracy is specified as being that of the lower millivolt (mV) DC range, and is known as the "basic DC volts accuracy" figure. Higher DC voltage ranges, current, resistance, AC and other ranges will usually have a lower accuracy than the basic DC volts figure. AC measurements only meet specified accuracy within a specified range of frequencies.
Manufacturers can provide calibration services so that new meters may be purchased with a certificate of calibration indicating the meter has been adjusted to standards traceable to, for example, the US National Institute of Standards and Technology (NIST), or other national standards organization.
Test equipment tends to drift out of calibration over time, and the specified accuracy cannot be relied upon indefinitely. For more expensive equipment, manufacturers and third parties provide calibration services so that older equipment may be recalibrated and recertified. The cost of such services is disproportionate for inexpensive equipment; however extreme accuracy is not required for most routine testing. Multimeters used for critical measurements may be part of a metrology program to assure calibration.
A multimeter can be assumed to be "average responding" to AC waveforms unless stated as being a "True RMS" type.
An average responding multimeter will only meet its specified accuracy on AC volts and amps for purely sinusoidal waveforms.
A True RMS responding multimeter on the other hand will meet its specified accuracy on AC volts and current with any waveform type up to a specified crest factor.
A meter's AC voltage and current accuracy may have different specifications for different ranges of frequency.
Sensitivity and input impedance.
When used for measuring voltage, the input impedance of the multimeter must be very high compared to the impedance of the circuit being measured; otherwise circuit operation may be changed, and the reading will also be inaccurate.
Meters with electronic amplifiers (all digital multimeters and some analog meters) have a fixed input impedance that is high enough not to disturb most circuits. This is often either one or ten megohms; the standardization of the input resistance allows the use of external high-resistance probes which form a voltage divider with the input resistance to extend voltage range up to tens of thousands of volts. High-end multimeters generally provide an input impedance >10 Gigaohms for ranges less than or equal to 10 V. Some high-end multimeters provide >10 Gigaohms of impedance to ranges greater than 10 V.
Most analog multimeters of the moving-pointer type are unbuffered, and draw current from the circuit under test to deflect the meter pointer. The impedance of the meter varies depending on the basic sensitivity of the meter movement and the range which is selected. For example, a meter with a typical 20,000 ohms/volt sensitivity will have an input resistance of two million ohms on the 100-volt range (100 V * 20,000 ohms/volt = 2,000,000 ohms). On every range, at full scale voltage of the range, the full current required to deflect the meter movement is taken from the circuit under test. Lower sensitivity meter movements are acceptable for testing in circuits where source impedances are low compared to the meter impedance, for example, power circuits; these meters are more rugged mechanically. Some measurements in signal circuits require higher sensitivity movements so as not to load the circuit under test with the meter impedance.
Sensitivity should not be confused with resolution of a meter, which is defined as the lowest signal change (voltage, current, resistance...) that can change the observed reading.
For general-purpose digital multimeters, the lowest voltage range is typically several hundred millivolts AC or DC, but the lowest current range may be several hundred microamperes, although instruments with greater current sensitivity are available. Multimeters designed for (mains) "electrical" use instead of general electronics engineering use will typically forego the microamps current ranges.
Measurement of low resistance requires lead resistance (measured by touching the test probes together) to be subtracted for best accuracy. This can be done with the "delta", "Zero", or "null" feature of many digital multimeters.
The upper end of multimeter measurement ranges varies considerably; measurements over perhaps 600 volts, 10 amperes, or 100 megohms may require a specialized test instrument.
Burden voltage.
Any ammeter, including a multimeter in a current range, has a certain resistance. Most multimeters inherently measure voltage, and pass a current to be measured through a shunt resistance, measuring the voltage developed across it. The voltage drop is known as the burden voltage, specified in volts per ampere. The value can change depending on the range the meter selects, since different ranges usually use different shunt resistors.
The burden voltage can be significant in very low-voltage circuit areas. To check for its effect on accuracy and on external circuit operation the meter can be switched to different ranges; the current reading should be the same and circuit operation should not be affected if burden voltage is not a problem. If this voltage is significant it can be reduced (also reducing the inherent accuracy and precision of the measurement) by using a higher current range.
Alternating current sensing.
Since the basic indicator system in either an analog or digital meter responds to DC only, a multimeter includes an AC to DC conversion circuit for making alternating current measurements. Basic meters utilize a rectifier circuit to measure the average or peak absolute value of the voltage, but are calibrated to show the calculated root mean square (RMS) value for a sinusoidal waveform; this will give correct readings for alternating current as used in power distribution. User guides for some such meters give correction factors for some simple non-sinusoidal waveforms, to allow the correct root mean square (RMS) equivalent value to be calculated. More expensive multimeters include an AC to DC converter that measures the true RMS value of the waveform within certain limits; the user manual for the meter may indicate the limits of the crest factor and frequency for which the meter calibration is valid. RMS sensing is necessary for measurements on non-sinusoidal periodic waveforms, such as found in audio signals and variable-frequency drives.
Digital multimeters (DMM or DVOM).
Modern multimeters are often digital due to their accuracy, durability and extra features. In a digital multimeter the signal under test is converted to a voltage and an amplifier with electronically controlled gain preconditions the signal. A digital multimeter displays the quantity measured as a number, which eliminates parallax errors.
Modern digital multimeters may have an embedded computer, which provides a wealth of convenience features. Measurement enhancements available include:
Modern meters may be interfaced with a personal computer by IrDA links, RS-232 connections, USB, or an instrument bus such as IEEE-488. The interface allows the computer to record measurements as they are made. Some DMMs can store measurements and upload them to a computer.
The first digital multimeter was manufactured in 1955 by Non Linear Systems.
Analog multimeters.
A multimeter may be implemented with a galvanometer meter movement, or less often with a bargraph or simulated pointer such as an LCD or vacuum fluorescent display. Analog multimeters are common; a quality analog instrument will cost about the same as a DMM. Analog multimeters have the precision and reading accuracy limitations described above, and so are not built to provide the same accuracy as digital instruments.
Analog meters are also useful in situations where it is necessary to pay attention to something other than the meter, and the swing of the pointer can be noticed without looking directly at it. This can happen when accessing awkward locations, or when working on cramped live circuitry.
Analog meter movements are inherently more fragile physically and electrically than digital meters. Many analog meters have been instantly broken by connecting to the wrong point in a circuit, or while on the wrong range, or by dropping onto the floor. Many analog multimeters feature a switch position marked "transit" to protect the meter movement during transportation. This feature works by placing a low resistance across the movement winding, resulting in dynamic braking. Sensitive meter movements may be protected in the same manner by connecting a shorting or jumper wire between the terminals when not in use. Meters which feature a shunt across the winding such as an ammeter may not require further resistance to arrest uncontrolled movements of the meter needle because of the low resistance of the shunt.
The meter movement in a moving pointer analog multimeter is practically always a moving-coil galvanometer of the d'Arsonval type, using either jeweled pivots or taut bands to support the moving coil. In a basic analog multimeter the current to deflect the coil and pointer is drawn from the circuit being measured; it is usually an advantage to minimize the current drawn from the circuit. The sensitivity of an analog multimeter is given in units of ohms per volt. For example, a very low cost multimeter with a sensitivity of 1000 ohms per volt would draw 1 milliampere from a circuit at full scale deflection. More expensive, (and mechanically more delicate) multimeters typically have sensitivities of 20,000 ohms per volt and sometimes higher, with 50,000 ohms per volt (drawing 20 microamperes at full scale) being about the upper limit for a portable, general purpose, non-amplified analog multimeter.
To avoid the loading of the measured circuit by the current drawn by the meter movement, some analog multimeters use an amplifier inserted between the measured circuit and the meter movement. While this increased the expense and complexity of the meter, by use of vacuum tubes or field effect transistors the input resistance can be made very high and independent of the current required to operate the meter movement coil. Such amplified multimeters are called VTVMs (vacuum tube voltmeters), TVMs (transistor volt meters), FET-VOMs, and similar names.
The American Radio Relay League states in their "Handbook for Radio Communications" that analog multimeters that have no amplification circuitry are less susceptible to radio frequency interference.
Probes.
A multimeter can utilize a variety of test probes to connect to the circuit or device under test. Crocodile clips, retractable hook clips, and pointed probes are the three most common attachments. Tweezer probes are used for closely spaced test points, as in surface-mount devices. The connectors are attached to flexible, thickly insulated leads that are terminated with connectors appropriate for the meter. Probes are connected to portable meters typically by shrouded or recessed banana jacks, while benchtop meters may use banana jacks or BNC connectors. 2mm plugs and binding posts have also been used at times, but are less common today.
The banana jacks are typically placed with a standardized center-to-center distance of 0.75" (19.05mm), to allow standard adapters or devices such as voltage multiplier or thermocouple probes to be plugged in.
Clamp meters clamp around a conductor carrying a current to measure without the need to connect the meter in series with the circuit, or make metallic contact at all. Types to measure AC current use the transformer principle; clamp-on meters to measure small current or direct current require more complicated sensors.
Safety.
Most multimeters include a fuse, or two fuses, which will sometimes prevent damage to the multimeter from a current overload on the highest current range. A common error when operating a multimeter is to set the meter to measure resistance or current, and then connect it directly to a low-impedance voltage source. Unfused meters are often quickly destroyed by such errors; fused meters often survive. Fuses used in meters must carry the maximum measuring current of the instrument, but are intended to disconnect if operator error exposes the meter to a low-impedance fault. Meters with inadequate or unsafe fusing were not uncommon; this situation has led to the creation of the IEC61010 categories to rate the safety and robustness of meters.
Digital meters are rated into four categories based on their intended application, as set forth by IEC 61010-1 and echoed by country and regional standards groups such as the CEN EN61010 standard.
Each category also specifies maximum transient voltages for selected measuring ranges in the meter. Category-rated meters also feature protections from over-current faults. On meters that allow interfacing with computers, optical isolation may be used to protect attached equipment against high voltage in the measured circuit.
Good quality multimeters designed to meet CAT II and above ratings will include High Rupture Capacity ceramic fuses typically rated at more than 20kA breaking capacity. They will also include high energy overvoltage MOV (Metal Oxide Varistor) protection, and circuit over-current protection in the form of a Polyswitch.
DMM alternatives.
A general-purpose electronics DMM is generally considered adequate for measurements at signal levels greater than one millivolt or one microampere, or below about 100 megohms—levels far from the theoretical limits of sensitivity. Other instruments—essentially similar, but with higher sensitivity—are used for accurate measurements of very small or very large quantities. These include nanovoltmeters, electrometers (for very low currents, and voltages with very high source resistance, such as one teraohm) and picoammeters. These measurements are limited by available technology, and ultimately by inherent thermal noise.
Power supply.
Analog meters can measure voltage and current using power from the test circuit, but require internal power from the meter for resistance testing; electronic meters always require an internal power supply. Hand-held meters use batteries, while bench meters usually use mains power; either arrangement allows the meter to test devices not connected to an active circuit. Testing often requires that the component under test be isolated from the circuit, as otherwise stray or leakage current paths may distort measurements.
Meters intended for testing in hazardous locations or for use on blasting circuits may require use of a manufacturer-specified battery to maintain their safety rating.

</doc>
<doc id="40628" url="https://en.wikipedia.org/wiki?curid=40628" title="Hayley Wickenheiser">
Hayley Wickenheiser

Hayley Wickenheiser (born August 12, 1978) is a Canadian women's ice hockey player. She was the first woman to play full-time professional hockey in a position other than goalie. Wickenheiser is a member of the Canada women's national ice hockey team. She has represented Canada at the Winter Olympics five times, capturing four gold and one silver medal and twice being named tournament MVP, and one time at the Summer Olympics in softball. She has the most gold medals of any Canadian Olympian and is widely considered the greatest female ice hockey player in the world. On February 20, 2014, Wickenheiser was elected to the International Olympic Committee's Athletes' Commission.
Hockey career.
Minor.
Wickenheiser started playing minor hockey on outdoor rinks in her hometown of Shaunavon, Saskatchewan when she was five years old. She played exclusively on boys teams until she was 13. Wickenheiser continued playing minor hockey in Calgary, Alberta after moving there with her family. In 1991, she represented Alberta at the 18-and-under Canada Winter Games. Alberta captured the gold medal in the tournament, with Wickenheiser scoring the game-winning goal and being named the Most Valuable Player of the final game.
International.
At the age of 15 (1994), Wickenheiser was named to Canada's National Women's Team for the first time and has remained a member since. Her first international tournament was the 1994 World Championship, held in Lake Placid, New York. She played three games, and picked up her first international point – an assist, and Canada won gold. Her second World Championship in 1997 also produced a gold medal and she earned a spot on the tournament All-Star team, the first of four such honours (1997, 1999, 2000, 2005). In 1999, Wickenheiser helped Canada to another gold medal and was named tournament MVP. Wickenheiser has seven World Championship gold medals (1994, 1997, 1999, 2000, 2004, 2007, 2012) and three silver medals (2005, 2008, 2009). She was named to Team Canada in 2001, but was unable to compete due to an injury, and was also on Canada's roster for the 2003 World Championship which was canceled.
Wickenheiser was a member of Team Canada at the 1998 Winter Olympics, when women's hockey was introduced as a medal sport. She also played 21 games for Team Canada during their pre-Olympic tour. Canada won a silver medal at the event and Wickenheiser was named to the tournament all-star team. Her performance at the 1998 Olympics impressed Men's Team Canada General Manager Bobby Clarke so much, that he invited her to participate in the Philadelphia Flyers rookie camps in 1998 and 1999. 2002 was another chance at Olympic gold, and Wickenheiser was named to Canada's roster for the 2002 Winter Olympics held in Salt Lake City, Utah. On Team Canada's pre-Olympic tour, Wickenheiser played 26 games and racked up 36 points. In a bit of redemption for 1998, Canada won the gold medal by defeating Team USA in the final game. Wickenheiser was named Tournament MVP and she was the top scorer on the Women's side. At the 2006 Winter Olympics, Canada was defending its gold medal status. When the final match was set, Canada was facing off against Sweden, a surprise finalist. They won gold again, and Wickenheiser once more was named tournament MVP, Top Forward, and to a berth on the all-star team. She also led the tournament in scoring.
Wickenheiser captained Canada to a gold medal at the 1998 Christmas Cup (World Women's Under-22 Championship). She has also contributed to at least 10 gold medals for Canada at the 4 Nations Cup tournaments (1996, 1999, 2000, 2001, 2002, 2004, 2005, 2006, 2007, 2010). At the 2006 Four Nations Cup, she served as team captain.
On February 17, 2010, Wickenheiser became the all-time leading Olympic goal scorer as Canada defeated Sweden 13–1 at the Vancouver Olympics. Wickenheiser reached her record total of 16 career Olympic goals by scoring once on Wednesday as Canada followed up their 18–0 win over Slovakia and 10–1 defeat of Switzerland.
With a third and fourth consecutive Olympic gold medal in women's hockey won by defeating the United States of America 2–0 in Vancouver and 3-2 in Sochi, Hayley now has 5 Olympic medals: 4 gold, 1 silver. She is one of only five athletes to win gold in four consecutive Winter Games, along with teammates Jayna Hefford and Caroline Ouellette.
Professional.
In 2003, Wickenheiser became the first woman to score a goal playing in a men's professional league (for the Kirkkonummi Salamat team in Finland’s division II league). Over the course of the season, Wickenheiser played 23 games, scoring 2 goals and adding 10 assists. Wickenheiser joined a European league to play professional hockey, as the game is more open and less physical than North American leagues. This attempt to play professional hockey was not an entirely smooth process, as Wickenheiser was initially slated to play in Italy, until the Italian Winter Sports Federation ruled that women were ineligible to play in a men's league. She also turned down an offer from Phil Esposito to play for the Cincinnati Cyclones of the ECHL. Finland's Hockey Federation unanimously supported letting women play in a men's league, allowing her to debut with HC Salamat in the Suomi-sarja, the third highest hockey league in Finland, on January 10, 2003. Wickenheiser played briefly with Salamat in 2004. They had won promotion to Mestis, Finland's second tier of professional hockey, and this was not as good a fit for her. She left the team after ten games.
In 2007, Wickenheiser had a week-long tryout contract with Swedish club IFK Arboga IK in the Swedish male third league. After two practice games, where Wickenheiser scored two goals in the first game, she was not offered a contract. In 2008, Wickenheiser signed a one-year contract with Eskilstuna Linden, also in the Swedish men's third league.
Wickenheiser was named one of the "Top 100 Most Influential People in Hockey" by "The Hockey News" (ranked #59 on the 2011 List), one of the "25 Toughest Athletes" by "Sports Illustrated" and one of the "Top 50 Most Powerful Women in Canada" by "The Globe and Mail".
Appearing with the Calgary Inferno in the 2016 Clarkson Cup finals, she logged two assists as the Inferno emerged victorious in a convincing 8-3 final.
Club.
In 1996, Wickenheiser was named MVP of the Esso National Women's Championship, helping Alberta to a fourth-place finish. In 1997 and 1998, Wickenheiser won Nationals with the Edmonton Chimos and Calgary Oval X-Treme respectively. She was named tournament MVP both years. Between 1999 and 2001, Wickenheiser continued to play for her club teams at the Esso Women's National Championships, winning a gold medal and two silvers. She played 2004–05 with the Calgary Oval X-Treme, in the inaugural season of the Western Women's Hockey League. The X-Treme were league champions. Wickenheiser was the regular season leading scorer and named to the league's all-star team. She also played for Alberta at the Esso National Championships, where they won gold. She led the tournament in scoring and was named MVP.
University.
Wickenheiser joined the 2010–11 University of Calgary Dinos women's ice hockey season that competes in the Canadian Interuniversity Sport (CIS). The Dinos are playing their second season of CIS hockey, and Wickenheiser is expected to provide leadership to a young team. While with the Dinos, Wickenheiser will be playing for her former teammate, Danielle Goyette, who is the team's head coach. Wickenheiser will be working to complete a degree in kinesiology at Calgary. The Dinos were Wickenheiser's choice because the team practices every day, and she was able to stay in Calgary with her family. Under CIS rules, Wickenheiser began her first year of eligibility in 2010 because she had never played university hockey. Players have up to five years of eligibility. In her CIS debut against the University of Regina, Wickenheiser scored two goals and added an assist in a 4–3 victory. A crowd of over 500 people attended her CIS debut in Regina. Wickenheiser was named the Canada West female athlete of the week on November 2, 2010 after scoring three goals and adding an assist in two games against the University of Alberta. Despite only playing in 15 of the Dino's 24 regular season games, Wickenheiser finished tied for the conference lead in scoring with 40 points (17 goals and 23 assists), and finishing with a plus-minus of +22. She scored four short handed goals, and had five game winners. At the end of the year, Wickenheiser was named the Canada West Most Valuable Player, and captured a spot on the conference's First All-Star Team. On March 9, 2011, Wickenheiser was named the Canadian Interuniversity Sport player of the year in women's hockey. She then became the first ever Dino to win the Brodrick Trophy as CIS MVP.
Softball and fastball career.
Wickenheiser is an accomplished softball player. On June 24, 2000, she was named to the Canadian softball team for the 2000 Summer Olympics. This was the culmination of a long ball career. In 1994, she participated at Canadian Midget Nationals, where she was named All-Canadian Shortstop and Top Batter. In 1995, Wickenheiser was a member of Team Canada at the World Junior Fastball Championships, held in Normal, Illinois. Canada finished fifth at this event. In 1997, Wickenheiser participated at Midget Nationals with the Silver Springs 76ers. Her team finished second and Wickenheiser was again named All Star Shortstop and Top Batter. In 1999 she also participated at Senior Nationals, where her team finished fourth. In 2000 Hayley attended and competed for Simon Fraser University, and helped lead the team to a 38 and 13 record, and route to a 3rd-place finish at the NAIA National Championships. Later that summer she competed in the Summer Olympic games in Sydney, Australia, where she led Canada with the team's highest batting average. Canada was competitive, but finished the tournament with a 1–6 record, losing three games by one run. Since that Olympics, Wickenheiser has not been as active in softball.
Personal life.
Her parents are Tom, a physical-education teacher, and Marilyn. She has a brother named Ross and a sister named Jane. Wickenheiser lives in Calgary with her adopted son, Noah. Doug Wickenheiser, the first overall pick in the 1980 NHL Entry Draft, was her cousin. He died of cancer in 1999.
Wickenheiser graduated with a degree in kinesiology in 2013 and has expressed a desire to attend medical school after she is finished playing hockey. On July 15, 2011 her hometown of Shaunavon named a new 14 million dollar recreational complex after her, Crescent Point Wickenheiser Centre. On June 30, 2011, she was named an Officer of the Order of Canada by Governor General David Johnston.
Hayley is the author of "Gold Medal Diary – Inside the World's Greatest Sports Event", outlining her training with Team Canada and the events leading up to, during, and following the 2010 Olympic Games.
Game appearance.
EA Sports officially announced that Wickenheiser would be among the first two real female hockey players in "NHL 13". Along with Angela Ruggiero, she has a playable character in the game which can be added to any team of the user's choice.

</doc>
<doc id="40629" url="https://en.wikipedia.org/wiki?curid=40629" title="Marc Gagnon">
Marc Gagnon

Marc Gagnon (born May 24, 1975 in Chicoutimi, Quebec) is a Canadian short track speed skater. He is a four-time Overall World Champion for 1993, 1994, 1996 and 1998, and winner of three Olympic gold medals.
Biography.
Gagnon started his Olympic career in 1994, when he had already won the 1993 World Championships. He won a bronze in the 1000 m event. Four years later, in Nagano, Japan, Gagnon won a gold medal with the Canadian relay team. The 2002 Salt Lake City Games proved to be Gagnon's best Olympics, with a total of three medals. A bronze in the inaugural 1500 m event, and two golds; in the 500 m and again as a part of the relay team. Even his disqualification in the 1000 m was memorable, as it was the first of an improbable series of events that led to Australian Steven Bradbury winning arguably the most unlikely gold medal in Olympic history.
Winning a total of five medals in three consecutive Winter Games made him the most decorated Canadian athlete in Winter Olympic history until 2006. He has now been overtaken by long track speed skater Cindy Klassen and long track speed skater/road cyclist Clara Hughes, who each have a total of 6 medals. Tied with track and field athlete Phil Edwards and fellow short track speed skater François-Louis Tremblay, he is one of the five most decorated Canadian athletes in all Olympic Games.
Gagnon won his World Championships in 1993, 1994, 1996 and 1998. He is the first man to have become a four-time Overall World Champion. In addition, he finished 2nd twice, and third once.
In 2008, Gagnon was inducted into Canada's Sports Hall of Fame.

</doc>
<doc id="40630" url="https://en.wikipedia.org/wiki?curid=40630" title="Beach">
Beach

A beach is a landform along the coast of an ocean or sea. It usually consists of loose particles, which are often composed of rock, such as sand, gravel, shingle, pebbles, or cobblestones. The particles comprising a beach are occasionally biological in origin, such as mollusc shells or coralline algae.
Some beaches have man-made infrastructure, such as lifeguard posts, changing rooms, and showers. They may also have hospitality venues (such as resorts, camps, hotels, and restaurants) nearby. Wild beaches, also known as undeveloped or undiscovered beaches, are not developed in this manner. Wild beaches can be valued for their untouched beauty and preserved nature.
Beaches typically occur in areas along the coast where wave or current action deposits and reworks sediments.
Overview.
Although the seashore is most commonly associated with the word "beach", beaches are found by lakes and alongside large rivers.
"Beach" may refer to: 
The former are described in detail below; the larger geological units are discussed elsewhere under bars.
There are several conspicuous parts to a beach that relate to the processes that form and shape it. The part mostly above water (depending upon tide), and more or less actively influenced by the waves at some point in the tide, is termed the beach berm. The berm is the deposit of material comprising the active shoreline. The berm has a "crest" (top) and a "face" — the latter being the slope leading down towards the water from the crest. At the very bottom of the face, there may be a "trough", and further seaward one or more long shore bars: slightly raised, underwater embankments formed where the waves first start to break.
The sand deposit may extend well inland from the "berm crest", where there may be evidence of one or more older crests (the "storm beach") resulting from very large storm waves and beyond the influence of the normal waves. At some point the influence of the waves (even storm waves) on the material comprising the beach stops, and if the particles are small enough (sand size or smaller), winds shape the feature. Where wind is the force distributing the grains inland, the deposit behind the beach becomes a "dune".
These geomorphic features compose what is called the "beach profile". The beach profile changes seasonally due to the change in wave energy experienced during summer and winter months. In temperate areas where summer is characterised by calmer seas and longer periods between breaking wave crests, the beach profile is higher in summer. The gentle wave action during this season tends to transport sediment up the beach towards the berm where it is deposited and remains while the water recedes. Onshore winds carry it further inland forming and enhancing dunes.
Conversely, the beach profile is lower in the storm season (winter in temperate areas) due to the increased wave energy, and the shorter periods between breaking wave crests. Higher energy waves breaking in quick succession tend to mobilise sediment from the shallows, keeping it in suspension where it is prone to be carried along the beach by longshore currents, or carried out to sea to form longshore bars, especially if the longshore current meets an outflow from a river or flooding stream. The removal of sediment from the beach berm and dune thus decreases the beach profile.
In tropical areas, the storm season tends to be during the summer months, with calmer weather commonly associated with the winter season.
If storms coincide with unusually high tides, or with a freak wave event such as a tidal surge or tsunami which causes significant coastal flooding, substantial quantities of material may be eroded from the coastal plain or dunes behind the berm by receding water. This flow may alter the shape of the coastline, enlarge the mouths of rivers and create new deltas at the mouths of streams that had not been powerful enough to overcome longshore movement of sediment.
The line between beach and dune is difficult to define in the field. Over any significant period of time, sediment is always being exchanged between them. The "drift line" (the high point of material deposited by waves) is one potential demarcation. This would be the point at which significant wind movement of sand could occur, since the normal waves do not wet the sand beyond this area. However, the drift line is likely to move inland under assault by storm waves.
Beaches and recreation.
History.
The development of the beach as a popular leisure resort from the mid-19th century was the first manifestation of what is now the global tourist industry. The first seaside resorts were opened in the 18th century for the aristocracy, who began to frequent the seaside as well as the then fashionable spa towns, for recreation and health. One of the earliest such seaside resorts, was Scarborough in Yorkshire during the 1720s; it had been a fashionable spa town since a stream of acidic water was discovered running from one of the cliffs to the south of the town in the 17th century. The first rolling bathing machines were introduced by 1735.
The opening of the resort in Brighton and its reception of royal patronage from King George IV, extended the seaside as a resort for health and pleasure to the much larger London market, and the beach became a centre for upper-class pleasure and frivolity. This trend was praised and artistically elevated by the new romantic ideal of the picturesque landscape; Jane Austen's unfinished novel "Sanditon" is an example of that. Later, Queen Victoria's long-standing patronage of the Isle of Wight and Ramsgate in Kent ensured that a seaside residence was considered as a highly fashionable possession for those wealthy enough to afford more than one home.
Seaside resorts for the working class.
The extension of this form of leisure to the middle and working class began with the development of the railways in the 1840s, which offered cheap and affordable fares to fast growing resort towns. In particular, the completion of a branch line to the small seaside town Blackpool from Poulton led to a sustained economic and demographic boom. A sudden influx of visitors, arriving by rail, provided the motivation for entrepreneurs to build accommodation and create new attractions, leading to more visitors and a rapid cycle of growth throughout the 1850s and 1860s.
The growth was intensified by the practice among the Lancashire cotton mill owners of closing the factories for a week every year to service and repair machinery. These became known as wakes weeks. Each town's mills would close for a different week, allowing Blackpool to manage a steady and reliable stream of visitors over a prolonged period in the summer. A prominent feature of the resort was the promenade and the pleasure piers, where an eclectic variety of performances vied for the people's attention. In 1863, the North Pier in Blackpool was completed, rapidly becoming a centre of attraction for elite visitors. Central Pier was completed in 1868, with a theatre and a large open-air dance floor.
Many of the popular beach resorts were equipped with bathing machines because even the all-covering beachwear of the period was considered immodest. By the end of the century the English coastline had over 100 large resort towns, some with populations exceeding 50,000.
Expansion around the world.
The development of the seaside resort abroad was stimulated by the well developed English love of the beach. The French Riviera alongside the Mediterranean had already become a popular destination for the British upper class by the end of the 18th century. In 1864, the first railway to Nice was completed, making the Riviera accessible to visitors from all over Europe. By 1874, residents of foreign enclaves in Nice, most of whom were British, numbered 25,000. The coastline became renowned for attracting the royalty of Europe, including Queen Victoria and King Edward VII.
Continental European attitudes towards gambling and nakedness tended to be more lax than in Britain, so British and French entrepreneurs were quick to exploit the possibilities. In 1863, the Prince of Monaco, Charles III and François Blanc, a French businessman, arranged for steamships and carriages to take visitors from Nice to Monaco, where large luxury hotels, gardens and casinos were built. The place was renamed Monte Carlo.
Commercial sea bathing also spread to the United States and parts of the British Empire such as Australia where surfing was developed in the early 20th century. By the 1970s cheap and affordable air travel was the catalyst for the growth of a truly global tourism market which benefited areas such as the Spain and the South of France with sunny climates.
Today.
Beaches can be popular on warm sunny days. In the Victorian era, many popular beach resorts were equipped with bathing machines because even the all-covering beachwear of the period was considered immodest. This social standard still prevails in many Muslim countries. At the other end of the spectrum are topfree beaches and nude beaches where clothing is optional or not allowed. In most countries social norms are significantly different on a beach in hot weather, compared to adjacent areas where similar behavior might not be tolerated and might even be prosecuted.
In more than thirty countries in Europe, South Africa, New Zealand, Canada, Costa Rica, South America and the Caribbean, the best recreational beaches are awarded Blue Flag status, based on such criteria as water quality and safety provision. Subsequent loss of this status can have a severe effect on tourism revenues.
Beaches are often dumping grounds for waste and litter, necessitating the use of beach cleaners and other cleanup projects. More significantly, many beaches are a discharge zone for untreated sewage in most underdeveloped countries; even in developed countries beach closure is an occasional circumstance due to sanitary sewer overflow. In these cases of marine discharge, waterborne disease from fecal pathogens and contamination of certain marine species are a frequent outcome.
Today, there seems to be more beach goers than ever before and because of the warming of the Earth, a dermatologist may recommend the use of sunscreen as a way of protection from the sun's harmful UVA and UVB rays which can be especially harmful at the open territory of a beach.
Artificial beaches.
Some beaches are artificial; they are either permanent or temporary (For examples see Monaco, Paris, Copenhagen, Rotterdam, Nottingham, Toronto, Hong Kong, Singapore, and Tianjin).
The soothing qualities of a beach and the pleasant environment offered to the beachgoer are replicated in artificial beaches, such as "beach style" pools with zero-depth entry and wave pools that recreate the natural waves pounding upon a beach. In a zero-depth entry pool, the bottom surface slopes gradually from above water down to depth. Another approach involves so-called urban beaches, a form of public park becoming common in large cities. Urban beaches attempt to mimic natural beaches with fountains that imitate surf and mask city noises, and in some cases can be used as a play park.
Beach nourishment involves pumping sand onto beaches to improve their health. Beach nourishment is common for major beach cities around the world; however the beaches that have been nourished can still appear quite natural and often many visitors are unaware of the works undertaken to support the health of the beach. Such beaches are often not recognized (by consumers) as artificial. The Surfrider Foundation has debated the merits of artificial reefs with members torn between their desire to support natural coastal environments and opportunities to enhance the quality of surfing waves. Similar debates surround beach nourishment and snow cannon in sensitive environments.
Restrictions on access.
Public access to beaches is restricted in some parts of the world. For example, most beaches on the Jersey Shore are restricted to people who can purchase beach tags.
Also, private beaches such as those along the shores, may belong to the neighborhood association nearby. Signs are usually posted the entrance. A permit or special use occasion event may be granted upon executing the proper channels to legally obtain one.
Public access to beaches is protected by law in the U.S. State of Oregon, thanks to a 1967 state law, the Oregon Beach Bill, which guaranteed public access from the Columbia River to the California state line, "so that the public may have the free and uninterrupted use".
Beach formation.
Beaches are the result of wave action by which waves or currents move sand or other loose sediments of which the beach is made as these particles are held in suspension. Alternatively, sand may be moved by saltation (a bouncing movement of large particles).
Beach materials come from erosion of rocks offshore, as well as from headland erosion and slumping producing deposits of scree. Some of the whitest sand in the world, along Florida's Emerald Coast, comes from the erosion of quartz in the Appalachian Mountains.
A coral reef offshore is a significant source of sand particles. Some species of fish that feed on algae attached to coral outcrops and rocks can create substantial quantities of sand particles over their lifetime as they nibble during feeding, digesting the organic matter, and discarding the rock and coral particles which pass through their digestive tracts.
The composition of the beach depends upon the nature and quantity of sediments upstream of the beach, and the speed of flow and turbidity of water and wind.
Sediments are moved by moving water and wind according to their particle size and state of compaction. Particles tend to settle and compact in still water. Once compacted, they are more resistant to erosion. Established vegetation (especially species with complex network root systems) will resist erosion by slowing the fluid flow at the surface layer.
When affected by moving water or wind, particles that are eroded and held in suspension will increase the erosive power of the fluid that holds them by increasing the average density, viscosity and volume of the moving fluid.
The nature of sediments found on a beach tends to indicate the energy of the waves and wind in the locality. Coastlines facing very energetic wind and wave systems will tend to hold only large rocks as smaller particles will be held in suspension in the turbid water column and carried to calmer areas by longshore currents and tides. Coastlines that are protected from waves and winds will tend to allow finer sediments such as clays and mud to precipitate creating mud flats and mangrove forests.
The shape of a beach depends on whether the waves are constructive or destructive, and whether the material is sand or shingle.
Waves are constructive if the period between their wave crests is long enough for the breaking water to recede and the sediment to settle before the succeeding wave arrives and breaks. Fine sediment transported from lower down the beach profile will compact if the receding water percolates or soaks into the beach. Compacted sediment is more resistant to movement by turbulent water from succeeding waves.
Conversely, waves are destructive if the period between the wave crests is short. Sediment that remains in suspension when the following wave crest arrives will not be able to settle and compact and will be more susceptible to erosion by longshore currents and receding tides.
Constructive waves move material up the beach while destructive waves move the material down the beach. During seasons when destructive waves are prevalent, the shallows will carry an increased load of sediment and organic matter in suspension.
On sandy beaches, the turbulent backwash of destructive waves removes material forming a gently sloping beach. On pebble and shingle beaches the swash is dissipated more quickly because the large particle size allows greater percolation, thereby reducing the power of the backwash, and the beach remains steep.
Compacted fine sediments will form a smooth beach surface that resists wind and water erosion. During hot calm seasons, a crust may form on the surface of ocean beaches as the heat of the sun evaporates the water leaving the salt which crystallises around the sand particles. This crust forms an additional protective layer that resists wind erosion unless disturbed by animals, or dissolved by the advancing tide.
Cusps and horns form where incoming waves divide, depositing sand as horns and scouring out sand to form cusps. This forms the uneven face on some sand shorelines.
Beach erosion and accretion.
Natural erosion and accretion.
Causes.
Beaches are changed in shape chiefly by the movement of water and wind. Any weather event that is associated with turbid or fast flowing water, or high winds will erode exposed beaches. Longshore currents will tend to replenish beach sediments and repair storm damage. Tidal waterways generally change the shape of their adjacent beaches by small degrees with every tidal cycle. Over time these changes can become substantial leading to significant changes in the size and location of the beach.
Effects on flora.
Changes in the shape of the beach may undermine the roots of large trees and other flora. Many beach adapted species (such as coconut palms) have a fine root system and large root ball which tends to withstand wave and wind action and tends to stabilize beaches better than other trees with a lesser root ball.
Effects on adjacent land.
Erosion of beaches can expose less resilient soils and rocks to wind and wave action leading to undermining of coastal headlands eventually resulting in catastrophic collapse of large quantities of overburden into the shallows. This material may be distributed along the beach front leading to a change in the habitat as sea grasses and corals in the shallows may be buried or deprived of light and nutrients.
Manmade erosion and accretion.
Coastal areas settled by man inevitably become subject to the effects of man-made structures and processes. Over long periods of time these influences may substantially alter the shape of the coastline, and the character of the beach.
Destruction of flora.
Beach front flora plays a major role in stabilizing the foredunes and preventing beach head erosion and inland movement of dunes. If flora with network root systems (creepers, grasses and palms) are able to become established, they provide an effective coastal defense as they trap sand particles and rainwater and enrich the surface layer of the dunes, allowing other plant species to become established. They also protect the berm from erosion by high winds, freak waves and subsiding flood waters.
Over long periods of time, well stabilized foreshore areas will tend to accrete, while unstabilized foreshores will tend to erode, leading to substantial changes in the shape of the coastline. These changes usually occur over periods of many years. Freak wave events such as tsunami, tidal waves, and storm surges may substantially alter the shape, profile and location of a beach within hours.
Destruction of flora on the berm by the use of herbicides, excessive pedestrian or vehicular traffic, or disruption to fresh water flows may lead to erosion of the berm and dunes. While the destruction of flora may be a gradual process that is imperceptible to regular beach users, it often becomes immediately apparent after storms associated with high winds and freak wave events that can rapidly move large volumes of exposed and unstable sand, depositing them further inland, or carrying them out into the permanent water forming offshore bars, lagoons or increasing the area of the beach exposed at low tide.
Large and rapid movements of exposed sand can bury and smother flora in adjacent areas, aggravating the loss of habitat for fauna, and enlarging the area of instability. If there is an adequate supply of sand, and weather conditions do not allow vegetation to recover and stabilize the sediment, wind-blown sand can continue to advance, engulfing and permanently altering downwind landscapes.
Sediment moved by waves or receding flood waters can be deposited in coastal shallows, engulfing reed beds and changing the character of underwater flora and fauna in the coastal shallows.
Burning or clearance of vegetation on the land adjacent to the beach head, for farming and residential development, changes the surface wind patterns, and exposes the surface of the beach to wind erosion.
Farming and residential development are also commonly associated with changes in local surface water flows. If these flows are concentrated in storm water drains emptying onto the beach head, they may erode the beach creating a lagoon or delta.
Dense vegetation tends to absorb rainfall reducing the speed of runoff and releasing it over longer periods of time. Destruction by burning or clearance of the natural vegetation tends to increase the speed and erosive power of runoff from rainfall. This runoff will tend to carry more silt and organic matter from the land onto the beach and into the sea. If the flow is constant, runoff from cleared land arriving at the beach head will tend to deposit this material into the sand changing its color, odor and fauna.
Creation of beach access points.
The concentration of pedestrian and vehicular traffic accessing the beach for recreational purposes may cause increased erosion at the access points if measures are not taken to stabilize the beach surface above high-water mark. Recognition of the dangers of loss of beach front flora has caused many local authorities responsible for managing coastal areas to restrict beach access points by physical structures or legal sanctions, and fence off foredunes in an effort to protect the flora. These measures are often associated with the construction of structures at these access points to allow traffic to pass over or through the dunes without causing further damage.
Concentration of runoff.
Beaches provide a filter for runoff from the coastal plain. If the runoff is naturally dispersed along the beach, water borne silt and organic matter will be retained on the land and will feed the flora in the coastal area. Runoff that is dispersed along the beach will tend to percolate through the beach and may emerge from the beach at low tide.
The retention of the fresh water may also help to maintain underground water reserves and will resist salt water incursion. If the surface flow of the runoff is diverted and concentrated by drains that create constant flows over the beach above the sea or river level, the beach will be eroded and ultimately form an inlet unless longshore flows deposit sediments to repair the breach.
Once eroded, an inlet may allow tidal inflows of salt water to pollute areas inland from the beach and may also affect the quality of underground water supplies and the height of the water table.
Deprivation of runoff.
Some flora naturally occurring on the beach head requires fresh water runoff from the land. Diversion of fresh water runoff into drains may deprive these plants of their water supplies and allow sea water incursion, increasing the saltiness of the ground water. Species that are not able to survive in salt water may die and be replaced by mangroves or other species adapted to salty environments.
Inappropriate beach nourishment.
Beach nourishment is the importing and deposition of sand or other sediments in an effort to restore a beach that has been damaged by erosion. Beach nourishment often involves excavation of sediments from riverbeds or sand quarries. This excavated sediment may be substantially different in size and appearance to the naturally occurring beach sand.
In extreme cases, beach nourishment may involve placement of large pebbles or rocks in an effort to permanently restore a shoreline subject to constant erosion and loss of foreshore. This is often required where the flow of new sediment caused by the longshore current has been disrupted by construction of harbors, breakwaters, causeways or boat ramps, creating new current flows that scour the sand from behind these structures, and deprive the beach of restorative sediments. If the causes of the erosion are not addressed, beach nourishment can become a necessary and permanent feature of beach maintenance.
During beach nourishment activities, care must be taken to place new sediments so that the new sediments compact and stabilize before aggressive wave or wind action can erode them. Material that is concentrated too far down the beach may form a temporary groyne that will encourage scouring behind it. Sediments that are too fine or too light may be eroded before they have compacted or been integrated into the established vegetation. Foreign unwashed sediments may introduce flora or fauna that are not usually found in that locality.
Brighton Beach, on the south coast of England, is a shingle beach that has been nourished with very large pebbles in an effort to withstand erosion of the upper area of the beach. These large pebbles made the beach unwelcoming for pedestrians for a period of time until natural processes integrated the naturally occurring shingle into the pebble base.
Beach access design.
Beach access is an important consideration where substantial numbers of pedestrians or vehicles require access to the beach. Allowing random access across delicate foredunes is seldom considered good practice as it is likely to lead to destruction of flora and consequent erosion of the fore dunes.
A well designed beach access should:
Concrete ramp or steps.
A concrete ramp should follow the natural profile of the beach to prevent it from changing the normal flow of waves, longshore currents, water and wind. A ramp that is below the beach profile will tend to become buried and cease to provide a good surface for vehicular traffic. A ramp or stair that protrudes above the beach profile will tend to disrupt longshore currents creating deposits in front of the ramp, and scouring behind. Concrete ramps are the most expensive vehicular beach accesses to construct requiring use of a quick drying concrete or a coffer dam to protect them from tidal water during the concrete curing process. Concrete is favored where traffic flows are heavy and access is required by vehicles that are not adapted to soft sand (e.g. road registered passenger vehicles and boat trailers). Concrete stairs are commonly favored on beaches adjacent to population centers where beach users may arrive on the beach in street shoes, or where the foreshore roadway is substantially higher than the beach head and a ramp would be too steep for safe use by pedestrians. A composite stair ramp may incorporate a central or side stair with one or more ramps allowing pedestrians to lead buggies or small boat dollies onto the beach without the aid of a powered vehicle or winch. Concrete ramps and steps should be maintained to prevent buildup of moss or algae that may make their wet surfaces slippery and dangerous to pedestrians and vehicles.
Corduroy (beach ladder).
A corduroy or beach ladder (or board and chain) is an array of planks (usually hardwood or treated timber) laid close together and perpendicular to the direction of traffic flow, and secured at each end by a chain or cable to form a pathway or ramp over the sand dune. Corduroys are cheap and easy to construct and quick to deploy or relocate. They are commonly used for pedestrian access paths and light duty vehicular access ways. They naturally conform to the shape of the underlying beach or dune profile, and adjust well to moderate erosion, especially longshore drift. However, they can cease to be an effective access surface if they become buried or undermined by erosion by surface runoff coming from the beach head. If the corduroy is not wide enough for vehicles using it, the sediment on either side may be displaced creating a spoon drain that accelerates surface run off and can quickly lead to serious erosion. Significant erosion of the sediment beside and under the corduroy can render it completely ineffective and make it dangerous to pedestrian users who may fall between the planks.
Fabric ramp.
Fabric ramps are commonly employed by the military for temporary purposes where the underlying sediment is stable and hard enough to support the weight of the traffic. A sheet of porous fabric is laid over the sand to stabilize the surface and prevent vehicles from bogging. Fabric Ramps usually cease to be useful after one tidal cycle as they are easily washed away, or buried in sediment.
Foliage ramp.
A foliage ramp is formed by planting resilient species of hardy plants such as grasses over a well formed sediment ramp. The plants may be supported while they become established by placement of layers of mesh, netting, or coarse organic material such as vines or branches. This type of ramp is ideally suited for intermittent use by vehicles with a low wheel loading such as dune buggies or agricultural vehicles with large tyres. A foliage ramp should require minimal maintenance if initially formed to follow the beach profile, and not overused.
Gravel ramp.
A gravel ramp is formed by excavating the underlying loose sediment and filling the excavation with layers of gravel of graduated sizes as defined by John Loudon McAdam. The gravel is compacted to form a solid surface according to the needs of the traffic. Gravel ramps are less expensive to construct than concrete ramps and are able to carry heavy road traffic provided the excavation is deep enough to reach solid subsoil. Gravel ramps are subject to erosion by water. If the edges are retained with boards or walls and the profile matches the surrounding beach profile, a gravel ramp may become more stable as finer sediments are deposited by percolating water.
Longest beaches.
Amongst the world's longest beaches are:-
Beach wildlife.
A beach is an unstable environment that exposes plants and animals to changeable and potentially harsh conditions. Some animals burrow into the sand and feed on material deposited by the waves. Crabs, insects and shorebirds feed on these beach dwellers. The endangered piping plover and some tern species rely on beaches for nesting. Sea turtles also bury their eggs in ocean beaches. Seagrasses and other beach plants grow on undisturbed areas of the beach and dunes.
Ocean beaches are habitats with organisms adapted to salt spray, tidal overwash, and shifting sands. Some of these organisms are found only on beaches. Examples of these beach organisms in the southeast US include plants like sea oats, sea rocket, beach elder, beach morning glory ("Ipomoea pes-caprae"), and beach peanut, and animals such as mole crabs ("Hippoidea"), coquina clams ("Donax"), ghost crabs, and white beach tiger beetles.

</doc>
<doc id="40633" url="https://en.wikipedia.org/wiki?curid=40633" title="Redundancy">
Redundancy

Redundancy or redundant may refer to:

</doc>
<doc id="40634" url="https://en.wikipedia.org/wiki?curid=40634" title="Convex hull">
Convex hull

In mathematics, the convex hull or convex envelope of a set "X" of points in the Euclidean plane or Euclidean space is the smallest convex set that contains "X". For instance, when "X" is a bounded subset of the plane, the convex hull may be visualized as the shape enclosed by a rubber band stretched around "X".
Formally, the convex hull may be defined as the intersection of all convex sets containing "X" or as the set of all convex combinations of points in "X". With the latter definition, convex hulls may be extended from Euclidean spaces to arbitrary real vector spaces; they may also be generalized further, to oriented matroids.
The algorithmic problem of finding the convex hull of a finite set of points in the plane or other low-dimensional Euclidean spaces is one of the fundamental problems of computational geometry.
Definitions.
A set of points is defined to be convex if it contains the line segments connecting each pair of its points. The convex hull of a given set "X" may be defined as
It is not obvious that the first definition makes sense: why should there exist a unique minimal convex set containing "X", for every "X"? However, the second definition, the intersection of all convex sets containing "X" is well-defined, and it is a subset of every other convex set "Y" that contains "X", because "Y" is included among the sets being intersected. Thus, it is exactly the unique minimal convex set containing "X". Each convex set containing "X" must (by the assumption that it is convex) contain all convex combinations of points in "X", so the set of all convex combinations is contained in the intersection of all convex sets containing "X". Conversely, the set of all convex combinations is itself a convex set containing "X", so it also contains the intersection of all convex sets containing "X", and therefore the sets given by these two definitions must be equal.
In fact, according to Carathéodory's theorem, if "X" is a subset of an "N"-dimensional vector space, convex combinations of at most "N" + 1 points are sufficient in the definition above. Therefore, the convex hull of a set "X" of three or more points in the plane is the union of all the triangles determined by triples of points from "X", and more generally in "N"-dimensional space the convex hull is the union of the simplices determined by at most "N" + 1 vertices from X.
If the convex hull of "X" is a closed set (as happens, for instance, if "X" is a finite set or more generally a compact set), then it is the intersection of all closed half-spaces containing "X". The hyperplane separation theorem proves that in this case, each point not in the convex hull can be separated from the convex hull by a half-space. However, there exist convex sets, and convex hulls of sets, that cannot be represented in this way. One example is an open halfspace together with a single point on its boundary.
More abstractly, the convex-hull operator Conv() has the characteristic properties of a closure operator:
Convex hull of a finite point set.
The convex hull of a finite point set formula_1 is the set of all convex combinations of its points. In a convex combination, each point formula_2 in formula_1 is assigned a weight or coefficient formula_4 in such a way that the coefficients are all non-negative and sum to one, and these weights are used to compute a weighted average of the points. For each choice of coefficients, the resulting convex combination is a point in the convex hull, and the whole convex hull can be formed by choosing coefficients in all possible ways. Expressing this as a single formula, the convex hull is the set:
The convex hull of a finite point set formula_6 forms a convex polygon when "n" = 2, or more generally a convex polytope in formula_7. Each point formula_2 in formula_1 that is not in the convex hull of the other points (that is, such that formula_10) is called a vertex of formula_11. In fact, every convex polytope in formula_7 is the convex hull of its vertices.
If the points of formula_1 are all on a line, the convex hull is the line segment joining the outermost two points.
When the set formula_1 is a nonempty finite subset of the plane (that is, two-dimensional), we may imagine stretching a rubber band so that it surrounds the entire set formula_1 and then releasing it, allowing it to contract; when it becomes taut, it encloses the convex hull of formula_1.
In two dimensions, the convex hull is sometimes partitioned into two polygonal chains, the upper hull and the lower hull, stretching between the leftmost and rightmost points of the hull. More generally, for points in any dimension in general position, each facet of the convex hull is either oriented upwards (separating the hull from points directly above it) or downwards; the union of the upward-facing facets forms a topological disk, the upper hull, and similarly the union of the downward-facing facets forms the lower hull.
Computation of convex hulls.
In computational geometry, a number of algorithms are known for computing the convex hull for a finite set of points and for other geometric objects.
Computing the convex hull means constructing an unambiguous, efficient representation of the required convex shape. The complexity of the corresponding algorithms is usually estimated in terms of n, the number of input points, and h, the number of points on the convex hull.
For points in two and three dimensions, output-sensitive algorithms are known that compute the convex hull in time O("n" log "h"). For dimensions "d" higher than 3, the time for computing the convex hull is formula_17, matching the worst-case output complexity of the problem.
Minkowski addition and convex hulls.
The operation of taking convex hulls behaves well with respect to the Minkowski addition of sets.
More generally, the "Minkowski sum" of a finite family of (non-empty) sets Sn is the set formed by element-wise addition of vectors
This result holds more generally for each finite collection of non-empty sets
In other words, the operations of Minkowski summation and of forming convex hulls are commuting operations.
These results show that "Minkowski addition" differs from the "union "operation of set theory; indeed, the union of two convex sets need "not" be convex: The inclusion Conv(S) ∪ Conv(T) ⊆ Conv(S ∪ T) is generally strict. The convex-hull operation is needed for the set of convex sets to form a lattice, in which the ""join"" operation is the convex hull of the union of two convex sets
Relations to other structures.
The Delaunay triangulation of a point set and its dual, the Voronoi diagram, are mathematically related to convex hulls: the Delaunay triangulation of a point set in R"n" can be viewed as the projection of a convex hull in R"n"+1.
Topologically, the convex hull of an open set is always itself open, and the convex hull of a compact set is always itself compact; however, there exist closed sets for which the convex hull is not closed. For instance, the closed set
has the open upper half-plane as its convex hull.
Applications.
The problem of finding convex hulls finds its practical applications in pattern recognition, image processing, statistics, geographic information system, game theory, construction of phase diagrams, and static code analysis by abstract interpretation. It also serves as a tool, a building block for a number of other computational-geometric algorithms such as the rotating calipers method for computing the width and diameter of a point set.
The convex hull is commonly known as the minimum convex polygon (MCP) in ethology, where it is a classic, though perhaps simplistic, approach in estimating an animal's home range based on points where the animal has been observed. Outliers can make the MCP excessively large, which has motivated relaxed approaches that contain only a subset of the observations (e.g., find an MCP that contains at least 95% of the points).

</doc>
<doc id="40642" url="https://en.wikipedia.org/wiki?curid=40642" title="NeXTSTEP">
NeXTSTEP

NeXTSTEP is a discontinued object-oriented, multitasking operating system based on UNIX. It was developed by NeXT Computer in the late 1980s and early 1990s and was initially used for its range of proprietary workstation computers such as the NeXTcube and later ported to several other computer architectures. Although relatively unsuccessful at the time, it attracted interest from computer scientists and researchers. It was used as the original platform for the development of the Electronic AppWrapper, the first commercial electronic software distribution catalog to collectively manage encryption and provide digital rights for apps and digital media, a forerunner of the modern 'App Store' concept. It was also the platform on which Tim Berners-Lee created the first web browser. After the purchase of NeXT by Apple, it became the source of the popular operating systems OS X, iOS, and now watchOS and tvOS. Many bundled OS X apps, such as TextEdit, Mail and Chess, are descendants of NeXTSTEP applications.
Overview.
NeXTSTEP (also stylized as NeXTstep, NeXTStep, and NEXTSTEP) is a combination of several parts:
NeXTSTEP is notable for having been a preeminent implementation of the latter three items. The toolkits offer considerable power, and are the canonical development system for all of the software on the machine.
NeXTSTEP's user interface is considered to be refined and consistent. It introduced the idea of the Dock (carried through OpenStep and into today's OS X) and the Shelf. NeXTSTEP also originated or innovated a large number of other GUI concepts which became common in other operating systems: 3D "chiseled" widgets, large full-color icons, system-wide drag and drop of a wide range of objects beyond file icons, system-wide piped services, real-time scrolling and window dragging, properties dialog boxes called "inspectors", and window modification notices (such as the saved status of a file). The system is among the first general-purpose user interfaces to handle publishing color standards, transparency, sophisticated sound and music processing (through a Motorola 56000 DSP), advanced graphics primitives, internationalization, and modern typography, in a consistent manner across all applications.
Additional kits were added to the product line to make the system more attractive. These include Portable Distributed Objects (PDO), which allow easy remote invocation, and Enterprise Objects Framework, a powerful object-relational database system. The kits made the system particularly interesting to custom application programmers, and NeXTSTEP had a long history in the financial programming community.
History.
A preview release of NeXTSTEP (version 0.8) was shown with the launch of the NeXT Computer on October 12, 1988. The first full release, NeXTSTEP 1.0, shipped on September 18, 1989. The last version, 3.3, was released in early 1995, by which time it ran on not only the Motorola 68000 family processors used in NeXT computers, but also on Intel x86, Sun SPARC, and HP PA-RISC-based systems.
NeXTSTEP was later modified to separate the underlying operating system from the higher-level object libraries. The result was the OpenStep API, which ran on multiple underlying operating systems, including NeXT's own OPENSTEP, Windows NT and SUN Solaris. NeXTSTEP's legacy stands today in the form of its direct descendents, Apple's OS X and iOS operating systems.
UNIX.
From day one, the operating system of NeXTSTEP was built upon Mach/BSD.
Legacy.
The first web browser, WorldWideWeb, and the first ever app store were both invented on the NeXTSTEP platform.
Some features and keyboard shortcuts now commonly found in web browsers can be traced back to NeXTSTEP conventions. The basic layout options of HTML 1.0 and 2.0 are attributable to those features available in NeXT's Text class.
Features seen first on NeXTStep:
In the 1990s, the pioneering PC games "Wolfenstein 3D", "Doom" (with its WAD level editor), "Doom II", and "Quake" (with its respective level editor) were developed by id Software on NeXT machines. Other games based on the "Doom" engine such as "Heretic" and its sequel "Hexen" by Raven Software as well as "Strife" by Rogue Entertainment were also developed on NeXT hardware using id's tools.
Altsys made a NeXTSTEP application called Virtuoso, version 2 of which was ported to Mac OS and Windows to become Macromedia FreeHand version 4. The modern "Notebook" interface for Mathematica, and the advanced spreadsheet Lotus Improv, were developed using NeXTSTEP. The software that controlled MCI's Friends and Family calling plan program was developed using NeXTSTEP.
About the time of the release of NeXTSTEP 3.2, NeXT partnered with Sun Microsystems to develop OpenStep. It is the product of an effort to separate the underlying operating system from the higher-level object libraries to create a cross-platform object-oriented API standard derived from NeXTSTEP. The OpenStep API targets multiple underlying operating systems, including NeXT's own OPENSTEP. Implementations of that standard were released for Sun's Solaris, Windows NT, and NeXT's version of the Mach kernel. NeXT's implementation is called "OPENSTEP for Mach" and its first release (4.0) superseded NeXTSTEP 3.3 on NeXT, Sun and Intel IA-32 systems.
Following an announcement on December 20, 1996, Apple Computer acquired NeXT on February 4, 1997 for $429 million. Based upon the "OPENSTEP for Mach" operating system, and developing the OPENSTEP API to become Cocoa, Apple created the basis of OS X, and eventually, in turn, of iOS.
A free software implementation of the OpenStep standard, GNUstep, also exists.
Release history.
Versions up to 4.1 are general releases. OPENSTEP 4.2 pre-release 2 is a bug-fix release published by Apple and was supported for five years after its September 1997 release.

</doc>
<doc id="40643" url="https://en.wikipedia.org/wiki?curid=40643" title="Non-uniform memory access">
Non-uniform memory access

Non-uniform memory access (NUMA) is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to the processor. Under NUMA, a processor can access its own local memory faster than non-local memory (memory local to another processor or memory shared between processors). The benefits of NUMA are limited to particular workloads, notably on servers where the data are often associated strongly with certain tasks or users.
NUMA architectures logically follow in scaling from symmetric multiprocessing (SMP) architectures. They were developed commercially during the 1990s by Burroughs (later Unisys), Convex Computer (later Hewlett-Packard), Honeywell Information Systems Italy (HISI) (later Groupe Bull), Silicon Graphics (later Silicon Graphics International), Sequent Computer Systems (later IBM), Data General (later EMC), and Digital (later Compaq, now HP). Techniques developed by these companies later featured in a variety of Unix-like operating systems, and to an extent in Windows NT.
The first commercial implementation of a NUMA-based Unix system was the Symmetrical Multi Processing XPS-100 family of servers, designed by Dan Gielan of VAST Corporation for Honeywell Information Systems Italy.
Basic concept.
Modern CPUs operate considerably faster than the main memory they use. In the early days of computing and data processing, the CPU generally ran slower than its own memory. The performance lines of processors and memory crossed in the 1960s with the advent of the first supercomputers. Since then, CPUs increasingly have found themselves "starved for data" and having to stall while waiting for data to arrive from memory. Many supercomputer designs of the 1980s and 1990s focused on providing high-speed memory access as opposed to faster processors, allowing the computers to work on large data sets at speeds other systems could not approach.
Limiting the number of memory accesses provided the key to extracting high performance from a modern computer. For commodity processors, this meant installing an ever-increasing amount of high-speed cache memory and using increasingly sophisticated algorithms to avoid cache misses. But the dramatic increase in size of the operating systems and of the applications run on them has generally overwhelmed these cache-processing improvements. Multi-processor systems without NUMA make the problem considerably worse. Now a system can starve several processors at the same time, notably because only one processor can access the computer's memory at a time.
NUMA attempts to address this problem by providing separate memory for each processor, avoiding the performance hit when several processors attempt to address the same memory. For problems involving spread data (common for servers and similar applications), NUMA can improve the performance over a single shared memory by a factor of roughly the number of processors (or separate memory banks). Another approach to addressing this problem, utilized mainly by non-NUMA systems, is the multi-channel memory architecture; multiple memory channels are increasing the number of simultaneous memory accesses.
Of course, not all data ends up confined to a single task, which means that more than one processor may require the same data. To handle these cases, NUMA systems include additional hardware or software to move data between memory banks. This operation slows the processors attached to those banks, so the overall speed increase due to NUMA depends heavily on the nature of the running tasks.
AMD implemented NUMA with its Opteron processor (2003), using HyperTransport. Intel announced NUMA compatibility for its x86 and Itanium servers in late 2007 with its Nehalem and Tukwila CPUs. Both CPU families share a common chipset; the interconnection is called Intel Quick Path Interconnect (QPI). 
Cache coherent NUMA (ccNUMA).
Nearly all CPU architectures use a small amount of very fast non-shared memory known as cache to exploit locality of reference in memory accesses. With NUMA, maintaining cache coherence across shared memory has a significant overhead. Although simpler to design and build, non-cache-coherent NUMA systems become prohibitively complex to program in the standard von Neumann architecture programming model.
Typically, ccNUMA uses inter-processor communication between cache controllers to keep a consistent memory image when more than one cache stores the same memory location. For this reason, ccNUMA may perform poorly when multiple processors attempt to access the same memory area in rapid succession. Support for NUMA in operating systems attempts to reduce the frequency of this kind of access by allocating processors and memory in NUMA-friendly ways and by avoiding scheduling and locking algorithms that make NUMA-unfriendly accesses necessary.
Alternatively, cache coherency protocols such as the MESIF protocol attempt to reduce the communication required to maintain cache coherency. Scalable Coherent Interface (SCI) is an IEEE standard defining a directory-based cache coherency protocol to avoid scalability limitations found in earlier multiprocessor systems. For example, SCI is used as the basis for the NumaConnect technology.
As of 2011, ccNUMA systems are multiprocessor systems based on the AMD Opteron processor, which can be implemented without external logic, and the Intel Itanium processor, which requires the chipset to support NUMA. Examples of ccNUMA-enabled chipsets are the SGI Shub (Super hub), the Intel E8870, the HP sx2000 (used in the Integrity and Superdome servers), and those found in NEC Itanium-based systems. Earlier ccNUMA systems such as those from Silicon Graphics were based on MIPS processors and the DEC Alpha 21364 (EV7) processor.
NUMA vs. cluster computing.
One can view NUMA as a tightly coupled form of cluster computing. The addition of virtual memory paging to a cluster architecture can allow the implementation of NUMA entirely in software. However, the inter-node latency of software-based NUMA remains several orders of magnitude greater (slower) than that of hardware-based NUMA.
Software support.
Since NUMA largely influences memory access performance, certain software optimizations are needed to allow scheduling threads and processes close to their in-memory data.

</doc>
<doc id="40645" url="https://en.wikipedia.org/wiki?curid=40645" title="Haar measure">
Haar measure

In mathematical analysis, the Haar measure assigns an "invariant volume" to subsets of locally compact topological groups, consequently defining an integral for functions on those groups.
This measure was introduced by Alfréd Haar in 1933. Haar measures are used in many parts of analysis, number theory, group theory, representation theory, statistics, and ergodic theory.
Preliminaries.
Let ("G.") be a locally compact Hausdorff topological group. The σ-algebra generated by all open sets of "G" is called the Borel algebra. An element of the Borel algebra is called a Borel set. If "g" is an element of "G" and "S" is a subset of "G", then we define the left and right translates of "S" as follows:
Left and right translates map Borel sets into Borel sets.
A measure μ on the Borel subsets of "G" is called "left-translation-invariant" if for all Borel subsets "S" of "G" and all "g" in "G" one has
A similar definition is made for right translation invariance.
Haar's theorem.
There is, up to a positive multiplicative constant, a unique countably additive, nontrivial measure μ on the Borel subsets of "G" satisfying the following properties:
Such a measure on "G" is called a "left Haar measure." It can be shown as a consequence of the above properties that μ("U") > 0 for every non-empty open subset "U". In particular, if "G" is compact then μ("G") is finite and positive, so we can uniquely specify a left Haar measure on "G" by adding the normalization condition μ("G") = 1.
Some authors define a Haar measure on Baire sets rather than Borel sets. This makes the regularity conditions unnecessary as Baire measures are automatically regular. Halmos rather confusingly uses the term "Borel set" for elements of the σ-ring generated by compact sets, and defines Haar measure on these sets.
The left Haar measure satisfies the inner regularity condition for all σ-finite Borel sets, but may not be inner regular for "all" Borel sets. For example, the product of the unit circle (with its usual topology) and the real line with the discrete topology is a locally compact group with the product topology and Haar measure on this group is not inner regular for the closed subset {1} x [0,1]. (Compact subsets of this vertical segment are finite sets and points have measure 0, so the measure of any compact subset of this vertical segment is 0. But, using outer regularity, one can show the segment has infinite measure.)
The existence and uniqueness (up to scaling) of a left Haar measure was first proven in full generality by André Weil. Weil's proof used the axiom of choice and Henri Cartan furnished a proof which avoided its use. Cartan's proof also proves the existence and the uniqueness simultaneously. A simplified and complete account of Cartan's argument was given by Alfsen in 1963. The special case of invariant measure for second countable locally compact groups had been shown by Haar in 1933.
Construction of Haar measure.
A construction using compact subsets.
The following method of constructing Haar measure is more or less the method used by Haar and Weil.
For any subsets "T", "U" of "G" with "U" nonempty define ["T":"U"] to be the smallest number of left translates of "U" that cover "T" (so this is a non-negative integer or infinity). This is not additive on compact sets "T", though it does have the property that ["S":"U"]+["T":"U"]=["S"∪"T":"U"] for disjoint compact sets "S" and "T" provided that "U" is a sufficiently small open neighborhood of the identity (depending on "S" and "T"). The idea of Haar measure is to take a sort of limit of ["T":"U"] as "U" becomes smaller to make it additive on all pairs of disjoint compact sets, though it first has to be normalized so that the limit is not just infinity. So fix a compact set "A" with non-empty interior (which exists as the group is locally compact) and for a compact set "T" define
where the limit is taken over a suitable directed set of open neighborhoods of the identity eventually contained in any given neighborhood; the existence of a directed set such that the limit exists follows using Tychonoff's theorem.
The function μ"A" is additive on disjoint compact sets of "G", which implies that it is a regular content. From a regular content one can construct a measure by first extending μ"A" to open sets by inner regularity, then to all sets by outer regularity, and then restricting it to Borel sets. (Even for open sets "T", the corresponding measure μ"A"("T") need not be given by the lim sup formula above. The problem is that the function given by the lim sup formula is not countably subadditive in general and in particular is infinite on any set without compact closure, so is not an outer measure.)
A construction using compactly supported functions.
Cartan introduced another way of constructing Haar measure as a Radon measure (a positive linear functional on compactly supported continuous functions) which is similar to the construction above except that "A", "S", "T", and "U" are positive continuous functions of compact support rather than subsets of "G". In this case we define ["T":"U"] to be the infimum of numbers "c"1+...+"c""n" such that "T"("g") is less than the linear combination "c"1"U"("g"1"g")+...+"c""n""U"("g""n""g") of left translates of "U" for some "g"1...,"g""n".
As before we define
The fact that the limit exists takes some effort to prove, though the advantage of doing this is that the proof avoids the use of the axiom of choice and also gives uniqueness of Haar measure as a by-product. The functional μA extends to a positive linear functional on compactly supported continuous functions and so gives a Haar measure. (Note that even though the limit is linear in "T", the individual terms ["T":"U"] are not usually linear in "T".)
A construction using mean values of functions.
Von Neumann gave a method of constructing Haar measure using mean values of functions, though it only works for compact groups. The idea is that given a function "f" on a compact group, one can find a convex combination Σ"a""i""f"("g""i""g") (where Σ"a""i"=1) of its left translates that differs from a constant function by at most some small number ε. Then one shows that as ε tends to zero the values of these constant functions tend to a limit, which is called the mean value (or integral) of the function "f".
For groups that are locally compact but not compact this construction does not give Haar measure as the mean value of compactly supported functions is zero. However something like it does work for almost periodic functions on the group which do have a mean value, though this is not given by with respect to Haar measure.
A construction on Lie groups.
On an "n"-dimensional Lie group, Haar measure can be constructed easily as the measure induced by a left-invariant "n"-form. This was known before Haar's theorem.
The right Haar measure.
It can also be proved that there exists a unique (up to multiplication by a positive constant) right-translation-invariant Borel measure formula_8 satisfying the above regularity conditions and being finite on compact sets, but it need not coincide with the left-translation-invariant measure formula_9. The left and right Haar measures are the same only for so-called "unimodular groups" (see below). It is quite simple, though, to find a relationship between formula_9 and formula_11.
Indeed, for a Borel set "S", let us denote by formula_12 the set of inverses of elements of "S". If we define 
then this is a right Haar measure. To show right invariance, apply the definition:
Because the right measure is unique, it follows that μ-1 is a multiple of ν and so
for all Borel sets "S", where "k" is some positive constant.
The modular function.
The "left" translate of a right Haar measure is a right Haar measure. More precisely, if ν is a right Haar measure, then
is also right invariant. Thus, by uniqueness of the Haar measure, there exists a function Δ from the group to the positive reals, called the Haar modulus, modular function or modular character, such that for every Borel set "S"
Since right Haar measure is well-defined up to a positive scaling factor, this equation shows the modular function is independent of the choice of right Haar measure in the above equation.
The modular function is a continuous group homomorphism into the multiplicative group of positive real numbers. A group is called unimodular if the modular function is identically 1, or, equivalently, if the Haar measure is both left and right invariant. Examples of unimodular groups are abelian groups, compact groups, discrete groups (e.g., finite groups), semisimple Lie groups and connected nilpotent Lie groups. An example of a non-unimodular group is the group of affine transformations
on the real line. This example shows that a solvable Lie group need not be unimodular.
In this group a left Haar measure is given by "dadb"/"a"2, and a right Haar measure by "dadb"/|"a"|.
Measures on homogeneous spaces.
If the locally compact group "G" acts transitively on a space "G"/"H", one can ask if this space has an invariant measure, or more generally a relatively invariant measure with the property that μ("gE") = χ("g")μ("E") for some character χ of "G". A necessary and sufficient condition for the existence of such a measure is that χ=Δ/δ on "H", where Δ and δ are the modular functions of "G" and "H". 
In particular an invariant measure on "Q" exists if and only if the modular function of "G" restricted to "H" is the modular function of "H".
Example. If "G" is the group "SL"2(R) and "H" the subgroup of upper triangular matrices, then the modular function of "H" is nontrivial but the modular function of "G" is trivial. The quotient of these cannot be extended to any character of "G", so the quotient space "G"/"H" (which can be thought of as 1-dimensional real projective space) does not even have a relatively invariant measure.
Haar integral.
Using the general theory of Lebesgue integration, one can then define an integral for all Borel measurable functions "f" on "G". This integral is called the Haar integral. If μ is a left Haar measure, then
for any integrable function "f". This is immediate for indicator functions, being essentially the definition of left invariance.
Uses.
In the same issue of "Annals of Mathematics" and immediately after Haar's paper, the Haar theorem was used to solve Hilbert's fifth problem for compact groups by John von Neumann.
Unless "G" is a discrete group, it is impossible to define a countably additive left-invariant regular measure on "all" subsets of "G", assuming the axiom of choice, according to the theory of non-measurable sets.
Abstract harmonic analysis.
The Haar measures are used in harmonic analysis on locally compact groups, particularly in the theory of Pontryagin duality. To prove the existence of a Haar measure on a locally compact group "G" it suffices to exhibit a left-invariant Radon measure on "G".
Mathematical statistics.
In mathematical statistics, Haar measures are used for prior measures, which are prior probabilities for compact groups of transformations. These prior measures are used to construct admissible procedures, by appeal to the characterization of admissible procedures as Bayesian procedures (or limits of Bayesian procedures) by Wald. For example, a right Haar measure for a family of distributions with a location parameter results in the Pitman estimator, which is best equivariant. When left and right Haar measures differ, the right measure is usually preferred as a prior distribution. For the group of affine transformations on the parameter space of the normal distribution, the right Haar measure is the Jeffreys prior measure. Unfortunately, even right Haar measures sometimes result in useless priors, which cannot be recommended for practical use, like other methods of constructing prior measures that avoid subjective information.
Another use of Haar measure in statistics is in conditional inference, in which the sampling distribution of a statistic is conditioned on another statistic of the data. In invariant-theoretic conditional inference, the sampling distribution is conditioned on an invariant of the group of transformations (with respect to which the Haar measure is defined). The result of conditioning sometimes depends on the order in which invariants are used and on the choice of a maximal invariant, so that by itself a statistical principle of invariance fails to select any unique best conditional statistic (if any exist); at least another principle is needed.
For non-compact groups, statisticians have extended Haar-measure results using amenable groups.
Weil's converse theorem.
In 1936 Weil proved a converse (of sorts) to Haar's theorem, by showing that if a group has a left invariant measure for which one can define a convolution product, then one can define a topology on the group, and the completion of the group is locally compact and the given measure is essentially the same as Haar measure on this completion.

</doc>
<doc id="40647" url="https://en.wikipedia.org/wiki?curid=40647" title="Viggo Brun">
Viggo Brun

Viggo Brun (13 October 1885, Lier – 15 August 1978, Drøbak) was a Norwegian mathematician.
He studied at the University of Oslo and began research at the University of Göttingen in 1910. In 1923, Brun became a professor at the Technical University in Trondheim and in 1946 a professor at the University of Oslo. He retired in 1955 at the age of 70.
In 1915, he introduced a new method, based on Legendre's version of the sieve of Eratosthenes, now known as the "Brun sieve", which addresses additive problems such as Goldbach's conjecture and the twin prime conjecture. He used it to prove that there exist infinitely many integers "n" such that "n" and "n"+2 have at most nine prime factors, and that all large even integers are the sum of two numbers with at most nine prime factors.
He also showed that the sum of the reciprocals of twin primes converges to a finite value, now called Brun's constant: by contrast, the sum of the reciprocals of all primes is divergent. 
He developed a multi-dimensional continued fraction algorithm in 1919–1920 and applied this to problems in musical theory.
He also served as praeses of the Royal Norwegian Society of Sciences and Letters in 1946.

</doc>
