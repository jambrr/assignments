<doc id="42636" url="https://en.wikipedia.org/wiki?curid=42636" title="Hubert Humphrey">
Hubert Humphrey

Hubert Horatio Humphrey Jr. (May 27, 1911January 13, 1978) was an American politician who served as the 38th Vice President of the United States under President Lyndon B. Johnson, from 1965 to 1969. Humphrey twice served in the United States Senate, representing Minnesota from 1949 to 1964 and 1971 to 1978. He was the nominee of the Democratic Party in the 1968 presidential election, losing to the Republican nominee, Richard M. Nixon.
Born in Wallace, South Dakota, Humphrey attended the University of Minnesota before earning his pharmacist license from the Capitol College of Pharmacy in 1931. He helped run his father's pharmacy until 1937 when he returned to academia, graduating with his masters from Louisiana State University in 1940, where he was a political science instructor. He returned to Minnesota during World War II and became a supervisor for the Works Progress Administration. He was then appointed state director of the Minnesota war service program before becoming the assistant director of the War Manpower Commission. In 1943, Humphrey became a Professor of political science at Macalester College and ran a failed campaign for Mayor of Minneapolis. Humphrey helped found the Minnesota Democratic–Farmer–Labor Party (DFL) in 1944, and in 1945, became the DFL candidate for Mayor of Minneapolis for a second time, winning with 61% of the vote. Humphrey served as mayor from 1945 to 1948, he was reelected and became the co-founder of the liberal anti-communism group Americans for Democratic Action in 1947.
Humphrey was elected to the Senate in 1948, the year his proposal of ending racial segregation was included into the party platform at the Democratic National Convention, where he gave one of his most notable speeches on the convention floor, suggesting the Democratic Party "walk into the sunshine of human rights." He served three terms in the Senate from 1949 to 1964 and was the Democratic Majority Whip from 1961 to 1964. During his tenure, Humphrey was the lead author of the Civil Rights Act of 1964, introduced the first initiative to create the Peace Corps, sponsored the clause of the McCarran Act to threaten concentration camps for 'subversives', proposed making Communist Party membership a felony and chaired the Select Committee on Disarmament.
Humphrey ran two failed campaigns for President in the 1952 and 1960 Democratic primaries. Lyndon B. Johnson became President on November 22, 1963, after the assassination of President John F. Kennedy. Johnson received the Democratic nomination for President in 1964, and he chose Humphrey as his vice presidential running mate, and both were elected in a landslide victory in the 1964 presidential election.
After Johnson made the surprise announcement that he would not seek reelection in March 1968, Humphrey launched his campaign for the presidency the following month. Humphrey's main Democratic challengers were anti-Vietnam War Senators Eugene McCarthy and Robert F. Kennedy. Humphrey, who was loyal to the Johnson administration's policies on the Vietnam War as Vice President, saw opposition from many within his own party and avoided the primaries to focus on receiving the delegates of non-primary states at the Democratic Convention. Humphrey's delegate strategy succeeded in clinching the nomination, choosing Senator Edmund Muskie as his running mate. With the assassination of civil rights leader Martin Luther King Jr. and Robert Kennedy that year, and heightened opposition to the Vietnam War, the convention saw major protests which later proved costly to Humphrey's campaign. On November 5, 1968, Humphrey lost to former Vice President Richard Nixon in the general election.
Humphrey then returned to teaching in Minnesota before returning to the Senate in 1971. He became the first Deputy President pro tempore of the senate and served in his seat until his death in 1978. Humphrey died of bladder cancer at his home in Waverly, Minnesota, and is buried at the Lakewood Cemetery in Minneapolis. He was succeeded by his wife of forty-one years Muriel Humphrey as the interim Senator for Minnesota.
Early life and education.
Humphrey was born in a room over his father's drugstore in Wallace, South Dakota. He was the son of Ragnild Kristine Sannes (1883–1973), a Norwegian immigrant, and Hubert Humphrey Sr. (1882–1949). Humphrey spent most of his youth in Doland, South Dakota, on the Dakota prairie; the town's population was about 600 people when he lived there. His father was a licensed pharmacist who served as mayor and a town council member; he also served briefly in the South Dakota state legislature and was a South Dakota delegate to the 1944 and 1948 Democratic National Conventions. In the late 1920s, a severe economic downturn hit Doland; both of the town's banks closed and Humphrey's father struggled to keep his drugstore open.
After his son graduated from Doland's high school, Hubert Humphrey Sr. left Doland and opened a new drugstore in the larger town of Huron, South Dakota, (population 11,000), where he hoped to improve his fortunes. Because of the family's financial struggles, Humphrey had to leave the University of Minnesota after just one year. He earned a pharmacist's license from the Capitol College of Pharmacy in Denver, Colorado (completing a two-year licensure program in just six months), and spent the years from 1931 to 1937 helping his father run the family drugstore. Both father and son were innovative businessmen in finding ways to attract customers to their drugstore: "to supplement their business, the Humphreys had become manufacturers...of patent medicines for both hogs and humans. A sign featuring a wooden pig was hung over the drugstore to tell the public about this unusual service. Farmers got the message, and it was Humphrey's that became known as the farmer's drugstore." One biographer noted that "while Hubert Jr. minded the store and stirred the concoctions in the basement, Hubert Sr. went on the road selling "Humphrey's BTV" (Body Tone Veterinary), a mineral supplement and dewormer for hogs, and "Humphrey's Chest Oil" and "Humphrey's Sniffles" for two-legged sufferers." Humphrey himself later wrote that "we made "Humphrey's Sniffles", a substitute for Vick's Nose Drops. I felt ours were better. Vick's used mineral oil, which is not absorbent, and we used a vegetable-oil base, which was. I added benzocaine, a local anesthetic, so that even if the sniffles didn't get better, you felt it less." The various "Humphrey cures...worked well enough and constituted an important part of the family income...the farmers that bought the medicines were good customers." Over time "Humphrey's Drug Store" became a profitable enterprise and the family again prospered.
Humphrey did not enjoy working as a pharmacist, and his dream remained to earn a doctorate in political science and become a college professor. In August 1937, he told his father that he wanted to return to the University of Minnesota. Hubert Sr. tried to convince his son not to leave by offering him a full partnership in the drugstore, but Hubert Jr. refused and told his father "how depressed I was, almost physically ill from the work, the dust storms, the conflict between my desire to do something and be somebody and my loyalty to him...he replied "Hubert, if you aren't happy, then you ought to do something about it." In 1937 Humphrey returned to the University of Minnesota and earned a Bachelor of Arts in 1939. He was a member of Phi Delta Chi Fraternity. He also earned a master's degree from Louisiana State University in 1940, serving as an assistant instructor of political science there. One of his classmates was Russell B. Long, a future U.S. Senator from Louisiana.
He then became an instructor and doctoral student at the University of Minnesota from 1940 to 1941 (joining the American Federation of Teachers), and was a supervisor for the Works Progress Administration (WPA). Humphrey was a star debater on the University of Minnesota's debate team; one of his debate teammates was future Minnesota Governor and US Secretary of Agriculture Orville Freeman. In the 1940 presidential campaign Humphrey and future University of Minnesota president Malcolm Moos debated the merits of Franklin D. Roosevelt, the Democratic candidate, and Wendell Willkie, the Republican candidate, on a Minneapolis radio station. Humphrey supported Roosevelt. Humphrey soon became active in Minneapolis politics, and as a result he never finished his PhD.
Marriage and early career.
In 1934 Hubert began dating Muriel Buck, a bookkeeper and graduate of local Huron College. They were married in 1936 and remained married until Humphrey's death nearly 42 years later. They had four children: Hubert Humphrey III, Nancy, Robert, and Douglas. Unlike many prominent politicians, Humphrey never became a millionaire; one biographer noted that "For much of his life he was short of money to live on, and his relentless drive to attain the White House seemed at times like one long, losing struggle to raise enough campaign funds to get there." To help boost his salary, Humphrey frequently took paid outside speaking engagements. Through most of his years as a U.S. Senator and Vice President, he lived in a middle-class housing development in Chevy Chase, Maryland. In 1958, Hubert and Muriel used their savings and his speaking fees to build a lakefront home in Waverly, Minnesota, about 40 miles west of Minneapolis. During the Second World War Humphrey tried three times to join the armed forces, but failed. His first two attempts were to join the Navy, first as a commissioned officer and then as an enlisted man. He was rejected by the Navy both times due to color blindness. He then tried to enlist in the Army in December 1944, but failed the physical exam due to a double hernia, color blindness, and calcification of the lungs. Despite his attempts to join the military, one biographer would note that "all through his political life, Humphrey was dogged by the charge that he was a draft dodger" during the war. Humphrey instead led various wartime government agencies and worked as a college instructor. In 1942, he was the state director of new production training and reemployment and chief of the Minnesota war service program. In 1943 he was the assistant director of the War Manpower Commission. From 1943 to 1944, Humphrey was a professor of political science at Macalester College in Saint Paul, Minnesota, where he headed the university's recently created international debate department; a department focusing on the international politics of World War II and the creation of the United Nations. After leaving Macalester in the spring of 1944, Humphrey worked as a news commentator for a Minneapolis radio station until 1945.
In 1943, Humphrey made his first run for elective office, for Mayor of Minneapolis. Although he lost, his poorly funded campaign still captured over 47% of the vote. In 1944, Humphrey was one of the key players in the merger of the Democratic and Farmer-Labor parties of Minnesota to form the Minnesota Democratic-Farmer-Labor Party (DFL). The same year, he worked on incumbent President Franklin Delano Roosevelt's reelection campaign in the 1944 presidential election. When in 1945, Minnesota Communists tried to seize control of the new party, Humphrey became an engaged anti-Communist and led the successful fight to oust the Communists from the DFL.
After the war, he again ran for mayor of Minneapolis and won the election with 61% of the vote. He served as mayor from 1945 to 1948. He was re-elected in 1947 by the largest margin in the city's history to that time. Humphrey gained national fame during these years by becoming one of the founders of the liberal anticommunist Americans for Democratic Action (ADA), where he served as chairman from 1949 to 1950, and for reforming the Minneapolis police force. The city had been named the "anti-Semitism capital" of the country, and the small African-American population of the city also faced discrimination. Humphrey's tenure as mayor is noted for his efforts to fight all forms of bigotry.
1948 Democratic National Convention.
The Democratic Party of 1948 was split between liberals who thought the federal government should actively protect civil rights for racial minorities, and social conservatives (mostly Southern Democrats) who believed that states should be able to enforce traditional racial segregation within their borders.
At the 1948 Democratic National Convention, the party platform reflected this division and contained only platitudes in favor of civil rights. The incumbent president, Harry S Truman, had shelved most of the recommendations of his 1946 Commission on Civil Rights, for fear of angering Southern Democrats. Humphrey, however, had written in "The Progressive" magazine that "The Democratic Party must lead the fight for every principle in the report. It is all or nothing."
A diverse coalition opposed the convention's tepid civil rights platform, including anti-communist liberals like Humphrey, Paul Douglas and John Shelley, all of whom would later become known as leading progressives in the Democratic Party. These liberals proposed adding a "minority plank" to the party platform that would commit the Democratic Party to a more aggressive opposition to racial segregation. The minority plank called for federal legislation against lynching, an end to legalized school segregation in the South, and ending job discrimination based on skin color. Also strongly backing the liberal civil rights plank were Democratic urban bosses like Ed Flynn of the Bronx, who promised the votes of northeastern delegates to Humphrey's platform, Jacob Arvey of Chicago, and David Lawrence of Pittsburgh. Although viewed as being conservatives, these urban bosses believed that Northern Democrats could gain many black votes by supporting civil rights, and that losses among anti-civil rights Southern Democrats would be relatively small. Though many scholars have suggested that labor unions were leading figures in this coalition, no significant labor leaders attended the convention, with the exception of the heads of the Congress of Industrial Organizations Political Action Committee (CIOPAC), Jack Kroll and A.F. Whitney.
Despite aggressive pressure by Truman's aides to avoid forcing the issue on the Convention floor, Humphrey chose to speak on behalf of the minority plank. In a renowned speech, Humphrey passionately told the Convention, "To those who say, my friends, to those who say, that we are rushing this issue of civil rights, I say to them we are 172 years (too) late! To those who say, this civil rights program is an infringement on states' rights, I say this: the time has arrived in America for the Democratic Party to get out of the shadow of states' rights and walk forthrightly into the bright sunshine of human rights!" Humphrey and his allies succeeded; the convention adopted the pro-civil-rights plank by a vote of 651½ to 582½.
As a result of the Convention's vote, the Mississippi and one half of the Alabama delegation walked out of the hall. Many Southern Democrats were so enraged at this affront to their "way of life" that they formed the Dixiecrat party and nominated their own presidential candidate, Governor Strom Thurmond of South Carolina. The goal of the Dixiecrats was to take Southern states away from Truman and thus cause his defeat. The Southern Democrats reasoned that after such a defeat the national Democratic Party would never again aggressively pursue a pro-civil rights agenda. However, the move backfired. Although the strong civil rights plank adopted at the Convention cost Truman the support of the Dixiecrats, it gained him many votes from blacks, especially in large northern cities. As a result, Truman won a stunning upset victory over his Republican opponent, Thomas E. Dewey. Truman's victory demonstrated that the Democratic Party could win presidential elections without the "Solid South", and thus weakened Southern Democrats instead of strengthening their position. Pulitzer Prize-winning historian David McCullough has written that Humphrey probably did more to get Truman elected in 1948 than anyone other than Truman himself.
United States Senate (1948–1964).
Minnesota elected Humphrey to the United States Senate in 1948 on the DFL ticket, defeating James M. Shields in the primary for the DFL nomination with 89% of the vote, and unseating incumbent Republican Joseph H. Ball with 60% of the vote in the general election. He took office on January 3, 1949, becoming the first Democrat elected senator from the state of Minnesota since before the Civil War. Humphrey's father died that year, and Humphrey stopped using the "Jr." suffix on his name. He was re-elected in 1954 and 1960. His colleagues selected him as majority whip in 1961, a position he held until he left the Senate on December 29, 1964, to assume the vice presidency. During this period, he served in the 81st, 82nd, 83rd, 84th, 85th, 86th, 87th, and a portion of the 88th Congress.
Initially, Humphrey's support of civil rights led to his being ostracized by Southern Democrats, who dominated most of the Senate leadership positions and who wanted to punish Humphrey for proposing the successful civil rights platform at the 1948 Convention. Senator Richard Russell Jr. of Georgia, a leader of Southern Democrats, once remarked to other Senators as Humphrey walked by, "Can you imagine the people of Minnesota sending that damn fool down here to represent them?" However, Humphrey refused to be intimidated and stood his ground; his integrity, passion and eloquence eventually earned him the respect of even most of the Southerners. His acceptance by the Southerners was also helped a great deal when Humphrey became a protégé of Senate Majority Leader Lyndon B. Johnson of Texas. Humphrey became known for his advocacy of liberal causes (such as civil rights, arms control, a nuclear test ban, food stamps, and humanitarian foreign aid), and for his long and witty speeches. During the period of McCarthyism (1950–1954), Humphrey was accused of being "soft on Communism", despite having been one of the founders of the anti-communist liberal organization Americans for Democratic Action, having been a staunch supporter of the Truman Administration's efforts to combat the growth of the Soviet Union, and having fought Communist political activities in Minnesota and elsewhere. In addition, Humphrey "was a sponsor of the clause in the McCarran Act of 1950 threatening concentration camps for 'subversives'", and in 1954 proposed to make mere membership in the Communist Party a felony – a proposal that failed. He was chairman of the Select Committee on Disarmament (84th and 85th Congresses). Although "Humphrey was an enthusiastic supporter of every U.S. war from 1938 to 1978", in February 1960, he introduced a bill to establish a National Peace Agency. With another former pharmacist, Representative Carl Durham, Humphrey cosponsored the Durham-Humphrey Amendment , which amended the Federal Food, Drug, and Cosmetic Act, defining two specific categories for medications, legend (prescription) and over-the-counter (OTC). As Democratic whip in the Senate in 1964, Humphrey was instrumental in the passage of the Civil Rights Act of that year. He was a lead author of the text of the civil rights act, alongside Republican Senate Republican Minority Leader Everett Dirksen of Illinois. Humphrey's consistently cheerful and upbeat demeanor, and his forceful advocacy of liberal causes, led him to be nicknamed "The Happy Warrior" by many of his Senate colleagues and political journalists.
While President John F. Kennedy is often credited for creating the Peace Corps, the first initiative came from Humphrey when he introduced the first bill to create the Peace Corps in 1957—three years prior to JFK and his University of Michigan speech. In his autobiography, "The Education of a Public Man", Humphrey wrote:
There were three bills of particular emotional importance to me: the Peace Corps, a disarmament agency, and the Nuclear Test Ban Treaty. The President, knowing how I felt, asked me to introduce legislation for all three. I introduced the first Peace Corps bill in 1957. It did not meet with much enthusiasm. Some traditional diplomats quaked at the thought of thousands of young Americans scattered across their world. Many senators, including liberal ones, thought the idea was silly and unworkable. Now, with a young president urging its passage, it became possible and we pushed it rapidly through the Senate. It is fashionable now to suggest that Peace Corps Volunteers gained as much or more, from their experience as the countries they worked. That may be true, but it ought not demean their work. They touched many lives and made them better.
Presidential and vice-presidential ambitions (1952–1964).
Humphrey ran for the Democratic presidential nomination twice before his election to the Vice Presidency in 1964. The first time was as Minnesota's favorite son in 1952, where he received only 26 votes on the first ballot; the second time was in 1960. In between these two presidential bids, Senator Humphrey was part of the free-for-all for the vice-presidential nomination at the 1956 Democratic National Convention, where he received 134 votes on the first ballot and 74 on the second.
In 1960, Humphrey ran again for the Democratic presidential nomination against fellow Senator John F. Kennedy in the primaries. Their first meeting was in the Wisconsin Primary, where Kennedy's well-organized and well-funded campaign overcame Humphrey's energetic but poorly funded effort. Kennedy's attractive brothers, sisters, and wife Jacqueline combed the state looking for votes. At one point Humphrey memorably complained that he "felt like an independent merchant competing against a chain store". Humphrey later wrote in his memoirs that "Muriel and I and our 'plain folks' entourage were no match for the glamour of Jackie Kennedy and the other Kennedy women, for Peter Lawford...and Frank Sinatra singing their commercial 'High Hopes'. Jack Kennedy brought family and Hollywood to Wisconsin. The people loved it and the press ate it up." Kennedy won the Wisconsin primary, but by a smaller margin than anticipated; some commentators argued that Kennedy's victory margin had come almost entirely from areas that were heavily Roman Catholic, and that Protestants actually supported Humphrey. As a result, Humphrey refused to quit the race and decided to run against Kennedy again in the West Virginia primary. According to one biographer "Humphrey thought his chances were good in West Virginia, one of the few states that had backed him in his losing race for vice-president four years earlier...West Virginia was more rural than urban, seemed to invite Humphrey's folksy stump style. The state, moreover, was a citadel of labor. It was depressed; unemployment had hit hard; and coal miners' families were hungry. Humphrey felt he could talk to such people, who were 95% Protestant (Humphrey was a Congregationalist) and deep-dyed Bible-belters besides."
Kennedy chose to meet the religion issue head-on. In radio broadcasts, he carefully repositioned the issue from one of Catholic versus Protestant to tolerance versus intolerance. Kennedy's appeal placed Humphrey, who had championed tolerance his entire career, on the defensive, and Kennedy attacked him with a vengeance. Franklin D. Roosevelt Jr., the son of the former president, stumped for Kennedy in West Virginia and raised the issue of Humphrey's failure to serve in the armed forces in World War II. Roosevelt told audiences "I don't know where he was in World War Two," and handed out flyers charging that Humphrey was a draft dodger. Historian Robert Dallek has written that Robert F. Kennedy, who was serving as his brother's campaign manager, came into "possession of information that Humphrey may have sought military deferments during World War Two ... he pressed Roosevelt to use this." Humphrey believed Roosevelt's draft-dodger claim "had been approved by Bobby [Kennedy, if not Jack". However, Dallek has written that the claims that Humphrey was a draft dodger were inaccurate, because during the war Humphrey had "tried and failed to get into the service because of physical disabilities". After the West Virginia primary, Roosevelt sent Humphrey a written apology and retraction. According to historian Arthur Schlesinger, Jr., Roosevelt "felt that he had been used, blaming [the draft-dodger charge on Robert Kennedy's determination to win at any cost...Roosevelt said later that it was the biggest political mistake of his career." Humphrey, who was short on funds, could not match the well-financed Kennedy operation. Humphrey traveled around the state in a rented bus, while Kennedy and his staff flew around West Virginia in a large, family-owned airplane. According to Carl Solberg, his biographer, Humphrey spent only $23,000 on the West Virginia primary, while Kennedy's campaign privately spent some $1.5 million, well over their official estimate of $100,000. There were accusations that the Kennedys bought the West Virginia primary by paying bribes to county sheriffs and other local officials to give Kennedy the vote; however, these accusations were never proven. Humphrey later wrote that "as a professional politician I was able to accept and indeed respect the efficacy of the Kennedy campaign. But underneath the beautiful exterior, there was an element of ruthlessness and toughness that I had trouble either accepting or forgetting." Kennedy defeated Humphrey soundly in West Virginia, winning 60.8% of the vote. That evening, Humphrey announced that he was no longer a presidential candidate. By winning the West Virginia primary, Kennedy was able to overcome the belief that Protestant voters would not elect a Catholic candidate to the Presidency and thus sewed up the Democratic nomination for President.
Humphrey did win the South Dakota and District of Columbia primaries, which JFK did not enter. At the 1960 Democratic National Convention, he received 41 votes even though he was no longer an active presidential candidate.
Humphrey's defeat in 1960 had a profound influence on his thinking; after the primaries he told friends that, as a relatively poor man in politics, he was unlikely to ever become President unless he served as Vice-President first. Humphrey believed that only in this way could he raise the funds and nationwide organization and visibility he would need to win the Democratic nomination. As such, as the 1964 presidential campaign began Humphrey made clear his interest in becoming President Lyndon Johnson's running mate. At the 1964 Democratic National Convention, Johnson kept the three likely vice presidential candidates, Connecticut Senator Thomas Dodd, fellow Minnesota Senator Eugene McCarthy, and Humphrey, as well as the rest of the nation in suspense before announcing Humphrey as his running-mate with much fanfare, praising Humphrey's qualifications for a considerable amount of time before announcing his name.
The following day Humphrey's acceptance speech overshadowed Johnson's own acceptance address:
Hubert warmed up with a long tribute to the President, then hit his stride as he began a rhythmic jabbing and chopping at Barry Goldwater. "Most Democrats and Republicans in the Senate voted for an $11.5 billion tax cut for American citizens and American business," he cried, "but not Senator Goldwater. Most Democrats and Republicans in the Senate – in fact four-fifths of the members of his own party – voted for the Civil Rights Act, but not Senator Goldwater."
Time after time, he capped his indictments with the drumbeat cry: "But not Senator Goldwater!" The delegates caught the cadence and took up the chant. A quizzical smile spread across Humphrey's face, then turned to a laugh of triumph. Hubert was in fine form. He knew it. The delegates knew it. And no one could deny that Hubert Humphrey would be a formidable political antagonist in the weeks ahead.
In 1964, the Johnson/Humphrey ticket won overwhelmingly, garnering 486 electoral votes out of 538. Only five Southern states and Goldwater's home state of Arizona supported the Republican ticket.
Vice Presidency (1965–1969).
Humphrey took office on January 20, 1965, after he was sworn in at 11:58 A.M. by Speaker of the House John McCormack; ending the 14-month vacancy of the Office of the Vice President of the United States, vacated when then-Vice President Lyndon B. Johnson assumed the Presidency after the assassination of John F. Kennedy. He was an early skeptic of the-then growing conflict in Vietnam. Following a successful Viet Cong hit-and-run attack on the US military installations at Pleiku on February 7, 1965 (where 7 Americans were killed and 109 wounded), Humphrey returned from Georgia to Washington D.C., to attempt to prevent further escalation. He told President Johnson that bombing North Vietnam was not a solution to the problems in South Vietnam, but that bombing would require the injection of US ground forces into South Vietnam to protect the airbases. Presciently, he noted that a military solution in Vietnam would take years, well beyond the next election cycle. In response to his advice, President Johnson punished Humphrey with coldness and a restriction from his inner circle for a number of months, until Humphrey decided to "get back on the team" and fully support the war effort.
As Vice President, Humphrey was controversial for his complete and vocal loyalty to Johnson and the policies of the Johnson Administration, even as many of his liberal admirers opposed Johnson's policies with increasing fervor regarding the Vietnam War. Many of Humphrey's liberal friends and allies abandoned him because of his refusal to publicly criticize Johnson's Vietnam War policies. Humphrey's critics later learned that Johnson had threatened Humphrey – Johnson told Humphrey that if he publicly criticized his Administration's Vietnam War policy, he would destroy Humphrey's chances to become President by opposing his nomination at the next Democratic Convention. However, Humphrey's critics were vocal and persistent: even his nickname, "the Happy Warrior", was used against him. The nickname referred not to his military hawkishness but rather to his crusading for social welfare and civil rights programs. After his narrow defeat in the 1968 presidential election, Humphrey wrote that "After four years as Vice-President ... I had lost some of my personal identity and personal forcefulness. ... I ought not to have let a man who was going to be a former President dictate my future."
While he was Vice President, Hubert Humphrey was the subject of a satirical song by songwriter/musician Tom Lehrer entitled "Whatever Became of Hubert?" The song addressed how some liberals and progressives felt let down by Humphrey, who had become a much more mute figure as Vice President than he had been as a senator. The song goes ""Whatever became of Hubert? Has anyone heard a thing? Once he shone on his own, now he sits home alone and waits for the phone to ring. Once a fiery liberal spirit, ah, but now when he speaks he must clear it. ..." "
During these years Humphrey was a repeated and favorite guest of Johnny Carson on "The Tonight Show". He also struck up a friendship with Frank Sinatra, who supported his campaign for president in 1968 before his conversion to the Republican party in the early 1970s, and was perhaps most on notice in the fall of 1977 when Sinatra was the star attraction and host of a tribute to a then-ailing Humphrey. He also appeared on "The Dean Martin Celebrity Roast" in 1973.
1968 Presidential election.
As 1968 began, it looked as if President Johnson, despite the rapidly decreasing approval rating of his Vietnam War policies, would easily win the Democratic nomination for a second time. Humphrey was widely expected to remain Johnson's running mate for reelection in 1968. Johnson was challenged by Senator Eugene McCarthy of Minnesota, who ran on an anti-Vietnam War platform. With the backing of out-of-state anti-war college students and activists while campaigning in the New Hampshire primary, McCarthy, who was not expected to be a serious contender for the Democratic nomination, nearly defeated Johnson, finishing with a surprising 42% of the vote to Johnson's 49%. A few days after the New Hampshire primary, after months of contemplation and originally intending to support Johnson's bid for reelection, Senator Robert Kennedy of New York also entered the race on an anti-war platform. On March 31, 1968, a week before the Wisconsin primary, where polls showed a strong standing for McCarthy, President Lyndon B. Johnson stunned the nation by withdrawing from his race for a second full term.
Following the announcement from Johnson, Humphrey announced his presidential candidacy on April 27, 1968. Declaring his candidacy in a speech in Washington, D.C. alongside Senators Fred Harris of Oklahoma and Walter Mondale of Minnesota (who both served as the co-chairs to his campaign), Humphrey stated:
Here we are, just as we ought to be, here we are, the people, here we are the spirit of dedication, here we are the way politics ought to be in America, the politics of happiness, politics of purpose, politics of joy; and that's the way it's going to be, all the way, too, from here on out. We seek an America able to preserve and nurture all the basic rights of free expression, yet able to reach across the divisions that too often separate race from race, region from region, young from old, worker from scholar, rich from poor. We seek an America able to do this in the higher knowledge that our goals and ideals are worthy of conciliation and personal sacrifice.
Also in his speech, Humphrey supported President Johnson's Vietnam initiative he proposed during his address to the nation four weeks earlier; partially halting the bombings in North Vietnam, while sending an additional 13,500 troops and increasing the Department of Defense's budget by 4% over the next fiscal year. Later in the campaign, Humphrey opposed a proposal by Senators McCarthy and George McGovern of South Dakota to the Democratic Convention's Policy Committee, calling for an immediate end to the bombings in Vietnam, an early withdrawal of troops and setting talks for a coalition government with the Viet Cong.
Many people saw Humphrey as Johnson's stand-in; he won major backing from the nation's labor unions and other Democratic groups that were troubled by young antiwar protesters and the social unrest around the nation. Humphrey entered the race too late to participate in the Democratic primaries and concentrated on winning delegates in non-primary states by gaining the support from Democratic officeholders who were elected delegates for the Democratic Convention. By June, McCarthy won in Oregon and Pennsylvania, while Kennedy had won in Indiana and Nebraska, though Humphrey was the front runner as he led the delegate count. The California primary was crucial for Kennedy's campaign, as a McCarthy victory would've prevented Kennedy from reaching the amount of delegates required to secure the nomination. On June 4, 1968, Kennedy defeated McCarthy by less than 4% in the California primary. But the nation was shocked yet again when Senator Kennedy was assassinated after his victory speech at the Ambassador Hotel in Los Angeles, California. After the assassination of Kennedy, Humphrey suspended his campaign for two weeks.
Humphrey and his running mate, Ed Muskie, went on to easily win the Democratic nomination at the party convention in Chicago, Illinois. Unfortunately for Humphrey and his campaign, in Grant Park and at other sites near downtown Chicago, well away from the convention hall, there were gatherings and protests by thousands of antiwar demonstrators, many of whom favored McCarthy, George McGovern, or other "anti-war" candidates. These protesters – most of them young college students – were attacked and beaten on live television by Chicago police, actions which merely amplified the growing feelings of unrest in the general public. Humphrey's inaction during these activities, as well as public backlash from securing the presidential nomination without entering a single primary, highlighted turmoil in the Democratic party's base that proved to be too much for Humphrey to overcome in time for the general election. The combination of the unpopularity of Johnson, the Chicago demonstrations, and the discouragement of liberals and African-Americans when both Robert F. Kennedy and Martin Luther King Jr. were assassinated during the election year, were all contributing factors that caused him to eventually lose the election to former Vice President Nixon. Although he lost the election by less than 1% of the popular vote, (43.4% for Nixon (31,783,783 votes) to 42.7% (31,271,839 votes) for Humphrey, with 13.5% (9,901,118 votes) for George Wallace), Humphrey carried just 13 states with 191 electoral college votes. Richard Nixon carried 32 states and 301 electoral votes, and Wallace carried 5 states in the South and 46 electoral votes (270 were needed to win).
In his concession speech, Humphrey said: "I have done my best. I have lost, Mr. Nixon has won. The democratic process has worked its will."
Post-Vice Presidency (1969–1978).
Teaching and return to the Senate.
After leaving the Vice Presidency, Humphrey taught at Macalester College and the University of Minnesota, and served as chairman of board of consultants at the Encyclopædia Britannica Educational Corporation.
Initially he had not planned to return to political life, but an unexpected opportunity changed his mind. McCarthy, who was up for re-election in 1970, realized that he had only a slim chance of winning even re-nomination (he had angered his party by opposing Johnson and Humphrey for the 1968 presidential nomination) and declined to run. Humphrey won the nomination, defeated Republican Congressman Clark MacGregor, and returned to the U.S. Senate on January 3, 1971. He was re-elected in 1976, and remained in office until his death. In a rarity in politics, Humphrey served as a Senator by holding both seats in his state (Class I and Class II, at different times). This time he served in the 92nd, 93rd, 94th, and a portion of the 95th Congress.
In 1972, Humphrey once again ran for the Democratic nomination for president. He drew upon continuing support from organized labor and the African-American and Jewish communities, but remained unpopular with college students because of his association with the Vietnam War, even though he had altered his position in the years since his 1968 defeat. Humphrey initially planned to skip the primaries, as he had in 1968. Even after he revised this strategy he still stayed out of New Hampshire, a decision that allowed McGovern to emerge as the leading challenger to Muskie in that state. Humphrey did win some primaries, including those in Ohio, Indiana and Pennsylvania, but was defeated by McGovern in several others, including the crucial California primary. Humphrey also was out-organized by McGovern in caucus states and was trailing in delegates at the 1972 Democratic National Convention in Miami Beach, Florida. His hopes rested on challenges to the credentials of some of the McGovern delegates. For example, the Humphrey forces argued that the winner-take-all rule for the California primary violated procedural reforms intended to produce a better reflection of the popular vote, the reason that the Illinois delegation was bounced. The effort failed, as several votes on delegate credentials went McGovern's way, guaranteeing his victory.
Humphrey also briefly considered mounting a campaign for the Democratic nomination from the Convention once again in 1976, when the primaries seemed likely to result in a deadlock, but ultimately decided against it. At the conclusion of the Democratic primary process that year, even with Jimmy Carter having the requisite number of delegates needed to secure his nomination, many still wanted Humphrey to announce his availability for a draft. However, he did not do so, and Carter easily secured the nomination on the first round of balloting. Humphrey had learned that he had terminal cancer, prompting him to sit the race out.
Deputy President pro tempore of the Senate (1976–1978).
In 1974, along with Rep. Augustus Hawkins of California, Humphrey authored the Humphrey-Hawkins Full Employment Act, the first attempt at full employment legislation. The original bill proposed to guarantee full employment to all citizens over 16 and set up a permanent system of public jobs to meet that goal. A watered-down version called the "Full Employment and Balanced Growth Act" passed the House and Senate in 1978. It set the goal of 4 percent unemployment and 3 percent inflation and instructed the Federal Reserve Board to try to produce those goals when making policy decisions.
Humphrey ran for Majority Leader after the 1976 election but lost to Robert Byrd of West Virginia. The Senate honored Humphrey by creating the post of Deputy President pro tempore of the Senate for him. On August 16, 1977, Humphrey revealed he was suffering from terminal bladder cancer. On October 25 of that year, he addressed the Senate, and on November 3, Humphrey became the first person other than a member of the House or the President of the United States to address the House of Representatives in session. President Carter honored him by giving him command of "Air Force One" for his final trip to Washington on October 23. One of Humphrey's speeches contained the lines "It was once said that the moral test of Government is how that Government treats those who are in the dawn of life, the children; those who are in the twilight of life, the elderly; and those who are in the shadows of life, the sick, the needy and the handicapped", which is sometimes described as the "liberals' mantra".
Death and funeral.
Humphrey spent his last weeks calling old political acquaintances. One call was to Richard Nixon inviting him to his upcoming funeral, which he accepted. Staying in the hospital, Humphrey went from room to room, cheering up other patients by telling them jokes and listening to them.
He died on January 13, 1978 of bladder cancer at his home in Waverly, Minnesota. His body lay in state in the rotunda of both the United States Capitol and the Minnesota State Capitol, and was interred in Lakewood Cemetery in Minneapolis. Old friends and opponents of Humphrey, from Gerald Ford and Richard Nixon to President Carter and Vice-President Walter Mondale paid their final respects. "He taught us how to live, and finally he taught us how to die", said Mondale.
His wife, Muriel Humphrey, was appointed by Minnesota's governor Rudy Perpich to serve in the US Senate until a special election to fill the term was held. She did not seek election to finish her husband's term in office.
Muriel Humphrey remarried in 1981 (to Max Brown) and took the name Muriel Humphrey Brown. She died in 1998 at the age of 86 and is interred next to Hubert Humphrey.
Honors.
On July 14, 1951, Humphrey and actor Richard Carlson were the guests on the CBS variety show, "Faye Emerson's Wonderful Town", in which hostess Faye Emerson visited Minneapolis to accent the kinds of music popular in the city.
In 1965, Humphrey was made an "Honorary Life Member" of Alpha Phi Alpha, a historically African American fraternity.
In 1978, Humphrey received the U.S. Senator John Heinz Award for Greatest Public Service by an Elected or Appointed Official, an award given out annually by Jefferson Awards.
He was awarded posthumously the Congressional Gold Medal on June 13, 1979 and the Presidential Medal of Freedom in 1980.
He was honored by the United States Postal Service with a 52¢ Great Americans series (1980–2000) postage stamp.
There is a slightly under-sized statue of him in front of the Minneapolis City Hall.
Named for Humphrey.
In popular culture.
In the film "Pump up the Volume", Christian Slater's character attends a fictional "Hubert Humphrey High" – which he uses as the basis for his pirate radio character – "Happy Harry Hardon".

</doc>
<doc id="42640" url="https://en.wikipedia.org/wiki?curid=42640" title="Sandra Day O'Connor">
Sandra Day O'Connor

Sandra Day O'Connor (born March 26, 1930) is a retired associate justice of the Supreme Court of the United States, serving from her appointment in 1981 by Ronald Reagan until her retirement in 2006. She was the first woman to be appointed to the Court.
Prior to O'Connor's appointment to the Court, she was an elected official and judge in Arizona serving as the first female Majority Leader in the United States as the Republican leader in the Arizona Senate. On July 1, 2005, she announced her intention to retire effective upon the confirmation of a successor. Samuel Alito was nominated to take her seat in October 2005, and joined the Court on January 31, 2006.
Considered a federalist and a moderate conservative, O'Connor tended to approach each case narrowly without arguing for sweeping precedents. She most frequently sided with the court's conservative bloc, although in the latter years of her tenure, she was regarded as having the swing opinion in many cases. Her unanimous confirmation by the Senate in 1981 was supported by most conservatives, led by Arizona Senator Barry Goldwater, and liberals, including Massachusetts Senator Ted Kennedy and women's rights groups like the National Organization for Women.
O'Connor was Chancellor of The College of William & Mary in Williamsburg, Virginia, and served on the board of trustees of the National Constitution Center in Philadelphia, Pennsylvania. She also served on the Board of Trustees for Colonial Williamsburg. Several publications have named O'Connor among the most powerful women in the world. On August 12, 2009, she was awarded the Presidential Medal of Freedom, the highest civilian honor of the United States, by President Barack Obama.
Early life and education.
She was born in El Paso, Texas, to Harry Alfred Day, a rancher, and Ada Mae (Wilkey). She grew up on a cattle ranch near Duncan, Arizona where she had to change automobile flat tires herself in dangerous environments. She later wrote a book with her brother, H. Alan Day, "Lazy B : Growing up on a Cattle Ranch in the American West" (2002), about her childhood experiences on the ranch. For most of her early schooling, O'Connor lived in El Paso with her maternal grandmother, and attended school at the Radford School for Girls, a private school. She graduated sixth in her class at Austin High School in El Paso in 1946. She attended Stanford University, where she received her B.A. in economics in 1950. She continued at the Stanford Law School for her LL.B.. There, she served on the Stanford Law Review with its presiding editor in chief, future Supreme Court Chief Justice William Rehnquist, who was the class valedictorian, and whom she briefly dated during law school. She has stated that she graduated third in her law school class, although Stanford's official position is that the law school did not rank students in 1952.
On December 20, 1952, six months after graduating from law school, she married John Jay O'Connor III. They had three sons: Scott, Brian, and Jay. Her husband suffered from Alzheimer's disease for nearly twenty years until his death in 2009, and she has become involved in raising awareness of the disease.
After graduation from law school, at least 40 law firms refused to interview her for a position as an attorney because she was a woman. She eventually found employment as a deputy county attorney in San Mateo, California, after she offered to work for no salary and without an office, sharing space with a secretary.
O'Connor served as Assistant Attorney General of Arizona 1965–69 until she was appointed to fill a vacancy in the Arizona State Senate. She was re-elected to the State Senate in 1973 and became the first woman to serve as its Majority Leader. In 1974 she was elected to the Maricopa County Superior Court serving from 1975 to 1979 when she was elevated to the Arizona State Court of Appeals. She served on the Court of Appeals until 1981 when she was appointed to the Supreme Court.
Supreme Court career.
Appointment.
On July 7, 1981, Reagan – who had pledged during his 1980 presidential campaign to appoint the first woman to the Court – announced he would nominate O'Connor as an Associate Justice of the Supreme Court, to replace the retiring Potter Stewart. O'Connor received notification from President Reagan of her nomination on the day prior to the announcement and did not know that she was a finalist for the position. Reagan formally nominated O'Connor on August 19, 1981.
Pro-life and religious groups opposed O'Connor's nomination because they suspected she would not be willing to overturn "Roe v Wade." U.S. Senate Republicans, including Don Nickles of Oklahoma, Steve Symms of Idaho, and Jesse Helms of North Carolina called the White House to express their discontent over the nomination; Nickles said he and "other profamily Republican senators would not support" O'Connor. For her part, O'Connor refused to telegraph her views on abortion, and she was careful not to leave the impression that she supported abortion rights. O'Connor told Reagan she did not remember whether she had supported the view of repealing Arizona's law banning abortion. However, she had cast a preliminary judgment in the Arizona State Senate in 1970 in favor of a bill to repeal the state's criminal-abortion statute. In 1974, O'Connor had opined against a measure to prohibit abortions in some Arizona hospitals.
Reagan wrote in his diary on July 6, 1981: "Called Judge O'Connor and told her she was my nominee for supreme court. Already the flak is starting and from my own supporters. Right to Life people say she is pro abortion. She says abortion is personally repugnant to her. I think she'll make a good justice." On September 21, O'Connor was confirmed by the U.S. Senate with a vote of 99–0; Senator Max Baucus of Montana was absent from the vote, and sent O'Connor a copy of "A River Runs Through It" by way of apology. In her first year on the Court she received over 60,000 letters from the public, more than any other justice in history.
Response to being first woman on the Supreme Court.
In response to an editorial in "The New York Times" which mentioned the "nine old men" of the Court, the self-styled FWOTSC (First Woman On The Supreme Court) sent a pithy letter to the editor:
In several speeches broadcast nationally on the cable network C-SPAN, she mentioned feeling some relief from the media clamor when Ruth Bader Ginsburg joined her as an Associate Justice of the Court in 1993. In May 2010, O'Connor warned female Supreme Court nominee Elena Kagan about the "unpleasant" process of confirmation hearings.
Supreme Court jurisprudence.
Voting record and deciding votes.
O'Connor was part of the federalism movement and approached each case as narrowly as possible, avoiding generalizations that might later "paint her into a corner" for future cases. Initially, her voting record aligned closely with the conservative William Rehnquist (voting with him 87% of the time her first three years at the Court). From that time until 1998 O'Connor's alignment with Rehnquist ranged from 93.4% to 63.2%, hitting above 90% in three of those years. In nine of her first sixteen years on the Court, O'Connor voted with Rehnquist more than with any other justice.
Later on, as the Court's make-up became more conservative (e.g., Anthony Kennedy replacing Lewis Powell, and Clarence Thomas replacing Thurgood Marshall), O'Connor often became the swing vote on the Court. However, she usually disappointed the Court's more liberal bloc in contentious 5–4 decisions: from 1994 to 2004, she joined the traditional conservative bloc of Rehnquist, Antonin Scalia, Anthony Kennedy, and Thomas 82 times; she joined the liberal bloc of John Paul Stevens, David Souter, Ginsburg, and Stephen Breyer only 28 times.
O'Connor's relatively small shift away from conservatives on the Court seems to have been due at least in part to Thomas's views. When Thomas and O'Connor were voting on the same side, she would typically write a separate opinion of her own, refusing to join his. In the 1992 term, O'Connor did not join a single one of Thomas' dissents.
Willamette University College of Law Professor Steven Green, who served for nine years as general counsel for Americans United for Separation of Church and State and has argued before the Court numerous times stated, "She was a moderating voice on the court and was very hesitant to expand the law in either direction." Green also noted that, unlike some other Court justices, O'Connor "eemed to look at each case with an open mind".
Some of the cases in which O'Connor was the deciding vote include:
O'Connor played an important role in other notable cases, such as:
On February 22, 2005, with Rehnquist and Stevens (who was senior to her) absent, she presided over oral arguments in the case of "Kelo v. City of New London", becoming the first woman to preside over an oral argument before the Court.
Fourth Amendment.
According to George Washington University law professor Jeffrey Rosen, "O'Connor was an eloquent opponent of intrusive group searches that threatened privacy without increasing security. In a 1983 opinion upholding searches by drug-sniffing dogs, she recognized that a search is most likely to be considered constitutionally reasonable if it is very effective at discovering contraband without revealing innocent but embarrassing information." Washington College of Law law professor Andrew Taslitz, referencing O'Connor's dissent in a 2001 case, said of her Fourth Amendment jurisprudence: "O'Connor recognizes that needless humiliation of an individual is an important factor in determining Fourth Amendment reasonableness."
Cases involving minorities.
From her start on the Court until 1998, O'Connor voted against the minority litigant in all but two of the forty-one close cases involving race.
In the 1990 and 1995 "Missouri v. Jenkins" rulings, O'Connor voted with the majority that district courts had no authority to require the state of Missouri to increase school funding in order to counteract racial inequality. In the 1991 "Freeman v. Pitts" case, O'Connor joined a concurring opinion in a plurality, agreeing that a school district that had formerly been under judicial review for racial segregation could be freed of this review, even though not all desegregation targets had been met. Law professor Herman Schwartz criticized these rulings, writing that in both cases "both the fact and effects of segregation were still present."
In 1987's "McCleskey v. Kemp", O'Connor joined a 5–4 majority that voted to uphold the death penalty for an African American man, Warren McCleskey, convicted of killing a white police officer, despite statistical evidence that black defendants were more likely to receive the death penalty than others both in Georgia and in the U.S. as a whole.
In 1996's "Shaw v. Hunt" and "Shaw v. Reno", O'Connor joined a Rehnquist opinion, following an earlier path-breaking decision she authored in 1993, in which the court struck down an electoral districting plan designed to facilitate the election of two black representatives out of twelve from North Carolina, a state that had not had any black representative since Reconstruction, despite being approximately 20% black—the Court held that the districts were unacceptably gerrymandered and O'Connor called the odd shape of the district in question, North Carolina's 12th, "bizarre".
Law Professor Herman Schwartz called O'Connor "the Court’s leader in its assault on racially oriented affirmative action," although she joined with the Court in upholding the constitutionality of race-based admissions to universities.
In late 2008, O'Connor said she believed racial affirmative action should continue to help heal the inequalities created by racial discrimination. She stressed this wouldn't be a cure-all but rather a bandage and that society has to do much more to correct our racial imbalance. In 2003 Justice O'Connor authored a majority Supreme Court opinion ("Grutter v. Bollinger") saying racial affirmative action wouldn't be constitutional permanently but long enough to correct past discrimination ─ an approximation limit of around 25 years, or until 2028.
Abortion.
In her confirmation hearings and early days on the court, O'Connor was carefully ambiguous on the issue of abortion, as some conservatives questioned her pro-life credentials on the basis of some of her votes in the Arizona legislature. O'Connor generally dissented from 1980s opinions which took an expansive view of "Roe v. Wade"; she criticized that decision's "trimester approach" sharply in her dissent in 1983's "City of Akron v. Akron Center for Reproductive Health." She criticized "Roe" in "Thornburgh v. American College of Obstetricians and Gynecologists": "... I dispute not only the wisdom but also the legitimacy of the Court's attempt to discredit and pre-empt state abortion regulation regardless of the interests it serves and the impact it has." In 1989, O'Connor stated during the deliberations over the "Webster" case that she would not overrule "Roe". While on the Court, O'Connor did not vote to strike down any restrictions on abortion until "Hodgson v. Minnesota" in 1990.
O'Connor allowed certain limits to be placed on access to abortion, but supported the fundamental right to abortion protected by the Due Process Clause of the Fourteenth Amendment. In "Planned Parenthood v. Casey", O'Connor used a test she had originally developed in "City of Akron v. Akron Center for Reproductive Health" to limit the holding of "Roe v. Wade," opening up a legislative portal where a State could enact measures so long as they did not place an "undue burden" on a woman's right to an abortion. Casey revised downward the standard of scrutiny federal courts would apply to state abortion restrictions, a major departure from Roe. However it preserved Roe's core constitutional precept: that the Fourteenth Amendment implies and protects a fundamental right to control the outcomes of one's reproductive actions. Writing the plurality opinion for the Court, O'Connor, along with Justices Kennedy and Souter, famously declared: “At the heart of liberty is the right to define one’s own concept of existence, of meaning, of the universe, and of the mystery of human life. Beliefs about these matters could not define the attributes of personhood were they formed under compulsion of the State.”
Foreign law.
O'Connor was a vigorous defender of the citing of foreign laws in judicial decisions. In a well-publicized October 28, 2003, speech at the Southern Center for International Studies, O'Connor said:The impressions we create in this world are important and can leave their mark ... is talk today about the "internationalization of legal relations". We are already seeing this in American courts, and should see it increasingly in the future. This does not mean, of course, that our courts can or should abandon their character as domestic institutions. But conclusions reached by other countries and by the international community, although not formally binding upon our decisions, should at times constitute persuasive authority in American courts—what is sometimes called "transjudicialism".
In the speech she noted the 2002 Court case, "Atkins v. Virginia", in which the majority decision (which included her) cited disapproval of the death penalty in Europe as part of its argument. This speech, and the general concept of relying on foreign law and opinion, was widely criticized by conservatives. In May 2004, the U.S. House of Representatives responded by passing a non-binding resolution, the "Reaffirmation of American Independence Resolution", stating that "U.S. judicial decisions should not be based on any foreign laws, court decisions, or pronouncements of foreign governments unless they are relevant to determining the meaning of American constitutional and statutory law."
O'Connor once quoted the constitution of the Middle Eastern nation of Bahrain, which states that "authority shall prevail over the judgement of a judge, and under no circumstances may the course of justice be interfered with." Further, "[it is in everyone's interest to foster the rule-of-law evolution." O'Connor proposed that such ideas be taught in American law schools, high schools and universities. Critics contend that such thinking is contrary to the U.S. Constitution and establishes a rule of man, rather than law. In her retirement, she has continued to speak and organize conferences on the issue of judicial independence.
Conservative criticism.
O'Connor's case-by-case approach routinely placed her in the center of the court and drew both criticism and praise. "The Washington Post" columnist Charles Krauthammer, for instance, described her as lacking a judicial philosophy and instead displaying "political positioning embedded in a social agenda". Another conservative commentator, Ramesh Ponnuru, wrote that, although O'Connor "has voted reasonably well", her tendency to issue very case-specific rulings "undermines the predictability of the law and aggrandizes the judicial role".
Retirement.
O'Connor was successfully treated for breast cancer in 1988 (she also had her appendix removed that year). One side effect of this experience was that there was perennial speculation over the next seventeen years that she might retire from the Court.
On December 12, 2000, "The Wall Street Journal" reported that O'Connor was reluctant to retire with a Democrat in the presidency: "At an Election Night party at the Washington, D.C. home of Mary Ann Stoessel, widow of former Ambassador Walter Stoessel, the justice's husband, John O'Connor, mentioned to others her desire to step down, according to three witnesses. But Mr. O'Connor said his wife would be reluctant to retire if a Democrat were in the White House and would choose her replacement. Justice O'Connor declined to comment."
By 2005, the membership of the Court had been static for eleven years, the second-longest period without a change in the Court's composition in American history. Rehnquist was widely expected to be the first justice to retire during Bush's term, because of his age and his battle with cancer. However, on July 1, 2005, it was O'Connor who announced her retirement plans. In her letter to Bush she stated that her retirement from active service would take effect upon the confirmation of her successor.
On July 19, Bush nominated D.C. Circuit Judge John G. Roberts, Jr. to succeed O'Connor. O'Connor heard the news over the car radio on the way back from a fishing trip. She felt he was an excellent and highly qualified choice — he had argued numerous cases before the Court during her tenure. However, she was terribly disappointed her replacement was not a woman.
On July 21, O'Connor spoke to a Ninth Circuit conference and blamed the televising of Senate Judiciary Committee hearings for escalated conflicts over judges. She expressed sadness over attacks on the independent judiciary, and praised President Reagan for opening doors for women. O'Connor had been expected to leave the Court before the next term started on October 3, 2005. However, Rehnquist died on September 3 (she spoke at his funeral). Two days later, Bush withdrew Roberts as his nominee for her seat and instead appointed him to fill the vacant office of Chief Justice. O'Connor agreed to stay on the Court until her replacement was confirmed. On October 3, Bush nominated White House Counsel Harriet Miers to replace O'Connor. After much criticism and controversy over her nomination, on October 27, Miers asked Bush to withdraw her nomination. Bush accepted her request later the same day. On October 31, Bush nominated Third Circuit Judge Samuel Alito to replace O'Connor; Alito was confirmed and sworn in on January 31, 2006.
O'Connor's last Court opinion, "Ayotte v. Planned Parenthood of New England", written for a unanimous court, was a procedural decision that involved abortion.
She stated that she planned to travel, spend time with family, and, because of her fear of the attacks on judges by legislators, would work with the American Bar Association on a commission to help explain the separation of powers and the role of judges. She also announced that she was working on a new book, which will focus on the early history of the Court. She is a trustee on the board of the Rockefeller Foundation. She stated that she would have preferred to stay on the Court for several more years but stepped down to spend more time with her husband, who had been diagnosed with Alzheimer's Disease prior to his death in 2009. O'Connor said it was her plan to follow the tradition of previous justices, who enjoy lifetime appointments. "Most of them get ill and are really in bad shape, which I would've done at the end of the day myself, I suppose, except my husband was ill and I needed to take action there."'
Since retiring, she has continued to hear cases and rendered over a dozen opinions in federal appellate courts across the country, filling in as a substitute judge when vacations or vacancies leave their three-member panels understaffed.
O'Connor has reflected on her time on the Supreme Court by saying that she regrets the court hearing the "Bush v. Gore" case in 2000 because it "stirred up the public" and "gave the court a less-than-perfect reputation." The former justice told the "Chicago Tribune" that "Maybe the court should have said, 'We’re not going to take it, goodbye,’...It turned out the election authorities in Florida hadn’t done a real good job there and kind of messed it up. And probably the Supreme Court added to the problem at the end of the day.”
Post-Supreme Court career.
Commentary.
On March 9, 2006, during a speech at Georgetown University, O'Connor said some political attacks on the independence of the courts pose a direct threat to the constitutional freedoms of Americans. She said "any reform of the system is debatable as long as it is not motivated by 'nakedly partisan reasoning' retaliation because congressmen or senators dislike the result of the cases. Courts interpret the law as it was written, not as the congressmen might have wished it was written", and "it takes a lot of degeneration before a country falls into dictatorship, but we should avoid these ends by avoiding these beginnings." On September 19, 2006, she echoed her concerns for an independent judiciary during the dedication address at the Elon University School of Law.
On September 28, 2006, O'Connor co-hosted and spoke at a conference at Georgetown University Law Center, "Fair and Independent Courts: A Conference on the State of the Judiciary."
Judge William H. Pryor, Jr., a conservative jurist, has criticized O'Connor's speeches and op-eds for hyperbole and factual inaccuracy, based in part on O'Connor's opinions as to whether judges face a rougher time in the public eye today than in the past.
On November 7, 2007, at a conference on her landmark opinion in "Strickland v. Washington" (1984) sponsored by the Constitution Project, O'Connor urged the creation of a system for "merit selection for judges". She also highlighted the lack of proper legal representation for many of the poorest defendants.
On August 7, 2008, O'Connor and Abdurrahman Wahid, the former President of Indonesia, wrote an editorial in the "Financial Times" stating their concerns about the threatened imprisonment of Malaysian opposition leader Anwar Ibrahim.
On November 19, 2008, O'Connor published an introductory essay to a themed issue on judicial accountability in the "Denver University Law Review". She calls for a better public understanding of judicial accountability.
On January 26, 2010, O'Connor issued her own polite public dissent to the "Citizens United v. Federal Election Commission" decision on corporate political spending, telling law students that the court has created an unwelcome new path for wealthy interests to exert influence on judicial elections.
On February 17, 2016, O'Connor argued in favor of President Barack Obama naming the replacement for Antonin Scalia, opposing Republican arguments that the next president should get to fill the vacancy. She said, "I think we need somebody there to do the job now and let's get on with it"; and that "just have to pick the best person you can under the circumstances, as the appointing authority must do. It's an important position and one that we care about as a nation and as a people. And I wish the president well as he makes choices and goes down that line. It's hard."
Activities and memberships.
As a Retired Supreme Court Justice (roughly equivalent to senior status for judges of lower federal courts), O'Connor has continued to receive a full salary, maintain a staffed office with at least one law clerk, and to hear cases on a part-time basis in federal district courts and courts of appeals as a visiting judge.
In 2003, she wrote a book titled "The Majesty of the Law: Reflections of a Supreme Court Justice" (ISBN 0-375-50925-9).
On October 4, 2005, President Gene Nichol of the College of William & Mary announced that O'Connor had accepted the largely ceremonial role of becoming the 23rd Chancellor of the College, replacing Henry Kissinger, and following in the position held by Margaret Thatcher, Chief Justice Warren Burger, and President George Washington. The Investiture Ceremony was held April 7, 2006. O'Connor continued to make semi-regular visits to the college until she was succeeded in that post by former Secretary of Defense Robert Gates.
In 2005, she wrote a children's book, "Chico" (ISBN 0-525-47452-8), which gives an autobiographical description of her childhood.
O'Connor was a member of the 2006 Iraq Study Group, appointed by the U.S. Congress.
On May 15, 2006, O'Connor gave the commencement address at the William & Mary School of Law, where she said that judicial independence is "under serious attack at both the state and national level".
As of Spring 2006, O'Connor teaches a two-week course called "The Supreme Court" at the University of Arizona's James E. Rogers College of Law every spring semester.
In October 2006, O'Connor sat as a member of panels of the United States Courts of Appeals for the Second, Eighth, and Ninth Circuits, to hear arguments in one-day's cases in each court.
O'Connor chaired the Jamestown 2007 celebration, commemorating the 400th anniversary of the founding of the colony at Jamestown, Virginia in 1607. Her appearances in Jamestown dovetailed with her appearances and speeches as chancellor at The College of William & Mary nearby.
In the fall of 2007, O'Connor and W. Scott Bales taught a course at the Sandra Day O'Connor College of Law at Arizona State University.
In 2008, O'Connor was named an inaugural Harry Rathbun Visiting Fellow by the Office for Religious Life at Stanford University. On April 22, 2008, she gave "Harry's Last Lecture on a Meaningful Life" in honor of the former Stanford Law professor who shaped her undergraduate and law careers.
In 2009, O'Connor founded the 501(c)3 non-profit organization, O'Connor House, dedicated to solving complex issues through civil discourse and collaborative action.
In February 2009, O'Connor launched Our Courts, a website she created to offer interactive civics lessons to students and teachers because she was concerned about the lack of knowledge among most young Americans about how their government works. She also serves as a co-chare with Lee H. Hamilton for the Campaign for the Civic Mission of Schools. On March 3, 2009, O'Connor appeared on the satirical television program "The Daily Show" with Jon Stewart to promote the website. In August 2009, http://ourcourts.org/ added two online interactive games. The initiative expanded, becoming iCivics in May 2010, and continues to offer free lessons plans, games, and interactive videogames for middle and high school educators. During the inauguration of Mesa Municipal Court on April 16, 2010, she gracefully received a blessed garland – along with a copy of "Bhagavad-Gītā As It Is" from Dr. Prayag Narayan Misra – a Hare Krishna devotee.
She currently serves on the Board of Trustees of the National Constitution Center in Philadelphia, which is a museum dedicated to the U.S. Constitution.
She wrote the 2013 book "Out of Order: Stories from the History of the Supreme Court".
In April 2013, the Board of Directors of Justice at Stake, a national judicial reform advocacy organization, announced that O'Connor would be joining the organization as Honorary Chair.”
On September 17, 2014 O'Connor appeared on the television show "Jeopardy!" and provided a couple of video answers to the category 'Supreme Court' which appeared on the show. On the same day in Concord, New Hampshire, she gave a talk alongside her former colleague Justice David Souter about the importance of meaningful civics education in the United States.
In March 2015, O'Connor's non-profit organization, O'Connor House, became the Sandra Day O'Connor Institute. The Institute's focus is to create an environment where important policy decisions are made through a process of civil discussion, critical analysis of facts and informed participation of all citizens. O'Connor serves as Founder and Advisor to the O'Connor Institute.

</doc>
<doc id="42642" url="https://en.wikipedia.org/wiki?curid=42642" title="16th century BC">
16th century BC

The 16th century BC is a century which lasted from 1600 BC to 1501 BC.
Sovereign States.
See: List of sovereign states in the 16th century BC.

</doc>
<doc id="42643" url="https://en.wikipedia.org/wiki?curid=42643" title="17th century BC">
17th century BC

The 17th century BC is a century which lasted from 1700 BC to 1601 BC.
Sovereign States.
See: List of sovereign states in the 17th century BC.

</doc>
<doc id="42644" url="https://en.wikipedia.org/wiki?curid=42644" title="18th century BC">
18th century BC

The 18th century BC was the century which lasted from 1800 BC to 1701 BC.
Deaths.
1750 BC—Hammurabi (middle chronology)
Sovereign States.
See: List of sovereign states in the 18th century BC.

</doc>
<doc id="42645" url="https://en.wikipedia.org/wiki?curid=42645" title="The Grapes of Wrath">
The Grapes of Wrath

The Grapes of Wrath is an American realist novel written by John Steinbeck and published in 1939. The book won the National Book Award
and Pulitzer Prize for fiction, and it was cited prominently when Steinbeck was awarded the Nobel Prize in 1962.
Set during the Great Depression, the novel focuses on the Joads, a poor family of tenant farmers driven from their Oklahoma home by drought, economic hardship, agricultural industry changes and bank foreclosures forcing tenant farmers out of work. Due to their nearly hopeless situation, and in part because they are trapped in the Dust Bowl, the Joads set out for California. Along with thousands of other "Okies", they seek jobs, land, dignity, and a future.
"The Grapes of Wrath" is frequently read in American high school and college literature classes due to its historical context and enduring legacy. A celebrated Hollywood film version, starring Henry Fonda and directed by John Ford, was made in 1940.
Plot.
The narrative begins just after Tom Joad is paroled from McAlester prison for homicide. On his return to his home near Sallisaw, Oklahoma, Tom meets former preacher Jim Casy, whom he remembers from his childhood, and the two travel together. When they arrive at Tom's childhood farm home, they find it deserted. Disconcerted and confused, Tom and Casy meet their old neighbor, Muley Graves, who tells them the family has gone to stay at Uncle John Joad's home nearby. Graves tells them that the banks have evicted all the farmers, but he refuses to leave the area.
The next morning, Tom and Casy go to Uncle John's. Tom finds his family loading their remaining possessions into a Hudson Motor Car Company saloon converted to a truck; with their crops destroyed by the Dust Bowl, the family has defaulted on their bank loans, and their farm has been repossessed. Consequently, the Joads have no option but to seek work in California, described in handbills as fruitful and offering high pay. 
The Joads put everything they have into making the journey. Although leaving Oklahoma would violate his parole, Tom decides it is worth the risk, and invites Casy to join him and his family.
Traveling west on Route 66, the Joad family find the road crowded with other migrants. In makeshift camps, they hear many stories from others, some returning from California, and the group worries about lessening prospects. The family unit dwindles, too: Granpa dies along the road, and they bury him in a field; Granma dies close to the California state line; and both Noah (the eldest Joad son) and Connie Rivers (the husband of the pregnant Joad daughter, Rose of Sharon) split from the family. Led by Ma, the remaining members realize they can only continue, as nothing is left for them in Oklahoma.
Reaching California, they find the state oversupplied with labor, so wages are low, and workers are taken advantage of. The big corporate farmers are in collusion, and smaller farmers suffer from collapsing prices. Weedpatch Camp, one of the clean, utility-supplied camps operated by the Resettlement Administration, a New Deal agency, offers better conditions, but does not have enough resources to care for all the needy families. Nonetheless, as a Federal facility, the camp protects the migrants from harassment by California deputies.
In response to the exploitation, Casy becomes a labor organizer and tries to recruit for a labor union. The remaining Joads work as strikebreakers in a peach orchard, where Casy is involved in a strike that eventually turns violent. When Tom Joad witnesses Casy's fatal beating, he kills the attacker and flees as a fugitive. The Joads later leave the orchard for a cotton farm, where Tom is at risk of being arrested for the homicide.
Tom bids his mother farewell and promises to work for the oppressed. Rose of Sharon's baby is stillborn. Ma Joad remains steadfast and forces the family through the bereavement. With rain, the Joads' dwelling is flooded, and they move to higher ground. In the final chapter of the book, the family takes shelter from the flood in an old barn. Inside, they find a young boy and his father, who is dying of starvation. Rose of Sharon takes pity on the man and offers him her breast, to save him from starvation.
Development.
Steinbeck was known to have borrowed from field notes taken during 1938 by Farm Security Administration worker and author Sanora Babb. While Babb collected personal stories about the lives of the displaced migrants for a novel she was developing, her supervisor, Tom Collins, shared her reports with Steinbeck, then working at the "San Francisco News". Babb's own novel, "Whose Names Are Unknown", was eclipsed in 1939 by the success of "The Grapes of Wrath" and was shelved until it was finally published in 2004, a year before Babb's death.
"The Grapes of Wrath" developed from "The Harvest Gypsies", a series of seven articles that ran in the "San Francisco News", from October 5 to 12, 1936. The newspaper commissioned that work on migrant workers from the Midwest in California's agriculture industry. (It was later compiled and published separately.)
Title.
While writing the novel at his home, 16250 Greenwood Lane, in what is now Monte Sereno, California, Steinbeck had unusual difficulty devising a title. "The Grapes of Wrath," suggested by his wife Carol Steinbeck, was deemed more suitable than anything by the author. The title is a reference to lyrics from "The Battle Hymn of the Republic", by Julia Ward Howe:
<poem>Mine eyes have seen the glory of the coming of the Lord:
He is trampling out the vintage where the grapes of wrath are stored;
He hath loosed the fateful lightning of His terrible swift sword:
His truth is marching on.</poem>
These lyrics refer, in turn, to the biblical passage Revelation 14:19–20, an apocalyptic appeal to divine justice and deliverance from oppression in the final judgment. This and other biblical passages had inspired a long tradition of imagery of Christ in the winepress, in various media.
And the angel thrust in his sickle into the earth, and gathered the vine of the earth, and cast it into the great winepress of the wrath of God. And the winepress was trodden without the city, and blood came out of the winepress, even unto the horse bridles, by the space of a thousand and six hundred furlongs.
The phrase also appears at the end of chapter 25 in "The Grapes of Wrath", which describes the purposeful destruction of food to keep the price high:
and in the eyes of the hungry there is a growing wrath. In the souls of the people the grapes of wrath are filling and growing heavy, growing heavy for the vintage.
The image invoked by the title serves as a crucial symbol in the development of both the plot and the novel's greater thematic concerns: from the terrible winepress of Dust Bowl oppression will come terrible wrath but also the deliverance of workers through their cooperation. This is suggested but not realized within the novel.
Author's note.
When preparing to write the novel, Steinbeck wrote: "I want to put a tag of shame on the greedy bastards who are responsible for this Great Depression and its effects." He famously said, "I've done my damndest to rip a reader's nerves to rags." This work won a large following among the working class due to Steinbeck's sympathy for the migrants and workers' movement, and his accessible prose style.
Critical reception.
Steinbeck scholar John Timmerman sums up the book's influence: ""The Grapes of Wrath" may well be the most thoroughly discussed novel – in criticism, reviews, and college classrooms – of 20th century American literature." "The Grapes of Wrath" is referred to as a Great American Novel.
At the time of publication, Steinbeck's novel "was a phenomenon on the scale of a national event. It was publicly banned and burned by citizens, it was debated on national talk radio; but above all, it was read."
According to "The New York Times," it was the best-selling book of 1939 and 430,000 copies had been printed by February 1940. In that month it won the National Book Award, favorite fiction book of 1939, voted by members of the American Booksellers Association. Soon it won the Pulitzer Prize for Fiction.
The book was noted for Steinbeck's passionate depiction of the plight of the poor, and many of his contemporaries attacked his social and political views. Bryan Cordyack writes, "Steinbeck was attacked as a propagandist and a socialist from both the left and the right of the political spectrum. The most fervent of these attacks came from the Associated Farmers of California; they were displeased with the book's depiction of California farmers' attitudes and conduct toward the migrants. They denounced the book as a 'pack of lies' and labeled it 'communist propaganda'". Some accused Steinbeck of exaggerating camp conditions to make a political point. Steinbeck had visited the camps well before publication of the novel and argued their inhumane nature destroyed the settlers' spirit.
In 1962, the Nobel Prize committee cited "Grapes of Wrath" as a "great work" and as one of the committee's main reasons for granting Steinbeck the Nobel Prize for Literature.
In 2005 "Time" magazine included the novel in its "TIME 100 Best English-language Novels from 1923 to 2005". In 2009, "The Daily Telegraph" of the United Kingdom included the novel in its "100 novels everyone should read". In 1998, the Modern Library ranked "The Grapes of Wrath" tenth on its list of the 100 best English-language novels of the 20th century. In 1999, French newspaper "Le Monde" of Paris ranked "The Grapes of Wrath" as seventh on its list of the 100 best books of the 20th century. In the UK, it was listed at number 29 among the "nation's best loved novels" on the BBC's 2003 survey The Big Read.
Adaptations.
In film.
The book was quickly made into a famed, 1940 Hollywood movie of the same name directed by John Ford and starring Henry Fonda as Tom Joad. The first part of the film version follows the book fairly accurately. However, the second half and the ending, in particular, differ significantly from the book. John Springer, author of "The Fondas" (Citadel, 1973), said of Henry Fonda and his role in film version of "The Grapes of Wrath": "The Great American Novel made one of the few enduring Great American Motion Pictures."
The documentary "" (2009) revealed that "The Grapes of Wrath" was comedian Bill Hicks' favorite novel. He based his famous last words on Tom Joad's final speech: "I left in love, in laughter, and in truth, and wherever truth, love and laughter abide, I am there in spirit."
In July 2013, Steven Spielberg announced his plans to direct a remake of "The Grapes of Wrath" for DreamWorks.
In music.
Woody Guthrie's two-part song—"Tom Joad - Parts 1 & 2"—from the album "Dust Bowl Ballads" (1940), explores the protagonist's life after being paroled from prison. It was covered in 1988 by Andy Irvine, who recorded both parts as a single song—"Tom Joad"—on Patrick Street's second album, "No. 2 Patrick Street".
The band The Mission UK included a song, titled "The Grapes of Wrath", in their album "Carved in Sand" (1990).
The progressive rock band Camel released an album, titled "Dust and Dreams" (1991), inspired by the novel.
American rock singer-songwriter Bruce Springsteen named his 11th studio album, "The Ghost of Tom Joad" (1995), after the character. The first track on the album is titled "The Ghost of Tom Joad". The song – and to a lesser extent, the other songs on the album – draws comparisons between the Dust Bowl and modern times.
Rage Against the Machine recorded a version of "The Ghost of Tom Joad" in 1997.
Like Andy Irvine in 1988, Dick Gaughan recorded Woody Guthrie's "Tom Joad" on his album "Outlaws & Dreamers" (2001).
An opera based on the novel was co-produced by the Minnesota Opera, and Utah Symphony and Opera, with music by Ricky Ian Gordon and libretto by Michael Korie. The opera made its world premiere in February 2007, to favorable local reviews.
Bad Religion have a song entitled "Grains of Wraith" on their album, "New Maps of Hell" (2007). Bad Religion lead vocalist, Greg Graffin, is a fan of Steinbeck's.
The song "Dust Bowl Dance" on Mumford & Sons' album "Sigh No More" (2009) is based on the novel.
In theatre.
The Steppenwolf Theatre Company produced a stage version of the book, adapted by Frank Galati. Gary Sinise played Tom Joad for its entire run of 188 performances on Broadway in 1990. One of these performances was filmed and shown on PBS the following year.
In 1990, the Illegitimate Players theater company in Chicago produced "Of Grapes and Nuts", an original, satirical mash-up of "The Grapes of Wrath" and Steinbeck's acclaimed novella "Of Mice and Men".

</doc>
<doc id="42646" url="https://en.wikipedia.org/wiki?curid=42646" title="United States Secretary of Agriculture">
United States Secretary of Agriculture

The United States Secretary of Agriculture is the head of the U.S. Department of Agriculture. The current secretary is Tom Vilsack, who was confirmed by the U.S. Senate on 20 January 2009. The position carries similar responsibilities to those of agriculture ministers in other governments.
The department includes several organizations. The 297,000 mi2 (770,000 km²) of national forests and grasslands are managed by the United States Forest Service. The safety of food produced that are produced in the United States and sold here is ensured by the United States Food Safety and Inspection Service. The Food Stamp Program works with the states to provide food to low-income people. Advice for farmers and gardeners is provided by the United States Cooperative State Research, Education, and Extension Service.
The line of succession for the Secretary of Agriculture is as follows:
Secretaries of Agriculture.
The following is a list of Secretaries of Agriculture, since the creation of the office in 1889.
Living former Secretaries of Agriculture.
As of , there are nine living former Secretaries of Agriculture, the oldest being Robert Bergland (served 1977-1981, born 1928). The most recent Secretary of Agriculture to die was Clifford M. Hardin (served 1969–1971, born 1915), on April 4, 2010. 

</doc>
<doc id="42647" url="https://en.wikipedia.org/wiki?curid=42647" title="Cracker (band)">
Cracker (band)

Cracker is an American alternative rock band led by singer David Lowery and guitarist Johnny Hickman. The band is best known for its gold-selling 1993 album, "Kerosene Hat", which includes the hit songs "Low" and "Euro-Trash Girl."
Lowery and Hickman formed the band in 1991, releasing the album "Cracker" the following year (which included singles "Happy Birthday to Me" and "Teen Angst") on Virgin Records. The band has been touring ever since, releasing 10 studio albums and several compilations, collaborations, solo projects and live albums. The band's newest studio album, "Berkeley to Bakersfield," was released December 9, 2014 on 429 Records.
Cracker mix influences and sounds from rock, punk, grunge, psychedelia, country, blues and folk.
History.
1990s.
Shortly after Lowery's former group Camper Van Beethoven disbanded in 1990, he began demoing material along with boyhood friend, guitarist Johnny Hickman. After moving from Redlands, California to Richmond, Virginia, Lowery and Hickman recorded a demo tape, later nicknamed "Big Dirty Yellow Demos" by the group's fans, which included early versions of songs that appeared on later albums. They eventually chose the name Cracker and teamed up with fellow Redlands bass guitarist Davey Faragher. A brief tour with Virginia drummer Greg Weatherford followed.
By 1991, the newly formed band had signed a recording contract with Virgin Records and enlisted the help of several drummers/percussionists (Jim Keltner, Michael Urbano and Phil Jones), issuing its first album, "Cracker", in 1992. From the album came radio hit "Teen Angst (What the World Needs Now)", which peaked at No. 1 on Modern Rock Tracks, and a second single entitled "Happy Birthday to Me."
A year later, Cracker issued its best-selling album, "Kerosene Hat". The album included hit singles "Low" and "Get Off This," as well as a cover of the Grateful Dead's "Loser." The album sold almost half a million copies that year and eventually almost reached platinum status. Urbano performed on "Kerosene Hat" and toured with Cracker before leaving the band, along with Faragher. After a short spell with Bruce Hughes, Lowery and Hickman added Bob Rupe, formerly of The Silos, as bass guitarist and Charlie Quintana (Bob Dylan, The JuJu Hounds) on drums. In 1993, Cracker contributed the song "Good Times Bad Times" to the "Encomium" tribute album to Led Zeppelin (which was recorded after a rendition of "When the Levee Breaks" had been deemed "too weird").
Three years later, "The Golden Age" was released, with "I Hate My Generation" as the lead single. However, the music scene was shifting away from guitar-driven alternative rock, and although critically acclaimed, the album sold only moderately. Following the long-term additions of drummer Frank Funaro and keyboard player Kenny Margolis, the band tried again in 1998 with "Gentleman's Blues", with "The Good Life" as the lead single. Although the album received only a lukewarm critical response, it solidified an ever-growing and devout following both in the United States and Europe who referred to themselves as "Crumbs".
Perhaps the highlight of the 1990s was 1995 when the track "Whole Lotta Trouble" co-written by Johnny Hickman and Chris LeRoy was used in the Film "Empire Records". In this same year the song "Shake Some Action" was used in the teen romantic-comedy "Clueless"
Camper Van Beethoven unexpectedly re-formed in 1999 and released the critically acclaimed "New Roman Times." During this time, Hickman released a first solo recording, "Palmhenge", which received "Voices Choice" accolades in "The Village Voice" by the rock critic Robert Christgau and a positive review in "Blender" magazine. Since then, Lowery has performed in both bands.
2000s.
A compilation album called "Garage D'Or" was released in 2000, with one disc composed of greatest hits and three new songs, and another of out-takes, soundtrack contributions, demos and other obscurities. Rupe departed in January 2000 and was replaced by bass guitarist Brandy Wood. In 2002, the band released its next studio album, "Forever" which, once again, was met with limited commercial and critical success.
The group left Virgin in 2003 with the independent release "Countrysides", composed of eight country and western covers and one new, original song. A collaboration with the bluegrass band Leftover Salmon, "Oh Cracker, Where Art Thou?" (2003), contained bluegrass versions of many Lowery and Hickman compositions. In 2005, Cracker and Camper Van Beethoven started an annual three-night "Campout" at Pappy and Harriet's Pioneertown Palace in Pioneertown, California, close to where Lowery and Hickman met, in which they and several other bands perform, including sets by Cracker and Camper band members performing their own music. Previous years' guests have included Roger Clyne, John Doe, Neko Case, Ike Reilly, Ryan Bingham, Vermillion Lies, Jason Molina and Magnolia Electric Co, Built To Spill, Brant Bjork and the Bros, Clem Snide, Gram Rabbit and The Bellrays.
With Camper Van Beethoven bass guitarist Victor Krummenacher replacing Wood, the band released the studio album "Greenland" on June 6, 2006, and continued to tour extensively. After the departures of Margolis and Krummenacher, the band's lineup stabilized in 2007 around Hickman, Lowery, Funaro and new bass guitarist Sal Maida, who had played with Roxy Music.
Cracker released a new studio album entitled "Sunrise in the Land of Milk and Honey" to positive reviews on May 5, 2009. It was the band's first chart on the "Billboard" 200 in more than a decade, after having sold more than 3,000 copies in a week. This was in part due to the Triple A chart success of the album's lead single, "Turn On, Tune In, Drop Out With Me," which was used in the television show "Californication".
2010s.
In January 2011, Lowery released his first solo album, "The Palace Guards", on 429 Records. In March, Cracker announced Campout East, the east coast counterpart to their Campout festival, to be held in Crozet, Virginia. The first Campout East was held at Misty Mountain Camp Resort and was co-hosted by Sons of Bill. The second Campout East took place in Buena Vista, Virginia at Glen Maury Park on June 1–2, 2012.
Johnny Hickman released his second solo album, "Tilting," in July 2012.
Cracker's Facebook page mentioned on October 10, 2011, that the band would be working on a new album in 2012. In July 2014, the band announced that it was off to mix its new record.
The band's song "Low" appeared in the 2012 film "The Perks of Being a Wallflower" and again in "The Wolverine" and an episode of "Hindsight".
Drummer Frank Funaro was unable to tour due to an injury to his arm that sidelined him for all of 2014. 
In July 2014, a revival of the Kerosene Hat era lineup toured China. David Lowery and Johnny Hickman were joined on the tour by original bassist Davey Faragher and former drummer Michael Urbano. Faragher and Urbano also joined the band in recording roughly half of the double album "Berkeley to Bakersfield." The other half was recorded with an entirely new lineup that also became the current touring lineup. The album was released on December 9, 2014 with "Waited My Whole Life" released as a single.
In December 2015, Lowery (along with Camper Van Beethoven) filed a class action lawsuit against music streaming service Spotify, alleging that Spotify knowingly and unlawfully reproduced and distributed copyrighted recordings without obtaining proper music licenses.

</doc>
<doc id="42648" url="https://en.wikipedia.org/wiki?curid=42648" title="Cracker (UK TV series)">
Cracker (UK TV series)

Cracker is a British crime drama series produced by Granada Television for ITV and created and principally written by Jimmy McGovern. Set in Manchester, the series is centered on a criminal psychologist (or "cracker"), Dr Edward "Fitz" Fitzgerald, played by Robbie Coltrane, who works with the Greater Manchester Police to help them solve crimes. The show consists of three series which were originally aired from 1993 to 1995. A 100-minute special set in Hong Kong followed in 1996, and another two-hour story in 2006.
Overview.
Fitz is a classic antihero, alcoholic, a chain smoker, obese, sedentary, addicted to gambling, manic, foul-mouthed and sarcastic, and yet cerebral and brilliant. He is a genius in his speciality: criminal psychology. As Fitz confesses in "Brotherly Love": "I drink too much, I smoke too much, I gamble too much. I "am" too much."
Each case spanned several episodes and cliffhangers were quite often used, but it was not until the end of the second series that a cliffhanger was employed to tie off the series. Some of the plotlines in the cases took as their starting point real events such as the Hillsborough disaster, while others were purely fictional with only tangential ties to actual events.
Several different psychotic types were explored during the run of the show with increasingly complex psychological motivations that, as the series entered the middle of the second series, began to expand beyond the criminals being investigated to the regular cast members. As the series moved forward the storylines became as much about the interactions of the regulars as it was about the crimes. In many later episodes, in fact, the crimes often became background to intense, provocative explorations of the police officers' reactions to the crimes they investigated.
To emphasise how fine a line the police (and Fitz) walk in their close association with criminals, all three series featured several stories in which the police themselves commit criminal acts or become victims of crime.
Crew.
The first two series were written by Jimmy McGovern, excepting the fifth serial "The Big Crunch," which was contributed by Ted Whitehead. Claiming that he had "nothing more to write about," McGovern originally planned to leave after the second series, but was allowed to write the controversial rape storyline, "Men Should Weep", when he agreed to contribute a three-part story to the third series. Two of McGovern's stories, "To Say I Love You" and "Brotherly Love" (from the first and third series respectively), received Edgar Awards from the Mystery Writers of America. Each serial had a different director, with the exceptions of "To Be a Somebody" and "True Romance", both directed by Tim Fywell.
Paul Abbott, who had produced the second series, wrote the remainder of the episodes (including the feature-length special "White Ghost"). Abbott later went on to create several high-profile dramas, including "Touching Evil" (1997), "State of Play" (2003) and "Shameless" (2004). Another crew member, Nicola Shindler, who worked as script editor on the programme, later went on to found the highly successful Red Production Company.
Of the regular cast, only Coltrane and Tomlinson featured in "White Ghost" (retitled "Lucky White Ghost" for some overseas markets), which was set in Hong Kong. Although the series was still drawing large audiences, after "White Ghost" Coltrane declined to return as Fitz unless McGovern returned to write the series.
"Cracker" returned to television screens a decade after "White Ghost" in the 2006 special episode, "Nine Eleven", written by McGovern and directed by Antonia Bird. Coltrane, Flynn and O'Brien were the only actors to return in their previous roles. The new roles of DCI Walters, DS Saleh and DS McAllister were played by Richard Coyle, Nisha Nayar and Rafe Spall respectively. The story involved Fitz returning to Manchester after several years of living in Australia with Judith and his son James (who had been born during the third series) to attend his daughter Katy's wedding. The murder of an American nightclub comedian sends the police to ask Fitz for his help.
Locations.
The series was principally filmed in South Manchester, at locations including Didsbury (where Fitz lived at the fictitious address of "15 Charlotte Road") and the police station at Longsight. The internals for the police station were filmed in the old "Daily Mirror" offices in central Manchester, now The Printworks retail complex. Other Manchester locations included Victoria Railway Station, St Peter's Square, Old Trafford, the Arndale Centre, UMIST, University of Salford, the Ramada Hotel, the Star & Garter pub, Fairfield Street (opposite Piccadilly Station) and the Safeway supermarket (now Morrisons) in Chorlton-cum-Hardy. The Hulme Crescents were also used for filming in the first two episodes of series one and the first episode of series two; during which time they were being demolished.
Influences.
In some respects, "Cracker" stories are structured like episodes of "Columbo". They often begin by showing the criminal committing the crime, and so sidestep the whodunnit format which is the central attraction of many television crime dramas. Both series feature a lead character who solves crimes while masking an intelligent, perceptive nature behind a slobbish exterior; Fitz delivers his summing-up in "To Say I Love You" while doing a Peter Falk impression. However, while Lieutenant Columbo invariably solves each case to perfection, Fitz's involvement often only exacerbates the situation, for example leading police to arrest the wrong man ("One Day a Lemming Will Fly"), or unwittingly causing a serial rapist to murder his victim ("Men Should Weep").
Cracker's conception was also in some ways a reaction against the police procedural approach of fellow Granada crime serial "Prime Suspect", placing more emphasis on emotional and psychological truth than on correct police procedure. In an interview with the "NME", McGovern dismissed "Prime Suspect", noting that "Good TV writing has narrative simplicity and emotional complexity," and characterising the series as "A narratively complex story going up its own arse." Gub Neal, who produced the first series of "Cracker", is quoted as saying, "That we had adopted the right approach was confirmed for me when Jacky Malton, the senior woman police officer who advised on "Prime Suspect", said that although the way things happened in "Cracker" was sometimes highly improbable, the relationships between the police were in many ways much more credible than they had been in "Prime Suspect"."
The "Men Should Weep" storyline was originally conceived as a plot for "Prime Suspect", in which the series' protagonist, Jane Tennison, was raped.
Other versions.
In 1997 a short spoof episode, "Prime Cracker", was produced for the BBC's biennial Red Nose Day charity telethon in aid of Comic Relief. A crossover with ITV stablemate crime drama "Prime Suspect", the spoof starred Coltrane and "Prime Suspect" lead Helen Mirren as their characters from the respective series, sending up both shows.
In 1997 a 16-part US version of "Cracker" — directed by Stephen Cragg and Michael Fields — was made, starring Robert Pastorelli in Coltrane's role. The original UK story lines were transferred to Los Angeles. The series finished after the first season. It was broadcast in the UK, retitled "Fitz".

</doc>
<doc id="42649" url="https://en.wikipedia.org/wiki?curid=42649" title="Max Ernst">
Max Ernst

Max Ernst (2 April 1891 – 1 April 1976) was a German painter, sculptor, graphic artist, and poet. A prolific artist, Ernst was a primary pioneer of the Dada movement and Surrealism.
Biography.
Early life.
Max Ernst was born in Brühl, near Cologne, the third of nine children of a middle-class Catholic family. His father Philipp was a teacher of the deaf and an amateur painter, a devout Christian and a strict disciplinarian. He inspired in Max a penchant for defying authority, while his interest in painting and sketching in nature influenced Max to take up painting himself. In 1909 Ernst enrolled in the University of Bonn, studying philosophy, art history, literature, psychology and psychiatry. He visited asylums and became fascinated with the art of the mentally ill patients; he also started painting that year, producing sketches in the garden of the Brühl castle, and portraits of his sister and himself. In 1911 Ernst befriended August Macke and joined his "Die Rheinischen Expressionisten" group of artists, deciding to become an artist. In 1912 he visited the Sonderbund exhibition in Cologne, where works by Pablo Picasso and post-Impressionists such as Vincent van Gogh and Paul Gauguin profoundly influenced his approach to art. His own work was exhibited the same year together with that of the Das Junge Rheinland group, at Galerie Feldman in Cologne, and then in several group exhibitions in 1913.
In 1914 Ernst met Hans Arp in Cologne. The two soon became friends and their relationship lasted for fifty years. After Ernst completed his studies in the summer, his life was interrupted by World War I. Ernst was drafted and served both on the Western and the Eastern front. Such was the devastating effect of the war on the artist that in his autobiography he referred to his time in the army thus: "On the first of August 1914 M.E. died. He was resurrected on the eleventh of November 1918." However, for a brief period on the Western Front, Ernst was assigned to chart maps, which allowed him to continue painting. Several German Expressionist painters died in action during the war, among them Macke and Franz Marc.
Dada and surrealism.
Ernst was demobilized in 1918 and returned to Cologne. He soon married art history student Luise Straus, whom he had met in 1914. In 1919, Ernst visited Paul Klee in Munich and studied paintings by Giorgio de Chirico, which deeply impressed him. The same year, inspired partly by de Chirico and partly by studying mail-order catalogues, teaching-aide manuals, and similar sources, he produced his first collages (notably "Fiat modes", a portfolio of lithographs), a technique which would come to dominate his artistic pursuits in the years to come. Also in 1919 Ernst, social activist Johannes Theodor Baargeld, and several colleagues founded the Cologne Dada group. In 1919–20 Ernst and Baargeld published various short-lived magazines such as "Der Strom" and "die schammade", and organized Dada exhibitions.
Ernst and Luise's son Ulrich 'Jimmy' Ernst was born on 24 June 1920; he also became a painter. Ernst's marriage to Luise was short-lived. In 1921 he met Paul Éluard, who became a close lifelong friend. Éluard bought two of Ernst's paintings ("Celebes" and "Oedipus Rex") and selected six collages to illustrate his poetry collection "Répétitions". A year later the two collaborated on "Les malheurs des immortels", and then with André Breton, whom Ernst met in 1921, on the magazine "Litterature". In 1922, unable to secure the necessary papers, Ernst entered France illegally and settled into a ménage à trois with Éluard and his wife Gala in Paris suburb Saint-Brice, leaving behind his wife and son. During his first two years in Paris Ernst took various odd jobs to make a living and continued to paint. In 1923 the Éluards moved to a new home in Eaubonne, near Paris, where Ernst painted numerous murals. The same year his works were exhibited at "Salon des Indépendants".
Although apparently accepting the ménage à trois at first, Éluard eventually became more concerned about the affair. In 1924 he abruptly left, first for Monaco, and then for Saigon, Vietnam. He soon asked his wife and Max Ernst to join him; both had to sell numerous paintings to finance the trip. Ernst went to Düsseldorf and sold a large number of his works to a longtime friend, Johanna Ey, owner of gallery "Das Junge Rheinland". After a brief time together in Saigon, the trio decided that Gala would remain with Paul. The Éluards returned to Eaubonne in early September, while Ernst followed them some months later, after exploring more of South-East Asia. He returned to Paris in late 1924 and soon signed a contract with Jacques Viot that allowed him to paint full-time. In 1925 Ernst established a studio at 22, rue Tourlaque.
Constantly experimenting, in 1925 Ernst invented a graphic art technique called frottage (see Surrealist techniques), which uses pencil rubbings of objects as a source of images. He also created the 'grattage' technique, in which paint is scraped across canvas to reveal the imprints of the objects placed beneath. He used this technique in his famous painting "Forest and Dove" (as shown at the Tate Modern).
The next year he collaborated with Joan Miró on designs for Sergei Diaghilev. With Miró's help, Ernst pioneered grattage, in which he troweled pigment from his canvases. He also explored with the technique of decalcomania, which involves pressing paint between two surfaces.
Ernst developed a fascination with birds that was prevalent in his work. His alter ego in paintings, which he called Loplop, was a bird. He suggested that this alter-ego was an extension of himself stemming from an early confusion of birds and humans. He said that one night when he was young, he woke up and found that his beloved bird had died, and a few minutes later his father announced that his sister was born. Loplop often appeared in collages of other artists' work, such as "Loplop presents André Breton". Ernst drew a great deal of controversy with his 1926 painting "The Virgin Chastises the infant Jesus before Three Witnesses: André Breton, Paul Éluard, and the Painter". In 1927 Ernst married Marie-Berthe Aurenche, and it is thought his relationship with her may have inspired the erotic subject matter of "The Kiss" and other works of that year. Ernst appeared in the 1930 film "L'Âge d'Or", directed by self-identifying Surrealist Luis Buñuel. Ernst began to make sculpture in 1934, and spent time with Alberto Giacometti. In 1938, the American heiress and artistic patron Peggy Guggenheim acquired a number of Max Ernst's works, which she displayed in her new gallery in London. Ernst and Peggy Guggenheim later were married (1942–1946).
World War II and later life.
In September 1939, the outbreak of World War II caused Ernst to be interned as an "undesirable foreigner" in Camp des Milles, near Aix-en-Provence, along with fellow surrealist, Hans Bellmer, who had recently emigrated to Paris. At the time, he was living with his then lover, Leonora Carrington who, not knowing whether or not he would return, saw no option but to sell their house to repay their debts and leave for Spain. Thanks to the intercession of Paul Éluard and other friends, including the journalist Varian Fry, he was released a few weeks later. Soon after the German occupation of France, he was arrested again, this time by the Gestapo, but managed to escape and flee to America with the help of Peggy Guggenheim and Fry. Ernst and Peggy Guggenheim arrived in the United States in 1941 and were married at the end of the year. Along with other artists and friends (Marcel Duchamp and Marc Chagall) who had fled from the war and lived in New York City, Ernst helped inspire the development of Abstract expressionism.
His marriage to Guggenheim did not last, and in Beverly Hills, California in October 1946, in a double ceremony with Man Ray and Juliet P. Browner, he married Dorothea Tanning. The couple first made their home in Sedona, Arizona. In 1948 Ernst wrote the treatise "Beyond Painting". As a result of the publicity, he began to achieve financial success. From the 1950s onwards he lived mainly in France. In 1954 he was awarded the Grand Prize for painting at the Venice Biennale. He died at the age of 84 on 1 April 1976 in Paris, and was interred at Père Lachaise Cemetery.
Legacy.
Max Ernst's life and career are examined in Peter Schamoni's 1991 documentary "Max Ernst". Dedicated to the art historian Werner Spies, it was assembled from interviews with Ernst, stills of his paintings and sculptures, and the memoirs of his wife Dorothea Tanning and son Jimmy. The 101-minute German film was released on DVD with English subtitles by Image Entertainment.
In 2005, "Max Ernst: A Retrospective" opened at the Metropolitan Museum of Art and included works such as "Celebes" (1921), "Ubu Imperator" (1923), and "Fireside Angel" (1937), which is one of the few definitively political pieces and is sub-titled "The Triumph of Surrealism" depicting a raging bird-like creature that symbolizes the wave of fascism that enveloped Europe. The exhibition also includes Ernst's works that experiment with free association writing and the techniques of frottage, created from a rubbing from a textured surface; grattage, involving scratching at the surface of a painting; and decalcomania, which involves altering a wet painting by pressing a second surface against it and taking it away.
Ernst's son Jimmy, a well known German/American abstract expressionist painter, who lived on the south shore of Long Island, died in 1984. His memoirs, "A Not-So-Still Life", were published shortly before his death. Max Ernst's grandson Eric and his granddaughter Amy are both artists and writers.

</doc>
<doc id="42650" url="https://en.wikipedia.org/wiki?curid=42650" title="Marcel Duchamp">
Marcel Duchamp

Henri-Robert-Marcel Duchamp (; 28 July 1887 – 2 October 1968) was a French, naturalized American painter, sculptor, chess player and writer whose work is associated with Cubism, conceptual art and Dada, although he was careful about his use of the term Dada and was not directly associated with Dada groups. Duchamp is commonly regarded, along with Pablo Picasso and Henri Matisse, as one of the three artists who helped to define the revolutionary developments in the plastic arts in the opening decades of the twentieth century, responsible for significant developments in painting and sculpture. Duchamp has had an immense impact on twentieth-century and twenty first-century art. By World War I, he had rejected the work of many of his fellow artists (like Henri Matisse) as "retinal" art, intended only to please the eye. Instead, Duchamp wanted to put art back in the service of the mind.
Early life and education.
Marcel Duchamp was born at Blainville-Crevon in Normandy, France, and grew up in a family that enjoyed cultural activities. The art of painter and engraver , his maternal grandfather, filled the house, and the family liked to play chess, read books, paint, and make music together.
Of Eugene and Lucie Duchamp's seven children, one died as an infant and four became successful artists. Marcel Duchamp was the brother of:
As a child, with his two older brothers already away from home at school in Rouen, Duchamp was close to his sister Suzanne, who was a willing accomplice in games and activities conjured by his fertile imagination. At 8 years old, Duchamp followed in his brothers' footsteps when he left home and began schooling at the Lycée Pierre-Corneille, in Rouen. Two other students in his class also became well-known artists and lasting friends: Robert Antoine Pinchon and Pierre Dumont. For the next 8 years, he was locked into an educational regime which focused on intellectual development. Though he was not an outstanding student, his best subject was mathematics and he won two mathematics prizes at the school. He also won a prize for drawing in 1903, and at his commencement in 1904 he won a coveted first prize, validating his recent decision to become an artist.
He learned academic drawing from a teacher who unsuccessfully attempted to protect his students from Impressionism, Post-Impressionism, and other avant-garde influences. However, Duchamp's true artistic mentor at the time was his brother Jacques Villon, whose fluid and incisive style he sought to imitate. At 14, his first serious art attempts were drawings and watercolors depicting his sister Suzanne in various poses and activities. That summer he also painted landscapes in an Impressionist style using oils.
Early work.
Duchamp's early art works align with Post-Impressionist styles. He experimented with classical techniques and subjects. When he was later asked about what had influenced him at the time, Duchamp cited the work of Symbolist painter Odilon Redon, whose approach to art was not outwardly anti-academic, but quietly individual.
He studied art at the Académie Julian from 1904 to 1905, but preferred playing billiards to attending classes. During this time Duchamp drew and sold cartoons which reflected his ribald humor. Many of the drawings use verbal puns (sometimes spanning multiple languages), visual puns, or both. Such play with words and symbols engaged his imagination for the rest of his life.
In 1905, he began his compulsory military service with the 39th Infantry Regiment, working for a printer in Rouen. There he learned typography and printing processes—skills he would use in his later work.
Due to his eldest brother Jacques' membership in the prestigious Académie royale de peinture et de sculpture Duchamp's work was exhibited in the 1908 Salon d'Automne. The following year his work was featured in the Salon des Indépendants. Of Duchamp's pieces in the show, critic Guillaume Apollinaire—who was to become a friend—criticized what he called "Duchamp's very ugly nudes". Duchamp also became lifelong friends with exuberant artist Francis Picabia after meeting him at the 1911 Salon d'Automne, and Picabia proceeded to introduce him to a lifestyle of fast cars and "high" living.
In 1911, at Jacques' home in Puteaux, the brothers hosted a regular discussion group with Cubist artists including Picabia, Robert Delaunay, Fernand Léger, Roger de La Fresnaye, Albert Gleizes, Jean Metzinger, Juan Gris, and Alexander Archipenko. Poets and writers also participated. The group came to be known as the Puteaux Group, or the Section d'Or. Uninterested in the Cubists' seriousness or in their focus on visual matters, Duchamp did not join in discussions of Cubist theory, and gained a reputation of being shy. However, that same year he painted in a Cubist style, and added an impression of motion by using repetitive imagery.
During this period Duchamp's fascination with transition, change, movement and distance became manifest, and like many artists of the time, he was intrigued with the concept of depicting the fourth dimension in art. His painting "Sad Young Man on a Train" embodies this concern:
First, there's the idea of the movement of the train, and then that of the sad young man who is in a corridor and who is moving about; thus there are two parallel movements corresponding to each other. Then, there is the distortion of the young man—I had called this "elementary parallelism". It was a formal decomposition; that is, linear elements following each other like parallels and distorting the object. The object is completely stretched out, as if elastic. The lines follow each other in parallels, while changing subtly to form the movement, or the form of the young man in question. I also used this procedure in the "Nude Descending a Staircase".
Works from this period included his first "machine" painting, "Coffee Mill (Moulin à café)" (1911), which he gave to his brother Raymond Duchamp-Villon. The "Coffee Mill" shows similarity to the "grinder" mechanism of the "Large Glass" he was to create years later.
In his 1911, "Portrait of Chess Players" ("Portrait de joueurs d'échecs") there is the Cubist overlapping frames and multiple perspectives of his two brothers playing chess, but to that Duchamp added elements conveying the unseen mental activity of the players. (Notably, "échec" is French for "failure".)
"Nude Descending a Staircase No.2".
Duchamp's first work to provoke significant controversy was "Nude Descending a Staircase, No. 2" "(Nu descendant un escalier n° 2)" (1912). The painting depicts the mechanistic motion of a nude, with superimposed facets, similar to motion pictures. It shows elements of both the fragmentation and synthesis of the Cubists, and the movement and dynamism of the Futurists.
He first submitted the piece to appear at the Cubist Salon des Indépendants, but Albert Gleizes (according to Duchamp in an interview with Pierre Cabanne, p. 31) asked Duchamp's brothers to have him voluntarily withdraw the painting, or to paint over the title that he had painted on the work and rename it something else. Duchamp's brothers did approach him with Gleizes' request, but Duchamp quietly refused. However, there was no jury at the Salon des Indépendants and Gleizes was in no position to reject the painting. The controversy, according to art historian Peter Brooke, was not whether the work should be hung or not, but whether or not it should be hung with the Cubist group.
Of the incident Duchamp later recalled, "I said nothing to my brothers. But I went immediately to the show and took my painting home in a taxi. It was really a turning point in my life, I can assure you. I saw that I would not be very much interested in groups after that." Yet Duchamp did appear in the illustrations to "Du "Cubisme"", he participated in the "La Maison Cubiste (Cubist House)", organized by the designer André Mare for the Salon d'Automne of 1912 (a few months after the Indépendants); he signed the Section d'Or invitation and participated in the Section d'Or exhibition during the fall of 1912. The impression is, Brooke writes, "it was precisely because he wished to remain part of the group that he withdrew the painting; and that, far from being ill treated by the group, he was given a rather privileged position, probably through the patronage of Picabia".
He later submitted the painting to the 1913 "Armory Show" in New York City. In addition to displaying works of American artists, this show was the first major exhibition of modern trends coming out of Paris, encompassing experimental styles of the European avant-garde, including Fauvism, Cubism, and Futurism. American show-goers, accustomed to realistic art, were scandalized, and the "Nude" was at the center of much of the controversy.
Leaving "retinal art" behind.
At about this time, Duchamp read Max Stirner's philosophical tract, "The Ego and Its Own", the study of which he considered another turning point in his artistic and intellectual development. He called it "a remarkable book ... which advances no formal theories, but just keeps saying that the ego is always there in everything."
While in Munich in 1912, he painted the last of his Cubist-like paintings and he started "Bride Stripped Bare by Her Bachelors, Even" image, and began making plans for "The Large Glass" – scribbling short notes to himself, sometimes with hurried sketches. It would be over 10 years before this piece was completed. Not much else is known about the two-month stay in Munich except that the friend he visited was intent on showing him the sights and the nightlife and that he was influenced by the works of the 16th century German painter Lucas Cranach the Elder in Munich’s famed Alte Pinakothek, known for its Old Master paintings. Duchamp recalled that he daily took the short walk to visit this museum. Duchamp scholars have long recognized in Cranach the subdued ochre and brown color range Duchamp later employed.
The same year, Duchamp also attended a performance of a stage adaptation of Raymond Roussel's 1910 novel, "Impressions d'Afrique" which featured plots that turned in on themselves, word play, surrealistic sets and humanoid machines. He credited the drama with having radically changed his approach to art, and having inspired him to begin the creation of his "The Bride Stripped Bare By Her Bachelors, Even", also known as "The Large Glass". Work on "The Large Glass" continued into 1913, with his invention of inventing a repertoire of forms. He made notes, sketches and painted studies, and even drew some of his ideas on the wall of his apartment.
Towards the end of 1912, he traveled with Picabia, Apollinaire and Gabrielle Buffet-Picabia through the Jura mountains, an adventure that Buffet-Picabia described as one of their "forays of demoralization, which were also forays of witticism and clownery ... the disintegration of the concept of art". Duchamp's notes from the trip avoid logic and sense, and have a surrealistic, mythical connotation.
Duchamp painted few canvases after 1912, and in those he did, he attempted to remove "painterly" effects, and instead to use a technical drawing approach.
His broad interests led him to an exhibition of aviation technology during this period, after which Duchamp said to his friend Constantin Brâncuși, "Painting is washed up. Who will ever do anything better than that propeller? Tell me, can you do that?". Brâncuși later sculpted bird forms, which U.S. Customs officials mistook for aviation parts and for which they attempted to collect import duties.
In 1913, Duchamp withdrew from painting circles and began working as a librarian in the Bibliothèque Sainte-Geneviève to be able to earn a living wage while concentrating on scholarly realms and working on his "Large Glass". He studied math and physics – areas in which exciting new discoveries were taking place. The theoretical writings of Henri Poincaré particularly intrigued and inspired Duchamp. Poincaré postulated that the laws believed to govern matter were created solely by the minds that "understood" them and that no theory could be considered "true". "The things themselves are not what science can reach..., but only the relations between things. Outside of these relations there is no knowable reality",Poincaré wrote in 1902. Reflecting the influence of Poincaré's writings, Duchamp tolerated any interpretation of his art by regarding it as the creation of the person who formulated it, not as truth.
Duchamp's own art-science experiments began during his tenure at the library. To make one of his favorite pieces, "3 Standard Stoppages" ("3 stoppages étalon"), he dropped three 1-meter lengths of thread onto prepared canvases, one at a time, from a height of 1 meter. The threads landed in three random undulating positions. He varnished them into place on the blue-black canvas strips and attached them to glass. He then cut three wood slats into the shapes of the curved strings, and put all the pieces into a croquet box. Three small leather signs with the title printed in gold were glued to each of the "stoppage" backgrounds. The piece appears to literally follow Poincaré's "School of the Thread", part of a book on classical mechanics.
In his studio he mounted a bicycle wheel upside down onto a stool, spinning it occasionally just to watch it. Although it is often assumed that the "Bicycle Wheel" represents the first of Duchamp's "Readymades", this particular installation was never submitted for any art exhibition, and it was eventually lost. However, initially, the wheel was simply placed in the studio to create atmosphere: "I enjoyed looking at it just as I enjoy looking at the flames dancing in a fireplace."
After World War I was declared in 1914, with his brothers and many friends in military service and himself exempted, Duchamp felt uncomfortable in Paris. Meanwhile, "Nude Descending a Staircase No. 2" had scandalized Americans at the Armory Show, and helped secure the sale of all four of his paintings in the exhibition. Thus, being able to finance the trip, Duchamp decided to emigrate to the United States in 1915. To his surprise, he found he was a celebrity when he arrived in New York in 1915, where he quickly befriended art patron Katherine Dreier and artist Man Ray. Duchamp's circle included art patrons Louise and Walter Conrad Arensberg, actress and artist Beatrice Wood and Francis Picabia, as well as other avant-garde figures. Though he spoke little English, in the course of supporting himself by giving French lessons and through some library work, he quickly learned the language. Duchamp became part of an artist colony in Ridgefield, New Jersey, across the Hudson River from New York City.
For two years the Arensbergs, who would remain his friends and patrons for 42 years, were the landlords of his studio. In lieu of rent, they agreed that his payment would be "The Large Glass". An art gallery offered Duchamp $10,000 per year in exchange for all of his yearly production, but Duchamp declined the offer, preferring to continue his work on "The Large Glass".
Société Anonyme.
Duchamp created the Société Anonyme in 1920, along with Katherine Dreier and Man Ray. This was the beginning of his lifelong involvement in art dealing and collecting. The group collected modern art works, and arranged modern art exhibitions and lectures throughout the 1930s.
By this time Walter Pach, one of the coordinators of the 1913 Armory Show, sought Duchamp's advice on modern art. Beginning with Société Anonyme, Dreier also depended on Duchamp's counsel in gathering her collection, as did Arensberg. Later Peggy Guggenheim, Museum of Modern Art directors Alfred Barr and James Johnson Sweeney consulted with Duchamp on their modern art collections and shows.
Dada.
Dada or Dadaism was an art movement of the European avant-garde in the early 20th century. It began in Zurich, Switzerland in 1916, spreading to Berlin shortly thereafter. To quote Dona Budd's "The Language of Art Knowledge", Dada was born out of negative reaction to the horrors of World War I. This international movement was begun by a group of artists and poets associated with the Cabaret Voltaire in Zurich. Dada rejected reason and logic, prizing nonsense, irrationality and intuition. The origin of the name Dada is unclear; some believe that it is a nonsensical word. Others maintain that it originates from the Romanian artists Tristan Tzara and Marcel Janco's frequent use of the words da, da, meaning yes, yes in the Romanian language. Another theory says that the name "Dada" came during a meeting of the group when a paper knife stuck into a French-German dictionary happened to point to 'dada', a French word for 'hobbyhorse'. The movement primarily involved visual arts, literature, poetry, art manifestoes, art theory, theatre, and graphic design, and concentrated its anti-war politics through a rejection of the prevailing standards in art through anti-art cultural works. In addition to being anti-war, Dada was also anti-bourgeois and had political affinities with the radical left.
Dada activities included public gatherings, demonstrations, and publication of art/literary journals; passionate coverage of art, politics, and culture were topics often discussed in a variety of media. Key figures in the movement included Hugo Ball, Emmy Hennings, Hans Arp, Raoul Hausmann, Hannah Höch, Johannes Baader, Tristan Tzara, Francis Picabia, Richard Huelsenbeck, Georg Grosz, John Heartfield, Marcel Duchamp, Beatrice Wood, Kurt Schwitters, and Hans Richter, among others. The movement influenced later styles like the avant-garde and downtown music movements, and groups including surrealism, Nouveau réalisme, pop art and Fluxus.
Dada is the groundwork to abstract art and sound poetry, a starting point for performance art, a prelude to postmodernism, an influence on pop art, a celebration of antiart to be later embraced for anarcho-political uses in the 1960s and the movement that lay the foundation for Surrealism.
New York Dada had a less serious tone than that of European Dadaism, and was not a particularly organized venture. Duchamp's friend Francis Picabia connected with the Dada group in Zürich, bringing to New York the Dadaist ideas of absurdity and "anti-art". Duchamp and Picabia first met in September 1911 at the Salon d'Automne in Paris, where they were both exhibiting. Duchamp showed a larger version of his "Young Man and Girl in Spring" 1911, a work that had an Edenic theme and a thinly veiled sexuality also found in Picabia's contemporaneous "Adam and Eve" 1911. According to Duchamp, "our friendship began right there". A group met almost nightly at the Arensberg home, or caroused in Greenwich Village. Together with Man Ray, Duchamp contributed his ideas and humor to the New York activities, many of which ran concurrent with the development of his Readymades and 'The Large Glass.'
The most prominent example of Duchamp's association with Dada was his submission of "Fountain", a urinal, to the Society of Independent Artists exhibit in 1917. Artworks in the Independent Artists shows were not selected by jury, and all pieces submitted were displayed. However, the show committee insisted that "Fountain" was not art, and rejected it from the show. This caused an uproar amongst the Dadaists, and led Duchamp to resign from the board of the Independent Artists.
Along with Henri-Pierre Roché and Beatrice Wood, Duchamp published a Dada magazine in New York, titled "The Blind Man", which included art, literature, humor and commentary.
When he returned to Paris after World War I, Duchamp did not participate in the Dada group.
Readymades.
"Readymades" were found objects which Duchamp chose and presented as art. In 1913, Duchamp installed a "Bicycle Wheel" in his studio. However, the idea of "Readymades" did not fully develop until 1915. The idea was to question the very notion of Art, and the adoration of art, which Duchamp found "unnecessary"
"Bottle Rack" (1914), a bottle drying rack signed by Duchamp, is considered to be the first "pure" readymade. "Prelude to a Broken Arm" (1915), a snow shovel, also called "In Advance of the Broken Arm", followed soon after. His "Fountain", a urinal signed with the pseudonym "R. Mutt", shocked the art world in 1917. "Fountain" was selected in 2004 as "the most influential artwork of the 20th century" by 500 renowned artists and historians.
In 1919, Duchamp made a parody of the "Mona Lisa" by adorning a cheap reproduction of the painting with a mustache and goatee. To this he added the inscription "L.H.O.O.Q.", a phonetic game which, when read out loud in French quickly sounds like ""Elle a chaud au cul"". This can be translated as "She has a hot ass", implying that the woman in the painting is in a state of sexual excitement and availability. It may also have been intended as a Freudian joke, referring to Leonardo da Vinci's alleged homosexuality. Duchamp gave a "loose" translation of L.H.O.O.Q. as "there is fire down below" in a late interview with Arturo Schwarz. According to Rhonda Roland Shearer, the apparent "Mona Lisa" reproduction is in fact a copy modeled partly on Duchamp's own face. Research published by Shearer also speculates that Duchamp himself may have created some of the objects which he claimed to be "found objects".
"The Large Glass".
Duchamp worked on his complex Futurism inspired piece "The Bride Stripped Bare by Her Bachelors, Even (The Large Glass)" from 1915 to 1923, with the exception of periods in Buenos Aires and Paris in 1918–1920. He executed the work on two panes of glass with materials such as lead foil, fuse wire, and dust. It combines chance procedures, plotted perspective studies, and laborious craftsmanship. He published notes for the piece, "The Green Box", intended to complement the visual experience. They reflect the creation of unique rules of physics, and a mythology which describes the work. He stated that his "hilarious picture" is intended to depict the erotic encounter between a bride and her nine bachelors.
The piece was inspired by a performance of the stage adaptation of Roussel's novel "Impressions d'Afrique" which Duchamp attended in 1912. Notes, sketches and plans for the work were drawn on Duchamp's studio walls as early as 1913. In order to concentrate on the work free from material obligations, Duchamp found work as a librarian while living in France. After immigrating to the United States in 1915, he commenced his work on the piece financed by the support of the Arensbergs.
The piece is partially constructed as a retrospective of Duchamp's works, including a three-dimensional reproduction of his earlier paintings "Bride" (1912), "Chocolate Grinder" (1914) and "Glider containing a water mill in neighboring metals" (1913–1915), which has opened for numerous interpretations. The work was formally declared "Unfinished" in 1923. Going home from its first public exhibition, the glass broke in its shipping crate and received a large crack in the glass. Duchamp repaired it, but left the cracks in the glass intact, accepting the chance element as a part of the piece.
Until 1969 when the Philadelphia Museum of Art revealed Duchamp's "Étant donnés" tableau, "The Large Glass" was thought to have been his last major work.
Kinetic works.
Duchamp's interest in kinetic works can be discerned as early as the notes for "The Large Glass" and the "Bicycle Wheel" readymade, and despite losing interest in "retinal art", he retained interest in visual phenomena. In 1920, with help from Man Ray, Duchamp built a motorized sculpture, "Rotative plaques verre, optique de précision" ("Rotary Glass Plates, Precision Optics"). The piece, which he did not consider to be art, involved a motor to spin pieces of rectangular glass on which were painted segments of a circle. When the apparatus spins, an optical illusion occurs, in which the segments appear to be closed concentric circles. Man Ray set up equipment to photograph the initial experiment, but when they turned the machine on for the second time, a belt broke, and caught a piece of the glass, which after glancing off Man Ray's head, shattered into bits.
After moving back to Paris in 1923, at André Breton's urging and through the financing of Jacques Doucet, Duchamp built another optical device based on the first one, "Rotative Demisphère, optique de précision" (Rotary Demisphere, Precision Optics). This time the optical element was a globe cut in half, with black concentric circles painted on it. When it spins, the circles appear to move backwards and forwards in space. Duchamp asked that Doucet not exhibit the apparatus as art.
"Rotoreliefs" were the next phase of Duchamp's spinning works. To make the optical "play toys", he painted designs on flat cardboard circles and spun them on a phonographic turntable. When spinning, the flat disks appeared three-dimensional. He had a printer produce 500 sets of six of the designs, and set up a booth at a 1935 Paris inventors' show to sell them. The venture was a financial disaster, but some optical scientists thought they might be of use in restoring three-dimensional stereoscopic sight to people who have lost vision in one eye. In collaboration with Man Ray and Marc Allégret, Duchamp filmed early versions of the "Rotoreliefs" and they named the film "Anémic Cinéma" (1926). Later, in Alexander Calder's studio in 1931, while looking at the sculptor's kinetic works, Duchamp suggested that these should be called "mobiles". Calder agreed to use this novel term in his upcoming show. To this day, sculptures of this type are called "mobiles".
Musical ideas.
Between 1912 and 1915, Duchamp worked with various musical ideas. At least three pieces have survived: two compositions and a note for a musical happening. The two compositions are based on chance operations. "Erratum Musical", written for three voices, was published in 1934. "La Mariée mise à nu par ses célibataires même. Erratum Musical" is unfinished and was never published or exhibited during Duchamp's lifetime. According to the manuscript, the piece was intended for a mechanical instrument "in which the virtuoso intermediary is suppressed". The manuscript also contains a description for "An apparatus automatically recording fragmented musical periods", consisting of a funnel, several open-end cars and a set of numbered balls. These pieces predate John Cage's Music of Changes (1951), which is often considered the first modern piece to be conceived largely through random procedures.
In 1968, Duchamp and John Cage appeared together at a concert entitled "Reunion", playing a game of chess and composing Aleatoric music by triggering a series of photoelectric cells underneath the chessboard.
Rrose Sélavy.
"Rrose Sélavy", also spelled Rose Sélavy, was one of Duchamp's pseudonyms. The name, a pun, sounds like the French phrase "Eros, c'est la vie", which may be translated as "Eros, such is life". It has also been read as "arroser la vie" ("to make a toast to life"). Sélavy emerged in 1921 in a series of photographs by Man Ray showing Duchamp dressed as a woman. Through the 1920s Man Ray and Duchamp collaborated on more photos of Sélavy. Duchamp later used the name as the byline on written material and signed several creations with it.
These included at least one sculpture, "Why Not Sneeze Rrose Sélavy?" (1921). The sculpture, a type of readymade called an assemblage, consists of a mercury oral thermometer, 152 white cubes (made of marble, but resembling sugar cubes), a piece of cuttlebone, and a tiny porcelain dish inside a birdcage.
The inspiration for the name "Rrose Sélavy" may have been Belle da Costa Greene, J.P. Morgan's librarian of the Pierpont Morgan Library. Following the death of J.P. Morgan, Sr., Greene became the Library's director, working there for a total of forty-three years. Empowered by the Morgans, she built the library collection, buying and selling rare manuscripts, books and art.
Rrose Sélavy and the other pseudonyms Duchamp used may be read as a comment on the fallacy of romanticizing the conscious individuality or subjectivity of the artist, a theme that is also a prominent subtext of the Readymades. Duchamp said in an interview,"You think you're doing something entirely your own, and a year later you look at it and you see actually the roots of where your art comes from without your knowing it at all."
Transition from art to chess.
In 1918, Duchamp took leave of the New York art scene, interrupting his work on the "Large Glass", and went to Buenos Aires, where he remained for nine months and often played chess. He carved his own chess set from wood with help from a local craftsman who made the knights. He moved to Paris in 1919, and then back to the United States in 1920. Upon his return to Paris in 1923, Duchamp was, in essence, no longer a practicing artist. Instead, his main interest was chess, which he studied for the rest of his life to the exclusion of most other activities.
Duchamp is seen, briefly, playing chess with Man Ray in the short film "Entr'acte" (1924) by René Clair. He designed the 1925 Poster for the Third French Chess Championship, and as a competitor in the event, finished at fifty percent (3–3, with two draws). Thus he earned the title of chess master. During this period his fascination with chess so distressed his first wife that she glued his pieces to the board. Duchamp continued to play in the French Championships and also in the Chess Olympiads from 1928–1933, favoring hypermodern openings such as the Nimzo-Indian.
Sometime in the early 1930s, Duchamp reached the height of his ability, but realized that he had little chance of winning recognition in top-level chess. In the following years, his participation in chess tournaments declined, but he discovered correspondence chess and became a chess journalist, writing weekly newspaper columns. While his contemporaries were achieving spectacular success in the art world by selling their works to high-society collectors, Duchamp observed, "I am still a victim of chess. It has all the beauty of art—and much more. It cannot be commercialized. Chess is much purer than art in its social position." On another occasion, Duchamp elaborated, "The chess pieces are the block alphabet which shapes thoughts; and these thoughts, although making a visual design on the chess-board, express their beauty abstractly, like a poem. ... I have come to the personal conclusion that while all artists are not chess players, all chess players are artists."
In 1932, Duchamp teamed with chess theorist Vitaly Halberstadt to publish "L'opposition et cases conjuguées sont réconciliées" (Opposition and Sister Squares are Reconciled), known as corresponding squares. This treatise describes the Lasker-Reichhelm position, an extremely rare type of position that can arise in the endgame. Using enneagram-like charts that fold upon themselves, the authors demonstrated that in this position, the most Black can hope for is a draw.
The theme of the "endgame" is important to an understanding of Duchamp's complex attitude towards his artistic career. Irish playwright Samuel Beckett was an associate of Duchamp, and used the theme as the narrative device for the 1957 play of the same name, "Endgame". In 1968, Duchamp played an artistically important chess match with avant-garde composer John Cage, at a concert entitled "Reunion". Music was produced by a series of photoelectric cells underneath the chessboard, triggered sporadically by normal game play.
On choosing a career in chess, Duchamp said, "If Bobby Fischer came to me for advice, I certainly would not discourage him—as if anyone could—but I would try to make it positively clear that he will never have any money from chess, live a monk-like existence and know more rejection than any artist ever has, struggling to be known and accepted." Duchamp left a legacy to chess in the form of an enigmatic endgame problem he composed in 1943. The problem was included in the announcement for Julian Levi's gallery exhibition "Through the Big End of the Opera Glass", printed on translucent paper with the faint inscription: "White to play and win". Grandmasters and endgame specialists have since grappled with the problem, with most concluding that there is no solution.
Later artistic involvement.
Although Duchamp was no longer considered to be an active artist, he continued to consult with artists, art dealers and collectors. From 1925 he often traveled between France and the United States, and made New York's Greenwich Village his home in 1942. He also occasionally worked on artistic projects such as the short film "Anemic Cinema" (1926), "Box in a Valise" (1935–41), "Self Portrait in Profile" (1958) and the larger work "Étant Donnés" (1946–66). In 1943, he participated with Maya Deren in her unfinished film "The Witch's Cradle", filmed in Peggy Guggenheim's Art of This Century gallery.
From the mid-1930s onwards, he collaborated with the Surrealists; however, he did not join the movement, despite the coaxing of André Breton. From then until 1944, together with Max Ernst, Eugenio Granell and Breton, Duchamp edited the Surrealist periodical "VVV", and also served as an advisory editor for the magazine "View", which featured him in its March 1945 edition, thus introducing him to a broader American audience.
Duchamp's influence on the art world remained behind the scenes until the late 1950s, when he was "discovered" by young artists such as Robert Rauschenberg and Jasper Johns, who were eager to escape the dominance of Abstract Expressionism. He was a co-founder of the international literary group Oulipo in 1960. Interest in Duchamp was reignited in the 1960s, and he gained international public recognition. In 1963, the Pasadena Art Museum mounted his first retrospective exhibition, and there he appeared in an iconic photograph playing chess opposite nude model Eve Babitz. The photograph was later described by the Smithsonian Archives of American Art as being "among the key documentary images of American modern art".
In 1966 the Tate Gallery hosted a large exhibit of his work. Other major institutions, including the Philadelphia Art Museum and the Metropolitan Museum of Art, followed with large showings of Duchamp's work. He was invited to lecture on art and to participate in formal discussions, as well as sitting for interviews with major publications. As the last surviving member of the Duchamp family of artists, in 1967 Duchamp helped to organize an exhibition in Rouen, France, called "Les Duchamp: Jacques Villon, Raymond Duchamp-Villon, Marcel Duchamp, Suzanne Duchamp". Parts of this family exhibition were later shown again at the Musée National d'Art Moderne in Paris.
Exhibition design.
Duchamp participated in the design of the 1938 International Surrealist Exhibition, which was held at the "Galerie des Beaux-arts", Paris. The show featured more than 60 artists from different countries, including approximately 300 paintings, objects, collages, photographs, and installations. The surrealists wanted to create an exhibition which in itself would be a creative act, and André Breton named Duchamp, Wolfgang Paalen, Man Ray, Salvador Dali, and Max Ernst to help him. At the exhibition's entrance he placed Salvador Dalí's "Rainy Taxi", a work consisting of a taxicab rigged to produce a drizzle of water down the inside of its windows, with a shark-headed creature in the driver's seat, and a blond mannequin covered with live snails in the back. In this way Duchamp confronted guests entering the exhibition, who were in full evening dress.
"Surrealist Street" filled one side of the lobby with mannequins dressed by various surrealists. The main hall was a simulation of a dark subterranean cave with 1,200 empty coal bags suspended from the ceiling. The floor was covered by Paalen with dead leaves and mud from the Montparnasse Cemetery. In the middle of the grand hall underneath Duchamp´s coal sacks, Paalen installed an artificial water-filled pond with real water lilies and reeds, which he called "Avant La Mare". Illumination was provided only by a single light bulb, so patrons were given flashlights with which to view the art (an idea of Man Ray), while the aroma of roasting coffee filled the air. Around midnight, the visitors witnessed the dancing shimmer of a scantily dressed girl who suddenly arose from the reeds, jumped on a bed, shrieked hysterically, then disappeared just as quickly. Much to the surrealists' satisfaction, the exhibition scandalized many of the guests.
In 1942, for the "First Papers of Surrealism" show in New York, surrealists called on Duchamp to design the exhibition. He wove a three-dimensional web of string throughout the rooms of the space, in some cases making it almost impossible to see the works. Duchamp made a secret arrangement with an associate's son to bring young friends to the opening of the show. When the formally-dressed patrons arrived, they found a dozen children in athletic clothes kicking and passing balls, and skipping rope. When questioned, the children were told to say "Mr. Duchamp told us we could play here". Duchamp's design of the catalog for the show included "found", rather than posed, photographs of the artists.
Personal life.
Throughout his adult life, Duchamp was a passionate smoker of Habana cigars.
Duchamp became a United States citizen in 1955.
In June 1927, Duchamp married Lydie Sarazin-Lavassor; however, they divorced six months later. It was rumored that Duchamp had chosen a marriage of convenience, because Sarazin-Lavassor was the daughter of a wealthy automobile manufacturer. Early in January 1928, Duchamp said that he could no longer bear the responsibility and confinement of marriage, and soon thereafter they were divorced.
After Sarazin-Lavassor's death (June 23, 1988), Duchamp allowed Mary Reynolds to reveal their complicated—and heretofore secret—ongoing 20-year relationship. They were together until her death in 1950 of uterine cancer.
Between 1946 and 1951 Maria Martins was his mistress.
In 1954, he and Alexina "Teeny" Sattler married, and they remained together until his death.
"Étant donnés".
Duchamp's final major art work surprised the art world that believed he had given up art for chess 25 years earlier. Entitled "Étant donnés: 1° la chute d'eau / 2° le gaz d'éclairage" ("Given: 1. The Waterfall, 2. The Illuminating Gas"), it is a tableau, visible only through a peep hole in a wooden door. A nude woman can be seen lying on her back with her face hidden, legs spread, and one hand holding a gas lamp in the air against a landscape backdrop. Duchamp had worked secretly on the piece from 1946 to 1966 in his Greenwich Village studio while even his closest friends thought he had abandoned art. The torso of the nude figure is based on Duchamp's lover, the Brazilian sculptor Maria Martins, with whom he had an affair from 1946 to 1951.
Death and burial.
Duchamp died suddenly and peacefully in the early morning of 2 October 1968 at his home in Neuilly-sur-Seine, France. After an evening dining at home with his friends Man Ray and Robert Lebel, Duchamp retired at 1:05 A.M., collapsed in his studio, and died of heart failure.
Duchamp was an atheist. He is buried in the Rouen Cemetery, in Rouen, France, with the epitaph, "D'ailleurs, c'est toujours les autres qui meurent" ("Besides, it's always the others who die"). Even in his death, Duchamp retained a sense of humor (a means for him of reaffirming his freedom, while undermining absolutes and certainties).
Legacy.
Duchamp is considered by many critics to be one of the most important artists of the 20th century, and his output influenced the development of post–World War I Western art. He advised modern art collectors, such as Peggy Guggenheim and other prominent figures, thereby helping to shape the tastes of Western art during this period. He challenged conventional thought about artistic processes and rejected the emerging art market, through subversive anti-art. He famously dubbed a urinal art and named it "Fountain". Duchamp produced relatively few artworks, while remaining mostly aloof of the avant-garde circles of his time. He went on to pretend to abandon art and devote the rest of his life to chess, while secretly continuing to make art. In 1958 Duchamp said of creativity,
The creative act is not performed by the artist alone; the spectator brings the work in contact with the external world by deciphering and interpreting its inner qualifications and thus adds his contribution to the creative act.
Duchamp in his later life explicitly expressed negativity towards art itself. In a BBC interview with Duchamp conducted by Joan Bakewell in 1966 Duchamp compared art with religion, whereby he stated that he wished to do away with art the same way many have done away with religion. Duchamp goes on to explain to the interviewer that "the word art etymologically means to do", that art means activity of any kind, and that it is our society that creates "purely artificial" distinctions of being an artist.
A quotation erroneously attributed to Duchamp suggests a negative attitude toward later trends in 20th-century art:
However, this was actually written in 1961 by fellow Dadaist Hans Richter, in the second person, i.e. "You threw the bottle-rack...". Although a marginal note in the letter suggests that Duchamp generally approved of the statement, Richter did not make the distinction clear until many years later.
Duchamp's attitude was actually more favorable, as evidenced by another statement made in 1964:
The Prix Marcel Duchamp (Marcel Duchamp Prize), established in 2000, is an annual award given to a young artist by the Centre Georges Pompidou. In 2004, as a testimony to the legacy of Duchamp's work to the art world, his "Fountain" was voted "the most influential artwork of the 20th century" by a panel of prominent artists and art historians.
External links.
Duchamp works
Essays by Duchamp
General resources
Audio and video

</doc>
<doc id="42652" url="https://en.wikipedia.org/wiki?curid=42652" title="United States Forest Service">
United States Forest Service

The United States Forest Service (USFS) is an agency of the U.S. Department of Agriculture that administers the nation's 154 national forests and 20 national grasslands, which encompass . Major divisions of the agency include the National Forest System, State and Private Forestry, Business Operations, and the Research and Development branch. Managing approximately 25% of federal lands, it is the only major national land agency that is outside the U.S. Department of Interior.
History.
In 1876, Congress created the office of Special Agent in the Department of Agriculture to assess the quality and conditions of forests in the United States. Franklin B. Hough was appointed the head of the office. In 1881, the office was expanded into the newly formed Division of Forestry. The Forest Reserve Act of 1891 authorized withdrawing land from the public domain as "forest reserves," managed by the Department of the Interior. In 1901, the Division of Forestry was renamed the Bureau of Forestry. The Transfer Act of 1905 transferred the management of forest reserves from the General Land Office of the Interior Department to the Bureau of Forestry, henceforth known as the United States Forest Service. Gifford Pinchot was the first United States Chief Forester in the Presidency of Theodore Roosevelt.
Significant federal legislation affecting the Forest Service includes the Weeks Act of 1911, the Multiple Use – Sustained Yield Act of 1960, P.L. 86-517; the Wilderness Act, P.L. 88-577; the National Forest Management Act, P.L. 94-588; the National Environmental Policy Act, P.L. 91-190; the Cooperative Forestry Assistance Act, P.L. 95-313; and the Forest and Rangelands Renewable Resources Planning Act, P.L. 95-307.
In February 2009, the Government Accountability Office evaluated whether the Forest Service should be moved from the Department of Agriculture to the Department of the Interior, which already includes the National Park Service, the Fish and Wildlife Service, and the Bureau of Land Management, managing some of public land.
Organization.
Overview.
As of 2009, the Forest Service has a total budget authority of $5.5 billion, of which 42% is spent fighting fires. The Forest Service employs 34,250 employees in 750 locations, including 10,050 firefighters, 737 law enforcement personnel, and 500 scientists.
The mission of the Forest Service is "To sustain the health, diversity, and productivity of the Nation's forests and grasslands to meet the needs of present and future generations." Its motto is "Caring for the land and serving people." As the lead federal agency in natural resource conservation, the US Forest Service provides leadership in the protection, management, and use of the nation's forest, rangeland, and aquatic ecosystems. The agency's ecosystem approach to management integrates ecological, economic, and social factors to maintain and enhance the quality of the environment to meet current and future needs. Through implementation of land and resource management plans, the agency ensures sustainable ecosystems by restoring and maintaining species diversity and ecological productivity that helps provide recreation, water, timber, minerals, fish, wildlife, wilderness, and aesthetic values for current and future generations of people.
The everyday work of the Forest Service balances resource extraction, resource protection, and providing recreation. The work includes managing of national forest and grasslands, including of roadless areas; 14,077 recreation sites; of trails; of roads; and the harvesting of 1.5 billion trees per year. Further, the Forest Service fought fires on of land.
The Forest Service organization includes ranger districts, national forests, regions, research stations and research work units and the Northeastern Area Office for State and Private Forestry. Each level has responsibility for a variety of functions.
National.
The Chief of the Forest Service is a career federal employee who oversees the entire agency. The Chief reports to the Under Secretary for Natural Resources and Environment in the U.S. Department of Agriculture (USDA), an appointee of the President confirmed by the Senate. The Chief's staff provides broad policy and direction for the agency, works with the Administration to develop a budget to submit to Congress, provides information to Congress on accomplishments, and monitors activities of the agency. There are five deputy chiefs for the following areas: National Forest System, State and Private Forestry, Research and Development, Business Operations, and Finance.
Research Stations and Research Work Units.
The Forest Service Research and Development deputy area includes five research stations, the Forest Products Laboratory, and the International Institute of Tropical Forestry, in Puerto Rico. Station directors, like regional foresters, report to the Chief. Research stations include Northern, Pacific Northwest, Pacific Southwest, Rocky Mountain, and Southern. There are 92 research work units located at 67 sites throughout the United States. there are 80 Experimental Forests and Ranges that have been established progressively since 1908; many sites are more than 50 years old. The system provides places for long-term science and management studies in major vegetation types of the of public land administered by the Forest Service. Individual sites range from 47 to 22,500 ha in size.
Operations of Experimental Forests and Ranges are directed by local research teams for the individual sites, by Research Stations for the regions in which they are located, and at the level of the Forest Service.
Major themes in research at the Experimental Forests and Ranges includes:
develop of systems for managing and restoring forests, range lands, and watersheds; investigate the workings of forest and stream ecosystems; characterize plant and animal communities; observe and interpret long-term environmental change and many other themes.
Regions.
There are nine regions in the USDA Forest Service; numbered 1 through 10 (Region 7 was eliminated
in 1965 when the current Eastern Region was created from the former Eastern and
North Central regions.
). Each encompasses a broad geographic area and is headed by a regional forester who reports directly to the Chief. The regional forester has broad responsibility for coordinating activities among the various forests within the region, for providing overall leadership for regional natural resource and social programs, and for coordinated regional land use planning.
National Forest or Grassland.
The Forest Service oversees 155 national forests and 20 grasslands. Each administrative unit typically comprises several ranger districts, under the overall direction of a forest supervisor. Within the supervisor's office, the staff coordinates activities among districts, allocates the budget, and provides technical support to each district. Forest supervisors are line officers and report to regional foresters.
Ranger District.
The Forest Service has more than 600 ranger districts. Each district has a staff of 10 to 100 people under the direction of a district ranger, a line officer who reports to a forest supervisor. The districts vary in size from to more than . Most on-the-ground activities occur on ranger districts, including trail construction and maintenance, operation of campgrounds, and management of vegetation and wildlife habitat.
Major divisions.
Law Enforcement & Investigations.
The U.S. Forest Service Law Enforcement & Investigations unit (LEI), headquartered in Washington, D.C., is a federal law enforcement agency of the U.S. government. It is responsible for enforcement of federal laws and regulations governing national forest lands and resources. All Law Enforcement Officers and Special Agents Receive their training through Federal Law Enforcement Training Center (FLETC).
Operations are divided into two major functional areas:
Uniformed Law Enforcement Officers (LEOs) enforce federal laws and regulations governing national forest lands and resources. LEOs also enforce some or all state laws on National Forest Lands. As part of that mission, LEOs carry firearms, defensive equipment, make arrests, execute search warrants, complete reports, and testify in court. They establish a regular and recurring presence on a vast amount of public lands, roads, and recreation sites. The primary focus of their jobs is the protection of natural resources, protection of Forest Service employees and the protection of visitors. To cover the vast and varied terrain under their jurisdiction, they use Ford Crown Victoria Police Interceptors, special service SUVs, horses, K-9 units, helicopters, snowmobiles, dirt bikes, and boats.
Special Agents are criminal investigators who plan and conduct investigations concerning possible violations of criminal and administrative provisions of the Forest Service and other statues under the United States Code. Special agents are normally plainclothes officers who carry concealed firearms, and other defensive equipment, make arrests, carry out complex criminal investigations, present cases for prosecution to U.S. Attorneys, and prepare investigative reports. All field agents are required to travel a great deal and usually maintain a case load of ten to fifteen ongoing criminal investigations at one time. Criminal investigators occasionally conduct internal and civil claim investigations.
National Forest System.
The of public land that are managed as national forests and grasslands are collectively known as the National Forest System. These lands are located in 44 states, Puerto Rico, and the Virgin Islands and comprise about 9% of the total land area in the United States. The lands are organized into 155 national forests and 20 national grasslands. The mission of the National Forest System is to protect and manage the forest lands so they best demonstrate the sustainable multiple-use management concept, using an ecological approach, to meet the diverse needs of people.
State and Private Forestry.
The mission of the State and Private Forestry program is to provide technical and financial assistance to private landowners, state agencies, tribes, and community resource managers to help sustain the United States' urban and rural forests and to protect communities and the environment from wildland fires, insects, disease, and invasive plants. The program employs approximately 537 staff located at 17 sites throughout the country. The delivery of the State and Private Forestry program is carried out by eight National Forest System regions and the Northeastern Area.
Research and Development.
The research and development (R&D) arm of the U.S. Department of Agriculture (USDA) Forest Service works to improve the health and use of the United States' forests and grasslands. Research has been part of the Forest Service mission since the agency's inception in 1905. Today, Forest Service researchers work in a range of biological, physical, and social science fields to promote sustainable management of United States' diverse forests and rangelands. Research employs about 550 scientists and several hundred technical and support staff, located at 67 sites throughout the United States and in Puerto Rico. Discovery and technology development and transfer is carried out through seven research stations.
Research focuses on informing policy and land management decisions and includes addressing invasive insects, degraded river ecosystems, or sustainable ways to harvest forest products. The researchers work independently and with a range of partners, including other agencies, academia, nonprofit groups, and industry. The information and technology produced through basic and applied science programs is available to the public for its benefit and use.
International Programs.
The Forest Service plays a key role in formulating policy and coordinating U.S. support for the protection and sound management of the world's forest resources. It works closely with other agencies such as USAID, the State Department, and the Environmental Protection Agency, as well as with nonprofit development organizations, wildlife organizations, universities, and international assistance organizations. The Forest Service's international work serves to link people and communities striving to protect and manage forests throughout the world. The program also promotes sustainable land management overseas and brings important technologies and innovations back to the United States. The program focuses on conserving key natural resource in cooperation with countries across the world.
Activities.
Although a large volume of timber is logged every year, not all National Forests are entirely forested. There are tidewater glaciers in the Tongass National Forest in Alaska and ski areas such as Alta, Utah in the Wasatch-Cache National Forest. In addition, the Forest Service is responsible for managing National Grasslands in the midwest. Furthermore, areas designated as wilderness by acts of Congress, prohibit logging, mining, road and building construction and land leases for purposes of farming and or livestock grazing.
Since 1978, several Presidents have directed the USFS to administer National Monuments inside of preexisting National Forests.
The Forest Service also manages Grey Towers National Historic Site in Milford, Pennsylvania, the home and estate of its first Chief, Gifford Pinchot.
Fighting fires.
In August 1944, to reduce the number of forest fires, the Forest Service and the Wartime Advertising Council began distributing fire education posters featuring a black bear. The poster campaign was a success; the black bear would later be named "Smokey Bear", and would, for decades, be the "spokesbear" for the Forest Service. Smokey Bear has appeared in innumerable TV commercials; his popular catch phrase, "Only YOU can prevent forest fires", is one of the most widely recognized slogans in the United States. A recent study found that 95% of the people surveyed could complete the phrase when given the first few words.
In September 2000, the Departments of Agriculture and the Interior developed a plan to respond to the fires of 2000, to reduce the impacts of these wildland fires on rural communities, and to ensure sufficient firefighting resources in the future. The report is entitled "Managing the Impacts of Wildfire on Communities and the Environment: A Report to the President In Response to the Wildfires of 2000"—The National Fire Plan for short. The National Fire Plan continues to be an integral part of the Forest Service today. The following are important operational features of the National Fire Plan:
In August 2014, Tom Vilsack, the Secretary of Agriculture, announced that the agency will have to put $400 to $500 million in wildfire prevention projects on hold because funding for firefighting is running low as the fiscal year ends. The decision is meant to preserve resources for fighting active fires burning in California, Oregon, Washington and Idaho. Politicians of both parties have indicated that they believe the current funding structure is broken, but they have not agreed on steps to fix the funding allocation.
Budget.
Although part of the Department of Agriculture, the Forest Service receives its budget through the Subcommittee on Appropriations—Interior, Environment, and Related Agencies.
Popular culture.
The U.S. Forest Service achieved widespread awareness during the 1960s, as it became the setting for the long running classic TV show "Lassie", with storylines focusing on Lassie's adventures with various forest rangers.
The iconic collie's association with the Forest Service led to Lassie receiving numerous awards and citations from the U.S. Senate and the Department of Agriculture, and was partly responsible for a bill regarding soil and water pollution that was signed into law in early 1968 by President Lyndon Johnson, which was dubbed by some as "The Lassie Program".
Controversies.
The history of the Forest Service has been fraught with controversy, as various interests and national values have grappled with the appropriate management of the many resources within the forests. These values and resources include grazing, timber, mining, recreation, wildlife habitat, and wilderness. Because of continuing development elsewhere, the large size of National Forests have made them de facto wildlife reserves for a number of rare and common species. In recent decades, the importance of mature forest for the spotted owl and a number of other species led to great changes in timber harvest levels.
In certain fire-adapted ecosystems, the ensuing decades of fire suppression unintentionally caused a buildup of fuels that replaced the historically natural fire regime of slow-burning, relatively cool fires with fast-burning, relatively hot wildfires in the fire-adapted forest lands across the nation.
In the 1990s, the agency was involved in scandal when it illegally provided surplus military aircraft to private contractors for use as airtankers. (See U.S. Forest Service airtanker scandal.)
Another controversial issue is the policy on road building within the National Forests. In 1999, President Clinton ordered a temporary moratorium on new road construction in the National Forests to "assess their ecological, economic, and social values and to evaluate long-term options for their management." Five and half years later, the Bush administration replaced this with a system where each state could petition the Forest Service to open forests in their territory to road building.
Some years the agency actually loses money on its timber sales.

</doc>
<doc id="42653" url="https://en.wikipedia.org/wiki?curid=42653" title="United States National Forest">
United States National Forest

National Forest is a classification of protected and managed federal lands in the United States.
National Forests are largely forest and woodland areas owned collectively by the American people through the federal government, and managed by the United States Forest Service, a division of the United States Department of Agriculture. 
History.
The National Forest System was created by the Land Revision Act of 1891, which was signed under the presidency of Benjamin Harrison. It was the result of concerted action by Los Angeles-area businessmen and property owners who were concerned by the harm being done to the watershed of the San Gabriel Mountains by ranchers and miners. Abbot Kinney and forester Theodore Lukens were key spokesmen for the effort.
Geography.
In the United States there are 155 National Forests containing almost 190 million acres (297,000 mi²/769 000 km²) of land. These lands comprise 8.5 percent of the total land area of the United States, an area about the size of Texas. Some 87 percent of National Forest land lies west of the Mississippi River in the mountain ranges of the Western United States. Alaska has 12 percent of all National Forest lands.
The U.S. Forest Service also manages all of the United States National Grasslands, and around half of the United States National Recreation Areas.
There are two distinctly different types of forests within the National Forest system. 
Management.
Land management of these areas focuses on conservation, timber harvesting, livestock grazing, watershed protection, wildlife, and recreation. Unlike national parks and other federal lands managed by the National Park Service, extraction of natural resources from national forests is permitted, and in many cases encouraged. National Forests are categorized by the U.S. as IUCN Category VI protected areas (Managed Resource Protected Area).
There are management decision conflicts between conservationists and environmentalists, and natural resource extraction companies and lobbies (e.g. logging & mining), over the protection and/or use of National Forest lands. These conflicts center on endangered species protection, logging of old-growth forests, intensive clear cut logging, undervalued stumpage fees, mining operations and mining claim laws, and logging/mining access road-building within National Forests. Additional conflicts arise from concerns that the grasslands, shrublands, and forest understory are grazed by sheep, cattle, and, more recently, rising numbers of elk and mule deer due to loss of predators.
Many ski resorts and summer resorts operate on leased land in National Forests.

</doc>
<doc id="42661" url="https://en.wikipedia.org/wiki?curid=42661" title="Myth (series)">
Myth (series)

Myth is a series of real-time tactics video games for Microsoft Windows and Mac OS. The games are:
"Myth" was developed by Bungie and published in 1997 by Eidos in Europe and Bungie in North America. "Myth II" was also developed by Bungie and self-published in North America in 1998. It was published by GT Interactive Software in Europe. As a result of Bungie's sale to Microsoft in 2000, the company lost the franchise rights to Take-Two Interactive. "Myth III: The Wolf Age" was developed by MumboJumbo and published by Take-Two in 2001.
All three games have received good reviews, especially the first and second game. Although the third game also received a generally positive reception, many reviewers cited a number of bugs in the initial release, and there was a general feeling that Take-Two had not given MumboJumbo enough time to complete the game.
The "Myth" games are categorized as real-time tactics, representing a departure from established real-time strategy titles such as "Warcraft" and "Command & Conquer"; resource micromanagement and the gradual building up of armies are not part of the gameplay, which instead focuses entirely on squad and soldier-level tactics. Some critics have argued that this style of gameplay allows the games a far greater sense of realism than their real-time strategy contemporaries.
Gameplay.
General.
Players control small forces made up of a number of different units, each possessing their own strengths and weaknesses. In single-player mode, only units representing "The Light" are playable, but in multiplayer mode, the player can control both light and dark units.
The "Myth" games are real-time tactics games, meaning that unlike the gameplay of real-time strategy games, the player does not have to worry about resource micromanagement and the gradual building up of their army; each level begins with the player's army already assembled and ready to go into combat straight away. Also unlike real-time strategy games, where the emphasis tends to be on producing as many soldiers as possible, in the "Myth" games, it is possible for a skilled player to defeat a much larger force with few or no casualties through tactical play. This is largely due to the advanced physics engine the games employ, as physically modelled environments, unit interactions, and diverse unit behaviours combine to create a gameplay experience in which realistic battlefield interactions can and do occur.
Nearly all objects on the maps, even the remains of dead units, are potential projectiles. These objects react with one another, units on the map, and terrain, with the expected physical behaviour, including rolling, bouncing, and crashing. Projectiles, including those fired by ranged units, have no guarantee of hitting any target; they are merely propelled in the directions instructed by the physics engine, based on the actions of the players. Arrows may miss their targets due to a small degree of simulated aiming error that becomes significant at long range, or the target may simply move out of the way before the arrow reaches them. This aiming error may cause the arrow to hit the attacker's own melee unit instead, causing the same amount of damage. As such, friendly fire is a prominent aspect of the game and can be used to the player's advantage when facing certain enemies.
Unit formations are important in all of the games, where a real battlefield is simulated accurately enough for maneuvers such as flanking and encirclement to be effective. When placed together in formation, units can provide an effective defensive front, block an enemy force's escape route, or exploit bad positioning of an enemy force by surrounding it. As healing is a very rare and extremely limited ability, units do not regenerate health, and there is no way to construct new units (although in some single-player missions, reinforcements are automatically received at a predetermined point), hit-and-run skirmishes are very effective, and unit conservation is essential.
Terrain and environmental factors are also important. Rain or standing water will put out some fire and explosive-based attacks. Archers on high ground are able to shoot farther than those on level ground. Most units will flinch when damaged, interrupting actions such as movement and attacks. This has many strategic implications; for example, if two or three melee units gang up to attack one enemy melee unit, it may flinch too frequently to have a chance to attack or escape.
Single-player.
In the single-player campaigns, the player starts each mission with an army which must be used to accomplish specific goals. These goals range from defending a location, reaching a certain point on the map, escorting a unit safely, or destroying an object of strategic significance.
The focus of the single-player campaigns is on a smaller force outmaneuvering and outthinking a much larger enemy force. For this reason, the importance of terrain and unit formation is particularly important. Using high ground to further the range of archers, creating bottle necks, and whittling down an enemy with hit-and-run tactics all become crucial strategies in the single-player game, especially on higher difficulty levels.
Units in the single-player campaign acquire experience with each kill. As they acquire experience, they become more resilient, attack faster, and deal more damage. Units retain this experience until killed or until a unit of their type does not appear in a given scenario.
Multiplayer.
In multiplayer, the player starts with an army and can usually customize it by trading units, using point values that approximate the value of the units. Proper selection of units is an important strategy given the goal of each multiplayer game. For example, if the goal of the game is to guard a flag as long as possible (such as "King of the Hill"), customizing the army with only ranged units would not be wise as there would be no melee units to guard the flag in close combat.
Multiplayer games generally are either "Free-For-All" (FFA), where each player has their own army and competes with everyone else, or "Team," where each army is controlled by a group of players with a captain who disperses units for his teammates to control. There are many different types of multiplayer games within this, ranging from simple "Body Count" to more complicated games involving flags, balls, or animals.
"Myth" development history.
Bungie.
"Myth: The Fallen Lords" and "Myth II: Soulblighter" were developed by Bungie in 1997 and 1998. Some reviewers felt that the games were influenced by Glen Cook's book series "The Black Company". Due to mapmaking tools released to the public by Bungie, and additional tools created by fans, new maps, units, 3D objects, and other plug-ins were created for "Myth II". Some of the better known mods were released in official bundles of the game. The expansion pack "Myth II: Chimera" was jointly developed by Bungie and Badlands Games, and was released in the bundle "Myth: The Total Codex", along with "Myth", and "Myth II" itself. "Myth: The Total Codex" was the last official release by Bungie for the "Myth" franchise.
Take-Two acquires "Myth" franchise.
In 2000, Microsoft purchased Bungie Studios, which had previously developed games for Microsoft's main competitor's platform, Apple's Macintosh, in order to have the studio develop "" exclusively for Microsoft's new Xbox game console. Early development versions of "Halo" resembled a sci-fi clone of "Myth". As part of the sale of Bungie, the rights to the "Oni" and the "Myth" series went to the video game publisher Take-Two Interactive who held a large share of the studio's stocks at the time of the sale. Take-Two initially released two "Myth" related titles; "Myth II: Worlds" (which included two disks of fan-created add-ons) and "Myth II: Green Berets" (a conversion from the medieval setting to a Vietnam war era setting).
Tournaments and online servers.
Bungie.net was the original "Myth" series server. The "Myth: The Fallen Lords" server closed in November 2001, and the "Myth II: Soulblighter" server closed in March, 2002. After Bungie.net closed, Bungie open sourced the online server code, and multiple other online servers appeared, the most famous being PlayMyth.net. PlayMyth.net was taken offline in 2007.
MumboJumbo develops "Myth III".
Take-Two hired the startup company MumboJumbo to develop "Myth III" based on "Myth II" source code. MumboJumbo had been founded by employees that left Ritual Entertainment, and "Myth III" would be their first game. Take-Two also hired many members of "Myth II"s modding community to work on both expansions for "Myth II" and the new "Myth III".
The developers made significant changes to the existing code to improve the game's visual aesthetics, such as increasing the game's texture quality. The new engine also sported full 3D characters, each with 300 to 800 polygons and at least 13 different animations, unlike its predecessor which relied on sprites for characters and animations. Soon before the game's release, "PC Gamer"s staff writer Jim Preston wrote that he was skeptical as to whether the developer had been given enough time to satisfactorily complete the game.
The developers worked to support the modding community by taking "Fear & Loathing", the application used to create mods for the previous games, and creating a new, easier to use application known as "Vengeance".
Shortly after the release of "Myth III", Take-Two cancelled all development and technical support for all three "Myth" games, and the complete MumboJumbo "Myth III" team was laid off.
Game-community support.
Lead developer Andrew Meggs joined with a group of fans who called themselves "MythDevelopers" with the aim of continuing to support the games. Given access to the source code for all three games by Take-Two, they have continued to work to update the series. This group, and successor groups, have continued to support and improve all three games, with software updates for the latest operating systems, bug fixes, and the addition of enhancements and features to both the games and modding tools.
In December 2003, MythDevelopers had internal struggles and disbanded, forming two smaller groups: Project Magma, and FlyingFlip. FlyingFlip went offline in 2007, leaving the currently active (as of October 2013) "Myth" development group as Project Magma.
Reception.
All three main games in the "Myth" franchise have been critically acclaimed, especially the first two.
Game Revolution's Calvin Hubble called "The Fallen Lords" "one of the most impressive looking strategy games to hit the market," whilst GameSpot's Michael E. Ryan argued that it "can rightfully claim its place among the best strategy games on the market." Hubble called "Myth II" "both one of the best sequels to hit the scene and one of the finest titles on the RTS market." Ryan wrote that ""Myth II" is about as good as a computer game can possibly be." IGN's Tal Blevins said ""Myth II" lives up to (and surpasses) all of the hype surrounding this long-awaited title."
"Myth III" did not get quite as good reviews, but it was still well received. GameSpot's Sam Parker wrote that ""Myth III"s single-player game represents the best the "Myth" series has to offer. Featuring great graphics, a memorable story, and plenty of diverse missions, "Myth III"s campaign will present a welcome challenge for veterans and newcomers alike." He also expressed some concern as to how long Take-Two would provide technical support for the game. IGN's Dan Adams found several faults, but still enjoyed the game, writing "some unfortunate set backs, whether they were by design or bug dulled the experience a little bit, but not enough to hamper my enjoyment. Fans of the series shouldn't be disappointed by MumboJumbo's effort to follow in the mighty footsteps that Bungie left behind."

</doc>
<doc id="42673" url="https://en.wikipedia.org/wiki?curid=42673" title="How Green Was My Valley">
How Green Was My Valley

How Green Was My Valley is a 1939 novel by Richard Llewellyn, narrated by Huw, the main character, about his Welsh family and the mining community in which they live. The author had claimed that he based the book on his own personal experiences but this was found to be untrue after his death; Llewellyn was English-born and spent little time in Wales, though he was of Welsh descent. Llewellyn gathered material for the novel from conversations with local mining families in Gilfach Goch.
The title of the novel appears in two sentences. It is first used in Chapter Thirty, after the narrator has had his first sexual experience. He sits up to "... look down in the valley." He then reflects: "How green was my Valley that day, too, green and bright in the sun." The phrase is used again in the novel's last sentence: "How green was my Valley then, and the Valley of them that have gone."
In the United States, Llewellyn won the National Book Award for favorite novel of 1940, voted by members of the American Booksellers Association.
Plot summary.
The novel is set in South Wales during the reign of Queen Victoria. It tells the story of the Morgans, a respectable mining family of the South Wales Valleys, through the eyes of one of the sons, Huw Morgan. 
Huw's academic ability sets him apart from his elder brothers and enables him to consider a future away from the dangerous coal mines. His five brothers and his father are miners; after the eldest brother, Ivor, is killed in a mining accident, Huw moves in with his sister-in-law, Bronwen, with whom he has always been in love. 
One of Huw's three sisters, Angharad, marries the wealthy mine owner's son - whom she does not love - and the marriage is an unhappy one. She never overcomes her clandestine relationship with the local minister. 
Huw's father is later killed in a mine explosion. After everyone Huw has known either dies or moves away, and the town is reduced to a contaminated shell, he decides to leave, and tells the story of his life just before going away.
Characters.
The Older Morgans:
The Middle Brothers:
These are Huw's young adult brothers. Ianto goes to London to find work early in the book, but returns unhappily; Owen and Gwilym do the same later. 
The Younger Morgans: 
Other Characters:
First printing.
The first edition was published in 1939 by Michael Joseph Ltd, London, set and printed in Great Britain by William Brendon & Son, Ltd., at the Mayflower Press, Plymouth, in Walbaum type, twelve point, leaded, on a toned opaque-wove paper made by John Dickinson, and bound by James Burn. It was published in 8vo size. The first printing included a limited edition run of 200, numbered and signed by Richard Llewellyn. The original print run also included a glossary covering Welsh words and terms at the end of the book. 
Sequels.
The author continued the story of Huw Morgan's life in three sequels:
Adaptations.
The 1941 Hollywood film adaptation, which was highly successful, had a cast that included Walter Pidgeon, Maureen O'Hara, Anna Lee, Roddy McDowall (as Huw), Donald Crisp, and Barry Fitzgerald. None of the leading players was Welsh (though Welsh actor Rhys Williams made his screen debut in the film in a minor role). Directed by John Ford, "How Green Was My Valley" was selected for preservation in the United States National Film Registry. "How Green Was My Valley" is available on DVD from 20th Century Fox as part of their 20th Century Fox Studio Classics collection.
The book has twice been adapted by the BBC for television, in 1960 and 1975. The 1975 production– scripted by Elaine Morgan – starred Stanley Baker, Siân Phillips, and Nerys Hughes.
The novel was adapted as a Broadway musical, called "A Time for Singing", which opened at the Broadway Theatre, New York, on 21 May 1966. The music was by John Morris; book and lyrics were by Gerald Freedman and John Morris. The production was directed by Mr. Freedman, and it starred Ivor Emmanuel, Tessie O'Shea, Shani Wallis, and Laurence Naismith.
A stage version, adapted by Shaun McKenna was performed at the Theatre Royal in Northampton in 1990. It marked the stage debut of Aled Jones as the teenage Huw. It was directed by Michael Napier Brown and designed by Ray Lett.

</doc>
<doc id="42674" url="https://en.wikipedia.org/wiki?curid=42674" title="Shor's algorithm">
Shor's algorithm

Shor's algorithm, named after mathematician Peter Shor, is a quantum algorithm (an algorithm that runs on a quantum computer) for integer factorization formulated in 1994. Informally it solves the following problem: given an integer "N", find its prime factors.
On a quantum computer, to factor an integer "N", Shor's algorithm runs in polynomial time (the time taken is polynomial in log "N", which is the size of the input). Specifically it takes quantum gates of order ) using fast multiplication, demonstrating that the integer factorization problem can be efficiently solved on a quantum computer and is thus in the complexity class BQP. This is substantially faster than the most efficient known classical factoring algorithm, the general number field sieve, which works in sub-exponential time — about . The efficiency of Shor's algorithm is due to the efficiency of the quantum Fourier transform, and modular exponentiation by repeated squarings.
If a quantum computer with a sufficient number of qubits could operate without succumbing to noise and other quantum decoherence phenomena, Shor's algorithm could be used to break public-key cryptography schemes such as the widely used RSA scheme. RSA is based on the assumption that factoring large numbers is computationally intractable. So far as is known, this assumption is valid for classical (non-quantum) computers; no classical algorithm is known that can factor in polynomial time. However, Shor's algorithm shows that factoring is efficient on an ideal quantum computer, so it may be feasible to defeat RSA by constructing a large quantum computer. It was also a powerful motivator for the design and construction of quantum computers and for the study of new quantum computer algorithms. It has also facilitated research on new cryptosystems that are secure from quantum computers, collectively called post-quantum cryptography.
In 2001, Shor's algorithm was demonstrated by a group at IBM, who factored 15 into 3 × 5, using an NMR implementation of a quantum computer with 7 qubits. After IBM's implementation, two independent groups, one at the University of Science and Technology of China, and the other one at the University of Queensland, have implemented Shor's algorithm using photonic qubits, emphasizing that multi-qubit entanglement was observed when running the Shor's algorithm circuits. In 2012, the factorization of 15 was repeated. Also in 2012, the factorization of 21 was achieved, setting the record for the largest number factored with a quantum computer. In April 2012, the factorization of 143 was achieved, although this used adiabatic quantum computation rather than Shor's algorithm. In November 2014, it was discovered that this 2012 adiabatic quantum computation had also factored larger numbers, the largest being 56153. Since April 2016, the largest integer factored on a quantum device is 200099, using D-Wave 2X quantum processor [http://arxiv.org/abs/1604.05796].
Procedure.
The problem we are trying to solve is: given an odd composite number formula_1, find an integer formula_2, strictly between formula_3 and formula_1, that divides formula_1. We are interested in odd values of formula_1 because any even value of formula_1 trivially has the number formula_8 as a prime factor. We can use a primality testing algorithm to make sure that formula_1 is indeed composite.
Moreover, for the algorithm to work, we need formula_1 not to be the power of a prime. This can be tested by checking that formula_11 is not an integer, for all formula_12.
Since formula_1 is not a power of a prime, it is the product of two coprime numbers greater than formula_3. As a consequence of the Chinese remainder theorem, the number formula_3 has at least four distinct square roots modulo formula_1, two of them being formula_3 and formula_18. The aim of the algorithm is to find a square root formula_19 of one other factor; such a formula_19 will lead to a factorization of formula_1, as in other factoring algorithms like the quadratic sieve.
In turn, finding such a formula_19 is reduced to finding an element formula_23 of even period with a certain additional property (as explained below, it is required that the condition of Step 6 of the classical part does not hold). The quantum algorithm is used for finding the period of randomly chosen elements formula_23, as order-finding is a hard problem on a classical computer.
Shor's algorithm consists of two parts:
Classical part.
For example: formula_25, formula_26, where formula_27, and formula_28.
Quantum part: Period-finding subroutine.
The quantum circuits used for this algorithm are custom designed for each choice of "N" and each choice of the random "a" used in "f"("x") = "a""x" mod "N". Given "N", find "Q" = 2"q" such that formula_29, which implies formula_30. The input and output qubit registers need to hold superpositions of values from 0 to "Q" − 1, and so have "q" qubits each. Using what might appear to be twice as many qubits as necessary guarantees that there are at least "N" different "x" which produce the same "f"("x"), even as the period "r" approaches "N"/2.
Proceed as follows:
where "x" runs from 0 to "Q" − 1. This initial state is a superposition of "Q" states.
This is still a superposition of "Q" states.
This leads to the final state
Now we reorder this sum as
This is a superposition of many more than "Q" states, but many fewer than "Q"2 states, since there are fewer than "Q" distinct values of formula_38. Let
Then formula_42 is a unit vector in the complex plane (formula_43 is a root of unity and "r" and "y" are integers), and the coefficient of formula_44 in the final state is
Each term in this sum represents a "different path to the same result", and quantum interference occurs constructive when the unit vectors formula_46 point in nearly the same direction in the complex plane, which requires that formula_42 point along the positive real axis.
Analysis now shows that this probability is higher the closer the unit vector formula_42 is to the positive real axis, or the closer "yr/Q" is to an integer. Unless r is a power of 2, it won't be a factor of Q.
Given these conditions (and assuming "d"/"s" is irreducible), "s" is very likely to be the appropriate period "r", or at least a factor of it.
Explanation of the algorithm.
The algorithm is composed of two parts. The first part of the algorithm turns the factoring problem into the problem of finding the period of a function, and may be implemented classically. The second part finds the period using the quantum Fourier transform, and is responsible for the quantum speedup.
Obtaining factors from period.
The integers less than "N" and coprime with "N" form a finite abelian group formula_52 under multiplication modulo "N". The size is given by Euler's totient function formula_53.
By the end of step 3, we have an integer "a" in this group. Since the group is finite, "a" must have a finite order "r", the smallest positive integer such that
Therefore, "N" divides (also written | ) "a" "r" − 1 . Suppose we are able to obtain "r", and it is even. (If "r" is odd, see step 5.) Now formula_55 is a square root of 1 modulo formula_1, different from 1. This is because formula_57 is the order of formula_23 modulo formula_1, so formula_60, else the order of formula_23 in this group would be formula_62. If formula_63, by step 6 we have to restart the algorithm with a different random number formula_23.
Eventually, we must hit an formula_23, of order formula_57 in formula_52, such that formula_68. This is because such a formula_19 is a square root of 1 modulo formula_1, other than 1 and formula_18, whose existence is guaranteed by the Chinese remainder theorem, since formula_1 is not a prime power.
We claim that formula_73 is a proper factor of formula_1, that is, formula_75. In fact if formula_76, then formula_1 divides formula_78, so that formula_79, against the construction of formula_19. If on the other hand formula_81, then by Bézout's identity there are integers formula_82 such that
Multiplying both sides by formula_84 we obtain
Since formula_1 divides formula_87, we obtain that formula_1 divides formula_84, so that formula_90, again contradicting the construction of formula_19.
Thus formula_2 is the required proper factor of formula_1.
Finding the period.
Shor's period-finding algorithm relies heavily on the ability of a quantum computer to be in many states simultaneously.
Physicists call this behavior a "superposition" of states. To compute the period of a function "f", we evaluate the function at all points simultaneously.
Quantum physics does not allow us to access all this information directly, though. A measurement will yield only one of all possible values, destroying all others. If not for the no cloning theorem, we could first measure "f"("x") without measuring "x", and then make a few copies of the resulting state (which is a superposition of states all having the same "f"("x")). Measuring "x" on these states would provide different "x" values which give the same "f"("x"), leading to the period. Because we cannot make exact copies of a quantum state, this method does not work. Therefore, we have to carefully transform the superposition to another state that will return the correct answer with high probability. This is achieved by the quantum Fourier transform.
Shor thus had to solve three "implementation" problems. All of them had to be implemented "fast", which means that they can be implemented with a number of quantum gates that is polynomial in formula_94.
After all these transformations a measurement will yield an approximation to the period "r". For simplicity assume that there is a "y" such that "yr/Q" is an integer. Then the probability to measure "y" is 1. To see that we notice that then
for all integers "b". Therefore, the sum whose square gives us the probability to measure "y" will be "Q/r" since "b" takes roughly "Q/r" values and thus the probability is formula_97. There are "r" "y" such that "yr/Q" is an integer and also "r" possibilities for formula_98, so the probabilities sum to 1.
Note: another way to explain Shor's algorithm is by noting that it is just the quantum phase estimation algorithm in disguise.
The bottleneck.
The runtime bottleneck of Shor's algorithm is quantum modular exponentiation, which is by far slower than the quantum Fourier transform and classical pre-/post-processing. There are several approaches to constructing and optimizing circuits for modular exponentiation. The simplest and (currently) most practical approach is to mimic conventional arithmetic circuits with reversible gates, starting with ripple-carry adders. Knowing the base and the modulus of exponentiation facilitates further optimizations. Reversible circuits typically use on the order of formula_99 gates for formula_100 qubits. Alternative techniques asymptotically improve gate counts by using quantum Fourier transforms, but are not competitive with less than 600 qubits due to high constants.
Discrete logarithms.
Given prime formula_101 with generator formula_102 where formula_103, for some "r", and we wish to compute "r", which is the discrete logarithm: formula_104. Consider the abelian group formula_105 where each factor corresponds to modular multiplication of nonzero values, assuming p is prime. Now, consider the function
This gives us an abelian hidden subgroup problem, as "f" corresponds to a group homomorphism. The kernel corresponds to modular multiples of ("r",1). So, if we can find the kernel, we can find "r".
In popular culture.
On the television show "Stargate Universe", the lead scientist, Dr. Nicholas Rush, hoped to use Shor's algorithm to crack "Destiny"'s master code. He taught a quantum cryptography class at the University of California, Berkeley, in which Shor's algorithm was studied.
Shor's algorithm was also a correct answer to a question in a Physics Bowl competition in the episode "The Bat Jar Conjecture" of the TV series "The Big Bang Theory".

</doc>
<doc id="42676" url="https://en.wikipedia.org/wiki?curid=42676" title="Mold health issues">
Mold health issues

Mold health issues are potentially harmful effects of molds.
Molds (US usage; British English "moulds") are ubiquitous in the biosphere, and mold spores are a common component of household and workplace dust. The United States Centers for Disease Control and Prevention reported in its June 2006 report, 'Mold Prevention Strategies and Possible Health Effects in the Aftermath of Hurricanes and Major Floods,' that "excessive exposure to mold-contaminated materials can cause adverse health effects in susceptible persons regardless of the type of mold or the extent of contamination." When mold spores are present in abnormally high quantities, they can present especially hazardous health risks to humans, including allergic reactions or poisoning by mycotoxins, or causing fungal infection (mycosis).
Health effects.
Studies have shown that people who are atopic (sensitive), already suffer from allergies, asthma, or compromised immune systems and occupy damp or moldy buildings are at an increased risk of health problems such as inflammatory and toxic responses to mold spores, metabolites and other components. The most common health problem is an allergic reaction. Other problems are respiratory and/or immune system responses including respiratory symptoms, respiratory infections, exacerbation of asthma, and rarely hypersensitivity pneumonitis, allergic alveolitis, chronic rhinosinusitis and allergic fungal sinusitis. Severe reactions are rare but possible. A person's reaction to mold depends on their sensitivity and other health conditions, the amount of mold present, length of exposure and the type of mold or mold products.
Some molds also produce mycotoxins that can pose serious health risks to humans and animals. The term "toxic mold" refers to molds that produce mycotoxins, such as "Stachybotrys chartarum", not to all molds. Exposure to high levels of mycotoxins can lead to neurological problems and in some cases death. Prolonged exposure, e.g., daily workplace exposure, can be particularly harmful.
The five most common genera of indoor molds are "Cladosporium", "Penicillium", "Aspergillus", "Alternaria" and "Trichoderma".
Damp environments which allow mold to grow can also produce bacteria and help release volatile organic compounds.
Symptoms of mold exposure.
Symptoms of mold exposure can include:
Health effects linking to asthma.
Infants may develop respiratory symptoms as a result of exposure to a specific type of fungal mold, called Penicillium. Signs that an infant may have mold-related respiratory problems include (but are not limited to) a persistent cough and/or wheeze. Increased exposure increases the probability of developing respiratory symptoms during their first year of life. Studies have shown that a correlation exists between the probability of developing asthma and increased exposure "Penicillium". The levels are deemed ‘no mold’ to ‘low level’ , from ‘low’ to ‘intermediate’ , and from ‘intermediate’ to ‘high’.
Mold exposures have a variety of health effects depending on the person. Some people are more sensitive to mold than others. Exposure to mold can cause a number of health issues such as; throat irritation, nasal stuffiness, eye irritation, cough and wheezing, as well as skin irritation in some cases. Exposure to mold may also cause heightened sensitivity depending on the time and nature of exposure. People at higher risk for mold allergies are people with chronic lung illnesses, which will result in more severe reactions when exposed to mold.
There has been sufficient evidence that damp indoor environments are correlated with upper respiratory tract symptoms such as coughing, and wheezing in people with asthma.
Mold-associated conditions.
Health problems associated with high levels of airborne mold spores include allergic reactions, asthma episodes, irritations of the eye, nose and throat, sinus congestion, and other respiratory problems, although it should be noted that mold spores won't actually cause asthma, just irritate existing conditions. For example, residents of homes with mold are at an elevated risk for both respiratory infections and bronchitis. When mold spores are inhaled by an immunocompromised individual, some mold spores may begin to grow on living tissue, attaching to cells along the respiratory tract and causing further problems. Generally, when this occurs, the illness is an epiphenomenon and not the primary pathology. Also, mold may produce mycotoxins, either before or after exposure to humans, potentially causing toxicity.
Fungal infection.
A serious health threat from mold exposure for immunocompromised individuals is systemic fungal infection (systemic mycosis). Immunocompromised individuals exposed to high levels of mold, or individuals with chronic exposure may become infected. Sinuses and digestive tract infections are most common; lung and skin infections are also possible. Mycotoxins may or may not be produced by the invading mold.
Dermatophytes are the parasitic fungi that cause skin infections such as athlete's foot and tinea cruris. Most dermataphyte fungi take the form of a mold, as opposed to a yeast, with appearance (when cultured) that is similar to other molds.
Opportunistic infection by molds such as "Penicillium marneffei" and "Aspergillus fumigatus" is a common cause of illness and death among immunocompromised people, including people with AIDS or asthma.
Mold-induced hypersensitivity.
The most common form of hypersensitivity is caused by the direct exposure to inhaled mold spores that can be dead or alive or hyphal fragments which can lead to allergic asthma or allergic rhinitis. The most common effects are rhinorrhea (runny nose), watery eyes, coughing and asthma attacks. Another form of hypersensitivity is hypersensitivity pneumonitis. Exposure can occur at home, at work or in other settings. It is predicted that about 5% of people have some airway symptoms due to allergic reactions to molds in their lifetimes.
Hypersensitivity may also be a reaction toward an established fungal infection in allergic bronchopulmonary aspergillosis.
Mycotoxin toxicity.
Molds excrete toxic compounds called mycotoxins, secondary metabolites produced by fungi under certain environmental conditions. These environmental conditions affect the production of mycotoxins at the transcription level. Temperature, water activity and pH, strongly influence mycotoxin biosynthesis by increasing the level of transcription within the fungal spore. It has also been found that low levels of fungicides can boost mycotoxin synthesis. Certain mycotoxins can be harmful or lethal to humans and animals when exposure is high enough.
Extreme exposure to very high levels of mycotoxins can lead to neurological problems and in some cases death; fortunately, such exposures rarely to never occur in normal exposure scenarios, even in residences with serious mold problems. Prolonged exposure, such as daily workplace exposure, can be particularly harmful.
The health hazards produced by mold have been associated with sick building syndrome, but no validated studies have been able to demonstrate that normal indoor exposures to these common organisms pose a significant threat.
It is thought that all molds may produce mycotoxins and thus all molds may be potentially toxic if large enough quantities are ingested, or the human becomes exposed to extreme quantities of mold. Mycotoxins are not produced all the time, but only under specific growing conditions. Mycotoxins are harmful or lethal to humans and animals only when exposure is high enough.
Mycotoxins can be found on the mold spore and mold fragments, and therefore they can also be found on the substrate upon which the mold grows. Routes of entry for these insults can include ingestion, dermal exposure and inhalation.
Some mycotoxins cause immune system responses that vary considerably, depending on the individual. The duration of exposure, the frequency of exposure and the concentration of the insult (exposure) are elements in triggering immune system response.
Aflatoxin is an example of a mycotoxin. It is a cancer-causing poison produced by certain fungi in or on foods and feeds, especially in field corn and peanuts.
Originally, toxic effects from mold were thought to be the result of exposure to the mycotoxins of some mold species, such as "Stachybotrys chartarum". However, studies are suggesting that the so-called toxic effects are actually the result of chronic activation of the immune system, leading to chronic inflammation. Studies indicate that up to 25% of the population have the genetic capability of experiencing chronic inflammation to mold exposure, but it is unknown how many actually experience such symptoms due to frequent misdiagnosis. A 1993–94 case study based on cases of pulmonary hemorrhage in infants in Cleveland, Ohio originally concluded there was causal relationship between the exposure and the disease. The investigators revisited the cases and established that there was no link to the exposure to "S. chartrum" and the infants in their homes.
The common house mold, "Trichoderma longibrachiatum", produces small toxic peptides containing amino acids not found in common proteins, like alpha-aminoisobutyric acid, called trilongins (up to 10% w/w). Their toxicity is due to absorption into cells and production of nano-channels that obstruct vital ion channels that ferry potassium and sodium ions across the cell membrane. This affects in the cells action potential profile, as seen in cardiomyocytes, pneumocytes and neurons leading to conduction defects. Trilongins are highly resistant to heat and antimicrobials making primary prevention the only management option.
Exposure sources and prevention.
The main sources of mold exposure are from the indoor air in buildings with substantial mold growth, and from ingestion of food with mold growths.
Air.
Prevention of mold exposure and its ensuing health issues begins with prevention of mold growth in the first place by avoiding a mold-supporting environment such as humid air. Extensive flooding and water damage can support extensive mold growth. Following hurricanes, homes with greater flood damage, especially those with more than of indoor flooding, demonstrated higher levels of mold growth compared with homes with little or no flooding. The aftermath of a hurricane is the worst-case scenario, but the concept of water damage supporting widespread mold growth is more generally applicable.
It is useful to perform an assessment of the location and extent of the mold hazard in a structure. Various practices of remediation can be followed to mitigate mold issues in buildings, the most important of which is to reduce moisture levels. Removal of affected materials after the source of moisture has been reduced and/or eliminated may be necessary. Thus, the concept of mold growth, assessment, and remediation is essential in prevention of mold health issues.
A common issue with mold hazards in the household is the placement of furniture, and the lack of ventilation which this causes to certain parts of the wall. The simplest method of avoiding mold in a home so affected is to move the furniture in question.
Adverse respiratory health effects are associated with occupancy in buildings with moisture and mold damage.
Molds may excrete liquids or low-volatility gases, but the concentrations are so low that frequently they cannot be detected even with sensitive analytical sampling techniques. Sometimes these by-products are detectable by odor, in which case they are referred to as "ergonomic odors" meaning the odors are detectable, but do not indicate toxicologically significant exposures.
Food.
Molds that are often found on meat and poultry include members of the genera "Alternaria", "Aspergillus", "Botrytis", "Cladosporium", "Fusarium", "Geotrichum", "Mortierella", "Mucor", "Neurospora","Paecilomyces", "Penicillium" and "Rhizopus". Grain crops in particular incur considerable losses both in field and storage due to pathogens, post-harvest spoilage and insect damage. A number of common microfungi are important agents of post-harvest spoilage, notably members of the genera "Aspergillus", "Fusarium" and "Penicillium". A number of these produce mycotoxins (soluble, non-volatile toxins produced by a range of microfungi that demonstrate specific and potent toxic properties on human and animal cells) that can render foods unfit for consumption. When ingested, inhaled, or absorbed through skin, mycotoxins may cause or contribute to a range of effects from reduced appetite and general malaise to acute illness or death in rare cases. Mycotoxins may also contribute to cancer. Dietary exposure to the mycotoxin aflatoxin B1, commonly produced by growth of the fungus "Aspergillus flavus" on improperly stored ground nuts in many areas of the developing world, is known to independently (and synergistically with Hepatitis B virus) induce liver cancer. Mycotoxin-contaminated grain and other food products have a significantly impact on human and animal health globally. According to the World Health Organization, roughly 25% of the world's food may be contaminated by mycotoxins.
Prevention of mold exposure from food is generally to consume food that has no mold growths on it. Also, mold growth in the first place can be prevented by the same concept of mold growth, assessment, and remediation that prevents air exposure. In addition, it is especially useful to clean the inside of the refrigerator, and to ensure dishcloths, towels, sponges and mops are clean.
Ruminants are considered to have increased resistance to some mycotoxins, presumably due to the superior mycotoxin-degrading capabilities of their gut microbiota. The passage of mycotoxins through the food chain may also have important consequences on human health. For example, in China in December 2011, high levels of carcinogen aflatoxin M1 in Mengniu brand milk were found to be associated with the consumption of mold-contaminated feed by dairy cattle.
History.
In the 1930s, mold was identified as the cause behind the mysterious deaths of farm animals in Russia and other countries. "Stachybotrys chartarum" was found growing on wet grain used for animal feed. Illness and death also occurred in humans when starving peasants ate large quantities of rotten food grains and cereals that were heavily overgrown with the "Stachybotrys" mold.
In the 1970s, building construction techniques changed in response to changing economic realities including the energy crisis. As a result, homes and buildings became more airtight. Also, cheaper materials such as drywall came into common use. The newer building materials reduced the drying potential of the structures making moisture problems more prevalent. This combination of increased moisture and suitable substrates contributed to increased mold growth inside buildings.
Today, the US Food and Drug Administration and the agriculture industry closely monitor mold and mycotoxin levels in grains and foodstuffs in order to keep the contamination of animal feed and human food supplies below specific levels. In 2005 Diamond Pet Foods, a US pet food manufacturer, experienced a significant rise in the number of corn shipments containing elevated levels of aflatoxin. This mold toxin eventually made it into the pet food supply, and dozens of dogs and cats died before the company was forced to recall affected products.
Litigation.
In 2002, the U.S. International Trade Commission reported that according to one estimate, US insurers paid over $3 billion in mold-related lawsuits, more than double the previous year's total. According to the Insurance Information Institute, in 2003 there were over 10,000 mold-related lawsuits pending in US state courts. Most were filed in states with high humidity, but suits were on the rise in other states as well. By 2004, many mold litigation settlements were for amounts well past $100,000. In 2005, the U.S. International Trade Commission reported that toxic mold showed signs of being the "new asbestos" in terms of claims paid. In 2012, a key appellate court in Manhattan found a consensus in the scientific literature for a causal relationship between the presence of mold and resultant illness.
In 1999, an Austin, Texas, woman was awarded $32 million when she sued her insurer over mold damage in her 22-room mansion.
In 2001, a jury awarded a couple and their eight-year-old son $2.7 million, plus attorney’s fees and costs, in a toxic mold-related personal injury lawsuit against the owners and managers of their apartment in Sacramento, California.
In 2003, "The Tonight Show" co-host Ed McMahon received $7.2 million from insurers and others to settle his lawsuit alleging that toxic mold in his Beverly Hills home made him and his wife ill and killed their dog. That same year environmental activist Erin Brockovich received settlements of $430,000 from two parties and an undisclosed amount from a third party to settle her lawsuit alleging toxic mold in her Agoura Hills, California, home.
In 2006, a Manhattan Beach, California family received a $22.6 million settlement in a toxic mold case. The family had asserted that that moldy lumber had caused severe medical problems in their child. That same year, Hilton Hotels received $25 million in settlement of its lawsuit over mold growth in the Hilton Hawaiian Village's Kalia Tower.
In 2010, a jury awarded $1.2 million in damages in a lawsuit against a landlord for neglecting to repair a mold-infested house in Laguna Beach, California. The lawsuit asserted that a child in the home suffered from severe respiratory problems for several years as a result of the mold.
In 2011, in North Pocono, Pennsylvania, a jury awarded two homeowners $4.3 million in a toxic mold verdict.

</doc>
<doc id="42677" url="https://en.wikipedia.org/wiki?curid=42677" title="Celtic Tiger">
Celtic Tiger

"Celtic Tiger" () is a term referring to the economy of the Republic of Ireland from the mid-1990s to the mid-2000s, a period of rapid real economic growth fuelled by foreign direct investment, and a subsequent property bubble which rendered the real economy uncompetitive. The Irish economy expanded at an average rate of 9.4% between 1995 and 2000 and continued to grow at an average rate of 5.9% during the following decade until 2008, when it fell into recession.
The economy underwent a dramatic reversal from 2008, with GDP contracting by 14% and unemployment levels rising to 14% by 2011.
Term.
The colloquial term "Celtic Tiger" has been used to refer to the country itself, and to the years associated with the boom. The first recorded use of the phrase is in a 1994 Morgan Stanley report by Kevin Gardiner. The term refers to Ireland's similarity to the East Asian Tigers: Hong Kong, Singapore, South Korea, and Taiwan during their periods of rapid growth in the early 1960s and late 1990s. "An Tíogar Ceilteach", the Irish language version of the term, appears in the official terminology database and has been used regularly in government and administrative contexts since at least 2005.
The Celtic Tiger period has also been called "The Boom" or "Ireland's Economic Miracle". During that time, the country experienced a period of economic growth that transformed it from one of Western Europe's poorer countries into one of its wealthiest. The causes of Ireland's growth are the subject of some debate, but credit has been primarily given to state-driven economic development; social partnership among employers, government and trade unions; increased participation by women in the labour force; decades of investment in domestic higher education; targeting of foreign direct investment; a low corporation tax rate; an English-speaking workforce; and membership of the European Union, which provided transfer payments and export access to the Single Market.
By mid-2007, in the wake of the growing global financial crisis, the Celtic Tiger had all but died. Some critics, such as David McWilliams, who had been warning about impending collapse for some time, concluded: "The case is clear: an economically challenged government, perniciously influenced by the interests of the housing lobby, blew it. The entire Irish episode will be studied internationally in years to come as an example of how not to do things."
Historian Richard Aldous stated the Celtic Tiger has now gone the "way of the dodo". In early 2008, many commentators thought a soft landing was likely, but by January 2009, it seemed possible the country could experience a depression. In early January 2009, "The Irish Times", in an editorial, declared:
"We have gone from the Celtic Tiger to an era of financial fear with the suddenness of a Titanic-style shipwreck, thrown from comfort, even luxury, into a cold sea of uncertainty." In February 2010, a report by Davy Research concluded that Ireland had "largely wasted” its years of high income during the boom, with private enterprise investing its wealth "in the wrong places". It compared Ireland's growth to other small eurozone countries such as Finland and Belgium – noting that the physical wealth of those countries exceeds that of Ireland because of their "vastly superior" transport infrastructure, telecommunications network, and public services.
Tiger economy.
From 1995 to 2000, GDP growth rate ranged between 7.8 and 11.5%; it then slowed to between 4.4 and 6.5% from 2001 to 2007. During that period, the Irish GDP per capita rose dramatically to equal, then eventually surpass, that of all but one state in Western Europe. Although GDP does not represent the standard of living, and the GNP remained lower than the GDP, in 2007, the GNP achieved the same level as of some other Western European countries'.
Causes.
Tax policy.
Many economists credit Ireland's growth to a low corporate taxation rate (10 to 12.5% throughout the late 1990s). Since 1956, successive Irish governments have pursued low-taxation policies.
European Union Structural and Cohesion Funds.
Since joining the EU in 1973, Ireland has received over €17 billion in EU Structural and Cohesion Funds. These are made up of the European Regional Development Fund (ERDF) and the European Social Fund (ESF) and were used to increase investment in the education system and to build physical infrastructure. These transfer payments from members of the European Union, such as Germany and France, were as high as 4% of Ireland's gross national product (GNP). Ireland is unique among cohesion countries, having allocated up to 35% of its Structural Funds to human resource investments, compared with an average of around 25% for other cohesion fund recipients. The Irish economy's increased productive capacity is sometimes attributed to these investments, which made Ireland more attractive to high-tech businesses, though the libertarian Cato Institute has suggested that the EU transfer payments were economically inefficient and may have actually slowed growth. The conservative Heritage Foundation also attributed to transfer payments no significant role in causing growth.
Trade within the European Union.
Ireland's membership in the EU since 1973 helped the country gain access to Europe's large markets. Ireland's trade had previously been predominantly with the United Kingdom.
Industrial policies.
In the 1990s, the provision of subsidies and investment capital by Irish state organisations (such as IDA Ireland) encouraged high-profile companies, such as Dell, Intel, and Microsoft, to locate in Ireland; these companies were attracted to Ireland because of its EU membership, relatively low wages, government grants, and low tax rates. Enterprise Ireland, a state agency, provides financial, technical, and social support to start-up businesses. Additionally, the building of the International Financial Services Centre in Dublin led to the creation of 14,000 high-value jobs in the accounting, legal, and financial management sectors.
In July 2003, the government established the Science Foundation Ireland on a statutory basis to promote education for highly skilled careers, particularly in biotechnology and information and communications technology, with the additional purpose to invest in science initiatives that aim to further Ireland's knowledge economy.
Geography and demographics.
A favourable time zone difference allows Irish and British employees to work the first part of each day while US workers sleep. US firms were drawn to Ireland by cheap wage costs compared to the UK, and by the limited government intervention in business compared to other EU members, and particularly to countries in Eastern Europe. Growing stability in Northern Ireland brought about by the Good Friday Agreement further established Ireland's ability to provide a stable business environment.
Irish workers can communicate effectively with Americans – especially compared to those in other low-wage, non-English-speaking EU nations, such as Portugal and Spain; this factor was vital to U.S. companies' choosing Ireland for their European headquarters. It has also been argued that the demographic dividend from the rising ratio of workers to dependents due to falling fertility, and increased female labour market participation, increased income per capita.
Impact of economic growth.
Ireland was transformed from one of the poorest countries in Western Europe to one of the wealthiest. Disposable income soared to record levels, enabling a huge rise in consumer spending with foreign holidays accounting for over 91% of total holiday expenditure in 2004. However, the gap between the highest and lowest income households widened in the five-year period to 2004-2005; in response, the Economic and Social Research Institute (ESRI) stated in 2002: "On balance, budgets over the past 10 to 20 years have been more favourable to high income groups than low income groups, but particularly so during periods of high growth". Unemployment fell from 18% in the late 1980s to 4.5% by the end of 2007, and average industrial wages grew at one of the highest rates in Europe. Inflation brushed 5% per annum towards the end of the "Tiger" period, pushing Irish prices up to those of Nordic Europe, even though wage rates are roughly the same as in the UK. The national debt had remained constant during the boom, but the GDP to debt ratio rose, due to the dramatic rise in GDP.
The new wealth resulted in large investments in modernising Irish infrastructure and cities. The National Development Plan led to improvements in roads, and new transport services were developed, such as the Luas light rail lines, the Dublin Port Tunnel, and the extension of the Cork Suburban Rail. Local authorities enhanced city streets and built monuments such as the Spire of Dublin.
Ireland's trend of net emigration was reversed as the republic became a destination for immigrants. This significantly changed Irish demographics and resulted in expanding multiculturalism, particularly in the Dublin, Cork, Limerick, and Galway areas. It was estimated in 2007 that 10% of Irish residents were foreign-born; most of the new arrivals were citizens of Poland and the Baltic states, many of whom found work in the retail and service sectors. A study conducted in 2006 found that many Irish people regarded immigration as an important factor for economic progress. Within Ireland, many young people left the rural countryside to live and work in urban centres.
Many people in Ireland believe that the growing consumerism during the boom years eroded the country's culture, with the adoption of American capitalist ideals. While Ireland's historical economic ties to the UK had often been the subject of criticism, Peader Kirby argued that the new ties to the US economy were met with a "satisfied silence". Nevertheless, voices on the political left have decried the "closer to Boston than Berlin" philosophy of the Fianna Fail-Progressive Democrat government. Writers such as William Wall, Mike McCormick, and Gerry Murphy have satirised these developments. Growing wealth was blamed for rising crime levels among youths, particularly alcohol-related violence resulting from increased spending power. However, it was also accompanied by rapidly increased life expectancy and very high quality of life ratings; the country ranked first in "The Economist"'s 2005 quality of life index.
The growing success of Ireland's economy encouraged entrepreneurship and risk-taking, qualities that had been dormant during poor economic periods. However, whilst some semblance of a culture of entrepreneurship exists, foreign-owned companies account for 93% of Ireland's exports.
Downturn, 2001–2003.
The Celtic Tiger's growth slowed along with the slowing in the world economy in 2002 after seven years of high growth.
The economy was impacted by a large reduction in investment in the worldwide information technology (IT) industry. The industry had over-expanded in the late 1990s, and its stock market equity declined sharply. Ireland was a major player in the IT industry: in 2002, it had exported US$10.4 billion worth of computer services, compared to $6.9 billion from the US. Ireland accounted for approximately 50% of all mass-market packaged software sold in Europe in 2002 (OECD, 2002; OECD, 2004).
Foot and mouth disease and the 11 September 2001 attacks damaged Ireland's tourism and agricultural sectors, deterring U.S. and British tourists. Several companies moved operations to Eastern Europe and the People's Republic of China because of a rise in Irish wage costs, insurance premiums, and a general reduction in Ireland's economic competitiveness. The rising value of the Euro hit non-EMU exports, particularly those to the U.S. and the United Kingdom.
At the same time, economies globally experienced a slowdown. The US economy grew only 0.3% in April, May, and June 2002 from a year earlier, and the Federal Reserve made 11 rate cuts that year in an attempt to stimulate the US economy. The EU scarcely grew throughout the whole of 2002, and many members' governments (notably in Germany and France) lost control of public finances, causing large deficits that broke the terms of the EMU Stability and Growth Pact.
The economic downturn in Ireland was not a recession but a slowdown in the rate of economic expansion. Signs of a recovery became evident in late 2003, as US investment levels increased once again. Many senior economists have heavily criticised the government for the economic imbalance in favour of the construction industry, and the prospect of sustaining economic growth in the future.
Post-2003 resurgence.
After the slowdown in 2001 and 2002, Irish economic growth began to accelerate again in late 2003 and 2004. Some of the media considered that an opportunity to document the return of the Celtic Tiger – occasionally referred to in the press as the "Celtic Tiger 2" and "Celtic Tiger Mark 2". In 2004, Irish growth was the highest, at 4.5%, of the EU-15 states, and a similar figure was forecast for 2005. Those rates contrast with growth rates of 1% to 3% for many other European economies, including France, Germany, and Italy. The pace of expansion in lending to households from 2003-2007 was among the highest in the euro area
In 2006, there was a surge in Foreign Direct Investment and a net increase of 3,795 in IDA supported jobs, with International and Financial Services having the highest growth rate. The reasons for the continuation of the Irish economic boom were somewhat controversial within Ireland. Some Economists, Civil Rights Activists and Social Commentators have said that the growth throughout this period was merely due to a great increase in property values, and to catch-up growth in employment in the construction sector.
Globally, the U.S. recovery boosted Ireland's economy due to Ireland's close economic ties to the US. The decline in tourism as a result of foot and mouth disease and the 11 September 2001 attacks had reversed itself. The recovery of the global information technology industry was also a factor; Ireland produced 25% of all European PCs, and Apple, Dell (whose major European manufacturing plant was in Limerick), HP, and IBM all had sizeable Irish operations.
There had been a renewed investment by multinational firms. Intel had resumed its Irish expansion, Google created an office in Dublin, Abbott Laboratories was building a new Irish facility, and Bell Labs planned to open a future facility.
Domestically, a new state body, Science Foundation Ireland, was established to promote new science companies in Ireland Maturing funds from the SSIA government savings scheme relaxed consumers' concerns about spending and thus fueled retail sales growth.
In September 2009, Tánaiste Mary Coughlan said Ireland had lost ground in international competitiveness every year since 2000.
Challenges.
Property market.
The return of the boom in 2004 was claimed to be primarily the result of the large construction sector's catching up with the demand caused by the first boom. The construction sector represented nearly 12% of GDP and a large proportion of employment among young, unskilled men. A number of sources, including "The Economist," warned of excessive Irish property values. 2004 saw the construction of 80,000 new homes, compared to the UK's 160,000 – a nation that has 15 times Ireland's population. House prices doubled between 2000 and 2006; tax incentives were a key driver of this price rise, and the Fianna Fáil-Progressive Democrats government subsequently received substantial criticism for these policies.
In January 2009, UCD economist Morgan Kelly predicted that house prices would fall by 80% from peak to trough in real terms.
Loss of competitiveness.
Rising wages, inflation, and excessive public spending led to a loss of competitiveness in the Irish economy. Irish wages were substantially above the EU average, particularly in the Dublin region, though many poorer Eastern European states had joined the EU since 2004, substantially lowering the average EU wage below its 1995 level. Low-paid sectors, such as retail and hospitality, remained below the EU-15 average, however. The pressures primarily affect unskilled, semi-skilled, and manufacturing jobs. Outsourcing of professional jobs also increased, with Poland in 2008 gaining several hundred former Irish jobs from the accountancy divisions of Philips and Dell.
Promotion of indigenous industry.
One of the major challenges facing Ireland is the successful promotion of indigenous industry. Although Ireland boasted a few large international companies, such as AIB, CRH, Élan, Kerry Group, Ryanair, and Smurfit Kappa Group, there are few companies with over one billion euros in annual revenue. The government has charged Enterprise Ireland with the task of boosting Ireland's indigenous industry and launched a website in 2003 with the objective of streamlining and marketing the process of starting a business in Ireland.
Reliance on foreign energy sources.
Ireland relies on imported fossil fuels for over 80% of its energy. Ireland for many years in the middle twentieth century limited its dependence on external energy sources by developing its peat bogs, building various hydroelectric projects, including a dam at Ardnacrusha on the River Shannon in 1928, developing offshore gas fields, and diversifying into coal in the 1970s. As gas, peat, and hydroelectric power have been almost fully exploited in Ireland, there is a continuously increasing need for imported fossil fuels at a time of increasing concerns about security of supply and global warming. One solution is to develop alternative energy sources, including wind power and, to a lesser extent, wave power. Wind,however, is not a panacea as it needs to have conventional plants to augment it. An offshore wind farm is currently under construction off the east coast near Arklow, and many remote locations in the west show potential for wind farm development. A report by Sustainable Energy Ireland indicated that if wind power were properly developed, Ireland could one day be exporting excess wind power if the natural difficulties of integrating wind power into the national grid are solved. Wind power by November 2009 already accounted for 15.4% of total installed generating capacity in the state. By 2020, the Irish government forecasts that 40% of the country's energy needs will come from renewable sources, well above the EU average.
Distribution of wealth.
Ireland's new wealth is unevenly distributed. The United Nations reported in 2004 that Ireland was second only to the US in inequality among Western nations. There is some opposition to the theory that Ireland's wealth has been unusually unevenly distributed, among them economist and journalist David McWilliams. He cites Eurostat figures which indicate that Ireland is just above average in terms equality by one type of measurement. However, while it is better off by this measurement than generally less developed or more free market countries like Britain, the Mediterranean, and the new accession states, Ireland is still more unequal than France, Germany, and the Scandinavan countries. Moreover, Ireland's inequality persists by other measurements. According to an ESRI report published in December 2006, Ireland's child poverty level ranks 22nd out of the 26 richest countries, and it is the 2nd most unequal country in Europe.
Banking scandals.
The "New York Times" in 2005 described Ireland as the "Wild West of European finance", a perception that helped prompt the creation of the Irish Financial Services Regulatory Authority. Despite its mandate for stricter oversight, the agency never imposed major sanctions on any Irish institution, even though Ireland had experienced several major banking scandals in overcharging of their customers. Industry representatives disputed the idea that Ireland may be home to unchecked financial frauds. In December 2008, irregularities in directors loans that had been kept off one bank's balance sheet for eight years forced the resignation of the financial regulator. Economic commentator David McWilliams has described the collapse of Anglo Irish Bank as Ireland's Enron.
Death of the Tiger.
In an economic analysis, the Economic and Social Research Institute (ESRI) on 24 June 2008 forecasted the possibility the Irish economy would experience marginal negative growth in 2008. This would be the first time since 1983. Outlining possible prospects for the economy for 2008, the ESRI said output of goods and services might fall that year—which would have been the Irish definition of a mild recession. It also predicted a recovery in 2009 and 2010.
In September 2008, Ireland became the first eurozone country to officially enter recession. The recession was confirmed by figures from the Central Statistics Office showing the bursting of the property bubble and a collapse in consumer spending that terminated the boom that was the Celtic Tiger. The figures show the gross domestic product (GDP), which measures the value of all the goods and services produced in the State, fell 0.8% in the second three months of 2008 compared with the same quarter of 2007. That was the second successive quarter of negative economic growth, which is the definition of a recession. The Celtic Tiger was declared dead by October 2008
In a November 2008 interview in" Hot Press," in a grim assessment of where Ireland stood, then Taoiseach Brian Cowen said many people still did not realise how badly shaken the public finances were.
By 30 January 2009, Ireland’s government debt had become the riskiest in the euro zone, surpassing Greece’s sovereign bonds, according to credit-default swap prices. In February 2009, Taoiseach Brian Cowen said that Ireland's economy appeared on course to contract by 6.5% in 2009.
Aftermath.
Former Taoiseach Garret FitzGerald blamed Ireland's dire economic state in 2009 on a series of "calamitous" government policy errors. Between the years of 2000 and 2003 the then Finance Minister Charlie McCreevy boosted public spending by 48% while cutting income tax. A second problem occurred when government policies allowed, or even encouraged, a housing bubble to develop, "on an immense scale". However, he wrote nothing of the impact of the European Central Bank's low interest rates which funded the property bubble and further exacerbated the overheating economy
Nobel laureate Paul Krugman had a bleak prediction,
"“As far as responding to the recession goes, Ireland appears to be really, truly without options, other than to hope for an export-led recovery, if and when the rest of the world bounces back.”"
The International Monetary Fund in mid-April 2009 forecast a very poor outlook for Ireland. It projected that the Irish economy would contract by 8 per cent in 2009 and by 3 per cent in 2010 – and that might be on the optimistic side.
Unemployment in Ireland was forecasted to rise almost 17 percent in 2010, the Economic and Social Research Institute (ESRI) stated in a report published on 28 April 2009, however the unemployment rate in 2010 steadied at 14%. In 2012, the unemployment rate was at 14.8 percent, and in order to escape economic downfall, Ireland requested €67.5 billion ($85.7 billion) from the International Monetary Fund and members of the euro area. Taking the money meant accepting austerity: The government has cut expenditure by 15 percent over three years, consumer spending has dropped for six straight quarters, and young Irish by the thousands have emigrated to Australia and elsewhere.
On 19 November 2010, The Irish Government had begun talks on a multibillion-dollar economic assistance package with experts from the International Monetary Fund (IMF) and the European Union.
In mid-2011 the ratings agency Moody's proceeded to downgrade Ireland's government bond ratings to junk.
References.
http://www.economist.com/media/pdf/QUALITY_OF_LIFE.pdf

</doc>
<doc id="42678" url="https://en.wikipedia.org/wiki?curid=42678" title="1630s BC">
1630s BC


</doc>
<doc id="42679" url="https://en.wikipedia.org/wiki?curid=42679" title="1640s BC">
1640s BC


</doc>
<doc id="42680" url="https://en.wikipedia.org/wiki?curid=42680" title="1690s BC">
1690s BC


</doc>
<doc id="42681" url="https://en.wikipedia.org/wiki?curid=42681" title="1680s BC">
1680s BC


</doc>
<doc id="42682" url="https://en.wikipedia.org/wiki?curid=42682" title="1670s BC">
1670s BC


</doc>
<doc id="42683" url="https://en.wikipedia.org/wiki?curid=42683" title="1660s BC">
1660s BC


</doc>
<doc id="42684" url="https://en.wikipedia.org/wiki?curid=42684" title="1610s BC">
1610s BC


</doc>
<doc id="42685" url="https://en.wikipedia.org/wiki?curid=42685" title="1620s BC">
1620s BC


</doc>
<doc id="42686" url="https://en.wikipedia.org/wiki?curid=42686" title="1600s BC (decade)">
1600s BC (decade)


</doc>
<doc id="42687" url="https://en.wikipedia.org/wiki?curid=42687" title="1650s BC">
1650s BC


</doc>
<doc id="42691" url="https://en.wikipedia.org/wiki?curid=42691" title="André Malraux">
André Malraux

André Malraux DSO (; 3 November 1901 – 23 November 1976) was a French novelist, art theorist and Minister of Cultural Affairs. Malraux's novel "La Condition Humaine" (Man's Fate) (1933) won the Prix Goncourt. He was appointed by President Charles de Gaulle as Minister of Information (1945–1946) and subsequently as France's first Minister of Cultural Affairs during de Gaulle's presidency (1959–1969).
Early years.
Malraux was born in Paris in 1901, the son of Fernand-Georges Malraux and Berthe Lamy (Malraux). His parents separated in 1905 and eventually divorced. There are suggestions that Malraux's paternal grandfather committed suicide in 1909.
Malraux was raised by his mother, maternal aunt Marie and maternal grandmother, Adrienne Lamy-Romagna, who had a grocery store in the small town of Bondy. His father, a stockbroker, committed suicide in 1930 after the international crash of the stock market and onset of the Great Depression. From his childhood, associates noticed that André had marked nervousness and motor and vocal tics. The recent biographer Olivier Todd, who published a book on Malraux in 2005, suggests that he had Tourette's syndrome, although that has not been confirmed. Either way, most critics have not seen this as a significant factor in Malraux's life or literary works.
The young Malraux left formal education early, but he followed his curiosity through the booksellers and museums in Paris, and explored its rich libraries as well.
Marriage and family.
In 1922, Malraux married Clara Goldschmidt. Malraux and his first wife separated in 1938 but didn't divorce until 1947. His daughter from this marriage, Florence (b. 1933), married the filmmaker Alain Resnais.
After the breakdown of his marriage with Clara, Malraux lived with journalist and novelist Josette Clotis, starting in 1933. Malraux and Josette had two sons: Pierre-Gauthier (1940–1961) and Vincent (1943–1961). During 1944, while Malraux was fighting in Alsace, Josette died, aged 34, when she slipped while boarding a train. His two sons died together in 1961 in an automobile accident.
In 1948, Malraux married a second time, to Marie-Madeleine Lioux, a concert pianist and the widow of his half-brother, Roland Malraux. They separated in 1966.
Subsequently, Malraux lived with Louise de Vilmorin in the Vilmorin family château at Verrières-le-Buisson, Essonne, a suburb southwest of Paris. Vilmorin was best known as a writer of delicate but mordant tales, often set in aristocratic or artistic milieu. Her most famous novel was "Madame de...", published in 1951, which was adapted into the celebrated film "The Earrings of Madame de..." (1953), directed by Max Ophüls and starring Charles Boyer, Danielle Darrieux and Vittorio de Sica. Vilmorin's other works included "Juliette", "La lettre dans un taxi", "Les belles amours", "Saintes-Unefois", and "Intimités". Her letters to Jean Cocteau were published after the death of both correspondents. After Louise's death, Malraux spent his final years with her relative, Sophie de Vilmorin.
Career.
Early years.
Malraux's first published work, an article entitled "The Origins of Cubist Poetry", appeared in the magazine "Action" in 1920. This was followed in 1921 by three semi-surrealist tales, one of which, "Paper Moons", was illustrated by Fernand Léger. Malraux also frequented the Parisian artistic and literary milieux of the period, meeting figures such as Demetrios Galanis, Max Jacob, François Mauriac, Guy de Pourtalès, André Salmon, Jean Cocteau, Raymond Radiguet, Florent Fels, Pascal Pia, Marcel Arland, Edmond Jaloux, and Pierre Mac Orlan.
Indochina.
In 1923, aged 22, Malraux left for Cambodia with Clara. There, together with Clara and a friend, Louis Chevasson, he undertook a small expedition into unexplored areas of the Cambodian jungle in search of lost Khmer temples, hoping to steal items that might be sold to art museums. On his return, he was arrested by French colonial authorities for removing a "bas-relief" from "Banteay Srei". Malraux, who believed he had acted within the law as it then stood, contested the charges but was unsuccessful.
Malraux's experiences in Indochina led him to become highly critical of the French colonial authorities there. In 1925, with Paul Monin, a progressive lawyer, he helped to organize the Young Annam League and founded a newspaper "L'Indochine".
On his return to France, Malraux published "The Temptation of the West" (1926). The work was in the form of an exchange of letters between a Westerner and an Asian, comparing aspects of the two cultures. This was followed by his first novel "The Conquerors" (1928), and then by "The Royal Way" (1930) which reflected some of his Cambodian experiences. In 1933 Malraux published "Man's Fate" ("La Condition Humaine"), a novel about the 1927 failed Communist rebellion in Shanghai. The work was awarded the 1933 Prix Goncourt.
Spanish Civil War.
During the 1930s, Malraux was active in the anti-fascist Popular Front in France. At the beginning of the Spanish Civil War he joined the Republican forces in Spain, serving in and helping to organize the small Spanish Republican Air Force. (Curtis Cate, one of his biographers, claims that Malraux was slightly wounded twice during efforts to stop the Falangists' takeover of Madrid, but the historian Hugh Thomas claims otherwise.)
The French government sent aircraft to Republican forces in Spain, but they were obsolete by the standards of 1936. They were mainly Potez 540 bombers and Dewoitine D.372 fighters. The slow Potez 540 rarely survived three months of air missions, flying at 80 knots against enemy fighters flying at more than 250 knots. Few of the fighters proved to be airworthy, and they were delivered intentionally without guns or gunsights. (The Ministry of Defense of France had feared that modern types of planes would easily be captured by the Germans fighting for Francisco Franco, and the lesser models were a way of maintaining official "neutrality".) The planes were surpassed by more modern types introduced by the end of 1936 on both sides.
The Republic circulated photos of Malraux standing next to some Potez 540 bombers suggesting that France was on their side, at a time when France and the United Kingdom had declared official neutrality. But Malraux's commitment to the Republicans was personal, like that of many other foreign volunteers, and there was never any suggestion that he was there at the behest of the French Government. Malraux himself was not a pilot, and never claimed to be one, but his leadership qualities seem to have been recognized because he was made Squadron Leader of the 'España' squadron. Acutely aware of the Republicans' inferior armaments, of which outdated aircraft were just one example, he toured the United States to raise funds for the cause. In 1938 he published "L'Espoir" (Man's Hope), a novel influenced by his Spanish war experiences.
Malraux's participation in major historical events such as the Spanish Civil War inevitably brought him determined adversaries as well as strong supporters, and the resulting polarization of opinion has colored, and rendered questionable, much that has been written about his life. Fellow combatants praised Malraux's leadership and sense of camaraderie, although Antony Beevor says André Marty of the Comintern described him as an "adventurer" for his high profile and demands on the Spanish Republican government. Beevor also claims that "Malraux stands out, not just because he was a mythomaniac in his claims of martial heroism – in Spain and later in the French Resistance – but because he cynically exploited the opportunity for intellectual heroism in the legend of the Spanish Republic."
Malraux's participation in events such as the Spanish Civil War has tended to distract attention from his important literary achievement. Malraux saw himself first and foremost as a writer and thinker (and not a "man of action" as biographers so often portray him) but his extremely eventful life – a far cry from the stereotype of the French intellectual confined to his study or a Left Bank café – has tended to obscure this fact. As a result, his literary works, including his important works on the theory of art, have received less attention than one might expect, especially in Anglophone countries.
World War II.
At the beginning of the Second World War, Malraux joined the French Army. He was captured in 1940 during the Battle of France but escaped and later joined the French Resistance. In 1944, he was captured by the Gestapo. He later commanded the tank unit Brigade Alsace-Lorraine in defence of Strasbourg and in the attack on Stuttgart.
After the war, Malraux was awarded the "Médaille de la Résistance" and the Croix de guerre. The British awarded him the Distinguished Service Order, for his work with British liaison officers in Corrèze, Dordogne and Lot. After Dordogne was liberated, Malraux led a battalion of former resistance fighters to Alsace-Lorraine, where they fought alongside the First Army.
During the war, he worked on his last novel, "The Struggle with the Angel", the title drawn from the story of the Biblical Jacob. The manuscript was destroyed by the Gestapo after his capture in 1944. A surviving first section, titled "The Walnut Trees of Altenburg", was published after the war.
After the war.
Shortly after the war, General Charles de Gaulle appointed Malraux as his Minister for Information (1945–1946). Soon after, he completed his first book on art, "The Psychology of Art", published in three volumes (1947–1949). The work was subsequently revised and republished in one volume as "The Voices of Silence" ("Les Voix du Silence"), the first part of which has been published separately as "The Museum without Walls". Other important works on the theory of art were to follow. These included the three-volume "Metamorphosis of the Gods" and "Precarious Man and Literature", the latter published posthumously in 1977.
When de Gaulle returned to the French presidency in 1958, Malraux became France's first Minister of Cultural Affairs, a post he held from 1958 to 1969. Among many initiatives, he launched an innovative (and subsequently widely imitated) program to clean the blackened façades of notable French buildings, revealing the natural stone underneath. He also created a number of "maisons de la culture" in provincial cities and worked to preserve France's national heritage.
In 1957, Malraux published the first volume of his trilogy on art entitled "The Metamorphosis of the Gods". The second two volumes (not yet translated into English) were published shortly before he died. They are entitled "L’Irréel" and "L'Intemporel" and discuss artistic developments from the Renaissance to modern times. Malraux also initiated the series "Arts of Mankind", an ambitious survey of world art that generated more than thirty large, illustrated volumes.
Malraux was an outspoken supporter of the Bangladesh liberation movement during the 1971 Pakistani Civil War and despite his age seriously considered joining the struggle. When Indira Gandhi came to Paris in November 1971, there was extensive discussion between them about the situation in Bangladesh.
During this post-war period, Malraux also published a series of semi-autobiographical works, the first entitled "Antimémoires" (1967). A later volume in the series, "Lazarus", is a reflection on death occasioned by his experiences during a serious illness. "La Tête d'obsidienne" (1974) (translated as "Picasso's Mask") concerns Picasso, and visual art more generally.
Malraux died in Créteil, near Paris, on 23 November 1976. He was buried in the Verrières-le-Buisson (Essonne) cemetery. In recognition of his contributions to French culture, his ashes were moved to the Panthéon in Paris during 1996, on the twentieth anniversary of his death.
Legacy and honours.
There is now a large and steadily growing body of critical commentary on Malraux's literary "œuvre", including his very extensive writings on art. Unfortunately, some of his works, including the last two volumes of "The Metamorphosis of the Gods" ("L'Irréel" and "L'Intemporel") are not yet available in English translation. Malraux's works on the theory of art contain a revolutionary approach to art that challenges the Enlightenment tradition that treats art simply as a source of "aesthetic pleasure". However, as French writer André Brincourt has commented, Malraux's books on art have been "skimmed a lot but very little read" (this is especially true in Anglophone countries) and the radical implications of his thinking are often missed. A particularly important aspect of Malraux's thinking about art is his explanation of the capacity of art to transcend time. In contrast to the traditional notion that art endures because it is timeless ("eternal"), Malraux argues that art lives on through metamorphosis – a process of resuscitation (where the work had fallen into obscurity) and transformation in meaning.
Quotations.
""Man is dead", after God". Malraux, "The Temptation of the West". (1926)
‘The artist is not the transcriber of the world, he is its rival.’ Malraux, "L'Intemporel" (3rd volume of "The Metamorphosis of the Gods".)
"What is a man? A miserable little pile of secrets" "Antimémoires", preface (1967)
'In a world in which everything is subject to the passing of time, art alone is both subject to time and yet victorious over it'. "Malraux in a television program about art, 1975".
"Art is an object lesson for the gods." "The Voices of Silence"
"The art museum is one of the places that give us the highest idea of man." "The Voices of Silence"
"Humanism does not consist in saying: ‘No animal could have done what I have done,’ but in declaring: ‘We have refused what the beast within us willed to do, and we seek to reclaim man wherever we find that which crushes him.’" "The Voices of Silence"
"The greatest mystery is not that we have been flung at random between this profusion of matter and the stars, but that within this prison we can draw from ourselves images powerful enough to deny our nothingness." "Les Noyers de l'Altenburg"
Bibliography.
For a more complete bibliography, see site littéraire André Malraux.

</doc>
<doc id="42693" url="https://en.wikipedia.org/wiki?curid=42693" title="Upper and lower bounds">
Upper and lower bounds

In mathematics, especially in order theory, an upper bound of a subset "S" of some partially ordered set ("K", ≤) is an element of "K" which is greater than or equal to every element of "S". The term lower bound is defined dually as an element of "K" which is less than or equal to every element of "S". A set with an upper bound is said to be bounded from above by that bound, a set with a lower bound is said to be bounded from below by that bound. The terms bounded above (bounded below) are also used in the mathematical literature for sets that have upper (respectively lower) bounds.
Examples.
5 is a lower bound for the set { 5, 8, 42, 34, 13934 }, but 8 is not. For the set { 42 }, the only number 42 is both an upper and a lower bound; all other numbers are either an upper bound or a lower bound for that set.
Every subset of the natural numbers has a lower bound, since the natural numbers have a least element (0, or 1 depending on the exact definition of natural numbers). An infinite subset of the natural numbers cannot be bounded from above. An infinite subset of the integers may be bounded from below or bounded from above, but not both. An infinite subset of the rational numbers may or may not be bounded from below and may or may not be bounded from above.
Every finite subset of a non-empty totally ordered set has both upper and lower bounds.
Bounds of functions.
The definitions can be generalized to functions and even sets of functions.
Given a function with domain and a partially ordered set as codomain, an element of is a upper bound of if for each in . The upper bound is called "sharp" if equality holds for at least one value of .
Function defined on domain and having the same codomain is an upper bound of if for each in .
Function is further said to be a upper bound of a set of functions if it is an upper bound of each function in that set.
The notion of lower bound for (sets of) functions is defined analogously, with ≤ replacing ≥.
Tight bounds.
An upper bound is said to be a "tight upper bound", a "least upper bound", or a "supremum" if no smaller value is an upper bound.
Similarly a lower bound is said to be a "tight lower bound", a "greatest lower bound", or an "infimum" if no greater value is a lower bound.

</doc>
<doc id="42694" url="https://en.wikipedia.org/wiki?curid=42694" title="Nabokov (surname)">
Nabokov (surname)

Nabokov is a surname. Notable people with the surname include:

</doc>
<doc id="42702" url="https://en.wikipedia.org/wiki?curid=42702" title="Gloster Meteor">
Gloster Meteor

The Gloster Meteor was the first British jet fighter and the Allies' only operational jet aircraft during the Second World War. The Meteor's development was heavily reliant on its ground-breaking turbojet engines, pioneered by Sir Frank Whittle and his company, Power Jets Ltd. Development of the aircraft itself began in 1940, although work on the engines had been under way since 1936. The Meteor first flew in 1943 and commenced operations on 27 July 1944 with No. 616 Squadron RAF. Nicknamed the "Meatbox", the Meteor was not a sophisticated aircraft in its aerodynamics, but proved to be a successful combat fighter.
Several major variants of the Meteor incorporated technological advances during the 1940s and 1950s. Thousands of Meteors were built to fly with the RAF and other air forces and remained in use for several decades. The Meteor saw limited action in the Second World War. Meteors of the Royal Australian Air Force (RAAF) fought in the Korean War. Several other operators such as Argentina, Egypt and Israel flew Meteors in later regional conflicts. Specialised variants of the Meteor were developed for use in photographic aerial reconnaissance and as night fighters.
The Meteor was also used for research and development purposes and to break several aviation records. On 7 November 1945, the first official air speed record by a jet aircraft was set by a Meteor F.3 of 606 miles per hour (975 km/h). In 1946, this record was broken when a Meteor F.4 reached a speed of 616 mph (991 km/h). Other performance-related records were broken in categories including flight time endurance, rate of climb, and speed. On 20 September 1945, a heavily modified Meteor I, powered by two Rolls-Royce Trent turbine engines driving propellers, became the first turboprop aircraft to fly. On 10 February 1954, a specially adapted Meteor F.8, the "Meteor Prone Pilot", which placed the pilot into a prone position to counteract inertial forces, took its first flight.
In the 1950s, the Meteor became increasingly obsolete as more nations introduced jet fighters, many of these newcomers having adopted a swept wing instead of the Meteor's conventional straight wing; in RAF service, the Meteor was replaced by newer types such as the Hawker Hunter and Gloster Javelin. As of 2013, two Meteors, "WL419" and "WA638", remain in active service with the Martin-Baker company as ejection seat testbeds. Two further aircraft in the UK remain airworthy, as does another in Australia.
Development.
Origins.
The development of the turbojet-powered Gloster Meteor was a collaboration between the Gloster Aircraft Company and Sir Frank Whittle's firm, Power Jets Ltd. Frank Whittle formed Power Jets Ltd in March 1936 to develop his ideas of jet propulsion, Whittle himself serving as the company's chief engineer. For several years, attracting financial backers and aviation firms prepared to take on Whittle's radical ideas was difficult; in 1931, Armstrong-Siddeley had evaluated and rejected Whittle's proposal, finding it to be technically sound but at the limits of engineering capability. Securing funding was a persistently worrying issue throughout the early development of the engine. The first Whittle prototype jet engine, the Power Jets WU, began running trials in early 1937; shortly afterwards, both Sir Henry Tizard, chairman of the Aeronautical Research Committee, and the Air Ministry gave the project their support.
On 28 April 1939, Whittle made a visit to the premises of the Gloster Aircraft Company, where he met several key figures, such as George Carter, Gloster's chief designer. Carter took a keen interest in Whittle's project, particularly when he saw the operational Power Jets W.1 engine; Carter quickly made several rough proposals of various aircraft designs powered by the engine. Independently, Whittle had also been producing several proposals for a high-altitude jet-powered bomber; following the start of the Second World War and the Battle for France, a greater national emphasis on fighter aircraft arose. Power Jets and Gloster quickly formed a mutual understanding around mid-1939.
In spite of ongoing infighting between Power Jets and several of its stakeholders, the Air Ministry contracted Gloster to manufacture a prototype aircraft powered by one of Whittle's new turbojet engines in late 1939. The single-engined proof-of-concept Gloster E28/39, the first British jet-powered aircraft, conducted its maiden flight on 15 May 1941, flown by Gloster's Chief Test Pilot, Flight Lieutenant Philip "Gerry" Sayer. The success of the smaller E.28/39 proved the viability of jet propulsion, and Gloster pressed ahead with designs for a production fighter aircraft. Due to the limited thrust available from early jet engines, it was decided that subsequent production aircraft would be powered by a pair of turbojet engines.
In 1940, for a "military load" of , the RAE had advised that work on an aircraft of all-up weight, with a static thrust of 3,200 lb (14.2 kN) should be started, with an 11,000 lb (4,990 kg) design for the expected more powerful W.2 and axial engine designs. George Carter's calculations based on the RAE work and his own investigations was that a aircraft with two or four 20 mm cannon and six 0.303 machine guns would have a top speed of 400–431 mph at sea level and 450–470 mph at 30,000 ft. In January 1941 Gloster were told by Lord Beaverbrook that the twin jet fighter was of "unique importance", and that the company was to stop work on a night-fighter being developed to Specification F.18/40.
Prototypes.
In August 1940, Carter presented Gloster's initial proposals for a twin-engined jet fighter with a nosewheel undercarriage. On 7 February 1941, Gloster received an order for twelve prototypes (later reduced to eight) under Specification F9/40. A letter of intent for the production of 300 of the new fighter, initially to be named "Thunderbolt," was issued on 21 June 1941; to avoid confusion with the USAAF Republic P-47 Thunderbolt which had been issued with the same name to the RAF in 1944, the aircraft's name was quickly changed to "Meteor." During the aircraft's secretive development, employees and officials made use of the codename "Rampage" to refer to the Meteor. Test locations and other key project information was similarly obscured.
Although taxiing trials were carried out in 1942, it was not until the following year that any flights took place due to production and approval holdups with the Power Jets W.2 engine powering the Meteor. Due to the delays at subcontractor Rover, who was struggling to manufacture the W.2 engines on schedule, on 26 November 1942, production of the Meteor was ordered to stop; considerable interest was shown in Gloster's E.1/44 proposal for a single-engine fighter, unofficially named Ace. Gloster continued development work on the Meteor and the production-stop order was overturned in favour of the construction of six (later increased to eight) F9/40 prototypes alongside three E.1/44 prototypes. Rover's responsibilities for development and production of the W.2B engine were also transferred to Rolls-Royce that year.
On 5 March 1943, the fifth prototype, serial "DG206", powered by two substituted de Havilland Halford H.1 engines owing to problems with the intended W.2 engines, became the first Meteor to become airborne at RAF Cranwell, piloted by Michael Daunt. On the initial flight, an uncontrollable yawing motion was discovered, which led to a redesigned larger rudder; however, no difficulties had been attributed to the groundbreaking turbojet propulsion. Only two prototypes flew with de Havilland engines because of the low flight endurance they were capable of providing. Before the first prototype aircraft had even undertaken its first flight, an extended order for 100 production-standard aircraft had already been placed by the RAF.
The first Whittle-engined aircraft, "DG205/G", flew on 12 June 1943 (later crashing during takeoff on 27 April 1944) and was followed by "DG202/G" on 24 July. "DG202/G" was later used for deck handling tests aboard aircraft carrier . "DG203/G" made its first flight on 9 November 1943, later becoming a ground instructional airframe. "DG204/G", powered by Metrovick F.2 engines, first flew on 13 November 1943; "DG204/G" was lost in an accident on 4 January 1944, the cause believed to have been an engine compressor failure due to overspeed. "DG208/G" made its début on 20 January 1944, by which time the majority of design problems had been overcome and a production design had been approved. "DG209/G" was used as an engine testbed by Rolls-Royce, first flying on 18 April 1944. "DG207/G" was intended to be the basis for the Meteor F.2 with de Havilland engines, but it did not fly until 24 July 1945, at which time the Meteor 3 was in full production and de Havilland's attention was being redirected to the incoming de Havilland Vampire, thus the F.2 was cancelled.
Into production.
On 12 January 1944, the first Meteor F.1, serial "EE210/G", took to the air from Moreton Valence. It was essentially identical to the F9/40 prototypes except for the addition of four nose-mounted 20 mm (.79 in) Hispano Mk V cannons and some changes to the canopy to improve all-round visibility. Due to the F.1's similarity to the prototypes, they were frequently operated in the test program to progress British understanding of jet propulsion, and it took until July 1944 for the aircraft to enter squadron service. "EE210/G" was later sent to the U.S. for evaluation in exchange for a pre-production Bell XP-59A Airacomet, the Meteor being flown first by John Grierson at Muroc Army Airfield on 15 April 1944.
Originally 300 F.1s were ordered, but the total produced was reduced to 20 aircraft as the follow-on orders had been converted to the more advanced models. Some of the last major refinements to the Meteor's early design were trialed using this first production batch, and what was to become the long-term design of the engine nacelles was introduced upon "EE211". The original nacelles had been discovered by the RAE to suffer from compressibility buffeting at higher speeds, causing increased drag, and the re-designed longer nacelles eliminated this and provided an increase in the Meteor's maximum speed. The lengthened nacelles were introduced on the final fifteen Meteor III's. "EE215" was the first Meteor to be fitted with guns; "EE215" was also used in engine reheat trials, the addition of reheat increasing top speed from 420 mph to 460 mph. and was later converted into the first two-seat Meteor. Due to the radical differences between jet-powered aircraft and those that preceded, a special "Tactical Flight" or "T-Flight" unit was established to prepare the Meteor for squadron service, led by Group Captain Hugh Joseph Wilson. The Tactical Flight was formed at Farnborough in May 1944, the first Meteors arriving the following month, upon which both tactical applications and limitations were extensively explored.
On 17 July 1944, the Meteor F.1 was cleared for service use. Shortly afterwards, elements of the Tactical Flight and their aircraft were transferred to operational RAF squadrons. The first deliveries to No. 616 Squadron RAF, the first operational squadron to receive the Meteor, began in July 1944. When the F.2 was cancelled, the Meteor F.3 became the immediate successor to the F.1 and alleviated some of the shortcomings of the F.1. In August 1944, the first F.3 prototype flew; early F.3 production aircraft were still fitted with the Welland engine as the Derwent engine's production line was only just starting at this point. A total of 210 F.3 aircraft were produced before they were in turn superseded by production of the Meteor F.4 in 1945.
Several Meteor F.3s were converted into navalised aircraft. The adaptations included a strengthened undercarriage and arrester hook. Operational trials of the type took place aboard . The trials included carrier landings and takeoffs. Performance of these naval prototype Meteors proved to be favorable, including takeoff performance, leading to further trials with a modified Meteor F.4 fitted with folding wings; a 'clipped wing' was also adopted. The Meteor later entered service with the Royal Navy, but only as a land-based trainer, the Meteor T.7, to prepare pilots of the Fleet Air Arm for flying other jet aircraft such as the de Havilland Sea Vampire.
While various marks of Meteor had been introduced by 1948, they had remained very similar to the prototypes of the Meteor; consequently, the performance of the Meteor F.4 was beginning to be eclipsed by new jet designs. Gloster therefore embarked on a redesign programme to produce a new version of the Meteor with better performance. Designated Meteor F.8, this upgraded variant was a potent fighter aircraft, forming the bulk of RAF Fighter Command between 1950 and 1955. The Meteor continued to be operated in a military capacity by several nations into the 1960s.
Night fighter.
In order to replace the increasingly obsolete de Havilland Mosquito as a night fighter, the Meteor was adapted to serve in the role as an interim aircraft. Gloster had initially proposed a night fighter design to meet the Air Ministry specification for the Mosquito replacement, based on the two seater trainer variant of the Meteor, with the pilot in the front seat and the navigator in the rear. Once accepted however, work on the project was swiftly transferred to Armstrong Whitworth to perform both the detailed design process and production of the type; the first prototype flew on 31 May 1950. Although based on the T.7 twin seater, it used the fuselage and tail of the F.8, and the longer wings of the F.3. An extended nose contained the AI Mk 10 (the 1940s Westinghouse SCR-720) Air Intercept radar. As a consequence the 20 mm cannons were moved into the wings, outboard of the engines. A ventral fuel tank and wing mounted drop tanks completed the Armstrong Whitworth Meteor NF.11.
As radar technology developed, a new Meteor night fighter was developed to use the improved US-built APS-21 system. The "NF.12" first flew on 21 April 1953. It was similar to the NF 11 but had a nose section 17 inches (43.2 cm) longer; the fin was enlarged to compensate for the greater keel area of the enlarged nose and to counter the airframe reaction to the "wig-wag" scan of the radar which affected the gunsighting, an anti-tramp motor operating on the rudder was fitted midway up the front leading edge of the fin. The NF.12 also had the new Rolls-Royce Derwent 9 engines and the wings were reinforced to handle the new engine. Deliveries of the NF.12 started in 1953, with the type entering squadron service in early 1954, equipping seven squadrons (Nos 85, 25, 152, 46, 72, 153 and 64); the aircraft was replaced over 1958–59.
The final Meteor night fighter was the "NF.14". First flown on 23 October 1953, the NF.14 was based on the NF.12 but had an even longer nose, extended by a further 17 inches to accommodate new equipment, increasing the total length to 51 ft 4 in (15.65 m) and a larger bubble canopy to replace the framed T.7 version. Just 100 NF.14s were built; they first entered service in February 1954 beginning with No. 25 Squadron and were being replaced as early as 1956 with the Gloster Javelin. Overseas, they remained in service a little longer, serving with No. 60 Squadron at Tengah, Singapore until 1961. As the NF.14 was replaced, some 14 were converted to training aircraft as the "NF(T).14" and given to No. 2 Air Navigation School on RAF Thorney Island until transferring to No. 1 Air Navigation School at RAF Stradishall where they served until 1965.
Design.
Overview.
The first operational version of the Meteor, designated as the Meteor F.1, apart from the minor airframe refinements, was a straightforward 'militarisation' of the earlier F9/40 prototypes. The dimensions of the standard Meteor F.1 were 41 ft 3 in (12.58 m) long with a span of 43 ft 0 in (13.11 m), with an empty weight of 8,140 lb (3,823 kg) and a maximum takeoff weight of 13,795 lb (6,270 kg). Despite the revolutionary turbojet propulsion used, the design of the Meteor was relatively orthodox and did not take advantage of many aerodynamic features utilised on other jet fighters, such as swept wings; the Meteor shared a broadly similar basic configuration to its German equivalent, the Messerschmitt Me 262.
It was an all-metal aircraft with a tricycle undercarriage and conventional low, straight wings with mid-mounted turbojet engines and a high-mounted tailplane clear of the jet exhaust. The Meteor F.1 exhibited some problematic flying characteristics typical of early jet aircraft; it suffered from stability problems at high transonic speeds, large trim changes, high stick forces and self-sustained yaw instability (snaking) caused by airflow separation over the thick tail surfaces. The longer fuselage of the Meteor T.7, a two-seater trainer, significantly reduced the aerodynamic instability that the early Meteors were known for.
Later Meteor variants would see a large variety of changes from the initial Meteor F.1 introduced to service in 1944. Much attention was given to raising the aircraft's top speed, often by improving the airframe's aerodynamic qualities, incorporating the latest engine developments, and increasing the strength of the airframe. The Meteor F.8, which emerged in the late 1940s, was considered to have substantially improved performance over prior variants; the F.8 was reportedly the most powerful single-seat aircraft flying in 1947, capable of ascending to 40,000 feet within five minutes.
Construction.
From the outset, each Meteor was constructed from several modular sections or separately produced units; this was a deliberate design choice to allow for production to be dispersed and for easy disassembly for transport. Each aircraft comprised five main sections: nose, forward fuselage, central section, rear fuselage and tail units; the wings were also built out of lengthwise sections. The forward section contained the pressure cabin, gun compartments, and forward undercarriage. The center section incorporated much of the structural elements, including the inner wing, engine nacelles, fuel tank, ammunition drums, and main undercarriage. The rear fuselage was of a conventional semi-monocoque structure. Various aluminium alloys were the primary materials used throughout the structure of the Meteor, such as the stressed duralumin skin.
Across the Meteor's production life, various different companies were subcontracted to manufacture aircraft sections and major components; due to the wartime workload on producing fighter aircraft such as the Hawker Hurricane and Hawker Typhoon, neither Gloster nor the wider Hawker Siddeley Group were able to internally meet the production demand of 80 aircraft per month. Bristol Tramways produced the forward fuselage of the aircraft, the Standard Motor Company manufactured the central fuselage and inner wing sections, the Pressed Steel Company produced the rear fuselage, and Parnall Aircraft made the tail unit. Other main subcontractors included Boulton Paul Aircraft, Excelsior Motor Radiator Company, Bell Punch, Turner Manufacturing Company, and Charlesworth Bodies; as many of these firms had little or no experience producing aircraft, both quality and interchangeability of components were maintained by contractually enforced adherence to Gloster's original drawings.
From the Meteor F.4 onwards, Armstrong Whitworth began completing whole units at their Coventry facility in addition to Gloster's own production line. Belgian aviation firm Avions Fairey would also produce the Meteor F.8 under license from Gloster for the Belgian Air Force; a similar license manufacturing arrangement was made with Dutch company Fokker to meet the Royal Netherlands Air Force's order.
Engines.
The "Meteor F.1" was powered by two Rolls-Royce Welland turbojet engines, Britain's first production jet engines, which were built under license from Whittle's designs. The Meteor embodied the advent of practical jet propulsion; in the type's service life, both military and civil aviation manufacturers would rapidly integrate turbine engines into their designs, favouring its advantages such as smoother running and greater power output. The Meteor's engines were considerably more practical than those of the German Me 262, having both a longer service life and being more efficient; unlike the Me 262, the engines were embedded into the wing in nacelles between the front and rear spars rather than underslung.
The W.2B/23C engines upon which the Welland was based produced 1,700 lbf (7.58 kN) of thrust each, giving the aircraft a maximum speed of 417 mph (670 km/h) at 3,000 m and a range of 1,006 miles (1,610 km). It incorporated a hydraulically driven engine starter developed by Rolls-Royce, which was automated following the press of a starter button in the cockpit. The engines also drove hydraulic and vacuum pumps as well as a generator via a Rotol gearbox fixed on the forward wing spar; the cockpit was also heated by bleed air from one of the engines. The acceleration rate of the engines was manually controlled by the pilot; rapid engine acceleration would frequently induce compressor stalls early on; the likelihood of compressor stalls was effectively eliminated upon further design refinements of both the Welland engine and the Meteor itself. At high speeds, the Meteor had an unfortunate tendency to lose directional stability, often during unfavourable weather conditions, leading to a 'snaking' motion; this could be easily resolved by throttling back to reduce speed.
Based upon designs produced by Power Jets, Rolls-Royce produced more advanced and powerful turbojet engines. Beyond numerous improvements made to the Welland engine that powered the early Meteors; Rolls-Royce and Power Jets collaborated to develop the more capable Derwent engine, which as the Rover B.26 had undergone a radical re-design from the W.2B/500 while at Rover. The Derwent engine, and the re-designed Derwent V based on the Nene, was installed on many of the later production Meteors, the adoption of this new powerplant let to considerable performance increases. The Meteor often served as the basis for the development of other early turbojet designs; a pair of Meteor F.4s were sent to Rolls-Royce to aid in their experimental engine trials, "RA435" being used for reheat testing, and "RA491" being fitted with the Rolls-Royce Avon, an axial-flow engine. From their involvement in the development of the Meteor's engines, Armstrong-Siddeley, Bristol Aircraft, Metropolitan-Vickers, and de Havilland would also independently develop their own gas turbine engines.
Performance.
During development, skeptical elements of the Air Ministry had expected mature piston-powered aircraft types to exceed the capabilities of the Meteor in all respects except that of speed; thus, the performance of early Meteors was considered favourable for the interceptor mission, being capable of out-diving the majority of enemy aircraft. The conclusion of in-service trials conducted between the Meteor F.3. and the Hawker Tempest V was that the performance of the Meteor exceeded the Tempest in almost all respects and that, barring some manoeuvrability issues, the Meteor could be considered a capable all-round fighter. Pilots formerly flying piston-engine aircraft often described the Meteor as being exciting to fly. Ex-RAF pilot Norman Tebbit stated of his experience of the Meteor: "Get airborne, up with the wheels, hold it low until you were about 380 knots, pull it up and she would go up, well we thought then, like a rocket".
As a general rule, the jet engine consumes more fuel than its piston-engine counterparts; the fuel-hungry Welland engines imposed considerable limitations on the Meteor F.1, leading to the type being used for local interception duties only. In the post-war environment, there was considerable pressure to increase the range of interceptors to counter the threat of bombers armed with nuclear weapons. The long term answer to this question was the in-flight refuelling; several Meteors were provided to Flight Refuelling Limited for trials of the newly developed probe-and-drogue refuelling techniques. This capability was not rolled out to service Meteors however, having already been supplanted by more modern interceptor aircraft at this point.
In May 1951, it was reported that the Meteor 4's tail unit lost half its strength when the skin tore. The skin tearing was found to originate round rivet holes, access panels or discontinuous stringers (stress risers).
A total of 890 Meteors were lost in RAF service (145 of these crashes occurring in 1953 alone), resulting in the deaths of 450 pilots. Contributory factors in the number of crashes were the high fuel consumption and consequent short flight endurance (less than one hour), causing pilots to run out of fuel, and difficult handling with one engine out due to the widely set engines. The casualty rate was exacerbated by the lack of ejection seats in early series Meteors; the ground-breaking high speed that the aircraft was capable of meant that, during the bailing out process, pilots were typically subject to high g forces hindering movement and the effect of slipstream winds; there was also a greater likelihood of the pilot striking the horizontal tailplane. Ejection seats would be fitted in the later F.8, FR.9, PR.10 and some experimental Meteors. The difficulty of bailing out of the Meteor has been noted by pilots during development, reporting several contributing design factors such as the limited size and relative position of the cockpit to the rest of the aircraft, and difficulty in using the two-lever jettisonable hood mechanism.
Operational service.
Second World War.
No. 616 Squadron RAF was the first to receive operational Meteors: a total of 14 aircraft were initially delivered. The squadron was based at RAF Culmhead, Somerset and had been previously equipped with the Spitfire VII. The conversion to the Meteor was initially a matter of great secrecy. Following a conversion course at Farnborough attended by the squadron's six leading pilots, the first aircraft was delivered to Culmhead on 12 July 1944. The squadron and its seven Meteors moved on 21 July 1944 to RAF Manston on the east Kent coast and, within a week, 32 pilots had been converted to the type.
The Meteor was initially used to counter the V-1 flying bomb threat. 616 Squadron Meteors saw action for the first time on 27 July 1944, when three aircraft were active over Kent. These were the first operational jet combat missions for the Meteor and for the Royal Air Force. After some problems, especially with jamming guns, the first two V1 "kills" were made on 4 August. By war's end, Meteors had accounted for 14 flying bombs. After the end of the V-1 threat, and the introduction of the ballistic V-2 rocket, the RAF was forbidden to fly the Meteor on combat missions over German-held territory for fear of an aircraft being shot down and salvaged by the Germans.
No. 616 Squadron briefly moved to RAF Debden to allow USAAF bomber crews to gain experience and create tactics in facing jet-engined foes before moving to Colerne, Wiltshire. For a week from 10 October 1944 a series of exercises were carried out in which a flight of Meteors made mock attacks on a formation of 100 B-24s and B-17s escorted by 40 Mustangs and Thunderbolts. These suggested that, if the jet fighter attacked the formation from above, it could take advantage of its superior speed in the dive to attack the bombers and then escape by diving through the formation before the escorts could react. The best tactic to counter this was to place a fighter screen 5,000 ft above the bombers and attempt to intercept the jets early in the dive. The exercise was also useful from No. 616 Squadron's perspective, gaining valuable practical experience in Meteor operations.
No. 616 Squadron exchanged its F.1s for the first "Meteor F.3"s on 18 December 1944. These first 15 F.3s differed from the F.1 in having a sliding canopy in place of the sideways hinging canopy, increased fuel capacity and some airframe refinements. They were still powered by Welland I engines. Later F.3s were equipped with the Derwent I engines. This was a substantial improvement over the earlier mark, although the basic design still had not reached its potential. Wind tunnel and flight tests demonstrated that the original short nacelles, which did not extend far fore and aft of the wing, contributed heavily to compressibility buffeting at high speed. New, longer nacelles not only cured some of the compressibility problems but added 120 km/h (75 mph) at altitude, even without upgraded powerplants. The last batch of Meteor F.3s featured the longer nacelles; other F.3s were retrofitted in the field with the new nacelles. The F.3 also had the new Rolls-Royce Derwent engines, increased fuel capacity, and a new larger, more strongly raked bubble canopy.
Judging the "Meteor F.3"s were ready for combat over Europe, the RAF finally decided to deploy them on the continent. On 20 January 1945, four Meteors from 616 Squadron were moved to Melsbroek in Belgium and attached to the Second Tactical Air Force, just under three weeks after the Luftwaffe's surprise Unternehmen Bodenplatte attack on New Year's Day, in which Melsbroek's RAF base, designated as Allied Advanced Landing Ground "B.58", had been struck by the piston-engined fighters of JG 27 and JG 54. The 616 Squadron Meteor F.3s' initial purpose was to provide air defence for the airfield, but their pilots hoped that their presence might provoke the Luftwaffe into sending Me 262s against them. At this point the Meteor pilots were still forbidden to fly over German-occupied territory, or to go east of Eindhoven, to prevent a downed aircraft being captured by the Germans or the Soviets.
In March, the entire squadron was moved to Gilze-Rijen and then in April, to Nijmegen. The Meteors flew armed reconnaissance and ground attack operations without encountering any German jet fighters. By late April, the squadron was based at Faßberg, Germany and suffered its first losses when two aircraft collided in poor visibility. The war ended with the Meteors having destroyed 46 German aircraft through ground attack. Friendly fire through misidentification as Messerschmitt Me 262s by Allied anti-aircraft gunners was more of a threat than the already-diminished forces of the Luftwaffe; to counter this, continental-based Meteors were given an all-white finish as a recognition aid. The nearest No.616 squadron came to a jet-to-jet battle came on 19 March, when a force of Arado Ar 234 jet bombers attacked their airfield. 
Post-war.
The next-generation "Meteor F.4" prototype first flew on 17 May 1945, and went into production in 1946 when 16 RAF squadrons were already operating Meteors. Equipped with Rolls-Royce Derwent 5 engines, the smaller version of the Nene, the F.4 was faster than the F.1 at sea level (585 against 415), but the reduced wings impaired its rate of climb.The F.4 wingspan was 86.4 cm shorter than the F.3 and with blunter wing tips, derived from the world speed record prototypes. Improvements included a strengthened airframe, fully pressurized cockpit, lighter ailerons to improve manoeuvrability, and rudder trim adjustments to reduce snaking. The F.4 could be fitted with a drop tank under each wing, and experiments were carried out with carriage of underwing stores and also in lengthened fuselage models.
Because of increased demand, F.4 production was divided between Gloster and Armstrong Whitworth. The majority of early F.4s did not go to the RAF: 100 were exported to Argentina, seeing action on both sides in the 1955 revolution; in 1947, only RAF Nos. 74 and 222 Squadrons were fully equipped with the F.4. Nine further RAF squadrons converted from 1948 onwards. From 1948, 38 F.4s were exported to the Dutch, equipping four squadrons (322, 323, 326 and 327) split between bases in Soesterberg and Leeuwarden until the mid-1950s. In 1949, only two RAF squadrons were converted to the F.4, Belgium was sold 48 aircraft in the same year (going to 349 and 350 Squadrons at Beauvechain) and Denmark received 20 over 1949–50. In 1950, three more RAF squadrons were upgraded, including No. 616 and, in 1951, six more.
A modified two-seater F.4 for jet-conversion and advanced training was tested in 1949 as the "T.7". It was accepted by the RAF and the Fleet Air Arm and became a common addition to the various export packages (for example 43 to Belgium 1948–57, a similar number to the Netherlands over the same period, two to Syria in 1952, six to Israel in 1953, etc.). Despite its limitations—unpressurised cockpit, no armament, limited instructor instrumentation—over 650 T.7s were manufactured. The T.7 remained in RAF service into the 1970s.
As improved jet fighters emerged, Gloster decided to modernise the F.4 while retaining as much of the manufacturing tooling as possible. The result was the definitive production model, the "Meteor F.8" (G-41-K), serving as a major RAF fighter until the introduction of the Hawker Hunter and the Supermarine Swift. The first prototype F.8 was a modified F.4, followed by a true prototype, "VT150", that flew on 12 October 1948 at Moreton Valence. Flight testing of the F.8 prototype led to the discovery of an aerodynamic problem: after ammunition was expended, the aircraft became tail-heavy and unstable around the pitch axis due to the weight of fuel in fuselage tanks no longer being balanced by the ammunition. Gloster solved the problem by substituting the tail of the abortive "G 42" single-engined jet fighter. The F.8 and other production variants successfully used the new tail design, giving the later Meteors a distinctive appearance, with taller straighter edges compared with the rounded tail of the F.4s and earlier marks.
The F.8 also featured a fuselage stretch of 76 centimetres (30 inches), intended to shift the aircraft's centre of gravity and also eliminate the use of ballast formerly necessary in earlier marks due to the subsequent elimination from the design of two of the originally-designed six installed cannon. The F.8 incorporated uprated engines, Derwent 8s, with 16 kN (1,633 kgp / 3,600 lbf) thrust each combined with structural strengthening, a Martin Baker ejection seat and a "blown" teardrop cockpit canopy that provided improved pilot visibility. Between 1950 and 1955, the Meteor F.8 was the mainstay of RAF Fighter Command, and served with distinction in combat in Korea with the RAAF as well as operating with many air forces worldwide, although it was clear that the original design was obsolete compared with contemporary swept-wing fighters such as the North American F-86 Sabre and the Soviet MiG-15.
Initial deliveries of the F.8 to the RAF were in August 1949, with the first squadron receiving its fighters in late 1950. Like the F.4, there were strong export sales of the F.8. Belgium ordered 240 aircraft, the majority assembled in The Netherlands by Fokker. The Netherlands had 160 F.8s, equipping seven squadrons until 1955. Denmark had 20, ordered in 1951; they were to be the last F.8s in front line service in Europe. The RAAF ordered 94 F.8s, which served in the Korean War. Despite arms embargoes, both Syria and Egypt received F.8s from 1952, as did Israel, each using their respective Meteors during the Suez Crisis. Brazil ordered 60 new Meteor F.8s and 10 T.7 trainers in October 1952, paying with 15,000 tons of raw cotton.
In the 1950s, Meteors were developed into effective photo-reconnaissance, training and night fighter versions. The fighter reconnaissance (FR) versions were the first to be built, replacing the ageing Spitfires and Mosquitos then in use. Two "FR.5"s were built on the F.4 body; one was used for nose section camera tests, the other broke up in midair while in testing over Moreton Valence. On 23 March 1950, the first "FR.9" flew. Based on the F.8, it was 20 cm longer with a new nose incorporating a remote control camera and window and was also fitted with additional external ventral and wing fuel tanks. Production of the FR.9 began in July. No. 208 Squadron, then based at Fayid, Egypt was the first to be upgraded followed by the 2nd Tactical Air Force in West Germany, No. 2 Squadron RAF at Bückeburg and No. 79 Squadron RAF at RAF Gutersloh flew the FR.9 from 1951 until 1956. In Aden, No. 8 Squadron RAF was given the FR.9 in November 1958 and used them until 1961. Ecuador (12), Israel (7) and Syria (2) were foreign customers for the FR.9.
In 1951, Nos. 29, 141, 85 and 264 Squadrons each received a number of NF.11 aircraft, the first of the Meteor night fighters. It was rolled out across the RAF until the final deliveries in 1954. A "tropicalised" version of the NF.11 for the Middle East was developed; first flying on 23 December 1952 as the "NF.13". The aircraft equipped No. 219 Squadron RAF at Kabrit and No. 39 Squadron at Fayid, both in Egypt. The aircraft served during the Suez crisis and remained with No. 39 Squadron after they were withdrawn to Malta until 1958. Several problems were encountered: the heavily framed T.7 canopy made landings tricky due to limited visibility, the under-wing external fuel tanks tended to break up when the wing cannons were fired, and gun harmonisation, normally set to about 400 yards, was poor due to the wings flexing in flight. Belgium (24), Denmark (20) and France (41) were foreign customers for the NF.11. Ex-RAF NF.13s were sold to France (two), Syria (six), Egypt (six) and Israel (six).
In addition to the armed, low altitude operation, tactical FR.9 variant, Gloster also developed the "PR.10" for high altitude missions. The first prototype flew on 29 March 1950 and was actually converted into the first production aircraft. Based on the F.4, it had the F.4-style tail and the longer wings of the earlier variant. All the cannons were removed and a single camera placed in the nose with two more in the rear fuselage; the canopy was also changed. The PR.10 was delivered to the RAF in December 1950 and were given to No. 2 and No. 541 Squadrons in Germany and No. 13 Squadron RAF in Cyprus. The PR.10 was rapidly phased out from 1956; rapid improvements in surface-to-air missile technology and the introduction of newer aircraft capable of flying at greater altitudes and speeds had rendered the aircraft obsolete.
Australia.
The Royal Australian Air Force (RAAF) acquired 113 Meteors between 1946 and 1952, 94 of which were the F.8 variant. The first RAAF Meteor was a F.3 delivered for evaluation in June 1946.
Australia's F.8s saw extensive service during the Korean War with No. 77 Squadron RAAF, part of British Commonwealth Forces Korea, and had personnel from other Commonwealth air forces attached to it. The squadron had arrived in Korea equipped with piston engine aircraft, the F-51D Mustangs. In order to match the threat posed by Communist MiG-15 jet fighters, it was decided to reequip the squadron with Meteors. Jet conversion training was conducted at Iwakuni, Japan, after which the squadron returned to the Korean theatre in April 1951 with about 30 Meteor F.8s and T.7s. The squadron moved to Kimpo Air Base in June, and was declared combat ready the following month. Other aircraft, such as the F-86 Sabre and the Hawker Hunter, were considered but were determined to be unavailable; the Meteor proved to be considerably inferior in combat against the MiG-15 in several respects, including speed and maneuverability at high altitude.
On 29 July 1951, 77 Squadron began operating their Meteors on combat missions. The squadron had mainly been trained in the ground attack role, and had difficulties when assigned to bomber escort duty at sub optimum altitudes. On 29 August 1951, eight Meteors were on escort duty in "MiG Alley" when they were engaged by six MiG-15s; one Meteor was lost and two damaged, and 77 Squadron did not officially destroy any enemy aircraft on this occasion. On 27 October, the squadron achieved its first probable followed by two probables six days later. On 1 December, during the air battle of Sunchon between 12 Meteors and some 40 MiG-15s, the squadron had its first two confirmed victories: Flying Officer Bruce Gogerly made the first kill. However, in the course of the same dogfight, four Meteors were also destroyed.
At the end of 1951, 77 Squadron and its Meteors were assigned to ground attack duties due to their favourable low-level performance and sturdy construction. In February 1952, over a thousand sorties were flown in the ground attack role; these sorties continued until May 1952, when 77 Squadron switched to fighter sweep operations. The last encounter between the Meteor and the MiG-15 was in March 1953, during which a Meteor piloted by Sergeant John Hale recorded a victory. By the end of the conflict, the squadron had flown 4,836 missions, destroying six MiG-15s, over 3,500 structures and some 1,500 vehicles. About 30 Meteors were lost to enemy action in Korea—the vast majority had been shot down by anti-aircraft fire while serving in a ground attack capacity.
The RAAF began introducing the domestically produced CAC Sabre in 1955, which progressively relegated the older Meteor to training and secondary duties. A number of Meteors would be assigned to the Citizen Air Force, while others were configured as pilotless drone aircraft or for target towing. No. 75 Squadron RAAF was the last Australian squadron to operate the Meteor; notably, it had operated a three-unit aerobatic team, named ""The Meteorites"".
Argentina.
Argentina became the first overseas operator of the Meteor, placing an order for 100 F Mk.4s in May 1947. The Meteor's procurement led to Argentina becoming the second air force in the Americas to operate jet aircraft.
The Argentine Meteors were first used in combat during the 16 June 1955 rebellion when, in an attempt to kill Juan Perón, rebel-flown aircraft bombed the Casa Rosada. A loyalist Meteor shot down a rebel AT-6, while another strafed rebel-held Ezeiza airport. The rebels seized Morón Airport and Air Base, base of the Meteors, and used several captured aircraft to perform multiple attacks against loyalist forces and the Casa Rosada before the rebellion was defeated by day's end.
A second revolt, the Revolución Libertadora broke out on 16 September 1955, with, again, both sides operating the Meteor. The rebels seized three Meteors. Government Meteors flew strafing attacks against the rebel-held destroyers "Rioja" and "Cervantes", and several landing ships near Rio Santiago on 16 September and attacking Pajas Blancas airport near the city of Córdoba, damaging several Avro Lincoln bombers. The rebel-flown Meteors were used to attack loyalist forces attacking Córdoba, losing one of their number on 19 September to an engine failure caused by use of automobile petrol instead of jet fuel.
The acquisition of North American F-86 Sabres in 1960 allowed the remaining Meteors to be transferred to the ground attack role. In this role, the aircraft were refitted with bomb pylons and rocket rails; the bare metal colour scheme was also discarded for a camouflage scheme.
Argentine Meteors were used to attack rebels during attempted uprisings in September 1962 and April 1963. The type was ultimately withdrawn from service in 1970.
Egypt.
Although Egypt's first order for the Meteor was placed in 1948, the rising tension in the region led to the imposition of a series of arms embargoes. Twelve F Mk.4s were eventually delivered between October 1949 and May 1950, along with three T Mk.7s. Twenty-four F Mk.8s were ordered in 1949, but this order was stopped by an embargo. A further order for 12 ex-RAF F.8s was placed in December 1952, of which four were delivered before the order was cancelled, with the final eight being delivered in 1955, along with three more T Mk.7s. and six NF Mk.13s, all ex-RAF aircraft. Britain had allowed the Meteor sales as part of an effort to foster and support good relations; tensions over the Suez Canal would lead to arms sales being suspended once again.
Egyptian Meteors participated in the fighting during the Suez Crisis of 1956, typically being used in ground attack missions against Israeli forces. In one incident, an Egyptian Meteor NF Mk.13 claimed to have damaged an RAF Vickers Valiant bomber. An aerial bombing campaign of Egyptian airfields by Anglo-French forces resulted in several aircraft being destroyed on the ground, the Egyptian Air Force subsequently decided to withdraw from combat within the Sinai region.
Syria.
Meteors were the fledgling Syrian Air Force's first jet aircraft. It would acquire 25 of them between 1952 and 1956. Although the British were willing to supply aircraft, they did not supply combat training or radar. As Syria became more aligned with Gamal Abdel Nasser's Egypt, British support for Meteor operations was withdrawn and Syrian pilots began training with their Egyptian counterparts. During the Suez Crisis, the RAF performed multiple high altitude reconnaissance flights over Syria by Canberra aircraft from bases in Cyprus. Lacking radar to track the aircraft, the Syrians developed a ground spotter network that reported information by telephone in an attempt to intercept these flights. On 6 November 1956, Syrian Meteors acting on spotter information successfully shot down a Canberra reconnaissance flight over Homs. In 1957, Syria began to replace its Meteors with newly procured MiG-17s from the Soviet Union.
France.
The French Air Force was keen to acquire jet aircraft as part of its re-equipment program following the Second World War; in response to French interest in the Meteor, a pair of F Mk.IVs were sent to France for evaluation purposes in 1948. In 1953, 25 new-build aircraft were diverted from RAF orders to fulfill a French order; a further 16 ex-RAF NF.11s were purchased in 1954 and delivered between September 1954 and April 1955, these being supplemented by about 14 T Mk.7s. The NF Mk.11s replaced the Mosquito night fighter with the Escadre de Chasse (EC) 30, serving with that Wing until replaced by the Sud Aviation Vautour in 1957. Several Meteors were then transferred to ECN 1/7 in Algeria, which saw combat in the Algerian War, operating from Bône, while others were used for training Vautour night fighter crews. The Vautour was retired from French Air Force service in 1964.
Five Meteor NF.11s were transferred to the Centre d’Essais en Vol (Flight Test Centre) in 1958, where they were used as equipment testbeds and chase planes, and were later joined by two NF Mk.13s and two NF Mk.14s. The test aircraft were used in a wide variety of experiments, including radar and missile tests and during the development of Concorde.
Israel.
Due to tensions between the newly formed nation of Israel and its neighbors, both sides had commenced an arms race which led to jet aircraft being vigorously purchased by various countries in the region. In 1953 Israel ordered four T Mk.7s and 11 F Mk.8s, with delivery continuing until early 1954. The F Mk.8s were modified to carry American HVAR rockets but were otherwise identical to RAF aircraft. A second batch of seven refurbished FR Mk.9s and two more T Mk.7s was delivered in 1955. In 1956, Israel purchased six NF Mk.13s, with three delivered that year, and the remaining three, delayed by an arms embargo, in 1958. Five more T Mk.7s were later purchased, these were converted from ex-Belgian F Mk.4s and were fitted with the Mk.8 tail.
On 1 September 1955, an Israeli Meteor shot down an Egyptian de Havilland Vampire, the first jet aircraft to be shot down in the theatre. The Meteor played a key role during the Suez Crisis; on 28 October 1956, an Israeli NF.13 took part in Operation Tarnegol, in which it successfully located and shot down an Egyptian Ilyushin Il-14 that had been carrying several high-ranking Egyptian Military officers on the eve of the crisis. The operation had intended to shoot down the Il-14 that was supposed to be carrying the supreme commander of the Egyptian armed forces, Abdel Hakim Amer, however a different aircraft had been inadvertently attacked and destroyed instead. After deploying paratroopers east of the Suez Canal, the Israeli Air Force continued to support them on the ground predominantly using its jet aircraft, fearing its propeller-driven aircraft would be vulnerable against Egypt's own jet fighters.
While initially flying combat air patrol missions, the Meteors and other Israeli aircraft could not prevent effective attacks by Egyptian aircraft on the ground forces. Israeli officers came to recognize that the Meteor was outclassed by Egyptian MiG-15s, and would subsequently limit the Meteor's employment as a fighter against other aerial adversaries. Following the start of the Anglo-French bombing campaign against Egypian airbases, the Egyptian Air Force mostly withdrew from combat in the Sinai, allowing Israeli aircraft to operate unhindered.
The Mk.8s remained in front line service until 1956, and were then used as training aircraft. The NF Mk.13s remained in operational use until 1962.
Record setting.
Late in 1945, two F.3 Meteors were modified for an attempt on the world air speed record. On 7 November 1945 at Herne Bay in Kent, UK, Group Captain Hugh "Willie" Wilson set the first official air speed record by a jet aircraft of TAS. In 1946, Group Captain Edward "Teddy" Donaldson broke this record with a speed of 616 mph (991 km/h) TAS, in "EE549", a Meteor F.4.
Neither of these records, however, exceeded Heini Dittmar's 623 mph (1,004 km/h) unofficial record velocity in one of the Me 163A rocket fighter prototypes, set on October 2, 1941 after being towed to the height for the attempt by a Bf 110. Test pilot Roland Beamont had previously taken "EE549" to its compressibility limit at , but not under official record conditions, and outside its official safety limits.
In 1947, Sqn Ldr Janusz Żurakowski set an international speed record: London-Copenhagen-London, 4–5 April 1950 in a production standard F.8 ("VZ468"). Suitably impressed, the Danes later purchased the type.
Another "claim to fame" was the Meteor's ability to perform the "Żurabatic Cartwheel", an aerobatics manoeuvre named after Gloster's acting Chief Test Pilot, it was first demonstrated by Meteor G-7-1 "G-AMCJ" prototype at the 1951 Farnborough Air Show; the Meteor, due to its widely set engines, could have individual engines throttled back and forward to achieve a seemingly stationary vertical cartwheel. Many Meteor pilots went on to "prove their mettle" by attempting the same feat.
On 7 August 1949, the Meteor III, "EE397", on loan from the RAF and flown by Flight Refuelling Ltd (FRL) test pilot Patrick Hornidge, took off from Tarrant Rushton and, refuelled 10 times by the Lancaster tanker, remained airborne for 12 hours and 3 minutes, receiving 2,352 gallons of fuel from the tanker in ten tanker contacts and flying an overall distance of , achieving a new jet endurance record.
Meteor F.8 "WA820" was adapted during 1948 to take two Armstrong Siddeley Sapphire turbojets, and from Moreton Valence, on August 31, 1951, established a time-to-height climb record. The pilot was Flt Lt Tom Prickett, of Armstrong Siddeley. A height of 9,843 ft was reached in 1 min 16 sec, 19,685 ft in 1 min 50 sec, 29,500 ft in 2 min 29 sec, and 39,370 ft in 3 min 7 sec. Air Service Training Ltd were responsible for the conversion.
Survivors.
Although many Meteors survive in museums, collections and on pylons in public spaces, only five remain airworthy. 

</doc>
<doc id="42704" url="https://en.wikipedia.org/wiki?curid=42704" title="Transatlantic communications cable">
Transatlantic communications cable

A transatlantic telecommunications cable is a submarine communications cable connecting one side of the Atlantic Ocean to the other. In the 19th and early 20th centuries each cable was a single wire. After mid-century Coaxial cable came into use, with amplifiers. Late in the century, all used optical fiber, and most now use optical amplifiers.
History.
When the first transatlantic telegraph cable was laid in 1858 by businessman Cyrus West Field, it operated for only three weeks; subsequent attempts in 1865 and 1866 were more successful. Although a telephone cable was discussed starting in the 1920s, to be practical it needed a number of technological advances which did not arrive until the 1940s. Starting in 1927, transatlantic telephone service was radio-based.
TAT-1 (Transatlantic No. 1) was the first transatlantic telephone cable system. It was laid between Gallanach Bay, near Oban, Scotland and Clarenville, Newfoundland between 1955 and 1956 by the cable ship "Monarch". It was inaugurated on September 25, 1956, initially carrying 36 telephone channels. In the first 24 hours of public service there were 588 London–U.S. calls and 119 from London to Canada. The capacity of the cable was soon increased to 48 channels. Later, an additional three channels were added by use of C Carrier equipment. Time-assignment speech interpolation (TASI) was implemented on the TAT-1 cable in June 1960 and effectively increased the cable's capacity from 37 (out of 51 available channels) to 72 speech circuits. TAT-1 was finally retired in 1978. Later coaxial cables, installed through the 1970s, used transistors and had higher bandwidth.
Current technology.
All cables presently in service use fiber optic technology. Many cables terminate in Newfoundland and Ireland, which lie on the great circle route (the shortest route) from London, UK to New York City, USA.
There have been a succession of newer transatlantic cable systems. All recent systems have used fiber optic transmission, and a self-healing ring topology. Late in the 20th century, communications satellites lost most of their North Atlantic telephone traffic to these low cost, high capacity, low latency cables. This advantage only increases over time as tighter cables provide higher speed – the 2012 generation of cables drop the transatlantic latency to under 60 milliseconds, according to Hibernia Atlantic, deploying such a cable that year.
Some new cables are being announced on the South Atlantic: SACS(South Atlantic Cable System) and SAex(South Atlantic Express) 
TAT cable routes.
The TAT series of cables constitute a large percentage of all North Atlantic cables. All TAT cables are joint ventures between a number of telecommunications companies, e.g. British Telecom. CANTAT cables terminate in Canada rather than in the USA.
Private cable routes.
There are a number of private non-TAT cables.

</doc>
<doc id="42706" url="https://en.wikipedia.org/wiki?curid=42706" title="Dreams (TV series)">
Dreams (TV series)

Dreams is an American television series that aired in 1984–1985 for one season on CBS. It follows the story of a fictional rock band that tries to get a recording contract.

</doc>
<doc id="42707" url="https://en.wikipedia.org/wiki?curid=42707" title="Frank Whittle">
Frank Whittle

Air Commodore Sir Frank Whittle (1 June 1907 – 9 August 1996) was an English Royal Air Force (RAF) engineer air officer. He is credited with single-handedly inventing the turbojet engine. A patent was submitted by Maxime Guillaume in 1921 for a similar invention; however, this was technically unfeasible at the time. Whittle's jet engines were developed some years earlier than those of Germany's Hans von Ohain who was the designer of the first jet engine to be used to actually power an aircraft.
From an early age, Whittle demonstrated an aptitude for engineering and an interest in flying. At first he was turned down by the RAF but, determined to join the Royal Air Force, he overcame his physical limitations and was accepted and sent to No. 2 School of Technical Training to join No 1 Squadron of Cranwell Aircraft Apprentices. He was taught the theory of aircraft engines and gained practical experience in the engineering workshops. His academic and practical abilities as an Aircraft Apprentice earned him a place on the officer training course at Cranwell. He excelled in his studies and became an accomplished pilot. While writing his thesis there he formulated the fundamental concepts that led to the creation of the turbojet engine, taking out a patent on his design in 1930. His performance on an officers' engineering course earned him a place on a further course at Peterhouse, Cambridge where he graduated with a First.
Without Air Ministry support, he and two retired RAF servicemen formed Power Jets Ltd to build his engine with assistance from the firm of British Thomson-Houston. Despite limited funding, a prototype was created, which first ran in 1937. Official interest was forthcoming following this success, with contracts being placed to develop further engines, but the continuing stress seriously affected Whittle's health, eventually resulting in a nervous breakdown in 1940. In 1944 when Power Jets was nationalised he again suffered a nervous breakdown, and resigned from the board in 1946.
In 1948, Whittle retired from the RAF and received a knighthood. He joined BOAC as a technical advisor before working as an engineering specialist with Shell, followed by a position with Bristol Aero Engines. After emigrating to the U.S. in 1976 he accepted the position of NAVAIR Research Professor at the United States Naval Academy from 1977–1979. In August 1996, Whittle died of lung cancer at his home in Columbia, Maryland. In 2002, Whittle was ranked number 42 in the BBC poll of the 100 Greatest Britons.
Early life.
Whittle was born in a terraced house in Newcombe Road, Earlsdon, Coventry, England on 1 June 1907, the eldest son of Moses Whittle and Sara Alice Garlick. When he was nine years old, the family moved to the nearby town of Royal Leamington Spa where his father, a highly inventive practical engineer and mechanic, purchased the Leamington Valve and Piston Ring Company, which comprised a few lathes and other tools and a single-cylinder gas engine, on which Whittle became an expert. Whittle developed a rebellious and adventurous streak, together with an early interest in aviation.
After two years attending Milverton School, Whittle won a scholarship to a secondary school which in due course became Leamington College for Boys, but when his father's business faltered there was not enough money to keep him there. He quickly developed practical engineering skills while helping in his father's workshop, and being an enthusiastic reader spent much of his spare time in the Leamington reference library, reading about astronomy, engineering, turbines, and the theory of flight. At the age of 15, determined to be a pilot, Whittle applied to join the RAF.
Entering the RAF.
In January 1923, having passed the RAF entrance examination with a high mark, Whittle reported to RAF Halton as an Aircraft Apprentice. He lasted only two days: just five feet tall and with a small chest measurement, he failed the medical. He then put himself through a vigorous training programme and special diet devised by a physical training instructor at Halton to build up his physique, only to fail again six months later, when he was told that he could not be given a second chance, despite having added three inches to his height and chest. Undeterred, he applied again under an assumed name and presented himself as a candidate at the No 2 School of Technical Training RAF Cranwell. This time he passed the physical and, in September that year, 364365 Boy Whittle, F started his three-year training as an aircraft mechanic in No. 1 Squadron of No. 4 Apprentices Wing, RAF Cranwell, because RAF Halton No. 1 School of Technical Training was unable to accommodate all the aircraft apprentices at that time.
Whittle hated the strict discipline imposed on apprentices and, convinced there was no hope of ever becoming a pilot he at one time seriously considered deserting. However, throughout his early days as an aircraft apprentice (and at the Royal Air Force College Cranwell), he maintained his interest in model aircraft and joined the Model Aircraft Society, where he built working replicas. The quality of these attracted the eye of the Apprentice Wing commanding officer, who noted that Whittle was also a mathematical genius. He was so impressed that in 1926 he recommended Whittle for officer training at RAF College Cranwell.
For Whittle, this was the chance of a lifetime, not only to enter the commissioned ranks but also because the training included flying lessons on the Avro 504. While at Cranwell he lodged in a bungalow at Dorrington. Being an ex-apprentice amongst a majority of ex-public schoolboys, life as an officer cadet was not easy for him, but he nevertheless excelled in the courses and went solo in 1927 after only 13.5 hours instruction, quickly progressing to the Bristol Fighter and gaining a reputation for daredevil low flying and aerobatics.
A requirement of the course was that each student had to produce a thesis for graduation: Whittle decided to write his on potential aircraft design developments, notably flight at high altitudes and speeds over 500 mph (800 km/h). In "Future Developments in Aircraft Design" he showed that incremental improvements in existing propeller engines were unlikely to make such flight routine. Instead he described what is today referred to as a motorjet; a motor using a conventional piston engine to provide compressed air to a combustion chamber whose exhaust was used directly for thrust – essentially an afterburner attached to a propeller engine. The idea was not new and had been talked about for some time in the industry, but Whittle's aim was to demonstrate that at increased altitudes the lower outside air pressure would increase the design's efficiency. For long-range flight, using an Atlantic-crossing mailplane as his example, the engine would spend most of its time at high altitude and thus could outperform a conventional powerplant.
Of the few apprentices accepted into the Royal Air Force College, Whittle graduated in 1928 at the age of 21 and was commissioned as a Pilot Officer in July. He ranked second in his class in academics, won the Andy Fellowes Memorial Prize for Aeronautical Sciences for his thesis, and was described as an "exceptional to above average" pilot. However, his flight logbook also showed numerous red ink warnings about showboating and overconfidence, and because of dangerous flying in an Armstrong Whitworth Siskin he was disqualified from the end of term flying contest.
Development of the turbojet engine.
Whittle continued working on the motorjet principle after his thesis work but eventually abandoned it when further calculations showed it would weigh as much as a conventional engine of the same thrust. Pondering the problem he thought: "Why not substitute a turbine for the piston engine?" Instead of using a piston engine to provide the compressed air for the burner, a turbine could be used to extract some power from the exhaust and drive a similar compressor to those used for superchargers. The remaining exhaust thrust would power the aircraft.
On 27 August 1928 Pilot Officer Whittle joined No. 111 Squadron, Hornchurch, flying Siskin IIIs. His continuing reputation for low flying and aerobatics provoked a public complaint that almost led to his being court-martialled. Within a year he was posted to Central Flying School, Wittering, for a flying instructor's course. He became a popular and gifted instructor, and was selected as one of the entrants in a competition to select a team to perform the "crazy flying" routine in the 1930 Royal Air Force Air Display at RAF Hendon. He destroyed two aircraft in accidents during rehearsals but remained unscathed on both occasions. After the second incident an enraged Flight Lieutenant Harold W. Raeburn said furiously, "Why don't you take all my bloody aeroplanes, make a heap of them in the middle of the aerodrome and set fire to them – it's quicker!"
Whittle showed his engine concept around the base, where it attracted the attention of Flying Officer Pat Johnson, formerly a patent examiner. Johnson, in turn, took the concept to the commanding officer of the base. This set in motion a chain of events that almost led to the engines being produced much sooner than actually occurred.
Earlier, in July 1926, A. A. Griffith had published a paper on compressors and turbines, which he had been studying at the Royal Aircraft Establishment (RAE). He showed that such designs up to this point had been flying "stalled", and that by giving the compressor blades an aerofoil-shaped cross-section their efficiency could be dramatically improved. The paper went on to describe how the increased efficiency of these sorts of compressors and turbines would allow a jet engine to be produced, although he felt the idea was impractical, and instead suggested using the power as a turboprop. At the time most superchargers used a centrifugal compressor, so there was limited interest in the paper.
Encouraged by his Commanding Officer, in late 1929 Whittle sent his concept to the Air Ministry to see if it would be of any interest to them. With little knowledge of the topic they turned to the only other person who had written on the subject and passed the paper on to Griffith. Griffith appears to have been convinced that Whittle's "simple" design could never achieve the sort of efficiencies needed for a practical engine. After pointing out an error in one of Whittle's calculations, he went on to comment that the centrifugal design would be too large for aircraft use and that using the jet directly for power would be rather inefficient. The RAF returned his comment to Whittle, referring to the design as being "impracticable".
Pat Johnson remained convinced of the validity of the idea, and had Whittle patent the idea in January 1930. Since the RAF was not interested in the concept they did not declare it secret, meaning that Whittle was able to retain the rights to the idea, which would have otherwise been their property. Johnson arranged a meeting with British Thomson-Houston (BTH), whose chief turbine engineer seemed to agree with the basic idea. However, BTH did not want to spend the ₤60,000 it would cost to develop it, and this potential brush with early success went no further.
In January 1930, Whittle was promoted to Flying Officer. In Coventry, on 24 May 1930, Whittle married his fiancée, Dorothy Mary Lee, with whom he later had two sons, David and Ian. Then, in 1931, he was posted to the Marine Aircraft Experimental Establishment at Felixstowe as an armament officer and test pilot of seaplanes, where he continued to publicize his idea. This posting came as a surprise for he had never previously flown a seaplane, but he nevertheless increased his reputation as a pilot by flying some 20 different types of floatplanes, flying boats, and amphibians. Every officer with a permanent commission was expected to take a specialist course, and as a result Whittle attended the Officers’ Engineering Course at RAF Henlow, Bedfordshire in 1932. He obtained an aggregate of 98% in all subjects in his exams, completing the course in 18 months instead of the more normal two years.
His performance in the course was so exceptional that in 1934 he was permitted to take a two-year engineering course as a member of Peterhouse, the oldest college of Cambridge University, graduating in 1936 with a First in the Mechanical Sciences Tripos. In February 1934, he had been promoted to the rank of Flight Lieutenant.
Power Jets Ltd.
Still at Cambridge, Whittle could ill afford the £5 renewal fee for his jet engine patent when it became due in January 1935, and because the Air Ministry refused to pay it the patent was allowed to lapse. Shortly afterwards, in May, he received mail from Rolf Dudley-Williams, who had been with him at Cranwell in the 1920s and Felixstowe in 1930. Williams arranged a meeting with Whittle, himself, and another by-then-retired RAF serviceman, James Collingwood Tinling. The two proposed a partnership that allowed them to act on Whittle's behalf to gather public financing so that development could go ahead.
The agreement soon bore fruit, and in 1935, through Tinling's father, Whittle was introduced to Mogens L. Bramson, a well-known independent consulting aeronautical engineer. Bramson was initially skeptical but after studying Whittle's ideas became an enthusiastic supporter. Bramson introduced Whittle and his two associates to the investment bank O.T. Falk & Partners, where discusions took place with Lancelot Law Whyte and occasionally Sir Maurice Bonham-Carter. The firm had an interest in developing speculative projects that conventional banks would not touch. Whyte was impressed by the 28-year-old Whittle and his design when they met on 11 September 1935:
However O.T. Falk & Partners specified they would only invest in Whittle's engine if they had independent verification that it was feasible. They financed an independent engineering review from Bramson (The historic "Bramson Report"
), which was issued in November 1935. It was favourable and Falk then agreed to finance Whittle. With that the jet engine was finally on its way to becoming a reality.
On 27 January 1936, the principals signed the "Four Party Agreement", creating "Power Jets Ltd" which was incorporated in March 1936. The parties were O.T. Falk & Partners, the Air Ministry, Whittle and, together, Williams and Tinling. Falk was represented on the board of Power Jets by Whyte as Chairman and Bonham-Carter as a director (with Bramson acting as alternate). Whittle, Williams and Tinling retained a 49% share of the company in exchange for Falk and Partners putting in £2,000 with the option of a further £18,000 within 18 months. As Whittle was still a full-time RAF officer and currently at Cambridge, he was given the title "Honorary Chief Engineer and Technical Consultant". Needing special permission to work outside the RAF, he was placed on the Special Duty List and allowed to work on the design as long as it was for no more than six hours a week. However he was allowed to continue at Cambridge for a year doing post-graduate work which gave him time to work on the turbojet.
The Air Ministry still saw little immediate value in the effort (they regarded it as long-range research), and having no production facilities of its own, Power Jets entered into an agreement with steam turbine specialists British Thomson-Houston (BTH) to build an experimental engine facility at a BTH factory in Rugby, Warwickshire. Work progressed quickly, and by the end of the year 1936 the prototype detail design was finalised and parts for it were well on their way to being completed, all within the original £2,000 budget. However by 1936, Germany had also started working on jet engines (Herbert A. Wagner at Junkers and Hans von Ohain at Heinkel) and, although they too had difficulty overcoming conservatism, the German Ministry of Aviation (Reichsluftfahrtministerium) was more supportive than their British counterpart.
Financial difficulty.
Earlier, in January, when the company formed, Henry Tizard, the rector of Imperial College London and chairman of the Aeronautical Research Committee (ARC), had prompted the Air Ministry's Director of Scientific Research to ask for a write-up of the design. The report was once again passed on to Griffith for comment, but was not received back until March 1937 by which point Whittle's design was well along. Griffith had already started construction of his own turbine engine design and, perhaps to avoid tainting his own efforts, he returned a somewhat more positive review. However, he remained highly critical of some features, notably the use of jet thrust. The Engine Sub-Committee of ARC studied Griffith's report, and decided to fund his effort instead.
Given this astonishing display of official indifference, Falk and Partners gave notice that they could not provide funding beyond £5,000. Nevertheless the team pressed ahead, and the W.U. (Whittle Unit) engine ran successfully on 12 April 1937. Tizard pronounced it "streaks ahead" of any other advanced engine he had seen, and managed to interest the Air Ministry enough to fund development with a contract for £5,000 to develop a flyable version. However, it was a year before the funds were made available, greatly delaying development.
In July, when Whittle's stay at Cambridge was over, he was released to work full-time on the engine. On 8 July Falk gave the company an emergency loan of £250, and on the 15th they agreed to find £4,000 to £14,000 in additional funding. The money never arrived and, entering into default, Falk's shares were returned to Williams, Tinling and Whittle on 1 November. Nevertheless, Falk arranged another loan of £3,000, and work continued. Whittle was promoted to Squadron Leader in December.
Testing continued with the W.U., which showed an alarming tendency to race out of control. Because of the dangerous nature of the work being carried out, development was largely moved from Rugby to BTH's lightly used Ladywood foundry at nearby Lutterworth in Leicestershire in 1938, where there was a successful run of the W.U. in March that year. BTH had decided to put in £2,500 of their own in January, and in March 1938 the Air Ministry funds finally arrived. This proved to be a mixed blessing – the company was now subject to the Official Secrets Act, which made it extremely difficult to gather more private equity.
These delays and the lack of funding slowed the project. In Germany, Hans von Ohain had started work on a prototype in 1935, and had by this point passed the prototype stage and was building the world's first flyable Jet aircraft, the Heinkel HeS 3. There is little doubt that Whittle's efforts would have been at the same level or even more advanced had the Air Ministry taken a greater interest in the design. When war broke out in September 1939, Power Jets had a payroll of only 10 and Griffith's operations at the RAE and Metropolitan-Vickers were similarly small.
The stress of the continual on-again-off-again development and problems with the engine took a serious toll on Whittle.
His smoking increased to three packs a day and he suffered from various stress-related ailments such as frequent severe headaches, indigestion, insomnia, anxiety, eczema and heart palpitations, while his weight dropped to nine stone (126 lb / 57 kg). In order to keep to his 16-hour workdays, he sniffed Benzedrine during the day and then took tranquillizers and sleeping pills at night to offset the effects and allow him to sleep. He admitted later he had become addicted to benzidrene. Over this period he became irritable and developed an "explosive" temper.
Changing fortunes.
By June 1939, Power Jets could barely afford to keep the lights on when yet another visit was made by Air Ministry personnel. This time Whittle was able to run the W.U. at high power for 20 minutes without any difficulty. One of the members of the team was the Director of Scientific Research, David Randall Pye, who walked out of the demonstration utterly convinced of the importance of the project. The Ministry agreed to buy the W.U. and then loan it back to them, injecting cash, and placed an order for a flyable version of the engine.
Whittle had already studied the problem of turning the massive W.U. into a flyable design, with what he described as very optimisitic targets, to power a little aeroplane weighing 2,000 lb with a static thrust of 1,389 lb. With the new contract work started in earnest on the "Whittle Supercharger Type W.1". It featured a reverse-flow design; air from the compressor was fed rearwards into the combustion chambers, then back towards the front of the engine, then finally reversing again into the turbine. This design reduced the length of the engine, and the length of the drive shaft connecting the compressor and turbine, thus reducing weight.
In January 1940, the Ministry placed a contract with the Gloster Aircraft Company for a simple aircraft specifically to flight-test the W.1, the Gloster E.28/39. They also placed a second engine contract, this time for a larger design that developed into the otherwise similar W.2. In February work started on a third design, the W.1A, which was the size of the W.1 but used the W.2's mechanical layout. The W.1A allowed them to flight test the W.2's basic mechanical design in the E.28/39. Power Jets also spent some time in May 1940 drawing up the W.2Y, a similar design with a "straight-through" airflow that resulted in a longer engine and, more critically, a longer driveshaft but having a somewhat simpler layout. To reduce the weight of the driveshaft as much as possible, the W.2Y used a large diameter, thin-walled, shaft almost as large as the turbine disc, "necked down" at either end where it connected to the turbine and compressor.
In April, the Air Ministry issued contracts for W.2 production lines with a capacity of up to 3,000 engines a month in 1942, asking BTH, Vauxhall and the Rover Company to join. However, the contract was eventually taken up by Rover only. In June, Whittle received a promotion to Wing Commander.
Rover.
Meanwhile work continued with the W.U., which eventually went through nine rebuilds in an attempt to solve the combustion problems that had dominated the testing. On 9 October the W.U. ran once again, this time equipped with Lubbock or "Shell" atomizing-burner combustion chambers. Combustion problems ceased to be an obstacle to development of the engine although intensive development was started on all features of the new combustion chambers.
By this point it was clear that Gloster's first airframe would be ready long before Rover could deliver an engine. Unwilling to wait, Whittle cobbled together an engine from spare parts, creating the W.1X ("X" standing for "experimental") which ran for the first time on 14 December 1940. On 10 December Whittle suffered a nervous breakdown, and left work for a month. Shortly afterwards an application for a US patent was made by Power Jets for an "Aircraft propulsion system and power unit"
The W1X engine powered the E.28/39 for taxi testing on 7 April 1941 near the factory in Gloucester, where it took to the air for two or three short hops of several hundred yards at about six feet from the ground.
The definitive W.1 of 850 lbf (3.8 kN) thrust ran on 12 April 1941, and on 15 May the W.1-powered E.28/39 took off from Cranwell at 7:40 pm, flying for 17 minutes and reaching a maximum speed of around 340 mph (545 km/h). At the end of the flight, Pat Johnson, who had encouraged Whittle for so long said to him, "Frank, it flies." Whittle replied, "Well, that's what it was bloody well designed to do, wasn't it?"
Within days the aircraft was reaching 370 mph (600 km/h) at 25,000 feet (7,600 m), exceeding the performance of the contemporary Spitfires. Success of the design was now evident; the first example of what was a purely experimental and entirely new engine design was already outperforming one of the best piston engines in the world, an engine that had five years of development and production behind it, and decades of engineering. Nearly every engine company in Britain then started their own crash efforts to catch up with Power Jets.
In 1941 Rover set up a new laboratory for Whittle's team along with a production line at their unused Barnoldswick factory, but by late 1941 it was obvious that the arrangement between Power Jets and Rover was not working. Whittle was frustrated by Rover's inability to deliver production-quality parts, as well as with their attitude of engineering superiority, and became increasingly outspoken about the problems. Rover decided to set up secretly a parallel effort with their own engineers at Waterloo Mill, in nearby Clitheroe. Here Adrian Lombard started work developing the W.2B into Rover's own production-quality design, dispensing with Whittle's "reverse-flow" combustion chambers and developing a longer but simpler "straight-through" engine instead. This was encouraged by the Air Ministry, who gave Whittle's design the name "B.23", and Rover's became the "B.26".
Work on all of the designs continued over the winter of 1941–42. The first W.1A was completed soon after, and on 2 March 1942 the second E.28/39 reached 430 mph (690 km/h) at 15,000 feet (4,600 m) on this engine. The next month work on an improved W.2B started under the new name, "W2/500". In April Whittle learned of Rover's parallel effort, creating discontentment and causing a major crisis in the programme. Work continued, however, and in September the first W2/500 ran for the first time, generating its full design thrust of 1,750 lbf (7.8 kN) the same day. Work started on a further improvement, the W2/700.
Rolls-Royce.
Earlier, in January 1940, Whittle had met Dr Stanley Hooker of Rolls-Royce, who in turn introduced Whittle to Rolls-Royce board member and manager of their Derby factory, Ernest Hives (later Lord Hives). Hooker was in charge of the supercharger division at Rolls-Royce Derby and was a specialist in the mathematics of "fluid flow". He had already increased the power of the Merlin piston engine by improving its supercharger. Such a speciality was naturally suited to the aero-thermodynamics of jet engines in which the optimisation of airflow in compressor, combustion chambers, turbine and jet pipe, is fundamental. Hives agreed to supply key parts to help the project. Also, Rolls-Royce built a compressor test rig which helped Whittle solve the surging problems (unstable airflow in the compressor) on the W.2 engine. In early 1942 Whittle contracted Rolls-Royce for six engines, known as the WR.1, identical to the existing W.1.
When Rolls-Royce became involved, Ray Dorey, the manager of the company's Flight Centre at Hucknall airfield on the north side of Nottingham, had a Whittle engine installed in the rear of a Vickers Wellington bomber. The installation was done by Vickers at Weybridge. A flying test-bed enables testing to be done in flight without the aircraft depending on an untried engine for its own propulsion and safety. This was the first flying test-bed used to test a jet engine.
The problems between Rover and Power Jets became a "public secret" and late in 1942 Spencer Wilks of Rover met with Hives and Hooker at the "Swan and Royal" pub, in Clitheroe, near the Barnoldswick factory. By arrangement with the Ministry of Aircraft Production they traded the jet factory at Barnoldswick for Rolls-Royce's tank engine factory in Nottingham, sealing the deal with a handshake. The official handover took place on 1 January 1943, although the W.2B contract had already been signed over in December. Rolls-Royce closed Rover's secret parallel plant at Clitheroe soon after; however, they continued the development of the W.2B/26 that had begun there.
Testing and production ramp-up was immediately accelerated. In December 1942 Rover had tested the W.2B for a total of 37 hours, but within the next month Rolls-Royce tested it for 390 hours. The W.2B passed its first 100-hour test at full performance of 1,600 lbf (7.1 kN) on 7 May 1943. The prototype Meteor airframe was already complete and took to the air on 12 June 1943. Production versions of the engine started rolling off the line in October, first known as the W.2B/23, then the RB.23 (for "Rolls-Barnoldswick") and eventually became known as the Rolls-Royce Welland. Barnoldswick was too small for full-scale production and turned back into a pure research facility under Hooker's direction, while a new factory was set up in Newcastle-under-Lyme. Rover's W.2B/26, as the Rolls-Royce Derwent, opened the new line and soon replaced the Welland, allowing the production lines at Barnoldswick to shut down in late 1944.
Despite lengthy delays in their own programme, the Luftwaffe beat the British efforts into the air by nine months. A lack of cobalt for high-temperature steel alloys meant the German designs were always at risk of overheating and damaging their turbines. The low-grade alloy production versions of the Junkers Jumo 004, designed by Dr. Anselm Franz and which powered the Messerschmitt Me 262 would typically last only 10–25 hours (longer with an experienced pilot) before burning out, if it was accelerated too quickly, the compressor would stall and power was immediately lost and sometimes it exploded on their first startup. Over 200 German pilots were killed during training. Nevertheless the Me 262 could fly far faster than allied planes and had very effective firepower. Although Me 262s were introduced late in the war they shot down 542 or more allied planes and in one allied bombing raid downed 32 of the 36 Boeing B-17 Flying Fortresses. Whittle's designs were more basic, with centrifugal compressors rather than the more complicated axial designs. The latter, having several stages of rotating blades, each stage increasing the pressure, were potentially more efficient but were much more difficult to develop. The UK designs also had better materials such as the Nimonic alloys for turbine blades. Early UK jet engines would run for 150 hours between overhauls and had better power-to-weight ratio and specific fuel consumption compared to the German designs. By the end of the Second World War, other UK engine companies were working on jet designs based on the Whittle pattern, such as the de Havilland Goblin and Ghost engines. However, the advantages of axial-flow compressors with their higher pressure ratios compared to simpler centrifugal designs led to a transition to axial compressors in the late 1940s, epitomised by the Rolls-Royce Avon series, Armstrong Siddeley Sapphire, Bristol Olympus, and others.
Continued development.
With the W.2 design proceeding smoothly, Whittle was sent to Boston, Massachusetts in mid-1942 to help the General Electric jet programme. GE, the primary supplier of turbochargers in the U.S., was well suited to starting jet production quickly. A combination of the W.2B design and a simple airframe from Bell Aircraft flew in autumn of 1942 as the Bell XP-59A Airacomet, six months before the flight of the British Meteor.
Whittle's developments at Power Jets continued, the W.2/700 later being fitted with an afterburner ("reheat" in British terminology), as well as experimental water injection to cool the engine and allow higher power settings without melting the turbine. Whittle also turned his attention to the axial-flow (straight-through) engine type as championed by Griffith, designing the L.R.1. Other developments included the use of fans to provide greater mass-flow, either at the front of the engine as in a modern turbofan or at the rear, which is much less common but somewhat simpler.
Whittle's work had caused a minor revolution within the British engine manufacturing industry, and even before the E.28/39 flew most companies had set up their own research efforts. In 1939, Metropolitan-Vickers set up a project to develop an axial-flow design as a turboprop but later re-engineered the design as a pure jet known as the Metrovick F.2. Rolls-Royce had already copied the W.1 to produce the low-rated WR.1 but later stopped work on this project after taking over Rover's efforts. In 1941, de Havilland started a jet fighter project, the Spider Crab — later called Vampire — along with their own engine to power it; Frank Halford's Goblin (Halford H.1). Armstrong Siddeley also developed a more complex axial-flow design with an engineer called Heppner, the ASX but reversed Vickers' thinking and later modified it into a turboprop instead, the Python. The Bristol Aeroplane Company proposed to combine jet and piston engines but dropped the idea and concentrated on propellor turbines instead.
Nationalisation.
During a demonstration of the E.28/39 to Winston Churchill in April 1943, Whittle proposed to Stafford Cripps, Minister of Aircraft Production, that all jet development be nationalised. He pointed out that the company had been funded by private investors who helped develop the engine successfully, only to see production contracts go to other companies. Nationalisation was the only way to repay those debts and ensure a fair deal for everyone, and he was willing to surrender his shares in Power Jets to make this happen. In October, Cripps told Whittle that he decided a better solution would be to nationalise Power Jets only.
Whittle believed that he had triggered this decision, but Cripps had already been considering how best to maintain a successful jet programme and act responsibly regarding the state's substantial financial investment, while at the same time wanting to establish a research centre that could utilise Power Jets' talents, and had come to the conclusion that national interests demanded the setting up of a Government-owned establishment. On 1 December Cripps advised Power Jets' directors that the Treasury would not pay more than £100,000 for the company.
In January 1944 Whittle was awarded the CBE in the New Year Honours. By this time he was a Group Captain, having been promoted from Wing Commander in July 1943. Later that month after further negotiations the Ministry made another offer of £135,500 for Power Jets, which was reluctantly accepted after the Ministry refused arbitration on the matter. Since Whittle had already offered to surrender his shares he would receive nothing at all, while Williams and Tinling each received almost £46,800 for their stock, and investors of cash or services had a threefold return on their original investment. Whittle met with Cripps to object personally to the nationalisation efforts and how they were being handled, but to no avail. The final terms were agreed on 28 March, and Power Jets officially became Power Jets (Research and Development) Ltd, with Roxbee Cox as Chairman, Constant of RAE Head of Engineering Division, and Whittle as Chief Technical Advisor. On 5 April 1944, the Ministry sent Whittle an award of only £10,000 for his shares.
From the end of March, Whittle spent six months in hospital recovering from nervous exhaustion, and resigned from Power Jets (R and D) Ltd in January 1946. In July the company was merged with the gas turbine division of the RAE to form the National Gas Turbine Establishment (NGTE) at Farnborough, and 16 Power Jets engineers, following Whittle's example, also resigned.
After the war.
In 1946 Whittle accepted a post as Technical Advisor on Engine Design and Production to Controller of Supplies (Air); was made Commander, the U.S. Legion of Merit; and was awarded the Order of the Bath (CB) in 1947. During May 1948 Whittle received an ex-gratia award of £100,000 from the Royal Commission on Awards to Inventors in recognition of his work on the jet engine, and two months later he was made a Knight Commander of the Order of the British Empire (KBE), Military Division.
During a lecture tour in the U.S. he again broke down and retired from the RAF on medical grounds on 26 August 1948, leaving with the rank of Air Commodore. He joined BOAC as a technical advisor on aircraft gas turbines and travelled extensively over the next few years, viewing jet engine developments in the United States, Canada, Africa, Asia and the Middle East. He left BOAC in 1952 and spent the next year working on a biography, "Jet: The Story of a Pioneer". He was awarded the Royal Society of Arts' Albert Medal that year.
Returning to work in 1953, he accepted a position as a Mechanical Engineering Specialist with Shell, where he developed a new type of self-powered drill driven by a turbine running on the lubricating mud that is pumped into the borehole during drilling. Normally a well is drilled by attaching rigid sections of pipe together and powering the cutting head by spinning the pipe from the surface, but Whittle's design removed the need for a strong mechanical connection between the drill and the head frame, allowing for much lighter piping to be used. He gave the Royal Institution Christmas Lectures in 1954 on "The Story of Petroleum".
Whittle left Shell in 1957 to work for Bristol Aero Engines who picked up the project in 1961, setting up "Bristol Siddeley Whittle Tools" to further develop the concept. In 1966 Rolls-Royce purchased Bristol Siddeley, but the financial pressures and eventual bankruptcy because of cost overruns of the RB211 project led to the slow wind-down and eventual disappearance of Whittle's "turbo-drill". The concept eventually re-appeared in the west in the late 1980s, imported from Russian designs. (Russia needed the technology because it lacked high strength drill pipe.)
Turbine drilling is best used for drilling hard rocks at high bit RPM's with diamond impregnated bits, and can be used with an angled drive shaft for directional drilling and horizontal drilling. It competes though with moyno motors and increasingly with rotary steerable systems and is again out of favour.
As part of his socialist ideals, he proposed that Power Jets be nationalised; in part because he saw that private companies would profit from the technology freely given during the war. By 1964 he had deserted his previously socialist beliefs, going so far as to launch a fierce attack on the Labour candidate in Smetwick.
In 1960 he was awarded an honorary degree, doctor techn. honoris causa, at the Norwegian Institute of Technology, later part of Norwegian University of Science and Technology.
In 1967, he was awarded an Honorary Degree (Doctor of Science) by the University of Bath.
Later life.
Whittle received the "Tony Jannus Award" in 1969 for his distinguished contributions to commercial aviation.
In 1976, his marriage to Dorothy was dissolved and he married American Hazel S Hall ("Tommie"). He emigrated to the U.S. and the following year accepted the position of NAVAIR Research Professor at the United States Naval Academy (Annapolis, Maryland). His research concentrated on the boundary layer before his professorship became part-time from 1978 to 1979. The part-time post enabled him to write a textbook entitled "Gas turbine aero-thermodynamics: with special reference to aircraft propulsion", published in 1981.
Having first met Hans von Ohain in 1966, Whittle again met him at Wright-Patterson Air Force Base in 1978 while von Ohain was working there as the Aero Propulsion Laboratory's Chief Scientist. Initially upset because he believed von Ohain's engine had been developed after seeing Whittle's patent, he eventually became convinced that von Ohain's work was, in fact, independent. The two became good friends and often toured the U.S. giving talks together.
In a conversation with Whittle after the war, Von Ohain stated that ""If you had been given the money you would have been six years ahead of us. If Hitler or Goering had heard that there is a man in England who flies 500mph in a small experimental plane and that it is coming into development, it is likely that World War II would not have come into being.""
In 1986, Whittle was appointed a member of the Order of Merit (Commonwealth). He was made a Fellow of the Royal Society, and of the Royal Aeronautical Society, and in 1991 he and von Ohain were awarded the Charles Stark Draper Prize for their work on turbojet engines.
Whittle was an atheist.
Whittle died of lung cancer on 9 August 1996, at his home in Columbia, Maryland. He was cremated in America and his ashes were flown to England where they were placed in a memorial in a church in Cranwell.

</doc>
<doc id="42708" url="https://en.wikipedia.org/wiki?curid=42708" title="Bion of Smyrna">
Bion of Smyrna

Bion (; , "gen".: Βίωνος) was a Greek bucolic poet.
Life.
He was a native of the city of Smyrna and flourished about 100 BC. Most of his work is lost. There remain 17 fragments (preserved in ancient anthologies) and the "Epitaph of Adonis", a mythological poem on the death of Adonis and the lament of Aphrodite (preserved in several late medieval manuscripts of bucolic poetry). Some of the fragments show the pastoral themes that were typical of ancient Greek bucolic poetry, while others attest the broader thematic interpretation of the bucolic form that prevailed in the later Hellenistic period. They are often concerned with love, mainly homosexual. Besides Adonis, other myths that appear in his work are those of Hyacinthus and the Cyclops; to judge from references in the "Epitaph on Bion", which frequently alludes to Bion's work, he also wrote a poem on Orpheus, to which some of the extant fragments may have belonged. The Greek texts of Bion's poems are generally included in the editions of Theocritus. There is no particular reason to think that the "Epithalamium of Achilles and Deidameia", preserved in bucolic manuscripts and usually included under his name in modern editions, is Bion's work.
Bion's influence can be seen in numerous ancient Greek and Latin poets and prose authors, including Virgil and Ovid. His treatment of the myth of Adonis in particular has influenced European and American literature since the Renaissance.
Almost nothing is known of Bion's life. The account formerly given of him, that he was the contemporary of Theocritus and a friend and teacher of Moschus, and lived about 280 BC, is now regarded as incorrect: it rests on a misreading of the "Epitaph of Bion", a poem commemorating his death, which in early modern times was erroneously attributed to Moschus. The Suda lists the ancient canon of Greek bucolic poets as Theocritus, Moschus, and Bion, which should reflect chronogical order, and Moschus flourished in the mid 2nd century BC. Probable and certain imitations of Bion by Greek and Latin poets begin to be seen in the early 1st century. Some information concerning Bion's life comes from the "Epitaph on Bion". Its anonymous author calls himself Bion's heir and an "Ausonian" (= Italian), which may mean that Bion traveled to Italy at some point, perhaps for patronage in Rome (as Greek poets were beginning to do in his lifetime). It may, however, mean only that the author considered himself Bion's poetic heir. The poem also asserts that Bion was poisoned, which may or may not be a poetic metaphor.
One ancient text gives his place of origin as "a little place called Phlossa," which is otherwise unknown; it was presumably a district under the administration of Smyrna, perhaps one of the villages out of which Smyrna was reconstituted during the Hellenistic period. The appellation "Bion of Phlossa," under which he is sometimes known (for example, by the Library of Congress), is therefore a pedantic solecism: outside of Smyrna itself he would have been known as Bion of Smyrna.
Works.
Recent editions are:
Bion and Moschus have been edited separately by 
Sources.
On the date of Bion:

</doc>
<doc id="42709" url="https://en.wikipedia.org/wiki?curid=42709" title="Pendulum">
Pendulum

A pendulum is a weight suspended from a pivot so that it can swing freely. When a pendulum is displaced sideways from its resting, equilibrium position, it is subject to a restoring force due to gravity that will accelerate it back toward the equilibrium position. When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth. The time for one complete cycle, a left swing and a right swing, is called the period. The period depends on the length of the pendulum and also to a slight degree on the amplitude, the width of the pendulum's swing.
From its examination in around 1602 by Galileo Galilei, the regular motion of pendulums was used for timekeeping, and was the world's most accurate timekeeping technology until the 1930s. Pendulums are used to regulate pendulum clocks, and are used in scientific instruments such as accelerometers and seismometers. Historically they were used as gravimeters to measure the acceleration of gravity in geophysical surveys, and even as a standard of length. The word "pendulum" is new Latin, from the Latin "pendulus", meaning 'hanging'.
The "simple gravity pendulum" is an idealized mathematical model of a pendulum. This is a weight (or bob) on the end of a massless cord suspended from a pivot, without friction. When given an initial push, it will swing back and forth at a constant amplitude. Real pendulums are subject to friction and air drag, so the amplitude of their swings declines.
Period of oscillation.
The period of swing of a simple gravity pendulum depends on its length, the local strength of gravity, and to a small extent on the maximum angle that the pendulum swings away from vertical, "θ0", called the amplitude. It is independent of the mass of the bob. If the amplitude is limited to small swings, the period "T" of a simple pendulum, the time taken for a complete cycle, is:
where L is the length of the pendulum and g is the local acceleration of gravity.
For small swings the period of swing is approximately the same for different size swings: that is, "the period is independent of amplitude". This property, called isochronism, is the reason pendulums are so useful for timekeeping. Successive swings of the pendulum, even if changing in amplitude, take the same amount of time.
For larger amplitudes, the period increases gradually with amplitude so it is longer than given by equation (1). For example, at an amplitude of "θ0" = 23° it is 1% larger than given by (1). The period increases asymptotically (to infinity) as "θ0" approaches 180°, because the value "θ0" = 180° is an unstable equilibrium point for the pendulum. The true period of an ideal simple gravity pendulum can be written in several different forms (see Pendulum (mathematics) ), one example being the infinite series:
The difference between this true period and the period for small swings (1) above is called the "circular error". In the case of a typical grandfather clock whose pendulum has a swing of 6° and thus an amplitude of 3° (0.05 radians), the difference between the true period and the small angle approximation (1) amounts to about 15 seconds per day.
For small swings the pendulum approximates a harmonic oscillator, and its motion as a function of time, t, is approximately simple harmonic motion:
where formula_4 is a constant value, dependent on initial conditions.
For real pendulums, corrections to the period may be needed to take into account the buoyancy and viscous resistance of the air, the mass of the string or rod, the size and shape of the bob and how it is attached to the string, flexibility and stretching of the string, and motion of the support.
Compound pendulum.
The length "L" used to calculate the period of the ideal simple pendulum in eq. (1) above is the distance from the pivot point to the center of mass of the bob. Any swinging rigid body free to rotate about a fixed horizontal axis is called a compound pendulum or physical pendulum. The appropriate equivalent length "L" for calculating the period of any such pendulum is the distance
from the pivot to the "center of oscillation". This point is located under the center of mass at a distance from the
pivot traditionally called the radius of oscillation, which depends on the mass distribution of the pendulum. If most of the mass is concentrated in a relatively small bob compared to the pendulum length, the center of oscillation is close to the center of mass.
The radius of oscillation or equivalent length "L" of any physical pendulum can be shown to be
where "I" is the moment of inertia of the pendulum about the pivot point,
"m" is the mass of the pendulum, and "R" is the distance between the pivot point and the center of mass.
Substituting this expression in (1) above, the period "T" of a compound pendulum is given by
for sufficiently small oscillations.
A rigid uniform rod of length "L" pivoted about either end has moment of inertia "I" = (1/3)"mL"2.
The center of mass is located at the center of the rod, so "R" = "L"/2. Substituting these values into the above equation gives "T" = 2π. This shows that a rigid rod pendulum has the same period as a simple pendulum of 2/3 its length.
Christiaan Huygens proved in 1673 that the pivot point and the center of oscillation are interchangeable. This means if any pendulum is turned upside down and swung from a pivot located at its previous center of oscillation, it will have the same period as before and the new center of oscillation will be at the old pivot point. In 1817 Henry Kater used this idea to produce a type of reversible pendulum, now known as a Kater pendulum, for improved measurements of the acceleration due to gravity.
History.
One of the earliest known uses of a pendulum was a 1st-century seismometer device of Han Dynasty Chinese scientist Zhang Heng. Its function was to sway and activate one of a series of levers after being disturbed by the tremor of an earthquake far away. Released by a lever, a small ball would fall out of the urn-shaped device into one of eight metal toad's mouths below, at the eight points of the compass, signifying the direction the earthquake was located.
Many sources claim that the 10th-century Egyptian astronomer Ibn Yunus used a pendulum for time measurement, but this was an error that originated in 1684 with the British historian Edward Bernard.
During the Renaissance, large pendulums were used as sources of power for manual reciprocating machines such as saws, bellows, and pumps. Leonardo da Vinci made many drawings of the motion of pendulums, though without realizing its value for timekeeping.
1602: Galileo's research.
Italian scientist Galileo Galilei was the first to study the properties of pendulums, beginning around 1602. The earliest extant report of his research is contained in a letter to Guido Ubaldo dal Monte, from Padua, dated November 29, 1602. His biographer and student, Vincenzo Viviani, claimed his interest had been sparked around 1582 by the swinging motion of a chandelier in the Pisa cathedral. Galileo discovered the crucial property that makes pendulums useful as timekeepers, called isochronism; the period of the pendulum is approximately independent of the amplitude or width of the swing. He also found that the period is independent of the mass of the bob, and proportional to the square root of the length of the pendulum. He first employed freeswinging pendulums in simple timing applications. His physician friend, Santorio Santorii, invented a device which measured a patient's pulse by the length of a pendulum; the "pulsilogium". In 1641 Galileo conceived and dictated to his son Vincenzo a design for a pendulum clock; Vincenzo began construction, but had not completed it when he died in 1649. The pendulum was the first harmonic oscillator used by man.
1656: The pendulum clock.
In 1656 the Dutch scientist Christiaan Huygens built the first pendulum clock. This was a great improvement over existing mechanical clocks; their best accuracy was increased from around 15 minutes deviation a day to around 15 seconds a day. Pendulums spread over Europe as existing clocks were retrofitted with them.
The English scientist Robert Hooke studied the conical pendulum around 1666, consisting of a pendulum that is free to swing in two dimensions, with the bob rotating in a circle or ellipse. He used the motions of this device as a model to analyze the orbital motions of the planets. Hooke suggested to Isaac Newton in 1679 that the components of orbital motion consisted of inertial motion along a tangent direction plus an attractive motion in the radial direction. This played a part in Newton's formulation of the law of universal gravitation. Robert Hooke was also responsible for suggesting as early as 1666 that the pendulum could be used to measure the force of gravity.
During his expedition to Cayenne, French Guiana in 1671, Jean Richer found that a pendulum clock was minutes per day slower at Cayenne than at Paris. From this he deduced that the force of gravity was lower at Cayenne. In 1687, Isaac Newton in "Principia Mathematica" showed that this was because the Earth was not a true sphere but slightly oblate (flattened at the poles) from the effect of centrifugal force due to its rotation, causing gravity to increase with latitude. Portable pendulums began to be taken on voyages to distant lands, as precision gravimeters to measure the acceleration of gravity at different points on Earth, eventually resulting in accurate models of the shape of the Earth.
1673: Huygens' "Horologium Oscillatorium".
In 1673, Christiaan Huygens published his theory of the pendulum, "Horologium Oscillatorium sive de motu pendulorum". Marin Mersenne and René Descartes had discovered around 1636 that the pendulum was not quite isochronous; its period increased somewhat with its amplitude. Huygens analyzed this problem by determining what curve an object must follow to descend by gravity to the same point in the same time interval, regardless of starting point; the so-called "tautochrone curve". By a complicated method that was an early use of calculus, he showed this curve was a cycloid, rather than the circular arc of a pendulum, confirming that the pendulum was not isochronous and Galileo's observation of isochronism was accurate only for small swings. Huygens also solved the problem of how to calculate the period of an arbitrarily shaped pendulum (called a "compound pendulum"), discovering the "center of oscillation", and its interchangeability with the pivot point.
The existing clock movement, the verge escapement, made pendulums swing in very wide arcs of about 100°. Huygens showed this was a source of inaccuracy, causing the period to vary with amplitude changes caused by small unavoidable variations in the clock's drive force. To make its period isochronous, Huygens mounted cycloidal-shaped metal 'chops' next to the pivots in his clocks, that constrained the suspension cord and forced the pendulum to follow a cycloid arc. This solution didn't prove as practical as simply limiting the pendulum's swing to small angles of a few degrees. The realization that only small swings were isochronous motivated the development of the anchor escapement around 1670, which reduced the pendulum swing in clocks to 4°–6°.
1721: Temperature compensated pendulums.
During the 18th and 19th century, the pendulum clock's role as the most accurate timekeeper motivated much practical research into improving pendulums. It was found that a major source of error was that the pendulum rod expanded and contracted with changes in ambient temperature, changing the period of swing. This was solved with the invention of temperature compensated pendulums, the mercury pendulum in 1721 and the gridiron pendulum in 1726, reducing errors in precision pendulum clocks to a few seconds per week.
The accuracy of gravity measurements made with pendulums was limited by the difficulty of finding the location of their center of oscillation. Huygens had discovered in 1673 that a pendulum has the same period when hung from its center of oscillation as when hung from its pivot, and the distance between the two points was equal to the length of a simple gravity pendulum of the same period. In 1818 British Captain Henry Kater invented the reversible Kater's pendulum which used this principle, making possible very accurate measurements of gravity. For the next century the reversible pendulum was the standard method of measuring absolute gravitational acceleration.
1851: Foucault pendulum.
In 1851, Jean Bernard Léon Foucault showed that the plane of oscillation of a pendulum, like a gyroscope, tends to stay constant regardless of the motion of the pivot, and that this could be used to demonstrate the rotation of the Earth. He suspended a pendulum free to swing in two dimensions (later named the Foucault pendulum) from the dome of the Panthéon in Paris. The length of the cord was . Once the pendulum was set in motion, the plane of swing was observed to precess or rotate 360° clockwise in about 32 hours.
This was the first demonstration of the Earth's rotation that didn't depend on celestial observations, and a "pendulum mania" broke out, as Foucault pendulums were displayed in many cities and attracted large crowds.
1930: Decline in use.
Around 1900 low-thermal-expansion materials began to be used for pendulum rods in the highest precision clocks and other instruments, first invar, a nickel steel alloy, and later fused quartz, which made temperature compensation trivial. Precision pendulums were housed in low pressure tanks, which kept the air pressure constant to prevent changes in the period due to changes in buoyancy of the pendulum due to changing atmospheric pressure. The accuracy of the best pendulum clocks topped out at around a second per year.
The timekeeping accuracy of the pendulum was exceeded by the quartz crystal oscillator, invented in 1921, and quartz clocks, invented in 1927, replaced pendulum clocks as the world's best timekeepers. Pendulum clocks were used as time standards until World War 2, although the French Time Service continued using them in their official time standard ensemble until 1954. Pendulum gravimeters were superseded by "free fall" gravimeters in the 1950s, but pendulum instruments continued to be used into the 1970s.
Use for time measurement.
For 300 years, from its discovery around 1581 until development of the quartz clock in the 1930s, the pendulum was the world's standard for accurate timekeeping. In addition to clock pendulums, freeswinging seconds pendulums were widely used as precision timers in scientific experiments in the 17th and 18th centuries. Pendulums require great mechanical stability: a length change of only 0.02%, 0.2 mm in a grandfather clock pendulum, will cause an error of a minute per week.
Clock pendulums.
Pendulums in clocks (see example at right) are usually made of a weight or bob "(b)" suspended by a rod of wood or metal "(a)". To reduce air resistance (which accounts for most of the energy loss in clocks) the bob is traditionally a smooth disk with a lens-shaped cross section, although in antique clocks it often had carvings or decorations specific to the type of clock. In quality clocks the bob is made as heavy as the suspension can support and the movement can drive, since this improves the regulation of the clock (see Accuracy below). A common weight for seconds pendulum bobs is . Instead of hanging from a pivot, clock pendulums are usually supported by a short straight spring "(d)" of flexible metal ribbon. This avoids the friction and 'play' caused by a pivot, and the slight bending force of the spring merely adds to the pendulum's restoring force. A few precision clocks have pivots of 'knife' blades resting on agate plates. The impulses to keep the pendulum swinging are provided by an arm hanging behind the pendulum called the "crutch", "(e)", which ends in a "fork", "(f)" whose prongs embrace the pendulum rod. The crutch is pushed back and forth by the clock's escapement, "(g,h)".
Each time the pendulum swings through its centre position, it releases one tooth of the "escape wheel" "(g)". The force of the clock's mainspring or a driving weight hanging from a pulley, transmitted through the clock's gear train, causes the wheel to turn, and a tooth presses against one of the pallets "(h)", giving the pendulum a short push. The clock's wheels, geared to the escape wheel, move forward a fixed amount with each pendulum swing, advancing the clock's hands at a steady rate.
The pendulum always has a means of adjusting the period, usually by an adjustment nut "(c)" under the bob which moves it up or down on the rod. Moving the bob up decreases the pendulum's length, causing the pendulum to swing faster and the clock to gain time. Some precision clocks have a small auxiliary adjustment weight on a threaded shaft on the bob, to allow finer adjustment. Some tower clocks and precision clocks use a tray attached near to the midpoint of the pendulum rod, to which small weights can be added or removed. This effectively shifts the centre of oscillation and allows the rate to be adjusted without stopping the clock.
The pendulum must be suspended from a rigid support. During operation, any elasticity will allow tiny imperceptible swaying motions of the support, which disturbs the clock's period, resulting in error. Pendulum clocks should be attached firmly to a sturdy wall.
The most common pendulum length in quality clocks, which is always used in grandfather clocks, is the seconds pendulum, about long. In mantel clocks, half-second pendulums, long, or shorter, are used. Only a few large tower clocks use longer pendulums, the 1.5 second pendulum, long, or occasionally the two-second pendulum, as is the case of Big Ben.
Temperature compensation.
The largest source of error in early pendulums was slight changes in length due to thermal expansion and contraction of the pendulum rod with changes in ambient temperature. This was discovered when people noticed that pendulum clocks ran slower in summer, by as much as a minute per week (one of the first was Godefroy Wendelin, as reported by Huygens in 1658). Thermal expansion of pendulum rods was first studied by Jean Picard in 1669. A pendulum with a steel rod will expand by about 11.3 parts per million (ppm) with each degree Celsius increase, causing it to lose about 0.27 seconds per day for every degree Celsius increase in temperature, or 9 seconds per day for a change. Wood rods expand less, losing only about 6 seconds per day for a change, which is why quality clocks often had wooden pendulum rods. The wood had to be varnished to prevent water vapor from getting in, because changes in humidity also affected the length.
Mercury pendulum.
The first device to compensate for this error was the mercury pendulum, invented by George Graham in 1721. The liquid metal mercury expands in volume with temperature. In a mercury pendulum, the pendulum's weight (bob) is a container of mercury. With a temperature rise, the pendulum rod gets longer, but the mercury also expands and its surface level rises slightly in the container, moving its centre of mass closer to the pendulum pivot. By using the correct height of mercury in the container these two effects will cancel, leaving the pendulum's centre of mass, and its period, unchanged with temperature. Its main disadvantage was that when the temperature changed, the rod would come to the new temperature quickly but the mass of mercury might take a day or two to reach the new temperature, causing the rate to deviate during that time. To improve thermal accommodation several thin containers were often used, made of metal. Mercury pendulums were the standard used in precision regulator clocks into the 20th century.
Gridiron pendulum.
The most widely used compensated pendulum was the gridiron pendulum, invented in 1726 by John Harrison. This consists of alternating rods of two different metals, one with lower thermal expansion (CTE), steel, and one with higher thermal expansion, zinc or brass. The rods are connected by a frame, as shown in the drawing at the right, so that an increase in length of the zinc rods pushes the bob up, shortening the pendulum. With a temperature increase, the low expansion steel rods make the pendulum longer, while the high expansion zinc rods make it shorter. By making the rods of the correct lengths, the greater expansion of the zinc cancels out the expansion of the steel rods which have a greater combined length, and the pendulum stays the same length with temperature.
Zinc-steel gridiron pendulums are made with 5 rods, but the thermal expansion of brass is closer to steel, so brass-steel gridirons usually require 9 rods. Gridiron pendulums adjust to temperature changes faster than mercury pendulums, but scientists found that friction of the rods sliding in their holes in the frame caused gridiron pendulums to adjust in a series of tiny jumps. In high precision clocks this caused the clock's rate to change suddenly with each jump. Later it was found that zinc is subject to creep. For these reasons mercury pendulums were used in the highest precision clocks, but gridirons were used in quality regulator clocks.
Gridiron pendulums became so associated with good quality that, to this day, many ordinary clock pendulums have decorative 'fake' gridirons that don't actually have any temperature compensation function.
Invar and fused quartz.
Around 1900 low thermal expansion materials were developed which, when used as pendulum rods, made elaborate temperature compensation unnecessary. These were only used in a few of the highest precision clocks before the pendulum became obsolete as a time standard. In 1896 Charles Édouard Guillaume invented the nickel steel alloy Invar. This has a CTE of around 0.5 µin/(in·°F), resulting in pendulum temperature errors over 71 °F of only 1.3 seconds per day, and this residual error could be compensated to zero with a few centimeters of aluminium under the pendulum bob (this can be seen in the Riefler clock image above). Invar pendulums were first used in 1898 in the Riefler regulator clock which achieved accuracy of 15 milliseconds per day. Suspension springs of Elinvar were used to eliminate temperature variation of the spring's restoring force on the pendulum. Later fused quartz was used which had even lower CTE. These materials are the choice for modern high accuracy pendulums.
Atmospheric pressure.
The effect of the surrounding air on a moving pendulum is complex and requires fluid mechanics to calculate precisely, but for most purposes its influence on the period can be accounted for by three effects:
Increases in barometric pressure increase a pendulum's period slightly due to the first two effects, by about 0.11 seconds per day per kilopascal (0.37 seconds per day per inch of mercury or 0.015 seconds per day per torr). Researchers using pendulums to measure the acceleration of gravity had to correct the period for the air pressure at the altitude of measurement, computing the equivalent period of a pendulum swinging in vacuum. A pendulum clock was first operated in a constant-pressure tank by Friedrich Tiede in 1865 at the Berlin Observatory, and by 1900 the highest precision clocks were mounted in tanks that were kept at a constant pressure to eliminate changes in atmospheric pressure. Alternatively, in some a small aneroid barometer mechanism attached to the pendulum compensated for this effect.
Gravity.
Pendulums are affected by changes in gravitational acceleration, which varies by as much as 0.5% at different locations on Earth, so pendulum clocks have to be recalibrated after a move. Even moving a pendulum clock to the top of a tall building can cause it to lose measurable time from the reduction in gravity.
Accuracy of pendulums as timekeepers.
The timekeeping elements in all clocks, which include pendulums, balance wheels, the quartz crystals used in quartz watches, and even the vibrating atoms in atomic clocks, are in physics called harmonic oscillators. The reason harmonic oscillators are used in clocks is that they vibrate or oscillate at a specific resonant frequency or period and resist oscillating at other rates. However, the resonant frequency is not infinitely 'sharp'. Around the resonant frequency there is a narrow natural band of frequencies (or periods), called the resonance width or bandwidth, where the harmonic oscillator will oscillate. In a clock, the actual frequency of the pendulum may vary randomly within this bandwidth in response to disturbances, but at frequencies outside this band, the clock will not function at all.
"Q" factor.
The measure of a harmonic oscillator's resistance to disturbances to its oscillation period is a dimensionless parameter called the "Q" factor equal to the resonant frequency divided by the bandwidth. The higher the "Q", the smaller the bandwidth, and the more constant the frequency or period of the oscillator for a given disturbance. The reciprocal of the Q is roughly proportional to the limiting accuracy achievable by a harmonic oscillator as a time standard.
The "Q" is related to how long it takes for the oscillations of an oscillator to die out. The "Q" of a pendulum can be measured by counting the number of oscillations it takes for the amplitude of the pendulum's swing to decay to 1/"e" = 36.8% of its initial swing, and multiplying by 2"π".
In a clock, the pendulum must receive pushes from the clock's movement to keep it swinging, to replace the energy the pendulum loses to friction. These pushes, applied by a mechanism called the escapement, are the main source of disturbance to the pendulum's motion. The "Q" is equal to 2"π" times the energy stored in the pendulum, divided by the energy lost to friction during each oscillation period, which is the same as the energy added by the escapement each period. It can be seen that the smaller the fraction of the pendulum's energy that is lost to friction, the less energy needs to be added, the less the disturbance from the escapement, the more 'independent' the pendulum is of the clock's mechanism, and the more constant its period is. The "Q" of a pendulum is given by:
where "M" is the mass of the bob, "ω" = 2"π"/"T" is the pendulum's radian frequency of oscillation, and "Γ" is the frictional damping force on the pendulum per unit velocity.
"ω" is fixed by the pendulum's period, and "M" is limited by the load capacity and rigidity of the suspension. So the "Q" of clock pendulums is increased by minimizing frictional losses ("Γ"). Precision pendulums are suspended on low friction pivots consisting of triangular shaped 'knife' edges resting on agate plates. Around 99% of the energy loss in a freeswinging pendulum is due to air friction, so mounting a pendulum in a vacuum tank can increase the "Q", and thus the accuracy, by a factor of 100.
The "Q" of pendulums ranges from several thousand in an ordinary clock to several hundred thousand for precision regulator pendulums swinging in vacuum. A quality home pendulum clock might have a "Q" of 10,000 and an accuracy of 10 seconds per month. The most accurate commercially produced pendulum clock was the Shortt-Synchronome free pendulum clock, invented in 1921. Its Invar master pendulum swinging in a vacuum tank had a "Q" of 110,000 and an error rate of around a second per year.
Their Q of 103–105 is one reason why pendulums are more accurate timekeepers than the balance wheels in watches, with "Q" around 100-300, but less accurate than the quartz crystals in quartz clocks, with "Q" of 105–106.
Escapement.
Pendulums (unlike, for example, quartz crystals) have a low enough "Q" that the disturbance caused by the impulses to keep them moving is generally the limiting factor on their timekeeping accuracy. Therefore, the design of the escapement, the mechanism that provides these impulses, has a large effect on the accuracy of a clock pendulum. If the impulses given to the pendulum by the escapement each swing could be exactly identical, the response of the pendulum would be identical, and its period would be constant. However, this is not achievable; unavoidable random fluctuations in the force due to friction of the clock's pallets, lubrication variations, and changes in the torque provided by the clock's power source as it runs down, mean that the force of the impulse applied by the escapement varies.
If these variations in the escapement's force cause changes in the pendulum's width of swing (amplitude), this will cause corresponding slight changes in the period, since (as discussed at top) a pendulum with a finite swing is not quite isochronous. Therefore, the goal of traditional escapement design is to apply the force with the proper profile, and at the correct point in the pendulum's cycle, so force variations have no effect on the pendulum's amplitude. This is called an "isochronous escapement".
The Airy condition.
In 1826 British astronomer George Airy proved what clockmakers had known for centuries; that the disturbing effect of a drive force on the period of a pendulum is smallest if given as a short impulse as the pendulum passes through its bottom equilibrium position. Specifically, he proved that if a pendulum is driven by an impulse that is symmetrical about its bottom equilibrium position, the pendulum's period will be unaffected by changes in the drive force. The most accurate escapements, such as the deadbeat, approximately satisfy this condition.
Gravity measurement.
The presence of the acceleration of gravity "g" in the periodicity equation (1) for a pendulum means that the local gravitational acceleration of the Earth can be calculated from the period of a pendulum. A pendulum can therefore be used as a gravimeter to measure the local gravity, which varies by over 0.5% across the surface of the Earth. The pendulum in a clock is disturbed by the pushes it receives from the clock movement, so freeswinging pendulums were used, and were the standard instruments of gravimetry up to the 1930s.
The difference between clock pendulums and gravimeter pendulums is that to measure gravity, the pendulum's length as well as its period has to be measured. The period of freeswinging pendulums could be found to great precision by comparing their swing with a precision clock that had been adjusted to keep correct time by the passage of stars overhead. In the early measurements, a weight on a cord was suspended in front of the clock pendulum, and its length adjusted until the two pendulums swung in exact synchronism. Then the length of the cord was measured. From the length and the period, "g" could be calculated from equation (1).
Kater's pendulum.
The precision of the early gravity measurements above was limited by the difficulty of measuring the length of the pendulum, "L" . "L" was the length of an idealized simple gravity pendulum (described at top), which has all its mass concentrated in a point at the end of the cord. In 1673 Huygens had shown that the period of a real pendulum (called a "compound pendulum") was equal to the period of a simple pendulum with a length equal to the distance between the pivot point and a point called the center of oscillation, located under the center of gravity, that depends on the mass distribution along the pendulum. But there was no accurate way of determining the center of oscillation in a real pendulum.
To get around this problem, the early researchers above approximated an ideal simple pendulum as closely as possible by using a metal sphere suspended by a light wire or cord. If the wire was light enough, the center of oscillation was close to the center of gravity of the ball, at its geometric center. This "ball and wire" type of pendulum wasn't very accurate, because it didn't swing as a rigid body, and the elasticity of the wire caused its length to change slightly as the pendulum swung.
However Huygens had also proved that in any pendulum, the pivot point and the center of oscillation were interchangeable. That is, if a pendulum were turned upside down and hung from its center of oscillation, it would have the same period as it did in the previous position, and the old pivot point would be the new center of oscillation.
British physicist and army captain Henry Kater in 1817 realized that Huygens' principle could be used to find the length of a simple pendulum with the same period as a real pendulum. If a pendulum was built with a second adjustable pivot point near the bottom so it could be hung upside down, and the second pivot was adjusted until the periods when hung from both pivots were the same, the second pivot would be at the center of oscillation, and the distance between the two pivots would be the length of a simple pendulum with the same period.
Kater built a reversible pendulum (shown at right) consisting of a brass bar with two opposing pivots made of short triangular "knife" blades "(a)" near either end. It could be swung from either pivot, with the knife blades supported on agate plates. Rather than make one pivot adjustable, he attached the pivots a meter apart and instead adjusted the periods with a moveable weight on the pendulum rod "(b,c)". In operation, the pendulum is hung in front of a precision clock, and the period timed, then turned upside down and the period timed again. The weight is adjusted with the adjustment screw until the periods are equal. Then putting this period and the distance between the pivots into equation (1) gives the gravitational acceleration "g" very accurately.
Kater timed the swing of his pendulum using the ""method of coincidences"" and measured the distance between the two pivots with a micrometer. After applying corrections for the finite amplitude of swing, the buoyancy of the bob, the barometric pressure and altitude, and temperature, he obtained a value of 39.13929 inches for the seconds pendulum at London, in vacuum, at sea level, at 62 °F. The largest variation from the mean of his 12 observations was 0.00028 in. representing a precision of gravity measurement of 7×10−6 (7 mGal or 70 µm/s2). Kater's measurement was used as Britain's official standard of length (see below) from 1824 to 1855.
Reversible pendulums (known technically as "convertible" pendulums) employing Kater's principle were used for absolute gravity measurements into the 1930s.
Later pendulum gravimeters.
The increased accuracy made possible by Kater's pendulum helped make gravimetry a standard part of geodesy. Since the exact location (latitude and longitude) of the 'station' where the gravity measurement was made was necessary, gravity measurements became part of surveying, and pendulums were taken on the great geodetic surveys of the 18th century, particularly the Great Trigonometric Survey of India.
Relative pendulum gravimeters were superseded by the simpler LaCoste zero-length spring gravimeter, invented in 1934 by Lucien LaCoste. Absolute (reversible) pendulum gravimeters were replaced in the 1950s by free fall gravimeters, in which a weight is allowed to fall in a vacuum tank and its acceleration is measured by an optical interferometer.
Standard of length.
Because the acceleration of gravity is constant at a given point on Earth, the period of a simple pendulum at a given location depends only on its length. Additionally, gravity varies only slightly at different locations. Almost from the pendulum's discovery until the early 19th century, this property led scientists to suggest using a pendulum of a given period as a standard of length.
Until the 19th century, countries based their systems of length measurement on prototypes, metal bar primary standards, such as the standard yard in Britain kept at the Houses of Parliament, and the standard "toise" in France, kept at Paris. These were vulnerable to damage or destruction over the years, and because of the difficulty of comparing prototypes, the same unit often had different lengths in distant towns, creating opportunities for fraud. Enlightenment scientists argued for a length standard that was based on some property of nature that could be determined by measurement, creating an indestructible, universal standard. The period of pendulums could be measured very precisely by timing them with clocks that were set by the stars. A pendulum standard amounted to defining the unit of length by the gravitational force of the Earth, for all intents constant, and the second, which was defined by the rotation rate of the Earth, also constant. The idea was that anyone, anywhere on Earth, could recreate the standard by constructing a pendulum that swung with the defined period and measuring its length.
Virtually all proposals were based on the seconds pendulum, in which each swing (a half period) takes one second, which is about a meter (39 inches) long, because by the late 17th century it had become a standard for measuring gravity (see previous section). By the 18th century its length had been measured with sub-millimeter accuracy at a number of cities in Europe and around the world.
The initial attraction of the pendulum length standard was that it was believed (by early scientists such as Huygens and Wren) that gravity was constant over the Earth's surface, so a given pendulum had the same period at any point on Earth. So the length of the standard pendulum could be measured at any location, and would not be tied to any given nation or region; it would be a truly democratic, worldwide standard. Although Richer found in 1672 that gravity varies at different points on the globe, the idea of a pendulum length standard remained popular, because it was found that gravity only varies with latitude. Gravitational acceleration increases smoothly from the equator to the poles, due to the oblate shape of the Earth. So at any given latitude (east-west line), gravity was constant enough that the length of a seconds pendulum was the same within the measurement capability of the 18th century. So the unit of length could be defined at a given latitude and measured at any point at that latitude. For example, a pendulum standard defined at 45° north latitude, a popular choice, could be measured in parts of France, Italy, Croatia, Serbia, Romania, Russia, Kazakhstan, China, Mongolia, the United States and Canada. In addition, it could be recreated at any location at which the gravitational acceleration had been accurately measured.
By the mid 19th century, increasingly accurate pendulum measurements by Edward Sabine and Thomas Young revealed that gravity, and thus the length of any pendulum standard, varied measurably with local geologic features such as mountains and dense subsurface rocks. So a pendulum length standard had to be defined at a single point on Earth and could only be measured there. This took much of the appeal from the concept, and efforts to adopt pendulum standards were abandoned.
Early proposals.
One of the first to suggest defining length with a pendulum was Flemish scientist Isaac Beeckman who in 1631 recommended making the seconds pendulum "the invariable measure for all people at all times in all places". Marin Mersenne, who first measured the seconds pendulum in 1644, also suggested it. The first official proposal for a pendulum standard was made by the British Royal Society in 1660, advocated by Christiaan Huygens and Ole Rømer, basing it on Mersenne's work, and Huygens in "Horologium Oscillatorium" proposed a "horary foot" defined as 1/3 of the seconds pendulum. Christopher Wren was another early supporter. The idea of a pendulum standard of length must have been familiar to people as early as 1663, because Samuel Butler satirizes it in "Hudibras":
In 1671 Jean Picard proposed a pendulum defined 'universal foot' in his influential "Mesure de la Terre". Gabriel Mouton around 1670 suggested defining the "toise" either by a seconds pendulum or a minute of terrestrial degree. A plan for a complete system of units based on the pendulum was advanced in 1675 by Italian polymath Tito Livio Burratini. In France in 1747, geographer Charles Marie de la Condamine proposed defining length by a seconds pendulum at the equator; since at this location a pendulum's swing wouldn't be distorted by the Earth's rotation. James Steuart (1780) and George Skene Keith were also supporters.
By the end of the 18th century, when many nations were reforming their weight and measure systems, the seconds pendulum was the leading choice for a new definition of length, advocated by prominent scientists in several major nations. In 1790, then US Secretary of State Thomas Jefferson proposed to Congress a comprehensive decimalized US 'metric system' based on the seconds pendulum at 38° North latitude, the mean latitude of the United States. No action was taken on this proposal. In Britain the leading advocate of the pendulum was politician John Riggs Miller. When his efforts to promote a joint British–French–American metric system fell through in 1790, he proposed a British system based on the length of the seconds pendulum at London. This standard was adopted in 1824 (below).
The metre.
In the discussions leading up to the French adoption of the metric system in 1791, the leading candidate for the definition of the new unit of length, the metre, was the seconds pendulum at 45° North latitude. It was advocated by a group led by French politician Talleyrand and mathematician Antoine Nicolas Caritat de Condorcet. This was one of the three final options considered by the French Academy of Sciences committee. However, on March 19, 1791 the committee instead chose to base the metre on the length of the meridian through Paris. A pendulum definition was rejected because of its variability at different locations, and because it defined length by a unit of time. (However, since 1983 the metre has been officially defined in terms of the length of the second and the speed of light.) A possible additional reason is that the radical French Academy didn't want to base their new system on the second, a traditional and nondecimal unit from the "ancien regime".
Although not defined by the pendulum, the final length chosen for the metre, 10−7 of the pole-to-equator meridian arc, was very close to the length of the seconds pendulum (0.9937 m), within 0.63%. Although no reason for this particular choice was given at the time, it was probably to facilitate the use of the seconds pendulum as a secondary standard, as was proposed in the official document. So the modern world's standard unit of length is certainly closely linked historically with the seconds pendulum.
Britain and Denmark.
Britain and Denmark appear to be the only nations that (for a short time) based their units of length on the pendulum. In 1821 the Danish inch was defined as 1/38 of the length of the mean solar seconds pendulum at 45° latitude at the meridian of Skagen, at sea level, in vacuum. The British parliament passed the "Imperial Weights and Measures Act" in 1824, a reform of the British standard system which declared that if the prototype standard yard was destroyed, it would be recovered by defining the inch so that the length of the solar seconds pendulum at London, at sea level, in a vacuum, at 62 °F was 39.1393 inches. This also became the US standard, since at the time the US used British measures. However, when the prototype yard was lost in the 1834 Houses of Parliament fire, it proved impossible to recreate it accurately from the pendulum definition, and in 1855 Britain repealed the pendulum standard and returned to prototype standards.
Other uses.
Seismometers.
A pendulum in which the rod is not vertical but almost horizontal was used in early seismometers for measuring earth tremors. The bob of the pendulum does not move when its mounting does, and the difference in the movements is recorded on a drum chart.
Schuler tuning.
As first explained by Maximilian Schuler in a 1923 paper, a pendulum whose period exactly equals the orbital period of a hypothetical satellite orbiting just above the surface of the earth (about 84 minutes) will tend to remain pointing at the center of the earth when its support is suddenly displaced. This principle, called Schuler tuning, is used in inertial guidance systems in ships and aircraft that operate on the surface of the Earth. No physical pendulum is used, but the control system that keeps the inertial platform containing the gyroscopes stable is modified so the device acts as though it is attached to such a pendulum, keeping the platform always facing down as the vehicle moves on the curved surface of the Earth.
Coupled pendulums.
In 1665 Huygens made a curious observation about pendulum clocks. Two clocks had been placed on his mantlepiece, and he noted that they had acquired an opposing motion. That is, their pendulums were beating in unison but in the opposite direction; 180° out of phase. Regardless of how the two clocks were started, he found that they would eventually return to this state, thus making the first recorded observation of a coupled oscillator.
The cause of this behavior was that the two pendulums were affecting each other through slight motions of the supporting mantlepiece. This process is called entrainment or mode locking in physics and is observed in other coupled oscillators. Synchronized pendulums have been used in clocks and were widely used in gravimeters in the early 20th century. Although Huygens only observed out-of-phase synchronization, recent investigations have shown the existence of in-phase synchronization, as well as "death" states wherein one or both clocks stops.
Religious practice.
Pendulum motion appears in religious ceremonies as well. The swinging incense burner called a censer, also known as a thurible, is an example of a pendulum. Pendulums are also seen at many gatherings in eastern Mexico where they mark the turning of the tides on the day which the tides are at their highest point. See also pendulums for divination and dowsing.
Execution.
During the Late Middle Ages, pendulums were used as a method of torture by the Spanish Inquisition. Using the basic principle of the pendulum, the weight (bob) is replaced by an axe head. The victim is strapped to a table below, the device is activated, and the axe begins to swing back and forth through the air. With each pass, or return, the pendulum is lowered, gradually coming closer to the victim until it finally cleaves the victim's torso. Because of the time required before the mortal action of the axe is complete, the pendulum is considered a method of torturing the victim before his or her demise.
Notes.
The value of g reflected by the period of a pendulum varies from place to place. The gravitational force varies with distance from the center of the Earth, i.e. with altitude - or because the Earth's shape is oblate, g varies with latitude.
A more important cause of this reduction in g at the equator is because the equator is spinning at one revolution per day, reducing the gravitational force there.
References.
Note: most of the sources below, including books, can be viewed online through the links given.

</doc>
<doc id="42713" url="https://en.wikipedia.org/wiki?curid=42713" title="Special Olympics">
Special Olympics

Special Olympics is the world's largest sports organization for children and adults with intellectual disabilities, providing year-round training and competitions to more than 4.5 million athletes in 170 countries.
Special Olympics competitions are held every day, all around the world—including local, national and regional competitions, adding up to more than 94,000 events a year. Like the International Paralympic Committee, the Special Olympics organization is recognized by the International Olympic Committee; however, unlike the same Paralympic Games, Special Olympics World Games are not held in conjunction with the Olympic Games, and regional Special Olympics committees are not closely modeled on national olympic committees.
These competitions include the Special Olympics World Games, which alternate between summer and winter games. Special Olympics World Games are held every two years. The most recent World Summer Games were the Special Olympics World Summer Games, held in Los Angeles, California (The largest event in LA since the 1984 Olympic Games), from July 25, 2015 to August 2, 2015 and for the first time were part of ESPN daily coverage.
The most recent Special Olympics World Winter Games were held in Pyeongchang, South Korea from January 29 to February 5, 2013. At the same time, the first Special Olympics Global Development Summit was held on "Ending the Cycle of Poverty and Exclusion for People with Intellectual Disabilities," gathering government officials, activists and business leaders from around the world 
Graz and Schladming, Austria will host the next Special Olympics World Winter Games from March 14–25, 2017.
History.
In June 1962, Eunice Kennedy Shriver started a day camp called Camp Shriver for children with intellectual disabilities at her home in Potomac, Maryland. She started this camp because she was concerned about children with intellectual disabilities having nowhere to play and that they could benefit from sports activities. Using Camp Shriver as an example, Eunice Kennedy Shriver, who was head of the Joseph P. Kennedy, Jr. Foundation and part of President John F. Kennedy's Panel on Mental Retardation, promoted the concept of involvement in physical activity and other opportunities for people with intellectual disabilities. Camp Shriver became an annual event, and the Kennedy Foundation (of which Eunice became director in 1957) gave grants to universities, recreation departments and community centers to hold similar camps.
Meanwhile, in 1958, Dr. James N. Oliver of England was conducting pioneering research, including a ground-breaking study showing that physical exercise and activities for children with intellectual disabilities had positive effects that also carried over into the classroom ("The Effects of Physical Conditioning Exercises and Activities on the Mental Characteristics of Educationally Sub-Normal Boys, British Journal of Educational Psychology, XXVIII, June 1958). Dr. Oliver would later (1964) serve as consultant to Camp Shriver, the forerunner to Special Olympics.
The 1964 research of Dr. Frank Hayden, a Canadian physical education professor from London, Ontario, had shown that persons with intellectual disabilities can and should participate in physical exercise. Moreover, he believed that the benefits of such activity would be seen in all areas of the athletes’ lives. And so, with the help of a local school that offered space in its gym, the first organised sport program floor hockey for intellectually disabled individuals became available in the fall of 1968.
It was also in the early 1960s that Eunice Kennedy Shriver wrote an article in the Saturday Evening Post, revealing that her sister—also President John F. Kennedy's sister—was born with intellectual disabilities. This frank article about the President's family was seen as a "watershed" in changing public attitudes toward people with intellectual disabilities. Though Rosemary was born with intellectual disabilities, she had later undergone a lobotomy; the brain damage inflicted by the operation caused her to be permanently incapacitated. It has often been said that Rosemary's disability was Eunice's inspiration to form Special Olympics (as the movement came to be called), but she told "The New York Times" in 1995 that that was not exactly the case. "The games should not focus on one individual,"she said.
The first International Special Olympics Summer Games were held in 1968 at Soldier Field in Chicago. About 1500 athletes from the U.S. and Canada took part in the one-day event, which was a joint venture by the Kennedy Foundation and the Chicago Park District. Anne McGlone Burke, a physical education teacher with the Chicago Park District and recipient of a Kennedy Foundation grant, began with the idea for a one-time Olympic-style athletic competition for people with special needs. Burke then approached her to fund the event. Eunice, in turn, encouraged her to expand on the idea and the JPK Jr. Foundation provided a grant of $25,000.
The advisory committee to the Chicago Special Olympics included Dr. William Freeberg, Southern Illinois University; Dr. Frank J. Hayden, Joseph P. Kennedy Foundation; Dr. Arthur Peavy; William McFetridge, Anne McGlone Burke and Stephen Kelly of the Chicago Park District; and Olympic decathlon champion Rafer Johnson. Eunice Kennedy Shriver was honorary chairman. At the July 1968 games, Shriver announced the formation of Special Olympics and that more games would be held every two years as a "Biennial International Special Olympics.".
In 1971, The U.S. Olympic Committee gave the Special Olympics official approval to use the name “Olympics”.
The first 1977 Special Olympics World Winter Games were held in February 1977 in Steamboat Springs, Colorado, U.S.
In 1988, the Special Olympics was officially recognized by the International Olympic Committee (IOC).
In 1997, Healthy Athletes became an official Special Olympics initiative, offering health information and screenings to Special Olympics athletes worldwide. By 2010, the Healthy Athletes program had given free health screenings and treatment to more than 1 million people with intellectual disabilities.
In 2003 the first Special Olympics World Summer Games to be held outside of the United States took place in Dublin, Ireland. Approximately 7,000 athletes from 150 countries competed over 18 disciplines. The Dublin games were also the first to have their own opening and closing ceremonies broadcast live, performed by the President of Ireland, Mary McAleese.
Most significantly the 2003 games dramatically changed the perceptions and attitudes of society regarding the abilities and limitations of people with intellectual disabilities. The opening ceremony of the 2003 Games has been described by President McAleese as "a time when Ireland was at its superb best".
On October 30, 2004, President George W. Bush signed into law the "Special Olympics Sport and Empowerment Act," Public Law 108-406. The bill authorized funding for its Healthy Athletes, Education, and Worldwide Expansion programs. Co-sponsored by Representatives Roy Blunt (R-MO), and Steny Hoyer (D-MD), and Senators Rick Santorum (R-PA) and Harry Reid (D-NV), the bills were passed by unanimous consent in both chambers.
In July 2006, the first Special Olympics USA Games were held at Iowa State University. Teams from all 50 states and the District of Columbia participated.
In 2008, Special Olympics and Best Buddies International launched the Spread the Word to End the Word campaign to encourage individuals to stop using the word "retard" in everyday speech.
In 2011, Senators Tom Harkin and Roy Blunt and Representatives Steny Hoyer and Peter King introduced the Eunice Kennedy Shriver Act to authorize federal funding for Special Olympics Programs and Best Buddies Programs.
Symbols.
The Special Olympics logo has gone through several changes in its lifetime. The "stick figure" is an abstract but humanistic form designed to convey the impression of movement and activity. The logo is a symbol of growth, confidence and joy among children and adults with disabilities who are learning coordination, mastering skills, participating in competitions and preparing themselves for richer, more productive lives. The spherical appearance of the logo is a representation of Special Olympics' global outreach.
Participation.
Special Olympics programs are available for athletes free of charge. More than 4 million athletes are involved in Special Olympics sports training and competition in approx. 180 countries. The organization offers year-round training and competition in 32 Olympic-style summer and winter sports.
People with intellectual disabilities are encouraged to join Special Olympics for the physical activity, which helps lower the rate of cardiovascular disease and obesity, among other health benefits. Also, they gain many emotional and psychological benefits, including self-confidence, social competence, building greater athletic skills and higher self-esteem. The motivations for joining the Special Olympics vary from one individual to the next; yet, there are common themes among individuals and their families that encourage them to either participate or abstain from the Special Olympics.
Special Olympics competitions are open to athletes ages 8 and up. For young people with intellectual disabilities ages 2–7, Special Olympics has a Young Athletes program—a sport and play program with a focus on fun activities that are important to mental and physical growth. Children engage in games and activities that develop motor skills and hand-eye coordination. Parents say their children in Young Athletes also develop better social skills. The confidence boost makes it easier for them to play and talk with other children on the playground and elsewhere . A study by the Center for Social Development and Education (University of Massachusetts, Boston) found that the activities also had the effect of helping children with intellectual disabilities learn routines and approaches to learning, along with how to follow rules and directions.
Families can also get involved with the Special Olympics experience. Family members support their athletes to the best of their ability, which may involve attending or volunteering at the events. By being involved they can boost their athlete's self-esteem and will be looked at as a constant source of encouragement.
Volunteers and supporters are an integral part of Special Olympics—and millions of people around the world are committed to its programs. Some are sponsors or donors. Many others are coaches, event volunteers and fans.
Coaches help the athletes be the best they can be regardless of ability—or disability. Special Olympics trains coaches through the Coaching Excellence program, which includes partnering with sports organizations. Special Olympics volunteers are introduced to lifetime friendships and great rewards.
There are many events that families and volunteers can get involved with, but the biggest event is the Law Enforcement Torch Run. The Torch Run involves police chiefs, police officers, secret service, FBI agents, military police, sheriffs, state troopers, prison guards, and other law enforcement personnel. They all get together to raise awareness and funds for Special Olympics. Ahead of a Special Olympics competition, law enforcement officers carry the torch in intervals along a planned route covering most of the state or country to the site of the opening ceremonies of the chapter or Special Olympics World Summer or Winter Games. Then they pass the torch to a Special Olympics athlete and together they run up to the cauldron and light it, signifying the beginning of the games.
The Special Olympics athlete's oath, which was first introduced by Eunice Kennedy Shriver at the inaugural Special Olympics international games in Chicago in 1968, is "Let me win. But if I cannot win, let me be brave in the attempt."
Sports offered.
In 1968, track and field and swimming were the first two official sports offered by Special Olympics. As in the Olympics, events are introduced in training and then added to the competitive schedule, and from there the list of sports and events continued to grow.
Special Olympics has more than 30 Olympic-type individual and team sports that provide meaningful training and competition opportunities for people with intellectual disabilities. As of 2016, these are:
Other recognized and demonstration sports that Special Olympics offers include Motor Activity Training Program and Beach Volleyball. Availability of sports can depend on location and season.
A key difference between Special Olympics competitions and those of other sports organizations is that athletes of all ability levels are encouraged to participate. Competitions are structured so that athletes compete with other athletes of similar ability in equitable divisions. An athlete's ability is the primary factor in divisioning Special Olympics competitions. The ability of an athlete or team is determined by an entry score from a prior competition or the result of a seeding round or preliminary event at the competition itself. Other factors that are significant in establishing competitive divisions are age and sex.
At competitions, medals are awarded to the first, second and third-place winners in each event, and ribbons are awarded to athletes who finish in fourth through eighth place.
In the Young Athletes program, children ages 2–7 play simple sports and games. The focus is on fun activities that are important to mental and physical growth.
Famous supporters.
The Special Olympics movement has attracted the support of a number of international sportsmen and other celebrities, including Rafer Johnson, Avril Lavigne, Bono, Joe Jonas, Dikembe Mutombo, Derek Poundstone, Pádraig Harrington, Jackie Chan, Zhang Ziyi, Yao Ming, Nadia Comaneci, Bart Conner, Vanessa Williams, Mary Alice Pearce DeVane, Colin Farrell and Arnold Schwarzenegger.
Nelson Mandela, Muhammad Ali and Quincy Jones took part in a 2003 Global Youth Summit at the Special Olympics World Summer Games in Dublin, Ireland.
U.S. President Bill Clinton took part in a Global Youth Summit during the 2005 Special Olympics World Winter Games in Nagano, Japan. Eloísa García Etchegoyhen who served for 20 years at the Organization of American States Inter-American Children's Institute (IIN) (1966-1986) as the head of the Special Education and Early Childhood Division, brought the Special Olympics program to Uruguay.
In 2011, Princess Charlene of Monaco, herself a former Olympian, was named as a Global Ambassador for Special Olympics. Olympic swimming legend Michael Phelps was also named a Global Ambassador and has taken part in aquatics clinics for Special Olympics swimmers in Shanghai, China and elsewhere. Other celebrity supporters include Olympic stars Michelle Kwan, Apolo Ohno, Kim Yuna, Yang Yang (A), and Scott Hamilton, and other sport greats Dikembe Mutombo, Pádraig Harrington, Vladimir Grbic, In-Kyung Kim, Dani Alves and Kaká, along with celebrities including Zhang Ziyi, Yang Lan, Brooklyn Decker, Lauren Alaina, Nicole Sherzinger, and the Wonder Girls. More recently, Olympic snowboarder Hannah Teter, Japanese football legend Hidetoshi Nakata, and WNBA player Elena Delle Donne, whose older sister Lizzie has multiple disabilities, were named Global Ambassadors in 2014. Newest Global Ambassadors include Joe Haden, Maria Menounos, Nancy O'Dell and Jamaal Charles.
Unified Sports.
In recent years, Special Olympics has pioneered the concept of Unified Sports, bringing together athletes with and without intellectual disabilities as teammates. The basic concept is that training together and playing together can create a path to friendship and understanding. The program has expanded beyond the U.S. and North America: a half-million people worldwide now take part in Special Olympics Unified Sports, breaking down stereotypes about people with intellectual disabilities.
A recent study of Special Olympics Unified Sports in Serbia, Poland, Ukraine, Germany and Hungary documented the program's benefits, including the effect of changing attitudes toward people with intellectual disabilities. As one Unified Sports partner said, "I am ashamed to say that I used to laugh at these people (people with intellectual disabilities), now I will tell anybody to stop laughing if I see it and I will stand up for people if I can." Other evaluations have also shown Unified Sports to be successful in building self-esteem and confidence in people with intellectual disabilities and also as a way to improve understanding and acceptance of people with intellectual disabilities among their non-disabled peers.
The Special Olympics Europe Eurasia Regional Research centre is based at the University of Ulster Jordanstown and is jointly led by Professor Roy McConkey and Professor David Hassan.
Healthy Athletes.
As Special Olympics began to grow, staffers and volunteers began to notice that athletes—children and adults with intellectual disabilities—also had many untreated health problems. In 1997, Special Olympics began an initiative called Healthy Athletes, which offers health screenings to athletes in need.
Healthy Athletes currently offers health screenings in seven areas: Fit Feet (podiatry), FUNfitness (physical therapy), Health Promotion (better health and well-being), Healthy Hearing (audiology), MedFest (sports physical exam), Opening Eyes (vision) and Special Smiles (dentistry). Screenings educate athletes on health and also identify problems that may need additional follow-up.
Since the Healthy Athletes program began, Special Olympics has become the largest global public health organization dedicated to serving people with intellectual disabilities. So far, more than 1.4 million Healthy Athletes screenings have been conducted for people with intellectual disabilities all around the world.
The Special Olympics health initiative has attracted high-profile partners, including the Hear the World Foundation, which screened more than 1,000 athletes during the most recent World Winter Games in Korea; more than 200 of them were found to have hearing loss.
In 2012, the Special Olympics Healthy Communities initiative launched in eight countries—Kazakhstan, Malawi, Malaysia, Mexico, Peru, Romania, South Africa and Thailand, as well as six U.S. states. The goal is to improve the health and well-being of people with intellectual disabilities and allow them to reach their full potential.
Criticism.
The Special Olympics program has occasionally been the subject of criticism. Scholar Keith Storey summarized many such objections in a 2004 article.
In previous years, some have felt that the Special Olympics in itself are a form of segregation. This is because of the necessity to have a disability to participate. Storey argues that since some studies have shown that Special Olympic events do not lead to the reduction of prejudice and also reinforces negative stereotypes of people with intellectual disabilities. One of the main arguments against the Special Olympics organization, according to Storey, is that there is a lack of normalization and promotion of negative images. The lack of normalization comes from the differences in reaction to events. For example, in previous years the Special Olympics would find people to stand at the finish line to hug the athletes once they've completed a race. Also, the Special Olympics do not announce anyone who's lost a race.
There are many other reasons that people object to Special Olympics, such as: perceived promotion of ableism, the alleged promotion of corporations, and degrading paternalism toward athletic ability. The integration of Corporations within the Special Olympics does help with fundraising and creates a large sum of donations to make these games possible. Yet, critics argue, such corporate involvement in Special Olympics is shallow public relations strategy that does little or nothing to integrate those with intellectual disabilities into the workforce at companies that sponsor Special Olympics. The term Paternalism, in this context, is used to describe posited problems with how the Special Olympics Organization is run. The board of directors have recognized only two of their board to have developmental disabilities. Therefore, the people doing the decision making and have the power of running this program are the people without disabilities. This double-standard, it is argued, reflects poorly on the Disability rights movement where people with disabilities control the service delivery system rather than relying on people without disabilities.

</doc>
<doc id="42716" url="https://en.wikipedia.org/wiki?curid=42716" title="Nelly Furtado">
Nelly Furtado

Nelly Kim Furtado , ComIH (born December 2, 1978) is a Canadian singer and songwriter. She has sold 20 million albums worldwide and more than 20 million singles, bringing her total sales to over 40 million records around the world. Furtado first gained fame with her debut album, "Whoa, Nelly!", which spawned two successful singles, "I'm Like a Bird" and "Turn Off the Light". "I'm Like A Bird" won a 2001 Juno Award for Single of the Year and a 2002 Grammy Award for Best Female Pop Vocal Performance. In 2003, Furtado released "Folklore", which produced three international singles: "Powerless (Say What You Want)", "Try", and "Força".
Three years later, she released "Loose", a worldwide commercial success with 10 million copies sold. The album spawned two number-one hits: "Promiscuous" and "Say It Right." After a three-year break, she released her first full-length Spanish album, "Mi Plan", and Furtado received a Latin Grammy for Best Female Pop Vocal Album. In 2012, Furtado's fourth English-language studio album, "The Spirit Indestructible", was released.
Furtado's work has earned her numerous awards and accolades, including a Grammy Award, 10 Juno Awards, three MuchMusic Video Awards and a star on Canada's Walk of Fame. Furtado was awarded "Commander of the Order of Prince Henry" on February 28, 2014, in Toronto by Aníbal Cavaco Silva, the former President of Portugal.
Early life.
Furtado was born on December 2, 1978, in Victoria, British Columbia, Canada. Her Portuguese parents, Maria Manuela and António José Furtado, were both from São Miguel Island in the Azores and had emigrated to Canada in the late 1960s. Nelly was named after Soviet gymnast Nellie Kim. Her siblings are Michael Anthony and Lisa Anne. They were raised Roman Catholic. At age four, she began performing and singing in Portuguese. Furtado's first public performance was when she sang a duet with her mother at a church on Portugal Day. She began playing musical instruments at the age of nine, learning the trombone, ukulele and – in later years – the guitar and keyboards. At the age of 12, she began writing songs, and as a teenager, she performed in a Portuguese marching band.
Furtado has acknowledged her family as the source of her strong work ethic; she spent eight summers working as a chambermaid with her mother, along with her brother and sister, who was a housekeeper in Victoria. She has stated that coming from a working-class background has shaped her identity in a positive way.
Career.
1996–99: Career beginnings.
During a visit with her sister Lisa Anne in Toronto, the summer after grade eleven, Furtado met Tallis Newkirk, member of the hip hop group Plains of Fascination. She contributed vocals to their 1996 album, "Join the Ranks," on the track "Waitin' 4 The Streets." After graduating from Mount Douglas Secondary School in 1996, she moved to Toronto to reside with her sister Lisa Anne. The following year, she formed Nelstar, a trip hop duo with Newkirk. Ultimately, Furtado felt the trip-hop style of the duo was "too segregated," and believed it did not represent her personality or allow her to showcase her vocal ability. She left the group and planned to move back home.
In 1997, she performed at the Honey Jam talent show. Her performance attracted the attention of The Philosopher Kings singer Gerald Eaton, who then approached her to write with him. He and fellow Kings member Brian West helped Furtado produce a demo. She left Toronto, but returned again to record more material with Eaton and West. The material recorded during these sessions was shopped to record companies by her attorney Chris Taylor and led to her 1999 record deal with DreamWorks Records, signed by A&R executive Beth Halper, partner of Garbage drummer and record producer Butch Vig. Furtado's first single, "Party's Just Begun (Again)", was released that year on the "".
2000–05: "Whoa, Nelly!" and "Folklore".
Furtado continued the collaboration with Eaton and West, who co-produced her debut album, "Whoa, Nelly!", which was released in October 2000. The album was an international success, supported by three international singles: "I'm like a Bird", "Turn off the Light", and "...On the Radio (Remember the Days)". It received four Grammy nominations in 2002, and her debut single won for Best Female Pop Vocal Performance. Furtado's work was also critically acclaimed for her innovative mixture of various genres and sounds. "Slant Magazine" called the album "a delightful and refreshing antidote to the army of 'pop princesses' and rap-metal bands that had taken over popular music at the turn of the millennium". The sound of the album was strongly influenced by musicians who had traversed cultures and "the challenge of making heartfelt, emotional music that's upbeat and hopeful". According to "Maclean's" magazine, "Whoa, Nelly!" had sold six million copies worldwide as of August 2006. Portions of the song "Scared of You" are in Portuguese, while "Onde Estás" is entirely in Portuguese, reflecting Furtado's Portuguese heritage. Following the release of the album, Furtado headlined the "Burn in the Spotlight Tour" and also appeared on Moby's "Area:One" tour.
In 2002, Furtado appeared on the song "Thin Line", on underground hip hop group Jurassic 5's album "Power in Numbers". The same year, Furtado provided her vocals to the Paul Oakenfold song "The Harder They Come" from the album "Bunkka". She also had a collaboration with Colombian artist Juanes in the song "Fotografía" ("Photograph"), where she showed her diversity of yet another language, Spanish. Furtado was also featured in "Breath" from Swollen Members' "Monsters in the Closet" release; the video for "Breath," directed by Spawn creator Todd McFarlane, won the 2003 Western Canadian Music Awards Outstanding Video and MuchVIBE Best Rap Video.
Furtado's second album, "Folklore", was released in November 2003. One of the tracks on the album, "Childhood Dreams", was dedicated to her daughter, Nevis. The album includes the single "Força" (meaning "strength"/ "power" or "you can do it!" in Portuguese), the official anthem of the 2004 European Football Championship. Furtado performed this song in Lisbon at the championship's final, in which Portugal's national team played. The lead single released was "Powerless (Say What You Want)" and the second single was the ballad "Try". The album was not as successful as her debut, partly due to the album's less "poppy" sound, as well as underpromotion from her label DreamWorks Records. DreamWorks had just been sold to Universal Music Group at the time of the album's release. Eventually in 2005, DreamWorks Records, along with many of its artists, including Furtado, were absorbed into Geffen Records. "Powerless (Say What You Want)" was later remixed into a Spanish version called "Abre Tu Corazón", featuring Juanes, who had previously worked with Furtado on his track "Fotografía". The two would collaborate again on "Te Busqué" ("I Searched For You"), a single from Furtado's 2006 album "Loose".
2006–08: "Loose".
Furtado's third album, named "Loose", after the spontaneous, creative decisions she made while creating the album, was released in June 2006. In this album, primarily produced by Timbaland, Furtado experiments with sounds from R&B, hip hop, and 1980s music. Furtado herself describes the album's sound as "punk-hop", described as "modern, poppy, spooky" and as having "a mysterious, after-midnight vibe... extremely visceral". She attributed the youthful sound of the album to the presence of her two-year-old daughter. The album received generally positive reviews from critics, with some citing the "revitalising" effect of Timbaland on Furtado's music, and others calling it "slick, smart and surprising".
"Loose" has become the most successful album of Furtado's career so far, as it reached number one, not only in Canada and the United States, but also several countries worldwide. The album produced her first number-one hit in the United States, "Promiscuous", as well as her first number-one hit in the United Kingdom, "Maneater". The single "Say It Right" eventually became Furtado's most successful song worldwide, due to its huge success in Europe and in the United States, where it became her second number-one hit. "All Good Things (Come to an End)" became her most successful song in Europe, topping single charts in numerous countries there.
On February 16, 2007, Furtado embarked on the "Get Loose Tour". She returned in March 2007 to her hometown of Victoria to perform a concert at the Save-On Foods Memorial Centre. In honour of her visit, local leaders officially proclaimed March 21, 2007, the first day of spring, as Nelly Furtado Day. After the tour, she released her first live DVD/CD named "Loose the Concert". On April 1, 2007, Furtado was a performer and host of the 2007 Juno Awards in Saskatoon, Saskatchewan. She won all five awards for which she was nominated, including Album of the Year and Single of the Year. She also appeared on stage at the Concert for Diana at Wembley Stadium in London on July 1, 2007, where she performed "Say It Right", "Maneater", and "I'm like a Bird". In 2007, Furtado and Justin Timberlake were featured on Timbaland's single "Give It to Me", which became her third number-one single in the U.S. and second in the UK. In late 2008, Furtado collaborated with James Morrison on a song called "Broken Strings" for his album "Songs for You, Truths for Me". The single was released on December 8 and peaked at No.2 on the UK Singles Chart in early January. In 2008, she sang with the Italian group "Zero Assoluto" the ballad Win or Lose – Appena prima di partire, released in Italy, France and Germany and whose video was shot in Barcelona. Furtado made a guest appearance on Flo Rida's new album, "R.O.O.T.S.". Furtado also made a guest appearance on Divine Brown's "Love Chronicles", co-writing and singing on the background of the song "Sunglasses". Furtado married Cuban sound engineer Demacio "Demo" Castellón, with whom she had worked on the "Loose" album, on July 19, 2008.
2009–11: "Mi Plan" and "The Best of Nelly Furtado".
Furtado's debut Spanish album, "Mi Plan" was released with the first single, "Manos Al Aire" ("Hands in the Air"). She had formed her own record label, Nelstar, in conjunction with Canadian independent label group Last Gang Labels. The first act signed to Nelstar is Fritz Helder & the Phantoms. "Manos al Aire" was released on the new label. The second, third and fourth singles were "Más", "Mi Plan" and "Bajo Otra Luz" respectively. Furtado won the Latin Grammy Award for Best Female Pop Vocal Album for "Mi Plan". She is the first Canadian to win a Latin Grammy award. Furtado also recorded "Manos al Aire" in Simlish for the new The Sims 3 expansion, World Adventures. "Lifestyle", her planned fourth English studio album, was not released during the summer of 2010 in favor a second leg of her "Mi Plan Tour". To promote the tour in Brazil, on March 24, 2010, Furtado made a ""VIP Pocket Show"" in reality show program Big Brother Brasil 10 from Rede Globo, the country's leading channel. Furtado participated in the live DVD recording of the Brazilian singer Ivete Sangalo in Madison Square Garden on September 4, 2010. Furtado released "Mi Plan Remixes" featuring 12 tracks of remixed hits from "Mi Plan." This album included the Original Spanglish Version of "Fuerte", her final release from "Mi Plan". Furtado made a guest appearance on Canadian singer k-os's new album "Yes!", collaborating alongside Saukrates on the song "I Wish I Knew Natalie Portman," released in early July 2009. Nelly Furtado also made a guest appearance on Tiësto's single "Who Wants to Be Alone" on his new album "Kaleidoscope". Furtado sang in a duet with Bryan Adams at the opening ceremonies of the 2010 Vancouver Winter Olympic Games. The song was called "Bang The Drum" released on EMI album "Sounds Of Vancouver 2010" (a commemorative album). Furtado is featured in a new song by N.E.R.D. called "Hot N Fun". She also participated in the Young Artists for Haiti song, in which many Canadian artists came together and sang K'naan's inspirational song "Wavin' Flag" to raise money for the victims of the Haiti Earthquake. Furtado was honoured with a star on Canada's Walk of Fame in October 2010.
Furtado released her first greatest hits album titled "The Best of Nelly Furtado" on November 16, 2010. Three new songs were included on the greatest hits album, including "Night Is Young", "Girlfriend in the City", and the Lester Mendez produced track, left over from the "Loose" sessions, "Stars". The album's first single, "Night Is Young", was released on October 12, 2010. Furtado had previously sung two of the new songs: "Girlfriend in the City" and "Night Is Young" at her concert in Warsaw, Poland.
Furtado came under fire after 2011 reports from the "New York Times" and a WikiLeaks document revealed she had accepted payment of one million dollars to perform for the family of Libyan ruler Muammar Gaddafi. Only after the story broke did she promise to donate to charity the CDN$1 million she received for a 2007 concert, which ended up going to Free the Children.
Furtado publicly endorsed Green Party leader Elizabeth May in Saanich-Gulf Islands during the federal election in 2011. Furtado was featured on one of the Game's The R.E.D. Album tracks, titled "Mamma Knows" (produced by The Neptunes). For the Canadian film The Year Dolly Parton Was My Mom, Furtado lent her vocals for the Dolly Parton gospel cover "The Seeker" featured during the credits of the film. Furtado collaborated with recording artist Alex Cuba and K'naan once again. The duet with K'naan "Is Anybody Out There", was released as the first single from his extended play "More Beautiful than Silence".
2012–2015: "The Spirit Indestructible".
"The Spirit Indestructible" was released in September 2012. Furtado previously proclaimed that the album was most like her 2000 debut "Whoa, Nelly!", but containing elements from urban, alternative, and reggae. The influences for the album range from Janelle Monáe, The xx, to Florence + the Machine. The album had input from producers such as The Neptunes, Tiësto, Timbaland, Rick Nowels, Ryan Tedder and Rodney Jerkins. The first single from "The Spirit Indestructible", "Big Hoops (Bigger the Better)", was released digitally on April 17, 2012 and was sent to North American radio stations on May 1, 2012. Furtado continued to collaborate with hip-hop producer Salaam Remi, who previously worked on the 2010 single "Night Is Young", on "The Edge". The lyrics for the Salaam Remi produced track are reported to be influenced by the Tiger Woods cheating scandal, in which was originally referred to as "Elin's Song". On July 2, 2013 Furtado performed a new track, the acoustic ballad "Mystery", from her upcoming studio album. Furtado promoted the album on her The Spirit Indestructible Tour.
2016-present: Sixth studio album.
On February 14, 2016, Furtado performed the Canadian National Anthem at the 2016 NBA All-Star Game which was held in Toronto. That same month, she also began teasing new music via social media, suggesting that the album would have a connection to Dallas, Texas, where much of the album was recorded.
Personal life.
On September 20, 2003, Furtado gave birth to daughter Nevis Chetan in Toronto with then-boyfriend Jasper Gahunia. Furtado and Gahunia, who had been good friends for several years, remained together for four years until their breakup in 2005. Furtado told "Blender" magazine that they continue to be good friends and jointly share responsibility of raising Nevis. In a June 2006 interview with "Genre" magazine, when asked if she had "ever felt an attraction to women", Furtado replied "Absolutely. Women are beautiful and sexy". Some considered this an announcement of bisexuality, but in August 2006, she stated that she was "straight, but very open-minded". In November 2006, Furtado revealed that she once turned down US$500,000 to pose fully clothed in "Playboy". On July 19, 2008, Furtado married sound engineer Demacio Castellon.
Philanthropy.
Furtado hosted a program about AIDS on MTV, which also featured guests Alicia Keys and Justin Timberlake. On September 27, 2011, Furtado announced during Free the Children's We Day Toronto, that she was giving CDN$1,000,000 to Free the Children's effort to build girls' schools in the Maasai region of Kenya.
Artistry.
During her pre-teenage to teenage years, Furtado embraced many musical genres, listening heavily to mainstream R&B, hip hop, alternative hip hop, drum and bass, trip hop, world music (including Portuguese fado, Brazilian bossa nova and Indian music), and a variety of others. Her biggest influence when growing up was Ani DiFranco, she explained that "hen I was a teenager, I wanted to be (the feminist punk-folk singer) Ani DiFranco. I never wanted to be part of corporate music." She cites diverse influences, including Madonna, Blondie, Prince, The Police, Eurythmics, Talking Heads, De La Soul, TLC, Nusrat Fateh Ali Khan, Amalia Rodrigues, Caetano Veloso, Juanes, Jeff Buckley, Esthero, Björk, Cornershop, Oasis, Radiohead, The Smashing Pumpkins and Beck. Furtado's music has also been influenced by her current residence, Toronto, which she calls "the most multicultural city in the entire world" and a place where she "can be any culture". Regarding Toronto's cultural diversity, she has said that she did not have to wait for the Internet revolution to learn about world music; she began listening to it at the age of five and continues to discover new genres.

</doc>
<doc id="42719" url="https://en.wikipedia.org/wiki?curid=42719" title="Do it yourself">
Do it yourself

Do it yourself, also known as DIY, is the method of building, modifying, or repairing something without the direct aid of experts or professionals. Academic research describes DIY as behaviors where "individuals engage raw and semi-raw materials and component parts to produce, transform, or reconstruct material possessions, including those drawn from the natural environment (e.g. landscaping)". DIY behavior can be triggered by various motivations previously categorized as marketplace motivations (economic benefits, lack of product availability, lack of product quality, need for customization), and identity enhancement (craftsmanship, empowerment, community seeking, uniqueness)
The term "do-it-yourself" has been associated with consumers since at least 1912 primarily in the domain of home improvement and maintenance activities. The phrase "do it yourself" had come into common usage (in standard English) by the 1950s, in reference to the emergence of a trend of people undertaking home improvement and various other small craft and construction projects as both a creative-recreational and cost-saving activity.
Subsequently, the term DIY has taken on a broader meaning that covers a wide range of skill sets. DIY is associated with the international alternative rock, punk rock, and indie rock music scenes; indymedia networks, pirate radio stations, and the zine community. In this context, DIY is related to the Arts and Crafts movement, in that it offers an alternative to modern consumer culture's emphasis on relying on others to satisfy needs. The abbreviation DIY is also widely used in the military as a way to teach commanders or other types of units to take responsibility, so that they'd be able to do things themselves just as a preparation for their own future.
History.
Italian archaeologists unearthed the ruins of a 6th-century BC Greek structure in southern Italy that came with detailed assembly instructions and is being called an "ancient IKEA building". The structure was a temple-like building discovered at Torre Satriano, near the southern city of Potenza, in Basilicata, a region where local people mingled with Greeks who settled along the southern coast known as Magna Graecia and in Sicily from the 8th century BC onwards. Professor Christopher Smith, director of the British School at Rome, said that the discovery was "the clearest example yet found of mason's marks of the time. It looks as if someone was instructing others how to mass-produce components and put them together in this way". Much like the instruction booklets, various sections of the luxury building were inscribed with coded symbols showing how the pieces slotted together. The characteristics of these inscriptions indicate they date back to around the 6th century BC, which tallies with the architectural evidence suggested by the decoration. The building was built by Greek artisans coming from the Spartan colony of Taranto in Apulia.
Home improvement.
The DIY movement is a re-introduction (often to urban and suburban dwellers) of the old pattern of personal involvement and use of skills in upkeep of a house or apartment, making clothes; maintenance of cars, computers, websites; or any material aspect of living. The philosopher Alan Watts (from the "Houseboat Summit" panel discussion in a 1967 edition of the "San Francisco Oracle") reflected a growing sentiment:
In the 1970s, DIY spread through the North American population of college- and recent-college-graduate age groups. In part, this movement involved the renovation of affordable, rundown older homes. But it also related to various projects expressing the social and environmental vision of the 1960s and early 1970s. The young visionary Stewart Brand, working with friends and family, and initially using the most basic of typesetting and page-layout tools, published the first edition of "The Whole Earth Catalog" (subtitled "Access to Tools") in late 1968.
The first "Catalog", and its successors, used a broad definition of the term "tools". There were informational tools, such as books (often technical in nature), professional journals, courses, classes, and the like. There were specialized, designed items, such as carpenters' and masons' tools, garden tools, welding equipment, chainsaws, fiberglass materials and so on; even early personal computers. The designer J. Baldwin acted as editor to include such items, writing many of the reviews. The "Catalog"'s publication both emerged from and spurred the great wave of experimentalism, convention-breaking, and do-it-yourself attitude of the late 1960s. Often copied, the "Catalog" appealed to a wide cross-section of people in North America and had a broad influence.
For decades, magazines such as "Popular Mechanics" and "Mechanix Illustrated" offered a way for readers to keep current on useful practical skills and techniques. DIY home improvement books began to flourish in the 1970s, first created as collections of magazine articles. An early, extensive line of DIY how-to books was created by Sunset Books, based upon previously published articles from their magazine, "Sunset", based in California. Time-Life, Better Homes and Gardens, and other publishers soon followed suit.
In the mid-1990s, DIY home-improvement content began to find its way onto the World Wide Web. HouseNet was the earliest bulletin-board style site where users could share information. HomeTips.com, established in early 1995, was among the first Web-based sites to deliver free extensive DIY home-improvement content created by expert authors. Since the late 1990s, DIY has exploded on the Web through thousands of sites.
In the 1970s, when home video (VCRs) came along, DIY instructors quickly grasped its potential for demonstrating processes by audio-visual means. In 1979, the PBS television series "This Old House", starring Bob Vila, premiered and this spurred a DIY television revolution. The show was immensely popular, educating people on how to improve their living conditions (and the value of their house) without the expense of paying someone else to do (as much of) the work. In 1994, the HGTV Network cable television channel was launched in the United States and Canada, followed in 1999 by the DIY Network cable television channel. Both were launched to appeal to the growing percentage of North Americans interested in DIY topics, from home improvement to knitting. Such channels have multiple shows showing how to stretch one's budget to achieve professional-looking results ("Design Cents", "Design on a Dime", etc.) while doing the work yourself. "Toolbelt Diva" specifically caters to female DIYers.
Beyond magazines and television, the scope of home improvement DIY continues to grow online where most mainstream media outlets now have extensive DIY-focused informational websites such as "This Old House", Martha Stewart, Hometalk, and the DIY Network. These are often extensions of their magazine or television brand. The growth of independent online DIY resources is also spiking. The number of homeowners who blog about their experiences continues to grow, along with DIY websites from smaller organizations.
Fashion.
DIY amongst the fashion community is popular. With ideas being shared on social media such as YouTube about clothing, jewellery and hair styles. Techniques include distressing jeans, bleaching jeans, redesigning an old shirt, and studding denim. This trend is becoming popular.
Subculture.
The terms "DIY" and "do-it-yourself" are also used to describe:
DIY as a subculture could be said to have begun with the punk movement of the 1970s. Instead of traditional means of bands reaching their audiences through large music labels, bands began recording, manufacturing albums and merchandise, booking their own tours, and creating opportunities for smaller bands to get wider recognition and gain cult status through repetitive low-cost DIY touring. The burgeoning zine movement took up coverage of and promotion of the underground punk scenes, and significantly altered the way fans interacted with musicians. Zines quickly branched off from being hand-made music magazines to become more personal; they quickly became one of the youth culture's gateways to DIY culture. This led to tutorial zines showing others how to make their own shirts, posters, zines, books, food, etc.
Groups and Publications.
Publications and websites that focus on DIY and/or crafting content include:

</doc>
