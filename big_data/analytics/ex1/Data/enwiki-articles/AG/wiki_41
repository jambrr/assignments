<doc id="42895" url="https://en.wikipedia.org/wiki?curid=42895" title="Walvis Bay">
Walvis Bay

Walvis Bay (Afrikaans "Walvisbaai", German "Walfischbucht" or "Walfischbai", all meaning "Whale Bay") is a city in Namibia and the name of the bay on which it lies. The town has 85,000 inhabitants and has a total area of of land.
The bay is a safe haven for sea vessels because of its natural deepwater harbour, protected by the Pelican Point sand spit, being the only natural harbour of any size along the country's coast. Being rich in plankton and marine life, these waters also drew large numbers of Southern right whales, attracting whalers and fishing vessels.
The Dutch referred to it as Walvisch Baye and the English as Whale Bay. In its eventual formal incorporation, it was named Walfish Bay, which was changed to Walvish Bay, and ultimately to Walvis Bay. It has also been referred to as Walwich Bay or Walwisch Bay. The Herero people of the area called it Ezorongondo.
A succession of colonists developed the location and resources of this strategic harbour settlement. The harbour's value in relation to the sea route around the Cape of Good Hope had caught the attention of world powers since it was discovered by the outside world in 1485. This explains the complicated political status of Walvis Bay down the years.
The town is situated just north of the Tropic of Capricorn in the Kuiseb River delta and lies at the end of the TransNamib Railway to Windhoek, and on the B2 road.
Walvis Bay, with its large bay and sand dunes, is an important centre of tourism activity in Namibia. Attractions include the artificial Bird Island, centre of a guano collection industry, the Dune 7 sand dune, the salt works, the abundant birdlife, and a museum. Kuisebmund Stadium, home to two clubs in the Namibia Premier League, is also located in the city. The beach resort of Langstrand lies just a few kilometres north. The Walvis Bay Export Processing Zone is an important facet of the local economy.
History.
The Portuguese navigator Diogo Cão reached Cape Cross, north of the bay, in 1485. There followed Bartolomeu Dias, who anchored his flagship "São Cristóvão" in what is now Walvis Bay on 8 December 1487, on his expedition to discover a sea route to the East via the Cape of Good Hope. He named the bay "O Golfo de Santa Maria da Conceição." However, the Portuguese did not formally stake a claim to Walvis Bay.
Little commercial development occurred on the site until the late 19th century. During the scramble for Africa, the United Kingdom occupied Walvis Bay and a small area surrounding the territory, and permitted the Cape Colony to annex it in 1884, although the initial steps to do so had been taken in 1878.
In 1910, Walvis Bay, as part of the Cape Colony, became part of the newly formed Union of South Africa. Subsequently, a dispute arose with Germany over the exclave's boundaries, which was eventually settled in 1911, with Walvis Bay being allocated an area of .
The exclave was overrun by the Germans during the South West Africa Campaign early in World War I, but South African Forces eventually ousted the Germans in 1915. Subsequently, Walvis Bay was quickly integrated into the new martial law regime established in South West Africa.
South Africa was later awarded control (a Class "C" mandate) over South West Africa by the League of Nations to administer the territory. Civilian rule was restored in South-West Africa in 1921 and administration of Walvis Bay was transferred to South-West Africa under the South West Africa Affairs Act of 1922.
Despite the territory never having been part of German South West Africa, the Act stated that: "the port and settlement of Walvis Bay, which forms part of the Cape of Good Hope, shall for judicial and administrative purposes be regarded as if it were part of the mandated territory of South West Africa". However, South Africa had also sought to annex South West Africa itself, and had presented such a proposal to the League of Nations. Consequently, in 1949, the Act was amended to give representation in the Parliament of South Africa to whites in South West Africa.
In 1977, following increasing international pressure to relinquish its control over South West Africa, South Africa repealed the Act, but transferred control of Walvis Bay back to the Cape Province, thereby making it an exclave. From 1980, it was represented in both the Provincial Council and the House of Assembly as part of the Green Point constituency in Cape Town, before becoming a separate constituency in 1982.
In response, the United Nations Security Council passed Resolution 432 (1978), which declared that "the territorial integrity and unity of Namibia must be assured through the reintegration of Walvis Bay within its territory".
In 1990, South-West Africa gained independence as Namibia, but Walvis Bay remained under South African sovereignty, with South Africa increasing the number of troops. However, in 1992, the two countries agreed to establish a transitional Joint Administrative Authority for Walvis Bay and the Offshore Islands. The Authority was headed by two Chief Executive Officers, Nangolo Mbumba, then Secretary to the Namibian Cabinet, and Carl von Hirschberg, former South African Ambassador to the United Nations.
In August 1993, prior to the end of apartheid, the Multiparty Negotiating Forum, in South Africa passed a resolution calling for "the incorporation-reintegration of Walvis Bay and the Off-Shore Islands into Namibia." 
The Transfer of Walvis Bay to Namibia Act was passed by the Parliament of South Africa that year. Following the signing of a treaty between the two countries, South Africa formally transferred sovereignty of Walvis Bay and the Penguin Islands to Namibia on 1 March 1994.
Education.
Walvis Bay has a number of public (government-run) and private schools, among them Duinesig Primary School, International School of Walvis Bay, Kuisebmond Secondary School, Walvis Bay Private High School and others. A number of kindergartens cater for young children.
The Namibian Maritime and Fisheries Institute (NAMFI) is a tertiary education institution based in town. International University of Management (IUM) and Monitronics Success College both have branches in Walvis Bay.
Fishing.
In Walvis Bay there are different fishing companies like Hangana Seafood, Caroline Fishing, Benguella Fishing Company, Etale Fishing Company, Cadilu Fishing, Etosha Fisheries, Kuiseb Fishing Enterprises, Blue Ocean Products, Benguella Sea Products, Consortium Fisheries, Talanam Fish Processor. These companies catch different types of fish like snoek, horse mackerel, anchovy, steenbras, kabeljou, kingklip, hake, catfish, tuna, and sardines. Hangana Seafood are processors and exporters of fish and fish products.
As such, the fishing enterprise accounts for a major part of Walvis Bay's economy.
Entertainment and sport.
Walvis Bay contains open spaces, scenic beauty and unique marine and plant life. It is well suited for the outdoor lifestyle, boasting sports such as sandboarding, kiting, surfing, swimming, angling, sailing, golf and other indoor and outdoor sport codes. There is Walvis Bay Lagoon and Aquatic Activities, Kuiseb River Delta and the beach itself where people enjoy swimming and catching fish.
The 2 km sand spit allows the adjacent water to remain smooth in very strong winds, ideal for record attempting vessels like Vestas Sailrocket
It is home to Eleven Arrows F.C. and Blue Waters F.C., local football clubs that compete in the Namibia Premier League.
Climate.
Walvis Bay features the very rare mild variation of the arid climate ("BWn", according to the Köppen climate classification). Walvis Bay receives an average of less than 10 mm of precipitation per year, making it one of the driest cities on the planet. Despite the fact that it has an arid climate, Walvis Bay seldom gets very hot or very cold, an extremely unusual feature for a city featuring this climate; this is primarily due to cold offshore currents near Walvis Bay.
Politics.
Walvis Bay is governed by a municipal council that has ten seats.
Twin towns – Sister cities.
Walvis Bay is twinned with:
Gallery.
Walvis Bay on Wikimedia Commons.

</doc>
<doc id="42896" url="https://en.wikipedia.org/wiki?curid=42896" title="Viscometer">
Viscometer

A viscometer (also called viscosimeter) is an instrument used to measure the viscosity of a fluid. For liquids with viscosities which vary with flow conditions, an instrument called a rheometer is used. Viscometers only measure under one flow condition.
In general, either the fluid remains stationary and an object moves through it, or the object is stationary and the fluid moves past it. The drag caused by relative motion of the fluid and a surface is a measure of the viscosity. The flow conditions must have a sufficiently small value of Reynolds number for there to be laminar flow.
At 20.00 degrees Celsius the dynamic viscosity (kinematic viscosity x density) of water is 1.0038 mPa·s and its kinematic viscosity (product of flow time x Factor) is 1.0022 mm2/s. These values are used for calibrating certain types of viscometers.
Standard laboratory viscometers for liquids.
U-tube viscometers.
These devices are also known as glass capillary viscometers or Ostwald viscometers, named after Wilhelm Ostwald. Another version is the Ubbelohde viscometer, which consists of a U-shaped glass tube held vertically in a controlled temperature bath. In one arm of the U is a vertical section of precise narrow bore (the capillary). Above there is a bulb, with it is another bulb lower down on the other arm. In use, liquid is drawn into the upper bulb by suction, then allowed to flow down through the capillary into the lower bulb. Two marks (one above and one below the upper bulb) indicate a known volume. The time taken for the level of the liquid to pass between these marks is proportional to the kinematic viscosity. Most commercial units are provided with a conversion factor, or can be calibrated by a fluid of known properties.
The time required for the test liquid to flow through a capillary of a known diameter of a certain factor between two marked points is measured. By multiplying the time taken by the factor of the viscometer, the kinematic viscosity is obtained.
Such viscometers can be classified as direct flow or reverse flow. Reverse flow viscometers have the reservoir above the markings and direct flow are those with the reservoir below the markings. Such classifications exist so that the level can be determined even when opaque or staining liquids are measured, otherwise the liquid will cover the markings and make it impossible to gauge the time the level passes the mark. This also allows the viscometer to have more than 1 set of marks to allow for an immediate timing of the time it takes to reach the 3rd mark, therefore yielding 2 timings and allowing for subsequent calculation of Determinability to ensure accurate results. The use of two timings in one viscometer in a single run is only possible if the sample being measured has Newtonian properties. Otherwise the change in driving head which in turn changes the shear rate will produce a different viscosity for the two bulbs.
Falling sphere viscometers.
Stokes' law is the basis of the falling sphere viscometer, in which the fluid is stationary in a vertical glass tube. A sphere of known size and density is allowed to descend through the liquid. If correctly selected, it reaches terminal velocity, which can be measured by the time it takes to pass two marks on the tube. Electronic sensing can be used for opaque fluids. Knowing the terminal velocity, the size and density of the sphere, and the density of the liquid, Stokes' law can be used to calculate the viscosity of the fluid. A series of steel ball bearings of different diameter are normally used in the classic experiment to improve the accuracy of the calculation. The school experiment uses glycerine as the fluid, and the technique is used industrially to check the viscosity of fluids used in processes. It includes many different oils, and polymer liquids such as solutions.
In 1851, George Gabriel Stokes derived an expression for the frictional force (also called drag force) exerted on spherical objects with very small Reynolds numbers (e.g., very small particles) in a continuous viscous fluid by changing the small fluid-mass limit of the generally unsolvable Navier-Stokes equations:
where:
If the particles are falling in the viscous fluid by their own weight, then a terminal velocity, also known as the settling velocity, is reached when this frictional force combined with the buoyant force exactly balance the gravitational force. The resulting settling velocity (or terminal velocity) is given by:
where:
Note that Stokes flow is assumed, so the Reynolds number must be small.
A limiting factor on the validity of this result is the roughness of the sphere being used.
A modification of the straight falling sphere viscometer is a rolling ball viscometer which times a ball rolling down a slope whilst immersed in the test fluid. This can be further improved by using a patented V plate which increases the number of rotations to distance traveled, allowing smaller more portable devices. This type of device is also suitable for ship board use.
Many instruments have been built that measure a liquid viscosity using the falling sphere principle. Most commercial viscometers make measurements at a constant temperature (that can be selected by the user) to avoid viscosity variations due to temperature and feature an heating system to control the sample fluid temperature to the target value. Different spheres of (known) densities are provided with the instrument to allow the test of liquids of different types. The sphere falling time is measured with a chronometer by the user that enables/disables the counter at the passage of the sphere at the two target points.
On the other hand, a few instruments do not have an heating system and measure the liquid temperature to compensate for viscosity variation due to temperature, such as the electronic portable instrument discussed here that measure viscosity to estimate the oil concentration in cutting fluids and features a temperature sensor and two proximity sensors for automatic measurements.
Falling ball viscometer.
In 1932 Fritz Höppler got a patent for the Falling ball viscometer, named after him - the worldwide first viscometer to determine the dynamic viscosity. More other world-firsts viscometers which were developed by Fritz Höppler in Medingen (Germany) are the Ball Pressure types Consistometer and Rheoviscometer, see Kugeldruckviskosimeter = Ball Pressure Viscometer.
Falling piston viscometer.
Also known as the Norcross viscometer after its inventor, Austin Norcross. The principle of viscosity measurement in this rugged and sensitive industrial device is based on a piston and cylinder assembly. The piston is periodically raised by an air lifting mechanism, drawing the material being measured down through the clearance (gap) between the piston and the wall of the cylinder into the space which is formed below the piston as it is raised. The assembly is then typically held up for a few seconds, then allowed to fall by gravity, expelling the sample out through the same path that it entered, creating a shearing effect on the measured liquid, which makes this viscometer particularly sensitive and good for measuring certain thixotropic liquids. The time of fall is a measure of viscosity, with the clearance between the piston and inside of the cylinder forming the measuring orifice. The viscosity controller measures the time of fall (time-of-fall seconds being the measure of viscosity) and displays the resulting viscosity value. The controller can calibrate the time-of-fall value to cup seconds (known as efflux cup), Saybolt universal second (SUS) or centipoise.
Industrial use is popular due to simplicity, repeatability, low maintenance and longevity. This type of measurement is not affected by flow rate or external vibrations. The principle of operation can be adapted for many different conditions, making it ideal for process control environments.
Oscillating piston viscometer.
Sometimes referred to as electromagnetic viscometer or EMV viscometer, was invented at Cambridge Viscosity (Formally Cambridge Applied Systems) in 1986. The sensor (see figure below) comprises a measurement chamber and magnetically influenced piston. Measurements are taken whereby a sample is first introduced into the thermally controlled measurement chamber where the piston resides. Electronics drive the piston into oscillatory motion within the measurement chamber with a controlled magnetic field. A shear stress is imposed on the liquid (or gas) due to the piston travel and the viscosity is determined by measuring the travel time of the piston. The construction parameters for the annular spacing between the piston and measurement chamber, the strength of the electromagnetic field, and the travel distance of the piston are used to calculate the viscosity according to Newton’s Law of Viscosity.
The oscillating piston viscometer technology has been adapted for small sample viscosity and micro-sample viscosity testing in laboratory applications. It has also been adapted to measure high pressure viscosity and high temperature viscosity measurements in both laboratory and process environments. The viscosity sensors have been scaled for a wide range of industrial applications such as small size viscometers for use in compressors and engines, flow-through viscometers for dip coating processes, in-line viscometers for use in refineries, and hundreds of other applications. Improvements in sensitivity from modern electronics, is stimulating a growth in oscillating piston viscometer popularity with academic laboratories exploring gas viscosity.
Vibrational viscometers.
Vibrational viscometers date back to the 1950s Bendix instrument, which is of a class that operates by measuring the damping of an oscillating electromechanical resonator immersed in a fluid whose viscosity is to be determined. The resonator generally oscillates in torsion or transversely (as a cantilever beam or tuning fork). The higher the viscosity, the larger the damping imposed on the resonator. The resonator's damping may be measured by one of several methods:
The vibrational instrument also suffers from a lack of a defined shear field, which makes it unsuited to measuring the viscosity of a fluid whose flow behaviour is not known before hand.
Vibrating viscometers are rugged industrial systems used to measure viscosity in the process condition. The active part of the sensor is a vibrating rod. The vibration amplitude varies according to the viscosity of the fluid in which the rod is immersed. These viscosity meters are suitable for measuring clogging fluid and high-viscosity fluids, including those with fibers (up to 1,000 Pa·s). Currently, many industries around the world consider these viscometers to be the most efficient system with which to measure the viscosities of a wide range of fluids; by contrast, rotational viscometers require more maintenance, are unable to measure clogging fluid, and require frequent calibration after intensive use. Vibrating viscometers have no moving parts, no weak parts and the sensitive part is very small. Even very basic or acidic fluids can be measured by adding a protective coating such as enamel, or by changing the material of the sensor to a material such as 316L stainless steel.
Quartz viscometer.
The quartz viscometer is a special type of vibrational viscometer. Here, an oscillating quartz crystal is immersed into a fluid and the specific influence on the oscillating behavior defines the viscosity. The principle of quartz viscosimetry is based on the idea of W.P. Mason. The basic concept is the application of a piezoelectric crystal for the determination of viscosity. The high-frequent electrical field that is applied to the oscillator causes a movement of the sensor and results in the shearing of the fluid. The movement of the sensor is then influenced by the external forces (the shear stress) of the fluid which affects the electrical response of the sensor. The calibration procedure as a pre-condition of viscosity determination by means of a quartz crystal goes back to B. Bode who facilitated the detailed analysis of the electrical and mechanical transmission behavior of the oscillating system. On the basis of this calibration, the quartz viscosimeter was developed which allows continuous viscosity determination in resting and flowing liquids. 
Rotational viscometers.
Rotational viscometers use the idea that the torque required to turn an object in a fluid is a function of the viscosity of that fluid. They measure the torque required to rotate a disk or bob in a fluid at a known speed.
'Cup and bob' viscometers work by defining the exact volume of a sample which is to be sheared within a test cell; the torque required to achieve a certain rotational speed is measured and plotted. There are two classical geometries in "cup and bob" viscometers, known as either the "Couette" or "Searle" systems - distinguished by whether the cup or bob rotates. The rotating cup is preferred in some cases because it reduces the onset of Taylor vortices, but is more difficult to measure accurately in insument.
'Cone and Plate' viscometers use a cone of very shallow angle in bare contact with a flat plate. With this system the shear rate beneath the plate is constant to a modest degree of precision and deconvolution of a flow curve; a graph of shear stress (torque) against shear rate (angular velocity) yields the viscosity in a straightforward manner.
Electromagnetically spinning sphere viscometer (EMS viscometer).
The EMS Viscometer measures the viscosity of liquids through observation of the rotation of a sphere which is driven by electromagnetic interaction: Two magnets attached to a rotor create a rotating magnetic field. The sample (3) to be measured is in a small test tube (2). Inside the tube is an aluminium sphere (4). The tube is located in a temperature controlled chamber (1) and set such that the sphere is situated in the centre of the two magnets.
The rotating magnetic field induces eddy currents in the sphere. The resulting Lorentz interaction between the magnetic field and these eddy currents generate torque that rotates the sphere. The rotational speed of the sphere depends on the rotational velocity of the magnetic field, the magnitude of the magnetic field and the viscosity of the sample around the sphere. The motion of the sphere is monitored by a video camera (5) located below the cell. The torque applied to the sphere is proportional to the difference in the angular velocity of the magnetic field ΩB and the one of the sphere ΩS. There is thus a linear relationship between (ΩB−ΩS)/ΩS and the viscosity of the liquid.
This new measuring principle was developed by Sakai et al. at the University of Tokyo. The EMS viscometer distinguishes itself from other rotational viscometers by three main characteristics: 
Stabinger viscometer.
By modifying the classic Couette type rotational viscometer, it is possible to combine the accuracy of kinematic viscosity determination with a wide measuring range.
The outer cylinder of the Stabinger Viscometer is a tube that rotates at constant speed in a temperature-controlled copper housing. The hollow internal cylinder – shaped as a conical rotor – is specifically lighter than the filled samples and therefore floats freely within them, centered by centrifugal forces. In this way all bearing friction, an inevitable factor in most rotational devices, is fully avoided. The rotating fluid's shear forces drive the rotor, while a magnet inside the rotor forms an eddy current brake with the surrounding copper housing. An equilibrium rotor speed is established between driving and retarding forces, which is an unambiguous measure of the dynamic viscosity. The speed and torque measurement is implemented without direct contact by a Hall effect sensor counting the frequency of the rotating magnetic field. This allows for a highly precise torque resolution of 50 pN·m and a wide measuring range from 0.2 to 20,000 mPa•s with a single measuring system. A built-in density measurement based on the oscillating U-tube principle allows the determination of kinematic viscosity from the measured dynamic viscosity employing the relation
where:
Bubble viscometer.
Bubble viscometers are used to quickly determine kinematic viscosity of known liquids such as resins and varnishes. The time required for an air bubble to rise is directly proportional to the viscosity of the liquid, so the faster the bubble rises, the lower the viscosity. The Alphabetical Comparison Method uses 4 sets of lettered reference tubes, A5 through Z10, of known viscosity to cover a viscosity range from 0.005 to 1,000 stokes. The Direct Time Method uses a single 3-line times tube for determining the "bubble seconds", which may then be converted to stokes.
This method is considerably accurate, but the measurements can vary due to variances in buoyancy because of the changing in shape of the bubble in the tube However, this does not cause any sort of serious miscalculation.
Rectangular-slit viscometer.
The basic design of a rectangular-slit viscometer/rheometer, as commercially developed by RheoSense, Inc. of San Ramon, CA, consists of a rectangular, slit channel with uniform cross-sectional area. A test liquid is pumped at a constant flow rate through this channel. Multiple pressure sensors flush mounted at linear distances along the stream-wise direction measure pressure drop as depicted in "Figure 1".
Measuring principle: The slit viscometer/rheometer is based on the fundamental principle that a viscous liquid resists flow, exhibiting a decreasing pressure along the length of the slit. The pressure decrease or drop (Δ"P") is correlated with the shear stress at the wall boundary.  The apparent shear rate is directly related to the flow rate and the dimension of the slit. The apparent shear rate, the shear stress, and the apparent viscosity are calculated:
= Apparent Shear Rate (s−1)
σ = Shear Stress (Pa)
"η"a = Apparent Viscosity (Pa-s)
"Δ"P = Pressure difference between the leading pressure sensor and the last pressure sensor (Pa)
"Q" = Flow Rate (ml/s)
"w" = width of the flow channel (mm)
"h" = depth of the flow channel (mm)
"l" = the distance between the leading pressure sensor and the last pressure sensor (mm)
To determine the viscosity of a liquid, pump the liquid sample to flow through the slit channel at a constant flow rate and measure the pressure drop.  Following these equations, calculate the apparent viscosity for the apparent shear rate.  For a Newtonian liquid, the apparent viscosity is the same as the true viscosity and the single shear rate measurement is sufficient.  For non-Newtonian liquids, the apparent viscosity is not true viscosity.  In order to obtain true viscosity, measure the apparent viscosities at multiple apparent shear rates. Then calculate true viscosities, "η", at various shear rates using Weissenberg-Rabinowitsch-Mooney correction factor:
The calculated true viscosity will be the same as the cone and plate value at the same shear rate. 
A modified version of the rectangular-slit viscometer/rheometer can also be used to determine apparent extensional viscosity.
Miscellaneous viscometer types.
Other viscometer types use balls or other objects. Viscometers that can characterize non-Newtonian fluids are usually called "rheometers" or "plastometers".
In the I.C.I "Oscar" viscometer, a sealed can of fluid was oscillated torsionally, and by clever measurement techniques it was possible to measure both viscosity and elasticity in the sample.
The Marsh funnel viscometer measures viscosity from the time ("efflux time") it takes a known volume of liquid to flow from the base of a cone through a short tube. This is similar in principle to the flow cups (efflux cups) like the Ford, Zahn and Shell cups which use different shapes to the cone and various nozzle sizes. The measurements can be done according to ISO 2431, ASTM D1200 - 10 or DIN 53411.
The Flexible blade rheometer improves the accuracy of measurements for the lower viscosity range liquids utilizing the subtle changes in the flow field due to the flexibility of the moving or stationary blade (sometimes called wing or single side clamped cantilever).

</doc>
<doc id="42897" url="https://en.wikipedia.org/wiki?curid=42897" title="Alexander Dubček">
Alexander Dubček

Alexander Dubček (; 27 November 1921 – 7 November 1992) was a Slovak politician and, briefly, leader of Czechoslovakia (1968–1969). He attempted to reform the communist regime during the Prague Spring but he was forced to resign following the Warsaw Pact invasion of Czechoslovakia. Later, after the overthrow of the government in 1989, he was Chairman of the federal Czechoslovak parliament. Also in 1989, the European Parliament awarded Dubček the Sakharov Prize for Freedom of Thought.
Early life.
Dubček was born in Uhrovec, Czechoslovakia, on 27 November 1921 and raised in the Kyrgyz SSR of the Soviet Union (now Kyrgyzstan) as a member of the Esperantist and Idist industrial cooperative Interhelpo. Alexander Dubček was conceived in Chicago, but born after the family relocated to Czechoslovakia. When Alexander Dubček was three, the family moved to the Soviet Union, in part to help build socialism and in part because jobs were scarce in Czechoslovakia. In 1938, the family returned to Czechoslovakia.
During the Second World War, Alexander Dubček joined the underground resistance against the wartime pro-German Slovak state headed by Jozef Tiso. In August 1944, Dubček fought in the Slovak National Uprising and was wounded. His brother, Július, was killed.
Political career.
During the war, Alexander Dubček joined the Communist Party of Slovakia (KSS), which had been created after the formation of the Slovak state and in 1948 was transformed into the Slovak branch of the Communist Party of Czechoslovakia (KSČ).
After the war, he steadily rose through the ranks in Communist Czechoslovakia. From 1951 to 1955 he was a member of the National Assembly, the parliament of Czechoslovakia. In 1953, he was sent to the Moscow Political College, where he graduated in 1958. In 1955 he joined the Central Committee of the Slovak branch and in 1962 became a member of the presidium. In 1958 he also joined the Central Committee of the Communist Party of Czechoslovakia, which he served as a secretary from 1960 to 1962 and as a member of the presidium after 1962. From 1960 to 1968 he once more was a member of the federal parliament.
In 1963, a power struggle in the leadership of the Slovak branch unseated Karol Bacílek and Pavol David, hard-line allies of Antonín Novotný, First Secretary of the KSČ and President of Czechoslovakia. In their place, a new generation of Slovak Communists took control of party and state organs in Slovakia, led by Alexander Dubček, who became First Secretary of the Slovak branch of the party.
Under Dubček's leadership, Slovakia began to evolve toward political liberalization. Because Novotný and his Stalinist predecessors had denigrated Slovak "bourgeois nationalists", most notably Gustáv Husák and Vladimír Clementis, in the 1950s, the Slovak branch worked to promote Slovak identity. This mainly took the form of celebrations and commemorations, such as the 150th birthdays of 19th century leaders of the Slovak National Revival Ľudovít Štúr and Jozef Miloslav Hurban, the centenary of the Matica slovenská in 1963, and the twentieth anniversary of the Slovak National Uprising. At the same time, the political and intellectual climate in Slovakia became freer than that in the Czech Lands. This was exemplified by the rising readership of "Kultúrny život", the weekly newspaper of the Union of Slovak Writers, which published frank discussions of liberalization, federalization and democratization, written by the most progressive or controversial writers – both Slovak and Czech. "Kultúrny život" consequently became the first Slovak publication to gain a wide following among Czechs.
Prague Spring.
The period following Novotný's downfall became known as the Prague Spring. During this time, Dubček and other reformers sought to liberalize the Communist government—creating "socialism with a human face". Though this loosened the party's influence on the country, Dubček remained a devoted Communist and intended to preserve the party's rule. However, during the Prague Spring, he and other reform-minded Communists sought to win popular support for the Communist government by eliminating its worst, most repressive features, allowing greater freedom of expression and tolerating political and social organizations not under Communist control. "Dubček! Svoboda!" became the popular refrain of student demonstrations during this period. Yet Dubček found himself in an increasingly untenable position. The program of reform gained momentum, leading to pressures for further liberalization and democratization. At the same time, hard-line Communists in Czechoslovakia and the leaders of other Warsaw Pact countries pressured Dubček to rein in the Prague Spring. Though Dubček wanted to oversee the reform movement, he refused to resort to any draconian measures to do so.
The Soviet leadership tried to slow down or stop the changes in Czechoslovakia through a series of negotiations. The Soviet Union agreed to bilateral talks with Czechoslovakia in July at Čierna nad Tisou, near the Slovak-Soviet border. At the meeting, Dubček tried to reassure the Soviets and the Warsaw Pact leaders that he was still friendly to Moscow, arguing that the reforms were an internal matter. He thought he had learned an important lesson from the failing of the Hungarian Revolution of 1956, in which the leaders had gone as far as withdrawing from the Warsaw Pact. Dubček believed that the Kremlin would allow him a free hand in pursuing domestic reform as long as Czechoslovakia remained a faithful member of the Soviet bloc. Despite Dubček's continuing efforts to stress these commitments, Brezhnev and other Warsaw Pact leaders remained wary.
Downfall.
On the night of 20–21 August 1968, Warsaw Pact forces entered Czechoslovakia. The occupying armies quickly seized control of Prague and the Central Committee's building, taking Dubček and other reformers into Soviet custody. But, before they were arrested, Dubček urged the people not to resist militarily. Later in the day, Dubček and the others were taken to Moscow on a Soviet military transport aircraft (reportedly one of the aircraft used in the Soviet invasion).
Despite the inspired non-violent resistance of the Czech and Slovak population, which delayed full loss of control to the Warsaw Pact forces for a full eight months (in contrast to the Soviet military's estimate of four days) and became a prime example of civilian-based defense, the reformers ultimately were forced to accede to Soviet demands, signing the Moscow protocols. (Only František Kriegel refused to sign.)
Dubček and most of the reformers were returned to Prague on 27 August and Dubček retained his post as the party's first secretary for a while. Indeed, the achievements of the Prague Spring were not reversed overnight, but over a period of several months.
In January 1969, Dubček was hospitalized in Bratislava complaining of a cold and had to cancel a speech. Rumours sprang up that his illness was radiation sickness and that it was caused by radioactive strontium being placed in his soup during his stay in Moscow in an attempt to kill him. However, a U.S. intelligence report discounted this for lack of evidence.
Dubček was forced to resign as First Secretary in April 1969, following the Czechoslovak Hockey Riots. He was re-elected to the Federal Assembly (as the federal parliament was now called) and became its Speaker. He was later sent as ambassador to Turkey (1969–70), allegedly in the hope that he would defect to the West, which however did not occur. In 1970, he was expelled from the Communist party and lost his seats in the Slovak parliament (which he had held continuously since 1964) and the Federal Assembly.
Private citizen.
After his expulsion from the party, Dubček worked in the Forestry Service in Slovakia. He remained a popular figure among the Slovaks and Czechs he encountered on the job, using this reverence to procure scarce and hard-to-find materials for his workplace. Dubček and his wife, Anna, continued to live in a comfortable villa in a nice neighbourhood in Bratislava. In 1988, Dubček was allowed to travel to Italy to accept an honorary doctorate from Bologna University, and, while there, he gave an interview with Italian newspaper "L'Unità", his first public remarks to the press since 1970. Dubček's appearance and interview helped to return him to international prominence.
In 1989, he was awarded the annual Sakharov Prize in its second year of existence.
Velvet Revolution.
During the Velvet Revolution of 1989, he supported the Public against Violence (VPN) and the Civic Forum. On the night of 24 November, Dubček appeared with Václav Havel on a balcony overlooking Wenceslas Square, where he was greeted with uproarious applause from the throngs of protesters below and embraced as a symbol of democratic freedom. Several onlookers even chanted, "Dubček na hrad!" ("Dubček to the Castle"—i. e., Dubček for President). He disappointed the crowd somewhat by calling the revolution a chance to continue the work he had started 20 years earlier, and prune out what was wrong with contemporary communist governments; by that time the demonstrators in Prague did not support the Czechoslovakian communist leadership or the planned economy. Later that night, Dubček was on stage with Havel at the Laterna Magika theatre, the headquarters of Civic Forum, when the entire leadership of the Communist Party resigned, in effect ending Communist rule in Czechoslovakia.
Dubček was elected Chairman of the Federal Assembly (the Czechoslovak Parliament) on 28 December 1989, and re-elected in 1990 and 1992.
At the time of the overthrow of Communist party rule, Dubček described the Velvet Revolution as a victory for his "humanistic socialist outlook". In 1990, he received the International Humanist Award from the International Humanist and Ethical Union. He also gave the commencement address to the graduates of the Class of 1990 at The American University in Washington, D.C.; it was his first trip to the United States.
In 1992, he became leader of the Social Democratic Party of Slovakia and represented that party in the Federal Assembly. At that time, Dubček passively supported the union between Czechs and Slovaks in a single Czecho-Slovak federation against the (ultimately successful) push towards an independent Slovak state.
Death.
Dubček died on 7 November 1992, as a result of injuries sustained in a car crash that took place on 1 September on the Czech D1 highway, near Humpolec. He was buried in Slávičie údolie cemetery in Bratislava, Slovakia.

</doc>
<doc id="42898" url="https://en.wikipedia.org/wiki?curid=42898" title="Anthrax">
Anthrax

Anthrax is a disease with rapid onset caused by the bacterium "Bacillus anthracis". Most forms of the disease are lethal, and it affects most animals. It can be transmitted through contact with infected meat. Effective vaccines against anthrax are available, and some forms of the disease respond well to antibiotic treatment. Anthrax can occur in three forms: skin, inhalation, and intestinal.
Like many other members of the genus "Bacillus", "B. anthracis" can form dormant spores that are able to survive in harsh conditions for decades or even centuries. Such spores can be found on all continents, including Antarctica. When inhaled, eaten, or come into contact with an area of broken skin, they may become reactivated and multiply rapidly.
Usually infection develops in plant eating mammals that eat or breathe in the spores while grazing. Eating is thought to be the most common route by which herbivores contract anthrax. Carnivores living in the same environment may become infected by eating infected animals. Diseased animals can spread anthrax to humans, either through direct contact or by eating raw or undercooked meat from infected animals. "B. anthracis" bacterial spores are soil-borne. Disturbed grave sites of infected animals have been known to cause infection over 70 years after the animal's death.
Until the 20th century, anthrax infections killed hundreds of thousands of people and other animals each year. The disease is more common in countries without good public health programs and it continues to be a problem in less developed countries. French scientist Louis Pasteur developed the first effective vaccine in 1881. Anthrax has been developed as a weapon in the past by at least five state bioweapons programs—those of the United Kingdom, Japan, the United States, Russia, and Iraq—and has been attempted by several others.
Signs and symptoms.
Lungs.
Respiratory infection in humans is relatively rare and initially presents with cold or flu-like symptoms for several days, followed by pneumonia and severe (and often fatal) respiratory collapse. Historical mortality rates were over 85%, but, when treated early (seen in the 2001 anthrax attacks), observed case fatality rate dropped to 45%. Distinguishing pulmonary anthrax from more common causes of respiratory illness is essential to avoiding delays in diagnosis and thereby improving outcomes. An algorithm for this purpose has been developed.
Gastrointestinal.
Gastrointestinal (GI) infection in humans is most often caused by consuming anthrax-infected meat and is characterized by serious GI difficulty, vomiting of blood, severe diarrhea, acute inflammation of the intestinal tract, and loss of appetite. Lesions have been found in the intestines and in the mouth and throat. After the bacterium invades the gastrointestinal system, it spreads to the bloodstream and throughout the body, while continuing to make toxins. GI infections can be treated, but usually result in fatality rates of 25% to 60%, depending upon how soon treatment commences. This form of anthrax is the rarest form.
Skin.
Cutaneous anthrax, also known as Hide porter's disease, is the cutaneous (on the skin) manifestation of anthrax infection in humans. It presents as a boil-like skin lesion that eventually forms an ulcer with a black center (eschar). The black eschar often shows up as a large, painless necrotic ulcer (beginning as an irritating and itchy skin lesion or blister that is dark and usually concentrated as a black dot, somewhat resembling bread mold) at the site of infection. In general, cutaneous infections form within the site of spore penetration between two and five days after exposure. Unlike bruises or most other lesions, cutaneous anthrax infections normally do not cause pain.
Cutaneous anthrax is typically caused when "B. anthracis" spores enter through cuts on the skin. This form is found most commonly when humans handle infected animals and/or animal products.
Cutaneous anthrax is rarely fatal if treated, because the infection area is limited to the skin, preventing the lethal factor, edema factor, and protective antigen from entering and destroying a vital organ. Without treatment, about 20% of cutaneous skin infection cases progress to toxemia and death.
Cause.
Bacteria.
"Bacillus anthracis" is a rod-shaped, Gram-positive, aerobic bacterium about 1 by 9 μm in size. It was shown to cause disease by Robert Koch in 1876 when he took a blood sample from an infected cow, isolated the bacteria and put them into a mouse. The bacterium normally rests in endospore form in the soil, and can survive for decades in this state. Herbivores are often infected whilst grazing, especially when eating rough, irritant, or spiky vegetation: the vegetation has been hypothesized to cause wounds within the gastrointestinal tract permitting entry of the bacterial endospores into the tissues, though this has not been proven. Once ingested or placed in an open wound, the bacterium begins multiplying inside the animal or human and typically kills the host within a few days or weeks. The endospores germinate at the site of entry into the tissues and then spread by the circulation to the lymphatics, where the bacteria multiply.
The production of two powerful exotoxins and lethal toxin by the bacteria causes death. Veterinarians can often tell a possible anthrax-induced death by its sudden occurrence, and by the dark, nonclotting blood that oozes from the body orifices. Most anthrax bacteria inside the body after death are outcompeted and destroyed by anaerobic bacteria within minutes to hours "post mortem". However, anthrax vegetative bacteria that escape the body via oozing blood or through the opening of the carcass may form hardy spores. One spore forms per one vegetative bacterium. The triggers for spore formation are not yet known, though oxygen tension and lack of nutrients may play roles. Once formed, these spores are very hard to eradicate.
The infection of herbivores (and occasionally humans) by the inhalational route normally proceeds as follows: Once the spores are inhaled, they are transported through the air passages into the tiny air sacs (alveoli) in the lungs. The spores are then picked up by scavenger cells (macrophages) in the lungs and are transported through small vessels (lymphatics) to the lymph nodes in the central chest cavity (mediastinum). Damage caused by the anthrax spores and bacilli to the central chest cavity can cause chest pain and difficulty in breathing. Once in the lymph nodes, the spores germinate into active bacilli that multiply and eventually burst the macrophages, releasing many more bacilli into the bloodstream to be transferred to the entire body. Once in the blood stream, these bacilli release three proteins named lethal factor, edema factor, and protective antigen. The three are not toxic by themselves, but the combination is incredibly lethal to humans. Protective antigen combines with these other two factors to form lethal toxin and edema toxin, respectively. These toxins are the primary agents of tissue destruction, bleeding, and death of the host. If antibiotics are administered too late, even if the antibiotics eradicate the bacteria, some hosts will still die of toxemia because the toxins produced by the bacilli remain in their system at lethal dose levels.
The lethality of the anthrax disease is due to the bacterium's two principal virulence factors: the poly-D-glutamic acid capsule, which protects the bacterium from phagocytosis by host neutrophils, and the tripartite protein toxin, called anthrax toxin. Anthrax toxin is a mixture of three protein components: protective antigen (PA), edema factor (EF), and lethal factor (LF). PA plus LF produces lethal toxin, and PA plus EF produces edema toxin. These toxins cause death and tissue swelling (edema), respectively.
To enter the cells, the edema and lethal factors use another protein produced by "B. anthracis" called protective antigen, which binds to two surface receptors on the host cell. A cell protease then cleaves PA into two fragments: PA20 and PA63. PA20 dissociates into the extracellular medium, playing no further role in the toxic cycle. PA63 then oligomerizes with six other PA63 fragments forming a heptameric ring-shaped structure named a prepore. Once in this shape, the complex can competitively bind up to three EFs or LFs, forming a resistant complex. Receptor-mediated endocytosis occurs next, providing the newly formed toxic complex access to the interior of the host cell. The acidified environment within the endosome triggers the heptamer to release the LF and/or EF into the cytosol. It is unknown how exactly the complex results in the death of the cell.
Edema factor is a calmodulin-dependent adenylate cyclase. Adenylate cyclase catalyzes the conversion of ATP into cyclic AMP (cAMP) and pyrophosphate. The complexation of adenylate cyclase with calmodulin removes calmodulin from stimulating calcium-triggered signaling, thus inhibiting the immune response. To be specific, LF inactivates neutrophils (a type of phagocytic cell) by the process just described so they cannot phagocytose bacteria. Throughout history, lethal factor was presumed to caused macrophages to make TNF-alpha and interleukin 1, beta (IL1B). TNF-alpha is a cytokine whose primary role is to regulate immune cells, as well as to induce inflammation and apoptosis or programmed cell death. Interleukin 1, beta is another cytokine that also regulates inflammation and apoptosis. The overproduction of TNF-alpha and IL1B ultimately leads to septic shock and death. However, recent evidence indicates anthrax also targets endothelial cells that line serous cavities such as the pericardial cavity, pleural cavity, and the peritoneal cavity, lymph vessels, and blood vessels, causing vascular leakage of fluid and cells, and ultimately hypovolemic shock and septic shock.
Exposure.
Occupational exposure to infected animals or their products (such as skin, wool, and meat) is the usual pathway of exposure for humans. Workers who are exposed to dead animals and animal products are at the highest risk, especially in countries where anthrax is more common. Anthrax in livestock grazing on open range where they mix with wild animals still occasionally occurs in the United States and elsewhere. Many workers who deal with wool and animal hides are routinely exposed to low levels of anthrax spores, but most exposure levels are not sufficient to develop anthrax infections. A lethal infection is reported to result from inhalation of about 10,000–20,000 spores, though this dose varies among host species. Little documented evidence is available to verify the exact or average number of spores needed for infection.
Historically, inhalational anthrax was called woolsorters' disease because it was an occupational hazard for people who sorted wool. Today, this form of infection is extremely rare, as almost no infected animals remain.
The last fatal case of natural inhalational anthrax in the United States occurred in California in 1976, when a home weaver died after working with infected wool imported from Pakistan. To minimize the chance of spreading the disease, the deceased was transported to UCLA in a sealed plastic body bag within a sealed metal container for autopsy.
In November 2008, a drum maker in the United Kingdom who worked with untreated animal skins died from anthrax. Gastrointestinal anthrax is exceedingly rare in the United States, with two cases on record, the first was reported in 1942, according to the Centers for Disease Control and Prevention. In December 2009, an outbreak of anthrax occurred amongst heroin addicts in Glasgow, Scotland, resulting in 14 deaths. The source of the anthrax is believed to be dilution of the heroin with bone meal in Afghanistan.
Also during December 2009, the New Hampshire Department of Health and Human Services confirmed a case of gastrointestinal anthrax in an adult female. The CDC investigated the source and the possibility that it was contracted from an African drum recently used by the woman taking part in a drumming circle. The woman apparently inhaled anthrax spore form from the hide of the drum. She became critically ill, but with gastrointestinal anthrax rather than inhaled anthrax, which made her unique in American medical history. The building where the infection took place was cleaned and reopened to the public and the woman recovered. Jodie Dionne-Odom, New Hampshire state epidemiologist, stated, "It is a mystery. We really don't know why it happened."
Mode of infection.
Anthrax can enter the human body through the intestines (ingestion), lungs (inhalation), or skin (cutaneous) and causes distinct clinical symptoms based on its site of entry. In general, an infected human will be quarantined. However, anthrax does not usually spread from an infected human to a noninfected human. But, if the disease is fatal to the person's body, its mass of anthrax bacilli becomes a potential source of infection to others and special precautions should be used to prevent further contamination. Inhalational anthrax, if left untreated until obvious symptoms occur, may be fatal.
Anthrax can be contracted in laboratory accidents or by handling infected animals or their wool or hides. It has also been used in biological warfare agents and by terrorists to intentionally infect as exemplified by the 2001 anthrax attacks.
Diagnosis.
Various techniques are used for the direct identification of "B. anthracis" in clinical material. Firstly, specimens may be Gram stained. "Bacillus" spp. are quite large in size (3 to 4 μm long), they grow in long chains, and they stain Gram-positive. To confirm the organism is "B. anthracis", rapid diagnostic techniques such as polymerase chain reaction-based assays and immunofluorescence microscopy may be used.
All "Bacillus" species grow well on 5% sheep blood agar and other routine culture media. Polymyxin-lysozyme-EDTA-thallous acetate can be used to isolate "B. anthracis" from contaminated specimens, and bicarbonate agar is used as an identification method to induce capsule formation. "Bacillus" spp. usually grow within 24 hours of incubation at 35 °C, in ambient air (room temperature) or in 5% CO2. If bicarbonate agar is used for identification, then the medium must be incubated in 5% CO2. "B. anthracis" colonies are medium-large, gray, flat, and irregular with swirling projections, often referred to as having a "medusa head" appearance, and are not hemolytic on 5% sheep blood agar. The bacteria are not motile, susceptible to penicillin, and produce a wide zone of lecithinase on egg yolk agar. Confirmatory testing to identify "B. anthracis" includes gamma bacteriophage testing, indirect hemagglutination, and enzyme linked immunosorbent assay to detect antibodies. The best confirmatory precipitation test for anthrax is the Ascoli test.
Prevention.
Vaccines.
Vaccines against anthrax for use in livestock and humans have had a prominent place in the history of medicine, from Pasteur's pioneering 19th-century work with cattle (the second effective vaccine ever) to the controversial 20th century use of a modern product (BioThrax) to protect American troops against the use of anthrax in biological warfare. Human anthrax vaccines were developed by the Soviet Union in the late 1930s and in the US and UK in the 1950s. The current FDA-approved US vaccine was formulated in the 1960s.
Currently administered human anthrax vaccines include acellular (United States) and live spore (Russia) varieties. All currently used anthrax vaccines show considerable local and general reactogenicity (erythema, induration, soreness, fever) and serious adverse reactions occur in about 1% of recipients. The American product, BioThrax, is licensed by the FDA and was formerly administered in a six-dose primary series at 0, 2, 4 weeks and 6, 12, 18 months, with annual boosters to maintain immunity. In 2008, the FDA approved omitting the week-2 dose, resulting in the currently recommended five-dose series. New second-generation vaccines currently being researched include recombinant live vaccines and recombinant subunit vaccines.
Prophylaxis.
If a person is suspected as having died from anthrax, every precaution should be taken to avoid skin contact with the potentially contaminated body and fluids exuded through natural body openings. The body should be put in strict quarantine. A blood sample should then be collected and sealed in a container and analyzed in an approved laboratory to ascertain if anthrax is the cause of death. Then, the body should be incinerated. Microscopic visualization of the encapsulated bacilli, usually in very large numbers, in a blood smear stained with polychrome methylene blue (McFadyean stain) is fully diagnostic, though culture of the organism is still the gold standard for diagnosis. Full isolation of the body is important to prevent possible contamination of others. Protective, impermeable clothing and equipment such as rubber gloves, rubber apron, and rubber boots with no perforations should be used when handling the body. No skin, especially if it has any wounds or scratches, should be exposed. Disposable personal protective equipment is preferable, but if not available, decontamination can be achieved by autoclaving. Disposable personal protective equipment and filters should be autoclaved, and/or burned and buried. "B. anthracis" bacillii range from 0.5–5.0 μm in size. Anyone working with anthrax in a suspected or confirmed victim should wear respiratory equipment capable of filtering this size of particle or smaller. The US National Institute for Occupational Safety and Health – and Mine Safety and Health Administration-approved high-efficiency respirator, such as a half-face disposable respirator with a high-efficiency particulate air filter, is recommended. All possibly contaminated bedding or clothing should be isolated in double plastic bags and treated as possible biohazard waste. The victim should be sealed in an airtight body bag. Dead victims who are opened and not burned provide an ideal source of anthrax spores. Cremating victims is the preferred way of handling body disposal. No embalming or autopsy should be attempted without a fully equipped biohazard laboratory and trained, knowledgeable personnel.
Delays of only a few days may make the disease untreatable, so treatment should be started even without symptoms if possible contamination or exposure is suspected. Animals with anthrax often just die without any apparent symptoms. Initial symptoms may resemble a common cold—sore throat, mild fever, muscle aches, and malaise. After a few days, the symptoms may progress to severe breathing problems and shock, and ultimately death. Death can occur from about two days to a month after exposure, with deaths apparently peaking at about eight days after exposure. Antibiotic-resistant strains of anthrax are known.
Early detection of sources of anthrax infection can allow preventive measures to be taken. In response to the anthrax attacks of October 2001, the United States Postal Service (USPS) installed biodetection systems (BDSs) in their large-scale mail cancellation facilities. BDS response plans were formulated by the USPS in conjunction with local responders including fire, police, hospitals and public health. Employees of these facilities have been educated about anthrax, response actions, and prophylactic medication. Because of the time delay inherent in getting final verification that anthrax has been used, prophylactic antibiotic treatment of possibly exposed personnel must be started as soon as possible.
Treatment.
Anthrax cannot be spread directly from person to person, but a person's clothing and body may be contaminated with anthrax spores. Effective decontamination of people can be accomplished by a thorough wash-down with antimicrobial soap and water. Waste water should be treated with bleach or other antimicrobial agent. Effective decontamination of articles can be accomplished by boiling them in water for 30 minutes or longer. Chlorine bleach is ineffective in destroying spores and vegetative cells on surfaces, though formaldehyde is effective. Burning clothing is very effective in destroying spores. After decontamination, there is no need to immunize, treat, or isolate contacts of persons ill with anthrax unless they were also exposed to the same source of infection.
Antibiotics.
Early antibiotic treatment of anthrax is essential; delay significantly lessens chances for survival.
Treatment for anthrax infection and other bacterial infections includes large doses of intravenous and oral antibiotics, such as fluoroquinolones (ciprofloxacin), doxycycline, erythromycin, vancomycin, or penicillin. FDA-approved agents include ciprofloxacin, doxycycline, and penicillin.
In possible cases of pulmonary anthrax, early antibiotic prophylaxis treatment is crucial to prevent possible death.
If death occurs from anthrax, the body should be isolated to prevent possible spread of anthrax germs. Burial does not kill anthrax spores.
In recent years, many attempts have been made to develop new drugs against anthrax, but existing drugs are effective if treatment is started soon enough.
Monoclonal antibodies.
In May 2009, Human Genome Sciences submitted a Biologic License Application (BLA, permission to market) for its new drug, raxibacumab (brand name ABthrax) intended for emergency treatment of inhaled anthrax. On 14 December 2012, the US Food and Drug Administration approved raxibacumab injection to treat inhalational anthrax. Raxibacumab is a monoclonal antibody that neutralizes toxins produced by "B. anthracis". On March, 2016, FDA approved a second anthrax treatment using a monoclonal antibody which neutralizes the toxins produced by "B. anthracis". Obiltoxaximab is approved to treat inhalational anthrax in conjunction with appropriate antibacterial drugs, and for prevention when alternative therapies are not available or appropriate. 
History.
Etymology.
The English name comes from "anthrax" (), the Greek word for coal, possibly having Egyptian etymology, because of the characteristic black skin lesions developed by victims with a cutaneous anthrax infection. The central, black eschar, surrounded by vivid red skin has long been recognised as typical of the disease. The first recorded use of the word "anthrax" in English is in a 1398 translation of Bartholomaeus Anglicus' work "" ("On the Properties of Things", 1240).
Anthrax has been known by a wide variety of names, indicating its symptoms, location and groups considered most vulnerable to infection. These include Siberian plague, Cumberland disease, charbon, splenic fever, malignant edema, woolsorter's disease, and even "".
Discovery.
Robert Koch, a German physician and scientist, first identified the bacterium that caused the anthrax disease in 1875 in Wolsztyn. His pioneering work in the late 19th century was one of the first demonstrations that diseases could be caused by microbes. In a groundbreaking series of experiments, he uncovered the lifecycle and means of transmission of anthrax. His experiments not only helped create an understanding of anthrax, but also helped elucidate the role of microbes in causing illness at a time when debates still took place over spontaneous generation versus cell theory. Koch went on to study the mechanisms of other diseases and won the 1905 Nobel Prize in Physiology or Medicine for his discovery of the bacterium causing tuberculosis.
Although Koch arguably made the greatest theoretical contribution to our understanding of anthrax, other researchers were more concerned with the practical questions of how to prevent the disease. In Britain, where anthrax affected workers in the wool, worsted, hides and tanning industries, it was viewed with fear. John Henry Bell, a doctor based in Bradford, first made the link between the mysterious and deadly "woolsorter's disease" and anthrax, showing in 1878 that they were one and the same. In the early twentieth century, Friederich Wilhelm Eurich, the German bacteriologist who settled in Bradford with his family as a child, carried out important research for the local Anthrax Investigation Board. Eurich also made valuable contributions to a Home Office Departmental Committee of Inquiry, established in 1913 to address the continuing problem of industrial anthrax. His work in this capacity, much of it collaboration with the factory inspector G. Elmhirst Duckering, led directly to the Anthrax Prevention Act (1919).
First vaccination.
Anthrax posed a major economic challenge in France and elsewhere during the nineteenth century. Horses, cattle and sheep were particularly vulnerable, and national funds were set aside to investigate the production of a vaccine. The noted French scientist Louis Pasteur was charged with the production of a vaccine, following his successful work in developing methods which helped to protect the important wine and silk industries.
In May 1881, Pasteur - in collaboration with his assistants Jean-Joseph Henri Toussaint, Émile Roux and others - performed a public experiment at Pouilly-le-Fort to demonstrate his concept of vaccination. He prepared two groups of 25 sheep, one goat, and several cows. The animals of one group were injected with an anthrax vaccine prepared by Pasteur twice, at an interval of 15 days; the control group was left unvaccinated. Thirty days after the first injection, both groups were injected with a culture of live anthrax bacteria. All the animals in the unvaccinated group died, while all of the animals in the vaccinated group survived.
After this apparent triumph, which was widely reported in the local, national and international press, Pasteur made strenuous efforts to export the vaccine beyond France. He used his celebrity status to establish Pasteur Institutes across Europe and Asia, and his nephew, Adrien Loir, travelled to Australia in 1888 to try and introduce the vaccine to combat anthrax in New South Wales. Ultimately the vaccine was unsuccessful in the challenging climate of rural Australia, and it was soon superseded by a more robust version developed by local researchers John Gunn and John McGarvie Smith.
The human vaccine for anthrax became available in 1954. This was a cell-free vaccine instead of the live-cell Pasteur-style vaccine used for veterinary purposes. An improved cell-free vaccine became available in 1970.
Society and culture.
The virulent Ames strain, which was used in the 2001 anthrax attacks in the United States, has received the most news coverage of any anthrax outbreak. The Ames strain contains two virulence plasmids, which separately encode for a three-protein toxin, called anthrax toxin, and a polyglutamic acid capsule. Nonetheless, the Vollum strain, developed but never used as a biological weapon during the Second World War, is much more dangerous. The Vollum (also incorrectly referred to as Vellum) strain was isolated in 1935 from a cow in Oxfordshire. This same strain was used during the Gruinard bioweapons trials. A variation of Vollum known as "Vollum 1B" was used during the 1960s in the US and UK bioweapon programs. Vollum 1B is widely believed to have been isolated from William A. Boyles, a 46-year-old scientist at the U.S. Army Biological Warfare Laboratories at Camp (later Fort) Detrick, Maryland, (precursor to USAMRIID), who died in 1951 after being accidentally infected with the Vollum strain. The Sterne strain, named after the Trieste-born immunologist Max Sterne, is an attenuated strain used as a vaccine, which contains only the anthrax toxin virulence plasmid and not the polyglutamic acid capsule expressing plasmid.
Site cleanup.
Anthrax spores can survive for very long periods of time in the environment after release. Chemical methods for cleaning anthrax-contaminated sites or materials may use oxidizing agents such as peroxides, ethylene oxide, Sandia Foam, chlorine dioxide (used in the Hart Senate Office Building), peracetic acid, ozone gas, hypochlorous acid, sodium persulfate, and liquid bleach products containing sodium hypochlorite. Nonoxidizing agents shown to be effective for anthrax decontamination include methyl bromide, formaldehyde, and metam sodium. These agents destroy bacterial spores. All of the aforementioned anthrax decontamination technologies have been demonstrated to be effective in laboratory tests conducted by the US EPA or others.
A bleach solution for treating hard surfaces has been approved by the EPA.
Chlorine dioxide has emerged as the preferred biocide against anthrax-contaminated sites, having been employed in the treatment of numerous government buildings over the past decade. Its chief drawback is the need for "in situ" processes to have the reactant on demand.
To speed the process, trace amounts of a nontoxic catalyst composed of iron and tetroamido macrocyclic ligands are combined with sodium carbonate and bicarbonate and converted into a spray. The spray formula is applied to an infested area and is followed by another spray containing tert-butyl hydroperoxide.
Using the catalyst method, a complete destruction of all anthrax spores can be achieved in under 30 minutes. A standard catalyst-free spray destroys fewer than half the spores in the same amount of time. 
Cleanups at a Senate office building, several contaminated postal facilities, and other US government and private office buildings showed decontamination to be possible, but it is time-consuming and costly. Clearing the Senate office building of anthrax spores cost $27 million, according to the Government Accountability Office. Cleaning the Brentwood postal facility in Washington cost $130 million and took 26 months. Since then, newer and less costly methods have been developed.
Cleanup of anthrax-contaminated areas on ranches and in the wild is much more problematic. Carcasses may be burned, though it often takes up to three days to burn a large carcass and this is not feasible in areas with little wood. Carcasses may also be buried, though the burying of large animals deeply enough to prevent resurfacing of spores requires much manpower and expensive tools. Carcasses have been soaked in formaldehyde to kill spores, though this has environmental contamination issues. Block burning of vegetation in large areas enclosing an anthrax outbreak has been tried; this, while environmentally destructive, causes healthy animals to move away from an area with carcasses in search of fresh grass. Some wildlife workers have experimented with covering fresh anthrax carcasses with shadecloth and heavy objects. This prevents some scavengers from opening the carcasses, thus allowing the putrefactive bacteria within the carcass to kill the vegetative "B. anthracis" cells and preventing sporulation. This method also has drawbacks, as scavengers such as hyenas are capable of infiltrating almost any exclosure.
The experimental site at Gruinard Island is said to have been decontaminated with a mixture of formaldehyde and seawater by the Ministry of Defence. It is not clear whether similar treatments had been applied to US test sites.
Biological warfare.
Anthrax spores can and have been used as a biological warfare weapon. Its first modern incidence occurred when Scandinavian rebels, supplied by the German General Staff, used anthrax with unknown results against the Imperial Russian Army in Finland in 1916. Anthrax was first tested as a biological warfare agent by Unit 731 of the Japanese Kwantung Army in Manchuria during the 1930s; some of this testing involved intentional infection of prisoners of war, thousands of whom died. Anthrax, designated at the time as Agent N, was also investigated by the Allies in the 1940s.
A long history of practical bioweapons research exists in this area. For example, in 1942, British bioweapons trials severely contaminated Gruinard Island in Scotland with anthrax spores of the Vollum-14578 strain, making it a no-go area until it was decontaminated in 1990. The Gruinard trials involved testing the effectiveness of a submunition of an "N-bomb" — a biological weapon containing dried anthrax spores. Additionally, five million "cattle cakes" (animal feed pellets impregnated with anthrax spores) were prepared and stored at Porton Down for "Operation Vegetarian" — antilivestock attacks against Germany to be made by the Royal Air Force. The plan was for anthrax-based biological weapons to be dropped on Germany in 1944. However, the edible cattle cakes and the bomb were not used; the cattle cakes were incinerated in late 1945.
Weaponized anthrax was part of the US stockpile prior to 1972, when the United States signed the Biological Weapons Convention. President Nixon ordered the dismantling of US biowarfare programs in 1969 and the destruction of all existing stockpiles of bioweapons. In 1978–1979, the Rhodesian government used anthrax against cattle and humans during its campaign against black rebels. The Soviet Union created and stored 100 to 200 tons of anthrax spores at Kantubek on Vozrozhdeniya Island. They were abandoned in 1992 and destroyed in 2002.
American military and British Army personnel are routinely vaccinated against anthrax prior to active service in places where biological attacks are considered a threat.
Sverdlovsk incident (2 April 1979).
Despite signing the 1972 agreement to end bioweapon production, the government of the Soviet Union had an active bioweapons program that included the production of hundreds of tons of weapons-grade anthrax after this period. On 2 April 1979, some of the over one million people living in Sverdlovsk (now called Ekaterinburg, Russia), about 850 miles east of Moscow, were exposed to an accidental release of anthrax from a biological weapons complex located near there. At least 94 people were infected, of whom at least 68 died. One victim died four days after the release, 10 over an eight-day period at the peak of the deaths, and the last six weeks later. Extensive cleanup, vaccinations, and medical interventions managed to save about 30 of the victims. Extensive cover-ups and destruction of records by the KGB continued from 1979 until Russian President Boris Yeltsin admitted this anthrax accident in 1992. Jeanne Guillemin reported in 1999 that a combined Russian and United States team investigated the accident in 1992.
Nearly all of the night-shift workers of a ceramics plant directly across the street from the biological facility (compound 19) became infected, and most died. Since most were men, some NATO governments suspected the Soviet Union had developed a sex-specific weapon. The government blamed the outbreak on the consumption of anthrax-tainted meat, and ordered the confiscation of all uninspected meat that entered the city. They also ordered all stray dogs to be shot and people not have contact with sick animals. Also, a voluntary evacuation and anthrax vaccination program was established for people from 18–55.
To support the cover-up story, Soviet medical and legal journals published articles about an outbreak in livestock that caused GI anthrax in people having consumed infected meat, and cutaneous anthrax in people having come into contact with the animals. All medical and public health records were confiscated by the KGB. In addition to the medical problems the outbreak caused, it also prompted Western countries to be more suspicious of a covert Soviet bioweapons program and to increase their surveillance of suspected sites. In 1986, the US government was allowed to investigate the incident, and concluded the exposure was from aerosol anthrax from a military weapons facility. In 1992, President Yeltsin admitted he was "absolutely certain" that "rumors" about the Soviet Union violating the 1972 Bioweapons Treaty were true. The Soviet Union, like the US and UK, had agreed to submit information to the UN about their bioweapons programs, but omitted known facilities and never acknowledged their weapons program.
Anthrax bioterrorism.
In theory, anthrax spores can be cultivated with minimal special equipment and a first-year collegiate microbiological education.
To make large amounts of an aerosol form of anthrax suitable for biological warfare requires extensive practical knowledge, training, and highly advanced equipment.
Concentrated anthrax spores were used for bioterrorism in the 2001 anthrax attacks in the United States, delivered by mailing postal letters containing the spores. The letters were sent to several news media offices and two Democratic senators: Tom Daschle of South Dakota and Patrick Leahy of Vermont. As a result, 22 were infected and five died. Only a few grams of material were used in these attacks and in August 2008, the US Department of Justice announced they believed that Dr. Bruce Ivins, a senior biodefense researcher employed by the United States government, was responsible. These events also spawned many anthrax hoaxes.
Due to these events, the U.S. Postal Service installed biohazard detection systems at its major distribution centers to actively scan for anthrax being transported through the mail.
Decontaminating mail.
In response to the postal anthrax attacks and hoaxes, the United States Postal Service sterilized some mail using gamma irradiation and treatment with a proprietary enzyme formula supplied by Sipco Industries Ltd.
A scientific experiment performed by a high school student, later published in "The Journal of Medical Toxicology", suggested a domestic electric iron at its hottest setting (at least 400 °F) used for at least 5 minutes should destroy all anthrax spores in a common postal envelope.
Other animals.
Anthrax is especially rare in dogs and cats, as is evidenced by a single reported case in the United States in 2001. Anthrax outbreaks occur in some wild animal populations with some regularity.

</doc>
<doc id="42899" url="https://en.wikipedia.org/wiki?curid=42899" title="Anthrax (American band)">
Anthrax (American band)

Anthrax is an American thrash metal band from New York City, formed in 1981 by guitarist Scott Ian and bassist Dan Lilker. The group was considered one of the leaders of the thrash metal scene during the 1980s. Of the "Big Four" thrash metal bands (the others being Metallica, Megadeth and Slayer), Anthrax were the only band from the East Coast. As of 2016, the band has released eleven studio albums, a number of singles and a single with American hip hop group Public Enemy. According to Nielsen SoundScan, Anthrax sold 2.5 million records in the United States from 1991 to 2004, with worldwide sales of 10 million.
Noted for its live performances, Anthrax signed with the independent label Megaforce Records (which released the band's debut studio album in 1984). Lilker soon left the band to form Nuclear Assault, and was replaced by roadie Frank Bello. Vocalist Neil Turbin was replaced after two years by Matt Fallon who was then subsequently replaced in 1985 by Joey Belladonna. With a new lineup, the band recorded "Spreading the Disease" (distributed by Island Records) in 1985. Anthrax's third album, "Among the Living", was released in 1987 to critical praise. The band experienced another lineup change in 1992, when John Bush replaced Belladonna as lead vocalist. "Sound of White Noise" was released the following year, peaking at number seven on the "Billboard" 200. Studio recordings during the 1990s saw the band, influenced by other genres, experimenting with its sound.
Anthrax's lineup has changed several times over their career. The band has had a number of vocalists including Neil Turbin, Joey Belladonna, Dan Nelson and John Bush. Founding member Scott Ian and early arrival Charlie Benante, who joined Anthrax in 1983, are the only band members to appear on every album. Bassist Frank Bello has played on every album except the band's first. In 2010, Joey Belladonna returned to Anthrax and has since recorded two more studio albums with the band, "Worship Music", released in 2011, and "For All Kings" released in 2016.
History.
Formation and debut album (1981–1984).
Anthrax was formed in Queens, New York on July 18, 1981 by guitarists Scott Ian and Dan Lilker. The band was named after the disease of the same name which Ian saw in a biology textbook. The name was chosen because it sounded "sufficiently evil". drummer Dave Weiss and bassist Paul Kahn. Kahn was briefly replaced by bassist Kenny Kushner before Lilker took over on bass and Greg Walls joined as lead guitarist. Weiss was then replaced early on by Greg D'Angelo, who was recommended to the band by Greg Walls. Scott Ian's younger brother Jason Rosenfeld was a temporary vocalist until Ian's former schoolmate Neil Turbin joined the band in late August 1982. The band recorded its first demo tape during this time.
Neil Turbin era (1982–1984).
The band's first performance with Neil Turbin was at Great Gildersleeves, a New York club, in September 1982. This line-up played regularly in the New York-New Jersey area over the next several months. Anthrax were also on the same bill as the up-and-coming Metallica for several shows in the spring of 1983. Guitarist Greg Walls left Anthrax that summer and was replaced by Bob Berry, who was recommended to Turbin by Rhett Forrester of Riot. Berry was in turn soon replaced by Dan Spitz, who was previously a member of the New Jersey thrash band Overkill. A second demo was recorded soon after.
Drummer Charlie Benante replaced D'Angelo (later of White Lion) in September 1983 after a several month courtship by Ian. By this time, Ian and Lilker had befriended New Jersey record store owner Jon Zazula, to whom they had given their demo tapes to critique. Zazula's new record label Megaforce Records had recently released Metallica's debut album "Kill 'Em All" to great success. In late 1983, Zazula agreed to sign Anthrax and the band recorded the ""Soldiers of Metal"" single, which was produced by Ross the Boss of Manowar. The B-side was the song ""Howling Furies"" which was taken from a previous demo with Greg D'Angelo on drums (his only Anthrax recording).
Anthrax released their debut album "Fistful of Metal" in January 1984. However, tensions were building between Lilker and the rest of the band for various reasons and he was asked to leave before touring began. He would soon after form the band Nuclear Assault with former Anthrax roadie John Connelly. Lilker was replaced by Benante's nephew and roadie Frank Bello. The band then went on a successful US tour opening for Raven and others to support "Fistful of Metal".
In August 1984, Neil Turbin and Anthrax went their separate ways after long standing personal issues. In his book "Eddie Trunk’s Essential Hard Rock and Heavy Metal", music journalist Eddie Trunk admits pressuring Jon Zazula, Scott Ian and Anthrax into firing Turbin because of his personal taste in vocals. Singer Matt Fallon was briefly hired in late 1984, but he and the band soon parted ways. The remaining members decided to play live shows as a four-piece billed as "The Diseased" with Scott Ian on vocals, performing hardcore punk covers until a permanent singer could be found.
Initial Joey Belladonna era (1984–1992).
In 1985, Joey Belladonna was chosen as the new vocalist. The "Armed and Dangerous" EP marked Belladonnas recording debut even though it featured two live tracks from 1984 and the two songs from the "Soldiers of Metal" single that all had Neil Turbin performing on them.
Anthrax's second album "Spreading the Disease" was released in October 1985. With left over studio time from the sessions for the album Ian, Benante and ex-bandmate Dan Lilker collaborated with vocalist Billy Milano and formed the side project Stormtroopers of Death and recorded the album "Speak English or Die" in three days, which was released in December 1985.
The US tour to support "Spreading the Disease" opening for Black Sabbath was cancelled after four dates due to Sabbath singer Glenn Hughes' voice problems. In April 1986 Anthrax attempted its first tour of Europe beginning in Bochum, Germany supported by Overkill and Agent Steel. The tour included a show near Chernobyl, Ukraine immediately after the Chernobyl disaster. Later that year, Anthrax toured Europe with Metallica. The tour began on September 10 at St David's Hall and ended on September 26 in Solnahallen, Sweden. The Swedish show was Anthrax's last performance before the bus accident the following day which killed Metallica bassist Cliff Burton.
The band's third studio album, "Among the Living", was released in March 1987. It showcased the band's humorous, experimental side and began a lyrical trend focusing on movies, comic books and Stephen King novels. The album was dedicated to Cliff Burton's memory. "I Am the Law" was issued as a single backed with "I'm the Man", a rap-metal hybrid. Anthrax further indulged its appreciation for rap by appearing on the title track of U.T.F.O.'s album, "Lethal". The band toured Europe with Metallica and Metal Church to promote "Among the Living".
Anthrax returned in 1988 with their fourth album "State of Euphoria". The single "Antisocial", originally by French heavy-metal band Trust, became an MTV staple as part of the rotation on "Headbangers Ball". The band expanded its horizons by touring the US with the funk metal band Living Colour and embarking on the Headbangers Ball Tour with Exodus and Helloween. In 1989, MTV sponsored a contest in which the winner had her home trashed by the band. This would later inspire Anthrax's 1992 appearance on the television series "Married... with Children", in which the Bundys win a similar TV contest.
In 1990 Anthrax released the more serious "Persistence of Time", which surpassed "State of Euphoria"s success. The album was darker, more technical and more progressive than the band's previous work, striking a chord with metal fans wary of Anthrax's "silly" side. The most successful single from the album was a cover of Joe Jackson's "Got the Time", which Jackson said he enjoyed. In 1991, Anthrax collaborated with Public Enemy on a version of "Bring the Noise". This was a hit, and a successful tour with Public Enemy followed. The compilation "Attack of the Killer B's" was recorded in 1991, with a new version of "I'm the Man" and a cover of "Bring the Noise" on which Ian did some vocals. In late 1992, singer Joey Belladonna was fired from Anthrax over creative and stylistic differences.
Initial John Bush era (1992–2005).
Former Armored Saint vocalist John Bush joined Anthrax shortly after Belladonna's dismissal. The band left Island Records to sign with Elektra, releasing "Sound of White Noise" in 1993. A change from Anthrax's earlier work, with a dark sound influenced by alternative rock, "Sound of White Noise" received mostly-positive reviews. Critic Dave Connolley of Allmusic.com would write that Bush "has a lower-register voice than Belladonna, and the result is menacing, premeditated, and sinister." The single "Only" was a hit; in the liner notes for "Return of the Killer A's", Ian said that James Hetfield told him it was a "perfect song". In keeping with the band's eye for unlikely collaborations, classical composer Angelo Badalamenti provided music for "Black Lodge" (a nod to "Twin Peaks"). This album demonstrated that Anthrax had fully shed its cartoonish persona in favor of mature, thoughtful songwriting, which began with "Persistence of Time".
After "Sound of White Noise" longtime guitarist Dan Spitz left the band to become a watchmaker, leaving Anthrax a quartet for two years. In 1995 Anthrax released "Stomp 442", on which Charlie Benante played most of the lead-guitar parts. Benante was assisted by Paul Crook, later the band's touring lead guitarist for several years, and Dimebag Darrell of Pantera. Because Elektra did not promote the album it was less commercially successful than its predecessor, and Anthrax severed its ties with the label.
The band signed with independent label Ignition Records, releasing "" in 1998. As on "Stomp 442", Benante played lead guitar with Crook and Darrell; Pantera vocalist Phil Anselmo also appeared. After the album's release the label went bankrupt, disrupting its distribution. Although Anthrax then signed with Beyond Records, releasing the greatest-hits album "Return of the Killer A's", Beyond went out of business as well. During this period a two-vocalist tour with Belladonna and Bush was planned, but Belladonna quit at the last minute.
During the 2001 anthrax attacks in the United States the band changed its website, providing information about the disease after people began typing "anthrax.com" into search engines. Amid a potential PR nightmare, Anthrax issued a press release on October 10, 2001 joking that the band's name would be changed to "something more friendly, like 'Basket Full of Puppies'." Anthrax dispelled any name-change rumors derived from the press release at the November 2001 New York Steel 9/11 benefit concert, when they took the stage in boiler suits with a different word on each one (reading "We're not changing our name"). Bello has stated they did so after receiving support from members of the NYPD and NYFD, who believed that changing the name of the band would send the wrong message. A picture of the band in the suits is on the inner tray card of "We've Come for You All".
Despite hardships and legal entanglements over album rights, Anthrax continued. In 2001 Rob Caggiano joined on lead guitar; two years later the band released "We've Come for You All", praised by metal journalists as a return to form, on Sanctuary Records. In early 2004 Anthrax released "The Greater of Two Evils", a "live in the studio" re-recording of the earlier work with the band's current lineup. Bassist Frank Bello announced shortly afterwards that he was leaving the band to join Helmet, and was replaced by Fates Warning and Armored Saint member Joey Vera.
Reunions with Belladonna and Bush (2005–2010).
In April 2005, Anthrax announced that the "classic" lineup of Scott Ian, Charlie Benante, Dan Spitz, Joey Belladonna and Frank Bello would reform. At some shows on the following tour, they played "Among the Living" in its entirety. Although the lineup was expected to record a new album after the tour, in January 2007 Ian said that Belladonna had not agreed to a reunion. After that announcement it was uncertain if John Bush would return, since Bush said he was unready to re-commit to Anthrax.
In May 2007 Ian said the decision of who would be singing for Anthrax would be made at the end of June, but the announcement was delayed until December. In June, Bush was asked by "Rock Hard" if he was bitter about the Anthrax reunion. He replied that he was asked to return to the band, but declined. Asked if he wanted to rejoin the band when Belladonna left, Bush said that he "just didn't feel right to do that."
In December 2007 it was announced that the band's new vocalist would be Dan Nelson, formerly of Devilsize, and Rob Caggiano would return as lead guitarist. In May 2008, Anthrax played its first show in 19 months at Double Door in Chicago. Appearing before a sold-out audience with Nelson, the band played new material which was well received (despite equipment problems).
In his monthly Food Coma column posted on December 22, 2008, Scott Ian wrote that he had "been in the studio working on the new Anthrax album since November 4"; drums, bass and rhythm had been recorded on 19 tracks, and the addition of vocals had begun. "We should be mixing at the end of January and soon after that giving birth to a really pissed off, loud, fast and heavy child." In a May 2009 Food Coma column Ian wrote that the album was being mixed by Dave Fortman, who had worked with Evanescence and Slipknot. In a post on the Anthrax website, Charlie Benante said that "Worship Music" would probably be out in May.
In early 2009, Anthrax began a brief tour opening for Iron Maiden in South America. In July, band manager Izvor Zivkovic confirmed the departure of Dan Nelson due to illness. Nelson denied this, saying that he was fired. All subsequent performances were canceled except the August UK Sonisphere Festival, which featured John Bush on vocals. Due to fan response after his performance, a "Bring Back Bush" campaign began and was endorsed by Ian.
In September 2009, it was announced that Bush would again sing with Anthrax at the October Loud Park '09 Festival in Japan. Soon afterwards, Benante said that Bush had rejoined the band. In February 2010, Anthrax performed five shows as part of Soundwave in Australia. After the Australian shows, Bush said the band intended to re-record the vocals of several tracks from the upcoming album.
"Worship Music" and "For All Kings" (2010–present).
In late 2009, Anthrax confirmed a "Big Four" event (with Metallica, Megadeth and Slayer) as part of the 2010 Sonisphere Festival. Bush decided that he did not want to commit to the band full-time, and again left. Joey Belladonna returned to Anthrax in early 2010 for shows that summer, and committed to record a studio album with the band. Anthrax, Metallica, Megadeth and Slayer performed on the same bill during that summer's Sonisphere Festival series, the first time all members of the thrash-metal "Big Four" played together. The Sofia, Bulgaria show was broadcast in cinemas and later .
In April 2011, Anthrax headlined in the Philippines for the first time at the annual Pulp Summer Slam with Death Angel and Hellyeah. The band also headlined the Jägermeister side stage at Mayhem Festival 2012, co-headlined by Slayer and Slipknot. In June Anthrax released "Fight 'Em 'Til You Can't" (from its upcoming album) on its website as a free download, to thank fans for their patience in waiting several years for "Worship Music"; the album was released on September 13.
In January 2013, Anthrax announced that lead guitarist Rob Caggiano had left the band. He later joined Volbeat. It was announced shortly afterwards that Jonathan Donais of Shadows Fall had been hired as the band's touring lead guitarist; he was confirmed as an official member in August of that year. In March 2013, Anthrax released its "Anthems" EP featuring covers of 1970s rock songs. According to Scott Ian, the band began working on its next studio album in late 2013. They released a live DVD, "Chile in Hell" in 2014. In early 2015 the band confirmed that they had recorded new material and were embarking on a tour with Volbeat. In October 2015, it was confirmed that Anthrax will support Iron Maiden on the Latin America leg of their The Book of Souls World Tour. Its eleventh studio album "For All Kings" was released on February 26, 2016.
Style and influences.
Anthrax is one of the bands responsible for the emergence of speed metal and thrash metal. It exhibited a typical thrash-metal sound on its early albums and was known for humor and comic-book references in the lyrics, distinguishing the band from its contemporaries. According to "Rolling Stone", Anthrax was one of the few heavy-metal bands to receive critical praise and redefine the genre during the 1980s. Original guitarists Scott Ian and Dan Spitz' styles were described as "aggressive and head pounding", with power chords and "chugging" pedal points providing the sonic drive. Author Thomas Harrison wrote that Anthrax played metal at a faster tempo because of its punk influences, noting the group's "antimetal stage persona" with "bright clothes more fit to surf culture than to metal". The band's sixth album, 1993's "Sound of White Noise" (its first with singer John Bush), incorporated grunge and alternative metal influences in a darker vein. Critics consider the band's studio releases from the Bush era as having a more alternative and groove metal sound. The album "Worship Music", marked a return to thrash metal and the return of singer Joey Belladonna. Although the songs are credited to the whole band, since "Spreading the Disease" the music has been written almost entirely by Charlie Benante and the lyrics by Scott Ian. Although John Bush made some lyrical contributions during his tenure in the band.
Anthrax was influenced by classic rock artists on its "Anthems" EP, which includes covers of 1970s bands Rush, Cheap Trick, AC/DC, Thin Lizzy, Boston and Journey. The band has been influenced by punk bands Bad Brains, the Sex Pistols and Discharge and traditional heavy metal bands Black Sabbath, Kiss, Judas Priest, Anvil, Iron Maiden and Motörhead. Anthrax is a member of the "big four" of thrash metal with Metallica, Megadeth and Slayer. The band has been credited for laying the groundwork for rap metal and nu metal. According to Nielsen SoundScan, Anthrax sold 2.5 million records in the United States from 1991 to 2004, and 10 million worldwide.

</doc>
<doc id="42900" url="https://en.wikipedia.org/wiki?curid=42900" title="Pythagorean tuning">
Pythagorean tuning

Pythagorean tuning () is a tuning of the syntonic temperament in which the generator is the ratio 3:2 (i.e., the untempered perfect fifth), which is 702 cents wide.
Hence, it is a system of musical tuning in which the frequency ratios of all intervals are based on the ratio 3:2, "found in the harmonic series." This ratio, also known as the "pure" perfect fifth, is chosen because it is one of the most consonant and easiest to tune by ear and because of importance attributed to the integer 3.
The system had been mainly attributed to Pythagoras (sixth century BC) by modern authors of music theory, while Ptolemy, and later Boethius, ascribed the division of the tetrachord by only two intervals, called "semitonium", "tonus", "tonus" in Latin (256:243 x 9:8 x 9:8), to Eratosthenes. The so-called "Pythagorean tuning" was used by musicians up to the beginning of the 16th century. "The Pythagorean system would appear to be ideal because of the purity of the fifths, but other intervals, particularly the major third, are so badly out of tune that major chords be considered a dissonance."
The Pythagorean scale is any scale which may be constructed from only pure perfect fifths (3:2) and octaves (2:1) or the gamut of twelve pitches constructed from only pure perfect fifths and octaves, and from which specific scales may be drawn. In Greek music it was used to tune tetrachords and the twelve tone Pythagorean system was developed by medieval music theorists using the same method of tuning in perfect fifths, however there is no evidence that Pythagoras himself went beyond the tetrachord.
Method.
Pythagorean tuning is based on a stack of intervals called perfect fifths, each tuned in the ratio 3:2, the next simplest ratio after 2:1. Starting from D for example ("D-based" tuning), six other notes are produced by moving six times a ratio 3:2 up, and the remaining ones by moving the same ratio down:
This succession of eleven 3:2 intervals spans across a wide range of frequency (on a piano keyboard, it encompasses 77 keys). Since notes differing in frequency by a factor of 2 are given the same name, it is customary to divide or multiply the frequencies of some of these notes by 2 or by a power of 2. The purpose of this adjustment is to move the 12 notes within a smaller range of frequency, namely within the interval between the base note D and the D above it (a note with twice its frequency). This interval is typically called the basic octave (on a piano keyboard, an octave encompasses only 13 keys ).
For instance, the A is tuned such that its frequency equals 3:2 times the frequency of D—if D is tuned to a frequency of 288 Hz, then A is tuned to 432 Hz. Similarly, the E above A is tuned such that its frequency equals 3:2 times the frequency of A, or 9:4 times the frequency of D—with A at 432 Hz, this puts E at 648 Hz. Since this E is outside the above-mentioned basic octave (i.e. its frequency is more than twice the frequency of the base note D), it is usual to halve its frequency to move it within the basic octave. Therefore, E is tuned to 324 Hz, a 9:8 (= one epogdoon) above D. The B at 3:2 above that E is tuned to the ratio 27:16 and so on. Starting from the same point working the other way, G is tuned as 3:2 below D, which means that it is assigned a frequency equal to 2:3 times the frequency of D—with D at 288 Hz, this puts G at 192 Hz. This frequency is then doubled (to 384 Hz) to bring it into the basic octave.
When extending this tuning however, a problem arises: no stack of 3:2 intervals (perfect fifths) will fit exactly into any stack of 2:1 intervals (octaves). For instance a stack such as this, obtained by adding one more note to the stack shown above
will be similar but not identical in size to a stack of 7 octaves. More exactly, it will be about a quarter of a semitone larger, called the Pythagorean comma. Thus, A and G, when brought into the basic octave, will not coincide as expected. The table below illustrates this, showing for each note in the basic octave the conventional name of the interval from D (the base note), the formula to compute its frequency ratio, its size in cents, and the difference in cents (labeled ET-dif in the table) between its size and the size of the corresponding one in the equally tempered scale.
In the formulas, the ratios 3:2 or 2:3 represent an ascending or descending perfect fifth (i.e. an increase or decrease in frequency by a perfect fifth), while 2:1 or 1:2 represent an ascending or descending octave.
The major scale based on C, obtained from this tuning is:
In equal temperament, pairs of enharmonic notes such as A and G are thought of as being exactly the same note—however, as the above table indicates, in Pythagorean tuning they have different ratios with respect to D, which means they are at a different frequency. This discrepancy, of about 23.46 cents, or nearly one quarter of a semitone, is known as a "Pythagorean comma".
To get around this problem, Pythagorean tuning constructs only twelve notes as above, with eleven fifths between them. For example, one may use only the 12 notes from E to G. This, as shown above, implies that only eleven just fifths are used to build the entire chromatic scale. The remaining interval (the diminished sixth from G to E) is left badly out-of-tune, meaning that any music which combines those two notes is unplayable in this tuning. A very out-of-tune interval such as this one is known as a "wolf interval". In the case of Pythagorean tuning, all the fifths are 701.96 cents wide, in the exact ratio 3:2, except the wolf fifth, which is only 678.49 cents wide, nearly a quarter of a semitone flatter.
If the notes G and E need to be sounded together, the position of the wolf fifth can be changed. For example, a C-based Pythagorean tuning would produce a stack of fifths running from D to F, making F-D the wolf interval. However, there will always be one wolf fifth in Pythagorean tuning, making it impossible to play in all keys in tune.
Size of intervals.
The table above shows only intervals from D. However, intervals can be formed by starting from each of the above listed 12 notes. Thus, twelve intervals can be defined for each interval type (twelve unisons, twelve semitones, twelve intervals composed of 2 semitones, twelve intervals composed of 3 semitones, etc.).
As explained above, one of the twelve fifths (the wolf fifth) has a different size with respect to the other eleven. For a similar reason, each of the other interval types, except for the unisons and the octaves, has two different sizes in Pythagorean tuning. This is the price paid for seeking just intonation. The tables on the right and below show their frequency ratios and their approximate sizes in cents. Interval names are given in their standard shortened form. For instance, the size of the interval from D to A, which is a perfect fifth (P5), can be found in the seventh column of the row labeled D. Strictly just (or pure) intervals are shown in bold font. Wolf intervals are highlighted in red.
The reason why the interval sizes vary throughout the scale is that the pitches forming the scale are unevenly spaced. Namely, the frequencies defined by construction for the twelve notes determine two different semitones (i.e. intervals between adjacent notes):
Conversely, in an equally tempered chromatic scale, by definition the twelve pitches are equally spaced, all semitones having a size of exactly
As a consequence all intervals of any given type have the same size (e.g., all major thirds have the same size, all fifths have the same size, etc.). The price paid, in this case, is that none of them is justly tuned and perfectly consonant, except, of course, for the unison and the octave.
By definition, in Pythagorean tuning 11 perfect fifths (P5 in the table) have a size of approximately 701.955 cents (700+ε cents, where ε ≈ 1.955 cents). Since the average size of the 12 fifths must equal exactly 700 cents (as in equal temperament), the other one must have a size of 700−11ε cents, which is about 678.495 cents (the wolf fifth). Notice that, as shown in the table, the latter interval, although enharmonically equivalent to a fifth, is more properly called a diminished sixth (d6). Similarly,
In short, similar differences in width are observed for all interval types, except for unisons and octaves, and they are all multiples of ε, the difference between the Pythagorean fifth and the average fifth.
Notice that, as an obvious consequence, each augmented or diminished interval is exactly 12ε (≈ 23.460) cents narrower or wider than its enharmonic equivalent. For instance, the d6 (or wolf fifth) is 12ε cents narrower than each P5, and each A2 is 12ε cents wider than each m3. This interval of size 12ε is known as a Pythagorean comma, exactly equal to the opposite of a diminished second (≈ −23.460 cents). This implies that ε can be also defined as one twelfth of a Pythagorean comma.
Pythagorean intervals.
Four of the above-mentioned intervals take a specific name in Pythagorean tuning. In the following table, these specific names are provided, together with alternative names used generically for some other intervals. Notice that the Pythagorean comma does not coincide with the diminished second, as its size (524288:531441) is the reciprocal of the Pythagorean diminished second (531441:524288). Also "ditone" and "semiditone" are specific for Pythagorean tuning, while "tone" and "tritone" are used generically for all tuning systems. Interestingly, despite its name, a semiditone (3 semitones, or about 300 cents) can hardly be viewed as half of a ditone (4 semitones, or about 400 cents). All the intervals with prefix "sesqui-" are justly tuned, and their frequency ratio, shown in the table, is a superparticular number (or epimoric ratio). The same is true for the octave.
History.
Because of the wolf interval, this tuning is rarely used today, although it is thought to have been widespread. In music which does not change key very often, or which is not very harmonically adventurous, the wolf interval is unlikely to be a problem, as not all the possible fifths will be heard in such pieces.
Because most fifths in Pythagorean tuning are in the simple ratio of 3:2, they sound very "smooth" and consonant. The thirds, by contrast, most of which are in the relatively complex ratios of 81:64 (for major thirds) and 32:27 (for minor thirds), sound less smooth. For this reason, Pythagorean tuning is particularly well suited to music which treats fifths as consonances, and thirds as dissonances. In western classical music, this usually means music written prior to the 15th century.
From about 1510 onward, as thirds came to be treated as consonances, meantone temperament, and particularly quarter-comma meantone, which tunes thirds to the relatively simple ratio of 5:4, became the most popular system for tuning keyboards. At the same time, syntonic-diatonic just intonation was posited by Zarlino as the normal tuning for singers.
However, meantone presented its own harmonic challenges. Its wolf intervals proved to be even worse than those of the Pythagorean tuning (so much so that it often required 19 keys to the octave as opposed to the 12 in Pythagorean tuning). As a consequence, meantone was not suitable for all music.
From around the 18th century, as the desire grew for instruments to change key, and therefore to avoid a wolf interval, this led to the widespread use of well temperaments and eventually equal temperament.
In 2007, the discovery of the syntonic temperament exposed the Pythagorean tuning as being a point on the syntonic temperament's tuning continuum.

</doc>
<doc id="42901" url="https://en.wikipedia.org/wiki?curid=42901" title="Indian Trade">
Indian Trade

The Native American Trade refers to historic trade between Europeans and their North American descendants and the Indigenous people of North America (today known as Native Americans in the United States, and First Nations in Canada, but formerly as "Indians"), beginning before the colonial period and continuing through the 19th century, although declining before mid-century.
The term Indian Trade describes the people involved in the trade. The products involved varied by region and era. In most of Canada the term is synonymous with the fur trade, since fur for making beaver hats was by far the most valuable product of the trade, from the European point of view. Demand for other products resulted in trade in those items: Europeans asked for deerskin in the Southeast coast of the United States, and for buffalo skins and meat, and pemmican on the Great Plains. In turn, Native American demand influenced the trade goods brought by Europeans.
Economic contact between Native Americans and European colonists began in the 16th century and lasted until the late 19th century. Although the relationship between Europeans and Indians was often marred by conflicts, many tribes established peaceful trade relations with the new colonists during the early stages of European settlement. From the 17th to the 19th century, the English and French mainly traded for animal pelts and fur with Native Americans. On the other hand, trading between the Spanish and Native Americans was sporadic and lasted only for a couple of decades. Eventually, wars, the dwindling of Native American populations and the westward expansion of the United States led to the confinement of tribes to reservations and the end of this kind of economic relations between Indians and European Americans.
Other economic relations continued, especially in the alcohol trade around many reservations, and for Native arts and crafts. Today, many Native Americans satisfy a different kind of demand with the associated trades of their gaming casinos on sovereign land. These have been developed as entertainment and conference resorts, serving a wide market of customers, and generating substantial revenues for tribes to use for economic development, as well as welfare and education of their people.
Pre-European settlements (18th century-early 19th century).
Economic contact between Native Americans, Australians and Europeans can be traced back to the 17th century when English and French fishermen fishing off he coast of Canada, traded guns and other weapons for beaver fur. Before Europeans settled permanently in North America, many European fishermen regularly made voyages to the shores of Canada to trade for furs from Native Americans. By the 17th century, the Eurasian beaver was almost extinct in France and England. Due to this shortage of fur, many fur traders began to look to the New World for pelts.
The first explorers to conduct trade with Native Americans were Giovanni da Verrazano and Jacques Cartier in the 1820s-1930s. Verrazano noted in his book, “If we wanted to trade with them for some of their things, they would come to the seashore on some rocks where the breakers were most violent while we remained on the little boat, and they sent us what they wanted to give on a rope, continually shouting to us not to approach the land.” As visits from Europeans became more frequent and some Europeans began to settle in North America, Indians began to establish regular trade relations with these new colonists. The ideal locations for fur trading were near harbors where ships could come in.
Trade with early European settlers.
Plymouth and Jamestown
In order to set up a thriving colony, settlers in the New World needed the five factors of production that contribute to the creation of wealth: land (natural resources), labor, capital, entrepreneurship and knowledge. Often, trading with Native Americans resulted in colonists gaining needed knowledge and natural resources. Examples of this can be seen in the English settlements of Plymouth Bay and Jamestown. Chief Massasoit, a Wampanoag, and Squanto, a Patuxet Indian, helped the Pilgrims of Plymouth Bay establish their colony by teaching them skills in cultivating this land and hunting. In return for weapons and tools, these Native Americans provided the colonists with important natural resources, including food. In 1621 Chief Massasoit established one of the earliest trading pacts between Europeans and Indians by signing a treaty with Plymouth Colony to engage in peaceful trade. As the number of English colonists in the New England area began to grow, the Wampanoag became uneasy of losing their land to these new settlers. Gradually, tensions escalated, leading to King Philip's War, an armed conflict between the Pilgrims and the Native Americans in the area. The war ended with the defeat of the Indian tribe, causing a serious fracture amongst relations between the Pilgrims and Native Americans.
Relations between settlers in the Jamestown area and Native Americans ended similarly. Initially, the Powahatan aided the English settlers with food and clothing, helping them survive the early difficult years. However, relations between the two groups deteriorated after three years, resulting in a war.
Fur trading posts
Fur trading was one of the main economic activities in Northern America from the late 16th century to the mid-19th century. At the time, demand for fur was surging in Europe as it was used to make cloth and fancy hats. Data collected from England in the 18th century highlights that the years from 1746 to 1763 saw an increase of 12 shillings per pelt. It has been calculated that over 20 million beaver hats were exported from England alone from 1700 to 1770. Both trading partners, Native Americans and Europeans, provided the other a comparative advantage in the fur trade industry. The opportunity cost of hunting beavers in Europe was extremely high: by the seventeenth and eighteenth centuries, the Eurasian beaver was near extinction in England and France. On the other hand, traders and trappers thought the wildlife in the New World was essentially limitless. Native Americans made use of the trade goods received, particularly knives, axes, and guns. The fur trade provided a stable source of income for many Native Americans until the mid-19th century, when changing fashion trends in Europe and a decline in the beaver population in North America brought about a collapse in demand for fur.
Trade with the Spanish
Trading between Spanish settlers and Native Americans was rare and occurred in parts of New Mexico and California. The Spanish mainly intended to spread the Christian faith to Indians and to use them as slaves for work. The most significant effect of trading with the Spanish was the introduction of the horse to the Ute in New Mexico. Gradually, horses bred and their use was adopted across the Great Plains, dramatically altering the lifestyles and customs of many Native American tribes. Many Indians switched from a hunter- gatherer economy to a nomadic lifestyle after they began using horses for transportation. They had a greater range for hunting bison and trading with other tribes.
Relationship between Europeans and Indians
It took time for Europeans and Native Americans to learn the customs of the other side. When Europeans first encountered a tribe, they would often be offered fur, food or other items as gifts. The Europeans did not understand they were supposed to take on an alliance with the natives, including helping them against their enemies. Native American tribes regularly practice gift giving as part of their social relations. Because the Europeans did not (or most of them), they were considered to be rude and crude.
After observing that Europeans wanted to trade goods for the skins and other items, Native Americans entered into that. Both sides became involved in the conflicts of the other. In New France, in Carolina, Virginia, and New England and in New Netherland, the Europeans became drawn into the endemic warfare of their trading partners. As Native Americans were pressed into alliances by the Europeans for Queen Anne's War, the Seven Years' War, the Nine Years' War, and other standing competitions among the European powers: France, Great Britain and Spain, with whom they were dealing in North America, they felt drawn into the Europeans' endemic warfare.
Late 19th century to present.
After the United States became independent, it enacted legislation to regulate trading with the Indians/Native Americans, under the Trade and Intercourse Act, first passed on July 22, 1790. Later the Indian Office, which was then part of the War Department, issued licenses to traders in the Indian Territory. Under removal, the largest tribes from the Southeast and north of the Ohio were moved west of the Mississippi river. By 1834 Indian Territory had been designated as what was then most of the United States west of the Mississippi, primarily what became Arkansas, Kansas and Oklahoma. Territories of the upper West were still occupied by native tribes as well. Mountain men and traders from Mexico freely operated there independently of the US.
After the formation of the United States, the commerce clause of the constitution gave Congress the power to “regulate Commerce with foreign Nations, and among the several States, and with the Indian tribes.” In the 19th century, the American government passed legislation to support relocation of tribes to reservations in order to extinguish their title to lands that could be sold to European Americans. The Indian Removal Act of 1830 forced tribes such as the Cherokee and the Choctaw to move out of their homelands. Resistance by Native Americans to relocate resulted in conflicts such as the Second Seminole War, that caused the deaths of 3000 Native Americans. Forcing tribes to relocate and to adjust to isolated reservations often unsuitable for the subsistence farming they were encouraged to undertake, made many of them dependent on the U.S. government for annuities and supplies. They had difficulty trying to develop economic systems of their own.
As outlined by Kalt and Cornell in their book, "What Can Tribes Do? Strategies and Institutions in American Indian Economic Development," on reservations, tribes lacked access to capital, were assigned to areas with poor natural resources (or had their resources stolen or kept from their control), and did not possess skilled labor.
Today, many programs, such as the Harvard Project on American Indian Economic Development, exist to foster conditions that will help reservations become independent and financially stable communities. Since the late 20th century, many tribes have established gaming casinos. The most successful ones use part of the revenues for economic development of their nations, as well as for welfare and education for all their tribal members.
References.
N.p.: W.W. Norton &, 2011. Print.

</doc>
<doc id="42903" url="https://en.wikipedia.org/wiki?curid=42903" title="Meantone temperament">
Meantone temperament

Meantone temperament is a musical temperament, which is a system of musical tuning. In general, a meantone is constructed the same way as Pythagorean tuning, as a stack of perfect fifths, but in meantone, each fifth is "narrow" compared to the ratio 27/12:1 used in 12 equal temperament. The meantone temperament:
Quarter-comma meantone is the best known type of meantone temperament, and the term "meantone temperament" is often used to refer to it specifically.
Meantone temperaments.
"Meantone" can receive the following equivalent definitions:
The family of meantone temperaments share the common characteristic that they form a stack of identical fifths, the tone being the result of two fifths minus one octave, the major third of four fifths minus two octaves. Such temperaments are also called "regular" or "syntonic". Meantone temperaments are often described by the fraction of the syntonic comma by which the fifths are tempered: quarter-comma meantone, the most common type, tempers the fifths by 1/4 syntonic comma, with the result that four fifths produce a just major third, a syntonic comma lower than a Pythagorean major third; third-comma meantone tempers by 1/3 syntonic comma, three fifths producing a just major sixth, a syntonic comma lower than a Pythagorean one.
All meantone temperaments fall on the syntonic temperament's tuning continuum, and as such are "syntonic tunings". The distinguishing feature of each unique syntonic tuning is the width of its generator in cents, as shown in the central column of Figure 1. Historically notable meantone temperaments, discussed below, occupy a narrow portion of the syntonic temperament's tuning continuum, ranging from approximately 695 to 699 cents. The criteria which define the limits (if any) of the meantone range of tunings within the syntonic temperament's tuning continuum are not yet well-defined.
While the term "meantone temperament" refers primarily to the tempering of 5-limit musical intervals, optimum values for the 5-limit also work well for the 7-limit, defining septimal meantone temperament. In Figure 1, the valid tuning ranges of 5-limit, 7-limit, and 11-limit syntonic tunings are shown, and can be seen to include many notable meantone tunings.
Meantone temperaments can be specified in various ways: by what fraction (logarithmically) of a syntonic comma the fifth is being flattened (as above), what equal temperament has the meantone fifth in question, the width of the tempered perfect fifth in cents, or the ratio of the whole tone to the diatonic semitone. This last ratio was termed "R" by American composer, pianist and theoretician Easley Blackwood, but in effect has been in use for much longer than that. It is useful because it gives us an idea of the melodic qualities of the tuning, and because if R is a rational number N/D, so is (3R+1)/(5R+2) or (3N+D)/(5N+2D), which is the size of fifth in terms of logarithms base 2, and which immediately tells us what division of the octave we will have. If we multiply by 1200, we have the size of fifth in cents.
In these terms, some historically notable meantone tunings are listed below. The relationship between the first two columns is exact, while that between them and the third is closely approximate.
Equal temperaments.
Neither the just fifth nor the quarter-comma meantone fifth is a rational fraction of the octave, but several tunings exist which approximate the fifth by such an interval; these are a subset of the equal temperaments (""N"-ET"), in which the octave is divided into some number ("N") of equally wide intervals.
Equal temperaments useful as meantone tunings include (in order of increasing generator width) 19-ET, 50-ET, 31-ET, 43-ET, and 55-ET. The farther the tuning gets away from quarter-comma meantone, however, the less related the tuning is to harmonic timbres, which can be overcome by tempering the timbre to match the tuning.
Wolf intervals.
A whole number of just perfect fifths will never add up to a whole number of octaves, because they are incommensurable (see Fundamental theorem of arithmetic). If a stacked-up whole number of perfect fifths is to close with the octave, then one of the fifths must have a different width than all of the others. For example, to make the 12-note chromatic scale in Pythagorean tuning close at the octave, one fifth must be out of tune by the Pythagorean comma; this altered fifth is called a wolf fifth.
Wolf intervals are an artifact of keyboard design. This can be shown most easily using an isomorphic keyboard, such as that shown in Figure 2.
Even edge conditions produce wolf intervals only if the isomorphic keyboard has fewer buttons per octave than the tuning has enharmonically-distinct notes (Milne, 2007). For example, the isomorphic keyboard in Figure 2 has 19 buttons per octave, so the above-cited edge-condition, from E to C, is "not" a wolf interval in 12-ET, 17-ET, or 19-ET; however, it "is" a wolf interval 26-ET, 31-ET, and 50-ET. In these latter tunings, using electronic transposition could keep the current key's notes on the isomorphic keyboard's white buttons, such that these wolf intervals would very rarely be encountered in tonal music, despite modulation to exotic keys.
Isomorphic keyboards expose the invariant properties of the meantone tunings of the syntonic temperament isomorphically (that is, for example, by exposing a given interval with a single consistent inter-button shape in every octave, key, and tuning) because both the isomorphic keyboard and temperament are two-dimensional ("i.e.", rank-2) entities (Milne, 2007). One-dimensional N-key keyboards can expose accurately the invariant properties of only a single one-dimensional N-ET tuning; hence, the one-dimensional piano-style keyboard, with 12 keys per octave, can expose the invariant properties of only one tuning: 12-ET.
When the perfect fifth is exactly 700 cents wide (that is, tempered by approximately 1/11 of a syntonic comma, or exactly 1/12 of a Pythagorean comma) then the tuning is identical to the familiar 12-tone equal temperament. This appears in the table above when R = 2/1.
Because of the compromises (and wolf intervals) forced on meantone tunings by the one-dimensional piano-style keyboard, well temperaments and eventually equal temperament became more popular.
Using standard interval names, twelve fifths equal six octaves plus one augmented seventh; seven octaves are equal to eleven fifths plus one diminished sixth. Given this, three "minor thirds" are actually augmented seconds (for example, B to C), and four "major thirds" are actually diminished fourths (for example, B to E). Several triads (like B–E–F and B–C–F) contain both these intervals and have normal fifths.
Extended meantones.
All meantone tunings fall into the valid tuning range of the syntonic temperament, so all meantone tunings are syntonic tunings. All syntonic tunings, including the meantones, have a conceptually infinite number of notes in each octave, that is, seven natural notes, seven sharp notes (F to B), seven flat notes (B to F), double sharp notes, double flat notes, triple sharps and flats, and so on. In fact, double sharps and flats are uncommon, but still needed; triple sharps/flats are almost never seen. In any syntonic tuning that happens to divide the octave into a small number of equally wide smallest intervals (such as 12, 19, or 31), this infinity of notes still exists, although some notes will be enharmonic. For example, in 19-ET, E and F are the same pitch.
Many musical instruments are capable of very fine distinctions of pitch, such as the human voice, the trombone, unfretted strings such as the violin, and lutes with tied frets. These instruments are well-suited to the use of meantone tunings.
On the other hand, the piano keyboard has only twelve physical note-controlling devices per octave, making it poorly suited to any tunings other than 12-ET. Almost all of the historic problems with the meantone temperament are caused by the attempt to map meantone's infinite number of notes per octave to a finite number of piano keys. This is, for example, the source of the "wolf fifth" discussed above. When choosing which notes to map to the piano's black keys, it is convenient to choose those notes that are common to a small number of closely related keys, but this will only work up to the edge of the octave; when wrapping around to the next octave, one must use a "wolf fifth" that is not as wide as the others, as discussed above.
The existence of the "wolf fifth" is one of the reasons why, before the introduction of well temperament, instrumental music generally stayed in a number of "safe" tonalities that did not involve the "wolf fifth" (which was generally put between G/A and D/E).
Throughout the Renaissance and Enlightenment, theorists as varied as Nicola Vicentino, Francisco de Salinas, Fabio Colonna, Marin Mersenne, Constantijn Huygens, and Isaac Newton advocated the use of meantone tunings that were extended beyond the keyboard's twelve notes, and hence have come to be called "extended" meantone tunings. These efforts required a concomitant extension of keyboard instruments to offer means of controlling more than 12 notes per octave, including Vincento's Archicembalo (shown in Figure 3), Mersenne's 19-ET harpsichord, Colonna's 31-ET sambuca, and Huygens' 31-ET harpsichord. Other instruments extended the keyboard by only a few notes. Some period harpsichords and organs have split D/E keys, such that both E major/C minor (4 sharps) and E major/C minor (3 flats) can be played without wolf fifths. Many of those instruments also have split G/A keys, and a few have all the five accidental keys split.
All of these alternative instruments were "complicated" and "cumbersome" (Isacoff, 2003), due to (a) not being isomorphic, and (b) not having the ability to transpose electronically, which can significantly reduce the number of note-controlling buttons needed on an isomorphic keyboard (Plamondon, 2009). Both of these criticisms could be addressed by electronic isomorphic keyboard instruments (such as the open source jammer keyboard), which could be simpler, less cumbersome, and more expressive than existing keyboard instruments.
Use of meantone temperament.
References to tuning systems that could possibly refer to meantone were published as early as 1496 (Gafori) and Aron (1523) is unmistakably referring to meantone. However, the first mathematically precise Meantone tuning descriptions are found in late 16th century treatises by Francisco de Salinas and Gioseffo Zarlino. Salinas (in De musica libra septum) describes three different mean tone temperaments: the 1/3 comma system, the 2/7 comma system, and the 1/4 comma system. He is the likely inventor of the 1/3 system, while he and Zarlino both wrote on the 2/7 system, apparently independently. Lodovico Fogliano mentions the 1/4 comma system, but offers no discussion of it.
In the past, meantone temperaments were sometimes used or referred to under other names or descriptions. For example, in 1691 Christiaan Huygens wrote his ""Lettre touchant le cycle harmonique"" ("Letter concerning the harmonic cycle") with the purpose of introducing what he believed to be a new division of the octave. In this letter Huygens referred several times, in a comparative way, to a conventional tuning arrangement, which he indicated variously as "temperament ordinaire", or "the one that everyone uses". But Huygens' description of this conventional arrangement was quite precise, and is clearly identifiable with what is now classified as (quarter-comma) meantone temperament.
Although meantone is best known as a tuning environment associated with earlier music of the Renaissance and Baroque, there is evidence of continuous usage of meantone as a keyboard temperament well into the middle of the 19th century. Meantone temperament has had considerable revival for early music performance in the late 20th century and in newly composed works specifically demanding meantone by composers including John Adams, György Ligeti and Douglas Leedy.
New uses of meantone tunings.
Meantone is one of many possible tuning effects found in Dynamic Tonality (Plamondon, 2009).

</doc>
<doc id="42904" url="https://en.wikipedia.org/wiki?curid=42904" title="Suva">
Suva

Suva is the capital and the second most populated municipality of Fiji, after Nasinu. It is on the southeast coast of the island of Viti Levu, in the Rewa Province, Central Division.
It is the largest and the most cosmopolitan city in the South Pacific and has become an important regional centre; students from the Pacific region and a growing expatriate community make up a significant portion of the city's population. Under authority of local government act Suva is governed and administratively looked after by Suva City Council.
Suva is Fiji's political and administrative capital. In 1877, it was decided to make Suva the capital of Fiji, as the geography of former main European settlement at Levuka on the island of Ovalau proved too restrictive. The administration of the colony was moved from Levuka to Suva in 1882.
At the 2007 census, the city of Suva had a population of 85,691. Including independent suburbs, the population of the Greater Suva urban area was 172,399 at the 2007 census. Suva, along with the bordering cities of Lami, Nasinu, and Nausori have a total urban population of around 330,000, over a third of the nation's population. This urban complex (not including Lami) is known also as the Suva–Nausori corridor.
History.
In return for a promise to pay off debts owed to the United States by the Bauan chieftain, Seru Epenisa Cakobau, the Australian-based Polynesia Company was granted 5000 km² of land, 575 km² of it near what was then the village of Suva, in 1868. The original intention was to develop a cotton farming industry, but the land and climate proved unsuitable.
Following the annexation of the Fiji Islands by the United Kingdom in 1874, the colonial authorities decided to move the capital to Suva from Levuka in 1877, as Levuka's location, between a steep mountain and the sea, made any expansion of the town impractical. The transfer was made official in 1882. Colonel F.E. Pratt of the Royal Engineers was appointed Surveyor-General in 1875 and designed the new capital, assisted by W. Stephens and Colonel R.W. Stewart.
Following the promulgation of the Municipal Constitution Ordinance of 1909, Suva acquired municipal status in 1910. The town initially comprised one square mile; these boundaries remained intact until 1952 when the Muanikau and Samabula wards were annexed, expanding its territory to 13 square kilometers. In October that year, Suva was proclaimed a city — Fiji's first. Tamavua was subsequently annexed; the most recent extension of the city boundaries has been to incorporate the Cunningham area to the north of the city. Urban sprawl has resulted in a number of suburbs that remain outside of the city limits; together with the city itself, they form a metropolitan area known as the Greater Suva Area.
The city hosted the 2003 South Pacific Games, being the third time in the event's 40-year history that they had been held in Suva. As part of the hosting of the event, a new gymnasium and indoor sports center, swimming pool, and stadium; field hockey pitch; and stands were built in the area around Suva, funded by the government and a $16 million People's Republic of China aid package.
Geography and physical characteristics.
Suva is the capital of Fiji and is a harbour city built on a peninsula reaching out into the sea. It has a mix of modern buildings and traditional colonial architecture.
The city is perched on a hilly peninsula between Laucala Bay and Suva Harbour in the southeast corner of Viti Levu. The mountains north and west catch the southeast trade winds, producing moist conditions year round.
Suva is the commercial and political centre of Fiji, though not necessarily the cultural centre, and the largest urban area in the South Pacific outside of Australia and New Zealand. It is Fiji's main port city.
Although Suva is on a peninsula, and almost surrounded by sea, the nearest beach is 40 kilometres (25 mi) away at Pacific Harbour and the nearby coast is lined by mangroves. A significant part of the city centre, including the old Parliament buildings, is built on reclaimed mangrove swamp.
Central.
The Central Business District encompasses an area known as the Central Ward; one of Suva's six wards, Central occupies close to the whole south-western side of the Suva Peninsula.
City wards.
The city's six wards beginning from the city centre, then north, then clockwise rotation.
Suva–Nausori Corridor.
Suva sits in the middle of an urban conurbation that stretches from Lami, to the immediate west of the city, along the Queens Highway and Nasinu, on its eastern border all the way to the Rewa River, along the Kings Highway. This conurbation, sometimes known as the Suva Urban Complex, continues till Nausori, over the Rewa River. The north of the city to its northeast contains the rainforest park areas of Colo-i-Suva and Sawani, along the Princes Road, connecting at the Rewa River Bridge. This entire conurbation, is generally referred to by locals as Suva, although it contains four local government areas. In formal reference, this complex has come to be known as the Suva–Nausori Corridor (where Lami is generally excluded) and is the most populous area in Fiji, with over 330,000 people.
Climate.
Suva features a tropical rainforest climate under the Köppen climate classification. The city sees a copious amount of precipitation during the course of the year, with no true dry season due to no month having an average rainfall below . Suva averages of precipitation annually with its driest month, July averaging . In fact, during all 12 months of the year, Suva receives substantial precipitation, such that the term "fine weather" in a weather report simply means "not actually raining". Like many other cities with a tropical rainforest climate, temperatures are relatively constant throughout the year, with an average high of about and an average low of about .
Suva has a markedly higher rainfall than Nadi and the western side of Viti Levu, which is known to Suva citizens as "the burning west". The second Governor of Fiji, Sir Arthur Gordon, allegedly remarked that it rained in Suva like he had seen nowhere else before and that there was hardly a day without rain. The most copious rainfall is observed from November to May, while the slightly cooler months from June to October are considerably drier.
Demographics.
Suva is a multiracial and multicultural city. Indigenous Fijians and Indo-Fijians, the two principal ethnic groups of Fiji, comprise the bulk of Suva's population, and the city is home to the majority of Fiji's ethnic minority populations, which include Caucasians (Europeans or "Kaivalagi"), part-Europeans (of European and Fijian descent), and Chinese, amongst others. The majority of expatriates working in Fiji are based in Suva. The most widely spoken language is English, but Fijian, Hindustani, Cantonese, and other Indian languages are also spoken by their respective communities. 
Municipal government.
Suva has municipal status and is supposed to be governed by a Lord Mayor and a 20-member city council. The Suva City Council is the municipal law-making body of the city of Suva, Fiji's capital. It consists of 20 Councillors, elected for three-year terms from four multi-member constituencies called wards. Councillors, who are elected by residents, landowners, and representatives of corporations owning or occupying ratable property in Suva, elect a Lord Mayor and Deputy Lord Mayor from among their own members; they serve one-year terms and are eligible for re-election.
In 2009, the Military-backed interim government dismissed all municipal governments throughout Fiji and appointed special administrators to run the urban areas. , elected municipal government has not been restored. The special administrator of Suva, along with nearby Nasinu, is Chandu Umaria, a former Lord Mayor of Suva.
Landmarks.
A well-known landmark is the Suva City Library or the Carnegie Library, built in 1909 as well as many other colonial buildings.
The government buildings complex sits on what was once the flowing waters of a creek. It was drained in 1935 and over five kilometres of reinforced concrete pilings were driven into the creek bed to support the massive buildings to be erected. After the foundation stone was laid in 1937, the building was completed in 1939; a new wing was completed in 1967. Parliament, however, was moved to a new complex on Ratu Sukuna Road in 1992.
Government House was formerly the residence of Fiji's colonial Governors and, following independence in 1970, Governors-General. It is now the official residence of Fiji's President. Originally erected in 1882, it had to be rebuilt in 1928, following its destruction by lightning in 1921.
The Suva campus of the University of the South Pacific (USP) occupies what was once a New Zealand military base. It is the largest of the many USP campuses dotted throughout the South Pacific and the largest university in the Pacific Islands outside Hawaii. It offers courses which are internationally recognized and endorsed.
The Fiji Museum, in Thurston Gardens, was founded in 1904 and originally occupied the old town hall, but moved to its present location in 1954. The museum houses the most extensive collection of Fijian artefacts in the world, and is also a research and educational institution, specializing in archaeology, the preservation of Fiji's oral tradition, and the publication of material on Fiji's language and culture.
Suva has around 78 parks, these include the new Takashi Suzuki Garden, Apted Park at Suva Point which is a popular spot for viewing sunrise and sunset, Thurston Gardens which was opened in 1913 and has flora from throughout the South Pacific.
Suva has many shopping and retail areas, notably Cumming street, which has since colonial times been a vibrant and colourful shopping area. Features of these streets include the original colonial buildings and narrow roads. More modern shopping malls, such as the Suva Central Shopping Mall, Mid-City Mall as well as MHCC are all part of the developments to give the city a modern and sophisticated look.
In December 2009, there was an addition to Suva's skyline with the opening of TappooCity valued at USD25.7 million (FJD50 million) a joint venture six storey low-rise building project by FNPF & Tappoo Group of Companies as Fiji's (and South Pacific's) largest department mall at present outside Australia & New Zealand.
Construction work began in January 2011 for a FJD30 million mini-mall complex at Grantham Road behind the Sports-City Complex and close proximity to University of the South Pacific, which will house restaurants, retail outlets and cinemas. Although construction was scheduled for end 2011, this complex will now be ready mid-2012.
Economy.
Unlike most cities and towns in Fiji and indeed many around the world, Suva did not grow around one industry but has gradually developed as a hub and one of the largest cities in the Pacific Islands. Suva is the commercial centre of Fiji with most banks having their Pacific headquarters here, including ANZ and the Westpac Bank. Most national financial institutions, non-governmental organizations and government ministries and departments are headquartered here. At one point both Air Pacific (now called Fiji Airways and Air Fiji were headquartered in Suva.
A large part of Fiji's international shipping is conducted at Suva's Kings Wharf as well as docking of international cruise ships, which has led to a growth in Suva's tourism industry. Many services are provided in Suva and is the basis of Suva's industrial and commercial activity.
There are large industrial areas, the largest being at Walu Bay, where there is a saturation of factories and warehouses and import and export companies. This area contains many shipyards for ship building and repairs as well as container yards. There is a brewery and many printeries. Other notable industrial zones are located in Vatuwaqa, Raiwaqa and Laucala Beach.
There is a large commercial and shopping scene in Suva with streets such as Cumming Street and Victoria Parade being popular. There are many shopping complexes to visit and many markets.
Institutions.
Suva is host to more international and regional intergovernmental agencies and NGOs than any other Pacific Island capital. Some of the bodies with a presence in Suva are:
Entertainment and culture.
Suva is host to many regional, national and local events and has very developed and advanced venue options.
Venues.
Suva has many multipurpose venues, the main ones being:
Parks and gardens.
Suva has a number of parks and a few gardens. Albert Park, in the City centre, is famous as the stage for many national-historical events such as the Independence of Fiji, the landing by Kingsford Smith on the Southern Cross and many parades and carnivals. Sukuna Park, also in the CBD is a popular recreational park and has many performances and events on a weekly basis. Thurston Gardens is the city's main botanical garden and the location of the Fiji Museum. Queen Elizabeth drive is popular as a scenic walk along Suva's foreshore. Many city residents go to the Colo-i-Suva Forest Reserve, a short drive from the city center, to swim under the waterfalls.
Music.
Many concerts are held in Suva, some coming from other countries to enjoy world-class performances. Concerts and shows are usually staged at one of the above-mentioned venues on a monthly basis. Some of the famous music artists to hold shows in Suva include UB40, Lucky Dube, O'Yaba, Sean Kingston and many others. Due to a favoured interests in Bollywood by all, some prominent singers and actors have held shows in the capital which includes singers like Shaan, Sonu Nigam, Sunidhi Chauhan and movie artists like Shah Rukh Khan, Priyanka Chopra, Johnny Lever, Dino Morea, Rajpal Yadav and the like.
Food.
Suva offers a varied and interesting culinary experience where almost every if not all major cuisines are represented. Particularly popular cuisines are Chinese, Indian, Fijian and Italian. At nights, especially on weekends, food stalls and outlets cater to the city's nightlife.
Festivals.
During the course of the year, arts, music and trade festivals are held in Suva, albeit on a small scale. There are a few large and notable festivals that occur annually and these include the Hibiscus Festival (largest carnival in the South Pacific islands), the New Years Street Party, and the Fiji Show Case tradeshow that includes carnival rides, food as well as magic and circus performances.
Night life.
Suva has a vibrant nightlife where most nightclubs and bars open in the late afternoon and remain open till 5 am. Suva's nightlife caters to all tastes, moods and likes. Food stalls are open throughout the night and the city is well policed at night. Apart from nightclubs, there are lounges and bars that cater to those seeking low-key entertainment
The seedier side of Suva is Victoria Parade where night clubs such Signals Night Club, East Court Restaurant, Angel Night Club are located in the same stretch.
Cinema.
Downtown Suva has one main cinema complex, Village Six, owned by the Damodar Brothers. The Regal and Phoenix theaters, once prominent cinema/theatre haunts before the new millennium owned by the Sharan Brothers, have since closed down. A development expected to be finished at the beginning of 2013 is the Damodar city complex (also owned by the Damodar brothers), in the shopping area of Laucala Bay, which will have a further six screens, along with shopping and eating outlets and cafes.
Another interesting feature of Suva is the increasing number of Bollywood films being shot in the capital: By the middle 2012 alone, there have been around six movies partly shot in Suva.
Sports.
Suva plays host to many regional and national sporting events, most notably at the ANZ National Stadium. A special highlight is the Coca-Cola Games, the largest secondary school athletics meet in the world. The Capital City is represented in major sporting events by its respective rugby, netball and soccer teams.
Suva was the host of the first Pacific Games, in 1963. Forty years later in 2003 the Games returned to Fiji's capital, with a full program of 32 sports introduced for the first time. Suva held the games for the second time in 1979. Having hosted the event three times, Suva has held the Pacific Games more often than any other city.
Mass media.
Headquartered in Suva are the three main national television stations, Fiji One, FBC TV and MAI TV along with the Fiji Ministry of Information, which produces government programs as well as national news and current affairs bulletins. Fiji One produces and airs its evening 'National News' bulletin from its studios in Gladstone Road in Central; FBC TV airs its 'FBC News' bulletin from its studios, also on Gladstone Road. Sky Pacific and Pacific Broadcasting Services Fiji are the two pay satellite television company headquartered here.
Suva is home to the national radio broadcasters Fiji Broadcasting Corporation (FBC) and Communications Fiji Limited (CFL), between them providing 12 of the national radio stations.
The two dailies, "The Fiji Times" and "The Fiji Sun" are printed here (and, formerly, the "Fiji Post"). Many other weekly newspapers are headquartered and published in Suva, including "Inside Fiji", "Nai Lalakai" (iTaukei language weekly), "Shanti Dut" (Fiji Hindi weekly), national magazines such as "Repúblika" and "Mai Life" as well as regional magazines such as "Islands Business".
Shopping and fashion.
Suva is one of the most shopper friendly cities in the Pacific and has long been known for its affordable and unique offerings, often duty-free. The city offers its shopping paradise in a cluster that is referred to as Suva Central. Areas like Cumming Street and Marks Street are for clothing, jewellery, food, electronics, pharmaceuticals and more. Terry Walk and the Flea Market offer handicrafts and local ware. Close by, huge, new shopping complexes dominate the canal area, such as MHCC, Tappoo City and Suva Central. The general outer areas of this radius are telecommunication and electronic stores, tourist favourite - Jack's and sporting gear stores.
Every year, Suva plays host to Fiji Fashion Week (FJFW) usually held in Suva and a condensed version in Nadi over consecutive weeks in late October. The shows offer the creations of local and overseas designers as well as shows focused on wearable art. FJFW began in 2008, with a show at the Hilton Hotel in Denarau, with the 2009 show at Albert Park. In 2010, Fiji Fashion Week was a bigger extravaganza with a Fashion Film Festival as well. FJFW 2010 was held at Boron House (a state mansion) where the shows were broadcast internationally by world-renowned Fashion TV. In 2011, the show took on a distinct urban theme with the show held on the sixth floor of the Tappoo City building with the city of Suva as a backdrop and for the first time, included models from overseas (mostly, international models who were in Fiji for the World Supermodel Competition). Fiji Fashion Week 2012 brings together designers from France, USA, India, Australia, New Zealand, Philippines, Nigeria, Samoa, Cook Islands, Wallis & Futuna and Fiji. It will once again be shown on Fashion TV.
Transportation.
Nausori International Airport caters mainly to the domestic market, connecting Suva with Fiji's other international airport, Nadi International Airport, and serves smaller international aircraft, at one time servicing Brisbane and Sydney routes. As of August 2010, Air Pacific will operate a twice weekly flight from Nausori International Airport to Auckland, New Zealand to complement its 13 weekly flights from Nadi to Auckland, furthermore, the Nausori - Sydney route is expected to resume in the later half of 2012. The airport provides services to its immediate Pacific neighbours Tonga and Tuvalu as well as the dependency of Rotuma.
Suva has a public transport system consisting of buses and taxis servicing the metropolitan area as well as the cities of Nasinu, Nausori and Lami town. There are bus services connecting Suva with other towns and cities on Viti levu by way of either the Kings, Queens or Princes highways, all originating within Suva, although the latter terminates at Rewa Bridge in Nausori. As of January 2012, a feasibility study was being conducted by JRK and Associates, in partnership with Canadian company Hatch Mott McDonald, to construct and operate a monorail train network from Suva, across the Suva - Nausori Corridor to ease congestion and traffic problems. The construction of the monorail system is expected to begin in the first quarter of 2013.
There is a domestic ferry services from the Princess Wharf to the outer islands of Fiji as well as Vanua Levu. International ships and cruise liners dock at Suva's Kings Wharf.
Notable residents and/or people from Suva.
This is a list of famous people who are either currently living in, or are originally from Suva.

</doc>
<doc id="42905" url="https://en.wikipedia.org/wiki?curid=42905" title="North American Aerospace Defense Command">
North American Aerospace Defense Command

North American Aerospace Defense Command (NORAD, ), known until March 1981 as the North American Air Defense Command, is a combined organization of the United States and Canada that provides aerospace warning, air sovereignty, and defense for Northern America. Headquarters for NORAD and the NORAD/United States Northern Command (USNORTHCOM) center are located at Peterson Air Force Base in El Paso County, near Colorado Springs, Colorado. The nearby Cheyenne Mountain Complex has the Alternate Command Center. The NORAD commander and deputy commander (CINCNORAD) are, respectively, a United States four-star general or equivalent and a Canadian three-star general or equivalent.
Organization.
CINCNORAD maintains the NORAD headquarters at Peterson Air Force Base near Colorado Springs, Colorado. The NORAD and USNORTHCOM Command Center at Peterson AFB serves as a central collection and coordination facility for a worldwide system of sensors designed to provide the commander and the leadership of Canada and the U.S. with an accurate picture of any aerospace or maritime threat. NORAD has administratively divided the North American landmass into three regions: the Alaska NORAD (ANR) Region, under Eleventh Air Force (11 AF); the Canadian NORAD (CANR) Region, under 1 Canadian Air Division, and the Continental U.S. (CONR) Region, under 1 AF/CONR-AFNORTH. Both the CONR and CANR regions are divided into eastern and western sectors.
Alaska NORAD Region.
The Alaska NORAD Region (ANR) maintains continuous capability to detect, validate and warn off any atmospheric threat in its area of operations from its Regional Operations Control Center (ROCC) at Joint Base Elmendorf–Richardson, Alaska (which is an amalgamation of the United States Air Force's Elmendorf Air Force Base and the United States Army's Fort Richardson, which were merged in 2010).
ANR also maintains the readiness to conduct a continuum of aerospace control missions, which include daily air sovereignty in peacetime, contingency and/or deterrence in time of tension, and active air defense against manned and unmanned air-breathing atmospheric vehicles in times of crisis.
ANR is supported by both active duty and reserve units. Active duty forces are provided by 11 AF and the Canadian Armed Forces (CAF), and reserve forces provided by the Alaska Air National Guard. Both 11 AF and the CAF provide active duty personnel to the ROCC to maintain continuous surveillance of Alaskan airspace.
Canadian NORAD Region.
1 Canadian Air Division/Canadian NORAD Region Headquarters is at CFB Winnipeg, Manitoba. It was established on 22 April 1983. It is responsible for providing surveillance and control of Canadian airspace. The Royal Canadian Air Force provides alert assets to NORAD. CANR is divided into two sectors, which are designated as the Canada East Sector and Canada West Sector. Both Sector Operations Control Centers (SOCCs) are co-located at CFB North Bay Ontario. The routine operation of the SOCCs includes reporting track data, sensor status and aircraft alert status to NORAD headquarters.
Canadian air defense forces assigned to NORAD include 409 Tactical Fighter Squadron at CFB Cold Lake, Alberta and 425 Tactical Fighter Squadron at CFB Bagotville, Quebec. All squadrons fly the McDonnell Douglas CF-18 Hornet fighter aircraft.
To monitor for drug trafficking, in cooperation with the Royal Canadian Mounted Police and the United States drug law enforcement agencies, the Canadian NORAD Region monitors all air traffic approaching the coast of Canada. Any aircraft that has not filed a flight plan may be directed to land and be inspected by RCMP and Canada Border Services Agency.
United States NORAD Region.
The Continental NORAD Region (CONR) is the component of NORAD that provides airspace surveillance and control and directs air sovereignty activities for the Contiguous United States (CONUS).
CONR is the NORAD designation of the United States Air Force First Air Force/AFNORTH. Its headquarters is located at Tyndall Air Force Base, Florida. The First Air Force (1 AF) became responsible for the USAF air defense mission on 30 September 1990. AFNORTH is the United States Air Force component of United States Northern Command (NORTHCOM).
1 AF/CONR-AFNORTH comprises State Air National Guard Fighter Wings assigned an air defense mission to 1 AF/CONR-AFNORTH, made up primarily of citizen Airmen. The primary weapons systems are the McDonnell Douglas F-15 Eagle and General Dynamics F-16 Fighting Falcon aircraft.
It plans, conducts, controls, coordinates and ensures air sovereignty and provides for the unilateral defense of the United States. It is organized with a combined First Air Force command post at Tyndall Air Force Base and two Sector Operations Control Centers (SOCC) at Rome, New York for the US East ROCC (Eastern Air Defense Sector) and McChord Field, Washington for the US West ROCC (Western Air Defense Sector) manned by active duty personnel to maintain continuous surveillance of CONUS airspace.
In its role as the CONUS NORAD Region, 1 AF/CONR-AFNORTH also performs counter-drug surveillance operations.
History.
NORAD (originally known as the North American Air Defense Command), was recommended by the Joint Canadian-U.S. Military Group in late 1956, approved by the United States JCS in February 1957, and announced on 1 August 1957; the "establishment of command headquarters" was on 12 September 1957, at Ent Air Force Base's 1954 blockhouse. The 1958 international agreement designated the NORAD commander always be a United States officer (Canadian vice commander), and "Royal Canadian Air Force officers ... agreed the command's primary purpose would be…early warning and defense for SAC's retaliatory forces." In late 1958, Canada and the United States started the Continental Air Defense Integration North (CADIN) for the SAGE air defense network (initial CADIN cost sharing agreement between the countries was on 5 January 1959), and two December 1958 plans submitted by NORAD had "average yearly expenditure of around five and one half billions", including "cost of the accelerated Nike Zeus program" and three Ballistic Missile Early Warning System (BMEWS) sites.
Canada's NORAD bunker with a SAGE AN/FSQ-7 Combat Direction Central computer was constructed from 1959 to 1963, and each of the USAF's eight smaller AN/FSQ-8 Combat Control Central systems provided NORAD with data and could command the entire United States air defense. The RCAF's 1950 "ground observer system, the Long Range Air Raid Warning System," was discontinued and on 31 January 1959, the United States Ground Observer Corps was deactivated. The Cheyenne Mountain nuclear bunker's planned mission was expanded in August 1960 to "a hardened center from which CINCNORAD would supervise and direct operations "against space attack" as well as air attack" (NORAD would be renamed North American Aero"space" Defense Command in March 1981). The Secretary of Defense assigned on 7 October 1960, "operational command of all space surveillance to Continental Air Defense Command (CONAD) and operational control to North American Air Defense Command (NORAD)".
The JCS placed the Ent Air Force Base Space Detection and Tracking System (496L System with Philco 2000 Model 212 computer) "under the operational control of CINCNORAD on December 1, 1960"; during Cheyenne Mountain nuclear bunker excavation, and the joint SAC-NORAD exercise "Sky Shield II"—and on 2 September 1962—"Sky Shield III" were conducted for mock penetration of NORAD sectors.
NORAD command center operations moved from Ent Air Force Base to the 1963 partially underground "Combined Operations Center" for Aerospace Defense Command and NORAD at the Chidlaw Building. President John F. Kennedy visited "NORAD headquarters" after the 5 June 1963 United States Air Force Academy graduation. and on 30 October 1964, "NORAD began manning" the Combat Operations Center in the Cheyenne Mountain Complex. By 1965, about 250,000 United States and Canadian personnel were involved in the operation of NORAD, On 1 January 1966, Air Force Systems Command turned the COC over to NORAD The NORAD Cheyenne Mountain Complex was accepted on 8 February 1966.
1968 reorganization.
United States Department of Defense realignments for the NORAD command organization began by 15 November 1968 ("e.g.", Army Air Defense Command (ARADCOM))Rings of Supersonic Steel: Air Defenses of the United States Army 1950–1979--></ref> and by 1972, there were eight NORAD "regional areas ... for all air defense", and the NORAD Cheyenne Mountain Complex Improvements Program (427M System) became operational in 1979.
False alarms.
On at least three occasions, NORAD systems failed, such as on 9 November 1979, when a technician in NORAD loaded a test tape, but failed to switch the system status to "test", causing a stream of constant false warnings to spread to two "continuity of government" bunkers as well as command posts worldwide. On 3 June 1980, and again on 6 June 1980, a computer communications device failure caused warning messages to sporadically flash in U.S. Air Force command posts around the world that a nuclear attack was taking place.</ref> During these incidents, Pacific Air Forces (PACAF) properly had their planes (loaded with nuclear bombs) in the air; Strategic Air Command (SAC) did not and took criticism, because they did not follow procedure, even though the SAC command knew these were almost certainly false alarms, as did PACAF. Both command posts had recently begun receiving and processing direct reports from the various radar, satellite, and other missile attack detection systems, and those direct reports simply did not match anything about the erroneous data received from NORAD.
1980 reorganization.
Following the 1979 Joint US-Canada Air Defense Study, the command structure for aerospace defense was changed, "e.g.", "SAC assumed control of ballistic missile warning and space surveillance facilities" on 1 December 1979 from ADCOM. The Aerospace Defense Command major command ended 31 March 1980. and its organizations in Cheyenne Mountain became the "ADCOM" "specified" command under the same commander as NORAD, "e.g.", HQ NORAD/ADCOM J31 manned the Space Surveillance Center. By 1982, a NORAD Off-site Test Facility was located at Peterson AFB. The DEW Line was to be replaced with the North Warning System (NWS); the Over-the-Horizon Backscatter (OTH-B) radar was to be deployed; more advanced fighters were deployed, and E-3 Sentry AWACS aircraft were planned for greater use. These recommendations were accepted by the governments in 1985. The United States Space Command was formed in September 1985 as an adjunct, but not a component of NORAD.
Post–Cold War.
In 1989 NORAD operations expanded to cover counter-drug operations, "e.g.", tracking of small aircraft entering and operating within the United States and Canada. DEW line sites were replaced between 1986 and 1995 by the North Warning System. The Cheyenne Mountain site was also upgraded, but none of the proposed OTH-B radars are currently in operation.
After the September 11, 2001 attacks, the NORAD Air Warning Center's mission "expanded to include the interior airspace of North America."
The Cheyenne Mountain Realignment was announced on 28 July 2006, to consolidate NORAD's day-to-day operations at Peterson Air Force Base with Cheyenne Mountain in "warm standby" staffed with support personnel.
In popular culture.
Movies and television.
The NORAD command center was depicted in the satirical film "Dr. Strangelove" that starred Peter Sellers and in the drama "Fail-Safe," which starred Henry Fonda. Both films were released in 1964; a television adaptation of "Fail-Safe" starring George Clooney and Richard Dreyfuss was broadcast live on CBS in 2000.
Cheyenne Mountain is a setting of the 1983 film "WarGames" and the television series "Jeremiah" and "Stargate".
NORAD HQ is a retreat facility for NASA in the mid/late 21st century in the 2014 science fiction film "Interstellar".
In the film "The Sum of All Fears", the Russian military intends to destroy NORAD headquarters.
NORAD Tracks Santa.
As a publicity move on December 24, 1955, NORAD's predecessor, the Continental Air Defense Command (CONAD), informed the press that CONAD was tracking Santa Claus's sleigh, adding that "CONAD, Army, Navy and Marine Air Forces will continue to track and guard Santa and his sleigh on his trip to and from the U.S. against possible attack from those who do not believe in Christmas," and a Christmas Eve tradition was born, known as the "NORAD Tracks Santa" program. Every year on Christmas Eve, "NORAD Tracks Santa" purports to track Santa Claus as he leaves the North Pole and delivers presents to children around the world. Today, NORAD relies on volunteers to make the program possible.

</doc>
<doc id="42906" url="https://en.wikipedia.org/wiki?curid=42906" title="The Queen of the Damned">
The Queen of the Damned

The Queen of the Damned (1988) is the third novel of Anne Rice's "The Vampire Chronicles" series. It follows "Interview with the Vampire" and "The Vampire Lestat". This novel is a continuation of the story that ends in a cliffhanger in "The Vampire Lestat" and explores the rich history and mythology of the origin of the vampires, which dates back to Ancient Egypt.
On March 9, 2014, it was announced that there would be another installment of "The Vampire Chronicles" titled "Prince Lestat" which would be a sequel to "The Queen of the Damned". The novel was released on October 28, 2014.
Plot summary.
Part One follows several different people over the same period of several days. Several of the characters appear in the two previous books, including Armand, Daniel (the "boy reporter" of "Interview with the Vampire"), Marius, Louis, Gabrielle and Santino. Each of the six chapters in Part One tells a different story about a different person or group of people. Two things unify these chapters: a series of dreams about red-haired twin sisters, and the fact that a powerful being is killing vampires around the world by means of spontaneous combustion.
Pandora and Santino rescue Marius, having answered his telepathic call for help. Marius informs his rescuers that Akasha has been awakened by Lestat, or rather his rock music, for he has joined a rock band of mortals whose names are Alex, Larry and Tough Cookie. Having been awakened by Lestat's rebellious music, Akasha destroys her husband Enkil and plots to rule the world. Akasha is also revealed as the source of the attacks on other vampires.
Part Two takes place at Lestat's concert. Jesse Reeves, a member of the secret Talamasca and relative of Maharet, is mortally injured while attending the concert, and is taken to Maharet's Sonoma compound where she is made into a vampire. The vampires from Part One later congregate in the Sonoma compound. The only vampires not present are Akasha and Lestat. Akasha has abducted Lestat and takes him as an unwilling consort to various locations in the world, inciting women to rise up and kill the men who have oppressed them.
Part Three takes place at Maharet's home in a Sonoma forest. There Maharet tells the story of Akasha and the red-haired twins (who are, in fact, Maharet and her sister, Mekare) to Pandora, Jesse, Marius, Santino, Eric, Armand, Daniel, Louis and Gabrielle. Also present are Mael and Khayman, who already know the story.
In Part Four, Akasha confronts the gathered vampires at Maharet's compound. There she explains her plans and offers the vampires a chance to be her "angels" in her New World Order. Akasha plans to kill 90 percent of the world's human men, and to establish a new Eden in which women will worship Akasha as a goddess. If the assembled vampires refuse to follow her, she will destroy them. The vampires refuse, but before Akasha can destroy them, Mekare enters. Mekare kills Akasha by severing her head and then consumes Akasha's brain and heart. Amel passes into Mekare, thereby saving the lives of the remaining vampires. She becomes the new Queen of the Damned.
In Part Five, the vampires leave Maharet's compound and assemble at Armand's resort, the Night Island, (according to Anne Rice, inspired by Fire Island) in Florida to recover. They eventually go their separate ways (as told in "The Tale of the Body Thief"). Lestat takes Louis to see David Talbot in London. After their brief visit with Talbot they depart into the night, an incensed Louis and his angry words filling Lestat with glee.
The Origin of Vampires.
"The Queen of the Damned", deals with the origins of vampires themselves. The mother of all vampires, Akasha, begins as a pre-Egyptian queen, in a land called Kemet (which will become Egypt), many thousands of years ago. During this time two powerful witches (Maharet and Mekare) live in the mountains of an unnamed region. The witches are able to communicate with invisible spirits and gain simple favors from them. During this period there is a bloodthirsty, invisible spirit known as Amel who continually asks the two witches if they need his assistance, although they prudently decline the offer. The witches' village is destroyed and they are incarcerated by the king and queen, who desire their knowledge. When the witches offend Akasha, the Queen condemns the twins. Enkil then orders his chief steward (who is Khayman as a mortal man) to rape the twins in his stead, which would prove their lack of power, before the eyes of the court. Afterward the witches are cast out into the desert. While making her way back home with a pregnant Maharet, Mekare curses the king and queen secretly with the bloodthirsty spirit. Eventually this spirit inflicts such torment on Akasha and Enkil that they again demand advice and help from the two witches.
Conspirators, unhappy with the young king's policies, assassinate the royal couple in Khayman's house while they were attempting to exorcise Amel, who had been tormenting Khayman. While the king and queen lie dying, the evil spirit sees its chance to ensnare the soul of the dying queen and pulls it back into her body. The spirit combines itself with the flesh and blood of the queen, transforming her into a vampire. Akasha allows the king to drink her blood, which saves his life. They then order Khayman to find the witches and bring them back to Egypt so that they could use their knowledge of spirits to help them, as they feel guilty because of their thirst for blood. However, when the witches admit that they cannot help the monarchs, Akasha orders the mutilation of the witches: Maharet loses her eyes and Mekare her tongue. Afterward, Khayman, who had been turned into a vampire by Akasha, comes to the witches' cell and turns them too. The three flee together, but are caught by Akasha's soldiers. Khayman escapes, but Maharet and Mekare are further punished. The witches are put into two separate coffins which are then set afloat on two separate bodies of water. They are only reunited near the end of the novel "Queen of the Damned".
In Mekare's absence, Maharet returns to watch over her daughter and her descendants. Maharet's descendants become what she calls the Great Family. A maternal line, the Great Family includes every culture, religion, ethnicity, and race. The Great Family represents all humanity and shows the vampires what Akasha would destroy with the creation of her New World Order.
As the source of all vampires, Akasha is connected to all vampires by the blood and spirit they collectively share. In an experiment by the first Keeper, Akasha and Enkil are exposed to sunlight when they are several thousand years old. This merely darkens their skin. However, the result on all other vampires is extreme, and many of the weakest vampires die, thus confirming the legend that anything that harms Akasha will also directly affect all of her progeny.

</doc>
<doc id="42909" url="https://en.wikipedia.org/wiki?curid=42909" title="Jacobus Henricus van 't Hoff">
Jacobus Henricus van 't Hoff

Jacobus Henricus van 't Hoff, Jr. (; 30 August 1852 – 1 March 1911) was a Dutch physical and organic chemist and the first winner of the Nobel Prize in Chemistry. He is best known for his discoveries in chemical kinetics, chemical equilibrium, osmotic pressure, and stereochemistry. Van 't Hoff's work in these subjects helped found the discipline of physical chemistry as it is today.
Biography.
The third of seven children, Van 't Hoff was born in Rotterdam, Netherlands, 30 August 1852. His father was Jacobus Henricus van 't Hoff, Sr., a physician, and his mother was Alida Kolff van 't Hoff. From a young age, he was interested in science and nature, and frequently took part in botanical excursions. In his early school years, he showed a strong interest in poetry and philosophy. He considered Lord Byron to be his idol.
Against the wishes of his father, Van 't Hoff chose to study chemistry. First, he enrolled at Delft University of Technology in September 1869, and studied until 1871, when he passed his final exam on at 8 July and obtained a degree of chemical technologist. He passed all his courses in two years, although the time assigned to study was three years. Then he enrolled at University of Leiden to study chemistry. He then studied in Bonn, Germany with Friedrich Kekulé and in Paris with C. A. Wurtz. He received his doctorate under Eduard Mulder at the University of Utrecht in 1874.
In 1878, Van 't Hoff married Johanna Francina Mees. They had two daughters, Johanna Francina (b. 1880) and Aleida Jacoba (b. 1882), and two sons, Jacobus Henricus van 't Hoff III (b. 1883) and Govert Jacob (b. 1889). Van 't Hoff died at the age of 58, on 1 March 1911, at Steglitz, near Berlin, from tuberculosis.
Career.
Van 't Hoff earned his earliest reputation in the field of organic chemistry. In 1874, he accounted for the phenomenon of optical activity by assuming that the chemical bonds between carbon atoms and their neighbors were directed towards the corners of a regular tetrahedron. This three-dimensional structure accounted for the isomers found in nature. He shares credit for this with the French chemist Joseph Le Bel, who independently came up with the same idea.
Three months before his doctoral degree was awarded Van 't Hoff published this theory, which today is regarded as the foundation of stereochemistry, first in a Dutch pamphlet in the fall of 1874, and then in the following May in a small French book entitled "La chimie dans l'espace". A German translation appeared in 1877, at a time when the only job van 't Hoff could find was at the Veterinary School in Utrecht. In these early years his theory was largely ignored by the scientific community, and was sharply criticized by one prominent chemist, Hermann Kolbe. Kolbe wrote:
"A Dr. J. H. van ’t Hoff of the Veterinary School at Utrecht has no liking, apparently, for exact chemical investigation. He has considered it more convenient to mount Pegasus (apparently borrowed from the Veterinary School) and to proclaim in his "‘La chimie dans l’espace’" how, in his bold flight to the top of the chemical Parnassus, the atoms appeared to him to be arranged in cosmic space." However, by about 1880 support for van 't Hoff's theory by such important chemists as Johannes Wislicenus and Viktor Meyer brought recognition.
In 1884, Van 't Hoff published his research on chemical kinetics, titled "Études de Dynamique chimique" (""Studies in Chemical Dynamics""), in which he described a new method for determining the order of a reaction using graphics and applied the laws of thermodynamics to chemical equilibria. He also introduced the modern concept of chemical affinity. In 1886, he showed a similarity between the behaviour of dilute solutions and gases. In 1887, he and German chemist Wilhelm Ostwald founded an influential scientific magazine named "Zeitschrift für physikalische Chemie" (""Journal of Physical Chemistry""). He worked on Svante Arrhenius's theory of the dissociation of electrolytes and in 1889 provided physical justification for the Arrhenius equation. In 1896, he became a professor at the Prussian Academy of Sciences in Berlin. His studies of the salt deposits at Stassfurt were an important contribution to Prussia's chemical industry.
Van 't Hoff became a lecturer in chemistry and physics at the Veterinary College in Utrecht. He then worked as a professor of chemistry, mineralogy, and geology at the University of Amsterdam for almost 18 years before eventually becoming the chairman of the chemistry department. In 1896, Van 't Hoff moved to Germany, where he finished his career at the University of Berlin in 1911. In 1901, he received the first Nobel Prize in Chemistry for his work with solutions. His work showed that very dilute solutions follow mathematical laws that closely resemble the laws describing the behavior of gases.
Honours and awards.
In 1885, Van 't Hoff was appointed as a member of the Royal Netherlands Academy of Sciences. Other distinctions include honorary doctorates from Harvard and Yale (1901), Victoria University, the University of Manchester (1903), and University of Heidelberg (1908). He was awarded the Davy Medal of the Royal Society in 1893 (along with Le Bel), and elected a Foreign Member of the Royal Society (ForMemRS) in 1897. He was awarded the Helmholtz Medal of the Prussian Academy of Sciences (1911) and appointed "Chevalier de la Légion d'honneur" (1894) and "Senator der Kaiser-Wilhelm-Gesellschaft" (1911). Van 't Hoff became an honorary member of the British Chemical Society in London, the Royal Dutch Academy of Sciences (1892), American Chemical Society (1898), and the Académie des Sciences, in Paris (1905). Of his numerous distinctions, Van 't Hoff regarded winning the first Nobel Prize in Chemistry as the culmination of his career. The following are named after him:

</doc>
<doc id="42910" url="https://en.wikipedia.org/wiki?curid=42910" title="JavaServer Pages">
JavaServer Pages

JavaServer Pages (JSP) is a technology that helps software developers create dynamically generated web pages based on HTML, XML, or other document types. Released in 1999 by Sun Microsystems, JSP is similar to PHP and ASP, but it uses the Java programming language.
To deploy and run JavaServer Pages, a compatible web server with a servlet container, such as Apache Tomcat or Jetty, is required.
Overview.
Architecturally, JSP may be viewed as a high-level abstraction of Java servlets. JSPs are translated into servlets at runtime; each JSP servlet is cached and re-used until the original JSP is modified.
JSP can be used independently or as the view component of a server-side model–view–controller design, normally with JavaBeans as the model and Java servlets (or a framework such as Apache Struts) as the controller. This is a type of Model 2 architecture.
JSP allows Java code and certain pre-defined actions to be interleaved with static web markup content, such as HTML, with the resulting page being compiled and executed on the server to deliver a document. The compiled pages, as well as any dependent Java libraries, contain Java bytecode rather than machine code. Like any other Java program, they must be executed within a Java virtual machine (JVM) that interacts with the server's host operating system to provide an abstract, platform-neutral environment.
JSPs are usually used to deliver HTML and XML documents, but through the use of OutputStream, they can deliver other types of data as well.
The Web container creates JSP implicit objects like pageContext, servletContext, session, request & response.
Syntax.
JSP pages use several delimiters for scripting functions. The most basic is <% ... %>, which encloses a JSP "scriptlet." A scriptlet is a fragment of Java code that is run when the user requests the page. Other common delimiters include <%= ... %> for "expressions," where the scriptlet and delimiters are replaced with the result of evaluating the expression, and "directives", denoted with <%@ ... %>.
Java code is not required to be complete or self-contained within a single scriptlet block. It can straddle markup content, provided that the page as a whole is syntactically correct. For example, any Java "if/for/while" blocks opened in one scriptlet must be correctly closed in a later scriptlet for the page to successfully compile.
Content which falls inside a split block of Java code (spanning multiple scriptlets) is subject to that code. Content inside an "if" block will only appear in the output when the "if" condition evaluates to true. Likewise, content inside a loop construct may appear multiple times in the output, depending upon how many times the loop body runs.
The following would be a valid for loop in a JSP page:
The output displayed in the user's web browser would be:
Expression Language.
Version 2.0 of the JSP specification added support for the Expression Language (EL), used to access data and functions in Java objects. In JSP 2.1, it was folded into the Unified Expression Language, which is also used in JavaServer Faces.
An example of EL syntax:
Additional tags.
The JSP syntax add additional tags, called JSP actions, to invoke built-in functionality. Additionally, the technology allows for the creation of custom JSP "tag libraries" that act as extensions to the standard JSP syntax. One such library is the JSTL, with support for common tasks such as iteration and conditionals (the equivalent of "for" and "if" statements in Java.)
Compiler.
A JavaServer Pages compiler is a program that parses JSPs, and transforms them into executable Java Servlets. A program of this type is usually embedded into the application server and run automatically the first time a JSP is accessed, but pages may also be precompiled for better performance, or compiled as a part of the build process to test for errors.
Some JSP containers support configuring how often the container checks JSP file timestamps to see whether the page has changed. Typically, this timestamp would be set to a short interval (perhaps seconds) during software development, and a longer interval (perhaps minutes, or even never) for a deployed Web application.
Criticism.
In 2000, Jason Hunter, author of "Java Servlet Programming", criticized JSP for either tempting or requiring the programmer to mix Java code and HTML markup, although he acknowledged it would "wean people off" of Microsoft's Active Server Pages. Later, he added a note to his site saying that JSP had improved since 2000, but also cited its competitors, Apache Velocity and Tea (template language).

</doc>
<doc id="42914" url="https://en.wikipedia.org/wiki?curid=42914" title="Concordia University">
Concordia University

Concordia University (commonly referred to as Concordia) is a public comprehensive university located in Montreal, Quebec, Canada. Founded in 1974 following the merger of Loyola College and Sir George Williams University, Concordia is one of the two universities in Montreal where English is the primary language of instruction. As of the 2014-2015 academic year, there were 46,378 students enrolled at Concordia, making the university among the largest in Canada by enrollment. The university has two campuses, set approximately apart: Sir George Williams Campus is the main campus in the downtown core of Montreal, in an area known as Quartier Concordia, and Loyola Campus in the residential district of Notre-Dame-de-Grâce. With four faculties, a school of graduate studies and numerous colleges, centres and institutes, Concordia offers over 300 undergraduate and 100 graduate programs and courses.
The university is ranked 16th in Canada and 411th worldwide by "QS World University Rankings" and is ranked 91st in the 2015 "Times Higher Education" ranking of the top 100 universities worldwide under 50 years old. The university's John Molson School of Business is consistently ranked within the top ten Canadian business schools, and within the top 100 worldwide. Moreover, Concordia was ranked 7th among Canadian and 229th among world universities in the International Professional Classification of Higher Education Institutions, a worldwide ranking compiled by the École des Mines de Paris that uses as its sole criterion the number of graduates occupying the rank of Chief Executive Officer at Fortune 500 companies.
Concordia is a non-sectarian and coeducational institution, with over 193,000 living alumni worldwide.
The University is a member of the Association of Universities and Colleges of Canada, the International Association of Universities, the Association of Commonwealth Universities, the Canadian Association of Research Libraries, the Canadian University Society for Intercollegiate Debate as well as the Canadian Bureau for International Education and the Canadian University Press. The university's varsity teams, known as the Stingers, compete in the Quebec Student Sport Federation of Canadian Interuniversity Sport.
History.
Although the roots of its founding institutions go back more than 160 years, Concordia University was formed on August 24, 1974, through the merger of Loyola College (1896) and Sir George Williams University (1926). Since its inception, Concordia has changed its logo four times.
Loyola College.
Loyola College traces its roots to an English-language program at the Jesuit Collège Sainte-Marie de Montréal (today part of the Université du Québec à Montréal) at the Sacred Heart Convent. In 1896, Loyola College was established at the corner of Bleury Street and Saint Catherine Street. Loyola College was named in honour of Ignatius of Loyola, founder of the Society of Jesus. On March 10, 1898, the institution was incorporated by the Government of Quebec and became a full-fledged college. The same year, following a fire, the college was relocated, further west on Drummond Street, south of Saint Catherine. Although founded as a "collège classique" (the forerunners of Quebec's college system), Loyola began granting university degrees through Université Laval in 1903.
The college moved into the present west-end campus on Sherbrooke Street West in Notre-Dame-de-Grâce in 1916. The School of Sociology opened in 1918. In 1920, the institution became affiliated with the Université de Montréal, which began granting degrees instead of Université Laval.
Memorial bronze honour roll plaques in the entrance hall, administrative offices are dedicated to those from Loyola College who fought in the First and Second World Wars and the Korean War.
The inter-war period was marked by the shift of education in the institution, the "collège classique" education was replaced by humanistic education (Liberal Arts College) in 1940, and Loyola became a four-year university. Loyola College never became a chartered university, and never had the ability to grant its own university degrees. Theology and philosophy were subjects taught to all students until 1972.
In 1940, the Faculty of Science and the Department of Engineering, which became a faculty in 1964, were created. In addition to providing the same undergraduate programs as other colleges, the institution also offered innovative fields of study at the time, such as exercise science and communication studies. Students could enroll in Academic majors starting in 1953 and honors programs in 1958. Students graduating from Loyola could afterwards pursue graduate-level education in other universities, with a few earning Rhodes Scholarships.
Starting in 1958, Loyola also began offering its first evening courses for students not being able to go to school full-time. New courses were given in library science and faith community nursing. Since its creation, Loyola College had welcomed almost exclusively young English-speaking Catholic men as students. It became co-ed in 1959 and became less homogeneous with the ever increasing number of foreign students.
Obtaining a university charter was an important issue in the 1960s. Although many wanted the Loyola College to become Loyola University, the Quebec government preferred to annex it to Sir George Williams University. Negotiations began in 1968 and ended with the creation of Concordia University on August 24, 1974.
Sir George Williams University.
In 1851, the first YMCA in North America was established on Ste-Helene street in Old Montreal. Beginning in 1873, the YMCA offered evening classes to allow working people in the English-speaking community to pursue their education while working during the day. Sixty years later, the Montreal YMCA relocated to its current location on Stanley Street in Downtown Montreal. In 1926, the education program at the YMCA was re-organized as Sir George Williams College, named after George Williams, founder of the original YMCA in London, upon which the Montreal YMCA was based. In 1934, Sir George Williams College offered the first undergraduate credit course in adult education in Canada.
The Sir George Williams College became Sir George Williams University (SGWU) in 1948, when it received a university charter from the provincial government, though it remained the education arm of the Montreal YMCA. SGWU expanded into its first standalone building, the Norris Building, in 1956. It established a Centre for Human Relations and Community Studies in 1963. SGWU continued to hold classes in the YMCA building until the construction of the Henry F. Hall Building in 1966.
The university gained international attention in 1969, when a group of students occupied the Hall Building's 9th floor computer lab (see Sir George Williams Computer Riot).
Following several years of discussions and planning, Sir George Williams University merged with Loyola College to create Concordia University in 1974. Concordia provided students with representative student organizations and greater power over administrative decisions at the University.
Merger.
In 1968, in the wake of the Parent Commission Report, which recommended for the secularization of Quebec's educational system, the Quebec government asked Loyola College and Sir George Williams University to consider some form of union. The proposed merger was discussed by the "Loyola-Sir George Williams Joint Steering Committee", a committee created to analyze all forms of possible mergers of the two institutions. It was proposed, in 1969, to create a university federation which allowed students to take courses at both campuses without paying additional fees. There is also mention of a shuttle bus service linking the remote facilities apart.
Criticized for the difficulties encountered by the cohesion of the various departments and faculties, this option was set aside, but not totally rejected by the Joint Steering Committee. The "Joint Committee of Representatives of the Board of Trustees of Loyola College and the Board of Governors of Sir George Williams University" was formed in December 1971 and produced in the fall of 1972, a document outlining the basis of a university with two campuses. While a number of possible models were considered, including that of a loose federation, the solution finally adopted was that of an integrated institution, Concordia University, operating under the existing charter of Sir George Williams University. Following several revisions in November 1972, the document became the main plan of the proposed merger. It was accepted by both institutions, which begun the process of consolidating their operations.
In early 1973, the two institutions announced the merger would take place that fall. However, legal and administrative procedures delayed the merger for another year. On August 24, 1974, the Government of Quebec recognized the merger, thus creating Concordia University. The name was taken from the motto of the city of Montreal, "Concordia salus" (meaning 'well-being through harmony').
Post merger.
The legal existence of Concordia dates from August 24, 1974. The integration of the various faculties of the two institutions into a coherent whole took several years. The five faculties of the new university were a combination of existing faculties and departments prior to the merger. There was a Faculty of Commerce, a Faculty of Science and Faculty of Arts at Sir George Williams University. Additionally, there was a Faculty of Arts and Science from Loyola College. The Faculty of Engineering of both institutions had previously been combined.
The Faculty of Fine Arts was created in 1976.
The first phase of combination of the Faculties of Arts and Science began in 1977 and ended in 1985.
In the late 1980s, the Georges P. Vanier Library on the Loyola Campus was enlarged, while in 1992, the library on Sir George Williams Campus moved to the new J.W. McConnell Building. The Norris Building was closed the same year.
On August 24, 1992, Valery Fabrikant, a Mechanical Engineering professor, shot five colleagues, killing four, on the ninth floor of the Hall Building. Fabrikant was convicted of the murders and sentenced to life imprisonment. The university erected a memorial to the slain professors (four granite tables) in the Hall Building lobby.
Starting in 1998, the University entered a major phase of expansion to meet its growing student enrollment. In August 2003, Concordia inaugurated the Richard J. Renaud Science Complex on Loyola Campus.
On September 9, 2002, a scheduled visit from the then former (and now current) Israeli Prime Minister Benjamin Netanyahu was cancelled after Montreal Police and pro-Palestinian protesters clashed inside the Henry F. Hall Building.
In 2005, the University launched a major urban redevelopment project in the neighbourhood surrounding Sir George Williams Campus known as the Quartier Concordia. That same year, the Engineering, Computer Science and Visual Arts Complex opened its doors on Saint Catherine Street West between Guy Street and Mackay Street.
In September 2009, the University marked the opening of the new building for the John Molson School of Business.
Campuses.
The university has two campuses, set approximately seven km apart: Sir George Williams Campus in the downtown core of Montreal, in an area known as Quartier Concordia (at Guy-Concordia Metro station), and Loyola Campus in the residential west-end district of Notre-Dame-de-Grâce. They are connected by free shuttle-bus service for students, faculty and staff.
Libraries, Archives and Galleries.
Concordia University has two main library locations: the R. Howard Webster Library located in the J.W. McConnell Building of Sir George Williams Campus, and the Georges P. Vanier Library on Loyola Campus. Concordia Libraries house several special and unique collections including the Azrieli Holocaust Collection and the Irving Layton Collection. Most special collections are located in the Vanier Library. The Libraries also maintains the University's institutional repository, Spectrum. The Concordia Libraries are members of the Canadian Association of Research Libraries. Concordia University Libraries also has partnerships with the Canadian Research Knowledge Network and The Data Liberation Initiative.
Concordia University's Hall Building houses The Leonard & Bina Ellen Art Gallery. Samuel Schecter, an art enthusiast and businessman, set up two funds in 1962 to be used for the purchase of Canadian art at Sir George Williams University and at Loyola College (Montreal). When Sir George Williams University and Loyola College merged under the name Concordia in 1974 their respective art collections were also combined. The Collection of the Leonard & Bina Ellen Gallery consists of 1700 paintings, sculptures, prints, photographs and videos, many of the works by 20th-century Canadian artists.
The Concordia University Archives house official records of, or relating to, or people/activities connected with Concordia University and its two founding institutions. The collection consists of manuscripts, texts, photographs, audio-visual material and artifacts.
New buildings.
In 2001, Concordia embarked on a mission to develop and expand the quality of the downtown campus, and to revive the west end in Montreal.
The university has also acquired the historic Grey Nuns motherhouse near its Sir George Williams Campus, for $18 million. Built in 1871, it would alone double the size of the current downtown campus. From 2007 to 2022, the university will begin occupying the building in 4 separate phases. The large property will house the faculty of Fine Arts and possibly the Mel Hoppenheim School of Cinema, and other departments. Currently the Grey Nuns building is only partially owned by Concordia (about 1/3 of the building on Saint-Mathieu Road), however full control of the building will be given to Concordia University in 2011. Concordia Residence Life currently houses nearly 250 students each year in the Grey Nuns building. The dorm-rooms are among the largest in the country, as many of the rooms have been transformed from when the section of the Grey Nuns building was occupied by the Grey Nuns. The site was designated a National Historic Site of Canada in 2011.
The Integrated Engineering, Computer Science and Visual Arts Complex at Saint Catherine Street and Guy Street was opened in September 2005. The building is directly connected to the Guy-Concordia Metro station and also houses Le Gym, a facility of Athletics and Recreation. Across the street, the 100-year-old TD Canada Trust building was donated to Concordia in 2005 by the Toronto-Dominion Bank. The university had planned to begin using this space in 2006.
Construction of the new John Molson School of Business Building that is located on the corner of Guy and de Maisonneuve streets began in February 2007. The Quebec Minister of Education, Recreation and Sports, Jean-Marc Fournier, on October 30, 2006 announced an investment of $60 million towards the construction of the new building. The minister made the announcement during a ceremony at Concordia. The government's $60 million represents about half of the total construction costs. Construction started on January 22, 2006 and the building was completed and opened in September 2009. The fifteen-story building now houses the JMSB's 6,000 full and part-time students under the same roof for the very first time. The Departments of Contemporary Dance, Theater, and Music at Concordia have also moved into the new JMSB building. It is connected to the EV building by a tunnel under Guy Street.
In April 2010, a 120-metre tunnel completed the underground connections of the Guy-Concordia Metro station with the Hall Building and the McConnell Library building.
Quartier Concordia.
Quartier Concordia is a neighbourhood redevelopment project centred around Concordia University's Sir George Williams Campus in downtown Montreal, Quebec, Canada. Bordered by Sherbrooke Street, Saint-Mathieu Street, René Lévesque Boulevard and Bishop Street, the district is designed to be a green urban campus that will improve the use and quality of public places and spaces, student life on campus and transportation.
As part of the redesign, the small Norman Bethune Square has been redesigned and enlarged. Sidewalks in the area will also be widened, with additional trees.
As of September 2010, an underground tunnel links the university's Hall and J.W. McConnell buildings with the Guy-Concordia Metro station. The hallway was completed in Spring 2010. However, a project to create a green space on Mackay Street has been put on hold.
Academics.
Students enter the university in September, or, in some cases, in January or May. An undergraduate degree normally takes three or four years studying full-time to complete, a Master's takes from a year and a half to three years, and a Ph.D. is at least four years long. Certificates and diplomas usually take no longer than a year and a half to complete.
Concordia has more than 300 undergraduate programs, divided into four faculties. The faculties are the Faculty of Arts and Science, the Faculty of Engineering and Computer Science, the Faculty of Fine Arts and the John Molson School of Business Students are normally enrolled in one of these Faculties, but they may take courses from any of the others as part of their studies. Class sizes vary from 85-400 students.
The School of Graduate Studies offers about 70 programs leading to Master's and doctoral degrees, as well as graduate diplomas and certificates for professionals seeking to upgrade their knowledge and skills.
The School of Extended Learning offers programs and services designed to make it easier for students to attend the university and be successful at their studies.
The Institute for Co-operative Education administers more than 35 bachelor's and master's programs in an alternating co-op work study format. Concordia's co-op programs enable students to enrich their learning by participating in career-relevant 12-17 week full-time, paid work terms. Depending on their faculty and major, co-op students will usually graduate with a minimum of 12 months of academically relevant work experience. There are also Industrial Experience and Professional Experience options in certain disciplinefs that enable students to participate in a summer-only work term. Concordia is a member of the Canadian Association for Co-operative Education (CAFCE).
During the 2014-2015 academic year, there were 30, 068 undergraduate students enrolled at Conocordia University and 7, 835 graduate students enrolled. 
Faculty of Arts and Science.
Concordia University's Faculty of Arts and Science contains 21 departments in the humanities, sciences and social sciences at the undergraduate and graduate levels. There are over 293 programs, offering more than 2,400 courses. There are 500 full-time and 400 part-time faculty members. During the 2010-2011 academic year, there were 15,767 undergraduate and 2,103 graduate students enrolled in the faculty.
In addition to regular academic programs, the Faculty of Arts and Science also includes three colleges, two schools and one institute. These are the Liberal Arts College, the Loyola College for Diversity and Sustainability, the School of Community and Public Affairs, the School of Canadian Irish Studies, the Science College and the Simone de Beauvoir Institute.
The Loyola College for Diversity and Sustainability (formerly Loyola International College) is an interdisciplinary college of Concordia University on Loyola Campus, the original site of Loyola College. It offers minor programs in "Diversity and the Contemporary World" and "Sustainability Studies".
At the undergraduate level, the Faculty of Arts and Science offers both Bachelor of Arts (B.A.) and Bachelor of Science (BSc) programs with majors ranging from economics, political science and sociology to actuarial mathematics, biology and ecology.
Faculty of Engineering and Computer Science.
The Faculty of Engineering and Computer Science (ENCS) offers 86 undergraduate and graduate-level programs in the following disciplines: Building Engineering, Civil Engineering, Computer Engineering, Computer Science, Electrical Engineering, Industrial Engineering, Information Systems Security, Mechanical Engineering, Quality Systems Engineering and Software Engineering. The engineering programs are all accredited by the Canadian Engineering Accreditation Board (CAEB). During the 2010-2011 academic year, there were 3,501 undergraduate and 2,438 graduate students enrolled in the faculty.
The Troitsky Bridge Building Competition brings together engineering students from across Canada and parts of the United States. Teams of students representing their universities must build a 1-metre-long bridge using only regular popsicle sticks, toothpicks, dental floss, and white glue. A panel of judges grades the bridges based on originality and presentation while a hydraulic loading device is used to determine the maximum load and performance.
Faculty of Fine Arts.
The Faculty of Fine Arts offers 76 programs at the undergraduate and graduate levels. It includes nine departments and three research institutes. During the 2010-2011 academic year, there were 3,153 undergraduate and 555 graduate students enrolled in the faculty. Among the departments is The Mel Hoppenheim School of Cinema. It is informally identified as MHSoC, and accepts 200 students a year, for study in the fields of animation, film production and film studies. It is the largest, university-based centre for the study of film animation, film production and film studies in Canada.
John Molson School of Business.
The John Molson School of Business (JMSB) (formerly the Faculty of Commerce and Administration) offers 48 different programs at the undergraduate and graduate levels from six different departments. The departments are Accountancy, Decision Sciences and MIS, Finance, International Business, Management and Marketing. During the 2010-2011 academic year, there were 7,508 undergraduate students and 1,470 graduate students enrolled as well as 37,788 alumni. The JMSB is accredited by the Association to Advance Collegiate Schools of Business (AACSB). The business school has been located in a LEED silver-certified building.
Reputation.
Concordia is included in the 2015 Times Higher Education World University Rankings "100 Under 50", a ranking of the top 100 universities worldwide under 50 years old.
The Academic Ranking of World Universities ranked Concordia University 19-23 overall in Canada. In addition, the Maclean's Guide to Canadian Universities ranked Concordia 10th nationally out of comprehensive universities in its 2016 edition. On an international scale, QS World University Rankings ranked Concordia 411-420 overall. Within specific fields in the QS World University Rankings, Concordia placed 51-100 for the fields of Education and Training and English Language and Literature, 101-150 for Communication and Media Studies, and 151-200 in the world for the field of Accounting and Finance. Additionally, Concordia placed 151-200 in the world for the fields of Linguistics, Psychology and Sociology. Also, Times Higher Education World University Rankings ranked Concordia's arts and humanities programs 79th worldwide. Concordia University was ranked 91st in Times Higher Education World University Rankings' "100 Under 50" ranking. Concordia University's John Molson School of Business has fared well in academic rankings. In 2012, The Economist ranked JMSB's Master of Business Administration program 78th in the world. The Academic Ranking of World Universities ranked Concordia University 101-150 worldwide in Economics and Business.
Concordia University has also gained a considerable level of prestige in social sciences and humanities. Higher Education Strategy Associates' rankings of Canadian universities in 2012 placed Concordia 9th nationally in social sciences and humanities. Concordia placed 20th in Canada in natural sciences and engineering according to rankings of Canadian universities by the Higher Education Strategy Associates. Finally, Concordia's computer science programs were ranked 151-200 worldwide by ARWU. Also, in 2014, LinkedIn ranked schools based on how successful recent graduates have been at landing desirable jobs. For the Software Development category, Concordia University was ranked as the sixth best university in Canada.
Student life.
Athletics.
Concordia University's athletic teams are called the Concordia Stingers. They compete with other schools in Canadian Interuniversity Sport, and more specifically, in the Quebec Student Sports Federation and the Quebec University Football League. The university has ten varsity teams. In the fall, teams compete in Canadian football, men's and women's soccer, men's and women's rugby union and sport wrestling. There are female and male wrestlers on the team from year to year, however they compete as one team. In the winter, teams compete in men's and women's ice hockey and men's and women's basketball.
Concordia won a national championship in 1999, when the women's hockey team beat the University of Alberta in the final game of the season. Recently, the Stingers beat Cape Breton University Capers 12-2 and won the 2009 National Baseball Crown.
Student organizations.
The Concordia Student Union (usually referred to as the CSU) is the organization representing undergraduate students at Concordia University in Montreal, Quebec, Canada. Its membership totals more than 33,000 students. Concordia students voted in favor of accreditation of their student union in a referendum in December 2000. As a result, the CSU is now legally accountable only to its student constituents.
Another noteworthy aspect of Concordia University is the number of longstanding fee-levy groups which provide numerous services, funded by the student population in the form of per-credit fees. These include the People's Potato which offers a four-course vegan meal, the anti-capitalist grocery store, The Frigo Vert, and the Coop Bookstore.
Concordia University has a campus radio station, (CJLO) and television station, (CUTV). Concordia also has three student-run newspapers, "The Link", "The Concordian" and French-language "L'Organe". "The Concordian" and "L'Organe" are members of Canadian University Press (CUP). The University also assists in the publishing of the only student-run, bilingual literary/arts magazine "The Void", founded in 2002, as well as arts magazine "Interfold". "The Link" left the CUP network in 2012.
Concordia University is home to local and international fraternities and sororities. The Delta Phi Epsilon Sorority, represented by the Beta Pi chapter, was established at Concordia in 1994. The Zeta Tau Omega sorority (ZTΩ) was founded in 1968 by six women studying at Montreal. Mu Omicron Zeta fraternity, commonly referred to as MOZ (pronounced like "moes"), was founded in 1992. The Brotherhood of Omicron is another locally based fraternity at Concordia. Tau Kappa Epsilon (TKE) Fraternity has its Kappa Chi (KX) Chapter at Concordia, which was founded in 1967 at Loyola College. Alpha Epsilon Pi (ΑΕΠ) — the largest fraternity in Canada—established a chapter at Concordia in 2015.
Notable alumni and faculty.
Concordia's alumni and faculty have achieved fame for their accomplishments in many fields. Distinguished alumni include a former governor general (Georges Vanier), a former prime minister of Dominica (Rosie Douglas), presidents and Chief Executive Officers of major businesses (Dominic D'Alessandro, Mireille Gingras, Gerald T. McCaughey), authors (E. Annie Proulx, Mordecai Richler, Nino Ricci, Chandra Venugopal, James Cummins), political leaders and ministers, academics Kim Sawchuk, scientists, actors (Will Arnett, Adam Kelly, Patrick Kwok-Choon), filmmakers (Moyra Davey, René Balcer, Peter Lenkov, Alex Rice, Lynne Stopkewich, B. P. Paquette, Donald Tarlton, James Tupper, Steven Woloshen), musicians (Emily Haines, Prita Chhabra, Régine Chassagne, Michael Laucke, Richard Reed Parry, Amy Millan, Matthew Otto of Majical Cloudz), and news anchors (Dareen Abu Ghaida, Mutsumi Takahashi).

</doc>
<doc id="42918" url="https://en.wikipedia.org/wiki?curid=42918" title="JSP">
JSP

JSP may stand for:

</doc>
<doc id="42922" url="https://en.wikipedia.org/wiki?curid=42922" title="Comparison of Java and C++">
Comparison of Java and C++

This is a comparison of the programming languages Java and C++.
Design aims.
The differences between the programming languages C++ and Java can be traced to their heritage, as they have different design goals.
The different goals in the development of C++ and Java resulted in different principles and design tradeoffs between the languages. The differences are as follows:
Language features.
Templates vs. generics.
Both C++ and Java provide facilities for generic programming, templates and generics, respectively. Although they were created to solve similar kinds of problems, and have similar syntax, they are quite different.
Miscellaneous.
An example comparing and exists in Wikibooks.
Performance.
In addition to running a compiled Java program, computers running Java applications generally must also run the Java virtual machine (JVM), while compiled C++ programs can be run without external applications. Early versions of Java were significantly outperformed by statically compiled languages such as C++. This is because the program statements of these two closely related languages may compile to a few machine instructions with C++, while compiling into several byte codes involving several machine instructions each when interpreted by a JVM. For example:
Since performance optimizing is a very complex issue, it is very difficult to quantify the performance difference between C++ and Java in general terms, and most benchmarks are unreliable and biased. Given the very different natures of the languages, definitive qualitative differences are also difficult to draw. In a nutshell, there are inherent inefficiencies and hard limits on optimizing in Java, given that it heavily relies on flexible high-level abstractions, however, the use of a powerful JIT compiler (as in modern JVM implementations) can mitigate some issues. In any case, if the inefficiencies of Java are too great, compiled C or C++ code can be called from Java via the JNI.
Some inefficiencies that are inherent to the Java language include, mainly:
However, there are a number of benefits to Java's design, some realized, some only theorized:
Also, some performance problems occur in C++:
Official standard and reference of the language.
Language specification.
The C++ language is defined by "ISO/IEC 14882", an ISO standard, which is published by the "ISO/IEC JTC1/SC22/WG21" committee. The latest, post-standardization draft of C++11 is available as well.
The C++ language evolves via an open steering committee called the C++ Standards Committee. The committee is composed of the creator of C++ Bjarne Stroustrup, the convener Herb Sutter, and other prominent figures, including many representatives of industries and user-groups (i.e., the stake-holders). Being an open committee, anyone is free to join, participate, and contribute proposals for upcoming releases of the standard and technical specifications. The committee now aims to release a new standard every few years, although in the past strict review processes and discussions have meant longer delays between publication of new standards (1998, 2003, and 2011).
The Java language is defined by the "Java Language Specification", a book which is published by Oracle.
The Java language continuously evolves via a process called the Java Community Process, and the world's programming community is represented by a group of people and organizations - the Java Community members—which is actively engaged into the enhancement of the language, by sending public requests - the Java Specification Requests - which must pass formal and public reviews before they get integrated into the language.
The lack of a firm standard for Java and the somewhat more volatile nature of its specifications have been a constant source of criticism by stake-holders wanting more stability and conservatism in the addition of new language and library features. In contrast, the C++ committee also receives constant criticism, for the opposite reason, i.e., being too strict and conservative, and taking too long to release new versions.
Trademarks.
"C++" is not a trademark of any company or organization and is not owned by any individual.
"Java" is a trademark of Oracle Corporation.

</doc>
<doc id="42925" url="https://en.wikipedia.org/wiki?curid=42925" title="Pine (email client)">
Pine (email client)

Pine is a freeware, text-based email client which was developed at the University of Washington. The first version was written in 1989, and announced to the public in March, 1992. Source code was available for only the Unix version under a license written by the University of Washington. Pine is no longer under development, and has been replaced by the Alpine client, which is available under the Apache License.
Supported platforms.
There are Unix, Windows, and Linux versions of Pine. The Unix/Linux version is text user interface based—its message editor inspired the text editor Pico. The Windows (and formerly DOS) version is called PC-Pine. WebPine is available to individuals associated with the University of Washington (students, faculty, etc.)—a version of Pine implemented as a web application.
Most moved over to Alpine, however there are still many users of this software.
Etymology.
Many people believe that Pine stands for "Pine Is Not Elm". One of its original authors, Laurence Lundblade, insists this was never the case and that it started off simply as a word and not an acronym, and that his first choice of a backronym for pine would be "Pine Is Nearly Elm". Over time, it was changed by the university to mean "Program for Internet News and E-mail". The original announcement said: "Pine was originally based on Elm, but it has evolved much since, ('Pine Is No-longer Elm')."
Licensing and clones.
Up to version 3.91, the Pine license was similar to BSD, and it stated that
The University registered a trademark for the Pine name with respect to "computer programs used in communication and electronic mail applications" in March 1995.
From version 3.92, the holder of the copyright, the University of Washington, changed the license so that even if the source code was still available, they did "not" allow modifications and changes to Pine to be distributed by anyone other than themselves. They also claimed that even the old license never allowed distribution of modified versions.
The trademark for the Pine name was part of their position in this matter.
In reaction, some developers forked version 3.91 under the name MANA (for "Mail And News Agent") to avoid the trademark issue and the GNU Project adopted it as GNU Mana. Richard Stallman claims that the University of Washington threatened to sue the Free Software Foundation for distributing the modified Pine program, resulting in the development of MANA ceasing and no versions being released.
The University of Washington later modified their license somewhat to allow unmodified distribution of Pine alongside collections of free software, but the license still does not conform to the Open Source and the Free Software Guidelines so it is semi-free software, effectively proprietary software.
Alpine.
In 2006, the University of Washington announced that it stopped development of Pine with Pine 4.64, although Pine continues to be supported.
In its place is a new family of email tools based upon Pine, called Alpine and licensed under the Apache License, version 2. November 29, 2006 saw the first public alpha release, which forms a new approach, since the alpha test of Pine was always non-public.
Alpine 1.0 was publicly released on December 20, 2007. The most recent version 2.20 was released in January 2015.

</doc>
<doc id="42927" url="https://en.wikipedia.org/wiki?curid=42927" title="John of Damascus">
John of Damascus

Saint John of Damascus (; ; , ALA-LC: "Yūḥannā ad-Dimashqī"), also known as John Damascene and as Χρυσορρόας / "Chrysorrhoas" (literally "streaming with gold"—i.e., "the golden speaker"; c. 675 or 676 – 4 December 749) was a Syrian monk and priest. Born and raised in Damascus, he died at his monastery, Mar Saba, near Jerusalem.
A polymath whose fields of interest and contribution included law, theology, philosophy, and music, he is said by some sources to have served as a Chief Administrator to the Muslim caliph of Damascus before his ordination. He wrote works expounding the Christian faith, and composed hymns which are still used both liturgically in Eastern Christian practice throughout the world as well as in western Lutheranism at Easter. He is one of the Fathers of the Eastern Orthodox church and is best known for his strong defense of icons. The Catholic Church regards him as a Doctor of the Church, often referred to as the "Doctor of the Assumption" due to his writings on the Assumption of Mary.
The most common source of information for the life of John of Damascus is a work attributed to one John of Jerusalem, identified therein as the Patriarch of Jerusalem. This is an excerpted translation into Greek of an earlier Arabic text. The Arabic original contains a prologue not found in most other translations, and was written by an Arab monk, Michael. Michael explained that he decided to write his biography in 1084 because none was available in his day. However, the main Arabic text seems to have been written by an earlier author sometime between the early 9th and late 10th centuries AD. Written from a hagiographical point of view and prone to exaggeration and some legendary details, it is not the best historical source for his life, but is widely reproduced and considered to contain elements of some value. The hagiographic novel "Barlaam and Josaphat", traditionally attributed to John, is in fact a work of the 10th century.
Family background.
John was born into a prominent Syriac family known as Mansour in Damascus in the 7th century AD. His grandfather had been responsible for the taxes of the region under the Emperor Heraclius and seems to have played a role in the capitulation of Damascus to the troops of Khalid b. al-Walid in 635. Eutychius, a 10th-century Melkite patriarch mentions him as one high-ranking official involved in the surrender of the city to the Muslims. When the region came under Arab Muslim occupation in the late 7th century AD, the court at Damascus retained its large complement of Christian civil servants, John's grandfather among them. John's father, Sarjun (Sergius) or Ibn Mansur, went on to serve the Umayyad caliphs. According to John of Jerusalem and some later versions of his life, after his father's death John also served as an official to the caliphal court before leaving to become a monk. This claim, that John actually served in a Muslim court, has been questioned since he is never mentioned in Muslim sources, which however do refer to his father Sarjun (Sergius) as a secretary in the caliphal administration. In addition, John's own writings never refer to any experience in a Muslim court. It is believed that John became a monk at Mar Saba, and that he was ordained as a priest in 735.
Education.
One of the "vitae" describes his father's desire for him to "learn not only the books of the Muslims, but those of the Greeks as well." From this it has been suggested that John may have grown up bilingual. John does indeed show some knowledge of the Quran, which he criticizes harshly.
Other sources describes his education in Damascus as having been conducted in accordance with the principles of Hellenic education, termed "secular" by one source and "Classical Christian" by another. One account identifies his tutor as a monk by the name of Cosmas, who had been kidnapped by Arabs from his home in Sicily, and for whom John's father paid a great price. Under the instruction of Cosmas, who also taught John's orphan friend (the future St. Cosmas of Maiuma), John is said to have made great advances in music, astronomy and theology, soon rivalling Pythagoras in arithmetic and Euclid in geometry. As a refugee from Italy, Cosmas brought with him the scholarly traditions of Western Christianity.
Career.
John had at least one and possibly two careers: one (less well-documented) as a civil servant for the Caliph in Damascus, and the other (better-attested) as a priest and monk at the Mar Saba monastery near Jerusalem. One source believes John left Damascus to become a monk around 706, when al-Walid I increased the Islamicisation of the Caliphate's administration. However, Muslim sources only mention that his father Sarjun (Sergius) left the administration around this time, and fail to name John at all. During the next two decades, culminating in the Siege of Constantinople (717-718), the Umayyad Caliphate progressively occupied the borderlands of the Byzantine Empire. An editor of John's works, Father Le Quien, has shown that John was already a monk at Mar Saba before the dispute over iconoclasm, explained below.
In the early 8th century AD, iconoclasm, a movement opposed to the veneration of icons, gained acceptance in the Byzantine court. In 726, despite the protests of St. Germanus, Patriarch of Constantinople, Emperor Leo III (who had forced the emperor to abdicate and himself assumed the throne in 717 immediately before the great siege) issued his first edict against the veneration of images and their exhibition in public places.
All agree that John of Damascus undertook a spirited defence of holy images in three separate publications. The earliest of these works, his ""Apologetic Treatises against those Decrying the Holy Images"", secured his reputation. He not only attacked the Byzantine emperor, but adopted a simplified style that allowed the controversy to be followed by the common people, stirring rebellion among those of Christian faith. Decades after his death, John's writings would play an important role during the Second Council of Nicaea (787), which convened to settle the icon dispute.
John's biography recounts at least one episode deemed improbable or legendary. Leo III reportedly sent forged documents to the caliph which implicated John in a plot to attack Damascus. The caliph then ordered John's right hand be cut off and hung up in public view. Some days afterwards, John asked for the restitution of his hand, and prayed fervently to the Theotokos before her icon: thereupon, his hand is said to have been miraculously restored. In gratitude for this miraculous healing, he attached a silver hand to the icon, which thereafter became known as the "Three-handed", or Tricheirousa.
Last days.
John died in 749 as a revered Father of the Church, and is recognized as a saint. He is sometimes called the last of the Church Fathers by the Roman Catholic Church. In 1890 he was declared a Doctor of the Church by Pope Leo XIII.
Veneration.
When the name of Saint John of Damascus was inserted in the General Roman Calendar in 1890, it was assigned to 27 March. The feast day was moved in 1969 to the day of the saint's death, 4 December, the day on which his feast day is celebrated also in the Byzantine Rite calendar, Lutheran Commemorations, and the Anglican Communion and Episcopal Church.
The 1884 choral work "John of Damascus" ("A Russian Requiem"), Op. 1, for four-part mixed chorus and orchestra, by Russian composer Sergei Taneyev, is dedicated to Saint John.
List of works.
Besides his purely textual works, many of which are listed below, John of Damascus also composed hymns, perfecting the canon, a structured hymn form used in Eastern Orthodox church services.
The Arabic translation.
It is believed that the homily on the Annunciation was the first work to be translated into Arabic. Much of this text is found in Manuscript 4226 of the Library of Strasbourg (France), dating to 885 AD.
Later in the 10th century, Antony, superior of the monastery of St. Simon (near Antioch) translated a corpus of saint John Damascene. In his introduction to John's work, Sylvestre patriarch of Antioch (1724–1766) said that Antony was monk at Saint Saba. This could be a misunderstanding of the title Superior of Saint Simon probably because Saint Simon's monastery was in ruins in the 18th century.
Most manuscripts give the text of the letter to Cosmas, the philosophical chapters, the theological chapters and five other small works. Since March 2013, a first edition of this translation is available on the web.
In 1085, Mikhael, a monk from Antioch wrote the Arabic life of the Chrysorrhoas. This work was first edited by Bacha in 1912 and then translated in many languages (German, Russian and English).
Modern English translations.
2 translations exist of the 10th century hagiographic novel "Barlaam and Josaphat", traditionally attributed to John:

</doc>
<doc id="42934" url="https://en.wikipedia.org/wiki?curid=42934" title="Cryostasis (clathrate hydrates)">
Cryostasis (clathrate hydrates)

The term cryostasis was introduced to name the reversible preservation technology for live biological objects which is based on using clathrate-forming gaseous substances under increased hydrostatic pressure and hypothermic temperatures.
Living tissues cooled below the freezing point of water are damaged by the dehydration of the cells as ice is formed between the cells. The mechanism of freezing damage in living biological tissues has been elucidated by Renfret (1968) (Renfret A.P. Cryobiology: some fundamentals in surgical context. In: Cryosurgery. Rand R.W., Rinfret A.P., von Lode H., Eds. Springfield, IL: Charles C. Thomas, 1968) and by Mazur (1984): ice formation begins in the intercellular spaces.
The vapor pressure of the ice is lower than the vapor pressure of the solute water in the surrounding cells and as heat is removed at the freezing point of the solutions, the ice crystals grow between the cells, extracting water from them. As the ice crystals grow, the volume of the cells shrinks, and the cells are crushed between the ice crystals. Additionally, as the cells shrink, the solutes inside the cells are concentrated in the remaining water, increasing the intracellular ionic strength and interfering with the organization of the proteins and other organized intercellular structures. Eventually, the solute concentration inside the cells reaches the eutectic and freezes. The final state of frozen tissues is pure ice in the former extracellular spaces, and inside the cell membranes a mixture of concentrated cellular components in ice and bound water. In general, this process is not reversible to the point of restoring the tissues to life.
Cryostasis utilizes using clathrate-forming gases that penetrate and saturate the biological tissues causing clathrate hydrates formation (under specific pressure-temperature conditions) inside the cells and in the extracellular matrix. Clathrate hydrates are a class of solids in which gas molecules occupy "cages" made up of hydrogen-bonded water molecules. These "cages" are unstable when empty, collapsing into conventional ice crystal structure, but they are stabilised by the inclusion of the gas molecule within them. Most low molecular weight gases (including CH4, H2S, Ar, Kr, and Xe) will form a hydrate under some pressure-temperature conditions.
Clathrates formation will prevent the biological tissues from dehydration which will cause irreversible inactivation of intracellular enzymes.

</doc>
<doc id="42935" url="https://en.wikipedia.org/wiki?curid=42935" title="Detection">
Detection

In general, detection is the extraction of particular information from a larger stream of information without specific cooperation from or synchronization with the sender.
In the history of radio communications, the term "detector" was first used for a device that detected the simple presence or absence of a radio signal, since all communications were in Morse code. The term is still in use today to describe a component that extracts a particular signal from all of the electromagnetic waves present. Detection is usually based on the frequency of the carrier signal, as in the familiar frequencies of radio broadcasting, but it may also involve filtering a faint signal from noise, as in radio astronomy, or reconstructing a hidden signal, as in steganography.
In optoelectronics, "detection" means converting a received optical input to an electrical output. For example, the light signal received through an optical fiber is converted to an electrical signal in a detector such as a photodiode.
In steganography, attempts to detect hidden signals in suspected carrier material is referred to as steganalysis. Steganalysis has an interesting difference from most other types of detection, in that it can often only determine the probability that a hidden message exists; this is in contrast to the detection of signals which are simply encrypted, as the ciphertext can often be identified with certainty, even if it cannot be decoded. 
In the military, detection refers to the special discipline of reconnaissance with the aim to recognize the presence of an object in a location or ambiance.
Finally, the art of detection, also known as "following clues", is the work of a detective in attempting to reconstruct a sequence of events by identifying the relevant information in a situation.

</doc>
<doc id="42937" url="https://en.wikipedia.org/wiki?curid=42937" title="Photodiode">
Photodiode

A photodiode is a semiconductor device that converts light into current. The current is generated when photons are absorbed in the photodiode. A small amount of current is also produced when no light is present. Photodiodes may contain optical filters, built-in lenses, and may have large or small surface areas. Photodiodes usually have a slower response time as their surface area increases. The common, traditional solar cell used to generate electric solar power is a large area photodiode.
Photodiodes are similar to regular semiconductor diodes except that they may be either exposed (to detect vacuum UV or X-rays) or packaged with a window or optical fiber connection to allow light to reach the sensitive part of the device. Many diodes designed for use specifically as a photodiode use a PIN junction rather than a p–n junction, to increase the speed of response. A photodiode is designed to operate in reverse bias.
Principle of operation.
A photodiode is a p–n junction or PIN structure. When a photon of sufficient energy strikes the diode, it creates an electron-hole pair. This mechanism is also known as the inner photoelectric effect. If the absorption occurs in the junction's depletion region, or one diffusion length away from it, these carriers are swept from the junction by the built-in electric field of the depletion region. Thus holes move toward the anode, and electrons toward the cathode, and a photocurrent is produced. The total current through the photodiode is the sum of the dark current (current that is generated in the absence of light) and the photocurrent, so the dark current must be minimized to maximize the sensitivity of the device.
Photovoltaic mode.
When used in zero bias or "photovoltaic mode", the flow of photocurrent out of the device is restricted and a voltage builds up. This mode exploits the photovoltaic effect, which is the basis for solar cells – a traditional solar cell is just a large area photodiode.
Photoconductive mode.
In this mode the diode is often reverse biased (with the cathode driven positive with respect to the anode). This reduces the response time because the additional reverse bias increases the width of the depletion layer, which decreases the junction's capacitance. The reverse bias also increases the dark current without much change in the photocurrent. For a given spectral distribution, the photocurrent is linearly proportional to the illuminance (and to the irradiance).
Although this mode is faster, the photoconductive mode tends to exhibit more electronic noise. The leakage current of a good PIN diode is so low (<1 nA) that the Johnson–Nyquist noise of the load resistance in a typical circuit often dominates.
Other modes of operation.
Avalanche photodiodes are photodiodes with structure optimized for operating with high reverse bias, approaching the reverse breakdown voltage. This allows each "photo-generated" carrier to be multiplied by avalanche breakdown, resulting in internal gain within the photodiode, which increases the effective "responsivity" of the device.
A phototransistor is a light-sensitive transistor. A common type of phototransistor, called a photobipolar transistor, is in essence a bipolar transistor encased in a transparent case so that light can reach the "base–collector junction". It was invented by Dr. John N. Shive (more famous for his wave machine) at Bell Labs in 1948, but it wasn't announced until 1950. The electrons that are generated by photons in the base–collector junction are injected into the base, and this photodiode current is amplified by the transistor's current gain β (or hfe). If the base and collector leads are used and the emitter is left unconnected, the phototransistor becomes a photodiode. While phototransistors have a higher responsivity for light they are not able to detect low levels of light any better than photodiodes. Phototransistors also have significantly longer response times. Field-effect phototransistors, also known as photoFETs, are light-sensitive field-effect transistors. Unlike photobipolar transistors, photoFETs control drain-source current by creating a gate voltage.
Materials.
The material used to make a photodiode is critical to defining its properties, because only photons with sufficient energy to excite electrons across the material's bandgap will produce significant photocurrents.
Materials commonly used to produce photodiodes include:
Because of their greater bandgap, silicon-based photodiodes generate less noise than germanium-based photodiodes.
Unwanted photodiode effects.
Any p–n junction, if illuminated, is potentially a photodiode. Semiconductor devices such as transistors and ICs contain p–n junctions, and will not function correctly if they are illuminated by unwanted electromagnetic radiation (light) of wavelength suitable to produce a photocurrent; this is avoided by encapsulating devices in opaque housings. If these housings are not completely opaque to high-energy radiation (ultraviolet, X-rays, gamma rays), transistors and ICs can malfunction due to induced photo-currents. Background radiation from the packaging is also significant. Radiation hardening mitigates these effects.
The infamous Raspberry Pi 2 Xenon Flash hanging bug is a result of Xenon flash's intense ultraviolet emission lines disrupting a switch mode power supply controller chip in bare-die wafer-scale package, with the resulting power surge causing the main processor to lock up.
Features.
Critical performance parameters of a photodiode include:
When a photodiode is used in an optical communication system, all these parameters contribute to the "sensitivity" of the optical receiver, which is the minimum input power required for the receiver to achieve a specified "bit error rate".
Applications.
P–n photodiodes are used in similar applications to other photodetectors, such as photoconductors, charge-coupled devices, and photomultiplier tubes. They may be used to generate an output which is dependent upon the illumination (analog; for measurement and the like), or to change the state of circuitry (digital; either for control and switching, or digital signal processing).
Photodiodes are used in consumer electronics devices such as compact disc players, smoke detectors, and the receivers for infrared remote control devices used to control equipment from televisions to air conditioners. For many applications either photodiodes or photoconductors may be used. Either type of photosensor may be used for light measurement, as in camera light meters, or to respond to light levels, as in switching on street lighting after dark.
Photosensors of all types may be used to respond to incident light, or to a source of light which is part of the same circuit or system. A photodiode is often combined into a single component with an emitter of light, usually a light-emitting diode (LED), either to detect the presence of a mechanical obstruction to the beam (slotted optical switch), or to couple two digital or analog circuits while maintaining extremely high electrical isolation between them, often for safety (optocoupler). The combination of LED and photodiode is also used in many sensor systems to characterize different types of products based on their optical absorbance.
Photodiodes are often used for accurate measurement of light intensity in science and industry. They generally have a more linear response than photoconductors.
They are also widely used in various medical applications, such as detectors for computed tomography (coupled with scintillators), instruments to analyze samples (immunoassay), and pulse oximeters.
PIN diodes are much faster and more sensitive than p–n junction diodes, and hence are often used for optical communications and in lighting regulation.
P–n photodiodes are not used to measure extremely low light intensities. Instead, if high sensitivity is needed, avalanche photodiodes, intensified charge-coupled devices or photomultiplier tubes are used for applications such as astronomy, spectroscopy, night vision equipment and laser rangefinding.
Pinned photodiode is not a PIN photodiode, it has p+/n/p regions in it.
It has a shallow P+ implant in N type diffusion layer over a P-type epitaxial substrate layer. It is used in CMOS Active pixel sensor.
Comparison with photomultipliers.
Advantages compared to photomultipliers:
Disadvantages compared to photomultipliers:
Photodiode array.
A one-dimensional array of hundreds or thousands of photodiodes can be used as a position sensor, for example as part of an angle sensor. 
One advantage of photodiode arrays (PDAs) is that they allow for high speed parallel read out since the driving electronics may not be built in like a traditional CMOS or CCD sensor.

</doc>
<doc id="42939" url="https://en.wikipedia.org/wiki?curid=42939" title="Autolysin">
Autolysin

An autolysin is an enzyme (, "gametolysin, Chlamydomonas cell wall degrading protease", "lysin", "Chlamydomonas reinhardtii metalloproteinase", "gamete lytic enzyme", "gamete autolysin") that hydrolyzes (and breaks down) the components of a biological cell or a tissue in which it is produced. It is similar in function to a lysozyme. This enzyme catalyses the following chemical reaction
This glycoprotein is present in "Chlamydomonas reinhardtii" gametes.
Autolysins exist in all bacteria containing peptidoglycan. The peptidoglycan matrix is very rigid, so these enzymes break down the peptidoglycan matrix in small sections so that growth and division of cells can occur. Autolysins do this by hydrolyzing the β-(1,4) bond between N-acetylmuramic acid and N-acetylglucosamine molecules. Autolysins are naturally produced by peptidoglycan containing bacteria, but excessive amounts will degrade the peptidoglycan matrix and cause the cell to burst due to osmotic pressure. Gram-positive bacteria regulate autolysins with teichoic acid molecules attached to the tetrapeptide of the peptidoglycan matrix.
Tariq Bangash Microbiology Kohat University of Science & Technology 2014
References.
Bao Quoc Tran. Autolysin and its affect on herpes. Microbiology text book ed 5 2012

</doc>
<doc id="42940" url="https://en.wikipedia.org/wiki?curid=42940" title="Biostasis">
Biostasis

Biostasis is the ability of an organism to tolerate environmental changes without having to actively adapt to them. The word is also used as a synonym for cryostasis or cryonics. It is found in organisms that live in habitats that may encounter unfavourable living conditions (i.e. drought, freezing, a change in pH, pressure, or temperature). Insects undergo diapause, which allows them to survive winter and other events. Diapause may be obligatory (required for the insect to survive) or facultative (the insect is able to undergo change before the initiating event arrives).
Medical Biostasis can be put to use in humans to help repair brain damage. 
Depending on where medicine is in the next decade medical biostasis procedures can be performed by trauma surgeons by 2026.

</doc>
<doc id="42942" url="https://en.wikipedia.org/wiki?curid=42942" title="Chitinase">
Chitinase

Chitinases (, "chitodextrinase", "1,4-beta-poly-N-acetylglucosaminidase", "poly-beta-glucosaminidase", "beta-1,4-poly-N-acetyl glucosamidinase", "poly[1,4-(N-acetyl-beta-D-glucosaminide)] glycanohydrolase", "(1->4)-2-acetamido-2-deoxy-beta-D-glucan glycanohydrolase") are hydrolytic enzymes that break down glycosidic bonds in chitin.
As chitin is a component of the cell walls of fungi and exoskeletal elements of some animals (including worms and arthropods), chitinases are generally found in organisms that either need to reshape their own chitin or dissolve and digest the chitin of fungi or animals.
Species distribution.
Chitinivorous organisms include many bacteria (Aeromonads, "Bacillus", "Vibrio", among others), which may be pathogenic or detritivorous. They attack living arthropods, zooplankton or fungi or they may degrade the remains of these organisms.
Fungi, such as "Coccidioides immitis", also possess degradative chitinases related to their role as detritivores and also to their potential as arthropod pathogens.
Chitinases are also present in plants (barley seed chitinase: , ); some of these are pathogenesis related (PR) proteins that are induced as part of systemic acquired resistance. Expression is mediated by the NPR1 gene and the salicylic acid pathway, both involved in resistance to fungal and insect attack. Other plant chitinases may be required for creating fungal symbioses.
Although mammals do not produce chitin, they have two functional chitinases, Chitotriosidase (CHIT1) and acidic mammalian chitinase (AMCase), as well as chitinase-like proteins (such as YKL-40) that have high sequence similarity but lack chitinase activity.
Function.
Like cellulose, chitin is an abundant biopolymer that is relatively resistant to degradation. It is typically not digested by animal, though certain fish are able to digest chitin. It is currently assumed that chitin digestion by animals requires bacterial symbionts and lengthy fermentations, similar to cellulase digestion by ruminants. Nevertheless, chitinases have been isolated from the stomachs of certain mammals, including humans.
Chitinase activity can also be detected in human blood and possibly cartilage. As in plant chitinases this may be related to pathogen resistance.
Clinical significance.
Chitinases produced in the human body (known as "human chitinases") may be related in response to allergies, and asthma has been linked to enhanced chitinase expression levels.
Human chitinases may explain the link between some of the most common allergies (dust mites, mold spores—both of which contain chitin) and worm (helminth) infections, as part of one version of the hygiene hypothesis (worms have chitinous mouthparts to hold the intestinal wall). Finally, the link between chitinases and salicylic acid in plants is well established—but there is a hypothetical link between salicylic acid and allergies in humans.
Presence in food.
Chitinase occurs naturally in many common foods. This is at least one cause of the cross-reaction phenomenon in latex-fruit syndrome. Bananas, chestnuts, kiwis, avocados, papaya, and tomatoes, for example, all contain significant levels of chitinase.
Applications.
Chitinases has a wealth of applications, some of which has already been realized by the industry. This includes bio-conversion of chitin to useful products such as fertilizer, the production of non-allergenic, non-toxic, biocompatible, and biodegradable materials (contact lenses, artificial skin and stitches with these qualities are already being produced) and enhancement of insecticides and fungicides.
Possible future applications of chitinases are as food additives to increase shelf life, therapeutic agent for asthma and chronic rhinosinusitis, as an anti-fungal remedy, an anti-tumor drug and as a general ingredient to be used in protein engineering.

</doc>
<doc id="42946" url="https://en.wikipedia.org/wiki?curid=42946" title="Encyclopedia Astronautica">
Encyclopedia Astronautica

The Encyclopedia Astronautica is a reference web site on space travel. A comprehensive catalog of vehicles, technology, astronauts, and flights, it includes information from most countries that have had an active rocket research program, from Robert Goddard to the NASA Space shuttle to the Soviet Shuttle Buran.
It is maintained by space enthusiast and author Mark Wade. He has been collecting such information for most of his life.

</doc>
<doc id="42948" url="https://en.wikipedia.org/wiki?curid=42948" title="Lip piercing">
Lip piercing

A lip piercing is a type of body piercing that penetrates the lips or the area surrounding the lips, which can be pierced in a variety of ways.
Procedure and healing.
Approximate healing time for most lip piercings is between 1 to 3 months; however, there is a possibility of serious infection if the piercing is not properly taken care of. After healing is complete, other jewelry may be used. After this time, some scar tissue may be present, but the fistula is normally fully developed and mostly healed. Aftercare consists of hot saline soaks two to three times daily. Soaking the wound for three to five minutes with a weak saline solution softens any blood and lymph discharge attached to the jewelry. Afterwards, taking a hot shower and using clean hands and a small amount of a mild soap such as castile soap removes excess matter from the site. Turning or otherwise moving jewelry on a fresh piercing is not advised, as it can irritate and lengthen swelling and healing time. Diluted mouthwash or salt water solution can also be used after meals along with toothbrushing to help remove debris and flush the piercing and is recommended by practitioners.
Initial jewelry is usually a labret stud or a captive bead ring, manufactured from high-grade surgical stainless steel, implant-grade titanium, or similar lightweight and inert metal. No matter which type of jewelry is used, the jewelry's diameter and length will be intentionally over sized to allow room for initial swelling. After healing, the jewelry can be replaced with a closer-fitting piece.
A home-made saline solution made from non-iodized sea salt and hot distilled or filtered water is a common way to heal a lip piercing and avoid infection. This solution can be used to rinse out the mouth after eating (or the mouth can be rinsed with non-alcoholic, non-antimicrobial mouth wash) and to soak the outside of the piercing. Anything with alcohol, peroxide, iodine, or any strong soaps should be avoided because they may irritate the fresh piercing, and cause additional swelling and trauma during the healing process. Using peroxide, iodine, teatree oil, conventional antibacterial soap, or dish soap can damage or kill the skin in and around the piercing, extending the healing process. The ornament should be periodically cleansed to prevent bacterial plaque accumulation.
Types.
Lip piercings can be placed anywhere around the mouth, but the surface of the lip is not typically pierced itself, except for horizontal lip piercings and canine bites. Piercings in specific positions have certain names. Monroe piercings, for example, are labret studs worn on the upper lip where Marilyn Monroe had her famous beauty mark. Medusa piercings go through the center of the upper lip (the philtrum), perpendicular to the tissue. Labret piercings are pierced with a labret stud and can pierced in the center or off-center. A variation of this is the lowbret, a lower labret. Vertical labret piercings go through the center of the bottom lip, parallel to the tissue. The variation is called the vertical lowbret, which starts inside the mouth between the lower lip and the teeth and travels straight down, exiting on the lower edge of the jawline. Horizontal lip piercings are very rare, and include a horizontal bar on the lower lip that goes through the lip surface. Another variation of the labret is known as the dahlia piercing. The piercings, placed at or very near the corners of the mouth, are named in reference to the murder of Black Dahlia, in which the victim's mouth was cut along the same horizontal line along which these piercings are placed. (See Glasgow smile)
History and culture.
Precolumbian cultures of South America historically used lip piercing called Tembetá. Lip piercing continues to be practiced by many people, the most well-known of which are certain African tribes, who wear large decorative lip plates or discs, usually in the lower lip.
In contemporary society, lip piercings are relatively common. In a study among Israeli young-adults, 4.3% had present or past body piercing (not included earlobe, lip or intra-oral piercing), and 5.7%, 6.2% and 15.7% had present or past lip piercing, body tattooing and intra-oral piercing, respectively.

</doc>
<doc id="42950" url="https://en.wikipedia.org/wiki?curid=42950" title="301">
301

__NOTOC__
Year 301 (CCCI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Postumius and Nepotianus (or, less frequently, year 1054 "Ab urbe condita"). The denomination 301 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="42951" url="https://en.wikipedia.org/wiki?curid=42951" title="302">
302

__NOTOC__
Year 302 (CCCII) was a common year starting on Thursday of the Julian calendar. At the time, it was known as the Year of the Consulship of Constantius and Valerius or, less frequently, year 1055 "Ab urbe condita". The denomination 302 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42952" url="https://en.wikipedia.org/wiki?curid=42952" title="303">
303

__NOTOC__
Year 303 (CCCIII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Valerius and Valerius (or, less frequently, year 1056 "Ab urbe condita"). The denomination 303 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42953" url="https://en.wikipedia.org/wiki?curid=42953" title="Irish Free State">
Irish Free State

The Irish Free State ( ; 6 December 192229 December 1937) was an independent state established in 1922 under the Anglo-Irish Treaty of December 1921. That treaty ended the three-year Irish War of Independence between the forces of the self-proclaimed Irish Republic, the Irish Republican Army (IRA), and British Crown forces.
The Free State was established as a Dominion of the British Commonwealth of Nations. It comprised 26 of the 32 counties of Ireland. Northern Ireland, which comprised the remaining six counties, exercised its right under the Treaty to opt out of the new state. The Free State government consisted of the Governor-General, the representative of the king, and the Executive Council, which replaced both the revolutionary Dáil Government and the Provisional Government set up under the Treaty. W. T. Cosgrave, who had led both of these governments since August 1922, became the first President of the Executive Council. The legislature consisted of Dáil Éireann (the lower house) and Seanad Éireann, also known as the Senate. Members of the Dáil were required to take an Oath of Allegiance, swearing fidelity to the king. The oath was a key issue for opponents of the Treaty, who refused to take the oath and therefore did not take their seats. Pro-Treaty members, who formed Cumann na nGaedheal in 1923, held an effective majority in the Dáil from 1922 to 1927, and thereafter ruled as a minority government until 1932.
The first months of the Free State saw a Civil War between the newly established National Army and the anti-Treaty IRA, who refused to recognise the state. The Civil War ended in victory for the government forces, with the anti-Treaty forces dumping its arms in May 1923. The anti-Treaty political party, Sinn Féin, refused to take its seats in the Dáil, leaving the relatively small Labour Party as the only opposition party. In 1926, when Sinn Féin president Éamon de Valera failed to have this policy reversed, he resigned from Sinn Féin and founded Fianna Fáil. Fianna Fáil first entered the Dáil following the 1927 general election, and entered government after the Irish general election, 1932, when it became the largest party.
De Valera abolished the Oath of Allegiance and embarked on an economic war with Britain. In 1937 he drafted a new constitution, which was passed by a referendum in July of that year.
The Free State came to an end with the coming into force of the new constitution on 29 December 1937. Under the new constitution the Irish state was named Ireland.
Historical background.
The Easter Rising of 1916, and particularly the execution of fifteen people by firing squad, the imprisonment or internment of hundreds more, and the imposition of martial law caused a profound shift in public opinion towards the republican cause in Ireland. Meanwhile, opposition increased to Ireland's participation in World War I in Europe and the Middle East. This came about when the Irish Parliamentary Party supported the Allied cause in World War I in response to the passing of the Third Home Rule Bill in 1914. Many people had begun to doubt whether the Bill, passed by Westminster in September 1914 but suspended for the duration of the war, would ever come into effect. Due to the war situation deteriorating badly on the Western Front in April 1918, which coincided with the publication of the final report and recommendations of the Irish Convention, the British Cabinet drafted a doomed "dual policy" of introducing Home Rule linked to compulsory military service for Ireland which it eventually had to drop. Sinn Féin, the Irish Party and all other Nationalist elements joined forces in opposition to the idea during the Conscription Crisis of 1918. At the same time the Irish Parliamentary lost in support on account of the crisis. Irish republicans felt further emboldened by successful anti-monarchical revolutions in the Russian Empire (1917), the German Empire (1918), and the Austro-Hungarian Empire (1918). In the December 1918 General Election, Sinn Féin won a large majority of the Irish seats in the Westminster parliament of the United Kingdom of Great Britain and Ireland: 73 of the 105 constituencies returned Sinn Féin members (25 uncontested). The Sinn Féin party, founded by Arthur Griffith in 1905, had previously espoused non-violent separatism. Under Éamon de Valera's leadership from 1917, it campaigned aggressively and militantly for an Irish republic.
On 21 January 1919, Sinn Féin MPs (who became known as "Teachta Dála", TDs), refusing to sit at Westminster, assembled in Dublin and formed a single-chamber Irish parliament called Dáil Éireann (Assembly of Ireland). It affirmed the formation of an Irish Republic and passed a Declaration of Independence, 
the irish people is resolved...to promote the common weal, to re-establish justice ...with equal rights and equal opportunity for every citizen. and calling itself "Saorstát Éireann" in Irish. Although the less than overwhelming majority of Irish people accepted this course, America and Soviet Russia were targeted to recognise the Irish Republic internationally. The Message to the Free Nations of the World called on every free nation to support the Irish Republic by recognizing Ireland's national status...the last outpost of Europe towards the West...demanded by the Freedom of the Seas.
Cathal Brugha, elected President of the Ministry Pro-Tem, warned, "Deputies you understand from this that we are now done with England."
A war for a new independent Ireland.
The War of Independence (1919–21) pitted the army of the Irish Republic, the Irish Republican Army (known subsequently as the "Old IRA" to distinguish it from later organisations of that name), against the British Army, the Black and Tans, the Royal Irish Constabulary, the Auxiliary Division, the Dublin Metropolitan Police, the Ulster Special Constabulary and the Ulster Volunteer Force. On 9 July 1921 a truce came into force. By this time the Ulster Parliament had been opened, established under the Government of Ireland Act 1920, presenting the republican side with a "fait accompli" and guaranteeing the British a permanent entanglement in Ireland. On 11 October negotiations opened between Prime Minister David Lloyd George and Arthur Griffith, who headed the Irish Republic's delegation. The Irish Treaty delegation set up its headquarters in Hans Place, Knightsbridge. On 5 December 1921 at 11:15 am the delegation decided during private discussions at 22 Hans Place to recommend the negotiated agreement to the Dáil Éireann; negotiations continued until 2:30 am on 6 December 1921, after which the parties signed Anglo-Irish Treaty.
Nobody had doubted that these negotiations would produce a form of Irish government short of the independence wished for by republicans. The United Kingdom could not offer a republican form of government without losing prestige and risking demands for something similar throughout the Empire. Furthermore, as one of the negotiators, Michael Collins, later admitted (and he would have known, given his leading role in the independence war), the IRA at the time of the truce was weeks, if not days, from collapse, with a chronic shortage of ammunition. "Frankly, we thought they were mad", Collins said of the sudden British offer of a truce - although the republicans would probably have continued the struggle in one form or another, given the level of public support. Since Lloyd George had already, after the truce had come into effect, made it clear to President of the Republic, Éamon de Valera, "that the achievement of a republic through negotiation was impossible", de Valera decided not to become a member of the treaty delegation (Griffith, Collins, Duggan, Barton, and Gavan Duffy) and so not to become accused by more militant republicans as a "sellout". Yet his own proposals - published in January 1922 - fell far short of an autonomous all-Ireland republic. Sinn Féin's abstention was unambiguous.
As expected, the Anglo-Irish Treaty explicitly ruled out a republic. It offered Ireland dominion status, as a state within the then British Empire, equal to Canada, Newfoundland, Australia, New Zealand and South Africa. Though less than expected by the Sinn Féin leadership, this deal offered substantially more than the initial form of home rule within the United Kingdom sought by Charles Stewart Parnell from 1880, and represented a serious advance on the Home Rule Bill of 1914 that the Irish nationalist leader John Redmond had achieved through parliamentary proceedings. However, it all but confirmed the partition of Ireland between Northern Ireland and the Irish Free State. The Second Dáil in Dublin ratified the Treaty (7 January 1922), splitting Sinn Féin in the process.
Northern Ireland "opts out".
The Treaty, and the legislation introduced to give it legal effect, implied that Northern Ireland would be a part of the Free State on its creation, but legally the terms of the Treaty applied only to the 26 counties, and the government of the Free State never had any powers—even in principle—in Northern Ireland.
The Treaty was given legal effect in the United Kingdom through the Irish Free State Constitution Act 1922. That act, which established the Free State, allowed Northern Ireland to "opt out" of it. Under Article 12 of the Treaty, Northern Ireland could exercise its option by presenting an address to the King requesting not to be part of the Irish Free State. Once the Treaty was ratified, the Houses of Parliament of Northern Ireland had one month (dubbed the "Ulster month") to exercise this option during which month the Government of Ireland Act continued to apply in Northern Ireland.
Realistically it was always certain that Northern Ireland would opt out of the Free State. The Prime Minister of Northern Ireland, Sir James Craig, speaking in the Parliament in October 1922 said that "when 6 December is passed the month begins in which we will have to make the choice either to vote out or remain within the Free State". He said it was important that that choice be made as soon as possible after 6 December 1922 "in order that it may not go forth to the world that we had the slightest hesitation". On the following day, 7 December 1922, the Parliament resolved to make the following address to the King so as to opt out of the Irish Free State:
Discussion in the Parliament of the address was short. Prime Minister Craig left for London with the memorial embodying the address on the night boat that evening, 7 December 1922. The King received it the following day, "The Times" reporting:
If the Houses of Parliament of Northern Ireland had not made such a declaration, under Article 14 of the Treaty Northern Ireland, its Parliament and government would have continued in being but the Oireachtas would have had jurisdiction to legislate for Northern Ireland in matters not delegated to Northern Ireland under the Government of Ireland Act. This, of course, never came to pass.
On 13 December 1922 Prime Minister Craig addressed the Parliament informing them that the King had responded to the Parliament's address as follows:
Governmental and constitutional structures.
The Treaty established that the new Irish Free State would be a constitutional monarchy, with a Governor-General. The "Constitution of the Irish Free State" made more detailed provision for the state's system of government, with a three-tier parliament, called the Oireachtas, made up of the King and two houses, Dáil Éireann and Seanad Éireann (the Irish Senate). Executive authority was vested in the King, and exercised by a cabinet called the Executive Council, presided over by a prime minister called the President of the Executive Council.
The Representative of the Crown.
The King in the Irish Free State was represented by a Governor-General of the Irish Free State. The office replaced the previous Lord Lieutenant, who had headed English and British administrations in Ireland since the Middle Ages. Governors-General were appointed by the King initially on the advice of the British Government, but with the consent of the Irish Government. From 1927 the Irish Government alone had the power to advise the King whom to appoint.
Oath of Allegiance.
As with all dominions, provision was made for an Oath of Allegiance. Within dominions, such oaths were taken by parliamentarians personally towards the monarch. The Irish Oath of Allegiance was fundamentally different. It had two elements; the first, an "oath to the Free State, as by law established", the second part a promise of "fidelity, to His Majesty, King George V, his heirs and successors". That second fidelity element, however, was qualified in two ways. It was to the King "in" Ireland, not specifically to the King of the United Kingdom. Secondly, it was to the King explicitly in his role as part of the Treaty settlement, not in terms of pre-1922 British rule. The Oath itself came from a combination of three sources, and was largely the work of Michael Collins in the Treaty negotiations. It came in part from a draft oath suggested prior to the negotiations by President de Valera. Other sections were taken by Collins directly from the Oath of the Irish Republican Brotherhood (IRB), of which he was the secret head. In its structure, it was also partially based on the form and structure used for 'Dominion status'.
Although 'a new departure', and notably indirect in its reference to the monarchy, it was criticised by nationalists and republicans for making any reference to the Crown, the claim being that it "was" a direct oath to the Crown, a fact demonstrably incorrect by an examination of its wording. But in 1922 Ireland and beyond, it was the perception, not the reality, that influenced public debate on the issue. Had its original author, Michael Collins, survived, he might have been able to clarify its actual meaning, but with his assassination in August 1922, no major negotiator to the Oath's creation on the Irish side was still alive, available or pro-Treaty. (The leader of the Irish delegation, Arthur Griffith, had also died in August 1922). The Oath became a key issue in the resulting Irish Civil War that divided the pro- and anti-treaty sides in 1922–23.
The Irish Civil War.
The compromises contained in the agreement caused the civil war in the 26 counties in June 1922 – April 1923, in which the pro-Treaty Provisional Government defeated the anti-Treaty Republican forces. The latter were led, nominally, by Éamon de Valera, who had resigned as President of the Republic on the treaty's ratification. His resignation outraged some of his own supporters, notably Seán T. O'Kelly, the main Sinn Féin organizer. On resigning, he then sought re-election but was defeated two days later on a vote of 60–58. The pro-Treaty Arthur Griffith followed as President of the Irish Republic. Michael Collins was chosen at a meeting of the members elected to sit in the House of Commons of Southern Ireland (a body set up under the Government of Ireland Act 1920) to become Chairman of the Provisional Government of the Irish Free State in accordance with the Treaty. The general election in June gave overwhelming support for the pro-Treaty parties. W. T. Cosgrave's Crown-appointed Provisional Government effectively subsumed Griffith's republican administration with the death of both Collins and Griffith in August 1922.
The "freedom to achieve freedom".
Governance.
The following were the principal parties of government of the Irish Free State between 1922 and 1937:
Constitutional evolution.
Michael Collins described the Treaty as 'the freedom to achieve freedom'. In practice, the Treaty offered most of the symbols and powers of independence. These included a functioning, if disputed, parliamentary democracy with its own executive, judiciary and written constitution which could be changed by the Oireachtas. However, a number of conditions existed:
The Statute of Westminster (of 1931), embodying a decision of an Imperial Conference, enabled each dominion to enact new legislation or to change any extant legislation, without resorting to any role for the British parliament that may have enacted the original legislation in the past.
The Free State symbolically marked these changes in two mould-breaking moves:
When Éamon de Valera became President of the Executive Council (prime minister) in 1932 he described Cosgrave's ministers' achievements simply. Having read the files, he told his son, Vivion, "they were magnificent, son".
The Statute of Westminster allowed de Valera, on becoming President of the Executive Council (February 1932), to go even further. With no ensuing restrictions on his policies, he abolished the Oath of Allegiance (which Cosgrave intended to do had he won the 1932 general election), the Senate, university representation in the Dáil, and appeals to the Privy Council.
One major policy error occurred in 1936 when he attempted to use the abdication of King Edward VIII to abolish the crown and governor-general in the Free State with the "Constitution (Amendment No. 27 Act)". He was advised by senior law officers and other constitutional experts that, as the crown and governor-generalship existed separately from the constitution in a vast number of acts, charters, orders-in-council, and letters patent, they both still existed. A second bill, the "Executive Powers (Consequential Provisions) Act, 1937" was quickly introduced to repeal the necessary elements. De Valera retroactively dated the second act back to December 1936.
Currency.
The new state continued to use sterling from its inception; there is no reference in the Treaty or in either of the enabling Acts to currency. Nonetheless and within a few years, the Dáil passed the [http://www.irishstatutebook.ie/1926/en/act/pub/0014/print.html Coinage Act, 1926 (which provided for a "Saorstát" State coinage) and the Currency Act, 1927 (which provided "inter alia" for banknotes of the Saorstát pound). The new Saorstát pound was defined by the 1927 Act to have exactly the same weight and fineness of gold as was the sovereign at the time, making the new currency pegged at 1:1 with sterling. The State circulated its new national coinage in 1928, marked "Saorstát Éireann" and a national series of banknotes. British coinage remained acceptable in the Free State at an equal rate. In 1937, when the Free State was superseded by Ireland ("Éire"), the pound became known as the "Irish pound" and the coins were marked "Éire".
Demographics.
According to one report, in 1924, shortly after the Irish Free State's establishment, the new dominion had the "lowest birth-rate in the world". The report noted that amongst countries for which statistics were available (Ceylon, Chile, Japan, Spain, South Africa, Netherlands, Canada, Germany, Australia, United States, Britain, New Zealand, Finland and the Irish Free State). Ceylon had the highest birth rate at 40.8 per 1,000 while the Irish Free State had a birth rate of just 18.6 per 1,000.
After the Irish Free State.
In 1937 the Fianna Fáil government presented a draft of an entirely new Constitution to Dáil Éireann. An amended version of the draft document was subsequently approved by the Dáil. A referendum was then held on the same day as the 1937 general election, when a relatively narrow majority approved it. The new Constitution of Ireland ("Bunreacht na hÉireann") repealed the 1922 Constitution, and came into effect on 29 December 1937.
The state was named Ireland (Éire in the Irish language), and a new office of President of Ireland was instituted in place of the Governor-General of the Irish Free State. The new constitution claimed jurisdiction over all of Ireland while recognising that legislation would not apply in Northern Ireland (see Articles 2 and 3). Articles 2 and 3 were reworded in 1998 to remove jurisdictional claim over the entire island and to recognise that "a united Ireland shall be brought about only by peaceful means with the consent of a majority of the people, democratically expressed, in both jurisdictions in the island".
With respect to religion, a section of Article 44 included the following:
It was left to the initiative of de Valera's successors in government to achieve the country's formal transformation into a republic. A small but significant minority of Irish people, usually attached to parties like Sinn Féin and the smaller Republican Sinn Féin, denied the right of the twenty-six county state to use the name "Ireland" and continued to refer to the state as the Free State. With Sinn Féin's entry into Dáil Éireann and the Northern Ireland Executive at the close of the 20th century, the number of those who refuse to accept the legitimacy of the state, which was already in a minority, declined further. After the setting up of the Free State in 1923, some Protestants left southern Ireland and unionism there largely came to an end.

</doc>
<doc id="42954" url="https://en.wikipedia.org/wiki?curid=42954" title="304">
304

__NOTOC__
Year 304 (CCCIV) was a leap year starting on Saturday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Valerius and Valerius (or, less frequently, year 1057 "Ab urbe condita"). The denomination 304 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="42957" url="https://en.wikipedia.org/wiki?curid=42957" title="Endospore">
Endospore

An endospore is a dormant, tough, and non-reproductive structure produced by certain bacteria from the Firmicute phylum. The name "endospore" is suggestive of a spore or seed-like form ("endo" means within), but it is not a true spore (i.e., not an offspring). It is a stripped-down, dormant form to which the bacterium can reduce itself. Endospore formation is usually triggered by a lack of nutrients, and usually occurs in gram-positive bacteria. In endospore formation, the bacterium divides within its cell wall. One side then engulfs the other. Endospores enable bacteria to lie dormant for extended periods, even centuries. Revival of spores millions of years old has been claimed. When the environment becomes more favorable, the endospore can reactivate itself to the vegetative state. Most types of bacteria cannot change to the endospore form. Examples of bacteria that can form endospores include "Bacillus" and "Clostridium".
The endospore consists of the bacterium's DNA, ribosomes and large amounts of dipicolinic acid. Dipicolinic acid is a spore-specific chemical that appears to help in the ability for endospores to maintain dormancy. This chemical comprises up to 10% of the spore's dry weight.
Endospores can survive without nutrients. They are resistant to ultraviolet radiation, desiccation, high temperature, extreme freezing and chemical disinfectants. Thermo-resistant endospores were first hypothesized by Ferdinand Cohn after studying "Bacillus subtilis" (pictured to the right) growth on cheese after boiling the cheese. His notion of spores being the reproductive mechanism for the growth was a large blow to the previous suggestions of spontaneous generation. Astrophysicist Steinn Sigurdsson said "There are viable bacterial spores that have been found that are 40 million years old on Earth – and we know they're very hardened to radiation." Common anti-bacterial agents that work by destroying vegetative cell walls do not affect endospores. Endospores are commonly found in soil and water, where they may survive for long periods of time. A variety of different microorganisms form "spores" or "cysts," but the endospores of low G+C gram-positive bacteria are by far the most resistant to harsh conditions.
Some classes of bacteria can turn into exospores, also known as microbial cysts, instead of endospores. Exospores and endospores are two kinds of "hibernating" or dormant stages seen in some classes of microorganisms.
Structure.
Bacteria produce a single endospore internally. The spore is sometimes surrounded by a thin covering known as the exosporium, which overlies the "spore coat". The spore coat, which acts like a sieve that excludes large toxic molecules like lysozyme, is resistant to many toxic molecules and may also contain enzymes that are involved in germination. The "cortex" lies beneath the spore coat and consists of peptidoglycan. The "core wall" lies beneath the cortex and surrounds the protoplast or "core" of the endospore. The core contains the spore chromosomal DNA which is encased in chromatin-like proteins known as SASPs (small acid-soluble spore proteins), that protect the spore DNA from UV radiation and heat. The core also contains normal cell structures, such as ribosomes and other enzymes, but is not metabolically active.
Up to 20% of the dry weight of the endospore consists of calcium dipicolinate within the core, which is thought to stabilize the DNA. Dipicolinic acid could be responsible for the heat resistance of the spore, and calcium may aid in resistance to heat and oxidizing agents. However, mutants resistant to heat but lacking dipicolinic acid have been isolated, suggesting other mechanisms contributing to heat resistance are also at work. Small acid-soluble proteins (SASPs) are found in endospores. These proteins tightly bind and condense the DNA, and are in part responsible for resistance to UV light and DNA-damaging chemicals.
Visualising endospores under light microscopy can be difficult due to the impermeability of the endospore wall to dyes and stains. While the rest of a bacterial cell may stain, the endospore is left colourless. To combat this, a special stain technique called a Moeller stain is used. That allows the endospore to show up as red, while the rest of the cell stains blue. Another staining technique for endospores is the Schaeffer-Fulton stain, which stains endospores green and bacterial bodies red. The arrangement of spore layers is as follows:
Location.
The position of the endospore differs among bacterial species and is useful in identification. The main types within the cell are terminal, subterminal, and centrally placed endospores. Terminal endospores are seen at the poles of cells, whereas central endospores are more or less in the middle. Subterminal endospores are those between these two extremes, usually seen far enough towards the poles but close enough to the center so as not to be considered either terminal or central. Lateral endospores are seen occasionally.
Examples of bacteria having terminal endospores include "Clostridium tetani", the pathogen that causes the disease tetanus. Bacteria having a centrally placed endospore include "Bacillus cereus", and those having a subterminal endospore include "Bacillus subtilis". Sometimes the endospore can be so large the cell can be distended around the endospore, this is typical of "Clostridium tetani".
Formation and destruction.
Under conditions of starvation, especially the lack of carbon and nitrogen sources, a single endospore forms within some of the bacteria. The process is called sporulation (def).(Kaiser, 2011)
When a bacterium detects environmental conditions are becoming unfavourable it may start the process of endosporulation, which takes about eight hours. The DNA is replicated and a membrane wall known as a "spore septum" begins to form between it and the rest of the cell. The plasma membrane of the cell surrounds this wall and pinches off to leave a double membrane around the DNA, and the developing structure is now known as a forespore. Calcium dipicolinate, the calcium salt of dipicolinic acid, is incorporated into the forespore during this time. The dipicolinic acid helps stabilize the proteins and DNA in the endospore. Next the peptidoglycan cortex forms between the two layers and the bacterium adds a spore coat to the outside of the forespore. In the final stages of endospore formation the newly forming endospore is dehydrated and allowed to mature before being released from the mother cell. The cortex is what makes the endospore so resistant to temperature. The cortex contains an inner membrane known as the core. The inner membrane that surrounds this core leads to the endospore's resistance against UV light and harsh chemicals that would normally destroy microbes. Sporulation is now complete, and the mature endospore will be released when the surrounding vegetative cell is degraded.
Endospores are resistant to most agents that would normally kill the vegetative cells they formed from. Unlike persister cells, endospores are the result of a morphological differentiation process triggered by nutrient limitation (starvation) in the environment; endosporulation is initiated by quorum sensing within the "starving" population. Most disinfectants such as household cleaning products, alcohols, quaternary ammonium compounds and detergents have little effect on endospores. However, sterilant alkylating agents (e.g. ethylene oxide), and 10% bleach are effective against endospores. To kill most anthrax spores, standard household bleach (with 10% sodium hypochlorite) must be in contact with the spores for at least several minutes; a very small proportion of spores can survive longer than 10 minutes in such a solution. Higher concentrations of bleach are not more effective, and can cause some types of bacteria to aggregate and thus survive.
While significantly resistant to heat and radiation, endospores can be destroyed by burning or by autoclaving at a temperature exceeding the boiling point of water, 100 °C. Endospores are able to survive at 100 °C for hours, although the longer the number of hours the fewer that will survive. An indirect way to destroy them is to place them in an environment that reactivates them to their vegetative state. They will germinate within a day or two with the right environmental conditions, and then the vegetative cells, not as hardy as endospores, can be straightforwardly destroyed. This indirect method is called Tyndallization. It was the usual method for a while in the late 19th century before the introduction of inexpensive autoclaves. Prolonged exposure to ionising radiation, such as x-rays and gamma rays, will also kill most endospores.
Certain types of endospores are used to ensure that an autoclaved item has been rendered truly sterile: a small capsule containing the spores is put into the autoclave with the items; after the cycle it is checked to see if anything will grow from it. If nothing will grow, then the spores were destroyed and the sterilization was successful.
In hospitals, endospores on delicate invasive instruments (e.g., video endoscopes) are killed by "low-temperature" and non-corrosive, non-toxic, plasma-activated concentrated hydrogen peroxide vapor in sterilizers. In contrast, "high level disinfection" does not kill endospores but is used for instruments that don't enter sterile bodily cavities (e.g., a colonoscope). This latter method uses only warm water, enzymes, and detergents.
Bacterial endospores are resistant to antibiotics, most disinfectants, and physical agents such as radiation, boiling, and drying. The impermeability of the spore coat is thought to be responsible for the endospore's resistance to chemicals. The heat resistance of endospores is due to a variety of factors:
Reactivation.
Reactivation of the endospore occurs when conditions are more favourable and involves "activation", "germination", and "outgrowth". Even if an endospore is located in plentiful nutrients, it may fail to germinate unless activation has taken place. This may be triggered by heating the endospore. Germination involves the dormant endospore starting metabolic activity and thus breaking hibernation. It is commonly characterised by rupture or absorption of the spore coat, swelling of the endospore, an increase in metabolic activity, and loss of resistance to environmental stress.
Outgrowth follows germination and involves the core of the endospore manufacturing new chemical components and exiting the old spore coat to develop into a fully functional vegetative bacterial cell, which can divide to produce more cells.
Endospores possess five times more sulfur than vegetative cells. This excess sulfur is concentrated in spore coats as an amino acid, cystine. It is believed that the macromolecule accountable for maintaining the dormant state has a protein coat rich in cystine, stabilized by S-S linkages. A reduction in these linkages has the potential to change the tertiary structure, causing the protein to unfold. This conformational change in the protein is thought to be responsible for exposing active enzymatic sites necessary for endospore germination.
Endospores can stay dormant for a very long time. For instance, endospores were found in the tombs of the Egyptian pharaohs. When placed in appropriate medium, under appropriate conditions, they were able to be reactivated. In 1995, Raul Cano of California Polytechnic State University found bacterial spores in the gut of a fossilized bee trapped in amber from a tree in the Dominican Republic. The bee fossilized in amber was dated to being about 25 million years old. The spores germinated when the amber was cracked open and the material from the gut of the bee was extracted and placed in nutrient medium. After the spores were analyzed by microscopy, it was determined that the cells were very similar to "Bacillus sphericus" which is found in bees in the Dominican Republic today.
Importance.
As a simplified model for cellular differentiation, the molecular details of endospore formation have been extensively studied, specifically in the model organism "Bacillus subtilis". These studies have contributed much to our understanding of the regulation of gene expression, transcription factors, and the sigma factor subunits of RNA polymerase.
Endospores of the bacterium "Bacillus anthracis" were used in the 2001 anthrax attacks. The powder found in contaminated postal letters was composed of extracellular anthrax endospores. This intentional distribution lead to 22 known cases of anthrax (11 inhalation and 11 cutaneous) making the case fatality rate among patients with inhalation anthrax 45% (5/11). The six other individuals with inhalation anthrax and all the individuals with cutaneous anthrax recovered. Had it not been for antibiotic therapy many more might have been stricken.
According to WHO veterinary documents, "B. anthracis" sporulates when it sees oxygen instead of the carbon dioxide present in mammal blood; this signals to the bacteria that it has reached the end of the animal, and an inactive dispersable morphology is useful.
"Sporulation requires the presence of free oxygen. in the natural situation, this means the vegetative cycles occur within the low oxygen environment of the infected host and, within the host, the organism is exclusively in the vegetative form. once outside the host, sporulation commences upon exposure to the air and the spore forms are essentially the exclusive phase in the environment."
"Geobacillus stearothermophilus" endospores are used as biological indicators when an autoclave is used in sterilization procedures.
Biotechnology.
"Bacillus subtilis" spores are useful for the expression of recombinant proteins and in particular for the surface display of peptides and proteins as a tool for fundamental and applied research in the fields of microbiology, biotechnology and vaccination.
Endospore-forming bacteria.
Examples of endospore-forming bacteria include the genera:

</doc>
<doc id="42958" url="https://en.wikipedia.org/wiki?curid=42958" title="Theodore the Studite">
Theodore the Studite

Theodore the Studite (also known as Theodorus Studita, St. Theodore of Stoudios, and St. Theodore of Studium; 759–826) was a Byzantine Greek monk and abbot of the Stoudios Monastery in Constantinople. Theodore's letter, containing suggested monastery reform rules, is the first recorded stand against slavery. He played a major role in the revivals both of Byzantine monasticism and of classical literary genres in Byzantium. He is known as a zealous opponent of iconoclasm, one of several conflicts that set him at odds with both emperor and patriarch.
Biography.
Family and childhood.
Theodore was born in Constantinople in 759. He was the oldest son of Photeinos, an important financial official in the palace bureaucracy, and Theoktiste, herself the offspring of a distinguished Constantinopolitan family. The brother of Theoktiste, Theodore's uncle Platon, was himself an important official in the imperial financial administration. The family therefore controlled a significant portion, if not all, of the imperial financial administration during the reign of Constantine V (r. 741–775). Theodore had two younger brothers (Joseph, later Archbishop of Thessaloniki, and Euthymios) and one sister, whose name we do not know.
It has often been assumed that Theodore's family belonged to the iconodule party during the first period of Byzantine Iconoclasm. There is however no evidence to support this, and their high position in the imperial bureaucracy of the time renders any openly iconodule position highly unlikely. Furthermore, when Platon left his office and entered the priesthood in 759, he was ordained by an abbot who, if he was not actively iconoclastic himself, at the very least offered no resistance to the iconoclastic policies of Constantine V. The family as a whole was most likely indifferent to the question of icons during this period.
According to the later hagiographical literature, Theodore received an education befitting his family's station, and from the age of seven was instructed by a private tutor, eventually concentrating in particular on theology. It is however not clear that these opportunities were available to even the most well-placed Byzantine families of the eighth century, and it is possible that Theodore was at least partially an autodidact.
Early monastic career.
Following the death of Emperor Leo IV (r. 775–780) in 780, Theodore's uncle Platon, who had lived as a monk in the Symbola Monastery in Bithynia since 759, visited Constantinople, and persuaded the entire family of his sister, Theoktiste, to likewise take monastic vows. Theodore, together with his father, brothers, sailed back to Bithynia with Platon in 781, where they set about transforming the family estate into a religious establishment, which became known as the Sakkudion Monastery. Platon became abbot of the new foundation, and Theodore was his "right hand." The two sought to order the monastery according to the writings of Basil of Caesarea.
During the period of the regency of Eirene, Abbot Platon emerged as a supporter of the Patriarch Tarasios, and was a member of Tarasios's iconodule party at the Second Council of Nicaea, where the veneration of icons was declared orthodox. Shortly thereafter Tarasios himself ordained Theodore as a priest. In 794, Theodore became abbot of the Sakkudion Monastery, while Platon withdrew from the daily operation of the monastery and dedicated himself to silence.
Conflict with Constantine VI.
Also in 794, Emperor Constantine VI (r. 776–797) decided to separate from his first wife, Maria of Amnia, and to marry Maria's "kubikularia" (Lady-in-waiting), Theodote, a cousin of Theodore the Studite. Although the Patriarch may initially have resisted this development, as a divorce without proof of adultery on the part of the wife could be construed as illegal, he ultimately gave way. The marriage of Constantine and Theodote was celebrated in 795, although not by the patriarch, as was normal, but by a certain Joseph, a priest of Hagia Sophia.
A somewhat obscure chain of events followed (the so-called "Moechian controversy," from the Greek "moichos", "adulterer"), in which Theodore initiated a protest against the marriage from the Sakkudion Monastery, and appears to have demanded the excommunication, not only of the priest Joseph, but also of all who had received communion from him, which, as Joseph was a priest of the imperial church, included implicitly the emperor and his court. This demand had no official weight, however, and Constantine appears to have attempted to make peace with Theodore and Platon (who, on account of his marriage, were now his relatives), inviting them to visit him during a sojourn at the imperial baths of Prusa in Bithynia. In the event neither appeared.
As a result, imperial troops were sent to the Sakkudion Monastery, and the community was dispersed. Theodore was flogged, and, together with ten other monks, banished to Thessaloniki, while Platon was imprisoned in Constantinople. The monks arrived in Thessaloniki in March 797, but did not remain for long; in August of the same year Constantine VI was blinded and overthrown, and his mother Irene, the new empress, lifted the exile.
Abbot of the Studites.
Following the accession of Irene, the priest Joseph was stripped of his office, and Theodoros was received in the imperial palace. The monks then returned to the Sakkudion Monastery, but were forced back to the capital in either 797 or 798 on account of an Arab raid on Bithynia. At this time, Irene offered Theodore the leadership of the ancient Stoudios Monastery in Constantinople, which he accepted. Theodore then set about building various workshops within the monastery to guarantee autarky, constructing a library and a scriptorium, and restoring and decorating the church. He also composed a series of poems on the duties of the various members of the community, which were likely inscribed and displayed within the monastery. He furthermore composed a rule for the governance of the monastery, and made the Studios community the center of an extensive congregation of dependent monasteries, including the Sakkudion. He maintained contact with these other monasteries above all through his prodigious literary output (letters as well as catechisms), which reached a quantitative peak at this time, and developed a system of messengers that was so elaborate as to resemble a private postal service.
To this period may also date the so-called iconophile epigrams, iambic acrostics composed by Theodore that replaced the "iconoclastic epigrams" which were previously exhibited on the Chalke gate of the Great Palace. It has been suggested that these were commissioned by Irene, as another sign of her good favor toward Theodore, although a commission under Michael I Rangabe (r. 811–813) is also possible; in any case, they were removed in 815 by Leo V the Armenian (r. 813–820) and replaced by new "iconoclastic" verses.
In 806, the Patriarch Tarasios died, and Emperor Nikephoros I (r. 802–811) set about seeking his replacement. It appears likely that Platon at this time put forth Theodore's name, but Nikephoros, a layman who held the rank of "asekretis" in the imperial bureaucracy, was chosen instead. The selection of Nikephoros gave rise to an immediate protest on the part of the Studites, and in particular Theodore and Platon, who objected to the elevation of a layman to the patriarchal throne. Theodore and Platon were jailed for 24 days before the Emperor Nikephoros allowed them to return to their congregations.
Conflict with Nikephoros.
Emperor Nikephoros soon requested that his new patriarch rehabilitate the priest Joseph, who had officiated at the wedding of Constantine and Theodote, possibly because Joseph had aided in the peaceful resolution of the revolt of Bardanes Tourkos. In 806, the Patriarch Nikephoros convened a synod to address the case, at which Theodore was present. The Synod decided to readmit Joseph to the priesthood, a decision to which Theodore did not at the time object.
Therefore, relations between the Studite Abbot and the Patriarch appear to have been initially untroubled, an impression which is reinforced by the choice (806/807) of Theodore's brother, Joseph, as Archbishop of Thesaloniki. However, soon after this ordination, perhaps in 808, Theodore began to express his unwillingness to associate with the rehabilitated priest Joseph, or for that matter with anyone else who knowingly associated with him, as he held the rehabilitation for uncanonical. As in the first dispute over the priest Joseph, the extension of this refusal beyond Joseph to those who associated with him included implicitly the patriarch and the emperor himself.
Early in 808, Theodoros offered in a series of letters to explain his position to the emperor, and furthermore to perform the customary proskynesis at his feet, which offer Nikephoros declined, instead setting off for the summer military campaign. In the winter of the same year, Theodore's brother Joseph visited him in Constantinople, but refused to attend the Christmas mass in Hagia Sophia, at which the emperor, the patriarch, and the priest Joseph would have been present. As a result, he was stripped of his archbishopric. At around the same time a small military division was dispatched to the Stoudios Monastery to arrest Theodore, Joseph, and Platon. A synod was then held in January of 809, at which Theodore and his followers were anathematized as schismatic. Theodore, Joseph, and Platon, were thereafter banished to the Princes' Islands: Theodore to Chalke, Joseph to Prote, and Platon to Oxeia.
Theodore maintained an extensive literary activity in exile, writing numerous letters to correspondents including his brother, various Studite monks, influential family members, and even Pope Leo III. He also continued to compose catechisms for the Studite congregation, as well as a number of poems.
Rehabilitation under Michael I.
In 811, the new emperor Michael I Rangabe called the Studites back from exile. The priest Joseph was once more defrocked, and Theodore was, at least superficially, reconciled with the Patriarch Nikephoros.
There are, however, indications that a certain rivalry between the Studite Abbot and the Patriarch persisted. In 812, Michael I resolved to persecute certain heretics in Phrygia and Lycaonia, namely the Paulicians and the "Athinganoi" (sometimes identified with the Roma). Theodore and Nikephoros were called before the emperor to debate the legality of punishing heresy by death, Theodore arguing against and Nikephoros for. Theodore is said to have won the day.
The second affair concerned a peace treaty proposed by Krum of Bulgaria (r. 803–814), also in 812, according to which the Byzantine and Bulgarian states should exchange refugees. It is likely that Krum sought the return of certain Bulgarians who had betrayed him to the Byzantines. In this instance Theodore argued against the exchange, as it would require that Christians be cast to barbarians, while Nikephoros urged the emperor to accept the treaty. Once more Theodore's opinion prevailed, although this time with serious consequences; Krum attacked and took Mesembria in November of the same year. Michael led a military campaign against the Bulgarians in 813, which ended in defeat, and as a result he abdicated in July and Leo V was crowned emperor.
On April 4, 814, Theodore's uncle Platon died in the Stoudios Monastery after a long illness. Theodore composed a long funeral oration, the "Laudatio Platonis", which remains one of the most important sources for the history of the family.
Second Iconoclasm.
At the very beginning of his reign, Leo V faced a new Bulgarian offensive that reached the walls of Constantinople and ravaged large sections of Thrace. This came to an end with the death of Krum on April 13, 814, and the internal power struggles that followed. However, as the previous 30 years since the approval of icon-veneration at the Synod of 787 had represented for the Byzantines a string of military catastrophes, Leo resolved to reach back to the policies of the more successful Isaurian dynasty. He renamed his son Constantine, thus drawing a parallel to Leo III (r. 717–741) and Constantine V, and beginning in 814 began to discuss with various clerics and senators the possibility of reviving the iconoclastic policy of the Isaurians. This movement met with strong opposition from the Patriarch Nikephoros, who himself gathered a group of bishops and abbots about him and swore them to uphold the veneration of images. The dispute came to a head in a debate between the two parties before the emperor in the Great Palace on Christmas 814, at which Theodore and his brother Joseph were present, and took the side of the iconophiles.
Leo held fast by his plan to revive iconoclasm, and in March 815 the Patrarch Nikephoros was stripped of his office and exiled to Bithynia. At this point Theodore remained in Constantinople, and assumed a leading role in the iconodule opposition. On March 25, Palm Sunday, he commanded his monks to process through the monastery's vineyard, holding up icons so that they could be seen over the walls by the neighbors. This provocation elicited only a rebuke from the emperor.
A new patriarch, Theodotos, was selected, and in April a synod was convened in Hagia Sophia, at which iconoclasm was re-introduced as dogma. Theodore composed a series of letters in which he called on "all, near and far," to revolt against the decision of the synod. Not long thereafter he was exiled by imperial command to a Metopa, a fortress on the eastern shore of Lake Apollonia in Bithynia. Shortly thereafter Leo had Theodore's poems removed from the Chalke Gate and replaced by a new set of "iconoclastic" epigrams.
While Theodore was in exile, the leadership of the Studite congregation was assumed by the Abbot Leontios, who for a time adopted the iconoclast position and won over many individuals monks to his party. He was, however, eventually won back to the iconodule party. The Studite situation mirrored a general trend, with a number of bishops and abbots at first willing to reach a compromise with the iconoclasts, but then in the years between 816 and 819 renouncing the iconoclast position, a movement that was perhaps motivated by the martyrdom of the Studite monk Thaddaios. It was during this upswell in icondule sentiment that Theodore began to compose his own polemic against the iconoclasts, the "Refutatio", concentrating in particular on refuting the arguments and criticizing the literary merits of the new iconoclastic epigrams on the Chalke.
Theodore exercised a wide influence during the first year of his exile, primarily through a massive letter-writing campaign. Accordingly, he was transferred in 816 to Boneta, a fortress in the more remote Anatolic theme, whence he nevertheless remained abreast of developments in the capital and maintained a regular correspondence. This continued activity led to an imperial order that Theodore be whipped, which his captors however refused to carry out. In 817, Theodore wrote two letters to Pope Paschal I, which were co-signed by several fellow iconophile abbots, in the first requesting that he summon an anti-iconoclastic Synod; letters to the Patriarchs of Alexandria and Jerusalem, among other "foreign" clerics, followed. As a result, the emperor ordered at least once more that Theodore be flogged, and the command was this time carried out, with the result that Theodore became quite ill. After his recovery Theodore was moved to Smyrna. Early in 821, however, Leo V fell victim to a grisly murder at the altar of the Church of St. Stephen in the imperial palace; Theodore was released from exile shortly thereafter.
Final years.
Following his release, Theodore made his way back to Constantinople, travelling through north-western Anatolia and meeting with numerous monks and abbots on the way. At the time he appears to have believed that the new emperor, Michael II (r. 820–829), would adopt a pro-icons policy, and he expressed this hope in two letters to Michael. An imperial audience was arranged for a group of iconodule clerics, including Theodore, at which however Michael expressed his attention to "leave the church as he had found it." The abbots were to be allowed to venerate images if they so wished, as long as they remained outside of Constantinople. Theodore returned to Anatolia, in what seems to have been a sort of self-imposed exile.
Theodore's activities in his final years are somewhat difficult to trace. He continued to write numerous letters supporting the use of icons, and appears to have remained an important leader of the opposition to imperial iconoclasm. He was present at a meeting of "more than a hundred" iconodule clerics in 823 or 824, which ended in an argument between the Studites and the host, one Ioannikos, which may have represented a power struggle within the movement. Theodore also spoke against the second marriage of Michael II to the nun Euphrosyne, a daughter of Constantine VI, although in a very moderate fashion, and with none of the passion or effect of the Moechian controversy.
Theodore's years of exile, regular fasting, and exceptional exertions had taken their toll, and in 826 he became quite ill. In this year, he dictated his "Testament", a form of spiritual guidance for the future abbots of the Stoudios monastery, to his disciple Naukratios. He died on the 11 of November of that same year, while celebrating mass, apparently in the monastery of Hagios Tryphon on Cape Akritas in Bithynia. Eighteen years later, his remains, along with those of his brother Joseph, were brought back to the Stoudios Monastery, where they were interred beside the grave of their uncle Platon.
Legacy.
Theodore's revival of the Stoudios monastery had a major effect on the later history of Byzantine monasticism. His disciple, Naukratios, recovered control of the monastery after the end of iconoclasm in 842, and throughout the remainder of the ninth century the Studite abbots continued Theodore's tradition of opposition to patriarchal and imperial authority. Elements of Theodore's "Testament" were incorporated verbatim in the typika of certain early Athonite monasteries. The most important elements of his reform were its emphases on cenobitic (communal) life, manual labor, and a carefully defined administrative hierarchy.
Theodore also built the Stoudios monastery into a major scholarly center, in particular through its library and scriptorium, which certainly surpassed all other contemporary Byzantine ecclesiastical institutions in this regard. Theodore himself was a pivotal figure in the revival of classical literary forms, in particular iambic verse, in Byzantium, and his criticisms of the iconoclastic epigrams drew a connection between literary skill and orthodox faith. After his death the Stoudios monastery continued to be a vital center for Byzantine hymnography and hagiography, as well as for the copying of manuscripts.
Following the "triumph of Orthodoxy" (i.e. the reintroduction of icons) in 843, Theodore became one of the great heroes of the iconodule opposition. There was no formal process of canonization in Byzantium, but Theodore was soon recognized as a saint. In the Latin West, a tradition arose according to which Theodore had recognized papal primacy, on the basis of his letters to Pope Paschal I, and he was formally canonized by the Catholic Church. His feast day is November 11 in the East and November 12 in the West.
Works.
Theodore was an immensely prolific author; among his most important works are:
Commentary on Theodore.
As also mentioned by Kirby Page in "Jesus or Christianity", Charles Loring Brace tells us in "Gesta Christi" that it was not until the 9th century that the first recorded stand against slavery itself was taken by St. Theodore:
No direct word against slavery, however, came forth from the great Teacher Christ. It was not until the ninth century after, that one of his humble followers, Saint Theodore of Studium (Constantinople), ventured to put forth the command "Thou shalt possess no slave, neither for domestic service nor for the labor of the fields, for man is made in the image of God."

</doc>
<doc id="42959" url="https://en.wikipedia.org/wiki?curid=42959" title="Çaro, Pyrénées-Atlantiques">
Çaro, Pyrénées-Atlantiques

Çaro () is a commune in the Pyrénées-Atlantiques department in south-western France.
It is located in the former province of Lower Navarre.

</doc>
<doc id="42960" url="https://en.wikipedia.org/wiki?curid=42960" title="Fractal transform">
Fractal transform

The fractal transform is a technique invented by Michael Barnsley "et al." to perform lossy image compression.
This first practical fractal compression system for digital images resembles a vector quantization system using the image itself as the codebook.
Fractal transform compression.
Start with a digital image A1.
Downsample it by a factor of 2 to produce image A2.
Now, for each block B1 of 4x4 pixels in A1, find the corresponding block B2 in A2 most similar to B1, and then find the grayscale or RGB offset and gain from A2 to B2.
For each destination block, output the positions of the source blocks and the color offsets and gains.
Fractal transform decompression.
Starting with an empty destination image A1, repeat the following algorithm several times:
Downsample A1 down by a factor of 2 to produce image A2. Then copy blocks from A2 to A1 as directed by the compressed data, multiplying by the respective gains and adding the respective color offsets.
This algorithm is guaranteed to converge to an image, and it should appear similar to the original image.
In fact, a slight modification of the decompressor to run at block sizes larger than 4x4 pixels produces a method of stretching images without causing the blockiness or blurriness of traditional linear resampling algorithms.
Patents.
The basic patents covering Fractal Image Compression, U.S. Patents 4,941,193, 5,065,447, 5,384,867, 5,416,856, and 5,430,812 appear to be expired.

</doc>
<doc id="42964" url="https://en.wikipedia.org/wiki?curid=42964" title="Snell's law">
Snell's law

Snell's law (also known as the Snell–Descartes law and the law of refraction) is a formula used to describe the relationship between the angles of incidence and refraction, when referring to light or other waves passing through a boundary between two different isotropic media, such as water, glass, or air.
In optics, the law is used in ray tracing to compute the angles of incidence or refraction, and in experimental optics to find the refractive index of a material. The law is also satisfied in metamaterials, which allow light to be bent "backward" at a negative angle of refraction with a negative refractive index.
Although named after Dutch astronomer Willebrord Snellius (1580–1626), the law was first accurately described by the scientist Ibn Sahl at the Baghdad court in 984. In the manuscript "On Burning Mirrors and Lenses", Sahl used the law to derive lens shapes that focus light with no geometric aberrations.
Snell's law states that the ratio of the sines of the angles of incidence and refraction is equivalent to the ratio of phase velocities in the two media, or equivalent to the reciprocal of the ratio of the indices of refraction:
with each formula_2 as the angle measured from the normal of the boundary, formula_3 as the velocity of light in the respective medium (SI units are meters per second, or m/s), formula_4 as the wavelength of light in the respective medium and formula_5 as the refractive index (which is unitless) of the respective medium.
The law follows from Fermat's principle of least time, which in turn follows from the propagation of light as waves.
History.
Ptolemy, a Greek living in Alexandria, Egypt, had found a relationship regarding refraction angles, but it was inaccurate for angles that were not small. Ptolemy was confident he had found an accurate empirical law, partially as a result of fudging his data to fit theory (see: confirmation bias). Alhazen, in his "Book of Optics" (1021), came closer to discovering the law of refraction, though he did not take this step.
Although named after Dutch astronomer Willebrord Snellius (1580–1626), the law was first accurately described by the scientist Ibn Sahl at the Baghdad court in 984. In the manuscript "On Burning Mirrors and Lenses", Sahl used the law to derive lens shapes that focus light with no geometric aberrations.
The law was rediscovered by Thomas Harriot in 1602, who however did not publish his results although he had corresponded with Kepler on this very subject. In 1621, Willebrord Snellius (Snell) derived a mathematically equivalent form, that remained unpublished during his lifetime. René Descartes independently derived the law using heuristic momentum conservation arguments in terms of sines in his 1637 essay "Dioptrics", and used it to solve a range of optical problems. Rejecting Descartes' solution, Pierre de Fermat arrived at the same solution based solely on his principle of least time. Interestingly, Descartes assumed the speed of light was infinite, yet in his derivation of Snell's law he also assumed the denser the medium, the greater the speed of light. Fermat supported the opposing assumptions, i.e., the speed of light is finite, and his derivation depended upon the speed of light being slower in a denser medium. Fermat's derivation also utilized his invention of adequality, a mathematical procedure equivalent to differential calculus, for finding maxima, minima, and tangents.
In his influential mathematics book "Geometry", Descartes solves a problem that was worked on by Apollonius of Perga and Pappus of Alexandria. Given n lines L and a point P(L) on each line, find the locus of points Q such that the lengths of the line segments QP(L) satisfy certain conditions. For example, when n = 4, given the lines a, b, c, and d and a point A on a, B on b, and so on, find the locus of points Q such that the product QA*QB equals the product QC*QD. When the lines are not all parallel, Pappus showed that the loci are conics, but when Descartes considered larger n, he obtained cubic and higher degree curves. To show that the cubic curves were interesting, he showed that they arose naturally in optics from Snell's law.
According to Dijksterhuis, "In "De natura lucis et proprietate" (1662) Isaac Vossius said that Descartes had seen Snell's paper and concocted his own proof. We now know this charge to be undeserved but it has been adopted many times since." Both Fermat and Huygens repeated this accusation that Descartes had copied Snell. In French, Snell's Law is called "la loi de Descartes" or "loi de Snell-Descartes."
In his 1678 "Traité de la Lumière", Christiaan Huygens showed how Snell's law of sines could be explained by, or derived from, the wave nature of light, using what we have come to call the Huygens–Fresnel principle.
As the development of modern optical and electromagnetic theory, the ancient Snell's law was brought into a new stage. In 1962, Bloembergen showed that at the boundary of nonlinear medium, the Snell's law should be written in a general form. In 2008 and 2011, plasmonic metasurfaces were also demonstrated to change the reflection and refraction directions of light beam.
Explanation.
Snell's law is used to determine the direction of light rays through refractive media with varying indices of refraction. The indices of refraction of the media, labeled formula_6, formula_7 and so on, are used to represent the factor by which a light ray's speed decreases when traveling through a refractive medium, such as glass or water, as opposed to its velocity in a vacuum.
As light passes the border between media, depending upon the relative refractive indices of the two media, the light will either be refracted to a lesser angle, or a greater one. These angles are measured with respect to the "normal line", represented perpendicular to the boundary. In the case of light traveling from air into water, light would be refracted towards the normal line, because the light is slowed down in water; light traveling from water to air would refract away from the normal line.
Refraction between two surfaces is also referred to as "reversible" because if all conditions were identical, the angles would be the same for light propagating in the opposite direction.
Snell's law is generally true only for isotropic or specular media (such as glass). In anisotropic media such as some crystals, birefringence may split the refracted ray into two rays, the "ordinary" or "o"-ray which follows Snell's law, and the other "extraordinary" or "e"-ray which may not be co-planar with the incident ray.
When the light or other wave involved is monochromatic, that is, of a single frequency, Snell's law can also be expressed in terms of a ratio of wavelengths in the two media, λ1 and λ2:
Derivations and formula.
Snell's law may be derived from Fermat's principle, which states that the light travels the path which takes the least time. By taking the derivative of the optical path length, the stationary point is found giving the path taken by the light (though it should be noted that the result does not show light taking the least time path, but rather one that is stationary with respect to small variations as there are cases where light actually takes the greatest time path, as in a spherical mirror). In a classic analogy, the area of lower refractive index is replaced by a beach, the area of higher refractive index by the sea, and the fastest way for a rescuer on the beach to get to a drowning person in the sea is to run along a path that follows Snell's law.
As shown in the figure on the right, assume the refractive index of medium 1 and medium 2 are formula_6 and formula_7 respectively. Light enters medium 2 from medium 1 via point O.
formula_11 is the angle of incidence, formula_12 is the angle of refraction.
The traveling velocities of light in medium 1 and medium 2 are
formula_15 is the speed of light in vacuum.
Let T be the time required for the light to travel from point Q to point P. 
Note that
formula_18
formula_19
Alternatively, Snell's law can be derived using interference of all possible paths of light wave from source to observer—it results in destructive interference everywhere except extrema of phase (where interference is constructive)—which become actual paths.
Another way to derive Snell's Law involves an application of the general boundary conditions of Maxwell equations for electromagnetic radiation.
Yet another way to derive Snell's law is based on translation symmetry considerations. For example, a homogeneous surface perpendicular to the z direction cannot change the transverse momentum. Since the propagation vector formula_23 is proportional to the photon's momentum, the transverse propagation direction formula_24 must remain the same in both regions. Assuming without loss of generality a plane of incidence in the formula_25 plane formula_26. Using the well known dependence of the wavenumber on the refractive index of the medium, we derive Snell's law immediately.
where formula_30 is the wavenumber in vacuum. Note that no surface is truly homogeneous, in the least at the atomic scale. Yet full translational symmetry is an excellent approximation whenever the region is homogeneous on the scale of the light wavelength.
Vector form.
Given a normalized light vector l (pointing from the light source toward the surface) and a normalized plane normal vector n, one can work out the normalized reflected and refracted rays, via the cosines of the angle of incidence formula_11 and angle of refraction formula_12, without explicitly using the sine values or any trigonometric functions or angles:
Note: formula_34 must be positive, which it will be if n is the normal vector that points from the surface toward the side where the light is coming from, the region with index formula_6. If formula_34 is negative, then n points to the side without the light, so start over with n replaced by its negative. 
This reflected direction vector points back toward the side of the surface where the light came from.
Now apply Snell's law to the ratio of sines to derive the formula for the refracted ray's direction vector:
The formula may appear simpler in terms of renamed simple values formula_41 and formula_42, avoiding any appearance of trig function names or angle names:
Example:
The cosine values may be saved and used in the Fresnel equations for working out the intensity of the resulting rays.
Total internal reflection is indicated by a negative radicand in the equation for formula_47, which can only happen for rays crossing into a less-dense medium (formula_48).
Total internal reflection and critical angle.
When light travels from a medium with a higher refractive index to one with a lower refractive index, Snell's law seems to require in some cases (whenever the angle of incidence is large enough) that the sine of the angle of refraction be greater than one. This of course is impossible, and the light in such cases is completely reflected by the boundary, a phenomenon known as total internal reflection. The largest possible angle of incidence which still results in a refracted ray is called the critical angle; in this case the refracted ray travels along the boundary between the two media.
For example, consider a ray of light moving from water to air with an angle of incidence of 50°. The refractive indices of water and air are approximately 1.333 and 1, respectively, so Snell's law gives us the relation
which is impossible to satisfy. The critical angle θcrit is the value of θ1 for which θ2 equals 90°:
Dispersion.
In many wave-propagation media, wave velocity changes with frequency or wavelength of the waves; this is true of light propagation in most transparent substances other than a vacuum. These media are called dispersive. The result is that the angles determined by Snell's law also depend on frequency or wavelength, so that a ray of mixed wavelengths, such as white light, will spread or disperse. Such dispersion of light in glass or water underlies the origin of rainbows and other optical phenomena, in which different wavelengths appear as different colors.
In optical instruments, dispersion leads to chromatic aberration; a color-dependent blurring that sometimes is the resolution-limiting effect. This was especially true in refracting telescopes, before the invention of achromatic objective lenses.
Lossy, absorbing, or conducting media.
In a conducting medium, permittivity and index of refraction are complex-valued. Consequently, so are the angle of refraction and the wave-vector. This implies that, while the surfaces of constant real phase are planes whose normals make an angle equal to the angle of refraction with the interface normal, the surfaces of constant amplitude, in contrast, are planes parallel to the interface itself. Since these two planes do not in general coincide with each other, the wave is said to be inhomogeneous. The refracted wave is exponentially attenuated, with exponent proportional to the imaginary component of the index of refraction.

</doc>
<doc id="42965" url="https://en.wikipedia.org/wiki?curid=42965" title="Éire">
Éire

Etymology.
The modern Irish "Éire" evolved from the Old Irish word "Ériu", which was the name of a Gaelic goddess. "Ériu" is generally believed to have been the matron goddess of Ireland, a goddess of sovereignty, or simply a goddess of the land. The origin of "Ériu" has been traced to the Proto-Celtic reconstruction *"Φīwerjon-" (nominative singular "Φīwerjū" < Pre-Proto-Celtic "-jō"). This suggests a descent from the Proto-Indo-European reconstruction *"piHwerjon-", likely related to the adjectival stem *"piHwer-" (cf. Sanskrit "pīvan", "pīvarī" and "pīvara" meaning "fat, full, abounding"). This would suggest a meaning of "abundant land".
This Proto-Celtic form became "Īweriū" or "Īveriū" in Proto-Goidelic. It is highly likely that explorers borrowed and modified this term. During his exploration of northwest Europe (circa 320 BC), Pytheas of Massilia called the island "Ierne" (written ). In his book "Geographia" (circa 150 AD), Claudius Ptolemaeus called the island "Iouernia" (written ). Based on these historical accounts, the Roman Empire called the island "Hibernia".
Thus, the evolution of the word would follow as such:
A 19th century proposal, which does not follow modern standards of etymology, derives the name from Scottish Gaelic:
This is similar in meaning to the Norse name for Irish people, "west men", which subsequently gave its name to the Icelandic island of Vestmannaeyjar.
Difference between "Éire" and "Erin".
While "Éire" is simply the name for the island of Ireland in the Irish language, and sometimes used in English, "Erin" is a common poetic name for Ireland, as in "Erin go bragh". The distinction between the two is one of the difference between cases of nouns in Irish. "Éire" is the nominative case, the case that (in the modern Gaelic languages) is used for nouns that are the subject of a sentence, i.e., the noun that is "doing" something as well as the direct object of a sentence. "Erin" derives from "Éirinn", the Irish dative case of "Éire", which has replaced the nominative case in Déise Irish and some non-standard sub-dialects elsewhere, in Scottish Gaelic (where the usual word for Ireland is ) and Manx (a form of Gaelic), where the word is spelled "Nerin," with the initial "n-" probably representing a fossilisation of the preposition "in"/"an" "in" (cf. Irish "in Éirinn", Scottish "an Èirinn"/"ann an Èirinn" "in Ireland"). The genitive case, "Éireann", is used in the Gaelic forms of the titles of companies and institutions in Ireland e.g. "Iarnród Éireann" ("Irish Rail"), "Dáil Éireann" ("Irish Parliament") or "Poblacht na hÉireann" ("The Republic of Ireland").
As a state name.
Article 4 of the Irish constitution adopted in 1937 by the government under Éamon de Valera states that "Éire" is the name of the state, or in the English language, "Ireland". The Constitution's English-language preamble also described the population as "We, the people of Éire". Despite the fact that Article 8 designated Irish as the "national" and "first official" language, "Éire" has to some extent passed out of everyday conversation and literature, and the state is referred to as "Ireland" or its equivalent in all other languages.
The name "Éire" has been used on Irish postage stamps since 1922; on all Irish coinage (including Irish euro coins); and together with "Ireland" on passports and other official state documents issued since 1937. "Éire" is used on the Seal of the President of Ireland.
The United Kingdom insisted on using only the name "Eire" and refused to accept the name "Ireland". It adopted the Eire (Confirmation of Agreements) Act 1938 putting in law that position. At the 1948 Summer Olympics the organisers insisted that the Irish team march under the banner "Eire" notwithstanding that every other team was marching according to what their name was in English. The UK Government used what some Irish politicians stated were "sneering titles such as Eirish". The UK Government would refer to "Eire Ministers" and the "Eireann Army" and generally avoid all reference to "Ireland" in connection with the state.
Before the 1937 Constitution, "Saorstát Éireann" (the Irish name of the Irish Free State) was generally used.
During the Emergency (as World War II was known), Irish ships had "EIRE" (and the Irish tricolour) painted large on their sides and deck, to identify them as neutrals.
In 1922–1938 the international plate on Irish cars was "SE". From 1938 to 1962 it was marked "EIR", short for Éire. In 1961 statutory instrument no. 269 allowed "IRL", and by 1962 "IRL" had been adopted. Irish politician Bernard Commons TD suggested to the Dáil in 1950 that the government examine "the tourist identification plate bearing the letters EIR ... with a view to the adoption of identification letters more readily associated with this country by foreigners". "EIR" is also shown in other legislation such as the car insurance statutory instrument no. 383 of 1952 and no. 82 of 1958.
Under the 1947 Convention Irish-registered aircraft have carried a registration mark starting "EI" for Éire.
From January 2007, the Irish government nameplates at meetings of the European Union have borne both "Éire" and "Ireland", following the adoption of Irish as a working language of the European Union.
Spelling "Eire" rather than "Éire".
When Irish-language texts were printed in Gaelic type, diacritics were retained on upper-case letters as for lower-case letters. From the later 1940s, in conjunction with other reforms, printing switched to the same "Roman type" used for most other Latin alphabet languages. There was some uncertainty about whether the "síneadh fada" (acute accent) should be written on upper-case letters. While it was preserved in all-Irish texts, it was often omitted when short fragments of Irish appeared alone or in English texts. Noel Davern asked in the Dáil in 1974 why Irish stamps had "EIRE" rather than "ÉIRE". The reply from the Minister for Posts and Telegraphs was:
The spelling "Eire" is generally deplored by Irish-speakers as worse than a misspelling, because "eire" is a separate word, meaning "a burden, load or encumbrance". The minister in 1974 stated, "The word on the stamp ... does not mean 'eire' and it is not understood to mean 'eire' by anybody except Davern." Stamps later reverted to a Gaelic type with the accent preserved.
In 1938 the British government provided in the Eire (Confirmation of Agreements) Act 1938 that British legislation could henceforth refer to the Irish Free State as "Eire" (but not as "Ireland"). The 1938 Act was repealed in 1981, and in 1996 a British journalist described "Eire" as "now an oddity rarely used, an out-of-date reference".
Founded in 1937, the Eire Society of Boston is an influential Irish-American group.
Other uses.
Éire has also been incorporated into the names of Irish commercial and social entities, such as Eir (formerly Eircom and Telecom Éireann) and its former mobile phone network, Eircell. In 2006 the Irish electricity network was devolved to EirGrid. The company "BetEire Flow" (eFlow), named as a pun on "better", is a French consortium running the electronic tolling system at the West-Link bridge west of Dublin. According to the Dublin Companies Registration Office in 2008, over 500 company names incorporate the word Éire in some form.
Sometimes the incorporation is used for humorous or ironic effect, such as the sub reddit for Irish software developers named "DevelEire", or Cormac Ó Gráda's "Éirvana" paper in 2007 on the Celtic Tiger economy.

</doc>
<doc id="42966" url="https://en.wikipedia.org/wiki?curid=42966" title="Montreal Canadiens">
Montreal Canadiens

The Montreal Canadiens () are a Canadian professional ice hockey team based in Montreal, Quebec, that competes in the National Hockey League (NHL). They are members of the league's Atlantic Division in the Eastern Conference.
The club's official name is . The team is frequently referred to in English and French as the Habs. French nicknames for the team include "Les Canadiens" (or "Le Canadien"), "Le Bleu-Blanc-Rouge", "La Sainte-Flanelle", "Le Tricolore", "Les Glorieux" (or "Nos Glorieux"), "Les Habitants", "Le CH" and "Le Grand Club".
Founded in 1909, the Canadiens are the longest continuously operating professional ice hockey team worldwide, and the only existing NHL club to predate the founding of the NHL. One of the oldest North American professional sports franchises, the Canadiens' history predates that of every other Canadian franchise outside of football as well as every American franchise outside of baseball and the National Football League's Arizona Cardinals. The franchise is one of the "Original Six" teams, a description used for the teams that made up the NHL from 1942 until the 1967 expansion. The team's championship season in 1992–93 was the last time a Canadian team won the Stanley Cup.
The Canadiens have won the Stanley Cup more times than any other franchise. They have won 24 championships, 22 of them since 1927, when NHL teams became the only ones to compete for the Stanley Cup. On a percentage basis, as of 2014, the franchise has won 25.3% of all Stanley Cup championships contested after the Challenge Cup era, making it the second most successful professional sports team of the traditional four major sports of Canada and the United States, behind only the Boston Celtics.
Since 1996, the Canadiens have played their home games at the Bell Centre, originally known as the Molson Centre. The team previously played at the Montreal Forum which housed the team for seven decades and all but their first two Stanley Cup championships.
History.
The Canadiens were founded by J. Ambrose O'Brien on December 4, 1909, as a charter member of the National Hockey Association,
the forerunner to the National Hockey League. It was to be the team of the francophone community in Montreal, composed of francophone players, and under francophone ownership as soon as possible. The team's first season was not a success, as they placed last. After the first year, ownership was transferred to George Kennedy of Montreal and the team's fortunes improved over the next seasons. The team won its first Stanley Cup championship in the 1915–16 season. In 1917, with four other NHA teams, the Canadiens formed the NHL, and they won their first NHL Stanley Cup during the 1923–24 season, led by Howie Morenz. The team moved from the Mount Royal Arena to the Montreal Forum for the 1926–27 season.
The club began the 1930s decade successfully, with Stanley Cup wins in 1930 and 1931. The Canadiens and its then-Montreal rival, the Montreal Maroons, declined both on the ice and economically during the Great Depression. Losses grew to the point where the team owners considering selling the team to interests in Cleveland, Ohio, though local investors were ultimately found to finance the Canadiens. The Maroons still suspended operations, and several of their players moved to the Canadiens.
Led by the "Punch Line" of Maurice "Rocket" Richard, Toe Blake and Elmer Lach in the 1940s, the Canadiens enjoyed success again atop the NHL. From 1953 to 1960, the franchise won six Stanley Cups, including a record five straight from 1956 to 1960, with a new set of stars coming to prominence: Jean Beliveau, Dickie Moore, Doug Harvey, Bernie "Boom Boom" Geoffrion, Jacques Plante and Richard's younger brother, Henri.
The Canadiens added ten more championships in 15 seasons from 1965 to 1979, with another dynastic run of four-straight Cups from 1976 to 1979. In the 1976–77 season, the Canadiens set two still-standing team records — for most points, with 132, and fewest losses, by only losing eight games in an 80-game season. The next season, 1977–78, the team had a 28-game unbeaten streak, the second-longest in NHL history. The next generation of stars included Guy Lafleur, Yvan Cournoyer, Ken Dryden, Pete Mahovlich, Jacques Lemaire, Pierre Larouche, Steve Shutt, Bob Gainey, Serge Savard, Guy Lapointe and Larry Robinson. Scotty Bowman, who would later set a record for most NHL victories by a coach, was the team's head coach for its last five Stanley Cup victories in the 1970s.
The Canadiens won Stanley Cups in 1986, led by rookie star goaltender Patrick Roy, and in 1993, continuing their streak of winning at least one championship in every decade from the 1910s to the 1990s (this streak came to an end in the 2000s). In 1996, the Habs moved from the Montreal Forum, their home during 70 seasons and 22 Stanley Cups, to the Molson Centre (now the Bell Centre).
Following Roy's departure in 1995, the Canadiens fell into an extended stretch of mediocrity, missing the playoffs in four of their next ten seasons and failing to advance past the second round of the playoffs until 2010. By the late 1990s, with both an ailing team and monetary losses exacerbated by a record-low value of the Canadian dollar, Montreal fans feared their team would end up relocated to the United States. Team owner Molson Brewery sold control of the franchise and the Molson Centre to American businessman George N. Gillett Jr. in 2001, with the right of first refusal for any future sale by Gillett and a condition that the NHL Board of Governors must unanimously approve any attempt to move to a new city. Led by president Pierre Boivin, the Canadiens returned to being a lucrative enterprise, earning additional revenues from broadcasting and arena events. In 2009, Gillett sold the franchise to a consortium led by the Molson family which included The Woodbridge Company, BCE/Bell, the QFL Solidarity Fund, Michael Andlauer, Luc Bertrand and the National Bank Financial Group for $575 million, more than double the $275 million he spent on the purchase eight years prior.
During the 2008–09 season, the Canadiens celebrated their 100th anniversary with various events, including hosting both the 2009 NHL All-Star Game, and the 2009 NHL Entry Draft. Said season also marked the Canadiens as the first team in NHL history to reach 3,000 victories, reaching the milestone after their 5–2 victory over the Florida Panthers on December 29, 2008.
Team identity.
The Canadiens organization operates in both English and French. For many years, public address announcements and press releases have been given in both languages, and the team Web site and social media outlets are in both languages as well.
Crest and sweater design.
One of sport's oldest and most recognizable logos, the classic 'C' and 'H' of the Montreal Canadiens was first used together in the 1917–18 season, when the club changed its name to "Club de hockey Canadien" from "Club athlétique Canadien", before evolving to its current form in 1952–53. The "H" stands for "hockey", not "Habitants," a popular misconception. According to NHL.com, the first man to refer to the team as "the Habs" was American Tex Rickard, owner of the Madison Square Garden, in 1924. Rickard apparently told a reporter that the "H" on the Canadiens' sweaters was for "Habitants".
The team's colours since 1911 are blue, red, and white. The home sweater is predominantly red in colour. There are four blue and white stripes, one across each arm, one across the chest and the other across the waistline. The main road sweater is mainly white with a red and blue stripe across the waist, red at the end of both arm sleeves red shoulder yokes. The basic design has been in use since 1914 and took its current form in 1925, generally evolving as materials changed. Because of the team's lengthy history and significance in Quebec, the sweater has been referred to as (the holy flannel sweater).
The Canadiens used multiple designs prior to adopting the aforementioned design in 1914. The original shirt of the 1909–10 season was blue with a white C. The second season had a red shirt featuring a green maple leaf with the C logo, and green pants. Lastly, the season before adopting the current look the Canadiens wore a "barber pole" design jersey with red, white and blue stripes, and the logo being a white maple leaf reading "CAC", "Club athlétique Canadien". All three designs were worn during the 2009–10 season as part of the Canadiens centenary.
The Canadiens' colours are a readily identifiable aspect of French Canadian culture. In the short story "The Hockey Sweater", Roch Carrier described the influence of the Canadiens and their jersey within rural Quebec communities during the 1940s.
The story was later made into an animated short, "The Sweater", narrated by Carrier.
A passage from the short story appears on the 2002 issue of the Canadian five dollar bill.
Motto.
"Nos bras meurtris vous tendent le flambeau, à vous toujours de le porter bien haut."
"To you from failing hands we throw the torch. Be yours to hold it high."
The motto is from the poem "In Flanders Fields" by John McCrae which was written in 1915, the year the Canadiens won their first Stanley Cup championship. The motto appears on the wall of the Canadiens dressing room, originally at the Montreal Forum and currently at the Bell Centre.
Mascot.
Beginning in the 2004–05 NHL season, the Canadiens adopted Youppi as their official mascot, the first costumed mascot in their long history. Youppi was the longtime mascot for the Montreal Expos baseball team, but was dropped from the franchise when they moved to Washington, D.C. in 2004 and became the Washington Nationals. With the switch, Youppi became the first mascot in professional sports to switch leagues.
Rivalries.
The Canadiens have developed strong rivalries with two fellow Original Six franchises, with whom they frequently shared divisions and competed in post-season play. The oldest is with the Toronto Maple Leafs, who first faced the Canadiens as the Toronto Arenas in 1917. The teams met 15 times in the playoffs, including five Stanley Cup finals. Featuring the two largest cities in Canada and two of the largest fanbases in the league, the rivalry is sometimes dramatized as being emblematic of Canada's English and French linguistic divide. From 1938 to 1970, they were the only two Canadian teams in the league.
The team's other Original Six rival are the Boston Bruins, who since their NHL debut in 1924 have played the Canadiens more than any other team in both regular season play and the playoffs combined. The teams have played 34 playoff series, seven of which were in the finals.
The Canadiens also had an intraprovincial rivalry with the Quebec Nordiques during its existence from 1979-1995, nicknamed the "Battle of Quebec."
Broadcasting.
Montreal Canadiens games are broadcast locally in both the French and English languages. On radio, Canadiens games are broadcast in French by CHMP 98.5, and in English by CKGM, "TSN Radio 690", who acquired the English broadcast rights under a 7-year deal which began in the 2011-12 season.
Regional television rights in French are currently held by Réseau des sports under a 12-year deal, effective as of the 2014–15 NHL season. A sister to the English-language network TSN, RDS was the only French-language sports channel in Canada until the 2011 launch of TVA Sports, and was also the previous national French rightsholder of the NHL; as a result, the Canadiens forewent a separate regional contract, and allowed its games to be televised nationally as part of RDS's national rights package.
With TVA Sports becoming the national French rightsholder in the 2014–15 season through a sub-licensing agreement with Rogers Communications, RDS parent company Bell Media subsequently announced a 12-year deal to maintain regional rights to Canadiens games not shown on TVA Sports. As a result, games on RDS are blacked out outside of the Canadiens' home market of Quebec, Atlantic Canada and parts of Ontario shared with the Ottawa Senators. At least 22 Canadiens games per season (primarily through its Saturday night "La super soirée LNH"), including all playoff games, are televised nationally by TVA Sports.
Regional television rights in English are held by Sportsnet East in a 3-year deal announced by Rogers on September 2, 2014, with selected games (three in its inaugural season) airing on CJNT "City Montreal". The remaining games are aired nationally through Rogers' aforementioned NHL rights deal (including additional games on Sportsnet, City, or on CBC during "Hockey Night in Canada"), thus giving Rogers rights to over all English-language telecasts of the Canadiens. Regional Canadiens games on Sportsnet East and City are called by John Bartlett and Jason York. TSN previously held regional, English-language television rights to the Canadiens from 2010 through 2014. They were broadcast on a part-time TSN feed with Dave Randorf on play-by-play; these rights were not renewed by Bell Media past the 2013–14 season.
Seasons and records.
Season by season results.
"This is a list of the last five seasons completed by the Canadiens. For the full season-by-season history, see List of Montreal Canadiens seasons."
"Note: GP = Games played, W = Wins, L = Losses, T = Ties, OTL = Overtime Losses, Pts = Points, GF = Goals for, GA = Goals against"
Franchise individual records.
Franchise scoring leaders.
These are the top-ten point-scorers in franchise history. Figures are updated after each completed NHL regular season.
"Note: Pos = Position; GP = Games Played; G = Goals; A = Assists; Pts = Points; P/G = Points per game
Sources: , 
Records – skaters.
Source: 
Records – goaltenders.
Source: 
Leaders.
Head coaches.
Source: 
Honoured members.
Retired numbers.
The Canadiens have retired 15 numbers in honour of 19 players, the most of any team in the NHL. All of the honourees were born in Canada. Howie Morenz was the first honouree, on November 2, 1937.
Hockey Hall of Fame.
Sixty-two people associated with the Canadiens have been inducted into the Hockey Hall of Fame. Thirty-six of these players are from three separate notable dynasties: 12 from 1955–60, 11 from 1964–69 and 13 from 1975–79. Howie Morenz and Georges Vezina were the first Canadiens given the honour in 1945, while Chris Chelios was the most recently inducted, in 2013.
The following are members of the Hockey Hall of Fame in the Builders category. The first inductee was Vice President William Northy in 1945. The most recent inductee was head coach Pat Burns in 2014.

</doc>
<doc id="42967" url="https://en.wikipedia.org/wiki?curid=42967" title="Ornithology">
Ornithology

Ornithology is a branch of zoology that concerns the study of birds. Etymologically, the word "ornithology" derives from the ancient Greek ὄρνις "ornis" ("bird") and λόγος "logos" ("rationale" or "explanation"). Several aspects of ornithology differ from related disciplines, due partly to the high visibility and the aesthetic appeal of birds. Most marked among these is the extent of studies undertaken by amateurs working within the parameters of strict scientific methodology.
The science of ornithology has a long history and studies on birds have helped develop several key concepts in evolution, behaviour and ecology such as the definition of species, the process of speciation, instinct, learning, ecological niches, guilds, island biogeography, phylogeography and conservation. While early ornithology was principally concerned with descriptions and distributions of species, ornithologists today seek answers to very specific questions, often using birds as models to test hypotheses or predictions based on theories. Most modern biological theories apply across taxonomic groups and the number of professional scientists who identify themselves as "ornithologists" has therefore declined. A wide range of tools and techniques are used in ornithology, both inside the laboratory and out in the field, and innovations are constantly made.
Etymology.
The origins of the word "ornithology" come from the Greek "ornithologos" and late 17th-century Latin "ornithologia" meaning "bird science".
History.
The history of ornithology largely reflects the trends in the history of biology, as well as many other scientific disciplines, including ecology, anatomy, physiology, paleontology, and more recently molecular biology. Trends include the move from mere descriptions to the identification of patterns, and thus towards elucidating the processes that produce these patterns.
Early knowledge and study.
Humans have had an observational relationship with birds since prehistory, with some stone age drawings being amongst the oldest indications of an interest in birds. Birds were perhaps important as a food source, and bones of as many as 80 species have been found in excavations of early Stone Age settlements. Waterbird and seabird remains have also been found in shell mounds on the island of Oronsay off the coast of Scotland.
Cultures around the world have rich vocabularies related to birds. Traditional bird names are often based on detailed knowledge of the behaviour, with many names being onomatopoeic, many still in use. Traditional knowledge may also involve the use of birds in folk medicine and knowledge of these practices are passed on through oral traditions (see ethno-ornithology). Hunting of wild birds as well as their domestication would have required considerable knowledge of their habits. Poultry farming and falconry were practised from early times in many parts of the world. Artificial incubation of poultry was practised in China around 246 BC and around at least 400 BC in Egypt. The Egyptians also made use of birds in their hieroglyphic scripts, many of which, though stylized, are still identifiable to species.
Early written records provide valuable information on the past distributions of species. For instance Xenophon records the abundance of the ostrich in Assyria (Anabasis, i. 5); this subspecies from Asia minor is extinct and all extant ostrich races are today restricted to Africa. Other old writings such as the Vedas (1500–800 BC) demonstrate the careful observation of avian life histories and includes the earliest reference to the habit of brood parasitism by the Asian koel ("Eudynamys scolopacea"). Like writing, the early art of China, Japan, Persia and India also demonstrate knowledge, with examples of scientifically accurate bird illustrations.
Aristotle in 350 BC in his "Historia Animalium" noted the habit of bird migration, moulting, egg laying and life spans, as well as compiling a list of 170 different bird species. However, he also introduced and propagated several myths, such as the idea that swallows hibernated in winter, although he noted that cranes migrated from the steppes of Scythia to the marshes at the headwaters of the Nile. The idea of swallow hibernation became so well established that, even as late as in 1878, Elliott Coues could list as many as 182 contemporary publications dealing with the hibernation of swallows and little published evidence to contradict the theory. Similar misconceptions existed regarding the breeding of barnacle geese. Their nests had not been seen and it was believed that they grew by transformations of goose barnacles, an idea that became prevalent from around the 11th century and noted by Bishop Giraldus Cambrensis (Gerald of Wales) in "Topographia Hiberniae" (1187). Around 77 AD, Pliny the Elder described birds, among other creatures, in his "Historia Naturalis".
The origins of falconry have been traced to Mesopotamia and the earliest record comes from the reign of Sargon II (722–705 BC). Falconry made its entry to Europe only after AD 400, brought in from the East after invasions by the Huns and Allans. Frederick II of Hohenstaufen (1194–1250) learned about Arabian falconry during wars in the region and obtained an Arabic treatise on falconry by Moamyn. He had this work translated into Latin and also conducted experiments on birds in his menagerie. By sealing the eyes of vultures and placing food nearby, he concluded that they found food by sight, and not by smell. He also developed methods to keep and train falcons. The studies that he undertook over nearly 30 years, were published in 1240 as De Arte Venandi cum Avibus (The Art of Hunting with Birds), considered one of the earliest studies on bird behaviour, and the first work known to include illustrations of birds.
Several early German and French scholars compiled old works and conducted new research on birds. These included Guillaume Rondelet who described his observations in the Mediterranean and Pierre Belon who described the fish and birds that he had seen in France and the Levant. Belon's Book of Birds (1555) is a folio volume with descriptions of some two hundred species. His comparison of the skeleton of humans and birds is considered as a landmark in comparative anatomy. Volcher Coiter (1534–1576), a Dutch anatomist made detailed studies of the internal structures of birds and produced a classification of birds, "De Differentiis Avium" (around 1572), that was based on structure and habits. Konrad Gesner wrote the "Vogelbuch" and "Icones avium omnium" around 1557. Like Gesner, Ulisse Aldrovandi, an encyclopedic naturalist began a 14-volume natural history with three volumes on birds, entitled "ornithologiae hoc est de avibus historiae libri XII" which was published from 1599 to 1603. Aldrovandi showed great interest in plants and animals and his work included 3000 drawings of fruits, flowers, plants and animals, published in 363 volumes. His "Ornithology" alone covers 2000 pages and included such aspects as the chicken and poultry techniques. He used a number of traits including behaviour, particularly bathing and dusting, to classify bird groups.
William Turner's "Historia Avium" ("History of Birds"), published at Cologne in 1544, was an early ornithological work from England. He noted the commonness of kites in English cities where they snatched food out of the hands of children. He included folk beliefs such as those of anglers. Anglers believed that the osprey emptied their fishponds and would kill them, mixing the flesh of the osprey into their fish bait. Turner's work reflected the violent times that he lived in and stands in contrast to later works such as Gilbert White's "The Natural History and Antiquities of Selborne" that were written in a tranquil era.
In the 17th century Francis Willughby (1635–1672) and John Ray (1627–1705) came up with the first major system of bird classification that was based on function and morphology rather than on form or behaviour. Willughby's "Ornithologiae libri tres" (1676) completed by John Ray is sometimes considered to mark the beginning of scientific ornithology. Ray also worked on "Ornithologia" which was published posthumously in 1713 as "Synopsis methodica avium et piscium". The earliest list of British birds, "Pinax Rerum Naturalium Britannicarum" was written by Christopher Merrett in 1667, but authors such as John Ray considered it of little value. Ray did however, value the expertise of the naturalist Sir Thomas Browne (1605–82) who, not only answered his queries on ornithological identification and nomenclature, but also those of Willoughby and Merrett in letter correspondence. Browne himself in his lifetime kept an eagle, owl, cormorant, bittern and ostrich, penned a tract on falconry, and introduced the words "incubation" and "oviparous" into the English language. 
Towards the late 18th century, Mathurin Jacques Brisson (1723–1806) and Comte de Buffon (1707–1788) began new works on birds. Brisson produced a six-volume work "Ornithologie" in 1760 and Buffon's included nine volumes (volumes 16–24) on birds "Histoire naturelle des oiseaux" (1770–1785) in his work on science "Histoire naturelle générale et particulière" (1749–1804). Coenraad Jacob Temminck (1778–1858) sponsored François Le Vaillant [1753–1824] to collect bird specimens in Africa and this resulted in Le Vaillant's six-volume "Histoire naturelle des oiseaux d'Afrique" (1796–1808). Louis Jean Pierre Vieillot (1748–1831) spent ten years studying North American birds and wrote the "Histoire naturelle des oiseaux de l'Amerique septentrionale" (1807–1808?). Vieillot pioneered in the use of life-histories and habits in classification. Alexander Wilson composed a nine-volume work, American Ornithology, published 1808-14—the first such record of North American birds, significantly predating Audubon. In the early 19th century, Lewis and Clark studied and identified many birds in the western United States. John James Audubon, born in 1785, observed and painted birds in France and later in the Ohio and Mississippi valleys. From 1827 to 1838, Audubon published "The Birds of America", which was engraved by Robert Havell, Sr. and his son Robert Havell, Jr.. Containing 435 engravings, it is often regarded as the greatest ornithological work in history.
Scientific studies.
The emergence of ornithology as a scientific discipline began in the 18th century when Mark Catesby published his two-volume "Natural History of Carolina, Florida and the Bahama Islands", a landmark work which included 220 hand-painted engravings and was the basis for many of the species Carl Linnaeus described in the 1758 "Systema Naturae". Linnaeus' work revolutionised bird taxonomy by assigning every species a binomial name, categorising them into different genera.
However, it was not until the Victorian era—with the concept of natural history, and the collection of natural objects such as bird eggs and skins—that ornithology emerged as a specialised science. This specialization led to the formation in Britain of the British Ornithologists' Union in 1858. In 1859 the members founded its journal "The Ibis". The sudden spurt in ornithology was also due in part to colonialism. A hundred years later, in 1959, R. E. Moreau noted that ornithology in this period was preoccupied with the geographical distributions of various species of birds.
The bird collectors of the Victorian era observed the variations in bird forms and habits across geographic regions, noting local specialization and variation in widespread species. The collections of museums and private collectors grew with contributions from various parts of the world. The naming of species with binomials and the organization of birds into groups based on their similarities became the main work of museum specialists. The variations in widespread birds across geographical region caused the introduction of trinomial names.
The search for patterns in the variations of birds was attempted by many. Friedrich Wilhelm Joseph Schelling (1775–1854), his student Johann Baptist von Spix (1781–1826) and several others believed that there was a hidden and innate mathematical order in the forms of birds. They believed that there was a "natural" classification that was superior to "artificial" ones. A particularly popular idea was the Quinarian system popularised by Nicholas Aylward Vigors (1785–1840), William Sharp Macleay (1792–1865), William Swainson and others. The idea was that nature followed a "rule of five" with five groups nested hierarchically. Some had attempted a rule of four, but Johann Jakob Kaup (1803–1873) insisted that the number five was special noting that other natural entities such as the senses also came in fives. He followed this idea and demonstrated his view of the order within the crow family. Where he failed to find 5 genera, he left a blank insisting that a new genus would found to fill these gaps. These ideas were replaced by more complex "maps" of affinities in works by Hugh Edwin Strickland and Alfred Russel Wallace.
The Galapagos finches were especially influential in the development of Charles Darwin's theory of evolution. His contemporary Alfred Russel Wallace also noted these variations and the geographical separations between different forms leading to the study of biogeography. Wallace was influenced by the work of Philip Lutley Sclater on the distribution patterns of birds.
For Darwin, the problem was how species arose from a common ancestor, but he did not attempt to find rules for delineation of species. The species problem was tackled by the ornithologist Ernst Mayr. Mayr was able to demonstrate that geographical isolation and the accumulation of genetic differences led to the splitting of species.
Early ornithologists were preoccupied with matters of species identification. Only systematics counted as true science and field studies were considered inferior through much of the 19th century. In 1901 Robert Ridgway wrote in the introduction to "The Birds of North and Middle America" that:
This early idea that the study of "living birds" was merely recreation held sway until ecological theories became the predominant focus of ornithological studies. The study of birds in their habitats was particularly advanced in Germany with bird ringing stations established as early as 1903. By the 1920s the "Journal für Ornithologie" included many papers on the behaviour, ecology, anatomy and physiology, many written by Erwin Stresemann. Stresemann changed the editorial policy of the journal, leading both to a unification of field and laboratory studies and a shift of research from museums to universities. Ornithology in the United States continued to be dominated by museum studies of morphological variations, species identities and geographic distributions, until it was influenced by Stresemann's student Ernst Mayr. In Britain, some of the earliest ornithological works that used the word ecology appeared in 1915. "The Ibis" however resisted the introduction of these new methods of study and it was not until 1943 that any paper on ecology appeared. The work of David Lack on population ecology was pioneering. Newer quantitative approaches were introduced for the study of ecology and behaviour and this was not readily accepted. For instance, Claud Ticehurst wrote:
David Lack's studies on population ecology sought to find the processes involved in the regulation of population based on the evolution of optimal clutch sizes. He concluded that population was regulated primarily by density-dependent controls, and also suggested that natural selection produces life-history traits that maximize the fitness of individuals. Others like Wynne-Edwards interpreted population regulation as a mechanism that aided the "species" rather than individuals. This led to widespread and sometimes bitter debate on what constituted the "unit of selection". Lack also pioneered the use of many new tools for ornithological research, including the idea of using radar to study bird migration.
Birds were also widely used in studies of the niche hypothesis and Georgii Gause's competitive exclusion principle. Work on resource partitioning and the structuring of bird communities through competition were made by Robert MacArthur. Patterns of biodiversity also became a topic of interest. Work on the relationship of the number of species to area and its application in the study of island biogeography was pioneered by E. O. Wilson and Robert MacArthur. These studies led to the development of the discipline of landscape ecology.
John Hurrell Crook studied the behaviour of weaverbirds and demonstrated the links between ecological conditions, behaviour and social systems. Principles from economics were introduced to the study of biology by Jerram L. Brown in his work on explaining territorial behaviour. This led to more studies of behaviour that made use of cost-benefit analyses. The rising interest in sociobiology also led to a spurt of bird studies in this area.
The study of imprinting behaviour in ducks and geese by Konrad Lorenz and the studies of instinct in herring gulls by Nicolaas Tinbergen, led to the establishment of the field of ethology. The study of learning became an area of interest and the study of bird song has been a model for studies in neuro-ethology. The study of hormones and physiology in the control of behaviour has also been aided by bird models. These have helped in finding the proximate causes of circadian and seasonal cycles. Studies on migration have attempted to answer questions on the evolution of migration, orientation and navigation.
The growth of genetics and the rise of molecular biology led to the application of the gene-centered view of evolution to explain avian phenomena. Studies on kinship and altruism, such as helpers, became of particular interest. The idea of inclusive fitness was used to interpret observations on behaviour and life-history and birds were widely used models for testing hypotheses based on theories postulated by W. D. Hamilton and others.
The new tools of molecular-biology changed the study of bird systematics. Systematics changed from being based on phenotype to the underlying genotype. The use of techniques such as DNA-DNA hybridization to study evolutionary relationships was pioneered by Charles Sibley and Jon Edward Ahlquist resulting in what is called the Sibley-Ahlquist taxonomy. These early techniques have been replaced by newer ones based on mitochondrial DNA sequences and molecular phylogenetics approaches that make use of computational procedures for sequence alignment, construction of phylogenetic trees and calibration of molecular clocks to infer evolutionary relationships. Molecular techniques are also widely used in studies of avian population biology and ecology.
Rise to popularity.
The use of field glasses or telescopes for bird observation began in the 1820s and 1830s with pioneers like J. Dovaston (who also pioneered in the use of bird-feeders), but it was not until the 1880s that instruction manuals began to insist on the use of optical aids such as "a first-class telescope" or "field glass."
The rise of field guides for the identification of birds was another major innovation. The early guides such as those of Thomas Bewick (2 volumes) and William Yarrell (3 volumes) were cumbersome, and mainly focused on identifying specimens in the hand. The earliest of the new generation of field guides was prepared by Florence Merriam, sister of Clinton Hart Merriam, the mammalogist. This was published in 1887 in a series "Hints to Audubon Workers:Fifty Birds and How to Know Them" in Grinnell's "Audubon Magazine". These were followed by new field guides including classics by Roger Tory Peterson.
The interest in birdwatching grew in popularity in many parts of the world and it was realized that there was a possibility for amateurs to contribute to biological studies. As early as 1916, Julian Huxley wrote a two part article in "The Auk", noting the tensions between amateurs and professionals and suggested the possibility that the "vast army of bird-lovers and bird-watchers could begin providing the data scientists needed to address the fundamental problems of biology."
Organizations were started in many countries and these grew rapidly in membership, most notable among them being the Royal Society for the Protection of Birds (RSPB) in Britain and the Audubon Society in the US. The Audubon Society started in 1885. Both these organizations were started with the primary objective of conservation. The RSPB, born in 1889, grew from a small group of women in Croydon who met regularly and called themselves the "Fur, Fin and Feather Folk" and who took a pledge "to refrain from wearing the feathers of any birds not killed for the purpose of food, the Ostrich only exempted." The organization did not allow men as members initially, avenging a policy of the British Ornithologists' Union to keep out women. Unlike the RSPB, which was primarily conservation oriented, the British Trust for Ornithology (BTO) was started in 1933 with the aim of advancing ornithological research. Members were often involved in collaborative ornithological projects. These projects have resulted in atlases which detail the distribution of bird species across Britain. In the United States, the Breeding Bird Surveys, conducted by the US Geological Survey have also produced atlases with information on breeding densities and changes in the density and distribution over time. Other volunteer collaborative ornithology projects were subsequently established in other parts of the world.
Techniques.
The tools and techniques of ornithology are varied and new inventions and approaches are quickly incorporated. The techniques may be broadly dealt under the categories of those that are applicable to specimens and those that are used in the field, however the classification is rough and many analysis techniques are usable both in the laboratory and field or may require a combination of field and laboratory techniques.
Collections.
The earliest approaches to modern bird study involved the collection of eggs, a practice known as oology. While collecting became a pastime for many amateurs, the labels associated with these early egg collections made them unreliable for the serious study of bird breeding. In order to preserve eggs, a tiny hole was pierced and the contents extracted. This technique became standard with the invention of the blow drill around 1830. Egg collection is no longer popular; however historic museum collections have been of value in determining the effects of pesticides such as DDT on physiology. Museum bird collections continue to act as a resource for taxonomic studies.
The use of bird skins to document species has been a standard part of systematic ornithology. Bird skins are prepared by retaining the key bones of the wings, leg and skull along with the skin and feathers. In the past, they were treated with arsenic to prevent fungal and insect (mostly dermestid) attack. Arsenic, being toxic, was replaced by borax. Amateur and professional collectors became familiar with these skinning techniques and started sending in their skins to museums, some of them from distant locations. This led to the formation of huge collections of bird skins in museums in Europe and North America. Many private collections were also formed. These became references for comparison of species and the ornithologists at these museums were able to compare species from different locations, often places that they themselves never visited. Morphometrics of these skins, particularly the lengths of the tarsus, bill, tail and wing became important in the descriptions of bird species. These skin collections have been utilized in more recent times for studies on molecular phylogenetics by the extraction of ancient DNA. The importance of type specimens in the description of species make skin collections a vital resource for systematic ornithology. However, with the rise of molecular techniques, it has now become possible to establish the taxonomic status of new discoveries, such as the Bulo Burti boubou ("Laniarius liberatus", no longer a valid species) and the Bugun liocichla ("Liocichla bugunorum"), using blood, DNA and feather samples as the holotype material.
Other methods of preservation include the storage of specimens in spirit. Such wet-specimens have special value in physiological and anatomical study, apart from providing better quality of DNA for molecular studies. Freeze drying of specimens is another technique that has the advantage of preserving stomach contents and anatomy, although it tends to shrink making it less reliable for morphometrics.
In the field.
The study of birds in the field was helped enormously by improvements in optics. Photography made it possible to document birds in the field with great accuracy. High power spotting scopes today allow observers to detect minute morphological differences that were earlier possible only by examination of the specimen "in the hand".
The capture and marking of birds enables detailed studies of life-history. Techniques for capturing birds are varied and include the use of bird liming for perching birds, mist nets for woodland birds, cannon netting for open area flocking birds, the bal-chatri trap for raptors, decoys and funnel traps for water birds.
The bird in the hand may be examined and measurements can be made including standard lengths and weight. Feather moult and skull ossification provide indications of age and health. Sex can be determined by examination of anatomy in some sexually non-dimorphic species. Blood samples may be drawn to determine hormonal conditions in studies of physiology, identify DNA markers for studying genetics and kinship in studies of breeding biology and phylogeography. Blood may also be used to pathogens and arthropod borne viruses. Ectoparasites may be collected for studies of coevolution and zoonoses. In many of cryptic species, measurements (such as the relative lengths of wing feathers in warblers) are vital in establishing identity.
Captured birds are often marked for future recognition. Rings or bands provide long-lasting identification but require capture for the information on them to be read. Field identifiable marks such as coloured bands, wing tags or dyes enable short-term studies where individual identification is required. Mark and recapture techniques make demographic studies possible. Ringing has traditionally been used in the study of migration. In recent times satellite transmitters provide the ability to track migrating birds in near real-time.
Techniques for estimating population density include point counts, transects and territory mapping. Observations are made in the field using carefully designed protocols and the data may be analysed to estimate bird diversity, relative abundance or absolute population densities. These methods may be used repeatedly over large time spans to monitor changes in the environment. Camera traps have been found to be a useful tool for the detection and documentation of elusive species, nest predators and in the quantitative analysis of frugivory, seed dispersal and behaviour.
In the laboratory.
Many aspects of bird biology are difficult to study in the field. These include the study of behavioural and physiological changes that require a long duration of access to the bird. Non-destructive samples of blood or feathers taken during field studies may be studied in the laboratory. For instance, the variation in the ratios of stable hydrogen isotopes across latitudes makes it possible to roughly establish the origins of migrant birds using mass spectrometric analysis of feather samples. These techniques can be used in combination with other techniques such as ringing.
The first attenuated vaccine developed by Louis Pasteur was for fowl cholera and was tested on poultry in 1878. Poultry continues to be used as a model for many studies in non-mammalian immunology.
Studies in bird behaviour include the use of tamed and trained birds in captivity. Studies on bird intelligence and song learning have been largely laboratory based. Field researchers may make use of a wide range of techniques such as the use of dummy owls to elicit mobbing behaviour, dummy males or the use of call playback to elicit territorial behaviour and thereby to establish the boundaries of bird territories.
Studies of bird migration including aspects of navigation, orientation and physiology are often studied using captive birds in special cages that record their activities. The Emlen funnel for instance makes use of a cage with an inkpad at the centre and a conical floor where the ink marks can be counted to identify the direction in which the bird attempts to fly. The funnel can have a transparent top and visible cues such as the direction of sunlight may be controlled using mirrors or the positions of the stars simulated in a planetarium.
The entire genome of the domestic fowl ("Gallus gallus") was sequenced in 2004 and was followed in 2008 by the genome of the zebra finch ("Taeniopygia guttata"). Such whole genome sequencing projects allow for studies on evolutionary processes involved in speciation. Associations between the expression of genes and behaviour may be studied using candidate genes. Variations in the exploratory behaviour of great tits ("Parus major") have been found to be linked with a gene orthologous to the human gene "DRD4" (Dopamine receptor D4) which is known to be associated with novelty-seeking behaviour. The role of gene expression in developmental differences and morphological variations have been studied in Darwin's finches. The difference in the expression of "Bmp4" have been shown to be associated with changes in the growth and shape of the beak.
The chicken has long been a model organism for studying vertebrate developmental biology. As the embryo is readily accessible, its development can be easily followed (unlike mice). This also allows the use of electroporation for studying the effect of adding or silencing a gene. Other tools for perturbing their genetic makeup are chicken embryonic stem cells and viral vectors.
Collaborative studies.
With the widespread interest in birds, it has been possible to use a large number of people to work on collaborative ornithological projects that cover large geographic scales. These citizen science projects include nationwide projects such as the Christmas Bird Count, Backyard Bird Count, the North American Breeding Bird Survey, the Canadian EPOQ or regional projects such as the Asian Waterfowl Census and Spring Alive in Europe. These projects help to identify distributions of birds, their population densities and changes over time, arrival and departure dates of migration, breeding seasonality and even population genetics. The results of many of these projects are published as bird atlases. Studies of migration using bird ringing or colour marking often involve the cooperation of people and organizations in different countries.
Applications.
Wild birds impact many human activities while domesticated birds are important sources of eggs, meat, feathers and other products. Applied and economic ornithology aim to reduce the ill effects of problem birds and enhance gains from beneficial species.
The role of some species of birds as pests has been well known, particularly in agriculture. Granivorous birds such as the queleas in Africa are among the most numerous birds in the world and foraging flocks can cause devastation. Many insectivorous birds are also noted as beneficial in agriculture. Many early studies on the benefits or damages caused by birds in fields were made by analysis of stomach contents and observation of feeding behaviour. Modern studies aimed to manage birds in agriculture make use of a wide range of principles from ecology. Intensive aquaculture has brought humans in conflict with fish-eating birds such as cormorants.
Large flocks of pigeons and starlings in cities are often considered as a nuisance and techniques to reduce their populations or their impacts are constantly innovated. Birds are also of medical importance and their role as carriers of human diseases such as Japanese Encephalitis, West Nile Virus and H5N1 have been widely recognised. Bird strikes and the damage they cause in aviation are of particularly great importance, due to the fatal consequences and the level of economic losses caused. It has been estimated that the airline industry incurs worldwide damages of US$1.2 billion each year.
Many species of birds have been driven to extinction by human activities. Being conspicuous elements of the ecosystem, they have been considered as indicators of ecological health. They have also helped in gathering support for habitat conservation. Bird conservation requires specialized knowledge in aspects of biology, ecology and may require the use of very location specific approaches. Ornithologists contribute to conservation biology by studying the ecology of birds in the wild and identifying the key threats and ways of enhancing the survival of species. Critically endangered species such as the California condor have had to be captured and bred in captivity. Such ex-situ conservation measures may be followed by re-introduction of the species into the wild.

</doc>
<doc id="42969" url="https://en.wikipedia.org/wiki?curid=42969" title="Dodge">
Dodge

Dodge is an American brand of cars, minivans, and sport utility vehicles manufactured by FCA US LLC (formerly known as Chrysler Group LLC), based in Auburn Hills, Michigan. Dodge vehicles presently include the lower-priced badge variants of Chrysler-badged vehicles as well as performance cars, though for much of its existence Dodge was Chrysler's mid-priced brand above Plymouth.
Founded as the Dodge Brothers Company machine shop by brothers Horace Elgin Dodge and John Francis Dodge in late-1900. Dodge was originally a supplier of parts and assemblies for Detroit-based automakers and began building complete automobiles under the "Dodge Brothers" brand in 1914, predating the founding of Chrysler Corporation. The Dodge brothers died suddenly in 1920 and the company was sold to Dillon, Read & Co. in 1925 before being sold to Chrysler in 1928. Dodge vehicles mainly consisted of trucks and full-sized passenger cars through the 1970s, though it did make some inroads into the compact car market during this time.
Due to various market conditions, Dodge's first financial crisis, as a division of Chrysler, was averted in 1955, when Prudential gave them US$250 million; combined with the all new styling approach ushered in by Virgil Exner, Chrysler recovered and sales increased.
The 1973 oil crisis and its subsequent impact on the American automobile industry led Chrysler to develop the K platform of compact to midsize cars for the 1981 model year. The K platform and its derivatives are credited with reviving Chrysler's business in the 1980s; one such derivative became the Dodge Caravan.
The Dodge brand has withstood the multiple ownership changes at Chrysler from 1998 to 2009, including its short-lived merger with Daimler-Benz AG from 1998 to 2007, its subsequent sale to Cerberus Capital Management, its 2009 bailout by the United States government, and its subsequent Chapter 11 bankruptcy and acquisition by Fiat.
In 2011, Dodge, Ram, and Dodge's Viper were separated. Dodge said that the Dodge Viper will now be an SRT product and Ram will be a manufacturer. In 2014, SRT was merged back into Dodge. Later that year, Chrysler Group was renamed FCA US LLC, corresponding with the merger of Fiat S.p.A. and Chrysler Group into the single corporate structure of Fiat Chrysler Automobiles.
History.
Founding and early years.
After the founding of the Dodge Brothers Company by Horace and John Dodge in 1900, the Detroit-based company quickly found work producing precision engine and chassis components for the city’s growing number of automobile firms. Chief among these customers were the established Olds Motor Vehicle Company and the then-new Ford Motor Company.
By 1914, Horace had created the new four-cylinder Dodge Model 30. Marketed as a slightly more upscale competitor to the ubiquitous Ford Model T, it pioneered or made standard many features later taken for granted: all-steel body construction (the vast majority of cars worldwide still used wood-framing under steel panels, though Stoneleigh and BSA used steel bodies as early as 1911); 12-volt electrical system (6-volt systems would remain the norm until the 1950s); 35 horsepower (versus the Model T's 20), and sliding-gear transmission (the best-selling Model T would retain an antiquated planetary design until its demise in 1927). As a result of this, and the brothers' well-earned reputation for the highest quality truck, transmission and motor parts they made for other successful vehicles, Dodge Brothers cars were ranked at second place for U.S. sales as early as 1916. That same year, Henry Ford decided to stop paying stock dividends to finance the construction of his new River Rouge complex. This led the Dodges to file suit to protect their annual stock earnings of approximately one million dollars, leading Ford to buy out his shareholders; the Dodges were paid some US$25 million.
Also in 1916, the Dodge Brothers' vehicles won acclaim for durability while in service with the U.S. Army's Pancho Villa Expedition into Mexico. One notable instance was in May when the 6th Infantry received a reported sighting of Julio Cárdenas, one of Villa's most trusted subordinates. Lt. George S. Patton led ten soldiers and two civilian guides in three Dodge Model 30 touring cars to conduct a raid at a ranch house in San Miguelito, Sonora. During the ensuing firefight the party killed three men, of whom one was identified as Cárdenas. Patton's men tied the bodies to the hoods of the Dodges, returning to headquarters in Dublán and an excited reception from US newspapermen.
Death of the Dodge brothers, Sale to Chrysler.
Dodge Brothers cars continued to rank second place in American sales in 1920. However, the same year, tragedy struck as John Dodge was felled by pneumonia in January. His brother Horace then died of cirrhosis in December of the same year (reportedly out of grief at the loss of his brother, to whom he was very close). With the loss of both founders, the Dodge Brothers Company passed into the hands of the brothers' widows, who promoted long-time employee Frederick Haynes to the company presidency. During this time, the Model 30 was evolved to become the new Series 116 (though it retained the same basic construction and engineering features). However, throughout the 1920s Dodge gradually lost its ranking as the third best-selling automobile manufacturer, slipping down to seventh in the U.S. market.
Dodge Brothers emerged as a leading builder of light trucks. They also entered into an agreement whereby they marketed trucks built by Graham Brothers of Evansville, Indiana. The three Graham brothers would later produce Graham-Paige and Graham automobiles.
Stagnation in development was becoming apparent, however, and the public responded by dropping Dodge Brothers to fifth place in the industry by 1925. That year, the Dodge Brothers company was sold by the widows to the well-known investment group Dillon, Read & Co. for no less than US$146 million (at the time, the largest cash transaction in history).
Dillon, Read & Co. offered non-voting stock on the market in the new Dodge Brothers, Inc., firm, and along with the sale of bonds was able to raise $160 million, reaping a $14 million (net) profit. All voting stock was retained by Dillon, Read. Frederick Haynes remained as company head until E.G. Wilmer was named board chairman in November, 1926. Wilmer was a banker with no auto experience and Haynes remained as president. Changes to the car, save for superficial things like trim levels and colors, remained minimal until 1927, when the new Senior six-cylinder line was introduced. The former four-cylinder line was kept on, but renamed the Fast Four line until it was dropped in favor of two lighter six-cylinder models (the Standard Six and Victory Six) for 1928.
On October 1, 1925, Dodge Brothers, Inc., acquired a 51% interest in Graham Brothers, Inc., for $13 million and the remaining 49% on May 1, 1926. The three Graham brothers, Robert, Joseph and Ray, assumed management positions in Dodge Brothers before departing early in 1927.
Despite all this, Dodge Brothers’ sales had already dropped to seventh place in the industry by 1927, and Dillon, Read began looking for someone to take over the company on a more permanent basis. Eventually Dodge was sold to Chrysler Corporation in 1928.
Pre-war years.
To fit better in the Chrysler Corporation lineup, alongside low-priced Plymouth and medium-priced DeSoto, Dodge’s lineup for early 1930 was trimmed down to a core group of two lines and thirteen models (from three lines and nineteen models just over a year previous). Prices started out just above DeSoto but were somewhat less than top-of-the-line Chrysler, in a small-scale recreation of General Motors’ “step-up” marketing concept. (DeSoto and Dodge would swap places in the market for the 1933 model year, Dodge dropping down between Plymouth and DeSoto.) As Plymouth cars were sold at Chrysler dealerships, Dodge branded vehicles were sold as a lower cost alternative to DeSoto.
For 1930, Dodge took another step up by adding a new eight-cylinder line to replace the existing Senior six-cylinder. This basic format of a dual line with Six and Eight models continued through 1933, and the cars were gradually streamlined and lengthened in step with prevailing trends of the day. The Dodge Eight was replaced by a larger Dodge DeLuxe Six for 1934, which was dropped for 1935. A long-wheelbase edition of the remaining Six was added for 1936 and would remain a part of the lineup for many years.
The Dodge line, along with most of the corporation’s output, was restyled in the so-called “Wind Stream” look for 1935. This was a mild form of streamlining, which saw sales jump remarkably over the previous year (even though Dodge as a whole still dropped to fifth place for the year after two years of holding down fourth). Dodge never got the radical Airflow styling that was the cause of depressed sales of Chryslers and DeSotos from 1934 to 1937, as a passenger sedan, but it was used on commercial truck for a short time.
Another major restyle arrived for the 25th-anniversary 1939 models, which Dodge dubbed the Luxury Liner series. These were once again completely redesigned, with new bodies for 1940, again in 1941, and a refreshing for 1942. However, just after the 1942 models were introduced, Japan’s attack on Pearl Harbor forced the shutdown of Dodge’s passenger car assembly lines in favor of war production in February 1942. 1941 saw the introduction of Fluid Drive for Dodge cars, which eliminated stalling or bucking if the clutch were released too quickly. This feature put a fluid coupling in between the engine and the clutch, although the driver still had to shift gears manually.
World War II.
Chrysler was prolific in its production of war materiel from 1942 to 1945, and Dodge in particular was well known to both average citizens and thankful soldiers for their tough military-spec truck models and ambulances like the WC54. Starting with the hastily converted VC series and evolving into the celebrated WC series, Dodge built a strong reputation for itself that readily carried over into civilian models after the war.
Post-war years.
Civilian production at Dodge was restarted by late 1945, in time for the 1946 model year. The "seller's market" of the early postwar years, brought on by the lack of any new cars throughout the war, meant that every automaker found it easy to sell vehicles regardless of any drawbacks they might have. Like almost every other automaker, Dodge sold lightly facelifted revisions of its 1942 design through the 1948 season. As before, these were a single series of six-cylinder models with two trim levels (basic Deluxe or plusher Custom). From 1949 until 1954, Fluid Drive could be combined with "Gyro-Matic," a semi-automatic transmmission which reduced (but didn't eliminate) the need to shift gears.
Styling was not initially Dodge’s strong point during this period, though that began to change by 1953 under the direction of corporate design chief Virgil Exner. At the same time, Dodge also introduced its first V8 engine – the Red Ram Hemi, a smaller version of the original design of the famed Hemi. The new 1953 bodies were smaller and based on the Plymouth. For 1954, sales dropped, the stubby styling not going over well with the public. 1954 also saw the introduction of the fully automatic PowerFlite transmission.
New corporate “Forward Look” styling for 1955 began a new era for Dodge. With steadily upgraded styling and ever-stronger engines every year through 1960, Dodge found a ready market for its products as America discovered the joys of freeway travel. This situation improved when Dodge introduced a new line of Dodges called the Dart to do battle against Ford, Chevrolet and Plymouth. The result was that Dodge sales in the middle price class collapsed. Special and regional models were sold as well, including the LaFemme (a white and orchid-trimmed hardtop marketed toward women) and the Texan, a gold-accented Dodge sold in the Lone Star State.
Dodge entered the compact car field for 1961 with their new Lancer, a variation on Plymouth's Valiant. Though it was
not initially successful, the Dart range that succeeded the Lancer in 1963 would prove to be one of the division's top sellers for many years.
Chrysler did make an ill-advised move to downsize the Dodge and Plymouth full-size lines for 1962, which resulted in a loss of sales. However, they turned this around in 1965 by turning those former full-sizes into "new" mid-size models; Dodge revived the Coronet nameplate in this way and later added a sporty fastback version called the Charger that became both a sales leader and a winner on the NASCAR circuit. Not only did this style dominate the racetrack for 4 full years, its aerodynamic improvements forever changed the face of NASCAR racing.
Full-size models evolved gradually during this time. After Dodge dealers complained about not having a true full-size car in the fall of 1961, the Custom 880 was hurried into production. The Custom 880 used the 1962 Chrysler Newport body with the 1961 Dodge front end and interior. The 880 continued into 1965, the year a completely new full-size body was put into production, the Polara entered the medium price class and the Monaco was added as the top series. The Polara and Monaco were changed mostly in appearance for the next ten years or so. Unique "fuselage" styling was employed for 1969 through 1973 and then was toned down again for the 1974 to 1977 models.
Dodge is well-known today for being a player in the muscle car market of the late 1960s and early 1970s. Along with the Charger, models like the Coronet R/T and Super Bee were popular with buyers seeking performance. The pinnacle of this effort was the introduction of the Challenger sports coupe and convertible (Dodge's entry into the "pony car" class ) in 1970, which offered everything from mild economy engines up to the wild race-ready Hemi V8 in the same package.
In an effort to reach every segment of the market, Dodge even reached a hand across the Pacific to its partner, Mitsubishi Motors, and marketed their subcompact as the Colt to compete with the AMC Gremlin, Chevrolet Vega, and Ford Pinto. Chrysler would over the years come to rely heavily on their relationship with Mitsubishi. At the same time, Dodge got a version of the Plymouth Duster, marketed as the Dodge Demon. It was inexpensive, but with its slant-six engine (or V8), the Demon couldn't achieve the fuel economy of the four-cylinder Colt. The Demon sold in much fewer numbers than the Duster, so it is considered more collectible today, especially the V8 versions.
Times of crisis.
The 1973 oil crisis caused significant changes at Dodge, as well as Chrysler as a whole. Except for the Colt and Slant Six models of the Dart, Dodge's lineup was quickly seen as extremely inefficient. In fairness, this was true of most American automakers at the time, but Chrysler was also not in the best financial shape to do anything about it. Consequently, while General Motors and Ford were quick to begin downsizing their largest cars, Chrysler (and Dodge) moved more slowly out of necessity.
At the very least, Chrysler was able to use some of its other resources. Borrowing the recently introduced Chrysler Horizon from their European division, Dodge was able to get its new Omni subcompact on the market fairly quickly. At the same time, they increased the number of models imported from Japanese partner Mitsubishi starting in 1971: first came a smaller Colt (based on Mitsubishi's Galant line), then a revival of the Challenger (Dodge Challenger) in 1976 as a compact hardtop coupe with nothing more than a four-cylinder under the hood, rather than the booming V8s of yore.
Bigger Dodges, though, remained rooted in old habits. The Dart was replaced by a new Aspen for 1976, and Coronet and Charger were effectively replaced by the Diplomat for 1977, which was actually a fancier Aspen. While the Aspen got accolades for styling and handling, build quality was problematic, sullying the car's reputation at the time when sales were desperately needed. Meanwhile, the huge Monaco (Royal Monaco beginning in 1977 when the mid-sized Coronet was renamed "Monaco") models hung around through 1977, losing sales every year, until finally being replaced by the St. Regis for 1979 following a one-year absence from the big car market. In a reversal of what happened for 1965, the St. Regis was an upsized Coronet. Buyers, understandably, were confused and chose to shop the competition rather than figure out what was going on at Dodge.
Everything came to a head in 1979 when Chrysler's new chairman, Lee Iacocca, requested and received federal loan guarantees from the United States Congress in an effort to save the company from having to file bankruptcy. With a Federal Loan in hand, Chrysler quickly set to work on new models that would leave the past behind, while reorganizing to pay the government loan which stood at 29%.
K-Cars and minivans.
The first fruit of Chrysler's crash development program was the "K-Car", the Dodge version of which was the Dodge Aries. This basic and durable front-wheel drive platform spawned a whole range of new models at Dodge during the 1980s, including the groundbreaking Dodge Caravan. The Caravan not only helped save Chrysler as a serious high-volume American automaker, but also spawned an entirely new market segment that remains popular today: the minivan.
Through the late 1980s and 1990s, Dodge's designation as the sporty-car division was backed by a succession of high-performance and/or aggressively styled models including the Daytona, mid-sized 600 and several versions of the Lancer. The Dodge Spirit sedan was well received in numerous markets worldwide. The Omni remained in the line through 1990. Dodge-branded Mitsubishi vehicles were phased out by 1993 except for the Dodge Stealth running through 1996, though Mitsubishi-made engines and electrical components were still widely used in American domestic Chrysler products. In 1992, Dodge moved their performance orientation forward substantially with the Viper, which featured an aluminum V10 engine and composite sports roadster body. This was the first step in what was marketed as "The New Dodge", which was an aggressive advertising campaign with a litany of new models, with television ads narrated by Edward Herrmann that pointed out the innovations in the vehicles and challenged their competitors. Later that year, was the introduction of new Intrepid sedan, totally different from its boxy Dynasty predecessor and, in 1994, the new second generation Dodge Ram pickup was introduced with bold styling that departed radically from the boxy designs of trucks made by the big 3 for two decades prior. The Intrepid used what Chrysler called "cab forward" styling, with the wheels pushed out to the corners of the chassis for maximum passenger space. They followed up on this idea in a smaller scale with the Neon and Stratus. The Neon in particular was a hit, buoyed by a clever marketing campaign and good performance.
The modern era.
DaimlerChrysler & private ownership.
In a move that never lived up to the expectations of its driving forces, Chrysler Corporation merged with Daimler-Benz AG in 1998 to form DaimlerChrysler. Rationalizing Chrysler's broad lineup was a priority, and Dodge's sister brand Plymouth was withdrawn from the market. With this move, Dodge became
DaimlerChrysler's low-price division as well as its performance division.
The Intrepid, Stratus, and Neon updates of the 1998 to 2000 timeframe were largely complete before Daimler's presence, and Dodge's first experience of any platform sharing with the German side of the company was the 2005 Magnum station wagon, introduced as a replacement for the Intrepid. Featuring Chrysler's first mainstream rear-wheel drive platform since the 1980s and a revival of the Hemi V8 engine. The Charger was launched in 2006 on the same platform.
Further cost savings were explored in the form of an extensive platform-sharing arrangement with Mitsubishi, which spawned the Caliber subcompact as a replacement for the Neon and the Avenger sedan. The rear-drive chassis was then used in early 2008 to build a new Challenger, with styling reminiscent of the original 1970 Challenger. Like its predecessor, the new Challenger coupe was available with a powerful V8 engine (base models featured a V6). In Spring 2007, DaimlerChrysler reached an agreement with Cerberus Capital Management to dump its Chrysler Group subsidiary, of which the Dodge division was a part. Soon after, the housing bubble began to collapse the American market, and on May 1, 2009, Chrysler and GM filed for bankruptcy on the same day.
Fiat ownership.
On June 10, 2009, Italian automaker Fiat formed a partnership with Chrysler under Sergio Marchionne, with the UAW, and the US Government to form Chrysler Group LLC, of which Dodge remained fully integrated. For its part, the US Government provided more than $6 billion in loans at 21%, called a "bridge loan" or "bailout". The newly formed company went on to fully repay that loan, remortgaging to reduce the interest rate several times down to 6%. They fully paid back the loan with interest to the U.S. Government on May 24, 2011, a full five years early. The UAW, being partners throughout the process, were paid well and above $3.9 billion in 2013 as Sergio's plan for full consolidation has continued on schedule. This has allowed Chrysler LLC to fully merge with Fiat to form FCA, Fiat Chrysler Automobiles, in 2014. The combined company will be based in London.
In 2013, Dodge re-introduced a compact car based on an Alfa-Romeo design called the Dart. It was the first new Dodge model produced under FCA.
On May 6, 2014, FCA announced a major restructuring, in which Dodge would focus solely on performance vehicles and will be positioned between Chrysler (which is moving downmarket into mainstream vehicles) and a relaunched Alfa Romeo (making its return to North America after a 20-year absence) in the FCA lineup. This is a set up similar to PSA Peugeot Citroën, which positions Peugeot as its conservative mainstream brand while Citroën is more performance-based, as well as Hyundai Motor Group having its two mainstream brands, Kia Motors and Hyundai Motor Company focusing on performance and mid-luxury, respectively. (Among the American press, it has drawn comparisons to the decades-long set up of Chevrolet and Pontiac at General Motors before the phase-out of Pontiac in 2010.) As part of the restructuring, Dodge will discontinue the Dodge Grand Caravan (after 32 years) and Dodge Avenger without replacements, while launching a sporty subcompact below the Dart in 2018. Additionally, while the Ram Trucks division will remain separate (although the Dodge Durango will remain in production as a Dodge), the SRT division was merged back into Dodge.
Dodge trucks.
Over the years, Dodge has become at least as well known for its many truck models as for its prodigious passenger car output. In 2009, trucks were spun off into the separate Ram brand, named after the brand's most popular truck, the Dodge Ram. However, it should be noted that even though the Ram trucks are marketed separately from Dodge cars, Ram President Fred Diaz has stated that "Ram trucks will always and forever be Dodges. Ram will always have the Dodge emblem inside and outside and they will be 'vinned' (from the acronym VIN, or Vehicle Identification Number) as a Dodge. We need to continue to market as Ram so Dodge can have a different brand identity: hip, cool, young, energetic. That will not fit the campaign for truck buyers. The two should have distinct themes."
Pickups and medium to heavy trucks.
Ever since the beginning of its history in 1914, Dodge has offered light truck models. For the first few years, these were based largely on the existing
passenger cars, but eventually gained their own chassis and body designs as the market matured. Light- and medium-duty models were offered first, then a heavy-duty range was added during the 1930s and 1940s.
Following World War II and the successful application of four-wheel drive to the truck line, Dodge introduced a civilian version that it called the Power Wagon. At first based almost exactly on the military-type design, variants of the standard truck line were eventually given 4WD and the same “Power Wagon” name.
Dodge was among the first to introduce car-like features to its trucks, adding the plush Adventurer package during the 1960s and offering sedan-like space in its Club Cab bodies of the 1970s. Declining sales and increased competition during the 1970s eventually forced the company to drop its medium- and heavy-duty models, an arena the company has only recently begun to reenter.
Dodge introduced what they called the "Adult Toys" line to boost its truck sales in the late 1970s, starting off with the limited edition Lil' Red Express pickup (featuring, a 360 c.i. police interceptor engine and visible big rig-style exhaust stacks). Later came the more widely available Warlock. Other "Adult Toys" from Dodge included the "Macho Power Wagon" and "Street Van".
As part of a general decline in the commercial vehicle field during the 1970s, Dodge eliminated their LCF Series heavy-duty trucks in 1975, along with the Bighorn and medium-duty D-Series trucks, and affiliated S Series school buses were dropped in 1978. On the other hand, Dodge produced several thousand pickups for the United States Military under the CUCV program from the late 1970s into the early 1980s.
Continuing financial problems meant that even Dodge’s light-duty models – renamed as the Ram Pickup line for 1981 – were carried over with the most minimal of updates until 1993. Two things helped to revitalize Dodge’s fortunes during this time. First was their introduction of Cummins’ powerful and reliable B Series turbo-diesel engine as an option for 1989. This innovation raised Dodge’s profile among serious truck buyers who needed power for towing or large loads. A mid-size Dakota pickup, which later offered a class-exclusive V8 engine, was also an attractive draw.
Dodge introduced the Ram's all-new “big-rig” styling treatment for 1994. Besides its instantly polarizing looks, exposure was also gained by usage of the new truck on the hit TV show "Walker, Texas Ranger" starring Chuck Norris. The new Ram also featured a totally new interior with a console box big enough to hold a laptop computer, or ventilation and radio controls that were designed to be easily used even with gloves on. A V10 engine derived from that used in the Viper sports car was also new, and the previously offered Cummins turbo-diesel remained available. The smaller Dakota was redesigned in the same vein for 1997, thus giving Dodge trucks a definitive “face” that set them apart from the competition.
The Ram was redesigned again for 2002 (the Dakota in 2005), basically as an evolution of the original but now featuring the revival of Chrysler’s legendary Hemi V8 engine. New medium-duty chassis-cab models were introduced for 2007 (with standard Cummins turbo-diesel power), as a way of gradually getting Dodge back in the business truck market again.
For a time during the 1980s, Dodge also imported a line of small pickups from Mitsubishi. Known as the D50 or (later) the Ram 50, they were carried on as a stopgap until the Dakota’s sales eventually made the imported trucks irrelevant. (Mitsubishi has more recently purchased Dakota pickups from Dodge and restyled them into their own Raider line for sale in North America.)
Vans.
Dodge had offered panel delivery models for many years since its founding, but their first purpose-built van model arrived for 1964 with the compact A Series. Based on the Dodge Dart platform and using its proven six-cylinder or V8 engines, the A-series was a strong competitor for both its domestic rivals (from Ford and Chevrolet/GMC) and the diminutive Volkswagen Transporter line.
As the market evolved, however, Dodge realized that a bigger and stronger van line would be needed in the future. Thus the B Series, introduced for 1971, offered both car-like comfort in its Sportsman passenger line or expansive room for gear and materials in its Tradesman cargo line. A chassis-cab version was also offered, for use with bigger cargo boxes or flatbeds.
Like the trucks, though, Chrysler’s dire financial straits of the late 1970s precluded any major updates for the vans for many years. Rebadged as the Ram Van and Ram Wagon for 1981, this venerable design carried on for 33 years with little more than cosmetic and safety updates all the way to 2003.
The DaimlerChrysler merger of 1999 made it possible for Dodge to explore new ideas; hence the European-styled Mercedes-Benz Sprinter line of vans was brought over and given a Dodge styling treatment. Redesigned for 2006 as a 2007 model, the economical diesel-powered Sprinters have become very popular for city usage among delivery companies like FedEx and UPS in recent years. Because of their fuel efficiency major motorhome manufacturer Thor Motor Coach made several Class C and Class A Motorhomes available on the Dodge Sprinter Chassis including their popular Four Winds Siesta & Chateau Citation product lines.
Dodge also offered a cargo version of its best-selling Caravan for many years, at first calling it the Mini Ram Van (a name originally applied to short-wheelbase B-Series Ram Vans) and later dubbing it the Caravan C/V (for "Cargo Van"). However, for model year 2011, the Caravan C/V was rebranded as a Ram, called the Ram C/V.
Sport utility vehicles.
Dodge’s first experiments with anything like a sport utility vehicle appeared in the late 1950s with a windowed version of their standard panel-truck - known as the Town Wagon. These were built in the same style through the mid-1960s.
But the division didn't enter the SUV arena in earnest until 1974, with the purpose-built Ramcharger. Offering the then-popular open body style and Dodge's powerful V8 engines, the Ramcharger was a strong competitor for trucks like the Ford Bronco, Chevrolet Blazer and International Harvester Scout II.
Once again, though, Dodge was left with outdated products during the 1980s as the market evolved. The Ramcharger hung on through 1993 with only minor updates. When the Ram truck was redesigned for the 1994 model year, the Ramcharger was discontinued in the American and Canadian markets. A version using the updated styling was made for the Mexican Market but was never imported to the U.S. or Canada.
Instead, Dodge tried something new in 1998. Using the mid-sized Dakota pickup's chassis as a base, they built the four-door Durango SUV with seating for eight people and created a new niche. Sized between smaller SUVs (like the Chevrolet Blazer and Ford Explorer) and larger models (like the Chevrolet Tahoe and Ford Expedition), Durango was both a bit more and bit less of everything. The redesigned version for 2004 grew a little bit in every dimension, becoming a full-size SUV (and thus somewhat less efficient), but was still sized between most of its competitors on either side of the aisle. For 2011 a new unibody Durango based on the Jeep Grand Cherokee was released. The 2011 Durango shrank slightly to size comparable to the original model.
Dodge also imported a version of Mitsubishi’s popular Montero (Pajero in Japan) as the Raider from 1987 to 1989.
International markets.
Dodge vehicles are now available in many countries throughout the world.
Argentina.
Dodge came to Argentina in the early 20th century with imported cars and trucks. But, since 1960, has partnered with a local representative: Fevre-Basset. The first vehicle made in Argentina was the pick up D-100 "Sweptilte". For 1961 to 1980 arrives the trucks, like: D-400/DP-400 D-500/DP-500 DP600, DD900 & DD1000 (the last two with one curiosity: the air-cooled Deutz engine rather Perkins or Chrysler). Respecting the passenger cars, made the Valiant I and II, and the local versions of the 1966 Dodge Dart (called Valiant III and IV). For 1971, arrives the Dodge 1500, a rebadged Hillman Avenger from UK. In 1982, ceased the Dodge brand, because Volkswagen bought the Fevre plant and the shares.
In 1993, Dodge cars and pick-ups began to be marketed in the country. Currently, the Journey and the Ram sold in Argentina by Dodge.
Asia.
Dodge entered the Japanese market in mid-2007, and re-entered the Chinese market in late 2007. Soueast Motors of China assembles the Caravan for the Chinese market. Dodge had already been marketing its vehicles in South Korea since 2004, starting with the Dakota.
Dodge vehicles have been sold in the Middle East for a considerably longer period.
Australia.
Dodge re-entered the Australian market in 2006 with the Caliber, their first offering since the AT4/D5N trucks in 1979 and the first Dodge passenger car to be marketed in Australia since the Phoenix sedan was discontinued in 1973. The second model to be introduced was the Nitro, with the Avenger and Journey followed. Dodge chose not use the full model lines and engines available to them, the 2.7L V6 being available in the Journey and Avenger instead of the 3.2 in the North American versions. However they did introduce diesel engines in all their cars.
Following the Global Financial Crisis, Chrysler introduced the facelifted model of the Caliber and discontinued the Avenger imports. From early 2012 on, model year 2010 cars were available. By early 2012 no new cars were being brought into Australia aside from the new facelifted 2012 Journey.
There are now rumours that Dodge cars will be re-badged as Fiats in the Australian market as has happened in Europe. In contrast, recent speculation has suggested that the Dodge nameplate would continue on until at least 2015, due to consistent sales of the Journey.
Brazil.
In Brazil, Dodge cars were produced between 1969 and 1981 with the models Dart, Charger, Magnum, LeBaron (all powered by the same 318 cid V8 engine), and the compact 1800/Polara, based on the British Hillman Avenger. The manufacturer was acquired by Volkswagen in 1981. In 1998, the Dakota pickup started production in a new plant in Campo Largo, Paraná by Mercedes-Benz, which belongs to its former partner Daimler AG. It was built there until 2001 with petrol and diesel engines and regular, extended and crew cabs. In 2010, Dodge started sales of the imported pickup Ram 2500. The model portfolio is being expanded, starting with the Journey crossover for the 2009 model year.
Canada.
In Canada, the Dodge lineup of cars started down the road to elimination along with the Plymouth line when in 1988 the Dodge Dynasty was sold in Canada as the Chrysler Dynasty and sold at both Plymouth and Dodge dealers. Similarly, the new Dodge Intrepid, the Dynasty's replacement, was sold as the Chrysler Intrepid.
For 2000, the new Neon became the Chrysler Neon. The Chrysler Cirrus and Mitsubishi-built Dodge Avenger were dropped. Dodge trucks, which have been sold at Canadian Plymouth dealers since 1973, continued without change. All Plymouth-Chrysler and Dodge-Chrysler dealers became Chrysler-Dodge-Jeep dealers.
The diluting of the Chrysler name did not go well in Canada, especially as the nameplate had been pushed as a luxury line since the 1930s. For 2003, the revamped Neon appeared in Canada as the Dodge SX 2.0. Since then all new Dodge models have been sold in Canada under the Dodge name.
Europe.
Dodge started assembling lorries (trucks) in the United Kingdom, from imported parts, in 1922. In 1933 it began to manufacture a British chassis, at its works in Kew, using American engines and gearboxes.
Following Chrysler's takeover of the British Rootes Group, Simca of France, and Barreiros of Spain, and the resultant establishment of Chrysler Europe in the late 1960s, the Dodge brand was used on light commercial vehicles, most of which were previously branded Commer or Karrier, on pickup and van versions of the Simca 1100, on the Spanish Dodge Dart, and on heavy trucks built in Spain. The most common of these was the Dodge 50 series, widely used by utility companies and the military, but rarely seen outside the UK, and the Spanish-built heavy-duty 300 series available as 4x2, 6x4, 8x2, and 8x4 rigids, as well as 4x2 semi-trailer tractors. All of these were also sold in selected export markets badged either as Fargo or De Soto.
Following Chrysler Europe's collapse in 1977, and the sale of their assets to Peugeot, the Chrysler/Dodge British and Spanish factories were quickly passed on to Renault Véhicules Industriels. Chrysler licensed the Dodge name to be used on Renault trucks sold in certain European markets - most notably the United Kingdom, although it eventually reverted to Renault when the associated models were discontinued. They would eventually drop these products altogether and used the plants to produce engines (in the UK) and "real" Renault truck models in Spain. Dodge vehicles would not return to the UK until the introduction of the Neon, badged as a Chrysler, in the mid-1990s.
The Dodge marque was reintroduced to Europe on a broad scale in 2006. Currently, the Dodge lineup in Europe consists of the Caliber, Avenger, Viper SRT-10, Nitro and Dodge Journey. However, in 2010 Chrysler pulled the Dodge marque from the UK lineup due to poor sales.
On June 1, 2011 the Dodge name was dropped from the rest of Europe when it was replaced by the Fiat brand, where Fiat rebadged the Dodge Journey as the Fiat Freemont. However, the Freemont is not available in the Ireland or UK Fiat lineup.
Mexico.
In Mexico, the Hyundai Accent, Hyundai Atos, and Hyundai H100 are branded as "Dodge" or "Verna by Dodge", "Atos by Dodge" and "Dodge H100" respectively, and sold at Chrysler/Dodge dealers. Current models are marketed with Hyundai logos instead of the "Ram" logo on previous model years. Dodge and Hyundai will end the venture and Dodge will use rebadged and reworked Fiats.
Logos.
A second emblem was revealed during the unveiling of the 2011 Durango, which used the same five-point shield-shaped outline of the old emblem, but with the ram's head replaced with a chrome cross reminiscent of the brand's signature cross-haired grille. This was only used on the steering wheel. In 2014, the cross logo was replaced by the word "DODGE" on the Durango steering wheel. A modified version of the Ram's head logo is still used for the Ram brand, with "RAM" written across the bottom in bold white or black lettering.

</doc>
<doc id="42970" url="https://en.wikipedia.org/wiki?curid=42970" title="Future history">
Future history

A future history is a postulated history of the future and is used by authors in the subgenre of speculative fiction (or science fiction) to construct a common background for fiction. Sometimes the author publishes a timeline of events in the history, while other times the reader can reconstruct the order of the stories from information provided therein.
Background.
The term appears to have been coined by John W. Campbell, Jr., the editor of "Astounding Science Fiction", in the February 1941 issue of that magazine, in reference to Robert A. Heinlein's "Future History". Neil R. Jones is generally credited as the first author to create a future history.
A set of stories which share a backdrop but are not really concerned with the sequence of history in their universe are rarely considered future histories. For example, neither Lois McMaster Bujold's "Vorkosigan Saga" nor George R. R. Martin's 1970s short stories which share a backdrop are generally considered future histories. Standalone stories which trace an arc of history are rarely considered future histories. For example, Walter M. Miller Jr.'s "A Canticle for Leibowitz" is not generally considered a future history.
Earlier, some works were published which constituted "future history" in a more literal sense—i.e., stories or whole books purporting to be excerpts of a history book from the future and which are written in the form of a history book—i.e., having no personal protagonists but rather describing the development of nations and societies over decades and centuries.
Such works include:
Future history and alternate history.
Unlike alternate history, where alternative outcomes are ascribed to past events, future history postulates certain outcomes to events in the writer's present and future.
The essential difference is that the writer of alternate history is in possession of knowledge of the actual outcome of a certain event, and that knowledge influences also the description of the event's alternate outcome. The writer of future history does not have such knowledge, such works being based on speculations and predictions current at the time of writing—which often turn out to be wildly inaccurate.
For example, in 1933 H. G. Wells postulated in "The Shape of Things to Come" a Second World War in which Nazi Germany and Poland are evenly matched militarily, fighting an indecisive war over ten years; and Poul Anderson's early 1950s Psychotechnic League depicted a world undergoing a devastating nuclear war in 1958, yet by the early 21st century managing not only to rebuild the ruins on Earth but also engage in extensive space colonization of the Moon and several planets. A writer possessing knowledge of the actual swift collapse of Poland in World War II and the enormous actual costs of far less ambitious space programs in a far less devastated world would have been unlikely to postulate such outcomes. "" was set in the future and featured developments in space travel and habitation which have not occurred on the timescale postulated.
A problem with future history science fiction is that it will date and be overtaken by real historical events, for instance H. Beam Piper's future history, which included a nuclear war in 1973, and much of the future history of "Star Trek". Jerry Pournelle's "CoDominium" future history assumed that the Cold War would end with the USA and Soviet Union establishing a co-rule of the world, the CoDominium of the title, which would last into the 22nd Century—rather than the Soviet Union collapsing in 1991. 
There are several ways this is dealt with. One solution to the problem is when some authors set their stories in an indefinite future, often in a society where the current calendar has been disrupted due to a societal collapse or undergone some form of distortion due to the impact of technology. Related to the first, some stories are set in the very remote future and only deal with the author's contemporary history in a sketchy fashion, if at all (e.g. the original "Foundation" Trilogy by Asimov). Another related case is where stories are set in the near future, but with an explicitly allohistorical past, as in Ken MacLeod's "Engines of Light" series.
In other cases, such as the "Star Trek" universe, the merging of the fictional history and the known history is done through extensive use of retroactive continuity. In yet other cases, such as the "Doctor Who" television series and the fiction based on it, much use is made of secret history, in which the events that take place are largely secret and not known to the general public.
As with Heinlein, some authors simply write a detailed future history and accept the fact that events will overtake it, making the sequence into a "de facto" alternate history.
Lastly, some writers formally transform their future histories into alternate history, once they had been overtaken by events. For example, Poul Anderson started The Psychotechnic League history in the early 1950s, assuming a nuclear war in 1958—then a future date. When it was republished in the 1980s, a new foreword was added explaining how that history's timeline diverged from ours and led to war.

</doc>
<doc id="42971" url="https://en.wikipedia.org/wiki?curid=42971" title="The Dukes of Hazzard">
The Dukes of Hazzard

The Dukes of Hazzard is an American television series that aired on the CBS television network from January 26, 1979 to February 8, 1985. The series was inspired by the 1975 film "Moonrunners", which was also created by Gy Waldron and had many identical or similar character names and concepts.
Overview.
"The Dukes of Hazzard" follows the adventures of "The Duke Boys," cousins Bo Duke (John Schneider) and Luke Duke (including Coy and Vance Duke for most of season 5) (Tom Wopat), who live on a family farm in fictional Hazzard County, Georgia, with their attractive female cousin Daisy (Catherine Bach) and their wise old Uncle Jesse (Denver Pyle). The Duke boys race around in their customized 1969 Dodge Charger stock car, dubbed "(The) General Lee", evading crooked and corrupt county commissioner Boss Hogg (Sorrell Booke) and his bumbling and corrupt Sheriff Rosco P. Coltrane (James Best) along with his deputy(s), and always managing to get caught in the middle of the various escapades and incidents that often occur in the area. Bo and Luke had previously been sentenced to probation for illegal transportation of moonshine; their Uncle Jesse made a plea bargain with the U.S. Government to refrain from distilling moonshine in exchange. As a result, Bo and Luke are on probation and not allowed to carry firearms — instead, they often use compound bows, sometimes with arrows tipped with dynamite — or to leave Hazzard County unless they get probation permission from their probation officer which is Boss Hogg, although the exact details of their probation terms vary from episode to episode. Sometimes it is implied that they would be jailed for merely crossing the county line; on other occasions, it is shown that they may leave Hazzard, as long as they are back within a certain time limit. Several other technicalities of their probation also came into play at various times.
Corrupt county commissioner Jefferson Davis "Boss" Hogg, who either runs or has fingers in virtually everything in Hazzard County, is forever angry with the Dukes, especially Bo and Luke for always foiling his crooked schemes. He is always looking for ways to get them out of the picture so that his plots have a chance of succeeding. Many episodes revolve around Hogg trying to engage in an illegal scheme, sometimes with aid of hired criminal help. Some of these are get-rich-quick schemes, though many others affect the financial security of the Duke farm, which Hogg has long wanted to acquire for various reasons. Other times, Hogg hires criminals from out of town to do his dirty work for him, and often tries to frame Bo and Luke for various crimes as part of these plots. Bo and Luke always seem to stumble over Hogg's latest scheme, sometimes by curiosity, and often by sheer luck, and put it out of business. Despite the Dukes often coming to his rescue (see below), Hogg forever seems to have an irrational dislike of the clan, particularly Bo and Luke, often accusing them of spying on him, robbing or planning to rob him, and other supposedly nefarious actions, as he believes they are generally out to get him.
The other main characters of the show include local mechanic Cooter Davenport (Ben Jones), who in early episodes was portrayed as a wild, unshaven rebel, often breaking or treading on the edge of the law, before setting down to become the Duke family's best friend (he is often referred to as an "honorary Duke") and owns the local garage; and Enos Strate (Sonny Shroyer), an honest but naive young deputy who, despite his friendship with the Dukes (and his crush on Daisy), is reluctantly forced to take part in Hogg and Rosco's crooked schemes. In the third and fourth seasons, when Enos leaves for his own show, he is replaced by Boss' cousin Deputy Cletus Hogg (Rick Hurst), Boss's cousin, who is slightly more wily than Enos but still a somewhat reluctant player in Hogg's plots.
Owing to their fundamentally good natures, the Dukes often wind up helping Boss Hogg out of trouble, albeit grudgingly. More than once Hogg is targeted by former associates who are either seeking revenge or have double crossed him after a scheme has unraveled in one way or another. Sheriff Coltrane also finds himself in some instances. On such occasions, Bo and Luke usually have to rescue their adversaries as an inevitable precursor to defeating the bad guys; in other instances, the Dukes join forces with Hogg and Coltrane to tackle bigger threats to Hazzard or one of their respective parties. These instances became more frequent as the show progressed, and later seasons saw a number of stories where the Dukes and Hogg (and Coltrane) temporarily work together.
Production.
The series was developed from the 1975 movie "Moonrunners". Created by Gy Waldron in collaboration with ex-moonshiner Jerry Rushing, this movie shares many identical and very similar names and concepts with the subsequent TV series. Although itself essentially a comedy, this original movie was much cruder and edgier than the family-friendly TV series that would evolve from it.
In 1977, Waldron was approached by Warner Bros. with the idea of developing "Moonrunners" into a television series. Waldron reworked various elements from "Moonrunners", and from it was devised what would become "The Dukes of Hazzard". Production began in October 1978 with the original intention of only nine episodes being produced as mid-season filler. The first five episodes were filmed in Covington and Conyers, Georgia and surrounding areas, including some location work in nearby Atlanta. Although most of the familiar "Dukes" elements are present in these initial early episodes, the first season especially first five stories feature a noticeably different tone from the rest of the series, including some more adult-oriented humor, with some raunchier elements and coarser language; several of the characters, noticeably those of Rosco (who shot a criminal in an early episode) and Cooter, are also given different interpretation to their more recognized roles. After completing production on the fifth episode, "High Octane", the cast and crew broke for Christmas break, expecting to return in several weeks' time to complete the ordered run of episodes. In the meantime, executives at Warner Bros. were impressed by the rough preview cuts of the completed episodes and saw potential in developing the show into a full-running series; part of this plan was to move production from Georgia to the Warner Bros. lot in Burbank, California, primarily to simplify production as well as develop a larger workshop to service the large number of automobiles needed for the series.
Rushing appeared as shady used car dealer Ace Parker in the third episode produced, "Repo Men" (the fourth to be broadcast). Rushing believed this to be the start of a recurring role, in return for which he would supply creative ideas from his experiences: many of the "Dukes" (and thus "Moonrunners") characters and situations were derived from Rushing's experiences as a youth, and much of the character of Bo Duke he states to be based on him. However, "Repo Men" would turn out to be the character's only appearance in the entire show's run, leading to a legal dispute in the following years over the rights to characters and concepts between Rushing and Warner Bros., although he remained on good terms with cast and crew and in recent years has made appearances at several fan conventions.
By the end of the first (half) season, the family-friendly tone of "The Dukes of Hazzard" was mostly in place. When the show returned for a second season in Fall 1979 (its first full season), with a few further minor tweaks, the show quickly found its footing as a family-friendly comedy-adventure series. By the third season, starting in Fall 1980, the template was well set in place for that which would be widely associated with the show.
As well as its regular car chases, jumps and stunts, "The Dukes of Hazzard" relied on character familiarity, with each character effectively serving the same role within a typical episode, and with Deputy Cletus replacing Deputy Enos in Seasons 3 and 4, and Coy and Vance Duke temporarily replacing Bo and Luke (due to a salary dispute) for most of Season 5, being the only major cast changes through the show's run (Ben Jones and James Best both left temporarily during the second season due to different disputes with producers, but both returned within a few episodes). Of the characters, only Uncle Jesse and Boss Hogg appeared in all 145 episodes; Daisy appears in all but one, the third season's "To Catch a Duke". The General Lee also appears in all but one (the early first season episode "Mary Kaye's Baby", the fourth to be produced and the third broadcast).
Cast and characters.
Main characters.
The pilot episode was to include a barber modeled after Floyd Lawson on "The Andy Griffith Show" as a regular character, but was eliminated when the final draft of the pilot's script was written and before the show was cast.
When John Schneider auditioned for the role of Bo Duke, he came to the audition in a dilapidated pickup truck, sporting a week-long beard growth, wearing overalls and a white T-shirt with a pack of cigarettes rolled up in a sleeve collar, and carrying a can of beer, trying to look the part. At the audition, Schneider drank the beer and said he was from Snellville. The producers bought his "Good Ol' Boy" act and Schneider was hired on the spot.
Notable guest appearances.
Throughout its network television run, "The Dukes of Hazzard" had a consistent mix of up-and-comers and established stars make guest appearances.
Others.
NASCAR driver Terry Labonte makes a brief, uncredited appearance as a crewman in the episode Undercover Dukes Part 1. The race cars supplied for both part 1 and part 2 of Undercover Dukes were supplied by Labonte's race owner, Billy Hagan. However, the emblems of the sponsors of the cars (at that time Labonte was sponsored by Budweiser) were covered to avoid paying royalties.
The celebrity speed trap.
During the show's second season, the show's writers began flirting with the idea of incorporating a "celebrity speed trap" into some of the episodes, as a means to feature top country stars of the day performing their hits. On its first couple of instances, the "Speed Trap" was featured early in the story, but for most of the cases, it was featured in the last few minutes of an episode, often used when the main story was running too short to fill episode time.
The "celebrity speed trap" feature was essentially similar: Aware that a big-name country star was passing through the area, Boss Hogg would order Rosco to lower the speed limit on a particular road to an unreasonable level (using a reversible sign, with one speed limit on one side and another, far lower, on the back), so that the targeted singer would be in violation of the posted limit. The singer would be required to give a free performance at the Boar's Nest in exchange for having their citations forgiven; the performer would then perform one of their best-known hits or other popular country music standard, while the Dukes, Boss, Rosco, Enos, Cletus, Cooter, and other patrons whooped and hollered in enjoyment of the performance. More often than not, the performer would give a sarcastic parting shot to Boss and Rosco.
Singers who were featured in the "speed trap" segments were:
Honorable Mentions: Mickey Gilley, Loretta Lynn
Gilley's and Lynn's appearances were not solely for the celebrity speed trap. After performing a concert in Hazzard, Gilley was nabbed while leaving and forced to do a second show to nullify his citation. Lynn was kidnapped by criminals wanting to break into the music business. Loretta Lynn was the very first country music guest star on the show in 1979 and had an entire show titled "Find Loretta Lynn."
Note: Janie Fricke was the only guest country star who did not perform a song, celebrity speed trap or otherwise. She played an accomplice to a robber in an episode who hid money in the dashboard of the car that was to become the General Lee.
Coy & Vance.
"The Dukes of Hazzard" was consistently among the top-rated television series (at one point, ranking second only to "Dallas", which immediately followed the show on CBS' Friday night schedule). With that success came huge profits in merchandising, with a wide array of "Dukes of Hazzard" toys and products being licensed and becoming big sellers. However, over the course of the show's fourth season, series stars Tom Wopat and John Schneider became increasingly concerned about a contract dispute over their salaries and merchandising royalties owed to them over the high sales of "Dukes" products. Neither were being paid what was owed to them and this became very frustrating to the duo. As a result, in the spring of 1982, as filming was due to begin on the fifth season, Wopat and Schneider did not report to the set in protest over the matter. Catherine Bach also considered walking out due to similar concerns, but Wopat and Schneider convinced her to stay, insisting that if she left then there may not be a show to come back to, and that settling the issue was up to them.
Production was pushed back by a few weeks as fairly similar looking replacements were subsequently, hastily hired: Byron Cherry as Coy Duke and Christopher Mayer as Vance Duke. Bo and Luke were said to have gone to race on the NASCAR circuit; how they managed to do this, bearing in mind the terms of their probation, was never mentioned. Cherry and Mayer were originally contracted at just ten episodes as stand-ins, still with hope that a settlement might be reached with Wopat and Schneider (in total, they made 19 episodes including 1 with Bo and Luke). Some scripts for Coy and Vance were originally written for Bo and Luke but with their names quite literally crossed out and Coy and Vance penned in. The new Dukes — previously-unmentioned nephews of Uncle Jesse, who were said to have left the farm in 1976, before the show had started — were unpopular with the great majority of viewers, and the ratings immediately sank. Much of the criticism was that Coy and Vance were nothing but direct clones of Bo and Luke, with Coy a direct "carbon copy" replacement for Bo and Vance for Luke, with little variation in character. This was something that even show creator Gy Waldron has said was wrong, and that he insisted, unsuccessfully, that audiences would not accept direct character clones and the two replacements should be taken in a different direction characterwise, but was overridden by producers. Waldron also commented that if Bach too had walked, the show would have most probably been cancelled. It was reported that prior to filming, Cherry and Mayer were given Bo and Luke episodes to watch, to study and learn to emulate them, although Cherry has said in interviews that he doesn't recall this ever happening.
Hit hard by the significant drop in ratings, Warner Bros. renegotiated with Wopat and Schneider, and eventually a settlement was reached, and the original Duke boys returned to the series in early 1983, four episodes from the conclusion of the fifth season. Initially, part of the press release announcing Wopat and Schneider's return suggested that Cherry and Mayer would remain as part of the cast (though presumably in a reduced role), but it was quickly realized that "four Duke boys" would not work within the context of the series, and due to the huge unpopularity associated with their time on the show, they were quickly written out of the same episode in which Bo and Luke returned.
Return of Bo and Luke.
Although Coy and Vance were never popular with the majority, a few viewers were disappointed by their departure episode, "Welcome Back, Bo 'N' Luke", which was for the most part a standard episode, with the return of Bo and Luke and the departure of Coy and Vance tacked onto the beginning (Bo and Luke return from their NASCAR tour just as Coy and Vance leave Hazzard to tend to a sick relative). Even a few viewers commented that they were disappointed by this, and that they would have liked to have seen both pairs of Duke boys team up to tackle a particularly dastardly plot by Boss Hogg before Coy and Vance's departure, but as it turned out, Coy and Vance had little dialogue and were gone by the first commercial break, never to be seen again.
While the return of Bo and Luke was welcomed by ardent and casual viewers alike, and as a result ratings recovered slightly, the show never completely regained its former popularity. One of Wopat and Schneider's disputes even before they left was what they considered to be increasingly weak and formulaic scripts and episode plots. With Wopat and Schneider's return, the producers agreed to try a wider scope of storylines. However, although it continued for two more seasons, the show never fully returned to its former glory. As well as what was widely recognized to be increasingly inferior scripts (including one involving an alien landing in Hazzard County and being helped by the Dukes, an obvious attempt to capitalize on the popularity of E.T.), many fans and cast members decried the miniature car effects newly incorporated to depict increasingly absurd General Lee and patrol car stunts (which had previously been performed with real cars by stunt drivers). The miniature car effects were intended as a budget saving measure (to save the cost of repairing or replacing damaged vehicles) and to help compete visually with KITT from the NBC series "Knight Rider". Finally, at the end of its seventh season, in early February 1985, "The Dukes of Hazzard" quietly ended its run.
Vehicles.
The General Lee (Dodge Charger).
The General Lee was based on a 1969 Dodge Charger owned by Bo and Luke (the series had 1968-1970 Chargers to look like a 1969). It was orange with a Confederate battle flag painted on the roof, the words "GENERAL LEE" over each door, and the number "01" on each door. In the original five Georgia-filmed episodes, a Confederate flag along with a checkered racing flag in a criss-cross pattern could be seen behind the rear window; this was removed when it was felt that this extra detail did not show up enough on-screen enough to warrant the already very tight time constraints of preparing and repairing each example of the car. The name refers to the American Civil War Confederate General Robert E. Lee. The television show was based on the movie "Moonrunners", in turn based on actual moonshine runners who used a 1958 Chrysler named Traveler, after General Lee's horse (with a slight spelling change). Traveler was originally intended to be the name of the Duke boys' stock car too, until producers agreed that General Lee had more punch to it.
Since it was built as a race car, the doors were welded shut. Through the history of the show, an estimated 309 Chargers were used; 17 are still known to exist in various states of repair. A replica was owned by John Schneider, known as "Bo's General Lee". In 2008, Schneider sold "Bo's General Lee" at the Barrett-Jackson automobile auction for $230,000. An eBay auction which garnered a bid of $9,900,500 for the car was never finalized, with the purported bidder claiming his account had been hacked. The underside of the hood has the signatures of the cast from the 1997 TV movie. Schneider has also restored over 20 other "General Lee"s to date. In 2008, a replica of the General Lee fetched a high bid of $450,000 at the Barrett-Jackson auto auction, indicating the significant interest in the car as a cultural icon. In 2012, the "General Lee 1", the first car used in filming the series, was purchased at auction by golfer Bubba Watson for $110,000. The car had been scrapped after being wrecked during the famous opening jump shoot, and was later discovered in a junk-yard by the president of the North American General Lee fan club. In 2015, following a wave of sentiment against confederate symbolism in the wake of shootings in Charleston, SC, (relating to photos where the attacker had posed with the Confederate flag), Bubba Watson announced that he would remove the Confederate Flag from the roof of General Lee 1 and repaint it with the US National Flag.
The show also used 1968 Chargers (which shared the same sheet metal) by changing the grille and taillight panel to the 1969 style, and removing the round side marker lights. These Chargers performed many record-breaking jumps throughout the show, almost all of them resulting in a completely destroyed car. The 1970s were modified by removing the chrome bumper and changing the taillights.
The Duke boys added a custom air horn to the General Lee that played the first twelve notes of the song "Dixie". The Dixie horn was not originally planned, until a Georgia local hot rod racer drove by and sounded his car's Dixie horn. The producers immediately rushed after him asking where he had bought the horn. Warner Bros. purchased several Chargers for stunts, as they generally destroyed at least one or two cars per episode. By the end of the show's sixth season, the Chargers were becoming harder to find, and more expensive. In addition, the television series "Knight Rider" began to rival the General Lee's stunts. As such, the producers used 1:8 scale miniatures, filmed by Jack Sessums' crew, or recycled stock jump footage — the latter being a practice that had been in place to an extent since the second season, and had increased as the seasons passed.
Some of the 01 and Confederate flag motifs were initially hand painted, but as production sped up, these were replaced with vinyl decals for quick application (and removal), as needed.
During the first five episodes of the show that were filmed in Georgia, the cars involved with filming were given to the crew at H&H body shop near the filming location. At this shop, the men worked day and night to prepare the wrecked cars for the next day while still running their body shop during the day. Time was of the essence, and the men that worked at this shop worked hard hours to get the cars prepared for the show.
The third episode "Mary Kaye's Baby" is the only one in which the General Lee does not appear. Instead, the Dukes drove around in a blue 1975 Plymouth Fury borrowed from Cooter that Luke later destroyed by shooting an arrow at the car, whose trunk had been leaking due to the moonshine stowed in the back.
The Duke boys' CB handle was (jointly) "Lost Sheep". Originally when the show was conceived, their handle was to be "General Lee" to match their vehicle, but this was only ever used on-screen on one occasion, in the second episode, "Daisy's Song", when Cooter calls Bo and Luke over the CB by this handle, although they were actually driving Daisy's Plymouth Roadrunner (see below) at the time. As it became obvious that the "General Lee" handle would be out of place when the Duke boys were in another vehicle, the "Lost Sheep" handle was devised (with Uncle Jesse being "Shepherd" and Daisy being "Bo Peep").
Hazzard police cars (AMC Matador, Dodge Polara, Dodge Monaco, Plymouth Fury).
The 1975 AMC Matador was one of many different Hazzard County police cars used on the series, mostly in the first season; they had light bars and working radios. A 1972 Dodge Polara and a 1974 Dodge Monaco were used during the pilot episode "One Armed Bandits", these were also seen in the show's title sequence. From the second season, the 1977 Dodge Monaco was mostly used. From mid-season four the similar looking 1978 Plymouth Fury was used instead. The Matadors and Furies were former Los Angeles Police Department vehicles, while the Monacos were former California Highway Patrol units.
Plymouth Road Runner/Plymouth Satellite.
A 1974 Plymouth Road Runner (yellow with a black stripe) was Daisy Duke's car in the first five episodes of the first season. For the last episodes of the first season and the second season, a similarly painted 1971 Plymouth Satellite with a matching "Road Runner" stripe was used until Bo and Luke sent it off a cliff in "The Runaway".
Jeep CJ-7.
Dixie was the name given to Daisy Duke's white 1980 Jeep CJ-7 "Golden Eagle" which had a golden eagle emblem on the hood and the name "Dixie" on the sides. Like other vehicles in the show, there was actually more than one Jeep used throughout the series. Sometimes it would have an automatic transmission, and other times it would be a manual. The design of the roll cage also varied across the seasons. When the Jeep was introduced at the end of the second season's "The Runaway", it was seen to have doors and a slightly different paint job, but, bar one appearance in the next produced episode, "Arrest Jesse Duke" (actually broadcast before "The Runaway", causing a continuity error), thereafter the doors were removed and the paint job was made all-white, with "Dixie" painted on the sides of the hood. These Jeeps were leased to the producers of the show by American Motors Corporation in exchange for a brief mention in the closing credits of the show.
Ford F-100 pickup truck.
Uncle Jesse's truck was a white Ford pickup truck, most commonly a Sixth generation (1973–1977) F100 Styleside. However, in the earliest episodes it had a Flareside bed, and varied between F100 and F250 models throughout the show's run. Bo, Luke and Daisy also drove Jesse's truck on occasion.
Cadillac Coupe de Ville.
A White 1970 Cadillac Coupe de Ville convertible was used as Boss Hogg's car, notably with large bull horns as a hood ornament. In early seasons, Hogg was almost always driven by a chauffeur, who was normally nameless and had little or no dialogue, but identified on occasion as being called "Alex"; and played by several different uncredited actors, including stuntman Gary Baxley. This chauffeur would often be dressed in a red plaid shirt and deep brown or black Stetson hat, but on occasion would be an older man, sometimes dressed in more typical chauffeur attire. Hogg is first seen to drive for himself in the second season opener "Days of Shine and Roses", where he and Jesse challenge each other to one last moonshine race. From the fourth season onward, except for a couple of brief reappearances of the chauffeur (during the fourth season), Hogg drove himself around in his Cadillac (or occasionally driven by Rosco and, in the series' finale, by Uncle Jesse) and frequently challenged others by invoking his driving expertise from his days as a ridge-runner. Unlike other vehicles in the series, Boss Hogg's Cadillac is typically treated with kid gloves. The car is almost always seen with its convertible top down, with the top only being seen in two episodes, "Daisy's Song" (the chauffeur was called called "Eddie" in this episode), the second to be produced and broadcast, and briefly in the second season episode "Witness For the Persecution", when Cooter is returning it to the Court House after repairs.
Tourist attraction.
Artifacts from the show are on display in Sperryville, Virginia, Nashville, Tennessee and in Gatlinburg, Tennessee. Cooter's Place in Sperryville is overseen by Ben "Cooter" Jones from the series. The Gatlinburg location features a gift shop, "Dukes of Hazzard"-themed indoor mini golf and go-cart track, with a small display of costumes, collectables and artifacts from the show.
Covington and Conyers, Georgia; where the original five episodes were produced, have been two major tourist attractions for "Dukes of Hazzard" fans.
Dixie Outfitters in Branson, Missouri on Highway 76 has the General Lee and Rosco's police car signed by Daisy, Cooter, Cletus and Enos.
Theme song.
The theme song "The Good Ol' Boys" was written and performed by Waylon Jennings. He was also "The Balladeer" (as credited), and served as narrator of the show. However, the version released as a single is not the same version that was used in the show's opening credits; the single version has a repeat of the chorus and an instrumental to pad out the length, uses a different instrumental mix that emphasizes the bass, and replaces the last verse with an inside joke about how the TV show producers "keep on showing (Jennings's) hands and not (his) face on TV."
In 1980, the song reached #1 on the American Country chart and peaked at #21 on the "Billboard" Hot 100.
Broadcast history.
Syndication.
Soon before the series ended its original run on CBS, "The Dukes of Hazzard" went into off-network syndication. Although not as widely run as it was back in the 1980s and the years since, reruns of the program do continue to air in various parts of the United States.
Notably, television stations that aired the show in syndication include KCOP Los Angeles, WGN-TV Chicago, KBHK San Francisco, WKBD Detroit, WTAF/WTXF Philadelphia, KTXL Sacramento, WVTV Milwaukee, KMSP Minneapolis–Saint Paul, among others.
Nationwide, the show also aired on ABC Family (2000–2001, 2004) and CMT (2005–2007, 2010–2012, 2014–15) and TV Land (2015); TV Land dropped the show in the wake of protests and controversy surrounding the display of the Confederate flag.
The Nashville Network bought "The Dukes of Hazzard" from Warner Bros. in 1997 for well over $10 million; not only did it improve the network's ratings, the show was also popular among younger viewers, a demographic TNN had a notorious difficulty in drawing; "The Dukes of Hazzard" has run either on TNN or sister network CMT ever since.
Nielsen ratings.
Season one (a mid-season debut) began with 21.0 rating. In season 2, the series managed to average 18.39 million viewers in 1979. Season 3 grew 15.6% to 21.81 million viewers while Season 4 dropped 15.5% to 18.41 million viewers in 1980–1981. Season 5 dropped extensively to below 14.327 million viewers but as ratings below the top 30, Seasons 6 and Season 7 ratings are unknown.
Episode list.
The show ran for seven seasons and a total of 145 episodes. Many of the episodes followed a similar structure "out-of-town crooks pull a robbery or commit a crime or scandal, Duke boys blamed, spend the rest of the hour clearing their names, the General Lee flies and the squad cars crash".
Spin-off.
The second season episodes "Jude Emery", about a Texas Ranger, and "Mason Dixon's Girls", about a travelling private investigator and his female associates, were both pilots written by "Dukes" creator Gy Waldron for proposed new shows. Both failed to sell.
Films.
There were two made-for-TV reunion movies that aired on CBS, ' (1997) and ' (2000). Also made were "The Dukes of Hazzard" in 2005 and a direct-to-video prequel "" in 2007.
Home media.
DVD.
Warner Home Video has released all seven seasons of The Dukes of Hazzard on DVD in regions 1 and 2. The two TV-movies that followed the series were released on DVD in Region 1 on June 10, 2008 and in Region 4 on June 4, 2014. In Region 4, Warner has released only the first six seasons on DVD and the two TV movies.
Streaming.
The TV series was also made available for streaming and download through a variety of services.
Legacy and influence in popular culture.
In 2005, Tom Wopat and John Schneider were reunited during "Exposed", a fifth season episode of the television series "Smallville". Wopat guest-starred as Kansas State Senator Jack Jennings, an old friend of Clark Kent's adoptive father Jonathan Kent (portrayed by Schneider). In the episode, Jennings drives a 1968 Dodge Charger—the same body style as "The General Lee".
"Lizard Lick Towing" featured an episode with its repossession specialists Ronnie Shirley and Bobby Brantley commandeering a General Lee replica.
John Schneider and Tom Wopat have recently been featured reprising their roles as Bo and Luke Duke in ads for Auto-Trader.com. Then The General Lee gets replaced in the commercial with the new generation version which is a 2013 Dodge Viper which is General Lee the 2nd.
In 2015, in the wake of renewed debate about the symbolism of the Confederate battle flag (which was prominently featured on the "General Lee"s) roof and panel behind the rear window in the first 5 episodes, reruns of the original series were pulled from circulation. Warner Bros., which owns the property, announced it would also no longer create merchandise bearing the flag, including miniatures of the "General Lee" so the General Lee will not have the Confederate Flag any more.

</doc>
<doc id="42975" url="https://en.wikipedia.org/wiki?curid=42975" title="Hubble's law">
Hubble's law

Hubble's law is the name for the observation in physical cosmology that:
Hubble's law is considered the first observational basis for the expansion of the universe and today serves as one of the pieces of evidence most often cited in support of the Big Bang model.
The motion of astronomical objects due solely to this expansion is known as the Hubble flow.
Although widely attributed to Edwin Hubble, the law was first derived from the general relativity equations by Georges Lemaître in a 1927 article where he proposed the expansion of the universe and suggested an estimated value of the rate of expansion, now called the Hubble constant. Two years later Edwin Hubble confirmed the existence of that law and determined a more accurate value for the constant that now bears his name. Hubble inferred the recession velocity of the objects from their redshifts, many of which were earlier measured and related to velocity by Vesto Slipher in 1917.
The law is often expressed by the equation , with "H"0 the constant of proportionality (Hubble constant) between the "proper distance" "D" to a galaxy (which can change over time, unlike the comoving distance) and its velocity "v" (i.e. the derivative of proper distance with respect to cosmological time coordinate; see "Uses of the proper distance" for some discussion of the subtleties of this definition of 'velocity'). The SI unit of "H"0 is s−1 but it is most frequently quoted in (km/s)/Mpc, thus giving the speed in km/s of a galaxy away. The reciprocal of "H"0 is the Hubble time.
Discovery.
A decade before Hubble made his observations, a number of physicists and mathematicians had established a consistent theory of the relationship between space and time by using Einstein's field equations of general relativity. Applying the most general principles to the nature of the universe yielded a dynamic solution that conflicted with the then-prevailing notion of a static universe.
FLRW equations.
In 1922, Alexander Friedmann derived his Friedmann equations from Einstein's field equations, showing that the Universe might expand at a rate calculable by the equations. The parameter used by Friedmann is known today as the scale factor which can be considered as a scale invariant form of the proportionality constant of Hubble's law. Georges Lemaître independently found a similar solution in 1927. The Friedmann equations are derived by inserting the metric for a homogeneous and isotropic universe into Einstein's field equations for a fluid with a given density and pressure. This idea of an expanding spacetime would eventually lead to the Big Bang and Steady State theories of cosmology.
Lemaitre's Equation.
In 1927, two years before Hubble published his own article, the Belgian priest and astronomer Georges Lemaître was the first to publish research deriving what is now known as Hubble's Law. Unfortunately, for reasons unknown, "all discussions of radial velocities and distances (and the very first empirical determination of "H") were omitted". It is speculated that these omissions were deliberate. According to the Canadian astronomer Sidney van den Bergh, "The 1927 discovery of the expansion of the Universe by Lemaitre was published in French in a low-impact journal. In the 1931 high-impact English translation of this article a critical equation was changed by omitting reference to what is now known as the Hubble constant. That the section of the text of this paper dealing with the expansion of the Universe was also deleted from that English translation suggests a deliberate omission by the unknown translator."
Shape of the universe.
Before the advent of modern cosmology, there was considerable talk about the size and shape of the universe. In 1920, the famous Shapley-Curtis debate took place between Harlow Shapley and Heber D. Curtis over this issue. Shapley argued for a small universe the size of the Milky Way galaxy and Curtis argued that the Universe was much larger. The issue was resolved in the coming decade with Hubble's improved observations.
Cepheid variable stars outside of the Milky Way.
Edwin Hubble did most of his professional astronomical observing work at Mount Wilson Observatory, home to the world's most powerful telescope at the time. His observations of Cepheid variable stars in spiral nebulae enabled him to calculate the distances to these objects. Surprisingly, these objects were discovered to be at distances which placed them well outside the Milky Way. They continued to be called "nebulae" and it was only gradually that the term "galaxies" took over.
Combining redshifts with distance measurements.
[[File:Hubble constant.JPG|thumb |250px |Fit of redshift velocities to Hubble's law. Various estimates for the Hubble constant exist. The HST Key "H"0 Group fitted type Ia supernovae for redshifts between 0.01 and 0.1 to find that "H"0 = 71 ± 2 (statistical) ± 6 (systematic) km s−1Mpc−1, while Sandage "et al." find "H"0 = 62.3 ± 1.3 (statistical) ± 5 (systematic) km s−1Mpc−1.]]
The parameters that appear in Hubble’s law: velocities and distances, are not directly measured. In reality we determine, say, a supernova brightness, which provides information about its distance, and the redshift "z" = ∆"λ"/"λ" of its spectrum of radiation. Hubble correlated brightness and parameter "z".
Combining his measurements of galaxy distances with Vesto Slipher and Milton Humason's measurements of the redshifts associated with the galaxies, Hubble discovered a rough proportionality between redshift of an object and its distance. Though there was considerable scatter (now known to be caused by peculiar velocities – the 'Hubble flow' is used to refer to the region of space far enough out that the recession velocity is larger than local peculiar velocities), Hubble was able to plot a trend line from the 46 galaxies he studied and obtain a value for the Hubble constant of 500 km/s/Mpc (much higher than the currently accepted value due to errors in his distance calibrations). (See cosmic distance ladder for details.)
At the time of discovery and development of Hubble's law, it was acceptable to explain redshift phenomenon as a Doppler shift in the context of special relativity, and use the Doppler formula to associate redshift "z" with velocity. Today, the velocity-distance relationship of Hubble's law is viewed as a theoretical result with velocity to be connected with observed redshift not by the Doppler effect, but by a cosmological model relating recessional velocity to the expansion of the Universe. Even for small "z" the velocity entering the Hubble law is no longer interpreted as a Doppler effect, although at small "z" the velocity-redshift relation for both interpretations is the same.
Hubble Diagram.
Hubble's law can be easily depicted in a "Hubble Diagram" in which the velocity (assumed approximately proportional to the redshift) of an object is plotted with respect to its distance from the observer. A straight line of positive slope on this diagram is the visual depiction of Hubble's law.
Cosmological constant abandoned.
After Hubble's discovery was published, Albert Einstein abandoned his work on the cosmological constant, which he had designed to modify his equations of general relativity, to allow them to produce a static solution which, in their simplest form, model either an expanding or contracting universe. After Hubble's discovery that the Universe was, in fact, expanding, Einstein called his faulty assumption that the Universe is static his "biggest mistake". On its own, general relativity could predict the expansion of the Universe, which (through observations such as the bending of light by large masses, or the precession of the orbit of Mercury) could be experimentally observed and compared to his theoretical calculations using particular solutions of the equations he had originally formulated.
In 1931, Einstein made a trip to Mount Wilson to thank Hubble for providing the observational basis for modern cosmology.
The cosmological constant has regained attention in recent decades as a hypothesis for dark energy.
Interpretation.
The discovery of the linear relationship between redshift and distance, coupled with a supposed linear relation between recessional velocity and redshift, yields a straightforward mathematical expression for Hubble's Law as follows:
where
Hubble's law is considered a fundamental relation between recessional velocity and distance. However, the relation between recessional velocity and redshift depends on the cosmological model adopted, and is not established except for small redshifts.
For distances "D" larger than the radius of the Hubble sphere "r"HS , objects recede at a rate faster than the speed of light ("See" Uses of the proper distance for a discussion of the significance of this):
Since the Hubble "constant" is a constant only in space, not in time, the radius of the Hubble sphere may increase or decrease over various time intervals. The subscript '0' indicates the value of the Hubble constant today. Current evidence suggests that the expansion of the Universe is accelerating ("see" Accelerating universe), meaning that, for any given galaxy, the recession velocity dD/dt is increasing over time as the galaxy moves to greater and greater distances; however, the Hubble parameter is actually thought to be decreasing with time, meaning that if we were to look at some "fixed" distance D and watch a series of different galaxies pass that distance, later galaxies would pass that distance at a smaller velocity than earlier ones.
Redshift velocity and recessional velocity.
Redshift can be measured by determining the wavelength of a known transition, such as hydrogen α-lines for distant quasars, and finding the fractional shift compared to a stationary reference. Thus redshift is a quantity unambiguous for experimental observation. The relation of redshift to recessional velocity is another matter. For an extensive discussion, see Harrison.
Redshift velocity.
The redshift "z" is often described as a "redshift velocity", which is the recessional velocity that would produce the same redshift "if" it were caused by a linear Doppler effect (which, however, is not the case, as the shift is caused in part by a cosmological expansion of space, and because the velocities involved are too large to use a non-relativistic formula for Doppler shift). This redshift velocity can easily exceed the speed of light. In other words, to determine the redshift velocity "v"rs, the relation:
is used. That is, there is "no fundamental difference" between redshift velocity and redshift: they are rigidly proportional, and not related by any theoretical reasoning. The motivation behind the "redshift velocity" terminology is that the redshift velocity agrees with the velocity from a low-velocity simplification of the so-called Fizeau-Doppler formula
Here, "λ"o, "λ"e are the observed and emitted wavelengths respectively. The "redshift velocity" "v"rs is not so simply related to real velocity at larger velocities, however, and this terminology leads to confusion if interpreted as a real velocity. Next, the connection between redshift or redshift velocity and recessional velocity is discussed. This discussion is based on Sartori.
Recessional velocity.
Suppose "R(t)" is called the "scale factor" of the Universe, and increases as the Universe expands in a manner that depends upon the cosmological model selected. Its meaning is that all measured proper distances "D(t)" between co-moving points increase proportionally to "R". (The co-moving points are not moving relative to each other except as a result of the expansion of space.) In other words:
where "t0" is some reference time. If light is emitted from a galaxy at time "te" and received by us at "t0", it is red shifted due to the expansion of space, and this redshift "z" is simply:
Suppose a galaxy is at distance "D", and this distance changes with time at a rate "dtD ". We call this rate of recession the "recession velocity" "vr":
We now define the Hubble constant as
and discover the Hubble law:
From this perspective, Hubble's law is a fundamental relation between (i) the recessional velocity contributed by the expansion of space and (ii) the distance to an object; the connection between redshift and distance is a crutch used to connect Hubble's law with observations. This law can be related to redshift "z" approximately by making a Taylor series expansion:
If the distance is not too large, all other complications of the model become small corrections and the time interval is simply the distance divided by the speed of light:
According to this approach, the relation "cz" = "v"r is an approximation valid at low redshifts, to be replaced by a relation at large redshifts that is model-dependent. See velocity-redshift figure.
Observability of parameters.
Strictly speaking, neither "v" nor "D" in the formula are directly observable, because they are properties "now" of a galaxy, whereas our observations refer to the galaxy in the past, at the time that the light we currently see left it.
For relatively nearby galaxies (redshift "z" much less than unity), "v" and "D" will not have changed much, and "v" can be estimated using the formula formula_16 where "c" is the speed of light. This gives the empirical relation found by Hubble.
For distant galaxies, "v" (or "D") cannot be calculated from "z" without specifying a detailed model for how "H" changes with time. The redshift is not even directly related to the recession velocity at the time the light set out, but it does have a simple interpretation: "(1+z)" is the factor by which the Universe has expanded while the photon was travelling towards the observer.
Expansion velocity vs relative velocity.
In using Hubble's law to determine distances, only the velocity due to the expansion of the Universe can be used. Since gravitationally interacting galaxies move relative to each other independent of the expansion of the Universe, these relative velocities, called peculiar velocities, need to be accounted for in the application of Hubble's law.
The Finger of God effect is one result of this phenomenon. In systems that are gravitationally bound, such as galaxies or our planetary system, the expansion of space is a much weaker effect than the attractive force of gravity.
Idealized Hubble's Law.
The mathematical derivation of an idealized Hubble's Law for a uniformly expanding universe is a fairly elementary theorem of geometry in 3-dimensional Cartesian/Newtonian coordinate space, which, considered as a metric space, is entirely homogeneous and isotropic (properties do not vary with location or direction). Simply stated the theorem is this:
In fact this applies to non-Cartesian spaces as long as they are locally homogeneous and isotropic; specifically to the negatively and positively curved spaces frequently considered as cosmological models (see shape of the universe).
An observation stemming from this theorem is that seeing objects recede from us on Earth is not an indication that Earth is near to a center from which the expansion is occurring, but rather that "every" observer in an expanding universe will see objects receding from them.
Ultimate fate and age of the universe.
The value of the Hubble parameter changes over time, either increasing or decreasing depending on the value of the so-called deceleration parameter formula_17, which is defined by
In a universe with a deceleration parameter equal to zero, it follows that "H" = 1/"t", where "t" is the time since the Big Bang. A non-zero, time-dependent value of formula_17 simply requires integration of the Friedmann equations backwards from the present time to the time when the comoving horizon size was zero.
It was long thought that "q" was positive, indicating that the expansion is slowing down due to gravitational attraction. This would imply an age of the Universe less than 1/"H" (which is about 14 billion years). For instance, a value for "q" of 1/2 (once favoured by most theorists) would give the age of the Universe as 2/(3"H"). The discovery in 1998 that "q" is apparently negative means that the Universe could actually be older than 1/"H". However, estimates of the age of the universe are very close to 1/"H".
Olbers' paradox.
The expansion of space summarized by the Big Bang interpretation of Hubble's Law is relevant to the old conundrum known as Olbers' paradox: if the Universe were infinite, static, and filled with a uniform distribution of stars, then every line of sight in the sky would end on a star, and the sky would be as bright as the surface of a star. However, the night sky is largely dark. Since the 17th century, astronomers and other thinkers have proposed many possible ways to resolve this paradox, but the currently accepted resolution depends in part on the Big Bang theory and in part on the Hubble expansion. In a universe that exists for a finite amount of time, only the light of a finite number of stars has had a chance to reach us yet, and the paradox is resolved. Additionally, in an expanding universe, distant objects recede from us, which causes the light emanating from them to be redshifted and diminished in brightness.
Dimensionless Hubble parameter.
Instead of working with Hubble's constant, a common practice is to introduce the dimensionless Hubble parameter, usually denoted by "h", and to write the Hubble's parameter "H"0 as "h" × 100 km s−1 Mpc−1, all the uncertainty relative of the value of "H"0 being then relegated to "h". If a subscript is presented after "h", it refers to the value of "h" used in that text's preceding calculation, and is equal to "H"0 / 100. Currently "h" = 0.678, which can be represented as "h"0.678. This should not be confused with the dimensionless value of Hubble's constant, usually expressed in terms of Planck units, with current value of "H"0×"t"P = 1.18 × 10−61.
Determining the Hubble constant.
The value of the Hubble constant is estimated by measuring the redshift of distant galaxies and then determining the distances to the same galaxies (by some other method than Hubble's law). Uncertainties in the physical assumptions used to determine these distances have caused varying estimates of the Hubble constant.
Earlier measurement and discussion approaches.
For most of the second half of the 20th century the value of formula_20 was estimated to be between 50 and .
The value of the Hubble constant was the topic of a long and rather bitter controversy between Gérard de Vaucouleurs, who claimed the value was around 100, and Allan Sandage, who claimed the value was near 50. In 1996, a debate moderated by John Bahcall between Sidney van den Bergh and Gustav Tammann was held in similar fashion to the earlier Shapley-Curtis debate over these two competing values.
This previously wide variance in estimates was partially resolved with the introduction of the ΛCDM model of the Universe in the late 1990s. With the ΛCDM model observations of high-redshift clusters at X-ray and microwave wavelengths using the Sunyaev-Zel'dovich effect, measurements of anisotropies in the cosmic microwave background radiation, and optical surveys all gave a value of around 70 for the constant.
More recent measurements from the Planck mission indicate a lower value of around 67.
"See table of measurements above for many recent and older measurements."
Acceleration of the expansion.
A value for formula_17 measured from standard candle observations of Type Ia supernovae, which was determined in 1998 to be negative, surprised many astronomers with the implication that the expansion of the Universe is currently "accelerating" (although the Hubble factor is still decreasing with time, as mentioned above in the Interpretation section; see the articles on dark energy and the ΛCDM model).
Derivation of the Hubble parameter.
Start with the Friedmann equation:
where formula_3 is the Hubble parameter, formula_24 is the scale factor, G is the gravitational constant, formula_25 is the normalised spatial curvature of the Universe and equal to −1, 0, or +1, and formula_26 is the cosmological constant.
Matter-dominated universe (with a cosmological constant).
If the Universe is matter-dominated, then the mass density of the Universe formula_27 can just be taken to include matter so
where formula_29 is the density of matter today. We know for nonrelativistic particles that their mass density decreases proportional to the inverse volume of the Universe, so the equation above must be true. We can also define (see density parameter for formula_30)
so formula_33 Also, by definition,
and
where the subscript nought refers to the values today, and formula_36. Substituting all of this into the Friedmann equation at the start of this section and replacing formula_24 with formula_38 gives
Matter- and dark energy-dominated universe.
If the Universe is both matter-dominated and dark energy- dominated, then the above equation for the Hubble parameter will also be a function of the equation of state of dark energy. So now:
where formula_41 is the mass density of the dark energy. By definition, an equation of state in cosmology is formula_42, and if this is substituted into the fluid equation, which describes how the mass density of the Universe evolves with time, then
If w is constant, then
Therefore, for dark energy with a constant equation of state w, formula_47. If this is substituted into the Friedman equation in a similar way as before, but this time set formula_48, which assumes a spatially flat universe, then (see Shape of the Universe)
If the dark energy derives from a cosmological constant such as that introduced by Einstein, it can be shown that formula_50. The equation then reduces to the last equation in the matter-dominated universe section, with formula_51 set to zero. In that case the initial dark energy density formula_52 is given by 
If dark energy does not have a constant equation-of-state w, then
and to solve this, formula_56 must be parametrized, for example if formula_57, giving
Other ingredients have been formulated recently.
Units derived from the Hubble constant.
Hubble time.
The Hubble constant formula_20 has units of inverse time; the Hubble time tH is simply defined as the inverse of the Hubble constant, i.e. formula_60 = 14.4 billion years. This is slightly different from the age of the universe formula_61 13.8 billion years. The Hubble time is the age it would have had if the expansion had been linear, and it is different from the real age of the universe because the expansion isn't linear; they are related by a dimensionless factor which depends on the mass-energy content of the universe, which is around 0.96 in the standard Lambda-CDM model.
We currently appear to be approaching a period where the expansion is exponential due to the increasing dominance of vacuum energy. In this regime, the Hubble parameter is constant, and the universe grows by a factor e each Hubble time:
Over long periods of time, the dynamics are complicated by general relativity, dark energy, inflation, etc., as explained above.
Hubble length.
The Hubble length or Hubble distance is a unit of distance in cosmology, defined as "cH"0−1 — the speed of light multiplied by the Hubble time. It is equivalent to 4,550 million parsecs or 14.4 billion light years. (The numerical value of the Hubble length in light years is, by definition, equal to that of the Hubble time in years.) The Hubble distance would be the distance between the Earth and the galaxies which are "currently" receding from us at the speed of light, as can be seen by substituting into the equation for Hubble's law, .
Hubble volume.
The Hubble volume is sometimes defined as a volume of the Universe with a comoving size of "c/H"0. The exact definition varies: it is sometimes defined as the volume of a sphere with radius "c/H"0, or alternatively, a cube of side "c/H"0. Some cosmologists even use the term Hubble volume to refer to the volume of the observable universe, although this has a radius approximately three times larger.

</doc>
<doc id="42977" url="https://en.wikipedia.org/wiki?curid=42977" title="Daimler AG">
Daimler AG

History.
Daimler AG is a German manufacturer of automobiles, motor vehicles, and engines, which dates back more than a century.
An "Agreement of Mutual Interest" was signed on 1 May 1924 between Benz & Cie (founded 1883 by Karl Benz) and Daimler Motoren Gesellschaft (founded 1890 by Gottlieb Daimler and Wilhelm Maybach).
Both companies continued to manufacture their separate automobile and internal combustion engine brands until, on 28 June 1926, when Benz & Cie. and Daimler Motoren Gesellschaft AG formally merged—becoming Daimler-Benz AG—and agreed that, thereafter, all of the factories would use the brand name of Mercedes-Benz on their automobiles.
In 1998, Daimler-Benz and Chrysler Corporation announced the world's largest cross-border deal ever, valued at 38billion, and the resulting change in company name to "DaimlerChrysler AG".
In 2007, when the Chrysler group was sold off to Cerberus Capital Management (see below), the name of the parent company was changed to simply "Daimler AG".
In November 2014, Daimler announced it would acquire 25 percent of Italian motorcycle producer MV Agusta for an undisclosed fee.
Timeline of Daimler AG.
Benz & Company, 1883–1926 
Daimler Motoren Gesellschaft AG, 1890–1926 
Daimler-Benz AG, 1926–1998 
DaimlerChrysler AG, 1998–2007 
Daimler AG, 2007–present
Merger with Chrysler.
In a so-called "Merger of Equals," or "Marriage made in Heaven", according to its then CEO and architect Jürgen E. Schrempp, Daimler-Benz AG and United States-based automobile manufacturer Chrysler Corporation, the smallest of the three American automakers, merged in 1998 in an exchange of shares as Daimler-Benz AG bought 92% of Chrysler, and 8% of Chrysler remained independent and formed DaimlerChrysler AG. The terms of the merger allowed Daimler-Benz's non-automotive businesses such as Daimler-Benz InterServices AG, "debis AG" for short, (created in 1989 to handle data processing, financial and insurance services, and real estate management for the Daimler group) to continue to pursue their respective strategies of expansion. "debis AG" reported revenues of $8.6 bn (DM 15.5 bn) in 1997.
The merger was contentious with investors launching lawsuits over whether the transaction was the 'merger of equals' that senior management claimed or actually amounted to a Daimler-Benz takeover of Chrysler. A class action investor lawsuit was settled in August 2003 for US$300 million while a suit by billionaire investor activist Kirk Kerkorian was dismissed on 7 April 2005. The transaction claimed the job of its architect, Chairman Jürgen E. Schrempp, who resigned at the end of 2005 in response to the fall of the company's share price following the transaction. The merger was also the subject of a book "Taken for a Ride: How Daimler-Benz Drove Off With Chrysler", (2000) by Bill Vlasic and Bradley A. Stertz.
Another issue of contention is whether the merger delivered promised synergies and successfully integrated the two businesses. Martin H. Wiggers' concept of a platform strategy like the VW Group, was implemented only for a few models, so the synergy effects in development and production were too low. As late as 2002, DaimlerChrysler appeared to run two independent product lines. Later that year, the company launched products that appeared to integrate elements from both sides of the company, including the Chrysler Crossfire, which was based on the Mercedes SLK platform and utilized Mercedes's 3.2L V6, and the Dodge Sprinter/Freightliner Sprinter, a re-badged Mercedes-Benz Sprinter van.
Sale of Chrysler.
Daimler agreed to sell the Chrysler unit to Cerberus Capital Management in May 2007 for US$6 billion. Through most of its history, Chrysler has been the smallest of the "Big 3" U.S. automakers, but in January 2007, DaimlerChrysler, excluding its luxury Mercedes and Maybach lines, also outsold traditionally second place Ford, though behind General Motors and Toyota.
Chrysler reported losses of US$1.5 billion in 2006. It then announced plans to lay off 13,000 employees in mid-February 2007, close a major assembly plant and reduce production at other plants in order to restore profitability by 2008.
DaimlerChrysler had reportedly approached other carmakers and investment groups to sell Chrysler in early 2007. General Motors was reported to be a suitor, but on 3 August 2007, DaimlerChrysler completed the sale of Chrysler Group to Cerberus Capital Management. The original agreement stated that Cerberus would take an 80.1 percent stake in the new company, Chrysler Holding LLC. DaimlerChrysler changed its name to Daimler AG and retained the remaining 19.9% stake in the separated Chrysler.
The terms saw Daimler pay Cerberus US$650 million to take Chrysler and associated liabilities off its hands. Of the US$7.4 billion purchase price, Cerberus Capital Management will invest US$5 billion in Chrysler Holdings and US$1.05 billion in Chrysler's financial unit. The de-merged Daimler AG received US$1.35 billion directly from Cerberus but directly invested US$2 billion in Chrysler itself.
Since Chrysler's 2009 bankruptcy filing in the United States, Chrysler has been controlled by Italian automaker Fiat and plans to integrate Chrysler's products into the Fiat portfolio, such as Lancia and Chrysler's namesake brand, and Fiat's namesake brand with Dodge. Despite the fact it had been nearly seven years after the Daimler/Chrysler split, the fourth-generation Jeep Grand Cherokee shares a platform with the Mercedes-Benz M-Class. This also includes the Chrysler LX platform vehicles which initially used Mercedes-Benz components since its 2005 introduction.
Automated cars.
On 3 August 2015, Nokia announced that it had reached a deal to sell its Here digital maps division to a consortium of three German automakers—BMW, Daimler AG, and Volkswagen Group, for €2.8 billion. This was seen as an indication that the automakers were interested in automated cars.
Corporate affairs.
Management.
Dieter Zetsche has been the Chairman of Daimler and Head of Mercedes-Benz Cars since 1 January 2006 as well as member of the Board of Management since 1998. He was former President and CEO of the Chrysler, LLC (previously owned by Daimler AG), he may be best known in the United States as "Dr. Z" from a Chrysler advertising campaign called "Ask Dr. Z".
Current (2015) members of the Board of Management of Daimler AG are:
The Board of Management total members of seven, after the unexpected resignation on 28 January 2014 of Andreas Renschler, former head of Manufacturing and Procurement Mercedes-Benz Cars & Mercedes-Benz Vans, has been brought back to eight after the nomination on 1 January 2015 of Swedish-born Ola Källenius to the Board of Management as Head of Mercedes-Benz Cars Marketing and Sales.
, the twenty members of Daimler AG's Supervisory Board are: Manfred Bischoff (Chairman), Michael Brecht (Deputy Chairman), Paul Achleitner, Sari Baldauf, Michael Bettag, Bernd Bohr, Clemens Börsig, Jürgen Hambrecht, Petraea Heynike, Andrea Jung, Joe Kaeser, Ergun Lümali, Sabine Maaßen, Wolfgang Nieke, Bernd Pischetsrieder, Valter Sanches, Jörg Spies, Elke Tönjes-Werner, Frank Weber, Roman Zitzelsberger.
Shareholder Structure.
"by Ownership"
"by Region"
29.7% Europe (excluding Germany),
32.1% German,
25.5% United States,
6.8% Kuwait,
5.4% Asia,
0.5% Others.
EADS shareholding.
As of March 2010, Daimler owned a 22.5% share of EADS, of which the public sector held 40%.
In April 2013, Daimler sold its shares in EADS, and the same year, EADS restructured itself into a new aerospace company named Airbus, into which Daimler AG has no shareholding.
On the side of the public sector, the KfW banking group holds 13%, HGV Hamburger Gesellschaft fur Vermogens- und Beteiligungsverwaltung (State of Hamburg) holds 10%, Hannoversche Beteiligungsgesellschaft (State of Lower Saxony) holds 5%, Bayerische Landesbodenkreditanstalt, Anstalt der Bayerischen Landesbank holds 3.5%, LfA Forderbank Bayern holds 1.5%, Landesbank Baden-Württemberg and Landeskreditbank Baden-Württemberg – Forderbank (L-Bank) each holds 2.5%, and Bremer Investitions-Gesellschaft (State of Bremen) holds 2%. 
North Charleston Expansion.
On 5 March 2015, Daimler AG announced a 1,200 jobs package to the North Charleston region for its van plant. This will allow the company to start manufacturing Mercedes-Benz Sprinter vans from scratch in a North Charleston plant to meet demand in North America. Currently, these vans are set up in Germany, then shipped to the United States partially disassembled for reassembly. This is all to avoid import tariffs, a practice that started in 2010. A Daimler official said that the Sprinter’s popularity in North America is making that process less efficient. The North Charleston plant had been employing only 100 workers. The Sprinter is available on the U.S. market as a panel van, crew bus and chassis in several variants with three lengths and roof heights, six-cylinder diesel or gasoline engines. The Sprinter has been assembled and sold in the United States since 2001.
Brands.
Daimler sells automobiles under the following brands worldwide:
Locations.
The Daimler AG has a worldwide networks of production plants and research centers. The following list is a description of all locations worldwide, that include a Daimler plant, including plants for Daimler subsidiaries EvoBus, Daimler Trucks North America, Detroit Diesel, Freightliner Trucks and Mitsubishi Fuso Truck and Bus Corporation. The list excludes the location of Daimler Financial Services locations.
Holdings.
Daimler currently holds interests in the following companies:
At the end of 2011 McLaren Group completely bought back the stocks from Daimler.
17 April 2013, Daimler AG exits EADS, the parent company of Airbus of Europe.
Joint ventures and alliances.
Beijing Automotive Group.
In February 2013, Daimler acquired a 12% stake in Beijing Automotive Industry Holding Co Ltd (BAIC), becoming the first western car manufacturer to own a stake in a Chinese company.
Daimler works with China's Beiqi Foton (a subsidiary of BAIC) to build Auman trucks.
Denza.
In 2010 BYD Auto and Daimler AG created a new joint venture Shenzhen BYD Daimler New Technology Co., Ltd. In 2012 the new brand Denza was launched by the joint venture to specialise in electric cars.
Fujian Benz.
In 2007 Daimler created a joint venture with Fujian Motors Group and China Motor Corporation and created Fujian Benz (originally Fujian Daimler Automotive Co.).
Renault-Nissan and Daimler Alliance.
On 7 April 2010 Renault-Nissan executives, Carlos Ghosn and Dr. Dieter Zetsche announced a partnership between the three companies. The first fruits of the alliance in 2012 included engine sharing (Infiniti Q50 utilising Mercedes diesel engines) and a re-badged Renault Kangoo being sold as a Mercedes-Benz Citan.
Alternative propulsion.
Biofuel research.
Daimler AG is involved in a joint project with Archer Daniels Midland Company and Bayer CropScience to develop the semi-evergreen shrub jatropha curcas as a biofuel.
Electric.
Daimler AG and the utility company RWE AG were set in 2009 to begin a joint electric car and charging station test project in the German capital, Berlin, called "E-Mobility Berlin". 
Following trials in 2007 and then with Tesla in 2009, Daimler is building a production Smart electric drive car using Tesla's battery technology.
Daimler's joint venture with BYD has resulted in the creation of the new brand Denza.
In 2016 Daimler subsidiary ACCUMOTIVE announced their stationary batteries, to store up to 20 kWh of solar power for later use.
Fuel cell.
Daimler has been involved with fuel cell vehicle development for some time, with a number of research and concept vehicles shown and demonstrated, the first being the 2002 Mercedes-Benz F-Cell car and the Mercedes-Benz Citaro Hydrogen bus. In 2013, the Renault-Nissan/Daimler alliance was joined by Ford to further develop the fuel cell technology with an aim for production by 2017.
Hybrid.
Mercedes-Benz launched its first passenger car model equipped with a hybrid drive system in summer 2009, the Mercedes-Benz S-Class 400 Hybrid. and the Citaro Hybrid bus in 2007. Daimler Trucks and Mitusbishi Fuso have also trailed various hybrid models including the Mitsubishi Fuso Canter Eco Hybrid and Mitsubishi Fuso Aero Star Aero Star Eco Hybrid bus.
Formula One.
On 16 November 2009 Daimler (45.1%) och Aabar Investments (30%) purchased a 75.1% stake in Brawn GP. The company was rebranded as Mercedes GP with its base in Brackley, UK, with Ross Brawn remaining team principal., However the purchase of Brawn meant that Daimler sold back its stake in McLaren in stages that ended in 2011. Mercedes will continue to provide sponsorship and engines to McLaren until 2015, when McLaren will switch to engines from Honda.
Prior to the 2011 season, Daimler and Aabar Investments purchased the remaining 24.9% stake owned by the team management in February 2011. In November 2012 Aabar Investments sold its remaining shares and the team (rebranded as Mercedes AMG Petronas F1 Team) is now wholly owned by Daimler.
Daimler also owns Mercedes AMG High Performance Powertrains, which as of 2014 supplies engines to Force India, McLaren and Williams, in addition to Mercedes AMG Petronas.
Bribery and corruption.
On 1 April 2010, Daimler AG's German and Russian subsidiaries each plead guilty to two counts of bribery charges brought by the U.S. Justice Department and the U.S. Securities and Exchange Commission. Daimler itself had to pay US$185 million as a settlement, but the company and its Chinese subsidiary remained subject to a two-year deferred prosecution agreement requiring further cooperation with regulators, adherence to internal controls and meeting other terms before final sentencing. Daimler would face harsher penalties should it fail to meet the terms of the agreement during the two-year period.
Additionally, Louis J. Freeh, a former director of the Federal Bureau of Investigation, served as an independent monitor to oversee Daimler's compliance with anti-bribery laws.
U.S. prosecutors accused key executives of Daimler, Daimler subsidiaries, and Daimler affiliates of illegally showering foreign officials with money and gifts between 1998 and 2008 to secure government contracts around the world. The investigation for the case revealed that Daimler improperly paid some $56 million in bribes related to more than 200 transactions in at least 22 countries (including China, Russia, Turkey, Hungary, Greece, Latvia, Serbia and Montenegro, Egypt and Nigeria, among other places) that, in return, awarded the company $1.9 billion in revenue and at least $91.4 million in illegal profits.
The SEC case was sparked in 2004 after David Bazzetta, a former auditor at then DaimlerChrysler Corp, filed a whistleblower complaint after he was fired for raising questions about bank accounts controlled by Mercedes-Benz units in South America. Bazzetta alleged that he learned in a July 2001 corporate audit executive committee meeting in Stuttgart that business units "continued to maintain secret bank accounts to bribe foreign government officials", though the company knew the practice violated U.S. laws.
In another attempt to silence Bazzetta, Daimler later offered to settle his termination of employment suit out of court and he eventually accepted a settlement. But Daimler's strategy with Bazzetta proved to be a failure as the U.S. criminal investigation for violating anti-bribery laws was already underway in what has been one of the most wide-ranging cases brought against a foreign corporation.
According to the charges, the bribes were frequently made by over-invoicing customers and paying the excess back to top government officials or their proxies. The bribes also took the form of luxury European vacations, armored Mercedes vehicles for high-ranking government officials and a birthday gift to the then notorious dictator of Turkmenistan, Turkmenbashi (Saparmurat Niyazov), including a golden box and 10,000 copies of his personal manifesto, Ruhnama, translated into German.
Investigators also found that the firm violated the terms of the United Nations' Oil-for-Food Programme with Iraq by giving kickbacks worth 10% of the contract values to officials within the Iraqi government, then led by Saddam Hussein. The SEC said the company made more than $4 million in profit from the sale of vehicles and spare parts in the corrupt Oil-for-Food deals.
U.S. prosecutors further alleged that some bribes were paid through shell companies based in the U.S. "In some cases Daimler wired these improper payments to U.S. bank accounts or to the foreign bank accounts of U.S. shell companies in order to transmit the bribe," the court papers said.
Prosecutors said that Daimler engaged in a "long-standing practice" of paying bribes, due in part to a corporate culture that encouraged the practice.
"Using offshore bank accounts, third-party agents and deceptive pricing practices, these companies AG, its subsidiaries and affiliates saw foreign bribery as a way of doing business," said Mythili Raman, a principal deputy in the Justice Department's criminal division.
"It is no exaggeration to describe corruption and bribe-paying at Daimler as a standard business practice," Robert Khuzami, director of the SEC's enforcement division, said in a statement.
"We have learned a lot from past experience," Dieter Zetsche, chairman of Daimler's board, said in a statement.
As per the agreement with prosecutors, the two Daimler subsidiaries admitted to knowingly violating the Foreign Corrupt Practices Act, which bars companies and their officials from paying bribes to foreign officials to win business. The Foreign Corrupt Practices Act applies to any company that lists its shares on U.S. stock exchanges. Daimler AG was listed with the symbol "DAI" on the New York Stock Exchange, giving the Justice Department jurisdiction over the German car maker's payments in countries around the globe.
Judge Richard J. Leon of the United States District Court in Washington, D.C., approved the plea agreement and settlement, calling it a "just resolution."
The primary case is "USA v. Daimler AG," United States District Court for the District of Columbia, No. 1:10-cr-00063-RJL .

</doc>
