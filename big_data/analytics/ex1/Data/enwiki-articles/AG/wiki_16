<doc id="40336" url="https://en.wikipedia.org/wiki?curid=40336" title="Rhododendron">
Rhododendron

Rhododendron (from Ancient Greek ῥρόδον ' "rose" and δέντρο ' "tree") is a genus of 1,024 species of woody plants in the heath family (Ericaceae), either evergreen or deciduous, and found mainly in Asia, although it is also widespread throughout the Southern Highlands of the Appalachian Mountains of North America. It is the national flower of Nepal. Most species have showy flowers which bloom from late winter through to early summer. Azaleas make up two subgenera of "Rhododendron". They are distinguished from "true" rhododendrons by having only five anthers per flower.
Description.
"Rhododendron" is a genus characterised by shrubs and small to (rarely) large trees, the smallest species growing to tall, and the largest, "R. protistum var. giganteum", reported to tall. The leaves are spirally arranged; leaf size can range from to over , exceptionally in "R. sinogrande". They may be either evergreen or deciduous. In some species, the undersides of the leaves are covered with scales (lepidote) or hairs (indumentum). Some of the best known species are noted for their many clusters of large flowers. There are alpine species with small flowers and small leaves, and tropical species such as section "Vireya" that often grow as epiphytes. Species in this genus may be part of the heath complex in oak-heath forests in eastern North America. They have frequently been divided based on the presence or absence of scales on the abaxial (lower) leaf surface (lepidote or elepidote). These scales, unique to subgenus "Rhododendron", are modified hairs consisting of a polygonal scale attached by a stalk.
"Rhododendron" are characterised by having inflorescences with scarious (dry) perulae, a chromosome number of x=13, fruit that has a septicidal capsule, an ovary that is superior (or nearly so), stamens that have no appendages, and agglutinate (clumped) pollen.
Taxonomy.
The "Rhododendron" genus is the largest of the genera in the Ericaceae family, with 1,024 species, though estimates vary from 850-1000 depending on the authority used, (Fayaz 2012) and is morphologically diverse. Consequently, the taxonomy has been historically complex.
Early history.
Although Rhododendrons had been known since the description of "Rhododendron hirsutum" by Charles de l'Écluse (Clusius) in the sixteenth century, and were known to classical writers (Magor 1990), and referred to as "Chamaerhododendron" (low-growing rose tree), the genus was first formally described by Linnaeus in his Species Plantarum in 1753. He listed five species under "Rhododendron" ("Rhododendron ferrugineum" (type species), "R. dauricum", "R. hirsutum", "R. chamaecistus" (now "Rhodothamnus chamaecistus" (L.) Rchb.) and "R. maximum"). At that time he considered the then known six species of "Azalea" that he had described earlier in 1735 in his Systema Naturae as a separate genus.
Linnaeus' six species of Azalea were "Azalea indica", "A. pontica", "A. lutea", "A. viscosa", "A. lapponica" and "A. procumbens" (now "Kalmia procumbens"), which he distinguished from "Rhododendron" by having five stamens, as opposed to ten. As new species of what are now considered "Rhododendron" were discovered, if they seemed to differ significantly from the type species they were assigned to separate genera. For instance "Rhodora" for "Rhododendron canadense" (Linnaeus 1763), "Vireya" (Blume 1826) and "Hymenanthes" for "Rhododendron metternichhii", now R. degronianum (1826). Meanwhile, other botanists such as Salisbury (1796) and Tate (1831) began to question the distinction between "Azalea" and "Rhododendron", and finally in 1836, "Azalea" was incorporated into "Rhododendron" (Don 1834) and the genus divided into eight sections. Of these "Tsutsutsi" ("Tsutsusi"), "Pentanthera", "Pogonanthum", "Ponticum" and "Rhodora" are still used, the other sections being "Lepipherum", "Booram", and "Chamaecistus". This structure largely survived till recently (2004), following which the development of molecular phylogeny led to major re-examinations of traditional morphological classifications, although other authors such as Candolle (1838), who described six sections, used slightly different numeration.
As more species became available in the nineteenth century a better understanding of the characteristics necessary for the major divisions. Chief amongst these were Maximovicz's "Rhododendreae Asiae Orientali" (1870) and Planchon. Maximovicz used flower bud position and its relationship with leaf buds to create eight Sections. Bentham and Hooker (1876) used a similar scheme, but called the divisions Series. It was not until 1893 that Koehne appreciated the significance of scaling and hence the separation of lepidote and elepidote species. The large number of species that were available by the early twentieth century prompted a new approach when Balfour introduced the concept of grouping species into series, in "The Species of Rhododendron" (1930), referred to as the Balfourian system. That system continued up to modern times in Davidian's four volume "The Rhododendron Species" (1982-1995).
Modern era.
The next major attempt at classification was by Sleumer who from 1934 began incorporating the Balfourian series into the older hierarchical structure of subgenera and sections, according to the International Code of Botanical Nomenclature, culminating in his "Ein System der Gattung Rhododendron L." (1949), and subsequent refinements. Most of the Balfourian series are represented by Sleumer as subsections, though some appear as sections or even subgenera. Sleumer based his system on the relationship of the flower buds to the leaf buds, habitat, flower structure, and whether the leaves were lepidote or non-lepidote. While Sleumer's work was widely accepted, many in the United States and the United Kingdom continued to use the simpler Balfourian system of the Edinburgh group.
Sleumer's system underwent many revisions by others, predominantly the Edinburgh group in their continuing Royal Botanic Garden Edinburgh notes. Cullen (1980) in Edinburgh, placing more emphasis on the lepidote characteristics of the leaves united all of the lepidote species into subgenus "Rhodendron", including four of Sleumer's (1980) subgenera ("Rhododendron", "Pseudoazalea", "Pseudorhodorastrum", "Rhodorastrum"). Philipson & Philipson (1986) raised two sections of subgenus "Aleastrum" ("Mumeazalea", "Candidastrum") to subgenera, while reducing genus "Therorhodion" to a subgenus of "Rhododendron". In 1987 Spethmann, adding phytochemical features proposed a system with fifteen subgenera grouped into three 'chorus' subgenera.
A number of closely related genera had been included together with "Rhododendron" in a former tribe, Rhodoreae. These have been progressively incorporated into "Rhododendron". Chamberlain and Rae (1990) moved the monotypic section "Tsusiopsis" together with the monotypic genus "Tsusiophyllum" into section "Tsutsusi", while in the same year Kron & Judd reduced genus "Ledum" to a subsection of section "Rhododendron". Then Judd & Kron (1995) moved two species ("Rhododendron schlippenbachii", "R. quinquefolium") from section "Brachybachii" subgenus "Tsutsusi" and two from section "Rhodora" subgenus "Pentanthera" ("R. albrechti"i, "R. pentaphyllu"m) into section "Sciadorhodion" subgenus "Pentanthera". Finally Chamberlain brought the various systems together in 1996, with 1,025 species divided into eight subgenera. For a comparison of the Sleuner and Chamberlain schemata see Table 1 of Goetsch (2005).
Phylogenetic analyses.
The era of molecular analysis rather than descriptive features can be dated to the work of Kurashige (1988) and Kron (1997) who used matK sequencing, while Lian-Ming used ITS sequences to determine a cladistic analysis. They confirmed that the genus "Rhodendron" was monophyletic, with subgenus "Therorhodion" in the basal position, consistent with the "mat"K studies. Following publication of the studies of Goetsch "et al." with RPB2 (2005). there began an ongoing realignment of species and groups within the genus, based on evolutionary relationships. Their work was more supportive of Sleumer's original system than the later modifications introduced by Chamberlain "et al.".
The major finding of Goetsch and colleagues was that all species examined (except "R. camtschaticum", subgenus "Therorhodion") formed three major clades which they labelled A, B and C, with the subgenera "Rhododendron" and "Hymenanthes" nested within clades A and B as monophyletic groups respectively. By contrast subgenera "Azaleastrum" and "Pentanthera"
were polyphyletic, while "R. camtschaticum" appeared as a sister to all other rhododendrons. The small polyphyletic subgenera "Pentanthera" and "Azaleastrum" were divided between two clades. The four sections of "Pentanethra" between clades B and C, with two each, while "Azaleastrum" had one section in each of A and C.
Thus subgenera "Azaleastrum" and "Pentanethera" needed to be dissassembled, and "Rhododendron", "Hymenanthes" and "Tsutsusi" correspondingly expanded. In addition to the two separate genera included under "Rhododendron" by Chamberlain ("Ledum", "Tsusiophyllum"), Goetsch "et al". added "Menziesia" (Clade C). Despite a degree of paraphyly, the subgenus "Rhodendron" was otherwise untouched with regard to its three sections but four other subgenera were eliminated and one new subgenus created, leaving a total of five subgenera in all, from eight in Chamberlain's scheme. The discontinued subgenera are "Pentanethera", "Tsutsusi", "Candidastrum" and "Mumeazalea", while a new subgenus was created by elevating subgenus "Azaleastrum" section "Choniastrum" to subgenus rank.
Subgenus "Pentanethera" (deciduous azaleas) with its four sections was dismembered by eliminating two sections and redistributing the other two between the existing subgenera in clades B ("Hymenanthes") and C ("Azaleastrum"), although the name was retained in section "Pentanethera" (14 species) which was moved to subgenus "Hymenanthes". Of the remaining three sections, monotypic "Viscidula" was discontinued by moving "Rhododendron nipponicum" to "Tsutsusi" (C), while "Rhodora" (2 species) was itself polyphyletic and was broken up by moving "Rhododendron canadense" to section "Pentanethera" (B) and "Rhododendron vaseyi" to section "Sciadorhodion", which then became a new section of subgenus "Azaleastrum" (C).
Subgenus "Tsutsusi" (C) was reduced to section status retaining the name, and included in subgenus "Azaleastrum". Of the three minor subgenera, all in C, two were discontinued. The single species of monotypic subgenus "Candidastrum " ("Rhododendron albiflorum") was moved to subgenus "Azaleastrum", section "Sciadorhodion". Similarly the single species in monotypic subgenus "Mumeazalea" "(Rhododendron semibarbatum)" was placed in the new section "Tsutsusi", subgenus "Azaleastrum". Genus "Menziesa" (9 species) was also added to section "Sciadorhodion". The remaining small subgenus "Therorhodion" with its two species was left intact. Thus two subgenera, "Hymenanthes" and "Azaleastrum" were expanded at the expense of four subgenera that were eliminated, although "Azaleastrum" lost one section ("Choniastrum") as a new subgenus, since it was a distinct subclade in A. In all, "Hymenanthes" increased from one to two sections, while "Azaleastrum", by losing one section and gaining two increased from two to three sections. (See schemata under Subgenera). (Table 1.)
Subsequent research has supported the revision by Goetsch, although has largely concentrated on further defining the phylogeny within the subdivisions.(Craven 2008) In 2011 the two species of "Diplarche" were also added to "Rhododendron", "incertae sedis".(Craven 2011) Similar findings were reported independently the following year by Brown "et al".
Subdivision.
This genus has been progressively subdivided into a hierarchy of subgenus, section, subsection, and species.
Subgenera.
Terminology from the Sleumer (1949) system is frequently found in older literature, with five subgenera and is as follows;
In the later traditional classification, attributed to Chamberlain (1996), and as used by horticulturalists and the American Rhododendron Society, "Rhododendron" has eight subgenera based on morphology, namely the presence of scales (lepidote), deciduousness of leaves, and the floral and vegetative branching patterns, after Sleumer (1980). These consist of four large and four small subgenera. The first two subgenera ("Rhododendron" and "Hymenanthes") represent the species commonly considered as 'Rhododendrons'. The next two smaller subgenera ("Pentanthera" and "Tsutsusi") represent the 'Azaleas'. The remaining four subgenera contain very few species. The largest of these is subgenus "Rhododendron", containing nearly half of all known species and all of the lepidote species.
For a comparison of the Sleumer and Chamberlain systems, see Goetsch et al. (2005) Table 1.
This division was based on a number of what were thought to be key morphological characteristics. These included the position of the inflorescence buds (terminal or lateral), whether lepidote or elepidote, deciduousness of leaves, and whether new foliage was derived from axils from previous year's shoots or the lowest scaly leaves (Table 2.).
Following the cladistic analysis of Goetsch "et al." (2005) this scheme was simplified, based on the discovery of three major clades (A,B,C) as follows.
Clade A
Clade B
Clade C
Sister taxon
Sections and subsections.
The larger subgenera are further subdivided into sections and subsections Some subgenera contain only a single section, and some sections only a single subsection. Shown here is the traditional classification, with species number after Chamberlain (1996), but this scheme is undergoing constant revision. Revisions by Goetsch "et al." (2005) and by Craven et al. (2008) shown in ("parenthetical italics"). Older ranks such as Series (groups of species) are no longer used but may be found in the literature, but the American Rhododendron Society still uses a similar device, called Alliances
Distribution and habitat.
Species of the genus "Rhododendron" are widely distributed between latitudes 80°N and 20°S and are considered Alpine native plants from North America to Europe, Russia, and Asia, and from Greenland to Queensland, Australia and the Solomon Islands. The centres of diversification are in the Himalayas and Malaysia, with the greatest species diversity in the Sino-Himalayan region, Southwest China and northern Burma, from Uttarakhand, Nepal and Sikkim to northwestern Yunnan and western Sichuan and southeastern Tibet, and with other significant areas of diversity in the mountains of Korea, Japan and Taiwan. More than 90% of "Rhododendron" "sensu" Chamberlain belong to the Asian subgenera "Rhododendron", "Hymenanthes" and section "Tsutsusi". Of the first two of these, the species are predominantly found in the area of the Himalayas and Southwest China (Sino-Himalayan Region).
The 300 Tropical species within the "Vereya" section of subgenus "Rhododendron" occupy the Malay archipelago from their presumed Southeast Asian origin to Northern Australia, with 55 known species in Borneo and 164 in New Guinea. The species in New Guinea are native to subalpine moist grasslands at around 3,000 metres above sea level in the Central Highlands. Subgenera "Rhododendron" and "Hymenanthes", together with section "Pentanethera" of subgenus "Pentanethera" are also represented to a lesser degree in the Mountainous areas of North America and Western Eurasia. Subgenus "Tsutsusi" is found in the maritime regions of East Asia (Japan, Korea, Taiwan, East China), but not in North America or Eurasia.
Ecology.
Invasive species.
Some species (e.g. "Rhododendron ponticum" in Ireland and the United Kingdom) are invasive as introduced plants, spreading in woodland areas replacing the natural understory. "R. ponticum" is difficult to eradicate, as its roots can make new shoots.
Insects.
A number of insects either target rhododendrons or will opportunistically attack them. Rhododendron borers and various weevils are major pests of rhododendrons, and many caterpillars will preferentially devour them.
"Rhododendron" species are used as food plants by the larvae of some members of the order Lepidoptera (butterflies and moths) (See List of Lepidoptera that feed on rhododendrons).
Diseases.
Major diseases include "Phytophthora" root rot, stem and twig fungal dieback; Ohio State University Extension provides information on maintaining health of rhododendrons. Rhododendrons can easily be suffocated by other plants.
Cultivation.
Both species and hybrid rhododendrons (including azaleas) are used extensively as ornamental plants in landscaping in many parts of the world, including both temperate and subtemperate regions,(Craven 2008) while many species and cultivars are grown commercially for the nursery trade. Rhododendrons are often valued in landscaping for their structure, size, flowers, and the fact that many of them are evergreen. Azaleas are frequently used around foundations and occasionally as hedges, and many larger-leafed rhododendrons lend themselves well to more informal plantings and woodland gardens, or as specimen plants. In some areas, larger rhododendrons can be pruned to encourage more tree-like form, with some species such as "R. arboreum" and "R. falconeri" eventually growing to 10–15 m or more tall.
Commercial growing.
Rhododendrons are grown commercially in many areas for sale, and are occasionally collected in the wild, a practice now rare in most areas. Larger commercial growers often ship long distances; in the United States, most of them are on the west coast (Oregon, Washington state and California). Large-scale commercial growing often selects for different characteristics than hobbyist growers might want, such as resistance to root rot when overwatered, ability to be forced into budding early, ease of rooting or other propagation, and saleability.
In the Indian state of Himachal Pradesh, rhododendron flowers have been used for some time to make popular fruit and flower wines. The industry is promoted by the state government with tax benefits, looking to promote this industry as a full-fledged subclass of its economy.
Horticultural divisions.
Horticulturally, rhododendrons may be divided into the following groups:-
Planting and care.
Like other ericaceous plants, most rhododendrons prefer acid soils with a pH of roughly 4.5-5.5; some tropical Vireyas and a few other rhododendron species grow as epiphytes and require a planting mix similar to orchids. Rhododendrons have fibrous roots and prefer well-drained soils high in organic material. In areas with poorly drained or alkaline soils, rhododendrons are often grown in raised beds using media such as composted pine bark. Mulching and careful watering are important, especially before the plant is established.
A new calcium-tolerant stock of rhododendrons (trademarked as 'Inkarho') has been exhibited at the RHS Chelsea Flower Show in London (2011). Individual hybrids of rhododendrons have been grafted on to a rootstock on a single rhododendron plant that was found growing in a chalk quarry. The rootstock is able to grow in calcium-rich soil up to a pH of 7.5.
Hybrids.
Rhododendrons are extensively hybridized in cultivation, and natural hybrids often occur in areas where species ranges overlap. There are over 28,000 cultivars of Rhododendron in the International Rhododendron Registry held by the Royal Horticultural Society. Most have been bred for their flowers, but a few are of garden interest because of ornamental leaves and some for ornamental bark or stems. Some hybrids have fragrant flowers—such as the Loderi hybrids, created by crossing "R. fortunei" and "R. griffithianum". Other examples include the PJM hybrids, formed from a cross between "Rhododendron carolinianum" and "Rhododendron dauricum", and named after Peter J. Mezitt of Weston Nurseries, Massachusetts.
Uses.
Pharmacology.
"Rhododendron" species have long been used in traditional medicine.Animal studies and "in vitro" research has identified possible anti-inflammatory and hepatoprotective activities which may be due to the antioxidant effects of flavonoids or other phenolic compounds and saponins the plant contains. Xiong "et al." have found that the root of the plant is able to reduce the activity of NF-κB in rats.
Toxicology.
Some species of rhododendron are poisonous to grazing animals because of a toxin called grayanotoxin in their pollen and nectar. People have been known to become ill from eating honey made by bees feeding on rhododendron and azalea flowers. Xenophon described the odd behaviour of Greek soldiers after having consumed honey in a village surrounded by "Rhododendron ponticum" during the march of the Ten Thousand in 401 BC. Pompey's soldiers reportedly suffered lethal casualties following the consumption of honey made from "Rhododendron" deliberately left behind by Pontic forces in 67 BC during the Third Mithridatic War. Later, it was recognized that honey resulting from these plants has a slightly hallucinogenic and laxative effect. The suspect rhododendrons are "Rhododendron ponticum" and "Rhododendron luteum" (formerly "Azalea pontica"), both found in northern Asia Minor. A brief documented video of this occurring in the modern day involves a group of men in Nepal foraging for this affected honey can be found here: http://eupterrafoundation.com/hallucinogenic-honey. Eleven similar cases have been documented in Istanbul, Turkey during the 1980s. Rhododendron is extremely toxic to horses, with some animals dying within a few hours of ingesting the plant, although most horses tend to avoid it if they have access to good forage. The effects of "R. ponticum" was mentioned in the 2009 film Sherlock Holmes as a proposed way to arrange a fake execution. It was also mentioned in the third episode of Season 2 of BBC's "Sherlock", and has been speculated to have been a part of Sherlock's fake death scheme.
Culture.
Symbolism.
"Rhododendron arboreum" ("lali guransh") is the national flower of Nepal. "R. ponticum" is the state flower of Indian-administered Kashmir and Pakistan-controlled Kashmir. "Rhododendron niveum" is the state tree of Sikkim in India. Rhododendron is also the state tree of the state of Uttarakhand, India. Pink Rhododendron (Rhododendron campanulatum) is the State Flower of Himachal Pradesh, India.
"Rhododendron maximum", the most widespread rhododendron of the Appalachian Mountains, is the state flower of West Virginia, and is in the Flag of West Virginia.
"Rhododendron macrophyllum", a widespread rhododendron of the Pacific Northwest, is the state flower of Washington.
Literature.
In Joyce's "Ulysses", rhododendrons play an important role in Leopold and Molly's early courtship: Molly remembers them in her soliloquy - "the sun shines for you he said the day we were lying among the rhododendrons on Howth head in the grey tweed suit and his straw hat the day I got him to propose to me". Jasper Fforde a British author, also uses rhododendron as a motif throughout many of his published books. See Thursday Next series, and .
Amongst the Zomi tribes in India and Myanmar, "Rhododendrons" called "Ngeisok" is used in a poetic manner to signify a lady.
Culinary.
The rhododendron is the national flower of Nepal, where the flower is considered edible and enjoyed for its sour taste. The pickled flower can last for months and the flower juice is also marketed. The flower, fresh or dried, is added to fish curry in the belief that it will soften the bones.
The juice of rhododendron flower is used to make a squash called burans (named after the flower) in the hilly regions of Uttarakhand. It is admired for its distinctive flavor and color. 
Labrador tea.
Labrador tea is an herbal tea (not a true tea) made from three closely related species: 
Additional Resources.
Records of the Rhododendron Society of America reside at the Albert and Shirley Small Special Collections Library at the University of Virginia.

</doc>
<doc id="40337" url="https://en.wikipedia.org/wiki?curid=40337" title="Fetchmail">
Fetchmail

Fetchmail is an open source software utility for POSIX-compliant operating systems which is used to retrieve e-mail from a remote POP3, IMAP, ETRN or ODMR mail server to the user's local system. It was developed from the popclient program, written by Carl Harris.
Its chief significance is perhaps that its author, Eric S. Raymond, used it as a model to discuss his theories of open source software development in a widely read and influential essay on software development methodologies, "The Cathedral and the Bazaar".
Design.
By design Fetchmail's only means of delivering messages is by submitting them to the local MTA/Message transfer agent; delivering directly to mail folders such as maildir is not supported.
Dan Bernstein, getmail creator Charles Cazabon and FreeBSD developer Terry Lambert, have criticized Fetchmail's design, its number of security holes, and that it was prematurely put into "maintenance mode". In 2004, a new team of maintainers took over Fetchmail development, and laid out development plans that broke with design decisions that Eric Raymond had made in earlier versions.

</doc>
<doc id="40338" url="https://en.wikipedia.org/wiki?curid=40338" title="Mayor of London">
Mayor of London

The Mayor of London is an elected politician who, along with the London Assembly of 25 members, is accountable for the strategic government of Greater London. Conservative Boris Johnson has held the position since 4 May 2008. The position was previously held by Ken Livingstone from the creation of the role on 4 May 2000 until his succession by Johnson.
The role, created in 2000 after the London devolution referendum, was the first directly elected mayor in the United Kingdom.
The Mayor of London is the mayor of the entirety of Greater London, including the City of London, for which there is also the ceremonial Lord Mayor of the City of London. Each London Borough also has a ceremonial mayor or, in Hackney, Lewisham, Newham or Tower Hamlets, an elected mayor.
Background.
The Greater London Council, the elected governance for Greater London, was abolished in 1986 following the Local Government Act 1985. Strategic functions were split off to various joint arrangements. Londoners voted in a referendum in 1998 to create new governance structures for Greater London. The directly elected Mayor of London was created by the Greater London Authority Act 1999 in 2000 as part of the reforms.
Elections.
The Mayor is elected by the supplementary vote method for a fixed term of four years, with elections taking place in May. As with most elected posts in the UK, there is a deposit, in this case of £10,000 which is returnable on the candidate's winning at least 5% of the first-choice votes cast.
2000.
The 2000 campaign was incident-filled. The eventual winner, Ken Livingstone, went back on an earlier pledge not to run as an independent after losing the Labour nomination to Frank Dobson. The Conservative Party had to replace Lord Archer of Weston-super-Mare as their candidate when he was charged with perjury; Steve Norris was selected as his replacement.
2004.
In 2004, the second election was held. After being re-admitted to the Labour Party, Ken Livingstone was their official candidate. He won re-election after second preference votes were counted, with Steve Norris again coming second.
2008.
The incumbent Labour Mayor, Ken Livingstone was defeated by Conservative candidate Boris Johnson who became London's 2nd Mayor.
2012.
Conservative Mayor Boris Johnson was reelected to a second term in office, defeating former Labour mayor Ken Livingstone. Livingstone announced his retirement from politics in his concession speech.
2016.
The 2016 London mayoral election is scheduled for 5 May 2016.
Incumbent Mayor Boris Johnson is not running for re-election for a third term in office, as he was elected the Member of Parliament for the Conservative Party in Uxbridge and South Ruislip in the 2015 general election.
Powers and functions.
Most powers are derived from the Greater London Authority Act 1999 with additional functions coming from the Greater London Authority Act 2007, the Localism Act 2011 and Police Reform and Social Responsibility Act 2011.
The main functions are:
The remaining local government functions are performed by the London borough councils. There is some overlap, for example the borough councils are responsible for waste management, but the mayor is required to produce a waste management strategy. In 2010 the Mayor launched an initiative in partnership with the Multi-academy Trust AET to transform schools across London. This led to the establishment of London Academies Enterprise Trust (LAET) which was intended to be a group of 10 Academies, but it only reached a group of 4 before the Mayor withdrew in 2013.
Initiatives.
Ken Livingstone.
Initiatives taken by Ken Livingstone as Mayor of London included the London congestion charge on private vehicles using city centre London on weekdays, the creation of the London Climate Change Agency, the London Energy Partnership and the founding of the international Large Cities Climate Leadership Group, now known as C40 Cities Climate Leadership Group. The congestion charge led to many new buses being introduced across London. In 2003 Livingstone oversaw the introduction of the Oyster Card electronic ticketing system for Transport for London services.
They have also included the London Partnerships Register which was a voluntary scheme without legal force for same-sex couples to register their partnership, and paved the way for the introduction by the United Kingdom Parliament of civil partnerships. Unlike civil partnerships, the London Partnerships Register was open to heterosexual couples who favour a public commitment other than marriage.
As Mayor of London, Ken Livingstone was also a supporter of the London Olympics in 2012, and is known to encourage sport in London; especially when sport can be combined with helping UK charities-like The London Marathon and British 10K charity races. However, Livingstone, in a Mayoral election debate on the BBC's "Question Time" in April 2008 did state that the primary reason he supported the Olympic bid was to secure funding for the redevelopment of the East End of London. In the summer of 2007 he brought the Tour de France cycle race to London.
Boris Johnson.
In May 2008, Boris Johnson introduced a new transport safety initiative to put 440 high-visibility police officers on bus hubs and the immediate vicinity. A ban on alcohol on underground, bus, Docklands Light Railway, and tram services and stations across the capital was announced.
Also in May 2008, Boris Johnson announced the closure of "The Londoner" newspaper, saving approximately £2.9 million. A percentage of this saving will be spent on planting 10,000 new street trees.
In 2010 Boris Johnson extended the coverage of Oyster Card electronic ticketing to all National Rail overground train services 
Also in 2010 Boris Johnson opened a cycle hire scheme (originally sponsored by Barclays, now Santander) with 5,000 bicycles available for hire across London. The scheme gained the nickname of "Boris Bikes" by both Londoners and members of the various media.
In 2011 Boris Johnson set up the Outer London Fund, a money pot of up to £50 million designed to help facilitate better, more effective local high streets. Areas in London were given the chance to submit proposals for two separate pots of money, which would be granted to them if their bid was successful. Successful bids for Phase 1 included Enfield, Muswell Hill and Bexley Town Centre. The recipients of Phase 2 funding are still to be announced.
In January 2013 Boris Johnson appointed journalist Andrew Gilligan as the first Cycling Commissioner for London.
In March 2013 Boris Johnson announced £1 billion of investment in infrastructure to make cycling safer in London, including a East-West segregated 'Crossrail for bikes'.
In the General Election of 7 May 2015, Boris Johnson was elected as MP for Uxbridge and Ruislip South with 50.2% of the vote on a turnout of 63.4%. For this he receives the basic MP's salary of £67,060 per annum plus expenses to cover staff, office expenses, accommodation if he does not have a London home and travel.
Salary.
The Mayor of London's salary is £143,911 per year, which is similar to that of a government Cabinet minister.

</doc>
<doc id="40339" url="https://en.wikipedia.org/wiki?curid=40339" title="Lord Mayor of London">
Lord Mayor of London

The Lord Mayor of London is the City of London's mayor and leader of the City of London Corporation. Within the City, the Lord Mayor is accorded precedence over all individuals except the sovereign and retains various traditional powers, rights and privileges, including the title and style The Right Honourable Lord Mayor of London. 
This office differs from the "Mayor of London", which is a popularly elected position and covers the much larger Greater London area. 
In 2006 the Corporation of London changed its name to the "City of London Corporation", when the title Lord Mayor of the City of London was reintroduced, partly to avoid confusion with the Mayor of London. However, the legal and commonly-used title remains Lord Mayor of London.
The Lord Mayor is elected at "Common Hall" each year on Michaelmas, and takes office on the Friday before the second Saturday in November, at "The Silent Ceremony".
The Lord Mayor's Show is held on the day after taking office; the Lord Mayor, preceded by a procession, travels to the Royal Courts of Justice at the Strand to swear allegiance to the sovereign before the Justices of the High Court.
One of the world's oldest continuously elected civic offices, the Lord Mayor's main role nowadays is to represent, support and promote the businesses and residents in the City of London. Today, these businesses are mostly in the financial sector and the Lord Mayor is regarded as the champion of the entire UK-based financial sector regardless of ownership or location throughout the country. As Leader of the Corporation of the City of London, the Lord Mayor serves as the key spokesman for the local authority and also has important ceremonial and social responsibilities. All Lord Mayors of London are apolitical. 
The Lord Mayor of London typically delivers dozens of speeches and addresses per year, and attends many receptions and other events in London and beyond. Many incumbents of the office make overseas visits while Lord Mayor of London. The Lord Mayor, also "ex-officio" Chancellor of London's City University, is assisted in day-to-day administration by the Mansion House staff who are senior administrative personnel in the Corporation of London and whose titles include the Town Clerk and Chief Executive to Chamberlain and Remembrancer.
The present Lord Mayor is Jeffrey Evans (for 2015-16).
Titles and honours.
Of the 69 cities in the United Kingdom, the City of London is among the 30 that have Lord Mayors (or, in Scotland, Lords Provost). The Lord Mayor is entitled to the style The Right Honourable; the same privilege extends only to the Lord Mayors of York, Cardiff and Belfast, and to the Lords Provost of Edinburgh and Glasgow. The style, however, is used when referring to the office as opposed to the holder thereof; thus, "The Rt Hon Lord Mayor of London" would be correct, while "The Rt Hon Jeffrey Mountevans" would be incorrect. The latter prefix applies only to Privy Counsellors.
A woman who holds the office is also known as a Lord Mayor. The wife of a male Lord Mayor is styled as Lady Mayoress, but no equivalent title exists for the husband of a female Lord Mayor. A female Lord Mayor or an unmarried male Lord Mayor may appoint a female consort, usually a fellow member of the corporation, to the role of Lady Mayoress. In speech, a Lord Mayor is referred to as "My Lord Mayor", and a Lady Mayoress as "My Lady Mayoress".
It was once customary for Lord Mayors to be appointed knights upon taking office and baronets upon retirement, unless they already held such a title. This custom was followed with a few inconsistencies from the 16th until the 19th centuries; creations became more regular from 1889 onwards. However, from 1964 onwards, the regular creation of hereditary titles such as baronetcies was phased out, so subsequent Lord Mayors were offered knighthoods (and, until 1993, most often as Knight Grand Cross of the Order of the British Empire (GBE)). Since 1993, Lord Mayors have not automatically received any national honour upon appointment; instead, they have been made Knights Bachelor upon retirement, although Gordon Brown's Government broke with that tradition by making Ian Luder a CBE, after his term of office in 2009, and the following year Nick Anstee declined offers of an honour. Furthermore, foreign Heads of State visiting the City of London on a UK State Visit, diplomatically bestow upon the Lord Mayor one of their suitable national honours. For example, in 2001, Sir David Howard was created a Grand Cordon (First Class) of the Order of Independence of Jordan by King Abdullah II. Recently Lord Mayors have been appointed at the beginning of their term of office Knights or Dames of St John, as a mark of respect, by HM The Queen, Sovereign Head of the Order of St John.
History.
The office of Lord Mayor was instituted in 1189, the first holder of the office being Henry Fitz-Ailwin de Londonestone. The Mayor of the City of London has been elected by the City, rather than appointed by the Sovereign, ever since a Royal Charter providing for a Mayor was issued by King John in 1215. The title "Lord Mayor" came to be used after 1354, when it was granted to Thomas Legge (then serving his second of two terms) by King Edward III.
Lord Mayors are elected for one-year terms; by custom, they do not now serve more than one consecutive term. Numerous individuals have served multiple terms in office, including:<br>
As Mayor:
As Lord Mayor:
The last individual to serve multiple terms was Sir Robert Fowler (elected in 1883 and in 1885).
Almost 700 people have served as Lord Mayor. Dame Mary Donaldson, elected in 1983, and Dame Fiona Woolf, elected in 2013, are the only women to have held the office.
Some Lord Mayors in the Middle Ages, such as Sir Edward Dalyngrigge (1392), did not reside in London. Since 1435, the Lord Mayor has been chosen from amongst the Aldermen of the City of London.
Election.
The Lord Mayor is elected at Common Hall, comprising liverymen belonging to all of the City's livery companies. Common Hall is summoned by the sitting Lord Mayor; it meets at Guildhall on Michaelmas Day (29 September) or on the closest weekday. Voting is by show of hands; if, however, any liveryman so demands, balloting is held a fortnight later.
The qualification to stand for election is that one must have served as a City Sheriff and be a current Alderman. Since 1385, prior service as Sheriff has been mandatory for election to the Lord Mayoralty. Two Sheriffs are selected annually by Common Hall, which meets on Midsummer's Day for this purpose. By an ordinance of 1435, the Lord Mayor must be chosen from amongst the Aldermen of the City of London. Those on the electoral roll of each of the City's 25 Wards select one Alderman, who formerly held office for life or until resignation. Now each Alderman must submit for re-election at least once in every six years.
The Lord Mayor is then sworn in November, on the day before the Lord Mayor's Show ("see below"). The ceremony is known as the "Silent Ceremony" because, aside from a short declaration by the incoming Lord Mayor, no speeches are made. At Guildhall, the outgoing Lord Mayor transfers the mayoral insignia — the seal, the purse, the sword and the mace — to the incoming Lord Mayor.
Lord Mayor's Show.
The day after being sworn in to office, the Lord Mayor leads a procession from the City of London to the Royal Courts of Justice in the City of Westminster, where the Lord Mayor swears allegiance to the Crown. This pageantry has evolved into one of London's longest-running and most popular annual events, known as the "Lord Mayor's Show". The Lord Mayor travels in the City's state coach that was built in 1757 at a cost of £1,065.0s.3d. Nowadays, this festival combines traditional British pageantry with the element of carnival, and since 1959 it has been held on the second Saturday in November. Participants include the livery companies, bands and members of the military, charities and schools. In the evening, a fireworks display is held.
Role.
The Lord Mayor is a member of the City of London's governing body, the City of London Corporation (incorporated as "The Mayor and Commonalty and Citizens of the City of London"). The Corporation comprises the Court of Aldermen and the Court of Common Council; the former includes only the Aldermen, while the latter includes both Aldermen and Common Councilmen. The Lord Mayor belongs to and presides over both bodies.
As noted earlier, the main role of the Lord Mayor is to represent, support and promote all aspects of UK-financial service industries, including maritime. They undertake this as head of the City of London Corporation and, during the year, host visiting foreign government ministers, businessmen and dignitaries; furthermore, they conduct several foreign visits of their own so as to promote British financial sectors.
Banquets hosted by the Lord Mayor serve as opportunities for senior Government figures to deliver major speeches. At the Lord Mayor's Banquet (held on the Monday after the Lord Mayor's Show), the Prime Minister delivers the keynote address. At the Banker's Dinner in June, the Chancellor of the Exchequer delivers a speech known as the "Mansion House Speech", which takes its name from the Lord Mayor's residence. At the Easter Banquet, also hosted each year at the Mansion House, the Foreign Secretary addresses an audience of international dignitaries.
The Lord Mayor sometimes takes part in major state occasions, for example in 2013, the then-Lord Mayor, Roger Gifford carried the Sword of Mourning at Margaret Thatcher's Funeral, processing ahead of the Queen and Prince Philip, Duke of Edinburgh, into St Paul's Cathedral.
The Lord Mayor performs numerous other functions, including serving as the Chief Magistrate of the City of London, Admiral of the Port of London, Chancellor of City University, President of Gresham College, President of City of London Reserve Forces and Cadets Association, and Trustee of St Paul's Cathedral. The Lord Mayor also heads the City's Commission of Lieutenancy, which represents the Sovereign in the City of London (other counties usually have Lord Lieutenants, as opposed to Commissions), and annually attends the Treloar Trust (named after Sir William Treloar, Lord Mayor in 1906), in Hampshire. The Treloar Trust runs two educational sites for disabled children, a school and college.
Rights and privileges.
The residence of the Lord Mayor is known as Mansion House. The creation of the residence was considered after the Great Fire of London (1666), but construction did not commence until 1739. It was first occupied by a Lord Mayor in 1752, when Sir Crispin Gascoigne took up residence.
In each of the eighteen courtrooms of the Old Bailey, the centre of the judges' bench is reserved for the Lord Mayor, in his capacity of Chief Justice of the City of London. The presiding judge therefore sits to one side.
It is sometimes asserted that the Lord Mayor may exclude the monarch from the City of London. The legend is based on the misinterpretation of the ceremony observed each time the sovereign enters the City. At Temple Bar the Lord Mayor presents the City's pearl-encrusted sword of state to the sovereign as a symbol of the latter's overlordship. The monarch does not, as is often purported, wait for the Lord Mayor's permission to enter the City. When the sovereign enters the city, a short ceremony usually takes place where the Lord Mayor symbolically surrenders his or her authority to the monarch by presenting the sword to them. If the sovereign is attending a service at St Paul's this ceremony would take place there rather than at the boundary of the City for matters of convenience.
The importance of the office is reflected by the composition of the Accession Council, a body which proclaims the accession of new Sovereigns. The Council includes the Lord Mayor and Aldermen of London, as well as members of the House of Lords and Privy Counsellors. At the coronation banquet which followed, the Lord Mayor of the City of London had the right to assist the Royal Butler. The same privilege is held by the Lord Mayor of Oxford; the Mayor of Winchester may assist the Royal Cook. Such privileges have not been exercised since 1821, when the last coronation banquet (commemorating the coronation of George IV) was held.
Official dress.
The Lord Mayor still continues to wear a form of court dress long abandoned by many modern day officials on a regular, almost daily, basis. Their basic under dress is of the traditional black velvet court dress (old style) consisting of a coat, waistcoat and knee breeches with steel cut buttons. This is worn with black silk stockings, patent court shoes with steel buckles, white shirt with lace cuffs and a large jabot stock. This form of court dress is worn by all Lord Mayors regardless of gender.
Over his or her underdress for ceremonial occasions is worn a black silk damask robe trimmed with gold lace of a design exactly the same as that of the Lord Chancellor, known as the Entertaining Gown. When outdoors, they wear a black beaver plush tricorne hat trimmed with white (or black in the event of memorials and funerals) ostrich feathers and a steel 'loop' for the cockade. This has been traditionally made by Patey's commissioned by the Worshipful Company of Feltmakers for each incumbent Lord Mayor.
For State occasions when the monarch is present, the Lord Mayor, instead of the gold-lace robe, wears a crimson velvet cape trimmed with an ermine cape and facings that have black sealskin spots on, very similar to a royal earl's coronation robe. It is tied with gold cordons, and dates from the reign of George IV.
Since 1545 the Lord Mayor of London has worn a Royal Livery Collar of Esses. However, the collar's origins are not royal, Sir John Alleyn, thrice Lord Mayor, having bequeathed it to the next Lord Mayor and his successors "to use and occupie yerely at and uppon principall and festivall dayes." It was enlarged in 1567, and in its present shape has 28 Esses (the Lancastrian ‘S’), Tudor roses and the tasselled knots of the Garter (alternating) and also the Portcullis, from which hangs the Mayoral Jewel. The collar is worn over whatever the Lord Mayor maybe wearing, secured onto their underdress or State Robes by means of black or white silk satin ribbons on the shoulders.
At coronations, the Lord Mayor wears a special coronation robe made especially for the incumbent by Ede & Ravenscroft. This is a cape-like mantle of scarlet superfine wool trimmed with bars of gold lace and ermine spotted with black sealskin. It is lined with white silk satin; they also carry a baton of office. After the coronation, the incumbent may personally keep their coronation robe as a token.
The Lord Mayor's wardrobe also includes a scarlet gown and a violet gown, which are "aldermanic" and worn only at certain meetings of the Corporation of London as directed by the City Ceremonial Book. There is also a plain black gown, worn by the Lord Mayor in times of national mourning and/or grief.

</doc>
<doc id="40343" url="https://en.wikipedia.org/wiki?curid=40343" title="Prehnite">
Prehnite

Prehnite is an inosilicate of calcium and aluminium with the formula: Ca2Al(AlSi3O10)(OH)2. Limited Fe3+ substitutes for aluminium in the structure. Prehnite crystallizes in the orthorhombic crystal system, and most oftens forms as stalactitic or botryoidal aggregates, with only just the crests of small crystals showing any faces, which are almost always curved or composite. Very rarely will it form distinct, well individualized crystals showing a square-like cross-section, including those found at the Jeffrey Mine in Asbestos, Quebec, Canada. It is brittle with an uneven fracture and a vitreous to pearly luster. Its hardness is 6-6.5, its specific gravity is 2.80-2.90 and its color varies from light green to yellow, but also colorless, blue, pink or white. In April 2000, a rare orange Prehnite was discovered at the famous Kalahari Manganese Fields in South Africa. It is mostly translucent, and rarely transparent.
Though not a zeolite, it is found associated with minerals such as datolite, calcite, apophyllite, stilbite, laumontite, heulandite etc. in veins and cavities of basaltic rocks, sometimes in granites, syenites, or gneisses. It is an indicator mineral of the prehnite-pumpellyite metamorphic facies. 
It was first described in 1788 for an occurrence in the Karoo dolerites of Cradock, Eastern Cape Province, South Africa. It was named for Colonel Hendrik Von Prehn (1733–1785), commander of the military forces of the Dutch colony at the Cape of Good Hope from 1768 to 1780.
Extensive deposits of gem quality prehnite occur in the basalt tableland surrounding Wave Hill Station in the central Northern Territory, of Australia.

</doc>
<doc id="40344" url="https://en.wikipedia.org/wiki?curid=40344" title="Semiconductor device">
Semiconductor device

Semiconductor devices are electronic components that exploit the electronic properties of semiconductor materials, principally silicon, germanium, and gallium arsenide, as well as organic semiconductors. Semiconductor devices have replaced thermionic devices (vacuum tubes) in most applications. They use electronic conduction in the solid state as opposed to the gaseous state or thermionic emission in a high vacuum.
Semiconductor devices are manufactured both as single discrete devices and as "integrated circuits" (ICs), which consist of a number—from a few (as low as two) to billions—of devices manufactured and interconnected on a single semiconductor substrate, or wafer.
Semiconductor materials are useful because their behavior can be easily manipulated by the addition of impurities, known as doping. Semiconductor conductivity can be controlled by the introduction of an electric or magnetic field, by exposure to light or heat, or by the mechanical deformation of a doped monocrystalline grid; thus, semiconductors can make excellent sensors. Current conduction in a semiconductor occurs via mobile or "free" "electrons" and "holes", collectively known as "charge carriers". Doping a semiconductor such as silicon with a small amount of impurity atoms, such as phosphorus or boron, greatly increases the number of free electrons or holes within the semiconductor. When a doped semiconductor contains excess holes it is called "p-type", and when it contains excess free electrons it is known as "n-type", where "p" (positive for holes) or "n" (negative for electrons) is the sign of the charge of the majority mobile charge carriers. The semiconductor material used in devices is doped under highly controlled conditions in a fabrication facility, or "fab", to control precisely the location and concentration of p- and n-type dopants. The junctions which form where n-type and p-type semiconductors join together are called p–n junctions.
Diode.
A semiconductor diode is a device typically made from a single p–n junction. At the junction of a p-type and an n-type semiconductor there forms a depletion region where current conduction is inhibited by the lack of mobile charge carriers. When the device is "forward biased" (connected with the p-side at higher electric potential than the n-side), this depletion region is diminished, allowing for significant conduction, while only very small current can be achieved when the diode is "reverse biased" and thus the depletion region expanded.
Exposing a semiconductor to light can generate electron–hole pairs, which increases the number of free carriers and thereby the conductivity. Diodes optimized to take advantage of this phenomenon are known as "photodiodes".
Compound semiconductor diodes can also be used to generate light, as in light-emitting diodes and laser diodes.
Transistor.
Bipolar junction transistors are formed from two p–n junctions, in either n–p–n or p–n–p configuration. The middle, or "base", region between the junctions is typically very narrow. The other regions, and their associated terminals, are known as the "emitter" and the "collector". A small current injected through the junction between the base and the emitter changes the properties of the base-collector junction so that it can conduct current even though it is reverse biased. This creates a much larger current between the collector and emitter, controlled by the base-emitter current.
Another type of transistor, the field-effect transistor, operates on the principle that semiconductor conductivity can be increased or decreased by the presence of an electric field. An electric field can increase the number of free electrons and holes in a semiconductor, thereby changing its conductivity. The field may be applied by a reverse-biased p–n junction, forming a "junction field-effect transistor" (JFET) or by an electrode insulated from the bulk material by an oxide layer, forming a "metal–oxide–semiconductor field-effect transistor" (MOSFET).
The MOSFET, a solid-state device, is the most used semiconductor device today. The "gate" electrode is charged to produce an electric field that controls the conductivity of a "channel" between two terminals, called the "source" and "drain". Depending on the type of carrier in the channel, the device may be an "n-channel" (for electrons) or a "p-channel" (for holes) MOSFET. Although the MOSFET is named in part for its "metal" gate, in modern devices polysilicon is typically used instead.
Semiconductor device materials.
By far, silicon (Si) is the most widely used material in semiconductor devices. Its combination of low raw material cost, relatively simple processing, and a useful temperature range makes it currently the best compromise among the various competing materials. Silicon used in semiconductor device manufacturing is currently fabricated into boules that are large enough in diameter to allow the production of 300 mm (12 in.) wafers.
Germanium (Ge) was a widely used early semiconductor material but its thermal sensitivity makes it less useful than silicon. Today, germanium is often alloyed with silicon for use in very-high-speed SiGe devices; IBM is a major producer of such devices.
Gallium arsenide (GaAs) is also widely used in high-speed devices but so far, it has been difficult to form large-diameter boules of this material, limiting the wafer diameter to sizes significantly smaller than silicon wafers thus making mass production of GaAs devices significantly more expensive than silicon.
Other less common materials are also in use or under investigation.
Silicon carbide (SiC) has found some application as the raw material for blue light-emitting diodes (LEDs) and is being investigated for use in semiconductor devices that could withstand very high operating temperatures and environments with the presence of significant levels of ionizing radiation. IMPATT diodes have also been fabricated from SiC.
Various indium compounds (indium arsenide, indium antimonide, and indium phosphide) are also being used in LEDs and solid state laser diodes. Selenium sulfide is being studied in the manufacture of photovoltaic solar cells.
The most common use for organic semiconductors is Organic light-emitting diodes.
List of common semiconductor devices.
"Two-terminal devices:"
"Three-terminal devices:"
"Four-terminal devices:"
Semiconductor device applications.
All transistor types can be used as the building blocks of logic gates, which are fundamental in the design of digital circuits. In digital circuits like microprocessors, transistors act as on-off switches; in the MOSFET, for instance, the voltage applied to the gate determines whether the switch is on or off.
Transistors used for analog circuits do not act as on-off switches; rather, they respond to a continuous range of inputs with a continuous range of outputs. Common analog circuits include amplifiers and oscillators.
Circuits that interface or translate between digital circuits and analog circuits are known as mixed-signal circuits.
Power semiconductor devices are discrete devices or integrated circuits intended for high current or high voltage applications. Power integrated circuits combine IC technology with power semiconductor technology, these are sometimes referred to as "smart" power devices. Several companies specialize in manufacturing power semiconductors.
Component identifiers.
The type designators of semiconductor devices are often manufacturer specific. Nevertheless, there have been attempts at creating standards for type codes, and a subset of devices follow those. For discrete devices, for example, there are three standards: JEDEC JESD370B in United States, Pro Electron in Europe and Japanese Industrial Standards (JIS) in Japan.
History of semiconductor device development.
Cat's-whisker detector.
Semiconductors had been used in the electronics field for some time before the invention of the transistor. Around the turn of the 20th century they were quite common as detectors in radios, used in a device called a "cat's whisker" developed by Jagadish Chandra Bose and others. These detectors were somewhat troublesome, however, requiring the operator to move a small tungsten filament (the whisker) around the surface of a galena (lead sulfide) or carborundum (silicon carbide) crystal until it suddenly started working. Then, over a period of a few hours or days, the cat's whisker would slowly stop working and the process would have to be repeated. At the time their operation was completely mysterious. After the introduction of the more reliable and amplified vacuum tube based radios, the cat's whisker systems quickly disappeared. The "cat's whisker" is a primitive example of a special type of diode still popular today, called a Schottky diode...
Metal rectifier.
Another early type of semiconductor device is the metal rectifier in which the semiconductor is copper oxide or selenium. Westinghouse Electric (1886) was a major manufacturer of these rectifiers.
World War II.
During World War II, radar research quickly pushed radar receivers to operate at ever higher frequencies and the traditional tube based radio receivers no longer worked well. The introduction of the cavity magnetron from Britain to the United States in 1940 during the Tizard Mission resulted in a pressing need for a practical high-frequency amplifier. 
On a whim, Russell Ohl of Bell Laboratories decided to try a cat's whisker. By this point they had not been in use for a number of years, and no one at the labs had one. After hunting one down at a used radio store in Manhattan, he found that it worked much better than tube-based systems.
Ohl investigated why the cat's whisker functioned so well. He spent most of 1939 trying to grow more pure versions of the crystals. He soon found that with higher quality crystals their finicky behaviour went away, but so did their ability to operate as a radio detector. One day he found one of his purest crystals nevertheless worked well, and interestingly, it had a clearly visible crack near the middle. However as he moved about the room trying to test it, the detector would mysteriously work, and then stop again. After some study he found that the behaviour was controlled by the light in the room–more light caused more conductance in the crystal. He invited several other people to see this crystal, and Walter Brattain immediately realized there was some sort of junction at the crack.
Further research cleared up the remaining mystery. The crystal had cracked because either side contained very slightly different amounts of the impurities Ohl could not remove–about 0.2%. One side of the crystal had impurities that added extra electrons (the carriers of electric current) and made it a "conductor". The other had impurities that wanted to bind to these electrons, making it (what he called) an "insulator". Because the two parts of the crystal were in contact with each other, the electrons could be pushed out of the conductive side which had extra electrons (soon to be known as the "emitter") and replaced by new ones being provided (from a battery, for instance) where they would flow into the insulating portion and be collected by the whisker filament (named the "collector"). However, when the voltage was reversed the electrons being pushed into the collector would quickly fill up the "holes" (the electron-needy impurities), and conduction would stop almost instantly. This junction of the two crystals (or parts of one crystal) created a solid-state diode, and the concept soon became known as semiconduction. The mechanism of action when the diode is off has to do with the separation of charge carriers around the junction. This is called a "depletion region".
Development of the diode.
Armed with the knowledge of how these new diodes worked, a vigorous effort began to learn how to build them on demand. Teams at Purdue University, Bell Labs, MIT, and the University of Chicago all joined forces to build better crystals. Within a year germanium production had been perfected to the point where military-grade diodes were being used in most radar sets.
Development of the transistor.
After the war, William Shockley decided to attempt the building of a triode-like semiconductor device. He secured funding and lab space, and went to work on the problem with Brattain and John Bardeen.
The key to the development of the transistor was the further understanding of the process of the electron mobility in a semiconductor. It was realized that if there were some way to control the flow of the electrons from the emitter to the collector of this newly discovered diode, an amplifier could be built. For instance, if contacts are placed on both sides of a single type of crystal, current will not flow between them through the crystal. However if a third contact could then "inject" electrons or holes into the material, current would flow.
Actually doing this appeared to be very difficult. If the crystal were of any reasonable size, the number of electrons (or holes) required to be injected would have to be very large, making it less than useful as an amplifier because it would require a large injection current to start with. That said, the whole idea of the crystal diode was that the crystal itself could provide the electrons over a very small distance, the depletion region. The key appeared to be to place the input and output contacts very close together on the surface of the crystal on either side of this region.
Brattain started working on building such a device, and tantalizing hints of amplification continued to appear as the team worked on the problem. Sometimes the system would work but then stop working unexpectedly. In one instance a non-working system started working when placed in water. Ohl and Brattain eventually developed a new branch of quantum mechanics, which became known as surface physics, to account for the behaviour. The electrons in any one piece of the crystal would migrate about due to nearby charges. Electrons in the emitters, or the "holes" in the collectors, would cluster at the surface of the crystal where they could find their opposite charge "floating around" in the air (or water). Yet they could be pushed away from the surface with the application of a small amount of charge from any other location on the crystal. Instead of needing a large supply of injected electrons, a very small number in the right place on the crystal would accomplish the same thing.
Their understanding solved the problem of needing a very small control area to some degree. Instead of needing two separate semiconductors connected by a common, but tiny, region, a single larger surface would serve. The electron-emitting and collecting leads would both be placed very close together on the top, with the control lead placed on the base of the crystal. When current flowed through this "base" lead, the electrons or holes would be pushed out, across the block of semiconductor, and collect on the far surface. As long as the emitter and collector were very close together, this should allow enough electrons or holes between them to allow conduction to start.
The first transistor.
The Bell team made many attempts to build such a system with various tools, but generally failed. Setups where the contacts were close enough were invariably as fragile as the original cat's whisker detectors had been, and would work briefly, if at all. Eventually they had a practical breakthrough. A piece of gold foil was glued to the edge of a plastic wedge, and then the foil was sliced with a razor at the tip of the triangle. The result was two very closely spaced contacts of gold. When the wedge was pushed down onto the surface of a crystal and voltage applied to the other side (on the base of the crystal), current started to flow from one contact to the other as the base voltage pushed the electrons away from the base towards the other side near the contacts. The point-contact transistor had been invented.
While the device was constructed a week earlier, Brattain's notes describe the first demonstration to higher-ups at Bell Labs on the afternoon of 23 December 1947, often given as the birthdate of the transistor. what is now known as the "p–n–p point-contact germanium transistor" operated as a speech amplifier with a power gain of 18 in that trial. John Bardeen, Walter Houser Brattain, and William Bradford Shockley were awarded the 1956 Nobel Prize in physics for their work.
Origin of the term "transistor".
Bell Telephone Laboratories needed a generic name for their new invention: "Semiconductor Triode", "Solid Triode", "Surface States Triode" , "Crystal Triode" and "Iotatron" were all considered, but "transistor", coined by John R. Pierce, won an internal ballot. The rationale for the name is described in the following extract from the company's Technical Memoranda (May 28, 1948) calling for votes:
Transistor. This is an abbreviated combination of the words "transconductance" or "transfer", and "varistor". The device logically belongs in the varistor family, and has the transconductance or transfer impedance of a device having gain, so that this combination is descriptive.
Improvements in transistor design.
Shockley was upset about the device being credited to Brattain and Bardeen, who he felt had built it "behind his back" to take the glory. Matters became worse when Bell Labs lawyers found that some of Shockley's own writings on the transistor were close enough to those of an earlier 1925 patent by Julius Edgar Lilienfeld that they thought it best that his name be left off the patent application.
Shockley was incensed, and decided to demonstrate who was the real brains of the operation. A few months later he invented an entirely new, considerably more robust, type of transistor with a layer or 'sandwich' structure. This structure went on to be used for the vast majority of all transistors into the 1960s, and evolved into the bipolar junction transistor.
With the fragility problems solved, a remaining problem was purity. Making germanium of the required purity was proving to be a serious problem, and limited the yield of transistors that actually worked from a given batch of material. Germanium's sensitivity to temperature also limited its usefulness. Scientists theorized that silicon would be easier to fabricate, but few investigated this possibility. Gordon K. Teal was the first to develop a working silicon transistor, and his company, the nascent Texas Instruments, profited from its technological edge. From the late 1960s most transistors were silicon-based. Within a few years transistor-based products, most notably easily portable radios, were appearing on the market. 
A major improvement in manufacturing yield came when a chemist advised the companies fabricating semiconductors to use distilled rather than tap water: calcium ions present in tap water were the cause of the poor yields. "Zone melting", a technique using a band of molten material moving through the crystal, further increased crystal purity.

</doc>
<doc id="40345" url="https://en.wikipedia.org/wiki?curid=40345" title="MOSFET">
MOSFET

The metal–oxide–semiconductor field-effect transistor (MOSFET, MOS-FET, or MOS FET) is a type of transistor used for amplifying or switching electronic signals.
Although the MOSFET is a four-terminal device with source (S), gate (G), drain (D), and body (B) terminals, the body (or substrate) of the MOSFET is often connected to the source terminal, making it a three-terminal device like other field-effect transistors. Because these two terminals are normally connected to each other (short-circuited) internally, only three terminals appear in electrical diagrams. The MOSFET is by far the most common transistor in both digital and analog circuits, though the bipolar junction transistor was at one time much more common.
The main advantage of a MOSFET over a regular transistor is that it requires very little current to turn on (less than 1mA), while delivering a much higher current to a load (10 to 50 times or more).
In "enhancement mode" MOSFETs, a voltage drop across the oxide induces a conducting channel between the source and drain contacts "via" the field effect. The term "enhancement mode" refers to the increase of conductivity with increase in oxide field that adds carriers to the channel, also referred to as the "inversion layer". The channel can contain electrons (called an nMOSFET or nMOS), or holes (called a pMOSFET or pMOS), opposite in type to the substrate, so nMOS is made with a p-type substrate, and pMOS with an n-type substrate (see article on semiconductor devices). In the less common "depletion mode" MOSFET, detailed later on, the channel consists of carriers in a surface impurity layer of opposite type to the substrate, and conductivity is decreased by application of a field that depletes carriers from this surface layer.
The "metal" in the name MOSFET is now often a misnomer because the previously metal gate material is now often a layer of polysilicon (polycrystalline silicon). Aluminium had been the gate material until the mid-1970s, when polysilicon became dominant, due to its capability to form self-aligned gates. Metallic gates are regaining popularity, since it is difficult to increase the speed of operation of transistors without metal gates.
Likewise, the "oxide" in the name can be a misnomer, as different dielectric materials are used with the aim of obtaining strong channels with smaller applied voltages.
An insulated-gate field-effect transistor or IGFET is a related term almost synonymous with MOSFET. The term may be more inclusive, since many "MOSFETs" use a gate that is not metal, and a gate insulator that is not oxide. Another synonym is MISFET for metal–insulator–semiconductor FET.
The basic principle of the field-effect transistor was first patented by Julius Edgar Lilienfeld in 1925.
Composition.
Usually the semiconductor of choice is silicon, but some chip manufacturers, most notably IBM and Intel, recently started using a chemical compound of silicon and germanium (SiGe) in MOSFET channels. Unfortunately, many semiconductors with better electrical properties than silicon, such as gallium arsenide, do not form good semiconductor-to-insulator interfaces, and thus are not suitable for MOSFETs. Research continues on creating insulators with acceptable electrical characteristics on other semiconductor material.
In order to overcome the increase in power consumption due to gate current leakage, a high-κ dielectric is used instead of silicon dioxide for the gate insulator, while polysilicon is replaced by metal gates (see Intel announcement).
The gate is separated from the channel by a thin insulating layer, traditionally of silicon dioxide and later of silicon oxynitride. Some companies have started to introduce a high-κ dielectric + metal gate combination in the 45 nanometer node.
When a voltage is applied between the gate and body terminals, the electric field generated penetrates through the oxide and creates an "inversion layer" or "channel" at the semiconductor-insulator interface. The inversion channel is of the same type, p-type or n-type, as the source and drain, and thus it provides a channel through which current can pass. Varying the voltage between the gate and body modulates the conductivity of this layer and thereby controls the current flow between drain and source. This is known as enhancement mode.
Circuit symbols.
A variety of symbols are used for the MOSFET. The basic design is generally a line for the channel with the source and drain leaving it at right angles and then bending back at right angles into the same direction as the channel. Sometimes three line segments are used for enhancement mode and a solid line for depletion mode (see depletion and enhancement modes). Another line is drawn parallel to the channel for the gate.
The "bulk" or "body" connection, if shown, is shown connected to the back of the channel with an arrow indicating pMOS or nMOS. Arrows always point from P to N, so an NMOS (N-channel in P-well or P-substrate) has the arrow pointing in (from the bulk to the channel). If the bulk is connected to the source (as is generally the case with discrete devices) it is sometimes angled to meet up with the source leaving the transistor. If the bulk is not shown (as is often the case in IC design as they are generally common bulk) an inversion symbol is sometimes used to indicate PMOS, alternatively an arrow on the source may be used in the same way as for bipolar transistors (out for nMOS, in for pMOS).
Comparison of enhancement-mode and depletion-mode MOSFET symbols, along with JFET symbols. The orientation of the symbols, (most significantly the position of source relative to drain) is such that more positive voltages appear higher on the page than less positive voltages, implying current flowing "down" the page:
In schematics where G, S, D are not labeled, the detailed features of the symbol indicate which terminal is source and which is drain. For enhancement-mode and depletion-mode MOSFET symbols (in columns two and five), the source terminal is the one connected to the triangle. Additionally, in this diagram, the gate is shown as an "L" shape, whose input leg is closer to S than D, also indicating which is which. However, these symbols are often drawn with a "T" shaped gate (as elsewhere on this page), so it is the triangle which must be relied upon to indicate the source terminal.
For the symbols in which the bulk, or body, terminal is shown, it is here shown internally connected to the source (i.e., the black triangles in the diagrams in columns 2 and 5). This is a typical configuration, but by no means the only important configuration. In general, the MOSFET is a four-terminal device, and in integrated circuits many of the MOSFETs share a body connection, not necessarily connected to the source terminals of all the transistors.
MOSFET operation.
Metal–oxide–semiconductor structure.
The traditional metal–oxide–semiconductor (MOS) structure is obtained by growing a layer of silicon dioxide (2) on top of a silicon substrate and depositing a layer of metal or polycrystalline silicon (the latter is commonly used). As the silicon dioxide is a dielectric material, its structure is equivalent to a planar capacitor, with one of the electrodes replaced by a semiconductor.
When a voltage is applied across a MOS structure, it modifies the distribution of charges in the semiconductor. If we consider a p-type semiconductor (with formula_1 the density of acceptors, "p" the density of holes; "p = NA" in neutral bulk), a positive voltage, formula_2, from gate to body (see figure) creates a depletion layer by forcing the positively charged holes away from the gate-insulator/semiconductor interface, leaving exposed a carrier-free region of immobile, negatively charged acceptor ions (see doping (semiconductor)). If formula_2 is high enough, a high concentration of negative charge carriers forms in an inversion layer located in a thin layer next to the interface between the semiconductor and the insulator. Unlike the MOSFET, where the inversion layer electrons are supplied rapidly from the source/drain electrodes, in the MOS capacitor they are produced much more slowly by thermal generation through carrier generation and recombination centers in the depletion region. Conventionally, the gate voltage at which the volume density of electrons in the inversion layer is the same as the volume density of holes in the body is called the threshold voltage. When the voltage between transistor gate and source (VGS) exceeds the threshold voltage (Vth), it is known as overdrive voltage.
This structure with p-type body is the basis of the n-type MOSFET, which requires the addition of an n-type source and drain regions.
MOSFET structure and channel formation.
A metal–oxide–semiconductor field-effect transistor (MOSFET) is based on the modulation of charge concentration by a MOS capacitance between a body electrode and a gate electrode located above the body and insulated from all other device regions by a gate dielectric layer which in the case of a MOSFET is an oxide, such as silicon dioxide. If dielectrics other than an oxide such as silicon dioxide (often referred to as oxide) are employed the device may be referred to as a metal–insulator–semiconductor FET (MISFET). Compared to the MOS capacitor, the MOSFET includes two additional terminals (source and drain), each connected to individual highly doped regions that are separated by the body region. These regions can be either p or n type, but they must both be of the same type, and of opposite type to the body region. The source and drain (unlike the body) are highly doped as signified by a "+" sign after the type of doping.
If the MOSFET is an n-channel or nMOS FET, then the source and drain are "n+" regions and the body is a "p" region. If the MOSFET is a p-channel or pMOS FET, then the source and drain are "p+" regions and the body is a "n" region. The source is so named because it is the source of the charge carriers (electrons for n-channel, holes for p-channel) that flow through the channel; similarly, the drain is where the charge carriers leave the channel.
The occupancy of the energy bands in a semiconductor is set by the position of the Fermi level relative to the semiconductor energy-band edges. 
depletion.
As described above, and shown in the figure, with sufficient gate voltage, the valence band edge is driven far from the Fermi level, and holes from the body are driven away from the gate. 
inversion.
At larger gate bias still, near the semiconductor surface the conduction band edge is brought close to the Fermi level, populating the surface with electrons in an "inversion layer" or "n-channel" at the interface between the p region and the oxide. This conducting channel extends between the source and the drain, and current is conducted through it when a voltage is applied between the two electrodes. Increasing the voltage on the gate leads to a higher electron density in the inversion layer and therefore increases the current flow between the source and drain.
For gate voltages below the threshold value, the channel is lightly populated, and only a very small subthreshold leakage current can flow between the source and the drain.
accumulation.
When a negative gate-source voltage (positive source-gate) is applied, it creates a "p-channel" at the surface of the n region, analogous to the n-channel case, but with opposite polarities of charges and voltages. When a voltage less negative than the threshold value (a negative voltage for p-channel) is applied between gate and source, the channel disappears and only a very small subthreshold current can flow between the source and the drain.
The device may comprise a Silicon On Insulator (SOI) device in which a buried oxide (BOX) is formed below a thin semiconductor layer. If the channel region between the gate dielectric and a BOX region is very thin, the very thin channel region is referred to as an ultrathin channel (UTC) region with the source and drain regions formed on either side thereof in and/or above the thin semiconductor layer. Alternatively, the device may comprise a semiconductor on insulator (SEMOI) device in which semiconductors other than silicon are employed. Many alternative semiconductor materials may be employed.
When the source and drain regions are formed above the channel in whole or in part, they are referred to as raised source/drain (RSD) regions.
Modes of operation.
The operation of a MOSFET can be separated into three different modes, depending on the voltages at the terminals. In the following discussion, a simplified algebraic model is used. Modern MOSFET characteristics are more complex than the algebraic model presented here.
For an enhancement-mode, n-channel MOSFET, the three operational modes are:
Body effect.
The occupancy of the energy bands in a semiconductor is set by the position of the Fermi level relative to the semiconductor energy-band edges. Application of a source-to-substrate reverse bias of the source-body pn-junction introduces a split between the Fermi levels for electrons and holes, moving the Fermi level for the channel further from the band edge, lowering the occupancy of the channel. The effect is to increase the gate voltage necessary to establish the channel, as seen in the figure. This change in channel strength by application of reverse bias is called the 'body effect'.
Simply put, using an nMOS example, the gate-to-body bias VGB positions the conduction-band energy levels, while the source-to-body bias VSB positions the electron Fermi level near the interface, deciding occupancy of these levels near the interface, and hence the strength of the inversion layer or channel.
The body effect upon the channel can be described using a modification of the threshold voltage, approximated by the following equation:
where "VTB" is the threshold voltage with substrate bias present, and "VT0" is the zero-"VSB" value of threshold voltage, formula_32 is the body effect parameter, and 2"φB" is the approximate potential drop between surface and bulk across the depletion layer when "VSB" = 0 and gate bias is sufficient to insure that a channel is present. As this equation shows, a reverse bias "VSB" > 0 causes an increase in threshold voltage "VTB" and therefore demands a larger gate voltage before the channel populates.
The body can be operated as a second gate, and is sometimes referred to as the "back gate"; the body effect is sometimes called the "back-gate effect".
Applications.
Digital integrated circuits such as microprocessors and memory devices contain thousands to millions of integrated MOSFET transistors on each device, providing the basic switching functions required to implement logic gates and data storage. Discrete devices are widely used in applications such as switch mode power supplies, variable-frequency drives and other power electronics applications where each device may be switching hundreds or thousands of watts. Radio-frequency amplifiers up to the UHF spectrum use MOSFET transistors as analog signal and power amplifiers. Radio systems also use MOSFETs as oscillators, or mixers to convert frequencies. MOSFET devices are also applied in audio-frequency power amplifiers for public address systems, sound reinforcement and home and automobile sound systems
History.
Discrete MOSFETs.
The basic principle of this kind of transistor was first patented by Julius Edgar Lilienfeld in 1925. Twenty five years later, when Bell Telephone attempted to patent the junction transistor, they found Lilienfeld already holding a patent, worded in a way that would include all types of transistors. Bell Labs was able to work out an agreement with Lilienfeld, who was still alive at that time (it is not known if they paid him money or not). It was at that time the Bell Labs version was given the name bipolar junction transistor, or simply junction transistor, and Lilienfeld's design took the name field effect transistor.
In 1959, Dawon Kahng and Martin M. (John) Atalla at Bell Labs invented the metal–oxide–semiconductor field-effect transistor (MOSFET) as an offshoot to the patented FET design.
Operationally and structurally different from the bipolar junction transistor,
the MOSFET was made by putting an insulating layer on the surface of the semiconductor and then placing a metallic gate electrode on that. It used crystalline silicon for the semiconductor and a thermally oxidized layer of silicon dioxide for the insulator. The silicon MOSFET did not generate localized electron traps at the interface between the silicon and its native oxide layer, and thus was inherently free from the trapping and scattering of carriers that had impeded the performance of earlier field-effect transistors.
Discrete power MOSFETs are currently widely used as low voltage switches.
MOS integrated circuits.
Following the development of clean rooms to reduce contamination to levels never before thought necessary, and of photolithography
and the planar process to allow circuits to be made in very few steps, the Si–SiO2 system possessed such technical attractions as low cost of production (on a per circuit basis) and ease of integration. Largely because of these two factors, the MOSFET has become the most widely used type of transistor in integrated circuits.
General Microelectronics introduced the first commercial MOS integrated circuit in 1964.
Additionally, the method of coupling two complementary MOSFETS (P-channel and N-channel) into one high/low switch, known as CMOS, means that digital circuits dissipate very little power except when actually switched.
The earliest microprocessors starting in 1970 were all "MOS microprocessors"—i.e., fabricated entirely from PMOS logic or fabricated entirely from NMOS logic.
In the 1970s, "MOS microprocessors" were often contrasted with "CMOS microprocessors" and "bipolar bit-slice processors".
CMOS circuits.
The MOSFET is used in digital complementary metal–oxide–semiconductor (CMOS) logic, which uses p- and n-channel MOSFETs as building blocks. Overheating is a major concern in integrated circuits since ever more transistors are packed into ever smaller chips. CMOS logic reduces power consumption because no current flows (ideally), and thus no power is consumed, except when the inputs to logic gates are being switched. CMOS accomplishes this current reduction by complementing every nMOSFET with a pMOSFET and connecting both gates and both drains together. A high voltage on the gates will cause the nMOSFET to conduct and the pMOSFET not to conduct and a low voltage on the gates causes the reverse. During the switching time as the voltage goes from one state to another, both MOSFETs will conduct briefly. This arrangement greatly reduces power consumption and heat generation. Digital and analog CMOS applications are described below.
Digital.
The growth of digital technologies like the microprocessor has provided the motivation to advance MOSFET technology faster than any other type of silicon-based transistor. A big advantage of MOSFETs for digital switching is that the oxide layer between the gate and the channel prevents DC current from flowing through the gate, further reducing power consumption and giving a very large input impedance. The insulating oxide between the gate and channel effectively isolates a MOSFET in one logic stage from earlier and later stages, which allows a single MOSFET output to drive a considerable number of MOSFET inputs. Bipolar transistor-based logic (such as TTL) does not have such a high fanout capacity. This isolation also makes it easier for the designers to ignore to some extent loading effects between logic stages independently. That extent is defined by the operating frequency: as frequencies increase, the input impedance of the MOSFETs decreases.
Analog.
The MOSFET's advantages in digital circuits do not translate into supremacy in all analog circuits. The two types of circuit draw upon different features of transistor behavior. Digital circuits switch, spending most of their time outside the switching region, while analog circuits depend on the linearity of response when the MOSFET is held precisely in the switching region. The bipolar junction transistor (BJT) has traditionally been the analog designer's transistor of choice, due largely to its higher transconductance and its lower output impedance (drain-voltage independence) in the switching region.
Nevertheless, MOSFETs are widely used in many types of analog circuits because of certain advantages. The characteristics and performance of many analog circuits can be scaled up or down by changing the sizes (length and width) of the MOSFETs used. By comparison, in most bipolar transistors the size of the device does not significantly affect its performance. MOSFETs' ideal characteristics regarding gate current (zero) and drain-source offset voltage (zero) also make them nearly ideal switch elements, and also make switched capacitor analog circuits practical. In their linear region, MOSFETs can be used as precision resistors, which can have a much higher controlled resistance than BJTs. In high power circuits, MOSFETs sometimes have the advantage of not suffering from thermal runaway as BJTs do. Also, MOSFETs can be configured to perform as capacitors and gyrator circuits which allow op-amps made from them to appear as inductors, thereby allowing all of the normal analog devices on a chip (except for diodes, which can be made smaller than a MOSFET anyway) to be built entirely out of MOSFETs. This means that complete analog circuits can be made on a silicon chip in a much smaller space and with simpler fabrication techniques.
MOSFETS are ideally suited to switch inductive loads because of tolerance to inductive kickback.
Some ICs combine analog and digital MOSFET circuitry on a single mixed-signal integrated circuit, making the needed board space even smaller. This creates a need to isolate the analog circuits from the digital circuits on a chip level, leading to the use of isolation rings and Silicon-On-Insulator (SOI). Since MOSFETs require more space to handle a given amount of power than a BJT, fabrication processes can incorporate BJTs and MOSFETs into a single device. Mixed-transistor devices are called Bi-FETs (bipolar FETs) if they contain just one BJT-FET and BiCMOS (bipolar-CMOS) if they contain complementary BJT-FETs. Such devices have the advantages of both insulated gates and higher current density.
MOSFET scaling.
Over the past decades, the MOSFET has continually been scaled down in size; typical MOSFET channel lengths were once several micrometres, but modern integrated circuits are incorporating MOSFETs with channel lengths of tens of nanometers. Robert Dennard's work on scaling theory was pivotal in recognising that this ongoing reduction was possible. Intel began production of a process featuring a 32 nm feature size (with the channel being even shorter) in late 2009. The semiconductor industry maintains a "roadmap", the ITRS, which sets the pace for MOSFET development. Historically, the difficulties with decreasing the size of the MOSFET have been associated with the semiconductor device fabrication process, the need to use very low voltages, and with poorer electrical performance necessitating circuit redesign and innovation (small MOSFETs exhibit higher leakage currents, and lower output resistance, discussed below).
Reasons for MOSFET scaling.
Smaller MOSFETs are desirable for several reasons. The main reason to make transistors smaller is to pack more and more devices in a given chip area. This results in a chip with the same functionality in a smaller area, or chips with more functionality in the same area. Since fabrication costs for a semiconductor wafer are relatively fixed, the cost per integrated circuits is mainly related to the number of chips that can be produced per wafer. Hence, smaller ICs allow more chips per wafer, reducing the price per chip. In fact, over the past 30 years the number of transistors per chip has been doubled every 2–3 years once a new technology node is introduced. For example, the number of MOSFETs in a microprocessor fabricated in a 45 nm technology can well be twice as many as in a 65 nm chip. This doubling of transistor density was first observed by Gordon Moore in 1965 and is commonly referred to as Moore's law.
It is also expected that smaller transistors switch faster. For example, one approach to size reduction is a scaling of the MOSFET that requires all device dimensions to reduce proportionally. The main device dimensions are the channel length, channel width, and oxide thickness. When they are scaled down by equal factors, the transistor channel resistance does not change, while gate capacitance is cut by that factor. Hence, the RC delay of the transistor scales with a similar factor.
While this has been traditionally the case for the older technologies, for the state-of-the-art MOSFETs reduction of the transistor dimensions does not necessarily translate to higher chip speed because the delay due to interconnections is more significant.
Difficulties arising due to MOSFET size reduction.
Producing MOSFETs with channel lengths much smaller than a micrometre is a challenge, and the difficulties of semiconductor device fabrication are always a limiting factor in advancing integrated circuit technology. Though processes such as ALD have improved fabrication for small components, the small size of the MOSFET (less than a few tens of nanometers) has created operational problems.
Higher subthreshold conduction.
As MOSFET geometries shrink, the voltage that can be applied to the gate must be reduced to maintain reliability. To maintain performance, the threshold voltage of the MOSFET has to be reduced as well. As threshold voltage is reduced, the transistor cannot be switched from complete turn-off to complete turn-on with the limited voltage swing available; the circuit design is a compromise between strong current in the "on" case and low current in the "off" case, and the application determines whether to favor one over the other. Subthreshold leakage (including subthreshold conduction, gate-oxide leakage and reverse-biased junction leakage), which was ignored in the past, now can consume upwards of half of the total power consumption of modern high-performance VLSI chips.
Increased gate-oxide leakage.
The gate oxide, which serves as insulator between the gate and channel, should be made as thin as possible to increase the channel conductivity and performance when the transistor is on and to reduce subthreshold leakage when the transistor is off. However, with current gate oxides with a thickness of around 1.2 nm (which in silicon is ~5 atoms thick) the quantum mechanical phenomenon of electron tunneling occurs between the gate and channel, leading to increased power consumption.
Silicon dioxide has traditionally been used as the gate insulator. Silicon dioxide however has a modest dielectric constant. Increasing the dielectric constant of the gate dielectric allows a thicker layer while maintaining a high capacitance (capacitance is proportional to dielectric constant and inversely proportional to dielectric thickness). All else equal, a higher dielectric thickness reduces the quantum tunneling current through the dielectric between the gate and the channel.
Insulators that have a larger dielectric constant than silicon dioxide (referred to as high-k dielectrics), such as group IVb metal silicates e.g. hafnium and zirconium silicates and oxides are being used to reduce the gate leakage from the 45 nanometer technology node onwards.
On the other hand, the barrier height of the new gate insulator is an important consideration; the difference in conduction band energy between the semiconductor and the dielectric (and the corresponding difference in valence band energy) also affects leakage current level. For the traditional gate oxide, silicon dioxide, the former barrier is approximately 8 eV. For many alternative dielectrics the value is significantly lower, tending to increase the tunneling current, somewhat negating the advantage of higher dielectric constant.
The maximum gate-source voltage is determined by the strength of the electric field able to be sustained by the gate dielectric before significant leakage occurs. As the insulating dielectric is made thinner, the electric field strength within it goes up for a fixed voltage. This necessitates using lower voltages with the thinner dielectric.
Increased junction leakage.
To make devices smaller, junction design has become more complex, leading to higher doping levels, shallower junctions, "halo" doping and so forth, all to decrease drain-induced barrier lowering (see the section on junction design). To keep these complex junctions in place, the annealing steps formerly used to remove damage and electrically active defects must be curtailed increasing junction leakage. Heavier doping is also associated with thinner depletion layers and more recombination centers that result in increased leakage current, even without lattice damage.
DIBL and VT roll off.
Because of the short-channel effect, channel formation is not entirely done by the gate, but now the drain and source also affect the channel formation. As the channel length decreases, the depletion regions of the source and drain come closer together and make the threshold voltage (VT) a function of the length of the channel. This is called VT roll-off. VT also becomes function of drain to source voltage VDS. As we increase the VDS, the depletion regions increase in size, and a considerable amount of charge is depleted by the VDS. The gate voltage required to form the channel is then lowered, and thus, the VT decreases with an increase in VDS. This effect is called drain induced barrier lowering (DIBL).
Lower output resistance.
For analog operation, good gain requires a high MOSFET output impedance, which is to say, the MOSFET current should vary only slightly with the applied drain-to-source voltage. As devices are made smaller, the influence of the drain competes more successfully with that of the gate due to the growing proximity of these two electrodes, increasing the sensitivity of the MOSFET current to the drain voltage. To counteract the resulting decrease in output resistance, circuits are made more complex, either by requiring more devices, for example the cascode and cascade amplifiers, or by feedback circuitry using operational amplifiers, for example a circuit like that in the adjacent figure.
Lower transconductance.
The transconductance of the MOSFET decides its gain and is proportional to hole or electron mobility (depending on device type), at least for low drain voltages. As MOSFET size is reduced, the fields in the channel increase and the dopant impurity levels increase. Both changes reduce the carrier mobility, and hence the transconductance. As channel lengths are reduced without proportional reduction in drain voltage, raising the electric field in the channel, the result is velocity saturation of the carriers, limiting the current and the transconductance.
Interconnect capacitance.
Traditionally, switching time was roughly proportional to the gate capacitance of gates. However, with transistors becoming smaller and more transistors being placed on the chip, interconnect capacitance (the capacitance of the metal-layer connections between different parts of the chip) is becoming a large percentage of capacitance. Signals have to travel through the interconnect, which leads to increased delay and lower performance.
Heat production.
The ever-increasing density of MOSFETs on an integrated circuit creates problems of substantial localized heat generation that can impair circuit operation. Circuits operate more slowly at high temperatures, and have reduced reliability and shorter lifetimes. Heat sinks and other cooling devices and methods are now required for many integrated circuits including microprocessors.
Power MOSFETs are at risk of thermal runaway. As their on-state resistance rises with temperature, if the load is approximately a constant-current load then the power loss rises correspondingly, generating further heat. When the heatsink is not able to keep the temperature low enough, the junction temperature may rise quickly and uncontrollably, resulting in destruction of the device.
Process variations.
With MOSFETs becoming smaller, the number of atoms in the silicon that produce many of the transistor's properties is becoming fewer, with the result that control of dopant numbers and placement is more erratic. During chip manufacturing, random process variations affect all transistor dimensions: length, width, junction depths, oxide thickness "etc.", and become a greater percentage of overall transistor size as the transistor shrinks. The transistor characteristics become less certain, more statistical. The random nature of manufacture means we do not know which particular example MOSFETs actually will end up in a particular instance of the circuit. This uncertainty forces a less optimal design because the design must work for a great variety of possible component MOSFETs. See process variation, design for manufacturability, reliability engineering, and statistical process control.
Modeling challenges.
Modern ICs are computer-simulated with the goal of obtaining working circuits from the very first manufactured lot. As devices are miniaturized, the complexity of the processing makes it difficult to predict exactly what the final devices look like, and modeling of physical processes becomes more challenging as well. In addition, microscopic variations in structure due simply to the probabilistic nature of atomic processes require statistical (not just deterministic) predictions. These factors combine to make adequate simulation and "right the first time" manufacture difficult.
MOSFET construction.
Gate material.
The primary criterion for the gate material is that it is a good conductor. Highly doped polycrystalline silicon is an acceptable but certainly not ideal conductor, and also suffers from some more technical deficiencies in its role as the standard gate material. Nevertheless, there are several reasons favoring use of polysilicon:
While polysilicon gates have been the de facto standard for the last twenty years, they do have some disadvantages which have led to their likely future replacement by metal gates. These disadvantages include:
Present high performance CPUs use metal gate technology, together with high-k dielectrics, a combination known as HKMG (High-K, Metal Gate). The disadvantages of metal gates are overcome by a few techniques:
Insulator.
As devices are made smaller, insulating layers are made thinner, and at some point tunneling of carriers through the insulator from the channel to the gate electrode takes place. To reduce the resulting leakage current, the insulator can be made thicker by choosing a material with a higher dielectric constant. To see how thickness and dielectric constant are related, note that Gauss's law connects field to charge as:
with "Q" = charge density, κ = dielectric constant, ε0 = permittivity of empty space and "E" = electric field. From this law it appears the same charge can be maintained in the channel at a lower field provided κ is increased. The voltage on the gate is given by:
with "VG" = gate voltage, "Vch" = voltage at channel side of insulator, and "tins" = insulator thickness. This equation shows the gate voltage will not increase when the insulator thickness increases, provided κ increases to keep "tins /κ = constant" (see the article on high-κ dielectrics for more detail, and the section in this article on gate-oxide leakage).
The insulator in a MOSFET is a dielectric which can in any event be silicon oxide, but many other dielectric materials are employed. The generic term for the dielectric is gate dielectric since the dielectric lies directly below the gate electrode and above the channel of the MOSFET.
Junction design.
The source-to-body and drain-to-body junctions are the object of much attention because of three major factors: their design affects the current-voltage ("I-V") characteristics of the device, lowering output resistance, and also the speed of the device through the loading effect of the junction capacitances, and finally, the component of stand-by power dissipation due to junction leakage.
The drain induced barrier lowering of the threshold voltage and channel length modulation effects upon "I-V" curves are reduced by using shallow junction extensions. In addition, "halo" doping can be used, that is, the addition of very thin heavily doped regions of the same doping type as the body tight against the junction walls to limit the extent of depletion regions.
The capacitive effects are limited by using raised source and drain geometries that make most of the contact area border thick dielectric instead of silicon.
These various features of junction design are shown (with artistic license) in the figure.
Junction leakage is discussed further in the section increased junction leakage.
Other MOSFET types.
Dual-gate MOSFET.
The dual-gate MOSFET has a tetrode configuration, where both gates control the current in the device. It is commonly used for small-signal devices in radio frequency applications where biasing the drain-side gate at constant potential reduces the gain loss caused by Miller effect, replacing two separate transistors in cascode configuration. Other common uses in RF circuits include gain control and mixing (frequency conversion). The "tetrode" description, though accurate, does not replicate the vacuum-tube tetrode. Vacuum-tube tetrodes, using a screen grid, exhibit much lower grid-plate capacitance and much higher output impedance and voltage gains than triode vacuum tubes. These improvements are commonly an order of magnitude (10 times) or considerably more. Tetrode transistors (whether bipolar junction or field-effect) do not exhibit improvements of such a great degree.
FinFET.
The FinFET, see figure to right, is a double-gate silicon-on-insulator device, one of a number of geometries being introduced to mitigate the effects of short channels and reduce drain-induced barrier lowering. The "fin" refers to the narrow channel between source and drain. A thin insulating oxide layer on either side of the fin separates it from the gate. SOI FinFETs with a thick oxide on top of the fin are called "double-gate" and those with a thin oxide on top as well as on the sides are called "triple-gate" FinFETs.
Depletion-mode MOSFETs.
There are "depletion-mode" MOSFET devices, which are less commonly used than the standard "enhancement-mode" devices already described. These are MOSFET devices that are doped so that a channel exists even with zero voltage from gate to source. To control the channel, a negative voltage is applied to the gate (for an n-channel device), depleting the channel, which reduces the current flow through the device. In essence, the depletion-mode device is equivalent to a normally closed (on) switch, while the enhancement-mode device is equivalent to a normally open (off) switch.
Due to their low noise figure in the RF region, and better gain, these devices are often preferred to bipolars in RF front-ends such as in TV sets. Depletion-mode MOSFET families include BF 960 by Siemens and BF 980 by Philips (dated 1980s), whose derivatives are still used in AGC and RF mixer front-ends.
NMOS logic.
For devices of equal current driving capability, n-channel MOSFETs can be made smaller than p-channel MOSFETs, due to p-channel charge carriers (holes) having lower mobility than do n-channel charge carriers (electrons), and producing only one type of MOSFET on a silicon substrate is cheaper and technically simpler. These were the driving principles in the design of NMOS logic which uses n-channel MOSFETs exclusively. However, neglecting leakage current, unlike CMOS logic, NMOS logic consumes power even when no switching is taking place. With advances in technology, CMOS logic displaced NMOS logic in the mid-1980s to become the preferred process for digital chips.
Power MOSFET.
Power MOSFETs have a different structure than the one presented above. As with most power devices, the structure is vertical and not planar. Using a vertical structure, it is possible for the transistor to sustain both high blocking voltage and high current. The voltage rating of the transistor is a function of the doping and thickness of the N-epitaxial layer (see cross section), while the current rating is a function of the channel width (the wider the channel, the higher the current). In a planar structure, the current and breakdown voltage ratings are both a function of the channel dimensions (respectively width and length of the channel), resulting in inefficient use of the "silicon estate". With the vertical structure, the component area is roughly proportional to the current it can sustain, and the component thickness (actually the N-epitaxial layer thickness) is proportional to the breakdown voltage.
Power MOSFETs with lateral structure are mainly used in high-end audio amplifiers and high-power PA systems. Their advantage is a better behaviour in the saturated region (corresponding to the linear region of a bipolar transistor) than the vertical MOSFETs. Vertical MOSFETs are designed for switching applications.
DMOS.
DMOS stands for double-diffused metal–oxide–semiconductor. Most power MOSFETs are made using this technology.
RHBD MOSFETs.
Semiconductor sub-micrometer and nanometer electronic circuits are the primary concern for operating within the normal tolerance in harsh radiation environments like outer space. One of the design approaches for making a radiation-hardened-by-design (RHBD) device is Enclosed-Layout-Transistor (ELT). Normally, the gate of the MOSFET surrounds the drain, which is placed in the center of the ELT. The source of the MOSFET surrounds the gate. Another RHBD MOSFET is called H-Gate. Both of these transistors have very low leakage current with respect to radiation. However, they are large in size and take more space on silicon than a standard MOSFET.
In older STI (shallow trench isolation) designs, radiation strikes near the silicon oxide region cause the channel inversion at the corners of the standard MOSFET due to accumulation of radiation induced trapped charges. If the charges are large enough, the accumulated charges affect STI surface edges along the channel near the channel interface (gate) of the standard MOSFET. Thus the device channel inversion occurs along the channel edges and the device creates off-state leakage path, causing device to turn on. So the reliability of circuits degrades severely. The ELT offers many advantages. These advantages include improvement of reliability by reducing unwanted surface inversion at the gate edges that occurs in the standard MOSFET. Since the gate edges are enclosed in ELT, there is no gate oxide edge (STI at gate interface), and thus the transistor off-state leakage is reduced very much.
Low-power microelectronic circuits including computers, communication devices and monitoring systems in space shuttle and satellites are very different from what we use on earth. They are radiation (high-speed atomic particles like proton and neutron, solar flare magnetic energy dissipation in Earth's space, energetic cosmic rays like X-ray, gamma ray etc.) tolerant circuits. These special electronics are designed by applying very different techniques using RHBD MOSFETs to ensure the safe space journey and also space-walk of astronauts.
MOSFET analog switch.
MOSFET analog switches use the MOSFET to pass analog signals when on, and as a high impedance when off. Signals flow in both directions across a MOSFET switch. In this application, the drain and source of a MOSFET exchange places depending on the relative voltages of the source/drain electrodes. The source is the more negative side for an N-MOS or the more positive side for a P-MOS. All of these switches are limited on what signals they can pass or stop by their gate–source, gate–drain and source–drain voltages; exceeding the voltage, current, or power limits will potentially damage the switch.
Single-type MOSFET switch.
This analog switch uses a four-terminal simple MOSFET of either P or N type.
In the case of an n-type switch, the body is connected to the most negative supply (usually GND) and the gate is used as the switch control. Whenever the gate voltage exceeds the source voltage by at least a threshold voltage, the MOSFET conducts. The higher the voltage, the more the MOSFET can conduct. An N-MOS switch passes all voltages less than Vgate–Vtn. When the switch is conducting, it typically operates in the linear (or ohmic) mode of operation, since the source and drain voltages will typically be nearly equal.
In the case of a P-MOS, the body is connected to the most positive voltage, and the gate is brought to a lower potential to turn the switch on. The P-MOS switch passes all voltages higher than Vgate–Vtp (threshold voltage Vtp is negative in the case of enhancement-mode P-MOS).
A P-MOS switch will have about three times the resistance of an N-MOS device of equal dimensions because electrons have about three times the mobility of holes in silicon.
Dual-type (CMOS) MOSFET switch.
This "complementary" or CMOS type of switch uses one P-MOS and one N-MOS FET to counteract the limitations of the single-type switch. The FETs have their drains and sources connected in parallel, the body of the P-MOS is connected to the high potential (VDD) and the body of the N-MOS is connected to the low potential (Gnd). To turn the switch on, the gate of the P-MOS is driven to the low potential and the gate of the N-MOS is driven to the high potential. For voltages between VDD–Vtn and Gnd–Vtp, both FETs conduct the signal; for voltages less than Gnd–Vtp, the N-MOS conducts alone; and for voltages greater than VDD–Vtn, the P-MOS conducts alone.
The voltage limits for this switch are the gate–source, gate–drain and source–drain voltage limits for both FETs. Also, the P-MOS is typically two to three times wider than the N-MOS, so the switch will be balanced for speed in the two directions.
Tri-state circuitry sometimes incorporates a CMOS MOSFET switch on its output to provide for a low-ohmic, full-range output when on, and a high-ohmic, mid-level signal when off.

</doc>
<doc id="40346" url="https://en.wikipedia.org/wiki?curid=40346" title="JFET">
JFET

The junction gate field-effect transistor (JFET or JUGFET) is the simplest type of field-effect transistor. They are three-terminal semiconductor devices that can be used as electronically-controlled switches, amplifiers, or voltage-controlled resistors. 
Unlike bipolar transistors, JFETs are exclusively voltage-controlled in that they do not need a biasing current. Electric charge flows through a semiconducting channel between "source" and "drain" terminals. By applying a reverse bias voltage to a "gate" terminal, the channel is "pinched", so that the electric current is impeded or switched off completely. A JFET is usually on when there is no potential difference between its gate and source terminals. If a potential difference of the proper polarity is applied between its gate and source terminals, the JFET will be more resistive to current flow, which means less current would flow in the channel between the source and drain terminals. Thus, JFETs are sometimes referred to as depletion-mode devices. 
JFETs can have an n-type or p-type channel. In the n-type, if the voltage applied to the gate is less than that applied to the source, the current will be reduced (similarly in the p-type, if the voltage applied to the gate is "greater" than that applied to the source). A JFET has a large input impedance (sometimes on the order of 1010 ohms), which means that it has a negligible effect on external components or circuits connected to its gate. 
History.
A succession of FET-like devices were patented by Julius Lilienfeld in the 1920s and 1930s. However, materials science and fabrication technology would require decades of advances before FETs could actually be made. In 1947, researchers John Bardeen, Walter Houser Brattain, and William Shockley failed in their repeated attempts to make a FET. They discovered the point-contact transistor in the course of trying to diagnose the reasons for their failures. The first practical JFETs were made a decade later.
Structure.
The JFET is a long channel of semiconductor material, doped to contain an abundance of positive charge carriers or holes ("p-type"), or of negative carriers or electrons ("n-type"). Ohmic contacts at each end form the source (S) and the drain (D). A pn-junction is formed on one or both sides of the channel, or surrounding it, using a region with doping opposite to that of the channel, and biased using an ohmic gate contact (G).
Function.
JFET operation can be compared to that of a garden hose. The flow of water through a hose can be controlled by squeezing it to reduce the cross section and the flow of electric charge through a JFET is controlled by constricting the current-carrying channel. The current also depends on the electric field between source and drain (analogous to the difference in pressure on either end of the hose).
Constriction of the conducting channel is accomplished using the field effect: a voltage between the gate and the source is applied to reverse bias the gate-source pn-junction, thereby widening the depletion layer of this junction (see top figure), encroaching upon the conducting channel and restricting its cross-sectional area. The depletion layer is so-called because it is depleted of mobile carriers and so is electrically non-conducting for practical purposes.
When the depletion layer spans the width of the conduction channel, "pinch-off" is achieved and drain-to-source conduction stops. Pinch-off occurs at a particular reverse bias (VGS) of the gate-source junction. The pinch-off voltage (Vp) varies considerably, even among devices of the same type. For example, VGS(off) for the Temic J202 device varies from to . Typical values vary from to .
To switch off an n-channel device requires a negative gate-source voltage (VGS). Conversely, to switch off a p-channel device requires positive VGS.
In normal operation, the electric field developed by the gate blocks source-drain conduction to some extent.
Some JFET devices are symmetrical with respect to the source and drain.
Schematic symbols.
The JFET gate is sometimes drawn in the middle of the channel (instead of at the drain or source electrode as in these examples). This symmetry suggests that "drain" and "source" are interchangeable, so the symbol should be used only for those JFETs where they are indeed interchangeable.
Officially, the style of the symbol should show the component inside a circle (representing the envelope of a discrete device). This is true in both the US and Europe. The symbol is usually drawn without the circle when drawing schematics of integrated circuits. More recently, the symbol is often drawn without its circle even for discrete devices.
In every case the arrow head shows the polarity of the P-N junction formed between the channel and the gate. As with an ordinary diode, the arrow points from P to N, the direction of conventional current when forward-biased. An English mnemonic is that the arrow of an N-channel device "points in".
Comparison with other transistors.
At room temperature, JFET gate current (the reverse leakage of the gate-to-channel junction) is comparable to that of a MOSFET (which has insulating oxide between gate and channel), but much less than the base current of a bipolar junction transistor. The JFET has higher gain (transconductance) than the MOSFET, as well as lower flicker noise, and is therefore used in some low-noise, high input-impedance op-amps.
Mathematical model.
The current in N-JFET due to a small voltage VDS (that is, in the linear ohmic region) is given by treating the channel as a rectangular bar of material of electrical conductivity formula_1: 
where
Linear region.
Then the drain current in the "linear region" can be expressed as:
In terms of formula_4, the drain current can also be:
Saturation region.
The drain current in the "saturation region" is often approximated in terms of gate bias as:
where
In the "saturation region", the JFET drain current is most significantly affected by the gate–source voltage and barely affected by the drain–source voltage. 
If the channel doping is uniform, such that the depletion region thickness will grow in proportion to the square root of the absolute value of the gate–source voltage, then the channel thickness "b" can be expressed in terms of the zero-bias channel thickness "a" as:
where 

</doc>
<doc id="40347" url="https://en.wikipedia.org/wiki?curid=40347" title="House of Babenberg">
House of Babenberg

The House of Babenberg was the ruling noble family of Austria from 976 to 1246. Originally from Bamberg in Franconia in present-day Bavaria, the Babenbergs were counts, margraves, and dukes in the Danube region of present-day Upper Austria, Lower Austria, and Styria.
One or two families.
The Babenberg family can be broken down into two distinct groups: 1) The "Franconian Babenbergs", the so-called "Elder House of Babenberg", or "Popponids" out of which came the Hennebergs and the Counts of Schweinfurt. 2) "Austrian Babenbergs" which ruled Austria. The second group claimed to have originated from the first but scholars have not been able to verify that claim.
Popponids.
Like the French royal Capetian dynasty, the Elder Babenbergs descended from the Robertians. The earliest known Babenberg was one Poppo, maybe a descendant of the Frankish count Cancor. In the early 9th century he appeared as a count in the Grabfeld, a historic region in northeastern Franconia bordering on Thuringia. One of his sons, Henry, sometimes called margrave and duke in Franconia under King Charles the Fat of East Francia, fell fighting against the Normans in 886; another, Poppo, was margrave in Thuringia from 880 to 892, when he was deposed by King Charles successor Arnulf of Carinthia. The Popponids had been favoured by Charles the Fat, but Arnulf reversed this policy in favour of the rival family of the Conradines from the Lahngau in Rhenish Franconia.
The leaders of the Babenbergs were the three sons of Duke Henry, who called themselves after their castle of Babenberg on the upper Main, around which their possessions centred. The city of Bamberg was built around the ancestral castle of the family.
The Babenberg feud.
The rivalry between the Babenberg and Conradine families was intensified by their efforts to extend their authority in the region of the middle Main, and this quarrel, known as the "Babenberg feud", came to a head at the beginning of the 10th century during the troubled reign of the German king Louis the Child. In the battle of Fritzlar in 906, the Conradines won a decisive victory, although count Conrad the Elder fell in the battle. Two of the Babenberg brothers were also killed. The third, Adalbert of Prague, was summoned before the imperial court by the regent Hatto I, Archbishop of Mainz, a partisan of the Conradines. He refused to appear, held his own for a time in his castle at Theres against the king's forces, but surrendered in 906, and in spite of a promise of safe-conduct by Hatto was beheaded.
The Conradines became dukes of Franconia, while the Babenbergs lost their influence in Franconia.
Margraves of Austria.
In 976 Leopold I, a member of the Babenberg family, who was a count in the Donnegau, is described as count of the Eastern March, a district not more than 60 miles in breadth on the eastern frontier of Bavaria which grew into the duchy of Austria. Leopold, who received the mark as a reward for his fidelity to the emperor Otto II during the Bavarian rising in 976, extended its area at the expense of the Hungarians, and was succeeded in 994 by his son Henry I. Henry, who continued his father's policy, was followed in 1018 by his brother Adalbert and in 1055 by his nephew, Ernest, whose marked loyalty to the emperors Henry II and Henry III was rewarded by many tokens of favour.
The succeeding margrave, Leopold II, quarrelled with Henry III, who was unable to oust him from the mark or to prevent the succession of his son Leopold III in 1096. Leopold supported Henry, the son of Henry IV, in his rising against his father, but was soon drawn over to the emperor's side, and in 1106 married the daughter of emperor Henry IV, Agnes, widow of Frederick I of Swabia. He declined the imperial crown in 1125. His zeal in founding monasteries earned for him his surname "the Pious", and canonization by Pope Innocent VIII in 1485. He is regarded as the patron saint of Austria.
Elevation to dukes.
One of Leopold's sons was Otto, Bishop of Freising. His eldest son, Leopold IV, became margrave in 1136, and in 1139 received from the German king Conrad III the Duchy of Bavaria, which had been forfeited by Henry the Proud. Leopold's brother Henry (surnamed Jasomirgott, allegedly from his favourite oath, "So help me God!") was made count palatine of the Rhine in 1140, and became margrave of Austria on Leopold's death in 1141. Having married Gertrude, the widow of Henry the Proud, he was invested in 1143 with the duchy of Bavaria, and resigned his office as count palatine. In 1147 he went on crusade, and after his return, renounced Bavaria at the instance of the new king Frederick I who gave the duchy of Bavaria to Henry the Lion of Saxony. As compensation for this, Austria, the capital of which had been transferred to Vienna in 1156, was elevated into a duchy in the Privilegium Minus.
The rise of Babenberg power.
The second duke was Henry's son Leopold V, who succeeded him in 1177 and took part in the crusades of 1182 and 1190. In Palestine he quarrelled with Richard I of England, captured him on his homeward journey and handed him over to the emperor Henry VI. Leopold increased the territories of the Babenbergs by acquiring Styria under the will of his kinsman Duke Ottokar IV. He died in 1194, and Austria fell to one son, Frederick, and Styria to another, Leopold; but on Frederick's death in 1198 they were again united by Leopold as Duke Leopold VI, surnamed "the Glorious".
The new duke fought against the infidels in Spain, Egypt, and Palestine, but is more celebrated as a lawgiver, a patron of letters, and a founder of towns. Under him Vienna became the centre of culture in Germany and the great school of Minnesingers. His later years were spent in strife with his son Frederick, and he died in 1230 at San Germano, now renamed Cassino, whither he had gone to arrange the peace between the emperor Frederick II and Pope Gregory IX.
The Last of the Babenbergs.
Frederick II, Leopold VI's son by Theodora Angelina, succeeded his father as duke upon the elder man's death in 1230. Frederick II soon earned the epithet "the Quarrelsome" as a result of his ongoing disputes with the kings of Hungary and Bohemia and with the Holy Roman Emperor, also named Frederick II. The Austrian Frederick II deprived his mother and sisters of their possessions, was hated by his subjects on account of his oppressive rule, and, in 1236, was placed under the imperial ban and driven from Austria. However, he was later restored to his duchy when the Emperor Frederick II was excommunicated. Subsequently, the Austrian Frederick II treated with the Emperor Frederick II in vain to make Austria a kingdom.
The male line of the Babenbergs became extinct in 1246, when Frederick II "the Quarrelsome" was killed in battle (the Henneberg branch of the Franconian Babenbergs lived on until 1583 when its lands where divided among the two branches of the Wettin family).
His heir general was Gertrude of Austria, the only child of his late elder brother, Henry of Austria by that man's wife, Agnes of Thuringia. However, neither her husbands nor her son succeeded in settling the Babenberg inheritance under their power.
After some years of struggle known as the "Interregnum", the Duchies of Austria and Styria fell to Otakar II of Bohemia, and subsequently to Rudolph I of Habsburg, whose descendants were to rule Austria until 1918.
Genetic legacy.
Byzantine blood.
All the Babenberg dukes from Leopold V onward were descended from Byzantine emperors — Leopold's mother, Theodora Komnene, being a granddaughter of the Emperor, John II Komnenos. Subsequently, Leopold V's younger son, Leopold VI, also married a Byzantine princess (Theodora Angelina), as did his youngest son (by Theodora), Frederick II, who married "Sophia Laskarina".
The Babenbergs and the Habsburgs.
The next dynasty in Austria—the Habsburgs—were originally not descendants of the Babenbergs. It was not until the children of Albert I of Germany that the Babenberg blood was brought into the Habsburg line, though this blood was from the pre-ducal Babenbergs. A side effect of this marriage was the use of the Babenberg name "Leopold" by the Habsburgs for one of their sons.
The Habsburgs did eventually gain descent from the Babenberg dukes, though at different times. The first Habsburg line to be descended from the Babenbergs was the "Albertine" line. This was achieved through the marriage of Albert III, Duke of Austria to Beatrix of Nuremberg. As such, their son, Albert IV, Duke of Austria, was the first Habsburg duke who was descended from the Babenberg dukes. However, the male line of that branch of the Habsburgs died out in 1457 with Ladislas V Posthumus of Bohemia.
The next Habsburg line to gain Babenberg blood was the "Styrian" line, which occurred with the children of Ferdinand I, Holy Roman Emperor and Anna of Bohemia and Hungary, the latter of whom descended from Babenberg dukes. It was actually from Elizabeth of Austria, the sister of Ladislas V Posthumus of Bohemia, that the Styrian line gained their Babenberg blood.
The "Spanish" line was the last Habsburg line to gain Babenberg blood. Again it was via the previous Habsburg line to gain Babenberg blood (i.e. the Styrian) that the Spanish Habsburg gained their descent from the Babenbergs — Anna of Austria, the wife of Philip II of Spain and mother of Philip (from whom all subsequent Spanish Habsburgs were descended), was a male-line granddaughter of Ferdinand and Anna. As a result, after 1598, all Habsburg scions descended from the Babenberg Dukes.

</doc>
<doc id="40348" url="https://en.wikipedia.org/wiki?curid=40348" title="Sacrosanctum Concilium">
Sacrosanctum Concilium

Sacrosanctum Concilium, the Constitution on the Sacred Liturgy, is one of the constitutions of the Second Vatican Council. It was approved by the assembled bishops by a vote of 2,147 to 4 and promulgated by Pope Paul VI on December 4, 1963. The main aim was to achieve greater lay participation in the Catholic Church's liturgy.
Contents.
"The numbers given correspond to section numbers within the text."
Title and purpose.
As is customary with Catholic documents, the name of this Constitution, "Sacred Council" in Latin, is taken from the first line ("incipit") of the document:
Participation of the laity.
One of the first issues considered by the council, and the matter that had the most immediate effect on the lives of individual Catholics, was the renewal of the liturgy. The central idea was that there ought to be greater lay participation in the liturgy.
Popes Pius X, Pius XI, and Pius XII consistently asked that the people be taught how to chant the responses at Mass and that they learn the prayers of the Mass in order to participate intelligently. Now the bishops decreed that: “To promote active participation, the people should be encouraged to take part by means of acclamations, responses, psalmody, antiphons, and songs.” (30) Composers should “produce compositions which …(provide) for the active participation of the entire assembly of the faithful. (121)
After centuries when, with the Mass in Latin, Catholic piety centered around popular devotions, the bishops decreed that “Popular devotions … should be so drawn up that they harmonize with the liturgical seasons, accord with the sacred liturgy, are in some fashion derived from it, and lead the people to it, since, in fact, the liturgy by its very nature far surpasses any of them.” (13)
Consilium.
The council fathers established guidelines to govern the renewal of the liturgy, which included, allowed, and encouraged greater use of the vernacular (native language) in addition to Latin, particularly for the biblical readings and other prayers. Implementation of the Council's directives on the liturgy was to be carried out under the authority of Pope Paul VI by a special papal commission, later incorporated in the Congregation for Divine Worship and the Discipline of the Sacraments, and, in the areas entrusted to them, by national conferences of bishops, which, if they had a shared language, were expected to collaborate in producing a common translation.

</doc>
<doc id="40351" url="https://en.wikipedia.org/wiki?curid=40351" title="The Cathedral and the Bazaar">
The Cathedral and the Bazaar

The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary (abbreviated CatB) is an essay, and later a book, by Eric S. Raymond on software engineering methods, based on his observations of the Linux kernel development process and his experiences managing an open source project, fetchmail. It examines the struggle between top-down and bottom-up design. The essay was first presented by the author at the Linux Kongress on May 27, 1997 in Würzburg and was published as part of the book in 1999.
The illustration on the cover of the book is a 1913 painting by titled "Composition with Figures" and belongs to the collection of the State Tretyakov Gallery.
It was released under the Open Publication License v2.0 around 1999.
"The Cathedral and the Bazaar".
The essay contrasts two different free software development models:
The essay's central thesis is Raymond's proposition that "given enough eyeballs, all bugs are shallow" (which he terms Linus's Law): the more widely available the source code is for public testing, scrutiny, and experimentation, the more rapidly all forms of bugs will be discovered. In contrast, Raymond claims that an inordinate amount of time and energy must be spent hunting for bugs in the Cathedral model, since the working version of the code is available only to a few developers.
Lessons for creating good open source software.
Raymond points to 19 "lessons" learned from various software development efforts, each describing attributes associated with good practice in open source software development:
Legacy and reception.
In 1998, the essay helped the final push for Netscape Communications Corporation to release the source code for Netscape Communicator and start the Mozilla project; it was cited by Frank Hecker and other employees as an outside independent validation of his arguments. Netscape's public recognition of this influence brought Raymond renown in hacker culture.
When O'Reilly Media published the book in 1999, it became one of the first (if not the first) complete and commercially distributed book published under the Open Publication License.
Marshall Poe, in his essay "The Hive", likens Wikipedia to the Bazaar model that Raymond defines. Jimmy Wales himself was in fact inspired by the work (as well as arguments put forward in works prior to the Internet age, such as Friedrich Hayek's "The Use of Knowledge in Society"), arguing that "It opened my eyes to the possibility of mass collaboration".
In 1999 Nikolai Bezroukov published two cited critical essays on Eric Raymond's views on open source software, the second one called "A second look at the Cathedral and the Bazaar". They produced a sharp response from Eric Raymond.

</doc>
<doc id="40352" url="https://en.wikipedia.org/wiki?curid=40352" title="Gaudium et spes">
Gaudium et spes

Gaudium et spes (, "Joy and Hope"), the Pastoral Constitution on the Church in the Modern World, was one of the four constitutions resulting from the Second Vatican Council. The document is an overview of the Catholic Church's teachings about humanity's relationship to society, especially in reference to economics, poverty, social justice, culture, science, technology and ecumenism.
Approved by a vote of 2,307 to 75 of the bishops assembled at the council, it was promulgated by Pope Paul VI on 7 December 1965, the day the council ended. As is customary with Catholic documents, the title is taken from its opening words in Latin. The English translation begins:
Overview.
The document was not drafted before the council met, but arose from the floor of the council and was one of the last to be promulgated.
The previous Vatican Council in 1869-70 had tried to defend the role of the church in an increasingly secular world. Those who interpret the purpose of the Second Council as one of embracing this world use "Gaudium et spes" as the primary hermeneutic for all its documents. One of the cardinals, Leo Joseph Suenens of Belgium, urged the council to take on social responsibility for Third World suffering, International peace and war, and the poor, sentiments echoed by Cardinal Giovanni Battista Montini of Milan and Cardinal Lercaro of Bologna.
Thomas Rosica points out that the Council Fathers "... were men who had experienced two world wars, the horror of the Holocaust, the onset of the nuclear weaponry, the hostility of communism, the awesome and only partially understood impact of science and technology." In the Introduction it states, "... the Church has always had the duty of scrutinizing the signs of the times and of interpreting them in the light of the Gospel." The mission of the Church needed to recognize the realities of secularization and pluralism.
Marie-Dominique Chenu, professor of the Pontifical University of Saint Thomas Aquinas, "Angelicum" was influential in the composition of "Gaudium et spes", as was Louis-Joseph Lebret. "The problem of poverty and of overcoming it through a healthy economy, respectful of the primary value of the person, allows for a vast discussion on political ethics in Gaudium et Spes."
"Gaudium et Spes" was adopted after "Lumen Gentium", the Constitution on the Church, and it reflects the ecclesiological approach of that text. It also recognized and encouraged the role of the laity in the life of the Church in the world. The decree was debated at length and approved by much the largest and most international council in the history of the Church.
"This council exhorts Christians, as citizens of two cities, to strive to discharge their earthly duties conscientiously and in response to the Gospel spirit.". This was further expanded in "Apostolicam Actuositatem", Decree on the Apostolate of the Laity, of 18 November 1965.
Contents.
The chief focus of Gaudium et Spes was on social teaching.
"The numbers given correspond to section numbers within the text."
Ecumenical impact.
The document has had a huge influence on the social teachings of the wider Christian churches and communities, especially the churches that belong to the World Council of Churches.

</doc>
<doc id="40353" url="https://en.wikipedia.org/wiki?curid=40353" title="London, Ontario">
London, Ontario

London is a city located in Southwestern Ontario, Canada along the Quebec City–Windsor Corridor. The city has a population of 366,151 according to the 2011 Canadian census. London is at the confluence of the non-navigable Thames River, approximately halfway between Toronto, Ontario and Detroit, Michigan. The City of London is a separated municipality, politically separate from Middlesex County, though it remains the county seat.
London and the Thames were named in 1793 by Lord Simcoe, who proposed the site for the capital of Upper Canada. The first European settlement was between 1801 and 1804 by Peter Hagerman. The village was founded in 1826 and incorporated in 1855. Since then, London has grown to be the largest Southwestern Ontario municipality and Canada's 11th largest municipality, having annexed many of the smaller communities that surrounded it. London is rated Canada's fourth greenest mid-sized cities according to prominent City Indexes with a Green Score of 101.
London is a regional centre of health care and education, being home to the University of Western Ontario, Fanshawe College, and several hospitals. The city hosts a number of musical and artistic exhibits and festivals, which contribute to its tourism industry, but its economic activity is centred on education, medical research, insurance, and information technology. London's university and hospitals are among its top ten employers. London lies at the junction of Highway 401 and 402, connecting it to Toronto, Windsor, and Sarnia. It also has an international airport, train and bus station.
History.
Founding.
Prior to European contact in the 18th century, the present site of London was occupied by several Neutral and Odawa/Ojibwa villages. Archaeological investigations in the region indicate that aboriginal people have resided in the area for at least the past 10,000 years.
The current location of London was selected as the site of the future capital of Upper Canada in 1793 by Lieutenant-Governor John Graves Simcoe. Simcoe intended to name the settlement "Georgina", in honour of King George III, and renamed the river. However, the choice of a capital site in the midst of extensive hardwood forests was rejected by Guy Carleton (Governor Dorchester). In 1814, there was a skirmish during the War of 1812 in what is now southwest London at Reservoir Hill, formerly Hungerford Hill.
The village of London, named after the English capital of London, was not founded until 1826, and not as the capital Simcoe envisioned. Rather, it was an administrative seat for the area west of the actual capital, York (now Toronto). Locally, it was part of the Talbot Settlement, named for Colonel Thomas Talbot, the chief coloniser of the area, who oversaw the land surveying and built the first government buildings for the administration of the Western Ontario peninsular region. Together with the rest of Southwestern Ontario, the village benefited from Talbot's provisions, not only for building and maintaining roads, but also for assignment of access priorities to main routes to productive land. At the time, Crown and clergy reserves were receiving preference in the rest of Ontario.
In 1832, the new settlement suffered an outbreak of cholera. London proved a centre of strong Tory support during the Upper Canada Rebellion of 1837, notwithstanding a brief rebellion led by Dr. Charles Duncombe. Consequently, the British government located its Ontario peninsular garrison there in 1838, increasing its population with soldiers and their dependents, and the business support populations they required. London was incorporated as a town in 1840.
On 13 April 1845, fire destroyed much of London, which was at the time largely constructed of wooden buildings. One of the first casualties was the town's only fire engine. This fire burned nearly 30 acres of land destroying 150 buildings before burning itself out later the same day. One-fifth of London was destroyed and this was the province's first million dollar fire.
On 1 January 1855, London was incorporated as a "city" (10,000 or more residents). In the 1860s, a sulphur spring was discovered at the forks of the Thames River while industrialists were drilling for oil. The springs became a popular destination for wealthy Ontarians, until the turn of the 20th century when a textile factory was built at the site, replacing the spa.
Long before the Royal Military College of Canada was established in 1876, there were proposals for military colleges in Canada. Staffed by British Regulars, adult male students underwent a 3 month long military courses from 1865 at the School of Military Instruction in London. Established by Militia General Order in 1865, the school enabled Officers of Militia or Candidates for Commission or promotion in the Militia to learn Military duties, drill and discipline, to command a Company at Battalion Drill, to Drill a Company at Company Drill, the internal economy of a Company and the duties of a Company's Officer. The school was not retained at Confederation, in 1867.
Development.
Sir John Carling, Tory MP for London, gave three events to explain the development of London in a 1901 speech. They were: the location of the court and administration in London in 1826; the arrival of the military garrison in 1838; and the arrival of the railway in 1853.
In 1875, London's first iron bridge, the Blackfriars Street Bridge, was constructed. It replaced a succession of flood-failed wooden structures that had provided the city's only northern road crossing of the river. A rare example of a bowstring truss bridge, the Blackfriars remains open to pedestrian and bicycle traffic, though it is currently closed indefinitely to vehicular traffic due to various structural problems. The Blackfriars, amidst the river-distance between the Carling Brewery and the historic Tecumseh Park (including a major mill), linked London with its western suburb of Petersville, named for Squire Peters of Grosvenor Lodge. That community joined with the southern subdivision of Kensington in 1874, formally incorporating as the municipality of Petersville. Although it changed its name in 1880 to the more inclusive "London West", it remained a separate municipality until ratepayers voted for amalgamation with London in 1897, largely due to repeated flooding. The most serious flood was that of July 1883, which resulted in serious loss of life and property devaluation. This area retains much original and attractively maintained 19th-century tradespeople's and workers' housing, including Georgian cottages as well as larger houses, and a distinct sense of place.
London's eastern suburb, London East, was (and remains) an industrial centre, which also incorporated in 1874. Attaining the status of town in 1881, it continued as a separate municipality until concerns over expensive waterworks and other fiscal problems led to amalgamation in 1885. The southern suburb of London, including Wortley Village, was collectively known as "London South". Never incorporated, the South was annexed to the city in 1890, although Wortley Village still retains a distinct sense of place. By contrast, the settlement at Broughdale on the city's north end had a clear identity, adjoined the university, and was not annexed until 1961.
On 24 May 1881, the ferry "SS Victoria" capsized in the Thames River, drowning approximately 200 passengers, the worst disaster in London's history. Two years later, on 12 July 1883, the first of the two most devastating floods in London's history killed 17 people. The second major flood, on 26 April 1937, destroyed more than a thousand houses and caused over $50 million in damages, particularly in West London. After repeated floods the Upper Thames River Conservation Authority in 1953 built Fanshawe Dam on the North Thames to control the downstream rivers. Financing for this project came from the federal, provincial, and municipal governments. Other natural disasters include a 1984 tornado that led to damage on several streets in the White Oaks area of South London.
London's role as a military centre continued into the 20th century during the two World Wars, serving as the administrative centre for the Western Ontario district. In 1905, the London Armoury was built and housed the First Hussars until 1975. A private investor purchased the historic site and built a new hotel (Delta London Armouries, 1996)in its place preserving the shell of the historic building. In the 1950s, two reserve battalions amalgamated and became London and Oxford Rifles (3rd Battalion), The Royal Canadian Regiment. This unit continues to serve today as 4th Battalion, The Royal Canadian Regiment. The Regimental Headquarters of The Royal Canadian Regiment remains in London at Wolseley Barracks on Oxford Street. The barracks are home to the First Hussars militia regiment as well.
Annexation to present.
London annexed many of the surrounding communities in 1961, including Byron and Masonville, adding 60,000 people and more than doubling its area. After this amalgamation, suburban growth accelerated as London grew outward in all directions, creating expansive new subdivisions such as Westmount, Oakridge, Whitehills, Pond Mills, White Oaks and Stoneybrook.
In 1992, London annexed nearly the entire township of Westminster, a large, primarily rural municipality directly south of the city, including the police village of Lambeth. With this massive annexation, London almost doubled in area again, adding several thousand more residents. London now stretches south to the boundary with Elgin County.
The 1993 annexation made London one of the largest urban municipalities in Ontario. Intense commercial and residential development is presently occurring in the southwest and northwest areas of the city. Opponents of this development cite urban sprawl, destruction of rare Carolinian zone forest and farm lands, replacement of distinctive regions by generic malls, and standard transportation and pollution concerns as major issues facing London. The City of London is currently the eleventh-largest urban area in Canada, eleventh-largest census metropolitan area in Canada, and the sixth-largest city in Ontario.
Geography.
The area was formed during the retreat of the glaciers during the last ice age, which produced areas of marshland, notably the Sifton Bog (which is actually a fen), as well as some of the most agriculturally productive areas of farmland in Ontario.
The Thames River dominates London's geography. The North and South branches of the Thames River meet at the centre of the city, a location known as "The Forks" or "The Fork of the Thames." The North Thames runs through the man-made Fanshawe Lake, located in northeast London. Fanshawe Lake was created by Fanshawe Dam, constructed to protect the downriver areas from the catastrophic flooding which affected the city in 1883 and 1937.
Climate.
London has a humid continental climate (Köppen "Dfb"), though due to its downwind location relative to Lake Huron and elevation changes across the city, it is virtually on the Dfa/Dfb (hot summer) boundary favouring the former climate zone to the southwest of the confluence of the South and North Thames Rivers, and the latter zone to the northeast (including the airport). Because of its location in the continent, London experiences large seasonal contrast, tempered to a point by the surrounding Great Lakes. The summers are usually warm to hot and humid, with a July average of , and temperatures above occur on average 10 days per year. In 2012, however, temperatures at or above occurred a total of 27 times. The city is affected by frequent thunderstorms due to hot, humid summer weather, as well as the convergence of breezes originating from Lake Huron and Lake Erie. The same convergence zone is responsible for spawning funnel clouds and the occasional tornado. London is located in Canada's Tornado Alley. Spring and autumn in between are not long, and winters are cold but witness frequent thaws. Annual precipitation averages . Its winter snowfall totals are heavy, averaging about per year. The majority of it comes from lake effect snow and snow squalls originating from Lake Huron, some to the northwest, which occurs when strong, cold winds blow from that direction. From 5 December 2010, to 9 December 2010, London experienced record snowfall when up to of snow fell in parts of the city. Schools and businesses were closed for three days and bus service was cancelled after the second day of snow.
The highest temperature ever recorded in London was 41.1 °C (106 °F) on 6 August 1918. The lowest temperature ever recorded was -32.2 °C (-26 °F) on 20 January 1892.
Parks.
London has a number of parks. Victoria Park in downtown London is a major centre of community events, attracting an estimated 1 million visitors per year. Other major parks include Harris Park, Gibbons Park, Fanshawe Conservation Area (Fanshawe Pioneer Village), Springbank Park, and Westminster Ponds. The city also maintains a number of gardens and conservatories.
Demographics.
According to the 2011 census, the city of London had a population of 366,151 people, a 3.9% increase from the 2006 population. Children under five accounted for approximately 5.2 percent of the resident population of London. The percentage of the resident population in London of retirement age (65 and over) is 13.7, also the percentage for Canada as a whole. The average age is 38.2 years of age, compared to 39.9 years of age for all of Canada.
Between 2006 and 2011, the population of metropolitan London grew by 3.7 percent, compared with an increase of 5.7 percent for Ontario as a whole.
According to the 2011 census, the majority of Londoners profess a Christian faith, which accounts for 62.8 percent of the population (Roman Catholic: 27.0%, Protestant: 25.0%, other Christian: 9.0%). Other religions include Islam (4.4%), Buddhism (0.8%), Hinduism (0.8%), and Judaism (0.5%), with 29.9 percent of the population reporting no religious affiliation.
According to the 2011 census, 82.0 percent of the population of London are European, 2.7 percent are Latin American, 2.6 percent are Arab, 2.4 percent are Black, 2.2 percent are South Asian, 2.0 percent are Chinese Canadian, 1.9 percent are Aboriginal, 1.0 percent are Southeast Asian, 0.8 percent are West Asian, 0.8 percent are Korean Canadian, 0.6 percent are Filipino, and 0.7 percent belong to other groups. In the 2011 census, the predominant ethnic origins of Londoners were English (30.5%), Canadian (26.0%), Scottish (20.8%), Irish (20.3%), German (11.5%), French (10.1%), Dutch (6.2%), Italian (4.7%), Polish (4.4%), Portuguese (2.8%), and Ukrainian (2.5%).
In February 2015, Statistics Canada published a population estimate of the London CMA of 502,360, as of July 1, 2014.
Economy.
London's economy is dominated by medical research, insurance, manufacturing, and information technology. Much of the life sciences and biotechnology-related research is conducted or supported by the University of Western Ontario, which adds about C$1.5 billion to the London economy annually.
The headquarters of the Canadian division of 3M are located in London. The London Life Insurance Company was founded there, as was Imperial Oil (in 1880) and both the Labatt and Carling breweries. The Libro Financial Group was founded in London 1951 and is the second largest credit union in Ontario and employs over 550 people.Canada Trust was also founded in London in 1864. The TD-Canada Trust tower is still one of the tallest buildings in London, and has been home to two nesting peregrine falcons for more than a decade.
General Dynamics Land Systems builds armoured personnel carriers in the city. GDLS has a 14-year $15-billion deal to supply light armoured vehicles to Saudi Arabia. There are 2,000 workers at GDLS Canada. A $223 million expansion project in 1984 temporarily made Kellogg's Canada's London plant one of the most technologically advanced manufacturing facilities in the Kellogg Company. In late 2013, Kellogg's announced the closure of this plant by end of 2014, resulting in 500 jobs lost (production to move to Belleville and Michigan plants).
A portion of the city's population work in factories outside of the city limits, including the General Motors automotive plant CAMI, and a Toyota plant in Woodstock. A Ford plant in Talbotville became one of the casualties of the economic crisis in 2011.
In 1999, the Western Fair Association introduced slot machines. Currently, 750 slot machines operate at the fair grounds year-round. McCormick Canada, formerly Club House Foods, was founded in 1883 and currently employs more than 500 Londoners.
London's city centre mall, Galleria, renamed Citi Plaza in 2009, has suffered since the 2000 collapse of Eaton's and the loss of its Hudson's Bay Company store. The large space left empty by the departure of the Bay has since been filled by London's central library. Other sections of Galleria/Citi Plaza have also lost businesses, which have been replaced by campuses for London's major post-secondary education schools, Fanshawe College and the University of Western Ontario. London Mews, another downtown mall, was demolished in 2001 and replaced by parking lots.
11 December 2009, Minister of State Gary Goodyear announced a new $11-million cargo terminal at the London International Airport.
Culture.
The city is home to many festivals, funded by the London Arts Council, including Sunfest, the Home County Folk Festival, the London Fringe Theatre Festival, the Expressions in Chalk Street Painting Festival, Rock the Park, Western Fair, the London Ontario Live Arts Festival (LOLA) and The International Food Festival]]. The London Rib-Fest, where barbecue ribs are cooked and served, is the second largest barbecue rib festival in North America. Pride London Festival is the 11th largest Pride festival in Ontario. Sunfest, a World music festival, is the second biggest in Canada after Caribana in Toronto, and is among the top 100 summer destinations in North America.
Musically, London is home to Orchestra London, the London Youth Symphony, noise music pioneers the Nihilist Spasm Band, and the Amabile Choirs of London, Canada.
London is home to several museums, including Museum London, which is located at the Forks of the Thames. Museum London exhibits art by a wide variety of local, regional and national artists. London is also home to the Museum of Ontario Archaeology, owned by the University of Western Ontario (UWO). Its main feature is Canada's only on-going excavation and partial reconstruction of a prehistoric village of the Neutral Nation (Lawson Site). Other museums include the London Regional Children’s Museum, the Royal Canadian Regiment Museum, and the Secrets of Radar Museum. The Guy Lombardo museum closed to the public in 2007 but its collection remains in London.
London is also home to the McIntosh Gallery, an art gallery on the UWO campus, and the Grand Theatre, a professional theatre. The Open House Arts Collective is involved in promoting cultural activities in London. The London Public Library also hosts art exhibitions and author readings. The Writers Resource Center is the home of the Canadian Poetry Association London Chapter. The Forest City Gallery is one of Canada's first artist run centres.
Eldon House is the former residence of the prominent Harris Family and oldest surviving such building in London. The entire property was donated to the city of London in 1959 and is now a heritage site. An Ontario Historical Plaque was erected by the province to commemorate The Eldon House's role in Ontario's heritage. The Banting House National Historic Site of Canada is the house where Sir Frederick Banting thought of the idea that led to the discovery of insulin. Banting lived and practiced in London for ten months, from July 1920 to May 1921. London is also the site of the Flame of Hope, which is intended to burn until a cure for diabetes is discovered.
For famous people born in London, Ontario see List of people from London, Ontario.
Sports.
London is currently the home of the London Knights of the Ontario Hockey League, who play at the Budweiser Gardens (previously known as the John Labatt Centre). The Knights were both 2004-2005 OHL and Memorial Cup Champions. During the summer months, the London Majors of the Intercounty Baseball League play at Labatt Park. London City of the Canadian Soccer League, is the highest level of soccer in London. The club was founded in 1973; it is the oldest active professional soccer franchise in North America. The squad plays at Cove Road Stadium at the German Canadian Club. Other sports teams include the London Silver Dolphins Swim Team, the Forest City Volleyball Club, London Cricket Club, the London St. George's Rugby Club, the London Aquatics Club, the London Rhythmic Gymnastics Club, London City Soccer Club and Forest City London.
Football teams include the London Beefeaters (Ontario Football Conference).
London's basketball team, the London Lightning plays at Budweiser Gardens as members of the National Basketball League of Canada. Finishing their inaugural regular season at 28-8, the Lightning would go on to win the 2011-12 NBL Canada championship, defeating the Halifax Rainmen in the finals three games to two.
There are also a number of former sports teams that have now either moved or folded. London's four former baseball teams are the London Monarchs (Canadian Baseball League), the London Werewolves (Frontier League), the London Tecumsehs (International Association) and the London Tigers (AA Eastern League). Other former sports teams include the London Lasers (Canadian Soccer League) and the London Nationals (Western Ontario Hockey League).
In March 2013, London hosted the 2013 World Figure Skating Championships.
The University of Western Ontario teams play under the name "Mustangs". The university's football team plays at TD Waterhouse Stadium. Western's Rowing Team rows out of one of two National Training Centres at Fanshawe Lake. Fanshawe College teams play under the name "Falcons". The Women's Cross Country team has won 3 consecutive Canadian Collegiate Athletic Association (CCAA) National Championships. In 2010, the program cemented itself as the first CCAA program to win both Men's and Women's National team titles, as well as CCAA Coach of the Year.
The Western Fair Raceway, about 85 acres harness racing track and simulcast centre, operates year-round. The grounds include a coin slot casino, a former IMAX theatre, and Sports and Agri-complex. Labatt Memorial Park the world's oldest continuously used baseball grounds was established as Tecumseh Park in 1877; it was renamed in 1937, because the London field has been flooded and rebuilt twice (1883 and 1937), including a re-orientation of the bases (after the 1883 flood). The Forest City Velodrome, located at the former London Ice House, is the only indoor cycling track in Ontario and the third to be built in North America, opened in 2005.
Law and government.
London's municipal government is divided among fourteen councillors (one representing each of London's fourteen wards) and the mayor. Matt Brown was elected mayor in the 2014 municipal election, officially taking office . Prior to Brown's election, London's most recent elected mayor was Joe Fontana; following Fontana's resignation on 19 June 2014, city councillor Joe Swan served as acting mayor until councillor Joni Baechler was selected as interim mayor 24 June. Until the elections in 2010, there was a Board of Control, consisting of four controllers and the mayor, all elected city-wide.
The composition of London City Council was challenged by two ballot questions during the civic election of 2003. A proposal to restructure the municipal government would have seen the council reduced to ten wards and the Board of Control eliminated. The council could not come to a determination and as a result decided to put two questions on the ballot for the fall 2003 election: whether city council should be reduced in size and whether the Board of Control should be eliminated. While the "yes" votes prevailed in both instances, the voter turnout failed to exceed 50 per cent and was therefore insufficient to make the decisions binding under the "Municipal Act". When the council voted to retain the status quo, Imagine London, a citizens group, petitioned the Ontario Municipal Board (OMB) to change the ward composition of the city from seven wards in a roughly radial pattern from the downtown core, to 14 wards defined by communities of interest.
The OMB ruled for the petitioners in December 2005 and, while the city sought leave to appeal the OMB decision via the courts, leave was denied on 28 February 2006, in a decision of Superior Court's Justice McDermid. In response, the city conceded change, but asked for special legislation from the province to ensure that there will only be one councillor in each of the 14 new wards, not two. 1 June 2006, the Ontario bill received royal assent, which guarantees that London will have one councillor per ward.
Although London has many ties to Middlesex County, it is now "separated" and the two have no jurisdictional overlap. The exception is the Middlesex County courthouse and former jail, as the judiciary is administered directly by the province.
In the provincial government, London is represented by Liberal Deb Matthews (London North Centre); Progressive Conservative Jeff Yurek (Elgin—Middlesex—London), and NDPs: Teresa Armstrong (London—Fanshawe) and Peggy Sattler (London West). In the federal government, London is represented by Conservatives Karen Vecchio (Elgin—Middlesex—London) and Susan Truppe (London North Centre), and NDP Irene Mathyssen (London—Fanshawe).
Serial killing.
Between 1959 and 1984, London contained the largest concentration of serial killers in the world, as the city was startled by 29 murders. During that time period, up to six serial killers may have been operating in London, though three were convicted for 13 of the killings: Gerald Thomas Archer (the "London Chamber Maid Slayer"), Christian Magee (the "Mad Slasher") and Russell Johnson (the "Balcony Killer"), with the other 16 murders still unsolved as of August 2015.
Civic initiatives.
The City of London initiatives in Old East London are helping to create a renewed sense of vigour in the East London Business District. Specific initiatives include the creation of the Old East Heritage Conservation District under Part V of the "Ontario Heritage Act", special Building Code policies and Facade Restoration Programs.
London is home to heritage properties representing a variety of architectural styles, including Queen Anne, Art Deco, Modern, and Brutalist
Londoners have become protective of the trees in the city, protesting "unnecessary" removal of trees. The City Council and tourist industry have created projects to replant trees throughout the city. As well, they have begun to erect metal trees of various colours in the downtown area, causing some controversy.
Transportation.
Road transportation.
London is at the junction of Highway 401 that connects the city to Toronto and Detroit, and Highway 402 to Sarnia. Also, Highway 403, which diverges from the 401 at nearby Woodstock, Ontario, provides ready access to Brantford, Hamilton, the Golden Horseshoe area, and the Niagara Peninsula. Many smaller two-lane highways also pass through or near London, including Kings Highways 2, 3, 4, 7 and 22. Many of these are "historical" names, as provincial downloading in the 1980s and 1990s put responsibility for most provincial highways on municipal governments. Nevertheless, these roads continue to provide access from London to nearby communities and locations in much of Western Ontario, including Goderich, Port Stanley and Owen Sound.
Since the 1970s, London has improved urban road alignments that eliminated "jogs" in established traffic patterns over 19th-century street mis-alignments. The lack of a municipal freeway (either through or around the city) as well as the presence of two significant railways (each with attendant switching yards and few over/under-passes) are the primary causes of rush hour congestion, along with construction and heavy snow. Thus, traffic times can be significantly variable, although major traffic jams are rare. Wellington Road between Commissioners Road E and Southdale Road E is London's busiest section of roadway, with more than 46,000 vehicles using the span on an average day City council rejected early plans for the construction of a freeway, and instead accepted the Veterans Memorial Parkway to serve the east end. Some Londoners have expressed concern that the absence of a local freeway may hinder London's economic and population growth, while others have voiced concern that such a freeway would destroy environmentally sensitive areas and further contribute to London's already uncontrolled suburban sprawl. Road capacity improvements have been made to Veterans Memorial Parkway (formerly named Airport Road and Highway 100) in the industrialized east end. However, the Parkway has received criticism for not being built as a proper highway; a recent city-run study suggested upgrading it by replacing the intersections with interchanges.
London's public transit system is run by the London Transit Commission, which has 38 bus routes throughout the city. The Transit Commission has been improving bus service over the years, but not enough to cope with the city's growing number of riders during peak periods. Bus service is currently the only mode of public transit available to the public in London, with no ground light rail or rapid transit networks like those used in other Canadian cities. London does have several taxi and for-hire limousine services. Recently, London has constructed cycleways along some of its major arteries in order to encourage a reduction in automobile use.
Intercity transport.
London is on the Canadian National Railway main line between Toronto and Chicago (with a secondary main line to Windsor) and the Canadian Pacific Railway main line between Toronto and Detroit. Via Rail operates regional passenger service through London station as part of the Quebec City–Windsor Corridor, with connections to the United States. Via Rail's London terminal is the fourth-busiest passenger terminal in Canada.
London is also a destination for inter-city bus travellers. London is the seventh-busiest Greyhound Canada terminal in terms of passengers, and connecting services radiate from London throughout Southwestern Ontario and through to the American cities of Detroit, Michigan and Chicago, Illinois.
Aboutown Transportation is a diversified transportation company based in the city that operates the "North Link", intercity bus service from Owen Sound, and six transit bus routes between Kings and Brescia Colleges, and the main campus at the University of Western Ontario.
London International Airport (YXU) is the 12th busiest passenger airport in Canada and the 11th busiest airport in Canada by take-offs and landings. It is served by airlines including Air Canada Jazz, United Airlines and WestJet, and provides direct flights to both domestic and international destinations, including Toronto, Chicago, Las Vegas, Orlando, Ottawa, Winnipeg, Calgary and Cancún.
Plans.
The city of London is considering light rail (LRT), bus rapid transit (BRT) and/or high-occupancy vehicle lanes (HOV) to help it achieve its long-term transportation plan. Additional cycleways are planned for integration in road-widening projects, where there is need and sufficient space along routes. An expressway/freeway network is possible along the eastern and western ends of the city, from Highway 401 (and Highway 402 for the western route) past Oxford Street, potentially with another highway, joining the two in the city's north end.
A parclo interchange between Highway 401 and Wonderland Road has been planned to move traffic more efficiently through the city's southwest end. It will probably be built when the Ontario Ministry of Transportation widens Highway 401 from four to six lanes between Highway 4 and Highway 402 and reconstructs the outdated cloverleaf interchange with nearby Colonel Talbot Road. Construction will begin in 2013.
The City of London has assessed the entire length of the Veterans Memorial Parkway, identifying areas where interchanges can be constructed, grade separations can occur, and where cul-de-sacs can be placed. Upon completion, the Veterans Memorial Parkway would no longer be an expressway, but a freeway, for the majority of its length.
A high-speed rail station has been proposed for London, connecting it to a future high-speed rail line along the Quebec City-Windsor corridor. It would run along the Canadian National rail right of way through the city.
Education.
London public elementary and secondary schools are governed by four school boards – the Thames Valley District School Board, the London District Catholic School Board and the French first language school boards (the "Conseil scolaire Viamonde" and the "Conseil scolaire catholique Providence" or CSC). The CSC has a satellite office in London.
There are also more than twenty private schools in the city.
London is home to London Central Secondary School, the highest ranking academic school in Ontario.
The city is home to two post-secondary institutions: the University of Western Ontario (UWO) and Fanshawe College, a college of applied arts and technology. UWO, founded in 1878, has about 3500 full-time faculty and staff members and almost 30,000 undergraduate and graduate students. It placed tenth in the 2008 "Maclean's" magazine rankings of Canadian universities. The Richard Ivey School of Business, part of UWO, was formed in 1922 and ranked among the best business schools in the country by the Financial Times in 2009. UWO has three affiliated colleges: Brescia University College, founded in 1919 (Canada's only university-level women's college); Huron University College, founded in 1863 (also the founding college of UWO) and King's University College, founded in 1954. All three are liberal arts colleges with religious affiliations: Huron with the Anglican Church of Canada, King's and Brescia with the Roman Catholic Church. London is also home to Lester B. Pearson School for the Arts one of few of its kind.
Fanshawe College has an enrollment of approximately 15,000 students, including 3,500 apprentices and over 500 international students from over 30 countries. It also has almost 40,000 students in part-time continuing education courses. Fanshawe's Key Performance Indicators (KPI) have been over the provincial average for many years now, with increasing percentages year by year.
The Ontario Institute of Audio Recording Technology (OIART) is also in London. Founded in 1983, it offers recording studio experience for audio engineering students.
Westervelt College is also located in London. This private career college was founded in 1885 and offers several diploma programs.
Sister cities.
London currently has one sister city:

</doc>
<doc id="40355" url="https://en.wikipedia.org/wiki?curid=40355" title="Optimizing compiler">
Optimizing compiler

In computing, an optimizing compiler is a compiler that tries to minimize or maximize some attributes of an executable computer program. The most common requirement is to minimize the time taken to execute a program; a less common one is to minimize the amount of memory occupied. The growth of portable computers has created a market for minimizing the power consumed by a program. Compiler optimization is generally implemented using a sequence of "optimizing transformations", algorithms which take a program and transform it to produce a semantically equivalent output program that uses fewer resources.
It has been shown that some code optimization problems are NP-complete, or even undecidable. In practice, factors such as the programmer's willingness to wait for the compiler to complete its task place upper limits on the optimizations that a compiler implementor might provide. (Optimization is generally a very CPU- and memory-intensive process.) In the past, computer memory limitations were also a major factor in limiting which optimizations could be performed. Because of all these factors, optimization rarely produces "optimal" output in any sense, and in fact an "optimization" may impede performance in some cases; rather, they are heuristic methods for improving resource usage in typical programs.
Types of optimization.
Techniques used in optimization can be broken up among various "scopes" which can affect anything from a single statement to the entire program. Generally speaking, locally scoped techniques are easier to implement than global ones but result in smaller gains. Some examples of scopes include:
In addition to scoped optimizations there are two further general categories of optimization:
The following is an instance of a local machine dependent optimization. To set a register to 0, the obvious way is to use the constant '0' in an instruction that sets a register value to a constant. A less obvious way is to XOR a register with itself. It is up to the compiler to know which instruction variant to use. On many RISC machines, both instructions would be equally appropriate, since they would both be the same length and take the same time. On many other microprocessors such as the Intel x86 family, it turns out that the XOR variant is shorter and probably faster, as there will be no need to decode an immediate operand, nor use the internal "immediate operand register". (A potential problem with this is that XOR may introduce a data dependency on the previous value of the register, causing a pipeline stall. However, processors often have XOR of a register with itself as a special case that doesn't cause stalls.)
Common themes.
To a large extent, compiler optimization techniques have the following themes, which sometimes conflict.
Specific techniques.
Loop optimizations.
Some optimization techniques primarily designed to operate on loops include
Data-flow optimizations.
Data-flow optimizations, based on data-flow analysis, primarily depend on how certain properties of data are propagated by control edges in the control flow graph. Some of these include:
SSA-based optimizations.
These optimizations are intended to be done after transforming the program into a special form called static single assignment (see SSA form), in which every variable is assigned in only one place. Although some function without SSA, they are most effective with SSA. Many optimizations listed in other sections also benefit with no special changes, such as register allocation.
Functional language optimizations.
Although many of these also apply to non-functional languages, they either originate in, are most easily implemented in, or are particularly critical in functional languages such as Lisp and ML.
Other optimizations.
"Please help separate and categorize these further and create detailed pages for them, especially the more complex ones, or link to one where one exists."
Interprocedural optimizations.
Interprocedural optimization works on the entire program, across procedure and file boundaries. It works tightly with intraprocedural counterparts, carried out with the cooperation of a local part and global part. Typical interprocedural optimizations are: procedure inlining, interprocedural dead code elimination, interprocedural constant propagation, and procedure reordering. As usual, the compiler needs to perform interprocedural analysis before its actual optimizations. Interprocedural analyses include alias analysis, array access analysis, and the construction of a call graph.
Interprocedural optimization is common in modern commercial compilers from SGI, Intel, Microsoft, and Sun Microsystems. For a long time the open source GCC was criticized for a lack of powerful interprocedural analysis and optimizations, though this is now improving. Another open source compiler with full analysis and optimization infrastructure is Open64.
Due to the extra time and space required by interprocedural analysis, most compilers do not perform it by default. Users must use compiler options explicitly to tell the compiler to enable interprocedural analysis and other expensive optimizations.
Problems with optimization.
Early in the history of compilers, compiler optimizations were not as good as hand-written ones. As compiler technologies have improved, good compilers can often generate better code than human programmers, and good post pass optimizers can improve highly hand-optimized code even further. For RISC CPU architectures, and even more so for VLIW hardware, compiler optimization is the key for obtaining efficient code, because RISC instruction sets are so compact that it is hard for a human to manually schedule or combine small instructions to get efficient results. Indeed, these architectures were designed to rely on compiler writers for adequate performance.
However, optimizing compilers are by no means perfect. There is no way that a compiler can guarantee that, for all program source code, the fastest (or smallest) possible equivalent compiled program is output; such a compiler is fundamentally impossible because it would solve the halting problem (assuming Turing completeness).
This may be proven by considering a call to a function, foo(). This function returns nothing and does not have side effects (no I/O, does not modify global variables and "live" data structures, etc.). The fastest possible equivalent program would be simply to eliminate the function call. However, if the function foo() in fact does "not" return, then the program with the call to foo() would be different from the program without the call; the optimizing compiler will then have to determine this by solving the halting problem.
Additionally, there are a number of other more practical issues with optimizing compiler technology:
Work to improve optimization technology continues. One approach is the use of so-called post-pass optimizers (some commercial versions of which date back to mainframe software of the late 1970s). These tools take the executable output by an "optimizing" compiler and optimize it even further. Post pass optimizers usually work on the assembly language or machine code level (contrast with compilers that optimize intermediate representations of programs). The performance of post pass compilers are limited by the fact that much of the information available in the original source code is not always available to them.
As processor performance continues to improve at a rapid pace, while memory bandwidth improves more slowly, optimizations that reduce memory bandwidth requirements (even at the cost of making the processor execute relatively more instructions) will become more useful. Examples of this, already mentioned above, include loop nest optimization and rematerialization.
History.
Early compilers of the 1960s were often primarily concerned with simply compiling code correctly or efficiently – compile times were a major concern. One of the earliest notable optimizing compilers was that for BLISS (1970), which was described in "The Design of an Optimizing Compiler" (1975). By the 1980s optimizing compilers were sufficiently effective that programming in assembly language declined, and by the late 1990s for even performance sensitive code, optimizing compilers exceeded the performance of human experts. This co-evolved with the development of RISC chips and advanced processor features such as instruction scheduling and speculative execution which were designed to be targeted by optimizing compilers, rather than by human-written assembly code.

</doc>
<doc id="40359" url="https://en.wikipedia.org/wiki?curid=40359" title="Due process">
Due process

Due process is the legal requirement that the state must respect all legal rights that are owed to a person. Due process balances the power of law of the land and protects the individual person from it. When a government harms a person without following the exact course of the law, this constitutes a due process violation, which offends the rule of law.
Due process has also been frequently interpreted as limiting laws and legal proceedings (see substantive due process) so that judges, instead of legislators, may define and guarantee fundamental fairness, justice, and liberty. That interpretation has proven controversial. Analogous to the concepts of natural justice, and procedural justice used in various other jurisdictions, the interpretation of due process is sometimes expressed as a command that the government must not be unfair to the people or abuse them physically.
The term is not used in contemporary English law, but two similar concepts are natural justice, which generally applies only to decisions of administrative agencies and some types of private bodies like trade unions, and the British constitutional concept of the rule of law as articulated by A. V. Dicey and others. However, neither concept lines up perfectly with the American theory of due process, which, as explained below, presently contains many implied rights not found in either ancient or modern concepts of due process in England.
Due process developed from clause 39 of the Magna Carta in England. When English and American law gradually diverged, due process was not upheld in England but became incorporated in the US Constitution.
By jurisdiction.
Magna Carta.
In clause 39 of Magna Carta, issued in 1215, John of England promised: "No free man shall be seized or imprisoned, or stripped of his rights or possessions, or outlawed or exiled, or deprived of his standing in any other way, nor will we proceed with force against him, or send others to do so, except by the lawful judgment of his equals or by the law of the land." Magna Carta itself immediately became part of the "law of the land", and Clause 61 of that charter authorized an elected body of 25 barons to determine by majority vote what redress the King must provide when the King offends "in any respect against any man." Thus, Magna Carta established the rule of law in England by not only requiring the monarchy to obey the law of the land but also limiting how the monarchy could change the law of the land. However, in the 13th century, the provisions may have been referring only to the rights of landowners, and not to ordinary peasantry or villagers.
Shorter versions of Magna Carta were subsequently issued by British monarchs, and Clause 39 of Magna Carta was renumbered "29." The phrase "due process of law" first appeared in a statutory rendition of Magna Carta in 1354 during the reign of Edward III of England, as follows: "No man of what state or condition he be, shall be put out of his lands or tenements nor taken, nor disinherited, nor put to death, without he be brought to answer by due process of law."
In 1608, the English jurist Edward Coke wrote a treatise in which he discussed the meaning of Magna Carta. Coke explained that no man shall be deprived but by "legem terrae", the law of the land, "that is, by the common law, statute law, or custom of England... (that is, to speak it once and for all) by the due course, and process of law.."
Both the clause in Magna Carta and the later statute of 1354 were again explained in 1704 (during the reign of Queen Anne) by the Queen's Bench, in the case of "Regina v. Paty". In that case, the British House of Commons had deprived John Paty and certain other citizens of the right to vote in an election and committed them to Newgate Prison merely for the offense of pursuing a legal action in the courts. The Queen's Bench, in an opinion by Justice Powys, explained the meaning of "due process of law" as follows:
Chief Justice Holt dissented in this case because he believed that the commitment had not in fact been by a legal authority. The House of Commons had purported to legislate unilaterally, without approval of the British House of Lords, ostensibly to regulate the election of its members. Although the Queen's Bench held that the House of Commons had not infringed or overturned due process, John Paty was ultimately freed by Queen Anne when she prorogued Parliament.
English law and American law diverge.
Throughout centuries of British history, many laws and treatises asserted various requirements as being part of "due process" or included in the "law of the land". That view usually held in regards to what was required by existing law, rather than what was intrinsically required by due process itself. As the US Supreme Court has explained, a due process requirement in Britain was not "essential to the idea of due process of law in the prosecution and punishment of crimes, but was only mentioned as an example and illustration of due process of law as it actually existed in cases in which it was customarily used."
Ultimately, the scattered references to "due process of law" in English law did not limit the power of the government, and American law professor John Orth wrote that "the great phrases failed to retain their vitality." Orth points out that it is generally attributed to the rise of the doctrine of parliamentary supremacy in the United Kingdom, which was accompanied by hostility towards judicial review as an undemocratic foreign invention.
Scholars have occasionally interpreted Lord Coke's ruling in "Dr. Bonham's Case" as implying the possibility of judicial review, but by the 1870s, Lord Campbell was dismissing judicial review as "a foolish doctrine alleged to have been laid down extra-judicially in Dr. Bonham's Case..., a conundrum ought to have been laughed at." Lacking the power of judicial review, English courts possessed no means by which to declare government statutes or acts invalid as a violation of due process. As a consequence, English law and American law diverged, with American legislators possessing no means by which to declare judicial invalidation of statutes incorrect (with the sole exception of proposing a constitutional amendment, which is rarely successful). In 1977, an English political science professor explained the present situation in England for the benefit of American lawyers:
An American constitutional lawyer might well be surprised by the elusiveness of references to the term 'due process of law' in the general body of English legal writing... Today one finds no space devoted to due process in Halsbury's "Laws of England", in Stephen's "Commentaries", or Anson's "Law and Custom of the Constitution." The phrase rates no entry in such works as Stroud's "Judicial Dictionary" or Wharton's "Law Lexicon."
Two similar concepts in contemporary English law are natural justice, which generally applies only to decisions of administrative agencies and some types of private bodies like trade unions, and the British constitutional concept of the rule of law as articulated by A. V. Dicey and others. However, neither concept lines up perfectly with the American conception of due process, which presently contains many implied rights not found in the ancient or modern concepts of due process in England.
United States.
The Fifth and Fourteenth Amendments to the United States Constitution each contain a Due Process Clause. Due process deals with the administration of justice and thus the Due Process Clause acts as a safeguard from arbitrary denial of life, liberty, or property by the Government outside the sanction of law. The Supreme Court of the United States interprets the Clauses as providing four protections: procedural due process (in civil and criminal proceedings), substantive due process, a prohibition against vague laws, and as the vehicle for the incorporation of the Bill of Rights.
Others.
Various countries recognize some form of due process under customary international law. Although the specifics are often unclear, most nations agree that they should guarantee foreign visitors a basic minimum level of justice and fairness. Some nations have argued that they are bound to grant no more rights to aliens than they do to their own citizens, the doctrine of national treatment, which also means that both would be vulnerable to the same deprivations by the government. With the growth of international human rights law and the frequent use of treaties to govern treatment of foreign nationals abroad, the distinction, in practice, between these two perspectives may be disappearing.

</doc>
<doc id="40363" url="https://en.wikipedia.org/wiki?curid=40363" title="Dosimeter">
Dosimeter

A radiation dosimeter is a device that measures exposure to ionizing radiation. It has two main uses: for human radiation protection and for measurement of dose in both medical and industrial processes.
Personal dosimeters.
The personal ionising radiation dosimeter is of fundamental importance in the disciplines of radiation dosimetry and radiation health physics and is primarily used to estimate the radiation dose deposited in an individual wearing the device.
Ionising radiation damage to the human body is cumulative, and is related to the total dose received, for which the SI unit is the sievert. Workers exposed to radiation, such as radiographers, nuclear power plant workers, doctors using radiotherapy, those in laboratories using radionuclides, and HAZMAT teams are required to wear dosimeters so a record of occupational exposure can be made. Such devices are known as "legal dosimeters" if they have been approved for use in recording personnel dose for regulatory purposes.
Dosimeters can be worn to obtain a whole body dose and there are also specialist types that can be worn on the fingers or clipped to headgear, to measure the localised body irradiation for specific activities.
Types.
Common types of personal dosimeters for ionizing radiation include:
Electronic personal dosimeter (EPD).
The electronic personal dosimeter (EPD) is an electronic device that has a number of sophisticated functions, such as continual monitoring which allows alarm warnings at preset levels and live readout of dose accumulated. These are especially useful in high dose areas where residence time of the wearer is limited due to dose constraints. The dosimeter can be reset, usually after taking a reading for record purposes, and thereby re-used multiple times.
MOSFET dosimeter.
MOSFET dosimeters are now used as clinical dosimeters for radiotherapy radiation beams. The main advantages of MOSFET devices are:
1. The MOSFET dosimeter is direct reading with a very thin active area (less than 2 μm).
2. The physical size of the MOSFET when packaged is less than 4 mm.
3. The post radiation signal is permanently stored and is dose rate independent.
Gate oxide of MOSFET which is conventionally silicon dioxide is an active sensing material in MOSFET dosimeters. Radiation creates defects (acts like electron-hole pairs) in oxide, which in turn affects the threshold voltage of the MOSFET. This change in threshold voltage is proportional to radiation dose. Alternate high-k gate dielectrics like Hafnium dioxide and Aluminum oxides are also proposed as a radiation dosimeters.
Film badge dosimeter.
Film badge dosimeters are for one-time use only. The level of radiation absorption is indicated by a change to the film emulsion, which is shown when the film is developed.
Quartz fiber dosimeter.
Quartz fiber dosimeters are charged to a high voltage. As the gas in the dosimeter chamber becomes ionized by radiation the charge leaks away, causing the fiber indicator to change against a graduated scale.
Thermoluminescent dosimeter (TLD).
A thermoluminescent dosimeter measures ionizing radiation exposure by measuring the intensity of visible light emitted from a crystal in the detector when heated. The intensity of light emitted is dependent upon the radiation exposure.
Both the quartz fiber and film badge types are being superseded by the TLD and the EPD.
Radiation protection dose quantities.
The dosimeter plays an important role within the international radiation protection system developed by the International Commission on Radiological Protection (ICRP) and the International Commission on Radiation Units and Measurements (ICRU). This is shown in the accompanying diagram.
Protection quantities.
The protection quantities are used as "limiting quantities" to specify exposure limits to ensure that the occurrence of stochastic health effects is kept below unacceptable levels and that tissue reactions are avoided. These quantities cannot be practically measured and are a calculated value of irradiation of organs of the human body, which is arrived at by using an anthropomorphic phantom. This is a 3D computational model of the human body which attempts to take into account a number of complex effects such as body self-shielding and internal scattering of radiation.
As protection quantities cannot practically be measured, operational quantities are used to relate them to practical radiation instrument and dosimeter responses.
Operational quantities.
Operational quantities are aimed at providing an estimate or upper limit for the value of the protection quantities related to an exposure. They are used in practical regulations or guidance. These relate real-life operational instrument measurements and responses to the calculated protection quantities.
Personal dose equivalent, Hp(d), is defined by the ICRP as the dose equivalent in soft tissue at an appropriate depth, d, below a specified point on the human body. The specified point is usually given by the position where the individual’s dosimeter is worn.
Instrument and dosimeter response.
This is an actual reading obtained from such as an ambient dose gamma monitor, or a personal dosimeter. The dosimeter is calibrated in a known radiation field to ensure display of accurate operational quantities and allow a relationship to known health effect. The personal dose equivalent is used to assess dose uptake, and allow regulatory limits to be met. It is the figure usually entered into the records of external dose for occupational radiation workers.
Dosimeter calibration.
The "slab" phantom is used to represent the human torso for calibration of whole body dosimeters. The IAEA states "The slab phantom is 300 mm × 300 mm × 150 mm depth to represent the human torso".
Process irradiation verification.
Manufacturing processes that treat products with ionizing radiation, such as food irradiation, use dosimeters to calibrate doses deposited in the matter being irradiated. These usually must have a greater dose range than personal dosimeters, and doses are normally measured in the unit of absorbed dose: the gray (Gy). The dosimeter is located on or adjacent to the items being irradiated during the process as a validation of dose levels received.

</doc>
<doc id="40364" url="https://en.wikipedia.org/wiki?curid=40364" title="Electrometer">
Electrometer

An electrometer is an electrical instrument for measuring electric charge or electrical potential difference. There are many different types, ranging from historical handmade mechanical instruments to high-precision electronic devices. Modern electrometers based on vacuum tube or solid-state technology can be used to make voltage and charge measurements with very low leakage currents, down to 1 femtoampere. A simpler but related instrument, the electroscope, works on similar principles but only indicates the relative magnitudes of voltages or charges.
Older electrometers.
Gold-leaf electrometer.
The gold-leaf electroscope was one of the first sensitive instruments used to indicate electric charge. It is still used for science demonstrations but has been superseded in most applications by electronic measuring instruments. The instrument consists of two thin leaves of gold foil suspended from an electrode. When the electrode is charged by induction or by contact, the leaves acquire similar electric charges and repel each other due to the Coulomb force. Their separation is a direct indication of the net charge stored on them. On the glass opposite the leaves, pieces of tin foil may be pasted, so that when the leaves diverge fully they may discharge into the ground. The leaves may be enclosed in a glass envelope to protect them from drafts, and the envelope may be evacuated to minimize charge leakage. A further cause of charge leakage is ionizing radiation, so to prevent this, the electrometer must be surrounded by lead shielding. This principle has been used to detect ionizing radiation, as seen in the quartz fibre electrometer and Kearny fallout meter.
This type of electroscope usually acts as an indicator and not a measuring device, although it can be calibrated. The Braun electroscope replaced the gold-leaf electroscope for more accurate measurements.
The instrument was developed in the 18th century by several researchers, among them Abraham Bennet and Alessandro Volta.
Early quadrant electrometer.
While the term "quadrant electrometer" eventually referred to Kelvin's version, this term was first used to describe a simpler device. It consists of an upright stem of wood, to which is affixed to a semicircle of ivory. From the center there hangs a light cork ball upon a pivot. When the instrument is placed upon a charged body, the stem participates and repels the cork ball. The amount of repulsion may be read off the graduated semicircle, though it is obvious that the measured angle is not in direct proportion to the charge.
Coulomb's electrometer.
This design uses torsion to give a measurement more sensitive than repulsion of gold leaves or cork-balls. It consists of a glass cylinder with a glass tube on top. In the axes of the tube is a glass thread, the lower end of this holds a bar of gum lac, with a gilt pith ball at each extremity. Through another aperture on the cylinder, another gum lac rod with gilt balls may be introduced. This is called the carrier rod.
If the lower ball of the carrier rod is charged when it is entered into the aperture, this will repel one of the movable balls inside. An index and scale (not pictured) is attached to the top of the twistable glass rod. The number of degrees twisted to bring the balls back together is in exact proportion of the amount of charge of the ball of the carrier rod.
Peltier electrometer.
Developed by Peltier, this uses a form of magnetic compass to measure deflection by balancing the electrostatic force with a magnetic needle.
Bohnenberger electrometer.
The Bohnenberger electrometer, developed by J.G.F. von Bohnenberger, consists of a single gold leaf suspended vertically between the anode and cathode of a dry pile. Any charge imparted to the gold leaf causes it to move toward one or the other pole; thus, the sign of the charge as well as its approximate magnitude may be gauged.
Attraction electrometer.
Also known as Attracted Disk Electrometers, attraction electrometers are sensitive balances measuring the attraction between charged disks. William Snow Harris is credited with the invention of this instrument, which was further improved by Lord Kelvin.
Kelvin's quadrant electrometer.
Developed by Lord Kelvin, this is the most sensitive and accurate of all the mechanical electrometers. The original design uses a light aluminum sector suspended inside a drum cut into four segments. The segments are insulated and connected diagonally in pairs. The charged aluminum sector is attracted to one pair of segments and repelled from the other. The deflection is observed by a beam of light reflected from a small mirror attached to the sector, just as in a galvanometer. The engraving on the right shows a slightly different form of this electrometer, using four flat plates rather than closed segments. The plates can be connected externally in the conventional diagonal way (as shown), or in a different order for specific applications.
A more sensitive form of quadrant electrometer was developed by Frederick Lindemann. It employs a metal-coated quartz fiber instead of an aluminum sector. The deflection is measured by observing the movement of the fiber under a microscope. Initially used for measuring star light, it was employed for the infrared detection of airplanes in the early stages of World War II.
Some mechanic electrometers were housed inside a cage often referred to as a “bird cage”. This is a form of Faraday Cage that protected the instrument from external electrostatic charges.
Modern electrometers.
A modern electrometer is a highly sensitive electronic voltmeter whose input impedance is so high that the current flowing into it can be considered, for most practical purposes, to be zero. The actual value of input resistance for modern electronic electrometers is around 1014Ω, compared to around 1010Ω for nanovoltmeters. Owing to the extremely high input impedance, special design considerations must be applied to avoid leakage current such as driven shields and special insulation materials.
Among other applications, electrometers are used in nuclear physics experiments as they are able to measure the tiny charges left in matter by the passage of ionizing radiation. The most common use for modern electrometers is the measurement of radiation with ionization chambers, in instruments such as geiger counters.
Vibrating reed electrometers.
Vibrating reed electrometers use a variable capacitor formed between a moving electrode (in the form of a vibrating reed) and a fixed input electrode. As the distance between the two electrodes varies, the capacitance also varies and electric charge is forced in and out of the capacitor. The alternating current signal produced by the flow of this charge is amplified and used as an analogue for the DC voltage applied to the capacitor. The DC input resistance of the electrometer is determined solely by the leakage resistance of the capacitor, and is typically extremely high, (although its AC input impedance is lower).
For convenience of use, the vibrating reed assembly is often attached by a cable to the rest of the electrometer. This allows for a relatively small unit to be located near the charge to be measured while the much larger reed-driver and amplifier unit can be located wherever it is convenient for the operator.
Valve electrometers.
Valve electrometers use a specialized vacuum tube (thermionic valve) with a very high gain (transconductance) and input resistance. The input current is allowed to flow into the high impedance grid, and the voltage so generated is vastly amplified in the anode (plate) circuit. Valves designed for electrometer use have leakage currents as low as a few femtoamperes (10−15 amperes). Such valves must be handled with gloved hands as the salts left on the glass envelope can provide leakage paths for these tiny currents.
In a specialized circuit called "inverted triode", the roles of anode and grid are reversed. This places the control electrode at a maximum distance from the space-charge region surrounding the filament, minimizing the amount of electrons collected by the control electrode, and thus minimizing the input current.
Solid-state electrometers.
The most modern electrometers consist of a solid state amplifier using one or more field-effect transistors, connections for external measurement devices, and usually a display and/or data-logging connections. The amplifier amplifies small currents so that they are more easily measured. The external connections are usually of a co-axial or tri-axial design, and allow attachment of diodes or ionization chambers for ionising radiation measurement. The display or data-logging connections allow the user to see the data or record it for later analysis. Electrometers designed for use with ionization chambers may include a high-voltage power supply, which is used to power the ionization chamber.
Solid-state electrometers are often multipurpose devices that can measure voltage, charge, resistance and current. They measure voltage by means of "voltage balancing", in which the input voltage is compared with an internal reference voltage source using an electronic circuit with a very high input impedance (of the order of 1014 ohms). A similar circuit modified to act as a current-to-voltage converter enables the instrument to measure currents as small as a few femtoamperes. Combined with an internal voltage source, the current measuring mode can be adapted to measure very high resistances, of the order of 1017 ohms. Finally, by calculation from the known capacitance of the electrometer's input terminal, the instrument can measure very small electric charges, down to a small fraction of a picocoulomb. [http://www.keithley.com/data?asset=11894]

</doc>
<doc id="40365" url="https://en.wikipedia.org/wiki?curid=40365" title="Galvanometer">
Galvanometer

A galvanometer is an electromechanical instrument for detecting and measuring electric current. The most common use of galvanometers was as analog measuring instruments, called ammeters, used to measure the direct current (flow of electric charge) through an electric circuit. A galvanometer works as an actuator, by producing a rotary deflection (of a "pointer"), in response to electric current flowing through a coil in a constant magnetic field.
Galvanometers developed from the observation that the needle of a magnetic compass is deflected near a wire that has electric current flowing trough it, first described by Hans Oersted in 1820. They were the first instruments used to detect and measure small amounts of electric currents. The name comes from the Italian electricity researcher Luigi Galvani, who in 1791 discovered the principle of the frog galvanoscope – that electric current would make the legs of a dead frog jerk.
Sensitive galvanometers have been essential for the development of science and technology in many fields. For example they enabled long range communication through submarine cables, such as the earliest Transatlantic telegraph cables, and were essential to discovering the electrical activity of the heart and brain, by their fine measurements of current.
Galvanometers also had widespread use as the visualising part in other kinds of analog meters, for example in light meters, VU meters etcetera, where they were used to measure and display the output of other sensors. Today the main type of galvanometer mechanism, still in use, is the moving coil, D'Arsonval/Weston type.
Operation.
Modern galvanometers, of the D'Arsonval/Weston type, are constructed with a small pivoting coil of wire in the field of a permanent magnet. The coil is attached to a thin pointer that traverses a calibrated scale. A tiny torsion spring pulls the coil and pointer to the zero position.
When a direct current (DC) flows through the coil, the coil generates a magnetic field. This field acts against the permanent magnet. The coil twists, pushing against the spring, and moves the pointer. The hand points at a scale indicating the electric current. Careful design of the pole pieces ensures that the magnetic field is uniform, so that the angular deflection of the pointer is proportional to the current. A useful meter generally contains provision for damping the mechanical resonance of the moving coil and pointer, so that the pointer settles quickly to its position without oscillation.
The basic sensitivity of a meter might be, for instance, 100 microamperes full scale (with a voltage drop of, say, 50 millivolts at full current). Such meters are often calibrated to read some other quantity that can be converted to a current of that magnitude. The use of current dividers, often called shunts, allows a meter to be calibrated to measure larger currents. A meter can be calibrated as a DC voltmeter if the resistance of the coil is known by calculating the voltage required to generate a full scale current. A meter can be configured to read other voltages by putting it in a voltage divider circuit. This is generally done by placing a resistor in series with the meter coil. A meter can be used to read resistance by placing it in series with a known voltage (a battery) and an adjustable resistor. In a preparatory step, the circuit is completed and the resistor adjusted to produce full scale deflection. When an unknown resistor is placed in series in the circuit the current will be less than full scale and an appropriately calibrated scale can display the value of the previously unknown resistor.
These capabilities to translate different kinds of electric quantities, in to pointer movements, make the galvanometer ideal for turning output of other sensors that outputs electricity (in some form or another), into something that can be read by a human.
Because the pointer of the meter is usually a small distance above the scale of the meter, parallax error can occur when the operator attempts to read the scale line that "lines up" with the pointer. To counter this, some meters include a mirror along the markings of the principal scale. The accuracy of the reading from a mirrored scale is improved by positioning one's head while reading the scale so that the pointer and the reflection of the pointer are aligned; at this point, the operator's eye must be directly above the pointer and any parallax error has been minimized.
Uses.
Probably the largest use of galvanometers was of the D'Arsonval/Weston type used in analog meters in electronic equipment. Since the 1980s, galvanometer-type analog meter movements have been displaced by analog to digital converters (ADCs) for many uses. A digital panel meter (DPM) contains an analog to digital converter and numeric display. The advantages of a digital instrument are higher precision and accuracy, but factors such as power consumption or cost may still favour application of analog meter movements.
Modern uses.
Most modern uses for the galvanometer mechanism are in positioning and control systems. Galvanometer mechanisms are divided into moving magnet and moving coil galvanometers; in addition, they are divided into "closed-loop" and "open-loop" - or "resonant" - types. 
"Mirror" galvanometer systems are used as beam positioning or beam steering elements in laser scanning systems. For example, for material processing with high-power lasers, closed loop mirror galvanometer mechanisms are used with servo control systems. These are typically high power galvanometers and the newest galvanometers designed for beam steering applications can have frequency responses over 10 kHz with appropriate servo technology. Closed-loop mirror galvanometers are also used in similar ways in stereolithography, laser sintering, laser engraving, laser beam welding, laser TVs, laser displays and in imaging applications such as retinal scanning with Optical Coherence Tomography (OCT). Almost all of these galvanometers are of the moving magnet type.
Open loop, or resonant mirror galvanometers, are mainly used in some types of laser-based bar-code scanners, printing machines, imaging applications, military applications and space systems. Their non-lubricated bearings are especially of interest in applications that require functioning in a high vacuum.
Moving coil type galvanometer mechanisms are used for controlling the "head positioning" servos in hard disk drives and CD/DVD players, in order to keep mass (and thus access times), as low as possible.
Past uses.
A major early use for galvanometers was for finding faults in telecommunications cables. They were superseded in this application late in the 20th century by time-domain reflectometers.
Galvanometer mechanisms were also used to get readings from photoresistors in the metering mechanisms of film cameras (as seen in the image to the right).
In analog strip chart recorders such as used in electrocardiographs, electroencephalographs and polygraphs, galvanometer mechanisms were used to position the "pen". Strip chart recorders with galvanometer driven pens may have a full scale frequency response of 100 Hz and several centimeters of deflection. 
History.
The deflection of a magnetic compass needle by current in a wire was first described by Hans Oersted in 1820. The phenomenon was studied both for its own sake and as a means of measuring electric current. The earliest galvanometer was reported by Johann Schweigger at the University of Halle on 16 September 1820. André-Marie Ampère also contributed to its development. Early designs increased the effect of the magnetic field generated by the current by using multiple turns of wire. The instruments were at first called "multipliers" due to this common design feature. The term "galvanometer," in common use by 1836, was derived from the surname of Italian electricity researcher Luigi Galvani, who in 1791 discovered that electric current would make a dead frog's leg jerk.
Originally, the instruments relied on the Earth's magnetic field to provide the restoring force for the compass needle. These were called "tangent" galvanometers and had to be oriented before use. Later instruments of the "astatic" type used opposing magnets to become independent of the Earth's field and would operate in any orientation. The most sensitive form, the Thomson or mirror galvanometer, was patented in 1858 by William Thomson (Lord Kelvin) as an improvement of an earlier design invented in 1826 by Johann Christian Poggendorff. Thomson's design, was able to detect very rapid current changes, by using small magnets attached to a lightweight mirror, suspended by a thread, instead of a compass needle. The deflection of a light beam on the mirror greatly magnified the deflection induced by small currents. Alternatively, the deflection of the suspended magnets could be observed directly through a microscope.
The ability to measure quantitatively voltage and current allowed Georg Ohm to formulate that – the voltage across a conductor is directly proportional to the current through it – Ohm's Law.
The early moving-magnet form of galvanometer had the disadvantage that it was affected by any magnets or iron masses near it, and its deflection was not linearly proportional to the current. In 1882 Jacques-Arsène d'Arsonval and Marcel Deprez developed a form with a stationary permanent magnet and a moving coil of wire, suspended by fine wires which provided both an electrical connection to the coil and the restoring torque to return to the zero position. An iron tube between the magnet's pole pieces defined a circular gap through which the coil rotated. This gap produced a consistent, radial magnetic field across the coil, giving a linear response throughout the instrument's range. A mirror attached to the coil deflected a beam of light to indicate the coil position. The concentrated magnetic field and delicate suspension made these instruments sensitive; d'Arsonval's initial instrument could detect ten microamperes.
Edward Weston extensively improved the design. He replaced the fine wire suspension with a pivot, and provided restoring torque and electrical connections through spiral springs rather like those of a wristwatch balance wheel hairspring. He developed a method of stabilizing the magnetic field of the permanent magnet, so the instrument would have consistent accuracy over time. He replaced the light beam and mirror with a knife-edge pointer that could be read directly. A mirror under the pointer, in the same plane as the scale, eliminated parallax observation error. To maintain the field strength, Weston's design used a very narrow circumferential slot through which the coil moved, with a minimal air-gap. This improved linearity of pointer deflection with respect to coil current. Finally, the coil was wound on a light-weight form made of conductive metal, which acted as a damper. By 1888, Edward Weston had patented and brought out a commercial form of this instrument, which became a standard electrical equipment component. It was known as a "portable" instrument because it was affected very little by mounting position or by transporting it from place to place. This design is almost universally used in moving-coil meters today.
Initially laboratory instruments relying on the Earth's own magnetic field to provide restoring force for the pointer, galvanometers were developed into compact, rugged, sensitive portable instruments essential to the development of electro-technology.
Types.
Some galvanometers use a solid pointer on a scale to show measurements; other very sensitive types use a miniature mirror and a beam of light to provide mechanical amplification of low-level signals.
Tangent galvanometer.
A tangent galvanometer is an early measuring instrument used for the measurement of electric current. It works by using a compass needle to compare a magnetic field generated by the unknown current to the magnetic field of the Earth. It gets its name from its operating principle, the tangent law of magnetism, which states that the tangent of the angle a compass needle makes is proportional to the ratio of the strengths of the two perpendicular magnetic fields. It was first described by Claude Pouillet in 1837.
A tangent galvanometer consists of a coil of insulated copper wire wound on a circular non-magnetic frame. The frame is mounted vertically on a horizontal base provided with levelling screws. The coil can be rotated on a vertical axis passing through its centre. A compass box is mounted horizontally at the centre of a circular scale. It consists of a tiny, powerful magnetic needle pivoted at the centre of the coil. The magnetic needle is free to rotate in the horizontal plane. The circular scale is divided into four quadrants. Each quadrant is graduated from 0° to 90°. A long thin aluminium pointer is attached to the needle at its centre and at right angle to it. To avoid errors due to parallax, a plane mirror is mounted below the compass needle.
In operation, the instrument is first rotated until the magnetic field of the Earth, indicated by the compass needle, is parallel with the plane of the coil. Then the unknown current is applied to the coil. This creates a second magnetic field on the axis of the coil, perpendicular to the Earth's magnetic field. The compass needle responds to the vector sum of the two fields, and deflects to an angle equal to the tangent of the ratio of the two fields. From the angle read from the compass's scale, the current could be found from a table. The current supply wires have to be wound in a small helix, like a pig's tail, otherwise the field due to the wire will affect the compass needle and an incorrect reading will be obtained.
Theory.
The galvanometer is oriented so that the plane of the coil is vertical and aligned along parallel to the horizontal component of the Earth's magnetic field (i.e. parallel to the local "magnetic meridian"). When an electric current flows through the galvanometer coil, a second magnetic field is created. At the center of the coil, where the compass needle is located, the coil's field is perpendicular to the plane of the coil. The magnitude of the coil's field is:
where is the current in amperes, is the number of turns of the coil and is the radius of the coil. These two perpendicular magnetic fields add vectorially, and the compass needle points along the direction of their resultant . The current in the coil causes the compass needle to rotate by an angle :
From tangent law, , i.e.
or
or , where is called the Reduction Factor of the tangent galvanometer.
One problem with the tangent galvanometer is that its resolution degrades at both high currents and low currents. The maximum resolution is obtained when the value of is 45°. When the value of is close to 0° or 90°, a large percentage change in the current will only move the needle a few degrees.
Geomagnetic field measurement.
A tangent galvanometer can also be used to measure the magnitude of the horizontal component of the geomagnetic field. When used in this way, a low-voltage power source, such as a battery, is connected in series with a rheostat, the galvanometer, and an ammeter. The galvanometer is first aligned so that the coil is parallel to the geomagnetic field, whose direction is indicated by the compass when there is no current through the coils. The battery is then connected and the rheostat is adjusted until the compass needle deflects 45 degrees from the geomagnetic field, indicating that the magnitude of the magnetic field at the center of the coil is the same as that of the horizontal component of the geomagnetic field. This field strength can be calculated from the current as measured by the ammeter, the number of turns of the coil, and the radius of the coils.
Astatic galvanometer.
Unlike a compass-needle galvanometer, the astatic galvanometer has two magnetic needles parallel to each other, but with the magnetic poles reversed. The needle assembly is suspended by a silk thread, and has no net magnetic dipole moment. It is not affected by the earth's magnetic field. The lower needle is inside the current sensing coils and is deflected by the magnetic field created by the passing current.
The "astatic galvanometer" was developed by Leopoldo Nobili in 1825.
Mirror galvanometer.
To get a higher level of precision, for extremely sensitive measuring equipment, the mirror galvanometer substituted the pointer with a lightweight mirror. Thus a beam of light, reflected from the mirror, acted as a long mass-less pointer. This kind of galvanometer were for example used as the receivers in early trans-Atlantic telegraph systems. In a device called an oscillograph, the moving beam of light was used, to produce graphs of current versus time, by recording measurements on photographic film. The string galvanometer was a type of mirror galvanometer so sensitive that it was used to make the first electrocardiogram of the electrical activity of the human heart.
Ballistic galvanometer.
A ballistic galvanometer is a type of sensitive galvanometer for measuring the quantity of charge discharged through it. In reality it is an integrator, unlike a current-measuring galvanometer, the moving part has a large moment of inertia that gives it a long oscillation period. It can be either of the moving coil or moving magnet type, commonly it is a mirror galvanometer.

</doc>
<doc id="40366" url="https://en.wikipedia.org/wiki?curid=40366" title="ADC">
ADC

ADC may refer to:

</doc>
<doc id="40367" url="https://en.wikipedia.org/wiki?curid=40367" title="Analog-to-digital converter">
Analog-to-digital converter

An analog-to-digital converter (ADC, A/D, A–D, or A-to-D) is a device that converts a continuous physical quantity (usually voltage) to a digital number that represents the quantity's amplitude.
The conversion involves quantization of the input, so it necessarily introduces a small amount of error. Furthermore, instead of continuously performing the conversion, an ADC does the conversion periodically, sampling the input. The result is a sequence of digital values that have been converted from a continuous-time and continuous-amplitude analog signal to a discrete-time and discrete-amplitude digital signal.
An ADC is defined by its bandwidth (the range of frequencies it can measure) and its signal to noise ratio (how accurately it can measure a signal relative to the noise it introduces). The actual bandwidth of an ADC is characterized primarily by its sampling rate, and to a lesser extent by how it handles errors such as aliasing. The dynamic range of an ADC is influenced by many factors, including the resolution (the number of output levels it can quantize a signal to), linearity and accuracy (how well the quantization levels match the true analog signal) and jitter (small timing errors that introduce additional noise). The dynamic range of an ADC is often summarized in terms of its effective number of bits (ENOB), the number of bits of each measure it returns that are on average not noise. An ideal ADC has an ENOB equal to its resolution. ADCs are chosen to match the bandwidth and required signal to noise ratio of the signal to be quantized. If an ADC operates at a sampling rate greater than twice the bandwidth of the signal, then perfect reconstruction is possible given an ideal ADC and neglecting quantization error. The presence of quantization error limits the dynamic range of even an ideal ADC, however, if the dynamic range of the ADC exceeds that of the input signal, its effects may be neglected resulting in an essentially perfect digital representation of the input signal.
An ADC may also provide an isolated measurement such as an electronic device that converts an input analog voltage or current to a digital number proportional to the magnitude of the voltage or current. However, some non-electronic or only partially electronic devices, such as rotary encoders, can also be considered ADCs. The digital output may use different coding schemes. Typically the digital output will be a two's complement binary number that is proportional to the input, but there are other possibilities. An encoder, for example, might output a Gray code.
The inverse operation is performed by a digital-to-analog converter (DAC).
Concepts.
Resolution.
The resolution of the converter indicates the number of discrete values it can produce over the range of analog values. The resolution determines the magnitude of the quantization error and therefore determines the maximum possible average signal to noise ratio for an ideal ADC without the use of oversampling. The values are usually stored electronically in binary form, so the resolution is usually expressed in bits. In consequence, the number of discrete values available, or "levels", is assumed to be a power of two. For example, an ADC with a resolution of 8 bits can encode an analog input to one in 256 different levels, since 28 = 256. The values can represent the ranges from 0 to 255 (i.e. unsigned integer) or from −128 to 127 (i.e. signed integer), depending on the application.
Resolution can also be defined electrically, and expressed in volts. The minimum change in voltage required to guarantee a change in the output code level is called the least significant bit (LSB) voltage. The resolution "Q" of the ADC is equal to the LSB voltage. The voltage resolution of an ADC is equal to its overall voltage measurement range divided by the number of discrete values:
where "M" is the ADC's resolution in bits and "E"FSR is the full scale voltage range (also called 'span'). "E"FSR is given by
where "V"RefHi and "V"RefLow are the upper and lower extremes, respectively, of the voltages that can be coded.
Normally, the number of voltage intervals is given by
where "M" is the ADC's resolution in bits.
That is, one voltage interval is assigned in between two consecutive code levels.
Example:
In practice, the useful resolution of a converter is limited by the best signal-to-noise ratio (SNR) that can be achieved for a digitized signal. An ADC can resolve a signal to only a certain number of bits of resolution, called the effective number of bits (ENOB). One effective bit of resolution changes the signal-to-noise ratio of the digitized signal by 6 dB, if the resolution is limited by the ADC. If a preamplifier has been used prior to A/D conversion, the noise introduced by the amplifier can be an important contributing factor towards the overall SNR.
Quantization error.
Quantization error is the noise introduced by quantization in an ideal ADC. It is a rounding error between the analog input voltage to the ADC and the output digitized value. The noise is non-linear and signal-dependent.
In an ideal analog-to-digital converter, where the quantization error is uniformly distributed between −1/2 LSB and +1/2 LSB, and the signal has a uniform distribution covering all quantization levels, the Signal-to-quantization-noise ratio (SQNR) can be calculated from
Where Q is the number of quantization bits. For example, a 16-bit ADC has a maximum signal-to-noise ratio of 6.02 × 16 = 96.3 dB, and therefore the quantization error is 96.3 dB below the maximum level. Quantization error is distributed from DC to the Nyquist frequency, consequently if part of the ADC's bandwidth is not used (as in oversampling), some of the quantization error will fall out of band, effectively improving the SQNR. In an oversampled system, noise shaping can be used to further increase SQNR by forcing more quantization error out of the band.
Dither.
In ADCs, performance can usually be improved using dither. This is a very small amount of random noise (white noise), which is added to the input before conversion.
Its effect is to cause the state of the LSB to randomly oscillate between 0 and 1 in the presence of very low levels of input, rather than sticking at a fixed value. Rather than the signal simply getting cut off altogether at this low level (which is only being quantized to a resolution of 1 bit), it extends the effective range of signals that the ADC can convert, at the expense of a slight increase in noise – effectively the quantization error is diffused across a series of noise values which is far less objectionable than a hard cutoff. The result is an accurate representation of the signal over time. A suitable filter at the output of the system can thus recover this small signal variation.
An audio signal of very low level (with respect to the bit depth of the ADC) sampled without dither sounds extremely distorted and unpleasant. Without dither the low level may cause the least significant bit to "stick" at 0 or 1. With dithering, the true level of the audio may be calculated by averaging the actual quantized sample with a series of other samples dither that are recorded over time.
A virtually identical process, also called dither or dithering, is often used when quantizing photographic images to a fewer number of bits per pixel—the image becomes noisier but to the eye looks far more realistic than the quantized image, which otherwise becomes banded. This analogous process may help to visualize the effect of dither on an analogue audio signal that is converted to digital.
Dithering is also used in integrating systems such as electricity meters. Since the values are added together, the dithering produces results that are more exact than the LSB of the analog-to-digital converter.
Note that dither can only increase the resolution of a sampler, it cannot improve the linearity, and thus accuracy does not necessarily improve.
Accuracy.
An ADC has several sources of errors. Quantization error and (assuming the ADC is intended to be linear) non-linearity are intrinsic to any analog-to-digital conversion.
These errors are measured in a unit called the least significant bit (LSB). In the above example of an eight-bit ADC, an error of one LSB is 1/256 of the full signal range, or about 0.4%.
Non-linearity.
All ADCs suffer from non-linearity errors caused by their physical imperfections, causing their output to deviate from a linear function (or some other function, in the case of a deliberately non-linear ADC) of their input. These errors can sometimes be mitigated by calibration, or prevented by testing.
Important parameters for linearity are integral non-linearity (INL) and differential non-linearity (DNL). These non-linearities reduce the dynamic range of the signals that can be digitized by the ADC, also reducing the effective resolution of the ADC.
Jitter.
When digitizing a sine wave formula_5, the use of a non-ideal sampling clock will result in some uncertainty in when samples are recorded. Provided that the actual sampling time "uncertainty" due to the "clock jitter" is formula_6, the error caused by this phenomenon can be estimated as formula_7. This will result in additional recorded noise that will reduce the effective number of bits (ENOB) below that predicted by quantization error alone.
The error is zero for DC, small at low frequencies, but significant when high frequencies have high amplitudes. This effect can be ignored if it is drowned out by the "quantizing error". Jitter requirements can be calculated using the following formula: formula_8, where q is the number of ADC bits.
Clock jitter is caused by phase noise.
The resolution of ADCs with a digitization bandwidth between 1 MHz and 1 GHz is limited by jitter.
When sampling audio signals at 44.1 kHz, the anti-aliasing filter should have eliminated all frequencies above 22 kHz.
The input frequency (in this case, < 22 kHz), not the ADC clock frequency, is the determining factor with respect to jitter performance.
Sampling rate.
The analog signal is continuous in time and it is necessary to convert this to a flow of digital values. It is therefore required to define the rate at which new digital values are sampled from the analog signal. The rate of new values is called the "sampling rate" or "sampling frequency" of the converter.
A continuously varying bandlimited signal can be sampled (that is, the signal values at intervals of time T, the sampling time, are measured and stored) and then the original signal can be "exactly" reproduced from the discrete-time values by an interpolation formula. The accuracy is limited by quantization error. However, this faithful reproduction is only possible if the sampling rate is higher than twice the highest frequency of the signal. This is essentially what is embodied in the Shannon-Nyquist sampling theorem.
Since a practical ADC cannot make an instantaneous conversion, the input value must necessarily be held constant during the time that the converter performs a conversion (called the "conversion time"). An input circuit called a sample and hold performs this task—in most cases by using a capacitor to store the analog voltage at the input, and using an electronic switch or gate to disconnect the capacitor from the input. Many ADC integrated circuits include the sample and hold subsystem internally.
Aliasing.
An ADC works by sampling the value of the input at discrete intervals in time. Provided that the input is sampled above the Nyquist rate, defined as twice the highest frequency of interest, then all frequencies in the signal can be reconstructed. If frequencies above half the Nyquist rate are sampled, they are incorrectly detected as lower frequencies, a process referred to as aliasing. Aliasing occurs because instantaneously sampling a function at two or fewer times per cycle results in missed cycles, and therefore the appearance of an incorrectly lower frequency. For example, a 2 kHz sine wave being sampled at 1.5 kHz would be reconstructed as a 500 Hz sine wave.
To avoid aliasing, the input to an ADC must be low-pass filtered to remove frequencies above half the sampling rate. This filter is called an "anti-aliasing filter", and is essential for a practical ADC system that is applied to analog signals with higher frequency content. In applications where protection against aliasing is essential, oversampling may be used to greatly reduce or even eliminate it.
Although aliasing in most systems is unwanted, it should also be noted that it can be exploited to provide simultaneous down-mixing of a band-limited high frequency signal (see undersampling and frequency mixer). The alias is effectively the lower heterodyne of the signal frequency and sampling frequency.
Oversampling.
Signals are often sampled at the minimum rate required, for economy, with the result that the quantization noise introduced is white noise spread over the whole pass band of the converter. If a signal is sampled at a rate much higher than the Nyquist rate and then digitally filtered to limit it to the signal bandwidth there are the following advantages:
Oversampling is typically used in audio frequency ADCs where the required sampling rate (typically 44.1 or 48 kHz) is very low compared to the clock speed of typical transistor circuits (>1 MHz). In this case, by using the extra bandwidth to distribute quantization error onto out of band frequencies, the accuracy of the ADC can be greatly increased at no cost. Furthermore, as any aliased signals are also typically out of band, aliasing can often be completely eliminated using very low cost filters.
Relative speed and precision.
The speed of an ADC varies by type. The Wilkinson ADC is limited by the clock rate which is processable by current digital circuits. Currently, frequencies up to 300 MHz are possible. For a successive-approximation ADC, the conversion time scales with the logarithm of the resolution, e.g. the number of bits. Thus for high resolution, it is possible that the successive-approximation ADC is faster than the Wilkinson. However, the time consuming steps in the Wilkinson are digital, while those in the successive-approximation are analog. Since analog is inherently slower than digital, as the resolution increases, the time required also increases. Thus there are competing processes at work. Flash ADCs are certainly the fastest type of the three. The conversion is basically performed in a single parallel step. For an 8-bit unit, conversion takes place in a few tens of nanoseconds.
There is, as expected, somewhat of a tradeoff between speed and precision. Flash ADCs have drifts and uncertainties associated with the comparator levels. This results in poor linearity. For successive-approximation ADCs, poor linearity is also present, but less so than for flash ADCs. Here, non-linearity arises from accumulating errors from the subtraction processes. Wilkinson ADCs have the highest linearity of the three. These have the best differential non-linearity. The other types require channel smoothing to achieve the level of the Wilkinson.
The sliding scale principle.
The sliding scale or randomizing method can be employed to greatly improve the linearity of any type of ADC, but especially flash and successive approximation types. For any ADC the mapping from input voltage to digital output value is not exactly a floor or ceiling function as it should be. Under normal conditions, a pulse of a particular amplitude is always converted to a digital value. The problem lies in that the ranges of analog values for the digitized values are not all of the same width, and the differential linearity decreases proportionally with the divergence from the average width. The sliding scale principle uses an averaging effect to overcome this phenomenon. A random, but known analog voltage is added to the sampled input voltage. It is then converted to digital form, and the equivalent digital amount is subtracted, thus restoring it to its original value. The advantage is that the conversion has taken place at a random point. The statistical distribution of the final levels is decided by a weighted average over a region of the range of the ADC. This in turn desensitizes it to the width of any specific level.
ADC types.
These are the most common ways of implementing an electronic ADC:
There can be other ADCs that use a combination of electronics and other technologies:
Commercial analog-to-digital converters.
Commercial ADCs are usually implemented as integrated circuits.
Most converters sample with 6 to 24 bits of resolution, and produce fewer than 1 megasample per second. Thermal noise generated by passive components such as resistors masks the measurement when higher resolution is desired. For audio applications and in room temperatures, such noise is usually a little less than (microvolt) of white noise. If the MSB corresponds to a of output signal, this translates to a noise-limited performance that is less than 20~21 bits, and obviates the need for any dithering. As of February 2002, Mega- and giga-sample per second converters are available. Mega-sample converters are required in digital video cameras, video capture cards, and TV tuner cards to convert full-speed analog video to digital video files.
Commercial converters usually have ±0.5 to ±1.5 LSB error in their output.
In many cases, the most expensive part of an integrated circuit is the pins, because they make the package larger, and each pin has to be connected to the integrated circuit's silicon. To save pins, it is common for slow ADCs to send their data one bit at a time over a serial interface to the computer, with the next bit coming out when a clock signal changes state, say from 0 to 5 V. This saves quite a few pins on the ADC package, and in many cases, does not make the overall design any more complex (even microprocessors which use memory-mapped I/O only need a few bits of a port to implement a serial bus to an ADC).
Commercial ADCs often have several inputs that feed the same converter, usually through an analog multiplexer. Different models of ADC may include sample and hold circuits, instrumentation amplifiers or differential inputs, where the quantity measured is the difference between two voltages.
Applications.
Music recording.
Analog-to-digital converters are integral to current music reproduction technology. People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
The current crop of analog-to-digital converters utilized in music can sample at rates up to 192 kilohertz. Considerable literature exists on these matters, but commercial considerations often play a significant role. Most high-profile recording studios record in 24-bit/192-176.4 kHz pulse-code modulation (PCM) or in Direct Stream Digital (DSD) formats, and then downsample or decimate the signal for Red-Book CD production (44.1 kHz) or to 48 kHz for commonly used radio and television broadcast applications.
Digital signal processing.
People must use ADCs to process, store, or transport virtually any analog signal in digital form. TV tuner cards, for example, use fast video analog-to-digital converters. Slow on-chip 8, 10, 12, or 16 bit analog-to-digital converters are common in microcontrollers. Digital storage oscilloscopes need very fast analog-to-digital converters, also crucial for software defined radio and their new applications.
Scientific instruments.
Digital imaging systems commonly use analog-to-digital converters in digitizing pixels.
Some radar systems commonly use analog-to-digital converters to convert signal strength to digital values for subsequent signal processing. Many other in situ and remote sensing systems commonly use analogous technology.
The number of binary bits in the resulting digitized numeric values reflects the resolution, the number of unique discrete levels of quantization (signal processing). The correspondence between the analog signal and the digital signal depends on the quantization error. The quantization process must occur at an adequate speed, a constraint that may limit the resolution of the digital signal.
Many sensors produce an analog signal; temperature, pressure, pH, light intensity etc. All these signals can be amplified and fed to an ADC to produce a digital number proportional to the input signal.
Testing.
Testing an Analog to Digital Converter requires an analog input source, hardware to send control signals and capture digital data output. Some ADCs also require an accurate source of reference signal.
The key parameters to test a SAR ADC are the following:

</doc>
<doc id="40372" url="https://en.wikipedia.org/wiki?curid=40372" title="John Thaw">
John Thaw

John Edward Thaw, CBE (3 January 1942 – 21 February 2002) was an English actor. He appeared in a range of television, stage, and cinema roles, his most popular being television series such as "Inspector Morse", "Redcap", "The Sweeney", "Home to Roost", and "Kavanagh QC".
Early life.
Thaw was born in Longsight, Manchester, to working class parents Dorothy (née Ablott) and John, a long-distance lorry driver. Thaw had a difficult childhood as his mother left when he was seven years old and he did not see her again for 12 years. His younger brother, Raymond Stuart "Ray" emigrated to Australia in the mid-1960s.</ref> Thaw grew up in Gorton and Burnage, attending the Ducie Technical High School for Boys. He entered the Royal Academy of Dramatic Art (RADA) at the age of 16, where he was a contemporary of Tom Courtenay.
Career.
Soon after leaving RADA Thaw made his formal stage début in "A Shred of Evidence" at the Liverpool Playhouse and was awarded a contract with the theatre. His first film role was a bit part in the 1962 adaptation of "The Loneliness of the Long Distance Runner" starring Tom Courtenay and he also acted on-stage opposite Sir Laurence Olivier in "Semi-Detached" (1962) by David Turner. He appeared in several episodes of the BBC police series "Z-Cars" in 1963–64 as a detective constable who left the force because of an unusual drink problem: he could not take the alcohol so often part of the policeman's work. Between 1964 and 1966, he starred in two series of the ABC Weekend Television/ITV production "Redcap", playing the hard-nosed military policeman Sergeant John Mann. He was also a guest star in an early episode of "The Avengers". In 1967 he appeared in the Granada TV/ITV series, "Inheritance", alongside James Bolam and Michael Goodliffe, as well as appearing in TV plays such as "The Talking Head" and episodes of series such as "Budgie", where he played against type (opposite Adam Faith) as an effeminate failed playwright with a full beard and a Welsh accent.
Thaw will perhaps be best remembered for two roles: the hard-bitten, tough talking Flying Squad detective Jack Regan in the Thames Television/ITV series (and two films) "The Sweeney" (1975–1978), which established him as a major star in the United Kingdom, and as the quietly spoken, introspective, well-educated and bitter detective "Inspector Morse" (1987–93, with specials from 1995–98 and 2000). 
Thaw was only 32 when he was cast in The Sweeney, although many viewers thought he was older. 
Thaw was the subject of "This Is Your Life" in 1981 when he was surprised by Eamonn Andrews in the foyer of the National Theatre, London.
Alongside his put-upon Detective Sergeant Lewis (Kevin Whately), Morse became a cult character—"a cognitive curmudgeon with his love of classical music, his classic Jaguar and spates of melancholy". Thaw was the definitive Morse, grumpy, crossword-fixated, drunk, slightly anti-feminist, and pedantic about grammar. Inspector Morse became one of the UK's most loved TV series; the final three episodes, shown in 2000, were seen by 18 million people, about one third of the British population, and have been enjoyed by global audiences for years. For example, repeat episodes are even currently (September 2015) enjoyed most weeks in Denmark on the main DR1 television channel in English with Danish subtitles. He won "Most Popular Actor" at the 1999 National Television Awards and won two BAFTA awards for his role as Morse.
He subsequently played liberal working-class Lancastrian barrister James Kavanagh in "Kavanagh QC" (1995–99, and a special in 2001). Thaw also tried his hand at comedy with two sitcoms—"Thick as Thieves" (London Weekend/ITV, 1974) with Bob Hoskins and "Home to Roost" (Yorkshire/ITV, 1985–90). Thaw is best known in America for the Morse series, as well as the BBC series "A Year in Provence" (1993) with Lindsay Duncan.
During the 1970s and '80s, Thaw frequently appeared in productions with the Royal Shakespeare Company and Royal National Theatre. He appeared in a number of films for director Richard Attenborough, including "Cry Freedom", where he portrayed the conservative South African justice minister Jimmy Kruger (for which he received a BAFTA nomination for Best Supporting Actor), and "Chaplin" alongside Robert Downey Jr..
Thaw also appeared in the TV adaptation of the Michelle Magorian book "Goodnight Mister Tom" (Carlton Television/ITV). It won "Most Popular Drama" at the National Television Awards, 1999. In September 2006, Thaw was voted by the general public as number 3 in a poll of "TV's Greatest Stars".
Personal life.
On 27 June 1964, Thaw married Sally Alexander, a feminist activist and theatre stage manager, and now professor of history at Goldsmiths, University of London. They divorced four years later. He met actress Sheila Hancock in 1969 on the set of a London comedy "So What About Love?" She was married to fellow actor Alexander "Alec" Ross, and after Thaw professed his love to Hancock, she told him that she would not have an affair. After the death of her husband (from oesophageal cancer) in 1971, Thaw and Hancock married on 24 December 1973 in Cirencester, and he remained with her until his death in 2002 (also from oesophageal cancer).
He had three daughters (all of whom are actresses): Abigail from his first marriage to Sally Alexander, Joanna from his second marriage to Sheila Hancock, and he also adopted Sheila Hancock's daughter Melanie Jane, from Hancock's first marriage to Alec Ross. Melanie Jane legally changed her surname from Ross to Thaw.
Thaw was a committed socialist and lifelong supporter of the Labour Party. He was appointed a Commander of the Most Excellent Order of the British Empire (CBE) in March 1993 by Queen Elizabeth II. In September 2006, Thaw was voted by the general public as number 3, after David Jason and Morecambe and Wise, in a poll of TV's 50 Greatest Stars for the past 50 years.
Illness and death.
A heavy drinker until going teetotal in 1995, and a heavy smoker from the age of 12, Thaw was diagnosed with cancer of the oesophagus in June 2001. He underwent chemotherapy in hope of overcoming the illness, and at first seemed to be responding well to the treatment, but just before Christmas 2001 he was told that the cancer had spread.
He died on 21 February 2002, seven weeks after his 60th birthday, the day after he signed a new contract with ITV, and the day before his wife's birthday. At the time of his death he was living at his country home, near the villages of Luckington and Sherston in Wiltshire, and was cremated in Westerleigh, near Yate in South Gloucestershire, in a private service. A memorial service was held on 4 September 2002 at St Martin-in-the-Fields church in Trafalgar Square, attended by 800 people including Prince Charles, Lord Attenborough, Sir Tom Courtenay and Cherie Blair.
Honours and awards.
Won
Nominated

</doc>
<doc id="40375" url="https://en.wikipedia.org/wiki?curid=40375" title="Outline of space technology">
Outline of space technology

Space technology – technology developed by space science or the aerospace industry for use in spaceflight, satellites, or space exploration. Space technology includes spacecraft, satellites, space stations, and support infrastructure, equipment, and procedures. Space is such a novel environment that attempting to work in it requires new tools and techniques. Many common everyday services such as weather forecasting, remote sensing, GPS systems, satellite television, and some long distance communications systems critically rely on space infrastructure. Of the sciences, astronomy and Earth science (via remote sensing) benefit from space technology. New technologies originating with or accelerated by space-related endeavors are often subsequently exploited in other economic activities.

</doc>
<doc id="40377" url="https://en.wikipedia.org/wiki?curid=40377" title="Ole Einar Bjørndalen">
Ole Einar Bjørndalen

Ole Einar Bjørndalen (born 27 January 1974) is a Norwegian professional biathlete, often referred to by the nickname "The King of Biathlon". He is the most medaled Olympian in the history of the Winter Olympic Games, with 13 medals. He is also the most successful biathlete of all time at the Biathlon World Championships, having won 44 medals, double that of any other biathlete. With 95 World Cup wins, Bjørndalen is ranked first all-time for career victories on the Biathlon World Cup tour, more than twice that of anyone else. He has won the Overall World Cup title six times, in 1997–98, in 2002–03, in 2004–05, in 2005–06, in 2007–08 and in 2008–09, more than any other male biathlete and the same as female record holder Magdalena Forsberg.
In 1992, he won his first career medal at the junior world championships. A year later in 1993, after winning three junior world championship titles, a medal haul only previously achieved by Sergei Tchepikov, Bjørndalen made his Biathlon World Cup debut. His breakthrough came in 1994 when he featured on his first World Cup podium in a sprint race held in Bad Gastein, Austria. Bjørndalen first competed in the Olympic Games at the Lillehammer 1994 Winter Olympics, held in his home country of Norway. He obtained his first major victory on 11 January 1996 in an individual competition held in Antholz-Anterselva, Italy. On 20 February 2014, Bjørndalen was elected to an eight-year term at the International Olympic Committee's athlete commission. In April 2016, he resigned from that position after deciding to continue his career until the 2018 Winter Olympics in Pyeongchang.
Career.
In 1993, at the age of 19, Bjørndalen first came into focus by winning 3 out of 4 possible gold medals at the Junior Biathlon World Championships, which among other things led to him being chosen to represent Norway in the 1994 Olympics, at the cost of highly merited biathlete Eirik Kvalfoss. As of 19 February 2014, Bjørndalen has won eight Olympic gold medals, four Olympic silver, one Olympic bronze, twenty World Championship gold medals, fourteen silver, and ten bronze, and a record high of 95 individual Biathlon World Cup wins, the most of any biathlete to date.
He has won the World Cup six times (1997–98, 2002–03, 2004–05, 2005–06, 2007–08, and 2008–09), finished second six times (1996–97, 1998–99, 1999–2000, 2000–01, 2003–04, and 2006–07), and third once (2001–02). In his first season (1992–93) he finished 62nd, the season after, 30th and the season after that, 4th. When winning the overall world cup in 1998, at the age of 24, he won every event in biathlon in one season – world championships gold medal, Olympic gold medal and the overall World Cup title. His World Cup podium record is 178 podium finishes, 95 1st places, 53 2nd places, and 30 3rd places in the individual events. Bjørndalen has 1 World Cup victory in the team event. In relay Bjørndalen has won 35 races, he has also 21 2nd places and 13 3rd.places. In total he has 69 podium finishes in the world cup, relay event. Bjørndalen has 248 World cup podium finishes, individual, team and relay races combined.
Bjørndalen has won the Sprint world cup nine times in the seasons: 1994-1995, 1996-1997, 1997-1998, 1999-2000, 2000–01, 2002–03, 2004–05, 2007–08 and 2008-09. Ole Einar Bjoerndalen also came 2nd in the Sprint world cup in the seasons: 2003-04 and 2005-06. Ole Einar has won Pursuit world cup five times from 1999-00, 2002–03, 2005–06, 2007–08 and 2008-09. He has 2nd place in the seasons 2000-01, 2003–04, 2004–05, 2006-07 and 3rd places in 1996-97, 1998–99 and 2001-02. Bjoerndalen has been winner of the Mass start world cup five times in: 2002-03, 2004–05, 2005–06, 2006–07 and 2007-08. He came 2nd in 2000-01, 2003–04 and 2008-09.
Ole Einar Bjoerndalen was number 3 in the Mass start world cup in the season 1998-99. He has also once won the Normal distance world cup. It was in 2004-05. Bjoerndalen has also finished number 2 in the 1998-99, 2000–01, 2001–02 and 2005-06 seasons.
Ole Einar also came 3rd in 1997-98 season. He has won a total of 20 times, 13 times finished in second place and five times came in 3rd place. Overall, he has been on the podium 38 times.
Bjørndalen has won the relay world cup ten times in the seasons: 1997-98, 1999-00, 2000–01, 2001–02, 2003–04, 2004–05, 2007–08, 2009–10, 2010-11 and 2015-16. He has 6 times finished second in the world cup relay in: 1996-97, 2006–07, 2008–09, 2011–12, 2012–13 and 2014-15.
Bjoerndalen also came in third place in: 1998-99 and 2002-03 . All together he has been on the podium 18 seasons in the world cup relay. Bjørndalen has won the mixed relay world cup 4 times. It happened in the seasons: 2012-13, 2013–14, 2014-15 and 2015-16.
Bjørndalen has won (together with the Norwegian biathlon team) the nations cup ten times. It happened in the: 1998/99, 2002/03, 2003/04, 2004/05, 2007/08, 2008/09, 2010/11, 2013/14, 2014/15 and 2015/16 season. Bjørndalen has also achieved five second places in the nationscup in the years: 1999/00, 2000/01, 2001/02, 2005/06 and 2012/13. He has finished in third place in the nations cup 3 times, in the: 1996/97, 1997/98 and 2006/07 season. In total he has finished 18 times at the podium in the nations cup for men.
He is the only biathlete ever to win all biathlon events in a single Winter Olympics (2002 Salt Lake City Games). This encompassed the sprint, pursuit, individual, and relay events, the latter together with three other participants. Bjørndalen's 95 biathlon World Cup victories and one cross-country victory is two behind of Gunda Niemann-Stirnemann's record of 98 World Cup victories for a winter sport athlete.
Bjørndalen occasionally competes in cross-country skiing, and in 2006 he won an FIS Cross-Country World Cup race in Gällivare, Sweden, to become the first male biathlete to win a cross-country competition. He is also the only biathlete who has won every event during the same Winter Olympic Games (four gold medals). He achieved this feat at the Salt Lake City 2002 Winter Olympics, becoming the most successful athlete there. This makes him one of only three Olympians to win four gold medals during the same Winter Games. He repeated this medal haul at the Biathlon World Championships 2005 in Hochfilzen, Austria and at the Biathlon World Championships 2009 in Pyeongchang, South Korea.
At the Vancouver 2010 Winter Olympics, Bjørndalen became the most successful biathlete in Winter Olympic history by surpassing the previous record of nine career Olympic medals, which he shared with Uschi Disl of Germany. He then anchored Norway to gold in the 4 × 7.5 km relay. This was the second time that Norway had won a title in this event, with the other being at the 2002 Winter Olympics (also anchored by Bjørndalen). With this victory he became the second most decorated Winter Olympian of all time and one of only two athletes to win 11 medals at the Winter Olympics. With his gold medal in 10 km sprint at the Sochi 2014 Winter Olympics, he tied fellow Norwegian Bjørn Dæhlie for most Winter Olympic medals, with 12 in total.
As of February 19, 2014, Bjørndalen has won eight Olympic gold medals, four silver and a bronze. He has also won 20 World Championship gold medals, 14 silver and ten bronze (more than anybody in biathlon history), along with a record 95 World Cup victories in biathlon and 1 World Cup victory in cross-country skiing, 178 podium finishes in biathlon individual races and 3 in cross-country skiing. He also finished in the top three of the Overall World Cup rankings for a record thirteen successive seasons between the 1996–97 and 2008–09 seasons. In total Ole Einar Bjørndalen has won 44 Norwegian Championship gold medals. He has won 30 gold medals in the Norwegian Championship, biathlon, winter event: 20 individual gold medals: individual (4), sprint (6), pursuit (6), mass start (4) and 10 gold medals in relay and the team event: relay (8) and team (2). Bjørndalen has also achieved 14 individual gold medals in the Norwegian Championship, biathlon, summer event: sprint (7) and pursuit (7).
2005–06 World Cup season.
Bjørndalen finished the 2005–06 International Biathlon Union World Cup season in first place, with Frenchman Raphaël Poirée in second place and German Sven Fischer in third. Bjørndalen lay in third place in the standings going into the last three races of the season in Holmenkollen, with Poirée in first, and Fischer in second. However, Bjørndalen won all three races, giving him six victories in the last eight races, and clinching the crystal globe. He also won the pursuit, and the mass start title, and came second in the individual and the sprint. In the pursuit he finished ahead of Fischer by 54 points, and 29 points ahead of Poirée in the mass start. In the individual he finished 41 points behind Michael Greis, and in the sprint he was 5 points behind Tomasz Sikora. Norway finished fourth in the relay.
Bjørndalen closed out the season by winning all three events (sprint, pursuit, and mass start) at the Holmenkollen ski festival biathlon competition. This put his career victories at the ski events to five, having won once both in 2003 (pursuit) and in 2004 (sprint).
2006–07 World Cup season.
Bjørndalen made a perfect start to the season, winning all of the first five races in Östersund and Hochfilzen. In the fifth race of the season, the pursuit race in Hochfilzen, he won with one of his largest margins ever, more than 2 minutes. On 30 December 2006 Bjørndalen took part in the Biathlon World Team Challenge in Gelsenkirchen in the Veltins Arena. In front of about 51,000 people he won it for fourth time in a row. His partner for second consecutive time was Linda Grubben. They both left their rivals, the Robert family, more than one minute behind.
In Oberhof, coming down from training in the heights, Bjørndalen performed below standard for the season, and finishing only 30th and 5th in the individual competitions.
In Ruhpolding he led his team-mates to victory in the relay event. He won the two following individual competitions. After competing in the FIS Nordic World Ski Championships Sapporo 2007, he missed several Biathlon World Cup events; after missing eight competitions altogether Bjørndalen finished second in the overall standings, after German Michael Greis.
2008–09 World Cup season.
Bjørndalen started off the season suffering from the effects of long-term illness, but still placed second in both of the pursuit events. He missed the Biathlon World Team Challenge in Gelsenkirchen, focusing on training instead. After the break, he returned with victories in both the sprint and pursuit events in Ruhpolding and a third place in the mass start in Oberhof.
At the Biathlon World Championships 2009 in Pyeongchang, during the men's 12.5 km pursuit, Bjørndalen with at least 15 other competitors accidentally skied the wrong way at the start of the first lap due to the bad marking. Just after leaving the start, the athletes skied over a bridge instead of skiing beside it, which was the right way. A jury meeting decided to give all these athletes a one-minute time penalty, following a complaint from the Russian team. However, another complaint by seven other member states led to the Appeal Jury reverting to the original result. Along with Bjørndalen's first ever 20 km individual World Championship title, he won four out of six possible gold medals (10 km sprint, 12.5 km pursuit, 20 km individual and the 4 × 7.5 km relay).
After the World Championships Bjørndalen came second in the sprint in Vancouver, he took over the world cup overall lead. He followed up with a second place, and two victories at the events in Granåsen, Trondheim (the latter being a mass start where he shot clean). He secured his sixth overall win in the last sprint of the season, in Khanty-Mansiysk where he placed second. In the following event (a pursuit), he was beaten at the finish line by teammate Emil Hegle Svendsen, but won the pursuit cup.
Personal life.
Bjørndalen resides in the village of Obertilliach, Austria. He also used to live in Toblach, Italy, with Italian-Belgian biathlete Nathalie Santer. They started dating in 1998 and married on 27 May 2006. On 4 October 2012 they filed for divorce by mutual consent.
In April 2016, along with announcing that he will continue his career until the 2018 Winter Olympics in Pyeongchang, Bjørndalen confirmed that he is in a relationship with Belarusian biathlete Darya Domracheva, and that she is pregnant with the couple's first child, which is due in the autumn.
Awards and honors.
Ole Einar Bjørndalen won the Aftenposten's gold medal in 1998. He was named the Norwegian Sportsperson of the Year in 2002 and 2014. For his accomplishments in biathlon and cross-country skiing, Bjørndalen received the Egebergs Ærespris in 2002. Bjørndalen was also awarded with the Fearnleys olympic honorary award in 2002. He was voted Best Male Athlete of 2002 by International Sports Press Association. Ole Einar Bjørndalen was nominated for Laureus World Sportsman of the Year in 2003. Bjørndalen was awarded the Fair Play Mecenante Award in Castiglion in Fiorentino in Italy in 2009. In March 2011, he, Michael Greis and Andrea Henkel were awarded the Holmenkollen Medal, the first biathletes to receive the medal. In February 2014, Bjørndalen was voted Best Male Athlete of the 2014 Winter Olympics by International Sports Press Association.
FIS Cross-Country World Cup.
Bjørndalen first participated in the FIS Cross-Country World Cup in Finland in the 10 kilometre freestyle event in a small town called Muonio in November 1998, finishing 23rd. His first podium place in the FIS Cross-Country World Cup came in Kuopio 25 November 2001, where he finished in 2nd place in the 10 km freestyle event. One month later he once again came in 2nd place, this time losing out to Per Elofsson in the 30 km freestyle mass-start event in Ramsau, Austria.
On 18 November 2006 Bjørndalen made history by becoming the first biathlete to win a FIS Cross-Country World Cup event in the Swedish town Gällivare. Bjørndalen won the 15 km freestyle event. In 2007 his fellow countryman, and fellow biathlete Lars Berger won the 15 km cross-country event at the World Championship in 2007.
Bjørndalen has twice finished on the podium in cross-country world cup relays for Norway: first in Beitostølen in 2003, where his team finished third, and secondly in La Clusaz in France in 2006, where Norway came in 2nd place. In total Bjørndalen has been on the podium 5 times in the Cross-Country World Cup.
FIS events and Winter Olympic Games in cross-country.
Bjørndalen has won FIS events in cross-country twice. His first win was in 1997 in the 30 kilometre freestyle event in Valdres, Norway, and the second was in the 10 km freestyle event in Beitostølen, Norway in 2006. He has also two 2nd places in a FIS-event: in the 15 km freestyle event in Misurina, Italy in 1998 and in the 10 km freestyle event at Beitostølen in 2004. In addition to this, Bjørndalen has one third place in a FIS event, in the 10 km freestyle at Beitostølen in 2001. Bjørndalen finished 5th in the Olympic Winter Games in the 30 km freestyle cross-country race in Salt Lake City on 9 February 2002. He won Skarverennet in 2006 and 2007, and came in 2nd after Petter Northug in 2008.
Other victories.
Ole Einar Bjørndalen won the Beach Volleyball Championship at Laguna Beach in 2001. Ole Einar Bjørndalen has achieved 2nd place in the 2003 Dobbiaco-Cortina, a long-distance cross-country skiing event, (42 km) in Italy in the town Cortina. He won his 2nd place in the 26th edition of this prestigious event. Pierluigi winner time was 1 hour 43 minutes and 16,5 seconds. Ole Einar came half a second shy of the winner time. In 2008, Bjørndalen won the biathlon show event in Püttlingen and also at Blink Festival in Sandnes.
Results.
All results are sourced from the International Biathlon Union.
Olympic Games.
"13 medals (8 gold, 4 silver, 1 bronze)"
World Championships.
"44 medals (20 gold, 14 silver, 10 bronze)"
Individual victories.
"95 victories (36 Sp, 37 Pu, 8 In, 14 MS)"; one victory at Winter Olympics 2014 is not counted as a World Cup victory. 
Shooting.
Bjørndalen is a solid shooter, but is generally outside the top twenty marksmen. Bjørndalen finished the 2005–06 season with a shooting percentage of 84%, hitting 292 out of 345 possible targets, that placed him in 36th position for shooting accuracy. His shooting record for both prone and standing were practically identical, 146/172 in the prone and 146/173 in the standing position. In the individual disciplines, he shot 92% in the individual, 89% in the sprint, 96% in the pursuit, 93% in the mass start and 96% in the relay.
In the 2004–05 season Bjørndalen was the 16th best shot with an 85% success rate, the second best Norwegian behind Egil Gjelland. He hit 331 targets out of a possible 364. His prone like most biathletes was much better than his standing shoot, he hit 169/180 (92%) in the prone and 163/184 (81%) in the standing. He had an average of 88% in the individual, sprint and relay, a 91% hit rate in the mass start but only 79% in the pursuit. During his career in 1999/00 he averaged 82%, in 2000–01 78%, 2001–02 74%, 2002–03 86% and in 2003–04 he hit 80% of the targets, however in those five years his standing shoot was the same or better than his prone shoot. In comparison, his greatest rival Raphaël Poirée averaged 87% in 2004–05 and 86% in 2005–06. Nikolay Kruglov was the best shot in 2004–05 with a 91% success rate, with Ricco Groß in second with 89%, and in 2005 Julien Robert was best with a 93% average and Groß again second with 91%.
Shooting statistics.
Statistics sourced from the International Biathlon Union.
and 
Equipment.
Bjørndalen uses Madshus skis, boots and poles.
He uses Rottefella NNN bindings.
His gloves and base layer are from Odlo, and he uses Casco glasses.
During the off-season in 2006 Bjørndalen was testing a new ski boot that had a high heel in the Torsby ski tunnel with boot manufacturers Madshus. The theory is that it forces the knee more forward for better position and it incorporates the large gluteal muscles.
References.
General
Specific

</doc>
<doc id="40381" url="https://en.wikipedia.org/wiki?curid=40381" title="Janne Lahtela">
Janne Lahtela

Janne Lahtela (born February 28, 1974 in Kemijärvi) is a Finnish former athlete, who established himself as one of the most dominant persons in the history of moguls skiing. He is currently the head coach of Japan's freestyle skiing team. He also is a key founder and sponsor for the IDOne ski company based out of Japan.
Lahtela won a gold medal in the moguls final of 2002 Winter Olympic Games. Four years earlier he had taken a silver medal in front of his cousin Sami Mustonen, who took bronze. He has also won the moguls skiing World Cup five times and became a World Champion in 1999.

</doc>
<doc id="40384" url="https://en.wikipedia.org/wiki?curid=40384" title="Tristan Gale">
Tristan Gale

Tristan Gale (born August 10, 1980) is an American skeleton racer who competed from 2001 to 2006. At the 2002 Winter Olympics, she became the inaugural women's skeleton champion. Gale dyed her hair with streaks of red, white and blue for the 2002 Olympics. During the 2002–2003 season, Tristan won a second gold medal on her home track in Salt Lake during a World Cup stop. She remains undefeated at the track in Utah since the Olympics.
Gale also won a bronze medal in the women's skeleton event at the 2003 FIBT World Championships in Nagano. She retired before the 2006 Winter Olympics in Turin. Gale's best overall seasonal finish in the Skeleton World Cup was third in 2002-3.
A native of Ruidoso, New Mexico, Gale lives in Salt Lake City.

</doc>
<doc id="40385" url="https://en.wikipedia.org/wiki?curid=40385" title="Ko Gi-hyun">
Ko Gi-hyun

Ko Gi-Hyun (Hangul: 고기현, Hanja: 高基鉉) (born May 11, 1986) is a South Korean short track speed skater. Ko remains the second youngest individual gold medalist after Tara Lipinski in the history of the Olympic Winter Games, winning gold in women's 1500 m event at the 2002 Winter Olympics in Salt lake city, United States, at 15 years and 277 days old.

</doc>
<doc id="40386" url="https://en.wikipedia.org/wiki?curid=40386" title="EFF">
EFF

EFF or eff may refer to:

</doc>
<doc id="40387" url="https://en.wikipedia.org/wiki?curid=40387" title="SVG (disambiguation)">
SVG (disambiguation)

SVG is an acronym that can stand for:

</doc>
<doc id="40389" url="https://en.wikipedia.org/wiki?curid=40389" title="Upper Canada">
Upper Canada

The Province of Upper Canada () was a part of British Canada established in 1791 by the United Kingdom to govern the central third of the lands in British North America and to accommodate Loyalist refugees of the United States after the American Revolution. The new province remained, for the next fifty years of growth and settlement, the colonial government of the territory.
Upper Canada existed from 26 December 1791 to 10 February 1841 and generally comprised present-day Southern Ontario. The "upper" prefix in the name reflects its geographic position being closer to the headwaters of the Saint Lawrence River than that of Lower Canada (or present-day Quebec) to the northeast.
Upper Canada included all of modern-day Southern Ontario and all those areas of Northern Ontario in the "Pays d'en Haut" which had formed part of New France, essentially the watersheds of the Ottawa River or Lakes Huron and Superior (excluding any lands within the watershed of Hudson Bay).
Establishment.
Control of all of Canada passed from France to Great Britain in 1763 when the Treaty of Paris ended the Seven Years' War in America. The territories of modern southern Ontario and southern Quebec were initially maintained as the single Province of Quebec, as it had been under the French. From 1763 to 1791, the Province of Quebec maintained its French language, cultural behavioural expectations, practices and laws. This status was renewed and reinforced by the Quebec Act of 1774, which expanded Quebec's territory to include part of the Indian Reserve to the west (i.e., parts of southern Ontario), and other western territories south of the Great Lakes including much of what would become the United States' Northwest Territory, including the modern states of Illinois, Indiana, Michigan, Ohio, Wisconsin and parts of Minnesota.
The part of the province west of Montreal and Quebec in the upper river basin soon began receiving many English-speaking Protestant United Empire Loyalists who arrived in the area as refugees from the American Revolution. This region quickly became culturally distinct. While the act addressed some religious issues, it did not appease those used to English law.
"Upper Canada" became a political entity on December 26, 1791 with the Parliament of Great Britain's passage of the Constitutional Act of 1791. The act divided the Province of Quebec into Upper and Lower Canada. The division was effected so that Loyalist American settlers and British immigrants in Upper Canada could have English laws and institutions, and the French-speaking population of Lower Canada could maintain French civil law and the Catholic religion. The first lieutenant-governor was John Graves Simcoe.
On February 1, 1796, the capital of Upper Canada was moved from Newark (now Niagara-on-the-Lake) to York (now Toronto), which was judged to be less vulnerable to attack by the Americans.
The Act of Union 1840, passed July 23, 1840 by the British Parliament and proclaimed by the Crown on February 10, 1841, merged Upper Canada with Lower Canada to form the short-lived United Province of Canada.
Government.
Provincial administration.
Upper Canada's constitution was said to be "the very image and transcript" of the British constitution, and based on the principal of "mixed monarchy" - a balance of monarchy, aristocracy and democracy.
The Executive arm of government in the colony consisted of a lieutenant-governor, his executive council, and the Officers of the Crown (equivalent to the Officers of the Parliament of Canada): the Adjutant General of the Militia, the Attorney General, the Auditor General of Land Patents, the Auditor General (only one appointment ever made), Crown Lands Office, Indian Office, Inspector General, Kings' Printer, Provincial Secretary & Registrar's Office, Receiver General, Solicitor General, & Surveyor General .
The Executive Council of Upper Canada had a similar function to the Cabinet in England but was not responsible to the Legislative Assembly. They held a consultative position, however, and did not serve in administrative offices as cabinet ministers do. Members of the Executive Council were not necessarily members of the Legislative Assembly but were usually members of the Legislative Council.
Parliament.
The Legislative branch of the government consisted of the parliament comprising legislative council and legislative assembly. When the capital was first moved to Toronto from Newark (present-day Niagara-on-the-Lake) in 1796, the Parliament Buildings of Upper Canada were located at the corner of Parliament and Front Streets, in buildings that were burned by U.S. forces in the War of 1812, rebuilt, then burned again by accident. The site was eventually abandoned for another, to the west.
The Legislative Council of Upper Canada was the upper house governing the province of Upper Canada. Although modelled after the British House of Lords, Upper Canada had no aristocracy. Members of the Legislative council, appointed for life, formed the core of the oligarchic group, the Family Compact, that came to dominate government and economy in the province.
The Legislative Assembly of Upper Canada functioned as the lower house in the Parliament of Upper Canada. Its legislative power was subject to veto by the appointed Lieutenant Governor, Executive Council, and Legislative Council.
Local government.
Local government in the Province of Upper Canada was based on districts. In 1788, four districts were created:
The name changes all took place in 1792.
Justices of the Peace were appointed by the Lt. Governor. Any two justices meeting together could form the lowest level of the justice system, the Courts of Request. A Court of Quarter Sessions was held four times a year in each district composed of all the resident justices. The Quarter Sessions met to oversee the administration of the district and deal with legal cases. They formed, in effect, the municipal government until an area was incorporated as either a Police Board or a City after 1834.
Additional districts were created from the existing districts as the population grew until 1849, when local government mainly based on counties came into effect. At that time, there were 20 districts; legislation to create a new Kent District was never completed. Up until 1841, the district officials were appointed by the lieutenant-governor, although usually with local input.
Politics.
The Family Compact.
The Family Compact is the epithet applied to an oligarchic group of men who exercised most of the political and judicial power in Upper Canada from the 1810s to the 1840s. It was noted for its conservatism and opposition to democracy. The uniting factors amongst the Compact were its loyalist tradition, hierarchical class structure and adherence to the established Anglican Church. Leaders such as John Beverley Robinson and John Strachan proclaimed it an ideal government, especially as contrasted with the rowdy democracy in the nearby United States. The Family Compact emerged from the War of 1812 and collapsed in the aftermath of the Rebellions of 1837.
The Reform Movement.
There were many outstanding individual reform politicians in Upper Canada, including Robert Randal, Peter Perry, Marshall Spring Bidwell, William Ketchum and Dr. William Warren Baldwin; however, organized collective reform activity began with Robert Fleming Gourlay. Gourlay was a well-connected Scottish emigrant who arrived in 1817, hoping to encourage "assisted emigration" of the poor from Britain. He solicited information on the colony through township questionnaires, and soon became a critic of government mismanagement. When the local legislature ignored his call for an inquiry, he called for a petition to the British Parliament. He organized township meetings, and a provincial convention — which the government considered dangerous and seditious. Gourlay was tried in December 1818 under the 1804 Sedition Act and jailed for 8 months. He was banished from the province in August 1819. His expulsion made him a martyr in the reform community.
The next wave of organized Reform activity emerged in the 1830s through the work of William Lyon Mackenzie, James Lesslie, John Rolph, William John O'Grady and Dr Thomas Morrison, all of Toronto. They were critical to introducing the British Political Unions to Upper Canada. Political Unions were not parties. The unions organized petitions to Parliament.
The Upper Canada Central Political Union was organized in 1832-3 by Dr Thomas David Morrison (mayor of Toronto in 1836) while William Lyon Mackenzie was in England. This union collected 19,930 signatures on a petition protesting Mackenzie's unjust expulsion from the House of Assembly by the Family Compact.
This union was reorganized as the Canadian Alliance Society (1835). It shared a large meeting space in the market buildings with the Mechanics Institute and the Children of Peace. The Canadian Alliance Society adopted much of the platform (such as secret ballot & universal suffrage) of the Owenite National Union of the Working Classes in London, England, that were to be integrated into the Chartist movement in England.
The Canadian Alliance Society was reborn as the Constitutional Reform Society (1836), when it was led by the more moderate reformer, Dr William W. Baldwin. After the disastrous 1836 elections, it took the final form as the Toronto Political Union in 1837. It was the Toronto Political Union that called for a Constitutional Convention in July 1837, and began organizing local "Vigilance Committees" to elect delegates. This became the organizational structure for the Rebellion of 1837.
The Upper Canada Rebellion of 1837.
The Upper Canada Rebellion was an insurrection against the oligarchic government of the Family Compact by W.L. Mackenzie in December 1837. Long term grievances included antagonism between Later Loyalists and British Loyalists, political corruption, the collapse of the international financial system and the resultant economic distress, and a growing republican sentiment. While public grievances had existed for years, it was the Rebellion in Lower Canada (present day Quebec) that emboldened rebels in Upper Canada to openly revolt soon after. The Upper Canada Rebellion was largely defeated shortly after it began, although resistance lingered until 1838 (and became more violent) - mainly through the support of the Hunters' Lodges, a secret anti-British, American militia that emerged in states around the Great Lakes. They launched the Patriot War in 1838-39.
John Lambton, Lord Durham's support for "responsible government" undercut the Tories and gradually led the public to reject what it viewed as poor administration, unfair land and education policies, and inadequate attention to urgent transportation needs. Durham's report led to the administrative unification of Upper and Lower Canada as the Province of Canada in 1841. Responsible government did not occur until the late 1840s under Robert Baldwin and Louis-Hippolyte Lafontaine.
Sydenham and the Union of the Canadas.
After the Rebellions, the new governor, Charles Poulett Thomson, 1st Baron Sydenham, proved an exemplary Utilitarian, despite his aristocratic pretensions. This combination of free trade and aristocratic pretensions needs to be underscored; although a liberal capitalist, Sydenham was no radical democrat. Sydenham approached the task of implementing those aspects of Durham’s report that the colonial office approved of, municipal reform, and the union of the Canadas, with a “campaign of state violence and coercive institutional innovation... empowered not just by the British state but also by his Benthamite certainties.” Like governors Bond Head before him, and Metcalfe after, he was to turn to the Orange Order for often violent support. It was Sydenham who played a critical role in transforming Compact Tories into Conservatives.
Sydenham introduced a vast expansion of the state apparatus through the introduction of municipal government. Areas not already governed through civic corporations or police boards would be governed through centrally controlled District Councils with authority over roads, schools, and local policing. A strengthened Executive Council would further usurp much of the elected assembly’s legislative role, leaving elected politician’s to simply review the administration’s legislative program and budgets.
Settlement.
First Nations Dispossession and Reserves.
The First Nations occupying the territory that was to become Upper Canada were:
Prior to the creation of Upper Canada in 1791 much land had already been ceded by the First Nations to the Crown in accordance with the Royal Proclamation of 1763. During the American Revolutionary War most of the First Nations supported the British. After the Americans launched a campaign that burned the villages of the Iroquois in New York State in 1779 the refugees fled to Fort Niagara and other British posts, and remained permanently in Canada.
Land was granted to these allied Six Nations who had served on the British side during the American Revolution by the Haldimand Proclamation (1784). Haldimand had purchased a tract of land from the Mississaugas. The nature of the grant has been under dispute.
Loyalists, Later Loyalists & the Land Grant System.
Crown land policy to 1825 was multi-fold in the use of a "free" resource that had value to people who themselves may have little or no money for its purchase and for the price of settling upon it to support themselves and a create a new society. First, the cash-strapped Crown government in Canada could pay and reward the services and loyalty of the “United Empire Loyalists” who, originated outside of Canada, with out encumbrance of debt by being awarded with small portions of land (under ) with the proviso that it be settled by those to which it was granted; Second, portions would be reserved for the future use of the Crown and the Clergy that did not require settlement by which to gain control. Lt. Governor Simcoe saw this as the mechanism by which an aristocracy might be created, and that compact settlement could be avoided with the grants of large tracts of land to those Loyalists not required to settle on it as the means of gaining control.
Assisted Immigration.
The Calton weavers were a community of handweavers established in the community of Calton, then in Lanarkshire just outside Glasgow, Scotland in the 18th century. In the early 19th century, many of the weavers emigrated to Canada, settling in Carleton Place and other communities in eastern Ontario, where they continued their trade.
In 1825, 1,878 Irish immigrants from the city of Cork arrived in the community of Scott's Plains. The British Parliament had approved an experimental emigration plan to transport poor Irish families to Upper Canada in 1822. The scheme was managed by Peter Robinson, a member of the Family Compact and brother of the Attorney General. Scott's Plains was renamed Peterborough in his honour.
The Talbot Settlement.
Thomas Talbot emigrated in 1791, where he became personal secretary to John Graves Simcoe, Lieutenant-Governor of Upper Canada. Talbot convinced the government to allow him to implement a land settlement scheme of in Elgin County in the townships of Dunwich and Aldborough in 1803. According to his government agreement, he was entitled to for every settler who received ; in this way he gained an estate of . Talbot's administration was regarded as despotic. He was infamous for registering settlers' names on the local settlement map in pencil and if displeased, erasing their entry. Talbot's abuse of power was a contributing factor in the Upper Canada Rebellion of 1837.
Crown & Clergy Reserves.
The Crown reserves, one seventh of all lands granted, were to provide the provincial executive with an independent source of revenue not under the control of the elected Assembly. The Clergy Reserves, also one seventh of all lands granted in the province, were created “for the support and maintenance of a Protestant clergy” in lieu of tithes. The revenue from the lease of these lands was claimed by the Rev. John Strachan on behalf of the Church of England. These reserves were directly administered by the Crown; which, in turn, came under increasing political pressure from other Protestant bodies. The Reserve lands were to be a focal point of dissent within the Legislative Assembly.
Land Sale System.
The land grant policy changed after 1825 as the Upper Canadian administration faced a financial crisis that would otherwise require raising local taxes, thereby making it more dependent on a local elected legislature. The Upper Canadian state ended its policy of granting land to “unofficial” settlers and implemented a broad plan of revenue-generating sales. The Crown replaced its old policy of land grants to ordinary settlers in newly opened districts with land sales by auction. It also passed legislation that allowed the auctioning of previously granted land for payment of back-taxes.
The Canada Company.
Few chose to lease the Crown reserves as long as free grants of land were still available. The Lieutenant Governor increasingly found himself depending upon the customs duties shared with, but collected in Lower Canada for revenue; after a dispute with the lower province on the relative proportions to be allocated to each, these duties were withheld, forcing the Lt. Governor of Upper Canada to search for new sources of revenue. It is important to note, then, that the Canada Company was created as a means of generating government revenue that was not under the control of the elected Assembly, thereby granting the Lt. Governor greater independence from local voters.
The plan for the Canada Company was promoted by the province’s Attorney General, John Beverly Robinson, then studying law at Lincoln’s Inn in London. The Lt. Governor’s financial crisis led to a quick adoption of Robinson’s scheme to sell the Crown reserves to a new land company which would provide the provincial government with annual payments of between £15,000 to £20,000. The Canada Company was chartered in London in 1826; after three years of mismanagement by John Galt, the company hired William Allan and Thomas Mercer Jones to manage the company’s Upper Canadian business. Jones was to manage the “Huron Tract,” and Allan to sell the Crown reserves already surveyed in other districts.
According to the Canada Company, “the poorest individual can here procure for himself and family a valuable tract; which, with a little labour, he can soon convert into a comfortable home, such as he could probably never attain in any other country — all his own!” However, recent studies have suggested that a minimum of £100 to £200 plus the cost of land was required to start a new farm in the bush. As a result, few of these poor settlers had any hope of starting their own farm, although many tried.
The Huron Tract.
The Huron Tract lies in the counties of Huron, Perth, Middlesex and present day Lambton County, Ontario bordering on Lake Huron to the west and Lake Erie to the east. The tract was purchased by the Canada Company for resale to settlers. Influenced by William "Tiger" Dunlop, John Galt and other businessmen formed the Canada Company. The Canada Company was the administrative agent for the Huron Tract.
The Clergy Corporation.
The Clergy Corporation was incorporated in 1819 to manage the Clergy Reserves. After the Rev. John Strachan was appointed to the Executive Council, the advisory body to the Lieutenant Governor, in 1815, he began to push for the Church of England's autonomous control of the clergy reserves on the model of the Clergy Corporation created in Lower Canada in 1817. Although all clergymen in the Church of England were members of the body corporate, the act prepared in 1819 by Strachan’s former student, Attorney General John Beverly Robinson, also appointed the Inspector General and the Surveyor General to the board, and made a quorum of three for meetings; these two public officers also sat on the Legislative Council with Strachan. These three were usually members of the Family Compact.
List of major cities and towns of Upper Canada.
In Upper Canada, major cities with key forts were an essential for survival, defending the area from armed attacks and composing the local militia.
Population.
Ethnic Groups.
Since the province is frequently referred to as "English Canada" after the Union of the Canadas, and its ethnic homogeneity said to be a factor in the Upper Canada Rebellion of 1837, it is interesting to note the range of ethnic groups in Upper Canada. However, due to the lack of a detailed breakdown, it is difficult to count each group, and this may be considered abuse of statistics. An idea of the ethnic breakdown can be had if one considers the religious census of 1842, which is helpfully provided below: Roman Catholics were 15% of the population, and adherents to this religion were, at the time, mainly drawn from the Irish and the French settlers. The Roman Catholic faith also numbered some votaries from amongst the Scottish settlers. The category of "other" religious adherents, somewhat under 5% of the population, included the Aboriginal and Metis culture.
First Nations.
See above: Land Settlement
Metis.
Many British and French-Canadian fur traders married First Nations and Inuit women from the Cree, Ojibwa, or Saulteaux First Nations. The majority of these fur traders were Scottish and French and were Catholic.
Canadiens/French-Canadians.
Early settlements in the region include the Mission of Sainte-Marie among the Hurons at Midland in 1649, Sault Ste. Marie in 1668, and Fort Pontchartrain du Détroit in 1701. Southern Ontario was part of the "Pays d'en-haut" (Upper Country) of New France, and later part of the province of Quebec until Quebec was split into Upper and Lower Canada in 1791. The first wave of settlement in the Detroit/Windsor area came in the 18th century during the French regime. A second wave came in the 19th and early 20th centuries to the areas of Eastern Ontario and Northeastern Ontario. In the Ottawa Valley, in particular, some families have moved back and forth across the Ottawa River for generations (the river is the border between Ontario and Quebec). In the city of Ottawa some areas such as Vanier and Orleans have a rich Franco-heritage where families often have members on both sides of the Ottawa River.
Loyalists/Later Loyalists.
After an initial group of about 7,000 United Empire Loyalists were thinly settled across the province in the mid-1780s, a far larger number of "late-Loyalists" arrived in the late 1790s and were required to take an oath of allegiance to the Crown in order to obtain land if they came from the US. Their fundamental political allegiances were always considered dubious. By 1812, this had become acutely problematic since the American settlers outnumbered the original Loyalists by more than ten to one. Following the War of 1812, the colonial government under Lt. Governor Gore took active steps to prevent Americans from swearing allegiance, thereby making them ineligible to obtain land grants. The tensions between the Loyalists and late Loyalists erupted in the "Alien Question" crisis in 1820-21 when the Bidwells (Barnabas and his son Marshall) sought election to the provincial assembly. They faced opponents who claimed they could not hold elective office because of their American citizenship. If the Bidwells were aliens so were the majority of the province. The issue was not resolved until 1828 when the Colonial government retroactively granted them citizenship.
Freed Slaves.
The Act Against Slavery passed in Upper Canada on July 9, 1793. The 1793 "Act against Slavery" forbade the importation of any additional slaves and freed children. It did not grant freedom to adult slaves—they were finally freed by the British Parliament in 1833. As a consequence, many Canadian slaves fled south to New England and New York, where slavery was no longer legal. Many American slaves who had escaped from the South via the Underground Railroad or fleeing from the Black Codes in the Ohio Valley came north to Ontario, a good portion settling on land lots and began farming. It is estimated that thousands of escaped slaves entered Upper Canada from the United States.
The British.
The Great Migration from Britain from 1815-1850 has been numbered at 800,000. The population of Upper Canada in 1837 is documented at 409,000. Given the lack of detailed census data it is difficult to assess the relative size of the American & Canadian born "British" and the foreign born "British." By the time of the first census in 1841, only half of the population of Upper Canada were foreign born British. References to "English Canada" can thus be confusing, and indicate little about individual ethnic identity.
Religion.
Church of England.
The first Lt. Governor, Sir John Graves Simcoe, sought to make the Church of England the Established Church of the province. To that end, he created the Clergy Reserves, the revenues of which were to support the church. The Clergy Reserves proved to be a long-term political issue, as other denominations, particularly the Church of Scotland (Presbyterians) sought a proportional share of the revenues. The Church of England was never numerically dominant in the province, as it was in England, especially in the early years when most of the American born Later Loyalists arrived. The growth of the Church of England depended largely on later British emigration for growth.
The Church was led by the Rev. John Strachan (1778-1867), a pillar of the Family Compact. Strachan was part of the oligarchic ruling class of the province, and besides leading the Church of England, also sat on the Executive Council, the Legislative Council, helped found the Bank of Upper Canada, Upper Canada College, and the University of Toronto.
Catholic Church.
Father Alexander Macdonell was a Scottish Catholic priest who formed his evicted clan into The Glengarry Fencibles regiment, of which he served as chaplain. He was the first Catholic chaplain in the British Army since the Reformation. When the regiment was disbanded, Rev. Macdonell appealed to the government to grant its members a tract of land in Canada, and, in 1804, 160,000 acres (650 km²) were provided in what is now Glengarry County, Canada.
In 1815, he began his service as the first Roman Catholic Bishop at St. Raphael's Church in the Highlands of Ontario. In 1819 he was appointed Vicar Apostolic of Upper Canada, which in 1826 was erected into a suffrigan bishopric of the Archdiocese of Quebec. In 1826, he was appointed to the legislative council.
Macdonell's role on the Legislative Council was one of the tensions with the Toronto congregation, led by Father William O'Grady. O'Grady, like Macdonell, had served as an army chaplain (to Connell James Baldwin's soldiers in Brazil). O'Grady followed Baldwin to Toronto Gore Township in 1828. From January 1829 he was pastor of St. Paul's church in York. Tensions between the Scottish and Irish came to a head when O'Grady was defrocked, in part for his activities in the Reform movement. He went on to edit a Reform newspaper in Toronto, the "Canadian Correspondent".
Ryerson and the Methodists.
The undisputed leader of the highly fractious Methodists in Upper Canada was Egerton Ryerson, editor of their newspaper, "The Christian Guardian". Ryerson (1803-1882) was an itinerant minister — or circuit rider — in the Niagara area for the Methodist Episcopal Church — an American branch of Methodism. As British immigration increased, Methodism in Upper Canada was torn between those with ties to the Methodist Episcopal Church and the British Wesleyan Methodists. Ryerson used the "Christian Guardian" to argue for the rights of Methodists in the province and, later, to help convince rank-and-file Methodists that a merger with British Wesleyans (effected in 1833) was in their best interest.
Presbyterians.
The earliest Presbyterian ministers in Upper Canada came from various denominations based in Scotland, Ireland, and the United States. The 'United Presbytery of the Canadas' was formed in 1818 primarily by Scottish Secessionist missionaries, yet independently of their mother denomination in the hope of uniting Presbyterians of all stripes in Upper and Lower Canada. Although successfully including members from Irish Secessionist, American Presbyterian and Reformed denominations, the ministers belonging to the Church of Scotland remained separate. Instead, in 1831, they formed the 'Synod of the Presbyterian Church of Canada in Connection with the Established Church of Scotland'. By about that time the 'United Presbytery of the Canadas' had grown and been re-organized into the 'United Synod of Upper Canada'. In its pursuit for Presbyterian unity (and a share of government funding from the Clergy Reserves) the United Synod sought a union with the Church of Scotland synod which it finally joined in 1840. However, some ministers had left the United Synod prior to this merger (including, notably, Rev. James Harris, Rev. William Jenkins, and Rev. Daniel Eastman). In the 1832 new Secessionist missionaries began to arrive, belonging to 'The United Associate Synod in Scotland' (after 1847, the United Presbyterian Church of Scotland). Committed to the voluntarist principle of rejecting government funding they decided against joining the 'United Synod of Upper Canada' and on Christmas Day 1834 formed the 'Missionary Presbytery of the Canadas'. Although the presbytery was formed at Rev. James Harris' church in Toronto, his congregation remained independent of the new presbytery. Rev. Jenkins and his congregation in Richmond Hill joined the Missionary Presbytery a few years later. Rev. Eastman had left the United Synod in 1833 to form the 'Niagara Presbytery' of the Presbyterian Church in the USA. After this presbytery dissolved following the Rebellion of 1837, he rejoined the United Synod. Beyond these, only two other Presbyterian denominations gained a foothold in the province. The small ‘Stamford Presbytery’ of the American Secessionist tradition was formed in 1835 in the Niagara region, and the Scottish Reformed Presbyterian or 'Covenanter' tradition was represented in the province to an even lesser extent. Despite the numerous denominations, by the late 1830s the synod connected to the Church of Scotland was the main expression of Presbyterianism in Upper Canada.
Mennonites, Tunkers, Quakers and Children of Peace.
These groups of later Loyalists were proportionately larger in the early decades of the province's settlement. The Mennonites, Tunkers, Quakers and Children of Peace are the traditional Peace churches. The Mennonites and Tunkers were generally German speaking, and immigrated as Later Loyalists from Pennsylvania. Many of their descendants continue to speak a form of German called Pennsylvania German. The Quakers (Society of Friends) immigrated from New York, the New England States and Pennsylvania. The Children of Peace were founded during the War of 1812 after a schism in the Society of Friends in York County. A further schism occurred in 1828, leaving two branches, "Orthodox" Quakers and "Hicksite" Quakers.
Poverty.
In the decade ending in 1837, the population of Upper Canada doubled, to 397,489, fed in large part by erratic spurts of displaced paupers, the “surplus population” of the British Isles. Historian Rainer Baehre estimated that between 1831 and 1835 a bare minimum of one fifth of all emigrants to the province arrived totally destitute, forwarded by their parishes in the United Kingdom. The pauper immigrants arriving in Toronto were the excess agricultural workers and artisans whose growing ranks sent the cost of parish-based poor relief in England spiraling; a financial crisis that generated frenetic public debate and the overhaul of the Poor Laws in 1834. “Assisted emigration,” a second solution to the problem touted by the Parliamentary Under-Secretary in the Colonial Office, Robert Wilmot Horton, would remove them permanently from the parish poor rolls.
The roots of Wilmot-Horton’s “assisted emigration” policies began in April, 1820, in the middle of an insurrection in Glasgow, where a young, already twice bankrupted William Lyon Mackenzie was setting sail for Canada on a ship called Psyche. After the week-long violence, the rebellion was easily crushed; the participants were driven less by treason than distress. In a city of 147,000 people without a regular parish system of poor relief, between ten and fifteen thousand were destitute. The Prime Minister agreed to provide free transportation from Quebec to Upper Canada, a 100-acre land grant, and a year’s supply of provisions to any of the rebellious weavers who could pay their own way to Quebec. In all, in 1820 and 1821, a private charity helped 2,716 Lanarkshire and Glasgow emigrants to Upper Canada to take up their free grants, primarily in the Peterborough area. A second project was the Petworth Emigration Committee organized by the Reverend Thomas Sockett, who chartered ships and sent emigrants from England to Canada in each of the six years between 1832 and 1837. This area in the south of England was terrorized by the Captain Swing Riots, a series of clandestine attacks on large farmers who refused relief to unemployed agricultural workers. The area hardest hit — Kent — was the area where Sir Francis Bond Head, later Lt. Governor of Upper Canada in 1836, was the Assistant Poor Law Commissioner. One of his jobs was to force the unemployed into "Houses of Industry."
Trade, monetary policy and financial institutions.
Corporations.
There were two types of corporate actors at work in the Upper Canadian economy: the legislatively chartered companies and the unregulated joint stock companies. The joint stock company was popular in building public works, since it should be for general public benefit, as the benefit would otherwise be sacrificed to legislated monopolies with exclusive privileges. or lie dormant. An example of the legislated monopoly is found in the Bank of Upper Canada. However, it should be noted that the benefit of the joint-stock shareholders, as the risk takers, was whole and entire; and the general public benefitted only indirectly. As late as 1849, even the moderate reform politician Robert Baldwin was to complain that “unless a stop were made to it, there would be nothing but corporations from one end of the country to the other.” Radical reformers, like William Lyon Mackenzie, who opposed all “legislated monopolies,” saw joint stock associations as the only protection against “the whole property of the country... being tied up as an irredeemable appendage to incorporated institutions, and put beyond the reach of individual possession.” As a result, most of the joint stock companies formed in this period were created by political reformers who objected to the legislated monopolies granted to members of the Family Compact.
Currency & Banking.
Currency.
See Coins of Upper Canada.
The government of Upper Canada never issued a provincial currency. A variety of coins, mainly of French, Spanish, English and American origin circulated. The government used the Halifax standard, where one pound Halifax equalled four Spanish dollars. One pound sterling equalled 1.111 Hailfax pounds (until 1820), and 1.127 Halifax pounds after 1820.
Paper currency was issued primarily by the Bank of Upper Canada, although with the diversification of the banking system, each bank would issue its own distinctive notes.
Bank of Upper Canada.
The Bank of Upper Canada was “captured” from Kingston merchants by the York elite at the instigation of John Strachan in 1821, with the assistance of William Allan, a Toronto merchant and Executive Councillor. York was too small to warrant such an institution as indicated by the inability of its promoters to raise even the minimal 10% of the £200,000 authorized capital required for start-up. It succeeded where the Bank of Kingston had failed only because it had the political influence to have this minimum reduced by half, and because the provincial government subscribed for two thousand of its eight thousand shares. The administration appointed four of the bank’s fifteen directors that, as with the Clergy Corporation, made for a tight bond between the nominally private company and the state. Forty-four men served as bank directors during the 1830s; eleven of them were executive councilors, fifteen of them were legislative councilors, and thirteen were magistrates in Toronto. More importantly, all 11 men who had ever sat on the Executive Council also sat on the board of the Bank at one time or another. 10 of these men also sat on the Legislative Council. The overlapping membership on the boards of the Bank of Upper Canada and on the Executive and Legislative Councils served to integrate the economic and political activities of church, state, and the “financial sector.” These overlapping memberships reinforced the oligarchic nature of power in the colony and allowed the administration to operate without any effective elective check. The Bank of Upper Canada was a political sore point for the Reformers throughout the 1830s.
Bank wars: the Scottish joint stock banks.
The difference between the chartered banks and the joint stock banks lay almost entirely on the issue of liability and its implications for the issuance of bank notes. The joint stock banks lacked limited liability, hence every partner in the bank was responsible for the bank’s debts to the full extent of their personal property. The formation of new joint stock banks blossomed in 1835 in the aftermath of a parliamentary report by Dr Charles Duncombe, which established their legality here. Duncombe’s report drew in large part on an increasingly dominant banking orthodoxy in the United Kingdom which challenged the English system of chartered banks. Duncombe’s Select Committee on Currency offered a template for the creation of joint stock banks based on several successful British banks. Within weeks two Devonshire businessmen, Capt. George Truscott and John Cleveland Green, established the “Farmer’s Bank” in Toronto. The only other successful bank established under this law was "The Bank of the People" which was set up by Toronto's Reformers. The Bank of the People provided the loan that allowed William Lyon Mackenzie to establish the newspaper The Constitution in 1836 in the lead up to the Rebellion of 1837. Mackenzie wrote at the time: “Archdeacon Strachan’s bank (the old one)... serve the double purpose of keeping the merchants in chains of debt and bonds to the bank manager, and the Farmer’s acres under the harrow of the storekeeper. You will be shewn how to break this degraded yoke of mortgages, ejectments, judgments and bonds. Money bound you - money shall loose you”. During the financial panic of 1836, the Family Compact sought to protect its interests in the nearly bankrupt Bank of Upper Canada by making joint stock banks illegal.
Trade.
After the Napoleonic Wars, as industrial production in Britain took off, English manufacturers began dumping cheap goods in Montreal; this allowed an increasing number of shopkeepers in York to obtain their goods competitively from Montreal wholesalers. It was during this period that the three largest pre-war merchants who imported directly from Britain retired from business as a result; Quetton St. George in 1815, Alexander Wood in 1821, and William Allan in 1822. Toronto and Kingston then underwent a boom in the number of increasingly specialized shops and wholesalers. The Toronto wholesale firm of Isaac Buchanan and Company were one of the largest of the new wholesalers. Isaac Buchanan was a Scots merchant in Toronto, in partnership with his brother Peter, who remained in Glasgow to manage the British end of the firm. They established their business in Toronto in 1835, having bought out Isaac’s previous partners, William Guild and Co., who had established themselves in Toronto in 1832. As a wholesale firm, the Buchanan’s had invested more than £10,000 in their business.
Another of those new wholesale businesses was the Farmers' Storehouse Company. The Farmers Storehouse Company was formed in the Home District and is probably Canada's first Farmers' Cooperative. The Storehouse expedited the sale of farmer's wheat to Montreal, and provided them with cheaper consumer goods.
Wheat and grains.
Upper Canada was in the unenviable position of having few exports with which to pay for all its imported manufactured needs. For the vast majority of those who settled in rural areas, debt could be paid off only through the sale of wheat and flour; yet, throughout much of the 1820s, the price of wheat went through periodic cycles of boom and bust depending upon the British markets that ultimately provided the credit upon which the farmer lived.
In the decade 1830-9, exports of wheat averaged less than £1 per person a year (less than £6 per household), and in the 1820s just half that.
Given the small amounts of saleable wheat and flour, and the rarity of cash, some have questioned how market oriented these early farmers were. Instead of depending on the market to meet their needs, many of these farmers depended on networks of shared resources and cooperative marketing. For example, rather than hire labour, they met their labour needs through "work bees." such farmers are said to be 'subsistence oriented' and not to respond to market cues; rather, they engage in a moral economy seeking 'subsistence insurance' and a 'just price'. The Children of Peace in the village of Hope (now Sharon) are a well documented example. They were the most prosperous agricultural community in Canada West by 1851.
Timber.
The Ottawa River timber trade resulted from Napoleon's 1806 Continental Blockade in Europe. The United Kingdom required a new source of timber for its navy and shipbuilding. Later the U.K.'s application of gradually increasing preferential tariffs increased Canadian imports. The trade in squared timber lasted until the 1850s. The transportation of raw timber by means of floating down the Ottawa River was proved possible in 1806 by Philemon Wright. Squared timber would be assembled into large rafts which held living quarters for men on their six-week journey to Quebec City, which had large exporting facilities and easy access to the Atlantic Ocean.
The timber trade was Upper and Lower Canada's major industry in terms of employment and value of the product. The largest supplier of square red and white pine to the British market was the Ottawa River and the Ottawa Valley. They had "rich red and white pine forests." Bytown (later called Ottawa), was a major lumber and sawmill centre of Canada.
Transportation and communications.
Canal system.
The early nineteenth century was the age of canals. The Erie Canal, stretching from Buffalo to Albany, New York, threatened to divert all of the grain and other trade on the upper Great Lakes through the Hudson River to New York city after its completion in 1825. Upper Canadians sought to build a similar system that would tie this trade to the St Lawrence River and Montreal.
The Rideau Canal.
The Rideau Canal's purpose was military and hence was paid for by the British and not the local treasury. It was intended to provide a secure supply and communications route between Montreal and the British naval base in Kingston. The objective was to bypass the St. Lawrence River bordering New York; a route which would have left British supply ships vulnerable to an attack. Westward from Montreal, travel would proceed along the Ottawa River to Bytown (now Ottawa), then southwest via the canal to Kingston and out into Lake Ontario. Because the Rideau Canal was easier to navigate than the St. Lawrence River due to the series of rapids between Montreal and Kingston, it became a busy commercial artery from Montreal to the Great Lakes. The construction of the canal was supervised by Lieutenant-Colonel John By of the Royal Engineers. The work started in 1826, and was completed 6 years later in 1832 at a cost of £822,000.
The Welland Canal.
The Welland Canal was created to directly link Lake Erie with Lake Ontario, bypassing Niagara Falls and the Erie Canal. It was the idea of William Hamilton Merritt who owned a sawmill, grist mill and store on the Twelve Mile Creek. The Legislature authorized the joint-stock Welland Canal Company on January 19, 1824, with a capitalization of $150,000, and Merritt as the agent. The canal was officially opened exactly five years later on November 30, 1829. However, the original route to Lake Erie followed the Welland and Niagara Rivers and was difficult and slow to navigate. The Welland Canal Company obtained a loan of 50,000 pounds from the Province of Upper Canada in March 1831 in order to cut a canal directly to Gravelly Bay (now Port Colborne) as the new Lake Erie terminus for the canal.
By the time the canal was finished in 1837, it had cost the province £425,000 in loans and stock subscriptions. The Company was supposed to have been a private one using private capital; but the province had little private capital available, hence most of the original funds came from New York. To keep the canal in Upper Canadian hands, the province had passed a law barring Americans from the company's directorate. The company was thus controlled by the Family Compact, even though they had few shares. By 1834, it was clear the canal would never make money and that the province would be on the hook for the large loans; the canal and the canal company thus became a political issue, as local farmers argued the huge expense would ultimately only benefit American farmers in the west and the merchants who transported their grain.
Desjardins Canal.
The Desjardins Canal, named after its promoter Pierre Desjardins, was built to give Dundas, Ontario, easier access to Burlington Bay and Lake Ontario. Access to Lake Ontario from Dundas was made difficult by the topography of the area, which included a natural sand and gravel barrier, across Burlington Bay which allowed only boats with a shallow draft through. In 1823 a canal was dug through the sandbar. In 1826 the passage was completed, allowing schooners to sail to neighbouring Hamilton. Hamilton then became a major port and quickly expanded as a center of trade and commerce. In 1826 a group of Dundas businessmen incorporated in order to compete with Hamilton and increase the value of their real estate holdings. The project to build Desjardins Canal continued for ten years, from 1827 to 1837, and required constant infusions of money from the province. In 1837, the year it opened, the company's income was £6,000, of which £5,000 was from a government loan and £166 was received from canal tolls.
Lake traffic: steamships.
There is disagreement as to whether the Canadian built "Frontenac" (170 feet), launched on September 7, 1816, at Ernestown, Ontario or the U.S. built "Ontario" (110 feet), launched in the spring of 1817 at Sacketts Harbor, New York, was the first steamboat on the Great Lakes. While the "Frontenac" was launched first, the "Ontario" began active service first. The first steamboat on the upper Great Lakes was the passenger carrying "Walk-In-The-Water", built in 1818 to navigate Lake Erie.
In the years between 1809 and 1837 just over 100 steamboats were launched by Upper and Lower Canadians for the St. Lawrence River and Great Lakes trade, of which ten operated on Lake Ontario. The single largest engine foundry in British North America before 1838 was the Eagle Foundry of Montreal, founded by John Dod Ward in the fall of 1819 which manufactured 33 of the steam engines. The largest Upper Canadian engine manufacturer was Sheldon & Dutcher of Toronto, who made three engines in the 1830s before being driven to Bankruptcy by the Bank of Upper Canada in 1837.
The major owner-operators of steamships on Lake Ontario were Donald Bethune, John Hamilton, Hugh Richardson, and Henry Gildersleeve, each of whom would have invested a substantial fortune.
Roads.
Besides marine travel, Upper Canada had a few Post roads or footpaths used for transportation by horse or stagecoaches along the key settlements between London to Kingston.
The Governor's Road was built beginning in 1793 from Dundas to Paris and then to the proposed capital of London by 1794. The road was further extended eastward with new capital of York in 1795. his road was eventually known as Dundas Road.
A second route was known as Lakeshore Road or York Road which was built from York to Trent River from 1799 to 1900 and later extended eastwards to Kingston in 1817. This road was later renamed as Kingston Road.
US relations.
War of 1812 (1812–1815).
During the War of 1812 with the United States, Upper Canada was the chief target of the Americans, since it was weakly defended and populated largely by American immigrants. However, division in the United States over the war, a lackluster American militia, the incompetence of American military commanders, and swift and decisive action by the British commander, Sir Isaac Brock, kept Upper Canada part of British North America.
Detroit was captured by the British on August 6, 1812. The Michigan Territory was held under British control until it was abandoned in 1813. The Americans won the decisive Battle of Lake Erie (September 10, 1813) and forced the British to retreat from the western areas. On the retreat they were intercepted at the Battle of the Thames (October 5, 1813) and destroyed in a major American victory that killed Tecumseh and broke the power of Britain's Indian allies.
Major battles fought on territory in Upper Canada included;
Many other battles were fought in American territory bordering Upper Canada, including the Northwest Territory (most in modern-day Michigan), upstate New York and naval battles in the Great Lakes.
The Treaty of Ghent (ratified in 1815) ended the war and restored the status quo ante bellum between the combatants.
1837 Rebellion and Patriot War.
Mackenzie, Duncombe, John Rolph and 200 supporters fled to Navy Island in the Niagara River, where they declared themselves the Republic of Canada on December 13. They obtained supplies from supporters in the United States, resulting in British reprisals (see Caroline affair). This incident has been used to establish the principle of "anticipatory self-defense" in international politics, which holds that it may be justified only in cases in which the "necessity of that self-defense is instant, overwhelming, and leaving no choice of means, and no moment for deliberation". This formulation is part of the "Caroline" test. The "Caroline" affair is also now invoked frequently in the course of the dispute around preemptive strike (or preemption doctrine).
On January 13, 1838, under attack by British armaments, the rebels fled. Mackenzie went to the United States where he was arrested and charged under the Neutrality Act. The Neutrality Act of 1794 made it illegal for an American to wage war against any country at peace with the United States. Application of the Neutrality Act during the Patriot War led to the largest use of US government military force against its own citizens since the Whiskey Rebellion.
The extended series of incidents comprising the Patriot War were finally settled by U.S. Secretary of State Daniel Webster and Alexander Baring, 1st Baron Ashburton, in the course of their negotiations leading to the Webster–Ashburton Treaty of 1842.
Education.
In 1807 the Grammar School Act allowed the government to take over various grammar schools across the province and incorporating them into a network of eight new, public grammar schools (secondary schools), one for each of the eight districts (Eastern, Johnstown, Midland, Newcastle, Home, Niagara, London, and Western).
Of those, these were the better known ones:
Canada West.
Canada West was the western portion of the United Province of Canada from February 10, 1841, to July 1, 1867. Its boundaries were identical to those of the former Province of Upper Canada. Lower Canada would also become Canada East.
The area was named the Province of Ontario under the British North America Act of 1867.

</doc>
<doc id="40390" url="https://en.wikipedia.org/wiki?curid=40390" title="Chat">
Chat

Chat or chats may refer to:

</doc>
<doc id="40394" url="https://en.wikipedia.org/wiki?curid=40394" title="Design Patterns">
Design Patterns

Design Patterns: Elements of Reusable Object-Oriented Software is a software engineering book describing recurring solutions to common problems in software design. The book's authors are Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides with a foreword by Grady Booch. The book is divided into two parts, with the first two chapters exploring the capabilities and pitfalls of object-oriented programming, and the remaining chapters describing 23 classic software design patterns. The book includes examples in C++ and Smalltalk.
It has been influential to the field of software engineering and is regarded as an important source for object-oriented design theory and practice. More than 500,000 copies have been sold in English and in 13 other languages. The authors are often referred to as the Gang of Four (GoF).
History.
The book started at a birds of a feather (BoF) session at OOPSLA '90, "Towards an Architecture Handbook", run by Bruce Anderson, where Erich Gamma and Richard Helm met and discovered their common interest. They were later joined by Ralph Johnson and John Vlissides. The original publication date of the book was October 21, 1994 with a 1995 copyright, hence it is often cited with a 1995-year, despite being published in 1994. The book was first made available to the public at the OOPSLA meeting held in Portland, Oregon, in October 1994.
In 2005 the ACM SIGPLAN awarded that year's Programming Languages Achievement Award to the authors, in recognition of the impact of their work "on programming practice and programming language design". As of March 2012, the book was in its 40th printing.
Introduction, Chapter 1.
Chapter 1 is a discussion of object-oriented design techniques, based on the authors' experience, which they believe would lead to good object-oriented software design, including:
The authors claim the following as advantages of interfaces over implementation:
Use of an interface also leads to dynamic binding and polymorphism, which are central features of object-oriented programming.
The authors refer to inheritance as "white-box reuse", with
white-box referring to visibility, because the internals of parent classes are often visible to subclasses. In contrast, the authors refer to object composition (in which objects with well-defined interfaces are used dynamically at runtime by objects obtaining references to
other objects) as "black-box reuse" because no internal details of composed objects need be visible in the code using them.
The authors discuss the tension between inheritance and encapsulation at length and state that in their experience, designers overuse inheritance (Gang of Four 1995:20). The danger is stated as follows:
They warn that the implementation of a subclass can become so bound up with the implementation of its parent class that any change in the parent's implementation will force the subclass to change. Furthermore, they claim that a way to avoid this is to inherit only from abstract classes—but then, they point out that there is minimal code reuse.
Using inheritance is recommended mainly when adding to the functionality of existing components, reusing most of the old code and adding relatively small amounts of new code.
To the authors, 'delegation' is an extreme form of object composition that can always be used to replace inheritance. Delegation involves two objects: a 'sender' passes itself to a 'delegate' to let the delegate refer to the sender. Thus the link between two parts of a system are established only at runtime, not at compile-time. The Callback article has more information about delegation.
The authors also discuss so-called parameterized types, which are also known as generics (Ada, Eiffel, Java, C#, VB.NET, and Delphi) or templates (C++). These allow any type to be defined without specifying all the other types it uses—the unspecified types are supplied as 'parameters' at the point of use.
The authors admit that delegation and parameterization are very powerful but add a warning:
The authors further distinguish between 'Aggregation', where one object 'has' or 'is part of' another object (implying that an aggregate object and its owner have identical lifetimes) and acquaintance, where one object merely 'knows of' another object. Sometimes acquaintance is called 'association' or the 'using' relationship. Acquaintance objects may request operations of each other, but they aren't responsible for each other. Acquaintance is a weaker relationship than aggregation and suggests much looser coupling between objects, which can often be desirable for maximum maintainability in a design.
The authors employ the term 'toolkit' where others might today use 'class library', as in C# or Java. In their parlance, toolkits are the object-oriented equivalent of subroutine libraries, whereas a 'framework' is a set of cooperating classes that make up a reusable design for a specific class of software. They state that applications are hard to design, toolkits are harder, and frameworks are the hardest to design.
Case study, Chapter 2.
Chapter 2 is a step-by-step case study on "the design of a 'What-You-See-Is-What-You-Get' (or 'WYSIWYG') document editor called Lexi." (pp33)
The chapter goes through seven problems that must be addressed in order to properly design Lexi, including any constraints that must be followed. Each problem is analyzed in depth, and solutions are proposed. Each solution is explained in full, including pseudo-code and a slightly modified version of Object Modeling Technique where appropriate.
Finally, each solution is associated directly with one or more design patterns. It is shown how the solution is a direct implementation of that design pattern.
The seven problems (including their constraints) and their solutions (including the pattern(s) referenced), are as follows:
Document Structure.
The document is "an arrangement of basic graphical elements" such as characters, lines, other shapes, etc., that "capture the total information content of the document"(pp35). The structure of the document contains a collection of these elements, and each element can in turn be a substructure of other elements.
Problems and Constraints
Solution and Pattern
A "recursive composition" is a hierarchical structure of elements, that builds "increasingly complex elements out of simpler ones" (pp36). Each node in the structure knows of its own children and its parent. If an operation is to be performed on the whole structure, each node calls the operation on its children (recursively).
This is an implementation of the composite pattern, which is a collection of nodes. The node is an abstract base class, and derivatives can either be leaves (singular), or collections of other nodes (which in turn can contain leaves or collection-nodes). When an operation is performed on the parent, that operation is recursively passed down the hierarchy.
Formatting.
Formatting differs from structure. Formatting is a method of constructing a particular instance of the document's physical structure. This includes breaking text into lines, using hyphens, adjusting for margin widths, etc.
Problems and Constraints
Solution and Pattern
A "Compositor" class will encapsulate the algorithm used to format a composition. Compositor is a subclass of the primitive object of the document's structure. A Compositor has an associated instance of a Composition object. When a Compositor runs its codice_1, it iterates through each element of its associated Composition, and rearranges the structure by inserting Row and Column objects as needed.
The Compositor itself is an abstract class, allowing for derivative classes to use different formatting algorithms (such as double-spacing, wider margins, etc.)
The Strategy Pattern is used to accomplish this goal. A Strategy is a method of encapsulating multiple algorithms to be used based on a changing context. In this case, formatting should be different, depending on whether text, graphics, simple elements, etc., are being formatted.
Embellishing the User Interface.
The ability to change the graphical interface that the user uses to interact with the document.
Problems and Constraints
Solution and Pattern
The use of a "transparent enclosure" allows elements that augment the behaviour of composition to be added to a composition. These elements, such as Border and Scroller, are special subclasses of the singular element itself. This allows the composition to be augmented, effectively adding state-like elements. Since these augmentations are part of the structure, their appropriate codice_2 will be called when the structure's codice_2 is called. This means that the client does not need any special knowledge or interface with the structure in order to use the embellishments.
This is a Decorator pattern, one that adds responsibilities to an object without modifying the object itself.
Supporting Multiple Look-And-Feel Standards.
Look-and-feel refers to platform-specific UI standards. These standards "define guidelines for how applications appear and react to the user" (pp47).
Problems and Constraints
Solution and Pattern
Since object creation of different concrete objects cannot be done at runtime, the object creation process must be abstracted. This is done with an abstract guiFactory, which takes on the responsibility of creating UI elements. The abstract guiFactory has concrete implementations, such as MotifFactory, which creates concrete elements of the appropriate type (MotifScrollBar). In this way, the program need only ask for a ScrollBar and, at run-time, it will be given the correct concrete element.
This is an Abstract Factory. A regular factory creates concrete objects of one type. An abstract factory creates concrete objects of varying types, depending on the concrete implementation of the factory itself. Its ability to focus on not just concrete objects, but entire "families" of concrete objects "distinguishes it from other creational patterns, which involve only one kind of product object" (pp51).
Supporting Multiple Window Systems.
Just as look-and-feel is different across platforms, so is the method of handling windows. Each platform displays, lays out, handles input to and output from, and layers windows differently.
Problems and Constraints
Solution and Pattern
It is possible to develop "our own abstract and concrete product classes", because "all window systems do generally the same thing" (p. 52). Each window system provides operations for drawing primitive shapes, iconifying/de-iconifying, resizing, and refreshing window contents.
An abstract base codice_4 class can be derived to the different types of existing windows, such as application, iconified, dialog. These classes will contain operations that are associated with windows, such as reshaping, graphically refreshing, etc. Each window contains elements, whose codice_5 functions are called upon by the codice_4's own draw-related functions.
In order to avoid having to create platform-specific Window subclasses for every possible platform, an interface will be used. The codice_4 class will implement a codice_4 implementation (codice_9) abstract class. This class will then in turn be derived into multiple platform-specific implementations, each with platform-specific operations. Hence, only one set of codice_4 classes are needed for each type of codice_4, and only one set of codice_9 classes are needed for each platform (rather than the Cartesian product of all available types and platforms). In addition, adding a new window type does not require any modification of platform implementation, or vice versa.
This is a Bridge pattern. codice_4 and codice_9 are different, but related. codice_4 deals with windowing in the program, and codice_9 deals with windowing on a platform. One of them can change without ever having to modify the other. The Bridge pattern allows these two "separate class hierarchies to work together even as they evolve independently" (p. 54).
User Operations.
All actions the user can take with the document, ranging from entering text, changing formatting, quitting, saving, etc.
Problems and Constraints
Solution and Pattern
Each menu item, rather than being instantiated with a list of parameters, is instead done with a "Command" object.
Command is an abstract object that only has a single abstract codice_17 method. Derivative objects extend the codice_17 method appropriately (i.e., the codice_19 would utilize the content's clipboard buffer). These objects can be used by widgets or buttons just as easily as they can be used by menu items.
To support undo and redo, codice_20 is also given codice_21 and codice_22. In derivative classes, the former contains code that will undo that command, and the latter returns a boolean value that defines if the command is undoable. codice_22 allows some commands to be non-undoable, such as a Save command.
All executed codice_24 are kept in a list with a method of keeping a "present" marker directly after the most recently executed command. A request to undo will call the codice_25 directly before "present", then move "present" back one command. Conversely, a codice_26 request will call codice_27 after "present", and move "present" forward one.
This codice_20 approach is an implementation of the Command pattern. It encapsulates requests in objects, and uses a common interface to access those requests. Thus, the client can handle different requests, and commands can be scattered throughout the application.
Spell Check and Hyphenation.
This is the document editor's ability to textually analyze the contents of a document. Although there are many analyses that can be performed, spell check and hyphenation-formatting are the focus.
Problems and Constraints
Solution and Pattern
Removing the integer-based index from the basic element allows for a different iteration interface to be implemented. This will require extra methods for traversal and object retrieval. These methods are put into an abstract codice_29 interface. Each element then implements a derivation of the codice_29, depending on how that element keeps its list (codice_31, codice_32, etc.).
Functions for traversal and retrieval are put into the abstract Iterator interface. Future Iterators can be derived based on the type of list they will be iterating through, such as Arrays or Linked Lists. Thus, no matter what type of indexing method any implementation of the element uses, it will have the appropriate Iterator.
This is an implementation of the Iterator pattern. It allows the client to traverse through any object collection, without needing to access the contents of the collection directly, or be concerned about the type of list the collection's structure uses.
Now that traversal has been handled, it is possible to analyze the elements of a structure. It is not feasible to build each type of analysis into the element structure themselves; every element would need to be coded, and much of the code would be the same for similar elements.
Instead, a generic codice_33 method is built into the element's abstract class. Each Iterator is given a reference to a specific algorithm (such as spell check, grammar check, etc.). When that Iterator iterates through its collection, it calls each element's codice_34, passing the specified algorithm. codice_34 then passes a reference to its element back to said algorithm for analysis.
Thus, to perform a spell check, a front-to-end iterator would be given a reference to a codice_36 object. The iterator would then access each element, executing its codice_33 method with the codice_36 parameter. Each codice_34 would then call the codice_36, passing a reference to the appropriate element.
In this manner, any algorithm can be used with any traversal method, without hard-code coupling one with the other. For example, Find can be used as "find next" or "find previous", depending on if a "forward" iterator was used, or a "backwards" iterator.
In addition, the algorithm themselves can be responsible for dealing with different elements. For example, a codice_36 algorithm would ignore a codice_42 element, rather than having to program every codice_42-derived element to not send themselves to a codice_36.
Patterns by Type.
Creational.
Creational patterns are ones that create objects for you, rather than having you instantiate objects directly. This gives your program more flexibility in deciding which objects need to be created for a given case.
Structural.
These concern class and object composition. They use inheritance to compose interfaces and define ways to compose objects to obtain new functionality.
Behavioral.
Most of these design patterns are specifically concerned with communication between objects.
Criticism.
Significant criticism has been directed at the concept of software design patterns generally, and at "Design Patterns" specifically.
A primary criticism of "Design Patterns" is that its patterns are simply workarounds for missing features in C++, replacing elegant abstract features with lengthy concrete patterns, essentially becoming a "human compiler" or "generating by hand the expansions of some macro". Peter Norvig demonstrates that 16 out of the 23 patterns in "Design Patterns" are simplified or eliminated (via direct language support) in Lisp or Dylan. Related observations were made by Hannemann and Kiczales who implemented several of the 23 design patterns using an aspect-oriented programming language (AspectJ) and showed that code-level dependencies were removed from the implementations of 17 of the 23 design patterns and that aspect-oriented programming could simplify the implementations of design patterns.
There has also been humorous criticism, such as a show trial at OOPSLA '99 on 3 November 1999, and a parody of the format, by Jim Coplien, entitled "Kansas City Air Conditioner".

</doc>
<doc id="40396" url="https://en.wikipedia.org/wiki?curid=40396" title="Montana-class battleship">
Montana-class battleship

The "Montana"-class battleships of the United States Navy were planned as successors to the , being slower but larger, better armored, and having superior firepower. Five were approved for construction during World War II, but changes in wartime building priorities resulted in their cancellation in favor of the s and before any "Montana"-class keels were laid. With beams of 121 feet, they would have been the first U.S. battleships as originally designed to be too wide to transit the 110-foot-wide locks of the Panama Canal.
Intended armament would have been 12 Mark 7 guns in four triple turrets, up from the "Iowas' " three triple 16s. With an increased anti-aircraft capability and thicker armor belt, the "Montana" class would have been the largest, best-protected, and most heavily armed U.S. battleships ever, the only class to come close to rivaling the Empire of Japan's immense s.
Preliminary design work for the "Montana" class began before the US entry into World War II. The first two vessels were approved by Congress in 1939 following the passage of the Second Vinson Act. The Japanese attack on Pearl Harbor delayed construction of the "Montana" class. The success of carrier combat at the Battle of the Coral Sea and, to a greater extent, the Battle of Midway, diminished the value of the battleship. Consequently, the US Navy chose to cancel the "Montana" class in favor of more urgently needed aircraft carriers, amphibious and anti-submarine vessels.
Because the "Iowa"s were fast enough to escort the new s, their orders were retained, making them the last US Navy battleships to be commissioned.
History.
As the political situation in Europe and Asia worsened in the prelude to World War II, Carl Vinson, the chairman of the House Committee on Naval Affairs, instituted the Vinson Naval Plan, which aimed to get the Navy into fighting shape after the cutbacks imposed by the Great Depression and pair of London Naval Treaties of the 1930s. As part of the overall plan Congress passed the Second Vinson Act in 1938, which cleared the way for construction of the four "South Dakota"-class fast battleships and the first two fast battleships (hull numbers BB-61 and BB-62). Four additional battleships (with hull numbers BB-63, BB-64, BB-65, and BB-66) were approved for construction in 1940, with the last two intended to be the first ships of the "Montana" class. By 1942, it was apparent to the US Navy high command that they needed as many fast battleships as possible, and hull numbers BB-65 and BB-66 were allocated to planned fast battleships and .
The Navy, mindful of the ongoing construction of Japan's battleships, had been working on a 58,000-ton "super battleship" concept since 1938. This new class, with twelve guns, was assigned the name "Montana" and cleared for construction by the United States Congress under the Two-Ocean Navy Act in 1940; funding for the new ships was approved in 1941. These ships, the last battleships to be ordered by the Navy, were originally to be designated BB-65 through BB-69; however, BB-65 and BB−66 were subsequently re-ordered as "Iowa"-class ships, "Illinois" and "Kentucky", and the "Montana"s were redesignated BB-67 through BB-71.
Completion of the "Montana"-class, and the last two "Iowa"-class battleships, was intended to give the US Navy a considerable advantage over any other nation, or probable combination of nations, with a total of 17 new battleships by the late 1940s. The "Montana"s also would have been the only American ships to come close to equaling Japan's massive "Yamato" and her sister "Musashi" in terms of size and firepower, with only the "Kriegsmarine" having even more enormous battleships planned, with their H-42 and onwards designs exceeding the "Montana" class in size and capabilities.
Design.
Preliminary planning for the "Montana"-class battleships took place in 1939, when the aircraft carrier was still considered strategically less important than the battleship. The Navy began designing a 65,000-ton battleship to counter the threat posed by the s of the Imperial Japanese Navy. Although the Navy knew little about the "Yamato"-class, the new Japanese battleships were rumored to have a main gun battery of . Initially, plans were drawn for a 45,000-ton (46,000-metric-ton) US battleship, but after evaluation, the Battleship Design Advisory Board increased the displacement of the planned ship to 58,000 tons (59,000 metric tons).
At the time, the design board issued a basic outline for the "Montana" class that called for it to be free of beam restrictions imposed by the Panama Canal, be 25% stronger offensively and defensively than any other battleship completed or under construction, and be capable of withstanding the "super heavy" shells used by US battleships equipped with either the 16-inch/45 caliber guns or /50 cal Mark 7 guns. Although freed of the restriction of fitting through the Panama Canal, the length and height of the "Montana"-class were limited by one of the shipyards at which they were to be built: the New York Navy Yard could not handle the construction of a 58,000-ton (59,000-metric-ton) ship, and vessels built there had to be low enough to clear the Brooklyn Bridge at low tide.
After debate at the design board about whether the "Montana"-class should be fast, achieving the high speed of the , or up-gunned and up-armored, firepower was selected over speed. By returning the "Montana" class to the slower maximum speed of the - and "South Dakota"- class ships, naval architects were able to increase armor protection for the "Montana"s, enabling the ships to withstand enemy fire equivalent to their own guns' ammunition. This limited the "Montana"s ability to escort and defend the Pacific-based Allied aircraft carrier fleet, as the class was to be powered by eight Babcock & Wilcox boilers which would have enabled them to steam at approximately .
Fate.
By January 1941, the design limit for the 58,000-ton (59,000-metric-ton) battleship plan had been reached, and consensus among those designing the battleship class was to increase the displacement to support the armor and weaponry on the ships. At the same time, planners decided to adopt a slightly greater length and reduce power for a better machinery arrangement, as well as improving internal subdivisions, and selecting as the secondary armament several dual-mounted /54 cal guns instead of the /38 cal guns used on the "Iowa"s. At this point, the net design for the "Montana" class somewhat resembled the "Iowa" class since they would be equipped with the same caliber main guns and similar caliber secondary guns; however, "Montana" and her sisters had more armor, mounted three more main guns in one more turret, and were longer and wider than the "Iowa" class.
By April 1942, the "Montana"-class design had been approved; construction was authorized by the United States Congress and the projected date of completion was estimated to be somewhere between 1 July and 1 November 1945. The Navy ordered the ships in May 1942, but the "Montana" class was placed on hold because the "Iowa"-class battleships and the "Essex"-class aircraft carriers were under construction in the shipyards intended to build the "Montana"s. Both the "Iowa" and "Essex" classes had been given higher priorities: the "Iowas" as they were fast enough to keep up with and defend the "Essex"-class carriers with 20 mm and 40 mm guns, and the "Essex"es because of their ability to launch aircraft to gain and maintain air supremacy over the islands in the Pacific and intercept warships of the Imperial Japanese Navy. The entire "Montana" class was suspended in May 1942, before any of their keels had been laid. In July 1942, the construction of the "Montana" class was canceled following the Battle of Midway and the corresponding shift in naval warfare from surface engagements to air supremacy and a corresponding shift from battleships to aircraft carriers.
Ships.
Five ships of the "Montana" class were authorized on 19 July 1940, but they were suspended indefinitely until being canceled on 21 July 1943. The ships were to be built at the New York Navy Yard, Philadelphia Navy Yard, and Norfolk Navy Yard.
USS "Montana" (BB-67).
"Montana" was planned to be the lead ship of the class. She was the third ship to be named in honor of the 41st state, and was assigned to the Philadelphia Navy Yard. Both the earlier battleship, , and BB-67 were canceled, so Montana is the only one of the (48 at the time) US states never to have had a battleship with a "BB" hull classification completed in its honor.
USS "Ohio" (BB-68).
"Ohio" was to be the second "Montana"-class battleship. She was to be named in honor of the 17th state, and was assigned to the Philadelphia Navy Yard for construction. "Ohio" would have been the fourth ship to bear that name had she been commissioned.
USS "Maine" (BB-69).
"Maine" was to be the third "Montana"-class battleship. She was to be named in honor of the 23rd state, and was assigned to the New York Navy Yard. "Maine" would have been the third ship to bear that name had she been commissioned.
USS "New Hampshire" (BB-70).
"New Hampshire" was to be the fourth "Montana"-class battleship, and was to be named in honor of the ninth state. She was assigned to the New York Navy Yard, and would have been the third ship to bear that name had she been commissioned.
USS "Louisiana" (BB-71).
"Louisiana" was to be the fifth and final "Montana"-class battleship. She was to be named in honor of the 18th state and assigned to the Norfolk Navy Yard, Portsmouth, Virginia. "Louisiana" would have been the third ship to bear that name had she been commissioned. By hull number, "Louisiana" was the last American battleship authorized for construction.
Armament.
The armament of the "Montana"-class battleships would have been similar to the preceding "Iowa"-class battleships, but with an increase in the number of primary and secondary guns for use against enemy surface ships and aircraft. Had they been completed, the "Montana"s would have been gun-for-gun the most powerful battleships the United States had constructed, and the only US battleship class that would have come close to equaling the Imperial Japanese Navy battleships "Yamato" and "Musashi" in armament, armor, and displacement.
Main battery.
The primary armament of a "Montana"-class battleship would have been 12 16"/50 caliber Mark 7 gun, which were to be housed in four three-gun turrets: two forward and two aft. The guns, the same used to arm the "Iowa"-class battleships, were long – 50 times their bore, or 50 calibers, from breechface to muzzle. Each gun weighed about without the breech, or with the breech. They fired projectiles weighing up to at a maximum speed of with a range of up to . At maximum range the projectile would have spent almost 1½ minutes in flight. The addition of the No. 4 turret would have allowed "Montana" to overtake the "Yamato" as the battleship having heaviest broadside overall; "Montana" and her sisters would have had a broadside of vs. for "Yamato". Each gun would have rested within an armored barbette, but only the top of the barbette would have protruded above the main deck. The barbettes would have extended either four decks (turrets 1 and 4) or five decks (turrets 2 and 3) down. The lower spaces would have contained rooms for handling the projectiles and storing the powder bags used to fire them. Each turret would have required a crew of 94 men to operate. The turrets would not have been attached to the ship, but would have rested on rollers, which meant that had any of the "Montana"-class ships capsized, the turrets would have fallen out. Each turret would have cost US$1.4 million, but this figure did not take into account the cost of the guns themselves.
The turrets would have been "three-gun", not "triple", because each barrel would have elevated and fired independently. The ships could fire any combination of their guns, including a broadside of all 12. Contrary to popular belief, the ships would not have moved sideways noticeably when a broadside was fired.
The guns would have been elevated from −5° to +45°, moving at up to 12° per second. The turrets would have rotated about 300° at about 4° per second and could even be fired back beyond the beam, which is sometimes called "over the shoulder". Within each turret, a red stripe on the wall of the turret, just inches from the railing, would have marked the boundary of the gun's recoil, providing the crew of each gun turret with a visual reference for the minimum safe distance range.
Like most battleships in World War II, the "Montana" class would have been equipped with a fire control computer, in this case the Ford Mk 1A Ballistic Computer, a rangekeeper designed to direct gunfire on land, sea, and in the air. This analog computer would have been used to direct the fire from the battleship's big guns, taking into account several factors such as the speed of the targeted ship, the time it takes for a projectile to travel, and air resistance to the shells fired at a target. At the time the "Montana" class was set to begin construction, the rangekeepers had gained the ability to use radar data to help target enemy ships and land-based targets. The results of this advance were telling: the rangekeeper was able to track and fire at targets at a greater range and with increased accuracy, as was demonstrated in November 1942 when the battleship engaged the Imperial Japanese Navy battleship at a range of at night; the "Washington" scored at least nine heavy caliber hits that critically damaged the "Kirishima" and led to her loss. This gave the US Navy a major advantage in World War II, as the Japanese did not develop radar or automated fire control to the level of the US Navy.
The large caliber guns were designed to fire two different shells: an armor-piercing round for anti-ship and anti-structure work, and a high-explosive round designed for use against unarmored targets and shore bombardment.
The Mk. 8 APC (Armor-Piercing, Capped) shell weighed in at , and was designed to penetrate the hardened steel armor carried by foreign battleships. At , the Mk. 8 could penetrate of steel armor plate. At the same range, the Mk. 8 could penetrate of reinforced concrete. For unarmored targets and shore bombardment, the Mk. 13 HC (High-Capacity—referring to the large bursting charge) shell was available. The Mk. 13 shell could create a crater wide and deep upon impact and detonation, and could defoliate trees from the point of impact.
The final type of ammunition developed for the 16-inch guns, well after the "Montanas" had been cancelled, were W23 "Katie" shells. These were born from the nuclear deterrence that had begun to shape the US armed forces at the start of the Cold War. To compete with the Air Force and the Army, which had developed nuclear bombs and nuclear shells for use on the battlefield, the Navy began a top-secret program to develop Mk. 23 nuclear naval shells with an estimated yield of 15 to 20 kilotons. The shells entered development around 1953, and were reportedly ready by 1956; however, only the "Iowa"-class battleships could have fired them.
Secondary battery.
The secondary armament for "Montana" and her sisters was to be 20 /54 cal guns housed in 10 turrets along the island of the battleship; five on the starboard side and five on the port. These guns, designed specifically for the "Montana"s, were to be the replacement for the /38 cal secondary gun batteries then in widespread use with the US Navy.
The /54 cal gun turrets were similar to the /38 cal gun mounts in that they were equally adept in an anti-aircraft role and for damaging smaller ships, but differed in that they weighed more, fired heavier rounds of ammunition, and resulted in faster crew fatigue than the /38 cal guns. The ammunition storage for the /54 cal gun was 500 rounds per turret, and the guns could fire at targets nearly away at a 45° angle. At an 85° angle, the guns could hit an aerial target at over .
The cancellation of the "Montana"-class battleships in 1943 pushed back the combat debut of the /54 cal guns to 1945, when they were used aboard the US Navy's s. The guns proved adequate for the carrier's air defense, but were gradually phased out of use by the carrier fleet because of their weight. (Rather than having the carrier defend itself by gunnery this would be assigned to other surrounding ships within a carrier battle group.)
Anti-aircraft batteries.
For the first time since the construction of the "Iowa"-class, the US Navy was not building a fast battleship class solely for the purpose of escorting Pacific-based aircraft carriers, and thus the "Montana"-class would not be designed principally for escorting the fast carrier task forces; nonetheless they would have been equipped with a wide array of anti-aircraft guns to protect themselves and other ships (principally the US aircraft carriers) from Japanese fighters and dive bombers.
Oerlikon 20 mm anti-aircraft guns.
The Oerlikon 20 mm anti-aircraft cannon was one of the most heavily produced anti-aircraft guns of World War II; the US alone manufactured a total of 124,735 of these guns. When activated in 1941, these guns replaced the .50 in (12.7 mm)/90 cal M2 Browning MG on a one-for-one basis. The Oerlikon 20 mm AA gun remained the primary anti-aircraft weapon of the United States Navy until the introduction of the 40 mm Bofors AA gun in 1943.
These guns are air-cooled and use a gas blow-back recoil system. Unlike other automatic guns employed during World War II, the barrel of the 20 mm Oerlikon gun does not recoil; the breechblock is never locked against the breech and is actually moving forward when the gun fires. This weapon lacks a counter-recoil brake, as the force of the counter-recoil is checked by recoil from the firing of the next round of ammunition.
Between December 1941 and September 1944, 32% of all Japanese aircraft downed were credited to this weapon, with the high point being 48.3% for the second half of 1942. In 1943, the revolutionary Mark 14 gunsight was introduced, which made these guns even more effective. The 20 mm guns, however, were found to be ineffective against the Japanese kamikaze attacks used during the latter half of World War II. They were subsequently phased out in favor of the heavier 40 mm Bofors AA guns.
Bofors 40 mm anti-aircraft guns.
The Bofors 40 mm anti-aircraft gun was used on almost every major warship in the US and UK fleet from about 1943 to 1945. Although a descendant of German, Dutch, and Swedish designs, the Bofors mounts used by the US Navy during World War II had been heavily Americanized to bring the guns up to the standards placed on them by the Navy. This resulted in a guns system set to British standards (now known as the Standard System) with interchangeable ammunition, which simplified the logistics situation for World War II. When coupled with hydraulic couple drives to reduce salt contamination and the Mark 51 director for improved accuracy, the Bofors 40 mm gun became a fearsome adversary, accounting for roughly half of all Japanese aircraft shot down between 1 October 1944 and 1 February 1945.
Armor.
Aside from its firepower, a battleship's defining feature is its armor. The exact design and placement of the armor, inextricably linked with the ship's stability and performance, is a complex science honed over decades.
A battleship is usually armored to withstand an attack from guns the size of its own, but the armor scheme of the preceding was only proof against shells (which they had originally been intended to carry), while the and classes were designed only to resist their original complement of Mark V shells, not the new "super-heavy" APC (Armor Piercing, Capped) Mark7 VIII shells they actually used. The "Montana"s were the only US battleships designed to resist the Mark VIII. Designed to give a zone of immunity against fire from 16-inch/45-caliber firing 2,700 lb (1,225 kg) shell, between 18,000 and 31,000 yards (16,459 and 28,346 m) and 16-inch/45-caliber firing 2,240 lb (1,016 kg) shell, between 16,500 and 34,500 yards (15,087 and 31,546 m) away.
Until the authorization of the "Montana" class all US battleships were built within the size limits for the Panama Canal. The main reason for this was logistical: the largest US shipyards were located on the East Coast of the United States, while the United States had territorial interests in both oceans. Requiring the battleships to fit within the Panama Canal took days off the transition time from the Atlantic Ocean to the Pacific Ocean by allowing ships to move through the canal instead of sailing around South America. By the time of the Two Ocean Navy bill, the Navy realized that ship designs could no longer be limited by the Panama Canal and thus approved the "Montana" class knowing that the ships would be unable to clear the locks. This shift in policy meant that the "Montana" class would have been the only World War II–era US battleships to be adequately armored against guns of the same power as their own.
Aircraft.
The "Montana"-class would have used aircraft for reconnaissance and for gunnery spotting. The type of aircraft used would have depended on when exactly the battleships would have been commissioned, but in all probability they would have used either the Kingfisher or the Seahawk. The aircraft would have been floatplanes launched from catapults on the ship's fantail. They would have landed on the water and taxied to the stern of the ship to be lifted by a crane back to the catapult.
Kingfisher.
The Vought OS2U Kingfisher was a lightly armed two-man aircraft designed in 1937. The Kingfisher's high operating ceiling made it well-suited for its primary mission: to observe the fall of shot from a battleship's guns and radio corrections back to the ship. The floatplanes used in World War II also performed search and rescue for naval aviators who were shot down or forced to ditch in the ocean.
Seahawk.
In June 1942, the US Navy Bureau of Aeronautics requested industry proposals for a new seaplane to replace the Kingfisher and Curtiss SO3C Seamew. The new aircraft was required to be able to use landing gear as well as floats. Curtiss submitted a design on 1 August, and received a contract for two prototypes and five service-test aircraft on 25 August. The first flight of a prototype XSC-1 took place on 16 February 1944 at the Columbus, Ohio Curtiss plant. The first production aircraft were delivered in October 1944, and by the beginning of 1945 the single-seat Curtiss SC Seahawk floatplane began replacing the Kingfisher. Had the "Montana"-class been completed, they would have arrived around the time of this replacement, and would likely have been equipped with the Seahawk for use in combat operations and seaborne search and rescue.

</doc>
<doc id="40400" url="https://en.wikipedia.org/wiki?curid=40400" title="James A. Garfield">
James A. Garfield

James Abram Garfield (November 19, 1831 – September 19, 1881) was the 20th President of the United States, serving from March 4, 1881, until his assassination later that year. Garfield had served nine terms in the House of Representatives, and had been elected to the Senate before his candidacy for the White House, though he declined the senatorship once he was president-elect. He is the only sitting House member to be elected president.
Garfield was raised in humble circumstances on an Ohio farm by his widowed mother. He worked at various jobs, including on a canal boat, in his youth. Beginning at age 17, he attended several Ohio schools, then studied at Williams College in Williamstown, Massachusetts, from which he graduated in 1856. A year later, Garfield entered politics as a Republican. He married Lucretia Rudolph in 1858, and served as a member of the Ohio State Senate (1859–1861). Garfield opposed Confederate secession, served as a major general in the Union Army during the American Civil War, and fought in the battles of Middle Creek, Shiloh, and Chickamauga. He was first elected to Congress in 1862 to represent Ohio's 19th District. Throughout Garfield's extended congressional service after the Civil War, he firmly supported the gold standard and gained a reputation as a skilled orator. Garfield initially agreed with Radical Republican views regarding Reconstruction, but later favored a moderate approach for civil rights enforcement for freedmen.
At the 1880 Republican National Convention, Senator-elect Garfield attended as campaign manager for Secretary of the Treasury John Sherman, and gave the presidential nomination speech for him. When neither Sherman nor his rivals – Ulysses S. Grant and James G. Blaine – could get enough votes to secure the nomination, delegates chose Garfield as a compromise on the 36th ballot. In the 1880 presidential election, Garfield conducted a low-key front porch campaign, and narrowly defeated Democrat Winfield Scott Hancock.
Garfield's accomplishments as president included a resurgence of presidential authority against senatorial courtesy in executive appointments, energizing American naval power, and purging corruption in the Post Office, all during his extremely short time in office. Garfield made notable diplomatic and judiciary appointments, including a U.S. Supreme Court justice. He enhanced the powers of the presidency when he defied the powerful New York senator Roscoe Conkling by appointing William H. Robertson to the lucrative post of Collector of the Port of New York, starting a fracas that ended with Robertson's confirmation and Conkling's resignation from the Senate. Garfield advocated agricultural technology, an educated electorate, and civil rights for African Americans. He also proposed substantial civil service reform, eventually passed by Congress in 1883 and signed into law by his successor, Chester A. Arthur, as the Pendleton Civil Service Reform Act. With his term cut short by his death after only 200 days, and much of it spent in ill health trying to recover from the attack, Garfield is little-remembered in the American cultural memory other than for his assassination; historians often forgo listing him in rankings of U.S. presidents due to the short length of his presidency.
Childhood.
James Garfield was born the youngest of five children on November 19, 1831, in a log cabin in Orange Township, now Moreland Hills, Ohio. Orange Township was located in the Western Reserve, and like many who settled there, Garfield's ancestors were from New England. James' father Abram had been born in Worcester, New York, and came to Ohio to woo his childhood sweetheart, Mehitabel Ballou, only to find her married. He instead wed her sister Eliza, who had been born in New Hampshire. James was named for an older brother, dead in infancy.
In early 1833, Abram and Eliza Garfield joined the Disciples of Christ, a decision that would help shape their youngest son's life. Abram Garfield died later that year; his son was raised in poverty in a household led by the strong-willed Eliza. James was her favorite child, and the two remained close for the rest of her life. Eliza Garfield remarried in 1842, but soon left her second husband, Warren Belden (possibly Alfred Belden), and a then-scandalous divorce was awarded against her in 1850. James took his mother's side and when Belden died in 1880, noted the fact in his diary with satisfaction. Garfield enjoyed his mother's stories about his ancestry, especially his Welsh great-great-grandfathers and his ancestor who served as a knight of Caerffili Castle.
Poor and fatherless, Garfield was mocked by his fellow boys, and throughout his life was very sensitive to slights. He escaped through reading, devouring all the books he could find. He left home at age 16 in 1847. Rejected by the only ship in port in Cleveland, Garfield instead found work on a canal boat, responsible for managing the mules that pulled it. This labor would be used to good effect by Horatio Alger, who penned Garfield's campaign biography in 1880.
After six weeks, illness forced Garfield to return home and, during his recuperation, his mother and a local education official got him to promise to postpone his return to the canals for a year and go to school. Accordingly, in 1848, he began at Geauga Seminary, in nearby Chester Township. Garfield later said of his childhood, "I lament that I was born to poverty, and in this chaos of childhood, seventeen years passed before I caught any inspiration ... a precious 17 years when a boy with a father and some wealth might have become fixed in manly ways."
Education, marriage and early career.
At Geauga Academy, which he attended from 1848 to 1850, Garfield learned academic subjects he had not previously had time for. He shone as a student, and was especially interested in languages and elocution. He began to appreciate the power a speaker had over an audience, writing that the speaker's platform "creates some excitement. I love agitation and investigation and glory in defending unpopular truth against popular error." Geauga was co-educational, and Garfield was attracted to one of his fellow students, Lucretia Rudolph, whom he later married. To support himself at Geauga, he worked as a carpenter's assistant and as a teacher. The need to go from town to town to find a place as a teacher disgusted Garfield, and he thereafter developed a dislike of what he called "place-seeking", which became, he said, "the law of my life". In later years, he would astound his friends by letting positions pass that could have been his with a little politicking. Garfield had attended church more to please his mother than to worship God, but in his late teens underwent a religious awakening, and attended many camp meetings, at one of which he was born again. The next day, March 4, 1850, he was baptized into the Disciples by being submerged in the icy waters of the Chagrin River.
After leaving Geauga, Garfield worked for a year at various jobs, including teaching. Finding that some New Englanders worked their way through college, Garfield determined to do the same, and first sought a school that could prepare him for the entrance examinations. From 1851 to 1854, he attended the Western Reserve Eclectic Institute (later named Hiram College) in Hiram, Ohio, a school run by the Disciples. While there, he was most interested in the study of Greek and Latin, but was inclined to learn about and discuss any new thing he encountered. Securing a position on entry as janitor, he was hired to teach while still a student. Lucretia Rudolph had also enrolled at the Institute, and Garfield wooed her while teaching her Greek. He developed a regular preaching circuit at neighboring churches, in some cases earning a gold dollar per service. By 1854, Garfield had learned all the Institute could teach him and was a full-time teacher. Garfield then enrolled at Williams College in Williamstown, Massachusetts, as a third-year student, given credit for two year's study at the Institute after passing a cursory examination. Garfield was impressed with the college president, Mark Hopkins, who had responded warmly to Garfield's letter inquiring about admission. He said of Hopkins, "The ideal college is Mark Hopkins on one end of a log with a student on the other." Hopkins later stated about Garfield in his student days, "There was a large general capacity applicable to any subject. There was no pretense of genius, or alternation of spasmodic effort, but a satisfactory accomplishment in all directions." After his first term, Garfield was hired to teach penmanship to the students of nearby Pownal, Vermont, a post whose previous incumbent was Chester A. Arthur.
Garfield graduated from Williams in August 1856 as salutatorian, giving an address at the commencement. Garfield biographer Ira Rutkow pointed out that the future president's years at Williams gave Garfield the opportunity to know and respect those of different social backgrounds, and despite his origin as an unsophisticated Westerner, he was liked and respected by socially conscious New Englanders. "In short," as Rutkow later wrote, "Garfield had an extensive and positive first experience with the world outside the Western Reserve of Ohio."
On his return to Ohio, the degree from a prestigious Eastern school made Garfield a man of distinction. He returned to Hiram to teach at the Institute, and in 1857 was made its president. He did not see education as a field in which he could realize his full potential. At Williams, he had become more politically aware in the intensely anti-slavery atmosphere of the Massachusetts school, and began to consider politics as a career. In 1858, he married Lucretia; they would have seven children, five of whom survived infancy. Soon after the wedding, he formally entered his name to read law at a Cleveland firm, although he did his studying in Hiram. He was admitted to the bar in 1861.
Local Republican Party leaders invited Garfield to enter politics upon the death of Cyrus Prentiss, the presumptive nominee for the local state senate seat. He was nominated by the party convention on the sixth ballot, and was elected, serving until 1861. Garfield's major effort in the state senate was a bill providing for Ohio's first geological survey to measure its mineral resources, though it failed.
Civil War.
After Abraham Lincoln's election as president, several Southern states announced their secession from the Union to form a new government, the Confederate States of America. Garfield read military texts while anxiously awaiting the war effort, which he regarded as a holy crusade against the Slave Power. In April 1861, the rebels bombarded Fort Sumter, one of the last federal outposts in the South, beginning the Civil War. Although he had no military training, Garfield knew that his place was in the Union Army.
At Governor William Dennison's request, Garfield deferred his military ambitions to remain in the legislature, where he helped appropriate the funds to raise and equip Ohio's volunteer regiments. Afterward, the legislature adjourned and Garfield spent the spring and early summer on a speaking tour of northeastern Ohio, encouraging enlistment in the new regiments. Following a trip to Illinois to purchase muskets, Garfield returned to Ohio and, in August 1861, received a commission as a colonel in the 42nd Ohio Infantry regiment. The 42nd Ohio existed only on paper, so Garfield's first task was to fill its ranks. He did so quickly, recruiting many of his neighbors and former students. The regiment traveled to Camp Chase, outside Columbus, Ohio, to complete training. In December, Garfield was ordered to bring the 42nd to Kentucky, where they joined the Army of the Ohio under Brigadier General Don Carlos Buell.
Buell's command.
Buell quickly assigned Garfield the task of driving Confederate forces out of eastern Kentucky, giving him the 18th Brigade for the campaign which, besides his own 42nd, included the 40th Ohio Infantry, two Kentucky infantry regiments and two cavalry units. They departed Catlettsburg, Kentucky, in mid-December, advancing through the valley of the Big Sandy River. The march was uneventful until Union forces reached Paintsville, Kentucky, on January 6, 1862, where Garfield's cavalry engaged the rebels at Jenny's Creek. Confederate troops under Brigadier General Humphrey Marshall held the town in numbers roughly equal to Garfield's own, but Garfield positioned his troops so as to deceive Marshall into believing that rebel forces were outnumbered. Marshall ordered his troops to withdraw to the forks of Middle Creek, on the road to Virginia; Garfield ordered his troops to pursue the Confederates. They attacked the rebel positions on January 9, 1862, in the Battle of Middle Creek, the only pitched battle Garfield personally commanded. At the end of the fighting, the Confederates withdrew from the field, and Garfield sent his troops to Prestonsburg to reprovision.
In recognition of his success, Garfield was promoted to brigadier general. After Marshall's retreat, Garfield's command was the sole remaining Union force in eastern Kentucky, and he announced that any men who had fought for the Confederacy would be granted amnesty if they returned to their homes and lived peaceably and remained loyal to the Union. The proclamation was surprisingly lenient, as Garfield now believed the war was a crusade for eradication of slavery. Following a brief skirmish at Pound Gap, the last rebel units in the area were outflanked, and they retreated to Virginia.
Garfield's promotion gave him command of the 20th Brigade of the Army of the Ohio, which was ordered in early 1862 to join Major General Ulysses S. Grant's forces as they advanced on Corinth, Mississippi. Before the 20th Brigade arrived, however, Confederate forces under General Albert Sidney Johnston surprised Grant's men in their camps, driving them back. Garfield's troops got word of the battle and advanced quickly, joining the rest of the army on the second day to drive the Confederates back across the field and into retreat. The action, later known as the Battle of Shiloh, was the bloodiest of the war to date; Garfield was exposed to fire for much of the day, but emerged uninjured. Major General Henry W. Halleck, Grant's superior, took charge of the combined armies and advanced ponderously toward Corinth; when they arrived, the Confederates had fled.
That summer Garfield suffered from jaundice and significant weight loss. He was forced to return home, where his wife nursed him back to health. While he was home, Garfield's friends worked to gain him the Republican nomination for Congress, although he refused to politick with the delegates. He returned to military duty that autumn and went to Washington to await his next assignment. During this period of idleness, a rumor of an extra-marital affair caused friction in the Garfield marriage until Lucretia eventually chose to overlook it. Garfield repeatedly received tentative assignments that were quickly withdrawn, to his frustration. In the meantime, he served on the court-martial of Fitz John Porter, a sensational trial in which Porter was tried for his tardiness at the Second Battle of Bull Run. He was convinced of Porter's guilt, and voted with his fellow generals to convict. The trial lasted almost two months, from November 1862 to January 1863, and by the end of it, Garfield had at last procured an assignment as Chief of Staff to Major General William S. Rosecrans.
Chief of staff for Rosecrans.
The position of Chief of Staff for a general was usually held by a more junior officer, but Garfield's influence with Rosecrans was greater than usual, with duties extending beyond mere communication of orders to duties that involved actual management of his Army of the Cumberland. Rosecrans had a voracious appetite for conversation, especially when he was unable to sleep; in Garfield, he found "the first well read person in the Army" and the ideal candidate for discussions that ran deep into the night. The two became close in spite of Garfield's being twelve years junior to Rosecrans, and their talks covered all topics, especially religion; Rosecrans, who had converted from Methodism to Roman Catholicism, succeeded in softening Garfield's view of his faith. Garfield recommended that Rosecrans replace wing commanders Alexander McCook and Thomas Crittenden, whom he believed ineffective, but Rosecrans ignored the suggestions. With Rosecrans, Garfield devised the Tullahoma Campaign to pursue and trap Confederate General Braxton Bragg in Tullahoma. After initial Union success, Bragg retreated toward Chattanooga, where Rosecrans stalled and requested more troops and supplies. Garfield argued for an immediate advance, in line with demands from Halleck and Lincoln. After a council of war and lengthy deliberations, Rosecrans agreed to attack.
At the ensuing Battle of Chickamauga on September 19 and 20, 1863, confusion among the wing commanders over Rosecrans's orders created a gap in the lines, resulting in a rout of the right flank. Rosecrans concluded that the battle was lost and fell back on Chattanooga to establish a defensive line. Garfield, however, thought that part of the army had held and, with Rosecrans's approval, headed across Missionary Ridge to survey the scene. Garfield's hunch was correct. His ride became legendary, while Rosecrans' error reignited criticism about his leadership. While Rosecrans's army had avoided disaster, they were stranded in Chattanooga, surrounded by Bragg's army. Garfield sent a telegram to Secretary of War Edwin M. Stanton alerting Washington to the need for reinforcements to avoid annihilation, and Lincoln and Halleck delivered 20,000 troops by rail within nine days. In the meantime, Grant was promoted to command of the western armies, and quickly replaced Rosecrans with George H. Thomas. Garfield was ordered to report to Washington, where he was promoted to major general, a commission he would resign before taking a seat in the House of Representatives. According to historian Jean Edward Smith, Grant and Garfield had a "guarded relationship", since Grant promoted Thomas to command of the Army of the Cumberland, rather than Garfield, after Rosecrans was dismissed.
Congressional career.
Election in 1862; Civil War years.
While serving in the army in early 1862, Garfield was approached by friends about running for Congress from Ohio's newly redrawn, heavily Republican 19th district. He was worried that he and other state-appointed generals would get obscure assignments, and running for Congress would allow him to resume his political career. The fact that the new Congress would not hold its first regular session until December 1863 would allow him to continue his war service for a time. Home on medical leave, he refused to campaign for the nomination, leaving that to political managers who secured it at the local convention in September 1862, on the eighth ballot. In October, he defeated D.B. Woods by a two-to-one margin in the general election for a seat in the 38th Congress.
Soon after the nomination, Garfield was ordered to report to War Secretary Edwin Stanton in Washington to discuss his military future. There, Garfield met Treasury Secretary Salmon P. Chase, who befriended him, seeing him as a younger version of himself. The two men agreed politically, and both were part of the Radical wing of the Republican Party. Once he took his seat in December 1863, Garfield was frustrated that Lincoln seemed reluctant to press the South hard. Many radicals, led in the House by Pennsylvania's Thaddeus Stevens, wanted lands owned by rebels to be confiscated, but Lincoln threatened to veto any bill that would do that on a widespread basis. Garfield, in debate on the House floor, supported such legislation and, discussing England's Glorious Revolution, hinted that Lincoln might be thrown out of office for resisting the bills. Although Garfield had supported Lincoln's Emancipation Proclamation, the congressman marveled that it was a "strange phenomenon in the world's history, when a second-rate Illinois lawyer is the instrument to utter words which shall form an epoch memorable in all future ages".
Garfield not only favored abolition of slavery, but believed that the leaders of the rebellion had forfeited their constitutional rights. He supported the confiscation of southern plantations and even exile or execution of rebellion leaders as a means to ensure the permanent destruction of slavery. Garfield felt Congress was obliged "to determine what legislation is necessary to secure equal justice to all loyal persons, without regard to color." Garfield was more supportive of Lincoln when Lincoln took action against slavery. Early in his tenure, he differed from his party on several issues; his was the solitary Republican vote to terminate the use of bounties in recruiting. Some financially able recruits had used the bounty system to buy their way out of service (called commutation), which Garfield considered reprehensible. Garfield gave a speech pointing out the flaws in the existing conscription law: that of 300,000 called upon to enlist, barely 10,000 had, the remainder claiming exemption or providing money or a substitute. Lincoln appeared before the Military Affairs committee on which Garfield served, demanding a more effective bill; even if it cost him re-election, Lincoln was confident he could win the war before his term expired. After many false starts, Garfield, with the support of Lincoln, procured the passage of a conscription bill which excluded commutation.
Under Chase's influence, Garfield became a staunch proponent of a dollar backed by a gold standard, and was therefore a strong opponent of the "greenback"; he regretted very much, but understood, the necessity for suspension of payment in gold or silver during the emergency presented by the Civil War. Garfield voted with the Radical Republicans in passing the Wade–Davis Bill, designed to give Congress more authority over Reconstruction, but it was defeated by Lincoln's pocket veto.
Garfield did not consider Lincoln particularly worthy of re-election, but no viable alternative seemed available. "He will probably be the man, though I think we could do better." The Ohioan attended the party convention and promoted Rosecrans as Lincoln's running mate, but delegates chose Military Governor of Tennessee Andrew Johnson. Both Lincoln and Garfield were re-elected. By then, Chase had left the Cabinet and had been appointed Chief Justice, and his relations with Garfield became more distant.
Garfield took up the practice of law in 1865 as a means to improve his personal finances. His efforts took him to Wall Street where, the day after Lincoln's assassination, a riotous crowd led him into an impromptu speech to calm it: "Fellow citizens! Clouds and darkness are round about Him! His pavilion is dark waters and thick clouds of the skies! Justice and judgment are the establishment of His throne! Mercy and truth shall go before His face! Fellow citizens! God reigns, and the Government at Washington still lives!" The speech, with no mention or praise of Lincoln, was according to Garfield biographer Robert G. Caldwell "quite as significant for what it did not contain as for what it did". In the following years, Garfield had more praise for Lincoln; a year after the Illinoisan's death Garfield stated that "greatest among all these developments were the character and fame of Abraham Lincoln", and in 1878 called Lincoln "one of the few great rulers whose wisdom increased with his power".
Reconstruction.
After the war, Garfield became a proponent of black suffrage, though he admitted that the idea of African Americans as political equals with whites gave him "a strong feeling of repugnance". The new president, Johnson, sought the rapid restoration of the Southern states during the months between his accession and the meeting of Congress in December 1865; Garfield hesitantly supported this policy as an experiment. Johnson, an old friend, sought Garfield's backing, and their conversations led Garfield to assume that differences between president and Congress were not large. When Congress assembled in December (to Johnson's chagrin without the elected representatives of the Southern states, who were excluded), Garfield urged conciliation on his colleagues, although he feared that Johnson, a former Democrat, might combine with other Democrats to gain political control if he rejoined the party. Garfield foresaw conflict even before February 1866 when Johnson vetoed a bill to extend the life of the Freedmen's Bureau, charged with aiding the former slaves. By April, Garfield had concluded that Johnson was either "crazy or drunk with opium".
The conflict between the branches of government was the major issue of the 1866 campaign, with Johnson taking to the campaign trail in a Swing Around the Circle and Garfield facing opposition within his party in his home district. With the South still disenfranchised and Northern public opinion behind them, the Republicans gained a two-thirds majority in both houses of Congress. Garfield, having overcome his challengers at his district nominating convention, was easily re-elected.
Garfield opposed the initial talk of impeaching President Johnson when Congress convened in December 1866. However, he supported legislation to limit Johnson's powers, such as the Tenure of Office Act, which restricted Johnson in removing presidential appointees. Distracted by committee duties, he rarely spoke in connection with these bills, but was a loyal Republican vote against Johnson. Due to a court case, he was absent on the day in April 1868 when the House impeached Johnson, but soon gave a speech aligning himself with Thaddeus Stevens and others who sought Johnson's removal. When the president was acquitted in trial before the Senate, Garfield was shocked, and blamed the outcome of the trial on its presiding officer, Chief Justice Chase, his onetime mentor.
By the time Ulysses S. Grant succeeded Johnson in 1869, Garfield had moved away from the remaining radicals (Stevens, their leader, had died in 1868). He hailed the ratification of the 15th Amendment in 1870 as a triumph, and he favored the re-admission of Georgia to the Union as a matter of right, not politics. In 1871, Garfield opposed passage of the Ku Klux Klan Act, saying "I have never been more perplexed by a piece of legislation". He was torn between his indignation at "these terrorists" and his concern for the freedoms endangered by the power the bill gave to the president to enforce the act through suspension of habeas corpus.
Tariffs and finance.
Throughout his political career, Garfield favored the gold standard and decried attempts to increase the money supply through the issuance of paper money not backed by gold, and later, through the free and unlimited coinage of silver. In 1865, Garfield was placed on the House Ways and Means Committee, a long-awaited opportunity to focus on financial and economic issues. He reprised his opposition to the greenback, saying, "any party which commits itself to paper money will go down amid the general disaster, covered with the curses of a ruined people." In 1868 Garfield gave a two-hour speech on currency in the House, which was widely applauded as his best oratory to that point; in it he advocated a gradual resumption of specie payments, that is, the government paying out silver and gold, rather than paper money that could not be redeemed.
Tariffs had been raised to high levels during the Civil War. Afterwards, Garfield, who made a close study of financial affairs, advocated moving towards free trade, though the standard Republican position was a protective tariff that would allow American industries to grow. This break with his party likely cost him his place on the Ways and Means Committee in 1867, and though Republicans held the majority in the House until 1875, Garfield remained off that committee during that time. Garfield came to chair the powerful House Appropriations Committee, but it was Ways and Means, with its influence over fiscal policy, that he really wanted to lead. Part of the reason Garfield was denied a place on Ways and Means was the opposition of the influential Republican editor, Horace Greeley.
In September 1870, Garfield, who was then chairman of the House Banking Committee, led an investigation into the Black Friday Gold Panic scandal. The committee investigation into corruption was thorough, but found no indictable offenses. Garfield blamed the easy availability of fiat money greenbacks for financing the speculation that led to the scandal.
Garfield was not at all enthused about the re-election of President Grant in 1872—until Horace Greeley, who emerged as the candidate of the Democrats and Liberal Republicans, became the only serious alternative. Garfield opined, "I would say Grant was not fit to be nominated and Greeley is not fit to be elected." Both Grant and Garfield won overwhelming re-election victories.
Crédit Mobilier scandal; Salary Grab.
The Crédit Mobilier of America scandal involved corruption in the financing of the Union Pacific Railroad, part of the transcontinental railroad that was completed in 1869. Union Pacific officers and directors secretly purchased control of the Crédit Mobilier of America company, then contracted with the firm to have it undertake the construction of the railroad. The grossly inflated invoices submitted by the company were paid by the railroad, using federal funds appropriated to subsidize the project, and the company was allowed to purchase Union Pacific securities at par value, well below the market rate. Crédit Mobilier showed large profits and stock gains, and distributed substantial dividends. The high expenses meant that Congress was called upon to appropriate more funds. One of the railroad officials who controlled Crédit Mobilier was also a congressman, Oakes Ames of Massachusetts. He offered some of his colleagues the opportunity to buy Crédit Mobilier stock at par value, well below what it sold for on the market, and the railroad got its additional appropriations.
The story broke in July 1872, in the middle of the presidential campaign. Among those named were Vice President (and former House Speaker) Schuyler Colfax, Grant's second-term running mate (Massachusetts Senator Henry Wilson), Speaker James G. Blaine of Maine, and Garfield. Greeley had little luck taking advantage of the scandal. When Congress reconvened after the election, Blaine, seeking to clear his name, demanded a House investigation. Evidence before the special committee exonerated Blaine. Garfield had stated, in September 1872, that Ames had offered him stock, but he had repeatedly refused it. Testifying before the committee in January, Ames alleged that he had offered Garfield ten shares of stock at par value, but that Garfield had never taken the shares, or paid for them. A year had passed, from 1867 to 1868, before Garfield had finally refused it. Garfield, appearing before the committee on January 14, 1873, confirmed much of this. Ames testified several weeks later that Garfield agreed to take the stock on credit, and that it was paid for by the company's huge dividends. The two men differed over a sum of some $300 that Garfield received and later paid back, with Garfield deeming it a loan and Ames a dividend.
Garfield's biographers were unwilling to exonerate him in Crédit Mobilier, with Allan Peskin writing "Did Garfield lie? Not exactly. Did he tell the truth? Not completely. Was he corrupted? Not really. Even Garfield's enemies never claimed that his involvement ... influenced his behavior". Rutkow wrote that "Garfield's real offense was that he knowingly denied to the House investigating committee that he had agreed to accept the stock and that he had also received a dividend of $329." Caldwell suggested that Garfield "while he told the truth the committee, certainly failed to tell the whole truth, clearly evading an answer to certain vital questions and thus giving the impression of worse faults than those of which he was guilty". That Crédit Mobilier was a corrupt organization had been a secret badly kept, even mentioned on the floor of Congress, and editor Sam Bowles wrote at the time that Garfield, in his positions on committees dealing with finance, "had no more right to be ignorant in a matter of such grave importance as this, than the sentinel has to snore on his post".
Another issue that caused Garfield trouble in his 1874 re-election bid was the so-called "Salary Grab" of 1873, which increased the compensation for members of Congress by 50 percent, retroactive to 1871. Garfield was responsible, as Appropriations Committee chairman, for shepherding the legislative appropriations bill through the House; during the debate in February 1873, Massachusetts Representative Benjamin Butler offered the increase as an amendment, and despite Garfield's opposition, it passed the House and eventually became law. The law was very popular in the House, as almost half the members were lame ducks, but the public was outraged, and many of Garfield's constituents blamed him, though he refused to accept the increase. In what was a bad year for Republicans, who lost control of the House for the first time since the Civil War, Garfield had his closest congressional election, winning with only 57 percent of the vote.
Minority leader; Hayes administration.
With the Democratic takeover of the House of Representatives in 1875, Garfield lost his chairmanship of the Appropriations Committee. The Democratic leadership in the House appointed Garfield as a Republican member of Ways and Means. With many of his leadership rivals defeated in the 1874 Democratic landslide, and Blaine elected to the Senate, Garfield was seen as the Republican floor leader and the likely Speaker should the party regain control of the chamber.
As the 1876 presidential election approached, Garfield was loyal to the candidacy of Senator Blaine, and fought for the former Speaker's nomination at the 1876 Republican National Convention in Cincinnati. When it became clear, after six ballots, that Blaine could not prevail, the convention nominated Ohio Governor Rutherford B. Hayes. Although Garfield had supported Blaine, he had kept good relations with Hayes, and wholeheartedly supported the governor. Garfield had hoped to retire from politics after his term expired to devote himself full-time to the practice of law, but to help his party, he sought re-election, and won it easily that October. Any celebration was short lived, as Garfield's youngest son, Neddie, fell ill with whooping cough shortly after the congressional election, and soon died.
When Hayes appeared to have lost the presidential election the following month to Democrat Samuel Tilden, the Republicans launched efforts to reverse the result in Southern states where they held the governorship: South Carolina, Louisiana, and Florida. If Hayes won all three states, he would take the election by a single electoral vote. Grant asked Garfield to serve as a "neutral observer" in the recount in Louisiana. The observers soon recommended to the state electoral commissions that Hayes be declared the winner—Garfield recommended that the entire vote of West Feliciana Parish, which had given Tilden a sizable majority, be thrown out. The Republican governors of the three states certified that Hayes had won their states, to the outrage of Democrats, who had the state legislatures submit rival returns, and threatened to prevent the counting of the electoral vote—under the Constitution, Congress is the final arbiter of the election. Congress then passed a bill establishing the Electoral Commission, to determine the winner. Although he opposed the Commission, feeling that Congress should count the vote and proclaim Hayes victorious, Garfield was appointed to it over the objections of Democrats that he was too partisan. Hayes emerged the victor by a Commission vote of 8 to 7, with all eight votes being cast by Republican politicians or appointees of that party to the Supreme Court. As part of the deal whereby they recognized Hayes as president, Southern Democrats secured the removal of federal troops from the South, ending Reconstruction.
Although a Senate seat would be disposed of by the Ohio General Assembly after the resignation of John Sherman to become Treasury Secretary, Hayes needed Garfield's expertise to protect him from the agenda of a hostile Congress, and asked him not to seek it. Garfield, as the president's key legislator, gained considerable prestige and respect from his role. When Congress debated what became the Bland-Allison Act, to have the government purchase large quantities of silver and strike it into fully legal tender dollar coins, Garfield fought against this deviation from the gold standard, but it was enacted over Hayes's veto in February 1878.
Garfield during this time purchased the property in Mentor that reporters later dubbed Lawnfield, and from which he would conduct the first successful front porch campaign for the presidency. Hayes suggested that Garfield run for governor in 1879, seeing that as a road that would likely put Garfield in the White House. Garfield preferred to seek election as senator, and devoted his efforts to seeing that Republicans won the 1879 election for the General Assembly, with the likely Democratic candidate the incumbent, Allen G. Thurman. The Republicans swept the legislative elections. Rivals were spoken of for the seat, such as Secretary Sherman, but he had presidential ambitions (for which he sought Garfield's support), and other candidates fell by the wayside. Garfield was elected to the Senate by the General Assembly in January 1880, though his term was not to begin until March 4, 1881.
Legal career and other activities.
Garfield was one of three attorneys who argued for the petitioners in the landmark Supreme Court case "Ex parte Milligan" in 1866. The petitioners were pro-Confederate northern men who had been found guilty and sentenced to death by a military court for treasonous activities. The case turned on whether the defendants should instead have been tried by a civilian court, and resulted in a ruling that civilians could not be tried before military tribunals while the civil courts were operating. The oral argument was Garfield's first court appearance. Jeremiah Black had taken him in as a junior partner a year before, and assigned the case to him in light of his highly regarded oratory skills. With the result, Garfield instantly achieved a reputation as a preeminent appellate lawyer.
During Grant's first term, discontented with public service, Garfield pursued opportunities in the law, but declined a partnership offer when told his prospective partner was of "intemperate and licentious" reputation. In 1873, after the death of Chase, Garfield appealed to Grant to appoint Justice Noah H. Swayne as Chief Justice. Grant, however, appointed Morrison R. Waite.
Garfield thought the land grants given to expanding railroads to be an unjust practice; as well, he opposed some monopolistic practices by corporations, as well as the power sought by the workers' unions. Garfield supported the proposed establishment of the United States civil service as a means of ridding officials of the annoyance of aggressive office seekers. He especially wished to eliminate the common practice whereby government workers, in exchange for their positions, were forced to kick back a percentage of their wages as political contributions.
In 1876, Garfield displayed his mathematical talent when he developed a trapezoid proof of the Pythagorean theorem. His finding was placed in the "New England Journal of Education". Mathematics historian William Dunham stated that Garfield's trapezoid work was "really a very clever proof".
Presidential election of 1880.
Republican nomination.
Having just been elected to the Senate with Sherman's support, Garfield entered the 1880 campaign season committed to Sherman as his choice for the Republican presidential nominee. Even before the convention began, however, a few Republicans, including Wharton Barker of Philadelphia, thought Garfield the best choice for the nomination. Garfield denied any interest in the position, but the attention was enough to make Sherman suspicious of his lieutenant's ambitions. Besides Sherman, the early favorites for the nomination were Blaine and former president Grant, but several other candidates attracted delegates as well.
As the convention began, Senator Roscoe Conkling of New York, the floor leader for the Grant forces (known as the Stalwart faction), proposed that the delegates pledge to support the eventual nominee in the general election. When three West Virginia delegates declined to be so bound, Conkling sought to expel them from the convention. Garfield rose to defend the men, giving a passionate speech in defense of their right to reserve judgement. The crowd turned against Conkling, and he withdrew the motion. The performance delighted Garfield's boosters, who now believed more than ever that he was the only man who could attract a majority of the delegates' votes.
After speeches in favor of the other front-runners, Garfield rose to place Sherman's name in nomination; his nominating speech was well-received, but the delegates mustered little excitement for the idea of Sherman as the next president. The first ballot showed Grant leading with 304 votes and Blaine in second with 284; Sherman's 93 placed him in a distant third. Subsequent ballots quickly demonstrated a deadlock between the Grant and Blaine forces, with neither having the 379 votes needed for nomination. Jeremiah McLain Rusk, a member of the Wisconsin delegation, and Benjamin Harrison, an Indiana delegate, sought to break the deadlock by shifting a few of the anti-Grant votes to a dark horse candidate—Garfield. Garfield gained 50 votes on the 35th ballot, and the stampede began. Garfield protested to the other members of his Ohio delegation that he had not sought the nomination and had never intended to betray Sherman, but they overruled his objections and cast their ballots for him. In the next round of voting, nearly all of the Sherman and Blaine delegates shifted their support to Garfield, giving him 399 votes and the Republican nomination. Most of the Grant forces backed the former president to the end, creating a disgruntled Stalwart minority in the party. To obtain that faction's support for the ticket, former New York customs collector Chester A. Arthur, a member of Conkling's political machine, was chosen as the vice-presidential nominee.
Campaign against Hancock.
Despite including a Stalwart on the ticket, animosity between the Republican factions carried over from the convention, and Garfield traveled to New York to meet with party leaders there. After convincing the Stalwart crowd to put aside their differences and unite for the coming campaign, Garfield returned to Ohio, leaving the active campaigning to others, as was traditional at the time. Meanwhile, the Democrats settled on their nominee, Major General Winfield Scott Hancock of Pennsylvania, a career military officer. Hancock and the Democrats expected to carry the Solid South, while much of the North was considered safe territory for Garfield and the Republicans; most of the campaign would involve a few close states, including New York and Indiana.
Practical differences between the candidates were few, and Republicans began the campaign with the familiar theme of waving the bloody shirt: reminding Northern voters that the Democratic Party was responsible for secession and four years of civil war, and that if they held power they would reverse the gains of that war, dishonor Union veterans, and pay Confederate veterans pensions out of the federal treasury. With fifteen years having passed since the end of the war, and Union generals at the head of both tickets, the bloody shirt was of diminishing value in exciting the voters. With a few months to go before the election, the Republicans switched tactics to emphasize the tariff. Seizing on the Democratic platform's call for a "tariff for revenue only", Republicans told Northern workers that a Hancock presidency would weaken the tariff protection that kept them in good jobs. Hancock made the situation worse when, attempting to strike a moderate stance, he said "the tariff question is a local question". The ploy proved effective in uniting the North behind Garfield. In the end, fewer than two thousand votes, of the more than 9.2 million popular votes cast, separated the two candidates, but in the Electoral College Garfield had an easy victory over Hancock, 214 to 155.
Presidency, 1881.
Cabinet and inauguration.
Between his election and his inauguration, Garfield was occupied with assembling a cabinet that would establish peace between Conkling's and Blaine's warring factions. Blaine's delegates had provided much of the support for Garfield's nomination, and the Maine senator received the place of honor: Secretary of State. Blaine was not only the president's closest advisor, he was obsessed with knowing all that took place in the White House, and was even said to have spies posted there in his absence. Garfield nominated William Windom of Minnesota as Secretary of the Treasury, William H. Hunt of Louisiana as Secretary of the Navy, Robert Todd Lincoln as Secretary of War, and Samuel J. Kirkwood of Iowa as Secretary of the Interior. New York was represented by Thomas Lemuel James as Postmaster General. Garfield appointed Pennsylvania's Wayne MacVeagh, an adversary of Blaine's, as Attorney General. Blaine tried to sabotage the appointment by convincing Garfield to name an opponent of MacVeagh, William E. Chandler, as Solicitor General under MacVeagh. Only Chandler's rejection by the Senate forestalled MacVeagh's resignation over the matter.
Distracted by cabinet maneuvering, Garfield's inaugural address was not up to his typical oratorical standards. In one high point, Garfield emphasized the civil rights of African-Americans, saying "Freedom can never yield its fullness of blessings so long as the law or its administration places the smallest obstacle in the pathway of any virtuous citizen." After discussing the gold standard, the need for education, and an unexpected denunciation of Mormon polygamy, the speech ended. The crowd applauded, but the speech, according to Peskin, "however sincerely intended, betrayed its hasty composition by the flatness of its tone and the conventionality of its subject matter."
Garfield's appointment of James infuriated Conkling, a factional opponent of the Postmaster General, who demanded a compensatory appointment for his faction, such as the position of Secretary of the Treasury. The resulting squabble occupied much of Garfield's brief presidency. The feud with Conkling reached a climax when the president, at Blaine's instigation, nominated Conkling's enemy, Judge William H. Robertson, to be Collector of the Port of New York. This was one of the prize patronage positions below cabinet level, and was then held by Edwin A. Merritt. Conkling raised the time-honored principle of senatorial courtesy in an attempt to defeat the nomination, to no avail. Garfield, who believed the practice to be corrupt, would not back down and threatened to withdraw all nominations unless Robertson was confirmed, intending to "settle the question whether the President is registering clerk of the Senate or the Executive of the United States." Ultimately, Conkling and his New York colleague, Senator Thomas C. Platt, resigned their Senate seats to seek vindication, but found only further humiliation when the New York legislature elected others in their places. Robertson was confirmed as Collector and Garfield's victory was clear. To Blaine's chagrin, the victorious Garfield returned to his goal of balancing the interests of party factions, and nominated a number of Conkling's Stalwart friends to offices.
Reforms.
Grant and Hayes had both advocated civil service reform, and by 1881, civil service reform associations had organized with renewed energy across the nation. Garfield sympathized with them, believing that the spoils system damaged the presidency and distracted from more important concerns. Some reformers were disappointed that Garfield had advocated limited tenure only to minor office seekers and had given appointments to his old friends, but many remained loyal and supported Garfield.
Corruption in the post office also cried out for reform. In April 1880, there had been a congressional investigation into corruption in the Post Office Department, in which profiteering rings allegedly stole millions of dollars, securing bogus mail contracts on star routes. After obtaining contracts with the lowest bid, costs to run the mail routes would be escalated and profits would be divided among ring members. That year, Hayes stopped the implementation of any new star route contracts. Shortly after taking office, Garfield received information from Attorney General MacVeagh and Postmaster General James of postal corruption by an alleged star route ringleader, Second Assistant Postmaster-General Thomas J. Brady. Garfield demanded Brady's resignation and ordered prosecutions that would end in trials for conspiracy. When told that his party, including his own campaign manager, Stephen W. Dorsey, was involved, Garfield directed MacVeagh and James to root out the corruption in the Post Office Department "to the bone", regardless of where it might lead. Brady resigned and was eventually indicted for conspiracy. After two "star route" ring trials in 1882 and 1883, the jury found Brady not guilty.
Civil rights and education.
Garfield believed that the key to improving the state of African American civil rights would be found in education aided by the federal government. During Reconstruction, freedmen had gained citizenship and suffrage that enabled them to participate in government, but Garfield believed their rights were being eroded by Southern white resistance and illiteracy, and was concerned that blacks would become America's permanent "peasantry". His answer was to propose a "universal" education system funded by the federal government. Congress and the northern white public, however, had lost interest in African-American rights, and federal funding for universal education did not find support in Congress during Garfield's term. Garfield also worked to appoint several African Americans to prominent positions: Frederick Douglass, recorder of deeds in Washington; Robert Elliot, special agent to the Treasury; John M. Langston, Haitian minister; and Blanche K. Bruce, register to the Treasury. Garfield believed that Southern support for the Republican party could be gained by "commercial and industrial" interests rather than race issues and began to reverse Hayes's policy of conciliating Southern Democrats. He appointed William H. Hunt, a carpetbagger Republican from Louisiana, as Secretary of the Navy. To break the hold of the resurgent Democratic Party in the Solid South, Garfield took patronage advice from Virginia Senator William Mahone of the biracial independent Readjuster Party, hoping to add the independents' strength to the Republicans' there.
Foreign policy and naval reform.
Entering the presidency, Garfield had little foreign policy experience, so he leaned heavily on Blaine. Blaine, a former protectionist, now agreed with Garfield on the need to promote freer trade, especially within the Western Hemisphere. Their reasons were twofold: firstly, Garfield and Blaine believed that increasing trade with Latin America would be the best way to keep Great Britain from dominating the region. Secondly, by encouraging exports, they believed they could increase American prosperity, and by doing so position the Republican party as the author of that prosperity, ensuring continued electoral success. Garfield authorized Blaine to call for a Pan-American conference in 1882 to mediate disputes among the Latin American nations and to serve as a forum for talks on increasing trade. At the same time, they hoped to negotiate a peace in the War of the Pacific then being fought by Bolivia, Chile, and Peru. Blaine favored a resolution that would not result in Peru yielding any territory, but Chile, which had by 1881 occupied the Peruvian capital, Lima, rejected any settlement that restored the previous "status quo". Garfield sought to expand American influence in other areas, calling for renegotiation of the Clayton-Bulwer Treaty to allow the United States to construct a canal through Panama without British involvement, as well as attempting to reduce British influence in the strategically located Kingdom of Hawaii. Garfield's and Blaine's plans for the United States' involvement in the world stretched even beyond the Western Hemisphere, as he sought commercial treaties with Korea and Madagascar. Garfield also considered enhancing the United States' military strength abroad, asking Navy Secretary Hunt to investigate the condition of the navy with an eye toward expansion and modernization. In the end, these ambitious plans came to nothing after Garfield was assassinated. Nine countries had accepted invitations to the Pan-American conference, but the invitations were withdrawn in April 1882 after Blaine resigned from the cabinet and Arthur, Garfield's successor, cancelled the conference. Naval reform continued under Arthur, if on a more modest scale than Garfield and Hunt had envisioned, ultimately ending in the construction of the Squadron of Evolution.
Assassination.
Guiteau and shooting.
Charles J. Guiteau had followed various professions in his life, but in 1880 had determined to gain federal office by supporting what he expected to be the winning Republican ticket. He composed a speech, "Garfield vs. Hancock", and got it printed by the Republican National Committee. One means of persuading the voter in that era was through orators expounding on the candidate's merits, but with the Republicans seeking more famous men, Guiteau received few opportunities to speak. On one occasion, according to Kenneth D. Ackerman in his book about Garfield's candidacy and assassination, Guiteau was unable to finish his speech due to nerves. Guiteau, who considered himself a Stalwart, deemed his contribution to Garfield's victory sufficient to justify the position of consul in Paris, despite the fact he spoke no French, nor any foreign language.
One of President Garfield's more wearying duties was seeing office seekers, and he saw Guiteau at least once. White House officials suggested to Guiteau that he approach Blaine, as the consulship was within the Department of State. Blaine also saw the public regularly, and Guiteau became a regular at these sessions; Blaine, who had no intention of giving Guiteau a position for which he was not qualified nor one he had not earned, simply stated that the deadlock in the Senate over Robertson's nomination made it impossible to consider the Paris consulship, which required Senate confirmation. Once the New York senators had resigned, and Robertson had been confirmed as Collector, Guiteau pressed his claim, and Blaine told him he would not receive the position.
Guiteau came to believe he had lost the position because he was a Stalwart. The office-seeker decided that the only way to end the internecine warfare in the Republican Party was for Garfield to die—though he had nothing personal against the president. Arthur's succession would restore peace, he felt, and lead to rewards for fellow Stalwarts, including Guiteau.
The assassination of Abraham Lincoln was deemed a fluke due to the Civil War, and Garfield, like most people, saw no reason why the president should be guarded; Garfield's movements and plans were often printed in the newspapers. Guiteau knew the president would leave Washington for cooler climes on July 2, and made plans to kill him before then. He purchased a gun he thought would look good in a museum, and followed Garfield several times, but each time his plans were frustrated, or he lost his nerve. His opportunities dwindled to one—Garfield's departure by train for New Jersey on the morning of July 2, 1881.
Guiteau concealed himself by the ladies' waiting room at the Sixth Street Station of the Baltimore and Potomac Railroad, from where Garfield was scheduled to depart. Most of Garfield's cabinet planned to accompany him at least part of the way; Blaine, who was to remain in Washington, came to the station to see him off. The two men were deep in conversation and did not notice Guiteau before he took out his revolver and shot Garfield twice, once in the back and once in the arm. The time was 9:30 a.m. The assassin attempted to leave the station, but was quickly captured. As Blaine recognized him and Guiteau made no secret of why he had shot Garfield, the assassin's motivation to benefit the Stalwarts reached many with the early news of the shooting, causing rage against that faction.
Treatment and death.
Garfield was hit by two shots; one glanced off his arm while the other pierced his back, shattering a rib and embedding itself in his abdomen. "My God, what is this?" he exclaimed. Guiteau, as he was led away, stated, "I did it. I will go to jail for it. I am a Stalwart and Arthur will be President."
Among those at the station was Robert Todd Lincoln, who sixteen years before had watched his father die from an assassin's bullet. Garfield was taken on a mattress upstairs to a private office, where several doctors examined him, probing the wound with unwashed fingers. At his request, Garfield was taken back to the White House, and his wife, then in New Jersey, was sent for. Blaine sent word to Vice President Arthur in New York City, who received threats against his life because of his animosity toward Garfield and Guiteau's statements.
Although Joseph Lister's pioneering work in antisepsis was known to American doctors, with Lister himself having visited America in 1876, few of them had confidence in it, and none of his advocates were among Garfield's treating physicians. The physician who took charge at the depot and then at the White House was Doctor Willard Bliss. A noted physician and surgeon, Bliss was an old friend of Garfield, and about a dozen doctors, led by Bliss, were soon probing the wound with unsterilized fingers and instruments. Garfield was given morphine for the pain, and asked Bliss to frankly tell him his chances, which Bliss put at one in a hundred. "Well, Doctor, we'll take that chance."
Over the next few days, Garfield made some improvement, as the nation viewed the news from the capital and prayed. Although he never stood again, he was able to sit up and write several times, and his recovery was viewed so positively that a steamer was fitted out as a seagoing hospital to aid with his convalescence. He was nourished on oatmeal (which he detested) and milk from a cow on the White House lawn. When told that Indian chief Sitting Bull, a prisoner of the army, was starving, Garfield said, "Let him starve", then, "Oh, no, send him my oatmeal." Alexander Graham Bell tried to locate the bullet with a primitive metal detector; he was not successful. One means of keeping the president comfortable in Washington's summer heat was one of the first successful air conditioning units: air that was propelled by fans over ice and then dried had reduced the temperature in the sickroom by 20 degrees Fahrenheit (11 degrees Celsius).
Beginning on July 23, Garfield took a turn for the worse. His temperature increased to ; doctors, concerned by a pus sac that had developed by the wound, operated and inserted a drainage tube. This initially seemed to help, and Garfield, in his bed, was able to hold a brief cabinet meeting on July 29, though members were under orders from Bliss to discuss nothing that might excite Garfield. Doctors probed the sac, which went into Garfield's body, hoping to find the bullet; they most likely only made the infections worse. Garfield performed only one state act in August, signing an extradition paper. By the end of the month, the president was much more feeble than he had been, and his weight had decreased to .
Garfield had long been anxious to escape hot, unhealthy Washington, and in early September the doctors agreed to move him to Elberon, where his wife had recovered earlier in the summer. He left the White House for the last time on September 5, traveling in a specially cushioned railway car; a spur line to the Franklyn Cottage, a seaside mansion given over to his use, was built in a night by volunteers. There, Garfield could see the ocean as officials and reporters maintained what became (after an initial rally) a death watch. Garfield's personal secretary, Joe Stanley Brown, wrote 40 years later, "to this day I cannot hear the sound of the low slow roll of the Atlantic on the shore, the sound which filled my ears as I walked from my cottage to his bedside, without recalling again that ghastly tragedy."
On September 18, Garfield asked A. F. Rockwell, a friend, if he would have a place in history. Rockwell assured him he would, and told Garfield he had much work still before him. But his response was, "No, my work is done." The following day, Garfield, by then also suffering from pneumonia and heart pains, marveled that he could not pick up a glass despite feeling well, and went to sleep without discomfort. He awoke that evening around 10:15 pm with great pain in his chest. The attendant watching him sent for Bliss, who found him unconscious. Despite efforts to revive him, Garfield never awoke, and died at 10:35 PM that evening.
According to some historians and medical experts, Garfield might have survived his wounds had the doctors attending him had at their disposal today's medical research, techniques, and equipment. Standard medical practice at the time dictated that priority be given to locating the path of the bullet. Several of his doctors inserted their unsterilized fingers into the wound to probe for the bullet, a common practice in the 1880s. Historians agree that massive infection was a significant factor in President Garfield's demise. Biographer Peskin stated that medical malpractice did not contribute to Garfield's death; the inevitable infection and blood poisoning that would ensue from a deep bullet wound resulted in damage to multiple organs and spinal bone fragmentation. Rutkow, a professor of surgery at the University of Medicine and Dentistry of New Jersey, has argued that starvation also played a role. Rutkow suggests that "Garfield had such a nonlethal wound. In today's world, he would have gone home in a matter of two or three days."
Guiteau was indicted on October 14, 1881, for the murder of the President. In a chaotic trial in which Guiteau often interrupted and argued, and in which his counsel used the insanity defense, the jury found him guilty on January 5, 1882, and he was sentenced to death by hanging. Guiteau might have had syphilis, a disease that causes physiological mental impairment. He was executed on June 30, 1882.
Funeral, memorials and commemorations.
Garfield's funeral train left Long Branch on the same special track that brought him there, traveling over tracks blanketed with flowers and past houses adorned with flags. His body was transported to the Capitol and then continued on to Cleveland for burial. More than 70,000 citizens, some waiting over three hours, passed by Garfield's coffin as his body lay in state in Washington; later, on September 25, 1881, in Cleveland, more than 150,000—a number equal to the entire population of that city—likewise paid their respects. His body was temporarily interred in a vault in Cleveland's Lake View Cemetery until his permanent memorial was built.
Memorials to Garfield were erected across the country. On April 10, 1882, seven months after Garfield's death, the U.S. Post Office issued a postage stamp in his honor, the second stamp issued by the U.S. to honor an assassinated president. In 1884, sculptor Frank Happersberger completed a monument on the grounds of the San Francisco Conservatory of Flowers. In 1887, the James A. Garfield Monument was dedicated in Washington. Another monument, in Philadelphia's Fairmount Park, was erected in 1896. In Victoria, Australia, Cannibal Creek was renamed Garfield in his honor.
On May 19, 1890, Garfield's body was permanently interred, with great solemnity and fanfare, in a mausoleum in Lake View Cemetery in Cleveland. Attending the dedication ceremonies were former president Hayes, President Benjamin Harrison, and future president William McKinley. Garfield's Treasury Secretary, William Windom, also attended. Harrison said that Garfield was always a "student and instructor" and that his life works and death would "continue to be instructive and inspiring incidents in American history". Three panels on the monument display Garfield as a teacher, Union major general, and orator; another shows him taking the Presidential oath, and a fifth shows his body lying in state at the Capitol rotunda in Washington D.C.
Garfield's murder by a deranged office-seeker awakened public awareness of the need for civil service reform legislation. Senator George H. Pendleton, a Democrat from Ohio, launched a reform effort that resulted in the Pendleton Act in January 1883. This act reversed the "spoils system" where office seekers paid up or gave political service in order to obtain or keep federally appointed positions. Under the act, appointments were awarded on merit and competitive examination. To ensure the reform was implemented, Congress and Arthur established and funded the Civil Service Commission. The Pendleton Act, however, covered only 10% of federal government workers. For Arthur, previously known for having been a "veteran spoilsman", civil service reform became his most noteworthy achievement.
Legacy and historical view.
For a few years after his assassination, Garfield's life story was seen as an exemplar of the American success story: that even the poorest boy might someday become President of the United States. Peskin noted that "in mourning Garfield, Americans were not only honoring a president; they were paying tribute to a man whose life story embodied their own most cherished aspirations". As the rivalry between Stalwarts and Half-Breeds faded from the scene in the late 1880s and after, so too did memories of Garfield. In the 1890s, Americans became disillusioned with politicians, and looked elsewhere for inspiration, focusing on industrialists, labor leaders, scientists, and others as their heroes. Increasingly, Garfield's short time as president was forgotten.
The 20th century saw no revival for Garfield. Thomas Wolfe deemed the presidents of the Gilded Age, including Garfield, "lost Americans" whose "gravely vacant and bewhiskered faces mixed, melted, swam together". The politicians of the Gilded Age faded from the public eye, their luster eclipsed by those who had influenced America outside of political office during that time: the robber barons, the inventors, those who had sought social reform, and others who had lived as America rapidly changed. Current events and more recent figures occupied America's attention: according to Ackerman, "the busy Twentieth Century has made Garfield's era seem remote and irrelevant, its leaders ridiculed for their very obscurity."
Garfield's biographers, and those who have studied his presidency, tend to think well of him, and that his presidency saw a promising start before its untimely end. Historian Justus D. Doenecke, while deeming Garfield a bit of an enigma, chronicles his achievements, "by winning a victory over the Stalwarts, he enhanced both the power and prestige of his office. As a man, he was intelligent, sensitive, and alert, and his knowledge of how government worked was unmatched." Yet Doenecke criticizes Garfield's dismissal of Merritt in Robertson's favor, and wonders if the president was truly in command of the situation even after the latter's confirmation. According to Caldwell, writing in 1931, "If Garfield lives in history, it will be partly on account of the charm of his personality—but also because in life and in death, he struck the first shrewd blows against a dangerous system of boss rule which seemed for a time about to engulf the politics of the nation. Perhaps if he had lived he could have done no more." Rutkow writes, "James Abram Garfield's presidency is reduced to a tantalizing 'what if.
Peskin believes Garfield deserves more credit for his political career than he has received:
Works cited.
Books
Periodicals
Online

</doc>
<doc id="40402" url="https://en.wikipedia.org/wiki?curid=40402" title="United States presidential election, 1876">
United States presidential election, 1876

The United States presidential election of 1876 was the 23rd quadrennial presidential election, held on Tuesday, November 7, 1876. It was one of the most contentious and controversial presidential elections in American history. The results of the election remain among the most disputed ever, although there is no question that Samuel J. Tilden of New York outpolled Ohio's Rutherford B. Hayes in the popular vote. After a first count of votes, Tilden won 184 electoral votes to Hayes's 165, with 20 votes unresolved. These 20 electoral votes were in dispute in four states: in the case of Florida, Louisiana, and South Carolina, each party reported its candidate had won the state, while in Oregon one elector was declared illegal (as an "elected or appointed official") and replaced. The question of who should have been awarded these electoral votes is the source of the continued controversy concerning the results of this election.
An informal deal was struck to resolve the dispute: the Compromise of 1877, which awarded all 20 electoral votes to Hayes. In return for the Democrats' acquiescence in Hayes's election, the Republicans agreed to withdraw federal troops from the South, ending Reconstruction. The Compromise effectively ceded power in the Southern states to the Democratic Redeemers, who went on to pursue their agenda of returning the South to a political economy resembling that of its pre-war condition, including the disenfranchisement of black voters.
This was the first presidential election in 24 years in which the Democratic candidate won a majority of the popular vote. This is also the only election in which a candidate for president received more than 50 percent of the popular vote but was not elected president by the Electoral College, and one of four elections (in addition to 1824, 1888, and 2000) in which the person winning the plurality of the popular vote did not win the election. It is to date the smallest electoral vote victory and the election with the highest voter turnout of the voting age population in American history, at 81.8%.
Nominations.
Republican Party nomination.
Republican candidates:
During 1875 it was widely assumed that despite the poor economy and numerous political scandals he had endured, incumbent President Ulysses S. Grant would run for a third term as President, as, despite the long-standing tradition set by George Washington that Presidents only served two terms, Grant was considerably younger than any of the other two-term Presidents (Grant would be 54 years old when his term ended; the second-youngest two-term President, Washington himself, had been 65). In the autumn of that year however, Grant's advisers told him that while he still had enough support within the party that he could probably have secured the nomination without too much difficulty, they doubted his ability to win the election. The sudden death of Vice-President Henry Wilson in November seemed to sap any remaining desire Grant had to hold onto his office, and he announced later in the month that he would not seek re-nomination.
When the 6th Republican National Convention assembled on June 14, 1876, it appeared that James G. Blaine would be the nominee. On the first ballot, Blaine was just 100 votes short of a majority. His vote began to slide after the second ballot, as many Republicans feared that Blaine could not win the general election. Anti-Blaine delegates could not agree on a candidate until Blaine's total rose to 41% on the sixth ballot. Leaders of the reform Republicans met privately and considered alternatives. The choice was Ohio's reform Governor, Rutherford B. Hayes. On the seventh ballot, Hayes was nominated with 384 votes to 351 for Blaine and 21 for Benjamin Bristow. William A. Wheeler was nominated for vice-president by a much larger margin (366–89), and then amidst the balloting through acclamation, over his chief rival, Frederick Theodore Frelinghuysen, who later served as a member of the electoral commission that awarded the election to Hayes.
Democratic Party nomination.
Democratic candidates:
The 12th Democratic National Convention assembled in St. Louis in June 1876, the first political convention held west of the Mississippi River. Five thousand people jammed the auditorium in St. Louis hoping for the Democrats' first presidential victory in 20 years. The platform called for immediate and sweeping reforms following the scandal-plagued Grant administration. Tilden won more than 400 votes on the first ballot and the nomination by a landslide on the second.
Tilden defeated Thomas A. Hendricks, Winfield Scott Hancock, William Allen, Thomas F. Bayard, and Joel Parker for the presidential nomination. Although Tilden was strongly opposed by "Honest John" Kelly, the leader of New York's Tammany Hall, he was still able to obtain the nomination. Thomas Hendricks was nominated for vice-president since he was the only person put forward for the position.
The Democratic platform pledged to replace the corruption of the Grant administration with honest, efficient government and to end "the rapacity of carpetbag tyrannies" in the South. It also called for treaty protection for naturalized U.S. citizens visiting their homeland, restrictions on Asian immigration, tariff reform, and opposition to land grants for railroads.
It is claimed that Tilden's nomination was received by the voting Democrats with more enthusiasm than any leader since Andrew Jackson.
Source: "Official proceedings of the National Democratic convention, held in St. Louis, Mo., June 27th, 28th and 29th, 1876". (September 3, 2012).
Source: "Official proceedings of the National Democratic convention, held in St. Louis, Mo., June 27th, 28th and 29th, 1876". (September 3, 2012).
Greenback Party nomination.
Greenback candidates:
Candidates gallery.
The Greenback Party had been organized by agricultural interests in Indianapolis in 1874 to urge the federal government to inflate the economy through the mass issuance of paper money called greenbacks. Their first national nominating convention was held in Indianapolis in the spring of 1876. Peter Cooper was nominated for president with 352 votes to 119 for three other contenders. The convention nominated anti-monopolist Senator Newton Booth of California for vice-president; after Booth declined to run, the national committee chose Samuel Fenton Cary as his replacement on the ticket. Cooper was 85 years old at the time of his nomination, thus the oldest person ever nominated by a political party to serve as President of the United States.
Source: US President - G Convention. "Our Campaigns". (February 10, 2012).
Prohibition Party nomination.
The Prohibition Party, in its second national convention, nominated Green Clay Smith as their presidential candidate and Gideon T. Stewart as their vice-presidential candidate.
American National Party nomination.
This small political party used several different names, often with different names in different states. It was a continuation of the Anti-Masonic Party that met in 1872 and nominated Charles F. Adams for president. When Adams declined to run, the party did not contest the 1872 election.
The convention was held from June 8–10, 1875, in Liberty Hall, Pittsburgh. B.T. Roberts of New York served as chairman, and Jonathan Blanchard was the keynote speaker.
The platform supported the Reconstruction Amendments to the Constitution, international arbitration, the reading of the scriptures in public schools, specie payments, justice for the American Indians, abolition of the Electoral College, and prohibition of the sale of alcoholic beverages. It declared the first day of the week to be a day of rest for the United States. The platform opposed secret societies and monopolies.
The convention considered three potential presidential nominees: Charles F. Adams, Jonathan Blanchard, and James B. Walker. When Blanchard declined to run, Walker was unanimously nominated. The convention then nominated Donald Kirkpatrick of New York unanimously for vice-president.
General election.
Campaign.
Tilden, who had prosecuted machine politicians in New York and sent legendary political boss William M. Tweed to jail, ran as a reform candidate against the background of the corruption of the Grant administration. Both parties backed civil service reform and an end to Reconstruction. Both sides mounted mud-slinging campaigns, with Democratic attacks on Republican corruption being countered by Republicans raising the Civil War issue, a tactic ridiculed by Democrats who called it "waving the bloody shirt". Republicans chanted, "Not every Democrat was a rebel, but every rebel was a Democrat."
The Democratic strategy for victory in the south was highly reliant on paramilitary groups such as the Red Shirts and the White League. Using the strategy of the Mississippi Plan, these groups actively suppressed black and white Republican voter turnouts by disrupting meetings and rallies and even using violence and intimidation. They saw themselves as the military wing of the Democratic Party.
Because it was considered improper for a candidate to pursue the presidency actively, neither Tilden nor Hayes actively stumped as part of the campaign, leaving that job to surrogates.
Colorado.
Colorado became the 38th state on August 1, 1876. With insufficient time or money to organize a presidential election in the new state, Colorado's state legislature selected the state's electors. These electors in turn gave their three votes to Hayes and the Republican Party. This is the last election where any state chose electors by state legislature.
Electoral disputes.
In Florida (with 4 electoral votes), Louisiana (with 8), and South Carolina (with 7), reported returns favored Tilden, but election results in each state were marked by fraud and threats of violence against Republican voters. One of the points of contention revolved around the design of ballots. At the time, parties would print ballots or "tickets" to enable voters to support them in the open ballots. To aid illiterate voters the parties would print symbols on the tickets. In this election, however, many Democratic ballots were printed with the Republican symbol, Abraham Lincoln, on them. The Republican-dominated state electoral commissions subsequently disallowed a sufficient number of Democratic votes to award their electoral votes to Hayes.
In two southern states, the governor recognized by the United States had signed the Republican certificates. The Democratic certificates from Florida were signed by the state attorney-general and the new Democratic governor. Those from Louisiana were signed by the Democratic gubernatorial candidate, and those from South Carolina by no state official. In the latter state, the Tilden electors simply claimed that they were chosen by the popular vote and so they were rejected by the state election board.
Meanwhile, in Oregon, the vote of a single elector was disputed. The statewide result clearly had favored Hayes, but the state's Democratic governor, La Fayette Grover, claimed that that elector, former postmaster John Watts, was ineligible under Article II, Section 1, of the United States Constitution, since he was a "person holding an office of trust or profit under the United States." Grover then substituted a Democratic elector in his place. The two Republican electors dismissed Grover's action and each reported three votes for Hayes, while the Democratic elector, C.A. Cronin, reported one vote for Tilden and two votes for Hayes. The two Republican electors presented a certificate signed by the secretary of state of Oregon. Cronin and the two electors he appointed (Cronin voted for Tilden while his associates voted for Hayes) used a certificate signed by the governor and attested by the secretary of state. Ultimately, all three of Oregon's votes were awarded to Hayes.
Hayes thus had a majority of one in the Electoral College. The Democrats cried fraud. Suppressed excitement pervaded the country. Threats were even muttered that Hayes would never be inaugurated. In Columbus, Ohio, a shot was fired at Governor Hayes' residence as he sat down to dinner. Supporters marched to his home, calling for the "president". Hayes urged the crowd that, "it is impossible, at so early a time, to obtain the result." President Grant quietly strengthened the military force in and around Washington.
The Constitution provides that "the President of the Senate shall, in presence of the Senate and House of Representatives, open all the certificates, and the votes shall then be counted." Certain Republicans held that the power to count the votes lay with the President of the Senate, the House and Senate being mere spectators. The Democrats objected to this construction, since Mr. Ferry, the Republican President of the Senate, could then count the votes of the disputed states for Hayes. The Democrats insisted that Congress should continue the practice followed since 1865, which was that no vote objected to should be counted except by the concurrence of both houses. The House was strongly Democratic; by throwing out the vote of one state it could elect Tilden.
Facing an unprecedented constitutional crisis, the U.S. Congress passed a law on January 29, 1877, forming a 15-member Electoral Commission to settle the result. Five members were selected from each house of Congress, and they were joined by five members of the Supreme Court. William M. Evarts served as counsel for the Republican Party. The Compromise of 1877 might have helped the Democrats accept this electoral commission as well.
The majority party in each house named three members and the minority party two. As the Republicans controlled the Senate and the Democrats the House of Representatives, this yielded five Democratic and five Republican members of the Commission. Of the Supreme Court justices, two Republicans and two Democrats were chosen, with the fifth to be selected by these four.
The justices first selected a political independent, Justice David Davis. According to one historian, "one, perhaps not even Davis himself, knew which presidential candidate he preferred." Just as the Electoral Commission Bill was passing Congress, the legislature of Illinois elected Davis to the Senate. Democrats in the Illinois legislature believed that they had purchased Davis's support by voting for him. However, they had made a miscalculation; instead of staying on the Supreme Court so that he could serve on the Commission, he promptly resigned as a Justice in order to take his Senate seat. All the remaining available justices were Republicans, so the four justices already selected chose Justice Joseph P. Bradley, who was considered the most impartial remaining member of the court. This selection proved decisive.
It was drawing perilously near to Inauguration Day. The commission met on the last day of January. The cases of Florida, Louisiana, Oregon, and South Carolina were in succession submitted to it by Congress. Eminent counsel appeared for each side. There were double sets of returns from every one of the states named.
The commission first decided not to question any returns that were "prima facie" lawful. Bradley joined the other seven Republican committee members in a series of 8-7 votes that gave all 20 disputed electoral votes to Hayes, giving Hayes a 185-184 electoral vote victory. The commission adjourned on March 2; two days later Hayes was inaugurated without disturbance.
The returns accepted by the Commission put Hayes' margin of victory in South Carolina at 889 votes, the second-closest popular vote margin in a decisive state in U.S. history, after the 2000 election, decided by 537 votes in Florida (though in 2000, the declared margin of victory in the Electoral College for George W. Bush was five votes to Hayes' one).
It is not possible to conclude definitively what the result would have been if a fair election had been held without the violence and intimidation throughout the South that disenfranchised many African Americans made eligible to vote under the 15th Amendment. Nevertheless, in the likeliest fair scenario, Hayes would have won the election with 189 electoral votes to Tilden's 180 by winning all of the states that he did ultimately carry, plus Mississippi, but minus Florida. A strong case can be made that South Carolina, Louisiana, and Mississippi, states with an outright majority African-American population, would have gone for Hayes, since nearly all African Americans during this time voted Republican (while nearly all European-Americans in the South during this time voted Democratic). Regardless, Hayes would be the last Republican until Dwight D. Eisenhower in 1956 to win the electoral votes of Louisiana and the last Republican until Barry M. Goldwater in 1964 to carry South Carolina (both of these states were carried by Strom Thurmond, nominee of the third-party "States' Rights Democrats," in 1948). Florida, with a majority white population, would have likely gone to Tilden in a fair election. It is therefore likely that Hayes would have won appreciably more of the popular vote in a fair election, perhaps even a plurality or majority.
Upon his defeat, Tilden said, "I can retire to public life with the consciousness that I shall receive from posterity the credit of having been elected to the highest position in the gift of the people, without any of the cares and responsibilities of the office."
Results.
"Reflecting the Commission's rulings."
Of the 2,249 counties/independent cities making returns, Tilden won in 1,301 (57.85%) while Hayes carried only 947 (42.11%). One county (0.04%) in Nevada split evenly between Tilden and Hayes.
This was the last presidential election to occur prior to the end of Reconstruction. It would be another 20 years before a Southern state would again vote for a Republican presidential candidate, as William McKinley would carry Kentucky and West Virginia in 1896.
Source (Popular Vote): 
Source (Electoral Vote): 
Results by state.
Source: Data from Walter Dean Burnham, "Presidential ballots, 1836-1892" (Johns Hopkins University Press, 1955) pp 247–57.
Close states.
Margin of victory less than 5% (171 electoral votes):
Margin of victory between 5% and 10% (33 electoral votes):
Popular culture.
The Presidential Election of 1876 is a major theme of Gore Vidal's novel 1876.

</doc>
<doc id="40405" url="https://en.wikipedia.org/wiki?curid=40405" title="George Whitefield">
George Whitefield

George Whitefield (30 September 1770), also known as George Whitfield, was an English Anglican cleric who helped spread the Great Awakening in Britain and, especially, in the American colonies.
Born in Gloucester, England, he attended Pembroke College, Oxford University, where he met the Wesley brothers. He was one of the founders of Methodism and of the evangelical movement generally. In 1740, Whitefield traveled to America, where he preached a series of revivals that came to be known as the "Great Awakening". Whitefield was probably the most famous religious figure of the 18th century. He exercised influence over thousands in Great Britain and America by his oratory. He preached at least 18,000 times to perhaps 10 million hearers.
Early life.
Whitefield was born 16 December 1714 at the Bell Inn, Southgate Street, Gloucester in England. Whitefield was the fifth son (seventh child) of Thomas Whitefield and Elizabeth Edwards who kept an inn at Gloucester. At an early age, he found that he had a passion and talent for acting in the theatre, a passion that he would carry on with the very theatrical re-enactments of Bible stories he told during his sermons. He was educated at the Crypt School, Gloucester, and Pembroke College, Oxford.
Because business at the inn had become poor, Whitefield did not have the means to pay for his tuition. He therefore entered Oxford as a servitor, the lowest rank of students at Oxford. In return for free tuition, he was assigned as a minister to a number of higher ranked students. His duties included teaching them in the morning, helping them bathe, taking out their garbage, carrying their books and even assisting with required written assignments. He was a part of the "Holy Club" at the University of Oxford with the Wesley brothers, John and Charles. An illness, as well as Henry Scougal's "The Life of God in the Soul of Man", influenced him to cry out to God for salvation. Following a religious conversion, he became passionate for preaching his new-found faith. The Bishop of Gloucester ordained him a deacon.
Evangelism.
Whitefield preached his first sermon at St Mary de Crypt Church in his home town of Gloucester, a week after his ordination. He had earlier become the leader of the Holy Club at Oxford when the Wesley brothers departed for Georgia.
In 1738 he went to Savannah, Georgia, in the American colonies, as parish priest. While there he decided that one of the great needs of the area was an orphan house. He decided this would be his life's work. He returned to England to raise funds, as well as to receive priest's orders. While preparing for his return he preached to large congregations. At the suggestion of friends he preached to the miners of Kingswood, outside Bristol, in the open air. Because he was returning to Georgia he invited John Wesley to take over his Bristol congregations, and to preach in the open air for the first time at Kingswood and then at Blackheath, London.
Whitefield accepted the Church of England's doctrine of predestination and disagreed with the Wesley brothers' views on the doctrine of the Atonement, Arminianism. As a result, Whitefield did what his friends hoped he would not do—hand over the entire ministry to John Wesley. Whitefield formed and was the president of the first Methodist conference. But he soon relinquished the position to concentrate on evangelical work.
Three churches were established in England in his name – one in Penn Street, Bristol, and two in London, in Moorfields and in Tottenham Court Road – all three of which became known by the name of "Whitefield's Tabernacle". The society meeting at the second Kingswood School at Kingswood, a town on the eastern edge of Bristol, was eventually also named Whitefield's Tabernacle. Whitefield acted as chaplain to Selina, Countess of Huntingdon, and some of his followers joined the Countess of Huntingdon's Connexion, whose chapels were built by Selina, where a form of Calvinistic Methodism similar to Whitefield's was taught. Many of Selina's chapels were built in the English and Welsh counties, and one was erected in London—Spa Fields Chapel.
In 1739, Whitefield returned to England to raise funds to establish the Bethesda Orphanage, now the Bethany Academy. It is the oldest extant charity in North America.
On returning to North America in 1740, he preached a series of revivals that came to be known as the Great Awakening of 1740. In 1740 he engaged Moravian Brethren from Georgia to build an orphanage for Negro children on land he had bought in the Lehigh Valley of Pennsylvania. Following a theological disagreement, he dismissed them but was unable to complete the building, which the Moravians subsequently bought and completed. This now is the Whitefield House in the center of the Moravian settlement of Nazareth.
He preached nearly every day for months to large crowds of sometimes several thousand people as he traveled throughout the colonies, especially New England. His journey on horseback from New York City to Charleston was the longest then undertaken in North America by a white man.
Like his contemporary and acquaintance, Jonathan Edwards, Whitefield preached staunchly Calvinist theology that was in line with the "moderate Calvinism" of the Thirty-nine Articles. While explicitly affirming God's sole agency in salvation, Whitefield freely offered the Gospel, saying at the end of his sermons: "Come poor, lost, undone sinner, come just as you are to Christ."
Revival meetings.
The Anglican Church did not assign him a pulpit, so he began preaching in parks and fields in England on his own, reaching out to people who normally did not attend church. Like Jonathan Edwards, he developed a style of preaching that elicited emotional responses from his audiences. But Whitefield had charisma, and his voice (which according to many accounts, could be heard over five hundred feet), his small stature, and even his cross-eyed appearance (which some people took as a mark of divine favour) all served to help make him one of the first celebrities in the American colonies. Whitefield included slaves in his revivals and their response was great. Historians see this as “the genesis of African-American Christianity.”
To Whitefield “the gospel message was so critically important that he felt compelled to use all earthly means to get the word out.” Thanks to widespread dissemination of print media, perhaps half of all colonists eventually heard about, read about, or read something written by Whitefield. He employed print systematically, sending advance men to put up broadsides and distribute handbills announcing his sermons. He also arranged to have his sermons published.
Whitefield arranged to influence the colonies after he returned to England from his 1740 tour in America. He “contracted to have his autobiographical "Journals" published throughout America. These "Journals" have been characterized as “the ideal vehicle for crafting a public image that could work in his absence.” They depicted Whitefield in the “best possible light”. When he returned to America for his third tour in 1745, he was better known than when he had left.
Much of Whitefield's publicity was the work of William Seward, a wealthy layman for accompanied Whitefield. Seward acted as Whitefield’s “fund-raiser, business co-ordinator, and publicist”. He furnished newspapers and booksellers with material, including copies of Whitefield's writings.
When Whitefield returned to England in 1742, a crowd Whitefield estimated at 20,000 and William M'Culloch, the local minister, at 30,000, met him.
Benjamin Franklin and Whitefield.
Benjamin Franklin attended a revival meeting in Philadelphia, Pennsylvania and was greatly impressed with Whitefield's ability to deliver a message to such a large group. Franklin had previously dismissed, as an exaggeration, reports of Whitefield preaching to crowds of the order of tens of thousands in England. When listening to Whitefield preaching from the Philadelphia court house, Franklin walked away towards his shop in Market Street until he could no longer hear Whitefield distinctly. He then estimated his distance from Whitefield and calculated the area of a semicircle centred on Whitefield. Allowing two square feet per person he computed that Whitefield could be heard by over thirty thousand people in the open air.
Franklin admired Whitefield as a fellow intellectual but thought Whitefield's plan to run an orphanage in Georgia would lose money. He published several of Whitefield's tracts and was impressed by Whitefield's ability to preach and speak with clarity and enthusiasm to crowds. Franklin was an ecumenist and approved of Whitefield's appeal to members of many denominations, but was not, like Whitefield, an evangelical. In his autobiography, Franklin famously wrote that he was a "thoroughgoing Deist," which precludes the idea that God is personal, though some suggest that Franklin was more traditional in his views, e.g., his speech at the Constitutional Convention where he recited the verse that not a single sparrow falls to the ground without God's notice; how then could the Constitution convention hope to succeed without God's careful oversight? After one of Whitefield's sermons, Franklin noted the:
A lifelong close friendship developed between the revivalist preacher and the worldly Franklin. Looking beyond their public images, one finds a common charity, humility, and ethical sense embedded in the character of each man. True loyalty based on genuine affection, coupled with a high value placed on friendship, helped their association grow stronger over time.
Letters exchanged between Franklin and Whitefield can be found at the American Philosophical Society in Philadelphia. These letters document the creation of an orphanage for boys named the Charity School.
And in 1749, Franklin chose the Whitefield meeting house, with its Charity School, to be purchased as the site of the newly formed Academy of Philadelphia which opened in 1751, followed in 1755 with the College of Philadelphia, both the predecessors of the University of Pennsylvania. A statue of George Whitefield is located in the Dormitory Quadrangle, standing in front of the Morris and Bodine sections of the present Ware College House on the University of Pennsylvania campus.
Travels.
Whitefield is remembered as one of the first to preach to the enslaved. Phillis Wheatley wrote a poem in his memory after he died.
In an age when crossing the Atlantic Ocean was a long and hazardous adventure, he visited America seven times, making thirteen ocean crossings in total. It is estimated that throughout his life, he preached more than 18,000 formal sermons, of which seventy-eight have been published In addition to his work in North America and England, he made fifteen journeys to Scotland—most famously to the ""Preaching Braes"" of Cambuslang in 1742—two journeys to Ireland, and one each to Bermuda, Gibraltar, and the Netherlands. In England and Wales, Whitefield’s itinerary included every county.
He went to the Georgia Colony in 1738 following John Wesley's departure, to serve as a colonial chaplain at Savannah.
Marriage.
“I believe it is God’s will that I should marry,” George Whitefield wrote to a friend in 1740. But he was concerned: “I pray God that I may not have a wife till I can live as though I had none.” That ambivalence—believing God willed a wife, yet wanting to live as if without one—brought Whitefield a disappointing love life and largely unhappy marriage.
His wife died of a fever on 9 August 1768. She was buried in a vault at the Tottenham chapel. After their 1744–8 stay in America, she never accompanied him on his travels. Whitefield reflected that “none in America could bear her”. His wife believed that she had been “but a load & burden” to him. Cornelius Winter, who for a time lived with the Whitefields observed that Whitefield “was not happy in his wife”. Thus, “her death set his mind much at liberty”.
Death.
In 1770, the 55-year-old Whitefield continued preaching in spite of poor health. He said, "I would rather wear out than rust out." His last sermon was preached in a field “atop a large barrel”. The next morning Whitefield died in the parsonage of Old South Presbyterian Church, Newburyport, Massachusetts, on 30 September 1770, and was buried, according to his wishes, in a crypt under the pulpit of this church. A bust of Whitefield is in the collection of the Gloucester City Museum & Art Gallery.
It was John Wesley who preached his funeral sermon in London, at Whitefield's request.
Whitefield left almost £1500 to friends and family. That would be some £185,700.00 in 2014 pounds. Furthermore, he had deposited £1000 for his wife if he predeceased her and had contributed £3300 to Bethesda. “Questions concerning the source of his personal wealth dogged his memory. His will stated that all this money had lately been left him ‘in a most unexpected way and unthought of means.’”
Relation to other Methodist leaders.
In terms of theology, Whitefield, unlike John Wesley, was a supporter of Calvinism. The two differed on eternal election, final perseverance, and sanctification, but were reconciled as friends and co-workers, each going his own way. It is a prevailing misconception that Whitefield was not primarily an organizer like Wesley. However, as Wesleyan historian Rev. Luke Tyerman states, "It is notable that the first Calvinistic Methodist Association was held eighteen months before Wesley held his first Methodist Conference." He was a man of profound experience, which he communicated to audiences with clarity and passion. His patronization by the Countess of Huntingdon reflected this emphasis on practice.
Opposition and controversy.
Whitefield welcomed opposition because as he said, “the more I am opposed, the more joy I feel”. He proved himself adept at creating controversy. In his 1740 visit to Charles Town, it “took Whitefield only four days to plunge Charles Town into religious and social controversy.”
Whitefield thought he might be killed for his views. After he attacked the established church, he predicted that he would “be set at nought by the Rabbies of our Church, and perhaps at last be killed by them”.
Whitefield versus other clergy.
Whitefield chastised other clergy for teaching only “the shell and shadow of religion” because they did not hold the necessity of a new birth without which a person would be “thrust down into Hell”.
America
In his 1740-1741 visit to America (as he done in England), he attacked other clergy (mostly Anglican) calling them “God's persecutors”. He said that Edmund Gibson, Bishop of London with supervision over Anglican clergy in America, knew no “more of Christianity, than Mahaomet, or an Infidel”.
Whitefield issue a blanket indictment of New England's Congregational ministers for their “lack of zeal”.
After Whitefield preached at St. Philip's, Charleston, the Commissary, the Rev. Alexander Garden suspended him. After being suspended, Whitefield attacked all South Carolina's Anglican clergy in print.
In 1740, Whitefield published attacks on “the works of two of Anglicanism's revered seventeenth-century authors”. Whitefield wrote that John Tillotson, archbishop of Canterbury (1691-1694), had “no more been a true Christian than had Muhammad”. He also attacked Richard Allestree's "The Whole Duty of Man", one of Anglicanism's most popular spiritual tracts. At least once Whitefield had his followers burn the tract “with great Detestation”.
England and Scotland
In England and Scotland (1741–1744), Whitefield bitterly accused John Wesley of undermining his work. He preached against Wesley, arguing that Wesley's attacks on predestination had alienated “very many of my spiritual children”. Wesley replied that Whitefield’s attacks were “treacherous” and that Whitefield had made himself “odious and contemptible”.
When Joseph Trapp criticized Whitefield’s "Journals", Whitefield retorted that Trapp was “no Christian but a servant of Satan”.
Whitefield had been influenced by the Moravian Church, but in 1753 he condemned them and attacked their leader, Count Nicolaus Zinzendorf and their practices.
Clergy versus Whitefield.
English, Scottish, and American clergy attacked Whitefield, often in response to his attacks on them and the Anglican Church, as documented in this section..
England and Scotland
Early in his career, Whitefield criticized the Church of England. In response, clergy called Whitefield one of “the young quacks in divinity” who are “breaking the peace and unity” of the church.
From 1738 to 1741, Whitefield issued seven "Journals". A sermon in St Paul's Cathedral depicted them as “a medley of vanity, and nonsense, and blasphemy jumbled together”. Joseph Trapp called the Journals “blasphemous” and accused Whitefield of being “besotted either with pride or madness”.
In England, by 1738 when he was ordained priest, Whitefield wrote that “the spirit of the clergy began to be much embittered” and that “churches were gradually denied me”.
In response to Whitefield’s "Journals", the bishop of London, Edmund Gibson, published a 1739 pastoral letter criticizing Whitefield. The title was "A Caution against Enthusiasm. Being the second part of the late Bishop of London's fourth Pastoral Letter”. Whitefield responded by labeling Anglican clerics as “lazy, non-spiritual, and pleasure seeking”. He rejected ecclesiastical authority claiming that ‘the whole world is now my parish’.
In 1740, Whitefield had attacked John Tillotson and Richard Allestree's "The Whole Duty of Man". These attacks
resulted in hostile responses and reduced attendance at his London open-air preaching
In 1741, Whitefield made his first visit to Scotland at the invitation of “Ralph and Ebenezer Erskine, leaders of the breakaway Associate Presbytery. When they demanded and Whitefield refused that he preach only in their churches, they attacked him as a “ sorcerer” and a “vain-glorious, self-seeking, puffed-up creature”. In addition, Whitefield’s collecting money for his Bethesda orphanage, combined with the hysteria evoke by his open-air sermons, resulted in bitter attacks in Edinburgh and Glasgow. 
America
Whitefield’s itinerant preaching throughout the colonies was opposed by Bishop Benson who had ordained him for a settled ministry in Georgia. Whitefield replied that if bishops did not authorize his itinerant preaching, God would give him the authority.
In 1740, Jonathan Edwards invited Whitefield to preach in his church in Northampton. Edwards was “deeply disturbed by his unqualified appeals to emotion, his openly judging those he considered unconverted, and his demand for instant conversions”. Whitefield refused to discuss Edwards’ misgivings with him. Later, Edwards delivered a series of sermons containing but “thinly veiled critiques” of Whitefield’s preaching, “warning against over-dependence upon a preacher's eloquence and fervency”.
During Whitefield’s 1744-1748 visit to America, ten critical pamphlets were published, two by officials of Harvard and Yale. This criticism was in part evoked by Whitefield’s criticism of “their education and Christian commitment” in his Journal of 1741. Whitefield saw this opposition as “a conspiracy” against him.
After Whitefield preached at St. Philip's, Charleston, the Commissary, the Rev. Alexander Garden suspended him as a “vagabond clergyman.”
Whitefield versus laity.
When Whitefield preached in a dissenting church and “the congregation’s response was dismal,” he ascribed the response to “the people’s being hardened” as were “Pharaoh and the Egyptians” in the Bible.
Laity versus Whitefield.
“Brutal mobs sometimes attacked Whitefield and his followers, maiming people and stripping women naked. Whitefield received three letters with death threats, and once he was stoned until nearly dead.”
After Whitefield preached in Charles Town, a local newspaper article attacked him as “blasphemous, uncharitable, and unreasonable.”
Many New Englanders claimed that Whitefield destroyed “New England's orderly parish system, communities, and even families”. The “Declaration of the Association of the County of New Haven, 1745" stated that after Whitefield’s preaching “religion is now in a far worse state than it was”.
After Whitefield condemned Moravians and their practices, his former London printer (a Moravian), called Whitefield “a Mahomet, a Caesar, an imposter, a Don Quixote, a devil, the beast, the man of sin, the Antichrist”.
In the open air in Dublin, Ireland (1757), Whitefield attacked Roman Catholicism that incited an attack by “hundreds and hundreds of papists” who cursed and wounded him severely and smashed his portable pulpit.
On various occasions, a woman assaulted Whitefield with “scissors and a pistol, and her teeth”. “Stones and dead cats” were thrown at him. A man almost killed him with a brass-headed cane. “Another climbed a tree to urinate on him.”
In 1760, Whitefield was burlesqued by Samuel Foote in the "The Minor".
Whitefield changes.
Selina Hastings, Countess of Huntingdon made Whitefield her personal chaplain. In her chapel, it was noted that his preaching was “more Considered among persons of a Superior Rank” who attended the Countess’s services. Whitefield was humble before the Countess saying that he cried when he was “thinking of your Ladyship's condescending to patronize such a dead dog as I am”. He now said that he “highly esteemed bishops of the Church of England because of their sacred character”. He confessed that in “many things” he had “judged and acted wrong” and had “been too bitter in my zeal”. In 1763, in a defense of Methodism, Whitefield “repeated contrition for much contained in his Journals”.
Among the nobility who heard Whitefield in the Countess of Huntingdon’s home was Lady Townshend. Regarding the changes in Whitefield, someone asked Lady Townshend, “Pray, madam, is it true that Whitefield has "recanted"?” She replied, “No, sir, he has only "canted".” One meaning of “cant” is “to affect religious or pietistic phraseology, esp. as a matter of fashion or profession; to talk unreally or hypocritically with an affectation of goodness or piety.”
Religious innovation.
In the First Great Awakening, rather than listening demurely to preachers, people groaned and roared in enthusiastic emotion. Whitefield was a “passionate preacher” who often “shed tears”. Underlying this was his conviction that genuine religion “engaged the heart, not just the head”.
New divinity schools opened to challenge the hegemony of Yale and Harvard; personal experience became more important than formal education for preachers. Such concepts and habits formed a necessary foundation for the American Revolution. Whitefield’s preaching bolstered “the evolving republican ideology that sought local democratic control of civil affairs and freedom from monarchial and parliamentary intrusion.”
Advocacy of slavery.
Slavery constitutes “an important part of understanding Whitefield” Whitefield was at first conflicted about slaves. He believed that they were “human,” but he also believed that they were “subordinate Creatures”.
In 1735, slavery had been outlawed in the young Georgia colony. In 1740, during his second visit to America, Whitefield published “an open letter to the planters of South Carolina, Virginia, and Maryland” chastising them for their cruelty to their slaves, He wrote, “I think God has a Quarrel with you for your Abuse of and Cruelty to the poor Negroes.” Furthermore, Whitefield wrote: “Your dogs are caressed and fondled at your tables; but your slaves who are frequently styled dogs or beasts, have not an equal privilege.” However, Whitefield “stopped short of rendering a moral judgment on slavery itself as an institution.”
Whitefield established the Bethesda Orphanage in 1740. By 1747, both the colony and the orphanage were suffering economically. Whitefield blamed this condition on Georgia’s prohibition of slavery. He argued that “the constitution of that colony is very bad, and it is impossible for the inhabitants to subsist without the use of slaves.”
Pro-slavery
In 1748-1750, Whitefield campaigned for slavery’s legalisation. He said that the colony would not be prosperous unless farmers had slave labor. Whitefield’s wanted slavery legalized not only for the prosperity of the colony, but also for the financial viability of Bethesda. “Had Negroes been allowed”, he said, “I should now have had a sufficiency to support a great many orphans without expending above half the sum that has been laid out.” Whitefield’s push for the legalization of slavery “cannot be explained solely on the basics of economics.” It was also that “the specter of massive slave revolts pursued him.”
Slavery was legalized in 1751. Whitefield saw the “legalization of slavery as part personal victory and part divine will.”
Whitefield now argued a scriptural justification for slavery. He increased his number of slaves, using his preaching to raise money to purchase them. Whitefield became “perhaps the most energetic, and conspicuous, evangelical defender and practitioner of slavery.” By propagating such “a theological defense for slavery” Whitefield “participated in a tragic chapter of the nation’s experience.”
Treatment of slaves
Bethesda “set an example of humane treatment of slaves”. Phillis Wheatley, 1753-1784, who was a slave, wrote a poem “On the Death of the Rev. Mr. George Whitefield. 1770. The first line calls Whitefield a “happy saint”.
Whitefield left everything in Georgia to the Countess of Huntingdon. This included 4,000 acres of land and fifty slaves.
Attitude toward slavery
Whitefield's attitude towards slavery is expressed in a letter to Mr B. written from Bristol on 22 March 1751. While justifying his ownership of slaves, he distanced himself from the slave trade that brought slaves from Africa.
Works.
Whitefield's sermons were widely reputed to inspire his audience's enthusiasm. Many of them as well as his letters and journals were published during his lifetime. He was an excellent orator as well, strong in voice and adept at extemporaneity. His voice was so expressive that people are said to have wept just hearing him allude to "Mesopotamia". His journals, originally intended only for private circulation, were first published by Thomas Cooper. James Hutton then published a version with Whitefield's approval. His exuberant and "too apostolical" language were criticised; his journals were no longer published after 1741.
Whitefield prepared a new installment in 1744–45, but it was not published until 1938. Nineteenth-century biographies generally refer to his earlier work, "A Short Account of God's Dealings with the Reverend George Whitefield" (1740), which covered his life up to his ordination. In 1747, he published "A Further Account of God's Dealings with the Reverend George Whitefield", covering the period from his ordination to his first voyage to Georgia. In 1756, a vigorously edited version of his journals and autobiographical accounts was published. Whitefield was “profoundly image-conscious”. His writings were “intended to convey Whitefield and his life as a model for biblical ethics . . . , as humble and pious”.
After Whitefield's death, John Gillies, a Glasgow friend, published a memoir and six volumes of works, comprising three volumes of letters, a volume of tracts, and two volumes of sermons. Another collection of sermons was published just before he left London for the last time in 1769. These were disowned by Whitefield and Gillies, who tried to buy all copies and pulp them. They had been taken down in shorthand, but Whitefield said that they made him say nonsense on occasion. These sermons were included in a nineteenth-century volume, "Sermons on Important Subjects", along with the "approved" sermons from the "Works". An edition of the journals, in one volume, was edited by William Wale in 1905. This was reprinted with additional material in 1960 by the Banner of Truth Trust. It lacks the Bermuda journal entries found in Gillies' biography and the quotes from manuscript journals found in 19th-century biographies. A comparison of this edition with the original 18th-century publications shows numerous omissions—some minor and a few major.
Whitefield also wrote several hymns. In 1739, Charles Wesley composed a hymn, "Hark, how all the welkin rings”. In 1758, Whitefield revised the opening couplet for "Hark, the Herald Angels Sing."
Veneration and legacy.
Whitefield is honoured together with Francis Asbury with a feast day on the liturgical calendar of the Episcopal Church (USA) on 15 November.
Whitfield County, Georgia,USA is named after Whitefield. When the act by the Georgia General Assembly was written to create the county, the "e" was omitted from the spelling of the name to reflect the pronunciation of the name.
Legacy
In a 2014 book Thomas S. Kidd summarizes Whitefield’s legacy.

</doc>
<doc id="40406" url="https://en.wikipedia.org/wiki?curid=40406" title="Sweyn Forkbeard">
Sweyn Forkbeard

Sweyn Forkbeard (Old Norse: "Sveinn Tjúguskegg"; Danish: "Sven Tveskæg"; 960 – 3 February 1014) was king of Denmark, England, and parts of Norway. His name appears as Swegen in the "Anglo-Saxon Chronicle". He was the son of King Harald Bluetooth of Denmark, and the father of Cnut the Great.
In the mid-980s, Sweyn revolted against his father and seized the throne. Harald was driven into exile and died shortly afterwards in November 986 or 987. In 1000, with the allegiance of Trondejarl, Eric of Lade, Sweyn ruled most of Norway. In 1013, shortly before his death, he became the first Danish king of England after a long effort.
Biography.
Family and early life.
Many details about Sweyn's life are contested. Scholars disagree about the various, too often contradictory, accounts of his life given in sources from this era of history, such as the "Anglo-Saxon Chronicle", Adam of Bremen's "Deeds of the Bishops of Hamburg", and the "Heimskringla", a 13th-century work by Icelandic author Snorri Sturluson. Conflicting accounts of Sweyn's later life also appear in the "Encomium Emmae Reginae", an 11th-century Latin "encomium" in honour of his son king Cnut's queen Emma of Normandy, along with "Chronicon ex chronicis" by Florence of Worcester, another 11th-century author.
The "Dictionary of National Biography" states that his mother's name is unknown, but the Danish encyclopedia "Den Store Danske" identifies her as Tove from the Western Wendland. "Den Store Danske" identifies Sweyn's wife as Gunhild, widow of Erik, king of Sweden, but the "Dictionary of National Biography", while agreeing that she was Erik's widow, describes her as an unnamed sister of Boleslav, ruler of Poland.
Many negative accounts build on Adam of Bremen's writings; Adam is said to have watched Sweyn and Scandinavia in general with an "unsympathetic and intolerant eye", according to some scholars. Adam accused Forkbeard of being a rebellious pagan who persecuted Christians, betrayed his father and expelled German bishops from Scania and Zealand. According to Adam, Sweyn was sent into exile by his father's German friends and deposed in favour of king Eric the Victorious of Sweden, whom Adam wrote ruled Denmark until his death in 994 or 995.
Historians generally have found problems with Adam's claims, such as that Sweyn was driven into exile in Scotland for a period as long as fourteen years. As many scholars point out, he built churches in Denmark throughout this period, such as Lund and Roskilde, while he led Danish raids against England.
-->
Invasions of England.
The "Chronicle of John of Wallingford" (ca. 1225–1250) records Sweyn's involvement in raids against England during 1002–1005, 1006–1007, and 1009–1012 to revenge the St. Brice's Day massacre of England's Danish inhabitants in November 1002. Sweyn was believed to have had a personal interest in the atrocities, with his sister Gunhilde and her husband possibly amongst the victims.
Sweyn campaigned in Wessex and East Anglia in 1003–1004, but a famine forced him to return to Denmark in 1005. Further raids took place in 1006–1007, and in 1009–1012 Thorkell the Tall led a Viking invasion into England. Simon Keynes regards it as uncertain whether Sweyn supported these invasions, but "whatever the case, he was quick to exploit the disruption caused by the activities of Thorkell's army".
Some scholars have argued that Sweyn's participation may have been prompted by his state of impoverishment after having been forced to pay a hefty ransom. He needed revenue from the raids. He acquired massive sums of "Danegeld" through the raids. In 1013, he is reported to have personally led his forces in a full-scale invasion of England.
The contemporary "Peterborough Chronicle" (also called the "Laud Manuscript"), one of the "Anglo-Saxon Chronicles", states:
before the month of August came king Sweyn with his fleet to Sandwich. He went very quickly about East Anglia into the Humber's mouth, and so upward along the Trent till he came to Gainsborough. Earl Uchtred and all Northumbria quickly bowed to him, as did all the people of the Kingdom of Lindsey, then the people of the Five Boroughs. He was given hostages from each shire. When he understood that all the people had submitted to him, he bade that his force should be provisioned and horsed; he went south with the main part of the invasion force, while some of the invasion force, as well as the hostages, were with his son Cnut. After he came over Watling Street, they went to Oxford, and the town-dwellers soon bowed to him, and gave hostages. From there they went to Winchester, and the people did the same, then eastward to London.
But the Londoners put up a strong resistance, because King Æthelred and Thorkell the Tall, a Viking leader who had defected to Æthelred, personally held their ground against him in London itself. Sweyn then went west to Bath, where the western thanes submitted to him and gave hostages. The Londoners then followed suit, fearing Sweyn's revenge if they resisted any longer. King Æthelred sent his sons Edward and Alfred to Normandy, and himself retreated to the Isle of Wight, and then followed them into exile. On Christmas Day 1013 Sweyn was declared King of England.
Based in Gainsborough, Lincolnshire, Sweyn began to organise his vast new kingdom, but he died there on 3 February 1014, having ruled England for only five weeks. His embalmed body was returned to Denmark for burial in the church he had built himself. (Tradition locates this church in Roskilde, but it is more plausible that it was actually located in Lund in Scania (now part of Sweden).) Sweyn's elder son, Harald II, succeeded him as King of Denmark, but the Danish fleet in England proclaimed his younger son Cnut king. In England, the councillors had sent for Æthelred, who upon his return from exile in Normandy in the spring of 1014 managed to drive Cnut out of England. But Cnut returned and became King of England in 1016, eventually also ruling Denmark, Norway, parts of Sweden, Pomerania, and Schleswig.
Sweyn's son Cnut and Cnut's own sons Harold Harefoot and Harthacnut ruled England for 26 years. After Harthacnut's death, the English throne reverted to the House of Wessex in the person of King Edward the Confessor (reigned 1042–1066).
Sweyn's descendants through his daughter Estrid continue to reign in Denmark to this day. One of his descendants, Margaret of Denmark, married James III of Scotland in 1469, introducing Sweyn's bloodline into the Scottish royal house. After James VI of Scotland inherited the English throne in 1603, Sweyn's descendants became monarchs of England again.
The Church and currency.
On the northern edges of the relatively recent Holy Roman Empire, with its roots in Charlemagne's conquests about two hundred years prior to Sweyn's time, Sweyn Forkbeard had coins made with an image in his likeness. The Latin inscription on the coins read, "ZVEN REX AD DENER", which translates as "Sven, king of the Danes".
Sweyn's father, Harald Bluetooth, was the first of the Scandinavian kings to accept Christianity officially, in the early or mid-960s. According to Adam of Bremen, an 11th-century historian, Harald's son Sweyn was baptised "Otto", in tribute to the German king Otto I, who was the first Holy Roman Emperor. Forkbeard is never known to have officially made use of this Christian name.
Religion.
Adam of Bremen's writings about Sweyn and his father may have been influenced by Adam's desire to emphasise Sweyn's father Harald as a candidate for sainthood. He claimed that Sweyn, who was baptised along with his father, was a . This may have been true, as much of Scandinavia was pagan at the time, but there are no data to corroborate the assertion. German and French records support that Harald Bluetooth was baptised.
According to Adam, Sweyn was punished by God for leading the uprising which led to king Harald's death, and had to spend "fourteen years" abroad – perhaps a Biblical reference from an ecclesiastical writer, as it refers to the symbolic number seven. Adam purports that Sweyn was shunned by all those with whom he sought refuge, but was finally allowed to live for a while in Scotland. Adam's intention appeared to be to show that Sweyn belonged with heathens and was not fit to rule a Christian country. According to Adam, Sweyn only achieved success as a ruler after accepting Christianity.
Sweyn was tolerant of paganism while favouring Christianity, at least politically. By allowing English ecclesiastical influence in his kingdom, he was spurning the Hamburg-Bremen archbishop. Since German bishops were an integral part of the secular state, Sweyn's preference for the English church may have been a political move. He sought to pre-empt any threat against his independence posed by the German kings. Contrary to Adam's writings, Sweyn did not appear to have re-established paganism. There is no evidence of reversion to pagan burial practices during Sweyn's reign. Whether King Sweyn was a heathen or not, he enlisted priests and bishops from England rather than from Hamburg. This may have been another reason for Adam of Bremen's apparent hostility in his accounts. Numerous converted priests of a Danish origin from the Danelaw lived in England, while Sweyn had few connections to Germany or its priests.
Sweyn must have known that once the Archbishop of Hamburg-Bremen gained influence in Denmark, the German Emperor Otto II would not be far behind. His Slavic neighbours to the south-east had been all but annexed by Germany once Otto's father Otto I divided their lands into bishoprics and put them under the "care" of the Holy Roman Emperor. Sweyn may have envisaged the same happening to his own territory.
Issue.
Sweyn had eight children with Sigrid the Haughty and Gunhild of Wenden:

</doc>
<doc id="40407" url="https://en.wikipedia.org/wiki?curid=40407" title="Harold Furth">
Harold Furth

Harold Paul Furth (January 13, 1930, Vienna - February 21, 2002, Philadelphia) was an Austrian-American physicist.
Furth emigrated to the United States in 1941. He graduated from Harvard University with a bachelor's degree in 1951 and received his Ph.D. from Harvard in 1960. Furth worked at Lawrence Livermore National Laboratory for several years before going to Princeton Plasma Physics Laboratory (PPPL) where he would spend the rest of his career working in plasma physics and nuclear fusion. He was also a professor of astrophysics at Princeton University.
In the late 1960s Furth contributed some important theoretical work on resistive magnetohydrodynamics instabilities in a slightly resistive plasma.
In 1981 Furth became the director at PPPL and led the laboratory until 1990 during record setting magnetic fusion energy experiments on the largest tokamak in the country, the Tokamak Fusion Test Reactor (TFTR).
He was awarded the Maxwell Prize in 1983 and the Delmer S. Fahrney Medal in 1992.
Furth was a member of the National Academy of Sciences and died of a heart ailment.

</doc>
