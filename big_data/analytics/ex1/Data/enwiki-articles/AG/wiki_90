<doc id="46757" url="https://en.wikipedia.org/wiki?curid=46757" title="Black Narcissus">
Black Narcissus

Black Narcissus is a 1947 Technicolor religious Drama film by the British writer-producer-director team of Michael Powell and Emeric Pressburger, based on the 1939 novel by Rumer Godden. It is a psychological drama about the emotional tensions of jealousy and lust within a convent of nuns in an isolated valley in the Himalayas, and features in the cast Deborah Kerr, Kathleen Byron, Sabu, David Farrar, Flora Robson, Esmond Knight, and Jean Simmons.
"Black Narcissus" achieved acclaim for its pioneering technical mastery, with the cinematographer Jack Cardiff, shooting in vibrant colour, winning an Academy Award for Best Cinematography and a Golden Globe Award for Best Cinematography, and Alfred Junge winning an Academy Award for Best Art Direction.
According to film critic David Thomson ""Black Narcissus" is that rare thing, an erotic English film about the fantasies of nuns, startling whenever Kathleen Byron is involved".
Plot summary.
A group of Anglican nuns travel to a remote location in the Himalayas (the Palace of Mopu, near Darjeeling) to set up a school and hospital for the local people, only to find themselves increasingly seduced by the sensuality of their surroundings in a converted seraglio high up in the mountains, and by the local British agent Mr Dean (David Farrar). Clodagh (Deborah Kerr), the Sister Superior, is attempting to forget a failed romance at home in Ireland. Tensions mount as Dean's laid-back charm makes an impression on Clodagh, but also attracts the mentally unstable Sister Ruth (Kathleen Byron), who becomes pathologically jealous of Clodagh, resulting in a nervous breakdown and a violent climax. In a subplot, 'the Young General' (Sabu), heir to the throne of a princely Indian state who has come to the convent for his education, becomes infatuated with Kanchi, a lower caste dancing girl (Jean Simmons).
Deviations from the novel.
While much of the film's dialogue is taken verbatim from the novel, the film does not follow the novel exactly. In particular the film does not include Mr Dean's rejection of Sister Clodagh's design for the chapel, in favour of his own design of an open-sided building without door, located at the top of the ridge, above the Holy Man. Additionally, (the imminently departing) Sister Philippa is not replaced by Sister Adela, a stern nun who is horrified at the dereliction of duty by the original nuns.
Production.
Of the three principal Indian roles, only the Young General was played by an ethnic Indian; the roles of Kanchi and the Old General were performed by white actors in makeup. The role of Kanchi was a change indeed for 'the demure Miss Simmons.' Kanchi, 17, is described by Rumer Godden as "a basket of fruit, piled high and luscious and ready to eat. Though she looks shyly down, there is something steady and unabashed about her; the fruit is there to be eaten, she does not mean it to rot." On landing the part Simmons told her mother she had been given a part in which she had to have 'oomph'. The Indian extras were cast from workers at the docks in Rotherhithe.
The film was made primarily at Pinewood Studios, but some scenes were shot in Leonardslee Gardens, West Sussex, the home of an Indian army retiree which had appropriate trees and plants for the Indian setting. The film makes extensive use of matte paintings and large scale landscape paintings to suggest the mountainous environment of the Himalayas, (credited to W. Percy Day) as well as some scale models for motion shots of the convent. Powell said later, 'Our mountains were painted on glass. We decided to do the whole thing in the studio and that's the way we managed to maintain colour control to the very end. Sometimes in a film its theme or its colour are more important than the plot.'
For the costumes, Alfred Junge, the art director, had three main colour schemes. The nuns were always in the white habits that he designed from a medley of medieval types. These white robes of heavy material stressed the nuns' other-worldliness amid the exotic native surroundings. The chief native characters were robed in brilliant colours, particularly the General and his young nephew, in jewels and rich silks. Other native characters brought into the film merely as 'atmosphere' were clad in more sombre colours, with the usual native dress of the Nepalese, Bhutanese and Tibetan peoples toned down to prevent overloading the eye with brilliance.
According to Robert Horton, Powell set the climactic sequence, a murder attempt on the cliffs of the cloister, to a pre-existing musical track, staging it as though it were a piece of visual choreography. Also, on a note of personal tension that existed behind-the-scenes, was the fact that Kerr was the director's ex-lover, and Byron his current one. "It was a situation not uncommon in show business, I was told," Powell later wrote, "but it was new to me."
The version of the film originally shown in the United States had scenes depicting flashbacks of Sister Clodagh's life before becoming a nun edited out at the behest of the Catholic Legion of Decency.
Lost scene.
Originally, the film was intended to end with an additional scene in which Sister Clodagh sobs and blames herself for the convent's failure, to Mother Dorothea. Mother Dorothea touches and speaks to Sister Clodagh welcomingly as the latter's tears continue to fall. When they filmed the scene with the rainfall on the leaves in what was to have been the penultimate scene, Powell was so impressed with it that he decided to designate that the last scene and to scrap the Mother Dorothea closing scene. It was filmed but it is not known whether it was printed.
Historical context.
"Black Narcissus" was released only a few months before India achieved independence from Britain in August 1947. Film critic Dave Kehr has suggested that the final images of the film, as the nuns abandon the Himalayas and proceed down the mountain, could have been interpreted by British viewers in 1947 as 'a last farewell to their fading empire'; he suggests that for the filmmakers, it is not an image of defeat 'but of a respectful, rational retreat from something that England never owned and never understood'. The story in the film quite closely follows that of the book, which was written in 1939.
Box Office.
According to trade papers, the film was a "notable box office attraction" at British cinemas in 1947.
Critical response and influence.
"Black Narcissus" achieved acclaim for its pioneering technical mastery and shocked audiences at the time of release with its vibrant colour and the themes of the film. Audiences gasped at some of the scenes, notably the shot of the vibrant pink flowers, which shown on the big screen was a spectacle at the time. The film's clever use of lighting and techniques have had a profound impact on later film makers, notably Martin Scorsese who used the extreme close-ups of the nuns for Tom Cruise's character around the pool table in "Color of Money". Martin Scorsese has said that the film is one of the earliest erotic films, in the last quarter of the film in particular. The film was one of his favourites as a boy, and Scorsese has stated that one of the greatest experiences he has had with film is viewing "Black Narcissus" projected on a massive screen at the Director's Guild in 1983. In Michael Powell's own view this was the most erotic film he ever made. "It is all done by suggestion, but eroticism is in every frame and image from beginning to end. It is a film full of wonderful performances and passion just below the surface, which finally, at the end of the film, erupts".
In "The Great British Picture Show", the writer George Perry stated, "Archers films looked better than they were – the location photography in Technicolor by Jack Cardiff in "Black Narcissus" was a great deal better than the story and lifted the film above the threatening banality". In contrast, the critic Ian Christie wrote in the "Radio Times" in the 1980s that "unusually for a British film from the emotionally frozen forties the melodrama works so well it almost seems as if Powell and Pressburger survived the slings and barbs of contemporary criticism to find their ideal audience in the 1980s". Marina Warner, introducing the film on BBC2 (on a nun-themed film evening, with "Thérèse"), called it a masterpiece:
Home media.
A DVD was released in the UK on 26 September 2005. A restored version was released on Blu-ray in the UK on 23 June 2008 by ITV DVD. It is also available in Region 1 DVD from the Criterion Collection, who released a Blu-ray version on 20 July 2010.
A Blu-ray was released in the UK from Network Distributing on 14 July 2014 [http://networkonair.com/shop/1909-black-narcissus.html]
Awards and honours.
The filmmakers were recognised with several awards for their work on "Black Narcissus":

</doc>
<doc id="46758" url="https://en.wikipedia.org/wiki?curid=46758" title="Edward Thomas (poet)">
Edward Thomas (poet)

Philip Edward Thomas (3 March 1878 – 9 April 1917) was a British poet, essayist, and novelist. He is commonly considered a war poet, although few of his poems deal directly with his war experiences, and his career in poetry only came after he had already been a successful writer and literary critic. In 1915, he enlisted in the British Army to fight in the First World War and was killed in action during the Battle of Arras in 1917, soon after he arrived in France.
Life and career.
Early life.
Thomas was born in Lambeth, London. He was educated at Battersea Grammar School, St Paul's School in London and Lincoln College, Oxford. His family were mostly Welsh. In June 1899 he married Helen Berenice Noble (1878-1967), in Fulham, while still an undergraduate, and determined to live his life by the pen. He then worked as a book reviewer, reviewing up to 15 books every week. He was already a seasoned writer by the outbreak of war, having published widely as a literary critic and biographer as well writing on the countryside. He also wrote a novel, "The Happy-Go-Lucky Morgans" (1913), a "book of delightful disorder".
Thomas worked as literary critic for the "Daily Chronicle" in London and became a close friend of Welsh tramp poet W. H. Davies, whose career he almost single-handedly developed.
From 1905, Thomas lived with his wife Helen and their family at Elses Farm near Sevenoaks, Kent. He rented to Davies a tiny cottage nearby, and nurtured his writing as best he could. On one occasion, Thomas even had to arrange for the manufacture, by a local wheelwright, of a makeshift wooden leg for Davies.
Even though Thomas thought that poetry was the highest form of literature and regularly reviewed it, he only became a poet himself at the end of 1914 when living at Steep, East Hampshire, and initially published his poetry under the name Edward Eastaway. Frost in particular encouraged Thomas (then more famous as a critic) to write poetry, and their friendship was so close that the two planned to reside side by side in the United States.
By August 1914, the village of Dymock in Gloucestershire had become the residence of a number of literary figures, including Lascelles Abercrombie, Wilfrid Gibson and American poet Robert Frost. Edward Thomas was a visitor at this time. 
Thomas immortalised the (now-abandoned) railway station at Adlestrop in a poem of that name after his train made a stop at the Cotswolds station on 24 June 1914, shortly before the outbreak of the First World War.
War service.
Thomas enlisted in the Artists Rifles in July 1915, despite being a mature married man who could have avoided enlisting. He was unintentionally influenced in this decision by his friend Frost, who had returned to the U.S. but sent Thomas an advance copy of "The Road Not Taken". The poem was intended by Frost as a gentle mocking of indecision, particularly the indecision that Thomas had shown on their many walks together; however, most audiences took the poem more seriously than Frost intended, and Thomas similarly took it seriously and personally, and it provided the last straw in Thomas' decision to enlist.
Thomas was promoted corporal, and in November 1916 was commissioned into the Royal Garrison Artillery as a second lieutenant. He was killed in action soon after he arrived in France at Arras on Easter Monday, 9 April 1917. To spare the feelings of his widow Helen, she was told the fiction of a "bloodless death" i.e. that Thomas was killed by the concussive blast wave of one of the last shells fired as he stood to light his pipe and that there was no mark on his body. However, a letter from his commanding officer Franklin Lushington written in 1936 (and discovered many years later in an American archive) states that in reality the cause of Thomas' death was due to being "shot clean through the chest".
W. H. Davies was devastated by the death and his commemorative poem "Killed In Action (Edward Thomas)" was included in Davies's 1918 collection "Raptures".
Thomas is buried in the Commonwealth War Graves Cemetery at Agny in France (Row C, Grave 43).
Personal life.
Thomas was survived by his wife, Helen, their son Merfyn and their two daughters Bronwen and Myfanwy. After the war, Thomas's widow, Helen, wrote about her courtship and early married life with Edward in the autobiography "As it Was" (1926); later she added a second volume, "World Without End" (1931). Myfanwy later said that the books had been written by her mother as a form of therapy to help lift herself from the deep depression into which she had fallen following Thomas's death.
Helen's short memoir "My Memory of W. H. Davies" was published in 1973, after her own death. In 1988, Helen's writings were gathered into a book published under the title "Under Storm's Wing", which included "As It Was" and "World Without End" as well as a selection of other short works by Helen and her daughter Myfanwy and six letters sent by Robert Frost to her husband.
Commemorations.
Thomas is commemorated in Poets’ Corner, Westminster Abbey, London, by memorial windows in the churches at Steep and at Eastbury in Berkshire and with a blue plaque at 14 Lansdowne Gardens in Stockwell, south London, where he was born.
There is also a plaque dedicated to him at 113 Cowley Road, Oxford, where he lodged before entering Lincoln College.
East Hampshire District Council have created a "literary walk" at Shoulder of Mutton Hill in Steep dedicated to Thomas, which includes a memorial stone erected in 1935. The inscription includes the final line from one of his essays: "And I rose up and knew I was tired and I continued my journey."
As "Philip Edward Thomas poet-soldier" he is commemorated, alongside "Reginald Townsend Thomas actor-soldier died 1918", who is buried at the spot, and other family members, at the North East Surrey (Old Battersea) Cemetery.
He is the subject of the biographical play "The Dark Earth and the Light Sky" by Nick Dear, which premiered at the Almeida Theatre, London in November 2012, with Pip Carter as Thomas and Hattie Morahan as his wife Helen.
In February 2013 his poem "Words" was chosen as the poem of the week by Carol Rumens in "The Guardian"
Poetry.
Thomas's poems are noted for their attention to the English countryside and a certain colloquial style. The short poem "In Memoriam" exemplifies how his poetry blends the themes of war and the countryside.
On 11 November 1985, Thomas was among 16 Great War poets commemorated on a slate stone unveiled in Westminster Abbey's Poet's Corner. The inscription, written by fellow poet Wilfred Owen, reads: "My subject is War, and the pity of War. The Poetry is in the pity."
Thomas was described by British Poet Laureate Ted Hughes as "the father of us all."
At least nineteen of his poems were set to music by the Gloucester composer Ivor Gurney.
References to Thomas by other writers.
'Now all roads lead to France/
And heavy is the tread/
Of the living; but the dead/
Returning lightly dance:'

</doc>
<doc id="46760" url="https://en.wikipedia.org/wiki?curid=46760" title="Terra Australis">
Terra Australis

Terra Australis (Latin for "South Land") was a hypothetical continent first posited in Antiquity and which appeared on maps between the 15th and 18th centuries. Although the landmass was drawn onto maps, Terra Australis was not based on any actual surveying of such a landmass but rather based on the hypothesis that continents in the Northern Hemisphere should be balanced by land in the south. This theory of balancing land has been documented as early as the 5th century on maps by Macrobius, who uses the term Australis on his maps.
In the early 1800s, British explorer Matthew Flinders had popularized the naming of Australia after "Terra Australis", giving his rationale that there was "no probability" of finding any significant land mass anywhere more south than Australia. The continent that would come to be named Antarctica would be explored decades after Flinders' 1814 book on Australia, which he had titled "A Voyage to Terra Australis", and after his naming switch had gained popularity.
Other names.
Terra Australis was one of several names applied to the largest landmass of what is now known as the continent of Australia, after its European discovery. Other names for the hypothetical landmass have included Terra Australis Ignota, Terra Australis Incognita ("The unknown land of the South") or Terra Australis Nondum Cognita ("The Southern Land Not Yet Known"). Other names for the hypothetical continent have included Brasiliae Australis, Magallanica or Magellanica ("the land of Magellan"), La Australia del Espíritu Santo (Spanish: "the southern land of the Holy Spirit"), and La grande isle de Java (French: "the great island of Java"). Other names actually used for the continent were New Holland and Australia.
Origins of Terra Australis.
The notion of Terra Australis was introduced by Aristotle, who simply declared that "...there must be a region bearing the same relation to the southern pole as the place we live in bears to our pole...". His ideas were later expanded by Ptolemy (1st century AD), who believed that the Indian Ocean was enclosed on the south by land, and that the lands of the Northern Hemisphere should be balanced by land in the south. Marcus Tullius Cicero used the term "cingulus australis" ("southern zone") in referring to the Antipodes in "Somnium Scipionis" ("Dream of Scipio"). The land ("terra" in Latin) in this zone was the "Terra Australis".
Legends of Terra Australis Incognita—an "unknown land of the South"—date back to Roman times and before, and were commonplace in medieval geography, although not based on any documented knowledge of the continent. Ptolemy's maps, which became well known in Europe during the Renaissance, did not actually depict such a continent, but they did show an Africa which had no southern oceanic boundary (and which therefore might extend all the way to the South Pole), and also raised the possibility that the Indian Ocean was entirely enclosed by land. Christian thinkers did not discount the idea that there might be land beyond the southern seas, but the issue of whether it could be inhabited was controversial.
The first depiction of Terra Australis on a globe was probably on Johannes Schöner's lost 1523 globe on which Oronce Fine is thought to have based his 1531 double cordiform (heart-shaped) map of the world. On this landmass he wrote "recently discovered but not yet completely explored". The body of water beyond the tip of South America is called the “Mare Magellanicum,” one of the first uses of navigator Ferdinand Magellan's name in such a context.
Schöner called the continent "Brasiliae Australis" in his 1533 tract, "Opusculum geographicum". In it, he explained: Brasilia Australis is an immense region toward Antarcticum, newly discovered but not yet fully surveyed, which extends as far as Melacha and somewhat beyond. The inhabitants of this region lead good, honest lives and are not Anthropophagi like other barbarian nations; they have no letters, nor do they have kings, but they venerate their elders and offer them obedience; they give the name Thomas to their children [after St Thomas the Apostle; close to this region lies the great island of Zanzibar at 102.00 degrees and 27.30 degrees South.
Mapping the Southern Continent.
Explorers of the Age of Discovery, from the late 15th century on, proved that Africa was almost entirely surrounded by sea, and that the Indian Ocean was accessible from both west and east. These discoveries reduced the area where the continent could be found; however, many cartographers held to Aristotle's opinion. Scientists, such as Gerardus Mercator (1569) and Alexander Dalrymple as late as 1767 argued for its existence, with such arguments as that there should be a large landmass in the south as a counterweight to the known landmasses in the Northern Hemisphere. As new lands were discovered, they were often assumed to be parts of the hypothetical continent.
The German cosmographer and mathematician Johannes Schöner (1477–1547) constructed a terrestrial globe in 1515, based on the world map and globe made by Martin Waldseemüller and his colleagues at St. Dié in Lorraine in 1507. Where Schöner departs most conspicuously from Waldseemüller is in his globe's depiction of an Antarctic continent, called by him Brasilie Regio. His continent is based, however tenuously, on the report of an actual voyage: that of the Portuguese merchants Nuno Manuel and Cristóvão de Haro to the River Plate, and related in the "Newe Zeytung auss Presillg Landt" (“New Tidings from the Land of Brazil”) published in Augsburg in 1514. The "Zeytung" described the Portuguese voyagers passing through a strait between the southernmost point of America, or Brazil, and a land to the south west, referred to as "vndtere Presill" (or "Brasilia inferior").
This supposed “strait” was in fact the Rio de la Plata (or the San Matias Gulf). By “vndtere Presill”, the Zeytung meant that part of Brazil in the lower latitudes, but Schöner mistook it to mean the land on the southern side of the “strait”, in higher latitudes, and so gave to it the opposite meaning. On this slender foundation he constructed his circum-Antarctic continent to which, for reasons that he does not explain, he gave an annular, or ring shape. In an accompanying explanatory treatise, "Luculentissima quaedam terrae totius descriptio" (“A Most Lucid Description of All Lands”), he explained: “The Portuguese, thus, sailed around this region, the Brasilie Regio, and discovered the passage very similar to that of our Europe (where we reside) and situated laterally between east and west.
From one side the land on the other is visible; and the cape of this region about 60 miles away, much as if one were sailing eastward through the Straits of Gibraltar or Seville and Barbary or Morocco in Africa, as our Globe shows toward the Antarctic Pole. Further, the distance is only moderate from this Region of Brazil to Malacca, where St. Thomas was crowned with martyrdom.” .
On this scrap of information, united with the concept of the Antipodes inherited from Graeco-Roman antiquity, Schöner constructed his representation of the southern continent. His strait served as inspiration for Ferdinand Magellan's expedition to reach the Moluccas by a westward route.
He took Magellan's discovery of Tierra del Fuego in 1520 as further confirmation of its existence, and on his globes of 1523 and 1533 he described it as "TERRA AVSTRALIS RECENTER INVENTA SED NONDUM PLENE COGNITA" (“Terra Australis, recently discovered but not yet fully known”). It was taken up by his followers, the French cosmographer Oronce Fine in his world map of 1531, and the Flemish cartographers Gerardus Mercator in 1538 and Abraham Ortelius in 1570. Schöner's concepts influenced the Dieppe school of mapmakers, notably in their representation of Jave la Grande.
"Terra Australis" was depicted on the mid-16th-century Dieppe maps, where its coastline appeared just south of the islands of the East Indies; it was often elaborately charted, with a wealth of fictitious detail. There was much interest in Terra Australis among Norman and Breton merchants at that time. In 1566 and 1570, Francisque and André d'Albaigne presented Gaspard de Coligny, Admiral of France, with projects for establishing relations with the Austral lands. Although the Admiral gave favourable consideration to these initiatives, they came to nought when Coligny was killed in 1572.
Gerardus Mercator believed in the existence of a large Southern continent on the basis of cosmographic reasoning, set out in the abstract of his "Atlas or Cosmographic Studies in Five Books," as related by his biographer, Walter Ghim, who said that even though Mercator was not ignorant that the Austral continent still lay hidden and unknown, he believed it could be "demonstrated and proved by solid reasons and arguments to yield in its geometric proportions, size and weight, and importance to neither of the other two, nor possibly to be lesser or smaller, otherwise the constitution of the world could not hold together at its centre".
The Flemish geographer and cartographer, Cornelius Wytfliet, wrote concerning the "Terra Australis" in his 1597 book, "Descriptionis Ptolemaicae Augmentum,": 
The terra Australis is therefore the southernmost of all other lands, directly beneath the antarctic circle; extending beyond the tropic of Capricorn to the West, it ends almost at the equator itself, and separated by a narrow strait lies on the East opposite to New Guinea, only known so far by a few shores because after one voyage and another that route has been given up and unless sailors are forced and driven by stress of winds it is seldom visited. The terra Australis begins at two or three degrees below the equator and it is said by some to be of such magnitude that if at any time it is fully discovered they think it will be the fifth part of the world.
Adjoining Guinea on the right are the numerous and vast Solomon Islands which lately became famous by the voyage of Alvarus Mendanius.
Juan Fernandez, sailing from Chile in 1576, claimed he had discovered the Southern Continent. The "Polus Antarcticus" map of 1641 by Henricus Hondius, bears the inscription: "”Insulas esse a Nova Guinea usque ad Fretum Magellanicum affirmat Hernandus Galego, qui ad eas explorandas missus fuit a Rege Hispaniae Anno 1576" (Hernando Gallego, who in the year 1576 was sent by the King of Spain to explore them, affirms that there are islands from New Guinea up to the Strait of Magellan)”.
Luis Váez de Torres, a Galician or Portuguese navigator who commanded the "San Pedro y San Pablo", the "San Pedrico" and the tender or yacht, "Los Tres Reyes Magos" during the 1605–1606 expedition led by Pedro Fernandes de Queiros in quest of the Southern Continent, proved the existence of a passage south of New Guinea, now known as Torres Strait. Commenting on this in 1622, the Dutch cartographer and publisher of Queiros' eighth memorial, Hessel Gerritsz, noted on his "Map of the Pacific Ocean:" "Those who sailed with the yacht of Pedro Fernando de Quiros in the neighbourhood of New Guinea to 10 degrees westward through many islands and shoals and over 23 and 24 fathoms for as many as 40 days, estimated that Nova Guinea does not extend beyond 10 degrees to the south; if this be so, then the land from 9 to 14 degrees would be a separate land".
Pedro Fernandes de Queirós, another Portuguese navigator sailing for the Spanish Crown, saw a large island south of New Guinea in 1606, which he named La Austrialia del Espiritu Santo. He represented this to the King of Spain as the Terra Australis incognita. In his 10th Memorial (1610), Queirós said: "It should be noted that New Guinea is the top end of the Austral Land of which I treat, and that people, and customs, with all the rest referred to, resemble them".[http://acms.sl.nsw.gov.au/album/ItemViewer.aspx?itemid=1012670&suppress=N&imgindex=8
Dutch father and son Isaac and Jacob Le Maire established the Australische Compagnie (Australian Company) in 1615 to trade with Terra Australis, which they called "Australia".
The cartographic depictions of the southern continent in the 16th and early 17th centuries, as might be expected for a concept based on such abundant conjecture and minimal data, varied wildly from map to map; in general, the continent shrank as potential locations were reinterpreted. At its largest, the continent included Tierra del Fuego, separated from South America by a small strait; New Guinea; and what would come to be called Australia. In Ortelius's atlas "Theatrum Orbis Terrarum", published in 1570, Terra Australis extends north of the Tropic of Capricorn in the Pacific Ocean.
As long as it appeared on maps at all, the continent minimally included the unexplored lands around the South Pole, but generally much larger than the real Antarctica, spreading far north – especially in the Pacific Ocean. New Zealand, first seen by the Dutch explorer Abel Tasman in 1642, was regarded by some as a part of the continent.
Alexander Dalrymple, the Examiner of Sea Journals for the English East India Company, whilst translating some Spanish documents captured in the Philippines in 1752, found de Torres's testimony. This discovery led Dalrymple to publish the "Historical Collection of the Several Voyages and Discoveries in the South Pacific Ocean" in 1770–1771. Dalrymple presented a beguiling tableau of the Terra Australis, or Southern Continent:
The number of inhabitants in the Southern Continent is probably more than 50 millions, considering the extent, from the eastern part discovered by Juan Fernandez, to the western coast seen by Tasman, is about 100 deg. of longitude, which in the latitude of 40 deg. amounts to 4596 geographic, or 5323 stature miles. This is a greater extent than the whole civilized part of Asia, from Turkey to the eastern extremity of China. There is at present no trade from Europe thither, though the scraps from this table would be sufficient to maintain the power, dominion, and sovereignty of Britain, by employing all its manufacturers and ships. Whoever considers the Peruvian empire, where arts and industry flourished under one of the wisest systems of government, which was founded by a stranger, must have very sanguine expectations of the southern continent, from whence it is more than probable Mango Capac, the first Inca, was derived, and must be convinced that the country, from whence Mango Capac introduced the comforts of civilized life, cannot fail of amply rewarding the fortunate people who shall bestow letters instead of quippos (quipus), and iron in place of more awkward substitutes.
Dalrymple's claim of the existence of an unknown continent aroused widespread interest and prompted the British government in 1769 to order James Cook in HM Bark "Endeavour" to seek out the Southern Continent to the South and West of Tahiti, discovered in June 1767 by Samuel Wallis in "HMS Dolphin" and named by him King George Island. The London press reported in June 1768 that two ships would be sent to the newly discovered island and from there to "attempt the Discovery of the Southern Continent". A subsequent press report stated: "We are informed, that the Island which Captain Wallis has discovered in the South-Sea, and named George's Land, is about fifteen hundred Leagues to the Westward and to Leeward of the Coast of Peru, and about five-and-thirty Leagues in circumference; that its principal and almost sole national Advantage is, its Situation for exploring the Terra Incognita of the Southern Hemisphere. The Endeavour, a North-Country Cat, is purchased by the Government, and commanded by a Lieutenant of the Navy; she is fitting out at Deptford for the South-Sea, thought to be intended for the newly-discovered Island". The aims of the expedition were revealed in days following: "To-morrow morning Mr. Banks, Dr. Solano with Mr. Green, the Astronomer, will set out for Deal, to embark on board the Endeavour, Capt. Cook, for the South Seas, under the direction of the Royal Society, to observe the Transit of Venus next summer, and to make discoveries to the South and West of Cape Horn". The London "Gazetteer" was more explicit when it reported on 18 August 1768: “The gentlemen, who are to sail in a few days for George's Land, the new discovered island in the Pacific ocean, with an intention to observe the Transit of Venus, are likewise, we are credibly informed, to attempt some new discoveries in that vast unknown tract, above the latitude 40”. The results of this first voyage of James Cook in respect of the quest for the Southern Continent were summed up by Cook himself. He wrote in his Journal on 31 March 1770 that the "Endeavour's" voyage "must be allowed to have set aside the most, if not all, the Arguments and proofs that have been advanced by different Authors to prove that there must be a Southern Continent; I mean to the Northward of 40 degrees South, for what may lie to the Southward of that Latitude I know not".
The second voyage of James Cook aboard explored the South Pacific for the landmass between 1772 and 1775 whilst also testing the Larcum Kendall's K1 chronometer as a method for measuring longitude.
Decline of the idea.
Over the centuries the idea of Terra Australis gradually lost its hold. In 1615, Jacob le Maire and Willem Schouten's rounding of Cape Horn proved that Tierra del Fuego was a relatively small island, while in 1642 Abel Tasman's first pacific voyage proved that Australia was not part of the mythical southern continent. Much later, James Cook sailed around most of New Zealand in 1770, showing that even it could not be part of a large continent. On his second voyage he circumnavigated the globe at a very high southern latitude, at some places even crossing the south polar circle, showing that any possible southern continent must lie well within the cold polar areas. There could be no extension into regions with a temperate climate, as had been thought before. In 1814, Matthew Flinders published the book "A Voyage to Terra Australis." Flinders had concluded that the Terra Australis as hypothesized by Aristotle and Ptolemy did not exist, so he wanted the name applied to what he saw as the next best thing: "Australia". He wrote:
There is no probability, that any other detached body of land, of nearly equal extent, will ever be found in a more southern latitude; the name Terra Australis will, therefore, remain descriptive of the geographical importance of this country, and of its situation on the globe: it has antiquity to recommend it; and, having no reference to either of the two claiming nations, appears to be less objectionable than any other which could have been selected.
...with the accompanying note at the bottom of the page:
Had I permitted myself any innovation upon the original term, it would have been to convert it into AUSTRALIA; as being more agreeable to the ear, and an assimilation to the names of the other great portions of the earth.
His conclusion would soon be revealed as a mistake, but by that time the name had stuck.
Kingdom of Beach.
"Beach" appeared on maps of the 16th century, notably that of Abraham Ortelius of 1570 and that of Jan Huygen van Linschoten of 1596, as the northernmost part of the southern continent, the "Terra Australis", along with "Locach". According to Marco Polo, "Locach" was a kingdom where gold was “so plentiful that no one who did not see it could believe it”. "Beach" was in fact a mistranscription of "Locach". Locach was Marco Polo's name for the southern Thai kingdom of Lavo, or Lop Buri, the “city of Lavo”, (ลพบร, after Lavo, the son of Rama in Hindu mythology). In Chinese (Cantonese), Lavo was pronounced “Lo-huk” (羅斛), from which Marco Polo took his rendition of the name. In the German cursive script, “Locach” and “Boeach” look similar, and in the 1532 edition of Marco Polo's "Travels" his Locach was changed to "Boëach", later shortened to "Beach".
They seem to have drawn on the map of the world published in Florence in 1489 by Henricus Martellus, in which "provincia boëach" appears as the southern neighbour of "provincia ciamba". Book III of Marco Polo's "Il Milione" described his journey by sea from China to India by way of Champa (= Southern Vietnam), Java (which he called "Java Major"), Locach and Sumatra (called "Java Minor"). After a chapter describing the kingdom of Champa there follows a chapter describing Java (which he did not visit himself). The narrative then resumes, describing the route southward from Champa toward Sumatra, but by a slip of the pen the name “Java” was substituted for “Champa” as the point of departure, locating Sumatra 1,300 miles to the south of Java instead of Champa. Locach, located between Champa and Sumatra, was likewise misplaced far to the south of Java, by some geographers on or near an extension of the "Terra Australis".
As explained by Sir Henry Yule, the editor of an English edition of Marco Polo's "Travels": “Some geographers of the 16th century, following the old editions which carried the travellers south-east of Java to the land of “Boeach” (or Locac), introduced in their maps a continent in that situation”. Gerard Mercator did just that on his 1541 globe, placing "Beach provincia aurifera" (“Beach the gold-bearing province”) in the northernmost part of the "Terra Australis" in accordance with the faulty text of Marco Polo's "Travels".
It remained in this location on his world map of 1569, with the amplified description, quoting Marco Polo, "Beach provincia aurifera quam pauci ex alienis regionibus adeunt propter gentis inhumanitatem" (“Beach the gold-bearing province, wither few go from other countries because of the inhumanity of its people”) with "Lucach regnum" shown somewhat to its south west. Following Mercator, Abraham Ortelius also showed "BEACH" and "LVCACH" in these locations on his world map of 1571. Likewise, Linschoten's very popular 1596 map of the East Indies showed "BEACH" projecting from the map's southern edge, leading (or misleading) Visscher and Tasman in their voyage of 1642 to seek Beach with its plentiful gold in a location to the south of the Solomon Islands somewhere between Staten Land near Cape Horn and the Cape of Good Hope.
Confirmation that land existed where the maps showed "Beach" to be had come from Dirk Hartog's landing in October 1616 on its west coast, which he called Eendrachtsland after the name of his ship. In August 1642, the Council of the Dutch East India Company despatched Abel Tasman and Franchoijs Visscher on a voyage of which one of the objects was to obtain knowledge of "all the totally unknown provinces of Beach".
Antarctica.
Antarctica was finally sighted in the hypothetical area of Terra Australis in 1820. The extent of Terra Australis was finally determined, also proving the Southern Hemisphere has much less land than the Northern. Terra Australis proved to consist of only two small continents: Antarctica and Australia.
In fiction.
The unexplored southern continent was a frequent subject of fantastic fiction in the 17th and 18th centuries in the Imaginary voyages genre. Among the works which dealt with imaginary visits to the continent (which at the time was still believed to be real) were:

</doc>
<doc id="46761" url="https://en.wikipedia.org/wiki?curid=46761" title="County Antrim">
County Antrim

County Antrim (named after the town of Antrim) is one of six counties that form Northern Ireland, situated in the north-east of the island of Ireland. Adjoined to the north-east shore of Lough Neagh, the county covers an area of and has a population of about 618,000. It is one of six traditional counties of Northern Ireland and is within the historic province of Ulster. County Antrim has a population density of 203 people per square kilometer / 526 people per square mile.
The Glens of Antrim offer isolated rugged landscapes, the Giant's Causeway is a unique landscape and a UNESCO World Heritage Site, Bushmills produces whiskey, and Portrush is a popular seaside resort and night-life area. The majority of Belfast, the capital city of Northern Ireland, is in County Antrim, with the remainder being in County Down.
Geography.
A large portion of Antrim is hilly, especially in the east, where the highest elevations are attained. The range runs north and south, and, following this direction, the highest points are Knocklayd , Slieveanorra , Trostan , Slemish , Agnew's Hill and Divis . The inland slope is gradual, but on the northern shore the range terminates in abrupt and almost perpendicular declivities, and here, consequently, some of the finest coast scenery in the world is found, widely differing, with its unbroken lines of cliffs, from the indented coast-line of the west. The most remarkable cliffs are those formed of perpendicular basaltic columns, extending for many miles, and most strikingly displayed in Fair Head and the celebrated Giant's Causeway. From the eastern coast the hills rise instantly but less abruptly, and the indentations are wider and deeper. On both coasts there are several resort towns, including Portrush (with well-known golf links), Portballintrae and Ballycastle; on the east Cushendun, Cushendall and Waterfoot on Red Bay, Carnlough and Glenarm, Larne on the Sea of Moyle, and Whitehead on Belfast Lough. All are somewhat exposed to the easterly winds prevalent in spring. The only island of size is the L-shaped Rathlin Island, off Ballycastle, in total length by maximum breadth, from the coast, and of similar basaltic and limestone formation to that of the mainland. It is partially arable, and supports a small population. Islandmagee is a peninsula separating Larne Lough from the North Channel.
The valleys of the Bann and Lagan, with the intervening shores of Lough Neagh, form the fertile lowlands. These two rivers, both rising in County Down, are the only ones of importance. The latter flows to Belfast Lough, the former drains Lough Neagh, which is fed by a number of smaller streams. The fisheries of the Bann and of Lough Neagh (especially for salmon and eels) are of value both commercially and to sportsmen, the small town of Toome, at the outflow of the river, being the centre. Immediately below this point lies Lough Beg, the "Small Lake", about lower than Lough Neagh.
Transport.
County Antrim has a number of air, rail and sea links.
Air.
Northern Ireland's main airport, Belfast International Airport, at Aldergrove is in County Antrim. Belfast International shares its runways with the Royal Air Force base RAF Aldergrove, which otherwise has its own facilities. It is the fifth-largest regional air cargo centre in the UK. There are regular services to Great Britain, Europe and North America.
The region is also served by George Best Belfast City Airport, a mile east of Belfast city centre on the County Down side of the city, which was renamed in 2006 in honour of footballer George Best.
Rail.
The main Translink Northern Ireland Railways routes are the major line between Belfast, Antrim, Ballymena, Coleraine and Londonderry, Belfast to Carrickfergus and Larne, the port for Stranraer in Scotland and Coleraine to Portrush.
Sea.
Two of Northern Ireland's main ports are in County Antrim, Larne and Belfast.
Ferries sail from Larne Harbour to destinations including Cairnryan and Troon in Scotland, and Fleetwood in England.
The Port of Belfast is Northern Ireland's principal maritime gateway, serving the Northern Ireland economy and increasingly that of the Republic of Ireland. It is a major centre of industry and commerce and has become established as the focus of logistics activity for Northern Ireland. Around two-thirds of Northern Ireland's seaborne trade, and a quarter of that for Ireland as a whole, is handled at the port, which receives over 6,000 vessels each year.
Population.
The population of County Antrim was 615,384 according to recent census information, making it the most populous county in Northern Ireland.
Irish language.
Statistics for 2009–2010 show 1,832 students attending the 12 Gaelscoileanna (Irish language primary schools) and 1 Gaelcholáiste (Irish language secondary school).
Religion.
The Presbyterian Church in Ireland is the largest religious denomination, followed by the Catholic Church and the Anglican Church of Ireland. County Antrim is one of two counties in Ireland in which the majority of people are Protestant, according to the 2001 census, the other being Down. The strong Presbyterian presence in the county is due largely to the county's historical links with lowland Scotland, which supplied many immigrants to Ireland.
Administration.
The traditional county town is Antrim. More recently, Ballymena was the seat of county government. The counties of Northern Ireland ceased to be administrative entities in 1973, with the reorganization of local government.
In Northern Ireland the county structure is no longer used in local government. Northern Ireland is split into districts. The majority of County Antrim residents are administered by the following nine councils:
Small portions of the county are administered by councils that are based in neighbouring counties, notably the village of Aghagallon in the Craigavon Borough and the town of Portrush in the Coleraine Borough.
The county contains within it the whole of five parliamentary constituencies:
Parts of the following constituencies are also in County Antrim:
Subdivisions.
Baronies
Parishes
Townlands
History.
At what date the county of Antrim was formed is not known, but it appears that a certain district bore this name before the reign of Edward II (early 14th century), and when the shiring of Ulster was undertaken by Sir John Perrot in the 16th century, Antrim and Down were already recognised divisions, in contradistinction to the remainder of the province. The earliest known inhabitants were Mesolithic hunter-gatherers of pre-Celtic origin, but the names of the townlands or subdivisions, supposed to have been made in the 13th century, are all of Gaelic derivation.
In ancient times, Antrim was inhabited by a Celtic people called the Darini. In the early Middle Ages, southern County Antrim was part of the Kingdom of Ulidia, ruled by the Dál Fiatach clans Keenan and MacDonlevy/McDunlavey; the north was part of Dál Riada, which stretched into what is now western Scotland over the Irish Sea. Dál Riada was ruled by the O'Lynch clan, who were vassals of the Ulidians. Besides the Ulidians and Dál Riada, there were the Dál nAraide of lower County Antrim, and the Cruthin, who were pre-Gaelic Celts and probably related to the Picts of Britain. Between the 8th and 11th centuries Antrim was exposed to the inroads of the Vikings.
In the late 12th century Antrim became part of the Earldom of Ulster, conquered by Anglo-Norman invaders. A revival of Gaelic power followed the campaign of Edward Bruce in 1315, leaving Carrickfergus as the only significant English stronghold. In the late Middle Ages, Antrim was divided into three parts: northern Clandeboye, the Glynnes and the Route. The Cambro-Norman MacQuillans were powerful in the Route. A branch of the O'Neills of Tyrone migrated to Clandeboye in the 14th century, and ruled it for a time. Their family was called O'Neill Clannaboy. A Gallowglass sept, the MacDonnells, became the most powerful in the Glynnes in the 15th century.
During the Tudor era (16th century) numerous adventurers from Britain attempted to colonise the region; many Scots settled in Antrim around this time. In 1588 the Antrim coast was the scene of one of the 24 wrecks of the Spanish Armada in Ireland. The Spanish vessel "La Girona" was wrecked off Lacana Point, Giant's Causeway in 1588 with the loss of nearly 1,300 lives.
Antrim is divided into sixteen baronies. Lower Antrim, part of Lower Clandeboye, was settled by the sept O'Flynn/O'Lynn. Upper Antrim, part of Lower Clandeboye, was the home of the O'Keevans. Belfast was part of Lower Clandeboye and was held by the O'Neill-Clannaboys. Lower Belfast, Upper Belfast, and Carrickfergus were also part of Lower Clandeboye. Cary was part of the Glynnes; ruled originally by the O'Quinn sept, the MacDonnell galloglasses from Scotland took power here in the late Middle Ages and some of the O'Haras also migrated from Connaught. Upper and Lower Dunluce were part of the Route, and were ruled by the MacQuillans. Upper and Lower Glenarm was ruled by the O'Flynn/O'Lynn sept, considered part of the Glynns. In addition to that sept and that of O'Quinn, both of which were native, the Scottish Gallowglass septs of MacKeown, MacAlister, and MacGee, are found there. Kilconway was originally O'Flynn/O'Lynn territory, but was held by the MacQuillans as part of the Route, and later by the gallowglass sept of MacNeill. Lower Massereene was part of Lower Clandeboye and was ruled by the O'Flynns and the O'Heircs. Upper Massereene was part of Lower Clandeboye, ruled by the O'Heircs. Upper and Lower Toome, part of the Route, were O'Flynn/O'Lynn territory. Misc was first ruled by the MacQuillans. Later, the Scottish Gallowglass MacDonnells and MacAlisters invaded. The MacDonnells were a branch of the Scottish Clan MacDonald; the MacAlisters traced their origin back to the Irish Colla Uais, eldest of the Three Collas.
Islandmagee had, besides antiquarian remains, a notoriety as a home of witchcraft, and during the Irish Rebellion of 1641 was the scene of an act of reprisal (for the massacre of Protestants) against the Catholic population by the Scottish Covenanter soldiery of Carrickfergus.
In 1689 during the Williamite War in Ireland, County Antrim was a centre of Protestant resistance against the rule of the Catholic James II. During the developing crisis James' garrison at Carrickfergus successfully repulsed an attempt by local Protestants to storm it. After the advance of the Irish Army under Richard Hamilton, all of County Antrim was brought under Jacobite control. Later in the year a major expedition from England under Marshal Schomberg landed in Belfast Lough and successfully laid siege to Carrickfergus. Having captured most of the largest towns of the area, they then marched southwards towards Dundalk.
Historic monuments.
The antiquities of the county consist of cairns, mounts or forts, remains of ecclesiastical and military structures, and round towers.
There are three round towers: one at Antrim, one at Armoy, and one on Ram's Island in Lough Neagh, only that at Antrim being perfect. There are some remains of the ecclesiastic establishments at Bonamargy, where the earls of Antrim are buried, Kells, Glenarm, Glynn, Muckamore and Whiteabbey.
The castle at Carrickfergus, dating from the Norman invasion of Ireland, is one of the best preserved medieval structures in Ireland. There are, however, remains of other ancient castles, as Olderfleet, Cam's, Shane's, Glenarm, Garron Tower, Red Bay, and Dunluce Castle, notable for its dramatic location on a rocky outcrop.
The principal cairns are: one on Colin mountain, near Lisburn; one on Slieve True, near Carrickfergus; and two on Colinward. The cromlechs most worthy of notice are: one near Cairngrainey, to the north-east of the old road from Belfast to Templepatrick; the large cromlech at Mount Druid, near Ballintoy; and one at the northern extremity of Islandmagee. The mounts, forts and entrenchments are very numerous.
The natural rock formations of Giant's Causeway on the Antrim coast are now designated a UNESCO World Heritage Site.
Saint Patrick.
Slemish, about eight miles (13 km) east of Ballymena, is notable as being the scene of St Patrick's early life. According to tradition Saint Patrick was a slave for seven years, near the hill of Slemish, until he escaped back to Great Britain.
Linen.
Linen manufacturing was previously an important industry in the County. At the time Ireland produced a large amount of flax. Cotton-spinning by jennies was first introduced to Belfast by industrialists Robert Joy and Thomas M'Cabe in 1777; and twenty-three years later it was estimated that more than 27,000 people were employed in the industry within ten miles (16 km) of Belfast. Women were employed in the working of patterns on muslin.
Flora and fauna.
Records of the seaweeds of County Antrim were brought together and published in 1907 by J. Adams who notes that the list contains 211 species. Batter's list, of 1902, contained 747 species in his catalogue of British marine algae.
Of the freshwater algae there are 10 taxa in the Charophyta (Charales) recorded from Co. Antrim: "Chara aspera" Deth. ex Willd. var. "aspera"; "Chara globularis" Thuill. var. "globularis"; "Chara globularis" var. "virgata" (Kütz.) R.D.;"Chara vulgaris" L. var. "vulgaris"; "Chara vulgaris" var. "contraria" (A. Braun ex Kütz.) J.A.Moore; "Chara vulgaris" var. "longibracteata" (Kütz.) J.Groves & Bullock-Webster; "Chara vulgaris" var. "papillata" Wallr. ex A. Braun; "Nitella flexilis" (L.) Ag. var. "flexilis"; "Nitella translucens" (Pers.) C.A. Ag. and "Tolypella nidifica" (O.Mull.) Leonh. var. "glomerata" (Desv.) R.D. Wood.
Surnames.
Most common surnames in County Antrim at the time of the United Kingdom Census of 1901, by order of incidence:

</doc>
<doc id="46762" url="https://en.wikipedia.org/wiki?curid=46762" title="Alfred Marshall">
Alfred Marshall

Alfred Marshall (26 July 1842 – 13 July 1924) was one of the most influential economists of his time. His book, "Principles of Economics" (1890), was the dominant economic textbook in England for many years. It brings the ideas of supply and demand, marginal utility, and costs of production into a coherent whole. He is known as one of the founders of neoclassical economics.
Life and career.
Marshall was born in Clapham, England, 26 July 1842. His father was a bank cashier and a devout Evangelical. Marshall grew up in the London suburb of Clapham and was educated at the Merchant Taylors' School and St John's College, Cambridge, where he demonstrated an aptitude in mathematics, achieving the rank of Second Wrangler in the 1865 Cambridge Mathematical Tripos. Marshall experienced a mental crisis that led him to abandon physics and switch to philosophy. He began with metaphysics, specifically "the philosophical foundation of knowledge, especially in relation to theology.". Metaphysics led Marshall to ethics, specifically a Sidgwickian version of utilitarianism; ethics, in turn, led him to economics, because economics played an essential role in providing the preconditions for the improvement of the working class. 
He saw that the duty of economics was to improve material conditions, but such improvement would occur, Marshall believed, only in connection with social and political forces. His interest in liberalism, socialism, trade unions, women's education, poverty and progress reflect the influence of his early social philosophy on his later activities and writings.
Marshall was elected in 1865 to a fellowship at St John's College at Cambridge, and became lecturer in the moral sciences in 1868. In 1885 he became professor of political economy at Cambridge, where he remained until his retirement in 1908. Over the years he interacted with many British thinkers including Henry Sidgwick, W.K. Clifford, Benjamin Jowett, William Stanley Jevons, Francis Ysidro Edgeworth, John Neville Keynes and John Maynard Keynes. Marshall founded the "Cambridge School" which paid special attention to increasing returns, the theory of the firm, and welfare economics; after his retirement leadership passed to Arthur Cecil Pigou and John Maynard Keynes.
Contributions to economics.
Marshall desired to improve the mathematical rigour of economics and transform it into a more scientific profession. In the 1870s he wrote a small number of tracts on international trade and the problems of protectionism. In 1879, many of these works were compiled into a work entitled "The Theory of Foreign Trade: The Pure Theory of Domestic Values". In the same year (1879) he published "The Economics of Industry" with his wife Mary Paley.
Although Marshall took economics to a more mathematically rigorous level, he did not want mathematics to overshadow economics and thus make economics irrelevant to the layman. Accordingly, Marshall tailored the text of his books to laymen and put the mathematical content in the footnotes and appendices for the professionals. In a letter to A. L. Bowley, he laid out the following system: 
Marshall had been Mary Paley's professor of political economy at Cambridge and the two were married in 1877, forcing Marshall to leave his position as a Fellow of St John's College, Cambridge to comply with celibacy rules at the university. He became the first principal at University College, Bristol, which was the institution that later became the University of Bristol, again lecturing on political economy and economics. He perfected his "Economics of Industry" while at Bristol, and published it more widely in England as an economic curriculum; its simple form stood upon sophisticated theoretical foundations. Marshall achieved a measure of fame from this work, and upon the death of William Jevons in 1882, Marshall became the leading British economist of the scientific school of his time.
Marshall returned to Cambridge, via a brief period at Balliol College, Oxford during 1883–4, to take the seat as Professor of Political Economy in 1884 on the death of Henry Fawcett. At Cambridge he endeavoured to create a new tripos for economics, a goal which he would only achieve in 1903. Until that time, economics was taught under the Historical and Moral Sciences Triposes which failed to provide Marshall the kind of energetic and specialised students he desired.
"Principles of Economics" (1890).
Marshall began his economic work, the "Principles of Economics", in 1881, and spent much of the next decade at work on the treatise. His plan for the work gradually extended to a two-volume compilation on the whole of economic thought. The first volume was published in 1890 to worldwide acclaim that established him as one of the leading economists of his time. The second volume, which was to address foreign trade, money, trade fluctuations, taxation, and collectivism, was never published.
"Principles of Economics" established his worldwide reputation. It appeared in 8 editions, starting at 750 pages and growing to 870 pages. It decisively shaped the teaching of economics in English-speaking countries. Its main technical contribution was a masterful analysis of the issues of elasticity, consumer surplus, increasing and diminishing returns, short and long terms, and marginal utility; many of the ideas were original with Marshall, others were improved version of ideas by W. S. Jevons and others.
In a broader sense Marshall hoped to reconcile the classical and modern theories of value. John Stuart Mill had examined the relationship between the value of commodities and their production costs, on the theory that value depends on effort expended in manufacture. Jevons and the Marginal Utility theorists had elaborated a theory of value based on the idea of maximising utility, holding that value depends on demand. Marshall's work used both these approaches, but he focused more on costs. He noted that, in the short run, supply cannot be changed and market value depends mainly on demand. In an intermediate time period, production can be expanded by existing facilities, such as buildings and machinery, but, since these do not require renewal within this intermediate period, their costs (called fixed, overhead, or supplementary costs) have little influence on the sale price of the product. Marshall pointed out that it is the prime or variable costs, which constantly recur, that influence the sale price most in this period. In a still longer period, machines and buildings wear out and have to be replaced, so that the sale price of the product must be high enough to cover such replacement costs. This classification of costs into fixed and variable and the emphasis given to the element of time probably represent one of Marshall's chief contributions to economic theory. He was committed to partial equilibrium models over general equilibrium on the grounds that the inherently dynamical nature of economics made the former more practically useful.
Much of the success of Marshall's teaching and "Principles" book derived from his effective use of diagrams, which were soon emulated by other teachers worldwide.
Alfred Marshall was the first to develop the standard supply and demand graph demonstrating a number of fundamentals regarding supply and demand including the supply and demand curves, market equilibrium, the relationship between quantity and price in regards to supply and demand, the law of marginal utility, the law of diminishing returns, and the ideas of consumer and producer surpluses. This model is now used by economists in various forms using different variables to demonstrate several other economic principles. Marshall's model allowed a visual representation of complex economic fundamentals where before all the ideas and theories were only capable of being explained through words. These models are now critical throughout the study of economics because they allow a clear and concise representation of the fundamentals or theories being explained.
Theoretical contributions.
Marshall is considered to be one of the most influential economists of his time, largely shaping mainstream economic thought for the next fifty years, and being one of the founders of the school of neoclassical economics. Although his economics was advertised as extensions and refinements of the work of Adam Smith, David Ricardo, Thomas Robert Malthus and John Stuart Mill, he extended economics away from its classical focus on the market economy and instead popularised it as a study of human behaviour. He downplayed the contributions of certain other economists to his work, such as Léon Walras, Vilfredo Pareto and Jules Dupuit, and only grudgingly acknowledged the influence of Stanley Jevons himself.
Marshall was one of those who used utility analysis, but not as a theory of value. He used it as a part of the theory to explain demand curves and the principle of substitution. Marshall's scissors analysis – which combined demand and supply, that is utility and cost of production, as if two blades of a pair of scissors – effectively removed the theory of value from the center of analysis and replaced it with the theory of price. While the term "value" continued to be used, for most people it was a synonym for "price". Prices no longer were thought to gravitate toward some ultimate and absolute basis of price; prices were existential, between the relationship of demand and supply.
Marshall's influence on codifying economic thought is difficult to deny. He popularised the use of supply and demand functions as tools of price determination (previously discovered independently by Cournot); modern economists owe the linkage between price shifts and curve shifts to Marshall. Marshall was an important part of the "marginalist revolution;" the idea that consumers attempt to adjust consumption until marginal utility equals the price was another of his contributions. The price elasticity of demand was presented by Marshall as an extension of these ideas. Economic welfare, divided into producer surplus and consumer surplus, was contributed by Marshall, and indeed, the two are sometimes described eponymously as 'Marshallian surplus.' He used this idea of surplus to rigorously analyse the effect of taxes and price shifts on market welfare. Marshall also identified quasi-rents.
Marshall's brief references to the social and cultural relations in the "industrial districts" of England were used as a starting point for late twentieth-century work in economic geography and institutional economics on clustering and learning organisations.
Gary Becker (1930-2014), the 1992 Nobel prize winner in economics, has mentioned that Milton Friedman and Alfred Marshall were the two greatest influences on his work.
Another contribution that Marshall made was differentiating concepts of internal and external economies of scale. That is that when costs of input factors of production go down, it is a positive externality for all the firms in the market place, outside the control of any of the firms.
The Marshallian industrial district.
A concept based on a pattern of organisation that was common in late nineteenth century Britain in which firms concentrating on the manufacture of certain products were geographically clustered. Comments made by Marshall in Book 4, Chapter 10 of "Principles of Economics" have been used by economists and economic geographers to discuss this phenomenon.
The two dominant characteristics of a Marshallian industrial district are high degrees of vertical and horizontal specialisation and a very heavy reliance on market mechanism for exchange. Firms tend to be small and to focus on a single function in the production chain. Firms located in industrial districts are highly competitive in the neoclassical sense, and in many cases there is little product differentiation. The major advantages of Marshallian industrial districts arise from simple propinquity of firms, which allows easier recruitment of skilled labour and rapid exchanges of commercial and technical information through informal channels. They illustrate competitive capitalism at its most efficient, with transaction costs reduced to a practical minimum, but they are feasible only when economies of scale are limited.
Later career.
Marshall served as President of the first day of the 1889 Co-operative Congress.
Over the next two decades he worked to complete the second volume of his "Principles," but his unyielding attention to detail and ambition for completeness prevented him from mastering the work's breadth. The work was never finished and many other, lesser works he had begun work on – a memorandum on trade policy for the Chancellor of the Exchequer in the 1890s, for instance – were left incomplete for the same reasons.
His health problems had gradually grown worse since the 1880s, and in 1908 he retired from the university. He hoped to continue work on his "Principles" but his health continued to deteriorate and the project had continued to grow with each further investigation. The outbreak of the First World War in 1914 prompted him to revise his examinations of the international economy and in 1919 he published "Industry and Trade" at the age of 77. This work was a more empirical treatise than the largely theoretical "Principles", and for that reason it failed to attract as much acclaim from theoretical economists. In 1923, he published "Money, Credit, and Commerce," a broad amalgam of previous economic ideas, published and unpublished, stretching back a half-century.
Final years, death and legacy.
From 1890 to 1924 he was the respected father of the economic profession and to most economists for the half-century after his death, the venerable grandfather. He had shied away from controversy during his life in a way that previous leaders of the profession had not, although his even-handedness drew great respect and even reverence from fellow economists, and his home at Balliol Croft in Cambridge had no shortage of distinguished guests. His students at Cambridge became leading figures in economics, including John Maynard Keynes and Arthur Cecil Pigou. His most important legacy was creating a respected, academic, scientifically founded profession for economists in the future that set the tone of the field for the remainder of the 20th century.
Having died aged 81 at his home in Cambridge, Marshall is buried in the Ascension Parish Burial Ground. The library of the Department of Economics at Cambridge University (The Marshall Library of Economics), the Economics society at Cambridge (The Marshall Society) as well as the University of Bristol Economics department are named for him. His archive is available for consultation by appointment at the Marshall Library of Economics.
His home, Balliol Croft, was renamed Marshall House in 1991 in his honour when it was bought by Lucy Cavendish College, Cambridge.
Alfred Marshall's wife was Mary Paley, co-founder Newnham College; she continued to live in Balliol Croft until her death in 1944; when her ashes were scattered in the garden.

</doc>
<doc id="46763" url="https://en.wikipedia.org/wiki?curid=46763" title="Crimean War">
Crimean War

The Crimean War was a military conflict fought between October 1853 – March 1856 in which Russia lost to an alliance of France, the United Kingdom, the Ottoman Empire, and Sardinia. The immediate cause involved the rights of Christian minorities in the Holy Land, which was controlled by the Ottoman Empire. The French promoted the rights of Catholics, while Russia promoted those of the Eastern Orthodox Christians. The longer-term causes involved the decline of the Ottoman Empire and the unwillingness of the United Kingdom and France to allow Russia to gain territory and power at Ottoman expense. It has widely been noted that the causes, in one case involving an argument over a key, have never revealed a "greater confusion of purpose", yet led to a war noted for its "notoriously incompetent international butchery."
While the churches eventually worked out their differences and came to an initial agreement, both Nicholas I of Russia and Napoleon III refused to back down. Nicholas issued an ultimatum that the Orthodox subjects of the Empire be placed under his protection. Britain attempted to mediate, and arranged a compromise that Nicholas agreed to. When the Ottomans demanded changes, Nicholas refused and prepared for war. Having obtained promises of support from France and Britain, the Ottomans officially declared war on Russia in October 1853.
The war opened in the Balkans when Russian troops occupied provinces in modern Romania and began to cross the Danube. Led by Omar Pasha, the Ottomans fought a strong defensive battle and stopped the advance at Silistra. A separate action on the fort town of Kars in eastern Turkey led to a siege, and a Turkish attempt to reinforce the garrison was destroyed by a Russian fleet at Sinop. Fearing an Ottoman collapse, France and the UK rushed forces to Gallipoli. They then moved north to Varna in June, arriving just in time for the Russians to abandon Silistra. Aside from a minor skirmish at Constanța there was little for the allies to do. Karl Marx quipped that "there they are, the French doing nothing and the British helping them as fast as possible".
Frustrated by the wasted effort, and with demands for action from their citizens, the allied force decided to attack the center of Russian strength in the Black Sea at Sevastopol on the Crimean peninsula. After extended preparations, the forces landed on the peninsula in September 1854 and fought their way to a point south of Sevastopol after a series of successful battles. The Russians counterattacked on 25 October in what became the Battle of Balaclava and were repulsed, but at the cost of seriously depleting the British Army forces. A second counterattack, ordered personally by Nicholas, was defeated by Omar Pasha. The front settled into a siege and led to horrible conditions for troops on both sides. Smaller actions were carried out in the Baltic, the Caucasus, the White Sea and in the North Pacific.
Sevastopol fell after eleven months, and formerly neutral countries began to join the allied cause. Isolated and facing a bleak prospect of invasion from the west if the war continued, Russia sued for peace in March 1856. This was welcomed by France and the UK, where the citizens began to turn against their governments as the war dragged on. The war was officially ended by the Treaty of Paris, signed on 30 March 1856. Russia lost the war, and was forbidden from hosting warships in the Black Sea. The Ottoman vassal states of Wallachia and Moldavia became largely independent. Christians were granted a degree of official equality, and the Orthodox church regained control of the Christian churches in dispute.
The Crimean War was one of the first conflicts to use modern technologies such as explosive naval shells, railways, and telegraphs. The war was one of the first to be documented extensively in written reports and photographs. As the legend of the "Charge of the Light Brigade" demonstrates, the war quickly became an iconic symbol of logistical, medical and tactical failures and mismanagement. The reaction in the UK was a demand for professionalization, most famously achieved by Florence Nightingale, who gained worldwide attention for pioneering modern nursing while treating the wounded.
The "Eastern Question".
Taylor argues that the war resulted not from aggression but from the interacting fears of the major players:
Weakening of the Ottoman Empire in 1820-40’s.
In 1820-1830’s the Ottoman Empire endured a number of strikes which challenged the existence of the country. The Greek Uprising (began in the spring of 1821) evidenced internal and military weakness of Ottoman Empire and caused severe atrocities by Ottoman military forces (see Chios massacre). The disbandment of the centuries-old Janissary corps by Sultan Mahmud II on 15 June 1826 (Auspicious Incident) was a good deed for the country in the longer term, but it has deprived the country from its army forces for the nearest future. In 1827 the allied Anglo-Franco-Russian fleet destroyed almost all the Ottoman naval forces during the Battle of Navarino. In 1830 Greece becomes an independent state after 10 years of independence war and the Russo-Turkish War of 1828–1829. According to the Treaty of Adrianople (1829) Russian and European commercial ships were authorized to freely pass through Black Sea straits, Serbia received autonomy, and Danubian Principalities (Moldavia and Walachia) became the territories under Russian protection.
France used the right moment and occupied Alger in 1830. In 1831 Muhammad Ali of Egypt, who was the most powerful vassal of the Ottoman Empire, claimed independence. Ottoman forces were defeated in a number of battles, and Egyptians were ready to capture Constantinople, which forced the sultan Mahmud II to seek for Russian military aid. 10 000 Russian army corps landed on the Bosphorus shores in 1833 and helped to prevent the capture of Constantinople, thus the possible disappearance of the Ottoman Empire was prevented.
As the result of that Russian military operation, the Treaty of Hünkâr İskelesi was signed. Russia benefited much of this treaty. It provided military union between Russia and Ottoman Empire, if one of the countries would be attacked. A secret additional clause allowed Ottomans not to send troops but to close the Straits to foreign warships if and when Russia was under threat.
In 1838 the situation was slightly the same as in 1831. Muhammad Ali of Egypt was not happy about lack of his control and power in Syria, he resumed military actions. The Ottoman army lost to Egyptians at the Battle of Nezib on June 24, 1839. The Ottoman Empire was saved by Great Britain, Austria, Prussia and Russia by signing a convention in London in July 15, 1840 to grant Muhammad Ali and his descendants the right to inherit power in Egypt in exchange for removal of Egyptian military forces from Syria and Lebanon. Moreover, Muhammad Ali had to admit a formal dependence from the Ottoman sultan. After Muhammad Ali refused to obey the requirements of the London convention, the allied Anglo-Austrian fleet blocked the Delta, bombarded Beirut and captured Acre. Muhammad Ali accepted the conditions of the London convention in 1840.
In July 13, 1841, after the expiry of the Treaty of Hünkâr İskelesi, the London Straits Convention was signed under pressure from European countries. The new treaty deprived Russia from its right to block warships to pass into the Black Sea in case of war. Thus, the way to the Black Sea was open for British and French warships in case of a possible Russo-Turkish/Ottoman conflict.
Thus the support by European countries has saved twice the Ottoman Empire from decay, but the Ottomans lost their independence in external policy. Great Britain and France desired more than any other state to preserve the integrity of the Ottoman Empire because they did not want at all to see Russia gaining access to the Mediterranean Sea. Austria had fears for to the same reasons.
Russian expansionism.
Russia, as a member of the Holy Alliance, had operated as the "police of Europe", maintaining the balance of power that had been established in the Treaty of Vienna in 1815. Russia had assisted Austria's efforts in suppressing the Hungarian Revolution of 1848, and expected gratitude; it wanted a free hand in settling its problems with the Ottoman Empire — the "sick man of Europe". The United Kingdom could not tolerate Russian dominance of Ottoman affairs, as that would challenge the British domination of the eastern Mediterranean.
For over 200 years, Russia had been expanding southwards across the sparsely populated "Wild Fields" toward the warm water ports of the Black Sea that did not freeze over like the handful of other ports available in the north. The goal was to promote year-round trade and a year-round navy. Pursuit of this goal brought the emerging Russian state into conflict with the Ukrainian Cossacks and then with the Tatars of the Crimean Khanate and Circassians. When Russia conquered these groups and gained possession of southern Ukraine, known as New Russia during Russian imperial times, the Ottoman Empire lost its buffer zone against Russian expansion, and Russia and the Ottoman Empire fell into direct conflict. The conflict with the Ottoman Empire also presented a religious issue of importance, as Russia saw itself as the protector of Orthodox Christians, many of whom lived under Ottoman control and were treated as second-class citizens.
The United Kingdom's immediate fear was Russian expansion at the expense of the Ottoman Empire, which the UK desired to preserve. The British were also concerned that Russia might make advances toward India, or move toward Scandinavia, or Western Europe. The Royal Navy also wanted to undermine the threat of a powerful Russian navy.
Taylor says that from the British perspective:
It is often said that Russia was militarily weak, technologically backward, and administratively incompetent. Despite its grand ambitions toward the south, it had not built its railroad network in that direction, and communications were poor. The bureaucracy was riddled with graft, corruption and inefficiency and was unprepared for war. Its navy was weak and technologically backward; its army, although very large, was good only for parades, suffered from colonels who pocketed their men's pay, poor morale, and was out of touch with the latest technology developed by Britain and France. By the war's end, everyone realized the profound weaknesses of the Russian military, and the Russian leadership was determined to reform it.
The immediate causes of the war.
The immediate chain of events leading to France and the United Kingdom declaring war on Russia on 27 and 28 March 1854 came from the ambition of the French emperor Napoleon III to restore the grandeur of France. He wanted Catholic support that would come his way if he attacked Eastern Orthodoxy, as sponsored by Russia. The Marquis Charles de La Valette was a zealous Catholic and a leading member of the "clerical party," which demanded French protection of the Roman Catholic rights to the holy places in Palestine. In May 1851, Napoleon appointed La Valette as his ambassador to the Porte (the Ottoman Empire). The appointment was made with the intent of forcing the Ottomans to recognise France as the "sovereign authority" over the Christian population. Russia disputed this attempted change in authority. Pointing to two more treaties, one in 1757 and the 1774 Treaty of Küçük Kaynarca, the Ottomans reversed their earlier decision, renouncing the French treaty and insisting that Russia was the protector of the Orthodox Christians in the Ottoman Empire.
Napoleon III responded with a show of force, sending the ship of the line "Charlemagne" to the Black Sea. This action was a violation of the London Straits Convention. Thus, France's show of force presented a real threat, and when combined with aggressive diplomacy and money, induced the Ottoman Sultan Abdülmecid I to accept a new treaty, confirming France and the Roman Catholic Church as the supreme Christian authority with control over the Roman Catholic holy places and possession of the keys to the Church of the Nativity, previously held by the Greek Orthodox Church.
Tsar Nicholas I then deployed his 4th and 5th army corps along the River Danube in Wallachia, as a direct threat to the Ottoman lands south of the river, and had Count Karl Nesselrode, his foreign minister, undertake talks with the Ottomans. Nesselrode confided to Sir George Hamilton Seymour, the British ambassador in Saint Petersburg:
"dispute over the holy places" had assumed a new character—that the acts of injustice towards the Greek church which it had been desired to prevent had been perpetrated and consequently that now the object must be to find a remedy for these wrongs. The success of French negotiations at Constantinople was to be ascribed solely to intrigue and violence—violence which had been supposed to be the ultima ratio of kings, being, it had been seen, the means which the present ruler of France was in the habit of employing in the first instance.
As conflict emerged over the issue of the holy places, Nicholas I and Nesselrode began a diplomatic offensive, which they hoped would prevent either Britain's or France's interfering in any conflict between Russia and the Ottomans, as well as to prevent their allying.
Nicholas began courting Britain by means of conversations with the British ambassador, George Hamilton Seymour, in January and February 1853. Nicholas insisted that he no longer wished to expand Imperial Russia but that he had an obligation to the Christian communities in the Ottoman Empire.
The Tsar next dispatched a highly abrasive diplomat, Prince Menshikov, on a special mission to the Ottoman Sublime Porte in February 1853. By previous treaties, the sultan was committed "to protect the (Eastern Orthodox) Christian religion and its churches." Menshikov demanded a Russian protectorate over all 12 million Orthodox Christians in the Empire, with control of the Orthodox Church's hierarchy. A compromise was reached regarding Orthodox access to the Holy Land, but the Sultan, strongly supported by the British ambassador, rejected the more sweeping demands.
The British and French sent in naval task forces to support the Ottomans, as Russia prepared to seize the Danubian Principalities.
First hostilities.
In February 1853, the British government of Lord Aberdeen, the prime minister, re-appointed Stratford Canning as British ambassador to the Ottoman Empire. Having resigned the ambassadorship in January, he had been replaced by Colonel Rose as "chargé d'affaires". Lord Stratford then turned around and sailed back to Constantinople, arriving there on 5 April 1853. There he convinced the Sultan to reject the Russian treaty proposal, as compromising the independence of the Turks. The Leader of the Opposition in the British House of Commons, Benjamin Disraeli, blamed Aberdeen and Stratford's actions for making war inevitable, thus starting the process which would eventually force the Aberdeen government to resign in January 1855, over the war.
Shortly after he learned of the failure of Menshikov's diplomacy toward the end of June 1853, the Tsar sent armies under the commands of Field Marshal Ivan Paskevich and General Mikhail Gorchakov across the Pruth River into the Ottoman-controlled Danubian Principalities of Moldavia and Wallachia. Fewer than half of the 80,000 Russian soldiers who crossed the Pruth in 1853 survived. By far, most of the deaths would result from sickness rather than combat, for the Russian army still suffered from medical services that ranged from bad to none.
Russia had previously obtained recognition from the Ottoman Empire of the Tsar's role as special guardian of the Orthodox Christians in Moldavia and Wallachia. Now Russia used the Sultan's failure to resolve the issue of the protection of the Christian sites in the Holy Land as a pretext for Russian occupation of these Danubian provinces. Nicholas believed that the European powers, especially Austria, would not object strongly to the annexation of a few neighbouring Ottoman provinces, especially considering that Russia had assisted Austria's efforts in suppressing the Hungarian Revolution in 1849.
In July 1853, the Tsar sent his troops into the Danubian Principalities. The United Kingdom, hoping to maintain the Ottoman Empire as a bulwark against the expansion of Russian power in Asia, sent a fleet to the Dardanelles, where it joined another fleet sent by France.
Sultan Abdulmecid I formally declared war on Russia and proceeded to the attack, his armies moving on the Russian army near the Danube later that month. Russia and the Ottoman Empire massed forces on two main fronts, the Caucasus and the Danube. Ottoman leader Omar Pasha managed to achieve some victories on the Danubian front. In the Caucasus, the Ottomans were able to stand ground with the help of Chechen Muslims led by Imam Shamil.
Battle of Sinop.
The European powers continued to pursue diplomatic avenues. The representatives of the four neutral Great Powers—the United Kingdom, France, Austria and Prussia—met in Vienna, where they drafted a note that they hoped would be acceptable to both the Russians and the Ottomans. The peace terms arrived at by the four powers at the Vienna Conference were delivered to the Russians by the Austrian Foreign Minister Count Karl von Buol on 5 December 1853. The note met with the approval of Nicholas I; however, Abdülmecid I rejected the proposal, feeling that the document's poor phrasing left it open to many different interpretations. The United Kingdom, France, and Austria united in proposing amendments to mollify the Sultan, but the court of St. Petersburg ignored their suggestions. The UK and France then set aside the idea of continuing negotiations, but Austria and Prussia did not believe that the rejection of the proposed amendments justified the abandonment of the diplomatic process.
The Russians sent a fleet to Sinop in northern Anatolia. In the Battle of Sinop on 30 November 1853 they destroyed a patrol squadron of Ottoman frigates and corvettes while they were anchored in port. Public opinion in the UK and France was outraged and demanded war. Sinop provided the United Kingdom and France with the "casus belli" ("cause for war") for declaring war against Russia. On 28 March 1854, after Russia ignored an Anglo-French ultimatum to withdraw from the Danubian Principalities, the UK and France formally declared war.
Dardanelles.
Britain was concerned about Russian activity and Sir John Burgoyne senior advisor to Lord Aberdeen urged that the Dardanelles should be occupied and throw up works of sufficient strength to block any Russian move to capture Constantinople and gain access to the Mediterranean Sea. The Corps of Royal Engineers sent men to the Dardanelles while Burgoyne went to Paris, meeting the British Ambassador and the French Emperor. The Lord Cowley wrote on 8 February to Burgoyne "Your visit to Paris has produced a visible change in the Emperor's views, and he is making every preparation for a land expedition in case the last attempt at negotiation should break down."
Burgoyne and his team of engineers inspected and surveyed the Dardanelles area in February, being fired on by Russian riflemen when they went to Varna. A team of sappers arrived in March and major building works commenced on a seven-mile line of defence designed to block the Gallipoli peninsula. French sappers were working on one half of the line which was finished in May.
Peace attempts.
Nicholas felt that, because of Russian assistance in suppressing the Hungarian revolution of 1848, Austria would side with him, or at the very least remain neutral. Austria, however, felt threatened by the Russian troops in the Balkans. On 27 February 1854, the United Kingdom and France demanded the withdrawal of Russian forces from the principalities; Austria supported them and, though it did not declare war on Russia, it refused to guarantee its neutrality. Russia's rejection of the ultimatum caused the UK and France to enter the war.
Russia soon withdrew its troops from the Danubian principalities, which were then occupied by Austria for the duration of the war. This removed the original grounds for war, but the UK and France continued with hostilities. Determined to address the Eastern Question by putting an end to the Russian threat to the Ottoman Empire, the allies in August 1854 proposed the "Four Points" for ending the conflict, in addition to the Russian withdrawal:
These points (particularly the third) would require clarification through negotiation, but Russia refused to negotiate. The allies including Austria therefore agreed that the UK and France should take further military action to prevent further Russian aggression against the Ottoman Empire. The United Kingdom and France agreed on the invasion of the Crimean peninsula as the first step.
Battles.
Danube campaign.
The Danube campaign opened when the Russians occupied the Danubian Principalities of Moldavia and Wallachia in May 1853, bringing their forces to the north bank of the river Danube. In response, the Ottoman Empire also moved its forces up to the river. It established strongholds at Vidin in the west, and Silistra, which was located in the east, near the mouth of the Danube.
The Turkish/Ottoman move up the Danube River was also of concern to the Austrians, who moved forces into Transylvania in response. However, the Austrians had begun to fear the Russians more than the Turks. Indeed, like the British, the Austrians were now coming to see that an intact Ottoman Empire was necessary as a bulwark against the Russians. Accordingly, the Austrians resisted Russian diplomatic attempts to join the war on the Russian side. Austria remained neutral in the Crimean War.
Following the Ottoman ultimatum in September 1853, forces under the Ottoman general Omar Pasha crossed the Danube at Vidin and captured Calafat in October 1853. Simultaneously, in the east, the Ottomans crossed the Danube at Silistra and attacked the Russians at Oltenița. The resulting Battle of Oltenița was the first engagement following the declaration of war. The Russians counterattacked, but were beaten back. On 31 December 1853, the Ottoman forces at Calafat moved against the Russian force at Chetatea or Cetate, a small village nine miles north of Calafat, and engaged them on 6 January 1854. The battle began when the Russians made a move to recapture Calafat. Most of the heavy fighting, however, took place in and around Chetatea until the Russians were driven out of the village. Despite the setback at Chetatea, on 28 January 1854, Russian forces laid siege to Calafat. The siege would continue until May 1854 when the Russians lifted the siege. The Ottomans would also later beat the Russians in battle at Caracal.
In the spring of 1854 the Russians again advanced, crossing the Danube River into the Turkish province of Dobruja. By April 1854, the Russians had reached the lines of Trajan's Wall where they were finally halted. In the center, the Russian forces crossed the Danube and laid siege to Silistra from 14 April with 60,000 troops, the defenders with 15,000 had supplies for three months. The siege was lifted on 23 June 1854. The English and French forces at this time were unable to take the field for lack of equipment.
In the west, the Russians were dissuaded from attacking Vidin by the presence of the Austrian forces, which had swelled to 280,000 men. On 28 May 1854 a protocol of the Vienna Conference was signed by Austria and Russia. One of the aims of the Russian advance had been to encourage the Orthodox Christian Serbs and Bulgarians living under Ottoman rule to rebel. However, when the Russian troops actually crossed the River Pruth into Moldavia, the Orthodox Christians still showed no interest in rising up against the Turks. Adding to the worries of Nicholas I was the concern that Austria would enter the war against the Russians and attack his armies on the western flank. Indeed, after attempting to mediate a peaceful settlement between Russia and Turkey, the Austrians entered the war on the side of Turkey with an attack against the Russians in the Principalities which threatened to cut off the Russian supply lines. Accordingly, the Russians were forced to raise the siege of Silistra on 23 June 1854, and begin abandoning the Principalities. The lifting of the siege reduced the threat of a Russian advance into Bulgaria.
In June 1854, the Allied expeditionary force landed at Varna, a city on the Black Sea's western coast (now in Bulgaria). They made little advance from their base there. In July 1854, the Turks under Omar Pasha crossed the Danube into Wallachia and on 7 July 1854, engaged the Russians in the city of Giurgiu and conquered it. The capture of Giurgiu by the Turks immediately threatened Bucharest in Wallachia with capture by the same Turk army. On 26 July 1854, Tsar Nicholas I ordered the withdrawal of Russian troops from the Principalities. Also, in late July 1854, following up on the Russian retreat, the French staged an expedition against the Russian forces still in Dobruja, but this was a failure.
By then, the Russian withdrawal was complete, except for the fortress towns of northern Dobruja, while their place in the Principalities was taken by the Austrians, as a neutral peacekeeping force. There was little further action on this front after the autumn of 1854 and in September the allied force boarded ships at Varna to invade the Crimean Peninsula.
Black Sea theatre.
The naval operations of the Crimean war commenced with the dispatch, in the summer of 1853, of the French and British fleets to the Black Sea region, to support the Ottomans and to dissuade the Russians from encroachment. By June 1853, both fleets were stationed at Besikas bay, outside the Dardanelles. With the Russian occupation of the Danube Principalities in October, they moved to the Bosphorus and in November entered the Black Sea.
During this period, the Russian Black Sea Fleet was operating against Ottoman coastal traffic between Constantinople (currently named Istanbul) and the Caucasus ports, while the Ottoman fleet sought to protect this supply line. The clash came on 30 November 1853 when a Russian fleet attacked an Ottoman force in the harbour at Sinop, and destroyed it at the Battle of Sinop. The battle outraged opinion in UK, which called for war. There was little additional naval action until March 1854 when on the declaration of war the British frigate "Furious" was fired on outside Odessa harbour. In response an Anglo-French fleet bombarded the port, causing much damage to the town. To show support for Turkey after the battle of Sinop, on the 22th of December 1853, the Anglo-French squadron entered the Black Sea and the steamship approached the Port of Sevastopol, the commander of which received an ultimatum not to allow any ships in the Black Sea.
In June, the fleets transported the Allied expeditionary forces to Varna, in support of the Ottoman operations on the Danube; in September they again transported the armies, this time to the Crimea. The Russian fleet during this time declined to engage the allies, preferring to maintain a "fleet in being"; this strategy failed when Sevastopol, the main port and where most of the Black Sea fleet was based, came under siege. The Russians were reduced to scuttling their warships as blockships, after stripping them of their guns and men to reinforce batteries on shore. During the siege, the Russians lost four 110- or 120-gun, three-decker ships of the line, twelve 84-gun two-deckers and four 60-gun frigates in the Black Sea, plus a large number of smaller vessels. During the rest of the campaign the allied fleets remained in control of the Black Sea, ensuring the various fronts were kept supplied.
In April 1855, they supported an invasion of Kerch and operated against Taganrog in the Sea of Azov. In September they moved against Russian installations in the Dnieper estuary, attacking Kinburn in the first use of ironclad ships in naval warfare.
Crimean campaign.
The Russians evacuated Wallachia and Moldavia in late July 1854. With the evacuation of the Danubian Principalities, the immediate cause of war was withdrawn and the war might have ended at this time. However, war fever among the public in both the UK and France had been whipped up by the press in both countries to the degree that politicians found it untenable to propose ending the war at this point. Indeed, the coalition government of George Hamilton-Gordon, 4th Earl of Aberdeen fell on 30 January 1855 on a no-confidence vote as Parliament voted to appoint a committee to investigate mismanagement of the war.
French and British officers and engineers were sent on 20 July on HMS Fury, a wooden Bulldog-class paddle sloop, to survey the harbour of Sevastopol and the coast near it, managing to get close to the harbour mouth to inspect the formidable batteries. Returning, they reported that they believed there were 15,000–20,000 troops encamped. Ships were prepared to transport horses and siege equipment was both manufactured and imported.
The Crimean campaign opened in September 1854. 360 ships sailed in seven columns, each steamer towing two sailing ships. Anchoring on 13 September in the bay of Eupatoria, the town surrendered and 500 Marines landed to occupy it. This town and bay would provide a fall back position in case of disaster. The ships then sailed east to make the landing of the allied expeditionary force on the sandy beaches of Calamita Bay on the south west coast of the Crimean Peninsula. The landing surprised the Russians, as they had been expecting a landing at Katcha; the last minute change proving that Russia had known the original battle plan. There was no sign of the enemy and the men were all landed on 14 September. It took another four days to land all the stores, equipment, horses and artillery.
The landing was north of Sevastopol, so the Russians had arrayed their army in expectation of a direct attack. The allies advanced and on the morning of 20 September came up to the Alma river and the whole Russian army. The position was strong, but after three hours, the frontal attack had driven the Russians out of their dug in positions with losses of 6000 men. The Battle of the Alma had 3,300 Allied losses. Failing to pursue the retreating forces was one of many strategic errors made during the war, and the Russians themselves noted that had they pressed south that day they would have easily captured Sevastopol.
Believing the northern approaches to the city too well defended, especially due to the presence of a large star fort and because Sevastopol was on the south side of the inlet from the sea that made the harbour, Sir John Burgoyne, the engineer advisor, recommended that the allies attack Sevastopol from the south. This was agreed by the joint commanders, Raglan and St Arnaud. On 25 September the whole army marched southeast and encircled the city to the south. This let them set up a new supply center in a number of protected inlets on the south coast. The Russians retreated into the city.
The Allied army relocated without problems to the south and the heavy artillery was brought ashore with batteries and connecting trenches built so that by 10 October some batteries were ready and by 17 October—when the bombardment commenced—126 guns were firing, 53 of them French. The fleet at the same time engaged the shore batteries. The British bombardment worked better than the French, who had smaller caliber guns. The fleet suffered high casualties during the day. The British wanted to attack that afternoon, but the French wanted to defer the attack. A postponement was agreed, but on the next day the French were still not ready. By 19 October the Russians had transferred some heavy guns to the southern defenses and outgunned the allies.
Reinforcements for the Russians gave them the courage to send out probing attacks. The Allied lines, beginning to suffer from cholera as early as September, were stretched. The French, on the west had less to do than the British on the east with their siege lines and the large nine mile open wing back to their supply base on the south coast.
Battle of Balaclava.
A large Russian assault on the allied supply base to the southeast, at Balaclava was rebuffed on 25 October 1854. The Battle of Balaclava is remembered in the UK for the actions of two British units. At the start of the battle, a large body of Russian cavalry charged the 93rd Highlanders, who were posted north of the village of Kadikoi. Commanding them was Sir Colin Campbell. Rather than 'form square', the traditional method of repelling cavalry, Campbell took the risky decision to have his Highlanders form a single line, two men deep. Campbell had seen the effectiveness of the new Minie rifles, with which his troops were armed, at the Battle of the Alma a month before, and was confident his men could beat back the Russians. His tactics succeeded. From up on the ridge to the west, "Times" correspondent William Howard Russell saw the Highlanders as a 'thin red streak topped with steel', a phrase which soon became the 'Thin Red Line.'
Soon after, a Russian cavalry movement was countered by the Heavy Brigade, who charged and fought hand-to-hand until the Russians retreated. This caused a more widespread Russian retreat, including a number of their artillery units. When the local commanders failed to take advantage of the retreat, Lord Raglan sent out orders to move up. The local commanders ignored the demands, leading to the British aide-de-camp personally delivering a quickly written and confusing order to attack the artillery. When the Earl of Cardigan questioned what they referred to, the aide-de-camp pointed to the first Russian battery he could see – the wrong one.
Cardigan formed up his unit and charged the length of the Valley of the Balaclava, under fire from Russian batteries in the hills. The charge of the Light Brigade caused 278 casualties of the 700-man unit. The Light Brigade was memorialized in the famous poem by Alfred Lord Tennyson, "The Charge of the Light Brigade." Although traditionally the charge of the Light Brigade was looked upon as a glorious but wasted sacrifice of good men and horses, recent historians say that the charge of the Light Brigade did succeed in at least some of its objectives. The aim of any cavalry charge is to scatter the enemy lines and frighten the enemy off the battlefield. The charge of the Light Brigade had so unnerved the Russian cavalry, which had previously been routed by the Heavy Brigade, that the Russian Cavalry was set to full-scale flight by the subsequent charge of the Light Brigade.
The shortage of men led to the failure of the British and French to follow up on the Battle of Balaclava which led directly to a much more bloody battle—the Battle of Inkerman. On 5 November 1854, the Russians attempted to raise the siege at Sevastopol with an attack against the allies which resulted in another allied victory.
Winter of 1854–55.
Winter, and a deteriorating supply situation on both sides of troops and materiel, led to a halt in ground operations. Sevastopol remained invested by the allies, while the allied armies were hemmed in by the Russian army in the interior. On 14 November a storm sank thirty allied transport ships including which was carrying a cargo of winter clothing. The storm and heavy traffic caused the road from the coast to the troops to disintegrate into a quagmire, requiring engineers to devote most of their time to its repair including quarrying stone. A tramroad was ordered. It arrived in January with a civilian engineering crew, however it was March before it was sufficiently advanced to be of any appreciable value. An Electrical telegraph was also ordered, but the frozen ground delayed its installation until March, when communications from the base port of Balaklava to the British HQ was established. The Pipe-and-cable-laying plough failed because of the hard frozen soil, but even so 21 miles of cable were laid.
The troops suffered greatly from cold and sickness, the shortage of fuel led them to start dismantling their defensive Gabions and Fascines. In February 1855, the Russians attacked the allied base at Eupatoria, where an Ottoman army had built up and was threatening Russian supply routes. The battle saw the Russians defeated and led to a change in command.
The strain of directing the war had taken its toll on the health of Tsar Nicholas. The Tsar, full of remorse for the disasters he had caused, caught pneumonia and died on 2 March.
Siege of Sevastopol.
The Allies had had time to consider the problem. The French being brought around to agree that the key to the defence was the Malakoff. Emphasis of the siege at Sevastopol shifted to the British left, against the fortifications on Malakoff hill. In March, there was fighting by the French over a new fort being built by the Russians at Mamelon, located on a hill in front of the Malakoff. Several weeks of fighting saw little change in the front line, and the Mamelon remained in Russian hands.
In April 1855, the allies staged a second all-out bombardment, leading to an artillery duel with the Russian guns, but no ground assault followed.
On 24 May 1855, sixty ships containing 7000 French, 5000 Turkish and 3000 British troops set off for a raid on the city of Kerch east of Sevastopol in an attempt to open another front on the Crimean peninsula and to cut off Russian supplies. When the allies landed the force at Kerch, the plan was to outflank the Russian army. The landings were successful, but the force made little progress thereafter.
Many more artillery pieces had arrived and been dug into batteries. In June, a third bombardment was followed after two days by a successful attack on the Mamelon, but a follow-up assault on the Malakoff failed with heavy losses. During this time the garrison commander, Admiral Nakhimov fell on 30 June 1855. Raglan having also died on 28 June. In August, the Russians again made an attack towards the base at Balaclava, defended by the French, newly arrived Sardinian and Ottoman troops. The resulting battle of Tchernaya was a defeat for the Russians, who suffered heavy casualties.
For months each side had been building forward rifle pits and defensive positions, which resulted in many skirmishes. Artillery fire aiming to gain superiority over the enemy guns. September saw the final assault. On 5 September, another French bombardment (the sixth) was followed by an assault by the French Army on 8 September resulting in the capture of the Malakoff by the French, and following their failure to retake it, the collapse of the Russian defences. Meanwhile, the British captured the Great Redan, just south of the city of Sevastopol. The Russians retreated to the north, blowing up their magazines and the city fell on 9 September 1855 after a 337-day-long siege.
At this point, both sides were exhausted, and no further military operations were launched in the Crimea before the onset of winter. The main objective of the siege, the destruction of the Russian fleet and docks took place over winter. On 28 February multiple mines blew up the five docks, the canal and three locks.
Azov campaign.
In spring 1855, the allied British-French commanders decided to send an Anglo-French naval squadron into the Azov Sea to undermine Russian communications and supplies to besieged Sevastopol. On 12 May 1855, British-French warships entered the Kerch Strait and destroyed the coast battery of the Kamishevaya Bay. On 21 May 1855, the gunboats and armed steamers attacked the seaport of Taganrog, the most important hub near Rostov on Don. The vast amounts of food, especially bread, wheat, barley, and rye that were amassed in the city after the outbreak of war were prevented from being exported.
The Governor of Taganrog, Yegor Tolstoy, and lieutenant-general Ivan Krasnov refused the ultimatum, responding that "Russians never surrender their cities". The British–French squadron bombarded Taganrog for 6½ hours and landed 300 troops near the Old Stairway in downtown Taganrog, but they were thrown back by Don Cossacks and a volunteer corps.
In July 1855, the allied squadron tried to go past Taganrog to Rostov on Don, entering the Don River through the Mius River. On 12 July 1855 HMS "Jasper" grounded near Taganrog thanks to a fisherman who moved buoys into shallow water. The Cossacks captured the gunboat with all of its guns and blew it up. The third siege attempt was made 19–31 August 1855, but the city was already fortified and the squadron could not approach close enough for landing operations. The allied fleet left the Gulf of Taganrog on the 2nd September 1855, with minor military operations along the Azov Sea coast continuing until late autumn 1855.
Caucasus theatre.
As in the previous wars the Caucasus front was secondary to what was happening in the west. Perhaps because of better communications western events sometimes influenced the east. The main events were the second capture of Kars and a landing on the Georgian coast. Several commanders on both sides were either incompetent or unlucky and few fought aggressively.
1853: There were four main events. 1. In the north the Turks captured the border fort of Saint Nicholas in a surprise night attack (27/28 October). They then pushed about 20000 troops across the Cholok River border. Being outnumbered the Russians abandoned Poti and Redut Kale and drew back to Marani. Both sides remained immobile for the next seven months. 2. In the center the Turks moved north from Ardahan to within cannon-shot of Akhaltsike and awaited reinforcements (13 November). The Russians routed them. The claimed losses were 4000 Turks and 400 Russians. 3. In the south about 30000 Turks slowly moved east to the main Russian concentration at Gyumri or Alexandropol (November). They crossed the border and set up artillery south of town. Prince Orbeliani tried to drive them off and found himself trapped. The Turks failed to press their advantage, the remaining Russians rescued Orbeliani and the Turks retired west. Orbeliani lost about 1000 men out of 5000. The Russians now decided to advance, the Turks took up a strong position on the Kars road and attacked. They were defeated in the battle of Başgedikler, losing 6000 men, half their artillery and all their supply train. The Russians lost 1300, including Prince Orbeliani. This was Prince Ellico Orbeliani whose wife was later kidnaped by Shamyl at Tsinandali. 4. At sea the Turks sent a fleet east which was destroyed by Admiral Nakhimov at Sinope.
1854: The British and French declared war on 3 January. That spring the Anglo-French fleet appeared in the Black Sea and the Russians abandoned the Black Sea Defensive Line from Anapa south. N. A. Read, who replaced Vorontsov, fearing an Anglo-French landing in conjunction with Shamyl and the Persians, recommended withdrawal north of the Caucasus. For this he was replaced by Baryatinsky. When the allies chose a land attack on Sebastopol any plan for a landing in the east was abandoned.
In the north Eristov pushed southwest, fought two battles, forced the Turks back to Batum, retired behind the Cholok River and suspended action for the rest of the year (June). In the far south Wrangel pushed west, fought a battle and occupied Bayazit. In the center the main forces stood at Kars and Gyumri. Both slowly approached along the Kars-Gyumri road and faced each other, neither side choosing to fight (June–July). On 4 August Russian scouts saw a movement which they thought was the start of a withdrawal, the Russians advanced and the Turks attacked first. They were defeated, losing 8000 men to the Russian 3000. 10000 irregulars deserted to their villages. Both sides withdrew to their former positions. About this time the Persians made a semi-secret agreement to remain neutral in exchange for the cancellation of the indemnity from the previous war.
1855:Kars: In the year up to May 1855 Turkish forces in the east were reduced from 120,000 to 75,000, mostly by disease. The local Armenian population kept Muravyev well-informed about the Turks at Kars and he judged they had about five months of supplies. He therefore decided to control the surrounding area with cavalry and starve them out. He started in May and by June was south and west of the town. A relieving force fell back and there was a possibility of taking Erzerum, but Muravyev chose not to. In late September he learned of the fall of Sevastopol and a Turkish landing at Batum. This led him to reverse policy and try a direct attack. It failed, the Russians losing 8000 men and the Turks 1500 (29 September). The blockade continued and Kars surrendered on 8 November.
1855: Georgian coast: Omar Pasha, the Turkish commander at Crimea had long wanted to land in Georgia, but the western powers vetoed it. When they relented in August most of the campaigning season was lost. In September 8000 Turks landed at Batum, but the main concentration was at Sukhum Kale. This required a 100-mile march south through a country with poor roads. The Russians planned to hold the line of the Ingur River which separates Abkhazia from Georgia proper. Omar crossed the Ingur on 7 November and then wasted a great deal of time, the Russians doing little. By 2 December he had reached the Tskhenis-dzqali, the rainy season had started, his camps were submerged in mud and there was no bread. Learning of the fall of Kars he withdrew to the Ingur. The Russians did nothing and he evacuated to Batum in February of the following year.
Baltic theatre.
The Baltic was a forgotten theatre of the Crimean War. Popularisation of events elsewhere overshadowed the significance of this theatre, which was close to Saint Petersburg, the Russian capital. In April 1854 an Anglo-French fleet entered the Baltic to attack the Russian naval base of Kronstadt and the Russian fleet stationed there. In August 1854 the combined British and French fleet returned to Kronstadt for another attempt. The outnumbered Russian Baltic Fleet confined its movements to the areas around its fortifications. At the same time, the British and French commanders Sir Charles Napier and Alexandre Ferdinand Parseval-Deschenes—although they led the largest fleet assembled since the Napoleonic Wars—considered the Sveaborg fortress too well-defended to engage. Thus, shelling of the Russian batteries was limited to two attempts in the summers of 1854 and 1855, and initially, the attacking fleets limited their actions to blockading Russian trade in the Gulf of Finland. Naval attacks on other ports, such as the ones in the island of Hogland in the Gulf of Finland, proved more successful. Additionally, allies conducted raids on less fortified sections of the Finnish coast. These battles are known in Finland as the Åland war.
Russia depended on imports - both for her domestic economy and for the supply of her military forces: the blockade forced Russia to rely on more expensive overland shipments from Prussia. The blockade seriously undermined the Russian export economy and helped shorten the war.
The burning of tar warehouses and ships led to international criticism, and in London the MP Thomas Gibson demanded in the House of Commons that the First Lord of the Admiralty explain "a system which carried on a great war by plundering and destroying the property of defenceless villagers".
In August 1855 a Franco-British naval force captured and destroyed the Russian Bomarsund fortress on Åland Islands. In the same month, the Western Allied Baltic Fleet tried to destroy heavily defended Russian dockyards at Sveaborg outside Helsinki. More than 1000 enemy guns tested the strength of the fortress for two days. Despite the shelling, the sailors of the 120-gun ship "Rossiya", led by Captain Viktor Poplonsky, defended the entrance to the harbor. The Allies fired over 20,000 shells but failed to defeat the Russian batteries. A massive new fleet of more than 350 gunboats and mortar vessels was prepared, but before the attack was launched, the war ended.
Part of the Russian resistance was credited to the deployment of newly invented blockade mines. Perhaps the most influential contributor to the development of naval mining was a Swede resident in Russia, the inventor and civil engineer Immanuel Nobel (the father of Alfred Nobel). Immanuel Nobel helped the Russian war effort by applying his knowledge of industrial explosives, such as nitroglycerin and gunpowder. One account dates modern naval mining from the Crimean War: "Torpedo mines, if I may use this name given by Fulton to self-acting mines underwater, were among the novelties attempted by the Russians in their defences about Cronstadt and Sevastopol", as one American officer put it in 1860.
White Sea theatre.
In autumn 1854, a squadron of three British warships led by HMS "Miranda" left the Baltic for the White Sea, where they shelled Kola (which was utterly destroyed) and the Solovki. Their attempt to storm Arkhangelsk proved unsuccessful.
Pacific theatre.
Minor naval skirmishes also occurred in the Far East, where at Petropavlovsk on the Kamchatka Peninsula a British and French Allied squadron including under Rear Admiral David Price and a French force under Counter-Admiral Auguste Febvrier Despointes besieged a smaller Russian force under Rear Admiral Yevfimy Putyatin. In September 1854, an Allied landing force was beaten back with heavy casualties, and the Allies withdrew. The Russians escaped under the cover of snow in early 1855 after Allied reinforcements arrived in the region.
The Anglo-French forces in the Far East also made several small landings on Sakhalin and Urup, one of the Kuril Islands.
Piedmontese Involvement.
Camillo di Cavour, under orders of Victor Emmanuel II of Piedmont-Sardinia, sent an expeditionary corps of 15,000 soldiers, commanded by General Alfonso La Marmora, to side with French and British forces during the war. This was an attempt at gaining the favour of the French, especially when the issue of uniting Italy would become an important matter. The deployment of Italian troops to the Crimea, and the gallantry shown by them in the Battle of the Chernaya (16 August 1855) and in the siege of Sevastopol, allowed the Kingdom of Sardinia to be among the participants at the peace conference at the end of the war, where it could address the issue of the "Risorgimento" to other European powers.
Greece.
Greece played a peripheral role in the war. When Russia attacked the Ottoman Empire in 1853, King Otto of Greece saw an opportunity to expand North and South into Ottoman areas that had large Greek Christian majorities. However, Greece did not coordinate its plans with Russia, did not declare war, and received no outside military or financial support. Greece, an Orthodox nation, had considerable support in Russia, but the Russian government decided it was too dangerous to help Greece expand its holdings. When the Russians invaded the Principalities, the Ottoman forces were tied down so Greece invaded Thessaly and Epirus. To block further Greek moves, the British and French occupied the main Greek port at Piraeus from April 1854 to February 1857, and effectively neutralized the Greek army. Greeks, gambling on a Russian victory, incited the large-scale Epirus Revolt of 1854 as well as uprisings in Crete. The insurrections were failures that were easily crushed by the Ottoman army. Greece was not invited to the peace conference and made no gains out of the war. The frustrated Greek leadership blamed the King for failing to take advantage of the situation; his popularity plunged and he was later forced to abdicate.
Kiev Cossack revolt and national awakening in Ukraine.
A Kiev cossack revolt that initially started in the Vasylkiv county of Kiev Governorate (province) in February 1855 spread across the whole Kiev and Chernigov governorates. Led by peasants, the revolt found great support among the Ukrainian landowners who opposed the war. The events were contemporary with the popular movement of Chłopomania that laid the foundations of the Ukrainian national awakening and the creation of the Kiev Hromada (Kiev Community).
End of the war.
British position.
Dissatisfaction with the conduct of the war was growing with the public in the UK and in other countries, aggravated by reports of fiascos, especially the humiliating defeat of the Charge of the Light Brigade at the Battle of Balaclava. On Sunday, 21 January 1855, a "snowball riot" occurred in Trafalgar Square near St. Martin-in-the-Field in which 1,500 people gathered to protest against the war by pelting buses, cabs, and pedestrians with snow balls. When the police intervened, the snowballs were directed at them. The riot was finally put down by troops and police acting with truncheons. In Parliament, Tories demanded an accounting of all soldiers, cavalry and sailors sent to the Crimea and accurate figures as to the number of casualties that had been sustained by all British armed forces in the Crimea; they were especially concerned with the Battle of Balaclava. When Parliament passed a bill to investigate by the vote of 305 to 148, Aberdeen said he had lost a vote of no confidence and resigned as prime minister on 30 January 1855. The veteran former Foreign Secretary Lord Palmerston became prime minister. Palmerston took a hard line; he wanted to expand the war, foment unrest inside the Russian Empire, and permanently reduce the Russian threat to Europe. Sweden and Prussia were willing to join the UK and France, and Russia was isolated.
Peace negotiations.
France, which had sent far more soldiers to the war than the United Kingdom had, and suffered far more casualties, wanted the war to end, as did Austria.
Peace negotiations at the Congress of Paris resulted in the signing of the Treaty of Paris on 30 March 1856. In compliance with article III, Russia restored to the Ottoman Empire the city and citadel of Kars in common with "all other parts of the Ottoman territory of which the Russian troop were in possession". Russia ceded some land in Bessarabia at the mouth of the Danube to Moldavia. By article IV The United Kingdom, France, Sardinia and Turkey restored to Russia "the towns and ports of Sevastopol, Balaklava, Kamish, Eupatoria, Kerch, Jenikale, Kinburn, as well as all other territories occupied by the allied troops". In conformity with article XI and XIII, the Tsar and the Sultan agreed not to establish any naval or military arsenal on the Black Sea coast. The Black Sea clauses weakened Russia, and it no longer posed a naval threat to the Ottomans. The principalities of Moldavia and Wallachia were nominally returned to the Ottoman Empire; in practice they became independent. The Great Powers pledged to respect the independence and territorial integrity of the Ottoman Empire.
Historical analysis.
The Treaty of Paris stood until 1871, when France was defeated by Prussia in the Franco-Prussian War of 1870–1871. While Prussia and several other German states united to form a powerful German Empire, the Emperor of the French, Napoleon III, was deposed to permit the formation of a Third French Republic. During his reign, Napoleon III, eager for the support of the United Kingdom, had opposed Russia over the Eastern Question. Russian interference in the Ottoman Empire, however, did not in any significant manner threaten the interests of France. Thus, France abandoned its opposition to Russia after the establishment of a republic. Encouraged by the decision of the French, and supported by the German minister Otto von Bismarck, Russia renounced the Black Sea clauses of the treaty agreed to in 1856. As the United Kingdom alone could not enforce the clauses, Russia once again established a fleet in the Black Sea.
Although it was Russia that was punished by the Paris Treaty, in the long run it was Austria that lost the most from the Crimean War despite having barely taken part in it. Having abandoned its alliance with Russia, Austria was diplomatically isolated following the war, which contributed to its disastrous defeats in the 1859 Franco-Austrian War that resulted in the cession of Lombardy to the Kingdom of Sardinia, and later in the loss of the Habsburg rule of Tuscany and Modena, which meant the end of Austrian influence in Italy. Furthermore, Russia did not do anything to assist its former ally, Austria, in the 1866 Austro-Prussian War with its loss of Venetia and more important than that, its influence in most German-speaking lands. The status of Austria as a great power, with the unifications of Germany and Italy was now severely questioned. It had to compromise with Hungary, the two countries shared the Danubian Empire and Austria slowly became a little more than a German satellite. With France now hostile to Germany, allied with Russia, and Russia competing with the newly renamed Austro-Hungarian Empire for an increased role in the Balkans at the expense of the Ottoman Empire, the foundations were in place for creating the diplomatic alliances that would lead to World War I.
Not withstanding the guarantees to preserve Ottoman territories specified in the Treaty of Paris, Russia, exploiting nationalist unrest in the Ottoman states in the Balkans and seeking to regain lost prestige, once again declared war on the Ottoman Empire on 24 April 1877. In this later Russo-Turkish War the states of Romania, Serbia, Montenegro gained international recognition of their independence and Bulgaria achieved its autonomy from direct Ottoman rule.
The Crimean War marked the ascendancy of France to the position of pre-eminent power on the Continent, the continued decline of the Ottoman Empire, and the beginning of a decline for Tsarist Russia. As Fuller notes, "Russia had been beaten on the Crimean peninsula, and the military feared that it would inevitably be beaten again unless steps were taken to surmount its military weakness." The Crimean War marks the demise of the Concert of Europe, the balance of power that had dominated Europe since the Congress of Vienna in 1815, and which had included France, Russia, Austria and the United Kingdom.
According to historian Shepard Clough, the war:
was not the result of a calculated plan, nor even of hasty last-minute decisions made under stress. It was the consequence of more than two years of fatal blundering in slow-motion by inept statesmen who had months to reflect upon the actions they took. It arose from Napoleon's search for prestige; Nicholas’s quest for control over the Straits; his naive miscalculation of the probable reactions of the European powers; the failure of those powers to make their positions clear; and the pressure of public opinion in Britain and Constantinople at crucial moments.
This view of 'diplomatic drift' as the cause of the war was first popularised by A. W, Kinglake, who portrayed the British as victims of newspaper sensationalism and duplicitous French and Ottoman diplomacy. More recently, the historians Andrew Lambert and Winfried Baumgart have argued that, first, Britain was following a geopolitical strategy in aiming to destroy a fledgling Russian Navy which might challenge the Royal Navy for control of the seas, and second that the war was a joint European response to a century of Russian expansion not just southwards but also into western Europe.
Russia feared losing Russian America without compensation in some future conflict, especially to the British. While Alaska attracted little interest at the time, the population of nearby British Columbia started to increase rapidly a few years after hostilities ended. Therefore, the Russian emperor, Alexander II, decided to sell Alaska. In 1859 the Russians offered to sell the territory to the United States, hoping that its presence in the region would offset the plans of Russia's greatest regional rival, the United Kingdom.
Documentation.
Notable documentation of the war was provided by William Howard Russell (writing for "The Times" newspaper) and the photographs of Roger Fenton. News from war correspondents reached all nations involved in the war and kept the public citizenry of those nations better informed of the day-to-day events of the war than had been the case in any other war to that date. The British public was very well informed regarding the day-to-day realities of the war in the Crimea. After the French extended the telegraph to the coast of the Black Sea during the winter of 1854, the news reached London in two days. When the British laid an underwater cable to the Crimean peninsula in April 1855, news reached London in a few hours. The daily news reports energised public opinion, which brought down the Aberdeen government and carried Lord Palmerston into office as prime minister.
Criticisms and reform.
The Crimean War also saw the first tactical use of railways and other modern inventions, such as the electric telegraph, with the first "live" war reporting to "The Times" by William Howard Russell. Some credit Russell with prompting the resignation of the sitting British government through his reporting of the lacklustre condition of British forces deployed in Crimea. Additionally, the telegraph reduced the independence of British overseas possessions from their commanders in London due to such rapid communications. Newspaper readership informed public opinion in the United Kingdom and France as never before. It was the first European war to be photographed.
The war also employed modern military tactics, such as trenches and blind artillery fire. The use of the Minié ball for shot, coupled with the rifling of barrels, greatly increased range and damage of the allied forces.
The British Army system of sale of commissions came under great scrutiny during the war, especially in connection with the Battle of Balaclava, which saw the ill-fated Charge of the Light Brigade. This scrutiny eventually led to the abolition of the sale of commissions.
The Crimean War was a contributing factor in the Russian abolition of serfdom in 1861: Tsar Alexander II (Nicholas I's son and successor) saw the military defeat of the Russian serf-army by free troops from Britain and France as proof of the need for emancipation. The Crimean War also led to the eventual realisation by the Russian government of its technological inferiority, in military practices as well as weapons.
Meanwhile, Russian military medicine saw dramatic progress: N. I. Pirogov, known as the father of Russian field surgery, developed the use of anaesthetics, plaster casts, enhanced amputation methods, and five-stage triage in Crimea, among other things.
The war also led to the establishment of the Victoria Cross in 1856 (backdated to 1854), the British Army's first universal award for valour. 111 medals were awarded.
The British issued the Crimea Medal with 5 clasps, and the Baltic Medal, as well as Valour medals, including the newly created Distinguished Conduct Medal, the Turkish the Turkish Crimea Medal, the French did not issue a campaign medal, issuing Médaille militaire and Legion of Honour for bravery, Sardinia also issued a medal. Russia issued a Defense of Sevastopol, and a Crimean War medal.

</doc>
<doc id="46764" url="https://en.wikipedia.org/wiki?curid=46764" title="Even-toed ungulate">
Even-toed ungulate

The even-toed ungulates (order Artiodactyla) are ungulates, hoofed animals, whose weight is borne approximately equally by the third and fourth toes - rather than primarily by the third toe as are odd-toed ungulates such as horses. The name Artiodactyla comes from the Greek ἄρτιος (ártios), "even", and δάκτυλος (dáktylos), "finger/toe"; so the name "even-toed" is a translation of the description. 
The roughly 220 artiodactyl species include pigs, peccaries, hippopotamuses, whales, camels, llamas, alpacas, mouse deer, deer, giraffes, antelopes, sheep, goats, and cattle - many of which are of great dietary, economic, and cultural importance to humans.
Taxonomy and phylogeny.
The classification of artiodactyls is hotly debated. This is because there is a morphologically defined order, yet cetaceans have evolved from them, and some groups (hippopotamuses) are more closely related to them than to other even-toed ungulates. This makes the artiodactyls a phylogenetic (defined through the tribal development) classification - which is significant in recent times -in essence, a paraphyletic taxon; that is, a group which, although descended from a common ancestor, does not include all descendants. The phylogenetic classification is recognized as only a monophyletic taxon; that is, groups that are descended from a common ancestor and include all descendants including their ancestors; in essence, the order Artiodactyla and infraorder Cetacea, are summarized in the taxon Cetartiodactyla.
Research History.
In the 1990s, the biological systematics not only went in accordance with aspects of the morphology and the fossil findings, but also by means of molecular biology. It seeks, by sequencing the DNA and RNA, to obtain genetic information and compare it with the data of other living beings to elicit the degree of relationship based on the degree of similarity notes. This method was, and still is, used in the classification of many living things and has changed the classification of many taxa significantly. These methods were performed between even-toed ungulates and cetaceans with the surprising result that the closest living relatives of the whales and hippopotamuses is the paraphyletic group Artiodactyla.
Among the first who came to that conclusion, Dan Graur and Desmond Higgins, included a study published in 1994. However, they did not recognize hippopotamuses and classified the ruminants as the sister group of cetaceans. Subsequent studies then came to the conclusion that the hippopotamuses are the closest living relative of cetaceans; these studies were based upon Caseingenen, SINEs, fibrinogen sequences, cytochrome and rRNA sequences, IRBP - and vWF gene sequences, adrenergic receptors, and apolipoproteins. In one of these studies, the scientific names of Cetacea and Artiodactyla was established in 1997 and for the first time, the name "Cetartiodactyla", proposed by Claudine Montgelard, Francois M. Catzeflis and Emmanuel Douzery, was composed.
In Pakistan, 2001, parts of the limb skeleton of a creature as big as a wolf, "Pakicetus", and another as large as a fox, "Ichthyolestes", were discovered; they were two archaeocetes from the Eocene from about 48 million years ago. These findings not only showed that archaeocetes were more terrestrial than previously thought, but also showed the special construction of the ankle bone (talus) with a double-rolled joint surface. This feature has long been considered an exclusive feature of even-toed ungulates and because it has now been discovered even in early cetaceans, the close relationship of the two groups could be assigned morphologically. In more modern cetaceans, there was a comprehensive reduction of the hind limbs that made the construction of the hind legs of these animals inconclusive about possible lineages between the two. The mesonychid did not show this special construction of the talus, thus a shared lineage with cetaceans was excluded.
Although the specific construction of the talus supported a close relationship between artiodactyls and cetaceans, the question of whether the even-toed ungulates are paraphyletic was not answered. Therefore, morphological studies were conducted to support the findings of molecular biology between that of hippopotamuses and cetaceans. The arrangement of cusps of the molars, the construction of the metatarsal bones, and the skull support a sister group relationship between these two taxa, but the striking commonality, the loss of fur and the sebaceous glands, is controversial.
The oldest member of cetaceans dates back to the early Eocene (53 million years ago), whereas the oldest known hippopotamus dates back only to the Miocene (15 million years ago). Because of the 40 million year gap between cetaceans and hippopotamuses in the fossil record, doubts have arisen. Given the relatively good fossil fund rate of even-toed ungulates, it seems unlikely that there are no remains of the ancestors of hippos. Some studies declared the late emergence of hippos is that they are relatives of peccaries and split recently, but this seems unlikely because of the molecular findings. The focus of research is therefore focused on the Anthracotheriidae, one dating from the Eocene to Miocene which has already been described in their discovery in the 19th century as being "hippo-like". A study from 2005 showed that they have a very similar skull structure, but the hippos have a different tooth design. It was nevertheless believed that cetaceans and the Anthracotheriidae descended from a common ancestor, and the hippopotamusess were developed from the Anthracotheriidae. A study published in a 2015 study was able to confirm this, but also revealed that the hippopotamuses, not as it was suspected, were phylogenetically much more developed, but can be derived from more original members of Anthracotherien. The newly introduced genus "Epirigenys" from eastern Africa is thus the sister group of hippos.
Morphological classification of Artiodactyla.
Linnaeus postulated a close relationship between camels and ruminants. Henri de Blainville recognized the similar construction of the limbs of these animals between those of pigs and hippos, and the British zoologist Richard Owen coined the term "even-toed ungulates" and the scientific name Artiodactyla in 1848.
Since then, the composition of this group was clear and was hardly ever questioned. The construction of the internal systematics (stomach and the molars) served for classification. Suinas and hippopotamuses have molars that have well-developed roots which formed early, and a simple stomach which digests food directly without rehashing. Thus, they were grouped together as non-ruminants, or Porcine. All other even-toed ungulates have molars with a selenodont construction (crescent-shaped cusps) and have the ability to ruminate. Differences in stomach construction indicated that rumination evolved independently between tylopods and ruminants; therefore tylopods were excluded from Ruminantia.
From a purely morphological point of view, the suspected classifications, which were widely accepted by the end of the 20th century, were:
Morphological classification of Cetacea.
Modern cetaceans are highly accustomed sea creatures that phenotypically have little in common with other mammals - they're similar to other marine mammals such as seals and sea cows which occurred due to convergence. It stands to reason; however, that they must have evolved from terrestrial mammals. The most likely candidates for the ancestors of cetaceans were long thought to be mesonychids. These were large, carnivorous animals from the early Cenozoic (Paleocene and Eocene), who had hooves instead of claws on their feet. Their molars were adapted to a carnivorous diet, resembling the teeth in modern toothed whales, which are aligned for a fish based diet, and, unlike other mammals, have a uniform construction.
The suspected relations can be as follows:
Inner systematics.
The molecular findings and morphological indications suggests that even-toed ungulates are paraphyletic to cetaceans and form a taxon Cetartiodactyla; the monophyly of Cetartiodactyla is well protected by a total of molecular and anatomical references. Shared modern nomenclatures divides Cetartiodactyla in five subordinate taxa that are also monophyletic: the camels (Tylopoda), the porcine (Suina), the ruminants (ruminant), the hippo (Ancodonta), and the whales (Cetacea).
The ruminants are likely to be more closely related to whales and hippos than with the other even-toed ungulates - this has so far only been explored by molecular biology, but not investigated morphologically and is therefore controversial. The presumed lineages within Cetartiodactyla can be represented in the following cladogram:
The pronghorn is the only extant representative of Gabelhorn carrier.
The four summarized Cetartiodactyla taxa are divided into ten extant families:
The pigs (Suina) are made up of two families:
The largest systematic problem within the subordinate taxa regards the ruminants. It is generally accepted that the mouse deer is the sister group of the remaining five families, but the systematics is confusing within the forehead weapons carrier. Although deer, musk deer and Gabelhorn carriers, have traditionally been summarized as cervids (Cervioidea), molecular studies provide different - and inconsistent - results, so that the question of phylogenetic systematics of forehead weapons carrier, for the time being, cannot be answered.
In December 2007, Hans Thewissen, professor at the Department of Anatomy of Northeastern Ohio Universities Colleges of Medicine and Pharmacy, hypothesized an alternative family tree. According to his studies, the next of kin of early whales were an extinct group called Raoellidae, and both taxa put together form the sister group of the remaining artiodactyl members, including the hippo.
His findings come from the study of a new skeleton found in the Kashmir in Pakistan. It was a member of the genus "Indohyus", which is a member of the Raoellidae family. Mainly due to a bony ring on temporal bone (bulla), called the involucrum, which was previously associated only with cetaceans, as well as other features of the premolars and the bone structure, the close relationship was established.
Outer systematics.
Cetartiodactyla is classified within the higher mammals to the superiority of the Laurasiatheria, a mammalian group named after their putative origins in the extinct continent Laurasia. Which major groups within the Laurasiatheria and Cetartiodactyla are more closely related is still unresolved; however, the previously proposed set of ungulates is not a natural group. Various molecular studies can recognize different possible lineages: a taxon together with the perissodactyls and ferae (pangolins and carnivores), or a common taxon, Fereuungulata, but what remains unclear is whether the odd-toed ungulates are more closely related to Cetartiodactyla or ferae. Another recently drawn up hypothesis assigns Perissodactyla, ferae and bats to a taxon, pegasoferae, together and sees Cetartiodactyla as its sister group.
Anatomy.
Artiodactyls have similar characteristics between each other, particularly the construction of the limbs. One common feature (synapomorphies) is the special construction of the anklebone with two castors (trochlea tali proximalis and distalis). However, the discovery of this special anklebone in archaeocetes has had many, in the 2001 discussion about systematics, rework their hunting methods.
Artiodactyls are generally medium to large quadrupeds. There are two major body types, which differ significantly in physical aspects. Suinas and hippopotamuses are characterized by a stocky body, short legs, and a large head. Camels and ruminants on the other hand have a more slender build and lanky legs. Size varies considerably, as the smallest member, the mouse deer, often reaches only in body length and a weight of , whereas the largest members, the hippopotamus, can grow up to in length and in head weight, and the giraffe can grow to be high and in body length. All species display some form of sexual dimorphism: the males are consistently larger and heavier than the females; gender differences also exist in the forehead weapons, as in deer where usually only the males boast antlers, and the horns of bovines are usually small or not present in the females, and the coat of Blackbucks differ between the genders in that the males coat is much darker than that of the females.
Almost all members of this order have fur. One exception is the nearly hairless hippopotamus. Fur coverage varies in length and coloration depending on the habitat. Species in cooler regions can shed their coat. Camouflaged coats come in colors of yellow, gray, brown, or black tones.
Limbs.
Even-toed ungulates bear their name; because, they have an even number of toes (two or four) - in some peccaries the hind legs have a reduction in the number of toes to three. The central axis of the leg is between the third and fourth toe. The first toe is missing in modern artiodactyls, and can only be found in now extinct genera. The second and fifth toes are designed differently between species: in the hippos, they are directed forward and fully functional; for the other even-toed ungulates, they are arranged in reverse or completely reduced. For pigs and deer, the toes are still in contact with soft, muddy ground and increase the contact surface area. In most cases, however, they no longer touch the ground. In some groups, like the camels and giraffes, regression has progressed so far that the second and fifth toe are not even present.
When camels have only two toes present, the claws are transformed into nails. These claws are made of keratin, just like human nails, and consist of three parts: the plate (top and sides), the sole (bottom), and the bale (rear), which can; however, grow in varying degrees. In general, the claws of the forelegs are wider and blunter than the hind legs and the gape is farther apart. Aside from camels, all even-toed ungulates put just the tip of the foremost phalanx on the ground. In camels, the horn formations on the feet reduces the toes that rest on an elastic pad made of connective tissue, which forms a wide sole area.
In even-toed ungulates, there is a tendency to coalescence metapodials (metacarpal and metatarsals). For Suinas and hippopotamuses, they are still isolated and coupled only by a taut connective tissue. 
The bones of the stylopodium (upper arm or thigh bone) and zygopodiums (tibia and fibula) are usually elongated. The muscles of the limbs are predominantly localized which ensures that artiodactyls often have very slender legs. A clavicle is never present, and the scapula is very agile and swings back and forth for added mobility when running.
The special construction of the legs ensures a rigid position of the lower limbs. Rotational movement of the legs are nearly impossible, but the immobility causes a higher stability when running at high speeds. In addition, many smaller artiodactyls have a very flexible body, contributing to their speed by increasing their stride length. The selection pressure to obtain high speeds with the flight of the specialized construction of the limbs increases the energy saved during slow movement, such as during food intake.
Head and teeth.
Many even-toed ungulates have a relatively large head. The facial skeleton is elongated and rather narrow, and the nasal bones run forward in one or two points. The frontal bone is enlarged backwards and displaces the parietal bone, which forms only part of the side of the cranium, especially in ruminants.
Horns and antlers.
Four families of even-toed ungulates have cranial appendages. These Pecora, (with the exception of the Moschidae), have one of four types of cranial appendages: horns, antlers, ossicones, or pronghorns.
True horns have a bone core that is covered in a permanent sheath of keratin, and are found only in the bovids. Antlers are bony structures that are shed and replaced each year in members of the family Cervidae. They grow from a permanent outgrowth of the frontal bone called the pedicle. and can be branched, as in the White-tailed deer ("Odocoileus virginianus"), or palmate, as in the Moose ("Alces alces"). Ossicones are permanent bone structures that fuse to the frontal or parietal bones during the lifetime of an animal and are found only in the Giraffidae. Pronghorns, while similar to horns in that they have keratinous sheaths covering permanent bone cores, are deciduous - and can be shed like antlers.
All these cranial appendages can serve for posturing, battling for mating privilege, and for defense. In almost all cases, they are sexually dimorphic, and often found only on the males.
Teeth.
The dentition of artiodactyls varies between species; it can, however, discern two trends. The Suina and hippopotamuses have a relatively large number of teeth (with some pigs containing 44). The dentition is more adapted to a squeezing mastication, which is the tendency for omnivores such as pigs. With camels and ruminants, the number of teeth is reduced; there is often a yawning diastema, a designated gap in the teeth where the molars are aligned on a mill for crushing plant matter.
The incisors are often reduced in ruminants, as they are completely absent in the upper jaw, and they instead press the lower incisors against a dental plate. The canines are pronounced differently: in the Suina, they are enlarged and tusk-like, and are used for digging in the ground and for defense; in ruminants, the upper canine in males of species without end arms (mouse deer, musk deer, water deer...) is enlarged and used as a weapon in the battle for mating privileges; species with frontal weapons, usually, are missing the upper canine. The lower canines of ruminants resemble the incisors, so that these animals have eight uniform teeth in the front part of the lower jaw.
The molars of porcine provide a few bumps. In contrast, the camels and ruminants have bumps that are crescent-shaped cusps (selenodont).
Senses.
Their environment primarily serves a sense of smell, which is very well developed in artiodactyls, as with most mammals. Their sense of hearing is also well-developed. Unlike many other mammals, they have a poor sense of sight which is least pronounced in ruminants and camels. Above all, motion perception is developed, and stationary objects are not well perceived. Similar to many other animals, which must be constantly mindful of predators that are eye laterally attached to the head, they have an almost complete panoramic view which helps with the earliest possible detection of threats.
Digestive system.
Pigs have a simple sack-shaped stomach, unlike other even-toed ungulates.
Deer have such a multi-chambered stomach, as with all ruminants, which is used for better utilization of the plant food.
As an adaptation to the indigestible plant food, artiodactyls have some peculiarities of the digestive tract developed which are especially strong in ruminants. The mouth often has additional salivary glands and the oral mucosa is often heavily callused to avoid injury from hard plant parts and to allow easier transport of roughly chewed food.
The stomach of ruminants is divided into three to four sections: the rumen, the reticulum, the omasum, and the abomasum. Rumination occurs in the ruminants (Ruminantia and Tylopoda), whereby food is regurgitated and rechewed then broken down by microbes in the stomach. After ingestion of plant material, it is mixed with saliva in the rumen and reticulum and separates into layers of solid and liquid material. The solids lump together to form a bolus (also known as the cud), this is regurgitated by reticular contractions while the glottis is closed. When the bolus enters the mouth, the fluid is squeezed out with the tongue and reswallowed. The bolus is chewed slowly to completely mix it with saliva and to break down the particle size. Ingested food passes to the 'fermentation chamber' (rumen and reticulum) where it is kept in continual motion by rhythmic contractions of this organ. Cellulytic microbes (bacteria, protozoa, and fungi) produce cellulase, which is needed to break down the cellulose found in plant material. Without this mutual symbiosis, ruminants would find plant material indigestible. This form of digestion has two advantages: the indigestible plants are best digested and utilized, and the duration of the actual food consumption is - especially with the unfavorable perception of the environmental posture with the head close to the ground - shortened, which is, in view of the threat of predators, an advantage; rumination can take place in sheltered places.
Tylopoda (camels, llamas, and alpacas) and chevrotains have three-chambered stomachs, while the rest of Ruminantia have four-chambered stomachs. The handicap of a heavy digestive system has increased selective pressure for limb bone adaptations to escape predators. Most species within Suina have a simple two-chambered stomach that allows an omnivorous diet, the babirusa, however, is a herbivore. They have extra maxillary teeth to allow for the proper mastication of plant material. Most of the fermentation occurs with the help of cellulolytic microorganisms within the caecum. Peccaries, however, have a complex stomach that contains four compartments. Microbial fermentation with the formation of high volatile fatty acid levels has been observed in the fore stomach; it has been proposed that their complex fore stomach is a means to slow digestive passage and increase digestive efficiency. Hippopotamuses have three-chambered stomachs and do not ruminate. They consume around 68 kg of grass and other plant matter each night. They may cover large distances (up to 20 miles) to obtain their food, which they digest with the help of microbes that produce cellulase. Their closest living relatives, the whales, are obligate carnivores.
Genitourinary system.
The construction of the urinary and sexual organs of even-toed ungulates also shows some peculiarities. The penis is curved S-shape at rest and rests in a pocket under the skin on the belly. The corpora cavernosa is developed only slightly and the erection causes mainly an extension of this curvature and thus an extension, but a thickening, of the penis. This construction of the penis is found in a similar manner with cetaceans. The testicles are located in the scrotum and thus outside the abdominal cavity. The ovaries of many females make a descent (prolapse ovary) - comparable to the testicle descent of many male mammals - and are close to the pelvic inlet at the level of the fourth lumbar vertebra. The uterus has two horns (uterus bicornis).
The number of mammary glands is variable and correlates, as in all mammals, with the litter size. In pigs, there are two rows of teats are lined from the armpit to the groin area. This is due to their large litter size, the biggest out of all even-toed ungulates. In most cases, however, due to a reduction of the number of young, even-toed ungulates have only one or two pairs of teats. These form, in some species, an udder in the groin region.
Secretory glands in the skin are present in virtually all types and can be located in different places, as in the eyes, behind the horns, the neck or back, on the feet, or in the anal region.
Distribution and habitat.
Artiodactyls are native to almost all parts of the world, with the exception of Oceania - Australia, New Zealand, and the many remote pacific islands - with pigs being feral, and Antarctica. Today, the latter inhabit Africa and Asia. In the Americas, they are relatively species-poor, and are found only in South America, where only peccaries, llamas, vicunas, and capreolinae occur. Humans have introduced different artiodactyls worldwide as hunting animals. For example, pigs, as these animals are found almost everywhere today, where there are, or were, people.
Artiodactyls inhabit almost every habitat, from tropical rain forests and steppes to the desert areas and high mountain regions and to the oceans (Cetacea). The greatest biodiversity prevails in open habitats such as grasslands and open forests. These animals are marked bottom dwellers, and only a few species lead a semi-aquatic, e.g., hippos. Some species have colonized the high mountains and can climb excellently.
Lifestyle.
Social behavior.
Artiodactyls often live in groups.
The social behavior of even-toed ungulates varies from species to species. Generally, however, there is a tendency to merge into larger groups, but there are also solitary or in pairs. Species living in groups, often have a hierarchy, both among males and females. But some species also live in harem groups, which means that a single male gathers several females and their common offspring around and no other rivals are tolerated. In other species the females and juveniles make up for the greater part of the year on their own groups, while males are solitary or live in bachelor groups and seek the females groups only during the mating season. Many occur during mating season for fierce fighting around the mating privilege between the males, which are discharged to the end weapons.
Many artiodactyls are territorial and mark their territory, for example, with glandular secretions or urine. In addition to year-round sedentary species, there are animals that take seasonal migrations in search of better grazing places.
There are diurnal, crepuscular, and nocturnal members as well as species associated with the day-night scheme which may vary depending on the season or habitat.
Reproduction and life expectancy.
Generally, even-toed ungulates have a tendency to long gestation period, smaller litter size and high level of development of the newborn. As with many other mammals, species in temperate or polar regions have a fixed mating season, while breeding can take place year-round in more tropical areas. They have a polygynous mating behavior, meaning a male so often pairs with several females, and competition will not be tolerated. The copulation is usually done by the mammals typical "ride up". In camels, exclusively, it is performed while lying down.
The length of the gestation period varies four–five months for porcine, deer, and musk deer, six to ten months with hippos, deer and bovines, ten to thirteen months with camels, and fourteen to fifteen months with giraffes. Most deliver one or two babies, but some pigs can deliver up to ten.
The newborns are precocial and come with open eyes and, with the exception of generally hairless hippos, hairy to the world. In deer and pigs, the striped or spotted coat in juveniles disappear as they grow. The juveniles of some species spend their first weeks with their mother in a safe storage location, where others may soon run after birth and follow the herd within a few hours or days.
The life expectancy is typically twenty to thirty years, as in many mammals smaller species often have a shorter lifespan than larger species. The oldest animals like hippos, cows and camels, can reach forty to fifty years.
Predators and parasites.
Artiodactyls have different natural predators depending on their size and habitat. There are several carnivores who would prey on such mammals such as cats, dogs or bears. Other predators are, for example, crocodiles, large raptors and, for small species and young animals, giant snakes.
Parasitic infection can come around from nematodes, botflies, fleas, louse or flukes, but they have debilitating effects only when the infestation is severe.
Interactions with humans.
Domestication.
Artiodactyls have been hunted by primitive humans for various reasons: for meat, to process their fur into clothing, and to use their forehead weapons, bones and teeth, as weapons or tools. The domestication of animals began around the 8,000 B.C.E. To date, humans have domesticated goats, sheep, cattle and pigs. Initially, livestock was used primarily as food suppliers, but then later, around 3,000, the animals were used for work activities. Clear evidence exists of antelope being used for food 2 million years ago in the Olduvai Gorge, part of the Great Rift Valley. Cro-Magnons relied heavily on reindeer for food, skins, tools, and weapons; with dropping temperatures and increased reindeer numbers at the end of the Pleistocene, they became the prey of choice. By around 12,500 years ago, reindeer remains accounted for 94% of bones and teeth found in a cave above the Céou River.
Today, artiodactyls are kept for various reasons. These are primarily for their meat, their milk, and the processing of their wool, fur, or hide (leather) into clothing. They are also used for work, to ride, or are used as pack animals, such as the domestic cattle, the water buffalo, the yak, or camels. Cattle are the basis of a multibillion-dollar industry worldwide. The international trade in beef in 2000 was over US$30 billion and represented only 23% of world beef production.
Two basic types of domestication were used. On one hand, the animals in different breeds were bred, which are spread throughout the world and partly differ significantly from the wild species, as with domestic cattle, domestic pigs, domestic goats and domestic sheep. Other pets have largely remained in their region of origin and, when compared with the wild species, changed little, like the reindeer, some cows (like the water buffalo, the banteng, the gaur, and yak), and camels (like the dromedary, the llama, and alpaca).
Some are not only used for food assistance, but also for sport. These practices are conducted under partly severe criticism and have driven some species, such as the Alpine ibex and the Arabian Oryx, to the brink of extinction.
Threats.
The hazard level of each even-toed ungulate is different. Some species are synanthropic (such as the wild boar) and can spread their range or have been brought by humans as farm animals or runaway pets in regions where they were not indigenous to. Some artiodactyls also benefit from the fact that their predators were severely decimated as competitors of the ranchers, such as "Thylacine".
Conversely, many artiodactyls have declined significantly in their population, and some were even eradicated. The reasons for this is over-hunting, and, more recently though, increasing habitat destruction. Currently extinct are several gazelle species (such as the Arabian gazelle), the Malagasy hippopotamus, the Blue Buck, and the Schomburgk's Deer. Two species, the Arabian Oryx and the Saudi Gazelle, are considered by the IUCN as being extinct in the wild. 14 species are considered Critically Endangered, including the Addax, the Kouprey, the red deer, Przewalski's gazelle, the Saiga, and the pygmy hog. Twenty four species are considered endangered.
Evolution.
The oldest fossils of even-toed ungulates date back to the early Eocene (about 55 million years ago). Since these findings almost simultaneously appeared in Europe, Asia and North America, it is very difficult to accurately determine the origin of artiodactyls. These ancient creatures are classified in the family Dichobunidae - their best-known and best-preserved member is "Diacodexis". These were small animals, with some as small as a hare, with a slim build, lanky legs, and a long tail. The hind legs were much longer than the front legs. The early to middle Eocene saw the emergence of the ancestors of most of today's mammals. The phylogeny of even-toed ungulates proceeded relatively uniformly and unspectacularly, giant or bizarre animals (such as perissodactyls), are hardly known in this group.
The earliest cetaceans evolved in the early Eocene (49 million years ago) and have believed to have developed in the Indian subcontinent. From then on, they separated from the other even-toed ungulates, due to the aquatic life, into their own lineage.
Two formerly widespread, but now extinct, groups of even-toed ungulates were "Entelodont" and Anthracotheriidae. The "Entelodont" existed from the middle Eocene to the early Miocene in Eurasia and North America. They had a stocky body with short legs and a massive head, which was characterized by two humps on the lower jaw bone. Anthracotheriidae had a large, porcine build, with short legs and an elongated muzzle. This group appeared in the Middle Eocene up until the Pliocene, and spread throughout Eurasia, Africa, and North America. Anthracotheriidae are thought to be the ancestors of hippos, and, likewise, they probably led a similar aquatic lifestyle. The hippos even appeared in the Late Miocene and occupied Africa and Asia - they never got to the Americas.
The camels (Tylopoda) were, during large parts of the Cenozoic, limited to North America; early forms like "Cainotheriidae" occupied Europe. Among the North American camels included groups like the stocky, short-legged "Merycoidodontidae" which was equipped with frontal weapons. They first appeared in the late Eocene and developed a great diversity of species in North America. Only in the late Miocene or early Pliocene did they migrate from America into Eurasia. North American variety became extinct around 10,000 years ago.
Members of the Suina have been around since the Eocene. In the late Eocene or Oligocene, the two still existing families remained restricted to Eurasia and Africa, and the peccaries, which became extinct in the Old World, exist today only in America.
Sivatherium was a group consisting of the giraffes with deer-like forehead weapons, and were the predecessors of giraffes and bovines.
The ruminants were designed with many early forms. These early forms, which are classified as Tragulina, lived up to the Miocene in Africa, Eurasia and North America, and then died out, except for the mouse deer. In the Oligocene or Miocene, the other members, with the majority remained confined to the Old World, developed. The giraffes (Giraffidae), emerging alongside the existing species, developed the stag-like end weapons. The deer (Cervidae) developed numerous species, but remained limited to Eurasia. Bovines and deer arrived relatively late in North America, however, the group with Gabelhorn carriers spread with numerous species, of which today only one species, the pronghorn, survived.
South America was settled by the even-toed ungulates only in Pliocene some three million years ago when the land bridge at the Isthmus of Panama formed. With peccaries, llamas and deceit deer, the South American artiodactyls, compared to the other continents, has remained poor in species.

</doc>
<doc id="46765" url="https://en.wikipedia.org/wiki?curid=46765" title="François Quesnay">
François Quesnay

François Quesnay (; June 4, 1694 – December 16, 1774) was a French economist of the Physiocratic school. He is known for publishing the "Tableau économique" (Economic Table) in 1758, which provided the foundations of the ideas of the Physiocrats. This was perhaps the first work attempting to describe the workings of the economy in an analytical way, and as such can be viewed as one of the first important contributions to economic thought. His "Le Despotisme de la Chine", written in 1767, describes Chinese politics and society, and his own political support for constitutional Oriental despotism.
Life.
Quesnay was born at Méré near Versailles, the son of an advocate and small landed proprietor. Apprenticed at the age of sixteen to a surgeon, he soon went to Paris, studied medicine and surgery there, and, having qualified as a master-surgeon, settled down to practice at Mantes. In 1737 he was appointed perpetual secretary of the academy of surgery founded by François Gigot de la Peyronie, and became surgeon in ordinary to King Louis XV. In 1744 he graduated as a doctor of medicine; he became physician in ordinary to the king, and afterwards his first consulting physician, and was installed in the Palace of Versailles. His apartments were on the "entresol", whence the Réunions de l'entresol received their name. Louis XV esteemed Quesnay highly, and used to call him his thinker. When he ennobled him he gave him for arms three flowers of the pansy (derived from "pensée", in French meaning "thought"), with the Latin motto "Propter cogitationem mentis".
He now devoted himself principally to economic studies, taking no part in the court intrigues which were perpetually going on around him. Around 1750 he became acquainted with Jacques C. M. V. de Gournay (1712–1759), who was also an earnest inquirer in the economic field; and round these two distinguished men was gradually formed the philosophic sect of the Économistes, or, as for distinction's sake they were afterwards called, the Physiocrates. The most remarkable men in this group of disciples were the elder Mirabeau (author of "L'Ami des hommes", 1756–60, and "Philosophie rurale", 1763), Nicolas Baudeau ("Introduction a la philosophie économique", 1771), G. F. Le Trosne ("De l'ordre social", 1777), André Morellet (best known by his controversy with Galiani on the freedom of the grain trade during the Flour War), Mercier Larivière, and du Pont de Nemours. Adam Smith, during his stay on the continent with the young Duke of Buccleuch in 1764–1766, spent some time in Paris, where he made the acquaintance of Quesnay and some of his followers; he paid a high tribute to their scientific services in his "Wealth of Nations".
Quesnay married in 1718, and had a son and a daughter; his grandson by the former was a member of the first Legislative Assembly. He died on December 16, 1774, having lived long enough to see his great pupil, Anne Robert Jacques Turgot, Baron de Laune, in office as minister of finance.
Works.
His economic writings are collected in the 2nd vol. of the "Principaux économistes", published by Guillaumin, Paris, with preface and notes by Eugène Daire; also his "OEuvres économiques et philosophiques" were collected with an introduction and note by August Oncken (Frankfort, 1888); a facsimile reprint of the "Tableau économique", from the original MS., was published by the British Economic Association (London, 1895). His other writings were the article "Évidence" in the "Encyclopédie", and "Recherches sur l'évidence des vérites geometriques", with a "Projet de nouveaux éléments de géometrie", 1773. Quesnay's Eloge was pronounced in the Academy of Sciences by Grandjean de Fouchy (see the Recueil of that Academy, 1774, p. 134). See also F.J. Marmontel, "Mémoires"; "Mémoires de Mme. du Hausset"; H. Higgs, "The Physiocrats" (London, 1897).
Economics.
In 1758 he published the "Tableau économique" (Economic Table), which provided the foundations of the ideas of the Physiocrats. This was perhaps the first work to attempt to describe the workings of the economy in an analytical way, and as such can be viewed as one of the first important contributions to economic thought.
The publications in which Quesnay expounded his system were the following: two articles, on "Fermiers" (Farmers) and on "Grains", in the "Encyclopédie" of Diderot and D'Alembert (1756, 1757); a discourse on the law of nature in the "Physiocratie" of Dupont de Nemours (1768); "Maximes générales de gouvernement economique d'un royaume agricole" (1758), and the simultaneously published "Tableau économique avec son explication, ou extrait des économies royales de Sully" (with the celebrated motto, "Pauvres paysans, pauvre royaume; pauvre royaume, pauvre roi"); "Dialogue sur le commerce et les travaux des artisans"; and other minor pieces.
The "Tableau économique", though on account of its dryness and abstract form it met with little general favor, may be considered the principal manifesto of the school. It was regarded by the followers of Quesnay as entitled to a place amongst the foremost products of human wisdom, and is named by the elder Mirabeau, in a passage quoted by Adam Smith, as one of the three great inventions which have contributed most to the stability of political societies, the other two being those of writing and of money. Its object was to exhibit by means of certain formulas the way in which the products of agriculture, which is the only source of wealth, would in a state of perfect liberty be distributed among the several classes of the community (namely, the productive classes of the proprietors and cultivators of land, and the unproductive class composed of manufacturers and merchants), and to represent by other formulas the modes of distribution which take place under systems of Governmental restraint and regulation, with the evil results arising to the whole society from different degrees of such violations of the natural order. It follows from Quesnay's theoretic views that the one thing deserving the solicitude of the practical economist and the statesman is the increase of the net product; and he infers also what Smith afterwards affirmed, on not quite the same ground, that the interest of the landowner is strictly and indissolubly connected with the general interest of the society. A small edition de luxe of this work, with other pieces, was printed in 1758 in the Palace of Versailles under the king's immediate supervision, some of the sheets, it is said, having been pulled by the royal hand. Already in 1767 the book had disappeared from circulation, and no copy of it is now procurable; but, the substance of it has been preserved in the "Ami des hommes" of Mirabeau, and the "Physiocratie" of Dupont de Nemours.
Orientalism and China.
Quesnay is known for his writings on Chinese politics and society. His book "Le Despotisme de la Chine", written in 1767, describes his views of the Chinese imperial system. He was supportive of the meritocratic concept of giving scholars political power, without the cumbersome aristocracy that characterized French politics, and the importance of agriculture to the welfare of a nation. The phrase "laissez-faire", coined by fellow Physiocrat Vincent de Gournay, is postulated to have come from Quesnay's writings on China. Gregory Blue writes that Quesnay "praised China as a constitutional despotism and openly advocated the adoption of Chinese institutions, including a standardized system of taxation and universal education." Blue speculates that this may have influenced the 1793 establishment of the Permanent Settlement in Bengal by the British Empire. Quesnay's interests in Orientalism has also been a source of criticism. Carol Blum, in her book "Strength in Numbers" on 18th century France, labels Quesnay an "apologist for Oriental despotism."
Because of his admiration of Confucianism, Quesnay followers bestowed him with the title "Confucius of Europe." Quesnay's infatuation for Chinese culture, as described by Jesuits, led him to persuade the son of Louis XV to mirror the "plowing of sacred land" by the Chinese emperor to symbolize the link between government and agriculture.

</doc>
<doc id="46769" url="https://en.wikipedia.org/wiki?curid=46769" title="Léon Walras">
Léon Walras

Marie-Esprit-Léon Walras (; December 16, 1834 – January 5, 1910) was a French mathematical economist. He formulated the marginal theory of value (independently of William Stanley Jevons and Carl Menger) and pioneered the development of general equilibrium theory.
Life and career.
Walras was the son of French economist Auguste Walras. His father was a school administrator and not a professional economist, yet his economic thinking had a profound effect on his son. He found the value of goods by setting their scarcity relative to human wants.
Walras enrolled in the Paris École des Mines de Paris, but grew tired of engineering. He also tried careers as a bank manager, journalist, romantic novelist and a clerk at a railway company before turning to economics. Walras received an appointment as the professor of political economy at the University of Lausanne.
Walras also inherited his father's interest in social reform. Much like the Fabians, Walras called for the nationalization of land, believing that land's value would always increase and that rents from that land would be sufficient to support the nation without taxes.
Another of Walras' influences was Augustin Cournot, a former schoolmate of his father. Through Cournot, Walras came under the influence of French Rationalism and was introduced to the use of mathematics in economics.
Professor of Political Economy at the University of Lausanne, Switzerland, Walras is credited for having founded what subsequently became known, under direction of his Italian disciple, the economist and sociologist Vilfredo Pareto, as the Lausanne school of economics.
Because for a long time most of Walras' publications were only available in French, only a relatively small section of the economics profession really became familiar with his work. This changed in the 1950s, largely due to the work of William Jaffé, the translator of Walras' main works, and the editor of his "Complete Correspondence" (1965). Walras' work was also too mathematically complex for many contemporary readers of his time. On the other hand, it has a great insight into the market process under idealized conditions so it has been far more read in the modern era.
Marginalist theory.
Although Walras came to be regarded as one of the three leaders of the marginalist revolution,
he was not familiar with the two other leading figures of marginalism, William Stanley Jevons and Carl Menger, and developed his theories independently.
General equilibrium theory.
In 1874 and 1877 Walras published "Elements of Pure Economics", a work that led him to be considered the father of the general equilibrium theory. The problem that Walras set out to solve was one presented by Cournot, that even though it could be demonstrated that prices would equate supply and demand to clear individual markets, it was unclear that an equilibrium existed for all markets simultaneously.
Walras constructed his basic theory of general equilibrium by beginning with simple equations and then increasing the complexity in the next equations. He began with a two-person bartering system, then moved on to the derivation of downward-sloping consumer demands. Next he moved on to exchanges involving multiple parties, and finally ended with credit and money.
Walras created a system of simultaneous equations in an attempt to solve Cournot's problem "(which supposedly Walras at first thought was complete merely because the number of equations equalled the number of unknowns)"
The crucial step in the argument was Walras' Law which states that any particular market must be in equilibrium, if all other markets in an economy are also in equilibrium. Walras' Law hinges on the mathematical notion that excess market demands (or, inversely, excess market supplies) must sum to zero. This means that, in an economy with n markets, it is sufficient to solve n-1 simultaneous equations for market clearing. Taking one good as the numéraire in terms of which prices are specified, the economy has n-1 prices that can be determined by the equation, so an equilibrium should exist. Although Walras set out the framework for thinking about the existence of equilibrium clearly and precisely his attempt to demonstrate existence by counting the number of equations and variables was severely flawed: it is easy to see that not all pairs of equations in two variables have solutions. A more rigorous version of the argument was developed independently by Lionel McKenzie and the pair Kenneth Arrow and Gérard Debreu in the 1950s.
Amoral definition of utility.
Léon Walras provides an amoral definition of economic utility:
I state that things are useful as soon as they may serve whatever usage, as soon as they match whatever need and allow its fulfillment. Thus, there is here no point to deal with 'nuances' by way of which one classes, in the language of everyday conversation, utility beside what is pleasant and between the necessary and the superfluous. Necessary, useful, pleasant and superfluous, all of this is, for us, more or less useful. There is here as well no need to take into account the morality or immorality of the need that the useful things matches and permits to fulfill. Whether a substance is searched for by a doctor to heal an ill person, or by a assassin to poison his family, this is an important question from other points of view, albeit totally indifferent from ours. The substance is useful, for us, in both cases, and may well be more useful in the second case than in the first one.
In Walras's theory of value, value is thus totally independent of the common meaning of "value" or "utility". Production or increase of "value", in fact monetary amounts as for instance measured in profit or GNP, is independent of notions like a just or fair society or a better world. This is a fundament of modern "neoliberalism" or neoclassical economics.
Reception.
In 1941 George Stigler wrote about Walras: ""There is no general history of economic thought in English which devotes more than passing reference to his work. … This sort of empty fame in English-speaking countries is of course attributable in large part to Walras' use of his mother tongue, French, and his depressing array of mathematical formulas."" What ever caused the u-turn of Walras' consideration in the US, the influx of German-speaking scientists – the German version of the "Éléments" is of 1881 – after Hitler's rule was the initial start. To Schumpeter: "Walras is … greatest of all economists. His system of economic equilibrium, uniting, as it does, the quality of ‘revolutionary" creativeness with the quality of classic synthesis, is the only work by an economist that will stand comparison with the achievements of theoretical physics".
Notes.
« Je dis que les choses sont utiles dès qu'elles peuvent servir à un usage quelconque, dès qu'elles répondent à un besoin quelconque et en permettent la satisfaction. Ainsi, il n'y a pas à s'occuper ici des nuances par lesquelles on classe, dans le langage de la conversation courante, l'utilité à côté de l'agréable entre le nécessaire et le superflu. Nécessaire, utile, agréable et superflu, tout cela, pour nous, est plus ou moins utile. Il n'y a pas davantage à tenir compte ici de la moralité ou de l'immoralité du besoin auquel répond la chose utile et qu'elle permet de satisfaire. Qu'une substance soit recherchée par un médecin pour guérir un malade ou pour un assassin pour empoisonner sa famille, c'est une question très importante à d'autres points de vue, mais tout à fait indifférente au nôtre. La substance est utile, pour nous, dans les deux cas, et peut l'être plus dans le second que dans le premier. » "Elements d'économie pure, ou théorie de la richesse sociale", 1874

</doc>
<doc id="46770" url="https://en.wikipedia.org/wiki?curid=46770" title="Fixed-wing aircraft">
Fixed-wing aircraft

[[File:Tarom.b737-700.yr-bgg.arp.jpg|thumb|300px|A Boeing 737 aeroplane -
A fixed-wing aircraft is an aircraft, such as an aeroplane, which is capable of flight using wings that generate lift caused by the vehicle's forward airspeed and the shape of the wings. Fixed-wing aircraft are distinct from rotary-wing aircraft, in which the wings form a rotor mounted on a spinning shaft, and ornithopters, in which the wings flap in similar manner to a bird.
Glider fixed-wing aircraft, including free-flying gliders of various kinds and tethered kites, can use moving air to gain height.
Powered fixed-wing aircraft that gain forward thrust from an engine (aeroplanes) include powered paragliders, powered hang gliders and some ground effect vehicles.
The wings of a fixed-wing aircraft are not necessarily rigid; kites, hang-gliders, variable-sweep wing aircraft and aeroplanes using wing-warping are all fixed-wing aircraft.
Most fixed-wing aircraft are flown by a pilot on board the aircraft, but some are designed to be remotely or computer-controlled.
History.
Early kites.
Kites were used approximately 2,800 years ago in China, where materials ideal for kite building were readily available. Some authors hold that leaf kites were being flown much earlier in what is now Indonesia, based on their interpretation of cave paintings on Muna Island off Sulawesi. By at least 549 AD paper kites were being flown, as it was recorded in that year a paper kite was used as a message for a rescue mission. Ancient and medieval Chinese sources list other uses of kites for measuring distances, testing the wind, lifting men, signaling, and communication for military operations.
Stories of kites were brought to Europe by Marco Polo towards the end of the 13th century, and kites were brought back by sailors from Japan and Malaysia in the 16th and 17th centuries. Although they were initially regarded as mere curiosities, by the 18th and 19th centuries kites were being used as vehicles for scientific research.
Gliders and powered models.
Around 400 BC in Greece, Archytas was reputed to have designed and built the first artificial, self-propelled flying device, a bird-shaped model propelled by a jet of what was probably steam, said to have flown some . This machine may have been suspended for its flight.
Some of the earliest recorded attempts with gliders were those by the 9th-century poet Abbas Ibn Firnas and the 11th-century monk Eilmer of Malmesbury; both experiments injured their pilots.
In 1799, Sir George Cayley set forth the concept of the modern aeroplane as a fixed-wing flying machine with separate systems for lift, propulsion, and control. Cayley was building and flying models of fixed-wing aircraft as early as 1803, and he built a successful passenger-carrying glider in 1853. In 1856, Frenchman Jean-Marie Le Bris made the first powered flight, by having his glider ""L'Albatros artificiel"" pulled by a horse on a beach. In 1884, the American John J. Montgomery made a controlled flight in a glider as a part of a series of gliders built between 1883-1886. Other aviators who made similar flights at that time were Otto Lilienthal, Percy Pilcher, and Octave Chanute.
In the 1890s, Lawrence Hargrave conducted research on wing structures and developed a box kite that lifted the weight of a man. His box kite designs were widely adopted. Although he also developed a type of rotary aircraft engine, he did not create and fly a powered fixed-wing aircraft.
Powered flight.
Sir Hiram Maxim built a craft that weighed 3.5 tons, with a 110-foot (34-meter) wingspan that was powered by two 360-horsepower (270-kW) steam engines driving two propellers. In 1894, his machine was tested with overhead rails to prevent it from rising. The test showed that it had enough lift to take off. The craft was uncontrollable, which Maxim, it is presumed, realized, because he subsequently abandoned work on it.
The Wright brothers' flights in 1903 with their "Flyer I" are recognized by the "Fédération Aéronautique Internationale" (FAI), the standard setting and record-keeping body for aeronautics, as "the first sustained and controlled heavier-than-air powered flight". By 1905, the Wright Flyer III was capable of fully controllable, stable flight for substantial periods.
In 1906, Brazilian inventor Alberto Santos Dumont designed, built and piloted an aircraft that set the first world record recognized by the Aéro-Club de France by flying the 14 bis in less than 22 seconds. The flight was certified by the FAI. This was the first controlled flight, to be officially recognised, by a plane able to take off under its own power alone without any auxiliary machine such as a catapult.
The Bleriot VIII design of 1908 was an early aircraft design that had the modern monoplane tractor configuration. It had movable tail surfaces controlling both yaw and pitch, a form of roll control supplied either by wing warping or by ailerons and controlled by its pilot with a joystick and rudder bar. It was an important predecessor of his later Bleriot XI Channel-crossing aircraft of the summer of 1909.
World War I.
World War I served as a testbed for the use of the aircraft as a weapon. Initially seen by the generals as a "toy", aircraft demonstrated their potential as mobile observation platforms, then proved themselves to be machines of war capable of causing casualties to the enemy. The earliest known aerial victory with a synchronised machine gun-armed fighter aircraft occurred in 1915, by German Luftstreitkräfte "Leutnant" Kurt Wintgens. Fighter aces appeared; the greatest (by number of air victories) was Manfred von Richthofen.
Following WWI, aircraft technology continued to develop. Alcock and Brown crossed the Atlantic non-stop for the first time in 1919. The first commercial flights took place between the United States and Canada in 1919.
World War II.
Aeroplanes had a presence in all the major battles of World War II. They were an essential component of the military strategies of the period, such as the German Blitzkrieg or the American and Japanese aircraft carrier campaigns of the Pacific.
Military gliders were developed and used in several campaigns, but they did not become widely used due to the high casualty rate often encountered. The Focke-Achgelis Fa 330 "Bachstelze" (Wagtail) rotor kite of 1942 was notable for its use by German submarines.
Before and during the war, both British and German designers were developing jet engines to power aeroplanes. The first jet aircraft to fly, in 1939, was the German Heinkel He 178. In 1943 the first operational jet fighter, the Messerschmitt Me 262, went into service with the German Luftwaffe and later in the war the British Gloster Meteor entered service but never saw action — top airspeeds of aircraft for that era went as high as 1,130 km/h (702 mph), with the early July 1944 unofficial record flight of the German Me 163B V18 rocket fighter prototype.
Postwar.
In October 1947, the Bell X-1 was the first aircraft to exceed the speed of sound.
In 1948–49, aircraft transported supplies during the Berlin Blockade. New aircraft types, such as the B-52, were produced during the Cold War.
The first jet airliner, the de Havilland Comet, was introduced in 1952, followed by the Soviet Tupolev Tu-104 in 1956. The Boeing 707, the first widely successful commercial jet, was in commercial service for more than 50 years, from 1958 to 2010. The Boeing 747 was the world's biggest passenger aircraft from 1970 until it was surpassed by the Airbus A380 in 2005.
Classes of fixed-wing aircraft.
Airplane/aeroplane.
An aeroplane (also known as an airplane or simply a plane) is a powered fixed-wing aircraft that is propelled forward by thrust from a jet engine or propeller. Planes come in a variety of sizes, shapes, and wing configurations. The broad spectrum of uses for planes includes recreation, transportation of goods and people, military, and research.
Seaplane.
A seaplane is a fixed-wing aircraft capable of taking off and landing (alighting) on water. Seaplanes that can also operate from dry land are a subclass called amphibian aircraft. These aircraft were sometimes called hydroplanes. Seaplanes and amphibians are usually divided into two categories based on their technological characteristics: floatplanes and flying boats.
Powered gliders.
Many forms of glider (see below) may be modified by adding a small power plant. These include:
Ground effect vehicle.
A ground effect vehicle (GEV) is a craft that attains level flight near the surface of the earth, making use of the ground effect - an aerodynamic interaction between the wings and the earth's surface. Some GEVs are able to fly higher out of ground effect (OGE) when required - these are classed as powered fixed-wing aircraft.
Glider.
A glider is a heavier-than-air craft that is supported in flight by the dynamic reaction of the air against its lifting surfaces, and whose free flight does not depend on an engine. A sailplane is a fixed-wing glider designed for soaring - the ability to gain height in updrafts of air and to fly for long periods.
Gliders are mainly used for recreation, but have also been used for other purposes such as aerodynamics research, warfare and recovering spacecraft.
A motor glider does have an engine for extending its performance and some have engines powerful enough to take off, but the engine is not used in normal flight.
As is the case with planes, there are a wide variety of glider types differing in the construction of their wings, aerodynamic efficiency, location of the pilot and controls. Perhaps the most familiar type is the toy paper plane.
Large gliders are most commonly launched by a tow-plane or by a winch. Military gliders have been used in war to deliver assault troops, and specialised gliders have been used in atmospheric and aerodynamic research. Rocket-powered aircraft and spaceplanes have also made unpowered landings.
Gliders and sailplanes that are used for the sport of gliding have high aerodynamic efficiency. The highest lift-to-drag ratio is 70:1, though 50:1 is more common. After launch, further energy is obtained through the skillful exploitation of rising air in the atmosphere. Flights of thousands of kilometres at average speeds over 200 km/h have been achieved.
The most numerous unpowered aircraft are paper aeroplanes, a handmade type of glider. Like hang gliders and paragliders, they are foot-launched and are in general slower, smaller, and less expensive than sailplanes. Hang gliders most often have flexible wings given shape by a frame, though some have rigid wings. Paragliders and paper aeroplanes have no frames in their wings.
Gliders and sailplanes can share a number of features in common with powered aircraft, including many of the same types of fuselage and wing structures. For example, the Horten H.IV was a tailless flying wing glider, and the delta wing-shaped Space Shuttle orbiter flew much like a conventional glider in the lower atmosphere. Many gliders also use similar controls and instruments as powered craft.
Types of glider.
The main application today of glider aircraft is sport and recreation.
Sailplane.
Gliders were developed from the 1920s for recreational purposes. As pilots began to understand how to use rising air, sailplane gliders were developed with a high lift-to-drag ratio. These allowed longer glides to the next source of 'lift', and so increase their chances of flying long distances. This gave rise to the popular sport of gliding.
Early gliders were mainly built of wood and metal but the majority of sailplanes now use composite materials incorporating glass, carbon or aramid fibres. To minimise drag, these types have a streamlined fuselage and long narrow wings having a high aspect ratio. Both single-seat and two-seat gliders are available.
Initially training was done by short 'hops' in primary gliders which are very basic aircraft with no cockpit and minimal instruments. Since shortly after World War II training has always been done in two-seat dual control gliders, but high performance two-seaters are also used to share the workload and the enjoyment of long flights. Originally skids were used for landing, but the majority now land on wheels, often retractable. Some gliders, known as motor gliders, are designed for unpowered flight, but can deploy piston, rotary, jet or electric engines. Gliders are classified by the FAI for competitions into glider competition classes mainly on the basis of span and flaps.
Military gliders.
Military gliders were used during World War II for carrying troops (glider infantry) and heavy equipment to combat zones. The gliders were towed into the air and most of the way to their target by military transport planes, e.g. C-47 Dakota, or by bombers that had been relegated to secondary activities, e.g. Short Stirling. Once released from the tow near the target, they landed as close to the target as possible. The advantage over paratroopers were that heavy equipment could be landed and that the troops were quickly assembled rather than being dispersed over a drop zone. The gliders were treated as disposable, leading to construction from common and inexpensive materials such as wood, though a few were retrieved and re-used. By the time of the Korean War, transport aircraft had also become larger and more efficient so that even light tanks could be dropped by parachute, causing gliders to fall out of favor.
Research gliders.
Even after the development of powered aircraft, gliders continued to be used for aviation research. The NASA Paresev Rogallo flexible wing was originally developed to investigate alternative methods of recovering spacecraft. Although this application was abandoned, publicity inspired hobbyists to adapt the flexible-wing airfoil for modern hang gliders.
Initial research into many types of fixed-wing craft, including flying wings and lifting bodies was also carried out using unpowered prototypes.
Hang glider.
A hang glider is a glider aircraft in which the pilot is ensconced in a harness suspended from the airframe, and exercises control by shifting body weight in opposition to a control frame. Most modern hang gliders are made of an aluminium alloy or composite-framed fabric wing. Pilots have the ability to soar for hours, gain thousands of metres of altitude in thermal updrafts, perform aerobatics, and glide cross-country for hundreds of kilometres.
Paraglider.
A paraglider is a lightweight, free-flying, foot-launched glider aircraft with no rigid primary structure. The pilot sits in a harness suspended below a hollow fabric wing whose shape is formed by its suspension lines, the pressure of air entering vents in the front of the wing and the aerodynamic forces of the air flowing over the outside. Paragliding is most often a recreational activity.
Unmanned gliders.
A paper plane is a toy aircraft (usually a glider) made out of paper or paperboard.
Model glider aircraft are models of aircraft using lightweight materials such as polystyrene and balsa wood. Designs range from simple glider aircraft to accurate scale models, some of which can be very large.
Glide bombs are bombs with aerodynamic surfaces to allow a gliding flightpath rather than a ballistic one. This enables the carrying aircraft to attack a heavily defended target from a distance.
Kite.
A kite is an aircraft tethered to a fixed point so that the wind blows over its wings. Lift is generated when air flows over the kite's wing, producing low pressure above the wing and high pressure below it, and deflecting the airflow downwards. This deflection also generates horizontal drag in the direction of the wind. The resultant force vector from the lift and drag force components is opposed by the tension of the one or more rope lines or tethers attached to the wing.
Kites are mostly flown for recreational purposes, but have many other uses. Early pioneers such as the Wright Brothers and J.W. Dunne sometimes flew an aircraft as a kite in order to develop it and confirm its flight characteristics, before adding an engine and flight controls, and flying it as an aeroplane.
Uses.
Military applications.
Kites have been used for signaling, for delivery of munitions, and for observation, by lifting an observer above the field of battle, and by using kite aerial photography.
Science and meteorology.
Kites have been used for scientific purposes, such as Benjamin Franklin's famous experiment proving that lightning is electricity. Kites were the precursors to the traditional aircraft, and were instrumental in the development of early flying craft. Alexander Graham Bell experimented with very large man-lifting kites, as did the Wright brothers and Lawrence Hargrave. Kites had a historical role in lifting scientific instruments to measure atmospheric conditions for weather forecasting.
Radio aerials and light beacons.
Kites can be used to carry radio antennas. This method was used for the reception station of the first transatlantic transmission by Marconi. Captive balloons may be more convenient for such experiments, because kite-carried antennas require a lot of wind, which may be not always possible with heavy equipment and a ground conductor.
Kites can be used to carry light effects such as lightsticks or battery powered lights.
Kite traction.
Kites can be used to pull people and vehicles downwind. Efficient foil-type kites such as power kites can also be used to sail upwind under the same principles as used by other sailing craft, provided that lateral forces on the ground or in the water are redirected as with the keels, center boards, wheels and ice blades of traditional sailing craft. In the last two decades several kite sailing sports have become popular, such as kite buggying, kite landboarding, kite boating and kite surfing. Snow kiting has also become popular.
Kite sailing opens several possibilities not available in traditional sailing:
Power generation.
Conceptual research and development projects by over a hundred entities are investigating the use of kites in harnessing high altitude wind currents to generate electricity.
Cultural uses.
Kite festivals are a popular form of entertainment throughout the world. They include local events, traditional festivals and major international festivals.
Characteristics.
Airframe.
The structural parts of a fixed-wing aircraft are called the airframe. The parts present can vary according to the aircraft's type and purpose. Early types were usually made of wood with fabric wing surfaces, When engines became available for powered flight around a hundred years ago, their mounts were made of metal. Then as speeds increased more and more parts became metal until by the end of WWII all-metal aircraft were common. In modern times, increasing use of composite materials has been made.
Typical structural parts include:
Wings.
The wings of a fixed-wing aircraft are static planes extending either side of the aircraft. When the aircraft travels forwards, 
air flows over the wings which are shaped to create lift.
Wing structure.
Kites and some light weight gliders and aeroplanes have flexible wing surfaces which are stretched across a frame and made rigid by the lift forces exerted by the airflow over them. Larger aircraft have rigid wing surfaces which provide additional strength.
Whether flexible or rigid, most wings have a strong frame to give them their shape and to transfer lift from the wing surface to the rest of the aircraft. The main structural elements are one or more spars running from root to tip, and many ribs running from the leading (front) to the trailing (rear) edge.
Early aeroplane engines had little power and light weight was very important. Also, early aerofoil sections were very thin, and could not have strong frame installed within. So until the 1930s most wings were too light weight to have enough strength and external bracing struts and wires were added. When the available engine power increased during the 1920s and 1930s, wings could be made heavy and strong enough that bracing was not needed any more. This type of unbraced wing is called a cantilever wing.
Wing configuration.
The number and shape of the wings varies widely on different types. A given wing plane may be full-span or divided by a central fuselage into port (left) and starboard (right) wings. Occasionally even more wings have been used, with the three-winged triplane achieving some fame in WWI. The four-winged quadruplane and other Multiplane (aeronautics) designs have had little success.
A monoplane has a single wing plane, a biplane has two stacked one above the other, a tandem wing has two placed one behind the other. When the available engine power increased during the 1920s and 1930s and bracing was no longer needed, the unbraced or cantilever monoplane became the most common form of powered type.
The wing planform is the shape when seen from above. To be aerodynamically efficient, a wing should be straight with a long span from side to side but have a short chord (high aspect ratio). But to be structurally efficient, and hence light weight, a wing must have a short span but still enough area to provide lift (low aspect ratio).
At transonic speeds, near the speed of sound, it helps to sweep the wing backwards or forwards to reduce drag from supersonic shock waves as they begin to form. The swept wing is just a straight wing swept backwards or forwards.
The delta wing is a triangle shape which may be used for a number of reasons. As a flexible Rogallo wing it allows a stable shape under aerodynamic forces, and so is often used for kites and other ultralight craft. As a supersonic wing it combines high strength with low drag and so is often used for fast jets.
A variable geometry wing can be changed in flight to a different shape. The variable-sweep wing transforms between an efficient straight configuration for takeoff and landing, to a low-drag swept configuration for high-speed flight. Other forms of variable planform have been flown, but none have gone beyond the research stage.
Fuselage.
A "fuselage" is a long, thin body, usually with tapered or rounded ends to make its shape aerodynamically smooth. The fuselage may contain the flight crew, passengers, cargo or payload, fuel and engines. The pilots of manned aircraft operate them from a "cockpit" located at the front or top of the fuselage and equipped with controls and usually windows and instruments. A plane may have more than one fuselage, or it may be fitted with booms with the tail located between the booms to allow the extreme rear of the fuselage to be useful for a variety of purposes.
Wings vs. bodies.
Flying wing.
A flying wing is a tailless aircraft which has no definite fuselage, with most of the crew, payload and equipment being housed inside the main wing structure.
The flying wing configuration was studied extensively in the 1930s and 1940s, notably by Jack Northrop and Cheston L. Eshelman in the United States, and Alexander Lippisch and the Horten brothers in Germany.
After the war, a number of experimental designs were based on the flying wing concept. Some general interest continued until the early 1950s but designs did not necessarily offer a great advantage in range and presented a number of technical problems, leading to the adoption of "conventional" solutions like the Convair B-36 and the B-52 Stratofortress. Due to the practical need for a deep wing, the flying wing concept is most practical for designs in the slow-to-medium speed range, and there has been continual interest in using it as a tactical airlifter design.
Interest in flying wings was renewed in the 1980s due to their potentially low radar reflection cross-sections. Stealth technology relies on shapes which only reflect radar waves in certain directions, thus making the aircraft hard to detect unless the radar receiver is at a specific position relative to the aircraft - a position that changes continuously as the aircraft moves. This approach eventually led to the Northrop B-2 Spirit stealth bomber. In this case the aerodynamic advantages of the flying wing are not the primary needs. However, modern computer-controlled fly-by-wire systems allowed for many of the aerodynamic drawbacks of the flying wing to be minimised, making for an efficient and stable long-range bomber.
Blended wing body.
Blended wing body aircraft have a flattened and airfoil shaped body, which produces most of the lift to keep itself aloft, and distinct and separate wing structures, though the wings are smoothly blended in with the body.
Thus blended wing bodied aircraft incorporate design features from both a futuristic fuselage and flying wing design. The purported advantages of the blended wing body approach are efficient high-lift wings and a wide airfoil-shaped body. This enables the entire craft to contribute to lift generation with the result of potentially increased fuel economy.
Lifting body.
A lifting body is a configuration in which the body itself produces lift. In contrast to a flying wing, which is a wing with minimal or no conventional fuselage, a lifting body can be thought of as a fuselage with little or no conventional wing. Whereas a flying wing seeks to maximize cruise efficiency at subsonic speeds by eliminating non-lifting surfaces, lifting bodies generally minimize the drag and structure of a wing for subsonic, supersonic, and hypersonic flight, or, spacecraft re-entry. All of these flight regimes pose challenges for proper flight stability.
Lifting bodies were a major area of research in the 1960s and 1970s as a means to build a small and lightweight manned spacecraft. The US built a number of famous lifting body rocket planes to test the concept, as well as several rocket-launched re-entry vehicles that were tested over the Pacific. Interest waned as the US Air Force lost interest in the manned mission, and major development ended during the Space Shuttle design process when it became clear that the highly shaped fuselages made it difficult to fit fuel tankage.
Empennage and foreplane.
The classic aerofoil section wing is unstable in flight and difficult to control. Flexible-wing types often rely on an anchor line or the weight of a pilot hanging beneath to maintain the correct attitude. Some free-flying types use an adapted aerofoil that is stable, or other ingenious mechanisms including, most recently, electronic artificial stability.
But in order to achieve trim, stability and control, most fixed-wing types have an empennage comprising a fin and rudder which act horizontally and a tailplane and elevator which act vertically. This is so common that it is known as the conventional layout. Sometimes there may be two or more fins, spaced out along the tailplane.
Some types have a horizontal "canard" foreplane ahead of the main wing, instead of behind it. This foreplane may contribute to the trim, stability or control of the aircraft, or to several of these.
Aircraft controls.
Kite control.
Kites are controlled by wires running down to the ground. Typically each wire acts as a tether to the part of the kite it is attached to.
Free-flying aircraft controls.
Gliders and aeroplanes have more complex control systems, especially if they are piloted.
The main controls allow the pilot to direct the aircraft in the air. Typically these are:
Other common controls include:
A craft may have two pilots' seats with dual controls, allowing two pilots to take turns. This is often used for training or for longer flights.
The control system may allow full or partial automation of flight, such as an autopilot, a wing leveler, or a flight management system. An unmanned aircraft has no pilot but is controlled remotely or via means such as gyroscopes or other forms of autonomous control.
Cockpit instrumentation.
On manned types, instruments provide information to the pilots, including flight, engines, navigation, communications and other aircraft systems that may be installed.
The six basic instruments (sometimes referred to as the six pack) include:
Other instruments might include:

</doc>
<doc id="46772" url="https://en.wikipedia.org/wiki?curid=46772" title="Lake Van">
Lake Van

Lake Van (, , ) is the largest lake in Turkey, located in the far east of the country in the provinces of Van and Bitlis. It is a saline soda lake, receiving water from numerous small streams that descend from the surrounding mountains. Lake Van is one of the world's largest endorheic lakes (having no outlet). The original outlet from the basin was blocked by an ancient volcanic eruption. Although Lake Van is situated at an altitude of in a region with harsh winters, its high salinity prevents most of it from freezing, and even the shallow northern section is only occasionally an exception.
Hydrology and chemistry.
Lake Van is across at its widest point, averaging a depth of with a maximum recorded depth of . The lake surface lies above sea level and the shore length is . Lake Van has an area of and a volume of .
The western portion of the lake is deepest, with a large basin deeper than lying northeast of Tatvan and south of Ahlat. The eastern arms of the lake are shallower. The Van-Ahtamar portion shelves gradually, with a maximum depth of about on its northwest side where it joins the rest of the lake. The Erciş arm is much shallower, mostly less than , with a maximum depth of about .
The lake water is strongly alkaline (pH 9.7–9.8) and rich in sodium carbonate and other salts, which are extracted by evaporation and used as detergents.
Geology.
The lake's outlet was blocked at some time during the Pleistocene, when lava flows from Nemrut volcano blocked westward outflow towards the Muş Plain. Now dormant, Nemrut Dağı is close to the western shore of the lake, and another dormant stratovolcano, Süphan Dağı dominates the northern side of the lake.
The water level of the lake has often altered dramatically: near Tatvan, Oswald (see Geology of Armenia, 1901) noted a raised beach high above the present level of the lake as well as recently drowned trees. Investigation by Degens and others in the early 1980s determined that the highest lake levels ( above the current height) had been during the last ice age, about 18,000 years ago. Approximately 9,500 years ago there was a dramatic drop to more than below the present level. This was followed by an equally-dramatic rise around 6,500 years ago.
Similar-but-smaller fluctuations have been seen recently. The level of the lake rose by at least three metres during the 1990s, drowning much agricultural land, and (after a brief period of stability and then retreat) seems to be rising again. The level rose approximately two meters in the ten years immediately prior to 2004.
As a deep lake with no outlet, Lake Van has accumulated great amounts of sediment washed in from surrounding plains and valleys, and occasionally deposited as ash from eruptions of nearby volcanoes.
This layer of sediment is estimated to be up to thick in places, and has attracted climatologists and vulcanologists interested in drilling cores to examine the layered sediments.
In 1989 and 1990, an international team of geologists led by Dr. Stephan Kempe from the University of Hamburg (now Professor at the Technische Universität Darmstadt) retrieved ten sediment cores from depths up to . Although these cores only penetrated the first few meters of sediment, they provided sufficient varves to give proxy climate data for up to 14,570 years BP.
A team of scientists headed by palaeontologist Professor Thomas Litt at the University of Bonn has applied for funding from the International Continental Scientific Drilling Program (ICDP) for a new, deeper-drilling project to examine the lake's sediments. Litt expects to find that "Lake Van stores the climate history of the last 800,000 years—an incomparable treasure house of data which we want to tap for at least the last 500,000 years." A test drilling in 2004 detected evidence of 15 volcanic eruptions in the past 20,000 years.
Climate.
Lake Van is situated in the highest and largest region of Turkey, which has a harsh continental climate. Average temperatures in July are between 22 and 25 °C, and in January between −3 °C to −12 °C. In particularly-cold winter nights the temperature reaches −30 °C. Lake Van mitigates the climate somewhat, so in the city of Van, on the shore of the lake, the average temperature in July is 22.5 °C, and in January −3.5 °C. The average annual rainfall in the basin of Lake Van, ranges from 400 to 700 mm.
Ecology.
The only fish known to live in the brackish water of Lake Van is "Chalcalburnus tarichi" the Pearl Mullet or "inci kefalı", a Cyprinid fish related to chub and dace, which is caught during the spring floods. In May and June, these fish migrate from the lake to less alkaline water, spawning either near the mouths of the rivers feeding the lake or in the rivers themselves. After spawning season it returns to the lake.
103 species of phytoplankton have been recorded in the lake including cyanobacteria, flagellates, diatoms, green algae and brown algae. 36 species of zooplankton have also been recorded including Rotatoria, Cladocera and Copepoda in the lake.
In 1991, researchers reported the discovery of tall microbialites in Lake Van. These are solid towers on the lake bed created by mats of coccoid cyanobacteria ("Pleurocapsa" group) that create aragonite in combination with calcite precipitating out of the lake water.
The Lake Van region is the home of the rare Van Cat breed of cat, noted for among other things its unusual fascination with water, and is surrounded by fruit and grain-growing agricultural areas.
History.
Tushpa, the capital of Urartu, was located near the shores of Lake Van, on the site of what became medieval Van's castle, west of present-day Van city. The ruins of the medieval city of Van are still visible below the southern slopes of the rock on which Van Castle is located.
Armenian kingdoms.
The lake was the centre of the Armenian kingdom of Ararat from about 1000 BC, afterwards of the Satrapy of Armina, Kingdom of Greater Armenia, and the Armenian Kingdom of Vaspurakan.
Along with Lake Sevan in today's Armenia and Lake Urmia in today's Iran, Van was one of the three great lakes of the Armenian Kingdom, referred to as "the seas of Armenia" (in ancient Assyrian sources: "tâmtu ša mât Nairi" (Upper Sea of Nairi), the Lower Sea being Lake Urmia). Over time, the lake was known by various Armenian names, including .
Byzantine empire.
By the 11th century the region around Lake Van was on the border between the Byzantine empire, with its capital at Constantinople, and the Seljuk Turkish empire, with its capital at Isfahan. In the uneasy peace between the two empires, local Armenian-Byzantine landowners employed Turcoman gazis and Byzantine akritoi for protection.
In the second half of the 11th century Emperor Romanus IV Diogenes launched a campaign to re-conquer Armenia and head off growing Seljuk control. Diogenes and his large army crossed the Euphrates and confronted a much smaller Seljuk force led by Alp Arslan at the Battle of Manzikert, north of Lake Van on 26 August 1071. Despite their greater numbers, the cumbersome Byzantine force was defeated by the more mobile Turkish horsemen and Diogenes was captured.
Seljuk empire.
Alp Arslan divided the conquered eastern portions of the Byzantine empire among his Turcoman generals, with each ruled as a hereditary beylik, under overall sovereignty of the Great Seljuq Empire. Alp Arslan gave the region around Lake Van to his commander Sökmen el Kutbî (literally "Sökmen the Slave"), who set up his capital at Ahlat on the western side of the lake. The dynasty of Ahlatshahs (also known as "Sökmenler") ruled this area from 1085 to 1192.
The Ahlatshahs were succeeded by the Ayyubid dynasty.
Architecture.
Near the Van Castle and the southern shore, on Akdamar Island lies the 10th century Church of the Holy Cross (, Surb Khach), which served as a royal church to the Armenian Vaspurakan kingdom. The ruins of Armenian monasteries also exist on the other three islands of Lake Van: Lim, Arter, and Ktuts. The area around Lake Van was also the home to a large number Armenian monasteries, among the most prominent of these being the 10th century Narekavank and the 11th century Varagavank, both now destroyed.
The Ahlatshahs left a large number of historic tombstones in and around the town of Ahlat. Local administrators are currently trying to have the tombstones included in UNESCO's World Heritage List, where they are currently listed tentatively.
Transportation.
The railway connecting Turkey and Iran was built in the 1970s, sponsored by CENTO. It uses a train ferry across Lake Van between the cities Tatvan and Van, rather than building railway tracks around the rugged shore line. Transfer from train to ship and back again limits the total carrying capacity.
In May 2008 talks started between Iran and Turkey to replace the ferry with a double track electrified railway.

</doc>
<doc id="46774" url="https://en.wikipedia.org/wiki?curid=46774" title="Malagasy">
Malagasy

Malagasy may refer to:

</doc>
<doc id="46776" url="https://en.wikipedia.org/wiki?curid=46776" title="Fanorona">
Fanorona

Fanorona () is a strategy board game for two players. The game is indigenous to Madagascar.
Introduction.
Fanorona has three standard versions: Fanoron-Telo, Fanoron-Dimy, and Fanoron-Tsivy. The difference between these variants is the size of board played on. Fanoron-Telo is played on a 3×3 board and the difficulty of this game can be compared to the game of tic-tac-toe. Fanoron-Dimy is played on a 5×5 board and Fanoron-Tsivy is played on a 9×5 board—Tsivy being the most popular. Black and white pieces, twenty-two each, are arranged on all points but the center. The objective of the game is to capture all the opponents pieces. The game is a draw if neither player succeeds in this. Capturing is done by either approaching or withdrawing from opponent's pieces.
Fanorona is very popular in Madagascar. According to one version of a popular legend, an astrologer had advised King Ralambo to choose his successor by selecting a time when his sons were away from the capital to feign sickness and urge their return; his kingdom would be given to the first son who returned home to him. When the king's messenger reached Ralambo's elder son Prince Andriantompokondrindra, he was playing fanorona and trying to win a "telo noho dimy" (3 against 5) situation, one that is infamously difficult to resolve. As a result, his younger brother Prince Andrianjaka was the first to arrive and inherited the throne.
Board.
The Fanorona board consists of lines and intersections, creating a grid with 5 rows and 9 columns subdivided diagonally to form part of the tetrakis square tiling of the plane. A line represents the path along which a stone can move during the game. There are weak and strong intersections. At a weak intersection it is only possible to move a stone horizontally and vertically, while on a strong intersection it is also possible to move a stone diagonally. A stone can only move from one intersection to an adjacent intersection.
Rules.
There exist variations of the rules; this is the main variant.
Analysis.
Using 10.000 games with Alpha-beta pruning players the game-tree complexity and state-space complexity can be computed. It turns out that Fanorona has a game-tree complexity of 1046 and a state-space complexity of 1021.
In 2007 the game of Fanorona and smaller variants has been solved weakly. It turns out that this game is a draw. Both the moves f2-e3A and d3-e3A lead to a draw.

</doc>
<doc id="46779" url="https://en.wikipedia.org/wiki?curid=46779" title="Human-powered transport">
Human-powered transport

Human-powered transport is the transport of person(s) and/or goods using human muscle power. Like animal-powered transport, human-powered transport has existed since time immemorial in the form of walking, running and swimming. Modern technology has allowed machines to enhance human-power.
Although motorization has increased speed and load capacity, many forms of human-powered transport remain popular for reasons of lower cost, leisure, physical exercise and environmentalism. Human-powered transport is sometimes the only type available, especially in underdeveloped or inaccessible regions.
Available muscle power.
In the 1989 Race Across America, one team (Team Strawberry) used an experimental device comprising a rear wheel hub, a sensor, and a handlebar mounted processor, to measure each cyclist's power output.
In lab experiments an average "in-shape" cyclist can produce about 3 watts/kg for more than an hour (e.g., around 200 watts for a rider), with top amateurs producing 5 watts/kg and elite athletes achieving 6 watts/kg for similar lengths of time. Elite track sprint cyclists are able to attain an instantaneous maximum output of around 2,000 watts, or in excess of 25 watts/kg; elite road cyclists may produce 1,600 to 1,700 watts as an instantaneous maximum in their burst to the finish line at the end of a five-hour-long road race.
Modes.
Human-powered vehicles (HPVs).
Land vehicles.
Skateboards have the advantage of being so small and light that users can easily carry them when not skating.
The most efficient human-powered land vehicle is the bicycle. Compared to the much more common upright bicycle, the recumbent bicycle may be faster on level ground or down hills due to better aerodynamics while having similar power transfer efficiency.
Velomobiles are increasingly popular in colder and/or wetter countries due to the protection they offer against the environment. Freight bicycles are used to transport cargo. Cycle rickshaws can be used as taxicabs.
In 2013, Dutch cyclist Sebastiaan Bowier pedaled a fully faired recumbent streamliner for at at Battle Mountain, Nevada.
Dutch cyclist Fred Rompelberg set a speed record at the Bonneville Salt Flats in Utah on October 3, 1995 while cycling in the wake of a motor dragster pace-car. The wake of the pace-car reduced the aerodynamic drag against which Rompelberg pedalled to almost zero.
Greg Kolodziejzyk set two world records recognized by both the International Human Powered Vehicle Association and Guinness (TM) World Records on July 17, 2006 on a race track in Eureka, California. The first record is for the most distance traveled in 24 hours by human power , and the second for the worlds fastest time trial (23 hours, 2 minutes).
Both records were broken on August 6, 2010 by Christian von Ascheberg who drove in 19 hours, 27 minutes and managed to go in 24 hours with his Milan SL Velomobile. In the same race he also raised the 12-hour record to , which is an average of .
In 1969, artists in a small Northern California town began the Kinetic sculpture race which has grown to a , three-day all terrain, human-powered sculpture race and county wide event. It is held every year on the last weekend in May.
Aircraft.
Fixed wing.
The "Pedaliante" flew short distances fully under human power in 1936, but the distances were not significant enough to win the prize of the Italian competition for which it was built. The flights were deemed to be a result of the pilot's significant strength and endurance, and not attainable by a typical human. Additional attempts were made in 1937 and 1938 using a catapult system, launching the plane to a height of . With the catapult launch, the plane successfully traveled the distance outlined by the competition, but was declined the prize due to the takeoff method.
The first officially authenticated regularly feasible take-off and landing of a human-powered aircraft (one capable of powered takeoffs, unlike a glider) was made on 9 November 1961 by Derek Piggott in Southampton University's Man Powered Aircraft (SUMPAC).
Perhaps the best-known human-powered plane is the Gossamer Albatross, which flew across the English Channel in 1979.
The current distance and duration record recognised by the FAI, a straight distance of in 3 hours and 54 minutes, was achieved on 23 April 1988 from Heraklion on Crete to Santorini in a MIT Daedalus 88 piloted by Kanellos Kanellopoulos.
The current speed record is held by the Monarch B, built by a team at MIT in 1983, which won a Kremer Prize of £20,000 for sustaining a speed of over over a triangular course.
Helicopters.
The first officially observed human-powered helicopter to have left the ground was the Da Vinci III in 1989. It was designed and built by students at Cal Poly San Luis Obispo in California, USA. It flew for 7.1 seconds and reached a height of . The second was the Yuri I in 1994, designed and built by students at Nihon University in Japan. It flew for 19.46 seconds and reached an altitude of . On 13 June 2013, the AeroVelo Atlas was the first to complete a flight that lasted 64 seconds and reached an altitude of 3.3 meters, thus winning the Sikorsky Prize.
Airships and balloons.
French inventors have built man-powered airships and balloons. Solar balloons and solar airships are new types of balloons and airships. Because lift is supplied through buoyancy, human power can be devoted to thrust.
Watercraft.
Human-powered watercraft include prehistoric and well-known traditional and sporting craft such as canoes, rowing boats and galleys. The term "human-powered boat" is often used for more modern craft using propellers and water wheels for propulsion. These can be more efficient than paddles or oars and especially allow the use of the leg muscles which are generally stronger than arm muscles, even for non-athletes. In addition, there is little skill required for forward propulsion while looking forwards and craft such as pedalos are popular at resorts.
Hydrofoils.
Hydrofoils have less water resistance at the highest speeds attainable by humans and are thus usually faster than displacement boats on short courses. The world speed record on water was set 27 October 1991 by MIT professor Mark Drela who pedalled a human-powered hydrofoil, "Decavitator", to 18.5 knots (21.3 mph)(9.53 meters/second) over a 100-meter course in Boston, Massachusetts, US.
Submarines.
In 1989, the first human-powered International Submarine Race (ISR) was held in Florida with 17 craft. Since then nine more races have been held. The races themselves have been moved from the waters of Florida to the United States Naval Surface Warfare Center's Carderock Division David Taylor Model Basin in Bethesda, Maryland, and are held biennially. At the 9th ISR in 2007 (in which 23 submarines participated) several new records were set: A single-person craft, Omer5 achieved a record speed of 8.035 knots breaking the Omer team's previous record of 7.19 knots set by Omer 4 in 2004. Also Omer 6 snatched up a record for non-propeller driven craft with a speed of 4.642 knots.

</doc>
<doc id="46780" url="https://en.wikipedia.org/wiki?curid=46780" title="Iolanthe">
Iolanthe

Iolanthe; or, The Peer and the Peri () is a comic opera with music by Arthur Sullivan and libretto by W. S. Gilbert. It is one of the Savoy operas and is the seventh of fourteen operatic collaborations by Gilbert and Sullivan. In the opera, the fairy Iolanthe has been banished from fairyland because she married a mortal; this is forbidden by fairy law. Her son, Strephon, is an Arcadian shepherd who wants to marry Phyllis, a Ward of Chancery. All the members of the House of Peers also want to marry Phyllis. When Phyllis sees Strephon hugging a young woman (not knowing that it is his mother – immortal fairies all appear young), she assumes the worst and sets off a climactic confrontation between the peers and the fairies. The opera satirises many aspects of British government, law and society. The confrontation between the fairies and the peers is a version of one of Gilbert's favourite themes: a tranquil civilisation of women is disrupted by a male-dominated world through the discovery of mortal love.
"Iolanthe" opened in London on 25 November 1882, at the Savoy Theatre to a warm reception, and ran for 398 performances, the fourth consecutive hit by Gilbert and Sullivan. It was the first work to premiere at the newly-built Savoy and was the first new theatre production in the world to be illuminated entirely with electric lights, permitting some special effects that had not been possible in the era of gas lighting. The opera opened simultaneously in New York, and touring companies were sent around the UK and US to play the piece. The first Australasian touring production followed in 1885, and the opera was revived in London beginning in 1901. The D'Oyly Carte Opera Company toured the opera nearly continuously in repertory from 1891 until 1982, and made several recordings of the opera over that period. Numerous other professional and amateur productions have been given of this enduring work, and various other recordings have been issued.
Background.
W. S. Gilbert presented his basic idea for a new opera to Arthur Sullivan in October 1881. Gilbert's earliest ideas for the story of "Iolanthe" originated in his "Bab Ballad", "The Fairy Curate": "Once a fairy / Light and airy / Married with a mortal". The fairy marries a "prosaic" attorney and bears him a son. After her son grows up, she visits him on Earth, but she is mistaken for his lover, since fairies perpetually appear young and beautiful. Sullivan found the premise funny, and Gilbert set to work on fleshing out the story. By December, he had written some lyrics for Sullivan to look at, but he struggled with the plot for several months, whereas he had dashed off earlier operas in a matter of weeks. During these months, Sullivan took an extended trip to Egypt, Italy and elsewhere. Upon his return to London in April 1882, he moved into a new home; in May, his beloved mother died rather suddenly. By the end of July 1882, Gilbert had supplied Sullivan with lyrics to several of the songs, and Sullivan began work setting them to music. Over the next two months, Sullivan met Gilbert to discuss the libretto as more lyrics were completed. Music rehearsals began in September, and staging began in October, scheduled around performances of Gilbert and Sullivan's previous opera, "Patience", which had transferred to the Savoy Theatre. Sullivan was still composing more numbers for the opera until 20 October, with a few modifications continuing into early November. Uncharacteristically, Sullivan composed the overture himself, instead of assigning it to an assistant. Two casts rehearsed simultaneously, as the opera was to open on the same night in London and New York City, an historic first for any play.
Gilbert had targeted the aristocracy and political officials for satiric treatment in earlier works. In this opera, the House of Lords is lampooned as a bastion of the ineffective, privileged and dim-witted, whose only qualification to govern is noble birth. The political party system, the law and other institutions also come in for a dose of satire. Throughout "Iolanthe", however, both author and composer managed to couch the criticism among such bouncy, amiable absurdities and "splendid pageantry" that it is all received as good humour, with Prime Minister Gladstone complimenting the opera's good taste. In fact, Gilbert later refused to allow quotes from the piece to be used as part of the campaign to diminish the powers of the House of Lords.
Although titled "Iolanthe" all along in Gilbert's plot book, for a time the piece was advertised as "Perola" and rehearsed under that name. According to an often-repeated myth, Gilbert and Sullivan did not change the name to "Iolanthe" until just before the première. In fact, however, the title was advertised as "Iolanthe" as early as 13 November 1882 – eleven days before the opening – so the cast had at least that much time to learn the name. It is also clear that Sullivan's musical setting was written to match the cadence of the word "Iolanthe," and could only accommodate the word "Perola" by preceding it (awkwardly) with "O", "Come" or "Ah". Henry Irving had produced a W. G. Wills adaptation of "King René’s Daughter" in London in 1880, under the name "Iolanthe", and in October 1882 Gilbert asked his producer, Richard D'Oyly Carte, to request Irving's permission to use the name. It is not known whether Irving replied.
"Iolanthe" premiered only three days after "Patience" closed at the Savoy. The Savoy Theatre, opened only a year earlier, was a state-of-the-art facility, the first theatre in the world to be lit entirely by electricity. "Patience" had transferred to the Savoy from the Opera Comique, upon the theatre's opening, but "Iolanthe" was the first show to premiere at the theatre. New lighting technologies made such special effects as sparkling fairy wands possible for the first time. The principal fairies' heads were also lit by wreaths of small illuminated stars attached to a battery. The audience that attended the opening night in London included Captain (later Captain Sir) Eyre Massey Shaw, head of the Metropolitan Fire Brigade, whom the Fairy Queen apostrophises in the second act ("Oh, Captain Shaw / Type of true love kept under / Could thy brigade with cold cascade / Quench my great love, I wonder?"). On the first night Alice Barnett, as the Queen of the Fairies, sang the verses directly to Captain Shaw, who was sitting in the centre of the stalls.
The opera's premiere was received by an enthusiastic audience and earned critical praise, although there was general agreement that the second act needed some trimming. "Iolanthe" became the fourth consecutive major success for Gilbert, Sullivan and their producer, Richard D'Oyly Carte, following "H.M.S. Pinafore" (1878), "The Pirates of Penzance" (1879) and "Patience" (1881). Increasingly viewing his work with Gilbert as frivolous, beneath his skills and repetitious, Sullivan had intended to resign from the partnership with Gilbert and Carte after "Iolanthe", but on the day of its premiere, he received a letter from his broker, Edward Hall, notifying him that Hall had lost all his money, including £7,000 of Sullivan's investments, the bulk of his fortune. Sullivan's lifestyle was not inexpensive, and he was helping to support his late brother's large family, as well as his mistress, Fanny Ronalds, and her family. He soon concluded that the only certain way to restore his financial security was to continue writing Savoy operas. On 8 February 1883, he signed a new five-year creative partnership agreement with Gilbert and Carte; Gilbert was already at work on their next piece, "Princess Ida". On 22 May 1883, Sullivan was knighted by Queen Victoria for his "services ... rendered to the promotion of the art of music" in Britain.
Synopsis.
Act I
Twenty-five years before the beginning of the opera, the fairy Iolanthe committed the capital crime (under fairy law) of marrying a mortal human. The Queen of the fairies commuted Iolanthe's sentence of death to banishment for life on the condition that Iolanthe left her husband and never communicated with him again. After the passage of 25 years, the fairies, still missing Iolanthe deeply, plead with their Queen to pardon Iolanthe and to restore her place in fairyland ("Tripping hither, tripping thither").
Summoned by the Fairy Queen ("Iolanthe! From thy dark exile thou art summoned"), Iolanthe rises from the frog-infested stream that has been her home in exile. The Queen, unable to bear punishing her any longer, pardons Iolanthe, who is warmly greeted by the other fairies. Iolanthe tells her sisters that she has a son, Strephon, noting that he's a fairy down to the waist, but his legs are mortal. The fairies laugh that Iolanthe appears too young to have a grown son, as one of the advantages of a fairy's immortality is that they never grow old. Strephon, a handsome Arcadian shepherd, arrives and meets his aunts ("Good-morrow, good mother"). He tells Iolanthe of his love for the Lord Chancellor's ward of court, the beautiful Phyllis, who does not know of Strephon's mixed origin. Strephon is despondent, however, as the Lord Chancellor has forbidden them to marry, partly because he feels that a shepherd is unsuitable for Phyllis, but partly because the Lord Chancellor wishes to marry Phyllis himself. In fact, so do half the members of Britain's House of Lords. The Fairy Queen promises her assistance ("Fare thee well, attractive stranger"). Soon Phyllis arrives, and she and Strephon share a moment of tenderness as they plan their future and possible elopement ("Good-morrow, good lover"; "None shall part us from each other").
A cadre of the peers of the realm arrive in noisy splendour ("Loudly let the trumpet bray" and "The law is the true embodiment"). They are all smitten with Phyllis, and they have appealed to the Lord Chancellor to decide who will have her hand. The Lord Chancellor hesitates to act upon his own regard for Phyllis due to his position as her guardian. The Lords send for Phyllis to choose one of their number, but she will not marry any of them, as virtue is found only in a "lowly" cottage ("My well-loved Lord" and "Nay, tempt me not"). The peers beg her not to scorn them simply because of their "blue blood" ("Spurn not the nobly born" and "My lords, it may not be"). Strephon approaches the Lord Chancellor, pleading that Nature bids him marry Phyllis. But the Lord Chancellor wryly notes that Strephon has not presented sufficient evidence that Nature has interested herself in the matter. He refuses his consent to the marriage between Strephon and Phyllis ("When I went to the Bar").
Disappointed, Strephon calls on Iolanthe for help. She appears and promises to support her son. Spying on the two, the peers – led by the brainless and stuffy Earls Tolloller and Mountararat – together with Phyllis, see Iolanthe and Strephon in a warm embrace. All three jump to the obvious conclusion, since the centuries-old Iolanthe appears to be a girl of seventeen ("When darkly looms the day"). The peers scoff at the seemingly absurd claim that Iolanthe is Strephon's mother as Strephon pleads: "She is, has been, my mother from my birth!" Phyllis angrily rejects Strephon for his supposed infidelity and declares that she will marry either Lord Tolloller or Lord Mountararat ("...and I don't care which!"). Strephon then calls for help from the fairies, who appear but are mistaken by the peers for a girls' school on an outing. Offended, the Fairy Queen pronounces a magical "sentence" upon the peers: Strephon shall not only become a Member of Parliament, but will have the power to pass any bill he proposes ("With Strephon for your foe, no doubt").
Act II
Private Willis, on night guard duty, paces outside the Palace of Westminster and muses on political life ("When all night long a chap remains"). The fairies arrive and tease the peers about the success of MP Strephon, who is advancing a bill to open the peerage to competitive examination ("Strephon's a member of Parliament"). The peers ask the fairies to stop Strephon's mischief, stating that the House of Peers is not susceptible of any improvement ("When Britain really ruled the waves"). Although the fairies say that they cannot stop Strephon, they have become strongly attracted to the peers ("In vain to us you plead"). The fairy Queen is dismayed by this. Pointing to Private Willis of the First Grenadier Guards, who is still on duty, the Queen claims that she is able to subdue her response to the effects of his manly beauty ("Oh, foolish fay").
Phyllis cannot decide whether she ought to marry Tolloller or Mountararat, and so she leaves the choice up to them. Tolloller tells Mountararat that his family's tradition would require the two Earls to duel to the death if the latter were to claim Phyllis. The two decide that their friendship is more important than love and renounce their claims to her ("Though p'r'aps I may incur thy blame"). The Lord Chancellor arrives dressed for bed and describes a nightmare caused by his unrequited love for Phyllis ("Love, unrequited, robs me of my rest"). The two peers try to cheer him up and urge him to make another effort to persuade himself to award Phyllis to ... himself ("If you go in you're sure to win").
Strephon now leads both parties in Parliament, but he is miserable at losing Phyllis. He sees Phyllis and reveals to her that his mother is a fairy, which accounts for her apparent youth ("If we're weak enough to tarry"). Phyllis and Strephon ask Iolanthe to plead with the Lord Chancellor to allow their marriage, for "none can resist your fairy eloquence." This is impossible, she replies, for the Lord Chancellor is her husband. He believes Iolanthe to have died childless, and she is bound not to "undeceive" him, under penalty of death. However, to save Strephon from losing his love, Iolanthe resolves to present his case to the Lord Chancellor while veiled ("My lord, a suppliant at your feet").
Although the Lord Chancellor is moved by her appeal, which evokes the memory of his wife, he declares that he himself will marry Phyllis. Desperate, Iolanthe unveils, ignoring the warnings of the unseen Fairies, revealing that she is his long-lost wife, and Strephon is his son. The Lord Chancellor is amazed to see her alive, but Iolanthe has again broken fairy law, and the Fairy Queen is now left with no choice but to punish Iolanthe with death ("It may not be ... Once again thy vow is broken"). As she prepares to execute Iolanthe, the Queen learns that the rest of the fairies have chosen husbands from among the peers, thus also incurring death sentences – but the Queen blanches at the prospect of slaughtering all of them. The Lord Chancellor suggests a solution: change the law by inserting a single word: "every fairy shall die who "doesn't" marry a mortal." The Fairy Queen cheerfully agrees and, to save her life, the dutiful soldier, Private Willis, agrees to marry her. Seeing no reason to stay in the mortal realm if peers are to be recruited "from persons of intelligence", the peers join the fairy ranks and "away go to fairyland" ("Soon as we may, off and away").
Musical numbers.
Act I
Act II
Musical and textual analysis.
At the time they wrote "Iolanthe", both Gilbert and Sullivan were in their peak creative years, and "Iolanthe", their seventh work together, drew the best from both composer and author. Sullivan's biographer, Arthur Jacobs, wrote: " had composed a brilliant new score (his most subtle yet) to a scintillating libretto. ... "Iolanthe" is the work in which Sullivan's operetta style takes a definite step forward, and metamorphosis of musical themes is its characteristic new feature. ... By recurrence and metamorphosis of themes Sullivan made the score more fluid". Sullivan's overture was superior in structure and orchestration to those that his assistants had constructed for the earlier operas. Much of his "fairy" music pays deliberate homage to the incidental music written by Felix Mendelssohn for an 1842 production of Shakespeare's "A Midsummer Night's Dream". Richard Wagner's "Ring" cycle premiered in London earlier in 1882. The music for the fairies reflects Wagner's style, and the score uses leitmotifs, including a distinctive four-note theme associated with the character of Iolanthe. The Fairy Queen's music parodies that of Wagnerian heroines such as Brünnhilde. The score is wider in range of emotion and style, with innovative use of pizzicato strings, clever and varied underscoring of patter, the tender, sentimental eleventh-hour number for the title character, apt matching of the music to the absurd comedy of the lyrics, and a sustained first act finale with a series of dramatic situations that ends with the confrontation between the fairies and peers.
Gilbert, too, was influenced by earlier works, including "The Mountain Sylph" by John Barnett. Two characters in "Iolanthe", Strephon and Phyllis, are described as "Arcadian" shepherds. Arcadia was a legendary site of rural perfection, first described by the Ancient Greeks, that was a popular setting for writers of the 19th century. Gilbert had written an earlier work called "Happy Arcadia". He had also created several "fairy comedies" at the Haymarket Theatre in the early 1870s. These plays, influenced by the fairy work of James Planché, are founded upon the idea of self-revelation by characters under the influence of some magic or some supernatural interference. Several of "Iolanthe's" themes are continued from "Patience", including the battle between the sexes and the satire on legal and political themes. "Iolanthe" is one of several of Gilbert's works, including among others "The Wicked World", "Broken Hearts", "Fallen Fairies" and "Princess Ida", where the introduction of males into a tranquil world of women brings "mortal love" that wreaks havoc with the status quo.
Gilbert's absurdist style is on full display in "Iolanthe". For example, all the members of the House of Lords are in love with Phyllis, a ward of the Lord Chancellor. Gilbert satirically sets up the fantastical fairies as the agents of common sense in contrast with the nonsensical peers, who should be sober parliamentarians, while the most poetically romantic of the fairies, the "Arcadian" shepherd, Strephon, is chosen to lead both houses of Parliament. One of Gilbert's biographers, Andrew Crowther wrote: "The things that make opera memorable as a work of art the peers entering in the full pomp of their formal robes, magnificent and ridiculous." Among many pot-shots that Gilbert takes at lawyers in this opera, the Lord Chancellor sings that, as a young lawyer, he decided to "work on a new and original plan" similar to the practice in other professions, that diligence, honesty, honour and merit should lead to promotion. Gilbert uses the "fairy law" as a proxy for mortal law, in which an "equity draughtsman" can, with "the insertion of a single word", change the entire meaning of the law. Crowther notes: "All kinds of tone ... mingle in this opera: whimsy, fantasy, romance, wit and political satire."
Productions.
"Iolanthe" had a successful initial run in London of 398 performances, spanning the holiday seasons of both 1882 and 1883. Gilbert designed the costumes himself, and sets were by the Drury Lane designer Henry Emden. In an unprecedented first for any play, the New York premiere was given on the same date – 25 November 1882, with the composer's assistant, Alfred Cellier, conducting there. In Australia, "Iolanthe" was first seen on 9 May 1885 at the Theatre Royal, Melbourne, produced by J. C. Williamson.
In the British provinces, "Iolanthe" played – either by itself, or in repertory – continuously from February 1882 through 1885, then not again until late 1891. From then on, it was always present in the D'Oyly Carte Opera Company's touring repertory, being included in some part of every season until the company's closure in 1982. Most of the costumes were redesigned by Percy Anderson in 1915 and by George Sheringham in 1932, and Peter Goffin designed new sets in 1957 and some new costumes in 1960. After its original production, "Iolanthe" was not revived in London until 1901, making it the first of the operas to be revived after the composer's death the year before. It was also included in two Savoy repertory seasons, in 1907 and 1908–09.
"Iolanthe" was the first Gilbert and Sullivan opera performed professionally in Britain by a non-D'Oyly Carte company. It was produced by the Sadler's Wells Opera (now English National Opera) in January 1962, immediately after the Gilbert copyrights expired. It was well received and was successfully revived for many seasons by Sadler's Wells until 1978. Michael Heyland restaged "Iolanthe" for D'Oyly Carte in 1977, the year of Queen Elizabeth's Silver Jubilee, with silver-themed designs. "Iolanthe" has remained one of the most popular of the Gilbert and Sullivan works. Thousands of professional and amateur productions of the opera have been given throughout the English-speaking world, and the opera continues to be performed regularly today. The Internet Broadway Database lists 20 productions of the opera on Broadway alone.
The following table shows the history of the D'Oyly Carte productions in Gilbert's lifetime (not including touring companies):
Historical casting.
The following tables show the casts of the principal original productions and D'Oyly Carte Opera Company touring repertory at various times through to the company's 1982 closure:
Selected recordings.
Of the D'Oyly Carte Opera Company recordings of this opera, the 1930 and 1960 recordings have been the best received, and the latter includes the dialogue. The revived D'Oyly Carte's 1991 recording contains Strephon's cut number "Fold Your Flapping Wings" as a bonus track.
On video are the 1982 Brent Walker production and more recent performances from the International Gilbert and Sullivan Festival.
Cultural influence.
"Iolanthe" offers a satirical portrayal of elements of the British constitution, such as the House of Lords and the position of Lord Chancellor that has influenced modern public debate concerning these institutions, and when Margaret Thatcher was elected as Prime Minister, the press joked about the line from the opera "This comes of women interfering in politics!" Lord Falconer, who served as Tony Blair's second Lord Chancellor, was reportedly influenced by "Iolanthe" in his moves to reform or disband the office.
William H. Rehnquist, former Chief Justice of the United States, was a great Gilbert and Sullivan fan and was inspired by the costume of the Lord Chancellor, in a production of "Iolanthe", to add four golden stripes to the sleeves of his judicial robes. The next Chief Justice, John G. Roberts Jr., did not retain the ornamentation. In 1980, while an Associate Justice, Rehnquist mentioned the Lord Chancellor in his dissenting opinion in the case of "Richmond Newspapers, Inc. v. Virginia", comparing the majority opinion to the hubris of the Lord Chancellor: "The Law is the true embodiment/Of everything that's excellent./It has no kind of fault or flaw/And I, My Lords, embody the Law."
"The Ratepayers' Iolanthe" was a 1984 musical adapted by Ned Sherrin and Alistair Beaton. Sherrin directed and won a Laurence Olivier Award for Outstanding Achievement in a Musical for the musical's "conception".
The science fiction writer Isaac Asimov was a Gilbert and Sullivan fan. His Foundation Trilogy was conceived after his reading "Iolanthe" started a train of thought about military empires. Also, in "Runaround", a story in Asimov's "I, Robot", a robot, while in a state similar to drunkenness, sings snippets of Gilbert and Sullivan songs, including "The Nightmare Song" from "Iolanthe". In Michael Chabon's 2004 novel "The Final Solution", Bruno the parrot sings bits from "Iolanthe". The eponymous hero of David Nobbs' "The Fall and Rise of Reginald Perrin" has "Iolanthe" as a middle name, allegedly due to his being born during a performance of the opera. An illustrated booklet, "A Parody on Iolanthe", was written and published by D. Dalziel in 1883 and concerns the Chicago & Alton Railway.
In his 1974 album Todd, Todd Rundgren performs the "Lord Chancellor's Nightmare Song" ("When you're lying awake...").

</doc>
<doc id="46784" url="https://en.wikipedia.org/wiki?curid=46784" title="Daniel Bernoulli">
Daniel Bernoulli

Daniel Bernoulli FRS (; ; 8 February 1700 – 17 March 1782) was a Swiss mathematician and physicist and was one of the many prominent mathematicians in the Bernoulli family. He is particularly remembered for his applications of mathematics to mechanics, especially fluid mechanics, and for his pioneering work in probability and statistics. His name is commemorated in the Bernoulli's principle, a particular example of the conservation of energy, which describes the mathematics of the mechanism underlying the operation of two important technologies of the 20th century: the carburetor and the airplane wing.
Early life.
Daniel Bernoulli was born in Groningen, in the Netherlands, into a family of distinguished mathematicians. 
The Bernoulli family came originally from Antwerp, at that time in the Spanish Netherlands, but emigrated to escape the Spanish persecution of the Huguenots. After a brief period in Frankfurt the family moved to Basel, in Switzerland.
Daniel was the son of Johann Bernoulli (one of the "early developers" of calculus), nephew of Jacob Bernoulli (who "was the first to discover the theory of probability"). He had two brothers, Niklaus and Johann II. Daniel Bernoulli was described by W. W. Rouse Ball as "by far the ablest of the younger Bernoullis". He is said to have had a bad relationship with his father. Upon both of them entering and tying for first place in a scientific contest at the University of Paris, Johann, unable to bear the "shame" of being compared as Daniel's equal, banned Daniel from his house. Johann Bernoulli also plagiarized some key ideas from Daniel's book "Hydrodynamica" in his own book "Hydraulica" which he backdated to before "Hydrodynamica". Despite Daniel's attempts at reconciliation, his father carried the grudge until his death.
Around schooling age, his father, Johann, encouraged him to study business, there being poor rewards awaiting a mathematician. However, Daniel refused, because he wanted to study mathematics. He later gave in to his father's wish and studied business. His father then asked him to study in medicine, and Daniel agreed under the condition that his father would teach him mathematics privately, which they continued for some time. Daniel studied medicine at Basel, Heidelberg, and Strasbourg, and earned a PhD in anatomy and botany in 1721.
He was a contemporary and close friend of Leonhard Euler. He went to St. Petersburg in 1724 as professor of mathematics, but was very unhappy there, and a temporary illness in 1733 gave him an excuse for leaving St. Petersberg. He returned to the University of Basel, where he successively held the chairs of medicine, metaphysics, and natural philosophy until his death.
In May, 1750 he was elected a Fellow of the Royal Society.
Mathematical work.
His earliest mathematical work was the "Exercitationes" ("Mathematical Exercises"), published in 1724 with the help of Goldbach. Two years later he pointed out for the first time the frequent desirability of resolving a compound motion into motions of translation and motion of rotation. His chief work is "Hydrodynamica", published in 1738; it resembles Joseph Louis Lagrange's "Mécanique Analytique" in being arranged so that all the results are consequences of a single principle, namely, conservation of energy. This was followed by a memoir on the theory of the tides, to which, conjointly with the memoirs by Euler and Colin Maclaurin, a prize was awarded by the French Academy: these three memoirs contain all that was done on this subject between the publication of Isaac Newton's "Philosophiae Naturalis Principia Mathematica" and the investigations of Pierre-Simon Laplace. Bernoulli also wrote a large number of papers on various mechanical questions, especially on problems connected with vibrating strings, and the solutions given by Brook Taylor and by Jean le Rond d'Alembert.
Together Bernoulli and Euler tried to discover more about the flow of fluids. In particular, they wanted to know about the relationship between the speed at which blood flows and its pressure. To investigate this, Daniel experimented by puncturing the wall of a pipe with a small open ended straw and noted that the height to which the fluid rose up the straw was related to fluid's pressure in the pipe.
Soon physicians all over Europe were measuring patients' blood pressure by sticking point-ended glass tubes directly into their arteries. It was not until about 170 years later, in 1896 that an Italian doctor discovered a less painful method which is still in use today. However, Bernoulli's method of measuring pressure is still used today in modern aircraft to measure the speed of the air passing the plane; that is its air speed.
Taking his discoveries further, Daniel Bernoulli now returned to his earlier work on Conservation of Energy. It was known that a moving body exchanges its kinetic energy for potential energy when it gains height. Daniel realised that in a similar way, a moving fluid exchanges its kinetic energy for pressure. Mathematically this law is now written:
where P is pressure, ρ is the density of the fluid and u is its velocity. A consequence of this law is that if the velocity increases then the pressure falls. This is exploited by the wing of an aeroplane which is designed to create an area above its surface where the air velocity increases. The pressure in this area is lower than that under the wing, so the wing is pushed upwards by the relatively higher pressure under the wing.
Statistics.
Daniel Bernoulli was also the author in 1738 of "Specimen theoriae novae de mensura sortis (Exposition of a New Theory on the Measurement of Risk)", in which the St. Petersburg paradox was the base of the economic theory of risk aversion, risk premium and utility.
One of the earliest attempts to analyze a statistical problem involving censored data was Bernoulli's 1766 analysis of smallpox morbidity and mortality data to demonstrate the efficacy of vaccination.
Physics.
In "Hydrodynamica (1738)" he laid the basis for the kinetic theory of gases, and applied the idea to explain Boyle's law.
He worked with Euler on elasticity and the development of the Euler-Bernoulli beam equation. Bernoulli's principle is of critical use in aerodynamics.
According to Léon Brillouin, the principle of superposition was first stated by Daniel Bernoulli in 1753: "The general motion of a vibrating system is given by a superposition of its proper vibrations."
Bibliography.
"Original entry based on the public domain Rouse History of Mathematics"

</doc>
<doc id="46789" url="https://en.wikipedia.org/wiki?curid=46789" title="Jean-Baptiste Say">
Jean-Baptiste Say

Jean-Baptiste Say (; 5 January 1767 – 15 November 1832) was a French economist and businessman. He had classically liberal views and argued in favor of competition, free trade, and lifting restraints on business. He is best known for Say's Law, also known as the law of markets, which he popularized. Scholars disagree on the surprisingly subtle question of whether it was Say who first stated what we now call Say's Law.
Biography.
Jean-Baptiste Say was born in Lyon. His father, Jean-Etienne Say, was born to a Protestant family which had moved from Nîmes to Geneva for some time in consequence of the revocation of the Edict of Nantes. (His brother Louis Auguste (1774–1840) was also an economist). Say was intended to follow a commercial career, and in 1785 was sent, with his brother Horace, to complete his education in England: here he attended a private school in Croydon, and was afterwards employed by a merchant in London. When, on the death of the latter, he returned to France in 1787, he was employed in the office of a life assurance company directed by Étienne Clavière.
Say's first literary attempt was a pamphlet on the liberty of the press, published in 1789. He later worked under Mirabeau on the Courrier de Provence. In 1792 he took part as a volunteer in the campaign of Champagne; in 1793 he assumed, in conformity with the Revolutionary fashion, the pre-name of Atticus, and became secretary to Clavière, then finance minister.
In 1793 Say married Mlle Deloche, daughter of a former lawyer. From 1794 to 1800 Say edited a periodical entitled "La Decade philosophique, litteraire, et politique", in which he expounded the doctrines of Adam Smith. He had by this time established his reputation as a publicist, and, when the consular government was established in 1799, he was selected as one of the hundred members of the tribunate, resigning the direction of the "Decade".
In 1800 he published in "Olbie, ou essai sur les moyens de réformer les mœurs d'une nation". In 1803 appeared Say's principal work, the "Traité d'économie politique ou simple exposition de la manière dont se forment, se distribuent et se composent les richesses". In 1804, having shown his unwillingness to sacrifice his convictions for the purpose of furthering the designs of Napoleon, he was removed from the office of tribune. He then turned to industrial pursuits, and, having made himself acquainted with the processes of the cotton manufacture, founded at Auchy-lès-Hesdin, in the Pas de Calais, a spinning-mill which employed four or five hundred persons, principally women and children. He devoted his leisure to the improvement of his economic treatise, which had for some time been out of print, but which the censorship did not permit him to republish.
In 1814 he "availed himself" (to use his own words) of the sort of liberty arising from the entrance of the allied powers into France to bring out a second edition of the work, dedicated to the emperor Alexander I of Russia, who had professed himself his pupil. In the same year the French government sent him to study the economic condition of the United Kingdom. The results of his observations appeared in a tract "De l'Angleterre et des Anglais".
A third edition of the "Traité" appeared in 1817. A chair of industrial economy was founded for him in 1819 at the Conservatoire des Arts et Métiers. Equally in 1819 he is co-founder of ESCP Europe which became the first business school in the world. In 1831 he was made professor of political economy at the Collège de France. Say in 1828–1830 published his "Cours complet d'economie politique pratique". In 1826, he was elected a foreign member of the Royal Swedish Academy of Sciences.
In his later years Say became subject to attacks of nervous apoplexy. He lost his wife in January 1830; and from that time his health constantly declined.
When the revolution of that year broke out, he was named a member of the council-general of the department of the Seine, but found it necessary to resign.
He died in Paris on 15 November 1832, and is buried in the cemetery of Invalides.
Say's Law.
He is well known for Say's Law (or Say's Law of Markets), often summarised as
The exact phrase "supply creates its own demand" was coined by John Maynard Keynes, who criticized it, but this characterization is disputed as a misrepresentation by some advocates of Say's law. Similar sentiments, though different wordings, appear in the work of J. S. Mill (1848) and his father, James Mill (1808). The Scottish classical economist James Mill restates Say's Law in 1808, writing that "production of commodities creates, and is the one and universal cause which creates a market for the commodities produced."
In Say's language, "products are paid for with products" (1803: p. 153) or "a glut can take place only when there are too many means of production applied to one kind of product and not enough to another" (1803: pp. 178–9). Explaining his point at length, he wrote that:
It is worthwhile to remark that a product is no sooner created than it, from that instant, affords a market for other products to the full extent of its own value. When the producer has put the finishing hand to his product, he is most anxious to sell it immediately, lest its value should diminish in his hands. Nor is he less anxious to dispose of the money he may get for it; for the value of money is also perishable. But the only way of getting rid of money is in the purchase of some product or other. Thus the mere circumstance of creation of one product immediately opens a vent for other products. "(J.B. Say, 1803: pp. 138–9)"
He also wrote, that it is not the abundance of money but the abundance of other products in general that facilitates sales:
Money performs but a momentary function in this double exchange; and when the transaction is finally closed, it will always be found, that one kind of commodity has been exchanged for another.
Say's Law may also have been culled from Ecclesiastes 5:11 – "When goods increase, they are increased that eat them: and what good is there to the owners thereof, saving the beholding of them with their eyes?" (KJV) Say's Law has been considered by John Kenneth Galbraith as "the most distinguished example of the stability of economic ideas, including when they are wrong."
Quotes.
"To encourage whale-hunting, the English government prohibits vegetable oils which we burn in France in draught-lamps. What results from this? That one of these lamps, which costs a Frenchmen 60 francs per year, costs an Englishman 150 francs. The intention, some say, is to support the navy and to multiply the number of sailors, that each lamp nozzle costs Englishmen 90 more francs than in France. In this case, it is to multiply the number of sailors by the means of a trade that generates losses: it would be better to multiply them by a lucrative trade."
"A hard working laborer, I was told, fancied working by candlelight. He had calculated that, during his vigil, he burned a 4-penny candle, earning 8 pennies by his work. A tax on tallows and another on the manufacture of the candles increased by 5 pennies the cost of his luminary, which became thus more expensive than the value of the product that it could shed light upon. From then on, as soon as night fell, the workman remained idle; he lost the 4 pennies which his work could obtain him, and without the tax service perceiving anything out of this production. Such a loss must be multiplied by the number of the workmen in a city and by the number of the days of the year."
"There is no security of property, where a despotic authority can possess itself of the property of the subject against his consent. Neither is there such security, where the consent is merely nominal and delusive."
"The property a man has in his own industry, is violated, whenever he is forbidden the free exercise of his faculties or talents, except insomuch as they would interfere with the rights of third parties."
— Jean-Baptiste Say, "A Treatise on Political Economy", 1803

</doc>
<doc id="46790" url="https://en.wikipedia.org/wiki?curid=46790" title="Desert varnish">
Desert varnish

Desert varnish or rock varnish is an orange-yellow to black coating found on exposed rock surfaces in arid environments. Desert varnish is usually around one micrometer thick and represents nanometre-scale layering. Rock rust and desert patina are other terms which are also used for the condition, but less often.
Formation.
Desert varnish forms only on physically stable rock surfaces that are no longer subject to frequent precipitation, fracturing or wind abrasion. The varnish is primarily composed of particles of clay along with iron and manganese oxides. There is also a host of trace elements and almost always some organic matter. The colour of the varnish varies from shades of brown to black.
It has been suggested that desert varnish should be investigated as a potential candidate for a "shadow biosphere".
Composition.
Originally scientists thought that the varnish was made from substances drawn out of the rocks it coats. Microscopic and microchemical observations, however, show that a major part of varnish is clay, which could only arrive by wind. Clay, then, acts as a to catch additional substances that chemically react together when the rock reaches high temperatures in the desert sun. Wetting by dew is also important in the process.
An important characteristic of black desert varnish is that it has an unusually high concentration of manganese. Manganese is relatively rare in the Earth's crust, making up only 0.12% of its weight. In black desert varnish, however, manganese is 50 to 60 times more abundant. One proposal for a mechanism of desert varnish formation is that it is caused by manganese-oxidizing microbes (mixotrophs) which are common in environments poor in organic nutrients. A micro-environment pH above 7.5 is inhospitable for manganese-concentrating microbes. In such conditions, orange varnishes develop, poor in manganese (Mn) but rich in iron (Fe). An alternative hypothesis for Mn/Fe fluctuation has been proposed that considers Mn-rich and Fe-rich varnishes to be related to humid and arid climates, respectively 
Even though it contains high concentrations of iron and manganese, there are no significant modern uses of desert varnish. However, some Native American peoples created petroglyphs by scraping or chipping away the dark varnish to expose the lighter rock beneath.
Desert varnish often obscures the identity of the underlying rock, and different rocks have varying abilities to accept and retain varnish. Limestones, for example, typically do not have varnish because they are too water-soluble and therefore do not provide a stable surface for varnish to form. Shiny, dense and black varnishes form on basalt, fine quartzites and metamorphosed shales due to these rocks' relatively high resistance to weathering.

</doc>
<doc id="46793" url="https://en.wikipedia.org/wiki?curid=46793" title="Death Valley National Park">
Death Valley National Park

Death Valley National Park is a national park in the United States Of America in the two states California and Nevada and is located east of the Sierra Nevada, occupying an interface zone between the arid Great Basin and Mojave deserts in the United States. The park protects the northwest corner of the Mojave Desert and contains a diverse desert environment of salt-flats, sand dunes, badlands, valleys, canyons, and mountains. It is the largest national park in the lower 48 states and has been declared an International Biosphere Reserve. Approximately 95% of the park is a designated wilderness area. It is the hottest and driest of the national parks in the United States. The second-lowest point in the Western Hemisphere is in Badwater Basin, which is below sea level. The park is home to many species of plants and animals that have adapted to this harsh desert environment. Some examples include creosote bush, bighorn sheep, coyote, and the Death Valley pupfish, a survivor of much wetter times.
A series of Native American groups inhabited the area from as early as 7000 BC, most recently the Timbisha around 1000 AD who migrated between winter camps in the valleys and summer grounds in the mountains. A group of European-Americans that became stuck in the valley in 1849 while looking for a shortcut to the gold fields of California gave the valley its name, even though only one of their group died there. Several short-lived boom towns sprang up during the late 19th and early 20th centuries to mine gold and silver. The only long-term profitable ore to be mined was borax, which was transported out of the valley with twenty-mule teams. The valley later became the subject of books, radio programs, television series, and movies. Tourism blossomed in the 1920s, when resorts were built around Stovepipe Wells and Furnace Creek. Death Valley National Monument was declared in 1933 and the park was substantially expanded and became a national park in 1994.
The natural environment of the area has been shaped largely by its geology. The valley itself is actually a graben. The oldest rocks are extensively metamorphosed and at least 1.7 billion years old. Ancient, warm, shallow seas deposited marine sediments until rifting opened the Pacific Ocean. Additional sedimentation occurred until a subduction zone formed off the coast. This uplifted the region out of the sea and created a line of volcanoes. Later the crust started to pull apart, creating the current Basin and Range landform. Valleys filled with sediment and, during the wet times of glacial periods, with lakes, such as Lake Manly.
In 2013, Death Valley National Park was designated as a dark sky park by the International Dark-Sky Association.
Geographic setting.
There are two major valleys in the park, Death Valley and Panamint Valley. Both of these valleys were formed within the last few million years and both are bounded by north–south-trending mountain ranges. These and adjacent valleys follow the general trend of Basin and Range topography with one modification: there are parallel strike-slip faults that perpendicularly bound the central extent of Death Valley. The result of this shearing action is additional extension in the central part of Death Valley which causes a slight widening and more subsidence there.
Uplift of surrounding mountain ranges and subsidence of the valley floor are both occurring. The uplift on the Black Mountains is so fast that the alluvial fans (fan-shaped deposits at the mouth of canyons) there are small and steep compared to the huge alluvial fans coming off the Panamint Range. Fast uplift of a mountain range in an arid environment often does not allow its canyons enough time to cut a classic V-shape all the way down to the stream bed. Instead, a V-shape ends at a slot canyon halfway down, forming a 'wine glass canyon.' Sediment is deposited on a small and steep alluvial fan.
At below sea level, Badwater Basin on Death Valley's floor is the second-lowest depression in the Western Hemisphere (behind Laguna del Carbón in Argentina), while Mount Whitney, only to the west, rises to . This topographic relief is the greatest elevation gradient in the contiguous United States and is the terminus point of the Great Basin's southwestern drainage. Although the extreme lack of water in the Great Basin makes this distinction of little current practical use, it does mean that in wetter times the lake that once filled Death Valley (Lake Manly) was the last stop for water flowing in the region, meaning the water there was saturated in dissolved materials. Thus the salt pans in Death Valley are among the largest in the world and are rich in minerals, such as borax and various salts and hydrates. The largest salt pan in the park extends from the Ashford Mill Site to the Salt Creek Hills, covering some of the valley floor. The best known playa in the park is the Racetrack, known for its moving rocks.
Climate.
Death Valley is the hottest and driest place in North America because of its lack of surface water and its low relief. It is so frequently the hottest spot in the United States that many tabulations of the highest daily temperatures in the country omit Death Valley as a matter of course. 
On the afternoon of July 10, 1913, the United States Weather Bureau recorded a high temperature of 134 °F (56.7 °C) at Greenland Ranch (now Furnace Creek) in Death Valley. This temperature stands as the highest ambient air temperature ever recorded at the surface of the Earth. (A report of a temperature of 58 °C (136.4 °F) recorded in Libya in 1922 was later determined to be inaccurate.) Daily summer temperatures of or greater are common, as well as below freezing nightly temperatures in the winter. July is the hottest month, with an average high of and an average low of . December is the coldest month, with an average high of and an average low of . The record low is . 
Several of the larger Death Valley springs derive their water from a regional aquifer, which extends as far east as southern Nevada and Utah. Much of the water in this aquifer has been there for many thousands of years, since the Pleistocene ice ages, when the climate was cooler and wetter. Today's drier climate does not provide enough precipitation to recharge the aquifer at the rate at which water is being withdrawn.
The highest range within the park is the Panamint Range with Telescope Peak being its highest point at . The Death Valley region is a transitional zone in the northernmost part of the Mojave Desert and consists of five mountain ranges removed from the Pacific Ocean. Three of these are significant barriers: the Sierra Nevada, the Argus Range, and the Panamint Range. Air masses tend to lose moisture as they are forced up over mountain ranges, in what climatologists call a rainshadow effect.
The exaggerated rainshadow effect for the Death Valley area makes it North America's driest spot, receiving about of rainfall annually at Badwater (some years fail to register any measurable rainfall). Annual average precipitation varies from overall below sea level to over in the higher mountains that surround the valley. When rain does arrive it often does so in intense storms that cause flash floods which remodel the landscape and sometimes create very shallow ephemeral lakes.
The hot, dry climate makes it difficult for soil to form. Mass wasting, the down-slope movement of loose rock, is therefore the dominant erosive force in mountainous area, resulting in "skeletonized" ranges (mountains with very little soil on them). Sand dunes in the park, while famous, are not nearly as widespread as their fame or the dryness of the area may suggest. The Mesquite Flat dune field is the most easily accessible from the paved road just east of Stovepipe Wells in the north-central part of the valley and is primarily made of quartz sand. Another dune field is just to the north but is instead mostly composed of travertine sand. The highest dunes in the park, and some of the highest in North America, are located in the Eureka Valley about to the north of Stovepipe Wells, while the Panamint Valley dunes and the Saline Valley dunes are located west and northwest of the town, respectively. The Ibex dune field is near the seldom-visited Ibex Hill in the southernmost part of the park, just south of the Saratoga Springs marshland. All of the latter four dune fields are accessible only via unpaved roads. Prevailing winds in the winter come from the north, and prevailing winds in the summer come from the south. Thus the overall position of the dune fields remains more or less fixed.
There are rare exceptions to the dry nature of the area. In 2005, an unusually wet winter created a 'lake' in the Badwater Basin and led to the greatest wildflower season in the park's history. In October 2015, a "1000 year flood event" with over three inches of rain caused major damage in Death Valley National Park. 
Human history.
Early inhabitants and transient populations.
Four Native American cultures are known to have lived in the area during the last 10,000 years. The first known group, the Nevares Spring People, were hunters and gatherers who arrived in the area perhaps 9,000 years ago (7000 BC) when there were still small lakes in Death Valley and neighboring Panamint Valley. A much milder climate persisted at that time, and large game animals were still plentiful. By 5,000 years ago (3000 BC) the Mesquite Flat People displaced the Nevares Spring People. Around 2,000 years ago the Saratoga Spring People moved into the area, which by then was probably already a hot, dry desert. This culture was more advanced at hunting and gathering and was skillful at handcrafts. They also left mysterious stone patterns in the valley.
One-thousand years ago, the nomadic Timbisha (formerly called Shoshone and also known as Panamint or Koso) moved into the area and hunted game and gathered mesquite beans along with pinyon pine nuts. Because of the wide altitude differential between the valley bottom and the mountain ridges, especially on the west, the Timbisha practiced a vertical migration pattern. Their winter camps were located near water sources in the valley bottoms. As the spring and summer progressed and the weather warmed, grasses and other plant food sources ripened at progressively higher altitudes. November found them at the very top of the mountain ridges where they harvested pine nuts before moving back to the valley bottom for winter. 
The California Gold Rush brought the first people of European descent known to visit the immediate area. In December 1849 two groups of California Gold Country-bound white travelers with perhaps 100 wagons total stumbled into Death Valley after getting lost on what they thought was a shortcut off the Old Spanish Trail. Called the Bennett-Arcane Party, they were unable to find a pass out of the valley for weeks; they were able to find fresh water at various springs in the area, but were forced to eat several of their oxen to survive. They used the wood of their wagons to cook the meat and make jerky. The place where they did this is today referred to as "Burned Wagons Camp" and is located near the sand dunes.
After abandoning their wagons, they eventually were able to hike out of the valley. Just after leaving the valley, one of the women in the group turned and said, "Goodbye Death Valley," giving the valley they endured its name. Included in the party was William Lewis Manly whose autobiographical book "Death Valley in '49" detailed this trek and popularized the area (geologists later named the prehistoric lake that once filled the valley after him).
Boom and bust.
The ores that are most famously associated with the area were also the easiest to collect and the most profitable: evaporite deposits such as salts, borate, and talc. Borax was found by Rosie and Aaron Winters near Furnace Creek Ranch (then called Greenland) in 1881. Later that same year, the Eagle Borax Works became Death Valley's first commercial borax operation. William Tell Coleman built the Harmony Borax Works plant and began to process ore in late 1883 or early 1884, continuing until 1888. This mining and smelting company produced borax to make soap and for industrial uses. The end product was shipped out of the valley to the Mojave railhead in 10-ton-capacity wagons pulled by "twenty-mule teams" that were actually teams of 18 mules and two horses each. The teams averaged two miles (3 km) an hour and required about 30 days to complete a round trip. The trade name "20-Mule Team Borax" was established by Francis Marion Smith's Pacific Coast Borax Company after Smith acquired Coleman's borax holdings in 1890. A memorable advertising campaign used the wagon's image to promote the Boraxo brand of granular hand soap and the Death Valley Days radio and television programs. In 1914, the Death Valley Railroad was built to serve mining operations on the east side of the valley. Mining continued after the collapse of Coleman's empire, and by the late 1920s the area was the world's number one source of borax. Some four to six million years old, the Furnace Creek Formation is the primary source of borate minerals gathered from Death Valley's playas.
Other visitors stayed to prospect for and mine deposits of copper, gold, lead, and silver. These sporadic mining ventures were hampered by their remote location and the harsh desert environment. In December 1903, two men from Ballarat were prospecting for silver. One was an out-of-work Irish miner named Jack Keane and the other was a one-eyed Basque butcher named Domingo Etcharren. Quite by accident, Keane discovered an immense ledge of free-milling gold by the duo's work site and named the claim the Keane Wonder Mine. This started a minor and short-lived gold rush into the area. The Keane Wonder Mine, along with mines at Rhyolite, Skidoo and Harrisburg, were the only ones to extract enough metal ore to make them worthwhile. Outright shams such as Leadfield also occurred, but most ventures quickly ended after a short series of prospecting mines failed to yield evidence of significant ore (these mines now dot the entire area and are a significant hazard to anyone who enters them). The boom towns which sprang up around these mines flourished during the 1900s (decade) but soon declined after the Panic of 1907.
Early tourism.
The first documented tourist facilities in Death Valley were a set of tent houses built in the 1920s where Stovepipe Wells is now located. People flocked to resorts built around natural springs thought to have curative and restorative properties. In 1927, Pacific Coast Borax turned the crew quarters of its Furnace Creek Ranch into a resort, creating the Furnace Creek Inn and resort. The spring at Furnace Creek was harnessed to develop the resort, and as the water was diverted, the surrounding marshes and wetlands started to shrink.
Soon the valley was a popular winter destination. Other facilities started off as private getaways but were later opened to the public. Most notable among these was Death Valley Ranch, better known as Scotty's Castle. This large ranch home built in the Spanish Revival style became a hotel in the late 1930s and, largely because of the fame of Death Valley Scotty, a tourist attraction. Death Valley Scotty, whose real name was Walter Scott, was a gold miner who pretended to be owner of "his castle", which he claimed to have built with profits from his gold mine. Neither claim was true, but the real owner, Chicago millionaire Albert Mussey Johnson, encouraged the myth. When asked by reporters what his connection was to Walter Scott's castle, Johnson replied that he was Mr. Scott's banker.
Protection and later history.
President Herbert Hoover proclaimed a national monument in and around Death Valley on February 11, 1933, setting aside almost two million acres (8,000 km2) of southeastern California and small parts of southwesternmost Nevada. Twelve companies worked in Death Valley using Civilian Conservation Corps workers during the Great Depression and on into the early 1940s. They built barracks, graded of roads, installed water and telephone lines, and erected a total of 76 buildings. Trails in the Panamint Range were built to points of scenic interest, and an adobe village, laundry and trading post were constructed for Shoshone Indians. Five campgrounds, restrooms, an airplane landing field and picnic facilities were also built.
Creation of the monument resulted in a temporary closing of the lands to prospecting and mining. However, Death Valley was quickly reopened to mining by Congressional action in June of the same year. As improvements in mining technology allowed lower grades of ore to be processed, and new heavy equipment allowed greater amounts of rock to be moved, mining in Death Valley changed. Gone were the days of the "single-blanket, jackass prospector" long associated with the romantic west. Open pit and strip mines scarred the landscape as international mining corporations bought claims in highly visible areas of the national monument. The public outcry that ensued led to greater protection for all national park and monument areas in the United States.
In 1976, Congress passed the Mining in the Parks Act, which closed Death Valley National Monument to the filing of new mining claims, banned open-pit mining and required the National Park Service to examine the validity of tens of thousands of pre-1976 mining claims. Mining was allowed to resume on a limited basis in 1980 with stricter environmental standards. The park's Resources Management Division monitors mining within park boundaries and continues to review the status of 125 unpatented mining claims and 19 patented claim groups, while ensuring that federal guidelines are followed and the park's resources are protected. In 2005, the Billie Mine, an underground borax mine located along the road to Dante's View, closed, ending mining in the park.
Death Valley National Monument was designated a biosphere reserve in 1984. On October 31, 1994, the monument was expanded by 1.3 million acres (5,300 km2) and re-designated as a national park, via congressional passage of the California Desert Protection Act (Public Law 103-433). Consequently, the elevated status for Death Valley made it the largest national park in the contiguous United States.
Many of the larger cities and towns within the boundary of the regional ground water flow system that the park and its plants and animals rely upon are experiencing some of the fastest growth rates of any place in the United States. Notable examples within a radius of Death Valley National Park include Las Vegas and Pahrump, Nevada. In the case of Las Vegas, the local Chamber of Commerce estimates that 6,000 people are moving to the city every month. Between 1985 and 1995, the population of the Las Vegas Valley increased from 550,700 to 1,138,800.
In 1977, parts of Death Valley were used by director George Lucas as a filming location for "Star Wars", providing the setting for the fictional planet Tatooine.
Geologic history.
The park has a diverse and complex geologic history. Since its formation, the area that comprises the park has experienced at least four major periods of extensive volcanism, three or four periods of major sedimentation, and several intervals of major tectonic deformation where the crust has been reshaped. Two periods of glaciation (a series of ice ages) have also had effects on the area, although no glaciers ever existed in the ranges now in the park.
Basement and Pahrump Group.
Little is known about the history of the oldest exposed rocks in the area due to extensive metamorphism (alteration of rock by heat and pressure). Radiometric dating gives an age of 1,700 million years for the metamorphism during the Proterozoic. About 1,400 million years ago a mass of granite now in the Panamint Range intruded this complex. Uplift later exposed these rocks to nearly 500 million years of erosion.
The Proterozoic sedimentary formations of the Pahrump Group were deposited on these basement rocks. This occurred following uplift and erosion of any earlier sediments from the Proterozoic basement rocks. The Pahrump is composed of arkose conglomerate (quartz clasts in a concrete-like matrix) and mudstone in its lower part, followed by dolomite from carbonate banks topped by algal mats as stromatolites, and finished with basin-filling sediment derived from the above, including possible glacial till from the hypothesized Snowball Earth glaciation. The very youngest rocks in the Pahrump Group are basaltic lava flows.
Rifting and deposition.
A rift opened and subsequently flooded the region as part of the breakup of the supercontinent Rodinia in the Neoproterozoic (by about 755 million years ago) and the creation of the Pacific Ocean. A shoreline similar to the present Atlantic Ocean margin of the United States lay to the east. An algal mat-covered carbonate bank was deposited, forming the Noonday Dolomite. Subsidence of the region occurred as the continental crust thinned and the newly formed Pacific widened, forming the Ibex Formation. An angular unconformity (an uneven gap in the geologic record) followed.
A true ocean basin developed to the west, breaking all the earlier formations along a steep front. A wedge of clastic sediment then began to accumulate at the base of the two underwater precipices, starting the formation of opposing continental shelfs. Three formations developed from sediment that accumulated on the wedge. The region's first known fossils of complex life are found in the resulting formations. Notable among these are the Ediacara fauna and trilobites, the evolution of the latter being part of the Cambrian Explosion of life.
The sandy mudflats gave way about 550 million years ago to a carbonate platform (similar to the one around the present-day Bahamas), which lasted for the next 300 million years of Paleozoic time (refer to the middle of the timescale image). Death Valley's position was then within ten or twenty degrees of the Paleozoic equator. Thick beds of carbonate-rich sediments were periodically interrupted by periods of emergence. Although details of geography varied during this immense interval of time, a north-northeasterly trending coastline generally ran from Arizona up through Utah. The resulting eight formations and one group are thick and underlay much of the Cottonwood, Funeral, Grapevine, and Panamint ranges.
Compression and uplift.
In the early-to-mid- Mesozoic the western edge of the North American continent was pushed against the oceanic plate under the Pacific Ocean, creating a subduction zone. A subduction zone is a type of contact between different crustal plates where heavier crust slides below lighter crust. Erupting volcanoes and uplifting mountains were created as a result, and the coastline was pushed to the west. The Sierran Arc started to form to the northwest from heat and pressure generated from subduction, and compressive forces caused thrust faults to develop.
A long period of uplift and erosion was concurrent with and followed the above events, creating a major unconformity, which is a large gap in the geologic record. Sediments worn off the Death Valley region were carried both east and west by wind and water. No Jurassic- to Eocene-aged sedimentary formations exist in the area, except for some possibly Jurassic-age volcanic rocks (see the top of the timescale image).
Erosion over many millions of years created a relatively featureless plain. Thirty-five million years ago, sluggish streams migrated laterally over its surface. Several other similar formations were also laid down.
Stretching and lakes.
Basin and Range-associated stretching of large parts of crust below southwestern United States and northwestern Mexico started around 16 million years ago and the region is still spreading. This stretching began to affect the Death and Panamint valleys area by 3 million years ago. Before this, rocks now in the Panamint Range were on top of rocks that would become the Black Mountains and the Cottonwood Mountains. Lateral and vertical transport of these blocks was accomplished by movement on normal faults. Right-lateral movement along strike-slip faults that run parallel to and at the base of the ranges also helped to develop the area. Torsional forces, probably associated with northwesterly movement of the Pacific Plate along the San Andreas Fault (west of the region), is responsible for the lateral movement.
Igneous activity associated with this stretching occurred from 12 million to 4 million years ago. Sedimentation is concentrated in valleys (basins) from material eroded from adjacent ranges. The amount of sediment deposited has roughly kept up with this subsidence, resulting in retention of more or less the same valley floor elevation over time.
Pleistocene ice ages started 2 million years ago, and melt from alpine glaciers on the nearby Sierra Nevada Mountains fed a series of lakes that filled Death and Panamint valleys and surrounding basins (see the top of the timescale image). The lake that filled Death Valley was the last of a chain of lakes fed by the Amargosa and Mojave Rivers, and possibly also the Owens River. The large lake that covered much of Death Valley's floor, which geologists call Lake Manly, started to dry up 10,500 years ago. Saltpans and playas were created as ice age glaciers retreated, thus drastically reducing the lakes' water source. Only faint shorelines are left.
Biology.
Habitat varies from saltpan at below sea level to the sub-alpine conditions found on the summit of Telescope Peak, which rises to . Vegetation zones include Creosote Bush, Desert Holly, and mesquite at the lower elevations and sage up through shadscale, blackbrush, Joshua Tree, pinyon-juniper, to Limber Pine and Bristlecone Pine woodlands. The saltpan is devoid of vegetation, and the rest of the valley floor and lower slopes have sparse cover, although where water is available, an abundance of vegetation is usually present. 
These zones and the adjacent desert support a variety of wildlife species, including 51 species of native mammals, 307 species of birds, 36 species of reptiles, 3 species of amphibians, and 2 species of native fish.
Small mammals are more numerous than large mammals, such as bighorn sheep, coyotes (image), bobcats, kit foxes, cougars, and mule deer. Mule deer are present in the pinyon/juniper associations of the Grapevine, Cottonwood, and Panamint ranges. Bighorn sheep are a rare species of mountain sheep that exist in isolated bands in the Sierra and in Death Valley. These are highly adaptable animals and can eat almost any plant. They have no known predators, but humans and burros compete for habitat.
The ancestors of the Death Valley Pupfish swam to the area from the Colorado River via a long-since dried-up system of rivers and lakes (see Lake Manly). They now live in two separate populations: one in Salt Creek and another in Cottonball Marsh.
Death Valley is one of the hottest and driest places in North America, yet it is home to over 1,000 species of plants; 23 of which, including the very rare Rock Lady ("Holmgrenanthe petrophila"), are not found anywhere else. Adaptation to the dry environment is key. For example, creosote bush and mesquite have tap-root systems that can extend down in order to take advantage of a year-round supply of ground water. The diversity of Death Valley's plant communities results partly from the region's location in a transition zone between the Mojave Desert, the Great Basin Desert and the Sonoran Desert.
This location, combined with the great relief found within the Park, supports vegetation typical of three biotic life zones: the lower Sonoran, the Canadian, and the Arctic/Alpine in portions of the Panamint Range. Based on the Munz and Keck (1968) classifications, seven plant communities can be categorized within these life zones, each characterized by dominant vegetation and representative of three vegetation types: scrub, desert woodland, and coniferous forest. Microhabitats further subdivide some communities into zones, especially on the valley floor.
Unlike more typical locations across the Mojave Desert, many of the water-dependent Death Valley habitats possess a diversity of plant and animal species that are not found anywhere else in the world. The existence of these species is due largely to a unique geologic history and the process of evolution that has progressed in habitats that have been isolated from one another since the Pleistocene epoch.
Activities.
Sightseeing is available by personal automobile, four-wheel drive, bicycle, mountain bike (on established roadways only), and hiking. Riding through the park on motorcycle is also a popular pastime. State Route 190, the Badwater Road, the Scotty's Castle Road, and paved roads to Dante's View and Wildrose provide access to the major scenic viewpoints and historic points of interest. More than of unpaved and four-wheel-drive roads provide access to wilderness hiking, camping, and historical sites. All vehicles must be licensed and street legal. There are hiking trails of varying lengths and difficulties, but most backcountry areas are accessible only by cross-country hiking. There are literally thousands of hiking possibilities. The normal season for visiting the park is from October 15 to May 15, because of summer extremes in temperature. Costumed living history tours of the historic Death Valley Scotty's Castle are conducted for a fee, but as of October 2015, are suspended due to flood damage to the Scotty's Castle buildings and grounds.
There are nine designated campgrounds within the park, and overnight backcountry camping permits are available at the Visitor Center. Xanterra Parks & Resorts owns and operates a private resort, the Furnace Creek Inn and Ranch Resort, which comprises two separate and distinct hotels: the Furnace Creek Inn is a four-star historic hotel, and the Furnace Creek Ranch is a three-star ranch-style property reminiscent of the mining and prospecting days. Death Valley Lodging Company operates the Stovepipe Wells Village motel. Stovepipe Wells Village is the only authorized concession operations located in Death Valley National Park. There are a few motels near various entrances to the park, in Shoshone, Death Valley Junction, Beatty, Nevada, and Panamint Springs.
The visitor center is located in the Furnace Creek resort area on State Route 190. A 12-minute introductory slide program is shown every 30 minutes. During the winter season—November through April—rangers offer interpretive tours and a wide variety of walks, talks, and slide presentations about Death Valley cultural and natural history. The visitor center has displays dealing with the park's geology, climate, wildlife and natural history. There are also specific sections dealing with the human history and pioneer experience. The Death Valley Natural History Association maintains a bookstore specifically geared to the natural and cultural history of the park.
Death Valley National Park is a popular location for stargazing as it has one of the darkest night skies in the United States. Despite Death Valley's remote location, its air quality and night visibility are threatened by civilization. In particular, light pollution is introduced by nearby Las Vegas. The darkest skies are, in general, located in the northwest of the park.

</doc>
<doc id="46795" url="https://en.wikipedia.org/wiki?curid=46795" title="Mono Lake">
Mono Lake

Mono Lake ( ) is a large, shallow saline soda lake in Mono County, California, formed at least 760,000 years ago as a terminal lake in an endorheic basin. The lack of an outlet causes high levels of salts to accumulate in the lake. These salts also make the lake water alkaline.
This desert lake has an unusually productive ecosystem based on brine shrimp that thrive in its waters, and provides critical nesting habitat for two million annual migratory birds that feed on the shrimp and blackflies (that also feed on the shrimp).
The human history of Mono Lake is associated with its productive ecosystem. The native Kutzadika'a people derived nutrition from the pupae of the alkali flies that live in the lake. When the city of Los Angeles diverted water from the lake, it lowered the lake level, which imperiled the migratory birds. The Mono Lake Committee formed in response and won a legal battle that forced Los Angeles to partially restore the lake level.
Geology.
Mono Lake occupies part of the Mono Basin, an endorheic basin that has no outlet to the ocean. Dissolved salts in the runoff thus remain in the lake and raise the water's pH levels and salt concentration. The tributaries of Mono Lake include Lee Vining Creek, Rush Creek and Mill Creek which flows through Lundy Canyon.
The basin was formed by geological forces over the last five million years: basin and range crustal stretching and associated volcanism and faulting at the base of the Sierra Nevada. Five million years ago, the Sierra Nevada was an eroded set of rolling hills and Mono Basin and Owens Valley did not yet exist.
From 4.5 to 2.6 million years ago, large volumes of basalt were extruded around what is now Cowtrack Mountain (east and south of Mono Basin); eventually covering and reaching a maximum thickness of . Later volcanism in the area occurred 3.8 million to 250,000 years ago. This activity was northwest of Mono Basin and included the formation of Aurora Crater, Beauty Peak, Cedar Hill (later an island in the highest stands of Mono Lake), and Mount Hicks.
Mono Lake is believed to have formed at least 760,000 years ago, dating back to the Long Valley eruption. Sediments located below the ash layer hint that Mono Lake could be a remnant of a larger and older lake that once covered a large part of Nevada and Utah, which would put it among the oldest lakes in North America. At its height during the most recent ice age, the lake would have been about deep. Prominent old shore lines, called strandlines by geologists, can be seen west of the Lake.
Currently, Mono Lake is in a geologically active area at the north end of the Mono–Inyo Craters volcanic chain and is close to Long Valley Caldera. Volcanic activity continues in the Mono Lake vicinity: the most recent eruption occurred 350 years ago, resulting in the formation of Paoha Island. Panum Crater (on the south shore of the lake) is an excellent example of a combined rhyolite dome and cinder cone.
Limnology.
The limnology of the lake shows it contains approximately 280 million tons of dissolved salts, with the salinity varying depending upon the amount of water in the lake at any given time. Before 1941, average salinity was approximately 50 grams per liter (g/l) (compared to a value of 31.5 g/l for the world's oceans). In January 1982, when the lake reached its lowest level of , the salinity had nearly doubled to 99 g/l. In 2002, it was measured at 78 g/l and is expected to stabilize at an average 69 g/l as the lake replenishes over the next 20 years.
An unintended consequence of ending the water diversions was the onset of a period of "meromixis" in Mono Lake. In the time prior to this, Mono Lake was typically "monomictic"; which means that at least once each year the deeper waters and the shallower waters of the lake mixed thoroughly, thus bringing oxygen and other nutrients to the deep waters. In meromictic lakes, the deeper waters do not undergo this mixing; the deeper layers are more saline than the water near the surface, and are typically nearly devoid of oxygen. As a result, becoming meromictic greatly changes a lake's ecology.
Mono Lake has experienced meromictic periods in the past; this most recent episode of meromixis, brought on by the end of the water diversions, commenced in 1994 and had ended by 2004.
Ecology.
Aquatic life.
The hypersalinity and high alkalinity (pH=10 or equivalent to 4 milligrams of NaOH per liter of water) of the lake means that no fish are native to the lake. An attempt by the California Department of Fish and Game to stock the lake failed.
The whole food chain of the lake is based on the high population of single-celled planktonic algae present in the photic zone of the lake. These algae reproduce rapidly during winter and early spring after winter runoff brings nutrients to the surface layer of water. By March the lake is "as green as pea soup" with photosynthesizing algae.
The lake is famous for the Mono Lake brine shrimp, "Artemia monica", a tiny species of brine shrimp, no bigger than a thumbnail, that are endemic to the lake. During the warmer summer months, an estimated 4–6 trillion brine shrimp inhabit the lake. Brine shrimp have no food value for humans, but are a staple for birds of the region. The brine shrimp feed on microscopic algae.
Alkali flies, "Ephydra hians" live along the shores of the lake and walk underwater, encased in small air bubbles for grazing and to lay eggs. These flies are an important source of food for migratory and nesting birds.
Birds.
Mono Lake is a vital resting and eating stop for migratory shorebirds and has been recognized as a site of international importance by the Western Hemisphere Shorebird Reserve Network.
Nearly 2,000,000 waterbirds, including 35 species of shorebirds, use Mono Lake to rest and eat for at least part of the year. Some shorebirds that depend on the resources of Mono Lake include American avocets, killdeer and sandpipers. Over 1.5 million eared grebes and phalaropes use Mono Lake during their long migrations.
Late every summer tens of thousands of Wilson's phalaropes and red-necked phalaropes arrive from their nesting grounds, and feed until they continue their migration to South America or the tropical oceans respectively.
In addition to migratory birds, a few species spend several months to nest at Mono Lake. Mono Lake has the second largest nesting population of California gulls, "Larus californicus", second only to the Great Salt Lake in Utah. Since abandoning the landbridged Negit Island in the late 1970s, California gulls have moved to some nearby islets and have established new, if less protected, nesting sites. Cornell University and Point Reyes Bird Observatory have continued the study of nesting populations on Mono Lake that was begun over 20 years ago. Snowy plovers also arrive at Mono Lake each spring to nest along the remote eastern shores.
History.
Native Americans.
The indigenous people of Mono Lake are from a band of the Northern Paiute, called the Kutzadika'a. They speak the Northern Paiute language. The Kutzadika'a traditionally forage alkali fly pupae, called kutsavi in their language. Mono Lake was also referred to as Teniega Bah. The origin of the name "Kutzadika'a" is uncertain but could be a Yokut Native American term for "fly eater".
The term "Mono" is derived from "Monachi", a Yokut term for the tribes that live on both the east and west side of the Sierra Nevada.
During early contact the first known Mono Lake Paiute chief was Captain John. He was also referred to by the Paiute names of "Shibana" or "Poko Tucket". Captain John was the son of a Northern Paiute named 'older Captain John.'
The Mono tribe has two bands: Eastern and Western. The Eastern Mono joined the Western Mono bands' villages annually at Hetch Hetchy Valley, Yosemite Valley, and along the Merced River to gather acorns, different plant species, and to trade. The Western Mono traditionally lived in the south-central Sierra Nevada foothills, including Historical Yosemite Valley.
Present day Mono Reservations are currently located in Big Pine, Bishop, and several in Madera County and Fresno County, California.
Conservation efforts.
The city of Los Angeles diverted water from the Owens River into the Los Angeles Aqueduct in 1913. In 1941, the Los Angeles Department of Water and Power extended the Los Angeles Aqueduct system farther upriver into the Mono Basin. So much water was diverted that evaporation soon exceeded inflow and the surface level of Mono Lake fell rapidly. By 1982 the lake was reduced to 69 percent of its 1941 surface area. "1990, the lake had dropped 45 vertical feet and had lost half its volume" relative to the 1941 pre-diversion water level. As a result, alkaline sands and formerly submerged tufa towers became exposed, the water salinity doubled, and Negit Island became a peninsula, exposing the nests of california gulls to predators (such as coyotes), and forcing the sea gull colony to abandon this site.
In 1974, Stanford University graduate student David Gaines studied the Mono Lake ecosystem, and he became instrumental in alerting the public of the effects of the lower water level. The National Science Foundation funded the first comprehensive ecological study of Mono Lake, conducted by Gaines and undergraduate students from the University of California at Davis, the University of California at Santa Cruz, and Earlham College. In June 1977, the Davis Institute of Ecology of the University of California published a report, "An Ecological Study of Mono Lake, California," which alerted California to the ecological dangers posed by the redirection of water away from the lake for municipal uses.
Gaines formed the Mono Lake Committee in 1978. He and Sally Judy, a UC Davis student, led the committee and pursued an informational tour of California. They joined with the Audubon Society to fight a now famous court battle, the National Audubon Society v. Superior Court, to protect Mono Lake through state public trust laws. While these efforts have resulted in positive change, the surface level is still below historical levels, and exposed shorelines are a source of significant alkaline dust during periods of high winds.
Owens Lake, the once-navigable terminus of the Owens River which had sustained a healthy ecosystem, is now a dry lake bed during dry years due to water diversion beginning in the 1920s. Mono Lake was spared this fate when the California State Water Resources Control Board (after over a decade of litigation) issued an order to protect Mono Lake and its tributary streams on September 28, 1994. Since that time, the lake level has steadily risen. In 1941 the surface level was at above sea level. As of October 2013, Mono Lake was at above sea level. The lake level of above sea level is the goal, a goal made more difficult during years of drought in the American West.

</doc>
<doc id="46797" url="https://en.wikipedia.org/wiki?curid=46797" title="Death Valley">
Death Valley

Death Valley is a desert valley located in Eastern California. It is the lowest, driest, and hottest area in North America.
Death Valley's Badwater Basin is the point of the lowest elevation in North America, at below sea level. This point is east-southeast of Mount Whitney, the highest point in the contiguous United States with an elevation of 14,505 feet (4,421 m). Death Valley's Furnace Creek holds the record for the highest reliably recorded air temperature in the world, 134 °F (56.7 °C) on July 10, 1913. This has been contested by other weather experts.
Located near the border of California and Nevada, in the Great Basin, east of the Sierra Nevada mountains, Death Valley constitutes much of Death Valley National Park and is the principal feature of the Mojave and Colorado Deserts Biosphere Reserve. It is located mostly in Inyo County, California. It runs from north to south between the Amargosa Range on the east and the Panamint Range on the west; the Sylvania Mountains and the Owlshead Mountains form its northern and southern boundaries, respectively. It has an area of about . The highest point in Death Valley itself is Telescope Peak in the Panamint Range, which has an elevation of .
Geology.
Death Valley is one of the best geological examples of a basin and range configuration. It lies at the southern end of a geological trough known as Walker Lane, which runs north into Oregon. The valley is bisected by a right lateral strike slip fault system, represented by the Death Valley Fault and the Furnace Creek Fault. The eastern end of the left lateral Garlock Fault intersects the Death Valley Fault. Furnace Creek and the Amargosa River flow through the valley but eventually disappear into the sands of the valley floor.
Death Valley also contains salt pans. According to current geological consensus, at various times during the middle of the Pleistocene era, inland lakes (collectively referred to as Lake Manly) formed in Death Valley. Lake Manly received water overflowing from a chain of other Pleistocene lakes, most of which are now also dry lakebeds. As the area turned to desert, the water evaporated, leaving the abundance of evaporitic salts such as common sodium salts and borax, which were later exploited during the modern history of the region, primarily 1883 to 1907.
Climate.
Death Valley has a subtropical, hot desert climate (Köppen: "BWh"), with long, extremely hot summers and short, warm or mild winters as well as little rainfall. As a general rule, lower altitudes tend to have higher temperatures. When the sun heats the ground, that heat is then radiated upward, but the dense below-sea-level air acts as a blanket and reflects the heat back. In addition, the high valley walls trap rising hot air and recycle it back down to the valley floor, where it is heated by compression.
This process is especially important in Death Valley as it provides its specific climate and geography. The valley is surrounded by mountains, while its surface is mostly flat and devoid of plants, and so much of the sun's heat can reach the ground, absorbed by soil and rock. When air at ground level is heated, it begins to rise, moving up past steep, high mountain ranges, which then cools slightly, sinking back down towards the valley more compressed. This air is then reheated by the sun to a higher temperature, moving up the mountain again, whereby the air moves up and down in a circular motion in cycles, similar to how a convection oven works. This heated air increases ground temperature markedly, forming the hot wind currents that are trapped by atmospheric pressure and mountains, thus stays mostly within the valley. Such hot wind currents contribute to perpetual drought-like conditions in Death Valley and prevent much cloud formation from passing through the confines of the valley, where precipitation is often in the form of a virga. Death Valley holds temperature records because it has an unusually high number of factors that lead to high atmospheric temperatures.
The depth and shape of Death Valley influence its summer temperatures. The valley is a long, narrow basin below sea level, yet is walled by high, steep mountain ranges. The clear, dry air and sparse plant cover allow sunlight to heat the desert surface. Summer nights provide little relief as overnight lows may only dip into the range. Moving masses of super-heated air blow through the valley creating extremely high temperatures.
The hottest air temperature ever recorded in Death Valley was on July 10, 1913, at Furnace Creek, which is the hottest atmospheric temperature ever recorded on earth. During the heat wave that peaked with that record, five consecutive days reached or above. Some meteorologists dispute the accuracy of the 1913 temperature measurement.
The greatest number of consecutive days with a maximum temperature of or above was 154 days in the summer of 2001. The summer of 1996 had 40 days over , and 105 days over . The summer of 1917 had 52 days where the temperature reached or above with 43 of them consecutive. Four major mountain ranges lie between Death Valley and the ocean, each one adding to an increasingly drier rain shadow effect, and in 1929, 1953 and 1989 no rain was recorded for the whole year. The period from 1931 to 1934 was the driest stretch on record with only of rain over a 40-month period. On June 30, 2013, during the 2013 extreme heat wave, the mercury reached 129 °F (54 °C) at Furnace Creek station, which is the all-time hottest air temperature recorded for the month of June.
The mean annual temperature for Death Valley (Furnace Creek Weather Station) is with an average high in January of around and in July. From 1934-1961 the weather station at Cow Creek recorded a mean annual temperature of .
The longest number of consecutive days where temperatures reached or more was 205 from April to Oct 1992. On average there are 192 days per year in Death Valley where temperatures reach 90 °F (32 °C) or more. Before being moved to Furnace Creek, the weather station at Greenland Ranch averaged 194.4 days annually where temperatures reached 90 °F (32 °C) or more.
On July 12, 2012, the day's low temperature was , tying the record for the world's hottest low temperature ever recorded. On the same day, the average temperature was , which is the world's hottest temperature averaged over 24 hours on record.
The lowest temperature recorded at Greenland Ranch was in January 1913.
The period from 17–19 July 1959, was the longest string of consecutive days where nighttime low temperatures did not drop below . The highest overnight or low temperature recorded in Death Valley is , recorded on July 5, 1918 and the current world-record for hottest over-night low. As recently as July 12, 2012, the low temperature at Death Valley dropped to just after a high of on the previous day. The only other location which matches Death Valley's overnight low temperature of in recent years is Khasab Airport in Oman, which also recorded a low of on June 27, 2012. Also on July 12, 2012 the mean 24-hour temperature recorded at Death Valley was , which makes it the world's warmest 24-hour temperature on record.
The average annual precipitation in Death Valley is , while the Greenland Ranch station averaged . The wettest month on record is January 1995 when fell on Death Valley. The wettest period on record was mid-2004 to mid-2005, in which nearly of rain fell in total, leading to ephemeral lakes in the valley and the region and tremendous wildflower blooms.
Snow with accumulation has only been recorded in January 1922, while scattered flakes have been recorded on other occasions.
Biota.
In spite of the overwhelming heat and sparse rainfall, Death Valley exhibits surprising biodiversity. Wildflowers, watered by snowmelt, carpet the desert floor each spring, continuing into June. Bighorn sheep, red-tailed hawks, and wild burros may be seen. Death Valley has over 600 springs and ponds. Salt Creek, a mile-long shallow depressing in the center of the valley, supports pupfish.
Darwin Falls, on the western edge of Death Valley Monument, falls into a large pond surrounded by willows and cottonwood trees. Over 80 species of birds have been spotted around the pond.
Lake Badwater and Glacial Lake Manly.
In 2005, Death Valley received four times its average annual rainfall of . As it has done before for hundreds of years, the lowest spot in the valley filled with a wide, shallow lake, but the extreme heat and aridity immediately began sucking the ephemeral lake dry.
This pair of images from NASA's Landsat 5 satellite documents the short history of Death Valley's Lake Badwater: formed in February 2005 (top) and long gone by February 2007 (bottom). In 2005, a big pool of greenish water stretched most of the way across the valley floor. By May 2005 the valley floor had resumed its more familiar role as Badwater Basin, a salt-coated salt flats. In time, this freshly dissolved and recrystallized salt will darken.
The western margin of Death Valley is traced by alluvial fans. During flash floods, rainfall from the steep mountains to the west pours through narrow canyons, picking up everything from fine clay to large rocks. When these torrents reach the mouths of the canyons, they widen and slow, branching out into braided streams. The paler the fans, the younger they are.
During the Pleistocene ice age, which ended roughly 10,000–12,000 years ago, the Sierra Nevada was much wetter. During that time, Death Valley was filled with a huge lake, called Glacial Lake Manly, that was nearly long and deep, the end-basin in a chain of lakes that began with Mono Lake in the north and continued through multiple basins down the Owens River Valley through Searles and China Lakes and the Panamint Valley to the immediate west. Remnants of this wetter period can still be seen in the region today, including the presence of several isolated populations of pupfish.
History.
Death Valley is home to the Timbisha tribe of Native Americans, formerly known as the Panamint Shoshone, who have inhabited the valley for at least the past millennium. The Timbisha name for the valley, "tümpisa", means "rock paint" and refers to the red ochre paint that can be made from a type of clay found in the valley. Some families still live in the valley at Furnace Creek. Another village was in Grapevine Canyon near the present site of Scotty's Castle. It was called in the Timbisha language "maahunu", whose meaning is uncertain, although it is known that "hunu" means "canyon".
The valley received its English name in 1849 during the California Gold Rush. It was called Death Valley by prospectors and others who sought to cross the valley on their way to the gold fields, after 13 pioneers perished from one early expedition of wagon trains. During the 1850s, gold and silver were extracted in the valley. In the 1880s, borax was discovered and extracted by mule-drawn wagons.
On the afternoon of July 10, 1913, the United States Weather Bureau recorded a high temperature of 134 °F (56.7 °C) at Greenland Ranch (now Furnace Creek) in Death Valley. This temperature stands as the highest ambient air temperature ever recorded at the surface of the Earth. (A report of a temperature of 58 °C (136.4 °F) recorded in Libya in 1922 was later determined to be inaccurate.)
Death Valley National Monument was proclaimed on February 11, 1933, by President Herbert Hoover, placing the area under federal protection. In 1994, the monument was redesignated as Death Valley National Park, as well as being substantially expanded to include Saline and Eureka Valleys.

</doc>
<doc id="46799" url="https://en.wikipedia.org/wiki?curid=46799" title="Long Valley">
Long Valley

Long Valley may refer to:

</doc>
<doc id="46802" url="https://en.wikipedia.org/wiki?curid=46802" title="Continued fraction">
Continued fraction

}</math>
In mathematics, a continued fraction is an expression obtained through an iterative process of representing a number as the sum of its integer part and the reciprocal of another number, then writing this other number as the sum of "its" integer part and another reciprocal, and so on. In a finite continued fraction (or terminated continued fraction), the iteration/recursion is terminated after finitely many steps by using an integer in lieu of another continued fraction. In contrast, an infinite continued fraction is an infinite expression. In either case, all integers in the sequence, other than the first, must be positive. The integers are called the coefficients or terms of the continued fraction.
Continued fractions have a number of remarkable properties related to the Euclidean algorithm for integers or real numbers. Every rational number has two closely related expressions as a finite continued fraction, whose coefficients can be determined by applying the Euclidean algorithm to . The numerical value of an infinite continued fraction will be irrational; it is defined from its infinite sequence of integers as the limit of a sequence of values for finite continued fractions. Each finite continued fraction of the sequence is obtained by using a finite prefix of the infinite continued fraction's defining sequence of integers. Moreover, every irrational number is the value of a "unique" infinite continued fraction, whose coefficients can be found using the non-terminating version of the Euclidean algorithm applied to the incommensurable values and 1. This way of expressing real numbers (rational and irrational) is called their "continued fraction representation".
It is generally assumed that the numerator of all of the fractions is 1. If arbitrary values and/or functions are used in place of one or more of the numerators or the integers in the denominators, the resulting expression is a generalized continued fraction. When it is necessary to distinguish the first form from generalized continued fractions, the former may be called a simple or regular continued fraction, or said to be in canonical form.
The term "continued fraction" may also refer to representations of rational functions, arising in their analytic theory. For this use of the term see Padé approximation and Chebyshev rational functions.
Motivation and notation.
Consider a typical rational number , which is around 4.4624.
As a first approximation, start with 4, which is the integer part;  = 4 + .
Note that the fractional part is the reciprocal of which is about 2.1628. Use the integer part, 2, as an approximation for the reciprocal, to get a second approximation of 4 +  = 4.5;  = 2 + .
The remaining fractional part, , is the reciprocal of , and is around 6.1429. Use 6 as an approximation for this to get 2 +  as an approximation for and 4 + , about 4.4615, as the third approximation;  = 6 + .
Finally, the fractional part, , is the reciprocal of 7, so its approximation in this scheme, 7, is exact ( = 7 + ) and produces the exact expression 4 +  for .
This expression is called the continued fraction representation of the number. Dropping some of the less essential parts of the expression 4 +  gives the abbreviated notation =Note that it is customary to replace only the "first" comma by a semicolon. Some older textbooks use all commas in the -tuple, e.g. [4,2,6,7.
If the starting number is rational then this process exactly parallels the Euclidean algorithm. In particular, it must terminate and produce a finite continued fraction representation of the number. If the starting number is irrational then the process continues indefinitely. This produces a sequence of approximations, all of which are rational numbers, and these converge to the starting number as a limit. This is the (infinite) continued fraction representation of the number. Examples of continued fraction representations of irrational numbers are:
Continued fractions are, in some ways, more "mathematically natural" representations of a real number than other representations such as decimal representations, and they have several desirable properties:
Basic formula.
A continued fraction is an expression of the form
where ai, and bi are either rational numbers, real numbers, or complex numbers.
If bi = 1 for all "i" the expression is called a "simple" continued fraction.
If the expression contains a finite number of terms it is called a "finite" continued fraction.
If the expression contains an infinite number of terms it is called an "infinite" continued fraction.
Thus, all of the following illustrate valid finite simple continued fractions:
Calculating continued fraction representations.
Consider a real number .
Let =⌊⌋ be the integer part of and let =− be the fractional part of .
Then the continued fraction representation of is [;1,2,…], where [1;2,…] is the continued fraction representation of 1/.
To calculate a continued fraction representation of a number , write down the integer part (technically the floor) of . Subtract this integer part from . If the difference is 0, stop; otherwise find the reciprocal of the difference and repeat. The procedure will halt if and only if is rational. This process can be efficiently implemented using the Euclidean algorithm when the number is rational.
The number 3.245 can also be represented by the continued fraction expansion [3;4,12,3,1]; refer to Finite continued fractions below.
Notations for continued fractions.
The integers "a"0, "a"1 etc., are called the "coefficients" or "terms" of the continued fraction. One can abbreviate the continued fraction
in the notation of Carl Friedrich Gauss
or as
or in the notation of Pringsheim as
or in another related notation as
Sometimes angle brackets are used, like this:
The semicolon in the square and angle bracket notations is sometimes replaced by a comma.
One may also define "infinite simple continued fractions" as limits:
This limit exists for any choice of "a"0 and positive integers "a"1, "a"2, ... .
Finite continued fractions.
Every finite continued fraction represents a rational number, and every rational number can be represented in precisely two different ways as a finite continued fraction, with the conditions that the first coefficient is an integer and other coefficients being positive integers. These two representations agree except in their final terms. In the longer representation the final term in the continued fraction is 1; the shorter representation drops the final 1, but increases the new final term by 1. The final element in the short representation is therefore always greater than 1, if present. In symbols:
For example,
Continued fractions of reciprocals.
The continued fraction representations of a positive rational number and its reciprocal are identical except for a shift one place left or right depending on whether the number is less than or greater than one respectively. In other words, the numbers represented by and are reciprocals. This is because if is an integer then if then and and if then and with the last number that generates the remainder of the continued fraction being the same for both and its reciprocal.
For example,
Infinite continued fractions.
Every infinite continued fraction is irrational, and every irrational number can be represented in precisely one way as an infinite continued fraction.
An infinite continued fraction representation for an irrational number is useful because its initial segments provide rational approximations to the number. These rational numbers are called the "convergents" of the continued fraction. The larger a term is in the continued fraction, the closer the corresponding convergent is to the irrational number being approximated. Numbers like π have occasional large terms in their continued fraction, which makes them easy to approximate with rational numbers. Other numbers like "e" have only small terms early in their continued fraction, which makes them more difficult to approximate rationally. The golden ratio ϕ has terms equal to 1 everywhere—the smallest values possible—which makes ϕ the most difficult number to approximate rationally. In this sense, therefore, it is the "most irrational" of all irrational numbers. Even-numbered convergents are smaller than the original number, while odd-numbered ones are larger.
For a continued fraction , the first four convergents (numbered 0 through 3) are
In words, the numerator of the third convergent is formed by multiplying the numerator of the second convergent by the third quotient, and adding the numerator of the first convergent. The denominators are formed similarly. Therefore, each convergent can be expressed explicitly in terms of the continued fraction as the ratio of certain multivariate polynomials called "continuants".
If successive convergents are found, with numerators , , … and denominators , , … then the relevant recursive relation is:
The successive convergents are given by the formula
Thus to incorporate a new term into a rational approximation, only the two previous convergents are necessary. The initial "convergents" (required for the first two terms) are 0⁄1 and 1⁄0. For example, here are the convergents for [0;1,5,2,2].
When using the Babylonian method to generate successive approximations to the square root of an integer, if one starts with the lowest integer as first approximant, the rationals generated all appear in the list of convergents for the continued fraction. Specifically, the approximants will appear on the convergents list in positions 0, 1, 3, 7, 15, … , , ... For example, the continued fraction expansion for square root of 3 is [1;1,2,1,2,1,2,1,2,…]. Comparing the convergents with the approximants derived from the Babylonian method:
Properties of infinite continued fractions.
Baire space is a topological space on infinite sequences of natural numbers. The infinite continued fraction provides a homeomorphism from Baire space to the space of irrational real numbers (with the subspace topology inherited from the usual topology on the reals). The infinite continued fraction also provides a map between the quadratic irrationals and the dyadic rationals, and from other irrationals to the set of infinite strings of binary numbers (i.e. the Cantor set); this map is called the Minkowski question mark function. The mapping has interesting self-similar fractal properties; these are given by the modular group, which is the subgroup of Mobius transformations having integer values in the transform. Roughly speaking, continued fraction convergents can be taken to be Mobius transformations acting on the (hyperbolic) upper half-plane; this is what leads to the fractal self-symmetry.
Some useful theorems.
If "a"0, "a"1, "a"2, … is an infinite sequence of positive integers, define the sequences "hn" and "kn" recursively:
Theorem 1. For any positive real number "z"
Theorem 2. The convergents of ["a"0; "a"1, "a"2, …] are given by
Theorem 3. If the "n"th convergent to a continued fraction is "hn"/"kn", then
Corollary 1: Each convergent is in its lowest terms (for if "hn" and "kn" had a nontrivial common divisor it would divide "knh""n"−1 − "k""n"−1"hn", which is impossible).
Corollary 2: The difference between successive convergents is a fraction whose numerator is unity:
Corollary 3: The continued fraction is equivalent to a series of alternating terms:
Corollary 4: The matrix
has determinant plus or minus one, and thus belongs to the group of 2×2 unimodular matrices GL(2, Z).
Theorem 4. Each ("s"-th) convergent is nearer to a subsequent ("n"-th) convergent than any preceding ("r"-th) convergent is. In symbols, if the "n"-th convergent is taken to be ["a"0; "a"1, ..., "a""n"] = "xn", then
for all "r" < "s" < "n".
Corollary 1: The even convergents (before the "n"th) continually increase, but are always less than "xn".
Corollary 2: The odd convergents (before the "n"th) continually decrease, but are always greater than "xn".
Theorem 5.
Corollary 1: Any convergent is nearer to the continued fraction than any other fraction whose denominator is less than that of the convergent
Corollary 2: Any convergent which immediately precedes a large quotient is a near approximation to the continued fraction.
Semiconvergents.
If
are successive convergents, then any fraction of the form
where is a nonnegative integer and the numerators and denominators are between the and terms inclusive are called "semiconvergents", secondary convergents, or intermediate fractions. Often the term is taken to mean that being a semiconvergent excludes the possibility of being a convergent, rather than that a convergent is a kind of semiconvergent.
The semiconvergents to the continued fraction expansion of a real number include all the rational approximations which are better than any approximation with a smaller denominator. Another useful property is that consecutive semiconvergents and are such that .
Best rational approximations.
One can choose to define a "best rational approximation" to a real number as a rational number , , that is closer to than any approximation with a smaller or equal denominator. The simple continued fraction for generates "all" of the best rational approximations for according to three rules:
For example, 0.84375 has continued fraction [0;1,5,2,2]. Here are all of its best rational approximations.
The strictly monotonic increase in the denominators as additional terms are included permits an algorithm to impose a limit, either on size of denominator or closeness of approximation.
The "half rule" mentioned above is that when is even, the halved term /2 is admissible if and only if This is equivalent to:
The convergents to are best approximations in an even stronger sense: / is a convergent for if and only if is the least "relative" error among all approximations / with ; that is, we have so long as . (Note also that as .)
Best rational within an interval.
A rational that falls within the interval , for , can be found with the continued fractions for and . When both and are irrational and
where and have identical continued fraction expansions up through , a rational that falls within the interval is given by the finite continued fraction,
This rational will be best in that no other rational in will have a smaller numerator or a smaller denominator.
If is rational, it will have "two" continued fraction representations that are "finite", and , and similarly a rational  will have two representations, and . The coefficients beyond the last in any of these representations should be interpreted as ; and the best rational will be one of , , , or .
For example, the decimal representation 3.1416 could be rounded from any number in the interval . The continued fraction representations of 3.14155 and 3.14165 are
and the best rational between these two is
Thus, in some sense, is the best rational number corresponding to the rounded decimal number 3.1416.
Interval for a convergent.
A rational number, which can be expressed as finite continued fraction in two ways,
will be one of the convergents for the continued fraction expansion of a number, if and only if the number is strictly between
Note that the numbers and are formed by incrementing the last coefficient in the two representations for , and that when is even, and when is odd.
For example, the number has the continued fraction representations
and thus is a convergent of any number strictly between
Comparison of continued fractions.
Consider and . If is the smallest index for which is unequal to then if and otherwise.
If there is no such , but one expansion is shorter than the other, say and with for , then if is even and if is odd.
Continued fraction expansions of.
To calculate the convergents of pi we may set , define and , and , . Continuing like this, one can determine the infinite continued fraction of as 
The fourth convergent of is [3;7,15,1] = = 3.14159292035..., sometimes called Milü, which is fairly close to the true value of .
Let us suppose that the quotients found are, as above, [3;7,15,1]. The following is a rule by which we can write down at once the convergent fractions which result from these quotients without developing the continued fraction.
The first quotient, supposed divided by unity, will give the first fraction, which will be too small, namely, . Then, multiplying the numerator and denominator of this fraction by the second quotient and adding unity to the numerator, we shall have the second fraction, , which will be too large. Multiplying in like manner the numerator and denominator of this fraction by the third quotient, and adding to the numerator the numerator of the preceding fraction, and to the denominator the denominator of the preceding fraction, we shall have the third fraction, which will be too small. Thus, the third quotient being 15, we have for our numerator , and for our denominator, . The third convergent, therefore, is . We proceed in the same manner for the fourth convergent. The fourth quotient being 1, we say 333 times 1 is 333, and this plus 22, the numerator of the fraction preceding, is 355; similarly, 106 times 1 is 106, and this plus 7 is 113.
In this manner, by employing the four quotients [3;7,15,1], we obtain the four fractions:
These convergents are alternately smaller and larger than the true value of , and approach nearer and nearer to . The difference between a given convergent and is less than the reciprocal of the product of the denominators of that convergent and the next convergent. For example, the fraction is greater than , but − is less than  =  (in fact, − is just more than = ).
The demonstration of the foregoing properties is deduced from the fact that if we seek the difference between one of the convergent fractions and the next adjacent to it we shall obtain a fraction of which the numerator is always unity and the denominator the product of the two denominators. Thus the difference between and is , in excess; between and , , in deficit; between and , , in excess; and so on. The result being, that by employing this series of differences we can express in another and very simple manner the fractions with which we are here concerned, by means of a second series of fractions of which the numerators are all unity and the denominators successively be the product of every two adjacent denominators. Instead of the fractions written above, we have thus the series:
The first term, as we see, is the first fraction; the first and second together give the second fraction, ; the first, the second and the third give the third fraction , and so on with the rest; the result being that the series entire is equivalent to the original value.
Generalized continued fraction.
A generalized continued fraction is an expression of the form
where the "a""n" ("n" > 0) are the partial numerators, the "b""n" are the partial denominators, and the leading term "b"0 is called the "integer" part of the continued fraction.
To illustrate the use of generalized continued fractions, consider the following example. The sequence of partial denominators of the simple continued fraction of does not show any obvious pattern:
or
However, several generalized continued fractions for have a perfectly regular structure, such as:
The first two of these are special cases of the function with = 4 arctan (1).
Other continued fraction expansions.
Periodic continued fractions.
The numbers with periodic continued fraction expansion are precisely the irrational solutions of quadratic equations with rational coefficients; rational solutions have finite continued fraction expansions as previously stated. The simplest examples are the golden ratio φ = and = [1;2,2,2,2,…, while = and = [6;2,12,2,12,2,12…. All irrational square roots of integers have a special form for the period; a symmetrical string, like the empty string (for ) or 1,2,1 (for ), followed by the double of the leading integer.
A property of the golden ratio φ.
Because the continued fraction expansion for φ doesn't use any integers greater than 1, φ is one of the most "difficult" real numbers to approximate with rational numbers. Hurwitz's theorem states that any real number can be approximated by infinitely many rational with
While virtually all real numbers will eventually have infinitely many convergents whose distance from is significantly smaller than this limit, the convergents for φ (i.e., the numbers , , , , etc.) consistently "toe the boundary", keeping a distance of almost exactly formula_24 away from φ, thus never producing an approximation nearly as impressive as, for example, Milü for pi. It can also be shown that every real number of the form , where , , , and are integers such that , shares this property with the golden ratio φ; and that all other real numbers can be more closely approximated.
Regular patterns in continued fractions.
While there is no discernable pattern in the simple continued fraction expansion of , there is one for , the base of the natural logarithm:
which is a special case of this general expression for positive integer :
Another, more complex pattern appears in this continued fraction expansion for positive odd :
with a special case for :
Other continued fractions of this sort are
where is a positive integer; also, for integral :
with a special case for :
If is the modified, or hyperbolic, Bessel function of the first kind, we may define a function on the rationals by
which is defined for all rational numbers, with and in lowest terms. Then for all nonnegative rationals, we have
with similar formulas for negative rationals; in particular we have
Many of the formulas can be proved using Gauss's continued fraction.
Typical continued fractions.
Most irrational numbers do not have any periodic or regular behavior in their continued fraction expansion. Nevertheless Khinchin proved that for almost all real numbers , the (for ) have an astonishing property: their geometric mean is a constant (known as Khinchin's constant, ) independent of the value of . Paul Lévy showed that the th root of the denominator of the th convergent of the continued fraction expansion of almost all real numbers approaches an asymptotic limit, approximately 3.27582, which is known as Lévy's constant. Lochs' theorem states that th convergent of the continued fraction expansion of almost all real numbers determines the number to an average accuracy of just over decimal places.
Generalized continued fraction for square roots.
Continued fraction techniques are one method of computing square roots.
The identity
leads via recursion to the generalized continued fraction for any square root: 
Pell's equation.
Continued fractions play an essential role in the solution of Pell's equation. For example, for positive integers and , and non-square , it is true that if and only if is a convergent of the regular continued fraction for .
Continued fractions and dynamical systems.
Continued fractions also play a role in the study of dynamical systems, where they tie together the Farey fractions which are seen in the Mandelbrot set with Minkowski's question mark function and the modular group Gamma.
The backwards shift operator for continued fractions is the map called the Gauss map, which lops off digits of a continued fraction expansion: . The transfer operator of this map is called the Gauss–Kuzmin–Wirsing operator. The distribution of the digits in continued fractions is given by the zero'th eigenvector of this operator, and is called the Gauss–Kuzmin distribution.
Eigenvalues and eigenvectors.
The Lanczos algorithm uses a continued fraction expansion to iteratively approximate the eigenvalues and eigenvectors of a large sparse matrix.

</doc>
<doc id="46811" url="https://en.wikipedia.org/wiki?curid=46811" title="Long Valley Caldera">
Long Valley Caldera

Long Valley Caldera is a depression in eastern California that is adjacent to Mammoth Mountain. The valley is one of the earth's largest calderas, measuring about long (east-west) and wide (north-south), and up to deep.
Long Valley was formed 760,000 years ago when a huge volcanic eruption released very hot ash that later cooled to form the Bishop tuff that is common to the area. The eruption was so colossal that the magma chamber under the now-destroyed volcano was emptied to the point of collapse. The collapse caused a larger secondary eruption of pyroclastic ash that burned and buried thousands of square miles. Ash from this eruption blanketed much of the western part of what is now the United States.
Geography.
The caldera is a giant bowl-shaped depression, approximately wide, surrounded by mountains, but open to the southeast. The elevation of the bottom of the bowl ranges from , being higher in the west.
Near the center of the bowl, there is a resurgent dome formed by magmatic uplift. The southeastern slope from the caldera down towards Bishop, California is filled with the Bishop Tuff, solidified ash that was ejected during the stupendous eruption that created the caldera. The Bishop tuff is thousands of feet thick and is cut by the Owens River Gorge, formed during the Pleistocene when the caldera filled with water and overtopped its rim.
The rim of the caldera is formed from pre-existing rock, rising about above the caldera floor. However, the eastern rim is less high, only about .
Mammoth Mountain is a lava dome complex in the southwestern corner of the caldera, consisting of about 12 rhyodacite and dacite overlapping domes. These domes formed in a long series of eruptions from 110,000 to 57,000 years ago, building a volcano that reaches in elevation.
The Mono–Inyo Craters are a -long volcanic chain situated along a narrow, north–south-trending fissure system extending along the western rim of the caldera from Mammoth Mountain to the north shore of Mono Lake. The Mono-Inyo Craters erupted from 40,000 to 600 years ago, from a magma source separate from the Long Valley Caldera.
The caldera has an extensive hydrothermal system. Casa Diablo Hot Springs at the base of the resurgent dome hosts a geothermal power plant. Hot Creek cuts into part of the resurgent dome and passes through hot springs. The warm water of Hot Creek supports many trout, and is used at the Hot Creek Fish Hatchery. The creek was closed to swimming in 2006 after geothermal activity in the area increased, and was still closed as of 2016. There are a number of other hot springs in the area, some of which are open to bathers.
Geology.
Caldera.
The tectonic causes of the Long Valley volcanism are still largely unexplained and are therefore a matter of much ongoing research. Long Valley is not above a hotspot as is Yellowstone or Hawaii, nor is it the result of subduction such as that which produces the volcanism of the Cascades.
The known volcanic history of the Long Valley Caldera area started several million years ago when magma began to collect several miles below the surface. Volcanic activity became concentrated in the vicinity of the present site of Long Valley Caldera 3.1 to 2.5 million years ago with eruptions of rhyodacite followed by high-silica rhyolite from 2.1 to 0.8 million years ago. After some time a cluster of mostly rhyolitic volcanoes formed in the area. All told, about were covered by lava.
All but one of these volcanoes, 1–2 million year old Glass Mountain (made of obsidian), were destroyed by the major eruption of the area 760,000 years ago, which released of material from vents just inside the margin of the caldera (the 1980 Mount St. Helens eruption was . About half of this material was ejected in a series of pyroclastic flows of a very hot, , mixture of noxious gas, pumice, and ash that covered the surrounding area hundreds of feet (meters) deep. One lobe of this material moved south into Owens Valley, past where Big Pine, California now lies. Another lobe moved west over the crest of the Sierra Nevada and into the drainage of the San Joaquin River. The rest of the pyroclastic material along with of other matter, was blown as far as into the air where winds distributed it as far away as eastern Nebraska and Kansas. However, much of the material ejected straight into the air fell back to earth to fill the deep caldera two-thirds to its rim.
Eruptions.
Subsequent eruptions from the Long Valley magma chamber were confined within the caldera with extrusions of relatively hot (crystal-free) rhyolite 700,000 to 600,000 years ago as the caldera floor was upwarped to form the resurgent dome followed by extrusions of cooler, crystal-rich moat rhyolite at 200,000-year intervals (500,000, 300,000, and 100,000 years ago) in clockwise succession around the resurgent dome. The declining volcanic activity and increasingly crystalline lava extruded over the last 650,000 years, as well as other trends, suggest that the magma reservoir under the caldera has now largely crystallized and is unlikely to produce large-scale eruptions in the future.
The Long Valley volcano is unusual in that it has produced eruptions of both basaltic and silicic lava in the same geological place.
Water from the Owens River filled the caldera to a depth of as of 600,000 years ago. At that time, the lake surface was at an elevation near . The lake drained sometime in the last 100,000 years after it overtopped the southern rim of the caldera, eroded the sill, and created the Owens River Gorge. A human-made dam in the gorge has created Lake Crowley, a partial restoration of the original lake. Since the great eruption, many hot springs developed in the area and the resurgent dome has uplifted.
During the last ice age, glaciers filled the canyons leading to Long Valley, but the valley floor was clear of ice. Excellent examples of terminal moraines can be seen at Long Valley: these moraines are the debris left from glacial sculpting. Laurel Creek, Convict Creek, and McGee Creek all have prominent moraines.
Recent activity.
In May 1980, a strong earthquake swarm that included four Richter magnitude 6 earthquakes struck the southern margin of Long Valley Caldera associated with a , dome-shaped uplift of the caldera floor. These events marked the onset of the latest period of caldera unrest that continues to this day. This ongoing unrest includes recurring earthquake swarms and continued dome-shaped uplift of the central section of the caldera (the resurgent dome) accompanied by changes in thermal springs and gas emissions. After the quake another road was created as an escape route. Its name at first was proposed as the "Mammoth Escape Route" but was changed to the Mammoth Scenic Loop after Mammoth area businesses and land owners complained.
In 1982, the United States Geological Survey under the Volcano Hazards Program began an intensive effort to monitor and study geologic unrest in Long Valley Caldera. The goal of this effort is to provide residents and civil authorities in the area reliable information on the nature of the potential hazards posed by this unrest and timely warning of an impending volcanic eruption, should it develop. Most, perhaps all, volcanic eruptions are preceded and accompanied by geophysical and geochemical changes in the volcanic system. Common precursory indicators of volcanic activity include increased seismicity, ground deformation, and variations in the nature and rate of gas emissions.
Hydrothermal system.
The Long Valley Caldera hosts an active hydrothermal system that includes hot springs, fumaroles (steam vents), and mineral deposits. Hot springs exist primarily in the eastern half of the caldera where land-surface elevations are relatively low; fumaroles exist primarily in the western half where elevations are higher. Mineral deposits from thermal activity are found on an uplifted area called the resurgent dome, at Little Hot Creek springs, Hot Creek Gorge, and other locations in the south and east moats of the caldera.
Hot springs discharge primarily in Hot Creek Gorge, along Little Hot Creek, and in the Alkali Lakes area. The largest springs are in Hot Creek Gorge where about per second of thermal water discharge and account for about 80% of the total thermal water discharge in the caldera. At the other extreme are springs at Hot Creek Fish Hatchery which contain a small component (2–5%) of thermal water that raises water temperatures about higher than background temperatures. Use of the warm spring water in the hatchery has increased fish production because trout growth rates are faster in the warm water than in ambient stream temperatures in Long Valley.
In hydrothermal systems the circulation of groundwater is driven by a combination of topography and heat sources. In Long Valley Caldera, the system is recharged primarily from snow-melt in the highlands around the western and southern rims of the caldera. The meteoric water infiltrates to depths of a few kilometers (miles) where it is heated to at least by hot rock near geologically young intrusions. Upflow occurs in the west moat where the heated water with lower density rises along steeply inclined fractures to depths of . This hydrothermal fluid flows laterally, down the hydraulic gradient, from the west to the southeast around the resurgent dome and then eastward to discharge points along Hot Creek and around Crowley Lake. Reservoir temperatures in the volcanic fill decline from near the Inyo Craters to near Crowley Lake due to a combination of heat loss and mixing with cold water.
Hot Creek has been a popular swimming hole for decades. Over a dozen people have died in Hot Creek since the late 1960s, but most of these deaths happened to people who ignored the numerous warning signs and attempted to use the hydrothermal pools as hot tubs (like the stream portion of the creek, these pools alternate in temperature but the eruptions in the pools are of super-heated water in already very hot water). Recent geothermal instability has led to its temporary closure for swimming. Officials are unsure of when (if ever) Hot Creek will officially reopen for swimming.
Hydrothermal activity has altered many rocks in the caldera, transforming them into travertine and clay. At the Huntley clay mine white chalky clay called kaolinite is mined; the kaolinite is exposed on the resurgent dome and appears as a brilliant white band.
Tourism and hiking.
The largest tourist attraction in the caldera is the Mammoth Mountain Ski Area: the area offers skiing and snowboarding in the winter, and mountain biking in the summer. The Hot Creek tourist attraction was closed to swimming in 2006 due to increased geothermal activity.
Hiking and off-road vehicle driving is available throughout the caldera, and in the glacial valleys of the Sherwin Range, immediately to the south of the caldera. Hikers can hike to several lakes in these glacial valleys, including Valentine Lake, Convict Lake, Lake Dorothy, and Laurel Lakes. Crowley Lake, at the south end of the caldera, is noted for its fishing.
The nearest hotel accommodations to the caldera are in Mammoth Lakes, California. There are also campgrounds scattered throughout the caldera, and in the mountains near the edge of the caldera.
Fatalities.
In April 2006, three members of the Mammoth Mountain Ski Area ski patrol died while on duty. All three died from suffocation by carbon dioxide when they fell into a fumarole on the slopes of the mountain.

</doc>
<doc id="46817" url="https://en.wikipedia.org/wiki?curid=46817" title="Mount Vesuvius">
Mount Vesuvius

Mount Vesuvius (; , ) is a stratovolcano in the Gulf of Naples, Italy, about east of Naples and a short distance from the shore. It is one of several volcanoes which form the Campanian volcanic arc. Vesuvius consists of a large cone partially encircled by the steep rim of a summit caldera caused by the collapse of an earlier and originally much higher structure.
Mount Vesuvius is best known for its eruption in AD 79 that led to the burying and destruction of the Roman cities of Pompeii, Herculaneum, and several other settlements. That eruption ejected a cloud of stones, ash, and fumes to a height of , spewing molten rock and pulverized pumice at the rate of 1.5 million tons per second, ultimately releasing a hundred thousand times the thermal energy released by the Hiroshima bombing. An estimated 16,000 people died due to hydrothermal pyroclastic flows. The only surviving eyewitness account of the event consists of two letters by Pliny the Younger to the historian Tacitus.
Vesuvius has erupted many times since and is the only volcano on the European mainland to have erupted within the last hundred years. Today, it is regarded as one of the most dangerous volcanoes in the world because of the population of 3,000,000 people living nearby and its tendency towards explosive (Plinian) eruptions. It is the most densely populated volcanic region in the world.
Mythology.
Vesuvius has a long historic and literary tradition. It was considered a divinity of the Genius type at the time of the eruption of 79 AD: it appears under the inscribed name Vesuvius as a serpent in the decorative frescos of many "lararia", or household shrines, surviving from Pompeii. An inscription from Capua to IOVI VESVVIO indicates that he was worshipped as a power of Jupiter; that is, "Jupiter Vesuvius".
The historian Diodorus Siculus relates a tradition that Hercules, in the performance of his labors, passed through the country of nearby Cumae on his way to Sicily and found there a place called "the Phlegraean Plain" ("phlegraion pedion", "plain of fire"), "from a hill which anciently vomited out fire ... now called Vesuvius." It was inhabited by bandits, "the sons of the Earth," who were giants. With the assistance of the gods he pacified the region and went on. The facts behind the tradition, if any, remain unknown, as does whether Herculaneum was named after it. An epigram by the poet Martial in 88 AD suggests that both Venus, patroness of Pompeii, and Hercules were worshipped in the region devastated by the eruption of 79. Mount Vesuvius was regarded by the Romans as being devoted to the hero and demigod Hercules.
Origin of the name.
Vesuvius was a name of the volcano in frequent use by the authors of the late Roman Republic and the early Roman Empire. Its collateral forms were Vesaevus, Vesevus, Vesbius and Vesvius. Writers in ancient Greek used Οὐεσούιον or Οὐεσούιος. Many scholars since then have offered an etymology. As peoples of varying ethnicity and language occupied Campania in the Roman Iron Age, the etymology depends to a large degree on the presumption of what language was spoken there at the time. Naples was settled by Greeks, as the name Nea-polis, "New City", testifies. The Oscans, a native Italic people, lived in the countryside. The Latins also competed for the occupation of Campania. Etruscan settlements were in the vicinity. Other peoples of unknown provenance are said to have been there at some time by various ancient authors.
Some theories about its origin are:
Physical appearance.
Vesuvius is a distinctive "humpbacked" mountain, consisting of a large cone ("Gran Cono") partially encircled by the steep rim of a summit caldera caused by the collapse of an earlier and originally much higher structure called Monte Somma. The Gran Cono was produced during the eruption of AD 79. For this reason, the volcano is also called Somma-Vesuvius or Somma-Vesuvio.
The caldera started forming during an eruption around 17,000 (or 18,300) years ago and was enlarged by later paroxysmal eruptions ending in the one of AD 79. This structure has given its name to the term "somma volcano", which describes any volcano with a summit caldera surrounding a newer cone.
The height of the main cone has been constantly changed by eruptions but is at present. Monte Somma is high, separated from the main cone by the valley of Atrio di Cavallo, which is some long. The slopes of the mountain are scarred by lava flows but are heavily vegetated, with scrub and forest at higher altitudes and vineyards lower down. Vesuvius is still regarded as an active volcano, although its current activity produces little more than steam from vents at the bottom of the crater. Vesuvius is a stratovolcano at the convergent boundary where the African Plate is being subducted beneath the Eurasian Plate. Layers of lava, scoria, volcanic ash, and pumice make up the mountain. Their mineralogy is variable, but generally silica-undersaturated and rich in potassium, with phonolite produced in the more explosive eruptions.
Formation.
Vesuvius was formed as a result of the collision of two tectonic plates, the African and the Eurasian. The former was subducted beneath the latter, deeper into the earth. As the water-saturated sediments of the oceanic African plate were pushed to hotter depths in the earth, the water boiled off and caused the melting point of the upper mantle to drop enough to create partial melting of the rocks. Because magma is less dense than the solid rock around it, it was pushed upward. Finding a weak place at the Earth's surface it broke through, producing the volcano.
The volcano is one of several which form the Campanian volcanic arc. Others include Campi Flegrei, a large caldera a few kilometres to the north west, Mount Epomeo, to the west on the island of Ischia, and several undersea volcanoes to the south. The arc forms the southern end of a larger chain of volcanoes produced by the subduction process described above, which extends northwest along the length of Italy as far as Monte Amiata in Southern Tuscany. Vesuvius is the only one to have erupted within recent history, although some of the others have erupted within the last few hundred years. Many are either extinct or have not erupted for tens of thousands of years.
Eruptions.
Mount Vesuvius has erupted many times. The famous eruption in 79 AD was preceded by numerous others in prehistory, including at least three significantly larger ones, the best known being the Avellino eruption around 1800 BC which engulfed several Bronze Age settlements. Since 79 AD, the volcano has also erupted repeatedly, in 172, 203, 222, possibly 303, 379, 472, 512, 536, 685, 787, around 860, around 900, 968, 991, 999, 1006, 1037, 1049, around 1073, 1139, 1150, and there may have been eruptions in 1270, 1347, and 1500.
The volcano erupted again in 1631, six times in the 18th century, eight times in the 19th century (notably in 1872), and in 1906, 1929, and 1944. There has been no eruption since 1944, and none of the post-79 eruptions were as large or destructive as the Pompeian one.
The eruptions vary greatly in severity but are characterized by explosive outbursts of the kind dubbed Plinian after Pliny the Younger, a Roman writer who published a detailed description of the 79 AD eruption, including his uncle's death. On occasion, eruptions from Vesuvius have been so large that the whole of southern Europe has been blanketed by ash; in 472 and 1631, Vesuvian ash fell on Constantinople (Istanbul), over away. A few times since 1944, landslides in the crater have raised clouds of ash dust, raising false alarms of an eruption.
Before AD 79.
Scientific knowledge of the geologic history of Vesuvius comes from core samples taken from a plus bore hole on the flanks of the volcano, extending into Mesozoic rock. Cores were dated by potassium–argon and argon–argon dating. The mountain started forming 25,000 years ago. Although the area has been subject to volcanic activity for at least 400,000 years, the lowest layer of eruption material from the Somma mountain lies on top of the 34,000‑year‑old Campanian Ignimbrite produced by the Campi Flegrei complex, and was the product of the Codola Plinian eruption 25,000 years ago.
It was then built up by a series of lava flows, with some smaller explosive eruptions interspersed between them. However, the style of eruption changed around 19,000 years ago to a sequence of large explosive plinian eruptions, of which the 79 AD one was the most recent. The eruptions are named after the tephra deposits produced by them, which in turn are named after the location where the deposits were first identified:
The volcano then entered a stage of more frequent, but less violent, eruptions until the most recent Plinian eruption, which destroyed Pompeii.
The last of these may have been in 217 BC. There were earthquakes in Italy during that year and the sun was reported as being dimmed by a haze or dry fog. Plutarch wrote of the sky being on fire near Naples and Silius Italicus mentioned in his epic poem "Punica" that Vesuvius had thundered and produced flames worthy of Mount Etna in that year, although both authors were writing around 250 years later. Greenland ice core samples of around that period show relatively high acidity, which is assumed to have been caused by atmospheric hydrogen sulfide.
The mountain was then quiet for hundreds of years and was described by Roman writers as having been covered with gardens and vineyards, except at the top which was craggy. The mountain may have had only one summit at that time, judging by a wall painting, "Bacchus and Vesuvius", found in a Pompeiian house, the House of the Centenary ("Casa del Centenario").
Several surviving works written over the 200 years preceding the 79 AD eruption describe the mountain as having had a volcanic nature, although Pliny the Elder did not depict the mountain in this way in his "Naturalis Historia":
Eruption of AD 79.
In the year of 79 AD, Mount Vesuvius erupted in one of the most catastrophic and famous eruptions of all time. Historians have learned about the eruption from the eyewitness account of Pliny the Younger, a Roman administrator and poet.
Mount Vesuvius spawned a deadly cloud of stones, ash and fumes to a height of , spewing molten rock and pulverized pumice at the rate of 1.5 Mt/s, ultimately releasing a hundred thousand times the thermal energy released by the Hiroshima bombing. The towns of Pompeii and Herculaneum were destroyed by pyroclastic flows and the ruins buried under dozens of feet of tephra. An estimated 16,000 people died from the eruption.
Precursors and foreshocks.
The 79 AD eruption was preceded by a powerful earthquake
seventeen years beforehand on February 5, AD 62, which caused widespread destruction around the Bay of Naples, and particularly to Pompeii. Some of the damage had still not been repaired when the volcano erupted. The deaths of 600 sheep from "tainted air" in the vicinity of Pompeii indicates that the earthquake of 62 may have been related to new activity by Vesuvius
The Romans grew accustomed to minor earth tremors in the region; the writer Pliny the Younger even wrote that they "were not particularly alarming because they are frequent in Campania". Small earthquakes started taking place on 20 August 79 becoming more frequent over the next four days, but the warnings were not recognised.
Scientific analysis of the eruption.
Reconstructions of the eruption and its effects vary considerably in the details but have the same overall features. The eruption lasted two days. The morning of the first day was perceived as normal by the only eyewitness to leave a surviving document, Pliny the Younger. In the middle of the day an explosion threw up a high-altitude column from which ash began to fall, blanketing the area. Rescues and escapes occurred during this time. At some time in the night or early the next day pyroclastic flows in the close vicinity of the volcano began. Lights were seen on the mountain interpreted as fires. People as far away as Misenum fled for their lives. The flows were rapid-moving, dense and very hot, knocking down wholly or partly all structures in their path, incinerating or suffocating all population remaining there and altering the landscape, including the coastline. These were accompanied by additional light tremors and a mild tsunami in the Bay of Naples. By evening of the second day the eruption was over, leaving only haze in the atmosphere through which the sun shone weakly.
The latest scientific studies of the ash produced by Vesuvius reveals a multi-phase eruption. The initial major explosion produced a column of ash and pumice ranging between high, which rained on Pompeii to the southeast but not on Herculaneum upwind. The chief energy supporting the column came from the escape of steam superheated by the magma, created from ground water seeping over time into the deep faults of the region.
Subsequently the cloud collapsed as the gases expanded and lost their capability to support their solid contents, releasing it as a pyroclastic surge, which reached Herculaneum but not Pompeii. Additional explosions reinstituted the column. The eruption alternated between Plinian and Peléan six times. Surges 3 and 4 are believed by the authors to have destroyed Pompeii. Surges are identified in the deposits by dune and cross-bedding formations, which are not produced by fallout.
Another study used the magnetic characteristics of over 200 samples of roof-tile and plaster fragments collected around Pompeii to estimate equilibrium temperature of the pyroclastic flow. The magnetic study revealed that on the first day of the eruption a fall of white pumice containing clastic fragments of up to fell for several hours. It heated the roof tiles up to . This period would have been the last opportunity to escape.
The collapse of the Plinian columns on the second day caused pyroclastic density currents (PDCs) that devastated Herculaneum and Pompeii. The depositional temperature of these pyroclastic surges ranged up to . Any population remaining in structural refuges could not have escaped, as the city was surrounded by gases of incinerating temperatures. The lowest temperatures were in rooms under collapsed roofs. These were as low as .
The Two Plinys.
The only surviving eyewitness account of the event consists of two letters by Pliny the Younger to the historian Tacitus. Pliny the Younger describes, amongst other things, the last days in the life of his uncle, Pliny the Elder. Observing the first volcanic activity from Misenum across the Bay of Naples from the volcano, approximately , the elder Pliny launched a rescue fleet and went himself to the rescue of a personal friend. His nephew declined to join the party. One of the nephew's letters relates what he could discover from witnesses of his uncle's experiences. In a second letter the younger Pliny details his own observations after the departure of his uncle.
The two men saw an extraordinarily dense cloud rising rapidly above the mountain. This cloud and a request by messenger for an evacuation by sea prompted the elder Pliny to order rescue operations in which he sailed away to participate. His nephew attempted to resume a normal life, but that night a tremor awoke him and his mother, prompting them to abandon the house for the courtyard. Further tremors near dawn caused the population to abandon the village and caused wave action in the Bay of Naples.
The early light was obscured by a black cloud through which shone flashes, which Pliny likens to sheet lightning, but more extensive. The cloud obscured Point Misenum near at hand and the island of Capraia (Capri) across the bay. Fearing for their lives, the population began to call to each other and move back from the coast along the road. A rain of ash fell, causing Pliny to shake it off periodically to avoid being buried. Later that same day the ash stopped falling and the sun shone weakly through the cloud, encouraging Pliny and his mother to return to their home and wait for news of Pliny the Elder.
Pliny's uncle Pliny the Elder was in command of the Roman fleet at Misenum, and had meanwhile decided to investigate the phenomenon at close hand in a light vessel. As the ship was preparing to leave the area, a messenger came from his friend Rectina (wife of Tascius) living on the coast near the foot of the volcano explaining that her party could only get away by sea and asking for rescue. Pliny ordered the immediate launching of the fleet galleys to the evacuation of the coast. He continued in his light ship to the rescue of Rectina's party.
He set off across the bay but in the shallows on the other side encountered thick showers of hot cinders, lumps of pumice and pieces of rock. Advised by the helmsman to turn back he stated "Fortune favors the brave" and ordered him to continue on to Stabiae (about 4.5 km from Pompeii).
Pliny the Elder and his party saw flames coming from several parts of the mountain. After staying overnight, the party was driven from the building by an accumulation of material, presumably, tephra, which threatened to block all egress. They woke Pliny, who had been napping and emitting loud snoring. They elected to take to the fields with pillows tied to their heads to protect them from rockfall. They approached the beach again but the wind prevented the ships from leaving. Pliny sat down on a sail that had been spread for him and could not rise even with assistance when his friends departed. Though Pliny the Elder died, his friends ultimately escaped by land.
In the first letter to Tacitus, Pliny the Younger suggested that his uncle's death was due to the reaction of his weak lungs to a cloud of poisonous, sulphurous gas that wafted over the group. However, Stabiae was 16 km from the vent (roughly where the modern town of Castellammare di Stabia is situated) and his companions were apparently unaffected by the fumes, and so it is more likely that the corpulent Pliny died from some other cause, such as a stroke or heart attack. His body was found with no apparent injuries on the next day, after dispersal of the plume.
Casualties from the eruption.
Along with Pliny the Elder, the only other noble casualties of the eruption to be known by name were Agrippa (a son of the Jewish princess Drusilla and the procurator Antonius Felix) and his wife.
An estimated 16,000 citizens in the Roman vicinities of Pompeii and Herculaneum perished due to hydrothermal pyroclastic flows. By 2003, around 1,044 casts made from impressions of bodies in the ash deposits had been recovered in and around Pompeii, with the scattered bones of another 100. The remains of about 332 bodies have been found at Herculaneum (300 in arched vaults discovered in 1980). What percentage these numbers are of the total dead or the percentage of the dead to the total number at risk remain completely unknown.
Thirty-eight percent of the 1,044 were found in the ash fall deposits, the majority inside buildings. These are thought to have been killed mainly by roof collapses, with the smaller number of victims found outside of buildings probably being killed by falling roof slates or by larger rocks thrown out by the volcano. The remaining 62% of remains found at Pompeii were in the pyroclastic surge deposits, and thus were probably killed by them – probably from a combination of suffocation through ash inhalation and blast and debris thrown around. In contrast to the victims found at Herculaneum, examination of cloth, frescoes and skeletons show that it is unlikely that high temperatures were a significant cause. Herculaneum, which was much closer to the crater, was saved from tephra falls by the wind direction, but was buried under of material deposited by pyroclastic surges. It is likely that most, or all, of the known victims in this town were killed by the surges.
People caught on the former seashore by the first surge died of thermal shock. No boats have been found, indicating they may have been used for the earlier escape of some of the population. The rest were concentrated in arched chambers at a density of as high as 3 persons per square meter. As only of the coast have been excavated, the casualties waiting to be excavated may well be as high as the thousands.
Later eruptions from the 3rd to the 19th century.
Since the eruption of 79 AD, Vesuvius has erupted around three dozen times. It erupted again in 203, during the lifetime of the historian Cassius Dio. In 472, it ejected such a volume of ash that ashfalls were reported as far away as Constantinople. The eruptions of 512 were so severe that those inhabiting the slopes of Vesuvius were granted exemption from taxes by Theodoric the Great, the Gothic king of Italy. Further eruptions were recorded in 787, 968, 991, 999, 1007 and 1036 with the first recorded lava flows. The volcano became quiescent at the end of the 13th century and in the following years it again became covered with gardens and vineyards as of old. Even the inside of the crater was filled with shrubbery.
Vesuvius entered a new phase in December 1631, when a major eruption buried many villages under lava flows, killing around 3,000 people. Torrents of boiling water were also ejected, adding to the devastation. Activity thereafter became almost continuous, with relatively severe eruptions occurring in 1660, 1682, 1694, 1698, 1707, 1737, 1760, 1767, 1779, 1794, 1822, 1834, 1839, 1850, 1855, 1861, 1868, 1872, 1906, 1926, 1929, and 1944.
Eruptions in the 20th century.
The eruption of April 7, 1906, killed more than 100 people and ejected the most lava ever recorded from a Vesuvian eruption. Italian authorities were preparing to hold the 1908 Summer Olympics when Mount Vesuvius erupted, devastating the city of Naples. Funds were diverted to the reconstruction of Naples, requiring a new location for the Olympics to be found.
The last major eruption was in March 1944. It destroyed the villages of San Sebastiano al Vesuvio, Massa di Somma, Ottaviano, and part of San Giorgio a Cremano. From March 18 to 23, 1944, lava flows appeared within the rim. There were outflows. Small explosions then occurred until the major explosion took place on March 18, 1944.
At the time of the eruption, the United States Army Air Forces (USAAF) 340th Bombardment Group was based at Pompeii Airfield near Terzigno, Italy, just a few kilometers from the eastern base of the mountain. The tephra and hot ash damaged the fabric control surfaces, the engines, the Plexiglas windshields and the gun turrets of the 340th's B-25 Mitchell medium bombers. Estimates ranged from 78 to 88 aircraft destroyed.
The eruption could be seen from Naples. Different perspectives and the damage caused to the local villages were recorded by USAAF photographers and other personnel based nearer to the volcano.
The future.
Large plinian eruptions which emit lava in quantities of about , the most recent of which overwhelmed Pompeii, have happened after periods of inactivity of a few thousand years. Subplinian eruptions producing about , such as those of 472 and 1631, have been more frequent with a few hundred years between them. Following the 1631 eruption until 1944 every few years saw a comparatively small eruption which emitted 0.001–0.01 km³ of magma. It seems that for Vesuvius the amount of magma expelled in an eruption increases very roughly linearly with the interval since the previous one, and at a rate of around for each year. This gives an approximate figure of for an eruption after 60 years of inactivity.
Magma sitting in an underground chamber for many years will start to see higher melting point constituents such as olivine crystallising out. The effect is to increase the concentration of dissolved gases (mostly steam and carbon dioxide) in the remaining liquid magma, making the subsequent eruption more violent. As gas-rich magma approaches the surface during an eruption, the huge drop in pressure caused by the reduction in weight of the overlying rock (which drops to zero at the surface) causes the gases to come out of solution, the volume of gas increasing explosively from nothing to perhaps many times that of the accompanying magma. Additionally, the removal of the higher melting point material will raise the concentration of felsic components such as silicates potentially making the magma more viscous, adding to the explosive nature of the eruption.
The government emergency plan for an eruption therefore assumes that the worst case will be an eruption of similar size and type to the 1631 VEI 4 one. In this scenario the slopes of the mountain, extending out to about from the vent, may be exposed to pyroclastic flows sweeping down them, whilst much of the surrounding area could suffer from tephra falls. Because of prevailing winds, towns to the south and east of the volcano are most at risk from this, and it is assumed that tephra accumulation exceeding 100 kg/m² – at which point people are at risk from collapsing roofs – may extend out as far as Avellino to the east or Salerno to the south east. Towards Naples, to the north west, this tephra fall hazard is assumed to extend barely past the slopes of the volcano. The specific areas actually affected by the ash cloud will depend upon
the particular circumstances surrounding the eruption.
The plan assumes between two weeks and 20 days' notice of an eruption and foresees the emergency evacuation of 600,000 people, almost entirely comprising all those living in the "zona rossa" ("red zone"), i.e. at greatest risk from pyroclastic flows. The evacuation, by
trains, ferries, cars, and buses is planned to take about seven days, and the evacuees will mostly be sent to other parts of the country rather than to safe areas in the local Campania region, and may have to stay away for several months. However, the dilemma that would face those implementing the plan is when to start this massive evacuation, since if it is left too late then thousands could be killed, while if it is started too early then the precursors of the eruption may turn out to have been a false alarm. In 1984, 40,000 people were evacuated from the Campi Flegrei area, another volcanic complex near Naples, but no eruption occurred.
Ongoing efforts are being made by the government at various levels (especially of Regione Campania) to reduce the population living in the red zone, by demolishing illegally constructed buildings, establishing a national park around the upper flanks of the volcano to prevent the erection of further buildings and by offering financial incentives to people for moving away. One of the underlying goals is to reduce the time needed to evacuate the area, over the next 20 or 30 years, to two or three days.
The volcano is closely monitored by the Osservatorio Vesuvio in Naples with extensive networks of seismic and gravimetric stations, a combination of a GPS-based geodetic array and satellite-based synthetic aperture radar to measure ground movement, and by local surveys and chemical analyses of gases emitted from fumaroles. All of this is intended to track magma rising underneath the volcano. No magma has been detected within 10 km of the surface, and so the volcano is classified by the Observatory as at a Basic or Green Level.
Vesuvius today.
[[File:Knackstedt & Näther Stereoskopie 1355 Italien. Drahtseilbahn auf den Vesuv. Bildseite.jpg|thumb|Funicular cable cars on Mount Vesuvius;
stereoscopy, about 1900]]
The area around Vesuvius was officially declared a national park on June 5, 1995. The summit of Vesuvius is open to visitors and there is a small network of paths around the mountain that are maintained by the park authorities on weekends.
There is access by road to within of the summit (measured vertically), but thereafter access is on foot only. There is a spiral walkway around the mountain from the road to the crater.
Funiculì, Funiculà.
The first funicular cable car on Mount Vesuvius opened in 1880. It was later destroyed by the 1944 eruption. "Funiculì, Funiculà", a famous Neapolitan song with lyrics by journalist Peppino Turco set to music by composer Luigi Denza, commemorates its opening.

</doc>
<doc id="46818" url="https://en.wikipedia.org/wiki?curid=46818" title="Surveillance aircraft">
Surveillance aircraft

A surveillance aircraft is an aircraft used for surveillance—collecting information over time. They are operated by military forces and other government agencies in roles such as intelligence gathering, battlefield surveillance, airspace surveillance, observation (e.g. artillery spotting), border patrol and fishery protection. This article concentrates on aircraft used in those roles, rather than for traffic monitoring, law enforcement and similar activities.
Surveillance aircraft usually carry no armament, or only limited defensive armament. A surveillance aircraft does not necessarily require high-performance capability or stealth characteristics. It may be a modified civilian aircraft. Surveillance aircraft have also included moored balloons (e.g. TARS) and Unmanned aerial vehicles (UAVs).
Definitions.
The terms “surveillance” and “reconnaissance” have sometimes been used interchangeably, but, in the military context, a distinction can be drawn between surveillance, which monitors a changing situation in real time, and reconnaissance, which captures a static picture for analysis.
Surveillance is sometimes grouped with Intelligence, Target acquisition and Reconnaissance under the title ISTAR.
Observation was the term used for surveillance when the main sensor was the human eye.
History.
Pre World War I.
In 1794, during the Battle of Fleurus, the French Aerostatic Corps balloon "L'Entreprenant" remained afloat for nine hours. French officers used the balloon to observe the movements of the Austrian Army, dropping notes to the ground for collection by the French Army, and also signalled messages using semaphore.
World War I.
One of the first aircraft used for surveillance was the Rumpler Taube during World War I, when aviators like Fred Zinn evolved entirely new methods of reconnaissance and photography. The translucent wings of the plane made it very difficult for ground based observers to detect a Taube at an altitude above 400 m. The French also called this plane "the Invisible Aircraft", and it is sometimes also referred to as the "world's very first stealth plane". German Taube aircraft were able to detect the advancing Russian army during the Battle of Tannenberg (1914).
World War II.
During World War II, light aircraft such as the Auster were used as air observation posts. Officers from the British Royal Artillery were trained as pilots to fly AOP aircraft for artillery spotting.
The air observation role was generally taken over by light observation helicopters, such as the Hughes OH-6 Cayuse, from the mid-1960s.
Pre war, the British identified a need for an aircraft that could follow and observe the enemy fleet at a distance. To this end the slow-flying Airspeed Fleet Shadower and General Aircraft Fleet Shadower designs were built and flown in 1940 but they were made obsolete by the introduction of airborne radar.
Cold War.
Spy flights were a source of major contention between the US and Russia during most of the 1960s. 
Roles.
Maritime patrol.
Maritime patrol aircraft are typically large, slow machines capable of flying continuously for many hours, with a wide range of sensors. Such aircraft include the Hawker-Siddeley Nimrod, the Breguet Atlantique, the Tupolev Tu-95, the Lockheed P-2 Neptune and the Lockheed P-3 Orion/CP-140 Aurora.
Law enforcement.
Predator UAVs have been used by the U.S. for border patrol.
Current use.
Unmanned (UAV) surveillance aircraft have been deployed or are under development in many countries, including Israel, the UK, the United States, Canada, China, India, South Africa and Pakistan 
Unmanned surveillance UAVs include both airships—such as Sky Sentinel 
and HiSentinel 80—
and airplanes.
Most air forces around the world lack dedicated surveillance planes.
Several countries adapt aircraft for electronic intelligence (ELINT) gathering. The Beech RC-12 Super King Air and Boeing RC-135 Rivet Joint are examples of this activity.

</doc>
<doc id="46821" url="https://en.wikipedia.org/wiki?curid=46821" title="Barry Took">
Barry Took

Barry Took (, 19 June 1928 – 31 March 2002) was an English writer, television presenter and comedian. His decade-and-a-half writing partnership with Marty Feldman led to the television series "Bootsie and Snudge" and the radio comedy "Round the Horne" and other projects.
He is also remembered in the UK for presenting "Points of View", a BBC Television programme featuring viewers' letters on the BBC's output, and the BBC Radio 4 programme "The News Quiz".
Early life and education.
The son of a manager at the Danish Bacon Company, Took was born in Muswell Hill or Wood Green, North London and brought up there during the war, running away from the home in Wisbech to which he had been evacuated. He attended Stationers School but quit school at age 15. His older brother Philip would eventually work for the US Space Program before dying as a young man.
Career.
With his limited education, Took found work as an office boy for a publisher and a cinema projectionist. During his period of National Service in the RAF in which he played the trumpet, he began performing and later worked as a stand-up comedian, eventually becoming a West End revue performer, working on "For Amusement Only" and "For Adults Only".
In terms of his comedy writing, Took's best work was written in collaboration with Marty Feldman, whom he first met in 1954. The two men wrote for several television shows in the 1950s and 1960s, including "The Army Game" and its spin-off "Bootsie and Snudge". He co-wrote "Beyond Our Ken" for two series (1958–1959) with Eric Merriman for BBC Radio before leaving after a disagreement with his fellow writer. With Marty Feldman he wrote most episodes of "Round the Horne"; the intermittent partnership between them continued until 1974.
In the late 1960s Took became comedy advisor to the BBC and was responsible for bringing together the performers who formed "Monty Python's Flying Circus", before moving to the USA to work briefly on "Rowan and Martin's Laugh In". He returned to the UK in early 1970, was involved in setting up the BBC series "The Goodies", although he had returned to take up the position of Head of Light Entertainment at London Weekend Television. He resigned from this position when Stella Richman, his superior and the Director of Programming, was dismissed. "On the Move" (1975–76), a programme linked to a national campaign against adult illiteracy, was written by Took and featured Bob Hoskins and Donald Gee. He was involved in two further television series on the issue, "Your Move" and "Write Away".
In 1977 Took hosted his own comedy sketch show, "Took and Co". Also featuring Robin Bailey, Chris Emmett, Andrew Sachs and Gwen Taylor, the series ran for seven episodes late at night on ITV.
In 1979 he became chairman of "The News Quiz" on BBC Radio 4, a role he filled for the next 17 years. In the same year he became a presenter of "Points of View", staying with the programme for 7 1/2 years.
Took also hosted the BBC Radio 2 comedy panel game "The Impressionists", which included Peter Goodwright, Roger Kitter, David Jason and Dave Evans and, in 1998, the single-season revival of "Twenty Questions" titled "Guess What?".
He had seven books published, including his autobiography and several histories of comedy. He also wrote Kenneth Williams's life story for the "Oxford Dictionary of National Biography" in 1996.
Personal life and final years.
While he was in National Service he met his first wife, Dorothy "Dot" Bird, also a member of the RAF. The couple married in 1950 and had three children (Barry, Susan and David) but they divorced. In 1964 he married Lynden "Lyn" Leonard. They had a daughter, Elinor. The couple separated in 1999 and eventually divorced.
Took was an admitted alcoholic who acknowledged its effects on his personal life and career. He also spoke publicly about his experiences with depression and undergoing extensive psychotherapy for several years.
After suffering from bladder cancer for a period during the 1970s, in 1999 he was diagnosed with cancer of the oesophagus, and suffered a stroke four weeks after undergoing major surgery. He died at age 73 on Easter Sunday, 2002 in a nursing home in Enfield, Middlesex.

</doc>
<doc id="46823" url="https://en.wikipedia.org/wiki?curid=46823" title="George V">
George V

George V (George Frederick Ernest Albert; 3 June 1865 – 20 January 1936) was King of the United Kingdom and the British Dominions, and Emperor of India, from 6 May 1910 until his death in 1936.
He was the second son of Albert Edward, Prince of Wales (later King Edward VII), and the grandson of the reigning British monarch, Queen Victoria. From the time of his birth, he was third in the line of succession behind his father and his elder brother, Prince Albert Victor, Duke of Clarence and Avondale. From 1877 to 1891, George served in the Royal Navy, until the unexpected death of his elder brother in early 1892 put him directly in line for the throne. On the death of his grandmother in 1901, George's father became King-Emperor of the British Empire, and George was created Prince of Wales. He succeeded his father in 1910. He was the only Emperor of India to be present at his own Delhi Durbar.
His reign saw the rise of socialism, communism, fascism, Irish republicanism, and the Indian independence movement, all of which radically changed the political landscape. The Parliament Act 1911 established the supremacy of the elected British House of Commons over the unelected House of Lords. As a result of the First World War (1914–18) the empires of his first cousins Tsar Nicholas II of Russia and Kaiser Wilhelm II of Germany fell while the British Empire expanded to its greatest effective extent. In 1917, George became the first monarch of the House of Windsor, which he renamed from the House of Saxe-Coburg and Gotha as a result of anti-German public sentiment. In 1924 he appointed the first Labour ministry and in 1931 the Statute of Westminster recognised the dominions of the Empire as separate, independent states within the Commonwealth of Nations. He was plagued by illness throughout much of his later reign and at his death was succeeded by his eldest son, Edward VIII.
Early life and education.
George was born on 3 June 1865, in Marlborough House, London. He was the second son of the Prince and Princess of Wales, Albert Edward and Alexandra. His father was the eldest son of Queen Victoria and Prince Albert, and his mother was the eldest daughter of King Christian IX of Denmark. As a son of the Prince of Wales, George was styled "His Royal Highness Prince George of Wales" at birth. He was baptised at Windsor Castle on 7 July 1865 by the Archbishop of Canterbury, Charles Longley.
As a younger son of the Prince of Wales, there was little expectation that George would become king. He was third in line to the throne, after his father and elder brother, Prince Albert Victor. George was only 17 months younger than Albert Victor, and the two princes were educated together. John Neale Dalton was appointed as their tutor in 1871. Neither Albert Victor nor George excelled intellectually. As their father thought that the navy was "the very best possible training for any boy", in September 1877, when George was 12 years old, both brothers joined the cadet training ship HMS "Britannia" at Dartmouth, Devon.
For three years from 1879, the royal brothers served on , accompanied by Dalton. They toured the colonies of the British Empire in the Caribbean, South Africa and Australia, and visited Norfolk, Virginia, as well as South America, the Mediterranean, Egypt, and East Asia. In 1881 on a visit to Japan, George had a local artist tattoo a blue and red dragon on his arm, and was received in an audience by the Emperor Meiji; George and his brother presented Empress Haruko with two wallabies from Australia. Dalton wrote an account of their journey entitled "The Cruise of HMS Bacchante". Between Melbourne and Sydney, Dalton recorded a sighting of the "Flying Dutchman", a mythical ghost ship. When they returned to Britain, Queen Victoria complained that her grandsons could not speak French or German, and so they spent six months in Lausanne in an ultimately unsuccessful attempt to learn another language. After Lausanne, the brothers were separated; Albert Victor attended Trinity College, Cambridge, while George continued in the Royal Navy. He travelled the world, visiting many areas of the British Empire. During his naval career he commanded "Torpedo Boat 79" in home waters then on the North America station, before his last active service in command of HMS "Melampus" in 1891–92. From then on, his naval rank was largely honorary.
Marriage.
As a young man destined to serve in the navy, Prince George served for many years under the command of his uncle, Prince Alfred, Duke of Edinburgh, who was stationed in Malta. There, he grew close to and fell in love with his uncle's daughter, his first cousin, Marie of Edinburgh. His grandmother, father and uncle all approved the match, but the mothers—the Princess of Wales and the Duchess of Edinburgh—both opposed it. The Princess of Wales thought the family was too pro-German, and the Duchess of Edinburgh disliked England. Marie's mother was the only daughter of Tsar Alexander II of Russia. She resented the fact that, as the wife of a younger son of the British sovereign, she had to yield precedence to George's mother, the Princess of Wales, whose father had been a minor German prince before being called unexpectedly to the throne of Denmark. Guided by her mother, Marie refused George when he proposed to her. She married Ferdinand, the heir to the King of Romania, in 1893.
In November 1891, George's elder brother Albert Victor became engaged to his second cousin once removed, Princess Victoria Mary of Teck. She was known within the family as "May", nicknamed after her birth month. May's father, Prince Francis, Duke of Teck, belonged to a morganatic, cadet branch of the house of Württemberg. Her mother, Princess Mary Adelaide of Cambridge, was a male-line granddaughter of King George III and a first cousin of Queen Victoria.
On 14 January 1892, six weeks after the formal engagement, Albert Victor died of pneumonia, leaving George second in line to the throne, and likely to succeed after his father. George had only just recovered from a serious illness himself, after being confined to bed for six weeks with typhoid fever, the disease that was thought to have killed his grandfather Prince Albert. Queen Victoria still regarded Princess May as a suitable match for her grandson, and George and May grew close during their shared period of mourning. A year after Albert Victor's death, George proposed to May and was accepted. They married on 6 July 1893 at the Chapel Royal in St James's Palace, London. Throughout their lives, they remained devoted to each other. George was, on his own admission, unable to express his feelings easily in speech, but they often exchanged loving letters and notes of endearment.
Duke of York.
The death of his elder brother effectively ended George's naval career, as he was now second in line to succeed to the throne, after his father. George was created Duke of York, Earl of Inverness and Baron Killarney by Queen Victoria on 24 May 1892, and received lessons in constitutional history from J. R. Tanner. After George's marriage to May, she was styled "Her Royal Highness The Duchess of York".
The Duke and Duchess of York lived mainly at York Cottage, a relatively small house in Sandringham, Norfolk, where their way of life mirrored that of a comfortable middle-class family rather than royalty. George preferred a simple, almost quiet, life in marked contrast to the lively social life pursued by his father. His official biographer, Harold Nicolson, later despaired of George's time as Duke of York, writing: "He may be all right as a young midshipman and a wise old king, but when he was Duke of York ... he did nothing at all but kill ["i.e." shoot] animals and stick in stamps." George was an avid stamp collector, which Nicolson disparaged, but George played a large role in building the Royal Philatelic Collection into the most comprehensive collection of United Kingdom and Commonwealth stamps in the world, in some cases setting record purchase prices for items.
George and May had five sons and a daughter. Randolph Churchill claimed that George was a strict father, to the extent that his children were terrified of him, and that George had remarked to Edward Stanley, 17th Earl of Derby: "My father was frightened of his mother, I was frightened of my father, and I am damned well going to see to it that my children are frightened of me." In reality, there is no direct source for the quotation and it is likely that George's parenting style was little different from that adopted by most people at the time.
In October 1894, George's uncle-by-marriage, Tsar Alexander III, died and his cousin, Tsar Nicholas II, ascended the Russian throne. At the request of his father, "out of respect for poor dear Uncle Sasha's memory", George joined his parents in St. Petersburg for the funeral. George and his parents remained in Russia for the wedding a week later of Nicholas to another one of George's first cousins, Princess Alix of Hesse-Darmstadt, who Queen Victoria had once hoped would marry George's elder brother.
Prince of Wales.
As Duke and Duchess of York, George and May carried out a wide variety of public duties. On the death of Queen Victoria on 22 January 1901, George's father ascended the throne as King Edward VII. George inherited the titles of Duke of Cornwall and Duke of Rothesay, and for much of the rest of that year, he was styled "His Royal Highness The Duke of Cornwall and York".
In 1901, George and May toured the British Empire. Their tour included Gibraltar, Malta, Port Said, Aden, Ceylon, Singapore, Australia, New Zealand, Mauritius, South Africa, Canada, and the Colony of Newfoundland. The tour was designed by Colonial Secretary Joseph Chamberlain with the support of Prime Minister Lord Salisbury to reward the Dominions for their participation in the South African War of 1899–1902. George presented thousands of specially designed South African War medals to colonial troops. In South Africa, the royal party met civic leaders, African leaders, and Boer prisoners, and was greeted by elaborate decorations, expensive gifts, and fireworks displays. Despite this, not all residents responded favourably to the tour. Many white Cape Afrikaners resented the display and expense, the war having weakened their capacity to reconcile their Afrikaner-Dutch culture with their status as British subjects. Critics in the English-language press decried the enormous cost at a time when families faced severe hardship.
In Australia, the Duke opened the first session of the Australian Parliament upon the creation of the Commonwealth of Australia. In New Zealand, he praised the military values, bravery, loyalty, and obedience to duty of New Zealanders, and the tour gave New Zealand a chance to show off its progress, especially in its adoption of up-to-date British standards in communications and the processing industries. The implicit goal was to advertise New Zealand's attractiveness to tourists and potential immigrants, while avoiding news of growing social tensions, by focusing the attention of the British press on a land few knew about. On his return to Britain, in a speech at London's Guildhall, George warned of "the impression which seemed to prevail among brethren across the seas, that the Old Country must wake up if she intends to maintain her old position of pre-eminence in her colonial trade against foreign competitors."
On 9 November 1901, George was created Prince of Wales and Earl of Chester. King Edward wished to prepare his son for his future role as king. In contrast to Edward himself, whom Queen Victoria had deliberately excluded from state affairs, George was given wide access to state documents by his father. George in turn allowed his wife access to his papers, as he valued her counsel and she often helped write her husband's speeches. As Prince of Wales, George supported reforms in naval training, including cadets being enrolled at the ages of twelve and thirteen, and receiving the same education, whatever their class and eventual assignments. The reforms were implemented by the then Second (later First) Sea Lord, Jacky Fisher.
From November 1905 to March 1906, George and May toured British India, where he was disgusted by racial discrimination and campaigned for greater involvement of Indians in the government of the country. The tour was almost immediately followed by a trip to Spain for the wedding of King Alfonso XIII to Victoria Eugenie of Battenberg, a first cousin of George, at which the bride and groom narrowly avoided assassination. A week after returning to Britain, George and May travelled to Norway for the coronation of King Haakon VII, George's cousin, and Queen Maud, George's sister.
King and Emperor.
On 6 May 1910, King Edward died, and George became king. He wrote in his diary, "I have lost my best friend and the best of fathers ... I never had a word with him in my life. I am heart-broken and overwhelmed with grief but God will help me in my responsibilities and darling May will be my comfort as she has always been. May God give me strength and guidance in the heavy task which has fallen on me".
George had never liked his wife's habit of signing official documents and letters as "Victoria Mary" and insisted she drop one of those names. They both thought she should not be called Queen Victoria, and so she became Queen Mary. Later that year, a radical propagandist, Edward Mylius, published a lie that George had secretly married in Malta as a young man, and that consequently his marriage to Queen Mary was bigamous. The lie had first surfaced in print in 1893 but George had shrugged it off as a joke. In an effort to kill off rumours, Mylius was arrested, tried and found guilty of criminal libel, and was sentenced to a year in prison.
George objected to the anti-Catholic wording of the Accession Declaration that he would be required to make at the opening of his first parliament. He made it known that he would refuse to open parliament as long as he was obliged to make the declaration in its current form. As a result, the Accession Declaration Act 1910 shortened the declaration and removed the most offensive phrases.
George and Mary's coronation took place at Westminster Abbey on 22 June 1911, and was celebrated by the Festival of Empire in London. In July, the King and Queen visited Ireland for five days; they received a warm welcome, with thousands of people lining the route of their procession to cheer. Later in 1911, the King and Queen travelled to India for the Delhi Durbar, where they were presented to an assembled audience of Indian dignitaries and princes as the Emperor and Empress of India on 12 December 1911. George wore the newly created Imperial Crown of India at the ceremony, and declared the shifting of the Indian capital from Calcutta to Delhi. They travelled throughout the sub-continent, and George took the opportunity to indulge in big game hunting in Nepal, shooting 21 tigers, 8 rhinoceroses and a bear over 10 days. He was a keen and expert marksman. On 18 December 1913, he shot over a thousand pheasants in six hours at the home of Lord Burnham, although even he had to acknowledge that "we went a little too far" that day.
National politics.
George inherited the throne at a politically turbulent time. Lloyd George's People's Budget had been rejected the previous year by the Conservative and Unionist-dominated House of Lords, contrary to the normal convention that the Lords did not veto money bills. Liberal Prime Minister H. H. Asquith had asked the previous king to give an undertaking that he would create sufficient Liberal peers to force the budget through the House. Edward had reluctantly agreed, provided the Lords rejected the budget after two successive general elections. After a general election in January 1910, the Conservative peers allowed the budget, for which the government now had an electoral mandate, to pass without a vote.
Asquith attempted to curtail the power of the Lords through constitutional reforms, which were again blocked by the Upper House. A constitutional conference on the reforms broke down in November 1910 after 21 meetings. Asquith and Lord Crewe, Liberal leader in the Lords, asked George to grant a dissolution, leading to a second general election, and to promise to create sufficient Liberal peers if the Lords blocked the legislation again. If George refused, the Liberal government would otherwise resign, which would have given the appearance that the monarch was taking sides – with "the peers against the people" – in party politics. The King's two private secretaries, Lords Knollys and Stamfordham, gave George conflicting advice. Knollys, who was Liberal, advised George to accept the Cabinet's demands, while Stamfordham, who was Unionist, advised George to accept the resignation. Like his father, George reluctantly agreed to the dissolution and creation of peers, although he felt his ministers had taken advantage of his inexperience to browbeat him. After the December 1910 election, the Lords let the bill pass on hearing of the threat to swamp the house with new peers. The subsequent Parliament Act 1911 permanently removed – with a few exceptions – the power of the Lords to veto bills. The King later came to feel that Knollys had withheld information from him about the willingness of the opposition to form a government if the Liberals had resigned.
The 1910 general elections had left the Liberals as a minority government dependent upon the support of Irish Nationalists. As desired by the Nationalists, Asquith introduced legislation that would give Ireland Home Rule, but the Conservatives and Unionists opposed it. As tempers rose over the Home Rule Bill, which would never have been possible without the Parliament Act, relations between the elderly Knollys and the Conservatives became poor, and he was pushed into retirement. Desperate to avoid the prospect of civil war in Ireland between Unionists and Nationalists, George called a meeting of all parties at Buckingham Palace in July 1914 in an attempt to negotiate a settlement. After four days the conference ended without an agreement. On 18 September 1914, the King – having considered vetoing the legislation – gave his assent to the Home Rule Bill after it had been passed by Westminster, but its implementation was postponed by a Suspensory Act due to the outbreak of the First World War.
First World War.
From 1914 to 1918, Britain and its allies were at war with the Central Powers, led by the German Empire. The German Kaiser Wilhelm II, who for the British public came to symbolise all the horrors of the war, was the King's first cousin. The King's paternal grandfather was Prince Albert of Saxe-Coburg and Gotha; consequently, the King and his children bore the titles Prince and Princess of Saxe-Coburg and Gotha and Duke and Duchess of Saxony. Queen Mary, although British like her mother, was the daughter of the Duke of Teck, a descendant of the German Dukes of Württemberg. The King had brothers-in-law and cousins who were British subjects but who bore German titles such as Duke and Duchess of Teck, Prince and Princess of Battenberg, and Prince and Princess of Schleswig-Holstein. When H. G. Wells wrote about Britain's "alien and uninspiring court", George famously replied: "I may be uninspiring, but I'll be damned if I'm alien."
On 17 July 1917, George appeased British nationalist feelings by issuing a royal proclamation that changed the name of the British royal house from the German-sounding House of Saxe-Coburg and Gotha to the House of Windsor. He and all his British relatives relinquished their German titles and styles, and adopted British-sounding surnames. George compensated his male relatives by creating them British peers. His cousin, Prince Louis of Battenberg, who earlier in the war had been forced to resign as First Sea Lord through anti-German feeling, became Louis Mountbatten, 1st Marquess of Milford Haven, while Queen Mary's brothers became Adolphus Cambridge, 1st Marquess of Cambridge, and Alexander Cambridge, 1st Earl of Athlone. George's cousins Princess Marie Louise and Princess Helena Victoria of Schleswig-Holstein dropped their territorial designations.
In Letters Patent gazetted on 11 December 1917 the King restricted the style "His (or Her) Royal Highness" and the titular dignity of "Prince (or Princess) of Great Britain and Ireland" to the children of the Sovereign, the children of the sons of the Sovereign and the eldest living son of the eldest living son of a Prince of Wales. The Letters Patent also stated that "the titles of Royal Highness, Highness or Serene Highness, and the titular dignity of Prince and Princess shall cease except those titles already granted and remaining unrevoked". George's relatives who fought on the German side, such as Prince Ernst August of Hanover, 3rd Duke of Cumberland and Teviotdale (the senior male-line great-grandson of George III) and Prince Carl Eduard, Duke of Albany and reigning Duke of Saxe-Coburg and Gotha (a male-line grandson of Queen Victoria), had their British peerages suspended by a 1919 Order in Council under the provisions of the Titles Deprivation Act 1917. Under pressure from his mother, Queen Alexandra, George also removed the Garter flags of his German relations from St George's Chapel, Windsor Castle.
When Tsar Nicholas II of Russia, George's first cousin (their mothers were sisters), was overthrown in the Russian Revolution of 1917, the British government offered political asylum to the Tsar and his family, but worsening conditions for the British people, and fears that revolution might come to the British Isles, led George to think that the presence of the Russian royals would be seen as inappropriate. Despite the later claims of Lord Mountbatten of Burma that Prime Minister Lloyd George was opposed to the rescue of the Russian imperial family, the letters of Lord Stamfordham suggest that it was George V who opposed the idea against the advice of the government. Advanced planning for a rescue was undertaken by MI1, a branch of the British secret service, but because of the strengthening position of the Bolshevik revolutionaries and wider difficulties with the conduct of the war, the plan was never put into operation. The Tsar and his immediate family remained in Russia, where they were killed by Bolsheviks in 1918. The following year, Nicholas's mother (George's aunt) Maria Feodorovna (Dagmar of Denmark) and other members of the extended Russian imperial family were rescued from the Crimea by British ships.
Two months after the end of the war, the King's youngest son, John, died at the age of 13 after a lifetime of ill health. George was informed of his death by Queen Mary, who wrote, " had been a great anxiety to us for many years ... The first break in the family circle is hard to bear but people have been so kind & sympathetic & this has helped us much."
In May 1922, the King toured Belgium and northern France, visiting the First World War cemeteries and memorials being constructed by the Imperial War Graves Commission. The event was described in a poem, "The King's Pilgrimage" by Rudyard Kipling. The tour, and one short visit to Italy in 1923, were the only times George agreed to leave the United Kingdom on official business after the end of the war.
Reign after the Great War.
Before the First World War, most of Europe was ruled by monarchs related to George, but during and after the war, the monarchies of Austria, Germany, Greece, and Spain, like Russia, fell to revolution and war. In March 1919, Lieutenant-Colonel Edward Lisle Strutt was dispatched on the personal authority of the King to escort the former Emperor Charles I of Austria and his family to safety in Switzerland. In 1922, a Royal Navy ship was sent to Greece to rescue his cousins, Prince and Princess Andrew. Prince Andrew was a nephew of Queen Alexandra through her brother King George I of Greece, and Princess Andrew was a daughter of Prince Louis of Battenberg, one of the German princes granted a British peerage in 1917. Their children included Prince Philip, who would later marry George's granddaughter, Elizabeth II. The Greek monarchy was restored again shortly before George's death.
Political turmoil in Ireland continued as the Nationalists fought for independence; George expressed his horror at government-sanctioned killings and reprisals to Prime Minister David Lloyd George. At the opening session of the Parliament of Northern Ireland on 22 June 1921, the King, in a speech part drafted by Lloyd George and General Jan Smuts, appealed for conciliation. A few weeks later, a truce was agreed. Negotiations between Britain and the Irish secessionists led to the signing of the Anglo-Irish Treaty. By the end of 1922, Ireland was partitioned, the Irish Free State was established, and Lloyd George was out of office.
The King and his advisers were concerned about the rise of socialism and the growing labour movement, which they mistakenly associated with republicanism. The socialists no longer believed in their anti-monarchical slogans and were ready to come to terms with the monarchy if it took the first step. George adopted a more democratic, inclusive stance that crossed class lines and brought the monarchy closer to the public and the working class—a dramatic change for the King, who was most comfortable with naval officers and landed gentry. He cultivated friendly relations with moderate Labour party politicians and trade union officials. His abandonment of social aloofness conditioned the royal family's behaviour and enhanced its popularity during the economic crises of the 1920s and for over two generations thereafter.
The years between 1922 and 1929 saw frequent changes in government. In 1924, George appointed the first Labour Prime Minister, Ramsay MacDonald, in the absence of a clear majority for any one of the three major parties. George's tactful and understanding reception of the first Labour government (which lasted less than a year) allayed the suspicions of the party's sympathisers. During the General Strike of 1926 the King advised the government of Conservative Stanley Baldwin against taking inflammatory action, and took exception to suggestions that the strikers were "revolutionaries" saying, "Try living on their wages before you judge them."
In 1926, George hosted an Imperial Conference in London at which the Balfour Declaration accepted the growth of the British Dominions into self-governing "autonomous Communities within the British Empire, equal in status, in no way subordinate one to another". In 1931, the Statute of Westminster formalised George's position as "the symbol of the free association of the members of the British Commonwealth of Nations". The Statute established "that any alteration in the law touching the Succession to the Throne or the Royal Style and Titles" would require the assent of the Parliaments of the Dominions as well as the Parliament at Westminster, which could not legislate for the Dominions, except by consent.
In the wake of a world financial crisis, the King encouraged the formation of a National Government in 1931 led by MacDonald and Baldwin, and volunteered to reduce the civil list to help balance the budget. He was concerned by the rise to power in Germany of Adolf Hitler and the Nazi Party. In 1934, the King bluntly told the German ambassador Leopold von Hoesch that Germany was now the peril of the world, and that there was bound to be a war within ten years if she went on at the present rate; he warned the British ambassador in Berlin Eric Phipps to be suspicious of the Nazis.
In 1932, George agreed to deliver a Royal Christmas speech on the radio, an event that became annual thereafter. He was not in favour of the innovation originally but was persuaded by the argument that it was what his people wanted. By the silver jubilee of his reign in 1935, he had become a well-loved king, saying in response to the crowd's adulation, "I cannot understand it, after all I am only a very ordinary sort of fellow."
George's relationship with his eldest son and heir, Edward, deteriorated in these later years. George was disappointed in Edward's failure to settle down in life and appalled by his many affairs with married women. In contrast, he was fond of his second eldest son, Prince Albert (later George VI), and doted on his eldest granddaughter, Princess Elizabeth; he nicknamed her "Lilibet", and she affectionately called him "Grandpa England". In 1935, George said of his son Edward: "After I am dead, the boy will ruin himself within 12 months", and of Albert and Elizabeth: "I pray to God my eldest son will never marry and have children, and that nothing will come between Bertie and Lilibet and the throne."
Declining health and death.
The First World War took a toll on George's health: he was seriously injured on 28 October 1915 when thrown by his horse at a troop review in France, and his heavy smoking exacerbated recurring breathing problems. He suffered from chronic obstructive pulmonary disease and pleurisy. In 1925, on the instruction of his doctors, he was reluctantly sent on a recuperative private cruise in the Mediterranean; it was his third trip abroad since the war, and his last. In November 1928, he fell seriously ill with septicaemia, and for the next two years his son Edward took over many of his duties. In 1929, the suggestion of a further rest abroad was rejected by the King "in rather strong language". Instead, he retired for three months to Craigweil House, Aldwick, in the seaside resort of Bognor, Sussex. As a result of his stay, the town acquired the suffix "Regis", which is Latin for "of the King". A myth later grew that his last words, upon being told that he would soon be well enough to revisit the town, were "Bugger Bognor!"
George never fully recovered. In his final year, he was occasionally administered oxygen. The death of his favourite sister Victoria in December 1935 depressed him deeply. On the evening of 15 January 1936, the King took to his bedroom at Sandringham House complaining of a cold; he remained in the room until his death. He became gradually weaker, drifting in and out of consciousness. Prime Minister Baldwin later said:
By 20 January, he was close to death. His physicians, led by Lord Dawson of Penn, issued a bulletin with words that became famous: "The King's life is moving peacefully towards its close." Dawson's private diary, unearthed after his death and made public in 1986, reveals that the King's last words, a mumbled "God damn you!", were addressed to his nurse, Catherine Black, when she gave him a sedative on the night of 20 January. Dawson wrote that he hastened the King's death by injecting him with a lethal combination of morphine and cocaine. Dawson noted that he acted to preserve the King's dignity, to prevent further strain on the family, and so that the King's death at 11:55 p.m. could be announced in the morning edition of "The Times" newspaper rather than "less appropriate ... evening journals".
The German composer Paul Hindemith went to a BBC studio on the morning after the King's death and in six hours wrote "Trauermusik" (Mourning Music). It was performed that same evening in a live broadcast by the BBC, with Adrian Boult conducting the BBC Symphony Orchestra and the composer as soloist.
At the procession to George's lying in state in Westminster Hall, part of the Imperial State Crown fell from on top of the coffin and landed in the gutter as the cortège turned into New Palace Yard. The new king, Edward VIII, saw it fall and wondered whether it was a bad omen for his new reign. As a mark of respect to their father, George's four surviving sons, Edward, Albert, Henry, and George, mounted the guard, known as the Vigil of the Princes, at the catafalque on the night before the funeral. The vigil was not repeated until the death of George's daughter-in-law, Queen Elizabeth The Queen Mother, in 2002. George V was interred at St George's Chapel, Windsor Castle, on 28 January 1936. Edward abdicated before the year was out, leaving his brother Albert, Duke of York, to ascend the throne (taking the regnal name George VI).
Legacy.
George preferred to stay at home pursuing his hobbies of stamp collecting and game shooting, and lived a life that later biographers would consider dull because of its conventionality. He was not an intellectual: on returning from one evening at the opera he wrote, "Went to Covent Garden and saw Fidelio and damned dull it was." Nonetheless, he was earnestly devoted to Britain and its Commonwealth. He explained, "it has always been my dream to identify myself with the great idea of Empire." He appeared hard-working and became widely admired by the people of Britain and the Empire, as well as "The Establishment". In the words of historian David Cannadine, George V and Queen Mary were an "inseparably devoted couple" who upheld "character" and "family values". George established a standard of conduct for British royalty that reflected the values and virtues of the upper middle-class rather than upper-class lifestyles or vices. He was by temperament a traditionalist who never fully appreciated or approved the revolutionary changes under way in British society. Nevertheless, he invariably wielded his influence as a force of neutrality and moderation, seeing his role as mediator rather than final decision maker.
Numerous statues of King George V include one by Bertram Mackennal outside the Flower Poll Bazaar Police Station in Madras, and one by William Reid Dick outside Westminster Abbey, London. Other memorials include the King George V Playing Fields in the United Kingdom. The many places named after him include a reservoir and a dock in London; King George V Park in St. John's, Newfoundland; King George V Memorial Hospital in Sydney, Australia and King George's Medical University, India; Stade George V in Curepipe, Mauritius; major thoroughfares in both Jerusalem and Tel Aviv; an avenue, a hotel and an underground station in Paris; King George V School, Seremban, Malaysia; and a school and two parks in Hong Kong. Two Royal Navy battleships were named HMS "King George V" in his honour, one in 1911 and her successor in 1939. George V gave both his name and donations to many charities, including King George's Fund for Sailors (later known as Seafarers UK).
On-screen portrayals.
On screen, George has been portrayed by:
Titles, styles, honours and arms.
Titles and styles.
His full style as king was ""His Majesty" George V, by the Grace of God, of the United Kingdom of Great Britain and Ireland and of the British Dominions beyond the Seas, King, Defender of the Faith, Emperor of India" until the Royal and Parliamentary Titles Act 1927, when it changed to ""His Majesty" George V, by the Grace of God, of Great Britain, Ireland and the British Dominions beyond the Seas, King, Defender of the Faith, Emperor of India".
British honours.
After his accession to the throne in 1910, George became sovereign of all the orders awarded by the British Empire and (later) Commonwealth, including those awarded him prior to his accession.
Arms.
As Duke of York, George's arms were the royal arms, with an inescutcheon of the arms of Saxony, all differenced with a label of three points argent, the centre point bearing an anchor azure. As Prince of Wales the centre label lost its anchor. As King, he bore the royal arms. In 1917, he removed, by warrant, the Saxony inescutcheon from the arms of all male-line descendants of the Prince Consort domiciled in the United Kingdom (although the royal arms themselves had never borne the shield).

</doc>
<doc id="46825" url="https://en.wikipedia.org/wiki?curid=46825" title="Otto Hahn">
Otto Hahn

Otto Hahn, , (8 March 1879 – 28 July 1968) was a German chemist and pioneer in the fields of radioactivity and radiochemistry who won the Nobel Prize in Chemistry in 1944 for the discovery and the radiochemical proof of nuclear fission. He is referred to as the father of nuclear chemistry.
Hahn was an opponent of Jewish persecution by the Nazi Party and, after World War II, he became a passionate campaigner against the use of nuclear energy as a weapon. He served as the last President of the Kaiser Wilhelm Society (KWG) in 1946 and as the founding President of the Max Planck Society (MPG) from 1948 to 1960. Considered by many to be a model for scholarly excellence and personal integrity, he became one of the most influential and respected citizens of the new Federal Republic of Germany.
Early life.
Hahn was the youngest son of Heinrich Hahn (1845–1922), a prosperous glazier and entrepreneur ("Glasbau Hahn"), and Charlotte Hahn, née Giese (1845–1905). Together with his brothers Karl, Heiner and Julius, Otto was raised in a sheltered environment. At the age of 15, he began to take a special interest in chemistry, and carried out simple experiments in the laundry room of the family home. His father wanted Otto to study architecture, as he had built or acquired several residential and business properties, but Otto persuaded him that his ambition was to become an industrial chemist.
In 1897, after taking his "Abitur" at the Klinger Oberrealschule in Frankfurt, Hahn began to study chemistry and mineralogy at the University of Marburg. His subsidiary subjects were physics and philosophy. Hahn joined the Students' Association of Natural Sciences and Medicine, a student fraternity and a forerunner of today's "Landsmannschaft Nibelungia" (Coburger Convent der akademischen Landsmannschaften und Turnerschaften). He spent his third and fourth semester studying under Adolf von Baeyer at the University of Munich. In 1901, Hahn received his doctorate in Marburg for a dissertation entitled "On Bromine Derivates of Isoeugenol", a topic in classical organic chemistry. After completing his one-year military service, the young chemist returned to the University of Marburg, where for two years he worked as assistant to his doctoral supervisor, Geheimrat Professor Theodor Zincke.
Research in London and Montreal (1904–1906).
Discovery of radiothorium and other 'new elements'.
Hahn's intention had been to work in industry. With this in mind, and also to improve his knowledge of English, he took up a post at University College London in 1904, working under Sir William Ramsay, known for having discovered the inert gases. Here Hahn worked on radiochemistry, at that time a very new field. In early 1905, in the course of his work with salts of radium, Hahn discovered a new substance he called radiothorium (thorium-228), which at that time was believed to be a new radioactive element. (In fact, it was a still undiscovered isotope of the known element thorium. The term "isotope" was only coined in 1913, by the British chemist Frederick Soddy).
Ramsay was very enthused when yet another new element was found in his institute, and he intended to announce the discovery in a correspondingly suitable way. In accordance with tradition this should be done before the committee of the venerable Royal Society. At the session of the Royal Society on the 16 March 1905 Ramsay communicated Hahn's discovery of radiothorium, and even the press was interested. The Daily Telegraph informed its readers:
For the first time the name of Otto Hahn was mentioned in connection with radium research, and his "New radioactive Element, which evolves Thorium Emanation" (so the original title) was published in the "Proceedings of the Royal Society" in the issue of 24 March 1905 (76 A, pages 115-117). It was the first of more than 250 scientific publications of Otto Hahn in the field of radiochemistry.
wrote Ramsay to Ernest Rutherford in May 1905.
Rutherford agreed and, from September 1905 until mid-1906, Hahn worked in his team at McGill University in Montreal, Canada where he discovered thorium C (later identified as polonium-212), radium D (later identified as lead-210), and radioactinium (later identified as thorium-227), and investigated the alpha rays of radiothorium, while Rutherford used to say in these days: ""Hahn has a special nose for discovering new elements.""
In his Rutherford biography the BBC Science Correspondent David Wilson analysed:
Research in Berlin (1906–1944).
Discovery of mesothorium I (Ra 228).
In 1906, Hahn returned to Germany, where he collaborated with Emil Fischer at the University of Berlin. Fischer placed at his disposal a former woodworking shop ("Holzwerkstatt") in the Chemical Institute to use as his own laboratory. There, in the space of a few months, using extremely primitive apparatus, Hahn discovered mesothorium I, mesothorium II, and – independently from Bertram Boltwood – the mother substance of radium, ionium (later identified as thorium-230). In subsequent years, mesothorium I (radium-228) assumed great importance because, like radium-226 (discovered by Pierre and Marie Curie), it was ideally suited for use in medical radiation treatment, while costing only half as much to manufacture.
wrote BBC's David Wilson in his Rutherford biography.
In 1914, for the discovery of mesothorium I (radium-228), Otto Hahn was first nominated for the Nobel Prize in Chemistry by Adolf von Baeyer and, in June 1907, by means of the traditional "habilitation" thesis, Hahn qualified to teach at the University of Berlin. On 28 September 1907 he made the acquaintance of the Austrian physicist Lise Meitner who was almost the same age, who had transferred from Vienna to Berlin. So began the thirty-year collaboration and lifelong close friendship between the two scientists.
Discovery of radioactive recoil.
After the physicist Harriet Brooks had observed a "radioactive recoil" in 1904, but interpreted it wrongly, Otto Hahn succeeded, in late 1908 and early 1909, in demonstrating the radioactive recoil incident to alpha particle emission and interpreting it correctly.
as the physicist Walther Gerlach put it. And Ernest Rutherford in Manchester wrote in a letter to his mother: ""He is doing the best work in Germany at present.""
In 1910 Hahn was appointed professor by the Prussian Minister of Culture and Education August von Trott zu Solz and, in 1912, he became head of the Radioactivity Department of the newly founded Kaiser Wilhelm Institute for Chemistry in Berlin-Dahlem (today 'Hahn-Meitner-Building' of the Free University, Berlin, Thielallee 63). Succeeding Alfred Stock, Hahn was director of the institute from 1928 to 1946. In 1924, Hahn was elected to full membership of the Prussian Academy of Sciences in Berlin (proposed by Albert Einstein, Max Planck, Fritz Haber, Wilhelm Schlenk, and Max von Laue).
Marriage with Edith Junghans.
In June 1911, while attending a conference in Stettin (today Szczecin, Poland) Otto Hahn met the young Edith Junghans (1887–1968), an art student at the ""Königliche Kunstschule"" (Royal Academy of Art) in Berlin. On 22 March 1913 the couple married in Edith's native city of Stettin, where her father, Paul Ferdinand Junghans, was a high-ranking law officer and President of the City Parliament until his 1915 death. Their only child, Hanno, born in 1922, became a distinguished art historian and architectural researcher (at the Hertziana in Rome), known for his discoveries in the early Cistercian architecture of the 12th century. In August 1960, while on a study trip in France, Dr Hanno Hahn was involved in a fatal car accident, together with his wife and assistant Ilse Hahn, née Pletz. They left a fourteen-year-old son, Dietrich. In 1990, the Hanno and Ilse Hahn Prize for outstanding contributions to Italian art history was established in memory of Hanno and Ilse Hahn to support young and talented art historians. It is awarded biennially by the Bibliotheca Hertziana – Max Planck Institute of Art History in Rome.
Discovery of protactinium.
During the First World War, Hahn was conscripted into the army, where he was assigned, together with James Franck and Gustav Hertz, to the special unit for chemical warfare under the direction of Fritz Haber. The unit developed, tested, and produced poison gas for military purposes, and was sent to both the western and eastern front lines. In December 1916, Hahn was transferred to the "Headquarters of His Majesty" in Berlin, and was able to resume his radiochemical research in his institute. In 1917-1918, Hahn and Lise Meitner isolated a long-lived activity, which they named "proto-actinium". Already in 1913, Kazimierz Fajans and Göhring had isolated a short-lived activity from uranium X2 (later known as 234mPa), and called the substance "brevium". The two activities were different isotopes of the same undiscovered element number 91. For their discovery Hahn and Meitner were repeatedly nominated for the Chemistry-Nobel Prize in the 1920s by a number of scientists, among them Max Bergmann, Viktor Moritz Goldschmidt, and even Kazimierz Fajans himself. In 1949, the International Union of Pure and Applied Chemistry (IUPAC) named the new element definitely protactinium, and confirmed Hahn and Meitner as discoverers.
Discovery of nuclear isomerism.
In February 1921, Otto Hahn published the first report on his discovery of uranium Z (later known as 234Pa ), the first example of nuclear isomerism.
as Walther Gerlach remarked. And, indeed, it was not until 1936 that the young physicist Carl Friedrich von Weizsäcker succeeded in providing a theoretical explanation of the phenomenon of nuclear isomerism. For this discovery, whose full significance was recognized by very few, Hahn was again proposed, from 1923 till 1929, for the Nobel Prize in Chemistry by Naunyn, Goldschmidt, and Max Planck.
Applied radiochemistry.
In the early 1920s, Otto Hahn created a new field of work. Using the "emanation method", which he had recently developed, and the "emanation ability", he founded what became known as ""Applied radiochemistry"" for the researching of general chemical and physical-chemical questions. In 1936 he published a book in English (and later in Russian) entitled "Applied Radiochemistry", which contained the lectures given by Hahn when he was a visiting professor at Cornell University in Ithaca, New York in 1933. This important publication had a major influence on almost all nuclear chemists and physicists in the United States, the United Kingdom, France, and the Soviet Union during the 1930s and 1940s.
In 1966, Glenn T. Seaborg, co-discoverer of many transuranium elements and President of the United States Atomic Energy Commission, wrote about this book as follows:
And Seaborg added:
Discovery of nuclear fission (1938).
Jointly with Lise Meitner and his pupil and assistant Fritz Strassmann (1902–1980), Otto Hahn furthered the research begun by Enrico Fermi and his team in 1934 when they bombarded uranium with neutrons. Until 1938, it was believed that the elements with atomic numbers greater than 92 (known as transuranium elements) arose when uranium atoms were bombarded with neutrons. The German chemist Ida Noddack proposed an exception. She anticipated the paradigm shift of 1938/39 in her article published in the journal "Angewandte Chemie", Nr. 47, 1934, in which she speculated:
But no physicist or chemist really took Noddack's speculation seriously or tested it, not even Ida Noddack herself. The idea that heavy atomic nuclei could break down into lighter elements was regarded as totally inadmissible.
Between 1934 and 1938, Hahn, Meitner, and Strassmann found a great number of radioactive transmutation products, all of which they regarded as transuranic. At that time the existence of actinides was not yet established, and uranium was wrongly believed to be a group 6 element similar to tungsten. It followed that first transuranic elements would be similar to group 7 to 10 elements, i.e. rhenium and platinoids. The Hahn group established the presence of multiple isotopes of at least four such elements, and (mistakenly) identify them as elements with atomic numbers 93 through 96. They were the first scientists to measure the half-life of 239U and to establish chemically that it was an isotope of uranium, but they were unable to continue this work to its logical conclusion and identify the decay product of 239U – namely, neptunium (the real element 93); this task was only completed by Edwin McMillan and Philip H. Abelson in 1940.
On 13 July 1938, with the help and support of Hahn, Lise Meitner – born into a Jewish family – escaped to the Netherlands; before she left, Hahn gave her a diamond ring he had inherited from his mother, to be used to bribe the frontier guards if required. Meitner emigrated to Stockholm, and Hahn continued to work with Strassmann. In late 1938 they found evidence of isotopes of an alkaline earth metal in their sample. The metal was detected by the use of an organic barium salt constructed by Wilhelm Traube. Finding a group 2 alkaline earth metal was problematic, because it did not logically fit with the other elements found thus far. Hahn initially suspected it to be radium, produced by splitting off two alpha-particles from the uranium nucleus. At the time, the scientific consensus was that even splitting off two alpha particles via this process was unlikely. The idea of turning uranium into barium (by removing around 100 nucleons) was seen as preposterous. On 10 November during a visit to Copenhagen, where he was invited to lecture in Bohr's Institute, Hahn discussed these results with Niels Bohr, Lise Meitner, and Otto Robert Frisch. Further refinements of the technique, leading to the decisive experiment on 16–17 December 1938 (the celebrated ""radium-barium-mesothorium-fractionation""), produced puzzling results: the three isotopes consistently behaved not as radium, but as barium. Hahn, who did not inform the physicists in his Institute, described the results exclusively in a letter to Meitner on 19 December: ""...we are more and more coming to the awful conclusion that our Ra isotopes behave not like Ra, but like Ba. ... Perhaps you can suggest some fantastic explanation. We ourselves realize that it can't really burst into Ba."" In her reply, Meitner concurred that Hahn's conclusion of "the bursting of the uranium nucleus" was very difficult to accept, but considered it possible.
On 22 December 1938, Hahn sent a manuscript to "Naturwissenschaften" reporting their radiochemical results, which were published on 6 January 1939. On 27 December, Hahn telephoned the editor of "Naturwissenschaften" and requested to add a paragraph to the article, speculating that some platinum group elements previously observed in irradiated uranium, which were originally interpreted as transuranium elements, could in fact be technetium (then called "masurium") and lower platinum-group metals (atomic numbers 43 through 46). By January 1939 he was sufficiently convinced that formation of light elements was occurring in his setup that he published a new revision of the article, essentially retracting former claims of observing transuranic elements and neighbors of uranium, and concluding instead that he was seeing light platinoids, barium, lanthanum, and cerium.
Fritz Strassmann recollects:
As a chemist, Hahn was reluctant to propose a revolutionary discovery in physics, but Lise Meitner and her nephew, the young physicist Otto Robert Frisch, in Sweden, came to the same conclusion (a "bursting") as Hahn and were able, because they had a lead of time, to work out the first theoretical interpretation of nuclear fission – the term that was coined by Frisch, and which subsequently became internationally known. Over the next few months, Frisch and Meitner published two articles discussing and experimentally confirming this hypothesis.
In a later appreciation (1963), Lise Meitner wrote:
And in an interview on West German television (ARD, 8 March 1959), Meitner said:
In the same interview Fritz Strassmann responded with this clarification:
And James Chadwick wrote in a preface:
In their second publication on nuclear fission ("Die Naturwissenschaften", 10 February 1939) Otto Hahn and Fritz Strassmann used for the first time the term "Uranspaltung" (uranium fission), and predicted the existence and liberation of additional neutrons during the fission process, which was proved to be a chain reaction by Frédéric Joliot and his team in March 1939.
Rudolf Ladenburg, émigré physicist at Princeton University (Palmer Laboratory) wrote to Hahn on February 22, 1939:
During the war, Otto Hahn – together with his assistants Hans-Joachim Born, Siegfried Flügge, Hans Götte, Walter Seelmann-Eggebert, and Fritz Strassmann – worked on uranium fission reactions. By 1945 he had drawn up a list of 25 elements and about 100 isotopes whose existence he had demonstrated.
Internment in England (1945).
At the end of World War II in 1945 Hahn was suspected of working on the German nuclear energy project to develop an atomic reactor or an atomic bomb, but his only connection was the discovery of fission; he did not work on the program. In April 1945, Hahn and nine leading German physicists (including Max von Laue, Werner Heisenberg, and Carl Friedrich von Weizsäcker) were taken into custody by the Alsos Mission (see Operation Epsilon) and interned at Farm Hall, Godmanchester, near Cambridge, England, from 3 July 1945 to 3 January 1946. The chief officer, Major Terence H. Rittner informed the authorities about his prisoners. He described Hahn as follows:
In Farm Hall the German scientists learned of the dropping of the atom bombs on Hiroshima and Nagasaki by the American airforce on 6 and 9 August 1945. Otto Hahn was on the brink of despair.
The historian Lawrence Badash (from the University of California at Santa Barbara) wrote in his essay:
On January 3, 1946, the group was allowed to return to Germany, and Hahn, Heisenberg, and von Laue were brought to the city of Göttingen, which was controlled by the British occupation authorities.
The Nobel Prize in Chemistry 1944.
On 15 November 1945 the Royal Swedish Academy of Sciences announced that Hahn had been awarded the 1944 Nobel Prize in Chemistry ""for his discovery of the fission of heavy atomic nuclei."" Some US-American historians have documented their view of the discovery of nuclear fission and believe Meitner should have been awarded the Nobel Prize with Hahn. Hahn was still being detained at Farm Hall when the announcement was made; thus, his whereabouts were a secret, and it was impossible for the Nobel committee to send him a congratulatory telegram. Instead, he learned about his award through the "Daily Telegraph" newspaper. His fellow interned German scientists celebrated his award on 18 November by giving speeches, making jokes, and composing songs. On 4 December, Hahn was persuaded by two of his captors to write a letter to the Nobel committee accepting the prize but also stating that he would not be able to attend the award ceremony. He could not participate in the Nobel festivities on 10 December since his captors would not allow him to leave Farm Hall.
wrote Lise Meitner to her friend B. Broomé-Aminoff on November 20, 1945. And Meitner's former assistant Carl Friedrich von Weizsäcker later added:
The radiochemist and Jewish émigré Elizabeth Rona (later a Professor of Chemistry in Miami) wrote in her memoirs:
Hahn attended the Nobel festivities the year after he was awarded the prize. On 10 December 1946, King Gustav V of Sweden presented him with his Nobel Prize medal and diploma.
The chemist and science historian Klaus Hoffmann wrote in his 1993 biography of Hahn (translated by J. Michael Cole, Leyburn, UK):
Otto Hahn had been nominated 22 times for the Nobel Prize in Chemistry from 1914 to 1945, and 16 times for the Nobel Prize in Physics from 1937 to 1947.
In 1951 Samuel C. Lind, the eminent American radiation scientist from the University of Minnesota in Minneapolis, wrote in a review:
Founder and President of the Max Planck Society.
From 1948 to 1960 Otto Hahn was the founding President of the newly formed Max Planck Society for the Advancement of Science, which through his tireless activity and his worldwide respected personality succeeded in regaining the renown once enjoyed by the Kaiser Wilhelm Society.
Lawrence Badash wrote:
And Sir James Chadwick noted:
Spokesman for social responsibility.
Immediately after the Second World War, Hahn reacted to the dropping of the atomic bombs on Hiroshima and Nagasaki by coming out strongly against the use of nuclear energy for military purposes. He saw the application of his scientific discoveries to such ends as a misuse, or even a crime.
In early 1954 he wrote an article ""Cobalt 60 - Danger or Blessing for Mankind?"" about the misuse of atomic energy, which was widely reprinted and transmitted in the radio in Germany, Norway, Austria, and Denmark, and in an English version worldwide via the BBC. The international reaction was encouraging.
The next year Hahn initiated and organized the Mainau Declaration of 1955, in which he and a number of international Nobel Prize-winners called attention to the dangers of atomic weapons and warned the nations of the world urgently against the use of ""force as a final resort"", and which was issued a week after the similar Russell-Einstein Manifesto. In 1956 Hahn repeated his appeal with the signature of 52 of his Nobel colleagues from all parts of the world.
He was also instrumental in and one of the authors of the Göttingen Manifesto of April 13, 1957, in which, together with 17 leading German atomic scientists, he protested against a proposed nuclear arming of the new West German armed forces (Bundeswehr).
On November 13, 1957, in the 'Konzerthaus' (Concerto Hall) in Vienna, Hahn warned in his Vienna Appeal of the ""dangers of A- and H-bomb-experiments"", and declared that ""today war is no means of politics anymore - it will only destroy all countries in the world"". His highly acclaimed speech was transmitted internationally by the Austrian radio, Österreichischer Rundfunk (ÖR). On December 28, 1957, Hahn repeated his appeal in an English translation for the Bulgarian Radio in Sofia, which was broadcast in all Warsaw pact states.
In January 1958, Otto Hahn, together with his friend Albert Schweitzer signed the Pauling Appeal to the United Nations in New York for the ""immediate conclusion of an international agreement to stop the testing of nuclear weapons"" and, in October, together with Clement Attlee, Edgar Faure, Tetsu Katayama, et al. he signed the international "Agreement to call a meeting to draw up a world constitution".
Since 1958 Hahn was sending messages to the annual conferences of the recently founded "Japan Council Against A and H Bombs" in Tokyo. In 1960, for instance, he wrote to president Koshiro Okakura:
In 1959 Hahn co-founded in Berlin the Federation of German Scientists (VDW), a non-governmental organization, which has been committed to the ideal of responsible science. The members of the Federation feel committed to taking into consideration the possible military, political, and economical implications and possibilities of atomic misuse when carrying out their scientific research and teaching. With the results of its interdisciplinary work the 'VDW' not only addresses the general public, but also the decision-makers at all levels of politics and society.
Right up to his death, Otto Hahn never tired of warning urgently of the dangers of the nuclear arms race between the great powers and of the radioactive contamination of the planet.
The philosopher Sir Karl R. Popper wrote in his last book:
The historian Lawrence Badash analysed:
From 1957, Hahn was repeatedly nominated for the Nobel Peace Prize by a number of international organizations, including the largest French trade union, the Confederation Generale du Travail (CGT). - Linus Pauling, the 1962 Nobel Peace laureate, once described Otto Hahn as ""an inspiration to me."" 
Honors and awards.
During his lifetime Hahn was awarded orders, medals, scientific prizes, and fellowships of Academies, Societies, and Institutions from all over the world. A selection:
In 1957 Hahn was elected an honorary citizen of the city of Magdeburg, DDR (German Democratic Republic) and, in 1958, an honorary member of the Academy of Sciences of the USSR (today Russian Academy of Sciences) in Moscow, but he declined both honors.
In 1966, President Lyndon B. Johnson of the USA and the United States Atomic Energy Commission (AEC) in Washington awarded Hahn (together with Lise Meitner and Fritz Strassmann) the Enrico Fermi Award (with a gold medal and citation). The diploma for Hahn bears the words:
Hahn, since 1960 honorary president of the MPG, was made an honorary citizen of the cities of Frankfurt am Main and Göttingen in 1959, and of the land and the city of Berlin in 1968. The British physicist Robert Spence FRS, concluded in his essay:
Otto Hahn died on 28 July 1968. The day after his death the Max Planck Society published the following obituary notice in all the major newspapers in Germany, Austria, and Switzerland:
Fritz Strassmann, Hahn's pupil and assistant, wrote:
Otto Robert Frisch, Lise Meitner's nephew, recollected:
And the Royal Society in London wrote in an obituary:
Legacy.
Hahn's death did not stop his public acclamation. Proposals were made at different times, first in 1971 by American chemists, that the newly synthesized element no. 105 should be named hahnium in Hahn's honor; in 1997 the IUPAC (International Union of Pure and Applied Chemistry) named it dubnium, after the Russian research center in Dubna (see element naming controversy). Although element 108 was given the name hassium by its officially-recognized German discoverers in 1992, a 1994 IUPAC committee recommended that it be named hahnium (Hn), in spite of the long-standing convention to give the discoverer the right to suggest a name. This recommendation was not adopted, following protests from the German discoverers, and the name hassium (Hs) was adopted internationally in 1997.
In 1964 the only European nuclear-powered civilian ship, the freighter "NS Otto Hahn", was named in his honor. In 1959 there were the opening ceremonies of the Otto Hahn Institute in Mainz and the Hahn-Meitner-Institut "for Nuclear Research" (HMI) in Berlin. There are craters on Mars and the Moon, and the asteroids No. "3676 Hahn" and No. "19126 Ottohahn" named in his honor, as were the Otto Hahn Prize of both the German Chemical and Physical Societies and the city of Frankfurt/Main, the Otto Hahn Medal, and the Otto Hahn Award of the Max Planck Society and, since 1988, the Otto Hahn Peace Medal in Gold of the United Nations Association of Germany (DGVN) in Berlin.
Many cities and districts in the German-speaking countries have named secondary schools after him, and streets, squares, and bridges throughout Europe bear his name. More than twenty states worldwide have honored Otto Hahn by issuing coins, medals or stamps with his portrait. An island in the Antarctic (near Mt. Discovery) was also named after him, as were two Intercity trains "Otto Hahn" of the German Federal Railways in 1971, running between Hamburg and Basel SBB, and the "Otto Hahn Library" in Göttingen. In 1974, in appreciation of the special contribution of Otto Hahn to German-Israeli relations, a wing of the Weizmann Institute of Science in Rehovot, Israel, was given his name, and a scientific research center of the Saint Louis University (Baguio) (Philippines) was named the "Otto Hahn Building".
In several cities and districts Otto Hahn busts, monuments, and memorial plaques were unveiled, including in Vienna in the foyer of the International Atomic Energy Agency (IAEA). There are public "Otto Hahn Centers" in Göttingen and Ottobrunn (near Munich), and planned in the near future also in Hahn's native city Frankfurt/Main, while in 2011 the city of Albstadt created an "Otto Hahn Memorial place" in her local IHK-Academy, focussed on Hahn's work in Tailfingen at the end of World War II. In early 2014, the University of Dortmund opened two new "Otto Hahn Libraries" in her General University Library, which are specialized in the natural sciences and technologies.
At the end of 1999, the German news magazine "Focus" published an inquiry of 500 leading natural scientists, engineers, and physicians about the most important scientists of the 20th century. In this poll the experimental chemist Otto Hahn – after the theoretical physicists Albert Einstein and Max Planck – was elected third (with 81 points), and thus the most significant empiric researcher of his time.

</doc>
<doc id="46826" url="https://en.wikipedia.org/wiki?curid=46826" title="Windsor">
Windsor

Windsor may refer to:

</doc>
<doc id="46827" url="https://en.wikipedia.org/wiki?curid=46827" title="Jesse Owens">
Jesse Owens

James Cleveland "Jesse" Owens (September 12, 1913March 31, 1980) was an American track and field athlete and four-time Olympic gold medalist.
Owens specialized in the sprints and the long jump and was recognized in his lifetime as "perhaps the greatest and most famous athlete in track and field history". His achievement of setting three world records and tying another in less than an hour at the 1935 Big Ten track meet in Ann Arbor, Michigan, has been called "the greatest 45 minutes ever in sport" and has never been equaled. At the 1936 Summer Olympics in Berlin, Germany, Owens won international fame with four gold medals: 100 meters, 200 meters, long jump, and 4 × 100 meter relay. He was the most successful athlete at the games and as such has been credited with "single-handedly crush Hitler's myth of Aryan supremacy."
The Jesse Owens Award is USA Track and Field's highest accolade for the year's best track and field athlete. Owens was ranked by ESPN as the sixth greatest North American athlete of the twentieth century and the highest-ranked in his sport.
Early life and education.
Owens was the youngest of ten children, three girls and seven boys, born to Henry Cleveland Owens (a sharecropper) and Mary Emma Fitzgerald in Oakville, Alabama, on September 12, 1913. "J.C.", as he was called, was nine years old when the family moved to Cleveland, Ohio, for better opportunities, as part of the Great Migration, when 1.5 million African Americans left the segregated South. When his new teacher asked his name (to enter in her roll book), he said "J.C.", but because of his strong Southern accent, she thought he said "Jesse". The name stuck, and he was known as Jesse Owens for the rest of his life.
As a boy, Owens took different jobs in his spare time: he delivered groceries, loaded freight cars and worked in a shoe repair shop while his father and older brother worked at a steel mill. During this period, Owens realized that he had a passion for running. Throughout his life, Owens attributed the success of his athletic career to the encouragement of Charles Riley, his junior high track coach at Fairmount Junior High School. Since Owens worked in a shoe repair shop after school, Riley allowed him to practice before school instead.
Owens and Minnie Ruth Solomon (1915-2001) met at Fairmount Junior High School in Cleveland when he was 15 and she was 13. They dated steadily through high school. Ruth gave birth to their first daughter, Gloria, in 1932. They married in 1935 and had two more daughters together: Marlene, born in 1939, and Beverly, born in 1940. They remained married until his death in 1980.
Owens first came to national attention when he was a student of East Technical High School in Cleveland; he equalled the world record of 9.4 seconds in the dash and long-jumped at the 1933 National High School Championship in Chicago.
Career.
The Ohio State University.
Owens attended The Ohio State University after employment was found for his father, ensuring the family could be supported. Affectionately known as the "Buckeye Bullet," Owens won a record eight individual NCAA championships, four each in 1935 and 1936. (The record of four gold medals at the NCAA was equaled only by Xavier Carter in 2006, although his many titles also included relay medals.) Though Owens enjoyed athletic success, he had to live off campus with other African-American athletes. When he traveled with the team, Owens was restricted to ordering carry-out or eating at "blacks-only" restaurants. Similarly, he had to stay at "blacks-only" hotels. Owens did not receive a scholarship for his efforts, so he continued to work part-time jobs to pay for school.
Owens's greatest achievement came in a span of 45minutes on May 25, 1935, during the Big Ten meet at Ferry Field in Ann Arbor, Michigan, where he set three world records and tied a fourth. He equaled the world record for the 100 yard dash (9.4 seconds); and set world records in the long jump (, a world record that would last 25 years); 220-yard (201.2 m) sprint (20.3 seconds); and 220-yard (201.2m) low hurdles (22.6 seconds, becoming the first to break 23 seconds). In 2005, University of Central Florida professor of sports history Richard C. Crepeau chose these wins on one day as the most impressive athletic achievement since 1850.
Berlin Olympics.
In 1936, Owens arrived in Berlin to compete for the United States at the Summer Olympics. According to fellow American athlete James LuValle, who won bronze in the 400 meters, Owens arrived in Berlin to a throng of fans, many of them young girls, yelling "Wo ist Jesse? Wo ist Jesse?" Many of them had come with scissors and had begun snipping at Owens' clothing, forcing him to retreat back onto the train. After that, when Owens left the athletes' village, he usually had to go with some soldiers to protect him. In contrast, Adolf Hitler was using the games to show the world a resurgent Nazi Germany. He and other government officials had high hopes that German athletes would dominate the games with victories. Meanwhile, Nazi propaganda promoted concepts of "Aryan racial superiority" and depicted others, including those of African descent, as inferior. Owens countered this by winning four gold medals.
On August 3, he won the 100m sprint with a time of 10.3s, defeating teammate college friend Ralph Metcalfe by a tenth of a second and defeating Tinus Osendarp of the Netherlands by two tenths of a second. On August 4, he won the long jump with a leap of , later crediting his achievement to the technical advice he received from Lutz Long, the German competitor whom he defeated. On August 5, he won the 200m sprint with a time of 20.7s, defeating Mack Robinson (the older brother of Jackie Robinson). On August 9, Owens won his fourth gold medal in the 4x100 sprint relay when coach Dean Cromwell replaced Jewish-American sprinters Marty Glickman and Sam Stoller with Owens and Ralph Metcalfe, who teamed up with Frank Wykoff and Foy Draper to set a world record of 39.8s in the event. This performance was not equaled until Carl Lewis won gold medals in the same events at the Soviet-boycotted 1984 Summer Olympics in Los Angeles. In 1935 (the year before the Berlin Olympics), Jesse Owens set the world record in the long jump with a leap of 26 ft 8 in, and this record would stand for 25 years (a very rare length of time for a track and field record), until it was finally broken by countryman Ralph Boston in 1960. Coincidentally, Owens was a spectator at the 1960 Summer Olympics in Rome when Boston took the gold medal in the long jump.
Just before the competitions, Owens was visited in the Olympic village by Adi Dassler, the founder of the Adidas athletic shoe company. He persuaded Owens to wear Gebrüder Dassler Schuhfabrik shoes, the first sponsorship for a male African American athlete.
The long-jump victory is documented, along with many other 1936 events, in the 1938 film "Olympia" by Leni Riefenstahl.
On the first day of competition, Hitler shook hands with only the German victors and then left the stadium. Olympic committee officials insisted Hitler greet every medalist or none at all. Hitler opted for the latter and skipped all further medal presentations. Historians have noted that Hitler may have left the games at this time due to looming rain clouds that might have postponed the games. This happened well before Owens was to compete, but has largely come to be believed to be the "snub". 
On reports that Hitler had deliberately avoided acknowledging his victories, and had refused to shake his hand, Owens said at the time:
Hitler had a certain time to come to the stadium and a certain time to leave. It happened he had to leave before the victory ceremony after the 100 meters. But before he left I was on my way to a broadcast and passed near his box. He waved at me and I waved back. I think it was bad taste to criticize the 'man of the hour' in another country.
Albert Speer wrote that Hitler "was highly annoyed by the series of triumphs by the marvelous colored American runner, Jesse Owens. People whose antecedents came from the jungle were primitive, Hitler said with a shrug; their physiques were stronger than those of civilized whites and hence should be excluded from future games." 
In a 2009 interview, Siegfried Mischner, a German journalist, claimed that Owens carried around a photograph in his wallet of the Führer shaking his hand before the latter left the stadium. Owens, who felt the newspapers of the day reported 'unfairly' on Hitler's attitude towards him, tried to get Mischner and his journalist colleagues to change the accepted version of history in the 1960s. Mischner claimed Owens showed him the photograph and told him: "That was one of my most beautiful moments." Mischner added "(the picture) was taken behind the honour stand and so not captured by the world's press. But I saw it, I saw him shaking Hitler's hand!" According to Mischner, "the predominating opinion in post-war Germany was that Hitler had ignored Owens, so we therefore decided not to report on the photo. The consensus was that Hitler had to continue to be painted in a bad light in relation to Owens." For some time, Mischner's assertion was not confirmed independently of his own account, and Mischner himself admitted in "Mail Online" that "All my colleagues are dead, Owens is dead. I thought this was the last chance to set the record straight. I have no idea where the photo is or even if it exists still."
However, in 2014, Eric Brown, British fighter pilot and test pilot, the Fleet Air Arm's most decorated living pilot, independently stated in a BBC documentary "I actually witnessed Hitler shaking hands with Jesse Owens and congratulating him on what he had achieved." Additionally, an article in "The Baltimore Sun" in August 1936 reported that Hitler sent Owens a commemorative inscribed cabinet photograph of himself.
In Germany, Owens was allowed to travel with and stay in the same hotels as whites, while at the time African Americans in many parts of the United States had to stay in segregated hotels. During a Manhattan ticker-tape parade along Broadway's Canyon of Heroes in his honor, someone handed Owens a paper bag. Owens paid it little mind until the parade concluded. When he opened it up, he found the bag contained $10,000 in cash. Owens's wife Ruth later said, "And he didn't know who was good enough to do a thing like that. And with all the excitement around, he didn't pick it up right away. He didn't pick it up until he got ready to get out of the car." After the parade, Owens was not permitted to enter through the main doors of the Waldorf Astoria New York and instead forced to travel up to the event in a freight elevator to reach the reception honoring him. President Franklin D. Roosevelt (FDR) never invited Jesse Owens to the White House following his triumphs at the Olympics games. While the Democrats had bid for the support of Owens, Owens rejected those overtures: as a staunch Republican, he endorsed Roosevelt's Republican opponent, Alf Landon, in the 1936 presidential race. 
Owens, who joined the Republican Party after returning from Europe, was paid to campaign for African American votes for the Republican presidential nominee Alf Landon in the 1936 presidential election. Speaking at a Republican rally held in Baltimore on October 9, 1936, Owens said "Some people say Hitler snubbed me. But I tell you, Hitler did not snub me. I am not knocking the President. Remember, I am not a politician, but remember that the President did not send me a message of congratulations because people said, he was too busy." Later, on October 15, 1936 Owens repeated this allegation when he addressed an audience of African American at a Republican rally in Kansas City remarking that "Hitler didn't snub me – it was our president who snubbed me. The president didn't even send me a telegram."
Later life.
Owens was quoted saying the secret behind his success was "I let my feet spend as little time on the ground as possible. From the air, fast down, and from the ground, fast up."
After the games had finished, the Olympic team and Owens were all invited to compete in Sweden. He decided to capitalize on his success by returning to the United States to take up some of the more lucrative commercial offers. United States athletic officials were furious and withdrew his amateur status, ending his career immediately. Owens was angry, saying, "A fellow desires something for himself." Owens argued that the racial discrimination he had faced throughout his athletic career, such as not being eligible for scholarships in college and therefore being unable to take classes between training and working to pay his way, meant he had to give up on amateur athletics in pursuit of financial gain elsewhere.
Prohibited from amateur sporting appearances to bolster his profile, Owens found out that the commercial offers had all but disappeared. In 1946, he joined Abe Saperstein in the formation of the West Coast Baseball Association (WCBA), a new Negro baseball league; Owens was Vice-President and the owner of the Portland (Oregon) Rosebuds franchise. He toured with the Rosebuds, sometimes entertaining the audience in between doubleheader games by competing in races against horses. The WCBA disbanded after only two months.
Owens helped promote the exploitation film "Mom and Dad" in African American neighborhoods. He tried to make a living as a sports promoter, essentially an entertainer. He would give local sprinters a ten- or twenty-yard start and beat them in the 100-yd (91-m) dash. He also challenged and defeated racehorses; as he revealed later, the trick was to race a high-strung thoroughbred that would be frightened by the starter's shotgun and give him a bad jump. Owens said, "People say that it was degrading for an Olympic champion to run against a horse, but what was I supposed to do? I had four gold medals, but you can't eat four gold medals." On the lack of opportunities, Owens added, "There was no television, no big advertising, no endorsements then. Not for a black man, anyway.”
Owens ran a dry cleaning business and worked as a gas station attendant to earn a living; he eventually filed for bankruptcy. In 1966, he was successfully prosecuted for tax evasion. At rock bottom, he was aided in beginning his rehabilitation. The government appointed him as a US goodwill ambassador. Owens traveled the world and spoke to companies such as the Ford Motor Company and stakeholders such as the United States Olympic Committee. After he retired, he owned racehorses.
Owens initially refused to support the black power salute by African-American sprinters Tommie Smith and John Carlos at the 1968 Summer Olympics. He told them:
The black fist is a meaningless symbol. When you open it, you have nothing but fingers – weak, empty fingers. The only time the black fist has significance is when there's money inside. There's where the power lies.
Four years later in his 1972 book "I Have Changed", he moderated his opinion:
I realized now that militancy in the best sense of the word was the only answer where the black man was concerned, that any black man who wasn't a militant in 1970 was either blind or a coward.
A few months before his death, Owens had tried unsuccessfully to convince President Jimmy Carter to withdraw his demand that the United States boycott the 1980 Moscow Olympics. He argued that the Olympic ideal was supposed to be observed as a time-out from war and that it was above politics.
Death.
Owens, a pack-a-day cigarette smoker for 35years, had been hospitalized with an extremely aggressive and drug-resistant type of lung cancer on and off beginning in December 1979. He died of the disease at age66 in Tucson, Arizona, on March 31, 1980, with his wife and other family members at his bedside. He is buried in Oak Woods Cemetery in Chicago.
Legacy.
The dormitory used by Owens during the Olympics has been fully restored into a living museum, with pictures of his accomplishments at the Games, and a letter (intercepted by the Gestapo) from a fan urging him not to shake hands with Hitler.

</doc>
<doc id="46828" url="https://en.wikipedia.org/wiki?curid=46828" title="Fertilisation">
Fertilisation

Fertilization (also known as conception, fecundation, syngamy and impregnation) is the fusion of gametes to initiate the development of a new individual organism. In animals, the process involves the fusion of an ovum with a sperm, which first creates a zygote and then leads to the development of an embryo. Depending on the animal species, the process can occur within the body of the female in internal fertilization, or outside (external fertilization). The cycle of fertilization and development of new individuals is called sexual reproduction.
History.
In 1784, Spallanzani established the need of interaction between the female's ovum and male's semen to form a zygote. Oscar Hertwig (1876), in Germany, described the fusion of nuclei of spermatozoa and of ova from sea urchin.
Fertilization in plants.
The gametes that participate in fertilization of plants are the sperm (male), and the egg cell, and in flowering plants a second fertilization event involves another sperm cell and the central cell which is a second female gamete. In flowering plants there are two sperm from each pollen grain.
In seed plants, after pollination, a pollen grain germinates, and a pollen tube grows and penetrates the ovule through a tiny pore called a micropyle. The sperm are transferred from the pollen through the pollen tube.
Bryophytes.
Bryophyte is a traditional name used to refer to all embryophytes (land plants) that do not have true vascular tissue and are therefore called "non-vascular plants". Some bryophytes do have specialized tissues for the transport of water; however, since these do not contain lignin, they are not considered true vascular tissue.
Ferns.
A fern is a member of a group of roughly 12,000 species of vascular plants that reproduce via spores and have neither seeds nor flowers. They differ from mosses by being vascular (i.e. having water-conducting vessels). They have stems and leaves, like other vascular plants. Most ferns have what are called fiddleheads that expand into fronds, which are each delicately divided.
Gymnosperms.
The gymnosperms are a group of seed-producing plants that includes conifers, Cycads, Ginkgo, and Gnetales. The term "gymnosperm" comes from the Greek composite word γυμνόσπερμος (γυμνός gymnos, "naked" and σπέρμα sperma, "seed"), meaning "naked seeds", after the unenclosed condition of their seeds (called ovules in their unfertilized state). Their naked condition stands in contrast to the seeds and ovules of flowering plants (angiosperms), which are enclosed within an ovary. Gymnosperm seeds develop either on the surface of scales or leaves, often modified to form cones, or at the end of short stalks as in Ginkgo.
Flowering plants.
The pollen tube does not directly reach the ovary in a straight line. It travels near the skin of the style and curls to the bottom of the ovary, then near the receptacle, it breaks through the ovule through the micropyle (an opening in the ovule wall) and the pollen tube "bursts" into the embryo sac.
After being fertilised, the ovary starts to swell and develop into the fruit. With multi-seeded fruits, multiple grains of pollen are necessary for syngamy with each ovule. The growth of the pollen tube is controlled by the vegetative (or tube) cytoplasm. Hydrolytic enzymes are secreted by the pollen tube that digest the female tissue as the tube grows down the stigma and style; the digested tissue is used as a nutrient source for the pollen tube as it grows. During pollen tube growth toward the ovary, the generative nucleus divides to produce two separate sperm nuclei (haploid number of chromosomes) – a growing pollen tube therefore contains three separate nuclei, two sperm and one tube. The sperms are interconnected and dimorphic, the large one, in a number of plants, is also linked to the tube nucleus and the interconnected sperm and the tube nucleus form the "male germ unit".
Double fertilisation is the process in angiosperms (flowering plants) in which two sperm from each pollen tube fertilise two cells in a female gametophyte (sometimes called an embryo sac) that is inside an ovule. After the pollen tube enters the gametophyte, the pollen tube nucleus disintegrates and the two sperm cells are released; one of the two sperm cells "fertilises" the egg cell (at the bottom of the gametophyte near the micropyle), forming a diploid (2n) zygote. This is the point when fertilisation actually occurs; pollination and fertilisation are two separate processes. The nucleus of the other sperm cell fuses with two haploid polar nuclei (contained in the central cell) in the centre of the gametophyte. The resulting cell is triploid (3n). This triploid cell divides through mitosis and forms the endosperm, a nutrient-rich tissue, inside the seed.
The two central-cell maternal nuclei (polar nuclei) that contribute to the endosperm arise by mitosis from the single meiotic product that also gave rise to the egg. Therefore, maternal contribution to the genetic constitution of the triploid endosperm is double that of the embryo.
One primitive species of flowering plant, "Nuphar polysepala", has endosperm that is diploid, resulting from the fusion of a sperm with one, rather than two, maternal nuclei. It is believed that early in the development of angiosperm linages, there was a duplication in this mode of reproduction, producing seven-celled/eight-nucleate female gametophytes, and triploid endosperms with a 2:1 maternal to paternal genome ratio.
In many plants, the development of the flesh of the fruit is proportional to the percentage of fertilised ovules. For example, with watermelon, about a thousand grains of pollen must be delivered and spread evenly on the three lobes of the stigma to make a normal sized and shaped fruit.
Cross-fertilisation and self-fertilisation represent different strategies with differing benefits and costs. An estimated 48.7% of plant species are either dioecious or self-incompatible obligate out-crossers. It is also estimated that about 42% of flowering plants exhibit a mixed mating system in nature. 
In the most common kind of mixed mating system, individual plants produce a single type of flower and fruits may contain self-fertilised, out-crossed or a mixture of progeny types. The transition from cross-fertilisation to self-fertilisation is the most common evolutionary transition in plants, and has occurred repeatedly in many independent lineages. About 10-15% of flowering plants are predominantly self-fertilising.
Self-Pollination.
Under circumstances where pollinators and/or mates are rare, self-fertilization offers the advantage of reproductive assurance. Self-fertilization can therefore result in improved colonization ability. In some species, self-fertilization has persisted over many generations. "Capsella rubella" is a self-fertilizating species that became self-compatible 50,000 to 100,000 years ago. "Arabidopsis thaliana" is a predominantly self-fertilizing plant with an out-crossing rate in the wild of less than 0.3%; a study suggested that self-fertilization evolved roughly a million years ago or more in "A. thaliana". In long-established self-fertilizing plants, the masking of deleterious mutations and the production of genetic variability is infrequent and thus unlikely to provide a sufficient benefit over many generations to maintain the meiotic apparatus. Consequently, one might expect self-fertilization to be replaced in nature by an ameiotic asexual form of reproduction that would be less costly. However the actual persistence of meiosis and self-fertilization as a form of reproduction in long-established self-fertilizing plants may be related to the immediate benefit of efficient recombinational repair of DNA damage during formation of germ cells provided by meiosis at each generation.
Fertilization in animals.
The mechanics behind fertilisation has been studied extensively in sea urchins and mice. This research addresses the question of how the sperm and the appropriate egg find each other and the question of how only one sperm gets into the egg and delivers its contents. There are three steps to fertilisation that ensure species-specificity:
Internal vs. external.
Consideration as to whether an animal (more specifically a vertebrate) uses internal or external fertilization is often dependent on the method of birth. Oviparous animals laying eggs with thick calcium shells, such as chickens, or thick leathery shells generally reproduce via internal fertilisation so that the sperm fertilises the egg without having to pass through the thick, protective, tertiary layer of the egg. Ovoviviparous and viviparous animals also use internal fertilisation. It is important to note that although some organisms reproduce via amplexus, they may still use internal fertilisation, as with some salamanders. Advantages to internal fertilisation include: minimal waste of gametes; greater chance of individual egg fertilisation, relatively "longer" time period of egg protection, and selective fertilisation; many females have the ability to store sperm for extended periods of time and can fertilise their eggs at their own desire.
Oviparous animals producing eggs with thin tertiary membranes or no membranes at all, on the other hand, use external fertilisation methods. Advantages to external fertilisation include: minimal contact and transmission of bodily fluids; decreasing the risk of disease transmission, and greater genetic variation (especially during broadcast spawning external fertilisation methods).
Sea urchins.
Sperm find the eggs via chemotaxis, a type of ligand/receptor interaction. Resact is a 14 amino acid peptide purified from the jelly coat of "A. punctulata" that attracts the migration of sperm.
After finding the egg, the sperm penetrates the jelly coat through a process called sperm activation. In another ligand/receptor interaction, an oligosaccharide component of the egg binds and activates a receptor on the sperm and causes the acrosomal reaction. The acrosomal vesicles of the sperm fuse with the plasma membrane and are released. In this process, molecules bound to the acrosomal vesicle membrane, such as bindin, are exposed on the surface of the sperm. These contents digest the jelly coat and eventually the vitelline membrane. In addition to the release of acrosomal vesicles, there is explosive polymerisation of actin to form a thin spike at the head of the sperm called the acrosomal process.
The sperm binds to the egg through another ligand reaction between receptors on the vitelline membrane. The sperm surface protein bindin, binds to a receptor on the vitelline membrane identified as EBR1.
Fusion of the plasma membranes of the sperm and egg are likely mediated by bindin. At the site of contact, fusion causes the formation of a fertilisation cone.
Mammals.
Mammals internally fertilise through copulation. After a male ejaculates, many sperm move to the upper vagina (via contractions from the vagina) through the cervix and across the length of the uterus to meet the ovum. In cases where fertilisation occurs, the female usually ovulates during a period that extends from hours before copulation to a few days after; therefore, in most mammals it is more common for ejaculation to precede ovulation than vice versa.
The capacitated spermatozoon and the oocyte meet and interact in the "ampulla" of the fallopian tube. Thermotactic and chemotactic gradients are involved in guiding sperm towards the egg during the final stage of sperm migration. Spermatozoa respond (see Sperm thermotaxis) to the temperature gradient of ~2 °C between the oviduct and the ampulla, and chemotactic gradients of progesterone have been confirmed as the signal emanating from the cumulus oophorus cells surrounding rabbit and human oocytes. Capacitated and hyperactivated sperm respond to these gradients by changing their behaviour and moving towards the cumulus-oocyte complex. Other chemotactic signals such as formyl Met-Leu-Phe (fMLF) may also guide spermatozoa.
The zona pellucida, a thick layer of extracellular matrix that surrounds the egg and is similar to the role of the vitelline membrane in sea urchins, binds with the sperm. Unlike sea urchins, the sperm binds to the egg before the acrosomal reaction. ZP3, a glycoprotein in the zona pellucida, is responsible for egg/sperm adhesion in mice. The receptor galactosyltransferase (GalT) binds to the N-acetylglucosamine residues on the ZP3 and is important for binding with the sperm and activating the acrosome reaction. ZP3 is sufficient though unnecessary for sperm/egg binding. Two additional sperm receptors exist: a 250kD protein that binds to an oviduct secreted protein, and SED1, which independently binds to the zona. After the acrosome reaction, the sperm is believed to remain bound to the zona pellucida through exposed ZP2 receptors. These receptors are unknown in mice but have been identified in guinea pigs.
In mammals, the binding of the spermatozoon to the GalT initiates the acrosome reaction. This process releases the hyaluronidase that digests the matrix of hyaluronic acid in the vestments around the oocyte. Fusion between the oocyte plasma membranes and sperm follows and allows the sperm nucleus, centriole and flagellum, but not the mitochondria, to enter the oocyte. The protein CD9 likely mediates this fusion in mice (the binding homolog). The egg "activates" itself upon fusing with a single sperm cell and thereby changes its cell membrane to prevent fusion with other sperm. Zinc atoms are released during this activation.
This process ultimately leads to the formation of a diploid cell called a zygote. The zygote divides to form a blastocyst and, upon entering the uterus, implants in the endometrium, beginning pregnancy. Embryonic implantation not in the uterine wall results in an ectopic pregnancy that can kill the mother.
In such animals as rabbits, coitus induces ovulation by stimulating the release of the pituitary hormone gonadotropin; this release greatly increases the likelihood of pregnancy.
Humans.
The term "conception" commonly refers to fertilisation, which is the successful fusion of gametes to form a new organism. Its use 'conception' by some to refer to implantation makes it a subject of semantic arguments about the beginning of pregnancy, typically in the context of the abortion debate.
Upon gastrulation, which occurs around 16 days after fertilisation, the implanted blastocyst develops three germ layers, the endoderm, the ectoderm and the mesoderm, and the genetic code of the father becomes fully involved in the development of the embryo; later twinning is impossible. Additionally, interspecies hybrids survive only until gastrulation and cannot further develop.
However, some human developmental biology literature refers to the "conceptus" and such medical literature refers to the "products of conception" as the post-implantation embryo and its surrounding membranes. The term "conception" is not usually used in scientific literature because of its variable definition and connotation.
Insects.
Insects in different groups, including the Odonata (dragonflies and damselflies) and the Hymenoptera (ants, bees, and wasps) practise delayed fertilisation. Anong the Odonata, females may mate with multiple males, and store sperm until the eggs are laid. The male may hover above the female during egg-laying (oviposition) to prevent her from mating with other males and replacing his sperm; in some groups such as the darters, the male continues to grasp the female with his claspers during egg-laying, the pair flying around in tandem. Among social Hymenoptera, honeybee queens mate only on mating flights, in a short period lasting some days; a queen may mate with eight or more drones. She then stores the sperm for the rest of her life, perhaps for five years or more.
Fertilization in fungi.
In many fungi (except chytrids), as in some protists, the process of karyogamy, which in other groups usually follows plasmogamy forming a diploid zygote, is delayed, producing dikarya or heterokarya.
Fertilization in protists.
Fertilisation in protozoa.
There are three types of fertilisation processes in protozoa:
Fertilisation and genetic recombination.
Meiosis results in a random segregation of the genes that each parent contributes. Each parent organism is usually identical save for a fraction of their genes; each gamete is therefore genetically unique. At fertilisation, parental chromosomes combine. In humans, (2²²)² = 17.6x1012 chromosomally different zygotes are possible for the non-sex chromosomes, even assuming no chromosomal crossover. If crossover occurs once, then on average (4²²)² = 309x1024 genetically different zygotes are possible for every couple, not considering that crossover events can take place at most points along each chromosome. The X and Y chromosomes undergo no crossover events and are therefore excluded from the calculation. The mitochondrial DNA is only inherited from the maternal parent.
Parthenogenesis.
Organisms that normally reproduce sexually can also reproduce via parthenogenesis, wherein an unfertilized female gamete produces viable offspring. These offspring may be clones of the mother, or in some cases genetically differ from her but inherit only part of her DNA. Parthenogenesis occurs in many plants and animals and may be induced in others through a chemical or electrical stimulus to the egg cell. In 2004, Japanese researchers led by Tomohiro Kono succeeded after 457 attempts to merge the ova of two mice by blocking certain proteins that would normally prevent the possibility; the resulting embryo normally developed into a mouse.
Allogamy and autogamy.
Allogamy, which is also known as cross-fertilization, refers to the fertilization of an egg cell from one individual with the male gamete of another.
Autogamy which is also known as self-fertilization, occurs in such hermaphroditic organisms as plants and flatworms; therein, two gametes from one individual fuse.
Other variants of bisexual reproduction.
Some relatively unusual forms of reproduction are:
Gynogenesis: A sperm stimulates the egg to develop without fertilization or syngamy. The sperm may enter the egg.
Hybridogenesis: One genome is eliminated to produce haploid eggs.
Canina meiosis: (sometimes called "permanent odd polyploidy") one genome is transmitted in the Mendelian fashion, others are transmitted clonally.
Benefits of cross-fertilization.
The major benefit of cross-fertilisation is generally thought to be the avoidance of inbreeding depression. Charles Darwin, in his 1876 book “The Effects of Cross and Self Fertilization in the Vegetable Kingdom” (pages 466-467) summed up his findings in the following way.
“It has been shown in the present volume that the offspring from the union of two distinct individuals, especially if their progenitors have been subjected to very different conditions, have an immense advantage in height, weight, constitutional vigour and fertility over the self-fertilised offspring from one of the same parents. And this fact is amply sufficient to account for the development of the sexual elements, that is, for the genesis of the two sexes.”
In addition, it is thought by some, that a long-term advantage of out-crossing in nature is increased genetic variability that promotes adaptation and/or avoidance of extinction (see Genetic variability).

</doc>
