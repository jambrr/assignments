<doc id="45858" url="https://en.wikipedia.org/wiki?curid=45858" title="Intellectual capital">
Intellectual capital

Intellectual capital is the intangible value of a business, covering its people (human capital), the value inherent in its relationships (Relational capital), and everything that is left when the employees go home(Structural capital), of which Intellectual property (IP) is but one component. The term is used in academia in an attempt to account for the value of intangible assets not listed explicitly on a company's balance sheets. A second meaning that is used in academia and was adopted in large corporations is focused on the recycling of knowledge via Knowledge management, Intellectual capital is used in the context of assessing the wealth of organizations. A metric for the value of intellectual capital is the amount by which the enterprise value of a firm exceeds its the value of its tangible (physical and financial) assets. Directly visible on corporate books is capital embodied in its physical assets and financial capital; however all three make up the value of an enterprise. Measuring the real value and the total performance of intellectual capital's components is a critical part of running a company in the knowledge economy and Information Age. Understanding the intellectual capital in an enterprise allows leveraging of its intellectual assets. For a corporation, the result will optimize its stock price.
The IFRS (International Financial Reporting Standards) committee developed the International Accounting System 38 with the purpose of prescribing the accounting treatment for intangible assets. IAS 38.8 defines an intangible asset as an identifiable non-monetary asset without physical substance. An asset is a resource that is controlled by the entity as the result of past events (for example purchase or self-creation) and from which future economic benefits (inflows of cash or other benefits) are expected.
Classification.
Intellectual capital is normally classified as follows:
Exploitation.
For a business, translating the potential of its intellectual capital is crucial. Works that focus on the subset, namely the patents, copyrights, and trade secrets ignore the benefits of their use with the business. The term "intellectual capital" is not yet common; other terms include "intangible assets". While corporate reports often stress the value and the know-how of its staff, this crucial asset cannot be considered property. A term "Workforce-in-place" can be used as a category when companies with their staff are purchased. Without that category, most of the excess purchase price over the tangible book value would just appear as goodwill. In order to profit from intellectual capital, knowledge management has become a task for management. Often, intellectual capital, or at least rights to it, are moved off-shore for exploitation, which entails risks that are hard to value. The transfer of rights to intellectual capital to offshore subsidiaries is a major enabler of corporate tax avoidance.
Audit.
An intellectual capital audit is an audit of a company’s intellectual capital to monitor and oversee the intellectual capital of a firm in order to capitalize on intellectual capital already within the company, and to identify opportunities to increase the intellectual capital of the company.

</doc>
<doc id="45859" url="https://en.wikipedia.org/wiki?curid=45859" title="Corte, Haute-Corse">
Corte, Haute-Corse

Corte ( ; , Corsican "Corti") is a commune in the Haute-Corse department of France on the island of Corsica. It is the fourth-largest commune in Corsica (after Ajaccio, Bastia, and Porto-Vecchio).
Administration.
Corte is a subprefecture of the Haute-Corse department.
History.
Corte was the capital of the Corsican independent state during the period of Pasquale Paoli.
During World War I, German prisoners of war were kept in the Citadel.
Sights.
Sites of interest include the Fortress ("A citadella"), the Museum of Corsica ("Museu di a Corsica"), and the University of Corsica ("Università di Corsica").
Transport.
National roads lead to Ajaccio and Bastia.
Corte is also linked to Ajaccio, Bastia and Calvi by the Chemin de fer de la Corse (Corsican Railway), and is served by trains running between Ajaccio and Calvi, and Ajaccio and Bastia.
Climate.
Corte has a mediterranean climate, sometimes alpine during the winter, with 52 summer days and 56 frost days.
Education.
Corte has become a major university town in Corsica since the Pasquale Paoli University opened up again in 1980s.
Personalities.
Corte was the birthplace of Joseph Bonaparte (1768–1844), the eldest brother of the French Emperor Napoleon I, who made him King of Naples (1806–1808) and Spain (1808–1813).

</doc>
<doc id="45862" url="https://en.wikipedia.org/wiki?curid=45862" title="Raster image processor">
Raster image processor

A raster image processor (RIP) is a component used in a printing system which produces a raster image also known as a bitmap. Such a bitmap is used by a later stage of the printing system to produce the printed output. The input may be a page description in a high-level page description language such as PostScript, Portable Document Format, XPS or another bitmap of higher or lower resolution than the output device. In the latter case, the RIP applies either smoothing or interpolation algorithms to the input bitmap to generate the output bitmap.
Originally RIPs were a rack of electronic hardware which received the page description via some interface (e.g. RS-232) and generated a "hardware bitmap output" which was used to enable or disable each pixel on a real-time output device such as an optical film recorder.
A RIP can be implemented either as a software component of an operating system or as a firmware program executed on a microprocessor inside a printer, though for high-end typesetting, standalone hardware RIPs are sometimes used. Ghostscript and GhostPCL are examples of software RIPs. Every PostScript printer contains a RIP in its firmware.
Earlier RIPs retained backward compatibility with photosetters so they supported the older languages. So, for example Linotype RIPs supported CORA (RIP30).
Stages of RIP.
A RIP chip is used in laser printers to communicate raster images to a laser.

</doc>
<doc id="45864" url="https://en.wikipedia.org/wiki?curid=45864" title="Giulio Racah">
Giulio Racah

Giulio (Yoel) Racah (; February 9, 1909 – August 28, 1965) was an Italian–Israeli physicist and mathematician.
Biography.
Born in Florence, Italy, he took his degree from the University there in 1930, and later studied in Rome with Enrico Fermi. In 1937 he was appointed Professor of Physics at the University of Pisa. In 1939, due to application of Anti-Jewish laws in Italy, Racah immigrated to the British Mandate of Palestine, and was appointed Professor of Theoretical Physics at the Hebrew University of Jerusalem, where he was later Dean of the Faculty of Sciences, and finally Rector and acting President. The physics institute at the Hebrew University is named "The Racah Institute of Physics".
In the Israeli War of Independence, Racah served as deputy commander of the Israeli forces defending Mount Scopus.
Racah's research was mainly in the fields of quantum physics and atomic spectroscopy. He first devised a systematic general procedure for classifying the energy levels of open shell atoms, which remains to this day the accepted technique for practical calculations of atomic structure. This formalism was described in a monograph coauthored by his cousin Ugo Fano ("Irreducible Tensorial Sets", 1959).
Racah died at the age of 56, apparently asphyxiated by gas from a faulty heater.
Awards.
In 1958, Racah was awarded the Israel Prize in exact sciences.
See also.
The crater Racah on the Moon is named after him.

</doc>
<doc id="45866" url="https://en.wikipedia.org/wiki?curid=45866" title="Amaya">
Amaya

Amaya may refer to:

</doc>
<doc id="45868" url="https://en.wikipedia.org/wiki?curid=45868" title="National Center for Supercomputing Applications">
National Center for Supercomputing Applications

The National Center for Supercomputing Applications (NCSA) is an American state-federal partnership to develop and deploy national-scale cyberinfrastructure that advances science and engineering. NCSA operates as a unit of the University of Illinois at Urbana-Champaign, 
and provides high-performance computing resources to researchers across the country. Support for NCSA comes from the National Science Foundation,
the state of Illinois, the University of Illinois, business and industry partners, and other federal agencies.
NCSA provides leading-edge computing, data storage, and visualization resources. NCSA computational and data environment implements a multi-architecture hardware strategy, deploying both clusters and shared memory systems to support high-end users and communities on the architectures best-suited to their requirements. Nearly 1,360 scientists, engineers and students used the computing and data systems at NCSA to support research in more than 830 projects.
NCSA is led by astrophysicist Ed Seidel.
History.
NCSA is one of the five original centers in the National Science Foundation's Supercomputer Centers Program. The idea for NCSA and the four other supercomputer centers arose from the frustration of its founder, Larry Smarr, who wrote an influential paper, "The Supercomputer Famine in American Universities," in 1982, after having to travel to Europe in summertime to access American supercomputers and conduct his research. 
Larry Smarr wrote a proposal to address the future needs of scientific research. Seven other University of Illinois professors joined as co-principal investigators, and many others provided descriptions of what could be accomplished if the proposal were accepted. Known as the Black Proposal (after the color of its cover), it was submitted to the NSF in 1983. It met the NSF's mandate and its contents immediately generated excitement. However, the NSF had no organization in place to support it, and the proposal itself did not contain a clearly defined home for its implementation.
The NSF established an Office of Scientific Computing in 1984 and, with strong congressional support, it quickly announced a national competition that would fund a set of supercomputer centers like the one described in the Black Proposal. 
The result was that four supercomputer centers would be chartered (Cornell, Illinois, Princeton, and San Diego), with a fifth (Pittsburgh) added later.
The Black Proposal was approved in 1985 and marked the foundation of NCSA, with $42,751,000 in funding from 1 January 1985 through 31 December 1989. This was also noteworthy in that the NSF's action of approving an unsolicited proposal was unprecedented. NCSA opened its doors in January 1986.
In 2007, NCSA was awarded a grant from the National Science Foundation to build "Blue Waters", a supercomputer capable of performing quadrillions of calculations per second, a level of performance known as petascale.
Black Proposal.
The 'Black Proposal' was a short, ten-page proposal for the creation of a supercomputing center which eventually led to funding from the National Science Foundation (NSF) to create supercomputing centers, including the National Center for Supercomputing Applications (NCSA) at the University of Illinois. In this sense, the significant role played by the U.S. Government in funding the center, and the first widely popular web browser (NCSA's Mosaic) cannot be denied.
The Black Proposal described the limitations on any scientific research that required computer capabilities, and it described a future world of productive scientific collaboration, centered on universal computer access, where technical limitations on scientific research would not exist. Significantly, it expressed a clear vision of how to get from the present to the future. The proposal was titled "A Center for Scientific and Engineering Supercomputing", and was ten pages long.
The proposal's vision of the computing future were then unusual or non-existent, but elements of it are now commonplace, such as visualization, workstations, high-speed I/O, data storage, software engineering, and close collaboration with the multi-disciplinary user community.
Modern readers of the Black Proposal may gain insight into a world that no longer exists. Today's computers are easy to use, and the web is omnipresent. Employees in high-tech endeavors are given supercomputer accounts simply because they are employees. Computers are universally available and can be used by almost anyone of any age, applicable to almost anything.
At the time the proposal was written, computers were available to almost no one. For scientists who needed computers in their research, access was difficult if available at all. The effect on research was crippling. Reading publications from that time gives no hint that scientists were required to learn the arcane technical details of whatever computer facilities were available to them, a time-consuming limitation on their research, and an exceedingly tedious distraction from their professional interests.
The implementation of the Black Proposal had a primary role in shaping the computer technology of today, and its impact on research (both scientific and otherwise) has been profound. The proposal's description of the leading edge of scientific research may be sobering, and the limitations on computer usage at major universities may be surprising. A comprehensive list of the world's supercomputers shows the best resources that were then available. The thrust of the proposal may seem obvious now, but was then novel.
The National Science Foundation announced funding for the supercomputer centers in 1985; 
the first supercomputer at NCSA came online in January 1986.
NCSA quickly came to the attention of the worldwide scientific community with the release of NCSA Telnet in 1986. A number of other tools followed, and like NCSA Telnet, all were made available to everyone at no cost. In 1993, NCSA released the Mosaic web browser, the first popular graphical Web browser, which played an important part in expanding the growth of the World Wide Web. NCSA Mosaic was written by Marc Andreessen and Eric Bina, who went on to develop the Netscape Web browser. Mosaic was later licensed to Spyglass, Inc. which provided the foundation for Internet Explorer. The server-complement was called NCSA HTTPd, which later became known as Apache HTTP Server.
Other notable contributions by NCSA were the black hole simulations supporting the development of LIGO in 1992, the tracking of the Hale-Bopp Comet in 1997, and the creation of a PlayStation 2 Cluster in 2003.
Facilities.
Initially, NCSA's administrative offices were in the Water Resources Building and employees were scattered across the campus. NCSA is now headquartered within its own building directly north of the Siebel Center for Computer Science, on the site of a former baseball field, Illini Field. NCSA's supercomputers are at the National Petascale Computing Facility.
Movies/Visualization.
NCSA's visualization department is internationally well-known. Donna Cox, leader of the Advanced Visualization Laboratory at NCSA and a professor in the School of Art and Design at the University of Illinois at Urbana-Champaign, and her team created thrilling visualizations for the Oscar-nominated IMAX film "Cosmic Voyage," the PBS NOVA episodes "Hunt for the Supertwister" and "Runaway Universe," as well as Discovery Channel documentaries and pieces for CNN and NBC Nightly News. Cox and NCSA worked with the American Museum of Natural History to produce high-resolution visualizations for the Hayden Planetarium's 2000 Millennium show, "Passport to the Universe," and for "The Search for Life: Are We Alone?" She produced visualizations for the Hayden's "Big Bang Theatre" and worked with the Denver Museum of Nature and Science to produce high-resolution data-driven visualizations of terabytes of scientific data for "Black Holes: The Other Side of Infinity," a digital dome program on black holes.
Private Business Partners.
Referred to as the Industrial Partners program when it began in 1986, NCSA's collaboration with major corporations ensured that its expertise and emerging technologies would be relevant to major challenges outside of the academic world, as those challenges arose. Business partners had no control over research or the disposition of its results, but they were well-situated to be early adopters of any benefits of the research. The program is now called the Private Sector Program.
Past and current business partners include:

</doc>
<doc id="45870" url="https://en.wikipedia.org/wiki?curid=45870" title="Ladin language">
Ladin language

Ladin ( or ; , , ) is a Romance language consisting of a group of dialects (which some consider part of a unitary Rhaeto-Romance language) mainly spoken in the Dolomite Mountains in Northern Italy in South Tyrol, the Trentino and the province of Belluno by the Ladin people. It exhibits similarities to Swiss Romansh and Friulian.
The precise extension of the Ladin language area is the subject of scholarly debates. A more narrow perspective includes only the dialects of the valleys around the Sella group, wider definitions comprise the dialects of adjacent valleys in the Province of Belluno and even dialects spoken in the northwestern Trentino.
A standard written variety of Ladin ("Ladin Dolomitan") has been developed by the Office for Ladin Language Planning as a common communication tool across the whole Ladin-speaking region, but it is not popular among Ladin speakers.
Ladin should not be confused with Ladino (also called Judeo-Spanish), which, although also Romance, is derived from Old Spanish.
Geographic distribution.
Ladin is recognized as a minority language in 54 Italian municipalities belonging to the provinces of South Tyrol, Trentino and Belluno. It is not possible to assess the exact number of Ladin speakers, because only in the provinces of South Tyrol and Trentino are the inhabitants asked to identify their native language in the general census of the population, which takes place every ten years.
South Tyrol.
In the 2011 census, 20,548 inhabitants of South Tyrol declared Ladin as their native language. Ladin is an officially recognised language, taught in schools and used in public offices (in written as well as spoken form). The following municipalities of South Tyrol have a majority of Ladin speakers:
Trentino.
In the 2011 census, 18,550 inhabitants of Trentino declared Ladin as their native language. It is prevailing in the following municipalities of Trentino in the Fassa Valley, where Ladin is recognized as a minority language:
The Nones language in the Non Valley and the related Solandro language found in the Sole Valley are Gallo-Romance languages and often grouped together into a single linguistic unit due to their similarity. They are spoken in 38 municipalities, but have no official status. Their more precise classification is uncertain. Both dialects show a strong resemblance to Trentinian dialect and Eastern Lombard, and scholars debate whether they are Ladin dialects or not.
About 23% of the inhabitants from Val di Non and 1.5% from Val di Sole declared Ladin as their native language at the 2011 census. The number of Ladin speakers in those valleys amounts to 8,730, outnumbering the native speakers in the Fassa Valley. In order to stress the difference between the dialects in Non and Fassa valleys, it has been proposed to distinguish between "ladins dolomitiches" (Dolomitic Ladinians) and "ladins nonejes" (Non Valley Ladinians) at the next census.
Belluno.
As there is no linguistic census in Belluno, the number of Ladin speakers can only be estimated. Around 3000 speakers are estimated to live in the part of the province of Belluno that used to be a part of the County of Tyrol until 1918: Cortina d'Ampezzo, Colle Santa Lucia, Livinallongo del Col di Lana.
Provincial administration of Belluno has enacted to identify Ladin as a minority language in additional municipalities. Those are: Agordo, Alleghe, Auronzo di Cadore, Borca di Cadore, Calalzo di Cadore, Canale d'Agordo, Cencenighe Agordino, Cibiana di Cadore, Comelico Superiore, Danta di Cadore, Domegge di Cadore, Falcade, Forno di Zoldo, Gosaldo, La Valle Agordina, Lozzo di Cadore, Ospitale di Cadore, Perarolo di Cadore, Pieve di Cadore, Rivamonte Agordino, Rocca Pietore, San Nicolò di Comelico, San Pietro di Cadore, San Tomaso Agordino, San Vito di Cadore, Santo Stefano di Cadore, Selva di Cadore, Taibon Agordino, Vallada Agordina, Valle di Cadore, Vigo di Cadore, Vodo di Cadore, Voltago Agordino, Zoldo Alto, Zoppè di Cadore. Ladinity in the province of Belluno is more ethnic than linguistic. The varieties spoken by Ladin municipalities are Venetian alpine dialects, grammatically no different to those spoken in municipalities that did not declare themselves as Ladin. Their language is called "Ladino Bellunese".
All Ladin dialects spoken in Belluno, including those in the former Tyrolean territories, enjoy a varying degree of influence by Venetian.
History.
The name derives from Latin, because Ladin is originally a vulgar Latin language left over from the Romanized Alps. Ladin is often attributed to be a relic of vulgar Latin dialects associated with Rhaeto-Romance languages. Whether a proto-Romance language ever existed is controversially discussed amongst linguists and historians, a debate known as "Questione Ladina". Starting in the 6th century, the Bavarii started moving in from the north, while from the south Gallo-Italic languages started pushing in, which further shrank the original extent of the Ladin area. Only in the more remote mountain valleys did Ladin survive among the isolated populations.
Starting in the very early Middle Ages, the area was mostly ruled by the County of Tyrol or the Bishopric of Brixen, both belonging to the realms of the Austrian Habsburg rulers. The area of Cadore was under the rule of the Republic of Venice. During the period of the Holy Roman Empire of the German Nation and, after 1804, the Austrian Empire, the Ladins underwent a process of Germanization.
After the end of World War I in 1918, Italy annexed the southern part of Tyrol, including the Ladin areas. The Italian nationalist movement of the 19th and 20th centuries regarded Ladin as an "Italian dialect", a notion rejected by various Ladin exponents and associations, despite their having been counted as Italians by the Austrian authorities as well. The programme of Italianization, professed by fascists such as Ettore Tolomei and Benito Mussolini, added further pressure on the Ladin communities to subordinate their identities to Italian. This included changing Ladin place names into the Italian pronunciation according to Tolomei's "Prontuario dei nomi locali dell'Alto Adige".
Following the end of World War II, the Gruber-De Gasperi Agreement of 1946 between Austria and Italy introduced a level of autonomy for Trentino and South Tyrol, but did not include any provisions for the Ladin language. Only in the second autonomy statute for South Tyrol in 1972 was Ladin recognized as a partially official language.
Status.
Ladin is officially recognised in Trentino and South Tyrol by provincial and national law. Italy signed the European Charter for Regional or Minority Languages of 1991, but has not ratified it so far. The charter calls for minority rights to be respected and minority languages, to which Ladin belongs, to be appropriately protected and promoted. Starting in the 1990s, the Italian parliament and provincial assembly have passed laws and regulations protecting the Ladin language and culture. A cultural institute was founded to safeguard and educate in the language and culture. School curricula were adapted in order to teach in Ladin, and street signs are being changed to bilingual.
Ladin is recognized as a protected language also in the Province of Belluno in Veneto region pursuant to the Standards for Protection of Historic Language Minorities Act No. 482 (1999). In comparison with South Tyrol and Trentino, the wishes of the Ladins have barely been addressed by the regional government. In a popular referendum in October 2007, the inhabitants of Cortina d'Ampezzo overwhelmingly voted to leave Veneto and return to South Tyrol. The redrawing of the provincial borders would return Cortina d'Ampezzo, Livinallongo del Col di Lana and Colle Santa Lucia to South Tyrol, to which they traditionally belonged when part of the County of Tyrol or the Bishopric of Brixen.
Although the Ladin communities are spread out over three neighbouring regions, the "Union Generala di Ladins dles Dolomites" is asking that they be reunited. The Ladin Autonomist Union and the Fassa Association run on a Ladin list and have sought more rights and autonomy for Ladin speakers. Ladins are also guaranteed political representations in the assemblies of Trentino and South Tyrol due to a reserved seats system.
In South Tyrol, in order to reach a fair allocation of jobs in public service, a system called "ethnic proportion" was established in the 1970s. Every ten years, when the general census of population takes place, each citizen has to identify with a linguistic group. The results determine how many potential positions in public service are allocated for each linguistic group. This has theoretically enabled Ladins to receive guaranteed representation in the South Tyrolean civil service according to their numbers.
The recognition of minority languages in Italy has been criticised since the implementation of Act No. 482 (1999), especially due to alleged financial benefits. This applies also to Ladin language, especially in the province of Belluno.
Subdivisions.
A possible subdivision of Ladin language identifies six major groups.
Athesian Group of the Sella.
The dialects of the Athesian group (from the river Adige Basin) of the Sella are spoken in South Tyrol:
The South Tyrolean dialects are the ones which preserverd the original Ladin characteristics better than all others.
Trentinian Group of the Sella.
The names of the Ladin dialects spoken in the Fassa Valley in Trentino are Moenat, Brach, and Cazet. 82,8% of the inhabitants of Fassa Valley are natively Ladin speaking; the Ladin language in Fassa is influenced by Trentinian dialects.
Agordino Group of the Sella.
In the Province of Belluno the following dialects are considered as part of the Agordino group:
Ampezzan Group.
Spoken in Cortina d'Ampezzo ("Anpezo"), similar to Cadorino dialect.
Even in Valle di Zoldo (from Forno-Fôr upwards) there are elements of the Ampezzan Group.
Cadorino Group.
Spoken in Cadore and Comelico and best known as Cadorino dialect.
Nones and Solandro Group.
In Western Trentino, in Non Valley, Val di Sole, Val di Peio, Val di Rabbi and part of Val Rendena, detached from the dolomitic area, dialects are spoken that are often considered as Ladin language (Anaunic Ladin), but enjoy strong influences from Trentinian an Eastern Lombard dialects.
Sample texts.
Lord's Prayer.
The first part of the 'Lord's Prayer' in Standard Ladin, Latin and Italian for comparison:
Phonology of Standard Ladin.
The vowel, spelled , as in "Urtijëi" (), occurs in some local dialects but is not a part of Standard Ladin.

</doc>
<doc id="45871" url="https://en.wikipedia.org/wiki?curid=45871" title="Loudspeaker">
Loudspeaker

A loudspeaker (or loud-speaker or speaker) is a device containing one or more electroacoustic transducers; which convert an electrical audio signal into a corresponding sound. The first primitive loudspeakers were invented during the development of telephone systems in the late 1800s, but electronic amplification by vacuum tube beginning around 1912 made loudspeakers truly practical. By the 1920s they were used in radios, phonographs, public address systems and theatre sound systems for talking motion pictures.
The most widely used type of speaker today is the dynamic speaker, invented in 1925 by Edward W. Kellogg and Chester W. Rice. The dynamic speaker operates on the same basic principle as a dynamic microphone, but in reverse, to produce sound from an electrical signal. When an alternating current electrical audio signal is applied to its voice coil, a coil of wire suspended in a circular gap between the poles of a permanent magnet, the coil is forced to move rapidly back and forth due to Faraday's law of induction, which causes a diaphragm (usually conically shaped) attached to the coil to move back and forth, pushing on the air to create sound waves. Besides this most common method, there are several alternative technologies that can be used to convert an electrical signal into sound. The sound source (e.g., a sound recording or a microphone) must be amplified with an amplifier before the signal is sent to the speaker.
Speakers are typically housed in an enclosure which is often a rectangular or square box made of wood or sometimes plastic, and the enclosure plays an important role in the quality of the sound. Where high fidelity reproduction of sound is required, multiple loudspeaker transducers are often mounted in the same enclosure, each reproducing a part of the audible frequency range "(picture at right)". In this case the individual speakers are referred to as "drivers" and the entire unit is called a loudspeaker. Drivers made for reproducing high audio frequencies are called tweeters, those for middle frequencies are called mid-range drivers, and those for low frequencies are called woofers. Smaller loudspeakers are found in devices such as radios, televisions, portable audio players, computers, and electronic musical instruments . Larger loudspeaker systems are used for music, sound reinforcement in theatres and concerts, and in public address systems.
Terminology.
The term "loudspeaker" may refer to individual transducers (known as "drivers") or to complete speaker systems consisting of an enclosure including one or more drivers.
To adequately reproduce a wide range of frequencies with even coverage, most loudspeaker systems employ more than one driver, particularly for higher sound pressure level or maximum accuracy. Individual drivers are used to reproduce different frequency ranges. The drivers are named subwoofers (for very low frequencies); woofers (low frequencies); mid-range speakers (middle frequencies); tweeters (high frequencies); and sometimes supertweeters, optimized for the highest audible frequencies. The terms for different speaker drivers differ, depending on the application. In two-way systems there is no mid-range driver, so the task of reproducing the mid-range sounds falls upon the woofer and tweeter. Home stereos use the designation "tweeter" for the high frequency driver, while professional concert systems may designate them as "HF" or "highs". When multiple drivers are used in a system, a "filter network", called a crossover, separates the incoming signal into different frequency ranges and routes them to the appropriate driver. A loudspeaker system with "n" separate frequency bands is described as ""n"-way speakers": a two-way system will have a woofer and a tweeter; a three-way system employs a woofer, a mid-range, and a tweeter. Loudspeakers were described as "dynamic" to distinguish them from the earlier moving iron speaker, or speakers using piezoelectric or electrostatic systems as opposed to a voice coil that moves through a steady magnetic field.
History.
Johann Philipp Reis installed an electric loudspeaker in his "telephone" in 1861; it was capable of reproducing clear tones, but also could reproduce muffled speech after a few revisions. Alexander Graham Bell patented his first electric loudspeaker (capable of reproducing intelligible speech) as part of his telephone in 1876, which was followed in 1877 by an improved version from Ernst Siemens. During this time, Thomas Edison was issued a British patent for a system using compressed air as an amplifying mechanism for his early cylinder phonographs, but he ultimately settled for the familiar metal horn driven by a membrane attached to the stylus. In 1898, Horace Short patented a design for a loudspeaker driven by compressed air; he then sold the rights to Charles Parsons, who was issued several additional British patents before 1910. A few companies, including the Victor Talking Machine Company and Pathé, produced record players using compressed-air loudspeakers. However, these designs were significantly limited by their poor sound quality and their inability to reproduce sound at low volume. Variants of the system were used for public address applications, and more recently, other variations have been used to test space-equipment resistance to the very loud sound and vibration levels that the launching of rockets produces.
The first experimental moving-coil (also called "dynamic") loudspeaker was invented by Oliver Lodge in 1898. The first practical moving-coil loudspeakers were manufactured by Danish engineer Peter L. Jensen and Edwin Pridham in 1915, in Napa, California. Like previous loudspeakers these used horns to amplify the sound produced by a small diaphragm. Jensen was denied patents. Being unsuccessful in selling their product to telephone companies, in 1915 they changed their target market to radios and public address systems, and named their product Magnavox. Jensen was, for years after the invention of the loudspeaker, a part owner of The Magnavox Company.
The moving-coil principle commonly used today in speakers was patented in 1924 by Chester W. Rice and Edward W. Kellogg. The key difference between previous attempts and the patent by Rice and Kellogg is the adjustment of mechanical parameters so that the fundamental resonance of the moving system is below the frequency where the cone's radiation impedance becomes uniform.
About this same period, Walter H. Schottky invented the first ribbon loudspeaker together with Dr. Erwin Gerlach.
These first loudspeakers used electromagnets, because large, powerful permanent magnets were generally not available at a reasonable price. The coil of an electromagnet, called a field coil, was energized by current through a second pair of connections to the driver. This winding usually served a dual role, acting also as a choke coil, filtering the power supply of the amplifier that the loudspeaker was connected to. AC ripple in the current was attenuated by the action of passing through the choke coil. However, AC line frequencies tended to modulate the audio signal going to the voice coil and added to the audible hum. In 1930 Jensen introduced the first commercial fixed-magnet loudspeaker; however, the large, heavy iron magnets of the day were impractical and field-coil speakers remained predominant until the widespread availability of lightweight Alnico magnets after World War II.
In the 1930s, loudspeaker manufacturers began to combine two and three bandpasses' worth of drivers in order to increase frequency response and sound pressure level. In 1937, the first film industry-standard loudspeaker system, "The Shearer Horn System for Theatres" (a two-way system), was introduced by Metro-Goldwyn-Mayer. It used four 15″ low-frequency drivers, a crossover network set for 375 Hz, and a single multi-cellular horn with two compression drivers providing the high frequencies. John Kenneth Hilliard, James Bullough Lansing, and Douglas Shearer all played roles in creating the system. At the 1939 New York World's Fair, a very large two-way public address system was mounted on a tower at Flushing Meadows. The eight 27″ low-frequency drivers were designed by Rudy Bozak in his role as chief engineer for Cinaudagraph. High-frequency drivers were likely made by Western Electric.
Altec Lansing introduced the "604", which became their most famous coaxial Duplex driver, in 1943. It incorporated a high-frequency horn that sent sound through the middle of a 15-inch woofer for near-point-source performance. Altec's "Voice of the Theatre" loudspeaker system arrived in the marketplace in 1945, offering better coherence and clarity at the high output levels necessary in movie theaters. The Academy of Motion Picture Arts and Sciences immediately began testing its sonic characteristics; they made it the film house industry standard in 1955. In 1954, Edgar Villchur developed the acoustic suspension principle of loudspeaker design in Cambridge, Massachusetts. This allowed for better bass response from loudspeakers mounted in smaller cabinets. He and his partner Henry Kloss formed the Acoustic Research company to manufacture and market speaker systems using this principle. Subsequently, continuous developments in enclosure design and materials led to significant audible improvements. The most notable improvements in modern speakers are improvements in cone materials, the introduction of higher-temperature adhesives, improved permanent magnet materials, improved measurement techniques, computer-aided design, and finite element analysis.
Driver design - Dynamic loudspeakers.
The most common type of driver, commonly called a dynamic loudspeaker, uses a lightweight diaphragm, or "cone", connected to a rigid "basket", or "frame", via a flexible suspension, commonly called a "spider", that constrains a voice coil to move axially through a cylindrical magnetic gap. When an electrical signal is applied to the voice coil, a magnetic field is created by the electric current in the voice coil, making it a variable electromagnet. The coil and the driver's magnetic system interact, generating a mechanical force that causes the coil (and thus, the attached cone) to move back and forth, thereby reproducing sound under the control of the applied electrical signal coming from the amplifier. The following is a description of the individual components of this type of loudspeaker.
The diaphragm is usually manufactured with a cone- or dome-shaped profile. A variety of different materials may be used, but the most common are paper, plastic, and metal. The ideal material would 1) be rigid, to prevent uncontrolled cone motions; 2) have low mass, to minimize starting force requirements and energy storage issues; 3) be well damped, to reduce vibrations continuing after the signal has stopped with little or no audible ringing due to its resonance frequency as determined by its usage. In practice, all three of these criteria cannot be met simultaneously using existing materials; thus, driver design involves trade-offs. For example, paper is light and typically well damped, but is not stiff; metal may be stiff and light, but it usually has poor damping; plastic can be light, but typically, the stiffer it is made, the poorer the damping. As a result, many cones are made of some sort of composite material. For example, a cone might be made of cellulose paper, into which some carbon fiber, Kevlar, glass, hemp or bamboo fibers have been added; or it might use a honeycomb sandwich construction; or a coating might be applied to it so as to provide additional stiffening or damping.
The chassis, frame, or basket, is designed to be rigid, avoiding deformation that could change critical alignments with the magnet gap, perhaps causing the voice coil to rub against the sides of the gap. Chassis are typically cast from aluminum alloy, or stamped from thin steel sheet, though in some drivers with large magnets cast chassis are preferable seeing as sheet metal can easily be warped in whenever the loudspeaker is subjected to rough handling. Other materials such as molded plastic and damped plastic compound baskets are becoming common, especially for inexpensive, low-mass drivers. Metallic chassis can play an important role in conducting heat away from the voice coil; heating during operation changes resistance, causes physical dimensional changes, and if extreme, may even demagnetize permanent magnets.
The suspension system keeps the coil centered in the gap and provides a restoring (centering) force that returns the cone to a neutral position after moving. A typical suspension system consists of two parts: the "spider", which connects the diaphragm or voice coil to the frame and provides the majority of the restoring force, and the "surround", which helps center the coil/cone assembly and allows free pistonic motion aligned with the magnetic gap. The spider is usually made of a corrugated fabric disk, impregnated with a stiffening resin. The name comes from the shape of early suspensions, which were two concentric rings of Bakelite material, joined by six or eight curved "legs." Variations of this topology included the addition of a felt disc to provide a barrier to particles that might otherwise cause the voice coil to rub. The German firm Rulik still offers drivers with uncommon spiders made of wood.
The cone surround can be rubber or polyester foam, or a ring of corrugated, resin coated fabric; it is attached to both the outer diaphragm circumference and to the frame. These different surround materials, their shape and treatment can dramatically affect the acoustic output of a driver; each class and implementation having advantages and disadvantages. Polyester foam, for example, is lightweight and economical, but is degraded by exposure to ozone, UV light, humidity and elevated temperatures, limiting its useful life to about 15 years.
The wire in a voice coil is usually made of copper, though aluminum—and, rarely, silver—may be used. The advantage of aluminum is its light weight, which raises the resonant frequency of the voice coil and allows it to respond more easily to higher frequencies. A disadvantage of aluminum is that it is not easily soldered, and so connections are instead often crimped together and sealed. These connections can corrode and fail in time. Voice-coil wire cross sections can be circular, rectangular, or hexagonal, giving varying amounts of wire volume coverage in the magnetic gap space. The coil is oriented co-axially inside the gap; it moves back and forth within a small circular volume (a hole, slot, or groove) in the magnetic structure. The gap establishes a concentrated magnetic field between the two poles of a permanent magnet; the outside of the gap being one pole, and the center post (called the pole piece) being the other. The pole piece and backplate are often a single piece, called the poleplate or yoke.
Modern driver magnets are almost always permanent and made of ceramic, ferrite, Alnico, or, more recently, rare earth such as neodymium and samarium cobalt. A trend in design—due to increases in transportation costs and a desire for smaller, lighter devices (as in many home theater multi-speaker installations)—is the use of the last instead of heavier ferrite types. Very few manufacturers still produce electrodynamic loudspeakers with electrically powered field coils, as was common in the earliest designs. When high field-strength permanent magnets became available, Alnico, an alloy of aluminum, nickel, and cobalt became popular, since it dispensed with the power supply problems of field-coil drivers. Alnico was used almost exclusively until about 1980. Alnico magnets can be partially degaussed (i.e., demagnetized) by accidental 'pops' or 'clicks' caused by loose connections, especially if used with a high power amplifier. This damage can be reversed by "recharging" the magnet.
After 1980, most (but not quite all) driver manufacturers switched from Alnico to ferrite magnets, which are made from a mix of ceramic clay and fine particles of barium or strontium ferrite. Although the energy per kilogram of these ceramic magnets is lower than Alnico, it is substantially less expensive, allowing designers to use larger yet more economical magnets to achieve a given performance.
The size and type of magnet and details of the magnetic circuit differ, depending on design goals. For instance, the shape of the pole piece affects the magnetic interaction between the voice coil and the magnetic field, and is sometimes used to modify a driver's behavior. A "shorting ring", or Faraday loop, may be included as a thin copper cap fitted over the pole tip or as a heavy ring situated within the magnet-pole cavity. The benefits of this complication is reduced impedance at high frequencies, providing extended treble output, reduced harmonic distortion, and a reduction in the inductance modulation that typically accompanies large voice coil excursions. On the other hand, the copper cap requires a wider voice-coil gap, with increased magnetic reluctance; this reduces available flux, requiring a larger magnet for equivalent performance.
Driver design—including the particular way two or more drivers are combined in an enclosure to make a speaker system—is both an art and science. Adjusting a design to improve performance is done using some combination of magnetic, acoustic, mechanical, electrical, and material science theory, and tracked with high precision measurements, and with the observations of experienced listeners. A few of the issues speaker and driver designers must confront are distortion, radiation lobing, phase effects, off-axis response, and crossover artifacts. Designers can use an anechoic chamber to ensure the speaker can be measured independently of room effects, or any of several electronic techniques that, to some extent, substitute for such chambers. Some developers eschew anechoic chambers in favor of specific standardized room setups intended to simulate real-life listening conditions.
Fabrication of finished loudspeaker systems has become segmented, depending largely on price, shipping costs, and weight limitations. High-end speaker systems, which are typically heavier (and often larger) than economic shipping allows outside local regions, are usually made in their target market region and can cost $140,000 or more per pair. Economical mass market speaker systems and drivers may be manufactured in China or other low-cost manufacturing locations.
Driver types.
Individual electrodynamic drivers provide optimal performance within a limited frequency range. Multiple drivers (e.g., subwoofers, woofers, mid-range drivers, and tweeters) are generally combined into a complete loudspeaker system to provide performance beyond that constraint.
The three most commonly used sound radiation systems are the cone, dome and horn type drivers.
Full-range drivers.
A full-range driver is a speaker designed to be used alone to reproduce an audio channel without the help of other drivers, and therefore must cover the entire audio frequency range. These drivers are small, typically in diameter to permit reasonable high frequency response, and carefully designed to give low-distortion output at low frequencies, though with reduced maximum output level. Full-range (or more accurately, wide-range) drivers are most commonly heard in public address systems, in televisions (although some models are suitable for hi-fi listening), small radios, intercoms, some computer speakers, etc. In hi-fi speaker systems, the use of wide-range drive units can avoid undesirable interactions between multiple drivers caused by non-coincident driver location or crossover network issues. Fans of wide-range driver hi-fi speaker systems claim a coherence of sound due to the single source and a resulting lack of interference, and likely also to the lack of crossover components. Detractors typically cite wide-range drivers' limited frequency response and modest output abilities (most especially at low frequencies), together with their requirement for large, elaborate, expensive enclosures—such as transmission lines, quarter wave resonators or horns—to approach optimum performance. With the advent of neodymium drivers, low cost quarter wave transmission lines are made possible and are increasingly made availably commercially.
Full-range drivers often employ an additional cone called a "whizzer": a small, light cone attached to the joint between the voice coil and the primary cone. The whizzer cone extends the high-frequency response of the driver and broadens its high frequency directivity, which would otherwise be greatly narrowed due to the outer diameter cone material failing to keep up with the central voice coil at higher frequencies. The main cone in a whizzer design is manufactured so as to flex more in the outer diameter than in the center. The result is that the main cone delivers low frequencies and the whizzer cone contributes most of the higher frequencies. Since the whizzer cone is smaller than the main diaphragm, output dispersion at high frequencies is improved relative to an equivalent single larger diaphragm.
Limited-range drivers, also used alone, are typically found in computers, toys, and clock radios. These drivers are less elaborate and less expensive than wide-range drivers, and they may be severely compromised to fit into very small mounting locations. In these applications, sound quality is a low priority. The human ear is remarkably tolerant of poor sound quality, and the distortion inherent in limited-range drivers may enhance their output at high frequencies, increasing clarity when listening to spoken word material.
Subwoofer.
A subwoofer is a woofer driver used only for the lowest part of the audio spectrum: typically below 200 Hz for consumer systems, below 100 Hz for professional live sound, and below 80 Hz in THX-approved systems. Because the intended range of frequencies is limited, subwoofer system design is usually simpler in many respects than for conventional loudspeakers, often consisting of a single driver enclosed in a suitable box or enclosure. Since sound in this frequency range can easily bend around corners by diffraction, the speaker aperture does not have to face the audience, and subwoofers can be mounted in the bottom of the enclosure, facing the floor.
To accurately reproduce very low bass notes without unwanted resonances (typically from cabinet panels), subwoofer systems must be solidly constructed and properly braced; good speakers are typically quite heavy. Many subwoofer systems include power amplifiers and electronic subsonic (sub)-filters, with additional controls relevant to low-frequency reproduction. These variants are known as "active" or "powered" subwoofers. In contrast, "passive" subwoofers require external amplification. In typical installations, subwoofers are physically separated from the rest of the transducers. Because of propagation delay, their output is slightly out of phase with the rest of the sound. Consequently, a subwoofer's power amp should have a phase-delay adjustment (approximately 1 ms of delay is required for each additional foot of separation from the listener).
Woofer.
A woofer is a driver that reproduces low frequencies. The driver combines with the enclosure design to produce suitable low frequencies (see speaker enclosure for the design choices available). Some loudspeaker systems use a woofer for the lowest frequencies, sometimes well enough that a subwoofer is not needed. Additionally, some loudspeakers use the woofer to handle middle frequencies, eliminating the mid-range driver. This can be accomplished with the selection of a tweeter that can work low enough that, combined with a woofer that responds high enough, the two drivers add coherently in the middle frequencies.
Mid-range driver.
A mid-range speaker is a loudspeaker driver that reproduces middle frequencies. Mid-range driver diaphragms can be made of paper or composite materials, and can be direct radiation drivers (rather like smaller woofers) or they can be compression drivers (rather like some tweeter designs). If the mid-range driver is a direct radiator, it can be mounted on the front baffle of a loudspeaker enclosure, or, if a compression driver, mounted at the throat of a horn for added output level and control of radiation pattern.
Tweeter.
A tweeter is a high-frequency driver that reproduces the highest frequencies in a speaker system. A major problem in tweeter design is achieving wide angular sound coverage (off-axis response), since high frequency sound tends to leave the speaker in narrow beams. Soft-dome tweeters are widely found in home stereo systems, and horn-loaded compression drivers are common in professional sound reinforcement. Ribbon tweeters have gained popularity in recent years, as their output power has been increased to levels useful for professional sound reinforcement, and their output pattern is wide in the horizontal plane, a pattern that has convenient applications in concert sound.
Coaxial drivers.
A coaxial driver is a loudspeaker driver with two or several combined concentric drivers. Coaxial drivers have been produced by many companies, such as Altec, Tannoy, Pioneer, KEF, SEAS, B&C Speakers, BMS, Cabasse and Genelec.
Loudspeaker system design.
Crossover.
Crossovers can be "passive" or "active". A passive crossover is an electronic circuit that uses a combination of one or more resistors, inductors, or non-polar capacitors. These parts are formed into carefully designed networks and are most often placed between the full frequency-range power amplifier and the loudspeaker drivers to divide the amplifier's signal into the necessary frequency bands before being delivered to the individual drivers. Passive crossover circuits need no external power beyond the audio signal itself, but have disadvantages: high cost, large components (inductors and capacitors), limited ability to adjust the circuit as desired due to limited choice of high power level components, etc. They also cause substantial overall signal loss and a significant reduction in damping factor between the voice coil and the crossover. An active crossover is an electronic filter circuit that divides the signal into individual frequency bands "before" power amplification, thus requiring at least one power amplifier for each bandpass. Passive filtering may also be used in this way before power amplification, but it is an uncommon solution, being less flexible than active filtering. Any technique that uses crossover filtering followed by amplification is commonly known as bi-amping, tri-amping, quad-amping, and so on, depending on the minimum number of amplifier channels. Some loudspeaker designs use a combination of passive and active crossover filtering, such as a passive crossover between the mid- and high-frequency drivers and an active crossover between the low-frequency driver and the combined mid- and high frequencies.
Passive crossovers are commonly installed inside speaker boxes and are by far the most usual type of crossover for home and low-power use. In car audio systems, passive crossovers may be in a separate box, necessary to accommodate the size of the components used. Passive crossovers may be simple for low-order filtering, or complex to allow steep slopes such as 18 or 24 dB per octave. Passive crossovers can also be designed to compensate for undesired characteristics of driver, horn, or enclosure resonances, and can be tricky to implement, due to component interaction. Passive crossovers, like the driver units that they feed, have power handling limits, have insertion losses (10% is often claimed), and change the load seen by the amplifier. The changes are matters of concern for many in the hi-fi world. When high output levels are required, active crossovers may be preferable. Active crossovers may be simple circuits that emulate the response of a passive network, or may be more complex, allowing extensive audio adjustments. Some active crossovers, usually digital loudspeaker management systems, may include facilities for precise alignment of phase and time between frequency bands, equalization, and dynamics (compression and limiting) control.
Some hi-fi and professional loudspeaker systems now include an active crossover circuit as part of an onboard amplifier system. These speaker designs are identifiable by their need for AC power in addition to a signal cable from a pre-amplifier. This active topology may include driver protection circuits and other features of a digital loudspeaker management system. Powered speaker systems are common in computer sound (for a single listener) and, at the other end of the size spectrum, in modern concert sound systems, where their presence is significant and steadily increasing.
Enclosures.
Most loudspeaker systems consist of drivers mounted in an enclosure, or cabinet. The role of the enclosure is to prevent sound waves emanating from the back of a driver from interfering destructively with those from the front. The sound waves emitted from the back are 180° out of phase with those emitted forward, so without an enclosure they typically cause cancellations which significantly degrade the level and quality of sound at low frequencies.
The simplest driver mount is a flat panel (i.e., baffle) with the drivers mounted in holes in it. However, in this approach, sound frequencies with a wavelength longer than the baffle dimensions are canceled out, because the antiphase radiation from the rear of the cone interferes with the radiation from the front. With an infinitely large panel, this interference could be entirely prevented. A sufficiently large sealed box can approach this behavior.
Since panels of infinite dimensions are impossible, most enclosures function by containing the rear radiation from the moving diaphragm. A sealed enclosure prevents transmission of the sound emitted from the rear of the loudspeaker by confining the sound in a rigid and airtight box. Techniques used to reduce transmission of sound through the walls of the cabinet include thicker cabinet walls, lossy wall material, internal bracing, curved cabinet walls—or more rarely, visco-elastic materials (e.g., mineral-loaded bitumen) or thin lead sheeting applied to the interior enclosure walls.
However, a rigid enclosure reflects sound internally, which can then be transmitted back through the loudspeaker diaphragm—again resulting in degradation of sound quality. This can be reduced by internal absorption using absorptive materials (often called "damping"), such as glass wool, wool, or synthetic fiber batting, within the enclosure. The internal shape of the enclosure can also be designed to reduce this by reflecting sounds away from the loudspeaker diaphragm, where they may then be absorbed.
Other enclosure types alter the rear sound radiation so it can add constructively to the output from the front of the cone. Designs that do this (including "bass reflex", "passive radiator", "transmission line", etc.) are often used to extend the effective low-frequency response and increase low-frequency output of the driver.
To make the transition between drivers as seamless as possible, system designers have attempted to time-align (or phase adjust) the drivers by moving one or more driver mounting locations forward or back so that the acoustic center of each driver is in the same vertical plane. This may also involve tilting the face speaker back, providing a separate enclosure mounting for each driver, or (less commonly) using electronic techniques to achieve the same effect. These attempts have resulted in some unusual cabinet designs.
The speaker mounting scheme (including cabinets) can also cause diffraction, resulting in peaks and dips in the frequency response. The problem is usually greatest at higher frequencies, where wavelengths are similar to, or smaller than, cabinet dimensions. The effect can be minimized by rounding the front edges of the cabinet, curving the cabinet itself, using a smaller or narrower enclosure, choosing a strategic driver arrangement, using absorptive material around a driver, or some combination of these and other schemes.
Horn loudspeakers.
Horn loudspeakers are the oldest form of loudspeaker system. The use of horns as voice-amplifying megaphones dates at least to the 17th century, and horns were used in mechanical gramophones as early as 1857. Horn loudspeakers use a shaped waveguide in front of or behind the driver to increase the directivity of the loudspeaker and to transform a small diameter, high pressure condition at the driver cone surface to a large diameter, low pressure condition at the mouth of the horn. This increases the sensitivity of the loudspeaker and focuses the sound over a narrower area. The size of the throat, mouth, the length of the horn, as well as the area expansion rate along it must be carefully chosen to match the drive to properly provide this transforming function over a range of frequencies (every horn performs poorly outside its acoustic limits, at both high and low frequencies). The length and cross-sectional mouth area required to create a bass or sub-bass horn require a horn many feet long. 'Folded' horns can reduce the total size, but compel designers to make compromises and accept increased complication such as cost and construction. Some horn designs not only fold the low frequency horn, but use the walls in a room corner as an extension of the horn mouth. In the late 1940s, horns whose mouths took up much of a room wall were not unknown amongst hi-fi fans. Room sized installations became much less acceptable when two or more were required.
A horn loaded speaker can have a sensitivity as high as 110 dB at 2.83 volts (1 watt at 8 ohms) at 1 meter. This is a hundredfold increase in output compared to a speaker rated at 90 dB sensitivity, and is invaluable in applications where high sound levels are required or amplifier power is limited.
Wiring connections.
Most loudspeakers use two wiring points to connect to the source of the signal (for example, to the audio amplifier or receiver). To accept the wire connection, the loudspeaker enclosure may have binding posts, spring clips, or a panel-mount jack. If the wires for a pair of speakers are not connected with respect to the proper electrical polarity (the + and − connections on the speaker and amplifier should be connected + to + and − to −), the loudspeakers are said to be "out of phase" or more properly "out of polarity". Given identical signals, motion in one cone is in the opposite direction of the other. This typically causes monophonic material in a stereo recording to be canceled out, reduced in level, and made more difficult to localize, all due to destructive interference of the sound waves. The cancellation effect is most noticeable at frequencies where the loudspeakers are separated by a quarter wavelength or less; low frequencies are affected the most. This type of wiring error does not damage speakers, but is not optimal for listening.
Wireless speakers.
Wireless speakers are very similar to traditional (wired) loudspeakers, but they receive audio signals using radio frequency (RF) waves rather than over audio cables. There is normally an amplifier integrated in the speaker's cabinet because the RF waves alone are not enough to drive the speaker. This integration of amplifier and loudspeaker is known as an active loudspeaker. Manufacturers of these loudspeakers design them to be as lightweight as possible while producing the maximum amount of audio output efficiency.
Wireless speakers still need power, so require a nearby AC power outlet, or possibly batteries. Only the wire to the amplifier is eliminated.
Specifications.
Speaker specifications generally include:
and optionally:
Electrical characteristics of dynamic loudspeakers.
The load that a driver presents to an amplifier consists of a complex electrical impedance—a combination of resistance and both capacitive and inductive reactance, which combines properties of the driver, its mechanical motion, the effects of crossover components (if any are in the signal path between amplifier and driver), and the effects of air loading on the driver as modified by the enclosure and its environment. Most amplifiers' output specifications are given at a specific power into an ideal resistive load; however, a loudspeaker does not have a constant resistance across its frequency range. Instead, the voice coil is inductive, the driver has mechanical resonances, the enclosure changes the driver's electrical and mechanical characteristics, and a passive crossover between the drivers and the amplifier contributes its own variations. The result is a load resistance that varies fairly widely with frequency, and usually a varying phase relationship between voltage and current as well, also changing with frequency. Some amplifiers can cope with the variation better than others can.
To make sound, a loudspeaker is driven by modulated electric current (produced by an amplifier) that pass through a "speaker coil" which then (through inductance) magnetizes the coil, creating a magnetic field. The electric current variations that pass through the speaker are thus converted to varying magnetic forces, which move the speaker diaphragm, which thus forces the driver to produce air motion that is similar to the original signal from the amplifier.
Electromechanical measurements.
Examples of typical measurements are: amplitude and phase characteristics vs. frequency; impulse response under one or more conditions (e.g., square waves, sine wave bursts, etc.); directivity vs. frequency (e.g., horizontally, vertically, spherically, etc.); harmonic and intermodulation distortion vs. sound pressure level (SPL) output, using any of several test signals; stored energy (i.e., ringing) at various frequencies; impedance vs. frequency; and small-signal vs. large-signal performance. Most of these measurements require sophisticated and often expensive equipment to perform, and also good judgment by the operator, but the raw sound pressure level output is rather easier to report and so is often the only specified value—sometimes in misleadingly exact terms. The sound pressure level (SPL) a loudspeaker produces is measured in decibels (dBspl).
Efficiency vs. sensitivity.
Loudspeaker efficiency is defined as the sound power output divided by the electrical power input. Most loudspeakers are inefficient transducers; only about 1% of the electrical energy sent by an amplifier to a typical home loudspeaker is converted to acoustic energy. The remainder is converted to heat, mostly in the voice coil and magnet assembly. The main reason for this is the difficulty of achieving proper impedance matching between the acoustic impedance of the drive unit and the air it radiates into. (At low frequencies, improving this match is the main purpose of speaker enclosure designs). The efficiency of loudspeaker drivers varies with frequency as well. For instance, the output of a woofer driver decreases as the input frequency decreases because of the increasingly poor match between air and the driver.
Driver ratings based on the SPL for a given input are called sensitivity ratings and are notionally similar to efficiency. Sensitivity is usually defined as so many decibels at 1 W electrical input, measured at 1 meter (except for headphones), often at a single frequency. The voltage used is often 2.83 VRMS, which is 1 watt into an 8 Ω (nominal) speaker impedance (approximately true for many speaker systems). Measurements taken with this reference are quoted as dB with 2.83 V @ 1 m.
The sound pressure output is measured at (or mathematically scaled to be equivalent to a measurement taken at) one meter from the loudspeaker and on-axis (directly in front of it), under the condition that the loudspeaker is radiating into an infinitely large space and mounted on an infinite baffle. Clearly then, sensitivity does not correlate precisely with efficiency, as it also depends on the directivity of the driver being tested and the acoustic environment in front of the actual loudspeaker. For example, a cheerleader's horn produces more sound output in the direction it is pointed by concentrating sound waves from the cheerleader in one direction, thus "focusing" them. The horn also improves impedance matching between the voice and the air, which produces more acoustic power for a given speaker power. In some cases, improved impedance matching (via careful enclosure design) lets the speaker produce more acoustic power.
A driver with a higher maximum power rating cannot necessarily be driven to louder levels than a lower-rated one, since sensitivity and power handling are largely independent properties. In the examples that follow, assume (for simplicity) that the drivers being compared have the same electrical impedance, are operated at the same frequency within both driver's respective pass bands, and that power compression and distortion are low. For the first example, a speaker 3 dB more sensitive than another produces double the sound power (is 3 dB louder) for the same power input. Thus, a 100 W driver ("A") rated at 92 dB for 1 W @ 1 m sensitivity puts out twice as much acoustic power as a 200 W driver ("B") rated at 89 dB for 1 W @ 1 m when both are driven with 100 W of input power. In this particular example, when driven at 100 W, speaker A produces the same SPL, or loudness as speaker B would produce with 200 W input. Thus, a 3 dB increase in sensitivity of the speaker means that it needs half the amplifier power to achieve a given SPL. This translates into a smaller, less complex power amplifier—and often, to reduced overall system cost.
It is typically not possible to combine high efficiency (especially at low frequencies) with compact enclosure size and adequate low frequency response. One can, for the most part, choose only two of the three parameters when designing a speaker system. So, for example, if extended low-frequency performance and small box size are important, one must accept low efficiency. This rule of thumb is sometimes called Hofmann's Iron Law (after J.A. Hofmann, the "H" in KLH).
Listening environment.
The interaction of a loudspeaker system with its environment is complex and is largely out of the loudspeaker designer's control. Most listening rooms present a more or less reflective environment, depending on size, shape, volume, and furnishings. This means the sound reaching a listener's ears consists not only of sound directly from the speaker system, but also the same sound delayed by traveling to and from (and being modified by) one or more surfaces. These reflected sound waves, when added to the direct sound, cause cancellation and addition at assorted frequencies (e.g., from resonant room modes), thus changing the timbre and character of the sound at the listener's ears. The human brain is very sensitive to small variations, including some of these, and this is part of the reason why a loudspeaker system sounds different at different listening positions or in different rooms.
A significant factor in the sound of a loudspeaker system is the amount of absorption and diffusion present in the environment. Clapping one's hands in a typical empty room, without draperies or carpet, produces a zippy, fluttery echo due both to a lack of absorption and to reverberation (that is, repeated echoes) from flat reflective walls, floor, and ceiling. The addition of hard surfaced furniture, wall hangings, shelving and even baroque plaster ceiling decoration changes the echoes, primarily because of diffusion caused by reflective objects with shapes and surfaces having sizes on the order of the sound wavelengths. This somewhat breaks up the simple reflections otherwise caused by bare flat surfaces, and spreads the reflected energy of an incident wave over a larger angle on reflection.
Placement.
In a typical rectangular listening room, the hard, parallel surfaces of the walls, floor and ceiling cause primary acoustic resonance nodes in each of the three dimensions: left-right, up-down and forward-backward. Furthermore, there are more complex resonance modes involving three, four, five and even all six boundary surfaces combining to create standing waves. Low frequencies excite these modes the most, since long wavelengths are not much affected by furniture compositions or placement. The mode spacing is critical, especially in small and medium size rooms like recording studios, home theaters and broadcast studios. The proximity of the loudspeakers to room boundaries affects how strongly the resonances are excited as well as affecting the relative strength at each frequency. The location of the listener is critical, too, as a position near a boundary can have a great effect on the perceived balance of frequencies. This is because standing wave patterns are most easily heard in these locations and at lower frequencies, below the Schroeder frequency – typically around 200–300 Hz, depending on room size.
Directivity.
Acousticians, in studying the radiation of sound sources have developed some concepts important to understanding how loudspeakers are perceived. The simplest possible radiating source is a point source, sometimes called a simple source. An ideal point source is an infinitesimally small point radiating sound. It may be easier to imagine a tiny pulsating sphere, uniformly increasing and decreasing in diameter, sending out sound waves in all directions equally, independent of frequency.
Any object radiating sound, including a loudspeaker system, can be thought of as being composed of combinations of such simple point sources. The radiation pattern of a combination of point sources is not the same as for a single source, but depends on the distance and orientation between the sources, the position relative to them from which the listener hears the combination, and the frequency of the sound involved. Using geometry and calculus, some simple combinations of sources are easily solved; others are not.
One simple combination is two simple sources separated by a distance and vibrating out of phase, one miniature sphere expanding while the other is contracting. The pair is known as a doublet, or dipole, and the radiation of this combination is similar to that of a very small dynamic loudspeaker operating without a baffle. The directivity of a dipole is a figure 8 shape with maximum output along a vector that connects the two sources and minimums to the sides when the observing point is equidistant from the two sources, where the sum of the positive and negative waves cancel each other. While most drivers are dipoles, depending on the enclosure to which they are attached, they may radiate as monopoles, dipoles (or bipoles). If mounted on a finite baffle, and these out of phase waves are allowed to interact, dipole peaks and nulls in the frequency response result. When the rear radiation is absorbed or trapped in a box, the diaphragm becomes a monopole radiator. Bipolar speakers, made by mounting in-phase monopoles (both moving out of or into the box in unison) on opposite sides of a box, are a method of approaching omnidirectional radiation patterns.
In real life, individual drivers are complex 3D shapes such as cones and domes, and they are placed on a baffle for various reasons. A mathematical expression for the directivity of a complex shape, based on modeling combinations of point sources, is usually not possible, but in the far field, the directivity of a loudspeaker with a circular diaphragm is close to that of a flat circular piston, so it can be used as an illustrative simplification for discussion. As a simple example of the mathematical physics involved, consider the following:
the formula for far field directivity of a flat circular piston in an infinite baffle is formula_1
where formula_2, formula_3 is the pressure on axis, formula_4 is the piston radius, formula_5 is the wavelength (i.e. formula_6) formula_7 is the angle off axis and formula_8 is the Bessel function of the first kind.
A planar source radiates sound uniformly for low frequencies' wavelengths longer than the dimensions of the planar source, and as frequency increases, the sound from such a source focuses into an increasingly narrower angle. The smaller the driver, the higher the frequency where this narrowing of directivity occurs. Even if the diaphragm is not perfectly circular, this effect occurs such that larger sources are more directive. Several loudspeaker designs approximate this behavior. Most are electrostatic or planar magnetic designs.
Various manufacturers use different driver mounting arrangements to create a specific type of sound field in the space for which they are designed. The resulting radiation patterns may be intended to more closely simulate the way sound is produced by real instruments, or simply create a controlled energy distribution from the input signal (some using this approach are called monitors, as they are useful in checking the signal just recorded in a studio). An example of the first is a room corner system with many small drivers on the surface of a 1/8 sphere. A system design of this type was patented and produced commercially by Professor Amar Bose—the 2201. Later Bose models have deliberately emphasized production of both direct and reflected sound by the loudspeaker itself, regardless of its environment. The designs are controversial in high fidelity circles, but have proven commercially successful. Several other manufacturers' designs follow similar principles.
Directivity is an important issue because it affects the frequency balance of sound a listener hears, and also the interaction of the speaker system with the room and its contents. A very directed speaker (i.e., on an axis perpendicular to the speaker face) may result in a reverberant field lacking in high frequencies, giving the impression the speaker is deficient in treble even though it measures well on axis (e.g., "flat" across the entire frequency range). Speakers with very wide, or rapidly increasing directivity at high frequencies, can give the impression that there is too much treble (if the listener is on axis) or too little (if the listener is off axis). This is part of the reason why on-axis frequency response measurement is not a complete characterization of the sound of a given loudspeaker.
Other speaker designs.
While dynamic cone speakers remain the most popular choice, many other speaker technologies exist. 
With a diaphragm.
Moving-iron loudspeakers.
Unlike the newer dynamic (moving coil) design, a moving-iron speaker uses a stationary coil to vibrate a magnetized piece of metal (called the iron, reed, or armature). The metal is either attached to the diaphragm, or is the diaphragm itself. This design was the original loudspeaker design, dating back to the early telephone. Moving coil drivers are inefficient and can only produce a small band of sound. They require large magnets and coils to increase force. 
Balanced armature drivers (a type of moving iron driver) use an armature that moves like a see-saw or diving board. Since they are not damped, they are highly efficient, but they also produce strong resonances. They are still used today for high end earphones and hearing aids, where small size and high efficiency are important. 
Piezoelectric speakers.
Piezoelectric speakers are frequently used as beepers in watches and other electronic devices, and are sometimes used as tweeters in less-expensive speaker systems, such as computer speakers and portable radios. Piezoelectric speakers have several advantages over conventional loudspeakers: they are resistant to overloads that would normally destroy most high frequency drivers, and they can be used without a crossover due to their electrical properties. There are also disadvantages: some amplifiers can oscillate when driving capacitive loads like most piezoelectrics, which results in distortion or damage to the amplifier. Additionally, their frequency response, in most cases, is inferior to that of other technologies. This is why they are generally used in single frequency (beeper) or non-critical applications.
Piezoelectric speakers can have extended high frequency output, and this is useful in some specialized circumstances; for instance, sonar applications in which piezoelectric variants are used as both output devices (generating underwater sound) and as input devices (acting as the sensing components of underwater microphones). They have advantages in these applications, not the least of which is simple and solid state construction that resists seawater better than a ribbon or cone based device would.
In 2013, Kyocera introduced piezoelectric ultra-thin medium-size film speakers with only 1 milimeter of thickness and 7 grams of weight for their 55" OLED televisions and they hope the speakers will also be used in PCs and tablets. Besides medium-size, there are also large and small sizes which can all produce relatively the same quality of sound and volume within 180 degrees. The highly responsive speaker material provides better clarity than traditional TV speakers.
Magnetostatic loudspeakers.
Instead of a voice coil driving a speaker cone, a magnetostatic speaker uses an array of metal strips bonded to a large film membrane. The magnetic field produced by signal current flowing through the strips interacts with the field of permanent bar magnets mounted behind them. The force produced moves the membrane and so the air in front of it. Typically, these designs are less efficient than conventional moving-coil speakers.
Magnetostrictive speakers.
Magnetostrictive transducers, based on magnetostriction, have been predominantly used as sonar ultrasonic sound wave radiators, but their use has spread also to audio speaker systems. Magnetostrictive speaker drivers have some special advantages: they can provide greater force (with smaller excursions) than other technologies; low excursion can avoid distortions from large excursion as in other designs; the magnetizing coil is stationary and therefore more easily cooled; they are robust because delicate suspensions and voice coils are not required. Magnetostrictive speaker modules have been produced by Fostex and FeONIC and subwoofer drivers have also been produced.
Electrostatic loudspeakers.
Electrostatic loudspeakers use a high voltage electric field (rather than a magnetic field) to drive a thin statically charged membrane. Because they are driven over the entire membrane surface rather than from a small voice coil, they ordinarily provide a more linear and lower-distortion motion than dynamic drivers. They also have a relatively narrow dispersion pattern that can make for precise sound-field positioning. However, their optimum listening area is small and they are not very efficient speakers. They have the disadvantage that the diaphragm excursion is severely limited because of practical construction limitations—the further apart the stators are positioned, the higher the voltage must be to achieve acceptable efficiency. This increases the tendency for electrical arcs as well as increasing the speaker's attraction of dust particles. Arcing remains a potential problem with current technologies, especially when the panels are allowed to collect dust or dirt and are driven with high signal levels.
Electrostatics are inherently dipole radiators and due to the thin flexible membrane are less suited for use in enclosures to reduce low frequency cancellation as with common cone drivers. Due to this and the low excursion capability, full range electrostatic loudspeakers are large by nature, and the bass rolls off at a frequency corresponding to a quarter wavelength of the narrowest panel dimension. To reduce the size of commercial products, they are sometimes used as a high frequency driver in combination with a conventional dynamic driver that handles the bass frequencies effectively.
Electrostatics are usually driven through a step-up transformer that multiplies the voltage swings produced by the power amplifier. This transformer also multiplies the capacitive load that is inherent in electrostatic transducers, which means the effective impedance presented to the power amplifiers varies widely by frequency. A speaker that is nominally 8 ohms may actually present a load of 1 ohm at higher frequencies, which is challenging to some amplifier designs.
Ribbon and planar magnetic loudspeakers.
A ribbon speaker consists of a thin metal-film ribbon suspended in a magnetic field. The electrical signal is applied to the ribbon, which moves with it to create the sound. The advantage of a ribbon driver is that the ribbon has very little mass; thus, it can accelerate very quickly, yielding very good high-frequency response. Ribbon loudspeakers are often very fragile—some can be torn by a strong gust of air. Most ribbon tweeters emit sound in a dipole pattern. A few have backings that limit the dipole radiation pattern. Above and below the ends of the more or less rectangular ribbon, there is less audible output due to phase cancellation, but the precise amount of directivity depends on ribbon length. Ribbon designs generally require exceptionally powerful magnets, which makes them costly to manufacture. Ribbons have a very low resistance that most amplifiers cannot drive directly. As a result, a step down transformer is typically used to increase the current through the ribbon. The amplifier "sees" a load that is the ribbon's resistance times the transformer turns ratio squared. The transformer must be carefully designed so that its frequency response and parasitic losses do not degrade the sound, further increasing cost and complication relative to conventional designs.
Planar magnetic speakers (having printed or embedded conductors on a flat diaphragm) are sometimes described as ribbons, but are not truly ribbon speakers. The term planar is generally reserved for speakers with roughly rectangular flat surfaces that radiate in a bipolar (i.e., front and back) manner. Planar magnetic speakers consist of a flexible membrane with a voice coil printed or mounted on it. The current flowing through the coil interacts with the magnetic field of carefully placed magnets on either side of the diaphragm, causing the membrane to vibrate more or less uniformly and without much bending or wrinkling. The driving force covers a large percentage of the membrane surface and reduces resonance problems inherent in coil-driven flat diaphragms.
Bending wave loudspeakers.
Bending wave transducers use a diaphragm that is intentionally flexible. The rigidity of the material increases from the center to the outside. Short wavelengths radiate primarily from the inner area, while longer waves reach the edge of the speaker. To prevent reflections from the outside back into the center, long waves are absorbed by a surrounding damper. Such transducers can cover a wide frequency range (80 Hz to 35,000 Hz) and have been promoted as being close to an ideal point sound source. This uncommon approach is being taken by only a very few manufacturers, in very different arrangements.
The Ohm Walsh loudspeakers use a unique driver designed by Lincoln Walsh, who had been a radar development engineer in WWII. He became interested in audio equipment design and his last project was a unique, one-way speaker using a single driver. The cone faced down into a sealed, airtight enclosure. Rather than move back-and-forth as conventional speakers do, the cone rippled and created sound in a manner known in RF electronics as a "transmission line". The new speaker created a cylindrical sound field. Lincoln Walsh died before his speaker was released to the public. The Ohm Acoustics firm has produced several loudspeaker models using the Walsh driver design since then.
The German firm, Manger, has designed and produced a bending wave driver that at first glance appears conventional. In fact, the round panel attached to the voice coil bends in a carefully controlled way to produce full range sound. Josef W. Manger was awarded with the "Diesel Medal" for extraordinary developments and inventions by the German institute of inventions.
Flat panel loudspeakers.
There have been many attempts to reduce the size of speaker systems, or alternatively to make them less obvious. One such attempt was the development of "exciter" transducer coils mounted to flat panels to act as sound sources, most accurately called exciter/panel drivers. These can then be made in a neutral color and hung on walls where they are less noticeable than many speakers, or can be deliberately painted with patterns, in which case they can function decoratively. There are two related problems with flat panel techniques: first, a flat panel is necessarily more flexible than a cone shape in the same material, and therefore moves as a single unit even less, and second, resonances in the panel are difficult to control, leading to considerable distortions. Some progress has been made using such lightweight, rigid, materials such as Styrofoam, and there have been several flat panel systems commercially produced in recent years.
Heil air motion transducers.
Oskar Heil invented the air motion transducer in the 1960s. In this approach, a pleated diaphragm is mounted in a magnetic field and forced to close and open under control of a music signal. Air is forced from between the pleats in accordance with the imposed signal, generating sound. The drivers are less fragile than ribbons and considerably more efficient (and able to produce higher absolute output levels) than ribbon, electrostatic, or planar magnetic tweeter designs.
ESS, a California manufacturer, licensed the design, employed Heil, and produced a range of speaker systems using his tweeters during the 1970s and 1980s. Lafayette Radio, a large US retail store chain, also sold speaker systems using such tweeters for a time. There are several manufacturers of these drivers (at least two in Germany—one of which produces a range of high-end professional speakers using tweeters and mid-range drivers based on the technology) and the drivers are increasingly used in professional audio. Martin Logan produces several AMT speakers in the US. GoldenEar Technologies incorporates them in its entire speaker line.
Transparent ionic conduction speaker.
In 2013, a research team introduced Transparent ionic conduction speaker which a 2 layers transparent conductive gel and a layer of transparent rubber in between to make high voltage and high actuation work to reproduce good sound quality. The speaker is suitable for robotics, mobile computing and adaptive optics fields.
Without a diaphragm.
Plasma arc speakers.
Plasma arc loudspeakers use electrical plasma as a radiating element. Since plasma has minimal mass, but is charged and therefore can be manipulated by an electric field, the result is a very linear output at frequencies far higher than the audible range. Problems of maintenance and reliability for this approach tend to make it unsuitable for mass market use. In 1978 Alan E. Hill of the Air Force Weapons Laboratory in Albuquerque, NM, designed the Plasmatronics Hill Type I, a tweeter whose plasma was generated from helium gas. This avoided the ozone and nitrous oxide produced by RF decomposition of air in an earlier generation of plasma tweeters made by the pioneering DuKane Corporation, who produced the Ionovac (marketed as the Ionofane in the UK) during the 1950s. Currently, there remain a few manufacturers in Germany who use this design, and a do-it-yourself design has been published and has been available on the Internet.
A less expensive variation on this theme is the use of a flame for the driver, as flames contain ionized (electrically charged) gases.
Thermoacoustic speakers.
In 2008, researchers of Tsinghua University demonstrated a thermoacoustic loudspeaker of carbon nanotube thin film, whose working mechanism is a thermoacoustic effect. Sound frequency electric currents are used to periodically heat the CNT and thus result in sound generation in the surrounding air. The CNT thin film loudspeaker is transparent, stretchable and flexible.
In 2013, researchers of Tsinghua University further present a thermoacoustic earphone of carbon nanotube thin yarn and a thermoacoustic surface-mounted device. They are both fully integrated devices and compatible with Si-based semiconducting technology.
Rotary woofers.
A rotary woofer is essentially a fan with blades that constantly change their pitch, allowing them to easily push the air back and forth. Rotary woofers are able to efficiently reproduce infrasound frequencies, which are difficult to impossible to achieve on a traditional speaker with a diaphragm. They are often employed in movie theaters to recreate rumbling bass effects, such as explosions. 
New technologies for driving speakers.
Digital speakers.
Digital speakers have been the subject of experiments performed by Bell Labs as far back as the 1920s. The design is simple; each bit controls a driver, which is either fully 'on' or 'off'. Problems with this design have led manufacturers to abandon it as impractical for the present. First, for a reasonable number of bits (required for adequate sound reproduction quality), the physical size of a speaker system becomes very large. Secondly, due to inherent analog digital conversion problems, the effect of aliasing is unavoidable, so that the audio output is "reflected" at equal amplitude in the frequency domain, on the other side of the sampling frequency, causing an unacceptably high level of ultrasonics to accompany the desired output. No workable scheme has been found to adequately deal with this.
The term "digital" or "digital-ready" is often used for marketing purposes on speakers or headphones, but these systems are not digital in the sense described above. Rather, they are conventional speakers that can be used with digital sound sources (e.g., optical media, MP3 players, etc.), as can any conventional speaker.

</doc>
<doc id="45873" url="https://en.wikipedia.org/wiki?curid=45873" title="Assured destruction">
Assured destruction

In military strategy, assured destruction is where behaviors or choices are deterred because they will lead to overwhelming punitive consequences. It was most often discussed as mutually assured destruction (MAD), assuming there are exactly two parties in the conflict. The concept of assured destruction occasionally arises also in the death penalty debate and biotechnology debate.
For an assured destruction strategy to be successful:
The examples of attempts to establish the conditions for assured destruction include:
When the concept of assured destruction is applied in the doctrine of law, it is often criticized by proponents of the restorative justice and transformative justice approaches, who point out that assured destruction doctrines are rarely implemented with rigor or integrity of due process. This contributes to the controversy of the death penalty debate. 
Psychologists, notably B. F. Skinner, are of the opinion that promises of punishment seem to play little or no role in deterrence of adult behavior.
Assured destruction tactics are not to be confused with "insurance" tactics such as retaliatory trade tariffs that are merely intended to compensate the aggrieved or to return conditions to the pre-existing "level playing field".

</doc>
<doc id="45876" url="https://en.wikipedia.org/wiki?curid=45876" title="Pre-emptive nuclear strike">
Pre-emptive nuclear strike

In nuclear strategy, a first strike is a preemptive surprise attack employing overwhelming force. First strike capability is a country's ability to defeat another nuclear power by destroying its arsenal to the point where the attacking country can survive the weakened retaliation while the opposing side is left unable to continue war. The preferred methodology is to attack the opponent's strategic nuclear weapon facilities (missile silos, submarine bases, bomber airfields), command and control sites, and storage depots first. The strategy is called counterforce.
Overview.
During the Cold War period, both superpowers, NATO and the Eastern Bloc, built massive nuclear arsenals, aimed, to a large extent, at each other. However, they were never used, as after a time, leaders on both sides of the Iron Curtain realized that global thermonuclear war would not be in either power's interest, as it would probably lead to the destruction of both sides, and possibly nuclear winter or other extinction level events. Therefore, at times, both sides refrained from deploying systems capable of unanswerable nuclear strikes against either side. However, in both nations, there were interests that benefited from the development and maintenance of first-strike weapons systems: what U.S. President Dwight Eisenhower termed the military-industrial complex; these forces encouraged the constant development of weapons systems of greater accuracy, power, and destruction. In addition, each side doubted the other side's commitment to not deploy first-strike weapons, or even in the event of their deployment, to not strike first. Some first-strike weapons were deployed; however like most nuclear weapons, they were never used.
Of the nuclear powers, only the People's Republic of China and India have declarative, unqualified, unconditional no-first-use policies. In 1982, at a special session of the General Assembly of United Nations, the USSR pledged not to use nuclear weapons first, regardless of whether its opponents possessed nuclear weapons or not. This pledge was later abandoned by post-Soviet Russia to compensate the overwhelming conventional weapon superiority enjoyed by NATO. The United States has a partial, qualified no-first-use policy, stating that they will not use nuclear weapons against states that do not possess nuclear weapons or other weapons of mass destruction.
Large-scale missile defense systems are not first-strike weapons, but certain critics view them as first-strike enabling weapons. U.S. President Ronald Reagan's proposed Strategic Defense Initiative, if it had ever been deployed (and proven successful), would have undermined the fundamental premise of mutual assured destruction (the inevitable outcome of equal and unacceptable destruction for both sides in the event of nuclear war), removing the incentive for the US not to strike first.
These proposed defense systems, intended to lessen the risk of devastating nuclear war, would lead to it, according to these critics. Indeed, according to game theory, the side not building large-scale missile defenses would have an incentive to launch a pre-emptive first strike while such a strike could still get through.
Historical background.
"First-strike attack", the use of a nuclear first strike capability, was greatly feared during the Cold War between NATO and the Soviet Bloc. At various points, fear of a first strike attack existed on both sides. Misunderstood changes in posture and well understood changes in technology used by either side often led to speculation regarding the enemy's intentions.
1948–1961.
In the immediate aftermath of World War II, the leadership of the Soviet Union feared the United States would use its nuclear superiority to its advantage, as from 1945 to 1948 the U.S. was the only state possessing nuclear weapons. The USSR countered by rapidly developing their own nuclear weapons, surprising the US with their first test in 1949. In turn, the U.S. countered by developing the vastly more powerful thermonuclear weapon, testing their first hydrogen bomb in 1952 at Ivy Mike, but the USSR quickly countered by testing their own thermonuclear weapons, with a test in 1953 of a semi-thermonuclear weapon of the Sloika design, and in 1956, with the testing of Sakharov's Third Idea – equivalent to the Castle Bravo device. Meanwhile, tensions between the two nations rose as 1956 saw the suppression of Hungary by the Soviets; the U.S. and European nations drew certain conclusions from that event, while in the U.S., a powerful social backlash was afoot, prompted by Senator Joseph McCarthy, the House Un-American Activities Committee, and Julius and Ethel Rosenberg, two atomic spies. This atmosphere was further inflamed by the 1957 launch of Sputnik, which led to fears of Communists attacking from space, as well as concerns that if the Soviets could launch a device into orbit, they could equally cause a device to re-enter the atmosphere and impact any part of the planet. John F. Kennedy capitalized on this situation by emphasizing the Bomber gap and the Missile gap, areas in which the Soviets were (inaccurately) perceived as leading the United States, while heated Soviet rhetoric, including Soviet Premier Nikita Khrushchev's famous threat that "We will bury you!" to Western ambassadors added to political pressure. The 1960 U-2 incident, involving Francis Gary Powers, as well as the Berlin Crisis, along with the test of the Tsar Bomba, escalated tensions still further.
Cuban Missile Crisis.
This escalating situation came to a head with the Cuban Missile Crisis of 1962. The arrival of Soviet missiles in Cuba was conducted by the Soviets on the rationale that the US already had nuclear missiles stationed in Turkey, as well as the desire by Fidel Castro to increase his power, his freedom of action, and to protect his government from US-initiated prejudicial resolution of ideological disputes through the use of military force, such as had been attempted during the Bay of Pigs Invasion in April 1961. During the crisis, Fidel Castro wrote Khrushchev a letter about the prospect that the "imperialists" would be "extremely dangerous" if they responded militarily to the Soviet stationing of nuclear missiles aimed at US territory, less than 90 miles away in Cuba. The following quotation from the letter suggests that Castro was calling for a Soviet first strike against the US if it responded militarily to the placement of nuclear missiles aimed at the US in Cuba:
The Cuban Missile Crisis resulted in Khrushchev publicly agreeing to remove the missiles from Cuba, while Kennedy secretly agreed to remove his country's missiles from Turkey. Both sides in the Cold War realized how close they came to nuclear war over Cuba, and decided to seek a reduction of tensions, resulting in US-Soviet détente for most of the 1960s and 1970s.
Nonetheless, this reduction of tensions only applied to the US and the USSR. Recently declassified interviews with high level former Soviet nuclear and military-industrial planners reveal that Fidel Castro continued to favour nuclear options, even during the later Cold War – according to former Soviet General Danilevich, "(...in the early 1980s...) Cuban leader Fidel Castro pressed the USSR to take a tougher line against the United States, including possible nuclear strikes. The Soviet Union, in response, sent experts to spell out for Castro the ecological consequences for Cuba of nuclear strikes on the United States. Castro, according to the General, quickly became convinced of the undesirability of such outcomes."
1970s/1980s.
However, tensions were inflamed again in the late 1970s and early 1980s with the Soviet invasion of Afghanistan, the Soviet deployment of the SS-20 Saber and the SS-18 Satan, and the decision of NATO to deploy the new Pershing II IRBM as well as the Tomahawk Ground Launched Cruise Missile, along with U.S. President Ronald Reagan's talk of 'limited' nuclear war. This increased Soviet fears that NATO was planning an attack. NATO's deployment of these missiles was a response to the Soviet deployment of the SS-20 Saber, which could hit most European NATO bases within minutes of launch. These mutual deployments led to a destabilizing strategic situation, which was exacerbated by malfunctioning U.S. and Soviet missile launch early warning systems, a Soviet intelligence gap that prevented the Soviets from getting a "read" on the strategic intentions of U.S. leaders, as well as inflammatory U.S. rhetoric combined with classical Soviet mistrust of the NATO powers. This culminated in a war scare that occurred during 1983 due to the inopportune timing of a NATO exercise called Able Archer, which was a simulation of a NATO nuclear attack on the Soviet Union; this exercise happened to occur during a massive Soviet intelligence mobilization called VRYAN, that was designed to discover intentions of NATO to initiate a nuclear first-strike. This poor timing drove the world very close to nuclear war, possibly even closer than the Cuban Missile Crisis over 20 years before.
Post-Cold War.
Subsequent events caused the fears of nuclear attack on both sides to diminish significantly, as the tensions between the superpowers decreased, and have remained—at least in nuclear terms—comparatively low. However, the present indicates that this might be changing. Relations between the two have recently fallen to new post–Cold War lows, and events have illustrated that the world may be heading back towards a more tense situation in terms of nuclear armament and use, possibly even to a first strike. Talk that has been characterized as "reckless" has been rife amongst certain U.S. politicians who favor the development of new nuclear weapons (such as through the Complex 2030 program) or new uses for old weapons, such as by using them as nuclear bunker busters, even against non-nuclear states. The military invasion of Iraq was seen by the Russian leadership as indicating potential U.S. disrespect for what the Russian leadership views as international law. The U.S. missile defense program has proven to be the primary persistent obstacle to better relations with Russia, which views the placement of U.S. missile defense systems in Eastern Europe for defense against "the Iranian threat" similarly to how the U.S. would view placement of Russian missile defense systems in, for example, Cuba, for Russian defense against "the insidious Asian". The assassination of a British citizen by alleged operatives of the Russian government using Polonium-210, a radioactive poison, as well as the alleged dioxin poisoning of the President of the Ukraine, has raised tensions between Russia and the West, with some commentators in Western nations regarding the poisonings as an indicator of the character and true intentions of the Kremlin. Western nations view Russian bellicosity and belligerence as having markedly increased as of late, with tests of new nuclear-capable missiles occurring on a regular basis, military conflicts with neighboring states, claims of a Russian "sphere of influence" on the perimeter of the old Soviet Union, the rise of ultra-nationalist "Putin Youth" groups, aggressive politicization of and threats of withdrawal of natural gas supplies to Europe should the Europeans not make certain policy concessions, and even threats of a nuclear first strike against Poland have been heard to be made by certain Russian generals.
Even with these developments, recent events in both nations have served to restrain rhetoric and action in the direction of strategic destabilization, and have encouraged the possibility of stabilizing developments. Both the US and Russia have suffered economic problems as a result of the recent economic crisis and both are seeking to retrench policies that are viewed as potentially costly or reckless between the two. Russia's military development is no longer backed and inflated by the record-high natural gas and oil prices that formerly allowed massive sums to be poured into military spending while US arms buildups are no longer encouraged by the previous Administration. Indeed, the correlation of forces and means between the two suggests the possibility of a potential reciprocal nuclear weapon drawdown to low levels consistent with minimum credible deterrence – and, beyond that – to ultimate levels comparable with the nuclear force levels of the other great powers – achievable within the next decade. Both nations have begun to realize the core truth of the post–Cold War era that, if the strategic reality, as described by the words of Ronald Reagan, is that "Nuclear war cannot be won and must not be fought", then large nuclear weapons stockpiles have no positive use, are expensive, and can lead to dangerous destabilization. The possibility of a peace with honor of strategic equals between Russia and the US may now be possible.
Still, strategic problems remain in other areas. Other nations have engaged in policies that are regarded as potentially destabilizing. Officials in the People's Republic of China recently tested an anti-satellite missile, leading to widespread international concern, as anti-satellite missiles are viewed as threats to nuclear-launch warning systems, which could facilitate a first strike; further, tensions amid the Chinese governments over Taiwan have been rife in recent years; in addition, the PRC is reportedly pursuing modernization of their nuclear forces. Israel has made threats of the use of weapons, including those of a non-conventional character, while the former administration in the U.S. has refused to "take options off the table" (including the "nuclear option"), in the nuclear dispute with Iran, which is widely viewed as pursuing a clandestine nuclear weapons program, and well known for their desire for the destruction of Israel (c.f. "The World Without Israel") and extreme dislike for the United States (c.f. regular political rallies in Tehran calling for "Death to America!"). The unpredictable North Korean government has tested (or, more likely, partially fizzled) a nuclear device, and has historically threatened to turn Seoul into a "sea of fire", or most recently, "ashes", in response to unspecified, but always imminent, U.S. or South Korean "aggression" against it. The foreign relations of Pakistan and India remain unstable, but are now exacerbated by the nuclear arsenals of both states, as well as the rise of political parties promoting Hindu nationalism in India, and the rise of al-Qaeda Islamism in Pakistan, as well as intercommunal strife—ranging from the demolition of a historic mosque by communal hooligans to a terrorist assault on Hindu shrines—could set off a nuclear war.
Historical analysis.
Neither side sought nuclear conflict, even though it threatened to break out on multiple occasions. What both sides had, however, was a deep and continuing fear that the other nation was seeking to start a nuclear conflict, or, at least, thought such a conflict was "winnable" and would not be deterred by the threat of nuclear war. This led to both sides adopting aggressive, confrontational military and nuclear strategies that were misinterpreted and countered by the other side, furthering distrust. These strategies led to destabilization of the strategic situation to the point where the two major war scares of the Cold War occurred: the Cuban Missile Crisis and the Able Archer/VRYAN crisis. Though neither side intended to start a nuclear war, and, in fact, were extremely concerned about the possibility of it, neither side adopted strategies to calm things down, so sure were they of their adversaries' bad faith.
U.S. military strategy (at least in Europe) was confined to responses to potential Soviet aggression against NATO countries. Soviet military theory was dominated by the theory of the "deep operation" – a large-scale combined-arms offensive into enemy-held territory – rather than a nuclear offensive. Soviet conventional superiority, shown by the fact that the Soviet Union certainly was prepared for war in Europe, having massed armored, mechanized, artillery, and air forces poised along the Inner German and Czech borders, led by the dreaded Third Shock Army of the Soviet Union, caused NATO to consider the use of tactical nuclear weapons to stop the "steamroller" of the Red Army if they decided to take a drive through the Fulda Gap or an amble through the North German Plain. NATO's position changed in the 1970s and 1980s, in favor of trying to stop a Soviet offensive through the employment, at least initially, of a doctrine involving non-nuclear AirLand Battle to try to buy time to either throw back the invader or work out the issues at hand through diplomacy. Both sides, however, were willing to use nuclear weapons, if necessary, to not lose the war at hand. Although neither side was actively pursuing a first-strike policy—since the time of Khrushchev, the leaders of orthodox communism believed that "peaceful coexistence" with the "imperialist" powers was possible—both sides relied on military strategies that could have still caused a general nuclear war.
Ideological determinism also played a role. President Ronald Reagan of the United States, at least before the Able Archer/VRYAN crisis, believed that everybody, including the Soviet Union, was completely aware of the United States' good intentions, even when he bellicosely declared that the USSR was an "evil empire" and (more jokingly) that the "bombing begins in 5 minutes" while encouraging the military to conduct threatening exercises, such as sneaking a Carrier Battle Group through the GIUK Gap and sending nuclear-capable bombers towards the territory of the USSR. Chairman Yuri Andropov of the Soviet Union had similar, distorted views; he believed that the Western Allies, and the U.S., in particular, were fascist states, whose leaders had territorial designs against the Soviet Motherland on the scale of Napoleon, at the least, and Adolf Hitler, at the worst; in addition, to counter the "fascists", he incited his military-industrial complex to build weapons such as the SS-20 MIRV IRBM and the SS-18 Satan MIRV ICBM, which the NATO countries reasonably viewed as a Soviet sword against their throats, and caused reaction through development of equivalent or superior weapons systems.
When the superpowers drew close to the edge of the nuclear abyss during both the Cuban Missile Crisis and the Able Archer/VRYAN Crisis, they learned and grew from their mistakes and miscalculations that led them to be within view of mutual assured destruction. Andropov was followed as Soviet leader by Konstantin Chernenko, who in turn was followed by Mikhail Gorbachev, and Gorbachev brought a far less hostile, ideological, and reflexively skeptical approach to the relations between the superpowers, helping to build an atmosphere of trust between the two. Reagan had a figurative conversion on the road to Damascus regarding nuclear weapons and (especially) ICBMs following this crisis, discarding his preconceived notions of general Soviet bad faith, leading him to come full circle and famously declare that "Nuclear war cannot be won and must not be fought". These new attitudes on both sides nearly brought about the disarmament and destruction of ICBMs, long-range SLBMs, and, possibly even nuclear weapons themselves at a groundbreaking disarmament summit between Gorbachev and Reagan at Reykjavík in 1986. (The sticking point causing agreement to be unreachable was the SDI Program, just as missile defense continues to be a thorn in the side of the Russians today.) However, progress was made; the INF Treaty, the Conventional Forces in Europe Treaty, and the START Treaty could be said to be the result of the change in leaders and leaders' attitudes that the Able Archer/VRYAN crisis facilitated, just as the Non-Proliferation Treaty and the Partial Test Ban Treaty, as well as U.S.-Soviet détente, could be considered to be the sons and daughters of the Cuban Missile Crisis. Still, both crises were dangerous times catalyzed by dangerous political and military mistakes caused by dangerous policies instituted by leaders who let their fear get the better of their judgment and reasoning. Thankfully for those who lived, and those who now live, these mistakes never caused a first strike to come to pass.
Likely first strike weapons systems.
Because of the low accuracy (circular error probable) of early generation intercontinental ballistic missiles (and especially submarine-launched ballistic missiles), counterforce strikes were initially only possible against very large, undefended targets like bomber airfields and naval bases. Later generation missiles with much improved accuracy made counterforce attacks against the opponent's hardened military facilities (like missile silos and command and control centers) possible. This is due to the inverse-square law, which predicts that the amount of energy dispersed from a single point release of energy (such as a thermonuclear blast) dissipates by the inverse of the square of distance from the single point of release. The result is that the power of a nuclear explosion to rupture hardened structures is greatly decreased by the distance from the impact point of the nuclear weapon. So a near-direct hit is generally necessary, as only diminishing returns are gained by increasing bomb power.
Anti-first-strike countermeasures.
According to the theory of nuclear deterrence and mutually assured destruction, full countervalue retaliation would be the likely fate for anyone who unleashed a first strike. So as to maintain credible deterrence, the nuclear-weapons states have taken measures to give their enemies reason to believe that a first strike would lead to unacceptable results.
The main strategy here relies on creating doubt among enemy strategists regarding nuclear capacity, weapons characteristics, facility and infrastructure vulnerability, early warning systems, intelligence penetration, strategic plans, and political will. In terms of military capabilities, the aim is to create the impression of the maximum possible force and survivability, leading the enemy to make increased estimates of the probability of a disabling counterstrike; while in terms of strategy and politics, the aim is to cause the enemy to believe that such a second strike would be forthcoming in the event of a nuclear attack.
Second strike.
One of the main reasons to deter first-strike, is the possibility that the victim of the first-strike will launch a retaliatory second-strike on the attacker.
Increasing SSBN deployment.
Nuclear-powered ballistic missile submarines (SSBNs) carrying submarine-launched ballistic missiles (SLBMs), commonly known as "boomers" in the US and "bombers" in the UK, are widely considered the most survivable component of the nuclear triad. The depths of the ocean are extremely large, and nuclear submarines are highly mobile, very quiet, have virtually unlimited range, and can generate their own oxygen and potable water; in essence, their undersea endurance is limited only by food supply. It is unlikely that any conceivable opponent of any nuclear power deploying ballistic missile submarines could locate and neutralize every ballistic missile submarine before it could launch a retaliatory strike, in the event of war. Therefore, to increase the percentage of nuclear forces surviving a first strike, a nation can simply increase SSBN deployment, as well as deployment of reliable communications links with SSBNs.
Hardening or mobilizing land-based nuclear assets.
In addition, land-based ICBM silos can be hardened. No missile launch facility can really defend against a direct nuclear hit, but a sufficiently hardened silo could defend against a near miss, especially if the detonation is not from a multimegaton thermonuclear weapon. In addition, ICBMs can be placed on road or rail-mobile launchers (RT-23 Molodets, RT-2PM2 Topol-M, DF-31, MGM-134 Midgetman), which can then be moved around; as an enemy has nothing fixed to aim at, this increases their survivability.
Increasing alert state and readiness.
The effectiveness of a first strike is contingent upon the aggressor's ability to immediately deplete its enemy's retaliatory capacity to a level that would make a second strike impossible, mitigable, or strategically undesirable. Intelligence and early warning systems increase the probability that the enemy will have the time to launch its own strike before its warmaking capacity has been significantly reduced, thus rendering a first strike pointless. Alert states such as DEFCON conditions, apart from serving a purpose in the internal management of a country's military, can have the effect of advising a potential aggressor that an escalation towards first strike has been detected, and therefore that effective retaliatory strikes could be made in the event of an attack.
Maintaining survivable C4ISTAR links.
Looking Glass, Nightwatch, and TACAMO are U.S. airborne nuclear command posts, and represent survivable communication links with U.S. nuclear forces. In the event of significant political-military tensions between the nuclear powers, they would take to the skies, and provide survivable communications in the event of enemy attack. They are capable of the full exercise of all available MAOs (Major Attack Options), as well as the full SIOP, in the event of a first strike, or the destruction of the NCA. They can directly initiate launch of all U.S. ICBMs via radio and satellite communication, signal SLBMs to launch, and send bombers on their strike missions. In addition to these airborne assets, the U.S. government has several command and control bunkers, the most famous of which is NORAD, tunneled a few thousand feet into the granite of Cheyenne Mountain Complex, outside of Colorado Springs, Colorado, which is believed to be capable of withstanding and continuing to operate after a nuclear direct hit. Other U.S. C4ISTAR bunkers include an installation called Site R, located at Raven Rock, Pennsylvania, which is believed to be the Pentagon's relocation site if Washington, D.C. is destroyed, as well as Mount Weather, in Virginia, which is believed to be the relocation site for top Executive Branch officials. The Greenbrier in West Virginia was once the site of the Supreme Court of the United States and Congress' relocation bunker; however, it is no longer a secret and is now a tourist attraction.
The Russians also have equivalent or superior capabilities in this area; they have a system called SPRN (СПРН), which is capable of detecting nuclear launches and providing early warning, so that any such strike would not be undetected until it is too late. But their unique and special capability can be found with their Dead Hand fail-deadly computerized nuclear release system, based at Mount Yamantaw in the Urals. Apparently, Dead Hand, named for either the Dead Man's Hand in poker, or the Dead Man's Switch in dangerous or deadly machinery, can be turned on in the event that the Russian leadership fears a nuclear attack. Allegedly, once Dead Hand is activated, if it detects a loss of communications with Moscow as well as nuclear detonations inside of Russian territory, it can give final authority for the release of nuclear weapons to military officers in a bunker under Mt. Yamantaw, who can then, if they so determine, launch Russia's arsenal. Mt. Yamantaw is believed to be able to withstand multiple direct nuclear detonations.
Decreasing tensions by mutual adoption of a minimum credible deterrent posture.
Instead of relying on sophisticated communications links and launch-on-warning postures, the French, British, and Chinese have chosen to assume different nuclear postures more suited to minimum credible deterrence, or the capability to inflict unacceptable losses so as to prevent the use of nuclear weapons against them, rather than pursuing types of nuclear weapons suitable to first-strike use.
The People's Republic of China is believed to pursue a minimum credible deterrent/second strike strategy with regards to the United States. This may or may not be true with regards to the PRC's stance vis a vis Russia, as the majority of Chinese nuclear platforms are non-intercontinental, and are deployed on the Russian-Chinese border. Unlike the relations of the United States and the PRC, the PRC and Russia have had military conflicts in the past. In recent years, the PRC has improved its early-warning systems and renovated certain of its platforms for intercontinental strike; this may be due to the U.S. missile defense system (it may not be, however). In general, it appears that the PRC's leaders do not greatly fear a first strike (due to their posture of merely inflicting unacceptable losses upon an adversary as opposed to the U.S./Russian policy of trying to "win" a nuclear war); in any event, the Chinese arsenal is considered sufficient to ensure that such a first strike would not go unavenged.
The United Kingdom and France possess sophisticated nuclear weapons platforms; however their nuclear strategies are minimum credible deterrent-based. Each possesses ballistic missile submarines armed with intercontinental submarine-launched ballistic missiles to ensure a devastating second strike retaliation anywhere in the world. France also possesses a number of nuclear capable fighter aircraft. Both countries' nuclear policies are believed to be that of effective deterrence towards a would be nuclear strike against themselves, NATO, European Union members and other allies.
Destabilizing role of land-based MIRVed ICBMs.
MIRVed land-based ICBMs are generally considered suitable for a first strike or a counterforce strike, due to:
Unlike a decapitation strike or a countervalue strike, a counterforce strike might result in a potentially more constrained retaliation. Though the Minuteman III of the mid-1960s was MIRVed with 3 warheads, heavily MIRVed vehicles threatened to upset the balance; these included the SS-18 Satan which was deployed in 1976, and was considered to threaten Minuteman III silos, which led some neoconservatives to conclude a Soviet first strike was being prepared for. This led to the development of the aforementioned Pershing II, the Trident I and Trident II, as well as the MX missile, and the B-1 Lancer.
MIRVed land-based ICBMs are considered destabilizing because they tend to put a premium on striking first. When a missile is MIRVed, it is able to carry many warheads (up to 8 in existing U.S. missiles, limited by New START, though Trident II is capable of carrying up to 12) and deliver them to separate targets. If it is assumed that each side has 100 missiles, with 5 warheads each, and further that each side has a 95 percent chance of neutralizing the opponent's missiles in their silos by firing 2 warheads at each silo, then the attacking side can reduce the enemy ICBM force from 100 missiles to about 5 by firing 40 missiles with 200 warheads, and keeping the rest of 60 missiles in reserve. As such, this type of weapon was intended to be banned under the START II agreement, however the START II agreement was never activated, and neither Russia nor the USA has adhered to the agreement.
Destabilizing role of missile defense.
Any defense system against nuclear missiles such as SDI will be more effective against limited numbers of missiles launched. At very small numbers of targets, each defensive asset will be able to take multiple shots at each warhead, and a high kill ratio could be achieved easily. As the number of targets increases, the defensive network becomes "saturated" as each asset must target and destroy more and more warheads in the same window of time. Eventually the system will reach a maximum number of targets destroyed and after this point all additional warheads will penetrate the defenses. This leads to several destabilizing effects.
First, a state that is not building similar defenses may be encouraged to attack before the system is in place, essentially starting the war while there is no clear advantage instead of waiting until they will be at a distinct disadvantage after the defenses are completed. Second, one of the easiest ways to counter any proposed defenses is to simply build more warheads and missiles, reaching that saturation point sooner and hitting targets through a strategy of attrition. Third, and most importantly, since defenses are more effective against small numbers of warheads, a nation with a defense system is actually encouraged to engage in a counterforce first strike. The smaller retaliatory strike is then more easily destroyed by the defense system than a full attack would be. This undermines the doctrine of MAD by discrediting a nation's ability to punish any aggressor with a lethal retaliatory second strike.

</doc>
<doc id="45877" url="https://en.wikipedia.org/wiki?curid=45877" title="Sigmoid">
Sigmoid

Sigmoid means resembling the lower-case Greek letter sigma (ς) or the Latin letter S. Specific uses include:

</doc>
<doc id="45879" url="https://en.wikipedia.org/wiki?curid=45879" title="Line printer">
Line printer

The line printer is an impact printer that prints one entire line of text at a time. It is mostly associated with unit record equipment and the early days of digital computing, but the technology is still in use. Print speeds of 600 lines-per-minute (approximately 10 pages per minute) were achieved in the 1950s, later increasing to as much as 1200 lpm. Line printers print a complete line at a time and have speeds in the range of 150 to 2500 lines per minute. The different types of line printers are drum printers and chain printers. Other non-impact technologies have also been used, as thermal line printers were popular in the 1970s and 1980s, and some inkjet and laser printers produce output a line or a page at a time.
Designs.
Many impact printers, such as the daisywheel printer and dot matrix printer, used a print head that printed a character then moved on until an entire line was printed. Line printers were much faster, as each impact printed an entire line.
There have been five principal designs:
Drum printer.
In a typical drum printer design, a fixed font character set is engraved onto the periphery of a number of print wheels, the number matching the number of columns (letters in a line) the printer could print. The wheels, joined to form a large drum (cylinder), spin at high speed and paper and an inked ribbon is stepped (moved) past the print position. As the desired character for each column passes the print position, a hammer strikes the paper from the rear and presses the paper against the ribbon and the drum, causing the desired character to be recorded on the continuous paper. Because the drum carrying the letterforms (characters) remains in constant motion, the strike-and-retreat action of the hammers had to be very fast. Typically, they were driven by voice coils mounted on the moving part of the hammer.
Often the character sequences are staggered around the drum, shifting with each column. This obviates the situation whereby all of the hammers fire simultaneously when printing a line that consists of the same character in all columns, such as a complete line of dashes ("----").
Lower-cost printers did not use a hammer for each column. Instead, a hammer was provided for every other column and the entire hammer bank was arranged to shift left and right, driven by another one voice coil. For this style of printer, two complete revolutions of the character drum were required with one revolution being used to print all the "odd" columns and another revolution being used to print all of the "even" columns. But in this way, only half (plus one) the number of hammers, magnets, and the associated channels of drive electronics were required.
At least one low-cost printer, made by CDC, achieved the same end by moving the paper laterally while keeping the hammer bank at rest.
Dataproducts was a typical vendor of drum printers, often selling similar models with both a full set of hammers (and delivering, for example 600 lines-per-minute of output) and a half set of hammers (delivering 300 LPM).
Chain (train) printer.
Chain printers (also known as train printers) placed the type on moving bars (a horizontally-moving chain). As with the drum printer, as the correct character passed by each column, a hammer was fired from behind the paper. Compared to drum printers, chain printers had the advantage that the type chain could usually be changed by the operator. A further advantage was that vertical registration of characters in a line was much improved over drum printers, which needed extremely precise hammer timing to achieve a reasonably straight line of print. By selecting chains that had a smaller character set (for example, just numbers and a few punctuation marks), the printer could print much faster than if the chain contained the entire upper- and lower-case alphabet, numbers, and all special symbols. This was because, with many more instances of the numbers appearing in the chain, the time spent waiting for the correct character to "pass by" was greatly reduced. Common letters and symbols would appear more often on the chain, according to the frequency analysis of the likely input. It was also possible to play primitive tunes on these printers by timing the nonsense of the printout to the sequence on the chain, a rather primitive piano. IBM was probably the best-known chain printer manufacturer and the IBM 1403 is probably the most famous example of a chain printer.
Band printer.
Band printers are a variation of chain printers, where a thin steel band is used instead of a chain, with the characters embossed on the band. Again, a selection of different bands were generally available with a different mix of characters so a character set best matched to the characters commonly printed could be chosen. Dataproducts was a well known manufacturer of band printers, with their B300, B600, and B1000 range, the model number representing the lines per minute rate of the printer. (The B300 was effectively a B600 with only half the number of hammers—one per two character positions. The hammer bank moved back and forth one character position, requiring two goes to print all characters on each line.)
Bar printer.
Bar printers were similar to chain printers but were slower and less expensive. Rather than a chain moving continuously in one direction, the characters were on fingers mounted on a bar that moved left-to-right and then right-to-left in front of the paper. An example was the IBM 1443.
In all three designs, timing of the hammers (the so-called "flight time") was critical, and was adjustable as part of the servicing of the printer. For drum printers, incorrect timing of the hammer resulted in printed lines that wandered vertically, albeit with characters correctly aligned horizontally in their columns. For train and bar printers, incorrect timing of the hammers resulted in characters shifting horizontally, albeit on vertically-level printed lines.
Most drum, chain, and bar printers were capable of printing up to 132 columns, but a few designs could only print 80 columns and some other designs as many as 160 columns.
Comb printer.
Comb printers, also called line matrix printers, printed a matrix of dots instead of individual characters in the same way as single-character dot matrix printers, but using a comb of hammers to print a portion of an entire row of pixels at one time (for example, every eighth pixel). By shifting the comb back and forth slightly, the entire pixel row could be printed (continuing the example, in eight cycles). The paper then advanced and the next pixel row was printed. Because far less print head motion was involved than in a conventional dot matrix printer, these printers were much faster, and competitive in speed with formed-character line printers without being restricted to a set of available characters, thus being able to print dot-matrix graphics and variable-sized characters.
Printronix and TallyGenicom are well-known vendors of comb printers.
Because all of these printing methods were noisy, line printers of all designs were enclosed in sound-absorbing cases of varying sophistication.
Wheel printers.
In 1949 IBM introduced the IBM 407 Accounting Machine with a wheel print mechanism that could print 150 alphanumeric lines a minute. Each of the 120 print positions had its own type wheel which rotated under electromechanical control. Once all were in position, print hammers struck the wheels against a ribbon and the paper. The 407 or its wheel line printer mechanism was attached to a variety of early IBM computers, including the IBM 650, most members of the IBM 700/7000 series and the IBM 1130, the last introduced in 1965.
Paper (forms) handling.
All line printers used continuous form paper provided in boxes of continuous fan-fold forms rather than cut-sheets. The paper was usually perforated to tear into cut sheets if desired and was commonly printed with alternating white and light-green areas, allowing the reader to easily follow a line of text across the page. This was the iconic "green bar" or "music-ruled" form that dominated the early computer age. Pre-printed forms were also commonly used (for printing cheques, invoices, etc.). A common task for the system operator was to change from one paper form to another as one print job completed and another was to begin. Some line printers had covers that opened automatically when the printer required attention.
Standard "green bar" page sizes included portrait-format pages of 8½ × 11 inches, usually printed at 80 columns by 66 lines (at 6 lines per inch) or 88 lines (at 8 LPI), and landscape-format pages of 14 × 11 inches, usually printed at 132 columns by 66 or 88 lines. Also common were landscape-format pages of 14 × 8½ inches, allowing for 132 columns by 66 lines (at 8 LPI) on a more compact page.
These continuous forms were advanced through the printer by means of "tractors" (sprockets or sprocket belts). Depending on the sophistication of the printer, there might simply be two tractors at the top of the printer (pulling the paper) or tractors at the top and bottom (thereby maintaining paper tension within the printer). The horizontal position of the tractors was usually adjustable to accommodate different forms. The earliest printers by IBM used a hydraulic motor to move the forms. In later line printers, High-speed servomechanisms usually drove the tractors, allowing very rapid positioning of the paper, both for advancing line-by-line and slewing to the top of the next form. The faster line printers, of necessity, also used "stackers" to re-fold and stack the fan-fold forms as they emerged from the printer.
The high-speed motion of the paper often developed large electrostatic charges. Line printers frequently used a variety of discharge brushes and active (corona discharge-based) static eliminators to discharge these accumulated charges.
Many printers supported ASA carriage control characters which provided a limited degree of control over the paper, by specifying how far to advance the paper between printed lines. Various means of providing vertical tabulation were provided, ranging from a paper carriage control tape loop to fully electronic (software-controllable) tab simulation.
Origins.
Tabulators built by the U.S. Census Bureau for the 1910 census could print their results. Prior to that, tabulator operators had to write down totals from counter wheels onto tally sheets. IBM developed a series of printing accounting machines, beginning in 1920. The 285 Numeric Printing Tabulator could read 150 cards per minute. The 405, introduced in 1934, could print at 80 lines per minute. It had 88 type bars, one for each print position, with 43 alphanumeric bars on the left, followed by 45 numeric-only bars. The IBM 402 series, introduced after World War II, had a similar print arrangement and was used by IBM in early computing devices, including the IBM Card-Programmed Electronic Calculator.
An early drum printer was the "Potter Flying Typewriter", in 1952. "Instead of working laboriously, one character at a time, it prints whole lines at once, 300 lines per minute, on a paper band. ... Heart of the machine is a continuously spinning disk with the necessary letters and numbers on its rim. ... As the disk revolves, 80 electrically operated hammers tap the back of the paper against an inked ribbon in contact with the disk, thus printing the proper characters in the proper places on the line." 
Current applications.
While the limited character set, fixed character spacing, and relatively poor print quality make impact line printers unsuitable for correspondence, books, and other applications requiring high print quality, the technology is cost-effective and remains in limited use in a number of applications such as printing box labels, medium volume accounting and other large business applications.
The names of the codice_1 and codice_2 commands in Unix were derived from the term "line printer". Analogously, many other systems call their printing devices "LP", "LPT", or some similar variant, whether these devices are in fact line printers or other types of printers. These references served to distinguish formatted final output from normal interactive output from the system, which in many cases in line printer days was also printed on paper (as by a teletype) but not by a line printer. Line printers printed characters, letters and numbers line by line.

</doc>
<doc id="45882" url="https://en.wikipedia.org/wiki?curid=45882" title="Trento">
Trento

Trento or (anglicized as Trent; local dialects: "Trènt"; ) is a city located in the Adige River valley in Trentino-Alto Adige/Südtirol in Italy. It is the capital of Trentino. In the 16th century, the city was the location of the Council of Trent. Formerly part of Austria, it was annexed by Italy in 1919.
Trento is an educational, scientific, financial and political centre in Trentino-Alto Adige/Südtirol, in Tyrol and Northern Italy in general. The University of Trento ranks highly out of Italy's top 30 colleges, coming 1st in the Italian Ministry of Education, Universities and Research ranking, 2nd according to Census ranking and 5th in the "Il Sole 24 Ore" ranking of Italian universities. The city contains a picturesque Medieval and Renaissance historic centre, with ancient buildings such as Trento Cathedral and the Castello del Buonconsiglio.
Together with other Alpine towns Trento engages in the Alpine Town of the Year Association for the implementation of the Alpine Convention to achieve sustainable development in the Alpine Arc. 
Trento was awarded Alpine Town of the Year 2004.
Modern-day Trento is a cosmopolitan city, with highly developed and organized modern social services. The city often ranks extremely highly out of all 103 Italian cities for quality of life, standard of living, and business and job opportunities, coming 1st, 6th and 2nd respectively. Trento is also one of the nation's wealthiest and most prosperous, with its province being one of the richest in Italy, although poorer than its neighbours Lombardy and South Tyrol, with a GDP per capita of €29,500 and a GDP (nominal) of €14.878 billion.
Geography.
The township of Trento encompasses the town centre as well as many suburbs of extremely varied geographical and population conditions (from the industrial suburb of Gardolo, just north of the city, to tiny mountain hamlets on Monte Bondone). Various distinctive suburbs still retain their traditional identity of rural or mountain villages.
Trento lies in a wide glacial valley called the Adige valley just south of the Alps foothill range Dolomite Mountains, where the Fersina River and Avisio rivers join the Adige River (the second longest river in Italy). River Adige is one of the three main south-flowing Alpine rivers; its broadly curving course alongside Trento was straightened in 1850. The valley is surrounded by mountains, including Vigolana (), Monte Bondone (), Paganella (), Marzola () and Monte Calisio (). Nearby lakes include Lake Caldonazzo, Lake Levico, Lake Garda and Lake Toblino.
History.
The origins of this city on the river track to Bolzano and the low Alpine passes of Brenner and the Reschen Pass over the Alps are disputed. Some scholars maintain it was a Rhaetian settlement: the Adige area was however influenced by neighbouring populations, including the (Adriatic) Veneti, the Etruscans and the Gauls (a Celtic people). According to other theories, the latter did instead found the city during the fourth century BC.
Trento was conquered by the Romans in the late 1st century BC, after several clashes with the Rhaetian tribes. Before the Romans, Trent was a Celtic village. In reality, the name derives from "Trent", which is a tribute to the Celtic god of the waters (because of the river Adige). The Romans gave their settlement the name "Tridentum" and is a tribute to the Roman god Neptune (Tri Dentum, meaning 'Three Teeth' because of the three hills that surround the city: the "Doss Trent", "Sant'Agata" and "San Rocco"). The Latin name is the source of the adjective Tridentine. On the old townhall a Latin inscription is still visible: "Montes argentum mihi dant nomenque Tridentum" ("Mountains give me silver and the name of Trento"), attributed to Fra' Bartolomeo da Trento (died in 1251). Tridentum became an important stop on the Roman road that led from Verona to Innsbruck.
After the fall of the Western Roman Empire, the independent bishopric of Trento was ruled by Ostrogoths, Byzantines, Lombards and Franks, finally becoming part of the Holy Roman Empire. In 1027, Emperor Conrad II created the Prince-Bishops of Trento, who wielded both temporal and religious powers. In the following centuries, however, the sovereignty was divided between the Bishopric of Trent and the County of Tyrol (from 1363 part of the Habsburg monarchy). Around 1200, Trento became a mining center of some significance: silver was mined from the Monte Calisio - Khalisperg, and Prince-Bishop Federico Wanga issued the first mining code of the alpine region.
In the 14th century, the region of Trent was part of the Austrian rule. The dukes of Austria (Habsburg Family) were also the counts of Tyrol and dominated the region for six centuries (1918).
A dark episode in the history of Trento was the Trent blood libel. When a three-year-old Christian boy, Simonino, later known as Simon of Trent, disappeared in 1475 on the eve of Good Friday, the city's small Jewish community was accused of killing him and draining his blood for Jewish ritual purposes. Eight Jews were tortured and burned at the stake, and their families forced to convert to Christianity. The bishop of Trent, Johannes Hinderbach, had Simonino canonized and published the first book printed in Trent, "Story of a Christian Child Murdered at Trent," embellished with 12 woodcuts. In a governmental ceremony in the 1990s, Trent apologized to the Jewish community for this dark episode and unveiled a plaque commemorating the formal apology.
In the 16th century Trento became notable for the Council of Trent (1545–1563) which gave rise to the Counter-Reformation. The adjective "Tridentine" (as in "Tridentine Mass") literally means pertaining to Trento, but can also refer to that specific event. Among the notable prince bishops of this time were Bernardo Clesio (who ruled the city 1514-1539, and managed to steer the Council to Trento) and Cristoforo Madruzzo (who ruled in 1539-1567), both able European politicians and Renaissance humanists, who greatly expanded and embellished the city.
During this period, and as an expression of this Humanism, Trento was also known as the site of a Jewish printing press. In 1558 Cardinal Madruzzo granted the privilege of printing Hebrew books to Joseph Ottolengo, a German rabbi. The actual printer was Jacob Marcaria, a local physician; after his death in 1562 the activity of the press of Riva di Trento ceased. Altogether thirty-four works were published in the period 1558 to 1562, most of them bearing the coat of arms of Madruzzo.
Prince-bishops ruled Trento until the Napoleonic era, when it bounced around among various states. Under the reorganization of the Holy Roman Empire in 1802, the Bishopric was secularized and annexed to the Habsburg territories. The Treaty of Pressburg in 1805 ceded Trent to Bavaria, and the Treaty of Schönbrunn four years later gave it to Napoleon's Kingdom of Italy.
The population resisted French domination with gunfights. The resistance leader was Andreas Hofer. During his youth he lived in the Italian Tyrol, where he learned the Italian language. When Hofer recovered Trento for the Austrians (1809), he was welcomed with enthusiasm by the population of Trento. Approximately 4.000 Trentinian volunteers ("Sìzzeri" or "Schützen") died in battle against the French and Bavarian troops. In 1810 Hofer was captured and brought to Mantua, and was shot by French soldiers on the express order of Napoleon.
With Napoleon's defeat in 1814, Trento was again annexed by the Habsburg Empire. The church government was finally extinguished, Trento now being governed by the secular government of Tyrol. In the next decades Trento experienced a modernization of administration and economy with the first railroad in the Adige valley opening in 1859.
During the late 19th century, Trento and Trieste, cities with ethnic Italian majorities still belonging to the Austrians, became icons of the Italian irredentist movement. Benito Mussolini briefly joined the staff of a local newspaper in 1909, but left Trent because they could not create an anti-Austrian group.
The nationalist cause led Italy into World War I. Damiano Chiesa and the deputy in the Austrian parliament Cesare Battisti were two well-known local irredentists who had joined the Italian army to fight against Austria-Hungary with the aim of bringing the territory of Trento into the new Kingdom of Italy. The two men were taken prisoners at the nearby southern front. They were put on trial for high treason and executed in the courtyard of Castello del Buonconsiglio.
The region was greatly affected during the war, and some of its fiercest battles were fought on the surrounding mountains. After World War I, Trento and its Italian-speaking province, along with Bolzano (Bozen) and the part of Tyrol that stretched south of the Alpine watershed (which was, in the main, German speaking), were annexed by Italy.
In 1943, Mussolini was deposed and Italy surrendered to the Allies, who had invaded southern Italy via Sicily. German troops promptly invaded northern Italy and the provinces of Trento, Belluno and South Tyrol became part of the Operation Zone of the Alpine Foothills, annexed to Greater Germany. Some German-speakers wanted revenge upon Italian-speakers living in the area, but were mostly prevented by the occupying Nazis, who still considered Mussolini head of the Italian Social Republic and wanted to preserve good relations with the Fascists. From November 1944 to April 1945, Trento was bombed as part of the so-called "Battle of the Brenner." War supplies from Germany to support the Gothic Line were for the most part routed through the rail line through the Brenner pass. Over 6,849 sorties were flown over targets from Verona to the Brenner Pass with 10,267 tons of bombs dropped. Parts of the city were hit by the Allied bombings, including the church of S. Maria Maggiore, the Church of the Annunciation and several bridges over the Adige river. In spite of the bombings, most of the medieval and renaissance town center was spared. It was finally liberated on 3 May 1945.
In 1947 Trento became the host of the Rally Stella Alpina.
Starting from the 1950s the region has enjoyed prosperous growth, thanks in part to its special autonomy from the central Italian government.
On 4 August 2015 the cathedral tower caught fire by 'spontaneous combustion'. The clock stopped at 10:50am just a few minutes after the fire started.
Society and economy.
The city owes much of its unique economy to its position along the main communication route between Italy and Northern Europe and to the Adige river which prior to its diversion in the mid-19th century ran through the center of the city. The Adige river was formerly a navigable river and one of the main commercial routes in the Alps. The original course of the river is now covered by the Via Torre Vanga, Via Torre Verde and the Via Alessandro Manzoni.
As late as the Second World War, Trento depended on wine-making and silk. The manufacturing industry installed in the post-war period has been mostly dismantled. Today Trento thrives on commerce, services, tourism, high-quality agriculture and food industry (including wine, fruit), as a research and conference center thanks to a small but renowned university 
and internationally renowned research centers such as Fondazione Bruno Kessler active in both fundamental and applied research, the [http://isig.fbk.eu/it/home Italian-German Historical Institute, the Centre for Computational and Systems Biology and ECT* [http://www.ectstar.eu, active in theoretical nuclear studies and part of FBK, and as logistics and transportation thoroughfare.
Valued pink and white porphyry is still excavated from some surrounding areas (Pila). This stone can be seen in many of Trento's buildings, both new and old.
The city has two long-running annual sporting events: the Giro al Sas (a professional road running competition) was first held in the city in 1907 and continues to the present, while the Giro del Trentino is an annual road cycling race which the city has hosted every year since 1963.
Politics.
The administrative elections of May 3, 2009 were won by a center-left coalition. Results are the following (only parties with more than 4% are listed):
Current mayor is Alessandro Andreatta, of the Partito Democratico, elected with 64.42% of the votes.
Main sights.
Although off the beaten path of mass tourism, Trento offers rather interesting monuments. Its architecture has a unique feel, with both Italian Renaissance and Germanic influences. The city center is small, and most Late-Medieval and Renaissance buildings have been restored to their original pastel colours and wooden balconies. Part of the medieval city walls is still visible in Piazza Fiera, along with a circular tower. Once, these walls encircled the whole town and were connected to the Castello del Buonconsiglio.
The main monuments of the city include:
Trento also sports modernist architecture, including the train station and the central post office, both by rationalist architect Angiolo Mazzoni. In particular, the train station (1934–36) is considered a landmark building of Italian railways architecture and combines many varieties of local stone with the most advanced building materials of the time: glass, reinforced concrete, metal. The post office was once decorated with colored windows by Fortunato Depero, but these were destroyed during bombings in World War II. Other buildings of that time include the Grand Hotel (by G. Lorenzi) with some guest rooms furnished with futurist furniture by Depero, and the "R. Sanzio" Primary School built in 1931–34 and designed by Adalberto Libera.
An aeronautical museum ("Museo dell'Aeronautica Gianni Caproni") is located in Mattarello, near Trento Airport.
The "Museo Tridentino di Scienze Naturali" (Trent Museum of Natural Sciences), a museum of natural history and science, is located in the city center.
Trento's surroundings are known for the mountain landscapes, and are the destination of both summer and winter tourism.
The Alpine Botanical Garden, located on Monte Bondone in "Le Viote", was founded in 1938. Trento is also the venue of a Mountain Film Festival
Notable natives.
In addition to the aforementioned Bernardo Clesio and Cristoforo Madruzzo, Giacomo Aconzio was born in Trento. Kurt von Schuschnigg was born in Riva del Garda, in the Trentino region. Other notable natives of Trento include:
Transport.
The A22-E45 highway connects Trento to Verona and to Bolzano, Innsbruck and Munich.
Trento railway station, opened in 1859, forms part of the Brenner railway (Verona–Innsbruck), which is the main rail connection between Italy and Germany. The station is also a junction with the Valsugana railway, which connects Trento to Venice. Trento has several other railway stations, including Trento FTM railway station, terminus of the Trento-Malè-Marilleva railway (FTM).
Bus or train services operate to the main surrounding valleys: Fassa, Fiemme, Gudicarie, Non, Primiero, Rendena, Sole, Tesino, Valsugana.
The public transport network within the city consists of 20 bus lines operated by Trentino Trasporti and a funicular service to Sardagna. The various railway stations within Trento's city limits are integrated into the public transport network.
Demographics.
In 2007, there were 112,637 people residing in Trento, of whom 48% were male and 52% were female. Minors (children ages 18 and younger) totalled 18.01 percent of the population compared to pensioners who number 19.37 percent. This compares with the Italian average of 18.06 percent (minors) and 19.94 percent (pensioners). The average age of Trento residents is 41 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Trento grew by 5.72 percent, while Italy as a whole grew by 3.56 percent. The current birth rate of Trento is 9.61 births per 1,000 inhabitants compared to the Italian average of 9.45 births.
, 92.68% of the population was Italian. The largest immigrant group came from other European countries (mostly Albania, Romania): 4.13%, North Africa: 1.08%, and the Americas: 0.85%.
Trento Informa (a magazine distributed by the "comune") reports that in 2011 there were 117,190 people residing in Trento, of whom 48.5% aged between 45 and 65. The average age was 43.1 years. 13,535 (11.5%) were foreigners.
International relations.
Twin towns - Sister cities.
Trento is twinned with:
Districts of Trento are twinned with:
"Frazioni".
Frazioni or subdivisions of Trento:

</doc>
<doc id="45883" url="https://en.wikipedia.org/wiki?curid=45883" title="Cathedral">
Cathedral

A cathedral (French: "cathédrale" from Latin: "cathedra", "seat" from the Greek "kathedra" (καθέδρα), seat, bench, from "kata" "down" + "hedra" seat, base, chair) is a Christian church which contains the seat of a bishop, thus serving as the central church of a diocese, conference, or episcopate. The counterpart term for such a church in German is "Dom" from Latin "domus ecclesiae" or "domus episcopalis"; also Italian Duomo, Dutch "Domkerk" and cognates in many other European languages. Churches with the function of "cathedral" are usually specific to those Christian denominations with an episcopal hierarchy, such as the Roman Catholic, Anglican, Orthodox, and some Lutheran and Methodist churches. Church buildings embodying the functions of a cathedral first appear in Italy, Gaul, Spain and North Africa in the 4th century, but cathedrals did not become universal within the Western Catholic Church until the 12th century, by which time they had developed architectural forms, institutional structures and legal identities distinct from parish churches, monastic churches and episcopal residences.
In respect of the church buildings in the Greek Orthodox Church and Russian Orthodox Church, the English word "cathedral" commonly translates "katholikon" and "sobor" respectively, both terms having a meaning of "assembly"; but this title is also applied to monastic and other major churches without episcopal responsibilities. When the church at which an archbishop or "metropolitan" presides is specifically intended, the term "kathedrikos naos" (literally: "cathedral church") is used.
Following the Protestant Reformation, the Christian church in several parts of Western Europe, such as Scotland, the Netherlands, certain Swiss Cantons and parts of Germany, adopted a Presbyterian polity that did away with bishops altogether. Where ancient cathedral buildings in these lands are still in use for congregational worship, they generally retain the title and dignity of "cathedral", maintaining and developing distinct cathedral functions, but void of hierarchical supremacy. From the 16th century onwards, but especially since the 19th century, churches originating in Western Europe have undertaken vigorous programmes of missionary activity, leading to the founding of large numbers of new dioceses with associated cathedral establishments of varying forms in Asia, Africa, Australasia, Oceania and the Americas. In addition, both the Catholic Church and Orthodox churches have formed new dioceses within formerly Protestant lands for converts and migrant co-religionists. Consequently, it is not uncommon to find Christians in a single city being served by three or more cathedrals of differing denominations.
Where a parish church serves temporarily as the cathedral of a diocese, this is termed a pro-cathedral. The cathedral church of a metropolitan bishop is termed a "metropolitan cathedral".
As cathedrals are often particularly impressive edifices, the term "cathedral" is often applied colloquially to any large and impressive church, regardless of whether it functions as a cathedral, such as the Crystal Cathedral in California or the Arctic Cathedral in Tromsø, Norway. The Crystal Cathedral was purchased by the Catholic Church (Roman Catholic Diocese of Orange) in February 2012; it will be converted into a genuine cathedral and renamed "Christ Cathedral".
Definition.
The word cathedral is derived from the Greek word cathedra ("seat" or "chair"), and refers to the presence and prominence of the bishop's or archbishop's chair or throne, raised above both clergy and laity, and originally located facing the congregation from behind the High Altar. In the ancient world the chair, on a raised dais, was the distinctive mark of a teacher or rhetor and thus symbolises the bishop's role as teacher. A raised throne within a basilican hall was also definitive for a Late Antique presiding magistrate; and so the "cathedra" also symbolises the bishop's role in governing his diocese.
The episcopal throne embodies the principle that only a bishop makes a cathedral, and this still applies even in those churches that no longer have bishops, but retain cathedral dignity and functions in ancient churches over which bishops formerly presided. But the throne can also embody the principle that a cathedral makes a bishop; both specifically, in that the bishop is elected within the cathedral and is inaugurated by being enthroned within the cathedral by acclamation of clergy and laity; and also generally, in that the bishops' essential qualifications of regular prayer, higher learning and musical worship were for many centuries, primarily accessible through cathedral functions. In this there is a distinction between those church traditions, predominantly those of Eastern Orthodox Christianity but formerly also including Celtic churches in Ireland, Scotland and Wales, whose bishops came to be made in monasteries; and those church traditions whose bishops have tended predominantly to arise through the ranks of cathedral clergy.
History and organization.
Origins and characteristics of the first cathedrals.
The history of cathedrals starts in the year 313, when the emperor Constantine the Great personally adopted Christianity and initiated the Peace of the Church. Indeed, in strict terminology, there could not have been "cathedrals" before that date, as before the 4th century there were no Christian "cathedrae"; bishops were never seated when leading congregational worship, but instead presided standing on a raised platform or "pulpitum". In the third century, the phrase "ascending the platform", "ad pulpitum venire", becomes the standard term for Christian ordination. During the siege of Dura Europos in 256, a complete Christian house church, or "domus ecclesiae" was entombed in a defensive bank, surviving when excavated, in places to wall-top height. The Dura church had been converted out of a large urban courtyard house of standard form, in which two rooms had been knocked together to make an assembly hall, capable of holding 60-75 standing; while a tank had been inserted in a room on the opposite side of the courtyard as a baptistery, with rich wall paintings above it. The large room was indeed found to have a raised pulptum at one end, big enough for one person in turn to read, preach and preside from; but too low to have been surmounted by a throne, and too small to have contained an altar. Otherwise the large room had no decoration or distinctive features at all.
In 269, soon after Dura fell to the Persian army, a body of clerics assembled a charge sheet against the bishop of Antioch, Paul of Samosata, in the form of an open letter. Amongst the accusations was that Paul, who had received the civil rank of "ducenarius" due to contacts in the imperial court, had improperly erected an enclosure, or "secretum", for himself in the church of Antioch; that within this enclosure he had erected a throne from which he presided in worship; and that he had trained a female choir to sing hymns of his own devising. These practices were all condemned as innovations, improperly importing the symbols of his secular Roman magistracy into church ritual; while presumptuously and blasphemously asserting that the person of the bishop in eucharistic worship is seated in the place of Christ himself. Still in a hundred years, all bishops in the Mediterranean world had cathedrals, all sat on thrones within an enclosed sanctuary space, and all had established trained choirs to enhance eucharistic worship.
The driving principle underlying this change was the acceptance by bishops, more or less willingly, of an imperial invitation to adopt and maintain the duties, dignity and insignia proper to a public magistrate. Characteristically a Roman magistrate presided from a raised throne in a large, richly decorated and aisled rectangular hall called a "basilica"; and now bishops would do the same. The earliest of these new basilican cathedrals of which substantial remains are still visible (and maybe amongst the very earliest to be built) is below the Cathedral of Aquileia on the northern tip of the Adriatic sea. Dated from a mosaic inscription between 313 and 319, the complex consisted of two parallel east-west aisled halls of similar size; with a third smaller north-south cross-hall connecting them, which has been interpreted as the presence hall of the "episcopium" or bishop's residence. The three halls create an open courtyard, in which was originally located a separate baptistery. Surviving from both large basilican halls are rich mosaic pavements showing (amongst other scenes) Jonah and the Whale, and a series of, mainly female, donor portraits. It appears that similar cathedrals of double-basilica and baptistry were soon afterwards erected in Milan, Trier and Pavia; but that subsequently single-basilican churches became the more common cathedral model.
Constantine's declaration of imperial favour towards Christianity transformed all aspects of Christian life in the Roman Empire. From being a minority religion, largely confined to urban areas and restricted social groupings, and subject to official hostility and occasional persecution; Christianity acquired greatly expanded numbers of potential adherents of all classes, initially still within city areas, but eventually extending out to the "pagus", the city's rural hinterland. The consequence was a radical expansion in the buildings, funding and personnel of associated Church establishments throughout the 4th century. The first cathedrals represent this expansion in material form.
Buildings.
The location and layout of the first cathedrals varied substantially from city to city, although most, as at Aquileia, tended to be sited within the city walls but away from the urban centre; but certain elements are almost always found.
Basilicas.
Basilican halls had previously been characteristic of major civic complexes and military headquarters buildings; but now became the standard structure for accommodating large Christian congregations. From now on, the term basilica denotes any substantial church building. These new basilicas were wholly different in scale from earlier Christian assembly halls, as they were also different in form from any Roman non-Christian temple or religious structure. The halls were longitudinal, aisled, and flooded with light from large clerestory windows. Floors and walls were richly decorated with mosaic and inlay – usually in abstract or floral patterns. The two original double basilicas at Aquileia had both been about 37m by 17m in size, but within 30 years one hall was quadrupled to 73m by 31m. This expanded basilica now demonstrated three additional features that became characteristic of early cathedrals; an enclosure at the eastern end of the church surrounding the altar; a "synthronos" east of the altar facing west, and consisting of a raised dais with a centrally place bishop's throne and benches either side for the clergy of his "familia"; and a paritioned off "narthex" at the western end into which "catechumens" would withdraw during the central act of the Eucharistic liturgy.
Baptisteries.
The baptistery in the Dura church was about 1m square and 1m deep; baptismal candidates could stand in it, but could not be immersed. In the new cathedrals, as had been the case before, only bishops baptised; and ceremonies were held not more than twice a year to allow for suitable periods of instruction. So baptisteries needed to be greatly increased in size, with associated accommodation to ensure privacy in undressing, anointing and redressing; and the baptismal tank, commonly octagonal, was now fully deep enough for total immersion, and wide enough to accommodate both the candidate and an assisting male or female deacon. Baptisteries commonly adopted centralised plan forms derived from funerary chapels; and are invariably separate from the congregational basilica.
Episcopium.
No one lived in the house church at Dura; such residential facilities as the latrine and kitchen were removed in the conversion. But cathedral complexes always included an episcopal residence. Prominent amongst the charges that had been directed against Paul of Samosata had been his alleged over-familiarity with pious women. As was common, Paul had been married when elected bishop; and again, as was universally expected for a bishop, he had then ceased sexual contact with his wife and no longer cohabited with her. But his accusers charged that, by continuing to associate with other women (even without any indication of actual impropriety) he was creating an unacceptable potential for scandal. To avoid similar such occasions arising, it was necessary for the new cathedrals to create male-only living quarters for the bishop and his entire establishment; and since, in churches in the West, all presbyters and deacons were also expected to live apart from their wives after ordination, these living quarters, the "episcopium", were necessarily substantial in extent. In addition to eating and sleeping quarters for ordained boys and men, the episcopium also commonly provided private dining halls for the hospitality expected of the bishop's enhanced social status, a private oratory or chapel for the bishop, and often a bath house.
Finances.
Just as the episcopal residence was integral within the complex of cathedral buildings, so too there was no distinction between episcopal, diocesan and cathedral property and endowments. In principle, all diocesan income was paid into a common fund, and divided into four fixed shares for each main area of expenditure; the Bishop himself; the cathedral clergy; the fabric and lighting of cathedral and city churches; and charitable donations. Many diocese already held substantial endowments, but income increased enormously with the Peace of the Church; partly due to imperial subsidies in kind, but mainly from private bequests and regular private benefactions (often called 'first fruits'); although at this date, tithe was never paid to the church. In addition, many individual landowners supported private chapels and oratories on their own property; and endowed independent charitable institutions, and eventually monasteries and nunneries too.
Bishop's share.
Augustine of Hippo estimated his personal income as being 20 times that of his father, a minor civil servant; and Augustine was by no means the wealthiest bishop in North Africa. But in accepting from Constantine the status of civil magistrates, bishops were now also committed to substantial expenditure to maintain their new style and status; and also to fulfil the associated duties, for instance in employing qualified legal assessors to support them when sitting as civil judges.
Clergy share.
All ordained clerics attached to the cathedral, both male and female, were paid through stipends from the general fund. This applied both to the clergy working directly within the cathedral itself, and also to the clergy, called "canonici" attached to churches founded by the bishop within the city. From the end of the 4th century, as the mission of the church extended more into rural areas, 'baptistery churches' were founded in more distant villages, so that rural populations could receive the bishop's baptism locally; and the clergy in these churches also counted as "canonici" and drew a regular stipend.
Fabric share.
Plentiful donor inscriptions show that most new church building programmes; mosaics, roofs, furnishings, were financed by private donations. The costs of maintenance and lighting, however, fell on the general fund. This also applied to the churches, known as "tituli", served directly by the bishop's clergy, generally also including any surviving house churches from the period before the Peace of the Church and the rural baptistery churches; but not to the chapels, called "parochiae", established by rural landowners for the convenience of their tenants. The bishop, in respect of his civil status, was expected to contribute to public works of general benefit; aqueducts, bridges, watercourses.
Charitable share.
In all cities, bishops dedicated substantial sums to the support of widows, orphans and the poor. Such donations had been a strong feature of the church in earlier centuries, but tended then to be specifically directed to the Christian needy. Now the charitable compass became general. Bishops were especially expected to take responsibility for raising ransom funds, where local persons had fallen captive. In addition, it was expected that each diocese would support a "xenodochium", a hostel for the homeless and strangers.
Personnel.
Just as the status of the bishop was transfomed at the Peace of the Church; so too was that of the male clergy. With the bishop now resident in the "episcopium" the other male clergy came to be recognised as his formal "familia", in mark of which male clergy now received the tonsure by shaving of their heads; this being originally a Roman badge of adoption. The early church had recognised the orders of bishop, presbyter (priest) and deacon, but a range of minor orders had since grown up in addition; and all were tonsured. These orders now tended to be understood as clerical 'ranks', equivalent to those in the military, such that the male clergy are now often referred to as a "clerical militia". And as in the Roman military or civil service, promotion was expected to follow the pinciple of "cursus honorum", rising through the ranks, with the expectation that ideally, a minimum period would be served in each. The female orders of virgin, widow and (female) deacon remained explicitly outside the bishop's familia; and so they did not receive the tonsure and nor did they progress through the "cursus honorum". But all orders of cathedral clergy, male and female, increased dramatically in numbers. Around 540 Justinian ordered that the clerical payroll of Hagia Sophia should be strictly limited to 60 presbyters, 100 male deacons, 90 subdeacons, 110 lectors, 25 singers, 100 doorkeepers and 40 female deacons; 525 in all.
Bishops.
Bishops were at the head of the local church; but not explicitly within the "cursus honorum", as appointment was by election from the local clergy and people. Not surprisingly, the clergy tended to favour appointment of bishops from within the ranks of cathedral presbyters; but local lay choice often tended rather to outsiders, either a spectacular holy man, hermit or ascetic; or otherwise a senior civil servant or diplomat, who might have favourable contacts to exploit at court. But most bishops came from the "curial" class, that is those holding the hereditary rank of decurion with the obligation to serve on the city council, as only persons of this class and above would be likely to have a full rhetorical education in Greek and Latin grammar; without which it was not possible for a boy raised with a knowledge only of Late Antique vernacular speech to express himself in approved classical linguistic forms.
Presbyters and archpriests.
It was expected that the normal president at both the Eucharist and Baptism would be the bishop; who would celebrate in the cathedral and in titular churches in turn. But, in practice, the bishop needed deputies for eucharistic worship and also for the Divine Office of daily prayer, and this duty fell to the presbyters. The bishop selected a senior presbyter as archpriest who acted as his official deputy in all ritual matters and as head of the familia. The archpriest was also responsible for the cathedral school. After the 5th century, there were no longer state-supported secular teachers of rhetoric and grammar in the West (other than in parts of Italy) and so the church would have to educate its own.
Deacons, subdeacons and archdeacons.
Just as the presbyters deputised for the bishop in ritual matters, so the deacons deputised in administrative and financial matters, especially in the raising and delivering of charity. At the head of the diaconate was the archdeacon; the bishop's main deputy in managerial affairs. Originally inferior in rank to the archpriest, the archdeacon by the sixth century had established clear pre-eminence. Subdeacons assisted the deacons, but unlike them were allowed to marry after ordination; consequently many clerics stopped the cursus honorum at this point, and it was not unusual for a subdeacon to be elected bishop; and even Pope.
Doorkeepers, exorcists, lectors, acolytes and primicerius.
In practice, the first three of these orders tended to be given together, and were typically applied to boys as young as seven. These boy lectors were too young for the grammar school, but were valued as choristers, and so were included in the "Schola Cantorum" or choir school. Originally under the responsibility of the deacons, the organisation of choirs was reformed by Pope Gregory the Great, who introduced the office of "primicerius" or head cantor for this purpose. This proved a vital reform; as without any comprehensive system of musical notation, the only way that sacred music could be maintained and passed on was through professional choirs of sound musical training undertaking cathedral worship – and such skills are not guaranteed to be present in high-ranking ecclesiastics.
Women's orders: virgins, widows and deaconesses.
These orders had been of considerable importance in earlier centuries; but tended to be sidelined in cathedrals from the 4th century onwards. So long as adult baptism continued as a regular occurrence, female deacons would continue to be needed for that service; but otherwise the main factor maintaining these orders was a knock-on effect from the rule of continence applied to bishops, presbyters and deacons. When a man became ordained, and moved into the episcopium with the rest of the bishop's "familia"; then there would usually also be a requirement for support to their mothers, wives and daughters; and the orders of widows and virgins respectively continued largely for this purpose.
Functions.
Notwithstanding wide differences over time in institutional structures and wider historical contexts; the key functions established for the first cathedrals have tended to remain as distinctive cathedral functions down the centuries; a regular cycle of choral prayer; providing a forum for civic leadership; a commitment to higher learning; and the promotion and dissemination of music.
Rule of the clergy.
Early Middle Ages: religious communities.
The history of the body of clergy attached to the cathedral church is obscure, and in each case local considerations affected its development, however the main features were more or less common to all.
Originally the bishop and cathedral clergy formed a kind of religious community, which, while not in the true sense a monastery, was nevertheless often called a "monasterium", the word not having the restricted meaning which it afterwards acquired. In this lies the reason for the apparent anomaly that churches like York Minster and Lincoln Cathedral, which never had any monks attached to them, have inherited the name of minster or monastery. In these early communities the clergy often lived apart in their own dwellings, and were not infrequently married.
In the 8th century Chrodegang, Bishop of Metz (743-766), compiled a code of rules for the clergy of the cathedral churches, which, though widely accepted in Germany and other parts of the continent, gained little acceptance in England.
According to Chrodegang's rule, the cathedral clergy were to live under a common roof, occupy a common dormitory and submit to the authority of a special officer. The rule of Chrodegang was, in fact, a modification of the Benedictine rule. Gisa, a native of Lorraine, who was bishop of Wells from 1061 to 1088, introduced it into England, and imposed its observance on the clergy of his cathedral church, but it was not followed for long there, or elsewhere in England.
Late Middle Ages: monastic and secular cathedrals.
During the 10th and 11th centuries, the cathedral clergy became more definitely organised and were divided into two classes. One was that of a monastic establishment of some recognised order of monks, often the Benedictines, while the other class was that of a college of clergy, bound by no vows except those of their ordination, but governed by a code of statutes or canons: hence the name of "canon". In this way arose the distinction between the monastic and secular cathedral churches. Outside Great Britain, monastic cathedrals are known only at Monreale in Sicily and Downpatrick in Ireland.
In the case of monastic cathedral churches, the internal government was that of the religious order to which the chapter belonged and all the members kept perpetual residence.
The alternative of this was the cathedral ruled by a secular chapter; the dignities of provost, dean, precentor, chancellor, treasurer, etc., came into being for the regulation and good order of the church and its services, while the non-residence of the canons, rather than their perpetual residence, became the rule, and led to their duties being performed by a body of "vicars", who officiated for them at the services of the church.
Reformation.
Prior to the Reformation all cathedrals of Western Europe were of the Roman Catholic Church. In England, much of the structure of the monastic and cathedral system was reconstituted during the English Reformation. Although the cathedrals were retained by the now independent and established Church of England, the monastic cathedral chapters were dissolved by King Henry VIII and, with the exceptions of Bath and Coventry, were refounded by him as chapters of canons with a dean as the head and other clergy as minor canons.
In Germany and other parts of Europe, with the spread of the Lutheran Church, some ancient churches, like Nidaros Cathedral, Norway, and Lübeck Cathedral, Germany, became the seats of Protestant bishops, as in England. Many new churches were built which serve the regional administrative function of a cathedral. However, not all churches that function as the seat of a bishop are known as "cathedral", the custom varying from place to place, according to local tradition. Some are simply designated "church", as occurs at Budolfi Church, the Lutheran cathedral of Aalborg in Denmark.
Roles.
Provosts.
In most of Europe, the earliest head of a secular church seems to have been the provost ("praepositus", "probst", etc.), who was charged not only with the internal regulation of the church and oversight of the members of the chapter and control of the services, but was also the steward or seneschal of the lands and possessions of the church. The latter often mainly engaged his attention, to the neglect of his domestic and ecclesiastical duties, and complaints were soon raised that the provost was too much mixed in worldly affairs, and was too frequently absent from his spiritual duties.
This led, in many cases, to the institution of a new officer called the "dean", who had charge of that portion of the provost's duties which related to the internal discipline of the chapter and the services of the church.
In some cases, the office of provost was abolished, but in others it was continued: the provost, who was occasionally an archdeacon as well, remaining head of the chapter. This arrangement was most commonly followed in Germany. In England the provost was almost unknown. Bishop Gisa introduced a provost as head of the chapter of Wells Cathedral, but the office was afterwards subordinated to the other dignities and the provost became simply the steward of certain of the prebendal lands. The provost of the collegiate church of Beverley Minster was the most notable instance of such an officer in England, but at Beverley he was an external officer with authority in the government of the church, no stall in the choir and no vote in chapter.
In Germany and Scandinavia, and in a few of the cathedral churches in the south of France, the provost was the ordinary head of the cathedral chapter, but the office was not common elsewhere. As regards France, of 136 cathedral churches existing at the Revolution, 38 only, and those either on the borders of Germany or in the extreme south, had a provost as the head of the chapter. In others the provost existed as a subordinate officer. There were two provosts at Autun, and Lyon and Chartres had four each, all as subordinate officers.
Secular chapter.
The normal constitution of the chapter of a secular cathedral church comprised four dignitaries (there might be more), in addition to the canons. These are the dean, the precentor, the chancellor and the treasurer. These four dignitaries, occupying the four corner stalls in the choir, are called in many of the statutes the "quatuor majores personae" of the church.
Deans.
The role of dean (from "decanus") seems to have derived its designation from the Benedictine "dean" who had ten monks under his charge. The role of dean came into existence to supply the place of the provost in the internal management of the church and chapter. In England every secular cathedral church was headed by a dean who was originally elected by the chapter and confirmed in office by the bishop. The dean is president of the chapter, and within the cathedral has charge of the performance of the services, taking specified portions of them by statute on the principal festivals. The dean sits in the chief stall in the choir, which is usually at the west end of the south side.
Precentors.
Next to the dean (as a rule) is the precentor ("primicerius", "cantor", etc.), whose special duty is that of regulating the musical portion of the services. The precentor presides in the dean's absence, and occupies the corresponding stall on the north side, although there are exceptions to this rule, where, as at St Paul's, the archdeacon of the cathedral city ranks second and occupies what is usually the precentor's stall.
Chancellors.
The third dignitary is the chancellor ("scholasticus", "écoldtre", "capiscol", "magistral", etc.), who must not be confounded with the chancellor of the diocese. The chancellor of the cathedral church is charged with the oversight of its schools, ought to read divinity lectures, and superintend the lections in the choir and correct slovenly readers. The chancellor is often the secretary and librarian of the chapter. In the absence of the dean and precentor, the chancellor is president of the chapter, and within the cathedral is usually assigned the easternmost stall, on the dean's side of the choir.
Treasurers.
The fourth dignitary is the treasurer ("custo", "sacrisla", "cheficier") who is guardian of the fabric, and of all the furniture and ornaments of the church, and whose duty was to provide bread and wine for the Eucharist, and candles and incense. The treasurer also regulated such matters as the ringing of the bells. The treasurer's stall is opposite to that of the chancellor.
Other clergy.
In many cathedral churches are additional dignitaries, as the praelector, subdean, vice-chancellor, succentor-canonicorum, and others, whose roles came into existence to supply the places of the other absent dignitaries, for non-residence was the fatal blot of the secular churches, and in this they contrasted very badly with the monastic churches, where all the members were in continuous residence. Besides the dignitaries there were the ordinary canons, each of whom, as a rule, held a separate prebend or endowment, besides receiving his share of the common funds of the church.
For the most part the canons also speedily became non-resident, and this led to the distinction of residentiary and non-residentiary canons, till in most churches the number of resident canons became definitely limited in number, and the non-residentiary canons, who no longer shared in the common funds, became generally known as prebendaries only, although by their non-residence they did not forfeit their position as canons, and retained their votes in chapter like the others.
This system of non-residence led also to the institution of vicars choral, each canon having his own vicar, who sat in his stall in his absence, and when the canon was present, in the stall immediately below, on the second form. The vicars had no place or vote in chapter, and, though irremovable except for offences, were the servants of their absent canons whose stalls they occupied, and whose duties they performed. Outside Britain they were often called demi-prebendaries. As time went on the vicars were themselves often incorporated as a kind of lesser chapter, or college, under the supervision of the dean and chapter.
Relationship of chapter and bishop.
There was no distinction between the monastic cathedral chapters and those of the secular canons, in their relation to the bishop or diocese. In both cases the chapter was the bishop's consilium which he was bound to consult on all important matters and without doing so he could not act. Thus, a judicial decision of a bishop needed the confirmation of the chapter before it could be enforced. He could not change the service books, or "use" of the church or diocese, without capitular consent, and there are episcopal acts, such as the appointment of a diocesan chancellor, or vicar general, which still need confirmation by the chapter, but the older theory of the chapter as the bishop's council in ruling the diocese has become a thing of the past, in Europe.
In its corporate capacity the chapter takes charge sede vacante of a diocese. In England, however (except as regards Salisbury and Durham), this custom has never obtained, the two archbishops having, from time immemorial, taken charge of the vacant dioceses in their respective provinces. When, however, either of the sees of Canterbury or York is vacant the chapters of those churches take charge, not only of the diocese, but of the province as well, and incidentally, therefore, of any of the dioceses of the province which may be vacant at the same time.
Functions of a cathedral.
The role of the cathedral is chiefly to serve God in the community, through its hierarchical and organisational position in the church structure. The building itself, by its physical presence, symbolises both the glory of God and of the church. A cathedral, its bishop and dignitaries have traditional functions which are mostly religious in nature, but may also be closely associated with the civil and communal life of the city and region.
Symbolic functions of the building.
The cathedral is frequently the most imposing building, and one of the most ancient buildings in its town. The great size and splendor of the cathedral may be out of all proportion to the town itself. The money and talents expended on the building are seen as honoring God, and may also demonstrate both the devotion and the status of the patrons.
Cathedrals are very often oriented east/west, so that the worshipers look towards the rising sun, symbolizing the Risen Christ. The architectural form of the building most frequently has the ground plan of a cross. This form is both functional and symbolic, its symbolism referring to the cross on which Jesus was crucified. The form is liturgically functional as it allows the building to be divided into sections where different activities take place, or that are occupied by different people, such as the clergy, the choir and the laity.
The main body of the building, making the longer arm of the cross, is called the nave, and is where worshipers congregate; the term is from the Latin word for ship. The cathedral is symbolically a ship bearing the people of God through the storms of life. The nave is also used for major processions, which gather or enter at the furthest door (liturgically generally called the West Door). The aisles on each side of the nave facilitate the movement of people within the building, without disrupting worshipers in the central space.
The arms of the cross are called the transepts and often contain a number of chapels. Farthest from the main entry is the "sanctuary" where the Blessed Sacrament is laid on the altar or communion table for the consecration. "Sanctuary" means "Holy Place". The word has passed into modern English with an altered meaning because traditionally a criminal who could gain access to this area without capture was thereby given the sanctuary of the church.
Cathedral buildings of the Western European tradition symbolize the progression of the Christian soul towards Salvation. Many cathedrals of Eastern European tradition are centrally planned. These churches are almost always domed. The symbolism in these cathedral structures is of the hierarchy of Earth and Heaven, and often reveals its meaning through the internal decoration of the building with frescoes or mosaics.
Religious functions.
Apart from its organisational function as the seat of the bishop, and the meeting place for the chapter of the diocese, the cathedral has a liturgical function in offering daily church services. Most cathedrals have at least three services of worship every day, often taking the form of matins, Holy Communion and an evening service which is often sung by the precentor and choir. There are often additional services on Sunday. Cathedrals generally have an area dedicated to the performance of choral services and with seating specifically for the choir and dignitories of the church and town. This part of the building is called the Choir or Quire, and is generally located between the sanctuary and the nave. Because music often plays an important part in the performance of the liturgy, cathedrals generally have a pipe organ to accompany the choir.
Cathedrals always have a font or water basin at which the rite of Baptism is performed, in which a person is formally accepted into the Christian church. The font is often placed towards the door because the Baptism signifies entry into the community of the church. In some cathedrals, most particularly in Italy, the rite of Baptism is performed in a separate building.
One of the functions of the cathedral is the reading and expounding upon the Holy Scripture. The cathedral generally has a lectern from which the scripture is read. This often takes the form of an eagle of brass or carved wood which supports the book on its outstretched wings and is the symbol of John the Evangelist. However, some cathedrals retain elaborate medieval structures on either side of the church, one for the reading of the Gospel and the other for the reading of the Epistle.
The function of expounding on the scriptures is traditionally performed from the pulpit which is generally constructed in such a way that the voice of the preacher is projected out to the congregation. The pulpit is often decorated with the winged figures of a man, a lion, a bull and an eagle, representing the Gospel writers, Matthew, Mark, Luke and John.
The services that are held within the cathedral follow an annual cycle. The designated scriptural readings for each day of the church's year establish a pattern which alternates periods of introspection and penitence with periods of celebration, and is punctuated by the two great celebrations of Christmas and Easter.
Many cathedrals are places of pilgrimage to which people travel in order to worship or venerate a holy object or the reliquary of a saint. Many cathedrals are regarded as places that have provided rewarding religious experiences, where prayers have been answered or miracles have taken place. Pilgrimage was particularly popular in the late medieval period. Some cathedrals such as Santiago de Compostela continue to attract pilgrims.
Civic and social functions.
The formal cathedral services are linked to the cycle of the year and respond to the seasons of the Northern Hemisphere, Christmas falling in the winter and Easter in the spring. Cathedrals often hold a service of thanksgiving called Harvest Festival in the autumn.
Births, marriages and deaths are often celebrated by services at cathedrals and the cathedral often acts as a repository of local history by recording these events. The cathedral marks times of national and local civic celebration and sadness with special services. The funerals of those famous within the community are invariably held at cathedrals. People who have served the community or the church are often buried within the cathedral with which they are associated. Alternatively, they may be commemorated by a memorial. Some cathedrals, such as Aachen and Rheims are the traditional coronation places of monarchs.
Another civic function of the cathedral is the imparting of significant civil information. Announcements may be to the populace from the steps of the cathedral, or within the cathedral itself.
Most cathedrals have a bell or bells. These are used to announce that a service is soon to take place. They are also used to convey information and celebration. The ringing of peals signifies a time of rejoicing, such as a wedding. An extended ringing of peals or "changes" conveys a time of great civic celebration. The slow tolling of the deepest bell signifies a death or disaster. Many cathedrals have a clock with associated chimes which announce the time. The bells of a cathedral are traditionally used to signal the outbreak and the ending of war.
Cathedrals are often associated with significant secular organisations such as the office of the local mayor and council, the local court, the local regiment, schools, sporting organisations and service clubs. The cathedral often has its own school, primarily for the education of choristers, but often including other children as well.
The cathedral, often being a large building, serves as a meeting place for many people. The cathedral often forms a centre of different activities related to community service, youth activities, study, music and decorative arts.
Buildings.
Cathedral buildings, especially those dating from the Medieval period, are frequently the grandest of churches in the diocese (and country). The ancient cathedrals of England, of Northern France, Belgium, Spain, Portugal, Germany and Sicily, the Baroque cathedrals of South America, and many individual cathedrals from Italy and other parts of Europe, are among the largest and finest religious buildings. Many are renowned for their architecture or their decorative features such as sculpture, stained glass and frescos.
While cathedral buildings, in general, tend to be large, size and grandeur have rarely been essential requirements. Early Celtic and Saxon cathedrals tended to be of diminutive size, as is the Byzantine so-called "Little Metropole Cathedral" of Athens. In Italy, with a few notable exceptions such as Florence Cathedral and Milan Cathedral, cathedrals are numerous and are often similar in form and size to monastic or large parish churches. In modern times, where functionality is the foremost consideration, a cathedral church may be a modest structure.
Cathedrals of monastic foundation, and some of secular clergy have cloisters which traditionally provided an open area where secular activities took place protected from wind and rain. Some cathedrals also have a chapter house where the chapter could meet. In England, where these buildings have survived, they are often octagonal. A cathedral may front onto the main square of a town, as in Florence, or it may be set in a walled "close" as at Canterbury. There may be a number of associated monastic or clergy buildings, a bishop's palace and often a school to educate the choristers.
Artworks, treasures and tourism.
Many cathedral buildings are very famous for their architecture and have local and national significance, both artistically and historically. Many are listed among the UNESCO World Heritage Sites.
Many cathedrals, because of their large size and the fact that they often have towers, spires or domes, have until the 20th century, been the major landmarks in cities or in views across the countryside. With highrise building, civil action has been taken in some cases, such as the Cologne Cathedral to prevent the vista of the cathedral from being spoiled.
Because many cathedrals took centuries to build and decorate, they constitute a major artistic investment for the city in which they stand. Not only may the building itself be architecturally significant, but the church often houses treasures such as stained glass, stone and wood statues, historic tombs, richly carved furniture and objects of both artistic and religious significance such as reliquaries. Moreover, the cathedral often plays a major role in telling the story of the town, through its plaques, inscriptions, tombs, stained glass and paintings.
For these reasons, tourists have travelled to cathedrals for hundreds of years. Many cathedrals cater for tourists by charging a fee to any visitors outside service times or requesting a donation or making a charge to take photos. Cathedrals which are particularly popular tourist venues sometimes provide guides, leaflets, souvenirs and cafes.

</doc>
<doc id="45884" url="https://en.wikipedia.org/wiki?curid=45884" title="Leeuwarden">
Leeuwarden

Leeuwarden (, Stadsfries: "Liwwadden", Frisian: "Ljouwert", ) is a city in the Netherlands. It is the capital city of the province of Friesland and situated in the northern part of the country.
Etymology.
The name "Leeuwarden" (or older spelling variants) first came into use for Nijehove, the most important one of the three villages that later merged into one,namely Oldehove and Hoek in the early 9th century (Villa Lintarwrde c. 825).
There is much uncertainty about the origin of the city's name. Historian and archivist Wopke Eekhoff summed up a total of over 200 different spelling variants, of which "Leeuwarden" (Dutch), "Liwwadden" (Stadsfries) and "Ljouwert" (West Frisian) are still in use.
The second syllable is easily explained. "Warden", Frisian/Dutch for an artificial dwelling hill, is a designation of terps, reflecting the historical situation.
The first part of the name, "leeuw", means lion in modern standard Dutch. This interpretation corresponds with the coat of arms adopted by the city, which features a heraldic lion. However, modern standard Dutch was not used in this region in the Middle Ages, when the city was called "Lintarwrde". Some scholars argue that the name of the city is derived from "leeu-", a corruption of "luw-" (Dutch for sheltered from the wind, cf. the maritime term Leeward) or from "lee-" (a Dutch word for water circulation). The last one suits the watery province of Fryslân.
History.
The area has been occupied since the 10th century (although recently, remains of houses dating back to the 2nd century AD were discovered during a dig near the Oldehove), and was mentioned as a city in German sources in 1285. The actual city charter was granted in 1435. Situated along the Middelzee, it was an active trade centre, until the waterway silted up in the 15th century. In 1901 the city had a population of 32,203.
Famous natives of Leeuwarden include stadtholder William IV of Orange, graphic artist M. C. Escher, and dancer-spy Mata Hari, as well as the theologian Dr. N.H. Gootjes.
During World War II, after extensive occupation by the German forces, on 15 April 1945, the Royal Canadian Dragoons, disobeying direct orders, charged into the heavily defended city and defeated the Germans, who were driven out by the next day. The Royal Canadian Dragoons still fly the flag of the city of Leeuwarden wherever they are stationed.
On Saturday 19 October 2013, a fire broke out in a clothes shop on a busy pedestrian street. The fire started late in the afternoon and destroyed over 15 shops and flats. Everyone on the street was evacuated as the blaze damaged dozens of properties. A 24-year-old man who was living in one of the flats died because the fire was not under control until Sunday morning. Due to this the fire burnt all through the night. The man called the fire brigade, before collapsing because the services could not reach him. The birthplace of Mata Hari was destroyed. The firemen took 4 and a half hours to put out the fire.
Heraldry.
The coat of arms of Leeuwarden is the official symbol of the municipality of Leeuwarden. It consists of a blue escutcheon, a golden lion and a crown. The fact Leeuwarden carries a lion in its seal seems logical, considering that "Leeuw" is Dutch for "Lion". However, it is very plausible the oldest name of the city conceals an indication of water rather than an animal. Some sources tell the lion had been called into life after the name became official. It is also possible the coat of arms was a gift to the city from the powerful "Minnema" family.
Geography.
Population centres.
Leeuwarden consists of 19 population centres as of 1 January 2014 when parts of the former municipality of Boarnsterhim were added to Leeuwarden.
Culture.
Architecture.
Well-known buildings in the city centre include the "Kanselarij" (the former chancellery), the Stadhouderlijk hof, former residence of the stadtholders of Friesland, the "Waag" (old trade centre of the city), the Saint Boniface church and the leaning tower "Oldehove". The tallest building in the city is the 115 metre tall Achmeatoren (Achmea insurance tower).
Leeuwarden is also the site of the country's largest cattle market, and on Ascension Day, the largest flower market in the Netherlands is held here. The "Froskepôlemolen" is the last surviving windmill of over 130 known to have stood in Leeuwarden. The remains of the "Cammingha-Buurstermolen" were demolished in 2000. The bases of two other windmills, "Wielinga-Stam" and "De Haan" also survive.
Sport.
Leeuwarden is the starting and finishing point for the celebrated Elfstedentocht, a 200 km-long speed skating race over the Frisian waterways that is held when winter conditions in the province allow. As of 2015, it last took place in January 1997, preceded by the races of 1986 and 1985. In 1986 the Dutch king Willem-Alexander participated in the Eleven cities tour, with the pseudonym W.A. van Buren, which is the pseudonym of the royal family of The Netherlands. The city's local football team, Cambuur Leeuwarden plays in the Eredivisie. In the season 2005/06, the club narrowly escaped bankruptcy. Its "Cambuurstadion" opened in 1995. The football team has proposed plans for a new stadium in the east side of the city, which will cost €35 million. The city's basketball team, Aris Leeuwarden plays in the Dutch Basketball League since 2004.
European capital of Culture.
On September 6, 2013 Leeuwarden was voted European Capital of Culture for the year 2018.
Politics.
Leeuwarden, as capital of the province of Fryslân, is seat of the provincial authorities.
Sister cities.
Leeuwarden has a sister city:
Transport.
Train routes with starting number of the train number series:
There are also bus lines:
And there are citybuses. Most buslines are operated by Arriva and a few (line 10,13,14 and 320) are operated by Qbuzz
Education.
Leeuwarden has a number of respected universities of applied science (HBO in Dutch), such as the Van Hall Instituut (agricultural and life sciences), the Stenden University(hotel management, economical and media management) and the Noordelijke Hogeschool Leeuwarden (economical, technical and arts).
Although the city has no scientific university, several dependencies are located here, including those of the Wageningen University, Universiteit Twente and the Rijksuniversiteit Groningen. About 16,000 students, among them an increasing number of foreign students, study at technical schools. Besides higher education, the city is also home to three regional vocational schools ("MBO"): the "Friese Poort", "Friesland College" and Nordwin College.

</doc>
<doc id="45890" url="https://en.wikipedia.org/wiki?curid=45890" title="1260s BC">
1260s BC


</doc>
<doc id="45891" url="https://en.wikipedia.org/wiki?curid=45891" title="Fermat pseudoprime">
Fermat pseudoprime

In number theory, the Fermat pseudoprimes make up the most important class of pseudoprimes that come from Fermat's little theorem.
Definition.
Fermat's little theorem states that if "p" is prime and "a" is coprime to "p", then "a""p"−1 − 1 is divisible by "p". For an integer "a" > 1, if a composite integer "x" divides "a""x"−1 − 1, then "x" is called a Fermat pseudoprime to base "a". In other words, a composite integer is a Fermat pseudoprime to base "a" if it successfully passes the Fermat primality test for the base "a". It follows that if "x" is a Fermat pseudoprime to base "a", then "x" is coprime to "a".
The smallest base-2 Fermat pseudoprime is 341. It is not a prime, since it equals 11·31, but it satisfies Fermat's little theorem: 2340 ≡ 1 (mod 341) and thus passes the
Fermat primality test for the base 2.
Pseudoprimes to base 2 are sometimes called Poulet numbers, after the Belgian mathematician Paul Poulet, Sarrus numbers, or Fermatians .
A Fermat pseudoprime is often called a pseudoprime, with the modifier Fermat being understood.
An integer "x" that is a Fermat pseudoprime for all values of "a" that are coprime to "x" is called a Carmichael number.
Variations.
Some sources use variations of the definition, for example to only allow odd numbers to be pseudoprimes.
Every odd number "q" satisfies formula_1 for formula_2. This trivial case is excluded in the definition of a Fermat pseudoprime given by Crandall and Pomerance:
Properties.
Distribution.
There are infinitely many pseudoprimes to a given base (in fact, infinitely many strong pseudoprimes (see Theorem 1 of
and infinitely many Carmichael numbers
, but they are rather rare.
There are only three pseudoprimes to base 2 below 1000, 245 below one million, and only 21853 less than 25·109 (see Table 1 of ).
Starting at 17·257, the product of consecutive Fermat numbers is a base-2 pseudoprime, and so are all Fermat composite and Mersenne composite.
Factorizations.
The factorizations of the 60 Poulet numbers up to 60787, including 13 Carmichael numbers (in bold), are in the below table.
A Poulet number all of whose divisors "d" divide 2"d" − 2 is called a super-Poulet number. There are infinitely many Poulet numbers which are not super-Poulet Numbers.
Smallest Fermat pseudoprimes.
The smallest pseudoprime for each base "a" ≤ 200 is given in the following table; the colors mark the number of prime factors. Unlike in the definition at the start of the article, pseudoprimes below "a" are excluded in the table. (For that to allow pseudoprimes below "a", see )
First few Fermat pseudoprimes in base "a" (up to 10000).
For more information (base 31 to 100), see to , and for all bases up to 150, see table of Fermat pseudoprimes (text in German), this page does not define "n" is a pseudoprime to a base congruent to 1 or -1 (mod "n")
Which bases "b" make "n" a Fermat pseudoprime?
The following is a table about all base "b" < "n" which "n" is a Fermat pseudoprime (all composite number is a pseudoprime to base 1, and for "b" > "n", the solutions are just shifted by "k"*"n" for "k" > 0), if a composite number "n" is not listed in the table (or "n" is in the sequence ), then "n" is a pseudoprime only in base 1, or the bases which congruent to 1 (mod "n") (that is, the number of the values of "b" is 1), these "n"s are up to 200)
For more information ("n" = 201 to 5000), see, this page does not define "n" is a pseudoprime to a base congruent to 1 or -1 (mod "n"). Note that when "p" is a prime, "p"2 is a Fermat pseudoprime to base "b" if and only if "p" is a Wieferich prime to base "b". For example, 10932 = 1194649 is a Fermat pseudoprime to base 2, and 112 = 121 is a Fermat pseudoprime to base 3.
The number of the values of "b" for "n" are (For "n" prime, the number of the values of "b" must be "n" - 1, since all "b" satisfy the Fermat little theorem)
The least base "b" > 1 which "n" is a pseudoprime to base "b" (or prime number) are
The number of the values of "b" for "n" must divides formula_5("n"), or ("n") = 1, 1, 2, 2, 4, 2, 6, 4, 6, 4, 10, 4, 12, 6, 8, 8, 16, 6, 18, 8, 12, 10, 22, 8, 20, 12, 18, 12, 28, 8, 30, 16, 20, 16, 24, 12, 36, 18, 24, 16, 40, 12, 42, 20, 24, 22, 46, 16, 42, 20, ... (The quotient can be any natural number, and the quotient = 1 if and only if "n" is a prime or a Carmichael number (561, 1105, 1729, 2465, 2821, 6601, 8911, 10585, 15841, ... ), the quotient = 2 if and only if "n" is in the sequence: 4, 6, 15, 91, 703, 1891, 2701, 11305, 12403, 13981, 18721, ... )
The least number with "n" values of "b" are (or 0 if no such number exists)
Weak pseudoprimes.
A composite number "n" which satisfy that "bn" = "b" (mod "n") is called weak pseudoprime to base "b", the least weak pseudoprime to base "b" are
Note that all terms are less than or equal to the smallest Carmichael number, 561. Except for 561, only semiprimes can occur in the above sequence, but not all semiprimes less than 561 occur, a semiprime "pq" ("p" ≤ "q") less than 561 occurs in the above sequences if and only if "p" - 1 divides "q" - 1. (see )
If we require that "n" > "b", they are
Carmichael numbers are weak pseudoprimes to all bases.
Euler–Jacobi pseudoprimes.
Another approach is to use more refined notions of pseudoprimality, e.g. strong pseudoprimes or Euler–Jacobi pseudoprimes, for which there are no analogues of Carmichael numbers. This leads to probabilistic algorithms such as the Solovay–Strassen primality test, the Baillie-PSW primality test, and the Miller–Rabin primality test, which produce what are known as industrial-grade primes. Industrial-grade primes are integers for which primality has not been "certified" (i.e. rigorously proven), but have undergone a test such as the Miller–Rabin test which has nonzero, but arbitrarily low, probability of failure.
Applications.
The rarity of such pseudoprimes has important practical implications. For example, public-key cryptography algorithms such as RSA require the ability to quickly find large primes. The usual algorithm to generate prime numbers is to generate random odd numbers and test them for primality. However, deterministic primality tests are slow. If the user is willing to tolerate an arbitrarily small chance that the number found is not a prime number but a pseudoprime, it is possible to use the much faster and simpler Fermat primality test.

</doc>
<doc id="45893" url="https://en.wikipedia.org/wiki?curid=45893" title="Michigan Technological University">
Michigan Technological University

Michigan Technological University (commonly referred to as Michigan Tech, MTU, or simply Tech) is a public research university located in Houghton, Michigan, United States. Its main campus sits on on a bluff overlooking Portage Lake. Michigan Tech was founded in 1885 as the first post-secondary institution in the Upper Peninsula of Michigan, and was created to train mining engineers to operate the local copper mines.
Science, technology, forestry and business have been added to the numerous engineering disciplines, and Michigan Tech now offers more than 130 degree programs through its five colleges and schools. "US News and World Report" ranked Michigan Tech's undergraduate program 116th in the nation based on peer assessment, student selectivity, financial resources and other factors. Michigan Tech was also rated among the "Best in the Midwest" by The Princeton Review.
Michigan Tech's athletic teams are nicknamed the Huskies and compete primarily in the NCAA Division II Great Lakes Intercollegiate Athletic Conference (GLIAC). The men's hockey team competes in Division I as a member of the Western Collegiate Hockey Association (WCHA), and has won three national championships. The women's basketball team were national runners-up in 2011.
History.
Michigan Tech was founded in 1885 as the Michigan Mining School. After much agitation by Jay Abel Hubbell, the state legislature established the school to train mining engineers. Hubbell donated land for the school's first buildings. 
The school started with four faculty members and twenty-three students. It was housed in the Houghton Fire Hall from 1886 through 1889. 
A few years after the school's creation, enrollment grew to such a point that its name no longer reflected its purpose. The name was then changed to the Michigan College of Mines in 1897. This name lasted through World War I until 1925, but by this time the school had begun offering a wider variety of degrees and once again decided to change its name to the Michigan College of Mining and Technology in 1927. 
By 1931 enrollment had reached nearly 600. During the next few years, due to the Great Depression, money was scarce, causing department heads and even the president of the university, William Hotchkiss, to take pay cuts. 
Grover C. Dillman was president from 1935 to 1956. During this time, the school underwent many notable changes, including the construction of the Memorial Union Building and purchase of an ice rink and golf course. 
Around 1948, enrollment passed 2000 students total. 
In 1956, J. Robert Van Pelt became the new president of the university. He restarted many PhD programs and created a focus on research. This included the school's first analog computation class in 1956–1957. 
In the final years of his presidency, the school changed from a college to a university, changing its name a final time to "Michigan Technological University". The change from the Michigan College of Mining and Technology was necessary for two reasons, according to Van Pelt. First, the college had expanded too greatly and the current name was no longer an accurate title. Also, including "mining" in the name of the college was misleading. The name "Michigan Technological University" was chosen in order to retain the nickname "Michigan Tech" that had already been in use since 1927. 
Although engineering still accounts for some 59 percent of all enrollment as of fall 2010, the university now offers more than 130 degree programs. 
Along with its new name, the school also gained new constitutional status in 1964. This gave responsibility for control of the university to its Board of Control rather than legislature.
Campus.
The main Michigan Tech campus is located mainly on US 41 in Houghton, Michigan. It is the safest campus in Michigan, and the third safest in the United States, according to "Reader's Digest". The main part of campus is relatively small, and can be traversed in about 10 minutes. Many of the buildings are tall, reducing the physical size of the campus and giving the impression of being a park of high-rise office buildings. The offices of the Michigan Tech Fund are located in the First Merit Bank Building in Hancock. The Lakeshore Center in downtown Houghton houses the offices of Human Relations, Vice President for Research and other departments.
Faculty are involved in several distance education programs with clients including General Motors.
The Portage Lake Golf Course opened for play in April 1902. In 1945 the members could no longer support the needs of the course and sold it to Michigan Tech for one dollar. Since then many improvements have been made such as the addition of another nine holes in 1969. Then in 1984 the new clubhouse was constructed. In 1996 a sprinkler system was installed to modernize the course and keep it playable. The Portage Lake Golf Course is located two miles (3 km) southeast of campus.
Academics.
Michigan Tech offers more than 130 undergraduate and graduate degrees in engineering, natural and physical sciences, computing, business and economics, technology, environmental studies, arts, humanities, and social sciences. The university is divided into five schools and colleges. The average overall ACT scores for incoming students is 26.4 in fall 2010, compared to 21.2 nationally. It currently has the highest tuition of all public universities in Michigan, exceeding both Michigan State and the University of Michigan. The College of Engineering's environmental engineering and mechanical engineering enrollments rank in the top ten nationally and their respective graduate programs are ranked in the top 50 in the US. The electrical engineering department uses an innovative "DSP First" curriculum found at only a few leading universities.
Michigan Tech has also developed an alternative program to provide students with engineering and other design experience called the Enterprise program. Enterprises develop engineering skills by allowing students to work in business-like environments on real-world projects while completing their education. Enterprises include Nanotechnology Innovations, Hybrid Transportation, Aerospace, Blue Marble Security, Husky Game Development, Boardsports Technologies, and Wireless Communications Enterprises.
Student body.
The student body consists of more than 7,000 graduate and undergraduate students (Fall 2011) and more than 450 academic faculty (Fall 2010). As is historically true of engineering institutions, female enrollment at Michigan Tech is low. The male to female student ratio was 22:1 in 1960; since 1980 it has remained around 3:1. Michigan Tech's admissions office has enlisted female students and faculty to contact every admitted female applicant via telephone or personal letter in an attempt to increase female enrollment. In this last semester, Fall 2012, female enrollment has risen for the 6th straight year to reach an all-time high of 1,837 students. This pulls women up to 26.1%. The Fall 2010 freshman class had a ratio of 3.1:1.
Michigan Tech students are primarily from Michigan, Wisconsin, Minnesota, and Illinois. The student body is approximately 75.4% European-American/Non-Hispanic, 14.2% International, 1.6% Hispanic, 1.5% percent African American, 1.0% Asian, 0.6% Native American, 1.0% Multiracial, 0.1% Pacific Islander, and the remaining 4.5% was not supplied. The university has recently focused on achieving a more diverse student body, in terms of ethnicity, gender, and areas of study. A key step in this effort was the recent introduction of several new academic majors, including psychology, biochemistry and molecular biology, cheminformatics, communication and culture studies, pharmaceutical chemistry, exercise science, sound design, audio production, and theater and entertainment technology.
Research.
Michigan Tech ranked 172nd of 600 US colleges and universities in research and development expenditures in 2007. Research expenditures exceeded $50 million in 2009.
Student life.
Students attending Michigan Technological University have a wide range of activities to participate in, whether or not they are living in the residence halls. In addition to the various small interest groups which form throughout the year, they participate in Greek Life, Student Organizations, and the Enterprise Program; many organize and attend campus traditions, such as K-Day, the Parade of Nations, and the Winter Carnival (which also attracts alumni from across the country); furthermore, there are motivational drives to raise student activity levels and involvement in the school community, typically for those without membership in a student organization.
Student organizations.
Michigan Tech currently recognizes more than two hundred student organizations, including:
Greek life.
Michigan Tech is currently host to thirteen fraternities, including three international and three local fraternities. Additionally, there are eight sororities on campus, including four local sororities.
Athletics.
As the school mascot is the husky (specifically, Blizzard T. Husky), the school's sports teams are known as the "Huskies". Michigan Tech competes in the NCAA's Division II Great Lakes Intercollegiate Athletic Conference. The men's hockey team competes in Division I as a member of the Western Collegiate Hockey Association. Michigan Tech owns a downhill ski/snowboard hill, Mont Ripley, just across Portage Lake from campus, and maintains extensive cross-country ski trails (used for mountain biking in summer). 
The men's hockey team competes in Division I as a member of the Western Collegiate Hockey Association (WCHA), and has won three national championships. The women's basketball team were national runners-up in 2014-2015 season.
School songs.
Michigan Tech has both an official fight song and an official Alma Mater. At most sporting events, however, both the "Engineer's Song" and "In Heaven There Is No Beer" are played by the Huskies Pep Band, and many students consider these to be the unofficial school songs. The "Blue Skirt Waltz" is played at home ice hockey games and is called the "Copper Country Anthem." During the song, the fans join arms and swing back and forth to the music.
People.
There are over 68,000 Michigan Tech alumni living in all 50 states and over 100 countries. Some notable alumni include:

</doc>
<doc id="45896" url="https://en.wikipedia.org/wiki?curid=45896" title="The Stranger (novel)">
The Stranger (novel)

The Stranger or The Outsider () is a novel by Albert Camus published in 1942. Its theme and outlook are often cited as exemplars of Camus's philosophy of the absurd and existentialism, though Camus personally rejected the latter label.
The title character is Meursault, an indifferent French Algerian ("a citizen of France domiciled in North Africa, a man of the Mediterranean, an "homme du midi" yet one who hardly partakes of the traditional Mediterranean culture"), who, after attending his mother's funeral, apathetically kills an Arab man whom he recognizes in French Algiers. The story is divided into two parts, presenting Meursault's first-person narrative view before and after the murder, respectively.
In January 1955, Camus wrote: "I summarized "The Stranger" a long time ago, with a remark I admit was highly paradoxical: 'In our society any man who does not weep at his mother's funeral runs the risk of being sentenced to death.' I only meant that the hero of my book is condemned because he does not play the game."
Plot.
Part one.
Meursault learns of his mother's death. At her funeral, he expresses none of the expected emotions of grief. When asked if he wishes to view the body, he says no, and, instead, smokes and drinks coffee in front of the coffin. Rather than expressing his feelings, he only comments to the reader about the others at the funeral. He later encounters Marie, a former employee of his firm. The two become re-acquainted, go swimming, watch a comedy film and begin to have a sexual relationship, despite the fact that his mother's funeral took place the day before. In the next few days, he helps his friend and neighbour, Raymond Sintès, take revenge on a Moorish girlfriend suspected of infidelity. For Raymond, Meursault agrees to write a letter to his girlfriend, with the sole purpose of inviting her over so that Raymond can have sex with her but spit in her face at the last minute as emotional revenge. Meursault sees no reason not to help him, and it pleases Raymond. He does not express concern that Raymond's girlfriend is going to be emotionally hurt, as he believes Raymond's story that she has been unfaithful, and he himself is both somewhat drunk and characteristically unfazed by any feelings of empathy. In general, he considers other people either interesting or annoying or feels nothing of them at all.
The letter works: the girlfriend returns, but the situation escalates when she slaps Raymond after he tries to kick her out, and Raymond beats her. Raymond is taken to court where Meursault testifies that she had been unfaithful, and Raymond is let off with a warning. After this, the girlfriend's brother and several Arab friends begin trailing Raymond. Raymond invites Meursault and Marie to a friend's beach house for the weekend, and when there, they encounter the spurned girlfriend's brother and an Arab friend; these two confront Raymond and wound him with a knife during a fist fight. Later, walking back along the beach alone and now armed with a revolver he took from Raymond so that Raymond would not do anything rash, Meursault encounters the Arab. Meursault is now disoriented on the edge of heatstroke, and when the Arab flashes his knife at him, Meursault shoots. Despite killing the Arab man with the first gunshot, he shoots the corpse four more times after a brief pause. He does not divulge to the reader any specific reason for his crime or emotions he experiences at the time, if any, aside from the fact that he was bothered by the heat and bright sunlight.
Part two.
Meursault is incarcerated, and explains his arrest, time in prison, and upcoming trial. His general detachment makes living in prison very tolerable, especially after he gets used to the idea of not being able to go places whenever he wants to and no longer being able to satisfy his sexual desires with Marie. He passes the time sleeping, or mentally listing the objects he owned back in his apartment building. At the trial, Meursault's quietness and passivity are seen as demonstrative of his seeming lack of remorse or guilt by the prosecuting attorney, and so the attorney concentrates more upon Meursault's inability or unwillingness to cry at his mother's funeral than on the actual murder. The attorney pushes Meursault to tell the truth but never comes through and later, on his own, Meursault explains to the reader that he simply was never really able to feel any remorse or personal emotions for any of his actions in life. The dramatic prosecutor theatrically denounces Meursault to the point that he claims Meursault must be a soulless monster, incapable of remorse and that he thus deserves to die for his crime. Although Meursault's attorney defends him and later tells Meursault that he expects the sentence to be light, Meursault is alarmed when the judge informs him of the final decision: that he will be decapitated publicly.
In prison, while awaiting the execution of his death sentence by the guillotine, Meursault meets with a chaplain, but rejects his proffered opportunity of turning to God, explaining that God is a waste of his time. Although the chaplain persists in attempting to lead Meursault from his atheism (or, perhaps more precisely, his apatheism), Meursault finally accosts him in a rage, with a climactic outburst on his frustrations and the absurdity of the human condition and his personal anguish at the meaninglessness of his existence without respite. At the beginning of his outrage he mentions other people in anger, that they have no right to judge him for his actions or for who he is, and no one has the right to judge someone else. Meursault ultimately grasps the universe's indifference towards humankind which allows him to come to terms with his execution.
Characters.
Meursault is a French Algerian who learns of his mother's death by telegram. Meursault's indifference to the news of his mother's death demonstrates some emotional detachment from his environment. There are multiple instances throughout the novel where significant moments do not have an emotional impact on Meursault. He doesn't show emotion to the fact that his mother is dead, Marie loves him, or that he killed someone. Another aspect of Meursault is that he is a truthful person. He always speaks his mind and does not care how other people see him. However, he may have committed perjury by providing hearsay testimony on behalf of his neighbor, Raymond. He is regarded as a stranger to society due to his indifference.
Meursault’s Mother was sent to an old people's home three years prior to her death, introduced in the opening line of the novel. There are multiple instances where Meursault relates to his mother's death. Towards Meursault's presumed execution he felt that his mother embraced a meaningless universe and lived for the moment, just as he did.
Raymond Sintès is the neighbour of Meursault who beats his mistress which causes a conflict with the Arabs. He brings Meursault into the conflict which ultimately results in Meursault killing the Arab. Raymond can be a foil character of Meursault in that he takes action while Meursault is indifferent. Raymond and Meursault seem to develop a bond as the story goes on, ending with Raymond Sintes testifying for Meursault during his trial. Raymond also believes that he can control people - he assaults a woman because he believes she cheated and he insists Meursault is his friend after a simple favour from Meursault.
Marie Cardona had been a typist in the same workplace as Meursault. A day after Meursault's mother's funeral she meets him at a public pool, which sparks their relationship. She asks if Meursault loves her but Meursault replies that he doesn't think so. He still agrees to marry her prior to the murder and his arrest. Marie, like Meursault, enjoys physical contact in their relationship through the act of sex. She represents the enjoyable life Meursault wants and her pleasing aesthetic is one of the things that Meursault misses in jail.
Masson is the owner of the beach house where Raymond takes Marie and Meursault. Masson is a carefree person who simply likes to live his life and be happy. He wants to live life without restrictions.
Salamano is an old man who routinely takes his dog out for walks. He abuses the dog, but is attached to it. When he loses his dog, he is distressed and asks Meursault for advice. Meursault does not offer helpful advice and Salamano acknowledges that his life has changed.
The Arabs They include Raymond's mistress. None of the Arabs in "The Stranger" are named.
The Arab He is shot by Meursault on a beach of colonial Algiers. "The Arab" was given an identity and a whole novel by the Algerian journalist and novelist Kamel Daoud in his 2013 novel "The Meursault Investigation".
Reception.
"The Stranger's" first edition consisted of a mere 4,400 copies and could not become a best-seller. But it was well received, due to Jean-Paul Sartre's article in the eve of the publication of this novel and a mistake from the Propaganda-Staffel.
Carl Viggiani wrote of the book: "On the surface, "L’Etranger" gives the appearance of being an extremely simple though carefully planned and written book. In reality, it is a dense and rich creation, full of undiscovered meanings and formal qualities. It would take a book at least the length of the novel to make a complete analysis of meaning and form and the correspondences of meaning and form, in "L’Etranger"."
Publication history.
Gallimard first published the original French-language novel in 1942. A British author, Stuart Gilbert, first translated "L’Étranger" into English in 1946 and for more than thirty years his version was the standard English translation. In 1982, the British publisher Hamish Hamilton, which had issued Gilbert's translation, published a second translation, by Joseph Laredo, that Penguin Books bought in 1983. In 1988, a third translation, by the American Matthew Ward, was published by Vintage with the alternative title "The Stranger". Camus was influenced by American literary style, and Ward's translation is Americanized. A translation by Sandra Smith was published by Penguin in 2012.
A critical difference among these translations is in the connotation of the original emotion in what is arguably the story's key sentence: "I laid my heart open to the benign indifference of the universe" in Gilbert's translation, versus Laredo's "I laid my heart open to the gentle indifference of the universe" (original French: "la tendre indifférence du monde" = literally, "the tender indifference of the world"), although in the Penguin Classics 2000 reprint of Laredo's translation, "gentle" was changed to "benign". The ending lines differ as well: Gilbert's "on the day of my execution there should be a huge crowd of spectators and that they should greet me with howls of execration" contrasts with Laredo's to "with cries of hatred", in a significant scene that serves as a foil to the prior "indifference of the world". In French, the triad is "cris de haine", which Ward's transliteral interpretation ("with cries of hate") is closest to in terms of phonics. Gilbert's interpretation takes the liberty of juxtaposing "execration" with "execution".
In popular culture.
The 1979 first single "Killing an Arab" by The Cure was recorded at the same time as their first LP in the UK, "Three Imaginary Boys" (1979) but not included on the album. However, it was included on the band's first US album, "Boys Don't Cry" (1980). Composer Robert Smith has said that the song "was a short poetic attempt at condensing my impression of the key moments in "L'Étranger (The Stranger)" by Albert Camus" (Cure News number 11, October 1991).
The 1995 song "Noch koroche dnya" ("Night is Shorter than Day") by the Russian heavy metal band Aria is based on Meursault's encounter with the chaplain in the final scene of the novel. It is also narrated from Meursault's first-person perspective and includes (in Russian) the line, "The cries of hate will be my reward / Upon my death, I will not be alone."
The passage in which Meursault accepts his impending execution was read over the end of the song "Asa Phelps Is Dead" by The Lawrence Arms; read by guitarist Chris McCaughan, the excerpt parallels certain themes in the song's lyrics by bassist Brendan Kelly.
The 1993 film "Menace II Society" is based loosely on the basic plot (minus the trial), interactions and realizations that the character Mersault experiences. The film's title can be found in the line from the novel, "Especially when this lack of every decent instinct is such as that of the man before you, a menace to society."
In "The Sopranos" episode "D-Girl", Anthony Soprano Jr tells his parents that life is absurd, that the hypothetical death of his friends would be "interesting," and that there is no God. Tony and Carmela ask where this is coming from. Meadow Soprano appears at this moment and explains that Anthony was assigned "The Stranger" in English class, stating "This is education."
In "Mad Men", themes explored in the novel are used as a backdrop for the character of Don Draper and his existential stance, starting from Season 1 (episode 1), in which Rachel Menken describes him as someone detached from others, to one of the last episodes of Season 7 (episode 12), in which "The Stranger" and "On the Road" are cited by Bert Cooper - appearing to Don in a vision - as the type of works Don is fond of. The representation of Don under the sun of California is also a reminder of his condition as a stranger.
In the 1990 film "Jacob's Ladder", Tim Robbins' character can be seen reading "The Stranger" during the subway scene at the beginning of the movie.
In the 2006 film "", Jean Girard is seen reading a French language copy of "The Stranger" while racing.
In the 2012 film "Life of Pi", the titular character of Pi can be seen reading a French language copy of "The Stranger" in a flashback scene to his youth in Pondicherry, India.
In the first episode of the 2014 HBO Series "The Leftovers", Tom Garvey can be seen in the middle of the night reading an English version "The Stranger", translated by Matthew Ward.
In the tenth episode of the 2014 WGN America Series "Manhattan", the character Ida is seen returning a copy of the book to Elodie and comments on the book "I thought it would be racy" .
In the first season of "American Horror Story", in the second episode, Violet is seen reading "The Stranger" in bed when her mother brings her a cupcake.
The Joe Iconis song, Kevin, deals with a young man who feels completely detached from his surroundings. The refrain states, "I can't feel a thing anymore. It's all been done before. And everything's a horrible bore. And living is a terrible chore. You know that it's true. There's nothing new to do in Brooklyn anymore". The near the end of the song, testing his apathy, the singer randomly strangles a stranger, killing her and dumping her body in an alley. However, he is "still numb".

</doc>
<doc id="45900" url="https://en.wikipedia.org/wiki?curid=45900" title="1270s BC">
1270s BC


</doc>
<doc id="45903" url="https://en.wikipedia.org/wiki?curid=45903" title="The Man in the High Castle">
The Man in the High Castle

The Man in the High Castle (1963) is an alternative history novel by American writer Philip K. Dick. Set in 1962, fifteen years after an alternative ending to World War II, the novel concerns intrigues between the victorious Axis Powers—Imperial Japan and Nazi Germany—as they rule over the former United States, as well as daily life under the resulting totalitarian rule. "The Man in the High Castle" won the Hugo Award for Best Novel in 1963.
Reported inspirations include Ward Moore's alternative Civil War history, "Bring the Jubilee" (1953), various classic World War II histories, and the "I Ching" (referred to in the novel). The novel features a "novel within the novel" comprising an alternate history within this alternate history wherein the Allies defeat the Axis (though in a manner distinct from the actual historical outcome).
Synopsis.
Briefly, "The Man in the High Castle" is a "fictional picture of a world divided by Germany and Japan, victors of the second World War".
Background.
In the novel's parallel history, U.S. President Franklin Roosevelt was assassinated in 1933, leading to the continuation of the Great Depression and U.S. isolationism. Thus, the U.S.'s military capability was insufficient to stop the Nazis from exterminating the Soviet Union's Slavic peoples and the Japanese from conquering Oceania. By 1947, the U.S. and the remaining Allies surrendered. By the 1960s, Imperial Japan and Nazi Germany were the world's competing superpowers, with Japan establishing the "Pacific States of America" (P.S.A.) from the former Western United States, with the remaining Rocky Mountain States now a neutral buffer zone between the P.S.A. and the Nazi-occupied former Eastern United States. Meanwhile, Adolf Hitler, though alive, is incapacitated from advanced syphilis, and Martin Bormann has become Chancellor of Germany, with Goebbels, Heydrich, Göring, Seyss-Inquart (who oversees the extermination of the peoples of Africa), and other Nazi leaders soon vying to take his place. The Nazis have drained the Mediterranean to make room for farmland, developed and used the hydrogen bomb, and designed rockets for extremely fast travel across the world as well as space, having colonized the Moon, Venus, and Mars. The novel is set mostly in San Francisco, P.S.A.
Plot summary.
In 1962, fifteen years after Imperial Japan and Nazi Germany have won World War II, Robert "Bob" Childan owns an Americana antiques shop in San Francisco, California (located in the Japanese-occupied Pacific States of America), which is most commonly frequented by the Japanese, who make a fetish of romanticized American cultural artifacts. Childan is contacted by Nobusuke Tagomi, a high-ranking Japanese trade official, who is seeking a gift to impress a visiting Swedish industrialist named Baynes. Childan's store is stocked in part by antiques from the Wyndam-Matson Corporation, a metalworking company. Frank Frink (formerly Fink), a secretly Jewish-American veteran of World War II, has just been fired from the Wyndam-Matson factory, when he agrees to join a former coworker to begin a handcrafted jewellery business. Meanwhile, Frink's ex-wife, Juliana, works as a judo instructor in Canon City, Colorado (in the neutral Mountain States buffer zone), where she begins a sexual relationship with an Italian truck driver and ex-soldier, Joe Cinnadella. Throughout the book, many of these characters frequently make important decisions using prophetic messages they interpret from the "I Ching". Many characters are also reading a widely banned yet extremely popular new novel, "The Grasshopper Lies Heavy", which depicts an alternative history in which the Allies won World War II, a concept that amazes and intrigues its readers.
Frink exposes that the Wyndam-Matson Corporation has been supplying Childan with counterfeit antiques, which effectively works to blackmail Wyndam-Matson for money to finance Frink's new jewelry venture. Tagomi and Baynes meet, but Baynes repeatedly delays any real business as they await an expected third party from Japan. Suddenly, the public receives news of the death of the recently-ill Chancellor of Germany, Martin Bormann. Childan tentatively, on consignment, takes some of Frink's authentic new metalwork and attempts to curry favor with a Japanese client, who surprisingly considers Frink's jewellery immensely spiritually alive. Juliana and Joe take a road trip to Denver, Colorado, and Joe impulsively decides they should go on a side-trip to meet the mysterious Hawthorne Abendsen, author of "The Grasshopper Lies Heavy", who supposedly lives in a guarded fortress-like estate called the "High Castle" in Cheyenne, Wyoming. Soon, Joseph Goebbels is announced as the new German Chancellor.
Baynes and Tagomi finally meet their Japanese contact as two agents of the Nazi secret police, the "Sicherheitsdienst" (SD), close in to arrest Baynes, who is actually revealed to be a Nazi defector named Rudolf Wegener. Wegener warns his contact, a famed Japanese general, of Operation Dandelion, an upcoming Goebbels-approved plan for the Nazis to surprise-attack the Japanese Home Islands, in order to obliterate them in one swift stroke. As Frink is elsewhere exposed as a Jew and arrested, Wegener and Tagomi are confronted by the SD agents, both of whom Tagomi shoots dead with an antique American pistol. Back in Colorado, Joe abruptly changes his appearance and mannerisms before the trip to the High Castle, leading Juliana to deduce that he intends to actually murder Abendsen. Joe confirms this, revealing himself to be an undercover Swiss Nazi assassin. Juliana mortally wounds Joe and drives off to warn Abendsen of the threat to his life.
Wegener flies back to Germany, while Tagomi remains shaken by the shootout and goes to Childan to sell back the gun he used in the fight; however, instead, sensing the energy from one of Frink's jewels, Tagomi impulsively buys it from Childan, before undergoing a spiritually intense if ambiguous moment where he momentarily perceives an alternative-history version of San Francisco. Later, Tagomi on a whim forces the German authorities to release Frink, whom Tagomi has never personally met and does not know is the maker of the jewel. Juliana soon has her own spiritual experience when she arrives in Cheyenne. There, she discovers that Abendsen now lives in a normal house with his family, having left behind the High Castle due to a change of outlook; he no longer preoccupies himself with thoughts that he might soon be assassinated. After dodging many of Juliana's questions about his inspiration for his novel, Abendsen finally confesses that he in fact used the "I Ching" to guide his writing of "The Grasshopper Lies Heavy". Before leaving, Juliana infers then that "Truth" itself wrote the book in order to reveal the "Inner Truth" that Japan and Germany really lost World War II.
"The Grasshopper Lies Heavy".
Several characters in "The Man in the High Castle" read the popular novel "The Grasshopper Lies Heavy", by Hawthorne Abendsen, whose title is assumed or supposed to have come from the Bible verse: "The grasshopper shall be a burden" (). Thus, "The Grasshopper Lies Heavy" constitutes a novel within a novel, wherein Abendsen writes of an alternate universe, where the Axis Powers lost World War II (1939–47). For this reason, the Germans have banned the novel in the occupied U.S.; but it is widely read in the Pacific, and its publication is legal in the neutral countries.
"The Grasshopper Lies Heavy" postulates that President Roosevelt survives an assassination attempt but forgoes re-election in 1940, honoring George Washington's two-term limit. The next president, Rexford Tugwell, removes the Pacific fleet from Pearl Harbor, Hawaii, saving it from Japanese attack, which ensures that the U.S. enters the conflict a well-equipped naval power. The United Kingdom retains most of its military-industrial strength, contributing more to the Allied war effort, leading to Rommel's defeat in North Africa; the British advance through the Caucasus to fight alongside the Soviets to victory in the Battle of Stalingrad; Italy reneges on its membership in the Axis Powers and betrays them; British tanks and the Red Army jointly conquer Berlin; at the end of the war, the Nazi leaders—including Adolf Hitler—are tried for their war crimes, wherein the "Führer's" last words are "Deutsche, hier steh' ich" ("Germans, here I stand"), in imitation of Martin Luther.
After the war, Winston Churchill remains the British Prime Minister, and, because of its military-industrial might, the British Empire does not collapse. The U.S. establishes strong business relations with Chiang Kai-shek's right-wing regime in China after vanquishing the Communist Mao Zedong. The British Empire becomes racist and more expansionist post-war, while the U.S. outlaws Jim Crow laws, resolving its racism by the 1950s. Both changes provoke racial-cultural tensions between the U.S. and the U.K., leading them to a Cold War for global hegemony between their two vaguely liberal, democratic, capitalist societies. Although the end of the novel is never depicted in the text, one character claims the book ends with the British Empire eventually defeating the U.S., becoming the world superpower.
Inspirations.
Dick said he conceived "The Man in the High Castle" when reading "Bring the Jubilee" (1953), by Ward Moore, which occurs in an alternate nineteenth-century U.S. wherein the Confederate States of America won the American Civil War. In the acknowledgments, he mentions other influences: "The Rise and Fall of the Third Reich" (1960), by William L. Shirer; "Hitler: A Study in Tyranny" (1962), by Alan Bullock; "The Goebbels Diaries" (1948), Louis P. Lochner, translator; "Foxes of the Desert" (1960), by Paul Carrell; and the "I Ching" (1950), Richard Wilhelm, translator.
The acknowledgments have three references to traditional Japanese and Tibetan poetic forms; (i) volume one of the "Anthology of Japanese Literature" (1955), edited by Donald Keene, from which is cited the "haiku" on page 48; (ii) from "Zen and Japanese Culture" (1955), by Daisetz Teitaro Suzuki, from which is cited a "waka" on page 135; and (iii) the "Tibetan Book of the Dead" (1960), edited by W. Y. Evans-Wentz.
Nathanael West's "Miss Lonelyhearts" (1933) is also mentioned in the text, written before the Roosevelt assassination divergence point that separates the world of "The Man in the High Castle" from ours. In this novella, "Miss Lonelyhearts" is a male newspaper journalist who writes anonymous advice as an agony aunt to forlorn readers during the height of the Great Depression; hence, "Miss Lonelyhearts" tries to find consolation in religion, casual sex, rural vacations and work, none of which provide him with the sense of authenticity and engagement with the outside world that he needs. West's book is about the elusive quality of interpersonal relationships and quest for personal meaning at a time of political turmoil within the United States.
Philip Dick used the "I Ching" to make decisions crucial to the plot of "The Man in the High Castle" just as characters within the novel use the "I Ching" to guide decisions.
Reception.
Avram Davidson praised the novel as a "superior work of fiction", citing Dick's use of the "I Ching" as "fascinating". Davidson concluded that "It's all here—extrapolation, suspense, action, art, philosophy, plot, character."
"The Man in the High Castle" secured for Dick the 1963 Hugo Award for Best Novel.
A new paperback edition of the novel was published in 1992 by Vintage Books.
Adaptations.
Audiobook.
An unabridged "The Man in the High Castle" audiobook, read by George Guidall and running approximately 9.5 hours over 7 audio cassettes, was released in 1997. Another unabridged audiobook version was released in 2008 by Blackstone Audio, read by Tom Weiner and running approximately 8.5 hours over 7 CDs. A third unabridged audiobook recording was released in 2014 by Brilliance Audio, read by Jeff Cummings with a running time of 9:58.
Television.
After a number of attempts to adapt the book to the screen, Amazon's film production unit began in October 2014 filming the pilot episode of "The Man in the High Castle" in Roslyn, Washington, for a new television drama to air on the Amazon Prime web video streaming service. The pilot episode was released by Amazon Studios on January 15, 2015, and was Amazon's "most watched pilot ever" according to Amazon Studios' vice president, Roy Price. On 18 February 2015, Amazon greenlit the series. The show became available for streaming on November 20, 2015.
The television series diverges from the novel in many significant respects. Both the Pacific States of America and the Eastern American puppet state appear to be mere provinces of the Japanese and German empires without any apparent autonomous (even quisling) government institutions whatsoever. The Rocky Mountain States become a literally anarchic Neutral Zone. World War II appears to have ended symbolically in 1945, with America surrendering unconditionally after the Nazis destroy Washington DC with an H-bomb, rather than in 1947 after the US is invaded and defeated by land as in the book. As for Hitler himself, while elderly, he is apparently mostly hale in his Season 1 finale appearance, though other characters elsewhere in the season do reference his supposed physical infirmity.
Characters from the book that do appear are in most cases far more fleshed out with deeper and sometimes rather different backstories than their novel originals. For instance Wegener is a "standartenführer" in the SS rather than a naval captain (and oddly there are no German military or naval - as opposed to SS - personnel depicted anywhere in the first season). Rather than being a member of an organized internal resistance (and despite his relatively low rank) Wegener is a close personal confidante of Hitler himself and his disillusionment with the regime appears to be largely personal. Juliana and Frank are unmarried but living together rather than divorced and separated. Frank has a sister, nephew and niece, although they are killed early in the series, and this propels him into a more active role in relation to the resistance. Juliana also has a sister whose murder by the "Kempeitai" early in the season instigates her search for the mysterious Man in the High Castle, as well as her having a mother and stepfather who are significant supporting characters. Joe Cinnadella is renamed Joe Blake and as he becomes closer to Juliana appears to have growing doubts about his role as a Nazi agent. Robert Childan is however a more minor character (at least in Season 1) than the original, while Ed McCarthy has a rather more prominent and active role.
There are several major additional characters introduced by the television series and numerous narrative details and the plotline differ radically from the source novel. For example, the planned Nazi pre-emptive nuclear strike on Japan, "Operation Dandelion," is apparently being prevented only by Hitler's personal refusal to authorise it, leading Heydrich and the faction demanding pre-emptive war to plot the Führer's assassination. In addition, Howard Abendsen does not appear in the first season of the television version and "The Grasshopper Lies Heavy" is a series of newsreel films depicting multiple alternate realities rather than a novel (although this idea may actually be borrowed from Dick's later novel Valis which features a mysterious film depicting yet another dystopian alternate history of the USA). As of the Season 1 finale, these films are being tracked down by SS agents like Blake for dispatch to Hitler himself for an as-yet-unknown purpose.
Uncompleted sequel.
In a 1976 interview, Dick said he planned to write a sequel novel to "The Man in the High Castle": "And so there's no real ending on it. I like to regard it as an open ending. It will segue into a sequel sometime." Dick said that he had "started several times to write a sequel", but progressed little, because he was too disturbed by his original research for "The Man in the High Castle" and could not mentally bear "to go back and read about Nazis again." He suggested that the sequel would be a collaboration with another author: "Somebody would have to come in and help me do a sequel to it. Someone who had the stomach for the stamina to think along those lines, to get into the head; if you're going to start writing about Reinhard Heydrich, for instance, you have to get into his face. Can you imagine getting into Reinhard Heydrich's face?"
Two chapters of the proposed sequel were published in "The Shifting Realities of Philip K. Dick", a collection of essays about Dick. The chapters describe Gestapo officers reporting to Nazi Party officials about their time-travel visits to a parallel world in which the Nazi conquest has failed, but which contains nuclear weapons, available for the stealing by the Nazis back to their world. A working title for the novel, describing the emergence of a hybrid Japanese–American culture, was "Ring of Fire".
On occasion, Dick said that 1967's "The Ganymede Takeover" began as a sequel to "The Man in the High Castle", but that it did not coalesce as such. Specifically, the Ganymedans occupying the Earth began as the Imperial Japanese occupying the conquered US. Dick's novel "Radio Free Albemuth" also is rumored to have started as a sequel to "The Man in the High Castle". Dick described the plot of this early version of "Radio Free Albemuth"—then titled "VALISystem A"—writing: "... a divine and loving ETI intelligence ... helpHawthorne Abendsen, the protagonist-author in ["The Man in the High Castle", continue on in his difficult life after the Nazi secret police finally got to him... VALISystem A, located in deep space, sees to it that nothing, absolutely nothing, can prevent Abendsen from finishing his novel." The novel eventually evolved into a new story unrelated to "The Man in the High Castle." Dick ultimately abandoned the Albemuth book, unpublished during his lifetime, though portions were salvaged and used for 1981's "VALIS". The full book was published in 1985, three years after Dick's death.

</doc>
<doc id="45906" url="https://en.wikipedia.org/wiki?curid=45906" title="Exponential distribution">
Exponential distribution

In probability theory and statistics, the exponential distribution (a.k.a. negative exponential distribution) is the probability distribution that describes the time between events in a Poisson process, i.e. a process in which events occur continuously and independently at a constant average rate. It is a particular case of the gamma distribution. It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless. In addition to being used for the analysis of Poisson processes, it is found in various other contexts.
The exponential distribution is not the same as the class of exponential families of distributions, which is a large class of probability distributions that includes the exponential distribution as one of its members, but also includes the normal distribution, binomial distribution, gamma distribution, Poisson, and many others.
Characterization.
Probability density function.
The probability density function (pdf) of an exponential distribution is
Alternatively, this can be defined using the right-continuous Heaviside step function, "H"("x") where "H"("0")=1:
Here λ > 0 is the parameter of the distribution, often called the "rate parameter". The distribution is supported on the interval [0, ∞). If a random variable "X" has this distribution, we write "X" ~ Exp(λ).
The exponential distribution exhibits infinite divisibility.
Cumulative distribution function.
The cumulative distribution function is given by
Alternatively, this can be defined using the Heaviside step function, "H"("x").
Alternative parameterization.
A commonly used alternative parametrization is to define the probability density function (pdf) of an exponential distribution as
where β > 0 is mean, standard deviation, and scale parameter of the distribution, the reciprocal of the "rate parameter", λ, defined above. In this specification, β is a "survival parameter" in the sense that if a random variable "X" is the duration of time that a given biological or mechanical system manages to survive and "X" ~ Exp(β) then E["X"] = β. That is to say, the expected duration of survival of the system is β units of time. The parametrization involving the "rate" parameter arises in the context of events arriving at a rate λ, when the time between events (which might be modeled using an exponential distribution) has a mean of β = λ−1.
The alternative specification is sometimes more convenient than the one given above, and some authors will use it as a standard definition. This alternative specification is not used here. Unfortunately this gives rise to a notational ambiguity. In general, the reader must check which of these two specifications is being used if an author writes ""X" ~ Exp(λ)", since either the notation in the previous (using λ) or the notation in this section (here, using "β" to avoid confusion) could be intended. An example of this notational switch: reference uses λ for β.
Properties.
Mean, variance, moments and median.
The mean or expected value of an exponentially distributed random variable "X" with rate parameter λ is given by
In light of the examples given above, this makes sense: if you receive phone calls at an average rate of 2 per hour, then you can expect to wait half an hour for every call.
The variance of "X" is given by
so the standard deviation is equal to the mean.
The moments of "X", for "n" = 1, 2, ..., are given by
The median of "X" is given by
where ln refers to the natural logarithm. Thus the absolute difference between the mean and median is
in accordance with the .
Memorylessness.
An exponentially distributed random variable "T" obeys the relation
When "T" is interpreted as the waiting time for an event to occur relative to some initial time, this relation implies that, if "T" is conditioned on a failure to observe the event over some initial period of time "s", the distribution of the remaining waiting time is the same as the original unconditional distribution. For example, if an event has not occurred after 30 seconds, the conditional probability that occurrence will take at least 10 more seconds is equal to the unconditional probability of observing the event more than 10 seconds relative to the initial time.
The exponential distribution and the geometric distribution are the only memoryless probability distributions.
The exponential distribution is consequently also necessarily the only continuous probability distribution that has a constant Failure rate.
Quantiles.
The quantile function (inverse cumulative distribution function) for Exp(λ) is
The quartiles are therefore:
And as a consequence the interquartile range is ln(3)/λ.
Kullback–Leibler divergence.
The directed Kullback–Leibler divergence of formula_13 ('approximating' distribution) from formula_14 ('true' distribution) is given by
Maximum entropy distribution.
Among all continuous probability distributions with support ∞) and mean μ, the exponential distribution with λ = 1/μ has the largest differential entropy. In other words, it is the maximum entropy probability distribution for a random variate "X" which is greater than or equal to zero and for which E["X" is fixed.
Distribution of the minimum of exponential random variables.
Let "X"1, ..., "X""n" be independent exponentially distributed random variables with rate parameters λ1, ..., λ"n". Then
is also exponentially distributed, with parameter
This can be seen by considering the complementary cumulative distribution function:
The index of the variable which achieves the minimum is distributed according to the law
Note that
is not exponentially distributed.
Parameter estimation.
Suppose random variable "X" is exponentially distributed with rate parameter λ, and formula_21 are "n" independent samples from "X", with sample mean formula_22. Among the estimators of λ, the maximum likelihood estimator (MLE) is formula_23 and the uniformly minimum variance unbiased estimator (UMVUE) is formula_24. Of the estimators of the form formula_25, the one that minimizes the expected mean squared error is formula_26.
Maximum likelihood.
The likelihood function for λ, given an independent and identically distributed sample "x" = ("x"1, ..., "x""n") drawn from the variable, is:
where:
is the sample mean.
The derivative of the likelihood function's logarithm is:
Consequently the maximum likelihood estimate for the rate parameter is:
Although this is "not" an unbiased estimator of formula_31, formula_32 "is" an unbiased MLE estimator of formula_33 where formula_34 is the scale parameter defined in the 'Alternative parameterization' section above and the distribution mean.
Confidence intervals.
The 100(1 − α)% confidence interval for the rate parameter of an exponential distribution is given by:
which is also equal to:
where is the percentile of the chi squared distribution with "v" degrees of freedom, n is the number of observations of inter-arrival times in the sample, and x-bar is the sample average. A simple approximation to the exact interval endpoints can be derived using a normal approximation to the distribution. This approximation gives the following values for a 95% confidence interval:
This approximation may be acceptable for samples containing at least 15 to 20 elements.
Bayesian inference.
The conjugate prior for the exponential distribution is the gamma distribution (of which the exponential distribution is a special case). The following parameterization of the gamma probability density function is useful:
The posterior distribution "p" can then be expressed in terms of the likelihood function defined above and a gamma prior:
Now the posterior density "p" has been specified up to a missing normalizing constant. Since it has the form of a gamma pdf, this can easily be filled in, and one obtains:
Here the hyperparameter α can be interpreted as the number of prior observations, and β as the sum of the prior observations.
The posterior mean here is:
Generating exponential variates.
A conceptually very simple method for generating exponential variates is based on inverse transform sampling: Given a random variate "U" drawn from the uniform distribution on the unit interval (0, 1), the variate
has an exponential distribution, where "F" −1 is the quantile function, defined by
Moreover, if "U" is uniform on (0, 1), then so is 1 − "U". This means one can generate exponential variates as follows:
Other methods for generating exponential variates are discussed by Knuth and Devroye.
The ziggurat algorithm is a fast method for generating exponential variates.
A fast method for generating a set of ready-ordered exponential variates without using a sorting routine is also available.
Related distributions.
Other related distributions:
Applications of exponential distribution.
Occurrence of events.
The exponential distribution occurs naturally when describing the lengths of the inter-arrival times in a homogeneous Poisson process.
The exponential distribution may be viewed as a continuous counterpart of the geometric distribution, which describes the number of Bernoulli trials necessary for a "discrete" process to change state. In contrast, the exponential distribution describes the time for a continuous process to change state.
In real-world scenarios, the assumption of a constant rate (or probability per unit time) is rarely satisfied. For example, the rate of incoming phone calls differs according to the time of day. But if we focus on a time interval during which the rate is roughly constant, such as from 2 to 4 p.m. during work days, the exponential distribution can be used as a good approximate model for the time until the next phone call arrives. Similar caveats apply to the following examples which yield approximately exponentially distributed variables:
Exponential variables can also be used to model situations where certain events occur with a constant probability per unit length, such as the distance between mutations on a DNA strand, or between roadkills on a given road.
In queuing theory, the service times of agents in a system (e.g. how long it takes for a bank teller etc. to serve a customer) are often modeled as exponentially distributed variables. (The arrival of customers for instance is also modeled by the Poisson distribution if the arrivals are independent and distributed identically.) The length of a process that can be thought of as a sequence of several independent tasks follows the Erlang distribution (which is the distribution of the sum of several independent exponentially distributed variables).
Reliability theory and reliability engineering also make extensive use of the exponential distribution. Because of the "memoryless" property of this distribution, it is well-suited to model the constant hazard rate portion of the bathtub curve used in reliability theory. It is also very convenient because it is so easy to add failure rates in a reliability model. The exponential distribution is however not appropriate to model the overall lifetime of organisms or technical devices, because the "failure rates" here are not constant: more failures occur for very young and for very old systems.
In physics, if you observe a gas at a fixed temperature and pressure in a uniform gravitational field, the heights of the various molecules also follow an approximate exponential distribution, known as the Barometric formula. This is a consequence of the entropy property mentioned below.
In hydrology, the exponential distribution is used to analyze extreme values of such variables as monthly and annual maximum values of daily rainfall and river discharge volumes.
Prediction.
Having observed a sample of "n" data points from an unknown exponential distribution a common task is to use these samples to make predictions about future data from the same source. A common predictive distribution over future samples is the so-called plug-in distribution, formed by plugging a suitable estimate for the rate parameter λ into the exponential density function. A common choice of estimate is the one provided by the principle of maximum likelihood, and using this yields the predictive density over a future sample "x""n"+1, conditioned on the observed samples "x" = ("x"1, ..., "xn") given by
The Bayesian approach provides a predictive distribution which takes into account the uncertainty of the estimated parameter, although this may depend crucially on the choice of prior.
A predictive distribution free of the issues of choosing priors that arise under the subjective Bayesian approach is
which can be considered as
The accuracy of a predictive distribution may be measured using the distance or divergence between the true exponential distribution with rate parameter, λ0, and the predictive distribution based on the sample "x". The Kullback–Leibler divergence is a commonly used, parameterisation free measure of the difference between two distributions. Letting Δ(λ0||"p") denote the Kullback–Leibler divergence between an exponential with rate parameter λ0 and a predictive distribution "p" it can be shown that
where the expectation is taken with respect to the exponential distribution with rate parameter , and is the digamma function. It is clear that the CNML predictive distribution is strictly superior to the maximum likelihood plug-in distribution in terms of average Kullback–Leibler divergence for all sample sizes .

</doc>
<doc id="45907" url="https://en.wikipedia.org/wiki?curid=45907" title="Beyond This Horizon">
Beyond This Horizon

Beyond This Horizon is a science fiction novel by Robert A. Heinlein. It was originally published as a two-part serial in "Astounding Science Fiction" (April, May 1942, under the pseudonym Anson MacDonald) and then as a single volume by Fantasy Press in 1948.
Overview.
The novel depicts a world where genetic selection for increased health, longevity, and intelligence has become so widespread that the unmodified 'control naturals' are a carefully managed and protected minority. Dueling and the carrying of arms is a socially accepted way of maintaining civility in public; a man can wear distinctive clothing to show his unwillingness to duel, but this results in an inferior social status. The world has become an economic utopia; the "economic dividend" is so high that work has become optional. The chief economic problem is in fact using up the economic surplus: many high-quality goods actually cost "less" than those of lower quality. Many people use lower-quality goods as status symbols. The government invests heavily in scientific research, but this has the side effect of further increasing productivity a decade or more later, so long-term projects with no expected economic return are favored above anything but medical research, on the theory that longer lifespans will consume more surplus.
The story's protagonist, Hamilton Felix (surname first), is the archetypal superman. Felix possesses a superhuman physique, an intellect to match it, and can expect to live centuries without any form of medical assistance. Authorities aware of his genetic makeup consider him to be the most advanced human in existence—the "star line". However, he lacks eidetic memory, which disqualifies him for what many consider to be humanity's most important occupation: that of an "encyclopedic synthesist", one who analyzes the sum total of human knowledge for untapped potential. As such, he finds his life—and the society he lives in—to be enjoyable but meaningless. However, when one of these synthesists seeks him out, inquiring when he plans to continue his line, he finds himself drawn into an adventure which not only gives him purpose but convinces him that his society is worth saving after all.
Major themes in the novel are reincarnation, the immortality of the soul, and telepathy. Hamilton Felix is the product of generations of genetic engineering. He is almost but not quite the perfect human. In the second half of the book his genetically engineered son is born. The son is the climax of generations of genetic engineering and selective breeding, and is a genetically perfect human. As the son grows he begins to develop almost superhuman mental abilities and a surprising telepathic ability. As the novel draws to a close, it becomes apparent that the son senses that Hamiton Felix's second child, a daughter, is the reincarnation of a wise elderly government official who foresaw her own death and arranged to die shortly before Felix's daughter was born. This official understood that the soul is reincarnated, and in preparation for her own death and reincarnation she was instrumental in the genetic engineering of the son and daughter.
Reception.
Boucher and McComas characterized "Beyond This Horizon" as among "the finest science fiction novels of the modern crop." P. Schuyler Miller reviewed the novel favorably, saying "in true Heinlein manner the basic theme of the book smashes the screen of action only in the closing pages."
In popular culture.
In the Japanese visual novel "Eden*", the term 'Felix' is used in the setting to refer to genetically engineered humans with abilities similar to those described in the book, and the connection to Heinlein's work is referred to in dialogue.

</doc>
<doc id="45908" url="https://en.wikipedia.org/wiki?curid=45908" title="Rocket Ship Galileo">
Rocket Ship Galileo

Rocket Ship Galileo is a science fiction novel by Robert A. Heinlein, published in 1947, about three teenagers who participate in a pioneering flight to the Moon. It was the first in the Heinlein juveniles, a long and successful series of science fiction novels published by Scribner's. The novel was originally envisioned as the first of a series of books called "Young Rocket Engineers". It was initially rejected by publishers, because going to the moon was "too far out".
Plot summary.
After World War II, three teenage boy rocket experimenters are recruited by one boy's uncle, Dr. Cargraves, a renowned physicist who had worked on the Manhattan Project, to refit a conventionally powered surplus "mail rocket". It is to be converted to run on a thorium nuclear pile which boils zinc as a propellant. They use a cleared area in a military weapons test range in the desert for their work, despite prying and sabotage attempts by unknown agents.
Upon completion of the modifications, they stock the rocket, which they name the "Galileo", and take off for the Moon, taking approximately 3 days to arrive. After establishing a semi-permanent structure based on a Quonset hut, they claim the moon on behalf of the United Nations.
As they set up a radio to communicate with the Earth they pick up a local transmission, the sender of which promises to meet them. Instead, their ship is bombed. Fortunately, they are able to hole up undetected in their hut and succeed in ambushing the other ship when it lands, capturing the pilot. They discover that there is a Nazi base on the Moon. They bomb it from their captured ship and land. One survivor is found, revived, and questioned.
The boys also find evidence of an ancient lunar civilization, and postulate that the craters of the moon were formed not by impacts from space, but by nuclear bombs that destroyed the alien race.
When the base's Nazi leader shoots the pilot in order to silence him, Cargraves convenes a trial and finds him guilty of murder. Cargraves prepares to execute the prisoner by ejecting him into vacuum, mostly as a bluff for information on how to fly the base's spaceship. The Nazi capitulates in the airlock and teaches them how to fly the ship back to Earth.
The boys radio the location of the hidden Nazi base on Earth to the authorities, leading to its destruction; they return as heroes.
Adaptations.
The 1950 movie "Destination Moon" was loosely based on "Rocket Ship Galileo", and Heinlein was one of three co-authors of the script. The film's plot also resembles that of "The Man Who Sold the Moon", which Heinlein wrote in 1949 but did not publish until 1951.
Critical reception.
Surveying Heinlein's juvenile novels, Jack Williamson noted that while "Rocket Ship Galileo" remains "readable, with Heinlein's familiar themes already emerging," it was a "sometimes fumbling experiment. ... The plot is often trite, and the characters are generally thin stereotypes." Robert Wilfred Franson said that "Heinlein wants there always to be young people of the right mind and character to seize such opportunities. His novels went a long way toward educating such a class of people, and still are doing so." Andrew Baker wrote: "'Rocket Ship Galileo' shares with numerous works composed before the advent of the actual Space Program a gross underestimation of the huge costs and investment of resources needed for any jaunt outside Earth's gravitational field. (...) The idea of private people (boys in this case) being able to just take off to the Moon on their own can ultimately be traced - like so many Science Fiction themes - to the fertile mind of H.G. Wells and to the two English gentlemen quietly taking off to the Moon in "The First Men in the Moon". (...) The politics of 'Galileo' are still those of the World War II anti-Nazi Alliance, not of the emerging Cold War. Had it been written a few years later, the villains would have likely been Russian Communists".

</doc>
<doc id="45912" url="https://en.wikipedia.org/wiki?curid=45912" title="Space Cadet">
Space Cadet

Space Cadet is a 1948 science fiction novel by Robert A. Heinlein about Matt Dodson, who joins the Space Patrol to help preserve peace in the Solar System. The story translates the standard military academy story into outer space: a boy from Iowa goes to officer school, sees action and adventure, shoulders responsibilities far beyond his experience, and becomes a man. It was published as the second of the series of Heinlein juveniles and inspired the Tom Corbett, Space Cadet media empire, including the 1950s television series and radio show which made "Space Cadet" a household phrase whose meaning later shifted in popular culture.
Plot summary.
In 2075, teenager Matt Dodson applies to join the prestigious Space Patrol. After a number of physical, mental, and ethical tests, he is accepted as a cadet. He makes friends with fellow recruits William 'Tex' Jarman, Venus-born Oscar Jensen, and Pierre Armand from Ganymede. His first roommate is Girard Burke, the arrogant son of a wealthy spaceship builder. They are transported to the orbiting school ship PRS "James Randolph" for further training.
Burke eventually either resigns or is asked to leave, and goes into the merchant service, but the remainder do well enough to be assigned to working Patrol ships. Dodson, Jarman and Jensen ship out on the "Aes Triplex". Their first real mission is to help search for a missing research vessel, the "Pathfinder", in the Asteroid Belt. They find it, but all aboard are dead, the unlucky victims of a fast-moving asteroid that punctured the ship when the armored outer airlock door was open. Before the accident, a researcher on the "Pathfinder" had found evidence that the planet which blew up to form the asteroids was inhabited by an intelligent species, and that the explosion had been artificial. The captain of the "Aes Triplex" transfers half the crew to the repaired "Pathfinder" so that they can take the ship and the news of the startling discovery back to Earth quickly. With the remainder (including all three cadets), he continues his patrol.
Then, he receives an urgent message to investigate an incident on Venus. He sends Lieutenant Thurlow and the cadets to the planet's surface. The lander touches down on a sinkhole, giving the crew barely enough time to get out before it disappears in the mud. With Thurlow comatose, injured when the lander fell over, Jensen assumes command. He contacts the sentient usually-friendly Venerians, but the entire party is taken captive. They soon find out why.
These particular natives had never seen human beings before, until old classmate Burke showed up in a prospecting ship. He had taken the matriarch of the local clan hostage when she refused to give him permission to exploit a rich deposit of radioactive ores. The locals promptly attacked the ship and killed his crew; Burke managed to send a message for help before being taken prisoner.
Jensen skillfully gains the matriarch's trust and convinces her that they are honorable and civilized, unlike Burke, and the Patrolmen are released. Neither the lander nor Burke's ship is flightworthy. To their amazement, she takes the stranded humans to the carefully preserved "Astarte", the legendary first ship to set out for Venus over a century before and thought to have been lost en route. According to the log, the crew perished from disease. With the help of the natives, the cadets recommission the ship and fly it back to (human) civilization at Venus's South Pole colony. Dodson is initially disappointed when they are not treated as heroes—but then he realizes that what they accomplished was simply what was expected of Patrolmen.
Themes.
The Space Patrol is entrusted by the worldwide Earth government with a monopoly on nuclear weapons, and is expected to maintain a credible threat to drop them on Earth from orbit as a deterrent against breaking the peace. Matt, on a visit home, causes a family argument when his parents refuse to believe that the Patrol—and especially their son—would actually bomb Iowa.
The cadets are expected to renounce their loyalty to their respective countries and replace it by a wider allegiance to humanity as a whole and to the sentient species of the Solar System. They are told the stories of four Patrol heroes/martyrs who exemplify this quality. One of them, Rivera, leaves orders to annihilate his hometown if he is held captive there during negotiations. Heinlein later expanded another of these anecdotes into "The Long Watch".
The young, idealistic Matt feels that he should be able, if the need arose, to emulate Rivera and destroy his own Iowa hometown. His father tells him such a need would never arise, since the Patrol's cosmopolitan allegiance is little more than a sham and in fact it is controlled by the "North American Federation" and serves its interests. Later, Matt's mentor in the Patrol makes him understand that if such an unlikely dilemma should arise, his commanding officer would lock him in his room rather than expect him to participate in the attack. The mentor uses this scenario to force Matt to confront the personal and political issues involved in the institutional control of atomic weapons in a more mature way.
Written almost a decade before the American Civil Rights Movement, and at a time when non-white characters were almost entirely absent from science fiction, the book also explores the theme of racism, both literally, in discussions about the cosmopolitan racial makeup of the (all-male) Patrol, and metaphorically, in its description of conflict with the Venerians. Venus is described as intensely hot and (incorrectly, as is now known) swampy, but habitable. The Venerians are at first thought to be primitive, but it is later revealed that they have a high level of technological sophistication, though developed along radically different lines than that of humans.
There is also a subplot revolving around the issue of what it means to be a good soldier. Discouraged by the intellectual demands of his Patrol training, and attracted to the glamor and esprit de corps of the Marines, Matt requests a transfer, but is dissuaded by his mentor. The mentor, dividing human motivations into three types, explains that the Patrol, which has the responsibility of holding the ultimate weapon and keeping overall peace, is manned by a certain sort of person, the man of ideals (its motto is "Quis custodiet ipsos custodes?)." In contrast, the Marines, the service branch who deal with ordinary military affairs, are trained to prize unquestioning loyalty and bravery as the highest ideals, and are deliberately recruited from the type of person who seeks glory and excitement. Matt belongs to the former category. The Merchant service, by implication, is for a third category, those motivated by economic concerns—which is where Burke fits in.
The novel contains an early description of a mobile phone: 
Matt dug a candy bar out of his pouch, split it and gave half to Jarman, who accepted it gratefully. "You're a pal, Matt, I've been living on my own fat ever since breakfast -- and that's risky. Say your telephone is sounding."
"Oh!" Matt fumbled in his pouch and got out his phone. "Hello?"
Critical reception.
Surveying Heinlein's juvenile novels, Jack Williamson characterized "Space Cadet" as "a long step forward. ... The characters are stronger the background is carefully built, original, and convincing, the story suspenseful enough." Williamson noted that Heinlein was "perfecting the "bildungsroman" form that shapes the whole series."
P. Schuyler Miller gave the book a favorable review as "a first-rate historical novel of the near future," saying "So subtly has the scientific detail been interwoven with plot and action that the reader never realizes how painstakingly it has been worked out."
Adaptations.
The novel inspired Joseph Greene of Grosset & Dunlap to develop the "Tom Corbett, Space Cadet" comic books, television series, radio show, comic strip, and novels that were popular in the early 1950s. Greene had originally submitted a radio script for "Tom Ranger and the Space Cadets" on January 16, 1946, but it remained unperformed when Heinlein's novel was published.
As Greene had submitted his radio script for "Tom Ranger and the Space Cadets" on January 16, 1946, prior to Robert A. Heinlein's 1948 Space Cadet but Heinlein influenced the evolution of "Tom Ranger" into "Tom Corbett" and launched his student astronaut title's common mention, they share credit for the popularity of both formal and later slang uses of "space cadet."
The movie "Star Trek" (2009) has a similar story, in which a boy from Iowa goes to space officer school, sees action and adventure in space, shoulders responsibilities far beyond his experience, and becomes a man.
In popular culture.
The "Tom Corbett, Space Cadet" television series and radio show made "space cadet" a household phrase. By 1955, Jackie Gleason spoke the phrase on "The Honeymooners" television show in an episode called 'TV or not to TV', original air date October 1, 1955.
The popular meanings of "space cadet" later shifted in popular culture away from astronaut-in-training to indicate, by the 1960s, an "eccentric person disconnected with reality" (often implying an intimacy with hallucinogenic drugs) although by the 2010s, drug use was rarely implied by this phrase, nor was low intelligence implied; "space cadet" was more simply associated with "spacing out," wandering from present concerns, especially of others present, and being a "space case". Both the "trainee astronaut" and "person regarded as being out of touch with reality" entered the Oxford Dictionary for English language, though by 2014 Oxford notes that in American English, the phrase had also recouped the positive connotations originally meant by Heinlein and Joseph Greene, the Tom Corbett, Space Cadet writer: "An enthusiast for space travel, typically a young person."

</doc>
<doc id="45913" url="https://en.wikipedia.org/wiki?curid=45913" title="Red Planet">
Red Planet

Red Planet is a nickname for the planet Mars, due to its surface color.
It may also refer to:

</doc>
<doc id="45915" url="https://en.wikipedia.org/wiki?curid=45915" title="Humpty Dumpty">
Humpty Dumpty

Humpty Dumpty is a character in an English nursery rhyme, probably originally a riddle and one of the best known in the English-speaking world. He is typically portrayed as an anthropomorphic egg, though he is not explicitly described so. The first recorded versions of the rhyme date from late eighteenth-century England and the tune from 1870 in James William Elliott's "National Nursery Rhymes and Nursery Songs". Its origins are obscure and several theories have been advanced to suggest original meanings.
The character of Humpty Dumpty was popularised in the United States by actor George L. Fox (1825–77). As a character and literary allusion, he has appeared or been referred to in a large number of works of literature and popular culture, particularly Lewis Carroll's "Through the Looking-Glass" (1872). The rhyme is listed in the Roud Folk Song Index as No. 13026.
Lyrics and melody.
The rhyme is one of the best known and most popular in the English language. The most common modern text is:
It is a single quatrain with external rhymes that follow the pattern of AABB and with a trochaic metre, which is common in nursery rhymes. The melody commonly associated with the rhyme was first recorded by composer and nursery rhyme collector James William Elliott in his "National Nursery Rhymes and Nursery Songs" (London, 1870). The Roud Folk Song Index catalogues folk songs and their variations by number, and classifies this song as 13026.
Origins.
The earliest known version was published in Samuel Arnold's "Juvenile Amusements" in 1797 with the lyrics:
<poem>Humpty Dumpty sat on a wall,
Humpty Dumpty had a great fall.
Four-score Men and Four-score more,
Could not make Humpty Dumpty where he was before.</poem>
A manuscript addition to a copy of "Mother Goose's Melody" published in 1803 has the modern version with a different last line: "Could not set Humpty Dumpty up again". It was published in 1810 in a version of "Gammer Gurton's Garland" as:
<poem>
Humpty Dumpty sate on a wall,
Humpti Dumpti had a great fall;
Threescore men and threescore more,
Cannot place Humpty dumpty as he was before.
</poem>
In 1842, James Orchard Halliwell published a collected version as:
<poem>
Humpty Dumpty lay in a beck.
With all his sinews around his neck;
Forty Doctors and forty wrights
Couldn't put Humpty Dumpty to rights!
</poem>
According to the "Oxford English Dictionary", the term "humpty dumpty" referred to a drink of brandy boiled with ale in the seventeenth century. The riddle probably exploited, for misdirection, the fact that "humpty dumpty" was also eighteenth-century reduplicative slang for a short and clumsy person. The riddle may depend upon the assumption that a clumsy person falling off a wall might not be irreparably damaged, whereas an egg would be. The rhyme is no longer posed as a riddle, since the answer is now so well known. Similar riddles have been recorded by folklorists in other languages, such as "Boule Boule" in French, "Lille Trille" in Swedish and Norwegian, and "Runtzelken-Puntzelken" or "Humpelken-Pumpelken" in different parts of Germany — although none is as widely known as Humpty Dumpty is in English.
Meaning.
The rhyme does not explicitly state that the subject is an egg, possibly because it may have been originally posed as a riddle. There are also various theories of an original "Humpty Dumpty". One, advanced by Katherine Elwes Thomas in 1930 and adopted by Robert Ripley, posits that Humpty Dumpty is King Richard III of England, depicted as humpbacked in Tudor histories and particularly in Shakespeare's play, and who was defeated, despite his armies, at Bosworth Field in 1485.
Professor David Daube suggested in "The Oxford Magazine" of 16 February 1956 that Humpty Dumpty was a "tortoise" siege engine, an armoured frame, used unsuccessfully to approach the walls of the Parliamentary held city of Gloucester in 1643 during the Siege of Gloucester in the English Civil War. This was on the basis of a contemporary account of the attack, but without evidence that the rhyme was connected. The theory was part of an anonymous series of articles on the origin of nursery rhymes and was widely acclaimed in academia, but it was derided by others as "ingenuity for ingenuity's sake" and declared to be a spoof. The link was nevertheless popularised by a children's opera "All the King's Men" by Richard Rodney Bennett, first performed in 1969.
From 1996, the website of the Colchester tourist board attributed the origin of the rhyme to a cannon recorded as used from the church of St Mary-at-the-Wall by the Royalist defenders in the siege of 1648. In 1648, Colchester was a walled town with a castle and several churches and was protected by the city wall. The story given was that a large cannon, which the website claimed was colloquially called Humpty Dumpty, was strategically placed on the wall. A shot from a Parliamentary cannon succeeded in damaging the wall beneath Humpty Dumpty which caused the cannon to tumble to the ground. The Royalists (or Cavaliers, "all the King's men") attempted to raise Humpty Dumpty on to another part of the wall, but the cannon was so heavy that "All the King's horses and all the King's men couldn't put Humpty together again". Author Albert Jack claimed in his 2008 book "Pop Goes the Weasel: The Secret Meanings of Nursery Rhymes" that there were two other verses supporting this claim. Elsewhere, he claimed to have found them in an "old dusty library, an even older book", but did not state what the book was or where it was found. It has been pointed out that the two additional verses are not in the style of the seventeenth century or of the existing rhyme, and that they do not fit with the earliest printed versions of the rhyme, which do not mention horses and men.
In "Through the Looking-Glass".
Humpty appears in Lewis Carroll's "Through the Looking-Glass" (1872), where he discusses semantics and pragmatics with Alice.
    "I don't know what you mean by 'glory,' " Alice said. 
    Humpty Dumpty smiled contemptuously. "Of course you don't—till I tell you. I meant 'there's a nice knock-down argument for you!' "
    "But 'glory' doesn't mean 'a nice knock-down argument'," Alice objected.
    "When "I" use a word," Humpty Dumpty said, in rather a scornful tone, "it means just what I choose it to mean—neither more nor less."
    "The question is," said Alice, "whether you "can" make words mean so many different things."
    "The question is," said Humpty Dumpty, "which is to be master—that's all."
    Alice was too much puzzled to say anything, so after a minute Humpty Dumpty began again. "They've a temper, some of them—particularly verbs, they're the proudest—adjectives you can do anything with, but not verbs—however, "I" can manage the whole lot! Impenetrability! That's what "I" say!"
This passage was used in Britain by Lord Atkin in his dissenting judgement in the seminal case "Liversidge v. Anderson" (1942), where he protested about the distortion of a statute by the majority of the House of Lords. It also became a popular citation in United States legal opinions, appearing in 250 judicial decisions in the Westlaw database , including two Supreme Court cases ("TVA v. Hill" and "Zschernig v. Miller").
It has been suggested by A. J. Larner that Carroll's Humpty Dumpty had prosopagnosia on the basis of his description of his finding faces hard to recognise. 
    "The face is what one goes by, generally," Alice remarked in a thoughtful tone.
    "That's just what I complain of," said Humpty Dumpty. "Your face is the same as everybody has—the two eyes,—" (marking their places in the air with his thumb) "nose in the middle, mouth under. It's always the same. Now if you had the two eyes on the same side of the nose, for instance—or the mouth at the top—that would be "some" help."
In popular culture.
Humpty Dumpty has become a highly popular nursery rhyme character. American actor George L. Fox (1825–77) helped to popularise the character in nineteenth-century stage productions of pantomime versions, music, and rhyme. The character is also a common literary allusion, particularly to refer to a person in an insecure position, something that would be difficult to reconstruct once broken, or a short and fat person. Humpty Dumpty has been used in a large range of literary works in addition to his appearance as a character in "Through the Looking-Glass", including L. Frank Baum's "Mother Goose in Prose" (1901), where the rhyming riddle is devised by the daughter of the king, having witnessed Humpty's "death" and her father's soldiers' efforts to save him. In Neil Gaiman's early short story "The Case of the Four and Twenty Blackbirds", the Humpty Dumpty story is turned into a film noir-style hardboiled crime story, involving also Cock Robin, the Queen of Hearts, Little Bo Peep, Old Mother Hubbard, and other characters from popular nursery rhymes. Robert Rankin used Humpty Dumpty as one victim of a serial fairy-tale character murderer in "The Hollow Chocolate Bunnies of the Apocalypse" (2002). Jasper Fforde included Humpty Dumpty in his novels "The Well of Lost Plots" (2003) and "The Big Over Easy" (2005), which use him respectively as a ringleader of dissatisfied nursery rhyme characters threatening to strike and as the victim of a murder.
The rhyme has also been used as a reference in more serious literary works, including as a recurring motif of the Fall of Man in James Joyce's 1939 novel "Finnegans Wake". Robert Penn Warren's 1946 American novel "All the King's Men" is the story of populist politician Willie Stark's rise to the position of governor and eventual fall, based on the career of the corrupt Louisiana Senator Huey Long. It won the 1947 Pulitzer Prize and was twice made into a film "All the King's Men" in 1949 and 2006, the former winning the Academy Award for best motion picture. This was echoed in Carl Bernstein and Bob Woodward's book "All the President's Men", about the Watergate scandal, referring to the failure of the President's staff to repair the damage once the scandal had leaked out. It was filmed as "All the President's Men" in 1976, starring Robert Redford and Dustin Hoffman. Similarly, Humpty Dumpty is referred to in Paul Auster's 1985 novel "City of Glass", when two characters discuss him as "the purest embodiment of the human condition" and quote extensively from "Through the Looking Glass".
It has also been used as a common motif in popular music, including Hank Thompson's "Humpty Dumpty Heart" (1948), The Monkees' "All the King's Horses" (1966), Aretha Franklin's "All the King's Horses" (1972), Tori Amos's "Humpty Dumpty" (1992), and Travis's "The Humpty Dumpty Love Song" (2001). In jazz, Ornette Coleman and Chick Corea wrote different compositions, both titled "Humpty Dumpty". (In Corea's case, however, it is a part of a concept album inspired by Lewis Carroll called ""The Mad Hatter"", 1978). 
In the Dolly Parton song "Starting Over Again", it's all the king's horses and all the king's men who can't put the divorced couple back together again. In an extra verse in one version of ABBA's "On and On and On", Humpty Dumpty is mentioned as being afraid of falling off the wall.
In science.
Humpty Dumpty has been used to demonstrate the second law of thermodynamics. The law describes a process known as entropy, a measure of the number of specific ways in which a system may be arranged, often taken to be a measure of "disorder". The higher the entropy, the higher the disorder. After his fall and subsequent shattering, the inability to put him together again is representative of this principle, as it would be highly unlikely (though not impossible) to return him to his earlier state of lower entropy, as the entropy of an isolated system never decreases.
A variation on the poem using near-sounding French nonsense words is often used to illustrate the difficulty of speech recognition in different languages. A common version is as follows:
To a listener expecting a nursery rhyme, it will generally be heard as the English version, while someone expecting French will instead tend to hear nonsense words. 

</doc>
<doc id="45918" url="https://en.wikipedia.org/wiki?curid=45918" title="Between Planets">
Between Planets

Between Planets is a science fiction novel by Robert A. Heinlein, originally serialized in "Blue Book" magazine in 1951 as "Planets in Combat". It was published in hardcover that year by Scribner's as part of the Heinlein juveniles.
Plot summary.
A young man named Don Harvey leaves his dude ranch high school on Earth to go to his scientist parents on Mars. He visits an old family friend who asks him to deliver a ring to his father, but they are both later arrested by security forces. Harvey is released and given his ring back, after it has been examined; he is told that his friend has died of "heart failure." It is only later that he realizes that all deaths can be described that way.
Harvey boards a shuttle to a space station orbiting the Earth. The station doubles as a transshipment terminus and a military base, armed with missiles to keep restive nations in check. On the trip up, he befriends one of his fellow passengers, a Venusian "dragon" named Sir Isaac Newton. Sir Isaac is a renowned physicist who can speak English using a portable device.
Harvey gets caught up in the Venusian war of independence when the station is captured by the colonials in a surprise raid. Most of the other travelers are sent back to Earth, while a few decide to join the rebels. Harvey is in a quandary. The spaceship to Mars has been confiscated, but he remains determined to get there, by way of Venus if necessary. Because he was born in space, with one parent from Venus and the other from Earth, he claims Venusian citizenship; more importantly, Sir Isaac vouches for him. He is allowed to tag along, which turns out to be very fortunate for Harvey. The rebels blow up the station to stir up trouble for the Earth government. When the shuttle returns to Earth with its radios disabled, the military assumes it has been booby-trapped and destroys it, killing all aboard.
On his arrival on Venus, Harvey finds that his Earth-backed money is now worthless. A banker lends him money, telling him to pay it forward. He gets a job washing dishes for his keep for Charlie, a Chinese immigrant who runs a small restaurant. He befriends a young woman, Isobel, when he tries to send a message to his parents. However, communication with Mars has been cut due to the hostilities. Harvey settles in to wait out the war, when the war comes to him.
Earth sends a military force to put down the rebellion. The Venusian ships are destroyed in orbit and the ground forces are routed. Charlie is killed resisting the occupying soldiers. Harvey is rounded up and questioned by a senior security officer, who is very eager to get his hands on Harvey's ring. Luckily, Harvey had given it to Isobel for safekeeping and he does not know where she is or whether she is even alive. Before he can be interrogated with drugs, he escapes and joins the Venusian guerrilla forces.
Harvey becomes an effective commando. In time, he is tracked down by the leaders of the resistance, who turn out to also be looking for the ring. Isobel and her father (who is an important member of the rebels) are safe at the very base where Harvey is taken.
The seemingly valueless ring turns out to be carrying the secret of scientific breakthroughs resulting from archeological studies of an extinct alien civilization on Mars. With Sir Isaac's assistance, it is used to build an advanced spaceship that is much faster than any other vessel in existence, with revolutionary weapons and defenses also derived from the new technology. As the only combat veteran with knowledge of the ship, christened "Little David", Harvey is recruited for its maiden voyage, manning a self-destruct mechanism, with strict orders to blow up the ship if it is in danger of being captured. "Little David" intercepts and defeats a group of warships on their way to Mars to crush the revolt there. Afterwards, Harvey is probably reunited with his parents, although the story ends before then.
Astronomy.
Like many science fiction works of its period, the novel depicts both Venus and Mars as suitable for human habitation. Since no interplanetary space probes had been launched at the time, neither the extreme pressure and temperature at the surface of Venus, nor the extremely low atmospheric pressure at the surface of Mars, were known to science. Even the length of the day on Venus was not yet known.
Reception.
Groff Conklin reviewed the novel favorably, calling it "a magnificently real and vivid Picture of the Possible." Boucher and McComas named it among the best sf novels of 1951, characterizing it as "more mature than most 'adult' science fiction.". P. Schuyler Miller praised the novel as "very smoothly and logically put together," although he noted that it lacked the level of "elaboration of background detail" that he expected from Heinlein."
Surveying Heinlein's juvenile novels, Jack Williamson characterized "Between Planets" as "mov the series still farther from its juvenile origins toward grownup concerns." Although describing the plot as "pretty traditional space opera," he praised the novel for its "ably drawn" characters, its "well-imagined" background, and its "story told with zest." Williamson also noted that Heinlein closed the novel "with a vigorous statement of his unhappiness with 'the historical imperative'" leading to the loss of individual freedom as governmental organizations grew."
Cartoon.
"Between Planets" was serialized in "Boys' Life" magazine in 1978 as a monthly cartoon series. The story took some liberties — for instance, the "Dragons" of Venus were portrayed as humanoids and the planets' names were changed — but the spirit of the story was relatively faithful.

</doc>
<doc id="45919" url="https://en.wikipedia.org/wiki?curid=45919" title="Academy Award for Best Dance Direction">
Academy Award for Best Dance Direction

The Academy Awards for Best Dance Direction (1935-1937 only)

</doc>
<doc id="45920" url="https://en.wikipedia.org/wiki?curid=45920" title="Augusta, Maine">
Augusta, Maine

Augusta is the capital of the U.S. state of Maine and the county seat of Kennebec County.
The city's population was 19,136 at the 2010 census, making it the third-smallest state capital (after Montpelier, Vermont and Pierre, South Dakota) and the ninth-largest city in Maine. Located on the Kennebec River at the head of tide, Augusta is home to the University of Maine at Augusta. Augusta is also the principal city in the "Augusta-Waterville, ME Micropolitan Statistical Area".
History.
The area was first explored by the ill-fated Popham Colony in September 1607. It was first inhabited by English settlers from the Plymouth Colony in 1629 as a trading post on the Kennebec River. The settlement was known by its Indian name—Cushnoc (or Coussinoc or Koussinoc), meaning "head of tide." Fur trading was at first profitable, but with Indian uprisings and declining revenues, the Plymouth Colony sold the Kennebec Patent in 1661. Cushnoc would remain unoccupied for the next 75 years. This area was inhabited by the Canibas Indians. During the 17th century they were on friendly terms with the English settlers in the region.
A hotbed of Abenaki hostility toward British settlements was located further up the Kennebec at Norridgewock. In 1722, the tribe and its allies attacked Fort Richmond (now Richmond) and destroyed Brunswick. In response, Norridgewock was sacked in 1724 during Dummer's War, when English forces gained tentative control of the Kennebec. In 1754, a blockhouse named Fort Western (now the oldest wooden fort in America), was built at Cushnoc on the eastern bank. It was intended as a supply depot for Fort Halifax upriver, as well as to protect its own region. In 1775, Benedict Arnold and his 1,100 troops would use Fort Western as a staging area before continuing their journey up the Kennebec to the Battle of Quebec.
Cushnoc was incorporated as part of Hallowell in 1771. Known as "the Fort," it was set off and incorporated by the Massachusetts General Court in February 1797 as Harrington. In August, however, the name changed to Augusta after Augusta Dearborn, daughter of Henry Dearborn. In 1799, it became county seat for newly created Kennebec County. Maine became a state in 1820 and Augusta was designated its capital in 1827. The Maine State Legislature continued meeting in Portland, however, until completion in 1832 of the new Maine State House designed by Charles Bulfinch. Augusta was chartered as a city in 1849. After being named the state capital and the introduction of new industry, the city flourished. In 1840 and 1850, the city ranked among the 100 largest urban populations. The next decade, however, the city was quickly bypassed by rapidly growing metropolises in the Midwest.
Excellent soil provided for agriculture, and water power from streams provided for industry. In 1837, a dam was built across the Kennebec where the falls drop 15 feet at the head of tide. By 1838, 10 sawmills were contracted. With the arrival of the Kennebec & Portland Railroad in 1851, Augusta became an even more productive mill town. In 1883, the property of A. & W. Sprague Company was purchased by the Edwards Manufacturing Company, which erected extensive brick mills for manufacturing cotton textiles. In the late 19th century, a paper and pulp plant was constructed. Other Augusta firms produced lumber, sash, doors, window shutters, broom handles, stone cutters' tools, shoes, headstones, ice and furniture. The city developed as a publishing and shipping center. Today, government and post-secondary education are important businesses.
In the 19th century, Augusta got a regular steamboat service and the railroad. The city installed gas lights in 1859. A telephone service was available in 1880 and a local hospital in 1898. In the early 20th century, Augusta built two movie houses and a film production studio.
For much of Augusta's history, the central business district was on and near Water Street on the west bank of the Kennebec River. The street, laid out in the late 1700s, was also the location of many of the government buildings. As the city grew and spread out the local government buildings moved further away from the business district. Many fires damaged this concentrated area, including one significant fire in 1865 that destroyed nearly 100 buildings. In 1890, the first trolley line began operation down Water Street, connecting Augusta with Gardiner and Hallowell to the south. In 1932, buses replaced the trolley line. With the completion of the Maine Turnpike and Interstate 95 in 1955, local commercial developments began to move away from Water Street and closer to the highway.
Since the 1980s, there has been an attempt by city officials to revitalize the downtown area. Historian Dan Holcomb noted "they don't say Augusta it's Auguster," in reference to his observation of the local dialect, noting that it had become pervasive and widespread throughout central to northern Maine by the mid to late 1980s. Surviving mill and factory buildings have been redeveloped into housing. The dam on the Kennebec was removed in 1999 and the area around the dam has been turned into a city park. The city hall and other local government departments were relocated to the eastern bank of the river in the 1980s.
Since the mid-eighteenth century, there has been a military presence in Augusta. Fort Western has not had troops garrisoned there since the 1790s, but in 1828, the U.S. Government built an arsenal to protect their interests from Britain. During the Civil War, Augusta was a rendezvous point for soldiers traveling to the front. Many of the soldiers camped on the green in front of the capitol building. In 1862, Camp E.D. Keyes was established in the northwestern portion of the city. During World War I, Camp Keyes was used as a mobilization and training camp for soldiers. The camp eventually became a headquarters for the Maine National Guard. In 1929, the state legislature approved the placement of the Augusta State Airport next to the camp. As the airport grew, the use of the camp as a training facility was no longer possible. Today, it is still used for administrative and logistical purposes by the National Guard.
Geography.
Augusta is located at , making it the easternmost state capital in the United States. According to the United States Census Bureau, the city has a total area of , of which is land and is water. Augusta is drained by Bond's Brook, Woromontogus Stream and the Kennebec River.
Roads.
The city is crossed by Interstate 95, U.S. Route 201, State Route 11, U.S. Route 202, State Route 9, State Route 3, State Route 100, State Route 27, State Route 8, State Route 104, and State Route 105.
Bordering.
Augusta borders the towns of Manchester to its west, Sidney and Vassalboro to its north, Windsor to its east, Chelsea to its south, and the city of Hallowell to its southwest.
Climate.
Augusta's climate is classified as a humid continental climate (Köppen: Dfb). Summers are typically warm, rainy, and humid, while winters are cold, windy, and snowy. Spring and fall are usually mild, but conditions are widely varied, depending on wind direction and jet stream positioning.
The hottest month is July, with an average high temperature of . The coldest month is January, with an average low of . Most snowfall occurs from December through March. There is usually little or no snow in April and November, and snow is rare in May and October.
Demographics.
2010 census.
As of the census of 2010, there were 19,136 people, 8,802 households, and 4,490 families residing in the city. The population density was . There were 9,756 housing units at an average density of . The racial makeup of the city was 94.1% White, 1.1% African American, 0.7% Native American, 1.5% Asian, 0.1% Pacific Islander, 0.4% from other races, and 2.3% from two or more races. Hispanic or Latino of any race were 1.8% of the population.
There were 8,802 households of which 23.0% had children under the age of 18 living with them, 35.2% were married couples living together, 11.8% had a female householder with no husband present, 4.0% had a male householder with no wife present, and 49.0% were non-families. 39.8% of all households were made up of individuals and 13.6% had someone living alone who was 65 years of age or older. The average household size was 2.08 and the average family size was 2.76.
The median age in the city was 43.2 years. 18.3% of residents were under the age of 18; 8.1% were between the ages of 18 and 24; 26% were from 25 to 44; 29.4% were from 45 to 64; and 18% were 65 years of age or older. The gender makeup of the city was 48.6% male and 51.4% female.
2000 census.
As of the census of 2000, there were 18,560 people, 8,565 households, and 4,607 families residing in the city. The population density was 335.1 people per square mile (129.4/km²). There were 9,480 housing units at an average density of 171.2 per square mile (66.1/km²). The racial makeup of the city was 96.21% White, 0.50% Black or African American, 0.48% Native American, 1.35% Asian, 0.01% Pacific Islander, 0.16% from other races, and 1.3% from two or more races. 0.86% of the population were Hispanic or Latino of any race.
There were 8,565 households out of which 24.3% had children under the age of 18 living with them, 39.1% were married couples living together, 10.9% had a female householder with no husband present, and 46.2% were non-families. 38.3% of all households were made up of individuals and 14.2% had someone living alone who was 65 years of age or older. The average household size was 2.10 and the average family size was 2.77.
In the city, the population was spread out with 20.5% under the age of 18, 8.7% from 18 to 24, 28.3% from 25 to 44, 24.8% from 45 to 64, and 17.7% who were 65 years of age or older. The median age was 40 years. For every 100 females there were 89.9 males. For every 100 females age 18 and over, there were 87.5 males.
The median income for a household in the city was $29,921, and the median income for a family was $42,230. Males had a median income of $31,209 versus $22,548 for females. The per capita income for the city was $19,145. About 11.4% of families and 15.0% of the population were below the poverty line, including 19.2% of those under age 18 and 9.8% of those age 65 or over.
Government.
Local government.
Augusta is governed by a mayor and council-manager system. The City Council oversees all City government activities and establishes the legislative policies of the City, adopts and amends ordinances and local laws, appropriates municipal resources, and sets the tax rate. The City Manager serves as the chief executive officer and purchasing agent of the city. The mayor presides at all meetings of the council, and is recognized ceremonially as the official head of the city.
The city maintains a police department remarkable for having not had an officer killed in the line of duty for over a century.
Political makeup.
Augusta has historically been Democratic. In the 2012 presidential election, Barack Obama received 5,192 of the votes to Mitt Romney's 3,339. The City has not voted for a Republican presidential candidate since the Republican landslide of 1988. Democrats are the majority political affiliation in all four voting wards, and there are more unenrolled voters than Republicans in the City.
Education.
There are five public schools, one private school, one college (the University of Maine at Augusta), and two public libraries in Augusta. Farrington, Gilbert, Hussey, and Lincoln are the four public elementary schools that are spread throughout the city. Cony is the public school serving students in grades 7-12 from Augusta and the surrounding towns; Cony comprises Cony High School and Cony Middle School. St. Michaels is the private Catholic school that children from Augusta and surround towns may attend for tuition. The University of Maine at Augusta is third largest university in the University of Maine System. The Maine State Library and Lithgow Public Library are both located in Augusta.
Media.
Television.
Augusta is part of the Portland television market, and receives most of that market's channels. WCBB channel 10, licensed to Augusta, is the local television outlet for the Maine Public Broadcasting Network.

</doc>
<doc id="45921" url="https://en.wikipedia.org/wiki?curid=45921" title="Starman Jones">
Starman Jones

Starman Jones is a 1953 science fiction novel by Robert A. Heinlein about a farm boy who wants to go to the stars. It was first published by Charles Scribner's Sons as part of the Heinlein juveniles series.
Plot summary.
Max Jones works the family farm in the Ozark Mountains. With his father dead and his stepmother remarrying a man he detests, Max runs away from home, taking his uncle's astrogation manuals.
Most occupations are tightly controlled by guilds with hereditary memberships. One such is the Astrogators Guild. Since his uncle had been a member and had no children, Max hopes that before he died, his uncle had named him his heir. He begins hitchhiking towards Earthport to find out. Along the way, he finds a friendly face in hobo Sam Anderson, who later alludes to being a deserter from the Imperial Marines. Sam feeds Max and offers advice, though he later departs with Max's valuable manuals.
At the guild's headquarters, Max is disappointed to find that he had not been named as an heir, but he is returned his uncle's substantial security deposit for his manuals. Max learns that Sam had tried to claim the deposit for himself.
By chance, he runs into an apologetic Sam. With Max's money, Sam is able to finagle them a one way job/trip aboard a starship using forged papers. Max signs on as a steward's mate third class, and then he absorbs the contents of the Stewards' Guild manual using his eidetic memory. Among his duties is caring for several animals, including passengers' pets. When passenger Eldreth "Ellie" Coburn visits her pet, an alien, semi-intelligent "spider puppy" that Max has befriended, she learns that he can play three-dimensional chess, and challenges him to a game. A champion player, she diplomatically lets him win. Meanwhile, Sam manages to rise to the position of master-at-arms.
When, through Ellie's machinations, the ship's officers discover that Max had learned astrogation from his uncle, Max is promoted to the command deck. Under the tutelage of Chief Astrogator Hendrix and Chief Computerman Kelly, he becomes a probationary apprentice chartsman, then a probationary astrogator. In a meeting with Hendrix, Max reluctantly admits to faking his record to get into space. Hendrix defers the matter until their return to Earth. The "Asgard" then departs for Halcyon, a human colony planet orbiting Nu Pegasi.
When Hendrix dies, the astrogation department is left dangerously shorthanded. The aging captain tries to take his place, but is not up to the task. When Max detects an error in his real-time calculations leading up to a transition, neither the captain nor Assistant Astrogator Simes believe him, and the ship becomes lost.
They locate a habitable world, which Ellie names charity, and the passengers become colonists. Meanwhile, the crew continues to try to figure out where they are and whether they can return to Earth. Unfortunately, it turns out the planet is already inhabited by intelligent centaur-like beings. Max and Ellie are captured, but Ellie's pet is able to guide Sam to them. They escape, though Sam is killed covering their retreat.
Upon his return, Max is informed that the captain has died. Simes tried to illegally take command and was killed by Sam, leaving Max as the only remaining astrogator. To make matters worse, Simes hid or destroyed the astrogation manuals.
Vastly outnumbered by the hostile natives, the humans are forced to attempt a perilous return to known space by reversing the erroneous transition. Max must not only pilot the ship; he must supply the missing astrogation tables from his eidetic memory. To add to his burdens, the remaining officers inform Max that he must take charge, as only an astrogator can be the captain. The pressure is immense, but Max succeeds and the ship returns to known space.
Max pays heavy fines for breaking their regulations, but becomes a member of the Astrogators Guild. However, he loses any chance for a relationship with Eldreth: she returns home to marry her boyfriend. Max accepts this with mixed feelings, but looks forward to his new career.
Reception.
Groff Conklin found the novel to be "a richly textured and thoroughly mature tale." Boucher and McComas praised it for its "good character-development, rousing adventure-telling, and brilliant creation of several forms of extra-Terrestrial life." P. Schuyler Miller ranked it "close to the best in mainline science fiction."
"New York Times" reviewer Villiers Gerson declared "Starman Jones" to be "superior science-fiction. ... carefully plotted, lucidly and beautifully written."
Surveying Heinlein's juvenile novels, Jack Williamson described "Starman Jones" as "a classic example of the "bildungsroman" pattern" and noted that "with its bold symbolism, the book makes a universal appeal." Despite "coincidence and occasional melodrama" in the plotting, Williamson concluded that "the novel is a fine juvenile reflects hopes and fears we all have known."
Adaptation to other media.
Although Heinlein rarely permitted dramatic adaptations of his work, he authorized Douglas L Lieberman to stage "Starman Jones" at the Goodman Children's Theater in Chicago. Written and directed by Lieberman, the 2-act play ran for 25 performances in 1972. The title role was played by Charles Fleischer, who later performed the voice of Roger Rabbit in Hollywood. In 1974, Avon Books published the script as part of the anthology "Contemporary Children's Theater" edited by Betty Jean Lifton.

</doc>
<doc id="45922" url="https://en.wikipedia.org/wiki?curid=45922" title="Geometric distribution">
Geometric distribution

\!</math>
In probability theory and statistics, the geometric distribution is either of two discrete probability distributions:
Which of these one calls "the" geometric distribution is a matter of convention and convenience.
These two different geometric distributions should not be confused with each other. Often, the name "shifted" geometric distribution is adopted for the former one (distribution of the number "X"); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly.
It’s the probability that the first occurrence of success requires "k" number of independent trials, each with success probability p. If the probability of success on each trial is "p", then the probability that the "k"th trial (out of "k" trials) is the first success is
for "k" = 1, 2, 3, ...
The above form of geometric distribution is used for modeling the number of trials up to and including the first success. By contrast, the following form of the geometric distribution is used for modeling the number of failures until the first success:
for "k" = 0, 1, 2, 3, ...
In either case, the sequence of probabilities is a geometric sequence.
For example, suppose an ordinary die is thrown repeatedly until the first time a "1" appears. The probability distribution of the number of times it is thrown is supported on the infinite set { 1, 2, 3, ... } and is a geometric distribution with "p" = 1/6.
Introduction to the geometric distribution.
Consider a sequence of trials, where each trial has only two possible outcomes (designated failure and success). The probability of success is assumed to be the same for each trial. In such a sequence of trials, the geometric distribution is useful to model the number of failures before the first success. The distribution gives the probability that there are zero failures before the first success, one failure before the first success, two failures before the first success, and so on.
Examples.
A newly-wed couple plans to have children, and will continue until the first girl. What is the probability that there are zero boys before the first girl, one boy before the first girl, two boys before the first girl, and so on?
A doctor is seeking an anti-depressant for a newly diagnosed patient. Suppose that, of the available anti-depressant drugs, the probability that any particular drug will be effective for a particular patient is p=0.6. What is the probability that the first drug found to be effective for this patient is the first drug tried, the second drug tried, and so on? What is the expected number of drugs that will be tried to find one that is effective?
A patient is waiting for a suitable matching kidney donor for a transplant. If the probability that a randomly selected donor is a suitable match is p=0.1, what is the expected number of donors who will be tested before a matching donor is found?
Assumptions: When is the geometric distribution an appropriate model?
The geometric distribution is an appropriate model if the following assumptions are true.
If these conditions are true, then the geometric random variable is the count of the number of failures before the first success. The possible number of failures before the first success is 0, 1, 2, 3, and so on. The geometric random variable Y is the number of failures before the first success. In the graphs above, this formulation is shown on the right.
An alternative formulation is that the geometric random variable X is the total number of trials up to and including the first success, and the number of failures is X-1. In the graphs above, this formulation is shown on the left.
Probability of outcomes.
Consider the anti-depressant example above. The probability that any given drug is effective (success) is p=0.6. The probability that a drug will not be effective (fail) is q = 1 – p = 1 – 0.6 = 0.4. Here are probabilities of some possible outcomes.
(i) The first drug works. There are zero failures before the first success. Y = 0 failures. The probability p(zero failures before first success) is simply the probability that the first drug works.
(ii) The first drug fails, but the second drug works. There is one failure before the first success. Y= 1 failure. The probability for this sequence of events is p(first drug fails) * p(second drug is success) which is given by
The general formula to calculate the probability of k failures before the first success, where the probability of success is p and the probability of failure is q = 1 - p, is
for k = 0, 1, 2, 3, ...
For the newly-weds awaiting their first girl, the probability of no boys before the first girl is
The probability of one boy before the first girl is
The probability of two boys before the first girl is
and so on.
Expected number of failures before the first success.
For the geometric distribution, the expected (mean) number of failures before the first success is E(Y) = (1-p)/p.
For the anti-depressant example, with p=0.6, the mean number of failures before the first success is E(Y) = (1-p)/p = (1-0.6)/0.6 = 0.67.
For the kidney-donor example, with p=0.1, the mean number of failures before the first success is E(Y) = (1-0.1)/0.1 = 9.
For the alternative formulation, where X is the number of trials up to and including the first success, the expected value is E(X) = 1/p.
Moments and cumulants.
The expected value of a geometrically distributed random variable "X" is 1/"p" and the variance is (1 − "p")/"p"2:
Similarly, the expected value of the geometrically distributed random variable "Y = X − 1" (where Y corresponds to the pmf listed in the right column) is q/"p" = (1 − "p")/"p", and its variance is (1 − "p")/"p"2:
Let "μ" = (1 − "p")/"p" be the expected value of "Y". Then the cumulants formula_30 of the probability distribution of "Y" satisfy the recursion
"Outline of proof:" That the expected value is (1 − "p")/"p" can be shown in the following way. Let "Y" be as above. Then
Parameter estimation.
For both variants of the geometric distribution, the parameter "p" can be estimated by equating the expected value with the sample mean. This is the method of moments, which in this case happens to yield maximum likelihood estimates of "p".
Specifically, for the first variant let "k" = "k"1, ..., "k""n" be a sample where "k""i" ≥ 1 for "i" = 1, ..., "n". Then "p" can be estimated as
In Bayesian inference, the Beta distribution is the conjugate prior distribution for the parameter "p". If this parameter is given a Beta("α", "β") prior, then the posterior distribution is
The posterior mean E["p"] approaches the maximum likelihood estimate formula_35 as "α" and "β" approach zero.
In the alternative case, let "k"1, ..., "k""n" be a sample where "k""i" ≥ 0 for "i" = 1, ..., "n". Then "p" can be estimated as
The posterior distribution of "p" given a Beta("α", "β") prior is
Again the posterior mean E["p"] approaches the maximum likelihood estimate formula_35 as "α" and "β" approach zero.
Related distributions.
Since: formula_54
Computer software for the geometric distribution.
Geometric distribution using R.
The R function codice_1 calculates the probability that there are k failures before the first success, where the argument "prob" is the probability of success on each trial.
For example,
codice_2
codice_3
R uses the convention that k is the number of failures, so that the number of trials up to and including the first success is k + 1.
The following R code creates a graph of the geometric distribution from Y= 0 to 10, with p=0.6.
codice_4
Geometric distribution using Excel.
The geometric distribution, for the number of failures before the first success, is a special case of the negative binomial distribution, for the number of failures before s successes.
The Excel function codice_5 calculates the probability of k = number_f failures before s = number_s successes where p = probability_s is the probability of success on each trial. For the geometric distribution, let number_s = 1 success.
For example,
codice_6 = 0.6
codice_7 = 0.24
Like R, Excel uses the convention that k is the number of failures, so that the number of trials up to and including the first success is k + 1.

</doc>
<doc id="45927" url="https://en.wikipedia.org/wiki?curid=45927" title="Podkayne of Mars">
Podkayne of Mars

Podkayne of Mars is a science fiction novel by Robert A. Heinlein, originally serialised in "Worlds of If" (November 1962, January, March 1963), and published in hardcover in 1963. The novel is about a teenage girl named Podkayne "Poddy" Fries and her younger, asocial genius brother, Clark, who leave their home on Mars to take a trip on a spaceliner to visit Earth, accompanied by their uncle.
This book, along with "Starship Troopers", shows Heinlein moving away from his old, comfortable territory of juvenile science fiction novels. Both books were written for a publisher expecting to market a juvenile science fiction novel, and both raised serious objections from the publisher.
Plot summary.
The book is a first-person narrative in the form of Podkayne's diaries. Podkayne is 15 in Earth years (a bit over eight Martian years) while her genius younger brother Clark is 11 earth years. Due to the unscheduled "uncorking" (birth) of their three test-tube babies, Podkayne's parents cancel a much-anticipated trip to Earth. Disappointed, Podkayne confesses her misery to her uncle, Senator Tom Fries, an elder statesman of the Mars government. Tom arranges for Clark and Podkayne, escorted by himself, to get upgraded passage on a luxury liner to Earth.
During boarding, Clark is asked by a customs official "Anything to declare?" and facetiously answers "Two kilos of happy dust!" As he anticipated, his seemingly flippant remark gets him taken away and searched, just in time to divert attention away from Podkayne's luggage, where he has hidden a package he was paid to smuggle aboard. Podkayne suspects the reason behind her brother's behavior, but cannot prove it. Clark was told it was a present for the captain, but is far too cynical to be taken in. He later carefully opens the package and finds a nuclear bomb, which he, in typical Clark-fashion, disarms and keeps.
Much of the description of the voyage is based on Heinlein's own experiences as a naval officer and world traveler. Clark's ploy is taken from a real-life incident, related in Heinlein's "Tramp Royale", in which his wife answers the same question with "heroin" substituted for the fictitious, but equally illegal, happy dust.
Once aboard, they are befriended by "Girdie", an attractive, capable, experienced woman left impoverished by her late husband. Much to Podkayne's surprise, the normally very self-centered Clark contracts a severe case of puppy love.
The liner makes a stop at Venus, which is depicted as a latter-day Las Vegas gone ultra-capitalistic. The planet is controlled by a single corporation; the dream of most of the frantically enterprising residents is to earn enough to buy a single share in it, which guarantees lifelong financial security. Just about anything goes, as long as one can pay for it. The penalty for murder is a fine paid to the corporation for the victim's estimated value plus his projected future earnings. On a less serious level, Heinlein anticipated, by over forty years, television ads in taxicabs (in the book, holographic), which have since been implemented in taxicabs in major cities worldwide.
The Fries are given VIP treatment by the Venus Corporation and Podkayne is escorted by Dexter Cunha, the Chairman's dashing son. She begins to realize that Tom is much more than just her pinochle-playing uncle. When Clark vanishes and even the corporation is unable to find him, Tom reveals that he is on a secret diplomatic mission, and the children have been his protective coloration—Tom appearing to be a doddering uncle escorting two young people on a tour of the solar system rather than the accredited representative to a vital conference on Luna that he is. Clark has been kidnapped by members of a political faction opposed to Tom.
Podkayne makes an ill-judged attempt to rescue Clark by herself and falls into the kidnappers' clutches as well—only to find her uncle caught too. The captors' scheme is to use the children to blackmail the uncle into doing their bidding at the Luna conference. Clark quickly realizes that once Uncle Tom is released, no matter what happens, their kidnappers will have little reason to keep their prisoners alive. He is prepared, however: he engineers an escape, kills his captors, and forgets to disable the nuclear bomb he had intended to go off only if they failed in their escape.
Two versions of the ending.
In Heinlein's original ending, Podkayne is killed. This did not please his publisher, who demanded and got a rewrite over the author's bitter objections. In a letter to Lurton Blassingame, his literary agent, Heinlein complained that it would be like "revising Romeo and Juliet to let the young lovers live happily ever after." He also declared that changing the end "isn't real life, because in real life, not everything ends happily."
In the original ending, after they escape from the kidnappers to a safe distance, Podkayne remembers that a semi-intelligent Venerian "fairy" baby has been left behind, and returns to rescue it. When the bomb that Clark leaves for the kidnappers blows up, Podkayne is killed, shielding the young fairy with her body. Clark takes over the narrative for the last chapter. The story ends with a hint of hope for him, as he admits his responsibility for what happened to Podkayne — that he "fubbed it, mighty dry" — then shows some human feeling by regretting his inability to cry and describes his plan to raise the fairy himself.
In the revised version, Podkayne is badly injured by the bomb, but not fatally. Uncle Tom, in a phone conversation with Podkayne's father, blames the parents — especially the mother — for neglecting the upbringing of the children. Uncle Tom feels that Clark is dangerous and maladjusted, and attributes this to the mother giving priority to her career. Clark still takes over as the narrator, and, again, regrets that Podkayne was hurt and plans to take care of the fairy, this time because Podkayne will want to see it when she is better. This is the ending that appeared when the book was published 1963.
The 1993 Baen edition included both endings (which differ only on the last page) and featured a "pick the ending" contest, in which readers were asked to submit essays on which ending they preferred. The 1995 edition included both endings, Jim Baen's own postlude to the story, and twenty-five of the essays. The ending in which Podkayne dies was declared the winner. Among the reasons readers favored this ending were that they felt Heinlein should have been free to create his own story, and they believed the changed ending turned a tragedy into a mere adventure, and not a very well constructed one at that. This ending has appeared in all subsequent editions

</doc>
<doc id="45929" url="https://en.wikipedia.org/wiki?curid=45929" title="Dark Angel (TV series)">
Dark Angel (TV series)

Dark Angel is an American biopunk/cyberpunk science fiction television series. It was created by James Cameron and Charles H. Eglee and starred Jessica Alba in her breakthrough role. The series chronicles the life of Max Guevara, a genetically-enhanced super-soldier who escapes from a covert government military facility as a child. In a post-apocalyptic Seattle, she tries to lead a normal life, while eluding capture by government agents and searching for her genetically-enhanced brothers and sisters scattered in the aftermath of their escape. The series was filmed in Vancouver, British Columbia, at Lions Gate Studios.
The show premiered in the United States on the Fox network on October 3, 2000. The high-budget pilot episode was Cameron's television debut and was heavily promoted by Fox. The first season, which was shown on Tuesday nights in the U.S., received mainly positive reviews and won several awards. Alba's portrayal of Max also received mostly positive reviews. For the second season the show was moved to Friday nights, received some criticism for new plot elements and suffered from a ratings drop. It was subsequently cancelled. The storyline was continued in a series of novels; a video game adaptation was also released after the show's cancellation.
Plot.
Season one.
In 2009, a genetically enhanced, nine-year-old female supersoldier designated as X5-452 (Geneva Locke) escapes along with eleven others from a secret government institution, codenamed Manticore, where they were born, raised and trained to be soldiers and assassins. On June 1, 2009, months after Max's escape, terrorists detonate an electromagnetic pulse weapon in the atmosphere over the U.S., which destroys the vast majority of computer and communication systems, throwing the country into chaos.
Ten years later in 2019, the now 19-year-old X5-452 (Jessica Alba), who calls herself Max Guevara, struggles to search for her Manticore brothers and sisters. In a recovering United States, which is now barely more than a Third World nation, she tries to live a relatively normal life and evade capture from Manticore, who wish to recover their lost asset. She joins forces and develops a romantic interest with Logan Cale (Michael Weatherly), an underground cyber-journalist with the alias Eyes Only. Logan recruits her to help fight corruption in the post-Pulse world; at the same time she makes a living as a bicycle messenger at Jam Pony, a courier company, along with her friends Original Cindy (Valarie Rae Miller), Herbal Thought (Alimi Ballard), and Sketchy (Richard Gunn). Other X5s are periodically introduced, most significantly Zack (William Gregory Lee), the unit leader. The Manticore hunt for the escaped X5s is led by Colonel Donald Lydecker (John Savage). Near the end of the season, Lydecker is betrayed by his superior, the even more ruthless Elizabeth Renfro (Nana Visitor), and subsequently defects from Manticore. He aids Max and Zack in an assault on the Manticore headquarters, though Max is badly wounded and captured. Zack, who has also been captured, commits suicide to provide Max with his heart, as she needs an X5 heart transplant to survive.
Season two.
Aided by Alec (Jensen Ackles), a fellow X5 who later joins Jam Pony, and Joshua (Kevin Durand), a transgenic with canine DNA, Max escapes the facility. When Max is reunited with Logan he immediately becomes ill and almost dies. Max discovers that Manticore infected her with a virus specifically designed to kill Logan, and the two must avoid all physical contact to keep him alive. Alec follows her to Logan's and informs her that she needs to take Logan and return to Manticore in order to save him. Instead, Max uses Logan's Eyes Only setup and exposes Manticore to the world. Renfro decides to burn the facility in an attempt to cover up the evidence, though she is killed in the process when Max returns to retrieve the life-saving serum Logan needs. Max takes this opportunity to save numerous transgenics, releasing them out into the world. Max learns that Joshua was the first transgenic created by Sandeman, Manticore's founder. It is revealed that a millennia-old breeding cult, similar in structure to the Illuminati, has bred their own super-soldiers that rival the Manticore-produced transgenics. Ames White (Martin Cummins), a government agent tasked with eliminating the freed transgenics, is revealed to be a member of the cult. When a strange message written in Max's genetic code makes an appearance on her skin, it is revealed that Sandeman is a renegade from the breeding cult and Ames White is his son. White is still loyal to the cult and hates his father's transgenic creations with a passion. Believing that Max is a threat to their plans, the breeding cult attempt to kill her, though she escapes to Terminal City, an abandoned part of Seattle where hundreds of outcast transgenics have been hiding. When the police begin to surround Terminal City, Max convinces the other transgenics to stand their ground rather than run. The series ends with the military surrounding and possibly preparing to invade Terminal City, as the residents raise their newly designed flag from one of their buildings.
Storyline for season three.
In the DVD commentary for "Freak Nation", the series finale, Charles H. Eglee, the executive producer and co-creator, explained what was planned for season three. The intention was to bring together the storylines of seasons one (Manticore) and two (breeding cult) and reveal the mythology of "Dark Angel".
The show's mythology was planned to be that, thousands of years ago, Earth passed through a comet's tail which deposited viral material that killed 97% of the human race. The great pyramids in Egypt were actually genetic repositories, preserving the DNA of the survivors, built by the breeding cult to pass on this genetic immunity so that when the comet returned only members of the cult would survive. Sandeman, a cult member and Max's creator, betrayed the cult and decided to give this genetic immunity to the rest of humanity, believing that everybody deserved the cure. The other cult members deemed Sandeman a heretic and a threat, undermining their goals of rebuilding humanity in their own image. Sandeman found a way to spread this genetic immunity to everyone through Max, who would be the savior of the human race. There were multiple ideas of how to spread Max's immunity to humanity, including an air burst that would disperse the antibody through the atmosphere, or attaching the immunity to a common cold virus (Eglee detailed how a scene would show Original Cindy sneezing as part of the beginning of the immunity spread). This intended storyline is expanded on in the final "Dark Angel" novel "After the Dark", though when the comet returns nobody falls ill, and it is believed that the cult simply had a false prediction.
Cast and characters.
The first season introduced Jessica Alba as the main character Max Guevara (X5-452), a genetically enhanced transgenic super-soldier who escaped from the government facility Manticore and now works as a bike messenger for courier company Jam Pony and as a cat burglar. Michael Weatherly played Logan Cale ("Eyes Only"), the second most prominent character. Cale is a wealthy cyber-journalist and vigilante who recruits Max to aid his campaign against corruption and crime in return for helping her find information on her fellow Manticore escapees. Main roles were given to several of the staff at Jam Pony, including J. C. MacKenzie as Reagan "Normal" Ronald, the company's boss, Valarie Rae Miller as Cynthia "Original Cindy" McEachin, Richard Gunn as Calvin "Sketchy" Theodore and Alimi Ballard as Herbal Thought, all of whom worked as couriers. Jennifer Blanc plays Kendra Maibaum, Max's first roommate, and John Savage plays the main antagonist, Col. Donald Lydecker, who is trying to recapture Max and the other Manticore escapees.
Col. Donald Lydecker's character is written out of the series early in the second season, and Herbal Thought and Kendra Maibuam do not appear at all. Season two introduces the main characters Jensen Ackles as Alec McDowell (X5-494), an X5 who has escaped from the recently destroyed Manticore facility, as well as Kevin Durand as Joshua, the first transgenic experimental creature from Manticore who has distinct canine facial features. Ashley Scott plays Asha Barlow, a member of the S.1.W. insurgent group and a friend to Logan. Martin Cummins portrays the season's main antagonist Ames White, a National Security Agency agent and cult member tasked with destroying the Manticore escapees.
Production.
Background.
Following his success with the film "Titanic", the director James Cameron teamed up with Eglee, with whom he had previously worked on projects including "". The two formed a production company and began working on ideas for a television series, considering several options including a family drama before deciding on the idea of "Dark Angel". Cameron said they began with the idea that Max would be genetic construct who "looked normal on the outside but was different on the cellular, genetic level. We explore what that could mean." Max followed a long line of strong female characters in Cameron's work, including Sarah Connor and Ellen Ripley. Cameron said "it's a win/win situation" as "women respond to characters who appear strong and capable" and young male audiences "want to see girls kick ass". Later they decided to set the series in a post-social collapse world, saying that the hysteria surrounding Y2K served as inspiration for the 'Pulse' in the series which has destroyed all computers in the United States. Working titles for the series included "Experimental Girl" and "Maximum Girl". The project marked Cameron's debut into television; Cameron would be working as a writer and executive producer, rather than directing.
Casting and filming.
More than 1000 young actresses were considered for the part of Max, and Cameron started reviewing audition tapes when it had been narrowed down to 20 or 30 applicants. Cameron was not impressed with Alba's audition tape, saying "she had her head down, she was reading out of the script ... she didn't present herself all that well. But there was something about the way she read the script that copped an attitude that I liked." Cameron continually reviewed the audition tapes but kept coming back to Alba's, eventually deciding that he needed to meet her. Alba was hired for the role before the script was written. Eglee said "We had the benefit of being able to write a script kind of backwards, we were writing for this actress, with her cadences and her rhythms and her sensibilities and her attitude and her slang." In order to train for the role, Alba spent a year doing martial arts and gymnastics and riding motorcycles.
The two-hour premiere episode cost up to $10 million to produce, and Cameron reportedly "brought the pilot in on time and on budget". Subsequent episodes had a considerably lower budget. Fox spent heavily on the promotional campaign for the premiere, paying for theatrical trailers, billboards and guerilla marketing. Cameron took a "very basic view" of the show's chance of success, saying "If it flies, it flies. If it doesn't, it doesn't ... If people connect with it, which I hope they will, fine. If we don't find an audience, we deserve to be off the air. It's that simple." Eglee admitted the series had been "routinely overbudget" for the first season, and feared that this would be a factor in whether the show was renewed for a second season, though Cameron downplayed the concerns.
Fox "just barely" renewed the series for a second season. The cost of episodes in season two was $1.3 million each. After the planned director for the final episode fell through, Cameron decided to step in and fill the position. He did this partially for the experience but also to show the network the potential for the third season. It was his first experience directing a TV drama. The producers were initially told a third season had been approved, but two days later Fox informed them that the series had actually been cancelled. 
While "Dark Angel" was set in Seattle, filming took place in Vancouver, British Columbia, at Lions Gate Studios. Other filming locations included the Vancouver Art Gallery, as well as Buntzen Lake and Riverview Hospital, also in British Columbia.
Broadcast history.
The first season premiered in the United States on Tuesday, October 3, 2000, from 9:00 pm until 11:00 pm. Fox had to obtain agreements from its affiliates to broadcast past 10:00 pm, as most of them air local news programs at this time. For the second season Fox moved the airing time from Tuesdays at 9:00 pm, where it had been competing with "Angel" on The WB, to at 8:00 pm on Fridays, where it preceded the new series "Pasadena".
The final episode of the series aired on May 3, 2002 as a special 90-minute episode. "Dark Angel" has been syndicated on the Syfy and the El Rey Network in the United States and on E4 and the Horror Channel in the UK.
Music.
The score for the "Dark Angel" pilot was composed and conducted by Joel McNeely. The score track "Bicycle Ride" was used in the end credits for the duration of the series. The pilot score was released in full as part of the original publicity press kit, titled "Dark Angel: Complete Score from the Dark Angel Pilot". The 37-track CD was for promotional use only and not for resale.
A soundtrack album consisting of hip hop and R&B songs was released on April 23, 2002 through Artemis Records. It peaked at No. 50 on the Top Independent Albums chart. Jason Birchmeier from AllMusic gave the soundtrack three out of five stars, calling it "impressive" and adding that it "exceeds your expectations for a television show soundtrack".
Reception and legacy.
Initial reaction to the series and the character of Max was mostly positive, with favorable reviews in "Rolling Stone" and "Time". Hal Boedeker from the "Orlando Sentinel" said "Television's newest warrior woman possesses skills worthy of Catwoman, Xena, Emma Peel and Wonder Woman." Howard Rosenberg said "If pouty faces and sexy walks could destroy, the highly arresting Max would be wiping out the entire planet." However Joyce Millman said Max was "little more than lips and ass" and that the series was "the most expensive Britney Spears video ever made." "People" gave a negative review of the Pilot episode in October 2000, though in December they listed Alba's portrayal of Max as among the "breakthrough" performances of 2000.
The first episode was only behind "" as the most watched new show of the week, albeit in a week with fewer new shows due to presidential debate coverage. Fox chose to debut "Dark Angel" instead of airing the first presidential debate, a move which TV analyst Marc Berman praised, saying "The people who watch the debates aren't the people who'll tune into "Dark Angel" anyway", though he predicted that the high ratings of the premiere would not hold up as the show competed against more various competition in subsequent weeks. It was the tenth most popular show overall that week, attracting 17.4 million viewers. Cameron said he did not know if the airing time change for the second season would have a positive or negative effect on the shows ratings, though R. D. Heldenfels from the "Sun Journal" noted the poor ratings of Friday night television, especially the low viewing rates among 18- to 24-year-olds, the age-group that "Dark Angel" was most popular with. The new time slot saw a ratings drop; for the 2001–02 season "Dark Angel" averaged 6 million viewers, ranking at No. 114 in Nielsen ratings.
Commenting at the release of the second season, Cynthia Fuchs from "PopMatters" said the first season of "Dark Angel" was one of the "few straight-up successes, a ratings hit among the coveted 'youth' demographic". She praised the series but clarified "I'm not getting carried away: Jim Cameron is not going to be making revolutionary art anytime soon." Michael Sauter from "Entertainment Weekly" gave the first season a B+ and spoke highly of Alba, saying that "for a while was TV's hottest kick-butt heroine." Elka Karl from Common Sense Media gave the entire series 3 out of 5 stars, saying "While the dialogue sometimes falls flat, overall the show is well-scripted and well acted, and Alba does an excellent job of carrying the series. Dark Angel isn't perfect by any stretch of the imagination, but it is compelling television that teen sci-fi fans will enjoy." While praising the first season, Randy Dankievitch from "TVOvermind" labelled the second season as "silly", criticizing "dumb stories" like Max's dream episode "Boo", the virus that prevents Logan and Max having physical contact, and the various half-animal Manticore experiments that are revealed.
Writing in his book "The Encyclopedia of Superheroes on Film and Television", John Kenneth Muir said it was necessary for Cameron to set "Dark Angel" in the future because the prosperity of the U.S. in 2000 "offered little possibility for crime, squalor and other societal problems." While criticizing certain plot elements in the second season as contributing to the show's downfall, Muir said a larger factor in the ratings drop was the change of life in the U.S. following events including the September 11 attacks, the Enron scandal, as well as the government losing their financial surplus, which changed "Dark Angel's" "futuristic vision of recession in a Third-World America" from an interesting far-fetched premise to a "depressing reminder that things could still get worse".
In 2004, Max was ranked at No. 17 in "TV Guide"s list of the "25 Greatest Sci-Fi Legends", and in 2012, Dave Golder from GamesRadar ranked her at No. 49 on his list of the 100 sexiest women in sci-fi.
The 2007 film "Hitman" re-used footage from "Dark Angel" of Max and other Manticore children in training. The footage was used to portray the Hitman protagonist Agent 47, a cloned assassin who like the Manticore children, has a barcode on the back of his head.
Accolades.
For its first season "Dark Angel" won the "Favorite Television New Dramatic Series" award at the 27th People's Choice Awards, and was nominated for "Best Television" at the International Horror Guild Awards. The production team was nominated for the "Excellence in Production Design Award" at the Art Directors Guild. Editor Stephen Mark won "Best Edited Motion Picture for Commercial Television" at the Eddie Awards for the pilot episode, and the pilot was also nominated for Outstanding Special Visual Effects at the 53rd Primetime Emmy Awards and "Best Visual Effects: Dramatic Series" at the Leo Awards.
Jessica Alba won "Best Actress on Television" at the 27th Saturn Awards, "Breakout Star of the Year" at the TV Guide Awards, "Outstanding Actress in a New Television Series" at the ALMA Awards and "Choice Actress" at the 2001 Teen Choice Awards. She was nominated for Best Actress – Television Series Drama at the 58th Golden Globe Awards and "Best Performance in a TV Drama Series – Leading Young Actress" at the 22nd Young Artist Awards.
"Dark Angel" was nominated for fewer awards in its second season. It was nominated for "Choice Drama/Action Adventure" at the 2002 Teen Choice Awards, where Alba was also nominated for "Choice Actress, Drama". Alba was also nominated for "Outstanding Actress in a Television Series" at the ALMA Awards. At the Leo Awards the episode "Boo" was nominated for "Best Visual Effects: Dramatic Series", and David Geddes won "Best Cinematography: Dramatic Series" for the episode "Two".
Home media.
20th Century Fox Home Entertainment released seasons 1 and 2 of "Dark Angel" on DVD in region 1 (R1), as well as a dual-coded region 2 and 4 (R2/4) set in 2003, as six-disc sets packaged in cardboard sleeves containing three DVD cases each of two discs. Season 1 was released in R2/4 in February and R1 in May, and season 2 was released in R2/4 in June and R1 in October.
The R1 releases contain several special features, including four episodes with optional commentary in each season, bloopers, deleted scenes and featurettes. The R2/4 releases contain no commentaries and fewer other special features, but the episodes are presented in anamorphic widescreen, while R1 releases are fullscreen. Adam Tyner from "DVD Talk" gave the R1 first season three out of five stars for audio and video, and three and a half stars for special features. Shannon Nutt from "DVD Talk" gave the R1 second season three stars out of five for audio and video, and two and a half stars for extras, stating "it appears have a decent number of features, but then you discover the length of each one and really feel short-changed by Fox", also noting the commentary in episodes was mainly with writers and producers, and did not feature James Cameron or any of the actors.
Both seasons were re-released in R1 on June 5, 2007, with slim packaging consisting of one plastic case containing all six discs (which were unchanged in content and cosmetics).
Related media.
A video game of the same name based on the series was created by Radical Entertainment and released on PlayStation 2 on November 18, 2002, and later on Xbox. Alba and Weatherly voiced their respective characters in the game. Development of the game started before the series was cancelled, and the game was met with mixed to negative reception upon release. Brett Todd from GameSpot gave the game 3.8 out of 10, saying "Although it's impossible to say whether or not the developers' morale was affected by the cancellation of the series, this third-person action adventure plays like it was cranked out to fulfill a contract" and concluding "the development of this game probably should have been cancelled at the same time as the television series".
Written by Max Allan Collins, three original novels expand upon the "Dark Angel" television series, with two picking up directly where the series ended.
A companion book, "Dark Angel: The Eyes Only Dossier", was also published in 2003. It is attributed to Logan Cale and was supposedly compiled by D. A. Stern. The book begins with a letter written by Logan during the stand-off at Terminal City. It is addressed to Detective Matt Sung, a recurring character from the series who aides Logan, instructing him that the package he is sending him contains documents pertaining to the four most critical Eyes Only investigations. In the event that Logan is killed by the potential invasion of Terminal City, he wants Sung to carry on the investigations. The rest of the book contains said documents relating to the four investigations.
Alleged plagiarism.
After the show's release the Argentine artists Carlos Trillo and Carlos Meglia, creators of the Argentine comic book series "Cybersix", filed a lawsuit against Cameron and Fox for plagiarism. "Cybersix" was created by Trillo (writer) and Meglia (penciler) in the early 90s for the European market, and appeared in Spanish in November 1993; an animated TV series based on the comic strip was released in 1999. Trillo and Meglia accused "Dark Angel" of stealing most of the comic's plot and its most recognizable elements. In a 2007 interview Trillo stated that he and Meglia were not able to carry on with the lawsuit due to lack of financial resources, so they dropped it, although the issue is still a matter of controversy:
Meglia and I were sure we had been plagiarized. "Cybersix" readers who watched Cameron's TV series were sure as well. We tried to move forward with a lawsuit against Cameron and Fox. It wasn't possible for us to continue because the comic book world does not give you the financial possibility Argentina of confronting a showbusiness multinational company. We couldn't afford lawyers in LA to carry on with the attempt to claim our original story.
References.
Bibliography

</doc>
<doc id="45930" url="https://en.wikipedia.org/wiki?curid=45930" title="Index fossil">
Index fossil

Index fossils (also known as guide fossils, indicator fossils or zone fossils) are fossils used to define and identify geologic periods (or faunal stages). They work on the premise that, although different sediments may look different depending on the conditions under which they were laid down, they may include the remains of the same species of fossil. If the species concerned were short-lived (in geological terms, lasting a few hundred thousand years), then it is certain that the sediments in question were deposited within that narrow time period. The shorter the lifespan of a species, the more precisely different sediments can be correlated, and so rapidly evolving types of fossils are particularly valuable. The best index fossils are common, easy-to-identify at species level, and have a broad distribution—otherwise the likelihood of finding and recognizing one in the two sediments is minor.
Ammonites fit these demands well, and are the best-known fossils that have been widely used for this. Other important groups that provide index fossils are the corals, graptolites, brachiopods, trilobites, and echinoids (sea urchins). Conodonts may be identified by experts using light microscopy such that they can be used to index a given sample with good resolution. Fossilized teeth of mammals have also been used.
Geologists use both large fossils (called macrofossils) and microscopic fossils (called microfossils) for this process, known as biostratigraphy. Macrofossils have the advantage of being easy to see in the field, but they are rarer, and microfossils are very commonly used by oil prospectors and other industries interested in mineral resources when accurate knowledge of the age of the rocks being looked at is needed.
The series of deposits that spans the occurrence of a particular index fossil, is often referred to as that fossil's zone, enabling to relate different faunas through time. An example would be to say that "Mesolenellus hyperborea" occurs in the late "Nevadella"-zone.
How index fossils are used.
"Imagine an E.L. Doctorow novel in which Alfred Tennyson, William Tweed, Abner Doubleday, Jim Bridger, and Martha Jane Canary sit down to a dinner prepared by Rutherford B. Hayes. ... a geologist could quickly decide -- as could anyone else -- that the dinner must have occurred in the middle 1870s, because Canary was 18 when the decade began, Tweed became extinct in 1878, and the biographies of the others do not argue with these limits." -- John McPhee, "Basin and Range" (1981).

</doc>
<doc id="45936" url="https://en.wikipedia.org/wiki?curid=45936" title="Spirit possession">
Spirit possession

Spirit possession is a term for the belief that animas, demons, extraterrestrials, gods, or spirits can take control of a human body. The concept of spirit possession exists in many religions, including Christianity, Buddhism, Haitian Vodou, Wicca, Hinduism, Islam and Southeast Asian and African traditions. Depending on the cultural context in which it is found, possession may be considered voluntary or involuntary and may be considered to have beneficial or detrimental effects to host. Within possession cults, the belief that one is possessed by spirits is more common among women than men.
African traditions.
Zār cult.
In Sudan and certain East African cultures the Zār cult conducts ethnomedical healing ceremonies involving possession, typically of Muslim women by a Zār spirit. This is also found in North Africa as well. 
Horn of Africa.
Ethiopia.
Gurage people.
Among the Gurage people of Ethiopia, spirit possession is a common belief. Wiliam A. Shack postulated that it is caused by Gurange cultural attitudes about food and hunger, while they have a plentiful food supply, cultural pressures that force the Gurange to either share it to meet social obligations, or hoard it and eat it secretly cause feelings of anxiety. Distinctions are drawn between spirits that strictly possess men, spirits that possess women, and spirits that possess victims of either sex. A ritual illness that only affects men is believed to be caused by a spirit called "awre". This affliction presents itself by loss of appetite, nausea, and attacks from severe stomach pains. If it persists the victim may enter a trancelike stupor, in which he sometimes regains consciousness long enough to take food and water. Breathing is often labored. Seizures and trembling overcome the patient, and in extreme cases, partial paralysis of the extremities.
If the victim does not recover naturally, a traditional healer, or "sagwara", is summoned. Once the "sagwara" has determined the spirit's name through the use of divination, he prescribes a routine formula to exorcise the spirit. This is not a permanent cure, however, it is believed to allow the victim to form a relationship with the spirit. Nevertheless, the victim is subject to chronic repossession, which is treated by repeating the formula. This formula involves the preparation and consumption of a dish of ensete, butter, and red pepper. During this ritual, the victim's head is covered with a drape, and he eats the ensente ravenously while other ritual participants participate by chanting. The ritual ends when the possessing spirit announces that it is satisfied. Shack notes that the victims are overwhelmingly poor men, and that women are not as food-deprived as men are due to ritual activities that involve food redistribution and consumption. Shack postulates that the "awre" serves to bring the possessed man to the center of social attention, and to relieve his anxieties over his inability to gain prestige from redistributing food, which is the primary way in which Gurange men gain status in their society.
Sidama people.
The belief in spirit possession is part of their native culture of the Sidama people of southwest Ethiopia. Anthropologists Irene and John Hamer postulated that it is a form of compensation for being deprived within Sidama society, although they do not draw from I.M Lewis (see Cultural anthropology section under Scientific views). The majority of the possessed are women whose spirits demand luxury goods to alleviate their condition, but men can be possessed as well. Possessed individuals of both sexes can become healers due to their condition. Hamer and Hamer suggest that this is a form of compensation among deprived men in the deeply competitive society of the Sidama, for if a man cannot gain prestige as an orator, warrior, or farmer, he may still gain prestige as a spirit healer. Women are sometimes accused of faking possession, but men never are.
East Africa.
Kenya.
Digo people.
The Digo people of Kenya refer to the spirits that supposedly possess them as "shaitani". These "shaitani" typically demand luxury items to make the patient well again. Despite the fact that men sometimes accuse women of faking the possessions in order to get luxury items, attention, and sympathy, they do generally regard spirit possession as a genuine condition, and view victims of it as being ill through no fault of their own. However, men sometimes suspect women of actively colluding with spirits in order to be possessed.
Giriama people.
The Giriama people of coastal Kenya believe in spirit possession.
Mayotte.
In Mayotte, approximately 25% of the adult population, and five times as many women as men, enter trance states in which they are supposedly possessed by certain identifiable spirits who maintain stable and coherent identities from one possession to the next.
Mozambique.
In Mozambique, a new belief in spirit possession appeared after the Mozambican Civil War. These spirits, called "gamba", are said to be identified as dead soldiers, and allegedly overwhelmingly possess women. Prior to the war, spirit possession was limited to certain families and was less common.
Uganda.
In Uganda, a woman named Alice Auma was reportedly possessed by the spirit of a male Italian soldier named Lakwena, meaning messenger. She had ultimately led a failed insurrection against governmental forces.
Southern Africa.
South Africa.
A belief in spirit possession appears among the Xesibe, a Xhosa speaking people from Transkei, South Africa. The majority of the supposedly possessed are married women. The condition of spirit possession among them is called "inwatso". Those who develop the condition of "inwatso" are regarded as having a special calling to divine the future. They are first treated with sympathy, and then with respect as they allegedly develop their abilities to foretell the future.
Tanzania.
The Sukuma people of Tanzania believe in spirit possession.
Zanzibar.
A now extinct spirit possession cult existed among the Hadimu women of Zanzibar, revering a spirit called "kitimiri". This cult described in an 1869 account by a French missionary. The cult faded by the 1920s and was virtually unknown by the 1960s.
West Africa.
See Hausa animism
African diasporic traditions.
Haitian Vodou.
In Haitian Vodou and related African diaspora traditions, one way that those who participate or practice can have a spiritual experience is by being possessed by the "Loa" (or "lwa"). When the "loa" descends upon a practitioner, the practitioner's body is being used by the spirit, according to the tradition. Some spirits are believed to be able to give prophecies of upcoming events or situations pertaining to the possessed one, also called "Chwal" or the "Horse of the Spirit." Practitioners describe this as a beautiful but very tiring experience. Most people who are possessed by the spirit describe the onset as a feeling of blackness or energy flowing through their body as if they were beig electrocuted. According to Vodou believers, when this occurs, it is a sign that a possession is about to take place.
According to tradition, the practitioner has no recollection of the possession and in fact when the possessing spirit leaves the body, the possessed one is tired and wonders what has happened during the possession. It is also believed that there are those who feign possessions because they want attention or a feeling of importance, because those who are possessed carry a high importance in ceremony. Often, a "chwal" will undergo some form of trial or testing to make sure that the possession is allegedly genuine. As an example, someone possessed by one of the Guédé spirits may be offered "piment", a liqueur made by steeping twenty-one chili peppers in "kleren", a potent alcoholic beverage. If the "chwal" consumes the "piment" without showing any evidence of pain or discomfort, the possession is regarded as genuine.
Umbanda.
The concept of spirit possession is also found in Umbanda, an Afro-Brazilian folk religion. According to tradition, one such possessing spirit is Pomba Gira, who possesses both women and effeminate males.
Asian traditions.
Buddhism.
According to the Indian medical literature and Tantric Buddhist scriptures, most of the "seizers," or those that threaten the lives of young children, appear in animal form: cow, lion, fox, monkey, horse, dog, pig, cat, crow, pheasant, owl, and snake. But apart from these "nightmare shapes," it is believed the impersonation or incarnation of animals could in some circumstances also be highly beneficial, according to Michel Strickmann.
Ch'i Chung-fu, a Chinese gynecologist writing early in the thirteenth century, wrote that in addition to five sorts of falling frenzy classified according to their causative factors, there were also four types of other frenzies distinguished by the sounds and movements given off by the victim during his seizure: cow, horse, pig, and dog frenzies.
East-Asian religions.
Certain sects of Taoism, Korean shamanism, Shinto, some Japanese new religious movements, and other East-Asian religions feature the idea of spirit possession. Some sects feature shamans who supposedly become possessed, or mediums who allegedly channel beings' supernatural power, or enchanters who it is said imbue or foster spirits within objects, like samurai swords. Hong Kong film Super Normal II (大迷信1993) shows the famous story of a woman in Taiwan who possesses a dead body to live her predeterminated remaining life. She is still working in the Zhen Tian Temple in Yunlin.
Chinese traditions.
See Chinese spirit possession, Shi (personator)
Indian traditions.
Rajasthan.
The concept of spirit possession exists in the culture of modern Rajasthan. Some of the spirits allegedly possessing Rajasthanis are seen as good and beneficial, while others are seen as malevolent. The good spirits are said to include murdered royalty, the underworld god Bhaironji, and Muslim saints & fakirs. Bad spirits are believed to include perpetual debtors who die in debt, stillborn infants, deceased widows, and foreign tourists. The supposedly possessed individual is referred to as a "ghorala", or "mount". Possession, even if by a benign spirit, is regarded as undesirable, as it is seen to entail loss of self-control, and violent emotional outbursts.
Tamil.
Tamil women in India are said to experience possession by "pey" spirits. According to tradition, these spirits overwhelmingly possess new brides, are usually identified as the ghosts of young men who died while romantically or sexually frustrated, and are ritually exorcised.
Indonesian traditions.
Bali.
The animist traditions of the island of Bali (Indonesia) include a practice called "sanghyang", induction of voluntary possession trance states for specific purposes. Roughly similar to voluntary possession in Vaudon (Voodoo), "sanghyang" is considered a sacred state in which hyangs (deities) or helpful spirits temporarily inhabit the bodies of participants. The purpose of "sanghyang" is believed to be to cleanse people and places of evil influences and restore spiritual balance. Thus, it is often referred to as an exorcism ceremony.
Sulawesi.
The women of the Bonerate people of Sulawesi, Indonesia practice a possession-trance ritual in which they smother glowing embers with their bare feet at the climax.
Japanese traditions.
See Misaki
Malaysian traditions.
Female workers in Malaysian factories have allegedly become possessed by spirits, and factory owners generally regard it as mass hysteria and an intrusion of irrational and archaic beliefs into a modern setting.
The anthropologist Aihwa Ong noted that spirit possession beliefs in Malaysia were typically held by older, married women, whereas the female factory workers are typically young and unmarried. She connects this to the rapid industrialization and modernization of Malaysia. Ong argued that spirit possession is a traditional way of rebelling against authority without punishment, and suggests that it is a means of protesting the untenable working conditions and sexual harassment that the women were compelled to endure.
Sri Lankan traditions.
The Coast Veddas, a social group within the minority group of Sri Lankan Tamil people in Eastern Province, Sri Lanka, enter trances during religious festivals in which they are regarded as being possessed by a spirit. Although they speak a dialect of Tamil, during trances they will sometimes use a mixed language that contains words from the Vedda language.
Oceanic traditions.
Melanesia.
The Urapmin people of the New Guinea Highlands practice a form of group possession known as the "spirit disco" (Tok Pisin: "spirit disko"). Men and women gather in church buildings, dancing in circles and jumping up and down while women sing Christian songs; this is called "pulling the spirit" (Tok Pisin: "pulim spirit", Urap: "Sinik dagamin"). The songs' melodies are borrowed from traditional women's songs sung at drum dances (Urap: "wat dalamin"), and the lyrics are typically in Telefol or other Mountain Ok languages. If successful, some dancers will "get the spirit" (Tok Pisin: "kisim spirit"), flailing wildly and careening about the dance floor. After an hour or more, those possessed will collapse, the singing will end, and the spirit disco will end with a prayer and, if there is time, a Bible reading and sermon. The body is believed to normally be "heavy" (Urapmin: "ilum") with sin, and possession is the process of the Holy Spirit throwing the sins from one's body, making the person "light" ("fong") again. This is a completely new ritual for the Urapmin, who have no indigenous tradition of spirit-possession.
Micronesia.
The concept of spirit possession appears in Chuuk State, one of the four states of Federated States of Micronesia. Although Chuuk is an overwhelmingly Christian society, traditional beliefs in spirit possession by the dead still exist, usually held by women, and "events" are usually brought on by family conflicts. The supposed spirits, speaking through the women, typically admonish family members to treat each other better.
Christianity.
Roman Catholic doctrine states that angels are non-corporeal, spiritual beings with intelligence and will. Fallen angels, or demons, are able to "demonically possess" individuals without the victim's knowledge or consent, leaving them morally blameless.
Islam.
No verses in the Quran clearly support stories of spirit possession. One verse in the Quran describes the behavior of those who earn interest on borrowings, acting as if they were possessed or controlled by a satanic touch. Muslims are told to "seek refuge in Allah from the accursed devil" but the meaning of this prayer relates to the fear Muslims should have of the wrath of God, as the purpose of Shaitan is to mislead humans and make them disobey God. It is also stated in the Quran that the devil has no power of influence over those whom God has guided. For example:
Judaism.
Although forbidden in the Hebrew Bible, magic was widely practiced in the late Second Temple Period and well documented in the period following the destruction of the Temple into the 3rd, 4th, and 5th centuries C.E. In Jewish folklore, a Dybbuk is a disembodied spirit that wanders restlessly until it inhabits the body of a living person. The Baal Shem could expel the harmful dybbuk through exorcism.
Jewish magical papyri were inscriptions on amulets, ostraca and incantation bowls used in Jewish magical practices against shedim and other unclean spirits.
Wicca.
Wiccans believe in voluntary possession by the Goddess, connected with the sacred ceremony of Drawing Down the Moon. The high priestess solicits the Goddess to possess her and speak through her.
Scientific views.
Cultural anthropology.
The anthropologist I.M. Lewis noted that women are more likely to be involved in spirit possession cults than men are, and postulated that such cults act as a means of compensation for their exclusion from other spheres within their respective cultures.
Physical anthropology.
Anthropologists Alice B. Kehoe and Dody H. Giletti argued that the reason that women are more commonly seen in Afro-Eurasian spirit possession cults is because of deficiencies in thiamine, tryptophan-niacin, calcium, and vitamin D. They argued that a combination of poverty and food taboos cause this problem, and that it is exacerbated by the strains of pregnancy and lactation. They postulated that the involuntary symptoms of these deficiencies affecting their nervous systems have been institutionalized as spirit possession.
Psychology.
Spirit possession is not recognized as a psychiatric or medical diagnosis by the DSM-IV or the ICD-10. People alleged to be possessed by spirits sometimes exhibit symptoms similar to those associated with mental illnesses such as psychosis, hysteria, mania, Tourette's syndrome, epilepsy, schizophrenia, or dissociative identity disorder, including involuntary, uncensored behavior, and an extra-human, extra-social aspect to the individual's actions. In cases of dissociative identity disorder in which the alter personality is questioned as to its identity, 29% are reported to identify themselves as demons. Physicians regard this as a mental disease called demonomania or demonopathy, a monomania in which the patient believes that he or she is possessed by one or more demons.

</doc>
<doc id="45938" url="https://en.wikipedia.org/wiki?curid=45938" title="General equilibrium theory">
General equilibrium theory

In economics, general equilibrium theory attempts to explain the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that the interaction of demand and supply will result in an overall (or "general") equilibrium. General equilibrium theory contrasts to the theory of "partial" equilibrium, which only analyzes single markets.
General equilibrium theory both studies economies using the model of equilibrium pricing and seeks to determine in which circumstances the assumptions of general equilibrium will hold. The theory dates to the 1870s, particularly the work of French economist Léon Walras in his pioneering 1874 work "Elements of Pure Economics".
Overview.
It is often assumed that agents are price takers, and under that assumption two common notions of equilibrium exist: Walrasian (or competitive) equilibrium, and its generalization; a price equilibrium with transfers.
Broadly speaking, general equilibrium tries to give an understanding of the whole economy using a "bottom-up" approach, starting with individual markets and agents. Macroeconomics, as developed by the Keynesian economists, focused on a "top-down" approach, where the analysis starts with larger aggregates, the "big picture". Therefore, general equilibrium theory has traditionally been classified as part of macroeconomics.
The difference is not as clear as it used to be, since much of modern macroeconomics has emphasized microeconomic foundations, and has constructed general equilibrium models of macroeconomic fluctuations. General equilibrium macroeconomic models usually have a simplified structure that only incorporates a few markets, like a "goods market" and a "financial market". In contrast, general equilibrium models in the microeconomic tradition typically involve a multitude of different goods markets. They are usually complex and require computers to help with numerical solutions.
In a market system the prices and production of all goods, including the price of money and interest, are interrelated. A change in the price of one good, say bread, may affect another price, such as bakers' wages. If bakers don't differ in tastes from others, the demand for bread might be affected by a change in bakers' wages, with a consequent effect on the price of bread. Calculating the equilibrium price of just one good, in theory, requires an analysis that accounts for all of the millions of different goods that are available.
The first attempt in neoclassical economics to model prices for a whole economy was made by Léon Walras. Walras' "Elements of Pure Economics" provides a succession of models, each taking into account more aspects of a real economy (two commodities, many commodities, production, growth, money). Some think Walras was unsuccessful and that the later models in this series are inconsistent.
In particular, Walras's model was a long-run model in which prices of capital goods are the same whether they appear as inputs or outputs and in which the same rate of profits is earned in all lines of industry. This is inconsistent with the quantities of capital goods being taken as data. But when Walras introduced capital goods in his later models, he took their quantities as given, in arbitrary ratios. (In contrast, Kenneth Arrow and Gérard Debreu continued to take the initial quantities of capital goods as given, but adopted a short run model in which the prices of capital goods vary with time and the own rate of interest varies across capital goods.)
Walras was the first to lay down a research program much followed by 20th-century economists. In particular, the Walrasian agenda included the investigation of when equilibria are unique and stable.(Walras' Lesson 7 shows neither uniqueness, nor stability, nor even existence of an equilibrium is guaranteed.)
Walras also proposed a dynamic process by which general equilibrium might be reached, that of the tâtonnement or groping process.
The tâtonnement process is a model for investigating stability of equilibria. Prices are announced (perhaps by an "auctioneer"), and agents state how much of each good they would like to offer (supply) or purchase (demand). No transactions and no production take place at disequilibrium prices. Instead, prices are lowered for goods with positive prices and excess supply. Prices are raised for goods with excess demand. The question for the mathematician is under what conditions such a process will terminate in equilibrium where demand equates to supply for goods with positive prices and demand does not exceed supply for goods with a price of zero. Walras was not able to provide a definitive answer to this question (see Unresolved Problems in General Equilibrium below).
In partial equilibrium analysis, the determination of the price of a good is simplified by just looking at the price of one good, and assuming that the prices of all other goods remain constant. The Marshallian theory of supply and demand is an example of partial equilibrium analysis. Partial equilibrium analysis is adequate when the first-order effects of a shift in the demand curve do not shift the supply curve. Anglo-American economists became more interested in general equilibrium in the late 1920s and 1930s after Piero Sraffa's demonstration that Marshallian economists cannot account for the forces thought to account for the upward-slope of the supply curve for a consumer good.
If an industry uses little of a factor of production, a small increase in the output of that industry will not bid the price of that factor up. To a first-order approximation, firms in the industry will experience constant costs, and the industry supply curves will not slope up. If an industry uses an appreciable amount of that factor of production, an increase in the output of that industry will exhibit increasing costs. But such a factor is likely to be used in substitutes for the industry's product, and an increased price of that factor will have effects on the supply of those substitutes. Consequently, Sraffa argued, the first-order effects of a shift in the demand curve of the original industry under these assumptions includes a shift in the supply curve of substitutes for that industry's product, and consequent shifts in the original industry's supply curve. General equilibrium is designed to investigate such interactions between markets.
Continental European economists made important advances in the 1930s. Walras' proofs of the existence of general equilibrium often were based on the counting of equations and variables. Such arguments are inadequate for non-linear systems of equations and do not imply that equilibrium prices and quantities cannot be negative, a meaningless solution for his models. The replacement of certain equations by inequalities and the use of more rigorous mathematics improved general equilibrium modeling.
Modern concept of general equilibrium in economics.
The modern conception of general equilibrium is provided by a model developed jointly by Kenneth Arrow, Gérard Debreu, and Lionel W. McKenzie in the 1950s. Debreu presents this model in "Theory of Value" (1959) as an axiomatic model, following the style of mathematics promoted by Nicolas Bourbaki. In such an approach, the interpretation of the terms in the theory (e.g., goods, prices) are not fixed by the axioms.
Three important interpretations of the terms of the theory have been often cited. First, suppose commodities are distinguished by the location where they are delivered. Then the Arrow-Debreu model is a spatial model of, for example, international trade.
Second, suppose commodities are distinguished by when they are delivered. That is, suppose all markets equilibrate at some initial instant of time. Agents in the model purchase and sell contracts, where a contract specifies, for example, a good to be delivered and the date at which it is to be delivered. The Arrow–Debreu model of intertemporal equilibrium contains forward markets for all goods at all dates. No markets exist at any future dates.
Third, suppose contracts specify states of nature which affect whether a commodity is to be delivered: "A contract for the transfer of a commodity now specifies, in addition to its physical properties, its location and its date, an event on the occurrence of which the transfer is conditional. This new definition of a commodity allows one to obtain a theory of free from any probability concept..."
These interpretations can be combined. So the complete Arrow–Debreu model can be said to apply when goods are identified by when they are to be delivered, where they are to be delivered and under what circumstances they are to be delivered, as well as their intrinsic nature. So there would be a complete set of prices for contracts such as "1 ton of Winter red wheat, delivered on 3rd of January in Minneapolis, if there is a hurricane in Florida during December". A general equilibrium model with complete markets of this sort seems to be a long way from describing the workings of real economies, however its proponents argue that it is still useful as a simplified guide as to how a real economies function.
Some of the recent work in general equilibrium has in fact explored the implications of incomplete markets, which is to say an intertemporal economy with uncertainty, where there do not exist sufficiently detailed contracts that would allow agents to fully allocate their consumption and resources through time. While it has been shown that such economies will generally still have an equilibrium, the outcome may no longer be Pareto optimal. The basic intuition for this result is that if consumers lack adequate means to transfer their wealth from one time period to another and the future is risky, there is nothing to necessarily tie any price ratio down to the relevant marginal rate of substitution, which is the standard requirement for Pareto optimality. Under some conditions the economy may still be constrained Pareto optimal, meaning that a central authority limited to the same type and number of contracts as the individual agents may not be able to improve upon the outcome, what is needed is the introduction of a full set of possible contracts. Hence, one implication of the theory of incomplete markets is that inefficiency may be a result of underdeveloped financial institutions or credit constraints faced by some members of the public. Research still continues in this area.
Properties and characterization of general equilibrium.
Basic questions in general equilibrium analysis are concerned with the conditions under which an equilibrium will be efficient, which efficient equilibria can be achieved, when an equilibrium is guaranteed to exist and when the equilibrium will be unique and stable.
First Fundamental Theorem of Welfare Economics.
The First Fundamental Welfare Theorem asserts that market equilibria are Pareto efficient. In a pure exchange economy, a sufficient condition for the first welfare theorem to hold is that preferences be locally nonsatiated. The first welfare theorem also holds for economies with production regardless of the properties of the production function. Implicitly, the theorem assumes complete markets and perfect information. In an economy with externalities, for example, it is possible for equilibria to arise that are not efficient.
The first welfare theorem is informative in the sense that it points to the sources of inefficiency in markets. Under the assumptions above, any market equilibrium is tautologically efficient. Therefore, when equilibria arise that are not efficient, the market system itself is not to blame, but rather some sort of market failure.
Second Fundamental Theorem of Welfare Economics.
Even if every equilibrium is efficient, it may not be that every efficient allocation of resources can be part of an equilibrium. However, the second theorem states that every Pareto efficient allocation can be supported as an equilibrium by some set of prices. In other words, all that is required to reach a particular Pareto efficient outcome is a redistribution of initial endowments of the agents after which the market can be left alone to do its work. This suggests that the issues of efficiency and equity can be separated and need not involve a trade-off. The conditions for the second theorem are stronger than those for the first, as consumers' preferences and production sets now need to be convex (convexity roughly corresponds to the idea of diminishing marginal rates of substitution i.e. "the average of two equally good bundles is better than either of the two bundles").
Existence.
Even though every equilibrium is efficient, neither of the above two theorems say anything about the equilibrium existing in the first place. To guarantee that an equilibrium exists, it suffices that consumer preferences be strictly convex. With enough consumers, the convexity assumption can be relaxed both for existence and the second welfare theorem. Similarly, but less plausibly, convex feasible production sets suffice for existence; convexity excludes economies of scale.
Proofs of the existence of equilibrium traditionally rely on fixed-point theorems such as Brouwer fixed-point theorem for functions (or, more generally, the Kakutani fixed-point theorem for set-valued functions). See Competitive equilibrium#Existence of a competitive equilibrium. In fact, the converse also holds, according to Uzawa's derivation of Brouwer’s fixed point theorem from Walras's law. Following Uzawa's theorem, many mathematical economists consider proving existence a deeper result than proving the two Fundamental Theorems.
Another method of proof of existence, global analysis, uses Sard's lemma and the Baire category theorem; this method was pioneered by Gérard Debreu and Stephen Smale.
Nonconvexities in large economies.
Starr (1969) applied the Shapley–Folkman–Starr theorem to prove that even without convex preferences there exists an approximate equilibrium. The Shapley–Folkman–Starr results bound the distance from an "approximate" economic equilibrium to an equilibrium of a "convexified" economy, when the number of agents exceeds the dimension of the goods. Following Starr's paper, the Shapley–Folkman–Starr results were "much exploited in the theoretical literature", according to Guesnerie, who wrote the following:
some key results obtained under the convexity assumption remain (approximately) relevant in circumstances where convexity fails. For example, in economies with a large consumption side, nonconvexities in preferences do not destroy the standard results of, say Debreu's theory of value. In the same way, if indivisibilities in the production sector are small with respect to the size of the economy, [ . . . ] then standard results are affected in only a minor way.
To this text, Guesnerie appended the following footnote:
The derivation of these results in general form has been one of the major achievements of postwar economic theory.
In particular, the Shapley-Folkman-Starr results were incorporated in the theory of general economic equilibria and in the theory of market failures and of public economics.
Uniqueness.
Although generally (assuming convexity) an equilibrium will exist and will be efficient, the conditions under which it will be unique are much stronger. While the issues are fairly technical the basic intuition is that the presence of wealth effects (which is the feature that most clearly delineates general equilibrium analysis from partial equilibrium) generates the possibility of multiple equilibria. When a price of a particular good changes there are two effects. First, the relative attractiveness of various commodities changes; and second, the wealth distribution of individual agents is altered. These two effects can offset or reinforce each other in ways that make it possible for more than one set of prices to constitute an equilibrium.
A result known as the Sonnenschein–Mantel–Debreu theorem states that the aggregate excess demand function inherits only certain properties of individual's demand functions, and that these (Continuity, Homogeneity of degree zero, Walras' law and boundary behavior when prices are near zero) are the only real restriction one can expect from an aggregate excess demand function: any such function can be rationalized as the excess demand of an economy. In particular uniqueness of equilibrium should not be expected.
There has been much research on conditions when the equilibrium will be unique, or which at least will limit the number of equilibria. One result states that under mild assumptions the number of equilibria will be finite (see regular economy) and odd (see index theorem). Furthermore, if an economy as a whole, as characterized by an aggregate excess demand function, has the revealed preference property (which is a much stronger condition than revealed preferences for a single individual) or the gross substitute property then likewise the equilibrium will be unique. All methods of establishing uniqueness can be thought of as establishing that each equilibrium has the same positive local index, in which case by the index theorem there can be but one such equilibrium.
Determinacy.
Given that equilibria may not be unique, it is of some interest to ask whether any particular equilibrium is at least locally unique. If so, then comparative statics can be applied as long as the shocks to the system are not too large. As stated above, in a regular economy equilibria will be finite, hence locally unique. One reassuring result, due to Debreu, is that "most" economies are regular.
Work by Michael Mandler (1999) has challenged this claim. The Arrow–Debreu–McKenzie model is neutral between models of production functions as continuously differentiable and as formed from (linear combinations of) fixed coefficient processes. Mandler accepts that, under either model of production, the initial endowments will not be consistent with a continuum of equilibria, except for a set of Lebesgue measure zero. However, endowments change with time in the model and this evolution of endowments is determined by the decisions of agents (e.g., firms) in the model. Agents in the model have an interest in equilibria being indeterminate:
"Indeterminacy, moreover, is not just a technical nuisance; it undermines the price-taking assumption of competitive models. Since arbitrary small manipulations of factor supplies can dramatically increase a factor's price, factor owners will not take prices to be parametric."
When technology is modeled by (linear combinations) of fixed coefficient processes, optimizing agents will drive endowments to be such that a continuum of equilibria exist:
"The endowments where indeterminacy occurs systematically arise through time and therefore cannot be dismissed; the Arrow-Debreu-McKenzie model is thus fully subject to the dilemmas of factor price theory."
Some have questioned the practical applicability of the general equilibrium approach based on the possibility of non-uniqueness of equilibria.
Stability.
In a typical general equilibrium model the prices that prevail "when the dust settles" are simply those that coordinate the demands of various consumers for various goods. But this raises the question of how these prices and allocations have been arrived at, and whether any (temporary) shock to the economy will cause it to converge back to the same outcome that prevailed before the shock. This is the question of stability of the equilibrium, and it can be readily seen that it is related to the question of uniqueness. If there are multiple equilibria, then some of them will be unstable. Then, if an equilibrium is unstable and there is a shock, the economy will wind up at a different set of allocations and prices once the convergence process terminates. However stability depends not only on the number of equilibria but also on the type of the process that guides price changes (for a specific type of price adjustment process see Walrasian auction). Consequently, some researchers have focused on plausible adjustment processes that guarantee system stability, i.e., that guarantee convergence of prices and allocations to some equilibrium. When more than one stable equilibrium exists, where one ends up will depend on where one begins.
Unresolved problems in general equilibrium.
Research building on the Arrow–Debreu–McKenzie model has revealed some problems with the model. The Sonnenschein–Mantel–Debreu results show that, essentially, any restrictions on the shape of excess demand functions are stringent. Some think this implies that the Arrow–Debreu model lacks empirical content. At any rate, Arrow–Debreu–McKenzie equilibria cannot be expected to be unique, or stable.
A model organized around the tâtonnement process has been said to be a model of a centrally planned economy, not a decentralized market economy. Some research has tried to develop general equilibrium models with other processes. In particular, some economists have developed models in which agents can trade at out-of-equilibrium prices and such trades can affect the equilibria to which the economy tends. Particularly noteworthy are the Hahn process, the Edgeworth process and the Fisher process.
The data determining Arrow-Debreu equilibria include initial endowments of capital goods. If production and trade occur out of equilibrium, these endowments will be changed further complicating the picture.
In a real economy, however, trading, as well as production and consumption, goes
on out of equilibrium. It follows that, in the course of convergence to equilibrium (assuming that occurs), endowments change. In turn this changes the set of equilibria. Put more succinctly, the set of equilibria is path dependent... path dependence
makes the calculation of equilibria corresponding to the initial state of the system essentially irrelevant. What matters is the equilibrium that the economy will reach from given initial endowments, not the equilibrium that it would have been in, given initial endowments, had prices happened to be just right
(Franklin Fisher).
The Arrow–Debreu model in which all trade occurs in futures contracts at time zero requires a very large number of markets to exist. It is equivalent under complete markets to a sequential equilibrium concept in which spot markets for goods and assets open at each date-state event (they are not equivalent under incomplete markets); market clearing then requires that the entire sequence of prices clears all markets at all times. A generalization of the sequential market arrangement is the temporary equilibrium structure, where market clearing at a point in time is conditional on expectations of future prices which need not be market clearing ones.
Although the Arrow–Debreu–McKenzie model is set out in terms of some arbitrary numéraire, the model does not encompass money. Frank Hahn, for example, has investigated whether general equilibrium models can be developed in which money enters in some essential way. One of the essential questions he introduces, often referred to as the Hahn's problem is : "Can one construct an equilibrium where money has value?" The goal is to find models in which existence of money can alter the equilibrium solutions, perhaps because the initial position of agents depends on monetary prices.
Some critics of general equilibrium modeling contend that much research in these models constitutes exercises in pure mathematics with no connection to actual economies. "There are endeavors that now pass for the most desirable kind of economic contributions although they are just plain mathematical exercises, not only without any economic substance but also without any mathematical value." Georgescu-Roegen cites as an example a paper that assumes more traders in existence than there are points in the set of real numbers.
Although modern models in general equilibrium theory demonstrate that under certain circumstances prices will indeed converge to equilibria, critics hold that the assumptions necessary for these results are extremely strong. As well as stringent restrictions on excess demand functions, the necessary assumptions include perfect rationality of individuals; complete information about all prices both now and in the future; and the conditions necessary for perfect competition. However some results from experimental economics suggest that even in circumstances where there are few, imperfectly informed agents, the resulting prices and allocations may wind up resembling those of a perfectly competitive market (although certainly not a stable general equilibrium in all markets).
Frank Hahn defends general equilibrium modeling on the grounds that it provides a negative function. General equilibrium models show what the economy would have to be like for an unregulated economy to be Pareto efficient.
Computing general equilibrium.
Until the 1970s general equilibrium analysis remained theoretical. With advances in computing power and the development of input-output tables, it became possible to model national economies, or even the world economy, and attempts were made to solve for general equilibrium prices and quantities empirically.
Applied general equilibrium (AGE) models were pioneered by Herbert Scarf in 1967, and offered a method for solving the Arrow–Debreu General Equilibrium system in a numerical fashion. This was first implemented by John Shoven and John Whalley (students of Scarf at Yale) in 1972 and 1973, and were a popular method up through the 1970s. In the 1980s however, AGE models faded from popularity due to their inability to provide a precise solution and its high cost of computation. Also, Scarf's method was proven non-computable to a precise solution by Velupillai (2006).
Computable general equilibrium (CGE) models surpassed and replaced AGE models in the mid-1980s, as the CGE model was able to provide relatively quick and large computable models for a whole economy, and was the preferred method of governments and the World Bank. CGE models are heavily used today, and while 'AGE' and 'CGE' is used inter-changeably in the literature, Scarf-type AGE models have not been constructed since the mid-1980s, and the CGE literature at current is "not" based on Arrow-Debreu and General Equilibrium Theory as discussed in this article. CGE models, and what is today referred to as AGE models, are based on static, simultaneously solved, macro balancing equations (from the standard Keynesian macro model), giving a precise and explicitly computable result.
Other schools.
General equilibrium theory is a central point of contention and influence between the neoclassical school and other schools of economic thought, and different schools have varied views on general equilibrium theory. Some, such as the Keynesian and Post-Keynesian schools, strongly reject general equilibrium theory as "misleading" and "useless"; others, such as the Austrian school, show more influence and acceptance of general equilibrium thinking, though the extent is debated. Other schools, such as new classical macroeconomics, developed from general equilibrium theory.
Keynesian and Post-Keynesian.
Keynesian and Post-Keynesian economists, and their Underconsumptionist predecessors criticize general equilibrium theory specifically, and as part of criticisms of neoclassical economics generally. Specifically, they argue that general equilibrium theory is neither accurate nor useful, that economies are not in equilibrium, that equilibrium may be slow and painful to achieve, and that modeling by equilibrium is "misleading", and that the resulting theory is not a useful guide, particularly for understanding of economic crises.
Robert Clower and others have argued for a reformulation of theory toward disequilibrium analysis to incorporate how monetary exchange fundamentally alters the representation of an economy as though a barter system.  • _____ (1967). "A Reconsideration of the Microfoundations of Monetary Theory," "Western Economic Journal", 6(1), pp. 1-8 (press +).  • _____ and Peter W. Howitt (1996). "Taking Markets Seriously: Groundwork for a Post-Walrasian Macroeconomics", in David Colander, ed., "Beyond Microfoundations", pp. 21-37.  • Herschel I. Grossman (1971). "Money, Interest, and Prices in Market Disequilibrium," "Journal of Political Economy",79(5), p p. 943-961.  • Jean-Pascal Bénassy (1990). "Non-Walrasian Equilibria, Money, and Macroeconomics," "Handbook of Monetary Economics", v. 1, ch. 4, pp. 103-169. Table of contents.  • _____ (1993). "Nonclearing Markets: Microeconomic Concepts and Macroeconomic Applications," "Journal of Economic Literature", 31(2), pp. 732-761 (press +).  • _____ (2008). "non-clearing markets in general equilibrium," in "The New Palgrave Dictionary of Economics", 2nd Edition. Abstract.</ref>
New classical macroeconomics.
While general equilibrium theory and neoclassical economics generally were originally microeconomic theories, New classical macroeconomics builds a macroeconomic theory on these bases. In new classical models, the macroeconomy is assumed to be at its unique equilibrium, with full employment and potential output, and that this equilibrium is assumed to always have been achieved via price and wage adjustment (market clearing). The best-known such model is Real Business Cycle Theory, in which business cycles are considered to be largely due to changes in the real economy, unemployment is not due to the failure of the market to achieve potential output, but due to equilibrium potential output having fallen and equilibrium unemployment having risen.
Socialist economics.
Within socialist economics, a sustained critique of general equilibrium theory (and neoclassical economics generally) is given in "Anti-Equilibrium", based on the experiences of János Kornai with the failures of Communist central planning.
Austrian economics.
Whether Austrian economics supports or rejects general equilibrium theory and the precise relationship is unclear. Different Austrian economists have advocated differing positions, which have changed as Austrian economics developed over time. Some new classical economists argue that the work of Friedrich Hayek in the 1920s and 1930s was in the general equilibrium tradition and was a precursor to business cycle equilibrium theory. Others argue that while there are clear influences of general equilibrium on Hayek's thought, and that he used it in his early work, he came to substantially reject it in his later work, post 1937. It is also argued by some that Friedrich von Wieser, along with Hayek, worked in the general equilibrium tradition, while others reject this, finding influences of general equilibrium on the Austrian economists superficial.

</doc>
<doc id="45939" url="https://en.wikipedia.org/wiki?curid=45939" title="Primary color">
Primary color

Primary colors are sets of colors that can be combined to make a useful range of colors. For human applications, three primary colors are typically used, since human color vision is usually trichromatic.
For "additive" combination of colors, as in overlapping projected lights or in electronic visual displays, the primary colors normally used are red, green, and blue. For a "subtractive" combination of colors, as in mixing of pigments or dyes for printing, the colors magenta, yellow, and cyan are normally used. However, red, yellow, and blue are commonly used as primaries when painting or drawing.
See RGB color model, CMYK color model, and RYB color model for more on these popular sets of primary colors.
In an additive system, choices of sets of primary colors are nearly arbitrary, subject to weak constraints from the spectral sensitivities of each of the human cone photoreceptors. An early color photographic process, autochrome, typically used orange, green, and violet primaries. However, unless negative amounts of a color are allowed, the gamut will be restricted to the color triangle defined by the choice of primaries.
The combination of any two primary colors creates a secondary color. The most commonly used additive color primaries are the secondary colors of the most commonly used subtractive color primaries, and vice versa.
Biological basis.
Primary colors are not a fundamental property of light but are related to the physiological response of the eye to light. Fundamentally, light is a continuous spectrum of the wavelengths that can be detected by the human eye, an infinite-dimensional stimulus space. However, the human eye normally contains only three types of color receptors, called cone cells. Each color receptor responds to different ranges of the color spectrum. Humans and other species with three such types of color receptors are known as trichromats. These species respond to the light stimulus via a three-dimensional sensation, which generally can be modeled as a mixture of three primary colors.
Before the nature of colorimetry and visual physiology were well understood, scientists such as Thomas Young, James Clerk Maxwell, and Hermann von Helmholtz expressed various opinions about what should be the three primary colors to describe the three primary color sensations of the eye. Young originally proposed red, green, and violet, and Maxwell changed violet to blue; Helmholtz proposed "a slightly purplish red, a vegetation-green, slightly yellowish (wavelength about 5600 tenth-metres), and an ultramarine-blue (about 4820)". In modern understanding, human cone cells do not correspond precisely to a specific set of primary colors, as each cone type responds to a range of color wavelengths.
Species with different numbers of receptor cell types would have color vision requiring a different number of primaries. For example, for species known as tetrachromats, with four different color receptors, one would use four primary colors. Since humans can only see to 380 nanometers (violet), but tetrachromats can see into the ultraviolet to about 300 nanometers, this fourth primary color for tetrachromats is located in the shorter-wavelength range.
Many birds and marsupials are tetrachromats, and it has been suggested that some human females are tetrachromats as well, having an extra variant version of the long-wave (L) cone type.
The peak response of human color receptors varies, even among individuals with "normal" color vision; in non-human species this polymorphic variation is even greater, and it may well be adaptive.
Most placental mammals other than primates have only two types of color receptors and are therefore dichromats; to them, there are only two primary colors.
It would be incorrect to assume that the world "looks tinted" to an animal (or human) with anything other than the human standard of three color receptors. To an animal (or human) born that way, the world would look normal to it, but the animal's ability to detect and discriminate colors would be different from that of a human with normal color vision. If a human and an animal both look at a natural color, they see it as natural; however, if both look at a color reproduced via primary colors, such as on a color television screen, the human may see it as matching the natural color, while the animal does not, since the primary colors have been chosen to suit human capabilities.
Additive primaries.
Media that combine emitted lights to create the sensation of a range of colors are using the additive color system. Typically, the primary colors used are red, green, and blue.
Television and other computer and video displays are a common example of the use of additive primaries and the RGB color model. The exact colors chosen for the primaries are a technological compromise between the available phosphors (including considerations such as cost and power usage) and the need for large color triangle to allow a large gamut of colors. The ITU-R BT.709-5/sRGB primaries are typical.
Additive mixing of red and green light produces shades of yellow, orange, or brown. Mixing green and blue produces shades of cyan, and mixing red and blue produces shades of purple, including magenta. Mixing nominally equal proportions of the additive primaries results in shades of grey or white; the color space that is generated is called an RGB color space.
The CIE 1931 color space defines "monochromatic" primary colors with wavelengths of 435.8 nm (violet), 546.1 nm (green) and 700 nm (red). The corners of the color triangle are therefore on the spectral locus, and the triangle is about as big as it can be. No real display device uses such primaries, as the extreme wavelengths used for violet and red result in a very low luminous efficiency.
Recent developments.
Some recent TV and computer displays are starting to include yellow as a fourth "primary" color, often in a four-point square pixel area, so as to achieve brighter pure yellows and a larger color gamut. 
Even the four-primary technology does not yet reach the range of colors the human eye is theoretically capable of perceiving (as defined by the sample-based estimate called the Pointer Gamut), with 4-primary LED prototypes providing typically about 87% and 5-primary prototypes about 95%. Several firms, including Samsung and Mitsubishi, have demonstrated LED displays with five or six "primaries", or color LED point light sources per pixel. A recent academic literature review claims a gamut of 99% can be achieved with 5-primary LED technology. While technology for achieving a wider gamut appears to be within reach, other issues remain; for example, affordability, dynamic range, and brilliance. In addition, there exists hardly any source material recorded in this wider gamut, nor is it currently possible to recover this information from existing visual media. Regardless, industry is still exploring a wide variety of "primary" active light sources (per pixel) with the goal of matching the capability of human color perception within a broadly affordable price. One example of a potentially affordable but yet unproven active light hybrid places a LED screen over a plasma light screen, each with different "primaries". Because both LED and plasma technologies are many decades old (plasma pixels going back to the 1960s), both have become so affordable that they could be combined.
Subtractive primaries.
Media that use reflected light and colorants to produce colors are using the subtractive color method of color mixing.
CMYK color model, or four-color printing.
In the printing industry, to produce the varying colors the subtractive primaries cyan, magenta, and yellow are applied together in varying amounts. Before the color names "cyan" and "magenta" were in common use, these primaries were often known as blue-green and purple, or in some circles as blue and red, respectively, and their exact color has changed over time with access to new pigments and technologies.
Mixing yellow and cyan produces green colors; mixing yellow with magenta produces reds, and mixing magenta with cyan produces blues. In theory, mixing equal amounts of all three pigments should produce grey, resulting in black when all three are applied in sufficient density, but in practice they tend to produce muddy brown colors. For this reason, and to save ink and decrease drying times, a fourth pigment, black, is often used in addition to cyan, magenta, and yellow.
These results are described by the CMYK color model. The abbreviation stands for cyan, magenta, yellow, and key—black is referred to as the "key" color, a shorthand for the "key printing plate" that impressed the artistic detail of an image, usually in black ink.
In practice, colorant mixtures in actual materials such as paint tend to be more complex. Brighter or more saturated colors can be created using natural pigments instead of mixing, and natural properties of pigments can interfere with the mixing. For example, mixing magenta and green in acrylic creates a dark cyan—something which would not happen if the mixing process were perfectly subtractive.
In the subtractive model, adding white to a color, whether by using less colorant or by mixing in a reflective white pigment such as zinc oxide, does not change the color's hue but does reduce its saturation. Subtractive color printing works best when the surface or paper is white, or close to it.
A system of subtractive color does not have a simple chromaticity gamut analogous to the RGB color triangle, but a gamut that must be described in three dimensions. There are many ways to visualize such models, using various 2D chromaticity spaces or in 3D color spaces.
History.
RYB color model.
RYB (red, yellow, and blue) is a historical set of colors. It is primarily used in art and art education, particularly painting. It predates modern scientific color theory.
RYB make up the primary colors in a painter's color wheel; the secondary colors OGV (orange, green, and violet) make up another triad. Triads are formed by 3 equidistant colors on a particular color wheel; neither RYB nor OGV is equidistant on a perceptually uniform color wheel, but rather have been "defined" to be equidistant in the RYB wheel.
Painters have long used more than three "primary" colors in their palettes—and at one point considered red, yellow, blue, and green to be the "four" primaries. Red, yellow, blue, and green are still widely considered the four psychological primary colors, though red, yellow, and blue are sometimes listed as the "three" psychological primaries, with black and white occasionally added as a fourth and fifth.
During the 18th century, as theorists became aware of Isaac Newton's scientific experiments with light and prisms, red, yellow, and blue became the canonical primary colors—supposedly the fundamental sensory qualities that are blended in the perception of all physical colors and equally in the physical mixture of pigments or dyes. This theory became dogma, despite abundant evidence that red, yellow, and blue primaries cannot mix all other colors, and has survived in color theory to the present day.
Using red, yellow, and blue as primaries yields a relatively small gamut, in which, among other problems, colorful greens, cyans, purples, and magentas are impossible to mix, because red, yellow, and blue do not correspond to the subtractive primaries dictated by human color vision. For this reason, modern three- or four-color printing processes, as well as color photography, use cyan, yellow, and magenta as primaries instead: Cyan pigment absorbs red light (reflects blue and green), magenta absorbs green (reflects red and blue), and yellow absorbs blue (reflects red and green); each of these pigments reflects a unique set of two of the colors that the human eye perceives as primaries.
Most painters include colors in their palettes which cannot be mixed from yellow, red, and blue paints, and thus do not fit within the RYB color model. Some who do use a three-color palette opt for the cyan, yellow, and magenta used by printers; others paint with 6 or more colors, in order to widen the gamuts. The cyan, magenta, and yellow used in printing are sometimes known as "process blue," "process red," and "process yellow."
Psychological primaries.
The opponent process is a color theory that states that the human visual system interprets information about color by processing signals from cones and rods in an antagonistic manner. The three types of cones have some overlap in the wavelengths of light to which they respond, so it is more efficient for the visual system to record "differences" between the responses of cones, rather than each type of cone's individual response. The opponent color theory suggests that there are three opponent channels: red versus green, blue versus yellow, and black versus white. Responses to one color of an opponent channel are antagonistic to those of the other color. The theory states that the particular colors considered by an observer to be uniquely representative of the concepts red, yellow, green, blue, white, and black might be called "psychological primary colors", because any other color could be described in terms of some combination of these.

</doc>
<doc id="45943" url="https://en.wikipedia.org/wiki?curid=45943" title="Swastika">
Swastika

The swastika (also known as the gammadion cross, cross cramponnée, or wanzi) (as a character: 卐 or 卍) is an ancient religious symbol that generally takes the form of an equilateral cross, with its four legs bent at 90 degrees. It is considered to be a sacred and auspicious symbol in Hinduism, Buddhism and Jainism and dates back to before 2nd century B.C.
It has been used as a decorative element in various cultures since at least the Neolithic. It is known most widely as an important symbol long used in Indian religions, denoting "auspiciousness."
It was adopted as such in pre-World War I-Europe and later, and most notably, by the Nazi Party and Nazi Germany prior to World War II.
In many Western countries, the swastika has been highly stigmatized because of its use in and association with Nazism.
It continues to be commonly used as a religious symbol in Hinduism and Buddhism.
Western literature's older term for the symbol, "gammadion cross", derives mainly from its appearance, which is identical to four Greek gamma letters affixed to each other. The name "swastika" comes from the Sanskrit word "svastika" (Devanāgarī: स्वस्तिक), meaning "lucky or auspicious object".
Names.
The word "swastika" has been in use in English since the 1870s, replacing "gammadion" (from Greek ).
It was loaned from the Sanskrit term (Devanāgarī: ), which is transliterated "" under the commonly used IAST transliteration system, but is pronounced "swastika" when letters are used as in English. It means any lucky or auspicious object, and in particular a mark made on persons and things to denote auspiciousness, or any piece of luck or well-being.
It is composed of "su-" meaning "good, well" and "asti" "it is", which form the word ', meaning good health or good fortune; the added suffix ' forms an abstract noun, and "" might thus be translated literally as "that which is associated with well-being," corresponding to "lucky charm" or "thing that is auspicious."
The word finds its origin in Vedic Sanskrit. As noted by Monier-Williams in his Sanskrit-English dictionary, according to Alexander Cunningham, its shape represents a monogram formed by interlacing of the letters of the auspicious words "su-astí" ("") written in Ashokan characters.
Other names for the symbol include:
Symbol in various scripts.
The swastika has been a standardized Sanskrit character. "" () and as such entered various other East Asian languages such as Japanese where the symbol is called or .
The swastika is included as part of the Chinese script and has Unicode encodings U+534D 卍 (left-facing) and U+5350 卐 (right-facing); the latter has a mapping in the original Big5 character set, but the former does not (although it is in Big5+). In Unicode 5.2, four swastika symbols were added to the Tibetan block: , , and .
Geometry.
Geometrically, the swastika can be regarded as an irregular icosagon or 20-sided polygon. The proportions of the Nazi swastika were fixed based on a 5 × 5 diagonal grid.
Characteristic is the 90° rotational symmetry and chirality, hence the absence of reflectional symmetry, and the existence of two versions of swastikas that are each other's mirror image.
The mirror-image forms are often described as:
If dimensioned appropriately, the swastika can interlock with its own negative space by translation alone, as shown:
However the swastika cannot tile the plane by itself, as indicated by the 1x1 square gaps above.
Origin hypotheses.
The earliest known object with swastika-motifs is a bird made from the tusk of a mammoth from the paleolithic settlement of Mezine, Ukraine dated to 10,000 BCE.
Among the earliest cultures utilizing swastika is the neolithic Vinča culture of South-East Europe (see Vinča symbols). More extensive use of the Swastika can be traced to Ancient India, during the Indus Valley Civilization.
The swastika is a repeating design, created by the edges of the reeds in a square basket-weave. Other theories attempt to establish a connection via cultural diffusion or an explanation along the lines of Carl Jung's collective unconscious.
The genesis of the swastika symbol is often treated in conjunction with cross symbols in general, such as the sun cross of pagan Bronze Age religion. Beyond its certain presence in the "proto-writing" symbol systems emerging in the Neolithic, nothing certain is known about the symbol's origin. There are nevertheless a number of speculative hypotheses. One hypothesis is that the cross symbols and the swastika share a common origin in simply symbolizing the sun. Another hypothesis is that the 4 arms of the cross represent 4 aspects of nature - the sun, wind, water, soil. Some have said the 4 arms of cross are four seasons, where the division for 90-degree sections correspond to the solstices and equinoxes. The Hindus represent it as the Universe in our own spiral galaxy in the fore finger of Lord Vishnu. This carries most significance in establishing the creation of the Universe and the arms as 'kal' or time, a calendar that is seen to be more advanced than the lunar calendar where the seasons drift from calendar year to calendar year. The luni-solar solution for correcting season drift was to intercalate an extra month in certain years to restore the lunar cycle to the solar-season cycle. The Star of David is thought to originate as a symbol of that calendar system, where the two overlapping triangles are seen to form a partition of 12 sections around the perimeter with a 13th section in the middle, representing the 12 and sometimes 13 months to a year. As such, the Christian cross, Jewish hexagram star and the Muslim crescent moon are seen to have their origins in different views regarding which calendar system is preferred for marking holy days. Groups in higher latitudes experience the seasons more strongly, offering more advantage to the calendar represented by the swastika/cross. (Note relation to the sun cross.)
According to Reza Assasi, the swastika is a geometric pattern in the sky representing the north ecliptic pole centred to Zeta Draconis. He argues that this primitive astrological symbol was later called the four-horse chariot of Mithra in ancient Iran and represented the centre of Ecliptic in the star map and also demonstrates that in Iranian mythology, the cosmos was believed to be pulled by four heavenly horses revolving around a fixed centre on clockwise direction possibly because of a geocentric understanding of an astronomical phenomenon called axial precession. He suggests that this notion was transmitted to the west and flourished in Roman mithraism in which this symbol appears in Mithraic iconography and astrological representations.
Carl Sagan in his book "Comet" (1985) reproduces Han period Chinese manuscript (the "Book of Silk", 2nd century BC) that shows comet tail varieties: most are variations on simple comet tails, but the last shows the comet nucleus with four bent arms extending from it, recalling a swastika. Sagan suggests that in antiquity a comet could have approached so close to Earth that the jets of gas streaming from it, bent by the comet's rotation, became visible, leading to the adoption of the swastika as a symbol across the world.
Bob Kobres in his 1992 paper "Comets and the Bronze Age Collapse" contends that the swastika like comet on the Han Dynasty silk comet atlas was labeled a "long tailed pheasant star" (Di-Xing) because of its resemblance to a bird's foot or footprint, the latter comparison also being drawn by J.F.K. Hewitt's observation on page 145 of "Primitive Traditional History: vol. 1". as well as an article concerning carpet decoration in "Good Housekeeping". Kobres goes on to suggest an association of mythological birds and comets also outside China.
In "Life's Other Secret" (1999), Ian Stewart suggests the ubiquitous swastika pattern arises when parallel waves of neural activity sweep across the visual cortex during states of altered consciousness, producing a swirling swastika-like image, due to the way quadrants in the field of vision are mapped to opposite areas in the brain.
Alexander Cunningham suggested that the Buddhist use of the shape arose from a combination of Brahmi characters abbreviating the words "su astí".
Archeological record.
[[File:Samarra bowl.jpg|left|thumb|The Samarra bowl, at the Pergamonmuseum, Berlin. The swastika in the center of the design is a reconstruction.]]
The earliest swastika known has been found in Mezine, Ukraine. It is carved on late paleolithic figurine of mammoth ivory, being dated as early as about 10,000 BCE. It has been suggested this swastika may be a stylized picture of a stork in flight and not the true swastika that is in use today.
In England, neolithic or Bronze Age stone carvings of the symbol have been found on Ilkley Moor.
Mirror-image swastikas (clockwise and anti-clockwise) have been found on ceramic pottery in the Devetashka cave, Bulgaria, dated 6,000 B.C.
Some of the earliest archaeological evidences of Swastika in the Indian subcontinent can be dated to 3,000 BCE. Swastikas have also been found on pottery in archaeological digs in Africa, in the area of Kush and on pottery at the Jebel Barkal temples, in Iron Age designs of the northern Caucasus (Koban culture), and in Neolithic China in the Majiabang,Majiayao, Dawenkou and Xiaoheyan cultures.
Other Iron Age attestations of the swastika can be associated with Indo-European cultures such as the Indo-Iranians, Celts, Greeks, Germanic peoples and Slavs.
The swastika is also seen in Egypt during the Coptic period. Textile number T.231-1923 held at the V&A Museum in London includes small swastikas in its design. This piece was found at Qau-el-Kebir, near Asyut, and is dated between AD300-600.
The "Tierwirbel" (the German for "animal whorl" or "whirl of animals") is a characteristic motif in Bronze Age Central Asia, the Eurasian Steppe, and later also in Iron Age Scythian and European (Baltic and Germanic) culture, showing rotational symmetric arrangement of an animal motif, often four birds' heads. Even wider diffusion of this "Asiatic" theme has been proposed, to the Pacific and even North America (especially Moundville).
Worldwide use.
Asia.
In Asia, the swastika symbol first appears in the archaeological record around 3000 BCE in the Indus Valley Civilization. It also appears in the Bronze and Iron Age cultures around the Black Sea and the Caspian Sea. In all these cultures the swastika symbol does not appear to occupy any marked position or significance, but appears as just one form of a series of similar symbols of varying complexity. In the Zoroastrian religion of Persia, the swastika was a symbol of the revolving sun, infinity, or continuing creation. It rose to importance in Buddhism during the Mauryan Empire and in Hinduism with the decline of Buddhism in India during the Gupta Empire. With the spread of Buddhism, the Buddhist swastika reached Tibet and China. The symbol was also introduced to Balinese Hinduism by Hindu kings. The use of the swastika by the Bön faith of Tibet, as well as Chinese Taoism, can also be traced to Buddhist influence. In Thailand, the word "Sawaddi" is normally used as a greeting which simply means "hello"; Sawaddi-ka (feminine) and Sawaddi-krup (masculine). "Sawaddi" derives from the Sanskrit word "swasti" and its meaning is a combination of the words: prosperity, luck, security, glory, and good.
Hinduism.
The swastika is an important Hindu symbol. It is traced with the finger with sindoor on the head or body during Hindu religious rites, and on doors on festival days - notably on diwali, or deepavalli. It is painted on many, if not most, three-wheel auto-rikshas and trucks. In all these uses it is a lucky charm protecting from evil and attracting good.
It is also said to represent God (the Brahman) in his universal manifestation, and energy ("Shakti"). It represents the four directions of the world (the four faces of Brahma). It also represents the Purushartha: Dharma (natural order), Artha (wealth), Kama (desire), and Moksha (liberation).
Among the Hindus of Bengal, it is common to see the name "swastika" ( "shostik") applied to a slightly different symbol, which has the same significance as the common swastika, that looks like a stick figure of a human being. Right-facing swastika in the decorative Hindu form is used to evoke the Shakti.
Buddhism.
Buddhism originated in the 5th century BC and spread throughout the Indian subcontinent. The swastika rose in importance around the 3rd century BC (during the Mauryan Empire). Also known as a "yungdrung" in ancient Tibet, it was a graphical representation of eternity.
Jainism.
Jainism gives even more prominence to the swastika as a tantra than Hinduism does. It is a symbol of the seventh tīrthaṅkara, Suparśvanātha. In the Śvētāmbara tradition, it is also one of the aṣṭamaṅgala. All Jain temples and holy books must contain the swastika and ceremonies typically begin and end with creating a swastika mark several times with rice around the altar. Jains use rice to make a swastika in front of statues and then put an offering on it, usually a ripe or dried fruit, a sweet ( ), or a coin or currency note. The four arms of the swastika symbolize the four places where a soul could be reborn in the cycle of birth and death - svarga "heaven", naraka "hell", manushya "humanity" or "tiryancha" "as flora or fauna" - before the soul attains moksha "salvation" as a siddha, having ended the cycle of birth and death and become omniscient.
East Asian traditions.
The paired swastika symbols are included, at least since the Liao Dynasty (AD 907–1125), as part of the Chinese writing system (卍 and 卐) and are variant characters for 萬 or 万 ("wàn" in Mandarin, "man" in Korean, Cantonese, and Japanese, "vạn" in Vietnamese) meaning "all" or "eternity" (lit. myriad). The swastika marks the beginning of many Buddhist scriptures. In East Asian countries, the left-facing character is often used as symbol for Buddhism and marks the site of a Buddhist temple on maps.
In Chinese, Japanese, and Korean the swastika is also a homonym of the number 10,000, and is commonly used to represent the whole of Creation, e.g. 'the myriad things' in the Dao De Jing. During the Chinese Tang Dynasty, Empress Wu Zetian (684-704) decreed that the swastika would also be used as an alternative symbol of the Sun.
When the Chinese writing system was introduced to Japan in the 8th century, the swastika was adopted into the Japanese language and culture. It is commonly referred as the "manji" (lit. Man-character). Since the Middle Ages, it has been used as a "mon" by various Japanese families such as Tsugaru clan, Hachisuka clan or around 60 clans that belong to Tokugawa clan. On Japanese maps, a swastika (left-facing and horizontal) is used to mark the location of a Buddhist temple. The right-facing "manji" is often referred to as the or , and can also be called .
In Chinese and Japanese art, the swastika is often found as part of a repeating pattern. One common pattern, called "sayagata" in Japanese, comprises left- and right-facing swastikas joined by lines. As the negative space between the lines has a distinctive shape, the sayagata pattern is sometimes called the ""key fret"" motif in English.
As a pottery graph of unknown provision and meaning the swastika-like sign is known in Chinese Neolithic culture (2400–2000 BCE, Liu wan 柳湾, Qinghai province).
Armenia.
In Armenia swastika is called "arevakhach" and "kerkhach" () and is the ancient symbol of eternity and eternal light (i.e. God). Swastikas in Armenia were founded on petroglyphs. During the bronze age it was depicted on cauldrons, belts, medallions and other items. Among the oldest petroglyphs is the seventh letter of the Armenian alphabet - "E" (which means "is" or "to be") - depicted as half-swastika.
Swastikas can also be seen on early Medieval churches and fortresses, including the principal tower in Armenia's historical capital city of Ani. The same symbol can be found on Armenian carpets, cross-stones (khachkar) and in medieval manuscripts, as well as on modern monuments (symbol of eternity).
Europe.
In Bronze Age Europe, the "Sun cross" (a three- or four-armed hooked cross in a circle) appears frequently, often interpreted as a solar symbol. Swastika shapes have been found on numerous artifacts from Iron Age Europe - Armenian Arevakhach (, արև arev "sun" + խաչ xač "cross", "sun cross"), Greco-Roman, Illyrian, Etruscan, Baltic, Celtic, Germanic, and Slavic.
Greco-Roman antiquity.
Ancient Greek architectural, clothing and coin designs are replete with single or interlinking swastika motifs. There are also gold plate fibulae from the 8th century BC decorated with an engraved swastika. Related symbols in classical Western architecture include the cross, the three-legged triskele or triskelion and the rounded lauburu. The swastika symbol is also known in these contexts by a number of names, especially "gammadion", or rather the tetra-gammadion. The name gammadion comes from the fact that it can be seen as being made up of four Greek gamma (Γ) letters. Ancient Greek priestesses would tattoo the symbol, along with the tetraskelion, on their bodies. Ancient Greek architectural designs are replete with the interlinking symbol.
In Greco-Roman art and architecture, and in Romanesque and Gothic art in the West, isolated swastikas are relatively rare, and the swastika is more commonly found as a repeated element in a border or tessellation. The swastika often represented perpetual motion, reflecting the design of a rotating windmill or watermill. A meander of connected swastikas makes up the large band that surrounds the Augustan Ara Pacis.
A design of interlocking swastikas is one of several tessellations on the floor of the cathedral of Amiens, France. A border of linked swastikas was a common Roman architectural motif, and can be seen in more recent buildings as a neoclassical element. A swastika border is one form of meander, and the individual swastikas in such a border are sometimes called "Greek keys". There have also been swastikas found on the floors of Pompeii.
Celts.
The bronze frontispiece of a ritual pre-Christian (c. 350-50 BC) shield found in the River Thames near Battersea Bridge (hence "Battersea Shield") is embossed with 27 swastikas in bronze and red enamel. An Ogham stone found in Anglish, Co Kerry, Ireland (CIIC 141) was modified into an early Christian gravestone, and was decorated with a cross pattée and two swastikas. The Book of Kells (ca. 800) contains swastika-shaped ornamentation. At the Northern edge of Ilkley Moor in West Yorkshire, there is a swastika-shaped pattern engraved in a stone known as the Swastika Stone.
The figure in the foreground of the picture is a 20th-century replica; the original carving can be seen a little farther away, at left of center.
Germanic Iron Age.
The swastika shape (also called a "fylfot") appears on various Germanic Migration Period and Viking Age artifacts, such as the 3rd century Værløse Fibula from Zealand, Denmark, the Gothic spearhead from Brest-Litovsk, today in Belarus, the 9th century Snoldelev Stone from Ramsø, Denmark, and numerous Migration Period bracteates drawn left-facing or right-facing.
The pagan Anglo-Saxon ship burial at Sutton Hoo, England, contained numerous items bearing the swastika, now housed in the collection of the Cambridge Museum of Archaeology and Anthropology. The Swastika is clearly marked on a hilt and sword belt found at Bifrons in Kent, in a grave of about the 6th century.
Hilda Ellis Davidson theorized that the swastika symbol was associated with Thor, possibly representing his hammer Mjolnir - symbolic of thunder - and possibly being connected to the Bronze Age sun cross. Davidson cites "many examples" of the swastika symbol from Anglo-Saxon graves of the pagan period, with particular prominence on cremation urns from the cemeteries of East Anglia. Some of the swastikas on the items, on display at the Cambridge Museum of Archaeology and Anthropology, are depicted with such care and art that, according to Davidson, it must have possessed special significance as a funerary symbol. The runic inscription on the 8th-century Sæbø sword has been taken as evidence of the swastika as a symbol of Thor in Norse paganism.
Illyrians.
Swastika was widespread among the Illyrians, symbolizing the Sun. The Sun cult was the main Illyrian cult, and the Sun was represented by a swastika in clockwise motion, and it stood for the movement of the Sun.
Slavic.
According to painter Stanisław Jakubowski the "little sun" is an Early Slavic pagan symbol of the sun. It was engraved on wooden monuments built near the final resting places of fallen Slavs to represent eternal life. The symbol was first seen in a collection of Early Slavic symbols and architectural features drawn and compiled by Polish painter Stanisław Jakubowski, which he named "Prasłowiańskie motywy architektoniczne" (). His work of art was published in 1923, by a publishing house that was then based in the Dębniki district of Kraków. The symbol can also be found on embroidery and pottery in most Slavic countries.
In Russia before the World War II the swastika was a favorite sign of the last Russian Empress Alexandra Feodorovna. She puts it all over for happiness, including drawn by pencil on the wall and window room in the Ipatiev House, - place of execution of royal family, and, without dating, on the wallpaper above the bed, where obviously slept heir. Was printed on some banknotes of the Russian Provisional Government (1917) and some sovznaks (1918-1922). In 1919 it was approved as insignia for the Kalmyk formations, not for long had certain popularity belong some artists, politics and army groups. Also it was present on icons and church clothes, but in times of War it was removed as the association with the symbol of the German occupation.
In modern Russia some neo-Nazis and neopagans followers pseudohistory argue that the Russian name of the swastika are "Kolovrat" (Russian: Коловрат, lit. "spinning wheel"). But there is no ethnographic sources, confirming that. In the traditional vernacular swastika it was called differently. For example, "breeze" - as in Christianity, the swastika represents a spiritual movement, descent of the Holy Spirit, and therefore the "wind" and "spirit" - a word with one meaning. Or "geeses", "ognevtsi" (dialect. "little flames"), "hares" (towel with a swastika was called as towel with the "hares"), "little horses", because it is such a curved cross.
The neo-Nazi Russian National Unity group's branch in Estonia is officially registered under the name "Kolovrat" and published an extremist newspaper in 2001 under the same name. A criminal investigation found the paper included an array of racial epithets . One Narva resident was sentenced to 1 year in jail for distribution of "Kolovrat". The Kolovrat has since been used by the Rusich Battalion, a Russian freedom fighter militant group known for its operation during the War in Donbass.
The swastika is contained in sign of the Polish national socialist organization Nacjonalistyczne Stowarzyszenie "Zadruga".
Sami.
An object very much like a hammer or a double axe is depicted among the magical symbols on the drums of Sami shamans, used in their religious ceremonies before Christianity was established. The name of the Sami thunder god was Horagalles, thought to be derived from "Old Man Thor" ("Þórr karl"). Sometimes on the drums, a male figure with a hammer-like object in either hand is shown, and sometimes it is more like a cross with crooked ends, or a swastika.
Medieval and early modern Europe.
In Christianity, the swastika is used as a hooked version of the Christian Cross, the symbol of Christ's victory over death. Some Christian churches built in the Romanesque and Gothic eras are decorated with swastikas, carrying over earlier Roman designs. Swastikas are prominently displayed in a mosaic in the St. Sophia church of Kiev, Ukraine dating from the 12th century. They also appear as a repeating ornamental motif on a tomb in the Basilica of St. Ambrose in Milan.
A ceiling painted in 1910 in the church of St Laurent in Grenoble has many swastikas. It can be visited today because the church became the archaeological museum of the city. A proposed direct link between it and a swastika floor mosaic in the Cathedral of Our Lady of Amiens, which was built on top of a pagan site at Amiens, France in the 13th century, is considered unlikely. The stole worn by a priest in the 1445 painting of the Seven Sacraments by Rogier van der Weyden presents the swastika form simply as one way of depicting the cross. Swastikas also appear on the vestments on the effigy of Bishop William Edington (d. 1366) in Winchester Cathedral, as can be seen at :File:Winchestercathedralheadonwilliamedingtontomb.jpg.
Swastikas also appear in art and architecture during the Renaissance and Baroque era. In fact, the famous fresco "The School of Athens" shows an ornament made out of swastikas, and the symbol can also be found on the facade of the "Santa Maria della Salute", a Roman Catholic church and minor basilica located at Punta della Dogana in the Dorsoduro sestiere of the city of Venice.
In the Polish First Republic the symbol of the swastika was also popular with the nobility. According to chronicles, the Rus' prince Oleg, who in the 9th century attacked Constantinople, nailed his shield (which had a large red swastika painted on it) to the city's gates. Several noble houses, e.g. Boreyko, Borzym, and Radziechowski from Ruthenia, also had Swastikas as their coat of arms. The family reached its greatness in the 14th and 15th centuries and its crest can be seen in many heraldry books produced at that time.
The Swastika was also a heraldic symbol, for example on the Boreyko coat of arms, used by noblemen in Poland and Ukraine. In the 19th century the swastika was one of the Russian empire's symbols; it was even placed in coins as a background to the Russian eagle.
A swastika can be seen on stonework at Valle Crucis Abbey, near Llangollen.
Early 20th-century Europe.
In the Western world, the symbol experienced a resurgence following the archaeological work in the late 19th century of Heinrich Schliemann, who discovered the symbol in the site of ancient Troy and associated it with the ancient migrations of Proto-Indo-Europeans, whose proto-language was not incidentally termed "Proto-Indo-Germanisch" by German language historians. He connected it with similar shapes found on ancient pots in Germany, and theorized that the swastika was a "significant religious symbol of our remote ancestors", linking Germanic, Greek and Indo-Iranian cultures. By the early 20th century, it was used worldwide and was regarded as a symbol of good luck and success.
The work of Schliemann soon became intertwined with the "völkisch" movements, for which the swastika was a symbol of the "Aryan race", a concept that came to be equated by theorists such as Alfred Rosenberg with a Nordic master race originating in northern Europe. Since its adoption by the Nazi Party of Adolf Hitler, the swastika has been associated with Nazism, fascism, racism in its (white supremacy) form, the Axis powers in World War II, and the Holocaust in much of the West. The swastika remains a core symbol of Neo-Nazi groups, and is used regularly by activist groups.
The Benedictine choir school at Lambach Abbey, Upper Austria, which Hitler attended for several months as a boy, had a swastika chiseled into the monastery portal and also the wall above the spring grotto in the courtyard by 1868. Their origin was the personal coat of arms of Abbot Theoderich Hagn of the monastery in Lambach, which bore a golden swastika with slanted points on a blue field. The Lambach swastika is probably of Medieval origin.
Denmark.
The Danish brewery company Carlsberg Group used the swastika as a logo from the 19th Century until the middle of the 1930s when it was discontinued because of association with the Nazi Party in neighbouring Germany. The swastika carved on elephants at the entrance gates of the company's headquarters in Copenhagen in 1901 can still be seen today.
Ireland.
The Swastika Laundry was a laundry founded in 1912, located on Shelbourne Road, Ballsbridge, a district of Dublin, Ireland. In the fifties Heinrich Böll came across a van belonging to the company while he was staying in Ireland, leading to some awkward moments before he realized the company was older than Nazism and totally unrelated to it. The chimney of the boiler-house of the laundry still stands, but the laundry has been redeveloped.
Finnish folklore.
In Finland the swastika was often used in traditional folk art products, as a decoration or magical symbol on textiles and wood. The swastika was also used by the Finnish Air Force until 1945, and is still used in air force flags.
The tursaansydän is used by scouts in some instances and a student organization. The village of Tursa uses the tursaansydän as a kind of a certificate of authenticity on products made there. Traditional textiles are still being made with swastikas as parts of traditional ornaments.
Swastika in Finnish military.
The Finnish Air Force used the swastika as an emblem, introduced in 1918. The type of swastika adopted by the air-force was the symbol of luck for the Swedish count Eric von Rosen, who donated one of its earliest aircraft; he later became a prominent figure in the Swedish nazi-movement.
The swastika was also used by the women's paramilitary organization Lotta Svärd, which was banned in 1944 in accordance with the Moscow Armistice between Finland and the allied Soviet Union and Britain.
The President of Finland is the grand master of the Order of the White Rose. According to the protocol, the president shall wear the Grand Cross of the White Rose with collar on formal occasions. The original design of the collar, decorated with 9 swastikas, dates from 1918, and was designed by the artist Akseli Gallen-Kallela. The Grand Cross with the swastika collar has been awarded 41 times to foreign heads of state. To avoid misunderstandings, the swastika decorations were replaced by fir crosses at the decision of president Urho Kekkonen in 1963 after it became known that the President of France Charles De Gaulle was uncomfortable with the swastika collar.
Also a design by Gallen-Kallela from 1918, the Cross of Liberty has a swastika pattern in its arms. The Cross of Liberty is depicted in the upper left corner of the standard of the President of Finland.
In December 2007, a silver replica of the WWII period Finnish air defence's relief ring decorated with a swastika became available as a part of a charity campaign.
The original war time idea was that the public swap their precious metal rings for the State air defence's relief ring, made of iron.
Latvia.
Latvia adopted the swastika, called the Ugunskrusts ("fire cross"), for its air force in 1918/1919 and continued its use until 1940. The cross itself was maroon on a white background, mirroring the colors of the Latvian flag. Earlier versions pointed counter-clockwise, while later versions pointed clock-wise and eliminated the white background.
Poland
The traditional symbols of the Podhale Rifles include the edelweiss flower and the Mountain Cross, a swastika symbol popular in folk culture of the Polish mountainous regions. The units of Podhale Rifles, both historical and modern, are notable for their high morale and distinctive uniforms.
North America.
The swastika motif is found in some traditional Native American art and iconography. Historically, the design has been found in excavations of Mississippian-era sites in the Ohio and Mississippi River valleys, and on objects associated with the Southeastern Ceremonial Complex (S.E.C.C.). It is also widely used by a number of southwestern tribes, most notably the Navajo, and plains nations such as the Dakota. Among various tribes, the swastika carries different meanings. To the Hopi it represents the wandering Hopi clan; to the Navajo it is one symbol for the whirling log ("tsil no'oli"), a sacred image representing a legend that is used in healing rituals. A brightly colored First Nations saddle featuring swastika designs is on display at the Royal Saskatchewan Museum in Canada.
A swastika shape is a symbol in the culture of the Kuna people of Kuna Yala, Panama. In Kuna tradition it symbolizes the octopus that created the world, its tentacles pointing to the four cardinal points.
In February 1925 the Kuna revolted vigorously against Panamanian suppression of their culture, and in 1930 they assumed autonomy. The flag they adopted at that time is based on the swastika shape, and remains the official flag of Kuna Yala. A number of variations on the flag have been used over the years: red top and bottom bands instead of orange were previously used, and in 1942 a ring (representing the traditional Kuna nose-ring) was added to the center of the flag to distance it from the symbol of the Nazi party.
The town of Swastika, Ontario, Canada is named after the symbol.
Africa.
Swastika can be found on Ashanti gold weights and among adinkra symbols in West Africa.
Use in Nazism.
In the wake of widespread popular usage, the Nazi Party ("Nationalsozialistische Deutsche Arbeiterpartei" or "NSDAP") formally adopted the swastika (in German: "Hakenkreuz" [hook-cross]) in 1920. This was used on the party's flag, badge, and armband.
In his 1925 work "Mein Kampf," Adolf Hitler writes that: "I myself, meanwhile, after innumerable attempts, had laid down a final form; a flag with a red background, a white disk, and a black swastika in the middle. After long trials I also found a definite proportion between the size of the flag and the size of the white disk, as well as the shape and thickness of the swastika."
When Hitler created a flag for the Nazi Party, he sought to incorporate both the swastika and "those revered colors expressive of our homage to the glorious past and which once brought so much honor to the German nation." (Red, white, and black were the colors of the flag of the old German Empire.) He also stated: "As National Socialists, we see our program in our flag. In red, we see the social idea of the movement; in white, the nationalistic idea; in the swastika, the mission of the struggle for the victory of the Aryan man, and, by the same token, the victory of the idea of creative work."
The swastika was also understood as "the symbol of the creating, effecting life" ("das Symbol des schaffenden, wirkenden Lebens") and as "race emblem of Germanism" ("Rasseabzeichen des Germanentums").
The use of the swastika was incorporated by Nazi theorists with their conjecture of Aryan cultural descent of the German people. Following the Nordicist version of the Aryan invasion theory, the Nazis claimed that the early Aryans of India, from whose Vedic tradition the swastika sprang, were the prototypical white invaders. The concept of racial hygiene was an ideology central to Nazism, though it is pseudoscience. For Alfred Rosenberg, the Aryans of India were both a model to be imitated and a warning of the dangers of the spiritual and racial "confusion" that, he believed, arose from the close proximity of races. Thus, they saw fit to co-opt the sign as a symbol of the Aryan master race. The use of the swastika as a symbol of the Aryan race dates back to writings of Emile Burnouf. Following many other writers, the German nationalist poet Guido von List believed it to be a uniquely Aryan symbol.
Before the Nazis, the swastika was already in use as a symbol of German "völkisch" nationalist movements ("Völkische Bewegung"). In "Deutschland Erwache" (ISBN 0-912138-69-6), Ulric of England says:
[...] what inspired Hitler to use the swastika as a symbol for the NSDAP was its use by the Thule Society (German: Thule-Gesellschaft) since there were many connections between them and the DAP ... from 1919 until the summer of 1921 Hitler used the special Nationalsozialistische library of Dr. Friedrich Krohn, a very active member of the "Thule-Gesellschaft" ... Dr. Krohn was also the dentist from Sternberg who was named by Hitler in "Mein Kampf" as the designer of a flag very similar to one that Hitler designed in 1920 ... during the summer of 1920, the first party flag was shown at Lake Tegernsee ... these home-made ... early flags were not preserved, the "Ortsgruppe München" (Munich Local Group) flag was generally regarded as the first flag of the Party.
José Manuel Erbez says:
The first time the swastika was used with an Aryan meaning was on December 25, 1907, when the self-named Order of the New Templars, a secret society founded by Joseph Jörg Lanz von Liebenfels, hoisted at Werfenstein Castle (Austria) a yellow flag with a swastika and four fleurs-de-lys.
However, Liebenfels was drawing on an already established use of the symbol.
On March 14, 1933, shortly after Hitler's appointment as Chancellor of Germany, the NSDAP flag was hoisted alongside Germany's national colors. It was adopted as the sole national flag on September 15, 1935 (see Nazi Germany).
The swastika was used for badges and flags throughout Nazi Germany, particularly for government and military organizations, but also for "popular" organizations such as the "Reichsbund Deutsche Jägerschaft" (German Hunting Society).
While the DAP and the NSDAP had used both right-facing and left-facing swastikas, the right-facing swastika was used consistently from 1920 onwards. Ralf Stelter notes that the swastika flag used on land had a right-facing swastika on both sides, while the ensign (naval flag) had it printed through so that a left-facing swastika would be seen when looking at the ensign with the flagpole to the right. Nazi ensigns had a through and through image, so both versions were present, one on each side, but the Nazi flag on land was right-facing on both sides and at a 45° rotation.
Several variants are found:
There were attempts to amalgamate Nazi and Hindu use of the swastika, notably by the French writer Savitri Devi who declared Hitler an Avatar of Vishnu (see Nazi mysticism).
One British fighter pilot inscribed a swastika in his logbook for each German plane he shot down in World War II.
American figher pilot Fred J. Christensen painted swastika symbols on the fuselage of his plane in the same way.
Post-WWII stigmatization.
Origins.
Because of its use by Nazi Germany, the swastika since the 1930s has been largely associated with Nazism and white supremacy in most Western countries.
As a result, all of its use, or its use as a Nazi or hate symbol is prohibited in some countries, including Germany. Because of the stigma attached to the symbol, many buildings that have contained the symbol as decoration have had the symbol removed.
Germany.
The German and Austrian postwar criminal code makes the public showing of the "Hakenkreuz" (the swastika), the sigrune, the Celtic cross (specifically the variations used by the White-Power-Activists), the wolfsangel, the odal rune and the SS skull illegal, except for scholarly reasons (and - in the case of the odal rune - as the insignia of the rank of sergeant major, "Hauptfeldwebel", in the modern German Bundeswehr). It is also censored from the reprints of 1930s railway timetables published by the Reichsbahn. The eagle remains, but appears to be holding a solid black circle between its talons. The swastikas on Hindu, Buddhist, and Jain temples are exempt, as religious symbols cannot be banned in Germany.
The German fashion company Esprit Holdings was investigated for using traditional British-made folded leather buttons after complaints that they resembled swastikas. In response, Esprit Holdings destroyed two hundred thousand catalogues.
A controversy was stirred by the decision of several police departments to begin inquiries against anti-fascists. In late 2005 police raided the offices of the punk rock label and mail order store "Nix Gut Records" and confiscated merchandise depicting crossed-out swastikas and fists smashing swastikas. In 2006 the Stade police department started an inquiry against anti-fascist youths using a placard depicting a person dumping a swastika into a trashcan. The placard was displayed in opposition to the campaign of right-wing nationalist parties for local elections.
On Friday, March 17, 2006, a member of the Bundestag, Claudia Roth reported herself to the German police for displaying a crossed-out swastika in multiple demonstrations against Neo-Nazis, and subsequently got the Bundestag to suspend her immunity from prosecution. She intended to show the absurdity of charging anti-fascists with using fascist symbols: "We don't need prosecution of non-violent young people engaging against right-wing extremism." On March 15, 2007, the Federal Court of Justice of Germany (Bundesgerichtshof) held that the crossed-out symbols were "clearly directed against a revival of national-socialist endeavors", thereby settling the dispute for the future.
Attempt to ban in the European Union.
The European Union's Executive Commission proposed a European Union-wide anti-racism law in 2001, but European Union states failed to agree on the balance between prohibiting racism and freedom of expression. An attempt to ban the swastika across the EU in early 2005 failed after objections from the British Government and others. In early 2007, while Germany held the European Union presidency, Berlin proposed that the European Union should follow German Criminal Law and criminalize the denial of the Holocaust and the display of Nazi symbols including the swastika, which is based on the Ban on the Symbols of Unconstitutional Organizations Act. This led to an opposition campaign by Hindu groups across Europe against a ban on the swastika. They pointed out that the swastika has been around for 5,000 years as a symbol of peace. The proposal to ban the swastika was dropped by Berlin from the proposed European Union wide anti-racism laws on January 29, 2007.
Media.
In 2010, Microsoft officially spoke out against the use of the swastika in the first-person shooter "". In "Black Ops", players are allowed to customize their name tags to represent, essentially, whatever they want. The swastika can be created and used, but Stephen Toulouse, director of Xbox Live policy and enforcement, stated that players with the symbol on their name tag will be banned (if someone reports as inappropriate) from Xbox Live.
In the Indiana Jones Stunt Spectacular in Disney Hollywood Studios in Orlando, Florida, the swastikas on German trucks, aircraft and actor uniforms in the reenactment of a scene from "Raiders of the Lost Ark" were removed in 2004. The swastika has been replaced by a stylized Greek Cross. "Sin City" character Miho occasionally uses shurikens shaped like a swastika as assassination tools.
Satirical use.
A book featuring "120 Funny Swastika Cartoons" was published in 2008 by New York Cartoonist Sam Gross. The author said he created the cartoons in response to excessive news coverage given to Swastika vandals, that his intent "...is to reduce the Swastika to something humorous."
The powerful symbolism acquired by the swastika has often been used in graphic design and propaganda as a means of drawing Nazi comparisons; examples include the cover of Stuart Eizenstat's 2003 book "Imperfect Justice", publicity materials for Constantin Costa-Gavras's 2002 film "Amen.", and a billboard that was erected opposite the United States Interests Section in Havana in Havana, Cuba, in 2004, which juxtaposed images of the Abu Ghraib torture and prisoner abuse pictures with a swastika.
Misinterpretation over imported Asian products in Western countries.
At the end of 20th century, and early 21st century, confusion and controversy has occurred when consumer goods bearing the Buddhist symbol have been exported to North America, and mistakenly interpreted by Western consumers as a Nazi symbol.
When a ten-year-old boy in Lynbrook, New York, bought a set of Pokémon cards imported from Japan in 1999, two of the cards contained the left-facing Buddhist swastika. The boy's parents misinterpreted the symbol as a Nazi swastika, which is right-facing with 45 degree rotation, and filed a complaint to the manufacturer. It also caused a lot of concern amongst fans from Jewish communities. Nintendo of America announced that the cards would be discontinued, explaining that what was acceptable in one culture was not necessarily so in another; their action was welcomed by the Anti-Defamation League who recognised that there was no intention to be offensive but said that international commerce meant that "isolating Swastika in Asia would just create more problems."
In 2002, Christmas crackers containing plastic toy red pandas sporting swastikas were pulled from shelves after complaints from consumers in Canada. The manufacturer, based in China, explained the symbol was presented in a traditional sense and not as a reference to the Nazis, and apologized to the customers for the cross-cultural mixup. In 2007, Spanish fashion chain Zara withdrew a handbag from its stores after a customer in Britain complained swastikas were embroidered on it. The bags were made by a supplier in India and inspired by commonly used Hindu symbols, which include the swastika.
Contemporary use in Asia.
Indian Subcontinent.
In Indian Subcontinent, the swastika is omnipresent as a symbol of wealth and good fortune. In India and Nepal, electoral ballot papers are stamped with a round swastika-like pattern (to ensure that the accidental ink imprint on the other side of a folded ballot paper can be correctly identified as such). Many businesses and other organisations, such as the Ahmedabad Stock Exchange and the Nepal Chamber of Commerce, use the swastika in their logos. The red swastika was suggested as an emblem of International Red Cross and Red Crescent Movement in India and Sri Lanka, but the idea was not implemented. Swastikas are fairly ubiquitous in Indian and Nepalese cities, located on buses, buildings, auto-rickshaws, and clothing. The swastika continues to be prominently used in Hindu religious ceremonies and temples, and is recognised as a Hindu religious symbol, sometimes used to evoke the Shakti in tantric rituals.
Musaeus College in Colombo, Sri Lanka which is a popular Buddhist girls' school in the country has a left facing swastika in their school logo alongside the Sanskrit motto පදීපං ගවේසථ" "(pronounced: "padeepang gavae saTha")" which means "Follow the Light".
In India, Swastik and Swastika, with their spelling variants, are common first names for males and females respectively, e.g. Swastika Mukherjee. Also, the Seal of Bihar contains two swastikas.
East Asia.
In the Sinosphere, countries and regions that were historically influenced by the culture of China, such as Taiwan, Japan, Hong Kong, Korea, Vietnam, Singapore and China itself, the symbol is most commonly associated with Buddhism.
They are commonly found in Buddhist temples, religious artifacts, texts related to Buddhism and schools founded by Buddhist religious groups.
The Red Swastika Society, a syncretic religious group that aspires to unify Taoism, Confucianism, and Buddhism, runs two schools in Hong Kong (Hong Kong Red Swastika Society Tai Po Secondary School and Hong Kong Red Swastika Society Tuen Mun Primary School ) and one in Singapore (Red Swastika School). All of them incorporated the Swastika in their school logo to signify the society's aspiration with philanthropy and moral education.
The swastika is also used in maps to denote a temple. For example, the symbol is designated by the Survey Act and related Japanese governmental rules to denote a Buddhist temple on Japanese maps.
Hirosaki City in Aomori Prefecture designates this symbol as its official flag, which stemmed from its use in the emblem of Tsugaru clan, the lord of Hirosaki Domain in Edo era. See also the section East Asian traditions in this article.
Central Asia.
In 2005, authorities in Tajikistan called for the widespread adoption of the swastika as a national symbol. President Emomali Rahmonov declared the swastika an Aryan symbol and 2006 to be "the year of Aryan culture," which would be a time to "study and popularize Aryan contributions to the history of the world civilization, raise a new generation (of Tajiks) with the spirit of national self-determination, and develop deeper ties with other ethnicities and cultures."
New religious movements.
Besides the use as a religious symbol in Buddhism, Hinduism and Jainism, which can be traced to pre-modern traditions, the swastika is also used by a number of new religious movements established in the modern period.

</doc>
<doc id="45945" url="https://en.wikipedia.org/wiki?curid=45945" title="Lower Canada">
Lower Canada

The Province of Lower Canada () was a British colony on the lower Saint Lawrence River and the shores of the Gulf of Saint Lawrence (1791–1841). It covered the southern portion of the modern-day Province of Quebec, Canada, and the Labrador region of the modern-day Province of Newfoundland and Labrador (until the Labrador region was transferred to Newfoundland in 1809).
Lower Canada consisted of part of the former colony of Canada of New France, populated mainly by Canadiens, which was ceded to Great Britain after that Empire's victory in the Seven Years' War, also called the French and Indian War in the United States. Other parts of New France ceded to Britain became the Colonies of Nova Scotia, New Brunswick, and Prince Edward Island.
The Province of Lower Canada was created by the "Constitutional Act of 1791" from the partition of the British colony of the Province of Quebec (1763–91) into the Province of Lower Canada and the Province of Upper Canada. The prefix "lower" in its name refers to its geographic position farther downriver from the headwaters of the St. Lawrence River than its contemporary Upper Canada, present-day southern Ontario.
The Colony/Province was abolished in 1841, when it and the adjacent Upper Canada were united into the Province of Canada.
Rebellion.
Like Upper Canada, there was significant political unrest. 22 years after the invasion by the Americans in the War of 1812, a rebellion now challenged the British rule of the predominantly French population. After the Patriote Rebellion in the Rebellions of 1837-1838 were crushed by the British Army and Loyal volunteers, the "1791 Constitution" was suspended on 27 March 1838 and a special council was appointed to administer the Colony. An abortive attempt by revolutionary Robert Nelson to declare a Republic of Lower Canada was quickly thwarted.
The provinces of Lower Canada and Upper Canada were combined as the United Province of Canada in 1841, when The Union Act of 1840 came into force. Their separate Legislatures were combined into a single Parliament with equal representation for both constituent parts, even if Lower Canada had more population.
Constitution.
The Province of Lower Canada inherited the mixed set of French and English institutions that existed in the Province of Quebec during the 1763–91 period and which continued to exist later in Canada-East (1841–67) and ultimately in the current Province of Quebec (1867–).
Transportation.
Traveling around Lower Canada was made mainly by water along the St. Lawrence River. On land the only main route was the Chemin du Roy or King's Highway, built in the 1730s by New France. The King's Highway remained as an alternate means of travel until the challenge of steamboats (1815) and trains on land (1850s) began to challenge the royal road.
Challenged by boats and trains, the royal road's importance waned after the 1850s and would not re-emerged as key means of transportation until the modern highway system of Quebec was created in the 20th Century.

</doc>
<doc id="45948" url="https://en.wikipedia.org/wiki?curid=45948" title="Saint Lawrence River">
Saint Lawrence River

The Saint Lawrence River (; Tuscarora: "Kahnawáʼkye"; Mohawk: "Kaniatarowanenneh", meaning "big waterway") is a large river in the middle latitudes of North America. The Saint Lawrence River flows in a roughly north-easterly direction, connecting the Great Lakes with the Atlantic Ocean and forming the primary drainage outflow of the Great Lakes Basin. It traverses the Canadian provinces of Quebec and Ontario, and is part of the international boundary between Ontario, Canada, and the U.S. state of New York. This river also provides the basis of the commercial Saint Lawrence Seaway.
Geography.
The St. Lawrence River begins at the outflow of Lake Ontario and flows through Gananoque, Brockville, Morristown, Ogdensburg, Massena, Cornwall, Montreal, Trois-Rivières, and Quebec City before draining into the Gulf of Saint Lawrence, one of the largest estuaries in the world. The estuary begins at the eastern tip of Île d'Orléans, just downstream from Quebec City. The river becomes tidal around Quebec City.
The St. Lawrence River runs from the farthest headwater to the mouth and from the outflow of Lake Ontario. The farthest headwater is the North River in the Mesabi Range at Hibbing, Minnesota. Its drainage area, which includes the Great Lakes, the world's largest system of freshwater lakes, is , of which is in Canada and is in the United States. The basin covers parts of Ontario and Quebec in Canada, parts of Illinois, Indiana, Minnesota, New York, Ohio, Pennsylvania, Vermont, and Wisconsin, and the entirety of the state of Michigan in the United States. The average discharge below the Saguenay River is . At Quebec City, it is . The average discharge at the river's source, the outflow of Lake Ontario, is .
The St Lawrence River includes Lake Saint-Louis south of Montreal, Lake Saint Francis at Salaberry-de-Valleyfield and Lac Saint-Pierre east of Montreal. It encompasses four archipelagoes: the Thousand Islands chain near Alexandria Bay, New York and Kingston, Ontario; the Hochelaga Archipelago, including the Island of Montreal and Île Jésus (Laval); the Lake St. Pierre Archipelago (classified biosphere world reserve by the UNESCO in 2000) and the smaller Mingan Archipelago. Other islands include Île d'Orléans near Quebec City and Anticosti Island north of the Gaspé. It is the second longest river in Canada.
Lake Champlain and the Ottawa, Richelieu, Saguenay, and Saint-François rivers drain into the St. Lawrence.
The St. Lawrence River is in a seismically active zone where fault reactivation is believed to occur along late Proterozoic to early Paleozoic normal faults related to the opening of Iapetus Ocean. The faults in the area are rift related and are called the Saint Lawrence rift system.
The St. Lawrence Valley is a physiographic province of the larger Appalachian division, containing the Champlain and Northern physiographic section.
History.
Though European mariners, such as John Cabot, the brothers Gaspar and Miguel Corte-Real, and Alonso Sanchez in the 15th century and the Norse 500 years still earlier, explored the Gulf of St. Lawrence the first European explorer known to have sailed up the St. Lawrence River itself was Jacques Cartier. At that time, the land along the river was inhabited by the St. Lawrence Iroquoians. Donnacona, an Iroquoian chief, had two sons who helped Cartier explore the area during his second trip to Canada in 1535. As Cartier arrived in the estuary on St. Lawrence's feast day, he named it the "Gulf of St. Lawrence". The St. Lawrence River is partly within the U.S. and as such is that country's sixth oldest surviving European place-name.
The earliest regular Europeans in the area were the Basques, who came to the St Lawrence Gulf and River in pursuit of whales from the early 16th century. The Basque whalers and fishermen traded with indigenous Americans and set up settlements, leaving vestiges all over the coast of eastern Canada and deep into the Saint Lawrence River. Basque commercial and fishing activity reached its peak before the "Armada Invencible"'s disaster (1588), when the Spanish Basque whaling fleet was confiscated by King Philip II of Spain and largely destroyed. Initially, the whaling galleons from Labourd were not affected by the Spanish defeat.
Until the early 17th century, the French used the name "Rivière du Canada" to designate the Saint Lawrence upstream to Montreal and the Ottawa River after Montreal. The Saint Lawrence River served as the main route for European exploration of the North American interior, first pioneered by French explorer Samuel de Champlain.
Control of the river was crucial to British strategy to capture New France in the Seven Years' War. Having captured Louisbourg in 1758, the British sailed up to Quebec the following year thanks to charts drawn up by James Cook. British troops were ferried via the St. Lawrence to attack the city from the west, which they successfully did at the Battle of the Plains of Abraham. The river was used again by the British to defeat the French siege of Quebec under the Chevalier de Lévis in 1760.
Because of the virtually impassable Lachine Rapids, the St. Lawrence was once continuously navigable only as far as Montreal. Opened in 1825, the Lachine Canal was the first to allow ships to pass the rapids. An extensive system of canals and locks, known as the Saint Lawrence Seaway, was officially opened on 26 June 1959 by Elizabeth II (representing Canada) and President Dwight D. Eisenhower (representing the United States). The Seaway now permits ocean-going vessels to pass all the way to Lake Superior.
During the Second World War, the Battle of the St. Lawrence involved submarine and anti-submarine actions throughout the lower St. Lawrence River and the entire Gulf of Saint Lawrence, Strait of Belle Isle and Cabot Strait from May to October 1942, September 1943, and again in October and November 1944. During this time, German U-boats sank several merchant marine ships and three Canadian warships.
In the late 1970s, the river was the subject of a successful ecological campaign (called "Save the River"), originally responding to planned development by the United States Army Corps of Engineers. The campaign was organized, among others, by Abbie Hoffman.
Sources.
The source of the North River in the Mesabi Range in Minnesota (Seven Beaver Lake) is considered to be the source of the Saint Lawrence River. Because it crosses so many lakes, the water system frequently changes its name. From source to mouth, the names are:
The Saint Lawrence River also passes through Lake Saint-Louis and Lake Saint-Pierre in Quebec.
Works.
The St. Lawrence River is at the heart of many Quebec novels (Anne Hébert's "Kamouraska", Réjean Ducharme's "L'avalée des avalés"), poems (in works of Pierre Morency, Bernard Pozier), and songs (Leonard Cohen's "Suzanne", Michel Rivard's "L'oubli", Joe Dassin's "Dans les yeux d'Émilie"), and André Gagnon's "Le Saint-Laurent"). The river was the setting for the Canadian television drama series Seaway. The river has also been portrayed in paintings, notably by the Group of Seven. In addition, the river is the namesake of Saint-Laurent Herald at the Canadian Heraldic Authority.
In 1980 Jacques Cousteau traveled to Canada to make two films on the St. Lawrence River and the Great Lakes, "Cries from the Deep" and "St. Lawrence: Stairway to the Sea".
Saint Lawrence River in art.
The Italian painter Vittorio Miele dedicated several works to the Saint Lawrence River.

</doc>
<doc id="45949" url="https://en.wikipedia.org/wiki?curid=45949" title="Academy Award for Best Assistant Director">
Academy Award for Best Assistant Director

In the first year of this award it referred to no specific film

</doc>
<doc id="45951" url="https://en.wikipedia.org/wiki?curid=45951" title="Minimal deterrence">
Minimal deterrence

In nuclear strategy, minimal deterrence (also called minimum deterrence) is an application of deterrence theory in which a state possesses no more nuclear weapons than is necessary to deter an adversary from attacking. Pure minimal deterrence is a doctrine of no first use, holding that the only mission of nuclear weapons is to deter a nuclear adversary by making the cost of a first strike unacceptably high. To present a credible deterrent, there must be the assurance that any attack would trigger a retaliatory strike. In other words, minimal deterrence requires rejecting a counterforce strategy in favor of pursuing survivable force that can be used in a countervalue second strike.
While the United States and the Soviet Union each developed robust first- and second-strike capabilities during the Cold War, the People's Republic of China pursued a doctrine of minimal nuclear deterrence. Assuming that decision-makers make cost-benefit analyses when deciding to use force, China's doctrine calls for acquiring a nuclear arsenal only large enough to destroy an adversary’s "strategic points" in such a way that the expected costs of a first strike outweigh the anticipated benefits. Both India and Pakistan have also adopted this strategy, which they term Minimum Credible Deterrence.
Minimal deterrence represents one way of solving the security dilemma and avoiding an arms race. Decision-makers often feel pressured to expand their arsenals when they perceive them to be vulnerable to an adversary’s first strike, especially when both sides seek to achieve the advantage. Eliminating this perceived vulnerability reduces the incentive to produce more and advanced weapons. For example, the United States’ nuclear force exceeds the requirements of minimal deterrence, and is structured to strike numerous targets in multiple countries and to have the ability to conduct successful counterforce strikes with high confidence. In response to this, China continues to modernize its nuclear forces because its leaders are concerned about the survivability of their arsenal in the face of the United States’ advances in strategic reconnaissance, precision strike, and missile defense.
One disadvantage of minimal deterrence is that it requires an accurate understanding of the level of damage an adversary finds unacceptable, especially if that understanding changes over time so that a previously credible deterrent is no longer credible. A minimal deterrence strategy must also account for the nuclear firepower that would be "lost" or "neutralized" during an adversary’s counterforce strike. Additionally, a minimal deterrence capability may embolden a state when it confronts a superior nuclear power, as has been observed in the relationship between China and the United States. Finally, while pursuing minimal deterrence during arms negotiations allows states to make reductions without becoming vulnerable, further reductions may be undesirable once minimal deterrence is reached because they will increase a state’s vulnerability and provide an incentive for an adversary to secretly expand its nuclear arsenal.

</doc>
<doc id="45955" url="https://en.wikipedia.org/wiki?curid=45955" title="Clanging">
Clanging

In psychology and psychiatry, clanging refers to a mode of speech characterized by association of words based upon sound rather than concepts. For example, this may include compulsive rhyming or alliteration without apparent logical connection between words. This is associated with the irregular thinking apparent in psychotic mental illnesses (e.g. schizophrenia).
Clanging refers specifically to behavior that is situationally inappropriate. While a poet rhyming is not evidence of mental illness, disorganized speech that impedes the patient's ability to communicate is a disorder in itself, often seen in schizophrenia.

</doc>
