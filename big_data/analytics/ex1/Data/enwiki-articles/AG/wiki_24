<doc id="41326" url="https://en.wikipedia.org/wiki?curid=41326" title="Loading coil">
Loading coil

A loading coil or load coil is an inductor that is inserted into an electronic circuit to increase its inductance. A loading coil is not a transformer as it does not provide coupling to another circuit. The term originated in the 19th century for inductors used to prevent signal distortion in long-distance telegraph transmission cables. The term is also used for inductors in radio antennas, or between the antenna and its feedline, to make an electrically short antenna resonant at its operating frequency.
Loading coils are historically also known as Pupin coils after Mihajlo Pupin, especially when used for the Heaviside condition and the process of inserting them is sometimes called "pupinization".
The concept of loading coils was discovered by Oliver Heaviside in studying the problem of slow signalling speed of the first transatlantic telegraph cable in the 1860s. He concluded additional inductance was required to prevent amplitude and time delay distortion of the transmitted signal. The mathematical condition for distortion-free transmission is known as the Heaviside condition. Previous telegraph lines were overland or shorter and hence had less delay, and the need for extra inductance was not as great. Submarine communications cables are particularly subject to the problem, but early 20th century installations using balanced pairs were often continuously loaded with iron wire or tape rather than discretely with loading coils, which avoided the sealing problem.
Applications.
Telephone lines.
A common application of loading coils is to improve the voice-frequency amplitude response characteristics of the twisted balanced pairs in a telephone cable. Because twisted pair is a balanced format, half the loading coil must be inserted in each leg of the pair to maintain the balance. It is common for both these windings to be formed on the same core. This increases the flux linkages, without which the number of turns on the coil would need to be increased.
Loading coils inserted periodically in series with a pair of wires reduce the attenuation at the higher voice frequencies up to the cutoff frequency of the low-pass filter formed by the inductance of the coils (plus the distributed inductance of the wires) and the distributed capacitance between the wires. Above the cutoff frequency, attenuation increases rapidly. The shorter the distance between the coils, the higher the cut-off frequency.
It should be emphasised that the cutoff effect is an artifact of using lumped inductors. With loading methods using continuous distributed inductance there is no cutoff.
Without loading coils, the line response is dominated by the resistance and capacitance of the line with the attenuation gently increasing with frequency. With loading coils of exactly the right inductance, neither capacitance nor inductance dominate: the response is flat, waveforms are undistorted and the characteristic impedance is resistive up to the cutoff frequency. The coincidental formation of an audio frequency filter is also beneficial in that noise is reduced.
DSL.
When loading coils are in place, signal attenuation remains low for signals within the passband of the transmission line but increases rapidly for frequencies above the audio cutoff frequency. Thus, if the pair is subsequently reused to support applications that require higher frequencies (such as analog or digital carrier systems or DSL), any loading coils that were present on the line must be removed or replaced with ones which are transparent to DSL. Using coils with parallel capacitors will form a filter with the topology of an m-derived filter and a band of frequencies above the cut-off will also be passed.
If the coils are not removed, and the subscriber is an extended distance (e.g. over 4 miles or 6.4 km) from the Central Office, DSL can not be supported. This sometimes happens in dense, growing areas such as Southern California in the late 1990s and early 21st century.
Carrier systems.
American early and middle 20th century telephone cables had load coils at intervals of a mile (1.61 km), usually in coil cases holding many. The coils had to be removed to pass higher frequencies, but the coil cases provided convenient places for repeaters of digital T-carrier systems, which could then transmit a 1.5 Mbit/s signal that distance. Due to narrower streets and higher cost of copper, European cables had thinner wires and used closer spacing. Intervals of a kilometer allowed European systems to carry 2 Mbit/s.
Radio antenna.
Another type of loading coil is used in radio antennas. Monopole and dipole radio antennas are designed to act as resonators for radio waves; the power from the transmitter, applied to the antenna through the antenna's transmission line, excites standing waves of voltage and current in the antenna element. To be resonant, the antenna must have a physical length of one quarter of the wavelength of the radio waves used (or a multiple of that length). At resonance the antenna acts electrically as a pure resistance, absorbing all the power applied to it from the transmitter.
In many cases for practical reasons it is necessary to make the antenna shorter than the resonant length. An antenna shorter than a quarter wavelength presents capacitive reactance to the transmission line. Some of the applied power is reflected back into the transmission line and travels back toward the transmitter. This causes standing waves on the transmission line (a standing wave ratio (SWR) greater than one) which waste energy, and can even overheat the transmitter.
So to make an electrically short antenna resonant, an inductor called a loading coil is inserted in series with the antenna. The inductive reactance of the coil is equal and opposite to, and cancels, the capacitive reactance of the antenna, so the loaded antenna presents a pure resistance to the transmission line, preventing energy from being reflected.
The loading coil is usually inserted at the base of the antenna, between it and the transmission line ("base loading"), but sometimes it is inserted in the center of the antenna element itself ("center loading").
Campbell equation.
The Campbell equation is a relationship due to George Ashley Campbell for predicting the propagation constant of a loaded line. It is stated as;
A more engineer friendly rule of thumb is that the approximate requirement for spacing loading coils is ten coils per wavelength of the maximum frequency being transmitted. This approximation can be arrived at by treating the loaded line as a constant k filter and applying image filter theory to it. From basic image filter theory the angular cutoff frequency and the characteristic impedance of a low-pass constant k filter are given by;
From these basic equations the necessary loading coil inductance and coil spacing can be found;
Expressing this in terms of number of coils per cutoff wavelength yields;
The phenomenon of cutoff whereby frequencies above the cutoff frequency are not transmitted is an undesirable side effect of loading coils (although it proved highly useful in the development of filters). Cutoff is avoided by the use of continuous loading since it arises from the lumped nature of the loading coils.
History.
Oliver Heaviside.
The origin of the loading coil can be found in the work of Oliver Heaviside on the theory of transmission lines. Heaviside (1881) represented the line as a network of infinitesimally small circuit elements. By applying his operational calculus to the analysis of this network he discovered (1887) what has become known as the Heaviside condition. This is the condition that must be fulfilled in order for a transmission line to be free from distortion. The Heaviside condition is that the series impedance, Z, must be proportional to the shunt admittance, Y, at all frequencies. In terms of the primary line coefficients the condition is:
Heaviside was aware that this condition was not met in the practical telegraph cables in use in his day. In general, a real cable would have,
This is mainly due to the low value of leakage through the cable insulator, which is even more pronounced in modern cables which have better insulators than in Heaviside's day. In order to meet the condition, the choices are therefore to try to increase G or L or to decrease R or C. Decreasing R requires larger conductors. Copper was already in use in telegraph cables and this is the very best conductor available short of using silver. Decreasing R means using more copper and a more expensive cable. Decreasing C would also mean a larger cable (although not necessarily more copper). Increasing G is highly undesirable; while it would reduce distortion, it would at the same time increase the signal loss. Heaviside considered, but rejected, this possibility which left him with the strategy of increasing L as the way to reduce distortion.
Heaviside immediately (1887) proposed several methods of increasing the inductance, including spacing the conductors further apart and loading the insulator with iron dust. Finally, Heaviside made the proposal (1893) to use discrete inductors at intervals along the line. However, he never succeeded in persuading the British GPO to take up the idea. Brittain attributes this to Heaviside's failure to provide engineering details on the size and spacing of the coils for particular cable parameters. Heaviside's eccentric character and setting himself apart from the establishment may also have played a part in their ignoring of him.
John Stone.
John S. Stone worked for the American Telephone & Telegraph Company (AT&T) and was the first to attempt to apply Heaviside's ideas to real telecommunications. Stone's idea (1896) was to use a bimetallic iron-copper cable which he had patented. This cable of Stone's would increase the line inductance due to the iron content and had the potential to meet the Heaviside condition. However, Stone left the company in 1899 and the idea was never implemented. Stone's cable was an example of continuous loading, a principle that was eventually put into practice is other forms, see for instance Krarup cable later in this article.
George Campbell.
George Campbell was another AT&T engineer working in their Boston facility. Campbell was tasked with continuing the investigation into Stone's bimetallic cable, but soon abandoned it in favour of the loading coil. His was an independent discovery, Campbell was aware of Heaviside's work in discovering the Heaviside condition, but unaware of Heaviside's suggestion of using loading coils to enable a line to meet it. The motivation for the change of direction was Campbell's limited budget.
Campbell was struggling to set up a practical demonstration over a real telephone route with the budget he had been allocated. After considering that his artificial line simulators used lumped components rather than the distributed quantities found in a real line, he wondered if he could not insert the inductance with lumped components instead of using Stone's distributed line. When his calculations showed that the manholes on telephone routes were sufficiently close together to be able to insert the loading coils without the expense of either having to dig up the route or lay in new cables he changed to this new plan. The very first demonstration of loading coils on a telephone cable was on a 46-mile length of the so-called Pittsburgh cable (the test was actually in Boston, the cable had previously been used for testing in Pittsburgh) on 6 September 1899 carried out by Campbell himself and his assistant. The first telephone cable using loaded lines put into public service was between Jamaica Plain and West Newton in Boston on 18 May 1900.
Campbell's work on loading coils provided the theoretical basis for his subsequent work on filters which proved to be so important for frequency-division multiplexing. The cut-off phenomena of loading coils, an undesirable side-effect, can be exploited to produce a desirable filter frequency response.
Michael Pupin.
Michael Pupin, inventor and Serbian immigrant to the USA, also played a part in the story of loading coils. Pupin filed a rival patent to the one of Campbell's. This patent of Pupin's dates from 1899. There is an earlier patent (1894, filed December 1893) which is sometimes cited as Pupin's loading coil patent but is, in fact, something different. The confusion is easy to understand, Pupin himself claims that he first thought of the idea of loading coils while climbing a mountain in 1894, although there is nothing from him published at that time.
Pupin's 1894 patent "loads" the line with capacitors rather than inductors, a scheme that has been criticised as being theoretically flawed and never put into practice. To add to the confusion, one variant of the capacitor scheme proposed by Pupin does indeed have coils. However, these are not intended to compensate the line in any way. They are there merely to restore DC continuity to the line so that it may be tested with regular equipment. Pupin states that the inductance is to be so large that it will block all AC signals above 50 Hz. Consequently, only the capacitor is adding any significant impedance to the line and "the coils will not exercise any material influence on the results before noted".
Legal battle.
Heaviside never patented his idea; indeed, he took no commercial advantage of any of his work. Despite the legal disputes surrounding this invention, it is unquestionable that Campbell was the first to actually construct a telephone circuit using loading coils. There also can be little doubt that Heaviside was the first to publish and many would dispute Pupin's priority.Behrend to Searle, in letter quoted by Brittain, p37Searle to Behrend, 1931, in letter quoted by Brittain, p37Nahin, p276</ref>
AT&T fought a legal battle with Pupin over his claim. Pupin was first to patent but Campbell had already conducted practical demonstrations before Pupin had even filed his patent (December 1899). Campbell's delay in filing was due to the slow internal machinations of AT&T.
However, AT&T foolishly deleted from Campbell's proposed patent application all the tables and graphs detailing the exact value of inductance that would be required before the patent was submitted. Since Pupin's patent contained a (less accurate) formula, AT&T was open to claims of incomplete disclosure. Fearing that there was a risk that the battle would end with the invention being declared unpatentable due to Heaviside's prior publication, they decided to desist from the challenge and buy an option on Pupin's patent for a yearly fee so that AT&T would control both patents. By January 1901 Pupin had been paid $200,000 ($13 million in 2011) and by 1917, when the AT&T monopoly ended and payments ceased, he had received a total of $455,000 ($25 million in 2011).
Benefit to AT&T.
The invention was of enormous value to AT&T. Telephone cables could now be used to twice the distance previously possible, or alternatively, a cable of half the previous quality (and cost) could be used over the same distance. When considering whether to allow Campbell to go ahead with the demonstration, their engineers had estimated that they stood to save $700,000 in new installation costs in New York and New Jersey alone. It has been estimated that AT&T saved $100 million in the first quarter of the 20th century. Heaviside, who began it all, came away with nothing. He was offered a token payment but would not accept, wanting the credit for his work. He remarked ironically that if his prior publication had been admitted it would "interfere . . . with the flow of dollars in the proper direction . . .".
Krarup cable.
Loading coils were not without their problems. In heavy submarine cables, loading coils were difficult to lay. Discontinuities where the coils were installed caused stresses in the cable during laying. Without great care, the cable might part and would be difficult to repair. A second problem was that the material science of the time had difficulties sealing the joint between coil and cable against ingress of seawater. When this occurred the cable was ruined.
A Danish engineer, Carl Emil Krarup, invented a form of continuously loaded cable which solved these problems and the cable is named for him. Krarup cable has iron wires continuously wound around the central copper conductor with adjacent turns in contact with each other. This cable was the first use of continuous loading on any telecommunication cable. In 1902, Krarup both wrote his paper on this subject and saw the installation of the first cable between Helsingør (Denmark) and Helsingborg (Sweden).
Permalloy cable.
Even though the Krarup cable added inductance to the line, this was insufficient to meet the Heaviside condition. AT&T searched for a better material with higher magnetic permeability. In 1914, Gustav Elmen discovered permalloy, a magnetic nickel-iron annealed alloy. In c. 1915, Oliver E. Buckley, H. D. Arnold, and Elmen, all at Bell Labs, greatly improved transmission speeds by suggesting a method of constructing submarine communications cable using permalloy tape wrapped around the copper conductors.
The cable was tested in a trial in Bermuda in 1923. The first permalloy cable placed in service connected New York City and Horta (Azores) in September 1924. Permalloy cable enabled signalling speed on submarine telegraph cables to be increased to 400 words/min at a time when 40 words/min was considered good. The first transatlantic cable achieved only two words/min.
Mu-metal cable.
Mu-metal has similar magnetic properties to permalloy but the addition of copper to the alloy increases the ductility and allows the metal to be drawn into wire. Mu-metal cable is easier to construct than permalloy cable, the mu-metal being wound around the core copper conductor in much the same way as the iron wire in Krarup cable. A further advantage with mu-metal cable is that the construction lends itself to a variable loading profile whereby the loading is tapered towards the ends.
Mu-metal was invented in 1923 by The Telegraph Construction and Maintenance Company Ltd., London, who made the cable, initially, for the Western Union Telegraph Co. Western Union were in competition with AT&T and the Western Electric Company who were using permalloy. The patent for permalloy was held by Western Electric which prevented Western Union from using it.
Patch loading.
Continuous loading of cables is expensive and hence is only done when absolutely necessary. Lumped loading with coils is cheaper but has the disadvantages of difficult seals and a definite cutoff frequency. A compromise scheme is patch loading whereby the cable is continuously loaded in repeated sections. The intervening sections are left unloaded.
Current practice.
Loaded cable is no longer a useful technology for submarine communication cables, having first been superseded by co-axial cable using electrically powered in-line repeaters and then by fibre-optic cable. Manufacture of loaded cable declined in the 1930s and was then superseded by other technologies post-war. Loading coils can still be found in some telephone landlines today but new installations would use more modern technology.

</doc>
<doc id="41327" url="https://en.wikipedia.org/wiki?curid=41327" title="Lobe">
Lobe

Lobe may refer to:

</doc>
<doc id="41328" url="https://en.wikipedia.org/wiki?curid=41328" title="Local access and transport area">
Local access and transport area

Local access and transport area (LATA) is a term used in U.S. telecommunications regulation. It represents a geographical area of the United States under the terms of the Modification of Final Judgment (MFJ) entered by the United States District Court for the District of Columbia in Civil Action number 82-0192 or any other geographic area designated as a LATA in the National Exchange Carrier Association, Inc. Tariff FCC No. 4. that precipitated the breakup of the original AT&T into the "Baby Bells" or created since that time for wireline regulation.
Generally, a LATA represents an area within which a divested Regional Bell Operating Company (RBOC) is permitted to offer exchange telecommunications and exchange access services. Under the terms of the MFJ, the RBOCs are generally prohibited from providing services that originate in one LATA and terminate in another.
LATA boundaries tend to be drawn around markets, and not necessarily along existing state or area code borders. Some LATAs cross over state boundaries, such as those for the New York metropolitan area and Greenwich, Connecticut; Chicago, Illinois; Portland, Oregon; and areas between Maryland, Virginia, and West Virginia. Area codes and LATAs do not necessarily share boundaries; many LATAs exist in multiple area codes, and many area codes exist in multiple LATAs.
Originally, the LATAs were grouped into regions within which one particular RBOC was allowed to provide services. The LATAs in each of these regions are numbered beginning with the same digit. Generally the LATAs were associated with carriers or other indications in the following manner:
In addition to this list, two local carriers were made independent: Cincinnati Bell in the Cincinnati area, and SNET (a former unit of AT&T, sold to Frontier) in Connecticut. These were assigned LATAs in the 9xx range.
Since the breakup of the original AT&T in 1984, however, some amount of deregulation, as well as a number of phone company mergers, have blurred the significance of these regions. A number of new LATAs have been formed within these regions since their inception, most beginning with the digit 9.
LATAs contribute to an often confusing aspect of long distance telephone service. Due to the various and overlapping regulatory limitations and inter-business arrangements, phone companies typically provide differing types of “long distance” service, each with potentially different rates:
Given the complexity of the legal and financial issues involved in each distinction, many long distance companies tend to not explain the details of these different rates, which can lead to billing questions from surprised customers.
Local carriers have various alternative terms for LATAs such as “Service Area” by Pacific Bell in California, or “Regional Calling Area” by Verizon in Maryland.
In order to facilitate the sharing of Telcordia telephone routing databases between countries, LATAs were later defined for the provinces of Canada, the other countries and territories of the North American Numbering Plan, and Mexico. Aside from U.S. territories, LATAs have no regulatory purpose in these areas. In 2000, the Canadian Radio-television and Telecommunications Commission eliminated all Canadian provincial LATAs in favor of a single LATA for Canada (888).
No LATAs exist with a second digit of 0 or 1, which distinguished them from traditional area codes.
List of LATAs.
US state LATAs.
The city or place name given with some LATAs is the name given to identify the LATA, not the limit of its boundary. Generally this is the most significant metropolitan area in the LATA. In some cases a LATA is named after the largest phone exchange in the LATA that was historically served by an RBOC. For example, the largest city in the Pahrump LATA in Nevada is Las Vegas. Since Las Vegas was not historically served by an RBOC, the LATA is named after the smaller town of Pahrump, which was historically served by Nevada Bell (now AT&T Inc.). Also, listing under a state does not necessarily limit the LATA's territory to that state; there may be overlaps as well as enclaves. Areas that include notable portions of other states are explained, but not all LATA state overlaps may be detailed.
LATA boundaries are not always solidly defined. Inter-carrier agreements, change proposals to the Federal Communications Commission (FCC), and new wiring developments into rural areas can and do often alter the effective borders between LATAs. Many sources on LATA boundary information conflict with each other at detailed levels. Telcordia data may provide the most up-to-date details of LATA inclusions.
Canada.
As LATAs exist for US regulatory purposes, where they serve as a demarcation between intra-LATA calls (handled by regional Bell operating companies) and inter-LATA calls (handled by interstate long distance carriers such as AT&T), they have no legal significance in Canada.
As of 2000, all of Canada (except for non-geographic numbers) is identified as LATA 888.
The use of this LATA set to identify individual provinces is therefore deprecated:
Local interconnection region.
Canada does define local interconnection regions (LIR's), which determine where points of interconnection (POI) must be provided by competing local exchange and mobile carriers to provide local number portability. A Canadian LIR is geographically smaller than a US LATA, typically comparable in size to a small city's flat-rate local calling area or to an entire large regional municipality. In areas where a small-city Digital Multiplex System controls a group of remote switching centres, one for each surrounding village, the local interconnect region normally includes each exchange in the city plus all downstream remotes of those exchanges. In a Toronto-sized city, the LIR will include only the city itself.
While the LIRs resemble local calling areas in geographic size, there are some key differences:
One example: The tiny unincorporated village of Beebe Plain, divided by the Quebec-Vermont border, is served by +1-819-876 Rock Island, Quebec, Canada (a remote station controlled from Magog) and +1-802-873 Derby Line, Vermont, USA (a remote station controlled from St. Johnsbury). Magog and St. Johnsbury are both a long-distance call from anywhere in Beebe Plain, even though Canadian subscribers can place local calls to Sherbrooke, US subscribers can locally call Newport and an international call within the village is local. An LIR assignment which follows network topology places the Canadian remote station in Magog's LIR, not Sherbrooke's LIR.

</doc>
<doc id="41329" url="https://en.wikipedia.org/wiki?curid=41329" title="Local battery">
Local battery


</doc>
<doc id="41330" url="https://en.wikipedia.org/wiki?curid=41330" title="Local call">
Local call

In telephony, the term local call has the following meanings:
Typically, local calls have shorter numbers than long distance calls, as the area code may not be required. However, this is not true in parts of the United States and Canada that are subject to overlay plans or many countries in Europe that require closed dialing plans.
Toll free (e.g. "800" numbers in the United States) are not necessarily local calls; despite being free to the caller, any charge due for the distance of the connection is charged to the "called" party.
Commercial users who make or accept many long distance calls to or from a particular distant place may make them as local calls by use of a foreign exchange service. Such an "FX" line also allows people in the distant place to call by using a telephone number local to them.

</doc>
<doc id="41332" url="https://en.wikipedia.org/wiki?curid=41332" title="Log-periodic antenna">
Log-periodic antenna

A log-periodic antenna (LP), also known as a log-periodic array or log-periodic aerial, is a multi-element, directional, antenna designed to operate over a wide band of frequencies. It was invented by Dwight Isbell and Raymond DuHamel at the University of Illinois in 1958.
The most common form of log-periodic antenna is the log-periodic dipole array or LPDA, The LPDA consists of a number of half-wave dipole driven elements of gradually increasing length, each consisting of a pair of metal rods. The dipoles are mounted close together in a line, connected in parallel to the feedline with alternating phase. Electrically, it simulates a series of two or three-element Yagi antennas connected together, each set tuned to a different frequency.
LPDAs look somewhat similar to multi-element Yagi designs, but work in very different ways. Adding elements to a Yagi increases its directionality, or gain, while adding elements to a LPDA increases its frequency response, or bandwidth. Because both designs are linear, a widely used design for television reception combined a Yagi for UHF reception in front of a larger LDPA for VHF. These can be identified by the much smaller elements at the front, and often a V-shaped reflector between the two sections.
LPDA/Yagi combo antennas were very popular from the 1960s through the 1980s when television broadcasting moved largely to cable. The digital transition in the 2000s led to the retirement of the VHF frequencies for television use in most countries. Modern terrestrial television antennas are more often dedicated to UHF, and the bowtie array is more common today. In the United States, however, some stations remained on the VHF spectrum. 
Basic concept.
The LPDA normally consists of a series of dipoles known as "elements" positioned along a support boom lying along the antenna axis. The elements are spaced at intervals following a logarithmic function of the frequency, known as "d" or "sigma". The length of the elements correspond to resonance at different frequencies within the antenna's overall bandwidth. This leads to a series of ever-shorter dipoles towards the "front" of the antenna. The relationship between the lengths is a function known as "tau". The ever-decreasing lengths makes the LPDA look, when viewed from the top, like a triangle or arrow with the tip pointed in the direction of the peak radiation pattern. "Sigma" and "tau" are the key design elements of the LPDA design.
Every element in the LPDA design is "active", that is, connected electrically to the feedline along with the other elements, though at any one frequency most of the elements draw little current from it. Each successive element is connected in "opposite" phase to the active connection running as a transmission line along the boom. For that reason, that transmission line can often be seen zig-zagging across the support boom holding the elements. One common design ploy is to use two booms that also acts as the transmission line, mounting the dipoles on the alternate booms. Other forms of the log-periodic design replace the dipoles with the transmission line itself, forming the log-periodic zig-zag antenna. Many other forms using the transmission wire as the active element also exist.
The Yagi and the LPDA designs look very similar at first glance, as both consist of a number of dipole elements spaced out along a support boom. The Yagi, however, has only a single dipole connected to the transmission line, usually the second one from the back of the array. The other dipoles on the boom are passive elements, with their two sides shorted, acting as "directors" or "reflectors" depending on their slightly different lengths and position relative to the "driven element". The difference between the LPDA and Yagi becomes obvious when examining their electrical connections; Yagi's lack the zig-zag connection between the elements. Another clear difference is the length of the dipoles; LPDA designs have much shorter dipoles towards the front of the antenna, forming a triangular shape as seen from the top, whereas the difference in lengths of Yagi elements is less noticeable or non-existent. Another visible difference is the spacing between the elements, which is normally constant in the Yagi, but becomes exponentially wider along the LPDA. Although both directional, the LPDA is intended to achieve a very wide bandwidth, whereas the Yagi has a very narrow bandwidth but achieves greater gain.
In general terms, the log-periodic design operates somewhat similar to a series of three-element Yagis, where each set of three consecutive elements forms a separate antenna with the driven element in the center, a director in front and reflector behind. However, the system is somewhat more complex than that, and all the elements contribute to some degree, so the gain for any given frequency is higher than a Yagi of the same dimensions as any one section of the log-periodic. However, it should also be noted that a Yagi with the same number of elements as a log-periodic would have "far" higher gain, as all of those elements are improving the gain of a single driven element. In its common use as a television antenna, it was common to combine a log-periodic design for VHF with a Yagi for UHF, with both halves being roughly equal in size. This resulted in much higher gain for UHF, typically on the order of 10 to 14 dB on the Yagi side and 6.5 dB for the log-periodic. But this extra gain was needed anyway in order to make up for a number of problems with UHF signals.
It should be strictly noted that the log-periodic shape, according to the IEEE definition, does not provide with broadband property for antennas. The broadband property of log-periodic antennas comes from its self-complementarity. Y. Mushiake found, for what he termed "the simplest self-complementary planar antenna," a driving point impedance of η0/2=188.4Ω at frequencies well within its bandwidth limits.
History.
The log periodic antenna was invented by Dwight E. Isbell, Raymond DuHamel and variants by Paul Mayes. The University of Illinois at Urbana-Champaign had patented the Isbell and Mayes-Carrel antennas and licensed the design as a package exclusively to JFD electronics in New York. Channel Master and Blonder-Tongue ignored the patents and produced a wide range of antennas based on this design. Lawsuits regarding the antenna patent which the UI Foundation lost, evolved into the Blonder-Tongue Doctrine. This precedent governs patent litigation.
Short wave broadcast antennas.
The log periodic is commonly used in high power short wave broadcasting where it is desired to invest in only a single antenna to cover transmissions over multiple bands. The log-periodic zig-zag design with up to 16 zig zag sections has been used. These large antennas are typically designed to cover 6 to 26 MHz but even larger ones have been built which operate as low as 2 MHz. Power ratings are available up to 500 KW. The antenna is fed from the small end. The antenna shown here would have about 14 dBi gain. An antenna array consisting of two such antennas, one above the other and driven in phase has a gain of up to 17 dBi. Being log-periodic, the antenna's main characteristics (radiation pattern, gain, driving point impedance) are almost constant over its entire frequency range, with the match to a 300 ohm feed line achieving a standing wave ratio of better than 2:1 over that range.

</doc>
<doc id="41333" url="https://en.wikipedia.org/wiki?curid=41333" title="Long-haul communications">
Long-haul communications

In telecommunication, the term long-haul communications has the following meanings:
1. In public switched networks, pertaining to circuits that span large distances, such as the circuits in inter-LATA, interstate, and international communications. See also Long line (telecommunications)
2. In the military community, communications among users on a national or worldwide basis.
"Note 1:" Compared to tactical communications, long-haul communications are characterized by (a) higher levels of users, such as the National Command Authority, (b) more stringent performance requirements, such as higher quality circuits, (c) longer distances between users, including worldwide distances, (d) higher traffic volumes and densities, (e) larger switches and trunk cross sections, and (f) fixed and recoverable assets.
"Note 2:" ""Long-haul communications"" usually pertains to the U.S. Defense Communications System.
" Note 3:" ""Long-haul telecommunications technicians"" can be translated into many fields of IT work within the corporate industry (Information Technology, Network Technician, Telecommunication Specialist, It Support, and so on). While the term is used in military most career fields that are in communications such as 3D1X2 - Cyber Transport Systems (the career field has been renamed so many times over the course of many years but essentially it is the same job (Network Infrastructure Tech., Systems Control Technician, and Cyber Transport Systems)) or may work in areas that require the "in between" (cloud networking) for networks (MSPP, ATM, Routers, Switches), phones (VOIP, DS0 - DS4 or higher, and so on), encryption (configuring encryption devices or monitoring), and video support data transfers. The "bulk data transfer" or aggregation networking.
The Long-haul telecommunication technicians is considered a 'jack of all" but it is much in the technician's interest to gather greater education with certifications to qualify for certain jobs outside the military. The Military provides an avenue but does not make the individual a master of the career field. The technician will find that the job out look outside of military requires many things that aren't required of them within the career field while in the military. So it is best to find the job that is similar to the AFSC and also view the companies description of the qualification to fit that job. Also at least get an associate degree, over 5 years experience, and all of the required "certs" (Network +, Security +, CCNA, CCNP and so on) to acquire the job or at least an interview. The best time to apply or get a guaranteed job is the last three months before you leave the military. Military personnel that are within the career field 3D1X2 require a Secrete, TS, or TS with SCI clearance in order to do the job.

</doc>
<doc id="41334" url="https://en.wikipedia.org/wiki?curid=41334" title="Longitudinal redundancy check">
Longitudinal redundancy check

In telecommunication, a longitudinal redundancy check (LRC) or horizontal redundancy check is a form of redundancy check that is applied independently to each of a parallel group of bit streams. The data must be divided into transmission blocks, to which the additional check data is added.
The term usually applies to a single parity bit per bit stream,
calculated independently of all the other bit streams (BIP-8). although it could also be used to refer to a larger Hamming code.
This "extra" LRC word at the end of a block of data is very similar to checksum and CRC.
Optimal Rectangular Code.
While simple longitudinal parity can only detect errors, it can be combined with additional error control coding, such as a transverse redundancy check, to correct errors.
The transverse redundancy check is stored on a dedicated "parity track".
Whenever any single bit error occurs in a transmission block of data,
such two dimensional parity checking or "two-coordinate parity checking"
enables the receiver to use the TRC to detect which byte the error occurred in, and the LRC to detect exactly which track the error occurred in, to discover exactly which bit is in error, and then correct that bit by flipping it.
Pseudocode.
International standard ISO 1155 states that a longitudinal redundancy check for a sequence of bytes may be computed in software by the following algorithm:
which can be expressed as "the 8-bit two's-complement value of the sum of all bytes modulo 28" (codice_1 is equivalent to codice_2).
Many protocols use an XOR-based longitudinal redundancy check byte,
(often called block check character or BCC),
including
the serial line internet protocol (SLIP),
the IEC 62056-21 standard for electrical meter reading,
smart cards as defined in ISO/IEC 7816, and
the ACCESS.bus protocol.
An 8-bit LRC such as this is equivalent to a cyclic redundancy check using the polynomial "x"8+1, but the independence of the bit streams is less clear when looked at in that way.

</doc>
<doc id="41336" url="https://en.wikipedia.org/wiki?curid=41336" title="Long-term stability">
Long-term stability

The long-term stability of an oscillator is the degree of uniformity of frequency over time, when the frequency is measured under identical environmental conditions, such as supply voltage, load, and temperature. Long-term frequency changes are caused by changes in the oscillator elements that determine frequency, such as crystal drift, inductance changes, and capacitance changes. 

</doc>
<doc id="41338" url="https://en.wikipedia.org/wiki?curid=41338" title="Loop gain">
Loop gain

In electronics and control system theory, loop gain is the sum of the gain, expressed as a ratio or in decibels, around a feedback loop. Feedback loops are widely used in electronics in amplifiers and oscillators, and more generally in both electronic and nonelectronic industrial control systems to control industrial plant and equipment. The concept is also used in biology. In a feedback loop, the output of a device, process or plant is sampled and applied to alter the input, to better control the output. The loop gain, along with the related concept of loop phase shift, determines the behavior of the device, and particularly whether the output is stable, or unstable, which can result in oscillation. The importance of loop gain as a parameter for characterizing electronic feedback amplifiers was first recognized by Heinrich Barkhausen in 1921,was developed further by Hendrik Wade Bode and Harry Nyquist at Bell Labs in the 1930s.
A block diagram of an electronic amplifier with negative feedback is shown at right. The input signal is applied to the amplifier with open-loop gain "A" and amplified. The output of the amplifier is applied to a feedback network with gain "β", and subtracted from the input to the amplifier. The loop gain is calculated by imagining the feedback loop is broken at some point, and calculating the net gain if a signal is applied. In the diagram shown, the loop gain is the product of the gains of the amplifier and the feedback network, "−Aβ". The minus sign is because the feedback signal is subtracted from the input. In amplifiers, the loop gain is the difference between the open-loop gain curve and the closed-loop gain curve (actually, the 1/β curve) on a dB scale. 
The gains "A" and "β", and therefore the loop gain, generally vary with the frequency of the input signal, and so are usually expressed as functions of the angular frequency "ω" in radians per second. 

</doc>
<doc id="41339" url="https://en.wikipedia.org/wiki?curid=41339" title="Low-performance equipment">
Low-performance equipment

In telecommunication, the term low-performance equipment has the following meanings:

</doc>
<doc id="41340" url="https://en.wikipedia.org/wiki?curid=41340" title="LPD433">
LPD433

LPD433 (low power device 433 MHz) is a UHF band in which licence free communication devices are allowed to operate. The frequencies correspond with the ITU region 1 ISM band of 433.050 MHz to 434.790 MHz, and operation is mainly limited to CEPT countries. The frequencies used are within the 70-centimeter band, which is traditionally reserved for higher power amateur radio operations in most nations worldwide.
LPD hand-held radios are authorized for license-free voice communications use in most of Europe using analog frequency modulation (FM) as part of short range device regulations, with 25 kHz channel spacing, for a total of 69 channels. In some countries, LPD devices may only be used with an integral and non-removable antenna with a maximum legal power output of 10 mW.
Voice communication in LPD band was introduced to reduce the burden on the eight PMR446 channels over shorter ranges (less than 1 km) . In some EU countries voice is not allowed over LPD.
LPD is also used by wireless instruments and digital devices such as car keylocks.
Usage by country.
I.T.U. Region 1 (Europe)
U.K.
In the UK, LPD433 equipment that meets the respective Ofcom Interface Requirement can be used for model control, analogue/digitised voice and remote keyless entry systems. There is significant scope for interference however, both on frequency and on adjacent frequencies, as the band is far from free. The frequencies from 430 to 440 MHz are allocated on a secondary basis to licensed radio amateurs who are allowed to use up to 40 W (16 dBW) between 430 and 432 MHz and 400 W (26 dBW) between 432 and 440 MHz. Channels 1 to 14 are UK Amateur repeater outputs and channels 62 to 69 are UK Amateur repeater inputs. This band is shared on a secondary basis for both licensed and licence exempt users, with the primary user being the Ministry of Defence.
Ofcom, together with the R.S.G.B. Emerging Technology Co-ordination Committee have produced guidelines to help mitigate the side effects of interference to an extent.
Other European countries
European remote keyless entry systems often use the 433 MHz band, although, as in the UK, these frequencies are within the 70-centimeter band allocated to amateur radio, and interference results. Germany's radio control enthusiasts that hold "amateurfunk" ham radio licenses already have use of frequencies from channel 03 through 67 on the above chart for radio control of any form of model (air or ground-based), all with odd channel numbers (03, 05, etc. up to ch. 67) as read on the chart, with each sanctioned frequency having 50 kHz of bandwidth separation between each adjacent channel.
I.T.U. Region 2 (America)
In ITU region 2 (the Americas), the frequencies that LPD433 uses are also within the 70-centimeter band allocated to amateur radio. In the United States LPD433 radios can only be used under FCC amateur regulations by properly licensed amateur radio operators.

</doc>
<doc id="41341" url="https://en.wikipedia.org/wiki?curid=41341" title="Machine-readable medium">
Machine-readable medium

In telecommunications and computing a machine-readable medium (automated data medium) is a medium capable of storing data in a format readable by a mechanical device (rather than human readable).
Examples of machine-readable media include magnetic media such as magnetic disks, cards, tapes, and drums, punched cards and paper tapes, optical disks, barcodes and magnetic ink characters.
Common machine-readable technologies include magnetic recording, processing waveforms, and barcodes. Optical character recognition (OCR) can be used to enable machines to read information available to humans. Any information retrievable by any form of energy can be machine-readable. Examples include:

</doc>
<doc id="41342" url="https://en.wikipedia.org/wiki?curid=41342" title="Magneto-ionic double refraction">
Magneto-ionic double refraction

In telecommunication, magneto-ionic double refraction is the combined effect of the Earth's magnetic field and atmospheric ionization, whereby a linearly polarized wave entering the ionosphere is split into two components called the ordinary wave and extraordinary wave.
The component waves follow different paths, experience different attenuations, have different phase velocities, and, in general, are elliptically polarized in opposite senses.The critical frequency of the extraordinary wave is always greater than the critical frequency of the ordinary wave (i.e. the wave in absence of the magnetic field) by the amount approximately equal to .5 times of gyro frequency .The amplitude of extraordinary wave is dependent on the earth magnetic field at that particular point . Beside splitting, the polarization of the incident radio wave is also effected by this phenomena because the electron that were earlier in simple harmonic motion only are now in spiral motion too due to the magnetic field.

</doc>
<doc id="41343" url="https://en.wikipedia.org/wiki?curid=41343" title="Magneto-optic effect">
Magneto-optic effect

A magneto-optic effect is any one of a number of phenomena in which an electromagnetic wave propagates through a medium that has been altered by the presence of a quasistatic magnetic field. In such a material, which is also called gyrotropic or gyromagnetic, left- and right-rotating elliptical polarizations can propagate at different speeds, leading to a number of important phenomena. When light is transmitted through a layer of magneto-optic material, the result is called the Faraday effect: the plane of polarization can be rotated, forming a Faraday rotator. The results of reflection from a magneto-optic material are known as the magneto-optic Kerr effect (not to be confused with the nonlinear Kerr effect).
In general, magneto-optic effects break time reversal symmetry locally (i.e. when only the propagation of light, and not the source of the magnetic field, is considered) as well as Lorentz reciprocity, which is a necessary condition to construct devices such as optical isolators (through which light passes in one direction but not the other).
Two gyrotropic materials with reversed rotation directions of the two principal polarizations, corresponding to complex-conjugate ε tensors for lossless media, are called optical isomers.
Gyrotropic permittivity.
In particular, in a magneto-optic material the presence of a magnetic field (either externally applied or because the material itself is ferromagnetic) can cause a change in the permittivity tensor ε of the material. The ε becomes anisotropic, a 3×3 matrix, with complex off-diagonal components, depending of course on the frequency ω of incident light. If the absorption losses can be neglected, ε is a Hermitian matrix. The resulting principal axes become complex as well, corresponding to elliptically-polarized light where left- and right-rotating polarizations can travel at different speeds (analogous to birefringence).
More specifically, for the case where absorption losses can be neglected, the most general form of Hermitian ε is:
or equivalently the relationship between the displacement field D and the electric field E is:
where formula_3 is a real symmetric matrix and formula_4 is a real pseudovector called the gyration vector, whose magnitude is generally small compared to the eigenvalues of formula_3. The direction of g is called the axis of gyration of the material. To first order, g is proportional to the applied magnetic field:
where formula_7 is the magneto-optical susceptibility (a scalar in isotropic media, but more generally a tensor). If this susceptibility itself depends upon the electric field, one can obtain a nonlinear optical effect of magneto-optical parametric generation (somewhat analogous to a Pockels effect whose strength is controlled by the applied magnetic field).
The simplest case to analyze is the one in which g is a principal axis (eigenvector) of formula_3, and the other two eigenvalues of formula_3 are identical. Then, if we let g lie in the "z" direction for simplicity, the ε tensor simplifies to the form:
Most commonly, one considers light propagating in the "z" direction (parallel to g). In this case the solutions are elliptically polarized electromagnetic waves with phase velocities formula_11 (where μ is the magnetic permeability). This difference in phase velocities leads to the Faraday effect.
For light propagating purely perpendicular to the axis of gyration, the properties are known as the Cotton-Mouton effect and used for a Circulator.
Kerr Rotation and Kerr Ellipticity.
Kerr Rotation and Kerr Ellipticity are changes in the polarization of incident light which comes in contact with a gyromagnetic material. Kerr Rotation is a rotation in the angle of transmitted light, and Kerr Ellipticity is the ratio of the major to minor axis of the ellipse traced out by elliptically polarized light on the plane through which it propagates. Changes in the orientation of polarized incident light can be quantified using these two properties.
According to classical physics, the speed of light varies with the permittivity of a material:
formula_12
where formula_13 is the velocity of light through the material, formula_14 is the material permittivity, and formula_15 is the material permeability. Because the permittivity is anisotropic, polarized light of different orientations will travel at different speeds.
This can be better understood if we consider a wave of light that is circularly polarized (seen to the right). If this wave interacts with a material at which the horizontal component (green sinusoid) travels at a different speed than the vertical component (blue sinusoid), the two components will fall out of the 90 degree phase difference (required for circular polarization) changing the Kerr Ellipticity.
A change in Kerr Rotation is most easily recognized in linearly polarized light, which can be separated into two Circularly polarized components: Left-Handed Circular Polarized (LCP) light and Right-Handed Circular Polarized (RCP) light. The anisotropy of the Magneto Optic material permittivity causes a difference in the speed of LCP and RCP light, which will cause a change in the angle of polarized light. Materials that exhibit this property are known as Birefringent.
From this rotation, we can calculate the difference in orthogonal velocity components, find the anisotropic permittivity, find the gyration vector, and calculate the applied magnetic field formula_16.
Wavelength parallel measurement of magneto-optical effect.
Because the MO activity is usually very small, normally less than 1°,in conventional systems, the monochromator produces quasi-monochromatic light in a narrow wavelength window since the amplitude of modulation is wavelength dependent. Therefore, to measure the spectroscopic MO activity, a large number of measurements over the full spectra is required to obtain satisfactory wavelength resolution and thus is very time consuming. To obtain the spectroscopic information of the MO activity, light wavelength is varied by the monochromator. Therefore, these methods cost huge amount of time though provide high sensitivity to small MO activities. Fast spectroscopic characterization of the MO activity is thus desirable. Can we use white light source and perform wavelength-parallel measurement such as that in the state-of-art ellipsometry for the characterization of refractive index?
It is well established that when this linear polarized light passes through another polarizer, also called analyzer, the transmitted light intensity could be varied depending on their relative angle θ governed by a cos2("θ") law. Based on this simple idea, now researcher has developed a fast spectroscopic MO system, they can get full spectral range MO activity in a single magnetic field scan. The system requires only stable continuous spectral light source, two polarizers, an achromatic quarter-wave plate and a spectrometer.
It is low cost and flexible for application in full spectral range from UV to IR, or even in THz applications.This new system would booster the exploration to the MO characteristics of a large variety of materials in the full spectral range. The minimum resolvable angle depends on the full scale signal of light source and is limited by the instability and dark noise of the spectrometer. A minimum resolvable angle of 0.004° has been demonstrated in their configuration.

</doc>
<doc id="41344" url="https://en.wikipedia.org/wiki?curid=41344" title="Main distribution frame">
Main distribution frame

In telephony, a main distribution frame (MDF or main frame) is a signal distribution frame for connecting equipment (inside plant) to cables and subscriber carrier equipment (outside plant). The MDF is a termination point within the local telephone exchange where exchange equipment and terminations of local loops are connected by jumper wires at the MDF. All cable copper pairs supplying services through user telephone lines are terminated at the MDF and distributed through the MDF to equipment within the local exchange e.g. repeaters and DSLAM. Cables to intermediate distribution frames (IDF) terminate at the MDF. Trunk cables may terminate on the same MDF or on a separate trunk main distribution frame (TMDF).
Like other distribution frames the MDF provides flexibility in assigning facilities, at lower cost and higher capacity than a patch panel.
The most common kind of large MDF is a long steel rack accessible from both sides. On one side, termination blocks are arranged horizontally at the front of rack shelves. Jumpers lie on the shelves and go through an insulated steel hoop to run vertically to other termination blocks that are arranged vertically. There is a hoop or ring at the intersection of each level and each vertical. Installing a jumper historically required two workers, one on either side of the MDF. The shelves are shallow enough to allow the rings to be within arm's reach, but the workers prefer to hang the jumper on a hook on a pole so their partner can pull it through the ring. A fanning strip at the back of each termination block prevents the wires from covering each other's terminals. With disciplined administration the MDF can hold over a hundred thousand jumpers, with dozens changed every day, for decades without tangling.
Before 1960, MDF jumpers were generally soldered. This was reliable but slow and expensive. Wire wrap was introduced in the 1960s, and punch blocks in the 1970s.
Each jumper is a twisted pair. Middle 20th century jumper wires in the USA were 24 AWG single strand copper, with a soft polyethylene inner jacket and a cotton wrapper, impregnated to make it slightly brittle and easy to remove neatly. Late 20th century ones had a single, thicker coating of polyethylene cross-linked to provide a suitable degree of brittleness.
Some urban telephone exchange MDFs are two stories high so they don't have to be more than a city block long. A few are three stories. Access to the upper levels can be either by a travelling ladder attached to the MDF, or by mezzanine walkways at a suitable height. By British custom the cables to the outside world are terminated on the horizontal side, and the indoors equipment on the vertical side. American usage is the opposite.
Smaller MDFs, and some modern large ones, are single sided so one worker can install, remove or change a jumper. COSMOS and other computerized Operations Support Systems help by assigning terminals close to one another, so most jumpers need not be long and shelves on either type of MDF do not become congested. This database keeps track of all terminals and jumpers. In the early and middle 20th century these records were kept as pencil entries in ledger books. The later database method saves much labor by permitting old jumpers to be reused for new lines.
The adoption of distributed switching in the late 20th century diminished the need for large, active, central MDFs.
The MDF usually holds telephone exchange protective devices including heat coils, and functions as a test point between a line and the exchange equipment. 
Sometimes the MDF is combined with other kinds of distribution frame in a CDF.
The MDF in a private branch exchange performs functions similar to those performed by the MDF in a central office.
In order to automate the manual jumpering the Automated Main Distribution Frame (AMDF)
becomes an important role.

</doc>
<doc id="41345" url="https://en.wikipedia.org/wiki?curid=41345" title="Main lobe">
Main lobe

In a radio antenna's radiation pattern, the main lobe, or main beam is the lobe containing the maximum power. This is the lobe that exhibits the greatest field strength.
The radiation pattern of most antennas shows a pattern of ""lobes"" at various angles, directions where the radiated signal strength reaches a maximum, separated by ""nulls"", angles at which the radiation falls to zero. In a directional antenna in which the objective is to emit the radio waves in one direction, the lobe in that direction is designed to be bigger (have higher field strength) than the others; this is the main lobe. The other lobes are called ""sidelobes"", and usually represent unwanted radiation in undesired directions. The sidelobe in the opposite direction from the main lobe is called the ""backlobe"". 
The radiation pattern referred to above is usually the horizontal radiation pattern, which is plotted as a function of azimuth about the antenna, although the vertical radiation pattern may also have a main lobe. The beamwidth of the antenna is the width of the main lobe, usually specified by the "half power beam width", the angle encompassed between the points on the side of the lobe where the power has fallen to half (-3 dB) of its maximum value.
The concepts of main lobe and sidelobes also apply to acoustics and optics, and are used to describe the radiation pattern of optical systems like telescopes, and acoustic transducers like microphones and loudspeakers. 

</doc>
<doc id="41347" url="https://en.wikipedia.org/wiki?curid=41347" title="Maintainability">
Maintainability

In engineering, maintainability is the ease with which a product can be maintained in order to:
In some cases, maintainability involves a system of continuous improvement - learning from the past in order to improve the ability to maintain systems, or improve reliability of systems based on maintenance experience.
In telecommunication and several other engineering fields, the term maintainability has the following meanings:
Software engineering.
In software engineering, these activities are known as software maintenance (cf. ISO/IEC 9126).
The maintainability index is calculated with certain formulae from lines-of-code measures, McCabe measures and Halstead complexity measures.
The measurement and track maintainability are intended to help reduce or reverse a system's tendency toward "code entropy" or degraded integrity, and to indicate when it becomes cheaper and/or less risky to rewrite the code than it is to change it.

</doc>
<doc id="41348" url="https://en.wikipedia.org/wiki?curid=41348" title="Maintenance">
Maintenance

Maintenance may refer to:
Technical maintenance.
Technical maintenance is intended to maintain or improve the health of some asset. It forms an integral part of any Asset health management strategy.

</doc>
<doc id="41349" url="https://en.wikipedia.org/wiki?curid=41349" title="Managed object">
Managed object

In telecommunication, the term managed object has the following meanings: 
1. In a network, an abstract representation of network resources that are managed. With "representation", we mean not the actual device that is managed, but also the device driver, that communicates with the device. An example of a printer as a managed object is the window that shows information about the printer, such as the location, printer status, printing progress, paper choice, and printing margins. 
The database, where all managed objects are stored, is called Management Information Base. In contrast with a CI, a managed object is "dynamic" and communicates with other network recourses that are managed. 
"Note:" A managed object may represent a physical entity, a network service, or an abstraction of a resource that exists independently of its use in management.
2. In telecommunications management, a resource within the telecommunications environment that may be managed through the use of operation, administration, maintenance, and provisioning (OAMP) application protocols. 

</doc>
<doc id="41350" url="https://en.wikipedia.org/wiki?curid=41350" title="Manchester code">
Manchester code

In telecommunication and data storage, Manchester coding (also known as phase encoding, or PE) is a line code in which the encoding of each data bit is either low then high, or high then low, of equal time. It therefore has no DC component, and is self-clocking, which means that it may be inductively or capacitively coupled, and that a clock signal can be recovered from the encoded data. As a result, electrical connections using a Manchester code are easily galvanically isolated using a network isolator—a simple one-to-one isolation transformer.
Background.
The name comes from its development at the University of Manchester, where the coding was used to store data on the magnetic drum of the Manchester Mark 1 computer.
Manchester coding is widely used (e.g., in 10BASE-T Ethernet (IEEE 802.3); consumer IR protocols; see also RFID or near field communication). There are more complex codes, such as 8B/10B encoding, that use less bandwidth to achieve the same data rate but may be less tolerant of frequency errors and jitter in the transmitter and receiver reference clocks.
According to Cisco, "Manchester encoding introduces some difficult frequency-related problems that make it unsuitable for use at higher data rates."
Features.
Manchester code ensures frequent line voltage transitions, directly proportional to the clock rate; this helps clock recovery.
The DC component of the encoded signal is not dependent on the data and therefore carries no information, allowing the signal to be conveyed conveniently by media (e.g., Ethernet) which usually do not convey a DC component.
Description.
Extracting the original data from the received encoded bit (from Manchester as per 802.3):
Summary:
Manchester code always has a transition at the middle of each bit period and may (depending on the information to be transmitted) have a transition at the start of the period also. The direction of the mid-bit transition indicates the data. Transitions at the period boundaries do not carry information. They exist only to place the signal in the correct state to allow the mid-bit transition. The existence of guaranteed transitions allows the signal to be self-clocking, and also allows the receiver to align correctly; the receiver can identify if it is misaligned by half a bit period, as there will no longer always be a transition during each bit period. The price of these benefits is a doubling of the bandwidth requirement compared to simpler NRZ coding schemes (or see also NRZI).
Manchester encoding as phase-shift keying.
Manchester encoding is a special case of binary phase-shift keying (BPSK), where the data controls the phase of a square wave carrier whose frequency is the data rate. Such a signal is easy to generate.
Conventions for representation of data.
There are two opposing conventions for the representations of data.
The first of these was first published by G. E. Thomas in 1949 and is followed by numerous authors (e.g., Andy Tanenbaum). It specifies that for a 0 bit the signal levels will be low-high (assuming an amplitude physical encoding of the data) - with a low level in the first half of the bit period, and a high level in the second half. For a 1 bit the signal levels will be high-low.
The second convention is also followed by numerous authors (e.g., William Stallings ) as well as by IEEE 802.4 (token bus) and lower speed versions of IEEE 802.3 (Ethernet) standards. It states that a logic 0 is represented by a high-low signal sequence and a logic 1 is represented by a low-high signal sequence.
If a Manchester encoded signal is inverted in communication, it is transformed from one convention to the other. This ambiguity can be overcome by using differential Manchester encoding.

</doc>
<doc id="41351" url="https://en.wikipedia.org/wiki?curid=41351" title="Mandrel wrapping">
Mandrel wrapping

In multimode fiber optics, mandrel wrapping is a technique used to preferentially attenuate high-order mode power of a propagating optical signal. Consequently, if the fibre is propagating substantial energy in affected modes, the modal distribution will be changed.
A cylindrical rod wrap consists of a specified number turns of fiber on a mandrel of specified size, depending on the fibre characteristics and the desired modal distribution. It has application in optical transmission performance tests, to create a defined mode power distribution or to prevent multimode propagation in single mode fibre. If the launch fibre is fully filled ahead of the mandrel wrap, the higher-order modes will be stripped off, leaving only lower-order modes. If the launch fibre is underfilled, for example as a consequence of being energized by a laser diode or edge-emitting LED, there will be no effect on the mode power distribution or loss measurements.
In multimode fibre, mandrel wrapping is used to eliminate the effect of "transient loss", the tendency of high order modes to experience higher loss than lower order modes. Numerical addition (in decibels) of the measured loss of multiple fibre segments and/or components overestimates the loss of the concatenated set if each segment or component has been measured with a full mode power distribution.
In single mode optical fibre measurements, it is used to enforce true single mode propagation at wavelengths near or below the theoretical cutoff wavelength, at which substantial power can exist in a higher order mode group. In this use, it is commonly termed a High Order Mode Filter (HOMF).
Ultimately, the effect of mandrel wrapping on optical measurements depends on the propagating mode power distribution. An additional loss mechanism has no effect unless power is present in the affected modes. 
Principle of operation.
The effect of physically bending an optical fibre around a cylindrical form is to slightly modify the effective refractive index in the curved region, which locally reduces the effective mode volume of the fibre. This causes optical power in the highest order modes to become unguided, or so weakly guided as to be released into an unbound state, absorbed by the fiber coating or completely ejected from the fibre. The practical effect of mandrel wrapping is to attenuate optical power propagating in the highest order modes. Lower order modes are unaffected, experiencing neither increased loss nor conversion into other modes (mode mixing). 
Determination of appropriate mandrel wrap conditions.
The mandrel diameter and number of turns are chosen to eliminate certain modes in a reproducible way. It is empirically observed that more than 5 full 360 degree wraps creates little additional loss, so 3 to 5 turns are commonly specified. The mandrel diameter affects how far into the mode volume the modal unbinding occurs. Experimentally, one plots the transmitted power from a wrapped fibre into which a uniform modal power distribution has been excited, as a function of mandrel diameter, maintaining a constant number of turns. This reveals step-like reductions in transmitted power as the diameter decreases, where each step is the point at which the mandrel is beginning to affect the next-lower mode group. For best measurement reproducibility, one would select a diameter that is not near such a transition, although this may not be possible if measurements must be performed over a range of wavelengths. Total mode volume in a fiber is a function of wavelength, so the mandrel diameter at which the mode group transitions occur will change with wavelength.

</doc>
<doc id="41352" url="https://en.wikipedia.org/wiki?curid=41352" title="Margin">
Margin

Margin may refer to:

</doc>
<doc id="41353" url="https://en.wikipedia.org/wiki?curid=41353" title="Maritime broadcast communications net">
Maritime broadcast communications net

In telecommunication, a maritime broadcast communications net is a communications net that is used for international distress calling, including international lifeboat, lifecraft, and survival-craft high frequency (HF); aeronautical emergency very high frequency (VHF); survival ultra high frequency (UHF); international calling and safety very high frequency (VHF); combined scene-of-search-and-rescue; and other similar and related purposes. 
"Note:" Basic international distress calling is performed at either medium frequency (MF) or at high frequency (HF).

</doc>
<doc id="41354" url="https://en.wikipedia.org/wiki?curid=41354" title="Master frequency generator">
Master frequency generator

A master frequency generator or master electronic oscillator, in frequency-division multiplexing (FDM), is a piece of equipment used to provide system end-to-end carrier frequency synchronization and frequency accuracy of tones. 
The following types of oscillators are used in the Defense Communications System FDM systems:

</doc>
<doc id="41355" url="https://en.wikipedia.org/wiki?curid=41355" title="Master station">
Master station

In telecommunication, a master station is a station that controls or coordinates the activities of other stations in the system.
Examples:
Operation modes.
In data transmission, a master station can be set to not wait for a reply from a slave station after transmitting each message or transmission block. In this case the station is said to be in "continuous operation".

</doc>
<doc id="41357" url="https://en.wikipedia.org/wiki?curid=41357" title="Material scattering">
Material scattering

Material scattering of an electromagnetic wave is scattering that is attributable to the intrinsic properties of the material through which the wave is propagating. Ionospheric scattering and Rayleigh scattering are examples of material scattering. In an optical fiber, material scattering is caused by micro-inhomogeneities in the refractive indices of the materials used to fabricate the fiber, including the dopants used to modify the refractive index profile.

</doc>
<doc id="41358" url="https://en.wikipedia.org/wiki?curid=41358" title="Maximal-ratio combining">
Maximal-ratio combining

In telecommunications, maximum-ratio combining (MRC) is a method of diversity combining in which:
It is also known as ratio-squared combining and predetection combining. Maximum-ratio combining is the optimum combiner for independent AWGN channels.
MRC can restore a signal to its original shape.
Example: Least Squares estimate in the case of Rx diversity.
We consider an example of which the receiver is endowed with N antennas. In this case, the received vector formula_1 is
where formula_2 is noise vector formula_3. Following the ML detection criterion the detection procedure may be written as
where formula_4 is the least square solution to the above model.
The least square solution in this case is also known as maximum-ratio-combining (MRC). In the case of N antennas the LS can be written as
which means that the signal from each antenna is rotated and weighted according to the phase and strength of the channel, such that the signals from all antennas are combined to yield the maximum ratio between signal and noise terms.
See also.
Diversity combining

</doc>
<doc id="41359" url="https://en.wikipedia.org/wiki?curid=41359" title="Maximum usable frequency">
Maximum usable frequency

In radio transmission maximum usable frequency (MUF) is the highest radio frequency that can be used for transmission between two points via reflection from the ionosphere (skywave or "skip" propagation) at a specified time, independent of transmitter power. This index is especially useful in regard to shortwave transmissions. 
In shortwave radio communication, a major mode of long distance propagation is for the radio waves to reflect off the ionized layers of the atmosphere and return diagonally back to Earth. In this way radio waves can travel beyond the horizon, around the curve of the Earth. However the refractive index of the ionosphere decreases with increasing frequency, so there is an upper limit to the frequency which can be used. Above this frequency the radio waves are not reflected by the ionosphere but are transmitted through it into space. 
The ionization of the atmosphere varies with time of day and season as well as with solar conditions, so the upper frequency limit for skywave communication varies on an hourly basis. MUF is a median frequency, defined as the highest frequency at which skywave communication is possible 50% of the days in a month, as opposed to the lowest usable high frequency (LUF) which is the frequency at which communication is possible 90% of the days, and the Frequency of optimum transmission (FOT).
Typically the MUF is a predicted number. Given the maximum observed frequency (MOF) for a mode on each day of the month at a given hour, the MUF is the highest frequency for which an ionospheric communications path is predicted on 50% of the days of the month. 
On a given day, communications may or may not succeed at the MUF. Commonly, the optimal operating frequency for a given path is estimated at 80 to 90% of the MUF. As a rule of thumb the MUF is approximately 3 times the critical frequency.
formula_1
where the critical frequency is the highest frequency reflected for a signal propagating directly upward.

</doc>
<doc id="41363" url="https://en.wikipedia.org/wiki?curid=41363" title="Mean time between outages">
Mean time between outages

In a system the mean time between outages (MTBO) is the mean time between equipment failures that result in loss of system continuity or unacceptable degradation. 
The MTBO is calculated by the equation,
formula_1
where MTBF is the nonredundant mean time between failures and FFAS is the fraction of failures for which the failed equipment is automatically bypassed. 

</doc>
<doc id="41364" url="https://en.wikipedia.org/wiki?curid=41364" title="Mechanically induced modulation">
Mechanically induced modulation

Mechanically induced modulation is an optical signal modulation induced by mechanical means. 
An example of deleterious mechanically induced modulation is speckle noise created in a multimode fiber by an imperfect splice or imperfectly mated connectors. Mechanical disturbance of the fiber ahead of the joint will introduce changes in the modal structure, resulting in variations of joint loss. This is a subset of many mechanisms that can lead to modal noise in an optical system.

</doc>
<doc id="41365" url="https://en.wikipedia.org/wiki?curid=41365" title="Mediation function">
Mediation function

In telecommunications network management, a mediation function is a function that routes or acts on information passing between network elements and network operations. 
Examples of mediation functions are communications control, protocol conversion, data handling, communications of primitives, processing that includes decision-making, and data storage. 
Mediation functions can be shared among network elements, mediation devices, and network operation centers.

</doc>
<doc id="41366" url="https://en.wikipedia.org/wiki?curid=41366" title="Medium-power talker">
Medium-power talker

In telecommunication, a medium-power talker is a hypothetical talker, within a log-normal distribution of talkers, whose volume lies at the medium power of all talkers determining the volume distribution at the point of interest. 
When the distribution follows a log-normal curve (values expressed in decibels), the mean and standard deviation can be used to compute the medium-power talker. The talker volume distribution follows a log-normal curve and the medium-power talker is uniquely determined by the average talker volume. The medium-power talker volume, "V", is given by "V" = "V" o + 0.115σ2, where "V" o is the average of the talker volume distribution in volume units (vu), and σ2 is the variance of the distribution.

</doc>
<doc id="41367" url="https://en.wikipedia.org/wiki?curid=41367" title="Message">
Message

A message is a discrete unit of communication intended by the source for consumption by some recipient or group of recipients. A message may be delivered by various means, including courier, telegraphy, carrier pigeon and electronic bus.
A message can be the content of a broadcast. An interactive
exchange of messages forms a conversation.
One example of a message is a communiqué (pronounced ), which is a brief report or statement released by a public agency.
Role in human communication.
In communication between humans, messages can be verbal or nonverbal:
In computer science.
There are two main senses of the word "message" in computing: messages between the human users of computer systems that are delivered by those computer systems, and messages passed between programs or between components of a single program, for their own purposes.

</doc>
<doc id="41368" url="https://en.wikipedia.org/wiki?curid=41368" title="Message format">
Message format

In telecommunication, a message format is a predetermined or prescribed spatial or time-sequential arrangement of the parts of a message that is recorded in or on a data storage medium. 
At one time, messages prepared for electrical transmission were composed on a printed blank form with spaces for each part of the message and for administrative entries.

</doc>
<doc id="41369" url="https://en.wikipedia.org/wiki?curid=41369" title="Micro-mainframe link">
Micro-mainframe link

In telecommunication, a micro-mainframe link is a physical or logical connection established between a remote microprocessor and mainframe host computer for the express purpose of uploading, downloading, or viewing interactive data and databases on-line in real time. 
"Note:" A micro-mainframe link usually requires terminal emulation software on the microcomputer.

</doc>
<doc id="41371" url="https://en.wikipedia.org/wiki?curid=41371" title="Mixer">
Mixer

Mixer may refer to:

</doc>
<doc id="41372" url="https://en.wikipedia.org/wiki?curid=41372" title="Sprague–Grundy theorem">
Sprague–Grundy theorem

In combinatorial game theory, the Sprague–Grundy theorem states that every impartial game under the normal play convention is equivalent to a nimber. The Grundy value or nim-value of an impartial game is then defined as the unique nimber that the game is equivalent to. In the case of a game whose positions (or summands of positions) are indexed by the natural numbers (for example the possible heap sizes in nim-like games), the sequence of nimbers for successive heap sizes is called the nim-sequence of the game.
The theorem and its proof encapsulate the main results of a theory discovered independently by R. P. Sprague (1935) and P. M. Grundy (1939).]
Definitions.
For the purposes of the Sprague–Grundy theorem, a "game" is a two-player game of perfect information satisfying the "ending condition" (all games come to an end: there are no infinite lines of play) and the "normal play condition" (a player who cannot move loses).
An "impartial game" is one such as nim, in which each player has exactly the same available moves as the other player in any position. Note that games such as tic-tac-toe, checkers, and chess are "not" impartial games. In the case of checkers and chess, for example, players can only move their own pieces, not their opponent's pieces. And in tic-tac-toe, one player puts down X's, while the other puts down O's. Positions in impartial games fall into two "outcome classes": either the next player (the one whose turn it is) wins (an "N-position") or the previous player wins (a "P-position").
In this proof, a position is identified with the set of positions that can be reached in one move (these positions are called "options"). For example, the position formula_1 is a P-position under normal play, because the current player has no moves and therefore loses. The position formula_2, in contrast, is an N-position; the current player has only one option, and that option is a losing position for their opponent.
A "nimber" is a special position denoted formula_3 for some ordinal formula_4. formula_5 is formula_1, the P-position given as an example earlier. The other nimbers are defined inductively by formula_7; in particular, formula_8 (the example N-position from above), formula_9 (a choice between the two example positions), etc. formula_3 therefore corresponds to a heap of formula_4 counters in the game of nim, hence the name.
Two positions formula_12 and formula_13 can be "added" to make a new position formula_14 in a combined game where the current player can choose either to move in formula_12 or in formula_13. Explicit computation of the set formula_14 is by repeated application of the rule formula_18, which incidentally indicates that position addition is both commutative and associative as expected.
Two positions formula_12 and formula_20 are defined to be "equivalent" if for every position formula_13, the position formula_14 is in the same outcome class as formula_23. Such an equivalence is written formula_24.
First Lemma.
As an intermediate step to proving the main theorem, we show that, for every position formula_12 and every P-position formula_26, the equivalence formula_27 holds. By the above definition of equivalence, this amounts to showing that formula_14 and formula_29 share an outcome class for all formula_13.
Suppose that formula_14 is a P-position. Then the previous player has a winning strategy for formula_29: respond to moves in formula_26 according to their winning strategy for formula_26 (which exists by virtue of formula_26 being a P-position), and respond to moves in formula_14 according to their winning strategy for formula_14 (which exists for analogous reason). So formula_29 must also be a P-position.
On the other hand, if formula_14 is an N-position, then the next player has a winning strategy: choose a P-position from among the formula_14 options, putting their opponent in the case above. Thus, in this case, formula_29 must be a N-position, just like formula_14.
As these are the only two cases, the lemma holds.
Second Lemma.
As a further step, we show that formula_24 if and only if formula_44 is a P-position.
In the forward direction, suppose that formula_24. Applying the definition of equivalence with formula_46, we find that formula_47 (which is equal to formula_44 by commutativity of addition) is in the same outcome class as formula_49. But formula_49 must be a P-position: for every move made in one copy of formula_12, the previous player can respond with the same move in the other copy, and so always make the last move.
In the reverse direction, since formula_52 is a P-position by hypothesis, it follows from the first lemma, formula_53, that formula_54. Similarly, since formula_55 is also a P-position, it follows from the first lemma in the form formula_56 that formula_57. By associativity and commutativity, the right-hand sides of these results are equal. Furthermore, formula_58 is an equivalence relation because equality is an equivalence relation on outcome classes. Via the transitivity of formula_58, we can conclude that formula_24.
Proof.
We prove that all positions are equivalent to a nimber by structural induction. The more specific result, that the given game's initial position must be equivalent to a nimber, shows that the game is itself equivalent to a nimber.
Consider a position formula_61. By the induction hypothesis, all of the options are equivalent to nimbers, say formula_62. So let formula_63. We will show that formula_64, where formula_65 is the mex (minimum exclusion) of the numbers formula_66, that is, the smallest non-negative integer not equal to some formula_67.
The first thing we need to note is that formula_68, by way of the second lemma. If formula_69 is zero, the claim is trivially true. Otherwise, consider formula_44. If the next player makes a move to formula_71 in formula_12, then the previous player can move to formula_73 in formula_20, and conversely if the next player makes a move in formula_20. After this, the position is a P-position by the lemma's forward implication. Therefore, formula_44 is a P-position, and, citing the lemma's reverse implication, formula_68.
Now let us show that formula_78 is a P-position, which, using the second lemma once again, means that formula_79. We do so by giving an explicit strategy for the previous player.
Suppose that formula_20 and formula_81 are empty. Then formula_78 is the null set, clearly a P-position.
Or consider the case that the next player moves in the component formula_81 to the option formula_84 where formula_85. Because formula_65 was the "minimum" excluded number, the previous player can move in formula_20 to formula_84. And, as shown before, any position plus itself is a P-position.
Finally, suppose instead that the next player moves in the component formula_20 to the option formula_73. If formula_91 then the previous player moves in formula_81 to formula_73; otherwise, if formula_94, the previous player moves in formula_73 to formula_81; in either case the result is a position plus itself. (It is not possible that formula_97 because formula_65 was defined to be different from all the formula_67.)
In summary, we have formula_24 and formula_79. By transitivity, we conclude that formula_64, as desired.
Development.
If formula_12 is a position of an impartial game, the unique integer formula_65 such that formula_64 is called its Grundy value, or Grundy number, and the function which assigns this value to each such position is called the Sprague–Grundy function. R.L.Sprague and P.M.Grundy independently gave an explicit definition of this function, not based on any concept of equivalence to nim positions, and showed that it had the following properties:
It follows straightforwardly from these results that if a position formula_12 has a Grundy value of formula_65, then formula_111 has the same Grundy value as formula_112, and therefore belongs to the same outcome class, for any position formula_13. Thus, although Sprague and Grundy never explicitly stated the theorem described in this article, it is nevertheless an almost trivial consequence of their results.
These results have subsequently been developed into the field of combinatorial game theory, notably by Richard Guy, Elwyn Berlekamp, John Horton Conway and others, where they are now encapsulated in the Sprague–Grundy theorem and its proof in the form described here. The field is presented in the books "Winning Ways for your Mathematical Plays" and "On Numbers and Games".

</doc>
<doc id="41373" url="https://en.wikipedia.org/wiki?curid=41373" title="Mode field diameter">
Mode field diameter

In fiber optics, the mode field diameter (MFD) is an expression of distribution of the irradiance, i.e., the optical power per unit area, across the end face of a single-mode fiber. 
For a Gaussian intensity (i.e., power density, W/m2) distribution in a single-mode optical fiber, the mode field diameter is that at which the electric and magnetic field strengths are reduced to 1/e of their maximum values, i.e., the diameter at which power density is reduced to 1/e2 of the maximum power density, because the power density is proportional to the square of the field strength.
See also.
Beam diameter

</doc>
<doc id="41374" url="https://en.wikipedia.org/wiki?curid=41374" title="Mode partition noise">
Mode partition noise

Mode partition noise: In an optical communication link, is phase jitter of the signal caused by the combined effects of mode hopping in the optical source and intramodal distortion in the fiber. 
Mode hopping causes random wavelength changes which in turn affect the group velocity, "i.e.", the propagation time. Over a long length of fiber, the cumulative effect is to create jitter, "i.e." mode partition noise. The variation of group velocity creates the mode partition noise.

</doc>
<doc id="41375" url="https://en.wikipedia.org/wiki?curid=41375" title="Mode scrambler">
Mode scrambler

In telecommunications, a mode scrambler mode mixer is a device for inducing mode coupling in an optical fiber, or a device that, itself, exhibits a uniform output intensity profile independent of the input mode volume or modal excitation condition. Mode scramblers are used to provide a modal distribution that is independent of the optical source for purposes of laboratory, manufacturing, or field measurements or tests. Mode scramblers are primarily used to improve reproducibility of multimode fiber bandwidth measurements.
If multimode fiber bandwidth is measured using a laser diode directly coupled to its input, the resulting measurement can vary by as much as an order of magnitude. This measurement variability is due to the combination of differences in laser output characteristics (emitted mode power distribution) and the differential mode delay of the fiber. Differential mode delay is the difference in the time delays amongst the fiber's propagating modes caused by imperfections or nonideality of the fiber refractive index profile.
The primary purpose of a mode scrambler is to create a uniform, overfilled launch condition that can be easily reproduced on multiple measurement systems, so that measurement systems have essentially the same launch conditions and can measure approximately the same bandwidth despite having different laser sources. These were used for this purpose in the first U.S. NIST round-robins on multimode fiber. The overfilled launch (OFL) was created to reduce measurement variability, and improve concatenation estimates for multimode fibers, used at that time for telecom 'long haul' (e.g., 7–10 km 850 nm or 20–30 km 1300 nm) systems.
When the telecom industry converted to near-exclusive use of single-mode fiber ca. 1984, multimode fiber was re-purposed for use in LANs, such as Fiber Distributed Date Interface (FDDI), then under development. The output modal power distribution of a mode scrambler is similar to the surface-emitters used in those first LAN transmitters, but this was fortuitous coincidence. On average, but not in every case, the OFL bandwidth measured using a mode scrambler is lower than that produced by excitation of a partial mode volume (restricted mode launch or RML), such as occurs with directly coupled laser diodes.
There are two common types of mode scramblers: the "Step-Graded-Step" (S-G-S) and the "step index with bends". The S-G-S mode scrambler is actually an assembly, a fusion-spliced concatenation of a step-index profile, a graded-index profile and another step-index profile fiber. Typically, each segment is approximately 1 meter long, and may use segments of unconventional size to produce the distribution required according to core size of fiber to be tested. Unconventional fiber size was not an issue, as they were developed by fiber manufacturers, but some test equipment has difficulty complying with revised qualification standards, and now use "Step Index with Bends" mode scramblers, which can be adjusted to purpose. Step Index with Bend mode scramblers are created simply by routing a specially designed step-index multimode fiber through a series of small radius bends, or by compressing fiber against surfaces with specific roughness. The implementations are simple, but generally less reproducible, and require care to avoid over-stressing the fiber.
A mode scrambler can be characterized and qualified by measuring its near-field and far-field distributions, as well as by measuring one of these distributions while restricting the other. Guidelines for constructing a mode scrambler and qualifying its output can be found in the ANSI/TIA/EIA-455-54 fiber optic test procedure (FOTP).

</doc>
<doc id="41376" url="https://en.wikipedia.org/wiki?curid=41376" title="Mode volume">
Mode volume

In fiber optics, mode volume is the number of bound modes that an optical fiber is capable of supporting. 
The mode volume "M" is approximately given by formula_1 and formula_2, respectively for step-index and power-law index profile fibers, where "g" is the profile parameter, and "V" is the normalized frequency, "which must be greater than 5 for this approximation to be valid".

</doc>
<doc id="41377" url="https://en.wikipedia.org/wiki?curid=41377" title="Modification of Final Judgment">
Modification of Final Judgment

In United States telecommunication law, Modification of Final Judgment (MFJ) is the August 1982 agreement approved by the court (consent decree) settling "United States v. AT&T", a landmark antitrust suit, originally filed on January 14, 1949 and modifying the previous Final Judgment of January 24, 1956. Entered into between the United States Department of Justice and the American Telephone & Telegraph Company (AT&T), the MFJ, after modification and upon approval of the United States District Court for the District of Columbia, required the Bell System divestiture of the Bell Operating Companies from AT&T. Judge Greene was the presiding judge for the case.
The exact term for the MFJ is given under the general definition of local access and transport area, a term used in U.S. telecommunications regulation for geographic areas in which local telephone companies are allowed to provide service, the term being used is "the Modification of Final Judgment (MFJ) entered by the United States District Court for the District of Columbia in Civil Action number 82-0192 or any other geographic area designated as a Local access and transport area (LATA) in the National Exchange Carrier Association, Inc. Tariff FCC No. 4."

</doc>
<doc id="41378" url="https://en.wikipedia.org/wiki?curid=41378" title="Modified AMI code">
Modified AMI code

Modified AMI codes are Alternate Mark Inversion (AMI) line codes in which bipolar violations may be deliberately inserted to maintain system synchronization. There are several types of modified AMI codes, used in various T-carrier and E-carrier systems.
Overview.
The clock rate of an incoming T-carrier is extracted from its bipolar line code. Each signal transition provides an opportunity for the receiver to see the transmitter's clock. The AMI code guarantees that transitions are always present before and after each mark (1 bit), but are missing between adjacent spaces (0 bits). To prevent loss of synchronization when a long string of zeros is present in the payload, deliberate bipolar violations are inserted into the line code, to create a sufficient number of transitions to maintain synchronization; this is a form of run length limited coding. The receive terminal equipment recognizes the bipolar violations and removes from the user data the marks attributable to the bipolar violations.
T-carrier was originally developed for voice applications. When voice signals are digitized for transmission via T-carrier, the data stream always includes ample 1 bits to maintain synchronization. (To help this, the μ-law algorithm for digitizing voice signals encodes silence as a continuous stream of 1 bits.) However, when used for the transmission of digital data, the conventional AMI line code may fail to have sufficient marks to permit recovery of the incoming clock, and synchronization is lost. This happens when there are too many consecutive zeros in the user data being transported. 
The exact pattern of bipolar violations that is transmitted in any given case depends on the line rate ("i.e.", the level of the line code in the T-carrier hierarchy) and the polarity of the last valid mark in the user data prior to the unacceptably long string of zeros. It would not be useful to have a violation immediately following a mark, as that would not produce a transition. For this reason, all modified AMI codes include a space (0 bit) before each violation mark.
In the descriptions below, "B" denotes a balancing mark with the opposite polarity to that of the preceding mark, while "V" denotes a bipolar violation mark, which has the same polarity as the preceding mark.
In order to preserve AMI coding's desirable absence of DC bias, the number of positive marks must equal the number of negative marks. This happens automatically for balancing (B) marks, but the line code must ensure that positive and negative violation marks balance each other.
Zero length code suppression (Road Construction).
The first technique used to ensure a minimum density of marks was zero code suppression a form of bit stuffing, which set the least significant bit of each 8-bit byte transmitted to a 1. (This bit was already unavailable due to robbed-bit signaling.) This avoided the need to modify the AMI code in any way, but limited available data rates to 56,000 bits per second per DS0 voice channel. Also, the low minimum density of ones (12.5%) sometimes led to increased clock slippage on the span.
Increased demand for bandwidth, and compatibility with the G.703 and ISDN PRI standards which called for 64,000 bits per second, led to this system being superseded by B8ZS.
B8ZS (North American T1).
Commonly used in the North American T1 (Digital Signal 1) 1.544 Mbit/s line code, bipolar with eight-zero substitution (B8ZS) replaces each string of 8 consecutive zeros with the special pattern "000VB0VB". Depending on the polarity of the preceding mark, that could be 000+−0−+ OR 000−+0+−.
B6ZS (North American T2).
At the North American T2 rate (6.312 Mbit/s), bipolar violations are inserted if 6 or more consecutive zeros occur. This line code is called bipolar with six-zero substitution (B6ZS), and replaces 6 consecutive zeros with the pattern "0VB0VB". Depending on the polarity of the preceding mark, that could be 0+−0−+ OR 0−+0+−.
HDB3 (European E-carrier).
Used in all levels of the European E-carrier system, the high density bipolar of order 3 (HDB3) code replaces any instance of 4 consecutive 0 bits with one of the patterns "000V" or "B00V". The choice is made to ensure that consecutive violations are of differing polarity; i.e., separated by an odd number of normal + or − marks.
These rules are applied on the code as it is being built from the original string. Every time there are 4 consecutive zeros in the code they will be replaced by either 000−, 000+, +00+ or −00−. To determine which pattern to use, one must count the number of pluses (+) and the number of minuses (−) since the last violation bit V, then subtract one from the other. If the result is an odd number then 000− or 000+ is used. If the result is an even number then +00+ or −00− is used. To determine which polarity to use, one must look at the pulse preceding the four zeros. If 000V form must be used then V simply copies the polarity of last pulse, if B00V form must be used then B and V chosen will have the opposite polarity of the last pulse.
Summary of HDB3 encoding rules
Examples.
The pattern of bits 10000110 encoded in HDB3 is +000V−+0 (the corresponding encoding using AMI is +0000−+0.
The pattern of bits 1010000011000011000000 encoded in HDB3 is +0−B00V0+−B00V+−B00V00 which is: +0−+00+0+−+00++−+00+00 (the corresponding encoding using AMI is +0−00000+−0000+−000000)
The pattern of bits 1010000100001100001110000111100001010000 encoded in HDB3 is +0−B00V−000V+−B00V−+−000V+−+−B00V−0+B00V which is: 
+0−+00+−000−+−+00+−+−000−+−+−+00+−0+−00− (the corresponding encoding using AMI is +0−0000+0000−+0000−+−0000+−+−0000+0−0000)
B3ZS (North American T3).
At the North American T3 rate (44.736 Mbit/s), bipolar violations are inserted if 3 or more consecutive zeros occur. This line code is called bipolar with three-zero substitution (B3ZS), and is very similar to HDB3. Each run of 3 consecutive zeros is replaced by "00V" or "B0V". The choice is made to ensure that consecutive violations are of differing polarity, i.e. separated by an odd number of normal B marks.
See also.
Other line codes that have 3 states:

</doc>
<doc id="41382" url="https://en.wikipedia.org/wiki?curid=41382" title="Μ-law algorithm">
Μ-law algorithm

The µ-law algorithm (sometimes written "mu-law", often approximated as "u-law") is a companding algorithm, primarily used in 8-bit PCM digital telecommunication systems in North America and Japan. It is one of two versions of the G.711 standard from ITU-T, the other version being the similar A-law, used in regions where digital telecommunication signals are carried on E-1 circuits, e.g. Europe.
Companding algorithms reduce the dynamic range of an audio signal. In analog systems, this can increase the signal-to-noise ratio (SNR) achieved during transmission; in the digital domain, it can reduce the quantization error (hence increasing signal to quantization noise ratio). These SNR increases can be traded instead for reduced bandwidth for equivalent SNR.
Algorithm types.
There are two forms of this algorithm—an analog version, and a quantized digital version.
Continuous.
For a given input , the equation for μ-law encoding is
where (8 bits) in the North American and Japanese standards. It is important to note that the range of this function is −1 to 1.
μ-law expansion is then given by the inverse equation:
The equations are culled from Cisco's Waveform Coding Techniques.
Discrete.
This is defined in ITU-T Recommendation G.711.
G.711 is unclear about how to code the values at the limit of a range (e.g. whether +31 codes to 0xEF or 0xF0).
However, G.191 provides example C code for a μ-law encoder which gives the following encoding. Note the difference between the positive and negative ranges, e.g. the negative range corresponding to +30 to +1 is −31 to −2. This is accounted for by the use of 1's complement (simple bit inversion) rather than 2's complement to convert a negative value to a positive value during encoding.
Implementation.
There are three ways of implementing a μ-law algorithm:
Usage justification.
This encoding is used because speech has a wide dynamic range. In the analog world, when mixed with a relatively constant background noise source, the finer detail is lost. Given that the precision of the detail is compromised anyway, and assuming that the signal is to be perceived as audio by a human, one can take advantage of the fact that the perceived acoustic intensity level or loudness is logarithmic by compressing the signal using a logarithmic-response operational amplifier (Weber-Fechner law). In telecommunications circuits, most of the noise is injected on the lines, thus after the compressor, the intended signal is perceived as significantly louder than the static, compared to an un-compressed source. This became a common solution, and thus, prior to common digital usage, the μ-law specification was developed to define an inter-compatible standard.
In digital systems this pre-existing algorithm had the effect of significantly reducing the number of bits needed to encode recognizable human voice. Using μ-law, a sample could be effectively encoded in as few as 8 bits, a sample size that conveniently matched the symbol size of most standard computers.
μ-law encoding effectively reduced the dynamic range of the signal, thereby increasing the coding efficiency while biasing the signal in a way that results in a signal-to-distortion ratio that is greater than that obtained by linear encoding for a given number of bits. This is an early form of perceptual audio encoding.
The μ-law algorithm is also used in the .au format, which dates back at least to the SPARCstation 1 by Sun Microsystems as the native method used by the /dev/audio interface, widely used as a de facto standard for sound on Unix systems. The au format is also used in various common audio APIs such as the classes in the sun.audio Java package in Java 1.1 and in some C# methods.
This plot illustrates how μ-law concentrates sampling in the smaller (softer) values. The abscissa represents the byte values 0-255 and the vertical axis is the 16-bit linear decoded value of μ-law encoding.
Comparison with A-law.
The µ-law algorithm provides a slightly larger dynamic range than the A-law at the cost of worse proportional distortion for small signals. By convention, A-law is used for an international connection if at least one country uses it.

</doc>
<doc id="41383" url="https://en.wikipedia.org/wiki?curid=41383" title="Multicast address">
Multicast address

A multicast address is a logical identifier for a group of hosts in a computer network, that are available to process datagrams or frames intended to be multicast for a designated network service. Multicast addressing can be used in the Link Layer (Layer 2 in the OSI model), such as Ethernet multicast, and at the Internet Layer (Layer 3 for OSI) for Internet Protocol Version 4 (IPv4) or Version 6 (IPv6) multicast.
IPv4.
IPv4 multicast addresses are defined by the leading address bits of "1110", originating from the classful network design of the early Internet when this group of addresses was designated as "Class D". The Classless Inter-Domain Routing (CIDR) prefix of this group is codice_1. The group includes the addresses from 224.0.0.0 to 239.255.255.255. Address assignments from within this range are specified in RFC 5771, an Internet Engineering Task Force (IETF) "Best Current Practice" document (BCP 51).
The following table is a list of notable well-known IPv4 addresses that are reserved for IP multicasting and that are registered with the Internet Assigned Numbers Authority (IANA).
Local subnetwork.
Addresses in the range of 224.0.0.0 to 224.0.0.255 are individually assigned by IANA and designated for multicasting on the local subnetwork only. For example, the Routing Information Protocol (RIPv2) uses 224.0.0.9, Open Shortest Path First (OSPF) uses 224.0.0.5 and 224.0.0.6, and Zeroconf mDNS uses 224.0.0.251. Routers must not forward these messages outside the subnet in which they originate.
Internetwork control block.
Addresses in the range 224.0.1.0 to 224.0.1.255 are individually assigned by IANA and designated the Internetwork Control Block. This block of addresses is used for traffic that must be routed through the public Internet, such as for applications of the Network Time Protocol (224.0.1.1).
AD-HOC block.
Addresses in the following ranges are individually assigned by IANA and designated the AD-HOC block:
codice_2 to codice_3<br>
codice_4 to codice_5<br>
codice_6 to codice_7<br>
These addresses are globally routed and are used for applications that don't fit either of the previously described purposes.
Source-specific multicast.
The 232.0.0.0/8 (IPv4) and FF3x::/32 (IPv6) block is reserved for use by source-specific multicast.
GLOP addressing.
The 233.0.0.0/8 range was originally assigned by RFC 2770 as an experimental, public statically assigned multicast address space for publishers and Internet service providers that wished to source content on the Internet. The allocation method is termed GLOP addressing and provides implementers a block of 255 addresses that is determined by their 16-bit autonomous system number (ASN) allocation. In a nutshell, the middle two octets of this block are formed from assigned ASNs, giving any operator assigned an ASN 256 globally unique multicast group addresses. The method is not applicable to the newer 32-bit extension AS numbers. RFC 3180, superseding RFC 2770, envisioned the use of the range for many-to-many multicast applications. This block has been one of the most successful multicast addressing schemes. Unfortunately, with only 256 multicast addresses available to each autonomous system, GLOP is not adequate for large-scale broadcasters.
Unicast-Prefix-Based IPv4 Multicast addresses.
The 234.0.0.0/8 range is assigned by RFC 6034 as a range of global IPv4 multicast address space provided to each organization that has /24 or larger globally routed unicast address space allocated; one multicast address is reserved per /24 of unicast space. A resulting advantage over GLOP is that the mechanisms in IPv4 and IPv6 become more similar.
Administratively Scoped IPv4 Multicast addresses.
The 239.0.0.0/8 range is assigned by RFC 2365 for private use within an organization. From the RFC, packets destined to administratively scoped IPv4 multicast addresses do not cross administratively defined organizational boundaries, and administratively scoped IPv4 multicast addresses are locally assigned and do not have to be globally unique. The RFC also discusses structuring the 239.0.0.0/8 range to be loosely similar to the scoped IPv6 multicast address range described in RFC 1884.
IPv6.
Multicast addresses in IPv6 have the prefix ff00::/8. IPv6 multicast addresses are generally formed from four bit groups, illustrated as follows:
The "prefix" holds the binary value 11111111 for any multicast address.
Currently, 3 of the 4 flag bits in the "flags" field are defined; the most-significant flag bit is reserved for future use. The other three flags are known as "R", "P" and "T".
Similar to unicast addresses, the prefix of IPv6 multicast addresses specifies their scope, however, the set of possible scopes is different. The 4-bit "sc" (or scope) field (bits 12 to 15) is used to indicate where the address is valid and unique.
The service is identified in the 112-bit "Group ID" field. For example, if ff02::101 refers to all Network Time Protocol (NTP) servers on the local network segment, then ff08::101 refers to all NTP servers in an organization's networks.
The "Group ID" field may be further divided for special multicast address types.
The following table is a partial list of well-known IPv6 multicast addresses that are registered with the Internet Assigned Numbers Authority (IANA).
Ethernet.
Ethernet frames with a value of 1 in the least-significant bit of the first octet of the destination address are treated as multicast frames and are flooded to all points on the network. While frames with ones in all bits of the destination address (codice_8) are sometimes referred to as broadcasts, Ethernet network equipment generally does not distinguish between multicast and broadcast frames. Modern Ethernet controllers filter received packets to reduce CPU load, by looking up the hash of a multicast destination address in a table, initialized by software, which controls whether a multicast packet is dropped or fully received.
802.11.
802.11 wireless networks use the same 01:00:5E:xx:xx:xx and 33:33:xx:xx:xx:xx MAC addresses for multicasting as Ethernet.

</doc>
<doc id="41385" url="https://en.wikipedia.org/wiki?curid=41385" title="Multipath propagation">
Multipath propagation

In wireless telecommunications, multipath is the propagation phenomenon that results in radio signals reaching the receiving antenna by two or more paths. Causes of multipath include atmospheric ducting, ionospheric reflection and refraction, and reflection from water bodies and terrestrial objects such as mountains and buildings.
Multipath causes multipath interference including constructive and destructive interference, and phase shifting of the signal. Destructive interference causes fading. Where the magnitudes of the signals arriving by the various paths have a distribution known as the Rayleigh distribution, this is known as Rayleigh fading. Where one component (often, but not necessarily, a line of sight component) dominates, a Rician distribution provides a more accurate model, and this is known as Rician fading.
Examples.
In facsimile and (analog) television transmission, multipath causes jitter and ghosting, seen as a faded duplicate image to the right of the main image. Ghosts occur when transmissions bounce off a mountain or other large object, while also arriving at the antenna by a shorter, direct route, with the receiver picking up two signals separated by a delay.
In radar processing, multipath causes ghost targets to appear, deceiving the radar receiver. These ghosts are particularly bothersome since they move and behave like the normal targets (which they echo), and so the receiver has difficulty in isolating the correct target echo. These problems can be overcome by incorporating a ground map of the radar's surroundings and eliminating all echoes which appear to originate below ground or above a certain height.
In digital radio communications (such as GSM) multipath can cause errors and affect the quality of communications. The errors are due to intersymbol interference (ISI). Equalisers are often used to correct the ISI. Alternatively, techniques such as orthogonal frequency division modulation and rake receivers may be used.
In a Global Positioning System receiver, Multipath Effect can cause a stationary receiver's output to indicate as if it were randomly jumping about or creeping. When the unit is moving the jumping or creeping may be hidden, but it still degrades the displayed accuracy of location and speed.
In wired media.
Multipath propagation may also happen in wired media, especially where impedance mismatch causes signal reflection. A well-known example is power line communication.
High-speed power line communication systems usually employ multi-carrier modulations (such as OFDM or Wavelet OFDM) to avoid the intersymbol interference that multipath propagation would cause.
The ITU-T G.hn standard provides a way to create a high-speed (up to 1 Gigabit/s) local area network using existing home wiring (power lines, phone lines and coaxial cables). G.hn uses OFDM with a cyclic prefix to avoid ISI. Because multipath propagation behaves differently in each kind of wire, G.hn uses different OFDM parameters (OFDM symbol duration, Guard Interval duration) for each media.
Mathematical modeling.
The mathematical model of the multipath can be presented using the method of the impulse response used for studying linear systems.
Suppose you want to transmit a single, ideal Dirac pulse of electromagnetic power at time 0, i.e.
At the receiver, due to the presence of the multiple electromagnetic paths, more than one pulse will be received (we suppose here that the channel has infinite bandwidth, thus the pulse shape is not modified at all), and each one of them will arrive at different times. In fact, since the electromagnetic signals travel at the speed of light, and since every path has a geometrical length possibly different from that of the other ones, there are different air travelling times (consider that, in free space, the light takes 3 μs to cross a 1 km span). Thus, the received signal will be expressed by
where formula_3 is the number of received impulses (equivalent to the number of electromagnetic paths, and possibly very large), formula_4 is the time delay of the generic formula_5 impulse, and formula_6 represent the complex amplitude (i.e., magnitude and phase) of the generic received pulse. As a consequence, formula_7 also represents the impulse response function formula_8 of the equivalent multipath model.
More in general, in presence of time variation of the geometrical reflection conditions, this impulse response is time varying, and as such we have
Very often, just one parameter is used to denote the severity of multipath conditions: it is called the multipath time, formula_12, and it is defined as the time delay existing between the first and the last received impulses
In practical conditions and measurement, the multipath time is computed by considering as last impulse the first one which allows to receive a determined amount of the total transmitted power (scaled by the atmospheric and propagation losses), e.g. 99%.
Keeping our aim at linear, time invariant systems, we can also characterize the multipath phenomenon by the channel transfer function formula_14, which is defined as the continuous time Fourier transform of the impulse response formula_8
where the last right-hand term of the previous equation is easily obtained by remembering that the Fourier transform of a Dirac pulse is a complex exponential function, an eigenfunction of every linear system.
The obtained channel transfer characteristic has a typical appearance of a sequence of peaks and valleys (also called "notches"); it can be shown that, on average, the distance (in Hz) between two consecutive valleys (or two consecutive peaks), is roughly inversely proportional to the multipath time. The so-called coherence bandwidth is thus defined as
For example, with a multipath time of 3 μs (corresponding to a 1 km of added on-air travel for the last received impulse), there is a coherence bandwidth of about 330 kHz.

</doc>
<doc id="41387" url="https://en.wikipedia.org/wiki?curid=41387" title="Multiple homing">
Multiple homing

In telecommunication, the term multiple homing has the following meanings: 
1. In telephone systems, the connection of a terminal facility so that it can be served by one or several switching centers. Multiple homing may use a single directory number. 
2. In telephone systems, the connection of a terminal facility to more than one switching center by separate access lines. Separate directory numbers are applicable to each switching center accessed. 

</doc>
<doc id="41388" url="https://en.wikipedia.org/wiki?curid=41388" title="Multiplex baseband">
Multiplex baseband

In telecommunication, the term multiplex baseband has the following meanings: 
For example, the output of a group multiplexer consists of a band of frequencies from 60 kHz to 108 kHz. This is the group-level baseband that results from combining 12 voice-frequency input channels, having a bandwidth of 4 kHz each, including guard bands. In turn, 5 groups are multiplexed into a super group having a baseband of 312 kHz to 552 kHz. This baseband, however, does not represent a group-level baseband. Ten super groups are in turn multiplexed into one master group, the output of which is a baseband that may be used to modulate a microwave-frequency carrier.

</doc>
<doc id="41389" url="https://en.wikipedia.org/wiki?curid=41389" title="Multiplexing">
Multiplexing

In telecommunications and computer networks, multiplexing (sometimes contracted to muxing) is a method by which multiple analog message signals or digital data streams are combined into one signal over a shared medium. The aim is to share an expensive resource. For example, in telecommunications, several telephone calls may be carried using one wire. Multiplexing originated in telegraphy in the 1870s, and is now widely applied in communications. In telephony, George Owen Squier is credited with the development of telephone carrier multiplexing in 1910.
The multiplexed signal is transmitted over a communication channel, such as a cable. The multiplexing divides the capacity of the communication channel into several logical channels, one for each message signal or data stream to be transferred. A reverse process, known as demultiplexing, extracts the original channels on the receiver end.
A device that performs the multiplexing is called a multiplexer (MUX), and a device that performs the reverse process is called a demultiplexer (DEMUX or DMX).
Inverse multiplexing (IMUX) has the opposite aim as multiplexing, namely to break one data stream into several streams, transfer them simultaneously over several communication channels, and recreate the original data stream.
Types.
Multiple variable bit rate digital bit streams may be transferred efficiently over a single fixed bandwidth channel by means of statistical multiplexing. This is an asynchronous mode time-domain multiplexing which is a form of time-division multiplexing.
Digital bit streams can be transferred over an analog channel by means of code-division multiplexing techniques such as frequency-hopping spread spectrum (FHSS) and direct-sequence spread spectrum (DSSS).
In wireless communications, multiplexing can also be accomplished through alternating polarization (horizontal/vertical or clockwise/counterclockwise) on each adjacent channel and satellite, or through phased multi-antenna array combined with a multiple-input multiple-output communications (MIMO) scheme.
Space-division multiplexing.
In wired communication, space-division multiplexing is the use of separate point-to-point electrical conductors for each transmitted channel. Examples include an analogue stereo audio cable, with one pair of wires for the left channel and another for the right channel, and a multi-pair telephone cable, a switched star network such as a telephone access network, a switched Ethernet network, and a mesh network.
In wireless communication, space-division multiplexing is achieved with multiple antenna elements forming a phased array antenna. Examples are multiple-input and multiple-output (MIMO), single-input and multiple-output (SIMO) and multiple-input and single-output (MISO) multiplexing. An IEEE 802.11n wireless router with "k" antennas makes it in principle possible to communicate with "k" multiplexed channels, each with a peak bit rate of 54 Mbit/s, thus increasing the total peak bit rate by the factor "k". Different antennas would give different multi-path propagation (echo) signatures, making it possible for digital signal processing techniques to separate different signals from each other. These techniques may also be utilized for space diversity (improved robustness to fading) or beamforming (improved selectivity) rather than multiplexing.
Frequency-division multiplexing.
Frequency-division multiplexing (FDM) is inherently an analog technology. FDM achieves the combining of several signals into one medium by sending signals in several distinct frequency ranges over a single medium.
One of the most common applications for FDM is traditional radio and television broadcasting from terrestrial, mobile or satellite stations, or cable television. Only one cable reaches a customer's residential area, but the service provider can send multiple television channels or signals simultaneously over that cable to all subscribers without interference. Receivers must tune to the appropriate frequency (channel) to access the desired signal.
A variant technology, called wavelength-division multiplexing (WDM) is used in optical communications.
Time-division multiplexing.
Time-division multiplexing (TDM) is a digital (or in rare cases, analog) technology which uses time, instead of space or frequency, to separate the different data streams. TDM involves sequencing groups of a few bits or bytes from each individual input stream, one after the other, and in such a way that they can be associated with the appropriate receiver. If done sufficiently quickly, the receiving devices will not detect that some of the circuit time was used to serve another logical communication path.
Consider an application requiring four terminals at an airport to reach a central computer. Each terminal communicated at 2400 baud, so rather than acquire four individual circuits to carry such a low-speed transmission, the airline has installed a pair of multiplexers. A pair of 9600 baud modems and one dedicated analog communications circuit from the airport ticket desk back to the airline data center are also installed. Some modern web proxy servers (e.g. polipo) use TDM in HTTP pipelining of multiple HTTP transactions onto the same TCP/IP connection.
Carrier sense multiple access and multidrop communication methods are similar to time-division multiplexing in that multiple data streams are separated by time on the same medium, but because the signals have separate origins instead of being combined into a single signal, are best viewed as channel access methods, rather than a form of multiplexing.
Polarization-division multiplexing.
Polarization-division multiplexing uses the polarization of electromagnetic radiation to separate orthogonal channels. It is in practical use in both radio and optical communications, particularly in 100 Gbit/s per channel fiber optic transmission systems.
Orbital angular momentum multiplexing.
Orbital angular momentum multiplexing is a relatively new and experimental technique for multiplexing multiple channels of signals carried using electromagnetic radiation over a single path. It can potentially be used in addition to other physical multiplexing methods to greatly expand the transmission capacity of such systems. it is still in its early research phase, with small-scale laboratory demonstrations of bandwidths of up to 2.5 Tbit/s over a single light path.
Code-division multiplexing.
Code division multiplexing (CDM), Code division multiple access (CDMA) or spread spectrum is a class of techniques where several channels simultaneously share the same frequency spectrum, and this spectral bandwidth is much higher than the bit rate or symbol rate. One form is frequency hopping, another is direct sequence spread spectrum. In the latter case, each channel transmits its bits as a coded channel-specific sequence of pulses called chips. Number of chips per bit, or chips per symbol, is the spreading factor. This coded transmission typically is accomplished by transmitting a unique time-dependent series of short pulses, which are placed within chip times within the larger bit time. All channels, each with a different code, can be transmitted on the same fiber or radio channel or other medium, and asynchronously demultiplexed. Advantages over conventional techniques are that variable bandwidth is possible (just as in statistical multiplexing), that the wide bandwidth allows poor signal-to-noise ratio according to Shannon-Hartley theorem, and that multi-path propagation in wireless communication can be combated by rake receivers.
A significant application of CDMA is the Global Positioning System (GPS).
Multiple access method.
A multiplexing technique may be further extended into a multiple access method or channel access method, for example, TDM into time division multiple access (TDMA) and statistical multiplexing into carrier sense multiple access (CSMA). A multiple access method makes it possible for several transmitters connected to the same physical medium to share its capacity.
Multiplexing is provided by the Physical Layer of the OSI model, while multiple access also involves a media access control protocol, which is part of the Data Link Layer.
The Transport layer in the OSI model as well as TCP/IP model provides statistical multiplexing of several application layer data flows to/from the same computer.
Code Division Multiplexing (CDM) is a technique in which each channel transmits its bits as a coded channel-specific sequence of pulses. This coded transmission typically is accomplished by transmitting a unique time-dependent series of short pulses, which are placed within chip times within the larger bit time. All channels, each with a different code, can be transmitted on the same fiber and asynchronously demultiplexed. Other widely used multiple access techniques are Time Division Multiple Access (TDMA) and Frequency Division Multiple Access (FDMA).
Code Division Multiplex techniques are used as an access technology, namely Code Division Multiple Access (CDMA), in Universal Mobile Telecommunications System (UMTS) standard for the third generation (3G) mobile communication identified by the ITU.
Application areas.
Telegraphy.
The earliest communication technology using electrical wires, and therefore sharing an interest in the economies afforded by multiplexing, was the electric telegraph. Early experiments allowed two separate messages to travel in opposite directions simultaneously, first using an electric battery at both ends, then at only one end.
Telephony.
In telephony, a customer's telephone line now typically ends at the remote concentrator box, where it is multiplexed along with other telephone lines for that neighborhood or other similar area. The multiplexed signal is then carried to the central switching office on significantly fewer wires and for much further distances than a customer's line can practically go. This is likewise also true for digital subscriber lines (DSL).
Fiber in the loop (FITL) is a common method of multiplexing, which uses optical fiber as the backbone. It not only connects POTS phone lines with the rest of the PSTN, but also replaces DSL by connecting directly to Ethernet wired into the home. Asynchronous Transfer Mode is often the communications protocol used.
Because all the phone (and data) lines have been clumped together, none of them can be accessed except through a demultiplexer. Where such demultiplexers are uncommon, this provides for more-secure communications, though the connections are not typically encrypted. 
Cable TV has long carried multiplexed television channels, and late in the 20th century began offering the same services as telephone companies. IPTV also depends on multiplexing.
Video processing.
In video editing and processing systems, multiplexing refers to the process of interleaving audio and video into one coherent data stream.
In digital video, such a transport stream is normally a feature of a container format which may include metadata and other information, such as subtitles. The audio and video streams may have variable bit rate. Software that produces such a transport stream and/or container is commonly called a statistical multiplexer or muxer. A demuxer is software that extracts or otherwise makes available for separate processing the components of such a stream or container.
Digital broadcasting.
In digital television and digital radio systems, several variable bit-rate data streams are multiplexed together to a fixed bitrate transport stream by means of statistical multiplexing. This makes it possible to transfer several video and audio channels simultaneously over the same frequency channel, together with various services.
In the digital television systems, this may involve several standard definition television (SDTV) programmes (particularly on DVB-T, DVB-S2, ISDB and ATSC-C), or one HDTV, possibly with a single SDTV companion channel over one 6 to 8 MHz-wide TV channel. The device that accomplishes this is called a statistical multiplexer. In several of these systems, the multiplexing results in an MPEG transport stream. The newer DVB standards DVB-S2 and DVB-T2 has the capacity to carry several HDTV channels in one multiplex. Even the original DVB standards can carry more HDTV channels in a multiplex if the most advanced MPEG-4 compressions hardware is used.
On communications satellites which carry broadcast television networks and radio networks, this is known as multiple channel per carrier or MCPC. Where multiplexing is not practical (such as where there are different sources using a single transponder), single channel per carrier mode is used.
Signal multiplexing of satellite TV and radio channels is typically carried out in a central signal playout and uplink centre, such as SES Platform Services in Germany, which provides playout, digital archiving, encryption, and satellite uplinks, as well as multiplexing, for hundreds of digital TV and radio channels.
In digital radio, both the Digital Audio Broadcasting (DAB) Eureka 147 system of digital audio broadcasting and the in-band on-channel HD Radio, FMeXtra, and Digital Radio Mondiale systems can multiplex channels. This is essentially required with DAB-type transmissions (where a multiplex is called a DAB ensemble), but is entirely optional with IBOC systems.
Analog broadcasting.
In FM broadcasting and other analog radio media, multiplexing is a term commonly given to the process of adding subcarriers to the audio signal before it enters the transmitter, where modulation occurs. (In fact, the stereo multiplex signal can be generated using time-division multiplexing, by switching between the two (left channel and right channel) input signals at an ultrasonic rate (the subcarrier), and then filtering out the higher harmonics.) Multiplexing in this sense is sometimes known as MPX, which in turn is also an old term for stereophonic FM, seen on stereo systems since the 1960s.
Other meanings.
In spectroscopy the term is used to indicate that the experiment is performed with a mixture of frequencies at once and their respective response unravelled afterwards using the Fourier transform principle.
In computer programming, it may refer to using a single in-memory resource (such as a file handle) to handle multiple external resources (such as on-disk files).
Some electrical multiplexing techniques do not require a physical "multiplexer" device, they refer to a "keyboard matrix" or "Charlieplexing" design style:

</doc>
<doc id="41391" url="https://en.wikipedia.org/wiki?curid=41391" title="Narrative traffic">
Narrative traffic

Narrative traffic is data communications consisting of plain or encrypted messages written in a natural language and transmitted in accordance with standard formats and procedures. 
Examples of narrative traffic include:

</doc>
<doc id="41392" url="https://en.wikipedia.org/wiki?curid=41392" title="Narrowband modem">
Narrowband modem

In telecommunication, a narrowband modem is a modem whose modulated output signal has an essential frequency spectrum that is limited to that which can be wholly contained within, and faithfully transmitted through, a voice channel with a nominal 4 kHz bandwidth. 
"Note:" High frequency (HF) modems are limited to operation over a voice channel with a nominal 3 kHz bandwidth.

</doc>
<doc id="41394" url="https://en.wikipedia.org/wiki?curid=41394" title="National Communications System">
National Communications System

The National Communications System (NCS) was an office within the United States Department of Homeland Security charged with enabling national security and emergency preparedness communications (NS/EP telecommunications) using the national telecommunications system. The NCS was disbanded by Executive Order 13618 on July 6, 2012.
Background and history.
The genesis of the NCS began in 1962 after the Cuban missile crisis when communications problems among the United States, the Union of Soviet Socialist Republics, the North Atlantic Treaty Organization, and foreign heads of state threatened to complicate the crisis further. After the crisis, President John F. Kennedy ordered an investigation of national security communications, and the National Security Council (NSC) formed an interdepartmental committee to examine the communications networks and institute changes. This interdepartmental committee recommended the formation of a single unified communications system to serve the President, Department of Defense, diplomatic and intelligence activities, and civilian leaders. Consequently, in order to provide better communications support to critical Government functions during emergencies, President Kennedy established the National Communications System by a Presidential Memorandum on August 21, 1963. The NCS mandate included linking, improving, and extending the communications facilities and components of various Federal agencies, focusing on interconnectivity and survivability.
On April 3, 1984, President Ronald Reagan signed Executive Order (E.O.) 12472 which broadened the NCS' national security and emergency preparedness (NS/EP) capabilities and superseded President Kennedy's original 1963 memorandum. The NCS expanded from its original six members to an interagency group of 23 Federal departments and agencies, and began coordinating and planning NS/EP telecommunications to support crises and disasters.
With the addition of the Office of the Director of National Intelligence (ODNI) on September 30, 2007, the NCS membership currently stands at 24 members.
Each NCS member organization is represented on the NCS through the Committee of Principals (COP) -- and its subordinate Council of Representatives (COR). The COP, formed as a result of Executive Order 12472, provides advice and recommendations to the NCS and the National Security Council through the President's Critical Infrastructure Protection Board on NS/EP telecommunications and its ties to other critical infrastructures. The NCS also participates in joint industry-Government planning through its work with the President's National Security Telecommunications Advisory Committee (NSTAC), with the NCS's National Coordinating Center for Telecommunications (NCC) and the NCC's subordinate Information Sharing and Analysis Center (ISAC).
After nearly 40 years with the Secretary of Defense serving as its Executive Agent, President George W. Bush transferred the National Communications System to the Department of Homeland Security (DHS). The NCS was one of 22 Federal agencies transferred to the Department on March 1, 2003, in accordance with Executive Order 13286. A revised Executive Order 12472 reflects the changes of E.O. 13286. On November 15, 2005, the NCS became part of the Department's Directorate for Preparedness after nearly two years under the Information Analysis and Infrastructure Protection Directorate. In March 2007 the NCS became an entity of the National Protection and Programs Directorate. The DHS Under Secretary for National Protection and Programs Directorate served as the NCS Manager.
On July 6, 2012, President Barack Obama signed Executive Order 13618, which revoked Executive Order 12472, thus eliminating the NCS. A ceremony to retire the colors of the NCS and to celebrate the legacy of the organization was held on August 30, 2012 in Arlington, VA.
Services.
In fulfillment of their mission to enable emergency communications, the NCS has created a number of different services.

</doc>
<doc id="41396" url="https://en.wikipedia.org/wiki?curid=41396" title="National Information Infrastructure">
National Information Infrastructure

The National Information Infrastructure (NII) was the product of the High Performance Computing Act of 1991. It was a telecommunications policy buzzword, which was popularized during the Clinton Administration under the leadership of Vice-President Al Gore. It proposed to build communications networks, interactive services, interoperable computer hardware and software, computers, databases, and consumer electronics in order to put vast amounts of information available to both public and private sectors. 
NII was to have included more than just the physical facilities (more than the cameras, scanners, keyboards, telephones, fax machines, computers, switches, compact disks, video and audio tape, cable, wire, satellites, optical fiber transmission lines, microwave nets, switches, televisions, monitors, and printers) used to transmit, store, process, and display voice, data, and images; it was also to encompass a wide range of interactive functions, user-tailored services, and multimedia databases that were interconnected in a technology-neutral manner that will favor no one industry over any other.

</doc>
<doc id="41400" url="https://en.wikipedia.org/wiki?curid=41400" title="Negative-acknowledge character">
Negative-acknowledge character

In the ASCII code, the NAK character is 21 (decimal), or ^U (-). EBCDIC uses 0x3D. Unicode also defines a visible representation at U+2415(␕).

</doc>
<doc id="41402" url="https://en.wikipedia.org/wiki?curid=41402" title="Neper">
Neper

The neper (unit symbol Np) is a logarithmic unit for ratios of measurements of physical field and power quantities, such as gain and loss of electronic signals. The unit's name is derived from the name of John Napier, the inventor of logarithms. As is the case for the decibel and bel, the neper is a unit of the International System of Quantities (ISQ), but not part of the International System of Units (SI), but it is accepted for use alongside the SI.
Definition.
Like the decibel, the neper is a unit in a logarithmic scale. While the bel uses the decadic (base-10) logarithm to compute ratios, the neper uses the natural logarithm, based on Euler's number ("e" ≈ 2.71828). The value of a ratio in nepers is given by
where formula_2 and formula_3 are the values of interest, and "ln" is the natural logarithm.
In the ISQ, the neper is defined as 1 Np = 1.
Units.
The neper is defined in terms of ratios of field quantities (for example, voltage or current amplitudes in electrical circuits, or pressure in acoustics), whereas the decibel was originally defined in terms of power ratios. A power ratio 10 log "r" dB is equivalent to a field-quantity ratio 20 log "r" dB, since power is proportional to the square (Joule's laws) of the amplitude. Hence the neper and dB are related via:
and
The decibel and the neper have a fixed ratio to each other. The (voltage) level ratio is
Like the decibel, the neper is a dimensionless unit. The International Telecommunication Union (ITU) recognizes both units.
Applications.
The neper is a natural linear unit of relative difference, meaning in nepers (logarithmic units), relative differences add, rather than multiply. This property is shared with logarithmic units in other bases, such as the bel.
Particular to the neper, however, is that the derived unit of "centineper" is asymptotically equal to percentage difference for very small differences – since the derivative of the natural log (at 1) is 1; this is not shared with other logarithmic units, which introduce a scaling factor due to the derivative not being unity. The centineper can thus be used as a linear replacement for percentage differences. The linear approximation for small percentage differences,
is widely used, particularly in finance—see for example the Fisher equation. However, it is only approximate, with error increasing for large percentage changes. Measured instead in centinepers, these linear approximations can be replaced with exact equalities, and applicable to any magnitude change, by defining the following centineper quantity for any change formula_8
formula_9

</doc>
<doc id="41403" url="https://en.wikipedia.org/wiki?curid=41403" title="Net gain (telecommunications)">
Net gain (telecommunications)

In telecommunications, net gain is the overall gain of a transmission circuit. Net gain is measured by applying a test signal at an appropriate power level at the input port of a circuit and measuring the power delivered at the output port. The net gain in dB is calculated by taking 10 times the common logarithm of the ratio of the output power to the input power.
The net gain expressed in dB may be positive or negative. If the net gain expressed in dB is negative, it is also called the net loss. If the net gain is expressed as a ratio, and the ratio is less than unity, a net loss is indicated.
The test signal must be chosen so that its power level is within the usual operating range of the circuit being tested.

</doc>
<doc id="41404" url="https://en.wikipedia.org/wiki?curid=41404" title="Net operation">
Net operation

In telecommunication, net operation is the operation of an organization of stations capable of direct communication on a common channel or frequency. 
"Note:" Net operations (a) allow participants to conduct ordered conferences among participants who usually have common information needs or related functions to perform, (b) are characterized by adherence to standard formats and procedures, and (c) are responsive to a common supervisory station, called the ""net control station"," which permits access to the net and maintains net operational discipline.

</doc>
<doc id="41406" url="https://en.wikipedia.org/wiki?curid=41406" title="Network architecture">
Network architecture

Network architecture is the design of a communication network. It is a framework for the specification of a network's physical components and their functional organization and configuration, its operational principles and procedures, as well as data formats used in its operation.
In telecommunication, the specification of a network architecture may also include a detailed description of products and services delivered via a communications network, as well as detailed rate and billing structures under which services are compensated.
The network architecture of the Internet is predominantly expressed by its use of the Internet Protocol Suite, rather than a specific model for interconnecting networks or nodes in the network, or the usage of specific types of hardware links.
OSI network model.
The Open Systems Interconnection model (OSI model) is a product of the Open Systems Interconnection effort at the International Organization for Standardisation (ISO) . It is a way of sub-dividing a communications system into smaller parts called layers. A layer is a collection of similar functions that provide services to the layer above it and receives services from the layer below it. On each layer, an instance provides services to the instances at the layer above and requests service from the layer below.
Physical layer.
The physical layer defines the electrical and physical specifications for devices. In particular, it defines the relationship between a device and a transmission medium, such as a copper or optical cable. This includes the layout of pins, voltages, cable specifications, hubs, repeaters, network adapters, host bus adapters (HBA used in storage area networks) and more. Its main task is the transmission of a stream of bits over a communication channel.
Data-linking layer.
The data link layer provides the functional and procedural means to transfer data between network entities and to detect and possibly correct errors that may occur in the physical layer. Originally, this layer was intended for point-to-point and point-to-multipoint media, characteristic of wide area media in the telephone system. Local area network architecture, which included broadcast-capable multi-access media, was developed independently of the ISO work in IEEE Project 802. IEEE work assumed sublayering and management functions not required for WAN use. In modern practice, only error detection, not flow control using sliding window, is present in data link protocols such as Point-to-Point Protocol (PPP), and, on local area networks, the IEEE 802.2 LLC layer is not used for most protocols on the Ethernet, and on other local area networks, its flow control and acknowledgment mechanisms are rarely used. Sliding-window flow control and acknowledgment is used at the transport layer by protocols such as TCP, but is still used in niches where X.25 offers performance advantages. Simply, its main job is to create and recognize the frame boundary. This can be done by attaching special bit patterns to the beginning and the end of the frame. The input data is broken up into frames.
Network layer.
The network layer provides the functional and procedural means of transferring variable length data sequences from a source host on one network to a destination host on a different network, while maintaining the quality of service requested by the transport layer (in contrast to the data link layer which connects hosts within the same network). The network layer performs network routing functions, and might also perform fragmentation and reassembly, and report delivery errors. Routers operate at this layer—sending data throughout the extended network and making the Internet possible. This is a logical addressing scheme; values are chosen by the network engineer. The addressing scheme is not hierarchical. It controls the operation of the subnet and determine the routing strategies between IMP and ensures that all the packs are correctly received at the destination in the proper order.
Transport layer.
The transport layer provides transparent transfer of data between end users, providing reliable data transfer services to the upper layers. The transport layer controls the reliability of a given link through flow control, segmentation/desegmentation, and error control. Some protocols are state and connection oriented. This means that the transport layer can keep track of the segments and retransmit those that fail. The transport layer also provides the acknowledgement of the successful data transmission and sends the next data if no errors occurred. Some transport layer protocols (such as TCP, but not UDP) support virtual circuits that provide connection-oriented communication over an underlying packet-oriented datagram network, where it assures the delivery of packets in the order in which they were sent and that they are free of errors. The datagram transportation deliver the packets randomly and broadcast it to multiple nodes.
The transport layer multiplexes several streams on to one physical channel. The transport headers indicate which message belongs to which connection.
Session layer.
This layer provides a user interface to the network where the user negotiates to establish a connection. The user must provide the remote address to be contacted. The operation of setting up a session between two processes is known as "binding". In some protocols, it is merged with the transport layer. Its main work is to transfer data from the other application to this application so this application is mainly used for transferred layer.
Presentation layer.
The presentation layer establishes context between entities on the application layer, in which the higher-layer entities may use different syntax and semantics if the presentation service provides a mapping between them. If a mapping is available, presentation service data units are encapsulated into session protocol data units, and passed down the stack. This layer provides independence from data representation (e.g. encryption) by translating between application and network formats. The presentation layer transforms data into the form that the application accepts. This layer formats and encrypts data to be sent across a network. It is sometimes called the syntax layer. The original presentation structure used the basic encoding rules of Abstract Syntax Notation One (ASSN), with capabilities such as converting an BODICE-coded text file to an ASCII-coded file, or serialization of objects and other data structures from and to XML.
Application layer.
The application layer is the OSI layer closest to the end user, which means that both the OSI application layer and the user interact directly with the software application. This layer interacts with software applications that implement a communicating component. Such application programs fall outside the scope of the OSI model. Application layer functions typically include identifying communication partners, determining resource availability, and synchronizing communication. When identifying communication partners, the application layer determines the identity and availability of communication partners for an application with data to transmit.
Distributed computing.
In distinct usage in distributed computing, the term "network architecture" often describes the structure and classification of a distributed application architecture, as the participating nodes in a distributed application are often referred to as a "network". For example, the applications architecture of the public switched telephone network (PSTN) has been termed the Advanced Intelligent Network. There are any number of specific classifications but all lie on a continuum between the dumb network (e.g. Internet) and the intelligent computer network (e.g. the telephone network). Other networks contain various elements of these two classical types to make them suitable for various types of applications. Recently the context aware network, which is a synthesis of two, has gained much interest with its ability to combine the best elements of both.
A popular example of such usage of the term in distributed applications, as well as PVCs (permanent virtual circuits), is the organization of nodes in peer-to-peer (P2P) services and networks. P2P networks usually implement overlay networks running over an underlying physical or logical network. These overlay network may implement certain organizational structures of the nodes according to several distinct models, the network architecture of the system.
Network architecture is a broad plan that specifies everything necessary for two application programs on different networks on an Internet to be able to work together effectively.

</doc>
<doc id="41407" url="https://en.wikipedia.org/wiki?curid=41407" title="Network engineering">
Network engineering

In telecommunications, network engineering may refer to:

</doc>
<doc id="41408" url="https://en.wikipedia.org/wiki?curid=41408" title="Network interface">
Network interface

In computing, a network interface is a system's (software and/or hardware) interface between two pieces of equipment or protocol layers in a computer network.
A network interface will usually have some form of network address. This may consist of a node Id and a port number or may be a unique node Id in its own right.
Network interfaces provide standardized functions such as passing messages, connecting and disconnecting, etc.

</doc>
<doc id="41409" url="https://en.wikipedia.org/wiki?curid=41409" title="Network interface device">
Network interface device

In telecommunications, a network interface device (NID) is a device that serves as the demarcation point between the carrier's local loop and the customer's premises wiring. Outdoor telephone NIDs also provide the subscriber with access to the station wiring and serve as a convenient test point for verification of loop integrity and of the subscriber’s inside wiring. 
Generically, an NID may also be called a network interface unit (NIU), telephone network interface (TNI), system network interface (SNI), or telephone network box. Australia's National Broadband Network uses the term network termination device or NTD. A smartjack is a type of NID with capabilities beyond simple electrical connection, such as diagnostics. An optical network terminal (ONT) is a type of NID used with fiber-to-the-premises applications.
Wiring termination.
The simplest NIDs are essentially just a specialized set of wiring terminals. These will typically take the form of a small, weather-proof box, mounted on the outside of the building. The telephone line from the telephone company will enter the NID and be connected to one side. The customer connects their wiring to the other side. A single NID enclosure may contain termination for a single line or multiple lines.
In its role as the demarcation point (dividing line), the NID separates the telephone company's equipment from the customer's wiring and equipment. The telephone company owns the NID itself, and all wiring up to it. Anything past the NID is the customer's responsibility. To facilitate this, there is typically a test jack inside the NID. Accessing the test jack disconnects the customer premises wiring from the network and allows the customer to plug a "known good" telephone into the jack to isolate trouble. If the telephone works at the test jack, the problem is the customer's wiring, and the customer is responsible for repair. If the telephone does not work, the line is faulty and the telephone company is responsible for repair.
Most NIDs also include "circuit protectors", which are surge protectors for a telephone line. They protect customer wiring, equipment, and personnel from any transient energy on the line, such as from a lightning strike to a telephone pole.
Simple NIDs contain no "intelligence" or "logic"; they are "dumb" devices. They have no capabilities beyond wiring termination, circuit protection, and providing a place to connect test equipment.
Smartjack.
Several types of NIDs provide more than just a terminal for the connection of wiring. Such NIDs are colloquially called "smartjacks" or "Intelligent Network Interface Devices" (INIDs) as an indication of their built-in "intelligence", as opposed to a simple NID, which is just a wiring device. Smartjacks are typically used for more complicated types of telecommunications service, such as T1 lines. Plain old telephone service lines generally cannot be equipped with smartjacks.
Despite the name, most smartjacks are much more than a simple telephone jack. One common form for a smartjack is a circuit board with a face plate on one edge, mounted in an enclosure.
A smartjack may provide signal conversion, converting codes and protocols (e.g. framing types) to the type needed by the customer equipment. It may buffer and/or regenerate the signal, to compensate for signal degradation from line transmission, similar to what a repeater does.
Smartjacks also typically provide diagnostic capabilities. A very common capability provided by a smartjack is loopback, such that the signal from the telephone company is transmitted back to the telephone company. This allows the telephone company to test the line from the central office, without the need to have test equipment at the customer site. The telephone company usually has the ability to remotely activate loopback, without even needing personnel at the customer site. When looped back, the customer equipment is disconnected from the line.
Additional smartjack diagnostic capabilities include alarm indication signal, which reports trouble at one end of the line to the far end. This helps the telephone company know if trouble is present in the line, the smartjack, or customer equipment. Indicator lights to show configuration, status, and alarms are also common.
Smartjacks typically derive their operating power from the telephone line, rather than relying on premises electrical power, although this is not a universal rule.
Optical network terminals.
In fiber-to-the-premises systems, the signal is transmitted to the customer premises using fiber optic technologies. Unlike many conventional telephone technologies, this does not provide power for premises equipment, nor is it suitable for direct connection to customer equipment. An optical network terminal (ONT) is used to terminate the fiber optic line, demultiplex the signal into its component parts (voice telephone, television, and Internet), and provide power to customer telephones. As the ONT must derive its power from the customer premises electrical supply, many ONTs have the option for a battery backup, to maintain service in the event of a power outage.
Environmental conditions.
According to Telcordia GR-49, requirements for telecommunications NIDs vary based on three categories of environmental conditions:
Service providers must decide which condition best suits their application.

</doc>
<doc id="41410" url="https://en.wikipedia.org/wiki?curid=41410" title="Network management">
Network management

Below, there is information on the different methods of network management.
Technologies.
A small number of accessory methods exist to support network and network device management. Access methods include the SNMP, command-line interface, custom XML, CMIP, Windows Management Instrumentation (WMI), Transaction Language 1, CORBA, NETCONF, and the Java Management Extensions (JMX).
Schemas include the Structure of Management Information, WBEM, the Common Information Model, and MTOSI amongst others.
Internet service providers (ISP) use a technology known as deep packet inspection in order to regulate network congestion and lessen Internet bottlenecks.
In the United States, Medical Service Providers provide a niche marketing utility for managed service providers as HIPAA legislation consistently increases demands for knowledgeable providers. Medical Service Providers are liable for the protection of their clients' confidential information, including in an electronic realm. This liability creates a significant need for managed service providers who can provide secure infrastructure for transportation of medical data.

</doc>
<doc id="41411" url="https://en.wikipedia.org/wiki?curid=41411" title="Network operating system">
Network operating system

The term network operating system is used to refer to two rather different concepts:
Network device operating systems.
Network operating systems can be embedded in a router or hardware firewall that operates the functions in the network layer (layer 3).
Historic network operating systems.
Early microcomputer operating systems such as CP/M, DOS and Mac OS were designed for one user on one computer. As local area network technology became available, two general approaches to handle sharing arose.
Peer-to-peer.
In a peer-to-peer network operating system users are allowed to share resources and files located on their computers and access shared resources from others. This system is not based with having a file server or centralized management source. A peer-to-peer network sets all connected computers equal; they all share the same abilities to use resources available on the network.
The advantages include:
The disadvantages include:
Client-server.
Network operating systems can be based on a client–server model (architecture) in which a server enables multiple clients to share resources.
Client-server network operating systems allow networks to centralize functions and applications in one or more dedicated file servers. The server is the center of the system, allowing access to resources and instituting security. The network operating system provides the mechanism to integrate all the components on a network to allow multiple users to simultaneously share the same resources regardless of physical location.
The advantages include:
The disadvantages include:

</doc>
<doc id="41413" url="https://en.wikipedia.org/wiki?curid=41413" title="Network topology">
Network topology

Network topology is the arrangement of the various elements (links, nodes, etc.) of a computer network. Essentially, it is the topological structure of a network and may be depicted physically or logically. "Physical topology" is the placement of the various components of a network, including device location and cable installation, while "logical topology" illustrates how data flows within a network, regardless of its physical design. Distances between nodes, physical interconnections, transmission rates, or signal types may differ between two networks, yet their topologies may be identical.
An example is a local area network (LAN): Any given node in the LAN has one or more physical links to other devices in the network; graphically mapping these links results in a geometric shape that can be used to describe the physical topology of the network. Conversely, mapping the data flow between the components determines the logical topology of the network.
Topology.
There are two basic categories of network topologies: physical topologies and logical topologies.
The cabling layout used to link devices is the physical topology of the network. This refers to the layout of cabling, the locations of nodes, and the interconnections between the nodes and the cabling. The physical topology of a network is determined by the capabilities of the network access devices and media, the level of control or fault tolerance desired, and the cost associated with cabling or telecommunications circuits.
The logical topology in contrast, is the way that the signals act on the network media, or the way that the data passes through the network from one device to the next without regard to the physical interconnection of the devices. A network's logical topology is not necessarily the same as its physical topology. For example, the original twisted pair Ethernet using repeater hubs was a logical bus topology with a physical star topology layout. Token Ring is a logical ring topology, but is wired as a physical star from the Media Access Unit.
The logical classification of network topologies generally follows the same classifications as those in the physical classifications of network topologies but describes the path that the "data" takes between nodes being used as opposed to the actual "physical" connections between nodes. The logical topologies are generally determined by network protocols as opposed to being determined by the physical layout of cables, wires, and network devices or by the flow of the electrical signals, although in many cases the paths that the electrical signals take between nodes may closely match the logical flow of data, hence the convention of using the terms "logical topology" and "signal topology" interchangeably.
Logical topologies are often closely associated with Media Access Control methods and protocols. Logical topologies are able to be dynamically reconfigured by special types of equipment such as routers and switches.
The study of network topology recognizes eight basic topologies: point-to-point, bus, star, ring or circular, mesh, tree, hybrid, or daisy chain.
Point-to-point.
The simplest topology with a dedicated link between two endpoints. Switched point-to-point topologies are the basic model of conventional telephony. The value of a permanent point-to-point network is unimpeded communications between the two endpoints. The value of an on-demand point-to-point connection is proportional to the number of potential pairs of subscribers and has been expressed as Metcalfe's Law.
Mesh.
The value of fully meshed networks is proportional to the exponent of the number of subscribers, assuming that communicating groups of any two endpoints, up to and including all the endpoints, is approximated by Reed's Law.
Fully connected network.
In a "fully connected network", all nodes are interconnected. (In graph theory this is called as a complete graph.) The simplest fully connected network is a two-node network. A fully connected network doesn't need to use packet switching or broadcasting. However, since the number of connections grows quadratically with the number of nodes:
formula_1
This makes it impractical for large networks.
Partially connected network.
In a partially connected network, certain nodes are connected to exactly one other node; but some nodes are connected to two or more other nodes with a point-to-point link. This makes it possible to make use of some of the redundancy of mesh topology that is physically fully connected, without the expense and complexity required for a connection between every node in the network.
Hybrid.
Hybrid networks combine two or more topologies in such a way that the resulting network does not exhibit one of the standard topologies (e.g., bus, star, ring, etc.). For example, a tree network (or "star-bus network") is a hybrid topology in which star networks are interconnected via bus networks. However, a tree network connected to another tree network is still topologically a tree network, not a distinct network type. A hybrid topology is always produced when two different basic network topologies are connected.
A "star-ring" network consists of two or more ring networks connected using a multistation access unit (MAU) as a centralized hub.
Snowflake topology is a star network of star networks.
Two other hybrid network types are "hybrid mesh" and "hierarchical star".
Daisy chain.
Except for star-based networks, the easiest way to add more computers into a network is by daisy-chaining, or connecting each computer in series to the next. If a message is intended for a computer partway down the line, each system bounces it along in sequence until it reaches the destination. A daisy-chained network can take two basic forms: linear and ring.
Centralization.
The star topology reduces the probability of a network failure by connecting all of the peripheral nodes (computers, etc.) to a central node. When the physical star topology is applied to a logical bus network such as Ethernet, this central node (traditionally a hub) rebroadcasts all transmissions received from any peripheral node to all peripheral nodes on the network, sometimes including the originating node. All peripheral nodes may thus communicate with all others by transmitting to, and receiving from, the central node only. The failure of a transmission line linking any peripheral node to the central node will result in the isolation of that peripheral node from all others, but the remaining peripheral nodes will be unaffected. However, the disadvantage is that the failure of the central node will cause the failure of all of the peripheral nodes.
If the central node is "passive", the originating node must be able to tolerate the reception of an echo of its own transmission, delayed by the two-way round trip transmission time (i.e. to and from the central node) plus any delay generated in the central node. An "active" star network has an active central node that usually has the means to prevent echo-related problems.
A tree topology (a.k.a. hierarchical topology) can be viewed as a collection of star networks arranged in a hierarchy. This tree has individual peripheral nodes (e.g. leaves) which are required to transmit to and receive from one other node only and are not required to act as repeaters or regenerators. Unlike the star network, the functionality of the central node may be distributed.
As in the conventional star network, individual nodes may thus still be isolated from the network by a single-point failure of a transmission path to the node. If a link connecting a leaf fails, that leaf is isolated; if a connection to a non-leaf node fails, an entire section of the network becomes isolated from the rest.
To alleviate the amount of network traffic that comes from broadcasting all signals to all nodes, more advanced central nodes were developed that are able to keep track of the identities of the nodes that are connected to the network. These network switches will "learn" the layout of the network by "listening" on each port during normal data transmission, examining the data packets and recording the address/identifier of each connected node and which port it is connected to in a lookup table held in memory. This lookup table then allows future transmissions to be forwarded to the intended destination only.
Decentralization.
In a mesh topology (i.e., a partially connected mesh topology), there are at least two nodes with two or more paths between them to provide redundant paths to be used in case the link providing one of the paths fails. This decentralization is often used to compensate for the single-point-failure disadvantage that is present when using a single device as a central node (e.g., in star and tree networks). A special kind of mesh, limiting the number of hops between two nodes, is a hypercube. The number of arbitrary fork in mesh networks makes them more difficult to design and implement, but their decentralized nature makes them very useful. In 2012 the IEEE published the Shortest path bridging protocol to ease configuration tasks and allows all paths to be active which increases bandwidth and redundancy between all devices.
This is similar in some ways to a grid network, where a linear or ring topology is used to connect systems in multiple directions. A multidimensional ring has a toroidal topology, for instance.
A fully connected network, complete topology, or full mesh topology is a network topology in which there is a direct link between all pairs of nodes. In a fully connected network with n nodes, there are n(n-1)/2 direct links. Networks designed with this topology are usually very expensive to set up, but provide a high degree of reliability due to the multiple paths for data that are provided by the large number of redundant links between nodes. This topology is mostly seen in military applications.

</doc>
<doc id="41414" url="https://en.wikipedia.org/wiki?curid=41414" title="Neutral direct-current telegraph system">
Neutral direct-current telegraph system

In telecommunication, a neutral direct-current telegraph system ("single-current system", "single-current transmission system", "single-Morse system") is a telegraph system in which (a) current flows during marking intervals and no current flows during spacing intervals for the transmission of signals over a line, and (b) the direction of current flow is immaterial.

</doc>
<doc id="41415" url="https://en.wikipedia.org/wiki?curid=41415" title="Noise">
Noise

Noise is a variety of sound. It means any unwanted sound. Sounds, particularly loud ones, that disturb people or make it difficult to hear wanted sounds, are noise. For example, conversations of other people may be called noise by people not involved in any of them; any unwanted sound such as neighbours playing loud music, portable mechanical saws, road traffic sounds, or a distant aircraft in quiet countryside, is called noise.
Acoustic noise can be anything from quiet but annoying to loud and harmful. At one extreme users of public transport sometimes complain about the faint and tinny sounds emanating from the headphones or earbuds of somebody listening to a portable audio player; at the other the sound of very loud music, a jet engine at close quarters, etc. can cause irreversible hearing damage. At intermediate levels there are a range of deleterious health effects from noise. This "intolerable corruption of human space" can be called noise pollution. A claim made by Luigi Russolo in his article, "The Joys of Noise" is that noise has become so prominent that pure sound no longer exists.
Roland Barthes also observes that noise can be perceived either physiologically or psychologically. We perceive noise physiologically when we "hear" it. On the other hand, when we "listen" to a noise we are doing this psychologically. When we perceive a physiological noise we subconsciously feel the vibrations of the noise (sound) waves with our particles in our physical body whereas psychological noise refers to noise that is perceived when our conscious awareness shifts its attention to that noise rather than letting it filter through our subconscious where it goes unnoticed.
Sound intensity follows an inverse square law with distance from the source; doubling the distance from a noise source reduces its intensity by a factor of four, or 6 dB.
Regulation of acoustic noise.
Noise regulation includes statutes or guidelines relating to sound transmission established by national, state or provincial and municipal levels of government. After a watershed passage of the U.S. Noise Control Act of 1972, the program was abandoned at the federal level, under President Ronald Reagan, in 1981 and the issue was left to local and state governments. Although the UK and Japan enacted national laws in 1960 and 1967 respectively, these laws were not at all comprehensive or fully enforceable as to address (a) generally rising ambient noise (b) enforceable numerical source limits on aircraft and motor vehicles or (c) comprehensive directives to local government.
Underwater noise is one of 11 Descriptors of Good Environmental Status according to the EU's Marine Strategy Framework Directive.
Recording and reproduction noise.
In audio, recording, and broadcast systems "audio noise" refers to the residual low level sound (usually hiss and hum) that is heard in quiet periods of programme. This is also known as white noise according to the Merriam Webster Definition. There is a similar phenomena to "white noise" which emanates not only from audio recording equipment but from everything and more particularly, musical instruments (whether they are acoustic or electric). These noises are "impurities." When an instrument plays a pitch, even the most beautiful sounding instruments, there is noise (consisting of impurities) projected. Henry Cowell claims that technological advancements have brought machines closer to diminishing these unwanted noises, but have not been completely successful thus far.
In audio engineering it can also refer to the unwanted residual electronic noise signal that gives rise to acoustic noise heard as hiss. This signal noise is commonly measured using A-weighting or ITU-R 468 weighting.
Interfering noise.
Interfering noises (or interfering sounds) are sounds with a negative sound quality, that is, the sound event leads to a hearing event, which is perceived as unpleasant, disturbing and interfering. This sound event usually releases negative associations as regards the suitability of the product and it is on the whole perceived as not matching the product.
Definition.
A noise can be characterised as interfering, if it fulfils at least one of the following conditions:
There is a multiplicity of parameters which play a role in the definition of sound quality. The definition considers the psychologically important distinction between disturbing and function sounds. Function sounds are sounds such as the often desired full sound of an engine. In addition, there is trend in the automotive industry that a complete acoustic insulation is not desirable from the point of view of the customer.
Emergence of interfering noises.
Interfering noises are a result of a relative motion at contact points. For the occurrence of interfering sounds two conditions must be fulfilled together:
A cause of interfering sounds occurring predominantly in the car interior is the relative motion of different construction parts to each other. Motion is usually caused by the vibration of the car when driving. Interference sound develops at contact points. If two parts touch one another or rub against each other, then interference sound can develop. Therefore the search for the core causes of interfering sounds is closely related to the search for relevant contact points.
All critical contact points can be isolated and marked on the basis of factors such as previous experience, surveys by quality-specialists from car manufacturing and surveys by specialists of interference
acoustics. Here, additionally, construction designs, pictures, drafts (and whatever is otherwise available) are used, in order to represent the problem visually. Videos from previous experience are particularly important thereby because they address the audiovisual part of the human brain and are therefore particularly efficient to make specialists aware of problems.
Characterization of the interfering noise level.
An interfering noise doesn't necessarily have to be loud. A mosquito can produce considerable disturbing sound, although it is comparatively quiet with a volume of only approx. 30 dB(A). An orchestra, by contrast, might produce very pleasant sounds, even if its volume amounts to nearly 90 dB(A). The final of an opera can be just as loud as heavy motorway noise. People differentiates unconsciously between good and bad sounds. Each sound signals a message, which, if perceived as disturbing, can then become the problem. It is thus the human mind and not the hearing, which decides whether a noise is felt as disturbing or pleasant. The human hearing can rather be seen as registering the pressure waves and frequencies of sound just like a physical measuring instrument. Stick-slip noises rank first in the hit-list of the most interfering sounds. Examples are sounds such as squeaking, creaking and grinding sounds.

</doc>
<doc id="41416" url="https://en.wikipedia.org/wiki?curid=41416" title="Noise-equivalent power">
Noise-equivalent power

Noise-equivalent power (NEP) is a measure of the sensitivity of a photodetector or detector system. It is defined as the signal power that gives a signal-to-noise ratio of one in a one hertz output bandwidth. An output bandwidth of one hertz is equivalent to half a second of integration time. The units of NEP are watts per square root hertz. The NEP is equal to the noise spectral density (expressed in units of formula_1 or formula_2) divided by the responsivity (expressed in units of formula_3 or formula_4, respectively). 
A smaller NEP corresponds to a more sensitive detector. For example, a detector with an NEP of formula_5 can detect a signal power of one picowatt with a signal-to-noise ratio (SNR) of one after one half second of averaging. The SNR improves as the square root of the averaging time, and hence the SNR in this example can be improved to 10 by averaging for 50 seconds.
If the NEP refers to the signal power absorbed in the detector, it is known as the electrical NEP. If instead it refers to the signal power incident on the detector system, it is called the optical NEP. The optical NEP is equal to the electrical NEP divided by the optical coupling efficiency of the detector system. 

</doc>
<doc id="41417" url="https://en.wikipedia.org/wiki?curid=41417" title="Noise figure">
Noise figure

Noise figure (NF) and noise factor ("F") are measures of degradation of the signal-to-noise ratio (SNR), caused by components in a radio frequency (RF) signal chain. It is a number by which the performance of an amplifier or a radio receiver can be specified, with lower values indicating better performance.
The noise factor is defined as the ratio of the output noise power of a device to the portion thereof attributable to thermal noise in the input termination at standard noise temperature "T"0 (usually 290 K). The noise factor is thus the ratio of actual output noise to that which would remain if the device itself did not introduce noise, or the ratio of input SNR to output SNR.
The noise "figure" is simply the noise "factor" expressed in decibels (dB).
General.
The noise figure is the difference in decibels (dB) between the noise output of the actual receiver to the noise output of an “ideal” receiver with the same overall gain and bandwidth when the receivers are connected to matched sources at the standard noise temperature "T"0 (usually 290 K). The noise power from a simple load is equal to "k T B", where "k" is Boltzmann's constant, "T" is the absolute temperature of the load (for example a resistor), and "B" is the measurement bandwidth. 
This makes the noise figure a useful figure of merit for terrestrial systems where the antenna effective temperature is usually near the standard 290 K. In this case, one receiver with a noise figure say 2 dB better than another, will have an output signal to noise ratio that is about 2 dB better than the other. However, in the case of satellite communications systems, where the receiver antenna is pointed out into cold space, the antenna effective temperature is often colder than 290 K. In these cases a 2 dB improvement in receiver noise figure will result in more than a 2 dB improvement in the output signal to noise ratio. For this reason, the related figure of "effective noise temperature" is therefore often used instead of the noise figure for characterizing satellite-communication receivers and low noise amplifiers.
In heterodyne systems, output noise power includes spurious contributions from image-frequency transformation, but the portion attributable to thermal noise in the input termination at standard noise temperature includes only that which appears in the output via the principal frequency transformation of the system and excludes that which appears via the image frequency transformation.
Definition.
The noise factor "F" of a system is defined as:
where SNRin and SNRout are the input and output signal-to-noise ratios, respectively. The SNR quantities are power ratios. 
The noise figure NF is defined as the noise factor in dB:
where SNRin, dB and SNRout, dB are in decibels (dB).
These formulae are only valid when the input termination is at standard noise temperature "T"0, although in practice small differences in temperature do not significantly affect the values.
The noise factor of a device is related to its noise temperature "T"e:
Attenuators have a noise factor "F" equal to their attenuation ratio "L" when their physical temperature equals "T"0. More generally, for an attenuator at a physical temperature "T", the noise temperature is formula_4, giving a noise factor of:
If several devices are cascaded, the total noise factor can be found with Friis' Formula:
where "F""n" is the noise factor for the "n"-th device and "G"n is the power gain (linear, not in dB) of the "n"-th device. The first amplifier in a chain has the most significant effect on the total noise figure than any
other amplifier in the chain. The lower noise figure amplifier should usually go first in a line of
amplifiers (assuming all else is equal).

</doc>
<doc id="41419" url="https://en.wikipedia.org/wiki?curid=41419" title="Noise power">
Noise power

In telecommunication, the term noise power has the following meanings: 

</doc>
<doc id="41420" url="https://en.wikipedia.org/wiki?curid=41420" title="Noise temperature">
Noise temperature

In electronics, noise temperature is one way of expressing the level of available noise power introduced by a component or source. The power spectral density of the noise is expressed in terms of the temperature (in kelvins) that would produce that level of Johnson–Nyquist noise, thus:
where:
Thus the noise temperature is proportional to the power spectral density of the noise, formula_6. That is the power that would be absorbed from the component or source by a matched load. Noise temperature is generally a function of frequency, unlike that of an ideal resistor which is simply equal to the actual temperature of the resistor at all frequencies.
Noise voltage and current.
A noisy component may be modelled as a noiseless component in series with a noisy voltage source producing a voltage of "vn", or as a noiseless component in parallel with a noisy current source producing a current of "in". This equivalent voltage or current corresponds to the above power spectral density formula_7, and would have a mean squared amplitude over a bandwidth "B" of:
where "R" is the resistive part of the component's impedance or "G" is the conductance (real part) of the component's admittance. Speaking of noise temperature therefore offers a fair comparison between components having different impedances rather than specifying the noise voltage and qualifying that number by mentioning the component's resistance. It is also more accessible than speaking of the noise's power spectral density (in watts per hertz) since it is expressed as an ordinary temperature which can be compared to the noise level of an ideal resistor at room temperature (290 K).
Note that one can only speak of the noise temperature of a component or source whose impedance has a substantial (and measurable) resistive component. Thus it doesn't make sense to talk about the noise temperature of a capacitor or of a voltage source. The noise temperature of an amplifier refers to the noise that would be added at the amplifier's "input" (relative to the input impedance of the amplifier) in order to account for the added noise observed following amplification.
Application to communication systems.
A communications system is typically made up of a transmitter, a communications channel, and a receiver. The communications channel may consist of a combination of different physical media, resulting in an electrical signal presented to the receiver. Whatever physical media a channel consists of, the transmitted signal will be attenuated and corrupted with additive noise.
The additive noise in a receiving system can be of thermal origin (thermal noise) or can be from other noise-generating processes. Most noise processes will have a white spectrum, at least over the bandwidth of interest, identical to that of thermal noise. Since they are indistinguishable, the contributions of all noise sources can be lumped together and regarded as a level of thermal noise. The noise power spectral density generated by all these sources (formula_10) can be described by assigning to the noise a temperature formula_11 as defined above:
In a wireless communications receiver, the equivalent input noise temperature formula_13 would equal the sum of two noise temperatures:
The antenna noise temperature formula_15 gives the noise power seen at the output of the antenna. The noise temperature of the receiver circuitry formula_16 represents noise generated by noisy components inside the receiver.
Note that formula_17 refers not to the noise at the output of the receiver after amplification, but the equivalent "input" noise power. In other words, the output of the receiver reflects that of a noiseless amplifier whose input had a noise level not of formula_18 but of formula_13. Thus the figure of merit of a communications system is not the noise level at the speaker of a radio, for instance, since that depends on the setting of the receiver's gain. Rather we ask how much noise the receiver "added" to the original noise level before its gain was applied. That additional noise level is formula_20. If a signal is present, then the decrease in signal to noise ratio incurred using the receiver system with a noise temperature of formula_16 is proportional to formula_22.
Noise figure.
One use of noise temperature is in the definition of a system's noise factor or noise figure. The noise factor specifies the increase in noise power (referred to the input of an amplifier) due to a component or system when its input noise temperature is formula_23.
formula_23 is customarily taken to be room temperature, 290 K. 
The noise factor (a linear term) is more often expressed as the "noise figure" (in decibels) using the conversion:
The noise figure can also be seen as the decrease in signal to noise ratio (SNR) caused by passing a signal through a system if the original signal had a noise temperature of 290 K. This is a common way of expressing the noise contributed by a radio frequency amplifier regardless of the amplifier's gain. For instance, assume an amplifier has a noise temperature 870 K and thus a noise figure of 6 dB. If that amplifier is used to amplify a source having a noise temperature of about room temperature (290 K), as many sources do, then the insertion of that amplifier would reduce the SNR of a signal by 6 dB. This simple relationship is frequently applicable where the source's noise is of thermal origin since a passive transducer will often have a noise temperature similar to 290 K.
However in many cases the input source's noise temperature is much higher, such as an antenna at lower frequencies where atmospheric noise dominates. Then there will be little degradation of the SNR. On the other hand a good satellite dish looking through the atmosphere into space (so that it sees a much lower noise temperature) would have the SNR of a signal degraded by "more" than 6 dB. In those cases a reference to the amplifier's noise temperature itself, rather than the noise figure defined according to room temperature, is more appropriate.
Noise temperature of an amplifier chain.
The noise temperature of an amplifier is commonly measured using the Y-factor method. If there are multiple amplifiers in cascade, the noise temperature of the cascade can be calculated using the Friis equation:
where
Therefore the amplifier chain can be modelled as a black box having a gain of formula_34 and a noise figure given by formula_35. In the usual case where the gains of the amplifier's stages are much greater than one, then it can be seen that the noise temperatures of the earlier stages have a much greater influence on the resulting noise temperature than those later in the chain. One can appreciate that the noise introduced by the first stage, for instance, is amplified by all of the stages whereas the noise introduced by later stages undergoes lesser amplification. Another way of looking at it is that the signal applied to a later stage already has a high noise level, due to amplification of noise by the previous stages, so that the noise contribution of that stage to that already amplified signal is of less significance.
This explains why the quality of a preamplifier or RF amplifier is of particular importance in an amplifier chain. In most cases only the noise figure of the first stage need be considered. However one must check that the noise figure of the second stage is not so high (or that the gain of the first stage is so low) that there is SNR degradation due to the second stage anyway. That will be a concern if the noise figure of the first stage plus that stage's gain (in decibels) is not much greater than the noise figure of the second stage.
One corollary of the Friis equation is that an attenuator prior to the first amplifier will degrade the noise figure due to the amplifier. For instance, if stage 1 represents a 6 dB attenuator so that formula_36, then formula_37. Effectively the noise temperature of the amplifier formula_38 has been quadrupled, in addition to the (smaller) contribution due to the attenuator itself formula_39 (usually room temperature if the attenuator is composed of resistors). An antenna with poor efficiency is an example of this principle, where formula_40 would represent the antenna's efficiency.

</doc>
<doc id="41421" url="https://en.wikipedia.org/wiki?curid=41421" title="Noise weighting">
Noise weighting

A noise weighting is a specific amplitude-vs.-frequency characteristic that is designed to allow subjectively valid measurement of noise. It emphasises the parts of the spectrum that are most important.
Usually, noise means audible noise, in audio systems, broadcast systems or telephone circuits. In this case the weighting is sometimes referred to as Psophometric weighting, though this term is best avoided because, although strictly a general term, the word Psophometric is sometimes assumed to refer to a particular weighting used in telecommunications.
A major use of noise weighting is in the measurement of residual noise in audio equipment, usually present as hiss or hum in quiet moments of programme material. The purpose of weighting here is to emphasise the parts of the audible spectrum that our ears perceive most readily, and attenuate the parts that contribute less to our perception of loudness, in order to get a measured figure that correlates well with subjective effect. 
The ITU-R 468 noise weighting was devised specifically for this purpose, and is widely used in broadcasting, especially in the UK and Europe. A-weighting is also used, especially in the USA, though this is only really valid for the measurement of tones, not noise, and is widely incorporated into sound level meters. 
In telecommunication, noise weightings are used by agencies concerned with public telephone service, and various standard curves are based on the characteristics of specific commercial telephone instruments, representing successive stages of technological development. The coding of commercial apparatus appears in the nomenclature of certain weightings. The same weighting nomenclature and units are used in military versions of commercial noise measuring sets.
Telecommunication measurements are made in lines terminated either by the measuring set or an instrument of the relevant class.

</doc>
<doc id="41425" url="https://en.wikipedia.org/wiki?curid=41425" title="Non-return-to-zero">
Non-return-to-zero

In telecommunication, a non-return-to-zero (NRZ) line code is a binary code in which ones are represented by one significant condition, usually a positive voltage, while zeros are represented by some other significant condition, usually a negative voltage, with no other neutral or rest condition. The pulses in NRZ have more energy than a return-to-zero (RZ) code, which also has an additional rest state beside the conditions for ones and zeros. NRZ is not inherently a self-clocking signal, so some additional synchronization technique must be used for avoiding bit slips; examples of such techniques are a run length limited constraint and a parallel synchronization signal.
For a given data signaling rate, i.e., bit rate, the NRZ code requires only half the baseband bandwidth required by the Manchester code (the passband bandwidth is the same). When used to represent data in an asynchronous communication scheme, the absence of a neutral state requires other mechanisms for bit synchronization when a separate clock signal is not available.
NRZ-Level itself is not a synchronous system but rather an encoding that can be used in either a synchronous or asynchronous transmission environment, that is, with or without an explicit clock signal involved. Because of this, it is not strictly necessary to discuss how the NRZ-Level encoding acts "on a clock edge" or "during a clock cycle" since all transitions happen in the given amount of time representing the actual or implied integral clock cycle. The real question is that of sampling—the high or low state will be received correctly provided the transmission line has stabilized for that bit when the physical line level is sampled at the receiving end.
However, it is helpful to see NRZ transitions as happening on the trailing (falling) clock edge in order to compare NRZ-Level to other encoding methods, such as the mentioned Manchester code, which requires clock edge information (is the XOR of the clock and NRZ, actually) see the difference between NRZ-Mark and NRZ-Inverted.
Unipolar non-return-to-zero level.
"One" is represented by a DC bias on the transmission line (conventionally positive), while "zero" is represented by the absence of bias - the line at 0 volts or grounded. For this reason it is also known as "on-off keying." In clock language, a "one" transitions to or remains at a biased level on the trailing clock edge of the previous bit, while "zero" transitions to or remains at no bias on the trailing clock edge of the previous bit. Among the disadvantages of unipolar NRZ is that it allows for long series without change, which makes synchronization difficult - although this is not unique to the unipolar case. One solution is to not send bytes without transitions. More critically, and unique to unipolar NRZ, are issues related to the presence of a transmitted DC level - the power spectrum of the transmitted signal does not approach zero at zero frequency. This leads to two significant problems - first, the transmitted DC power leads to higher power losses than other encodings and second, the presence of a DC signal component requires that the transmission line be DC coupled.
Bipolar non-return-to-zero level.
"One" is represented by one physical level (usually a positive voltage), while "zero" is represented by another level (usually a negative voltage). In clock language, in bipolar NRZ-Level the voltage "swings" from positive to negative on the trailing edge of the previous bit clock cycle.
An example of this is RS-232, where "one" is −12 V to −5 V and "zero" is +5 V to +12 V.
Non-return-to-zero space.
"One" is represented by no change in physical level, while "zero" is represented by a change in physical level. In clock language, the level transitions on the trailing clock edge of the previous bit to represent a "zero".
This "change-on-zero" is used by High-Level Data Link Control and USB. They both avoid long periods of no transitions (even when the data contains long sequences of 1 bits) by using zero-bit insertion. HDLC transmitters insert a 0 bit after five contiguous 1 bits (except when transmitting the frame delimiter '01111110'). USB transmitters insert a 0 bit after six consecutive 1 bits. The receiver at the far end uses every transition — both from 0 bits in the data and these extra non-data 0 bits — to maintain clock synchronization. The receiver otherwise ignores these non-data 0 bits.
Non-return-to-zero inverted.
Non return to zero, inverted (NRZI) is a method of mapping a binary signal to a physical signal for transmission over some transmission media. The two level NRZI signal has a transition at a clock boundary if the bit being transmitted is a logical 1, and does not have a transition if the bit being transmitted is a logical 0.
"One" is represented by a transition of the physical level, while "zero" has no transition. Also, NRZI might take the opposite convention, as in Universal Serial Bus (USB) signalling, when in Mode 1, in which a transition occurs when signaling zero, and a steady level when signaling a one. The transition occurs on the leading edge of the clock for the given bit. This distinguishes NRZI from NRZ-Mark.
However, even NRZI can have long series of zeros (or ones if transitioning on "zero"), and thus clock recovery can be difficult unless some form of run length limited (RLL) coding is used in addition to NRZI. Magnetic disk and tape storage devices generally use fixed-rate RLL codes, while USB uses bit stuffing, which inserts an additional 0 bit after 6 consecutive 1 bits, thus forcing a transition. While bit stuffing is efficient, it results in a variable data rate because it takes slightly longer to send a long string of 1 bits than it does to send a long string of 0 bits.

</doc>
<doc id="41426" url="https://en.wikipedia.org/wiki?curid=41426" title="Normalized frequency">
Normalized frequency

Normalized frequency can refer to:

</doc>
<doc id="41427" url="https://en.wikipedia.org/wiki?curid=41427" title="NS/EP telecommunications">
NS/EP telecommunications

NS/EP telecommunications is an abbreviation for "National Security or Emergency Preparedness telecommunications" of the United States. Telecommunications services that are used to maintain a state of readiness or to respond to and manage any event or crisis (local, national, or international) that causes or could cause injury or harm to the population, damage to or loss of property, or degrade or threaten the national security or emergency preparedness posture of the United States.
NS/EP telecommunications are managed and controlled by the National Communications System using Telecommunications Service Priority through both the Government Emergency Telecommunications Service and Wireless Priority Service.

</doc>
<doc id="41428" url="https://en.wikipedia.org/wiki?curid=41428" title="N-entity">
N-entity

In telecommunication, a "n"-entity is an active element in the "n"-th layer of the Open Systems Interconnection--Reference Model (OSI-RM) that (a) interacts directly with elements, "i.e.", entities, of the layer immediately above or below the "n"-th layer, (b) is defined by a unique set of rules, "i.e.", syntax, and information formats, including data and control formats, and (c) performs a defined set of functions. 
The "n" refers to any one of the 7 layers of the OSI-RM. 
In an existing layered open system, the "n" may refer to any given layer in the system. 
Layers are conventionally numbered from the lowest, "i.e.", the physical layer, to the highest, so that the -th layer is above the "n"-th layer and the -th layer is below.

</doc>
<doc id="41432" url="https://en.wikipedia.org/wiki?curid=41432" title="Numerical aperture">
Numerical aperture

In optics, the numerical aperture (NA) of an optical system is a dimensionless number that characterizes the range of angles over which the system can accept or emit light. By incorporating index of refraction in its definition, NA has the property that it is constant for a beam as it goes from one material to another, provided there is no optical power at the interface. The exact definition of the term varies slightly between different areas of optics. Numerical aperture is commonly used in microscopy to describe the acceptance cone of an objective (and hence its light-gathering ability and resolution), and in fiber optics, in which it describes the range of angles within which light that is incident on the fiber will be transmitted along it.
General optics.
In most areas of optics, and especially in microscopy, the numerical aperture of an optical system such as an objective lens is defined by
where is the index of refraction of the medium in which the lens is working (1.00 for air, 1.33 for pure water, and typically 1.52 for immersion oil; see also list of refractive indices), and is the maximal half-angle of the cone of light that can enter or exit the lens. In general, this is the angle of the real marginal ray in the system. Because the index of refraction is included, the NA of a pencil of rays is an invariant as a pencil of rays passes from one material to another through a flat surface. This is easily shown by rearranging Snell's law to find that is constant across an interface.
In air, the angular aperture of the lens is approximately twice this value (within the paraxial approximation). The NA is generally measured with respect to a particular object or image point and will vary as that point is moved. In microscopy, NA generally refers to object-space NA unless otherwise noted.
In microscopy, NA is important because it indicates the resolving power of a lens. The size of the finest detail that can be resolved is proportional to , where is the wavelength of the light. A lens with a larger numerical aperture will be able to visualize finer details than a lens with a smaller numerical aperture. Assuming quality (diffraction-limited) optics, lenses with larger numerical apertures collect more light and will generally provide a brighter image, but will provide shallower depth of field.
Numerical aperture is used to define the "pit size" in optical disc formats.
Increasing the magnification and the numerical aperture of the objective reduces the working distance, i.e. the distance between front lens and specimen.
Numerical aperture versus -number.
Numerical aperture is not typically used in photography. Instead, the angular aperture of a lens (or an imaging mirror) is expressed by the -number, written / or , which is defined as the ratio of the focal length to the diameter of the entrance pupil :
This ratio is related to the image-space numerical aperture when the lens is focused at infinity. Based on the diagram at the right, the image-space numerical aperture of the lens is:
The approximation holds when the numerical aperture is small, but it turns out that for well-corrected optical systems such as camera lenses, a more detailed analysis shows that is almost exactly equal to even at large numerical apertures. As Rudolf Kingslake explains, "It is a common error to suppose that the ratio [] is actually equal to , and not ... The tangent would, of course, be correct if the principal planes were really plane. However, the complete theory of the Abbe sine condition shows that if a lens is corrected for coma and spherical aberration, as all good photographic objectives must be, the second principal plane becomes a portion of a sphere of radius centered about the focal point". In this sense, the traditional thin-lens definition and illustration of f-number is misleading, and defining it in terms of numerical aperture may be more meaningful.
Working (effective) -number.
The -number describes the light-gathering ability of the lens in the case where the marginal rays on the object side are parallel to the axis of the lens. This case is commonly encountered in photography, where objects being photographed are often far from the camera. When the object is not distant from the lens, however, the image is no longer formed in the lens's focal plane, and the -number no longer accurately describes the light-gathering ability of the lens or the image-side numerical aperture. In this case, the numerical aperture is related to what is sometimes called the "working -number" or "effective -number".
The working -number is defined by modifying the relation above, taking into account the magnification from object to image:
where is the working -number, is the lens's magnification for an object a particular distance away, is the pupil magnification, and the NA is defined in terms of the angle of the marginal ray as before. The magnification here is typically negative, and the pupil magnification is most often assumed to be 1 — as Allen R. Greenleaf explains, "Illuminance varies inversely as the square of the distance between the exit pupil of the lens and the position of the plate or film. Because the position of the exit pupil usually is unknown to the user of a lens, the rear conjugate focal distance is used instead; the resultant theoretical error so introduced is insignificant with most types of photographic lenses."
In photography, the factor is sometimes written as , where represents the absolute value of the magnification; in either case, the correction factor is 1 or greater. The two equalities in the equation above are each taken by various authors as the definition of working -number, as the cited sources illustrate. They are not necessarily both exact, but are often treated as if they are.
Conversely, the object-side numerical aperture is related to the -number by way of the magnification (tending to zero for a distant object):
Laser physics.
In laser physics, the numerical aperture is defined slightly differently. Laser beams spread out as they propagate, but slowly. Far away from the narrowest part of the beam, the spread is roughly linear with distance—the laser beam forms a cone of light in the "far field". The relation used to define the NA of the laser beam is the same as that used for an optical system,
but is defined differently. Laser beams typically do not have sharp edges like the cone of light that passes through the aperture of a lens does. Instead, the irradiance falls off gradually away from the center of the beam. It is very common for the beam to have a Gaussian profile. Laser physicists typically choose to make the "divergence" of the beam: the far-field angle between the propagation direction and the distance from the beam axis for which the irradiance drops to times the wavefront total irradiance. The NA of a Gaussian laser beam is then related to its minimum spot size by
where is the vacuum wavelength of the light, and is the diameter of the beam at its narrowest spot, measured between the irradiance points ("Full width at maximum of the intensity"). This means that a laser beam that is focused to a small spot will spread out quickly as it moves away from the focus, while a large-diameter laser beam can stay roughly the same size over a very long distance. See also: Gaussian beam width.
Fiber optics.
A multi-mode optical fiber will only propagate light that enters the fiber within a certain cone, known as the acceptance cone of the fiber. The half-angle of this cone is called the acceptance angle, . For step-index multimode fiber in a given medium, the acceptance angle is determined only by the indices of refraction of the core, the cladding, and the medium:
where is the refractive index of the medium, is the refractive index of the fiber core, and is the refractive index of the cladding. While the core will accept light at higher angles, those rays will not totally reflect off the core–cladding interface, and so will not be transmitted to the other end of the fiber.
When a light ray is incident from a medium of refractive index n to the core of index at the maximum acceptance angle, Snell's law at the medium–core interface gives
From the geometry of the above figure we have:
where 
is the critical angle for total internal reflection.
Substituting for in Snell's law we get:
By squaring both sides 
Solving, we find the formula stated above:
This has the same form as the numerical aperture in other optical systems, so it has become common to "define" the NA of any type of fiber to be
where is the refractive index along the central axis of the fiber. Note that when this definition is used, the connection between the NA and the acceptance angle of the fiber becomes only an approximation. In particular, manufacturers often quote "NA" for single-mode fiber based on this formula, even though the acceptance angle for single-mode fiber is quite different and cannot be determined from the indices of refraction alone.
The number of bound modes, the mode volume, is related to the normalized frequency and thus to the NA.
In multimode fibers, the term "equilibrium numerical aperture" is sometimes used. This refers to the numerical aperture with respect to the extreme exit angle of a ray emerging from a fiber in which equilibrium mode distribution has been established.

</doc>
<doc id="41435" url="https://en.wikipedia.org/wiki?curid=41435" title="Nyquist rate">
Nyquist rate

In signal processing, the Nyquist rate, named after Harry Nyquist, is twice the bandwidth of a bandlimited function or a bandlimited channel. This term means two different things under two different circumstances: 
Nyquist rate relative to sampling.
When a continuous function, x(t), is sampled at a constant rate, fs "samples/second", there is always an unlimited number of other continuous functions that fit the same set of samples. But only one of them is bandlimited to ½ fs "cycles/second" (hertz), which means that its Fourier transform, X(f), is 0 for all |f| ≥ ½ fs.  The mathematical algorithms that are typically used to recreate a continuous function from samples create arbitrarily good approximations to this theoretical, but infinitely long, function. It follows that if the original function, x(t), is bandlimited to ½ fs, which is called the "Nyquist criterion", then it is the one unique function the interpolation algorithms are approximating. In terms of a function's own bandwidth (B), as depicted above, the Nyquist criterion is often stated as fs > 2B.  And 2B is called the Nyquist rate for functions with bandwidth B. When the Nyquist criterion is not met (B > ½ fs), a condition called aliasing occurs, which results in some inevitable differences between x(t) and a reconstructed function that has less bandwidth. In most cases, the differences are viewed as distortion.
Intentional aliasing.
Figure 1 depicts a type of function called baseband or lowpass, because its positive-frequency range of significant energy is [0, "B"). When instead, the frequency range is ("A", "A"+"B"), for some "A" > "B", it is called bandpass, and a common desire (for various reasons) is to convert it to baseband. One way to do that is frequency-mixing (heterodyne) the bandpass function down to the frequency range (0, "B"). One of the possible reasons is to reduce the Nyquist rate for more efficient storage. And it turns out that one can directly achieve the same result by sampling the bandpass function at a sub-Nyquist sample-rate that is the smallest integer-sub-multiple of frequency "A" that meets the baseband Nyquist criterion:  fs > 2"B". For a more general discussion, see bandpass sampling.
Nyquist rate relative to signaling.
Long before Harry Nyquist had his name associated with sampling, the term "Nyquist rate" was used differently, with a meaning closer to what Nyquist actually studied. Quoting Harold S. Black's 1953 book "Modulation Theory," in the section Nyquist Interval of the opening chapter "Historical Background:"
According to the OED, Black's statement regarding 2"B" may be the origin of the term "Nyquist rate".
Nyquist's famous 1928 paper was a study on how many pulses (code elements) could be transmitted per second, and recovered, through a channel of limited bandwidth. "Signaling at the Nyquist rate" meant putting as many code pulses through a telegraph channel as its bandwidth would allow. Shannon used Nyquist's approach when he proved the sampling theorem in 1948, but Nyquist did not work on sampling per se.
Black's later chapter on "The Sampling Principle" does give Nyquist some of the credit for some relevant math:

</doc>
<doc id="41437" url="https://en.wikipedia.org/wiki?curid=41437" title="Off-axis optical system">
Off-axis optical system

An off-axis optical system is an optical system in which the optical axis of the aperture is not coincident with the mechanical center of the aperture. Note: The principal applications of off-axis optical systems are to avoid obstruction of the primary aperture by secondary optical elements, instrument packages, or sensors, and to provide ready access to instrument packages or sensors at the focus. The engineering tradeoff of an off-axis optical system is an increase in image aberrations.

</doc>
<doc id="41438" url="https://en.wikipedia.org/wiki?curid=41438" title="Off-hook">
Off-hook

In telephony, the term off-hook has the following meanings:
On an ordinary two-wire telephone line, off-hook status is communicated to the telephone exchange by a resistance short across the pair. When an off-hook condition persists without dialing, for example because the handset has fallen off or the cable has been flooded, it is treated as a "permanent loop" or permanent signal.
The act of "going off-hook" is also referred to as "seizing" the line or channel.
Etymology.
Off-hook originally referred to the condition that prevailed when telephones had a separate earpiece ("i.e.", receiver), which hung from its switchhook until the user wished to activate it. The weight of the receiver no longer depresses the spring-loaded switchhook, thereby connecting the instrument to the telephone line.

</doc>
<doc id="41440" url="https://en.wikipedia.org/wiki?curid=41440" title="Online and offline">
Online and offline

The terms "online" and "offline" have specific meanings in regard to computer technology and telecommunications in which "online" indicates a state of connectivity, while "offline" indicates a disconnected state. Common vernacular extended from their computing and telecommunication meanings and refers specifically to an Internet connection. Lastly, in the area of human interaction and conversation, discussions taking place during a business meeting are "online", while issues that do not concern all participants of the meeting should be "taken offline"—continued outside of the meeting.
Definitions.
In computer technology and telecommunication, online and offline are defined by Federal Standard 1037C. They are states or conditions of a "device or equipment" or of a "functional unit". To be considered online, one of the following may apply to a system: it is under the direct control of another device; it is under the direct control of the system with which it is associated; or it is available for immediate use on demand by the system without human intervention.
In contrast, a device that is offline meets none of these criteria (e.g., its main power source is disconnected or turned off, or it is off-power).
The Oxford dictionary defines "online" (sometimes also referenced as "On the Line") as "controlled by or connected to a computer" and as an activity or service which is "available on or performed using the Internet or other computer network". The term is utilized within terms such as these: "online identity", "online predator", "online gambling", "online shopping", "online banking", and "online learning". The online context is given to other words by the prefixes "cyber" and "e", as in the words "cyberspace", "cybercrime", "email", and "ecommerce".
Antecedents.
During the 19th century, the term "on line" was commonly used in both the railroad and telegraph industries. For railroads, a signal box would send a messages down the line (track), via a telegraph line (cable), indicating the track's status: "Train on line" or "Line clear". Telegraph linemen would refer to sending current through a line as "direct on line" or "battery on line"; or they may refer to a problem with the circuit as being "on line", as opposed to the power source or end-point equipment.
Examples.
Offline email.
One example of a common use of these concepts with email is a mail user agent (MUA) that can be instructed to be in either online or offline states. One such MUA is Microsoft Outlook. When online it will attempt to connect to mail servers (to check for new mail at regular intervals, for example), and when offline it will not attempt to make any such connection. The online or offline state of the MUA does not necessarily reflect the connection status between the computer on which it is running and the Internet. That is, the computer itself may be online—connected to Internet via a cable modem or other means—while Outlook is kept offline by the user, so that it makes no attempt to send or to receive messages. Similarly, a computer may be configured to employ a dial-up connection on demand (as when an application such as Outlook attempts to make connection to a server), but the user may not wish for Outlook to trigger that call whenever it is configured to check for mail.
Offline media playing.
Another example of the use of these concepts is digital audio technology. A tape recorder, digital audio editor, or other device that is online is one whose clock is under the control of the clock of a synchronization master device. When the sync master commences playback, the online device automatically synchronizes itself to the master and commences playing from the same point in the recording. A device that is offline uses no external clock reference and relies upon its own internal clock. When a large number of devices are connected to a sync master it is often convenient, if one wants to hear just the output of one single device, to take it offline because, if the device is played back online, all synchronized devices have to locate the playback point and wait for each other device to be in synchronization. (For related discussion, see MIDI timecode, word sync, and recording system synchronization.)
Offline browsing.
A third example of a common use of these concepts is a web browser that can be instructed to be in either online or offline states. The browser attempts to fetch pages from servers while only in the online state. In the offline state, users can perform offline browsing, where pages can be browsed using local copies of those pages that have previously been downloaded while in the online state. This can be useful when the computer is offline and connection to the Internet is impossible or undesirable. The pages are downloaded either implicitly into the web browser's own cache as a result of prior online browsing by the user or explicitly by a browser configured to keep local copies of certain web pages, which are updated when the browser is in the online state, either by checking that the local copies are up-to-date at regular intervals or by checking that the local copies are up-to-date whenever the browser is switched to the online state. One such web browser capable of being explicitly configured to download pages for offline browsing is Internet Explorer. When pages are added to the Favourites list, they can be marked to be "available for offline browsing". Internet Explorer will download to local copies both the marked page and, optionally, all of the pages that it links to. In Internet Explorer version 6, the level of direct and indirect links, the maximum amount of local disc space allowed to be consumed, and the schedule on which local copies are checked to see whether they are up-to-date, are configurable for each individual Favourites entry.
For communities that lack adequate Internet connectivity—such as developing countries, rural areas, and prisons—offline information stores such as the eGranary Digital Library (a collection of approximately thirty million educational resources from more than two thousand web sites and hundreds of CD-ROMs) provide offline access to information. Numerous organizations have developed, or are developing, flash memory chips with collections of educational materials for offline use in smartphones, tablets, and laptops.
Offline storage.
Likewise, offline storage is computer data storage that is not "available for immediate use on demand by the system without human intervention." Additionally, an otherwise online system that is powered down may be considered offline.
Offline messages.
With the growing communication tools and media, the words offline and online are used very frequently. If a person is active over a messaging tool and is able to accept the messages it is termed as online message and if the person is not available and the message is left to view when the person is back, it is termed as offline message. In the same context, the person's availability is termed as online and non availability is termed as offline
Generalizations.
Online and offline distinctions have been generalized from computing and telecommunication into the field of human interpersonal relationships. The distinction between what is considered online and what is considered offline has become a subject of study in the field of sociology.
The distinction between online and offline is conventionally seen as the distinction between computer-mediated communication and face-to-face communication (e.g., face time), respectively. Online is virtuality or cyberspace, and offline is reality (i.e., Real life or meatspace). Slater states that this distinction is "obviously far too simple". To support his argument that the distinctions in relationships are more complex than a simple dichotomy of online versus offline, he observes that some people draw no distinction between an online relationship, such as indulging in cybersex, and an offline relationship, such as being pen pals. He argues that even the telephone can be regarded as an online experience in some circumstances, and that the blurring of the distinctions between the uses of various technologies (such as PDA versus mobile phone, Internet television versus Internet, and telephone versus Voice over Internet Protocol) has made it "impossible to use the term "online" meaningfully in the sense that was employed by the first generation of Internet research".
Slater asserts that there are legal and regulatory pressures to reduce the distinction between online and offline, with a "general tendency to assimilate online to offline and erase the distinction," stressing, however, that this does not mean that online relationships are being reduced to "pre-existing" offline relationships. He conjectures that greater legal status may be assigned to online relationships (pointing out that contractual relationships, such as business transactions, online are already seen as just as "real" as their offline counterparts), although he states it to be hard to imagine courts awarding palimony to people who have had a purely online sexual relationship. He also conjectures that an online/offline distinction may be seen by people as "rather quaint and not quite comprehensible" within 10 years.
This distinction between "online" and "offline" is sometimes inverted, with online concepts being used to define and to explain offline activities, rather than (as per the conventions of the desktop metaphor with its desktops, trash cans, folders, and so forth) the other way around. Several cartoons appearing in "The New Yorker" have satirized this. One includes Saint Peter asking for a username and a password before admitting a man into Heaven. Another illustrates "the off-line store" where "All items are actual size!", shoppers may "Take it home as soon as you pay for it!", and "Merchandise may be handled prior to purchase!"

</doc>
<doc id="41441" url="https://en.wikipedia.org/wiki?curid=41441" title="Off-the-air">
Off-the-air

In telecommunication, the term off-air or off-the-air has the following meanings:
"Note": The carrier wave may continue unmodulated or it may be modulated by another signal source, such as a subcarrier.
Also, off-the-air may be synonymous with over-the-air or from-the-air, as in picking up a terrestrial broadcast TV station off-the-air instead of from cable TV. As this usage may be confusing due to the term's other meanings, the terms "over the air" or "on the air" are more standard in the broadcasting industry.

</doc>
<doc id="41442" url="https://en.wikipedia.org/wiki?curid=41442" title="One-way trunk">
One-way trunk

In telecommunication, a one-way trunk is a trunk between two switching centers, over which traffic may be originated from one preassigned location only. 
"Note 1:" The traffic may consist of two-way communications; the expression ""one way"" refers only to the origin of the demand for a connection. 
"Note 2:" At the originating end, the one-way trunk is known as an ""outgoing trunk"" ; at the other end, it is known as an ""incoming trunk"." 
References.
See also: Telephone signaling interface

</doc>
<doc id="41443" url="https://en.wikipedia.org/wiki?curid=41443" title="On-hook">
On-hook

In telephony, the term on-hook has the following meanings: 
The act of "going on-hook" is also referred to as "releasing the line" or "channel", and may initiate the process of clearing.

</doc>
<doc id="41445" url="https://en.wikipedia.org/wiki?curid=41445" title="On-premises wiring">
On-premises wiring

On-premises wiring (customer premises wiring) is customer-owned telecommunication transmission or distribution lines. The transmission lines may be metallic (copper) or optical fiber, and may be installed within or between buildings.
Premises wiring may consist of horizontal wiring, vertical wiring, and backbone cabling. It may extend from the point-of-entry to user work areas. Any type of communications or data wiring is considered premises wiring, including telephone, computer/data, intercom, closed-circuit television.
Premises networks are wired worldwide, across every industry, in both small and large scale applications. Any type or number of topologies may be used -- star, bus, ring, etc.
Ownership.
The ownership of on-premises wiring varies between jurisdictions: It depends on the location of the demarcation point. The location determines ownership and responsibility for maintenance and repair.
In the United States and Canada, most premises wiring is owned by the customer. There generally is a demarcation point "as close to the poles" as possible. For many installations, this is a network interface device mounted on the outside of the building. In some cases, it is a minimum-point-of-entry (MPOE) location inside the building.
In the United Kingdom, the demarcation point is the wall jack, and hence most of the on-premises wiring is the property of the telephone company.

</doc>
<doc id="41448" url="https://en.wikipedia.org/wiki?curid=41448" title="Open network architecture">
Open network architecture

In telecommunications, and in the context of Federal Communications Commission's (FCC) Computer Inquiry III, Open network architecture (ONA) is the overall design of a communication carrier's basic network facilities and services to permit all users of the basic network to interconnect to specific basic network functions and interfaces on an unbundled, equal-access basis.
The ONA concept consists of three integral components:

</doc>
<doc id="41449" url="https://en.wikipedia.org/wiki?curid=41449" title="Open systems architecture">
Open systems architecture

Open systems architecture, in telecommunication, is a standard that describes the layered hierarchical structure, configuration, or model of a communications or distributed data processing system that:
Open systems architecture may be implemented using the OSI Model as a guide while designing the system to meet performance requirements.

</doc>
<doc id="41453" url="https://en.wikipedia.org/wiki?curid=41453" title="Operation">
Operation

Operation or Operations may refer to:

</doc>
<doc id="41455" url="https://en.wikipedia.org/wiki?curid=41455" title="Optical attenuator">
Optical attenuator

An optical attenuator , or fiber optic attenuator, is a device used to reduce the power level of an optical signal, either in free space or in an optical fiber. The basic types of optical attenuators are fixed, step-wise variable, and continuously variable.
Applications.
Optical attenuators are commonly used in fiber optic communications, either to test power level margins by temporarily adding a calibrated amount of signal loss, or installed permanently to properly match transmitter and receiver levels. Sharp bends stress optic fibers and can cause losses. If a received signal is too strong a temporary fix is to wrap the cable around a pencil until the desired level of attenuation is achieved. However, such arrangements are unreliable, since the stressed fiber tends to break over time.
Priniciples of operation.
The power reduction is done by such means as absorption, reflection, diffusion, scattering, deflection, diffraction, and dispersion, etc. Optical attenuators usually work by absorbing the light, like sunglasses absorb extra light energy. They typically have a working wavelength range in which they absorb the light energy equally. They should not reflect the light since that could cause unwanted back reflection in the fiber system. Or by scattering the light such as an air gap. Another type of attenuator utilizes a length of high-loss optical fiber, that operates upon its input optical signal power level in such a way that its output signal power level is less than the input level. 
Types.
Optical attenuators can take a number of different forms and are typically classified as fixed or variable attenuators. What's more, they can be classified as LC, SC, ST, FC, MU, E2000 etc. according to the different types of connectors.
Fixed Attenuators.
Fixed optical attenuators used in fiber optic systems may use a variety of principles for their functioning. Preferred attenuators use either doped fibers, or mis-aligned splices,or total power since both of these are reliable and inexpensive.
"Inline" style attenuators are incorporated into patch cables. The alternative "build out" style attenuator is a small male-female adapter that can be added onto other cables.
Non-preferred attenuators often use gap loss or reflective principles. Such devices can be sensitive to: modal distribution, wavelength, contamination, vibration, temperature, damage due to power bursts, may cause back reflections, may cause signal dispersion etc.
Loopback attenuators.
Loopback fiber optic attenuator is designed for testing, engineering and the burn-in stage of boards or other equipment. Available in SC/UPC, SC/APC, LC/UPC, LC/APC, MTRJ, MPO for singlemode application.900um fiber cable inside of the black shell for LC and SC type.
No black shell for MTRJ and MPO type.
Built-in variable attenuators.
Built-in variable optical attenuators may be either manually or electrically controlled. A manual device is useful for one-time set up of a system, and is a near-equivalent to a fixed attenuator, and may be referred to as an "adjustable attenuator". In contrast, an electrically controlled attenuator can provide adaptive power optimization.
Attributes of merit for electrically controlled devices, include speed of response and avoiding degradation of the transmitted signal. Dynamic range is usually quite restricted, and power feedback may mean that long term stability is a relatively minor issue. Speed of response is a particularly major issue in dynamically reconfigurable systems, where a delay of one millionth of a second can result in the loss of large amounts of transmitted data. Typical technologies employed for high speed response include LCD, or Lithium niobate devices. There is a class of built-in attenuators that is technically indistinguishable from test attenuators, except they are packaged for rack mounting, and have no test display.
Variable optical test attenuators.
Variable optical test attenuators generally use a variable neutral density filter. Despite relatively high cost, this arrangement has the advantages of being stable, wavelength insensitive, mode insensitive, and offering a large dynamic range. Other schemes such as LCD, variable air gap etc. have been tried over the years, but with limited success.
They may be either manually or motor controlled. Motor control give regular users a distinct productivity advantage, since commonly used test sequences can be run automatically. 
Attenuator instrument calibration is a major issue. The user typically would like an absolute port to port calibration. Also, calibration should usually be at a number of wavelengths and power levels, since the device is not always linear. However a number of instruments do not in fact offer these basic features, presumably in an attempt to reduce cost. The most accurate variable attenuator instruments have thousands of calibration points, resulting in excellent overall accuracy in use.
Test automation.
Test sequences that use variable attenuators, can be very time consuming. Therefore, automation is likely to achieve useful benefits. Both bench and handheld style devices are available that offer such features.

</doc>
<doc id="41456" url="https://en.wikipedia.org/wiki?curid=41456" title="Optical axis">
Optical axis

An optical axis is a line along which there is some degree of rotational symmetry in an optical system such as a camera lens or microscope. 
The optical axis is an imaginary line that defines the path along which light propagates through the system, up to first approximation. For a system composed of simple lenses and mirrors, the axis passes through the center of curvature of each surface, and coincides with the axis of rotational symmetry. The optical axis is often coincident with the system's mechanical axis, but not always, as in the case of off-axis optical systems.
For an optical fiber, the optical axis is along the center of the fiber core, and is also known as the "fiber axis".

</doc>
<doc id="41458" url="https://en.wikipedia.org/wiki?curid=41458" title="Optical disc">
Optical disc

In computing and optical disc recording technologies, an optical disc (OD) is a flat, usually circular disc which encodes binary data (bits) in the form of pits (binary value of 0 or off, due to lack of reflection when read) and lands (binary value of 1 or on, due to a reflection when read) on a special material (often aluminium ) on one of its flat surfaces. The encoding material sits atop a thicker substrate (usually polycarbonate) which makes up the bulk of the disc and forms a dust defocusing layer. The encoding pattern follows a continuous, spiral path covering the entire disc surface and extending from the innermost track to the outermost track. The data is stored on the disc with a laser or stamping machine, and can be accessed when the data path is illuminated with a laser diode in an optical disc drive which spins the disc at speeds of about 200 to 4,000 RPM or more, depending on the drive type, disc format, and the distance of the read head from the center of the disc (inner tracks are read at a higher disc speed). Most optical discs exhibit a characteristic iridescence as a result of the diffraction grating formed by its grooves. This side of the disc contains the actual data and is typically coated with a transparent material, usually lacquer. The reverse side of an optical disc usually has a printed label, sometimes made of paper but often printed or stamped onto the disc itself. Unlike the 3½-inch floppy disk, most optical discs do not have an integrated protective casing and are therefore susceptible to data transfer problems due to scratches, fingerprints, and other environmental problems.
Optical discs are usually between 7.6 and 30 cm (3 to 12 in) in diameter, with 12 cm (4.75 in) being the most common size. A typical disc is about 1.2 mm (0.05 in) thick, while the track pitch (distance from the center of one track to the center of the next) ranges from 1.6 µm (for CDs) to 320 nm (for Blu-ray discs).
An optical disc is designed to support one of three recording types: read-only (e.g.: CD and CD-ROM), recordable (write-once, e.g. CD-R), or re-recordable (rewritable, e.g. CD-RW). Write-once optical discs commonly have an organic dye recording layer between the substrate and the reflective layer. Rewritable discs typically contain an alloy recording layer composed of a phase change material, most often AgInSbTe, an alloy of silver, indium, antimony, and tellurium.
Optical discs are most commonly used for storing music (e.g. for use in a CD player), video (e.g. for use in a Blu-ray player), or data and programs for personal computers (PC). The Optical Storage Technology Association (OSTA) promotes standardized optical storage formats. Although optical discs are more durable than earlier audio-visual and data storage formats, they are susceptible to environmental and daily-use damage. Libraries and archives enact optical media preservation procedures to ensure continued usability in the computer's optical disc drive or corresponding disc player.
For computer data backup and physical data transfer, optical discs such as CDs and DVDs are gradually being replaced with faster, smaller solid-state devices, especially the USB flash drive. This trend is expected to continue as USB flash drives continue to increase in capacity and drop in price. Additionally, music purchased or shared over the Internet has significantly reduced the number of audio CDs sold annually.
History.
American inventor James T. Russell has been credited with inventing the first system to record a digital signal on an optical transparent foil which is lit from behind by a high-power halogen lamp. Russell's patent application was first filed in 1966 and he was granted a patent in 1970. Following litigation, Sony and Philips licensed Russell's patents (then held by a Canadian company, Optical Recording Corp.) in the 1980s.
Both Gregg's and Russell's disc are floppy media read in transparent mode, which impose serious drawbacks. In the Netherlands in 1969, Philips Research physicist, Pieter Kramer invented an optical videodisc in reflective mode with a protective layer read by a focused laser beam , filed 1972, issued 1991. Kramer's physical format is used in all optical discs. In 1975, Philips and MCA began to work together, and in 1978, commercially much too late, they presented their long-awaited Laserdisc in Atlanta. MCA delivered the discs and Philips the players. However, the presentation was a commercial failure, and the cooperation ended.
In Japan and the U.S., Pioneer succeeded with the videodisc until the advent of the DVD. In 1979, Philips and Sony, in consortium, successfully developed the audio compact disc.
In the mid-1990s, a consortium of manufacturers developed the second generation of the optical disc, the DVD.
Magnetic disks found limited applications in storing the data in large amount. So, there was the need of finding some more data storing techniques. As a result, it was found that by using optical means large data storing devices can be made which in turn gave rise to the optical discs.The very first application of this kind was the Compact Disc (CD) which was used in audio systems.
Sony and Philips developed the first generation of the CDs in the mid 1980s with the complete specifications for these devices. With the help of this kind of technology the possibility of representing the analog signal into digital signal was exploited to great level. For this purpose the 16 bit samples of the analog signal were taken at the rate of 44,100 samples per second. This sample rate was based on the Nyquist rate of 40,000 samples per second required to capture the audible frequency range to 20 kHz without aliasing, with an additional tolerance to allow the use of less-than-perfect analog audio pre-filters to remove any higher frequencies. The first version of the standard allowed up to 75 minutes of music which required 650MB of storage.
The third generation optical disc was developed in 2000–2006, and was introduced as Blu-ray Disc. First movies on Blu-ray Discs were released in June 2006. Blu-ray eventually prevailed in a high definition optical disc format war over a competing format, the HD DVD. A standard Blu-ray disc can hold about 25 GB of data, a DVD about 4.7 GB, and a CD about 700 MB.
First-generation.
Initially, optical discs were used to store music and computer software. The Laserdisc format stored analog video signals for the distribution of home video, but commercially lost to the VHS videocassette format, due mainly to its high cost and non-re-recordability; other first-generation disc formats were designed only to store digital data and were not initially capable of use as a digital video medium.
Most first-generation disc devices had an infrared laser reading head. The minimum size of the laser spot is proportional to the wavelength of the laser, so wavelength is a limiting factor upon the amount of information that can be stored in a given physical area on the disc. The infrared range is beyond the long-wavelength end of the visible light spectrum, so it supports less density than shorter-wavelength visible light. One example of high-density data storage capacity, achieved with an infrared laser, is 700 MB of net user data for a 12 cm compact disc.
Other factors that affect data storage density include: the existence of multiple layers of data on the disc, the method of rotation (Constant linear velocity (CLV), Constant angular velocity (CAV), or zoned-CAV), the composition of lands and pits, and how much margin is unused is at the center and the edge of the disc.
Second-generation.
Second-generation optical discs were for storing great amounts of data, including broadcast-quality digital video. Such discs usually are read with a visible-light laser (usually red); the shorter wavelength and greater numerical aperture allow a narrower light beam, permitting smaller pits and lands in the disc. In the DVD format, this allows 4.7 GB storage on a standard 12 cm, single-sided, single-layer disc; alternatively, smaller media, such as the DataPlay format, can have capacity comparable to that of the larger, standard compact 12 cm disc.
Third-generation.
Third-generation optical discs are in development, meant for distributing high-definition video and support greater data storage capacities, accomplished with short-wavelength visible-light lasers and greater numerical apertures. Blu-ray Disc and HD DVD uses blue-violet lasers and focusing optics of greater aperture, for use with discs with smaller pits and lands, thereby greater data storage capacity per layer.
In practice, the effective multimedia presentation capacity is improved with enhanced video data compression codecs such as H.264/MPEG-4 AVC and VC-1.
Fourth-generation.
The following formats go beyond the current third-generation discs and have the potential to hold more than one terabyte (1 TB) of data:
Recordable and writable optical discs.
There are numerous formats of optical direct to disk recording devices on the market, all of which are based on using a laser to change the reflectivity of the digital recording medium in order to duplicate the effects of the pits and lands created when a commercial optical disc is pressed.
Formats such as CD-R and DVD-R are "Write once read many", while CD-RW and DVD-RW are rewritable, more like a magnetic recording hard disk drive (HDD).
Media technologies vary, M-DISC uses a different recording technique & media versus DVD-R and BD-R.

</doc>
<doc id="41459" url="https://en.wikipedia.org/wiki?curid=41459" title="Normandie-Niemen">
Normandie-Niemen

The Normandie-Niemen Regiment () is a fighter squadron, later regiment (of three squadrons) of the French Air Force. It served on the Eastern Front of the European Theatre of World War II with the 1st Air Army. The regiment is notable for being one of only two air combat units from an Allied western European country to participate on the Eastern Front during World War II, the other being the British No. 151 Wing RAF, and the only one to fight together with the Soviets until the end of the war in Europe.
The unit originated in mid-1943 during World War II. Initially the "groupe" comprised a group of French fighter pilots sent to aid Soviet forces on the Eastern Front at the suggestion of Charles de Gaulle, leader of the Free French Forces, who felt it important that French servicemen serve on all fronts in the war.
"Groupe de Chasse 3" (GC 3) (3rd Fighter Group) in the Free French Air Force, first commanded by Jean Tulasne, fought in three campaigns on behalf of the Soviet Union between 22 March 1943, and 9 May 1945, during which time it destroyed 273 enemy aircraft and received numerous orders, citations and decorations from both France and the Soviet Union, including the French "Légion d’Honneur" and the Soviet Order of the Red Banner. Joseph Stalin awarded the unit the name Niemen for its participation in the Battle of the Niemen River (1944).
Operational history.
Six months after the Germans invaded the USSR in June 1941, talks aimed at closer co-operation between Free France and the Soviet Union resulted in setting up a special squadron with an initial core of 12 fighter pilots and 47 ground staff for service on the Russo-German front. De Gaulle officially promulgated the "Groupe de Chasse" GC 3 "Normandie" on 1 September 1942, with "Commandant" Pouliquen in command. Mechanics, pilots and hardware travelled by rail and air via Tehran (Iran) to Baku ( the capital of Azerbaijan). They completed a period of training on the Yakovlev Yak-7 by the end of January 1943, when "Commandant" Jean Tulasne took command of the "groupe". The unit became operational on 22 March 1943.
The first campaign of GC 3, equipped with the Yakovlev Yak-1 fighter, lasted until 5 October, and saw combat between Polotniani-Zavod and Sloboda/Monostirtchina. From an initial aerial victory over a Focke-Wulf Fw 190 on 5 April their tally rose dramatically and the squadron became the focus of Soviet propaganda, so much so that "Generalfeldmarschall" Wilhelm Keitel decreed that any French pilot captured would be executed.
Tulasne was killed in combat on 17 July, and "Commandant" Pierre Pouyade took command. On 11 October de Gaulle accorded the "groupe" the title of "Compagnon de la Libération". By the time GC 3 relocated to Tula on 6 November 1943, only six pilots remained from the original "groupe", which had accumulated 72 aerial victories since becoming operational. In their first year on the front they claimed 86 kills (77 confirmed, 9 'probables') and 16 enemy aircraft damaged, for the loss of 25 Yak fighters.
In 1944 the "groupe" was expanded to become a "régiment", with a fourth "escadrille" joining its ranks. After completing training on the more advanced Yakovlev Yak-9D fighter at Tula, the expanded regiment rejoined front line operations for its second campaign. This took place around Doubrovka (in Russia) and Gross-Kalweitchen (in East Prussia, Germany) until 27 November 1944. During this campaign Joseph Stalin ordered the regiment to style itself "Normandie-Niemen" in recognition of its participation in the battles to liberate the river of the same name. On 16 October, the first day of a new offensive against East Prussia, the regiment’s pilots claimed 29 enemy aircraft destroyed without loss. By the following month the regiment found itself based in German territory. By the end of the year, Pouyade was released from command of the regiment and he, along with other veteran pilots, returned to France. He was replaced by Commandant Louis Delfino. By the end of 1944 201 kills have been claimed.
14 January 1945 saw the "Normandie-Niemen" start its third campaign (from Dopenen to Heiligenbeil), concentrating in the East Prussian part of the German "Reich", until the formal announcement of victory in the east on 9 May the day after V-E Day in Europe. The USSR expressed its gratitude to the regiment by offering 37 of the unit’s Yak-3 fighters as a gift to France. The pilots returned to a heroes' welcome in Paris on 20 June 1945.
At the end of the war, the regiment had claimed 273 enemy aircraft shot down, 37 probables, and lost 87 aircraft and 52 pilots in return. Some 5,240 sorties were flown and the unit took part in 869 dogfights. The unit also destroyed 27 trains, 22 locomotives, two E-boats, 132 trucks, and 24 staff cars. Forty-two of the squadron's pilots were killed and 30 reached ace status.
Four of its pilots, Marcel Albert, Marcel Lefèvre, Jacques André and Roland de La Poype, became Heroes of the Soviet Union.
Its battle honours included such names such as Bryansk, Orel, Ielnia, Smolensk, Königsberg (later renamed Kaliningrad by the Soviets), and Pillau. It received the following decorations: from France, the "Légion d'Honneur", the "Croix de la Libération", the "Médaille Militaire", the "Croix de guerre" with six "palmes"; from the USSR, it received the Order of the Red Banner and the Order of Alexander Nevsky, with eleven citations between the two orders.
The squadron's last Yak-3 fighter is on static display at the Le Bourget Air and Space Museum.
Popular culture.
The 1960 Franco-Russian film "Normandie-Niemen" directed by Jean Dréville and Damir Viatich-Berejnykh, relates the arrival in Russia of the first twenty pilots for intensive training and the formation of the squadron.
In the Yuri Bondarev 1970-1971 "Liberation" film dramatization of the course of the war from the Battle of Kursk to the Battle of Berlin, the "Normandie-Niemen" makes an appearance. Pierre Pouyade is portrayed by Italian actor Erno Bertoli.
Character Lieutenant Duroc (Patrick Chauvel) accounts his battles as Normandie-Niemen Free French fighter in Pierre Schoendoerffer's 1992 movie "Dien Bien Phu".

</doc>
<doc id="41460" url="https://en.wikipedia.org/wiki?curid=41460" title="Optical isolator">
Optical isolator

An optical isolator, or optical diode, is an optical component which allows the transmission of light in only one direction. It is typically used to prevent unwanted feedback into an optical oscillator, such as a laser cavity. The operation of the device depends on the Faraday effect (which in turn is produced by magneto-optic effect), which is used in the main component, the Faraday rotator.
Theory.
The main component of the optical isolator is the Faraday rotator. The magnetic field, formula_1, applied to the Faraday rotator causes a rotation in the polarization of the light due to the Faraday effect. The angle of rotation, formula_2, is given by,
where, formula_4 is the Verdet constant of the material (amorphous or crystalline; solid, liquid, or gaseous) of which the rotator is made, and formula_5 is the length of the rotator. This is shown in Figure 2. Specifically for an optical isolator, the values are chosen to give a rotation of 45°.
It has been shown that a crucial requirement for any kind of optical isolator (not only the Faraday isolator) is some kind of non-reciprocal optics 
Polarization dependent isolator.
The polarization dependent isolator, or Faraday isolator, is made of three parts, an input polarizer (polarized vertically), a Faraday rotator, and an output polarizer, called an analyser (polarized at 45°).
Light traveling in the forward direction becomes polarized vertically by the input polarizer. The Faraday rotator will rotate the polarization by 45°. The analyser then enables the light to be transmitted through the isolator.
Light traveling in the backward direction becomes polarized at 45° by the analyser. The Faraday rotator will again rotate the polarization by 45°. This means the light is polarized horizontally (the rotation is sensitive to direction of propagation). Since the polarizer is vertically aligned, the light will be extinguished.
Figure 2 shows a Faraday rotator with an input polarizer, and an output analyser. For a polarization dependent isolator, the angle between the polarizer and the analyser, formula_2, is set to 45°. The Faraday rotator is chosen to give a 45° rotation.
Polarization dependent isolators are typically used in free space optical systems. This is because the polarization of the source is typically maintained by the system. In optical fibre systems, the polarization direction is typically dispersed in non polarization maintaining systems. Hence the angle of polarization will lead to a loss.
Polarization independent isolator.
The polarization independent isolator is made of three parts, an input birefringent wedge (with its ordinary polarization direction vertical and its extraordinary polarization direction horizontal), a Faraday rotator, and an output birefringent wedge (with its ordinary polarization direction at 45°, and its extraordinary polarization direction at −45°).
Light traveling in the forward direction is split by the input birefringent wedge into its vertical (0°) and horizontal (90°) components, called the ordinary ray (o-ray) and the extraordinary ray (e-ray) respectively. The Faraday rotator rotates both the o-ray and e-ray by 45°. This means the o-ray is now at 45°, and the e-ray is at −45°. The output birefringent wedge then recombines the two components.
Light traveling in the backward direction is separated into the o-ray at 45, and the e-ray at −45° by the birefringent wedge. The Faraday Rotator again rotates both the rays by 45°. Now the o-ray is at 90°, and the e-ray is at 0°. Instead of being focused by the second birefringent wedge, the rays diverge.
Typically collimators are used on either side of the isolator. In the transmitted direction the beam is split and then combined and focused into the output collimator. In the isolated direction the beam is split, and then diverged, so it does not focus at the collimator.
Figure 3 shows the propagation of light through a polarization independent isolator. The forward travelling light is shown in blue, and the backward propagating light is shown in red. The rays were traced using an ordinary refractive index of 2, and an extraordinary refractive index of 3. The wedge angle is 7°.
The Faraday rotator.
The most important optical element in an isolator is the Faraday rotator. The characteristics that one looks for in a Faraday rotator optic include a high Verdet constant, low absorption coefficient, low non-linear refractive index and high damage threshold. Also, to prevent self-focusing and other thermal related effects, the optic should be as short as possible. The two most commonly used materials for the 700–1100 nm range are terbium doped borosilicate glass and terbium gallium garnet crystal (TGG). For long distance fibre communication, typically at 1310 nm or 1550 nm, yttrium iron garnet crystals are used (YIG). Commercial YIG based Faraday isolators reach isolations higher than 30 dB.
Optical isolators are different from 1/4 wave plate based isolators because the Faraday rotator provides non-reciprocal rotation while maintaining linear polarization. That is, the polarization rotation due to the Faraday rotator is always in the same relative direction. So in the forward direction, the rotation is positive 45°. In the reverse direction, the rotation is −45°. This is due to the change in the relative magnetic field direction, positive one way, negative the other. This then adds to a total of 90° when the light travels in the forward direction and then the negative direction. This allows the higher isolation to be achieved.
Optical isolators and thermodynamics.
It might seem at first glance that a device that allows light to flow in only one direction would violate Kirchhoff's law and the second law of thermodynamics, by allowing light energy to flow from a cold object to a hot object and blocking it in the other direction, but the violation is avoided because the isolator must absorb (not reflect) the light from the hot object and will eventually reradiate it to the cold one. Attempts to re-route the photons back to their source unavoidably involve creating a route by which other photons can travel from the hot body to the cold one, avoiding the paradox.

</doc>
<doc id="41461" url="https://en.wikipedia.org/wiki?curid=41461" title="Optical path length">
Optical path length

In optics, optical path length (OPL) or optical distance is the product of the geometric length of the path light follows through the system, and the index of refraction of the medium through which it propagates. A difference in optical path length between two paths is often called the optical path difference (OPD). Optical path length is important because it determines the phase of the light and governs interference and diffraction of light as it propagates.
Optical path difference (OPD).
"Optical path difference" corresponds to the phase shift which happens between two previously coherent sources when passed through different mediums. For example a wave passed through glass will appear to travel a greater distance than an identical wave in air. This is because the source in the glass will have experienced a greater number of wavelengths due to the higher refractive index of the glass.
The OPD can be calculated from the following equation:
where "d"1 and "d"2 are the distances of the ray passing through medium 1 or 2, "n"1 is the greater refractive index (e.g., glass) and "n"2 is the smaller refractive index (e.g., air).
Details.
In a medium of constant refractive index, "n", the OPL for a path of physical length "d" is just
If the refractive index varies along the path, the OPL is given by
where "n"("s") is the local refractive index as a function of distance, "s", along the path "C".
An electromagnetic wave that travels a path of given optical path length arrives with the same phase shift as if it had traveled a path of that "physical" length in a vacuum. Thus, if a wave is traveling through several different media, then the optical path length of each medium can be added to find the total optical path length. The optical path difference between the paths taken by two identical waves can then be used to find the phase change. Finally, using the phase change, the interference between the two waves can be calculated.
Fermat's principle states that the path light takes between two points is the path that has the minimum optical path length.

</doc>
<doc id="41462" url="https://en.wikipedia.org/wiki?curid=41462" title="Optical power budget">
Optical power budget

The optical power budget in a fiber-optic communication link is the allocation of available optical power (launched into a given fiber by a given source) among various loss-producing mechanisms such as launch coupling loss, fiber attenuation, splice losses, and connector losses, in order to ensure that adequate signal strength (optical power) is available at the receiver. In optical power budget attenuation is specified in decibels (dB) and optical power in dBms. 
The amount of optical power launched into a given fiber by a given transmitter depends on the nature of its active optical source (LED or laser diode) and the type of fiber, including such parameters as core diameter and numerical aperture. Manufacturers sometimes specify an optical power budget only for a fiber that is optimum for their equipment—or specify only that their equipment will operate over a given distance, without mentioning the fiber characteristics. The user must first ascertain, from the manufacturer or by testing, the transmission losses for the type of fiber to be used, and the required signal strength for a given level of performance. 
In addition to transmission loss, including those of any splices and connectors, allowance should be made for at least several dB of optical power margin losses, to compensate for component aging and to allow for future splices in the event of a severed cable.
Definitions:

</doc>
<doc id="41463" url="https://en.wikipedia.org/wiki?curid=41463" title="Optical power margin">
Optical power margin

In an optical communications link, the optical power margin is the difference between the optical power that is launched by a given transmitter into the fiber, less transmission losses from all causes, and the minimum optical power that is required by the receiver for a specified level of performance. An optical power margin is typically measured using a calibrated light source and an optical power meter.
The optical power margin is usually expressed in decibels (dB). At least several dB of optical power margin should be included in the optical power budget. The amount of optical power launched into a given fiber by a given transmitter depends on the nature of its active optical source (LED or laser diode) and the type of fiber, including such parameters as core diameter and numerical aperture. 

</doc>
<doc id="41464" url="https://en.wikipedia.org/wiki?curid=41464" title="Visible spectrum">
Visible spectrum

The visible spectrum is the portion of the electromagnetic spectrum that is visible to the human eye. Electromagnetic radiation in this range of wavelengths is called visible light or simply light. A typical human eye will respond to wavelengths from about 390 to 700 nm. In terms of frequency, this corresponds to a band in the vicinity of 430–770 THz.
The spectrum does not, however, contain all the colors that the human eyes and brain can distinguish. Unsaturated colors such as pink, or purple variations such as magenta, are absent, for example, because they can be made only by a mix of multiple wavelengths. Colors containing only one wavelength are also called pure colors or spectral colors.
Visible wavelengths pass through the "optical window", the region of the electromagnetic spectrum that allows wavelengths to pass largely unattenuated through the Earth's atmosphere. An example of this phenomenon is that clean air scatters blue light more than red wavelengths, and so the midday sky appears blue. The optical window is also referred to as the "visible window" because it overlaps the human visible response spectrum. The near infrared (NIR) window lies just out of the human vision, as well as the Medium Wavelength IR (MWIR) window, and the Long Wavelength or Far Infrared (LWIR or FIR) window, although other animals may experience them.
History.
In the 13th century, Roger Bacon theorized that rainbows were produced by a similar process to the passage of light through glass or crystal.
In the 17th century, Isaac Newton discovered that prisms could disassemble and reassemble white light, and described the phenomenon in his book "Opticks". He was the first to use the word "spectrum" (Latin for "appearance" or "apparition") in this sense in print in 1671 in describing his experiments in optics. Newton observed that, when a narrow beam of sunlight strikes the face of a glass prism at an angle, some is reflected and some of the beam passes into and through the glass, emerging as different-colored bands. Newton hypothesized light to be made up of "corpuscles" (particles) of different colors, with the different colors of light moving at different speeds in transparent matter, red light moving more quickly than violet in glass. The result is that red light is bent (refracted) less sharply than violet as it passes through the prism, creating a spectrum of colors.
In the 18th century, Goethe wrote about optical spectra in his "Theory of Colours". Goethe used the word "spectrum" ("Spektrum") to designate a ghostly optical afterimage, as did Schopenhauer in "On Vision and Colors". Goethe argued that the continuous spectrum was a compound phenomenon. Where Newton narrowed the beam of light to isolate the phenomenon, Goethe observed that a wider aperture produces not a spectrum but rather reddish-yellow and blue-cyan edges with white between them. The spectrum appears only when these edges are close enough to overlap.
In the early 19th century, the concept of the visible spectrum became more definite, as light outside the visible range was discovered and characterized by William Herschel (infrared) and Johann Wilhelm Ritter (ultraviolet), Thomas Young, Thomas Johann Seebeck, and others.
Young was the first to measure the wavelengths of different colors of light, in 1802.
The connection between the visible spectrum and color vision was explored by Thomas Young and Hermann von Helmholtz in the early 19th century. Their theory of color vision correctly proposed that the eye uses three distinct receptors to perceive color.
Animal color vision.
Many species can see light with frequencies outside the human "visible spectrum". Bees and many other insects can detect ultraviolet light, which helps them find nectar in flowers. Plant species that depend on insect pollination may owe reproductive success to their appearance in ultraviolet light rather than how colorful they appear to humans. Birds, too, can see into the ultraviolet (300–400 nm), and some have sex-dependent markings on their plumage that are visible only in the ultraviolet range. Many animals that can see into the ultraviolet range, however, cannot see red light or any other reddish wavelengths. Bees' visible spectrum ends at about 590 nm, just before the orange wavelengths start. Birds, however, can see some red wavelengths, although not as far into the light spectrum as humans. The popular belief that the common goldfish is the only animal that can see both infrared and ultraviolet light is incorrect, because goldfish cannot see infrared light. Similarly, dogs are often thought to be color blind but they have been shown to be sensitive to colors, though not as many as humans.
Spectral colors.
Colors that can be produced by visible light of a narrow band of wavelengths (monochromatic light) are called pure spectral colors. The various color ranges indicated in the illustration are an approximation: The spectrum is continuous, with no clear boundaries between one color and the next.
Spectroscopy.
Spectroscopy is the study of objects based on the spectrum of color they emit, absorb or reflect. Spectroscopy is an important investigative tool in astronomy, where scientists use it to analyze the properties of distant objects. Typically, astronomical spectroscopy uses high-dispersion diffraction gratings to observe spectra at very high spectral resolutions. Helium was first detected by analysis of the spectrum of the sun. Chemical elements can be detected in astronomical objects by emission lines and absorption lines.
The shifting of spectral lines can be used to measure the Doppler shift (red shift or blue shift) of distant objects.
Color display spectrum.
Color displays (e.g. computer monitors and televisions) cannot reproduce "all" colors discernible by a human eye. Colors outside the color gamut of the device, such as most spectral colors, can only be approximated. For color-accurate reproduction, a spectrum can be projected onto a uniform gray field. The resulting mixed colors can have all their R,G,B coordinates non-negative, and so can be reproduced without distortion. This accurately simulates looking at a spectrum on a gray background.

</doc>
<doc id="41465" url="https://en.wikipedia.org/wiki?curid=41465" title="Optical switch">
Optical switch

In telecommunication, an optical switch is a switch that enables signals in optical fibers or integrated optical circuits (IOCs) to be selectively switched from one circuit to another.
Terminology.
The word applies on several levels. In commercial terms (such as "the telecom optical switch market size") it refers to any piece of circuit switching equipment between fibers. The majority of installed systems in this category actually use electronic switching between fiber transponders. Systems that perform this function by routing light beams are often referred to as "photonic" switches, independent of how the light itself is switched. Away from telecom, an optical switch is the unit that actually switches light between fibers, and a photonic switch is one that does this by exploiting nonlinear material properties to steer light (i.e., to switch wavelengths or signals within a given fiber).
Hence a certain portion of the optical switch market is made up of photonic switches. These will contain within them an optical switch, which will, in some cases, be a photonic switch.
Operation.
An optical switch may operate by mechanical means, such as physically shifting an optical fiber to drive one or more alternative fibers, or by electro-optic effects, magneto-optic effects, or other methods. Slow optical switches, such as those using moving fibers, may be used for alternate routing of an optical switch transmission path, such as routing around a fault. Fast optical switches, such as those using electro-optic or magneto-optic effects, may be used to perform logic operations; also included in this category are semiconductor optical amplifiers, which are optoelectronic devices that can be used as optical switches and be integrated with discrete or integrated microelectronic circuits.
Functionality.
The functionality of any switch can be described in terms of the connections it can establish. As stated in Telcordia GR-1073, 
a connection is the association between two ports on a switch and is indicated as a
pair of port identifiers ("i", "j" ), where "i" and "j" are two ports between which the
connection is established. A connection identifies the transmission path between
two ports. An optical signal can be applied to either one of the connected ports.
However, the nature of the signal emerging at the other port depends on the optical
switch and the state of the connection. A connection can be in the "on" state or the
"off" state. A connection is said to be in the "on" state if an optical signal applied to
one port emerges at the other port with essentially zero loss in optical energy. A
connection is said to be in the "off" state if essentially zero optical energy emerges
at the other port.
Connections established in optical switches can be unidirectional or bidirectional. A unidirectional connection only allows optical signal transmission in one direction between the connected ports. A bidirectional connection allows optical signal transmission in both directions over the connection. Connections in passive and transparent optical switches are bidirectional, i.e., if a connection ("i", "j" ) is set up, optical transmission is possible from "i" to "j" and from "j" to "i".
A device is optically “transparent” if the optical signal launched at the input remains optical throughout its transmission path in the device and appears as an optical signal at the output. Optically transparent devices operate over a range of wavelengths called the passband.
A passive optical switch does not have optical gain elements. An active optical switch has optical gain elements. An all-optical switch is a transparent optical switch in which the actuating signal is also optical. Thus, in an all-optical switch, an optical signal is used to switch the path another optical signal takes through the switch.
Performance.
Various parameters are defined and specified to quantify the performance of optical switches. The steady state performance of an optical switch (or optical switching matrix) is measured by its ability to effectively transmit optical power from an input port to any one of N output ports over the “on” state transmission path, and its ability to effectively isolate input power sources from all non-active ports over the “off” state transmission paths. Other key optical performance parameters include transmission efficiency over a range of wavelengths, the ability to minimize input optical power reflected back into the input fiber, transmission balance, and bidirectional transmission. The optical switch (or switching matrix) transient behavior is another important characteristic that is specified by its speed of response to control stimulation via the time interval it takes to either transmit or block the optical signal on any given output port.
Two rates can be associated with switches: the switching rate and the signal transmission rate. The switching rate is the rate at which a switch changes states. The signal transmission rate is the modulation rate of information passing through a switch. The signal transmission rate is usually much greater than the switching rate. (If the switching rate approaches or exceeds the transmission rate, then the switch can be called an optical modulator.)
A switch’s ability to sustain its steady state and transient performance specifications under stressful environmental conditions and over time is also an important characteristic.
Applications.
Optical switching technology is driven by the need to provide flexibility in optical network connectivity. Prime applications are optical protection, test systems, and remotely reconfigurable add-drop multiplexers. Possible future applications include remote optical provisioning and restoration.
Current switching applications include passive protection switching for service restoration following a disruption, such as a fiber cut. One common application for switches is in Remote Fiber Test Systems (RFTSs) that can monitor and locate a fault on a fiber transmission line. An emerging application of optical switches is optical cross-connection. Optical cross-connects utilize optical switching fabrics to establish an interconnection between multiple optical inputs and outputs.
Patents.
A 2011 search on “optical switch” [http://patft.uspto.gov/netahtml/PTO/search-bool.html] yielded some 8,000 patents, roughly categorized as follows:

</doc>
<doc id="41466" url="https://en.wikipedia.org/wiki?curid=41466" title="Optical time-domain reflectometer">
Optical time-domain reflectometer

An optical time-domain reflectometer (OTDR) is an optoelectronic instrument used to characterize an optical fiber. An OTDR is the optical equivalent of an electronic time domain reflectometer. It injects a series of optical pulses into the fiber under test and extracts, from the same end of the fiber, light that is scattered (Rayleigh backscatter) or reflected back from points along the fiber. The scattered or reflected light that is gathered back is used to characterize the optical fiber. This is equivalent to the way that an electronic time-domain meter measures reflections caused by changes in the impedance of the cable under test. The strength of the return pulses is measured and integrated as a function of time, and plotted as a function of fiber length.
Reliability and quality of OTDR equipment.
The reliability and quality of an OTDR is based on its accuracy, measurement range, ability to resolve and measure closely spaced events, measurement speed, and ability to perform satisfactorily under various environmental extremes and after various types of physical abuse. The instrument is also judged on the basis of its cost, features provided, size, weight, and ease of use.
Some of the terms often used in specifying the quality of an OTDR are as follows:
Industry requirements for the reliability and quality of OTDRs are specified in the Generic Requirements for Optical Time Domain Reflectometer (OTDR) Type Equipment.
Types of OTDR-like test equipment.
The common types of OTDR-like test equipment are:
OTDR Data Format.
In the late 1990s, OTDR industry representatives and the OTDR user community developed a unique data format to store and analyze OTDR fiber data. This data was based on the specifications in GR-196, Generic Requirements for Optical Time Domain Reflectometer (OTDR) Type Equipment. The goal was for the data format to be truly universal, in that it was intended to be implemented by all OTDR manufacturers. OTDR suppliers developed the software to implement the data format. As they proceeded, they identified inconsistencies in the format, along with areas of misunderstanding among users.
From 1997 to 2000, a group of OTDR supplier software specialists attempted to resolve problems and inconsistencies in what was then called the “Bellcore” OTDR Data Format. This group, called the OTDR Data Format Users Group (ODFUG), made progress. Since then, many OTDR developers continued to work with other developers to solve individual interaction problems and enable cross use between manufacturers.
In 2011, Telcordia decided to compile industry comments on this data format into one document entitled Optical Time Domain Reflectometer (OTDR) Data Format. This Special Report (SR) summarizes the state of the Bellcore OTDR Data Format, renaming it as the Telcordia OTDR Data Format.
The data format is intended for all OTDR-related equipment designed to save trace data and analysis information. Initial implementations require standalone software to be provided by the OTDR supplier to convert existing OTDR trace files to the SR-4731 data format and to convert files from this universal format to a format that is usable by their older OTDRs. This file conversion software can be developed by the hardware supplier, the end user, or a third party. This software also provides backward compatibility of the OTDR data format with existing equipment.
The SR-4731 format describes binary data. While text information is contained in several fields, most numbers are represented as either 16-bit (2-byte) or 32-bit (4-byte) signed or unsigned integers stored as binary images. Byte ordering in this file format is explicitly low-byte ordering, as is common on Intel® processor-based machines. String fields are terminated with a zero byte “\0”. OTDR waveform data are represented as short, unsigned integer data uniformly spaced in time, in units of decibels (dB) times 1000, referenced to the maximum power level. The maximum power level is set to zero, and all waveform data points are assumed to be zero or negative (the sign bit is implied), so that the minimum power level in this format is -65.535 dB, and the minimum resolution between power level steps is 0.001 dB. In some cases, this will not provide sufficient power range to represent all waveform points. For this reason, the use of a scale factor has been introduced to expand the data point power range.

</doc>
<doc id="41472" url="https://en.wikipedia.org/wiki?curid=41472" title="Outside plant">
Outside plant

In telecommunication, the term outside plant has the following meanings:
The CATV industry divides its fixed assets between head end or inside plant, and outside plant. The electrical power industry also uses the term outside plant to refer to electric power distribution systems.
Context.
Network connections between devices such as computers, printers, and phones require a physical infrastructure to carry and process signals. Typically, this infrastructure will consist of:
The portion of this infrastructure contained within a building is the inside plant, and the portion of this infrastructure connecting buildings or facilities is the outside plant. Where these two plants meet in a given structure is the demarcation point.
Outside plant cabling, whether copper or fiber, is generally installed as aerial cable between poles, in an underground conduit system, or by direct burial.
Hardware associated with the outside plant must be either protected from the elements (for example, distribution frames are generally protected by a street side cabinet) or constructed with materials suitable for exposure to the elements. Installation of the outside plant elements often require construction of significant physical infrastructure, such as underground vaults. In older large installations, cabling is sometimes protected by air pressure systems designed to prevent water infiltration. While this is not a modern approach, the cost of replacement of the older cabling with sealed cabling is often prohibitively expensive. The cabling used in the outside plant must also be protected from electrical disturbances caused by lightning or voltage surges due to electrical shorts or induction.
Example: copper access network.
In civilian telecommunications, the copper access network (also known as the local loop) providing basic telephone or DSL services typically consists of the following elements:
Active equipment (such as a POTS or DSL line circuit) can then be connected to the line in order to provide service, but this is not considered part of outside plant.
Protecting equipment in the outside plant.
The environment can play a large role in the quality and lifespan of equipment used in the outside plant. It is critical that environmental testing criteria as well as design and performance requirements be defined for this type of equipment.
There are generally four operating environments or classes covering all outside plant (OSP) applications, including wireless facilities.
Electronic equipment located in one or more of these environmental class locations is designed to withstand various environmental operating conditions resulting from climatic conditions that may include rain, snow, sleet, high winds, ice, salt spray, and sand storms. Since outside temperatures can possibly range from −40°C (−40°F) to 46°C (115°F), with varying degrees of solar loading, along with humidity levels ranging from below 10% up to 100%, significant environmental stresses within the enclosure or facility can be produced.
Telcordia GR-3108, Generic Requirements for Network Equipment in the Outside Plant (OSP), contains the most recent industry data regarding each Class described above. It also discusses what is currently happening in ATIS and Underwriters Laboratories (UL).
The document also includes 
Handholes and other below-ground splice vaults.
Handholes and other below-ground splice vaults house telecommunications components used in an Outside Plant (OSP) environment.
Handholes are plastic or polymer concrete structures set below ground with their lids flush to the surrounding soil, turf, footpath, or road surface. They can be used to house and protect copper, coaxial, and optical fiber telephone cable splices and distribution elements. They safeguard and provide convenient access to cable termination and branch points, provide flexibility and access for installation operations (e.g., pulling or blowing cables), provide mechanical and environmental protection for splices, allow access for craftsperson work activities, and discourage access by unauthorized persons. 
Handholes and other below-ground splice vaults are deployed in a variety of environments. The major distinctions in these environments focus on the strength and frequency of vehicular and foot traffic loading. There are four basic application environments:
Handhole-type products deployed in any environment are subjected to the following types of traffic loading: Vertical Cover Load, Vertical Sidewall Load, Lateral Sidewall Load, and Long-Term Lateral Sidewall Load.
Telcordia GR-902, "Generic Requirements for Handholes and Other Below-Ground Splice Vaults," contains detailed industry requirements for handholes, and includes specific loading requirements for the defined application environments. It provides explicit correlations to other standards such as ANSI/SCTE-77, AASHTO specifications, and ASTM C857.
Corrosion resistance.
Corrosion in outside plant telecommunications network components is caused by exposure to the effects of temperature, humidity, electrical power, and contaminants. Corrosion resistance criteria for these network components are based on the environments to which they are exposed.
Outside plant environments can be above-ground, underground, buried, or underwater. Industry requirements document Telcordia GR-2836 defines these environments and provides corrosion resistance criteria for the telecommunications equipment in each. It also includes references to various associated ASTM Standards.
Above-ground plant.
Above-ground plant includes all the telecommunications equipment physically located on or above the ground. This includes enclosures such as huts, cabinets, and pedestals, and the equipment mounted therein. It also includes pole-mounted equipment and cases, and pole-line hardware. 
Above-ground plant can be exposed to extreme temperatures, and to humidity that varies with the seasons and with daily temperature changes. When humidity condenses on the surfaces of outdoor apparatus or equipment, the corrosivity of the moisture layer can be increased by industrial pollutants that render the condensate moisture corrosive. In sea coastal areas, wind-borne, salt-laden water droplets can deposit on exposed components. 
Near large cultivated areas, where fertilizers are applied by airplanes, the wind may carry nitrates, phosphates, and ammonium compounds to settle on metallic components of the above-ground telephone plant. Similarly, in residential areas, lawn fertilizers and herbicides can cause corrosion. In regions with snow, the salts used to melt snow and ice on roadways can accelerate corrosion. Under extreme conditions, pedestals and cabinets may be flooded with water that contains mud and corrosive salts. Corrosion of these flooded components may be accelerated by the presence of dc voltages used to power the networks. Secretions from insects can also accelerate corrosion. Finally, chewing by rodents may expose metallic components, normally protected by a polymer or paint coating, to a corrosive environment.
Underground plant.
Underground plant includes all the telecommunications equipment installed in underground structures such as utility holes, Controlled Environment Vaults (CEVs), and ducts, along with associated hardware. Underground plant can be exposed to waters containing water-soluble salts of the native soil. Utility holes often show evidence of corrosion of support hardware and bonding ribbons that is caused by sulfate-reducing bacteria. The environment in utility holes and ducts can be made corrosive by man-made chemicals such as industrial effluent, fertilizers, and de-icing salts. Protective plastic coatings and cable jackets can rapidly deteriorate from leaking steam pipes present in many urban areas and from gasoline leaking from underground storage tanks.
The most aggressive contributor to corrosion of underground plant is dc stray current from electrified rail transportation systems, cathodic protection rectifiers, or welding and mining operations. Although such dc currents are mostly dealt with “after the fact” using protective systems (e.g., low resistance bonds, reverse current switches, cathodic protection), some of the protection has to be included at the manufacturing stage. This protection may include insulating covers on cable shields, or nonmetallic components or coatings for apparatus.
Buried plant.
Buried plant consists of telecommunications equipment such as cables, splice closures, lower parts of pedestals, and grounding systems directly buried in the soil. Buried plant can be exposed to the same corrosive environment as underground plant. In addition, attack by gophers can expose underlying components to corrosion attack.
Underwater plant.
Underwater plant includes all telecommunications equipment located beneath the surface of a body of water. This includes cables and repeaters. The water can range from relatively pure, to brackish, to badly contaminated with industrial effluent.

</doc>
<doc id="41473" url="https://en.wikipedia.org/wiki?curid=41473" title="Ovality">
Ovality

In telecommunications and fiber optics, ovality or noncircularity is the degree of deviation from perfect circularity of the cross section of the core or cladding of the fiber.
The cross-sections of the core and cladding are assumed to a first approximation to be elliptical. Quantitatively, the ovality of either the core or cladding is expressed as formula_1, where "a" is the length of the major axis and "b" is the length of the minor axis. The dimensionless quantity so obtained may be multiplied by 100 to express ovality as a percentage. Alternatively, ovality of the core or cladding may be specified by a tolerance field consisting of two concentric circles, within which the cross section boundaries must lie.
In measurements, ovality is the amount of out-of-roundness of a hole or cylindrical part in the typical form of an oval.
In chemistry.
In computational chemistry, especially in QSAR studies, ovality refers to, a measure of how the shape of a molecule approaches a sphere (at one extreme) or a cigar shape (at the other). 
Ovality is described by a ratio of volume to area:
formula_2
where:
The ovality of the He atom is 1.0 and that of HC24H (12 triple bonds) is ~1.7.

</doc>
<doc id="41474" url="https://en.wikipedia.org/wiki?curid=41474" title="Overfill">
Overfill

In telecommunications, overfill is the condition that prevails when the numerical aperture or the beam diameter of an optical source, such as a laser, light-emitting diode, or optical fiber, exceeds that of the driven element, e.g. an optical fiber core. In optical communications testing, overfill in both numerical aperture and mean diameter (core diameter or spot size) is usually required.
In polygonal mirror scanners, an overfilled type is one which uses each mirror facet at least in one dimension completely.

</doc>
<doc id="41475" url="https://en.wikipedia.org/wiki?curid=41475" title="Overflow">
Overflow

Overflow may refer to:

</doc>
<doc id="41476" url="https://en.wikipedia.org/wiki?curid=41476" title="Overhead information">
Overhead information

Overhead information is digital information transferred across the functional interface between a user and a telecommunications system, or between functional units within a telecommunications system, for the purpose of directing or controlling the transfer of user information or the detection and correction of errors. 
Overhead information originated by the user is not considered to be system overhead information. Overhead information generated within the communications system and not delivered to the user is system overhead information. Thus, the user throughput is reduced by both overheads while system throughput is reduced only by system overhead.

</doc>
<doc id="41477" url="https://en.wikipedia.org/wiki?curid=41477" title="Overmodulation">
Overmodulation

Overmodulation is the condition that prevails in telecommunication when the instantaneous level of the modulating signal exceeds the value necessary to produce 100% modulation of the carrier. In the sense of this definition, it is almost always considered a fault condition. In layman's terms, the signal is going "off the scale". Overmodulation results in spurious emissions by the modulated carrier, and distortion of the recovered modulating signal. This means that the envelope of the output waveform is distorted. 
Although overmodulation is sometimes considered permissible, it should not occur in practice; a distorted waveform envelope will result in a distorted output signal of the receiving medium.

</doc>
<doc id="41478" url="https://en.wikipedia.org/wiki?curid=41478" title="Override">
Override

Override may refer to:

</doc>
<doc id="41479" url="https://en.wikipedia.org/wiki?curid=41479" title="Overshoot">
Overshoot

Overshoot may refer to:

</doc>
<doc id="41480" url="https://en.wikipedia.org/wiki?curid=41480" title="Overtone">
Overtone

An overtone is any frequency greater than the fundamental frequency of a sound. Using the model of Fourier analysis, the fundamental and the overtones together are called partials. Harmonics, or more precisely, harmonic partials, are partials whose frequencies are integer multiples of the fundamental (including the fundamental which is 1 times itself). These overlapping terms are variously used when discussing the acoustic behavior of musical instruments. (See etymology below.) The model of Fourier analysis provides for the inclusion of inharmonic partials, which are partials whose frequencies are not whole-number ratios of the fundamental (such as 1.1 or 2.14179).
When a resonant system such as a blown pipe or plucked string is excited, a number of overtones may be produced along with the fundamental tone. In simple cases, such as for most musical instruments, the frequencies of these tones are the same as (or close to) the harmonics. Examples of exceptions include the circular drum, – a timpani whose first overtone is about 1.6 times its fundamental resonance frequency, gongs and cymbals, and brass instruments. The human vocal tract is able to produce highly variable amplitudes of the overtones, called formants, which define different vowels.
Explanation.
Most oscillators, from a guitar string to a flute, will naturally vibrate at a series of distinct frequencies known as normal modes. The lowest normal mode frequency is known as the fundamental frequency, while the higher frequencies are called overtones. Often, when an oscillator is excited by, for example, plucking a guitar string, it will oscillate at several of its modal frequencies at the same time. So when a note is played, this gives the sensation of hearing other frequencies (overtones) above the lowest frequency (the fundamental).
Timbre is the quality that gives the listener the ability to distinguish between the sound of different instruments. The timbre of an instrument is determined by which overtones it emphasizes. That is to say, the relative volumes of these overtones to each other determines the specific "flavor" or "color" of sound of that family of instruments. The intensity of each of these overtones is rarely constant for the duration of a note. Over time, different overtones may decay at different rates, causing the relative intensity of each overtone to rise or fall independent of the overall volume of the sound. A carefully trained ear can hear these changes even in a single note. This is why the timbre of a note may be perceived differently when played staccato or legato.
A driven non-linear oscillator, such as the vocal folds, a blown wind instrument, or a bowed violin string (but not a struck guitar string or bell) will oscillate in a periodic, non-sinusoidal manner. This generates the impression of sound at integer multiple frequencies of the fundamental known as harmonics, or more precisely, harmonic partials. For most string instruments and other long and thin instruments such as a bassoon, the first few overtones are quite close to integer multiples of the fundamental frequency, producing an approximation to a harmonic series. Thus, in music, overtones are often called harmonics. Depending upon how the string is plucked or bowed, different overtones can be emphasized.
However, some overtones in some instruments may not be of a close integer multiplication of the fundamental frequency, thus causing a small dissonance. "High quality" instruments are usually built in such a manner that their individual notes do not create disharmonious overtones. In fact, the flared end of a brass instrument is not to make the instrument sound louder, but to correct for tube length “end effects” that would otherwise make the overtones significantly different from integer harmonics. This is illustrated by the following:
Consider a guitar string. Its idealized 1st overtone would be exactly twice its fundamental if its length were shortened by ½, perhaps by lightly pressing a guitar string at the 12th fret; however, if a vibrating string is examined, it will be seen that the string does not vibrate flush to the bridge and nut, but it instead has a small “dead length” of string at each end. This dead length actually varies from string to string, being more pronounced with thicker and/or stiffer strings. This means that halving the physical string length does not halve the actual string vibration length, and, hence, the overtones will not be exact multiples of a fundamental frequency. The effect is so pronounced that properly set up guitars will angle the bridge such that the thinner strings will progressively have a length up to few millimeters shorter than the thicker strings. Not doing so would result in inharmonious chords made up of two or more strings. Similar considerations apply to tube instruments.
Musical usage term.
An overtone is a partial (a "partial wave" or "constituent frequency") that can be either a harmonic partial (a harmonic) other than the fundamental, or an inharmonic partial. A harmonic frequency is an integer multiple of the fundamental frequency. An inharmonic frequency is a non-integer multiple of a fundamental frequency.
An example of harmonic overtones: (absolute harmony)
Some musical instruments produce overtones that are slightly sharper or flatter than true harmonics. The sharpness or flatness of their overtones is one of the elements that contributes to their unique sound. Due to phase inconsistencies between the fundamental and the partial harmonic, this also has the effect of making their waveforms not perfectly periodic.
Musical instruments that can create notes of any desired duration and definite pitch have harmonic partials.
A tuning fork, provided it is sounded with a mallet (or equivalent) that is reasonably soft, has a tone that consists very nearly of the fundamental, alone; it has a sinusoidal waveform. Nevertheless, music consisting of pure sinusoids was found to be unsatisfactory in the early 20th century.
Etymology.
In Hermann von Helmholtz's classic "On The Sensations Of Tone" he used the German "Obertöne" which was actually a contraction of "Oberpartialtöne", or in English: "upper partial tones". According to Alexander Ellis (in pages 24–25 of his definitive English translation of Helmholtz), the similarity of German "ober" to English "over" caused a Prof. Tyndall to mistranslate Helmholtz' term, thus creating "overtone". Ellis disparages the term "overtone" for its awkward implications. Because "overtone" makes the upper partials seem like such a distinct phenomena, it leads to the mathematical problem described above where the first overtone is the second partial. Also, unlike discussion of "partials", the word "overtone" has connotations that have led people to wonder about the presence of "undertones" (a term sometimes confused with "difference tones" but also used in speculation about a hypothetical "undertone series").
"Overtones" in barbershop music.
In barbershop music, the word "overtone" is often used in a related but particular manner. It refers to a psychoacoustic effect in which a listener hears an audible pitch that is higher than, and different from, the fundamentals of the four pitches being sung by the quartet. The barbershop singer's "overtone" is created by the interactions of the upper partial tones in each singer's note (and by sum and difference frequencies created by nonlinear interactions within the ear). Similar effects can be found in other "a cappella" polyphonic music such as the music of the Republic of Georgia and the Sardinian "cantu a tenore".
String instruments.
String instruments can also produce multiphonic tones when strings are divided in two pieces. The most developed instrument for playing multiphonic tones is the Sitar in which there are sympathetic strings which help to bring out the overtones while one is playing. The most well-known technique on a guitar is playing flageolet tones. The Ancient Chinese instrument the Guqin contains a scale based on the knotted positions of overtones. Also the Vietnamese Đàn bầu functions on flageolet tones. Other multiphonic extended techniques used are prepared piano, prepared guitar and 3rd bridge.
Overtone singing.
Overtone singing, also called harmonic singing, occurs when the singer amplifies voluntarily two overtones in the sequence available given the fundamental tone he/she is singing. Overtone singing is a traditional form of singing in many parts of the Himalayas and Altay; Tibetans, Mongols and Tuvans are known for their overtone singing. In these contexts it is often referred to as throat singing, though it should not be confused with Inuit throat singing, which is produced by different means.
Jaw harp.
A similar technique is used for playing the jaw harp: the performer amplifies the instrument's overtones by changing the shape, and therefore the resonance, of their vocal tract.
Free-reed aerophone.
Likewise, when playing a harmonica or pitch pipe, one may alter the shape of their mouth to amplify specific overtones.

</doc>
<doc id="41481" url="https://en.wikipedia.org/wiki?curid=41481" title="Packet-switching node">
Packet-switching node

Packet-switching node: In a packet-switching network, a node that contains data switches and equipment for controlling, formatting, transmitting, routing, and receiving data packets. 
"Note:" In the Defense Data Network (DDN), a packet-switching node is usually configured to support up to thirty-two X.25 56 kbit/s host connections, as many as six 56 kbit/s interswitch trunk (IST) lines to other packet-switching nodes, and at least one Terminal Access Controller (TAC).

</doc>
<doc id="41482" url="https://en.wikipedia.org/wiki?curid=41482" title="Paired disparity code">
Paired disparity code

In telecommunication, a paired disparity code is a line code in which at least one of the data characters is represented by two codewords of opposite disparity that are used in sequence so as to minimize the total disparity of a longer sequence of digits.
A particular codeword of any line code can either have no disparity (the average weight of the codeword is zero), negative disparity (the average weight of the codeword is negative), or positive disparity (the average weight of the codeword is positive).
In a paired disparity code, every codeword that averages to a negative level (negative disparity) is paired with some other codeword that averages to a positive level (positive disparity).
In a system that uses a paired disparity code, the transmitter must keep track of the running DC buildup -- the running disparity -- and always pick the codeword that pushes the DC level back towards zero. The receiver is designed so that either codeword of the pair decodes to the same data bits.
Most line codes use either a paired disparity code or a constant-weight code.
The simplest paired disparity code is alternate mark inversion signal.
Other paired disparity codes include 8B10B, , the modified AMI codes, coded mark inversion, and 4B3T.
The digits may be represented by disparate physical quantities, such as two different frequencies, phases, voltage levels, magnetic polarities, or electrical polarities, each one of the pair representing a 0 or a 1.

</doc>
<doc id="41486" url="https://en.wikipedia.org/wiki?curid=41486" title="Title 47 CFR Part 68">
Title 47 CFR Part 68

Title 47 CFR Part 68 is a section of the Code of Federal Regulations of the United States that regulate the direct electrical connection of telecommunications equipment and customer premises wiring with the public switched telephone network, certain private line services, and connection of private branch exchange (PBX) equipment to certain telecommunication interfaces.
Scope.
Part 68 rules provide the technical and procedural standards under which direct electrical connection of customer-provided telephone equipment, systems, and protective apparatus may be made to the nationwide network without causing harm and without a requirement for protective circuit arrangements in the service-provider networks.
The equivalent European regulation is called TBR21.

</doc>
<doc id="41487" url="https://en.wikipedia.org/wiki?curid=41487" title="Party line">
Party line

Party line may refer to:

</doc>
<doc id="41488" url="https://en.wikipedia.org/wiki?curid=41488" title="Passband">
Passband

A passband is the range of frequencies or wavelengths that can pass through a filter. For example, a radio receiver contains a bandpass filter to select the frequency of the desired radio signal out of all the radio waves picked up by its antenna. The passband of a receiver is the range of frequencies it can receive.
A bandpass-filtered signal (that is, a signal with energy only in a passband), is known as a bandpass signal, in contrast to a baseband signal.
Filters.
In telecommunications, optics, and acoustics, a passband (a band-pass filtered signal) is the portion of the frequency spectrum that is transmitted (with minimum relative loss or maximum relative gain) by some filtering device. In other words, it is a "band" of frequencies which "pass"es through some filter or set of filters.
The accompanying figure shows a schematic of a waveform being filtered by a bandpass filter consisting of a highpass and a lowpass filter.
Radio receivers generally include a tunable band-pass filter with a passband that is wide enough to accommodate the bandwidth of the radio signal transmitted by a single station.
Digital transmission.
There are two main categories of digital communication transmission methods: baseband and passband.
Details.
In general, there is an inverse relationship between the width of a filter's passband and the time required for the filter to respond to new inputs. Broad passbands yield faster response. This is a consequence of the mathematics of Fourier analysis.
The limiting frequencies of a passband are defined as those at which the relative intensity or power decreases to a specified fraction of the maximum intensity or power. This decrease in power is often specified to be the half-power points, "i.e.", 3 dB below the maximum power.
The difference between the limiting frequencies is called the bandwidth, and is expressed in hertz (in the optical regime, in nanometers or micrometers of differential wavelength).
The related term "bandpass" is an adjective that describes a type of filter or filtering process; it is frequently confused with "passband", which refers to the actual portion of affected spectrum. The two words are both compound words that follow the English rules of formation: the primary meaning is the latter part of the compound, while the modifier is the first part. Hence, one may correctly say 'A dual bandpass filter has two passbands'.

</doc>
<doc id="41490" url="https://en.wikipedia.org/wiki?curid=41490" title="Password length parameter">
Password length parameter

In telecommunication, a password length parameter is a basic parameter the value of which affects password strength against brute force attack and so is a contributor to computer security. 
One use of the password length parameters is in the expression formula_1, where formula_2 is the probability that a password can be guessed in its lifetime, formula_3 is the maximum lifetime a password can be used to log into a system, formula_4 is the number of guesses per unit of time, and formula_5 is the number of unique algorithm-generated passwords (the 'password space'). 
The degree of password security is determined by the probability that a password can be guessed in its lifetime.

</doc>
<doc id="41492" url="https://en.wikipedia.org/wiki?curid=41492" title="Path loss">
Path loss

Path loss (or path attenuation) is the reduction in power density (attenuation) of an electromagnetic wave as it propagates through space. Path loss is a major component in the analysis and design of the link budget of a telecommunication system.
This term is commonly used in wireless communications and propagation. Path loss may be due to many effects, such as free-space loss, refraction, diffraction, reflection, aperture-medium coupling loss, and absorption. Path loss is also influenced by terrain contours, environment (urban or rural, vegetation and foliage), propagation medium (dry or moist air), the distance between the transmitter and the receiver, and the height and location of antennas.
Causes.
Path loss normally includes "propagation losses" caused by the natural expansion of the radio wave front in free space (which usually takes the shape of an ever-increasing sphere), "absorption losses" (sometimes called penetration losses), when the signal passes through media not transparent to electromagnetic waves, "diffraction losses" when part of the radiowave front is obstructed by an opaque obstacle, and losses caused by other phenomena.
The signal radiated by a transmitter may also travel along many and different paths to a receiver simultaneously; this effect is called multipath. Multipath waves combine at the receiver antenna, resulting in a received signal that may vary widely, depending on the distribution of the intensity and relative propagation time of the waves and bandwidth of the transmitted signal. The total power of interfering waves in a Rayleigh fading scenario vary quickly as a function of space (which is known as "small scale fading"). Small-scale fading refers to the rapid changes in radio signal amplitude in a short period of time or travel distance.
Loss exponent.
In the study of wireless communications, path loss can be represented by the path loss exponent, whose value is normally in the range of 2 to 4 (where 2 is for propagation in free space, 4 is for relatively lossy environments and for the case of full specular reflection from the earth surface—the so-called Flat Earth model). In some environments, such as buildings, stadiums and other indoor environments, the path loss exponent can reach values in the range of 4 to 6. On the other hand, a tunnel may act as a waveguide, resulting in a path loss exponent less than 2.
Path loss is usually expressed in dB. In its simplest form, the path loss can be calculated using the formula
where formula_2 is the path loss in decibels, formula_3 is the path loss exponent, formula_4 is the distance between the transmitter and the receiver, usually measured in meters, and formula_5 is a constant which accounts for system losses.
Radio engineer formula.
Radio and antenna engineers use the following simplified formula (also known as the Friis transmission equation) for the path loss between two isotropic antennas in free space:
Path loss in dB: 
where formula_2 is the path loss in decibels, formula_8 is the wavelength and formula_4 is the transmitter-receiver distance in the same units as the wavelength.
Prediction.
Calculation of the path loss is usually called "prediction". Exact prediction is possible only for simpler cases, such as the above-mentioned "free space" propagation or the "flat-earth model". For practical cases the path loss is calculated using a variety of approximations.
"Statistical" methods (also called "stochastic" or "empirical") are based on measured and averaged losses along typical classes of radio links. Among the most commonly used such methods are Okumura-Hata, the COST Hata model, W.C.Y.Lee, etc. These are also known as "radio wave propagation models" and are typically used in the design of cellular networks and PLMN. For wireless communications in the VHF and UHF frequency band (the bands used by walkie-talkies, police, taxis and cellular phones), one of the most commonly used methods is that of Okumura-Hata as refined by the COST 231 project. Other well-known models are those of Walfisch-Ikegami, W.C.Y. Lee, and Erceg. For FM radio and TV broadcasting the path loss is most commonly predicted using the ITU model as described in P.1546 (successor to P.370) recommendation.
Deterministic methods based on the physical laws of wave propagation are also used; ray tracing is one such method. These methods are expected to produce more accurate and reliable predictions of the path loss than the empirical methods; however, they are significantly more expensive in computational effort and depend on the detailed and accurate description of all objects in the propagation space, such as buildings, roofs, windows, doors, and walls. For these reasons they are used predominantly for short propagation paths. Among the most commonly used methods in the design of radio equipment such as antennas and feeds is the finite-difference time-domain method.
The path loss in other frequency bands (MW, SW, Microwave) is predicted with similar methods, though the concrete algorithms and formulas may be very different from those for VHF/UHF. Reliable prediction of the path loss in the SW/HF band is particularly difficult, and its accuracy is comparable to weather predictions.
Easy approximations for calculating the path loss over distances significantly shorter than the distance to the radio horizon:
Examples.
In cellular networks, such as UMTS and GSM, which operate in the UHF band, the value of the path loss in built-up areas can reach 110–140 dB for the first kilometer of the link between the BTS and the mobile. The path loss for the first ten kilometers may be 150–190 dB ("Note": These values are very approximate and are given here only as an illustration of the range in which the numbers used to express the path loss values "can eventually be", these are not definitive or binding figures—the path loss may be very different for the same distance along two different paths and it can be different even along the same path if measured at different times.)
In the radio wave environment for mobile services the mobile antenna is close to the ground. LOS propagation models are highly modified. The signal path from the BTS antenna normally elevated above the roof tops is refracted down into the local physical environment (hills, trees, houses) and the LOS signal seldom reaches the antenna. The environment will produce several deflections of the direct signal onto the antenna, where typically 2-5 deflected signal components will be vectorially added.
These refraction and deflection processes cause loss of signal strength, which changes when the mobile antenna moves (Raleigh fading), causing instantaneous variations of up to 20 dB. The network is therefore designed to provide an excess of signal strength compared to LOS of 8-25 dB depending on the nature of the physical environment, and another 10 dB to overcome the fading due to movement.

</doc>
<doc id="41493" url="https://en.wikipedia.org/wiki?curid=41493" title="Path profile">
Path profile

In telecommunication, a path profile is a graphic representation of the physical features of a propagation path in the vertical plane containing both endpoints of the path, showing the surface of the Earth and including trees, buildings, and other features that may obstruct the radio signal. 
Profiles are drawn either with an effective Earth radius simulated by a parabolic arc--in which case the ray paths are drawn as straight lines--or with a ""flat Earth"--" in which case the ray paths are drawn as parabolic arcs.

</doc>
<doc id="41494" url="https://en.wikipedia.org/wiki?curid=41494" title="Path quality analysis">
Path quality analysis

Path quality analysis: In a communications path, an analysis that (a) includes the overall evaluation of the component quality measures, the individual link quality measures, and the aggregate path quality measures, and (b) is performed by evaluating communications parameters, such as bit error ratio, signal-plus-noise-plus-distortion to noise-plus-distortion ratio, and spectral distortion.

</doc>
<doc id="41495" url="https://en.wikipedia.org/wiki?curid=41495" title="Payload">
Payload

Payload is the carrying capacity of an aircraft or launch vehicle, usually measured in terms of weight. Depending on the nature of the flight or mission, the payload of a vehicle may include cargo, passengers, flight crew, munitions, scientific instruments or experiments, or other equipment. Extra fuel, when optionally carried, is also considered part of the payload. In a commercial context (i.e., an airline or air freight carrier), payload may refer only to revenue-generating cargo or paying passengers.
For a rocket, the payload can be a satellite, space probe, or spacecraft carrying humans, animals, or cargo. For a ballistic missile, the payload is one or more warheads and related systems; the total weight of these systems is referred to as the throw-weight.
The fraction of payload to the total liftoff weight of the air or spacecraft is known as the "payload fraction". When the weight of the payload and fuel are considered together, it is known as the "useful load fraction". In spacecraft, "mass fraction" is normally used, which is the ratio of payload to everything else, including the rocket structure.
Relationship of range and payload.
There is a natural trade-off between the payload and the range of an aircraft. A payload range diagram (also known as the "elbow chart") illustrates the trade-off.
The top horizontal line represents the maximum payload. It is limited structurally by maximum zero-fuel weight (MZFW) of the aircraft. Maximum payload is the difference between maximum zero-fuel weight and operational empty weight (OEW). Moving left-to-right along the line shows the constant maximum payload as the range increases. More fuel needs to be added for more range.
The vertical line represents the range at which the combined weight of the aircraft, maximum payload and needed fuel reaches the maximum take-off weight (MTOW) of the aircraft. If the range is increased beyond that point, payload has to be sacrificed for fuel.
The maximum take-off weight is limited by a combination of the maximum net power of the engines and the lift/drag ratio of the wings. The diagonal line after the range-at-maximum-payload point shows how reducing the payload allows increasing the fuel (and range) when taking off with the maximum take-off weight.
The second kink in the curve represents the point at which the maximum fuel capacity is reached. Flying further than that point means that the payload has to be reduced further, for an even lesser increase in range. The absolute range is thus the range at which an aircraft can fly with maximum possible fuel without carrying any payload.
Examples.
Examples of payload capacity:
Structural capacity.
For aircraft, the weight of fuel in wing tanks does not contribute as significantly to the bending moment of the wing as does weight in the fuselage. So even when the airplane has been loaded with its maximum payload that the wings can support, it can still carry a significant amount of fuel.
Payload constraints.
Launch and transport system differ not only on the payload that can be carried but also in the stresses and other factors placed on the payload. The payload must not only be lifted to its target, it must also arrive safely, whether elsewhere on the surface of the Earth or a specific orbit. To ensure this the payload, such as a warhead or satellite, is designed to withstand certain amounts of various types of "punishment" on the way to its destination. Most rocket payloads are fitted within a payload fairing to protect them against dynamic pressure of high-velocity travel through the atmosphere, and to improve the overall aerodynamics of the launch vehicle. Most aircraft payloads are carried within the fuselage for similar reasons. Outsize cargo may require a fuselage with unusual proportions, such as the Super Guppy.
The various constraints placed on the launch system can be roughly categorized into those that cause physical damage to the payload and those that can damage its electronic or chemical makeup. Examples of physical damage include extreme accelerations over short time scales caused by atmospheric buffeting or oscillations, extreme accelerations over longer time scales caused by rocket thrust and gravity, and sudden changes in the magnitude or direction of the acceleration caused by how quick engines are throttled and shut down, etc. Electrical, chemical, or biological payloads can be damage by extreme temperatures (hot or cold), rapid changes in temperature or pressure, contact with fast moving air streams causing ionization, and radiation exposure from cosmic rays, the van Allen belt, or solar wind.

</doc>
<doc id="41496" url="https://en.wikipedia.org/wiki?curid=41496" title="Pseudo bit error ratio">
Pseudo bit error ratio

Pseudo bit error ratio (PBER) in adaptive high-frequency (HF) radio, is a bit error ratio derived by a majority decoder that processes redundant transmissions. 
"Note:" In adaptive HF radio automatic link establishment, PBER is determined by the extent of error correction, such as by using the fraction of non-unanimous votes in the 2-of-3 majority decoder. 

</doc>
<doc id="41497" url="https://en.wikipedia.org/wiki?curid=41497" title="PCS switching center">
PCS switching center

PCS switching center: In personal communications service, a facility that (a) supports access-independent call control/service control, and connection control (switching) functions, and (b) is responsible for interconnection of access and network systems to support end-to-end services. 
"Note 1:" The PCS switching center represents a collection of one or more network elements. 
"Note 2:" The term ""center"" does not imply a physical location.

</doc>
<doc id="41498" url="https://en.wikipedia.org/wiki?curid=41498" title="Greater Poland Voivodeship">
Greater Poland Voivodeship

Greater Poland Voivodeship (in Polish: "Województwo Wielkopolskie" ), also known as Wielkopolska Voivodeship or Wielkopolska Province, is a voivodeship, or province, in west-central Poland. It was created on 1 January 1999 out of the former Poznań, Kalisz, Konin, Piła and Leszno Voivodeships, pursuant to the Polish local government reforms adopted in 1998. The province is named after the region called Greater Poland or "Wielkopolska" . The modern province includes most of this historic region, except for some south-western parts.
Greater Poland Voivodeship is second in area and third in population among Poland's sixteen voivodeships, with an area of and a population of close to 3.4 million. Its capital city is Poznań; other important cities include Kalisz, Konin, Piła, Ostrów Wielkopolski, Gniezno (an early capital of Poland) and Leszno. It is bordered by seven other voivodeships: West Pomeranian to the northwest, Pomeranian to the north, Kuyavian-Pomeranian to the north-east, Łódź to the south-east, Opole to the south, Lower Silesian to the southwest and Lubusz to the west.
The city of Poznań has international twinning arrangements with the English county of Nottinghamshire.
History.
Greater Poland, sometimes called the "cradle of Poland," formed the heart of the 10th-century early Polish state. Poznań and Gniezno were early centers of royal power, but following the region's devastation by pagan rebellion in the 1030s, and an invasion by Bretislaus I of Bohemia in 1038, the capital was moved by Casimir the Restorer from Gniezno to Kraków.
In the testament of Bolesław III Krzywousty, which initiated the period of fragmentation of Poland (1138–1320), the western part of Greater Poland (including Poznań) was granted to Mieszko III the Old. The eastern part, with Gniezno and Kalisz, was part of the Duchy of Kraków, granted to Władysław II. However, for most of the period the two parts were under a single ruler, and were known as the Duchy of Greater Poland (although at times there were separately ruled duchies of Poznań, Gniezno, Kalisz and Ujście). The region came under the control of Władysław I the Elbow-High in 1314, and thus became part of the reunited Poland of which Władyslaw was crowned king in 1320.
In the reunited kingdom, and later in the Polish–Lithuanian Commonwealth, the country came to be divided into administrative units called voivodeships. In the case of the Greater Poland region these were Poznań Voivodeship and Kalisz Voivodeship. The Commonwealth also had larger subdivisions known as "prowincja", one of which was named Greater Poland. However, this "prowincja" covered a larger area than the Greater Poland region itself, also taking in Masovia and Royal Prussia. (This division of Crown Poland into two entities called Greater and Lesser Poland had its roots in the Statutes of Casimir the Great of 1346–1362, where the laws of "Greater Poland" – the northern part of the country – were codified in the Piotrków statute, with those of "Lesser Poland" in the separate Wiślica statute.)
In 1768 a new Gniezno Voivodeship was formed out of the northern part of Kalisz Voivodeship. However more far-reaching changes would come with the Partitions of Poland. In the first partition (1772), northern parts of Greater Poland along the Noteć (German "Netze") were taken over by Prussia, becoming the Netze District. In the second partition (1793) the whole of Greater Poland was absorbed by Prussia, becoming part of the province of South Prussia. It remained so in spite of the first Greater Poland Uprising (1794), part of the unsuccessful Kościuszko Uprising directed chiefly against Russia.
More successful was the Greater Poland Uprising of 1806, which led to the region's becoming part of the Napoleonic Duchy of Warsaw (forming the Poznań Department and parts of the Kalisz and Bydgoszcz Departments). However, following the Congress of Vienna in 1815, Greater Poland was again partitioned, with the western part (including Poznań) going to Prussia. The eastern part joined the Russian-controlled Kingdom of Poland, where it formed the Kalisz Voivodeship until 1837, then the Kalisz Governorate (merged into the Warsaw Governorate between 1844 and 1867).
Within the Prussian empire, western Greater Poland became the Grand Duchy of Posen (Poznań), which theoretically held some autonomy. Following an unrealized uprising in 1846, and the more substantial but still unsuccessful uprising of 1848 (during the Spring of Nations), the Grand Duchy was replaced by the Province of Posen. The authorities made efforts to Germanize the region, particularly after the founding of Germany in 1871, and from 1886 onwards the Prussian Settlement Commission was active in increasing German land ownership in formerly Polish areas.
Following the end of World War I, the Greater Poland Uprising (1918–1919) ensured that most of the region became part of the newly independent Polish state, forming most of Poznań Voivodeship (1921–1939). Northern and some western parts of Greater Poland remained in Germany, where they formed much of the province of Posen-West Prussia (1922–1938), whose capital was Schneidemühl (Piła).
Following the German invasion of 1939, Greater Poland was incorporated into Nazi Germany, becoming the province called Reichsgau Posen, later Reichsgau Wartheland ("Warthe" being the German name for the Warta river). The Polish population was oppressed, with many former officials and others considered potential enemies by the Nazis being imprisoned or executed, including at the notorious Fort VII concentration camp in Poznań. Poznań was declared a stronghold city "(Festung)" in the closing stages of the war, being taken by the Red Army in the Battle of Poznań, which ended on 22 February 1945.
After the war, Greater Poland was fully within the Polish People's Republic, as Poznań Voivodeship. With the reforms of 1975 this was divided into smaller provinces (the voivodeships of Kalisz, Konin, Leszno and Piła, and a smaller Poznań Voivodeship). The present-day Greater Poland Voivodeship, again with Poznań as its capital, was created in 1999.
Cities and towns.
The voivodeship contains 109 cities and towns. These are listed below in descending order of population (according to official figures for 2006 ):
Geography.
Topography.
The relief of Greater Poland, geological conditions and soil have been shaped by two glaciations:
The highest elevation is Greater Kobyla Mountain (284 m) in the Ostrzeszowski Hills, the lowest area is located in the valley of the Warta River at the mouth of its tributary the Noteć (21 m) in the north-western part of the region. Agriculturally fertile soils account for around 60% of the province's area, while 20%, the rest of the non-forested or urban areas, is mostly wetland soil (muck-peat and alluvial soils).
An area of approximately 800 thousand hectares is covered by forests, this represents around 25.8% of the total surface area of the region.
In the lake districts of the northern and central parts of the province there are about 800 lakes; 58% of which cover an area of at least 10 hectares and 8%, with an area exceeding 100 hectares. The largest reservoir is the natural Greater Powidzkie Lake (1036 ha) in the Gniezno Lake District.
Wielkopolska Region lies within the basin of the Oder River, 88% of the province's surface water drains into the Warta river basin, and the remaining 12% is drained by a multitude of other river systems, including the Barycz, Ladislaus Trench and Obrzycy waterways. The quality of river waters is generally poor, but their condition is gradually improving and should soon be classed as 'clean'.
Geology.
The main mineral energy resources in Greater Poland are lignite, natural gas, oil and peat.
Brown coal deposits are currently mined in the Konin area, and form the basis for the province's power industry (the Pątnów-Adams-Konin coal-fired power stations account for more than 10% of the national electricity production). The region also has significant quantities of peat deposits; it is calculated that there are ca. 886 thousand hectares of land covered with an average thickness of 1.5 m of peat. An abundance of raw materials used in the production of numerous medicines was recently discovered in the muds of Błażejewo, Oderbank and Mechnacz. In addition, very large deposits of brown coal have been discovered in the vicinity of Kościan, these however are not currently being extracted and probably never will be extracted, due to the expense that would be incurred in adapting the site to build a coal mine and the need to resettle thousands of people.
Rock salt is mined intensively at a salt mine in Kłodawa (this mine alone accounts for about 20% of domestic production).
Throughout the province there are significant deposits of aggregates, gypsum, ceramic materials, and lacustrine chalk. In Kościan the largest and most modern, a natural gas production site is in operation. It supplies raw material for Kościańska Zieme, and Zielona Gora CHP. It is estimated that at the rate local gas reserves are being exploited, the reserves in Kościan will be enough for about 20 years of operation, thus practically allowing for local independence against the effects of gas crises.
Climate.
Wielkopolska is influenced by oceanic air masses that affect the mildness of the climate. The farther east one travels the more distinctly continental the climate becomes. The area is situated in the Silesian Greater Poland agro-climatic region where the average annual temperature is about 8.2 °C, and in the north drops to around 7.6 °C. It is slightly warmer in the south and west where the average temperature is usually about 8.5 °C. The number of days with snow can reach up to 57 days in and around the Kalisz district.
The growing season is one of the longest in Poland. On the province's southern plains this season constitutes around 228 days, while north of Gniezno and Szamotuły this gradually declines to 216 days.
Precipitation ranges from 500 to 550 mm. Despite this the region is still faced with a deficit in rainfall, particularly in the eastern part of the province (around Słupcy, Kazimierz Biskupi, Kleczew) where sometimes experience only 450 mm of rainfall per year, this threatens steppization of the region. Throughout the province there is typically a prevailing westerly wind.
Transportation.
Greater Poland is a major transport hub within Poland, a great deal of traffic from Russia and other states of the former Soviet Union pass through Poznań and Konin to reach Germany and other EU member states. To the south runs the international route from Gdańsk via Poznań and Leszno to Prague and then to the south of Europe. There is also a major highway being built in the province, the A2 motorway, which when completed will run from the western border of Poland with Germany, through Poznań to Warsaw and then onwards via Belarus to Moscow.
The main railway hubs located in Greater Poland are Poznań, Piła and Ostrów Wielkopolski. PKP Intercity operate a number of trains a day between Warsaw and Berlin which provide a fast connection for the two cities also to Poznań. This route was the first in Poland, adapted for use by the European high-speed transportation system.
In the near future the government expects to construct a high-speed rail line in the shape of a Y connecting Kalisz and Poznań from Łódź, Warsaw and Wrocław.
Poznań is the port of arrival for most international travellers as it is plays host to Ławica International Airport which has recently seen the second highest passenger growth rate in the country.
Politics.
The Greater Poland voivodeship's government is headed by the province's voivode "(governor)" who is appointed by the Polish Prime Minister. The voivode is then assisted in performing his duties by the voivodeship's marshal, who is the appointed speaker for the voivodeship's executive and is elected by the sejmik "(provincial assembly)". The current voivode of Greater Poland is Piotr Florek, whilst the present marshal is Marek Woźniak.
The Sejmik of Greater Poland consists of 39 members.
Administrative division.
Greater Poland Voivodeship is divided into 35 counties (powiats): 4 city counties and 31 land counties. These are further divided into 226 gminas.
The counties are listed in the following table (ordering within categories is by decreasing population).
Protected areas.
Protected areas in Greater Poland Voivodeship include two National Parks and 12 Landscape Parks. These are listed below.

</doc>
<doc id="41500" url="https://en.wikipedia.org/wiki?curid=41500" title="Penetration">
Penetration

Penetration may refer to:
In popular culture

</doc>
<doc id="41501" url="https://en.wikipedia.org/wiki?curid=41501" title="Performance management">
Performance management

Performance management (PM) includes activities which ensure that goals are consistently being met in an effective and efficient manner. Performance management can focus on the performance of an organization, a department, employee, or even the processes to build a product or service, as well as many other areas.
PM is also known as a process by which organizations align their resources, systems and employees to strategic objectives and priorities.
Application.
This is used most often in the workplace, can apply wherever people interact — schools, churches, community meetings, sports teams, health setting, governmental agencies, social events, and even political settings - anywhere in the world people interact with their environments to produce desired effects. Armstrong and Baron (1998) defined it as a “strategic and integrated approach to increase the effectiveness of companies by improving the performance of the people who work in them and by developing the capabilities of teams and individual contributors.”
It may be possible to get all employees to reconcile personal goals with organizational goals and increase productivity and profitability of an organization using this process. It can be applied by organizations or a single department or section inside an organization, as well as an individual person. The performance process is appropriately named the self-propelled performance process (SPPP).
First, a commitment analysis must be done where a job mission statement is drawn up for each job. The job mission statement is a job definition in terms of purpose, customers, product and scope. The aim with this analysis is to determine the continuous key objectives and performance standards for each job position.
Following the commitment analysis is the work analysis of a particular job in terms of the reporting structure and job description. If a job description is not available, then a systems analysis can be done to draw up a job description. The aim with this analysis is to determine the continuous critical objectives and performance standards for each job.
Werner Erhard, Michael C. Jensen, and their colleagues have developed a new approach to improving performance in organizations. Their model stresses how the constraints imposed by one’s own worldview can impede cognitive abilities that would otherwise be available. Their work delves into the source of performance, which is not accessible by mere linear cause-and-effect analysis. They assert that the level of performance that people achieve correlates with how work situations occur to them and that language (including what is said and unsaid in conversations) plays a major role in how situations occur to the performer. They assert that substantial gains in performance are more likely to be achieved by management understanding how employees perceive the world and then encouraging and implementing changes that make sense to employees' worldview. 
Benefits.
Managing employee or system performance and aligning their objectives facilitates the effective delivery of strategic and operational goals. Some proponents argue that there is a clear and immediate correlation between using performance management programs or software and improved business and organizational results. In the public sector, the effects of performance management systems have differed from positive to negative, suggesting that differences in the characteristics of performance management systems and the contexts into which they are implemented play an important role to the success or failure of performance management.
For employee performance management, using integrated software, rather than a spreadsheet based recording system, may deliver a significant return on investment through a range of direct and indirect sales benefits, operational efficiency benefits and by unlocking the latent potential in every employees work day (i.e. the time they spend not actually doing their job). Benefits may include:
Organizational development.
In organizational development (OD), "performance" can be thought of as Actual Results vs Desired Results. Any discrepancy, where Actual is less than Desired, could constitute the performance improvement zone. Performance management and improvement can be thought of as a cycle:
A performance problem is any gap between Desired Results and Actual Results. Performance improvement is any effort targeted at closing the gap between Actual Results and Desired Results.
Other organizational development definitions are slightly different. The U.S. Office of Personnel Management (OPM) indicates that Performance Management consists of a system or process whereby:
Performance management in companies.
Many people equate performance management with performance appraisal. This is a common misconception. Performance management is the term used to refer to activities, tools, processes, and programs that companies create or apply to manage the performance of individual employees, teams, departments, and other organizational units within their organizational influence. In contrast, performance appraisal refers to the act of appraising or evaluating performance during a given performance period to determine how well an employee, a vendor or an organizational unit has performed relative to agreed objectives or goals, and this is only one of many important activities within the overall concept of performance management.
At the workplace, performance management is implemented by employees with supervisory roles. Normally, the goal of managing performance is to allow individual employees to find out how well they had performed relative to performance targets or key performance indicators during a specific performance period from their supervisors and managers. 
Organizations and companies typically manage employee performance over a formal 12-month period (otherwise known as the formal company performance period).
The results of performance management exercises are used:

</doc>
<doc id="41502" url="https://en.wikipedia.org/wiki?curid=41502" title="Performance measurement period">
Performance measurement period

In telecommunication, performance measurement period is the period during which performance parameters are measured. 
A performance measurement period is determined by required confidence limits and may vary as a function of the observed parameter values. User time is divided into consecutive performance measurement periods to enable measurement of user information transfer reliability.

</doc>
<doc id="41503" url="https://en.wikipedia.org/wiki?curid=41503" title="Periscope antenna">
Periscope antenna

In telecommunication, a periscope antenna is an antenna configuration in which the transmitting antenna is oriented to produce a vertical radiation pattern, and a flat or off-axis parabolic reflector, mounted above the transmitting antenna, is used to direct the beam in a horizontal path toward the receiving antenna. 
A periscope antenna facilitates increased terrain clearance without long transmission lines, while permitting the active equipment to be located at or near ground level for ease of maintenance.

</doc>
<doc id="41506" url="https://en.wikipedia.org/wiki?curid=41506" title="Personal mobility">
Personal mobility

In Universal Personal Telecommunications (UPT), personal mobility is the ability of a user to access telecommunication services at any UPT terminal on the basis of a personal identifier, and the capability of the network to provide those services in accord with the user's service profile. 
Personal mobility involves the network's capability to locate the terminal associated with the user for the purposes of addressing, routing, and charging the user for calls. "Access" is intended to convey the concepts of both originating and terminating services. Management of the service profile by the user is not part of personal mobility. The personal mobility aspects of personal communications are based on the UPT number.

</doc>
<doc id="41507" url="https://en.wikipedia.org/wiki?curid=41507" title="Phantom circuit">
Phantom circuit

In telecommunication and electrical engineering, a phantom circuit is an electrical circuit derived from suitably arranged wires with one or more conductive paths being a circuit in itself and at the same time acting as one conductor of another circuit. 
Phantom group.
A phantom group is composed of three circuits that are derived from two single-channel circuits to form a "phantom circuit". Here the phantom circuit is a third circuit derived from two suitably arranged pairs of wires, called side circuits, with each pair of wires being a circuit in itself and at the same time acting as one conductor of the third circuit. The "side circuits" within phantom circuits can be coupled to their respective voltage drops by center-tapped transformers, usually called "repeating coils". The center taps are on the line side of the side circuits. Current from the phantom circuit is split evenly by the center taps. This cancels crosstalk from the phantom circuit to the side circuits. 
Phantom working increased the number of circuits on long distance routes in the early 20th century without putting up more wires. Phantoming declined with the adoption of carrier systems. 
It is theoretically possible to create a phantom circuit from two other phantom circuits and so on up in a pyramid with a maximum 2n-1 circuits being derived from n original circuits. However, more than one level of phantoming is usually impractical. Isolation between the phantom circuit and the side circuits relies on accurate balance of the line and transformers. Imperfect balance results in crosstalk between the phantom and side circuits and this effect accumulates as each level of phantoms is added. Even small levels of crosstalk are unacceptable on analogue telecommunications circuits since speech crosstalk is still intelligible down to quite low levels.
Phantom microphone powering.
Condenser microphones have impedance converter (current amplifier) circuitry that requires powering; in addition, the capsule of any non-electret, non-RF condenser microphone requires a polarizing voltage to be applied. Since the mid- to late 1960s most balanced, professional condenser microphones for recording and broadcast have used phantom powering. It can be provided by outboard AC or battery supplies, but nowadays is most often built into the mixing console, recorder or microphone preamplifier to which the microphones are connected.
By far the most common circuit uses +48 VDC fed through a matched pair of 6.8 kOhm resistors for each input channel. This arrangement has been standardized by the IEC and ISO, along with a less-commonly-used arrangement with +12 VDC and 680 Ohm feed resistors.
As a practical matter, phantom powering allows the same two-conductor shielded cables to be used for both dynamic microphones and condenser microphones, while being harmless to balanced microphones that aren't designed to consume it, since the circuit balance prevents any substantial DC from flowing through the output circuit of those microphones.
DC phantom.
Simple DC signalling can be achieved on a telecommunications line in a similar way to phantom powering of microphones. A switch connected to the transformer centre-tap at one end of the line can operate a similarly connected relay at the other end. The return path is through the ground connection. This arrangement can be used for remotely controlling equipment.
Carrier circuit phantoms.
From the 1950s to around the 1980s, using phantoms on star-quad trunk carrier circuits was a popular method of deriving a high quality broadcast audio circuit. The multiplexed FDM telecommunications carrier system usually did not use the baseband of the cable because it was inconvenient to separate low frequencies with filters. On the other hand, a one-way audio phantom could be formed from the two pairs (go and return signals) making up the star-quad cable.
Unloaded phantom.
Unloaded phantom is a phantom configuration of loaded lines (a circuit fitted with loading coils). The idea here is not to create additional circuits. Rather, the purpose is to cancel or greatly reduce the effect of the loading coils fitted to a line. The reason for doing this is that loaded lines have a definite cut-off frequency and it may be desired to equalise the line to a frequency which is higher than this, for example to make a circuit suitable for use by a broadcaster. Ideally, the loading would be removed or reduced for a permanent connection, but this is not feasible for temporary arrangements such as a requirement for outside broadcast. Instead, two circuits in a phantom configuration can be used to greatly reduce the inductance being inserted by the loading coils, and hence the loading effect.
It works because the loading coils used on balanced lines have two windings, one for each leg of the circuit. They are both wound on a common core and the windings are so arranged that the magnetic flux induced by both of them is in the same direction. Both windings induce an emf in each other as well as their own self-induction. This effect greatly increases the inductance of the coil and hence its loading effectiveness. By contrast, when the circuit is in the phantom configuration the currents in the two wires of each pair are in the same direction and the magnetic flux is being cancelled. This has precisely the opposite effect and the inductance is greatly reduced.
This configuration is most commonly used on the two pairs of a star-quad cable. It is not so successful with other pairs of wires. The difference in the path of the two pairs can easily destroy the balance and results in crosstalk and interference.
This configuration can also be called "bunched pairs". However, "bunched pairs" can also refer to the straightforward connection of two lines in parallel which is not a phantom circuit and will not reduce the loading.

</doc>
<doc id="41508" url="https://en.wikipedia.org/wiki?curid=41508" title="Phase angle">
Phase angle

In the context of phasors, phase angle refers to the angular component of the complex number representation of the function. The notation formula_1  for a vector with magnitude (or "amplitude") "A" and phase angle θ, is called angle notation.
This notation is frequently used to represent an electrical impedance. In this case the phase angle is the phase difference between the voltage applied to the impedance and the current driven through it.
In the context of periodic phenomena, such as a wave, "phase angle" is synonymous with phase.
Bioelectric impedance.
In bioelectrical impedance analysis in humans, an estimate of the phase angle can be obtained and is based on changes in resistance and reactance as alternating current passes through tissues, which causes a phase shift. The measured phase angle therefore depends on several biological factors. Phase angle is greater in men than women, and decreases with increasing age.

</doc>
<doc id="41509" url="https://en.wikipedia.org/wiki?curid=41509" title="Phased array">
Phased array

In antenna theory, a phased array is an array of antennas in which the relative phases of the respective signals feeding the antennas are set in such a way that the effective radiation pattern of the array is reinforced in a desired direction and suppressed in undesired directions. The phase relationships among the antennas may be fixed, as is usual in a tower array, or may be adjustable, as for beam steering.
History.
Phased array transmission was originally shown in 1905 by Nobel laureate Karl Ferdinand Braun who demonstrated enhanced transmission of radio waves in one direction. During World War II, Nobel laureate Luis Alvarez used phased array transmission in a rapidly steerable radar system for "ground-controlled approach", a system to aid in the landing of aircraft. At the same time, the GEMA in Germany built the PESA Mammut 1. It was later adapted for radio astronomy leading to Nobel Prizes for Physics for Antony Hewish and Martin Ryle after several large phased arrays were developed at the University of Cambridge. This design is also used for radar, and is generalized in interferometric radio antennas. In 2007, DARPA researchers announced a 16 element phased array radar antenna which was also integrated with all the necessary circuits on a single silicon chip and operated at 30–50 GHz.
The relative amplitudes of—and constructive and destructive interference effects among—the signals radiated by the individual antennas determine the effective radiation pattern of the array. A phased array may be used to point a fixed radiation pattern, or to scan rapidly in azimuth or elevation. Simultaneous electrical scanning in both azimuth and elevation was first demonstrated in a phased array antenna at Hughes Aircraft Company, California in 1957.
Phased arrays are used in optical communication as a wavelength-selective splitter.
For information about active and passive phased array radars, see also active electronically scanned array.
Broadcasting.
In broadcast engineering, phased arrays are used by many AM broadcast radio stations to enhance signal strength and therefore coverage in the city of license, while minimizing interference to other areas. Due to the differences between daytime and nighttime ionospheric propagation at mediumwave frequencies, it is common for AM broadcast stations to change between day (groundwave) and night (skywave) radiation patterns by switching the phase and power levels supplied to the individual antenna elements (mast radiators) daily at sunrise and sunset. For shortwave broadcasts many stations use arrays of horizontal dipoles. A common arrangement uses 16 dipoles in a 4×4 array. Usually this is in front of a wire grid reflector. The phasing is often switchable to allow Beam steering in azimuth and sometimes elevation.
More modest phased array longwire antenna systems may be employed by private radio enthusiasts to receive longwave, mediumwave (AM) and shortwave radio broadcasts from great distances.
On VHF, phased arrays are used extensively for FM broadcasting. These greatly increase the antenna gain, magnifying the emitted RF energy toward the horizon, which in turn greatly increases a station's broadcast range. In these situations, the distance to each element from the transmitter is identical, or is one (or other integer) wavelength apart. Phasing the array such that the lower elements are slightly delayed (by making the distance to them longer) causes a downward beam tilt, which is very useful if the antenna is quite high on a radio tower.
Other phasing adjustments can increase the downward radiation in the far field without tilting the main lobe, creating null fill to compensate for extremely high mountaintop locations, or decrease it in the near field, to prevent excessive exposure to those workers or even nearby homeowners on the ground. The latter effect is also achieved by half-wave spacing – inserting additional elements halfway between existing elements with full-wave spacing. This phasing achieves roughly the same horizontal gain as the full-wave spacing; that is, a five-element full-wave-spaced array equals a nine- or ten-element half-wave-spaced array.
Radar.
Phased array radar systems are also used by warships of many navies. Because of the rapidity with which the beam can be steered, phased array radars allow a warship to use one radar system for surface detection and tracking (finding ships), air detection and tracking (finding aircraft and missiles) and missile uplink capabilities. Before using these systems, each surface-to-air missile in flight required a dedicated fire-control radar, which meant that ships could only engage a small number of simultaneous targets. Phased array systems can be used to control missiles during the mid-course phase of the missile's flight. During the terminal portion of the flight, continuous-wave fire control directors provide the final guidance to the target. Because the radar beam is electronically steered, phased array systems can direct radar beams fast enough to maintain a fire control quality track on many targets simultaneously while also controlling several in-flight missiles.
The AN/SPY-1 phased array radar, part of the Aegis Combat System deployed on modern U.S. cruisers and destroyers, "is able to perform search, track and missile guidance functions simultaneously with a capability of over 100 targets." Likewise, the Thales Herakles phased array multi-function radar used in service with France and Singapore has a track capacity of 200 targets and is able to achieve automatic target detection, confirmation and track initiation in a single scan, while simultaneously providing mid-course guidance updates to the MBDA Aster missiles launched from the ship. The German Navy and the Royal Dutch Navy have developed the Active Phased Array Radar System (APAR). The MIM-104 Patriot and other ground-based antiaircraft systems use phased array radar for similar benefits.
Phased arrays are used in naval sonar, in active (transmit and receive) and passive (receive only) and hull-mounted and towed array sonar.
Space probe communication.
The "MESSENGER" spacecraft was a space probe mission to the planet Mercury (2011–2015). This was the first deep-space mission to use a phased-array antenna for communications. The radiating elements are linearly-polarized, slotted waveguides. The antenna, which uses the X band, used 26 radiative elements and can gracefully degrade.
Weather research usage.
The National Severe Storms Laboratory has been using a SPY-1A phased array antenna, provided by the US Navy, for weather research at its Norman, Oklahoma facility since April 23, 2003. It is hoped that research will lead to a better understanding of thunderstorms and tornadoes, eventually leading to increased warning times and enhanced prediction of tornadoes. Current project participants include the National Severe Storms Laboratory and National Weather Service Radar Operations Center, Lockheed Martin, United States Navy, University of Oklahoma School of Meteorology, School of Electrical and Computer Engineering, and Atmospheric Radar Research Center, Oklahoma State Regents for Higher Education, the Federal Aviation Administration, and Basic Commerce and Industries. The project includes research and development, future technology transfer and potential deployment of the system throughout the United States. It is expected to take 10 to 15 years to complete and initial construction was approximately $25 million.
Optics.
Within the visible or infrared spectrum of electromagnetic waves it is possible to construct optical phased arrays. They are used in wavelength multiplexers and filters for telecommunication purposes, laser beam steering, and holography. Synthetic array heterodyne detection is an efficient method for multiplexing an entire phased array onto a single element photodetector.
Radio-frequency identification (RFID).
By 2014, phased array antennas were integrated into RFID systems to increase the area of coverage of a single system by 100% to while still using traditional passive UHF tags.
Human-machine interfaces (HMI).
A phased array of acoustic transducers, denominated airborne ultrasound tactile display (AUTD), was developed at the University of Tokyo's Shinoda Lab to induce tactile feedback. This system was demonstrated to enable a user to interactively manipulate virtual holographic objects.
Mathematical perspective and formulas.
A phased array is an example of "N"-slit diffraction. It may also be viewed as the coherent addition of "N" line sources. Since each individual antenna acts as a slit, emitting radio waves, their diffraction pattern can be calculated by adding the phase shift φ to the fringing term.
We will begin from the "N"-slit diffraction pattern derived on the diffraction formalism page.

</doc>
<doc id="41510" url="https://en.wikipedia.org/wiki?curid=41510" title="Phase distortion">
Phase distortion

In signal processing, phase distortion or phase-frequency distortion is distortion, that is, change in the shape of the waveworm, that occurs when (a) a filter's phase response is not linear over the frequency range of interest, that is, the phase shift introduced by a circuit or device is not directly proportional to frequency, or (b) the zero-frequency intercept of the phase-frequency characteristic is not 0 or an integral multiple of 2π radians.
Audibility of phase distortion.
Grossly changed phase relationships, without changing amplitudes, can be audible but the degree of audibility of the type of phase shifts expected from typical sound systems remains debated.

</doc>
<doc id="41511" url="https://en.wikipedia.org/wiki?curid=41511" title="Phase inversion">
Phase inversion

Phase inversion is the swapping of the two poles of an alternating current source. A phase inversion is neither a time shift nor a phase shift, but simply a swap of plus and minus.
For example, in a push-pull power amplifier using vacuum tubes, the signal is most often "split" by a phase splitter (aka phase inverter) stage which produces two signals, one "in phase", and the other "out of phase", that is, phase inverted. These two sinep signals then drive the two halves of the first push-pull stage, which may be either the output stage (in which case the phase splitter will be in between the driver stage if there is one and the output stage) or the driver stage. The other common arrangements for driving a push-pull stage are by using an isolation transformer to produce the split signals, or by using the in-phase half of the first push-pull stage to drive the other half. A common circuit using this last technique is the long-tailed pair, often seen in television sets and oscilloscopes. 
In solid state electronics all of these techniques can be used, and phase inversion can also be produced by the use of NPN/PNP complementary circuitry, which has no corresponding technique in vacuum tube designs. 
Phase inversion may occur with a random or periodic, symmetrical or non-symmetrical waveform, although it is usually produced by the inversion of a symmetrical periodic signal, resulting in a change in sign. A symmetrical periodic signal represented by "f" ("t" ) = "A" ej"ωt", after phase inversion, becomes "f" 1("t" ) = Aej(ω"t" +π), where "t" is time, "A" is the magnitude of the vector, ω is angular frequency (ω = 2π"f" ), where "f" is the frequency and π ≈3.1416 and e ≈ 2.7183. The algebraic sum of "f" ("t" ) and "f" 1("t" ) will always be zero.

</doc>
<doc id="41512" url="https://en.wikipedia.org/wiki?curid=41512" title="Voivodeships of Poland">
Voivodeships of Poland

A województwo (; plural: "województwa") is the highest-level administrative subdivision of Poland, corresponding to a "province" in many other countries. The term ""województwo"" has been in use since the 14th century, and is commonly translated in English as "province". The word ""województwo"" is also rendered as "voivodeship" () or a variant spelling.
The Polish local government reforms adopted in 1998, which went into effect on 1 January 1999, created sixteen new voivodeships. These replaced the 49 former voivodeships that had existed from 1 July 1975.
Today's voivodeships are mostly named after historical and geographical regions, while those prior to 1998 generally took their names from the cities on which they were centered. The new units range in area from under (Opole Voivodeship) to over (Masovian Voivodeship), and in population from one million (Lubusz Voivodeship) to over five million (Masovian Voivodeship).
Administrative authority at the voivodeship level is shared between a government-appointed governor called a voivode ("wojewoda"), an elected assembly called a sejmik, and an executive board chosen by that assembly, headed by a voivodeship marshal ("marszałek województwa"). Voivodeships are further divided into powiats (counties) and gminas (communes or municipalities): see Administrative divisions of Poland.
Voivodeships since 1999.
Administrative powers.
Competences and powers at voivodeship level are shared between the voivode (governor), the sejmik (regional assembly) and the marshal. In most cases these institutions are all based in one city, but in Kuyavian-Pomeranian and Lubusz Voivodeship the voivode's offices are in a different city from those of the executive and the sejmik. Voivodeship capitals are listed in the table below.
The voivode is appointed by the Prime Minister and is the regional representative of the central government. The voivode acts as the head of central government institutions at regional level (such as the police and fire services, passport offices, and various inspectorates), manages central government property in the region, oversees the functioning of local government, coordinates actions in the field of public safety and environment protection, and exercises special powers in emergencies. The voivode's offices collectively are known as the "urząd wojewódzki".
The sejmik is elected every four years, at the same time as the local authorities at powiat and gmina level. It passes bylaws, including the voivodeship's development strategies and budget. It also elects the "marszałek" and other members of the executive, and holds them to account.
The executive ("zarząd województwa"), headed by the "marszałek" drafts the budget and development strategies, implements the resolutions of the sejmik, manages the voivodeship's property, and deals with many aspects of regional policy, including management of European Union funding. The marshal's offices are collectively known as the "urząd marszałkowski".
Former voivodeships.
Poland's voivodeships 1975–1998.
Administrative division of Poland between 1979 and 1998 included 49 voivodeships upheld after the establishment of the Third Polish Republic in 1989 for another decade. This reorganization of administrative division of Poland was mainly a result of local government reform acts of 1973–1975. In place of the three-level administrative division (voivodeship, county, commune), a new two-level administrative division was introduced (49 small voivodeships, and communes). The three smallest voivodeships – Warsaw, Kraków and Łódź – had the special status of municipal voivodeship; the city president (mayor) was also provincial governor.
Poland's voivodeships 1945–1975.
After World War II, the new administrative division of the country within the new national borders was based on the prewar one and included 14 (+2) voivodeships, then 17 (+5). The voivodeships in the east that had not been annexed by the Soviet Union had their borders left almost unchanged. The newly acquired territories in the west and north were organized into the new voivodeships of Szczecin, Wrocław and Olsztyn, and partly joined to Gdańsk, Katowice and Poznań voivodeships. Two cities were granted voivodeship status: Warsaw and Łódź.
In 1950, new voivodeships were created: Koszalin (previously part of Szczecin), Opole (previously part of Katowice), and Zielona Góra (previously part of Poznań, Wrocław and Szczecin voivodeships).
In 1957, three more cities were granted voivodeship status: Wrocław, Kraków and Poznań.
Poland's voivodeships 1921–1939.
The administrative division of Poland in the interwar period included 16 voivodeships and Warsaw (with voivodeship rights).
They were very similar to the current voivodeships.
Congress Poland 1816–1837.
From 1816 to 1837 there were 8 voivodeships in Congress Poland.
Etymology and use of "voivodeship".
Some English-language sources, in historic contexts, speak of "palatinates" rather than "voivodeships"; the former term traces back to the Latin "palatinus" ("palatine"). More commonly used now is "voivodeship", a loanword-calque hybrid formed on the Polish ""województwo"". Other sources refer instead to "provinces" (Polish singular: ""prowincja""), though in pre-1795 contexts this may be confusing because the cognate Polish ""prowincyja"" (as it was then spelled) was idiosyncratically applied, until the last of the three Partitions of the Polish–Lithuanian Commonwealth, in 1795, to each of the three main Regions (Greater Poland, Lesser Poland, and Lithuania) of the Polish–Lithuanian Commonwealth, each of those Regions in turn comprising a number of "województwa" (plural of ""województwo"").
The Polish ""województwo"", designating a second-tier Polish or Polish–Lithuanian administrative unit, derives from ""wojewoda"" (etymologically, a "warlord", "war leader" or "leader of warriors", but now simply the governor of a "województwo") and the suffix ""-stwo"" (a "state or condition").
The English "voivodeship", which is a hybrid of the loanword "voivode" and "-ship" (the latter a suffix, likewise meaning a "state or condition", that calques the Polish ""-stwo""), has never been much used and is absent from many dictionaries. According to the "Oxford English Dictionary", it first appeared in 1792, spelled "woiwodship", in the sense of "the district or province governed by a voivode." The word subsequently also appeared in 1886 in the sense of "the office or dignity of a voivode."
An official Polish body, the Commission on Standardization of Geographic Names outside the Republic of Poland, recommends the spelling "voivodship", without the "e".This is consistently reflected in publications [http://ksng.gugik.gov.pl/english/sopgn.php and in the international arena, e.g., at the United Nations.[http://ksng.gugik.gov.pl/pliki/gegn22wp18.pdf]

</doc>
<doc id="41515" url="https://en.wikipedia.org/wiki?curid=41515" title="Cod">
Cod

Cod is the common name for the genus "Gadus" of demersal fishes, belonging to the family Gadidae. Cod is also used as part of the common name for a number of other fish species, and there are species suggested to belong to genus "Gadus" that are not called cod (the Alaska pollock).
The two most common species of cod are the Atlantic cod ("Gadus morhua"), which lives in the colder waters and deeper sea regions throughout the North Atlantic, and the Pacific cod ("Gadus macrocephalus"), found in both eastern and western regions of the northern Pacific. "Gadus morhua" was named by Linnaeus in 1758. (However, "G. morhua callarias", a low-salinity, non-migratory race restricted to parts of the Baltic, was originally described as "Gadus callarias" by Linnaeus.)
Cod is popular as a food with a mild flavour and a dense, flaky white flesh. Cod livers are processed to make cod liver oil, an important source of vitamin A, vitamin D, vitamin E and omega-3 fatty acids (EPA and DHA). Young Atlantic cod or haddock prepared in strips for cooking is called scrod. In the United Kingdom, Atlantic cod is one of the most common ingredients in fish and chips, along with haddock and plaice.
Species.
At various times in the past, taxonomists included many species in the genus "Gadus". Most of these are now either classified in other genera, or have been recognized as simply forms of one of three species. All these species have a number of common names, most of them ending with the word "cod", whereas other species, as closely related, have other common names (such as pollock and haddock). On the other hand, many other, unrelated species also have common names ending with cod. The usage often changes with different localities and at different times.
Cod in the genus "Gadus".
There are three species in the "Gadus" genus currently called cod:
Related species.
"Cod" forms part of the common name of many other fish no longer classified in the genus "Gadus". Many are members of the family Gadidae; others are members of three related families within the order Gadiformes whose names include the word "cod": the morid cods, Moridae (100 or so species); the eel cods, Muraenolepididae (four species); and the Eucla cod, Euclichthyidae (one species). The tadpole cod family (Ranicipitidae) has now been placed in Gadidae.
Gadiformes include:
Some fish have common names derived from "cod", such as codling, codlet or tomcod. ("Codling" is also used as a name for a young cod.)
Other species.
Some fish commonly known as cod are unrelated to "Gadus". Part of this name confusion is market-driven. Severely shrunken Atlantic cod stocks have led to the marketing of cod replacements using culinary names of the form ""x" cod", according to culinary rather than phyletic similarity. The common names for the following species have become well established; note that all inhabit the Southern Hemisphere.
Fish of the order Perciformes that are commonly called "cod" include:
Almost all coral cod, reef cod or rock cod are also in order Perciformes. Most are better known as groupers, and belong to the family Serranidae. Others belong to the Nototheniidiae. Two exceptions are the Australasian red rock cod, which belongs to a different order (see below), and the fish known simply as the rock cod and as soft cod in New Zealand, "Lotella rhacina", which as noted above actually is related to the true cod (it is a morid cod).
From the order Scorpaeniformes:
The tadpole cod family, Ranicipitidae, and the Eucla cod family, Euclichthyidae, were formerly classified in the order Ophidiiformes, but are now grouped with the Gadiformes.
Marketed as cod.
Some fish that do not have "cod" in their names are sometimes sold as cod. Haddock and whiting belong in the same family, the Gadidae, as cod.
Characteristics.
Cods of the genus "Gadus" have three rounded dorsal and two anal fins. The pelvic fins are small, with the first ray extended, and are set under the gill cover (i.e. the throat region), in front of the pectoral fins. The upper jaw extends over the lower jaw, which has a well-developed chin barbel. The eyes are medium-sized, approximately the same as the length of the chin barbel. Cod have a distinct white lateral line running from the gill slit above the pectoral fin, to the base of the caudal or tail fin. The back tends to be a greenish to sandy brown, and shows extensive mottling, especially towards the lighter sides and white belly. Dark brown colouration of the back and sides is not uncommon, especially for individuals that have resided in rocky inshore regions.
The Atlantic cod can change colour at certain water depths. It has two distinct colour phases: gray-green and reddish brown. Its average weight is , but specimens weighing up to have been recorded. Pacific cod are smaller than Atlantic cod and are darker in colour.
Distribution.
Atlantic cod ("Gadus morhua") live in the colder waters and deeper sea regions throughout the North Atlantic. Pacific cod ("Gadus macrocephalus") is found in both eastern and western regions of the Pacific.
Atlantic cod divide into several stocks, including the Arcto-Norwegian, North Sea, Faroe, Iceland, East Greenland, West Greenland, Newfoundland, and Labrador stocks. There seems to be little interchange between the stocks, although migrations to their individual breeding grounds may involve distances of or more.
Atlantic cod occupy varied habitat, favouring rough ground, especially inshore, and are demersal in depths between , on average, although not uncommonly to depths of . Off the Norwegian and New England coasts and on the Grand Banks of Newfoundland, cod congregate at certain seasons in water of depth. Cod are gregarious and form schools, although shoaling tends to be a feature of the spawning season.
Life cycle.
Spawning of northeastern Atlantic cod occurs between January and April (March and April are the peak months), at a depth of in specific spawning grounds at water temperatures between . Around the UK, the major spawning grounds are in the middle to southern North Sea, the start of the Bristol Channel (north of Newquay), the Irish Channel (both east and west of the Isle of Man), around Stornoway, and east of Helmsdale.
Prespawning courtship involves fin displays and male grunting, which leads to pairing. The male inverts himself beneath the female, and the pair swim in circles while spawning. The eggs are planktonic and hatch between eight and 23 days, with larva reaching in length. This planktonic phase lasts some ten weeks, enabling the young cod to increase its body weight by 40-fold, and growing to about . The young cod then move to the seabed and change their diet to small benthic crustaceans, such as isopods and small crabs. They increase in size to in the first six months, by the end of their first year, and to by the end of the second. Growth tends to be less at higher latitudes. Cod reach maturity at about at about 3 to 4 years of age.
Ecology.
Adult cod are active hunters, feeding on sand eels, whiting, haddock, small cod, squid, crabs, lobsters, mussels, worms, mackerel, and molluscs.
In the Baltic Sea the most important species are Atlantic cod, herring, and sprat. Many studies that analyze the stomach contents of these fish indicate that cod is the top predator, preying on the herring and sprat. Sprat form particularly high concentrations in the Bornholm Basin in the southern Baltic Sea. Although cod feed primarily on adult sprat, sprat tend to prey on the cod eggs and larvae.
Cod and related species are plagued by parasites. For example, the cod worm, "Lernaeocera branchialis", starts life as a copepod, a small free-swimming crustacean larva. The first host used by cod worm is a flatfish or lumpsucker, which they capture with grasping hooks at the front of their body. They penetrate the lumpsucker with a thin filament which they use to suck its blood. The nourished cod worms then mate on the lumpsucker. The female worm, with her now fertilized eggs, then finds a cod, or a cod-like fish such as a haddock or whiting. There the worm clings to the gills while it metamorphoses into a plump, sinusoidal, wormlike body, with a coiled mass of egg strings at the rear. The front part of the worms body penetrates the body of the cod until it enters the rear bulb of the host's heart. There, firmly rooted in the cod's circulatory system, the front part of the parasite develops like the branches of a tree, reaching into the main artery. In this way, the worm extracts nutrients from the cod's blood, remaining safely tucked beneath the cod's gill cover until it releases a new generation of offspring into the water. 
Fisheries.
The 2006 northwest Atlantic cod quota is 23,000 tons, representing half the available stocks, while the northeast Atlantic quota is 473,000 tons. Pacific cod is currently enjoying strong global demand. The 2006 total allowable catch (TAC) for the Gulf of Alaska and Aleutian Islands was 260,000 tons.
Aquaculture.
Farming of Atlantic cod has received a significant amount of interest due to the overall trend of increasing cod prices alongside reduced wild catches. However, progress in creating large scale farming of cod has been slow, mainly due to bottlenecks in the larval production stage, where survival and growth are often unpredictable. It has been suggested that this bottleneck may be overcome by ensuring cod larvae are fed diets with similar nutritional content as the copepods they feed on in the wild Recent examples have shown that increasing dietary levels of minerals such as selenium, iodine and zinc may improve survival and/or biomarkers for health in aquaculture reared cod larvae.
As food.
Cod is popular as a food with a mild flavor and a dense, flaky white flesh. Cod livers are processed to make cod liver oil, an important source of vitamin A, vitamin D, vitamin E and omega-3 fatty acids (EPA and DHA).
Young Atlantic cod or haddock prepared in strips for cooking is called scrod. In the United Kingdom, Atlantic cod is one of the most common ingredients in fish and chips, along with haddock and plaice. Cod's soft liver can be tinned (canned) and eaten. Cod is mainly consumed in Portugal, Spain, Italy and Brazil.
USDA data: Pacific cod; Atlantic cod
Management.
Following the early 1990s collapse of Canadian stocks, the Canadian Department of Fisheries and Oceans (DFO) banned fishing for northern (that is, cod to the north and east of the island of Newfoundland, in NAFO areas JKL) cod in 1992, which caused great economic hardship in Newfoundland and Labrador. The collapse was blamed on cold water, or seals, and it had even been suggested the cod were really still there; only rarely was overfishing acknowledged, or management's role in that.
The DFO partly lifted its ban in 1997, although the International Council for the Exploration of the Sea noted the poor recovery of Canadian cod stocks. In general, depleted populations of cod and other gadids appear to recover poorly when fishing pressure is reduced or stopped.
In 1998, the Committee on the Status of Endangered Wildlife in Canada (COSEWIC) listed the Atlantic cod as "vulnerable", a category subsequently rebranded as "special concern", though not as an endangered species. Dr. Kim Bell, who drafted the report for COSEWIC, subsequently stated the original report in fact "had" advised endangered status, but political pressure by the DFO within COSEWIC had resulted in a decision of "vulnerable".
In 2000, WWF placed cod on the endangered species list. The WWF issued a report stating the global cod catch had suffered a 70% drop over the last 30 years, and if this trend continued, the world’s cod stocks would disappear in 15 years. Åsmund Bjordal, director of the Norwegian Institute of Marine Research disputed the WWF's claim, noting the healthy Barents Sea cod population. Cod (known in Norway as skrei) is among Norway's most important fishery exports and the Barents Sea is Norway's most important cod fishery. In 2015, the Norwegian Seafood Council invited Crown Prince Haakon to take part in opening the year’s cod fishing season at Senja.
In 2003, under the new legislative framework of the Species At Risk Act , COSEWIC placed the Newfoundland and Labrador fisheries cod on the endangered species list and Fisheries Minister Robert Thibault announced an indefinite closure in the Gulf of St. Lawrence and off Newfoundland's northeast coast. In a 2004 report, the WWF agreed the Barents Sea cod fishery appeared to be healthy, but that the situation may not last due to illegal fishing, industrial development, and high quotas. In 2005, the WWF—Canada accused both foreign and Canadian fishing vessels of deliberate, large-scale violations of the restrictions on the Grand Banks, in the form of bycatch. WWF also claimed poor enforcement by NAFO, an intergovernmental organization with a mandate to provide scientific fishery advice and management in the northwestern Atlantic.
In 2006, the Norwegian Institute of Marine Research considered coastal cod (but not the North East Arctic cod) endangered, but has since reversed this assessment. In 2010, Greenpeace International added the Atlantic cod to its seafood red list. "The Greenpeace International seafood red list is a list of fish that are commonly sold in supermarkets around the world, and which have a very high risk of being sourced from unsustainable fisheries." According to Seafood Watch, cod is currently on the list of fish consumers should avoid. In the book , it is claimed cod is an example of how unsustainable fishing is destroying ocean ecosystems.
In a letter to "Nature" in 2011, a group of Canadian scientists reported that cod in the Scotian Shelf ecosystem off Canada are showing signs of recovery.
History.
Cod has been an important economic commodity in international markets since the Viking period (around 800 AD). Norwegians traveled with dried cod and soon a dried cod market developed in southern Europe. This market has lasted for more than 1,000 years, enduring the Black Death, wars and other crises, and is still an important Norwegian fish trade. The Portuguese began fishing cod in the 15th century. Clipfish is widely enjoyed in Portugal. The Basques played an important role in the cod trade, and allegedly found the Canadian fishing banks before Columbus' discovery of America. The North American east coast developed in part due to the vast cod stocks. Many cities in the New England area are located near cod fishing grounds. The fish was so important to the history and development of Massachusetts, the state's House of Representatives hung a wood carving of a codfish, known as the Sacred Cod of Massachusetts, in its chambers.
Apart from the long history, cod differ from most fish because the fishing grounds are far from population centers. The large cod fisheries along the coast of North Norway (and in particular close to the Lofoten islands) have been developed almost uniquely for export, depending on sea transport of stockfish over large distances. Since the introduction of salt, dried and salted cod (clipfish or 'klippfisk' in Norwegian) has also been exported. By the end of the 14th century, the Hanseatic League dominated trade operations and sea transport, with Bergen as the most important port.
William Pitt the Elder, criticizing the Treaty of Paris in Parliament, claimed cod was "British gold"; and that it was folly to restore Newfoundland fishing rights to the French.
In the 17th and 18th centuries in the New World, especially in Massachusetts and Newfoundland, cod became a major commodity, creating trade networks and cross-cultural exchanges. In 1733, Britain tried to gain control over trade between New England and the British Caribbean by imposing the Molasses Act, which they believed would eliminate the trade by making it unprofitable. The cod trade grew instead, because the "French were eager to work with the New Englanders in a lucrative contraband arrangement". In addition to increasing trade, the New England settlers organized into a "codfish aristocracy". The colonists rose up against Britain's "tariff on an import".
In the 20th century, Iceland re-emerged as a fishing power and entered the Cod Wars. In the late 20th and early 21st centuries, fishing off the European and American coasts severely depleted stocks and become a major political issue. The necessity of restricting catches to allow stocks to recover upset the fishing industry and politicians reluctant to hurt employment.

</doc>
<doc id="41519" url="https://en.wikipedia.org/wiki?curid=41519" title="Photic zone">
Photic zone

The photic zone, euphotic zone (Greek for "well lit": "well" + "light"), or sunlight zone is the depth of the water in a lake or ocean that is exposed to such intensity of sunlight which designates compensation point, i.e. the intensity of light at which the rate of carbon dioxide uptake, or equivalently, the rate of oxygen production, is equal to the rate of carbon dioxide production, equivalently to the rate of oxygen consumption, reducing thus the net carbon dioxide assimilation to zero. 
It extends from the surface down to a depth where light intensity falls to one percent of that at the surface, called the euphotic depth. Accordingly, its thickness depends on the extent of light attenuation in the water column. Typical euphotic depths vary from only a few centimetres in highly turbid eutrophic lakes, to around 200 metres in the open ocean. It also varies with seasonal changes in turbidity.
Since the photic zone is where almost all of the photosynthesis occurs, the depth of the photic zone is generally proportional to the level of primary production that occurs in that area of the ocean. About 90% of all marine life lives in the photic zone. A small amount of primary production is generated deep in the abyssal zone around the hydrothermal vents which exist along some mid-oceanic ridges.
The zone which extends from the base of the euphotic zone to about 200 metres is sometimes called the disphotic zone. While there is some light, it is insufficient for photosynthesis, or at least insufficient for photosynthesis at a rate greater than respiration. The euphotic zone together with the disphotic zone coincides with the epipelagic zone. The bottommost zone, below the euphotic zone, is called the aphotic zone. Most deep ocean waters belong to this zone. 
The transparency of the water, which determines the depth of the photic zone, is measured simply with a Secchi disk. It may also be measured with a photometer lowered into the water.

</doc>
<doc id="41520" url="https://en.wikipedia.org/wiki?curid=41520" title="Masovian Voivodeship">
Masovian Voivodeship

Masovian Voivodeship or Mazovia Province ( ), is the largest and most populous of the sixteen Polish provinces, or voivodeships, created in 1999. It occupies of east-central Poland, and has 5,324,500 inhabitants. Its principal cities are Warsaw (1.729 million) in the centre of the Warsaw metropolitan area, Radom (226,000) in the south, Płock (127,000) in the west, Siedlce (77,000) in the east, and Ostrołęka (55,000) in the north. The capital of the voivodeship is the national capital, Warsaw.
The province was created on January 1, 1999, out of the former Warsaw, Płock, Ciechanów, Ostrołęka, Siedlce and Radom Voivodeships, pursuant to the Polish local government reforms adopted in 1998. The province's name recalls the traditional name of the region, "Mazowsze" (sometimes rendered in English as "Masovia"), with which it is roughly coterminous. However, southern part of the voivodeship, with Radom, historically belongs to Małopolska (Lesser Poland), while Łomża and its surroundings, even though historically part of Masovia, now is part of Podlaskie Voivodeship.
It is bordered by six other voivodeships: Warmian-Masurian to the north, Podlaskie to the north-east, Lublin to the south-east, Świętokrzyskie to the south, Łódź to the south-west, and Kuyavian-Pomeranian to the north-west.
Administrative division.
Masovian Voivodeship is divided into 42 counties ("powiats"): 5 city counties ("miasto na prawach powiatu") and 37 "land counties" ("powiat ziemski"). These are subdivided into 314 gminas, which include 85 "urban gminas".
Cities and towns.
The voivodeship contains 85 cities and towns. These are listed below in descending order of population (according to official figures for 2006):
Protected areas.
Protected areas in Masovian Voivodeship include one National Park and nine Landscape Parks. These are listed below.
Historical.
Masovian Voivodeship (1526–1795).
Masovia Voivodeship, 1526–1795 () was an administrative region of the Kingdom of Poland, and of the Polish-Lithuanian Commonwealth, from the 15th century until the partitions of the Polish-Lithuanian Commonwealth (1795). Together with Płock and Rawa Voivodeships, it formed the province (prowincja) of Masovia.
Masovian Voivodeship (1816–1837).
Masovian Voivodeship was one of the voivodeships of Congress Poland. It was formed from Warsaw Department, and transformed into Masovia Governorate.
Transport.
There are three main road routes that pass through the voivodship: Cork-Berlin-Poznań-Warszawa-Minsk-Moscow-Omsk, Prague-Wrocław-Warsaw-Białystok-Helsinki and Pskov-Gdańsk-Warsaw-Kraków-Budapest.
Currently there are only small stretches of autostrada in the area. However, the A2 autostrada, upon its completion, will be the first autostrada to connect the region, and therefore the capital city, with the rest of Europe. The autostrada will pass directly through the voivodship from east to west connecting it with Belarus and Germany.
The railroad system is based on Koleje Mazowieckie and PKP Intercity.
The main international airport in the region is Warsaw Frederic Chopin Airport.
Economy.
Masovian Voivodeship is the wealthiest in Poland. It produces 22% of Polish GDP, and GDP per capita is 160% of country average.

</doc>
<doc id="41522" url="https://en.wikipedia.org/wiki?curid=41522" title="Northanger Abbey">
Northanger Abbey

Northanger Abbey was the first of Jane Austen's novels to be completed for publication, though she had previously made a start on "Sense and Sensibility" and "Pride and Prejudice". According to Cassandra Austen's "Memorandum", "Susan" (as it was first called) was written circa 1798–99. It was revised by Austen for the press in 1803, and sold in the same year for £10 to a London bookseller, Crosby & Co., who decided against publishing. In the spring of 1816, the bookseller was content to sell it back to the novelist's brother, Henry Austen, for the exact sum—£10—that he had paid for it at the beginning, not knowing that the writer was by then the author of four popular novels.
The novel was further revised by Austen in 1816/17, with the intention of having it published. Among other changes, the lead character's name was changed from Susan to Catherine, and Austen retitled the book "Catherine" as a result.
Austen died in July 1817. "Northanger Abbey" (as the novel was now called) was brought out posthumously in late December 1817 (1818 given on the title page), as the first two volumes of a four-volume set that also featured another previously unpublished Austen novel, "Persuasion". Neither novel was published under the title Jane Austen had given it; the title "Northanger Abbey" is presumed to have been the invention of Henry Austen, who had arranged for the book's publication.
Plot summary.
Seventeen-year-old Catherine Morland is one of ten children of a country clergyman. She was born in room 114 of Murray Hall. Although a tomboy in her childhood, by the age of 17 she is "in training for a heroine" and is excessively fond of reading Gothic novels, among which Ann Radcliffe's "Mysteries of Udolpho" is a favourite.
Catherine is invited by the Allens, her wealthier neighbours in Fullerton, to accompany them to visit the town of Bath and partake in the winter season of balls, theatre and other social delights. Although initially the excitement of Bath is dampened by her lack of acquaintances, she is soon introduced to a clever young gentleman, Henry Tilney, with whom she dances and converses. Much to Catherine's disappointment, Henry does not reappear in the subsequent week and, not knowing whether or not he has left Bath for good, she wonders if she will ever see him again. Through Mrs Allen's old school-friend Mrs Thorpe, she meets her daughter Isabella, a vivacious and flirtatious young woman, and the two quickly become friends. Mrs Thorpe's son John is also a friend of Catherine's older brother, James, at Oxford where they are both students.
James and John arrive unexpectedly in Bath. While Isabella and James spend time together, Catherine becomes acquainted with John, a vain and crude young gentleman who incessantly tells fantastical stories about himself. Henry Tilney then returns to Bath, accompanied by his younger sister Eleanor, who is a sweet, elegant, and respectable young lady. Catherine also meets their father, the imposing General Tilney.
The Thorpes are not very happy about Catherine's friendship with the Tilneys, as they (correctly as it happens) perceive Henry as a rival for Catherine's affections. Catherine tries to maintain her friendships with both the Thorpes and the Tilneys, though John Thorpe continuously tries to sabotage her relationship with the Tilneys. This leads to several misunderstandings, which upset Catherine and put her in the awkward position of having to explain herself to the Tilneys.
Isabella and James become engaged. James's father approves of the match and offers his son a country parson's living of a modest sum, 400 pounds annually, which he may have in two and a half years. The couple must therefore wait until that time to marry. Isabella is dissatisfied, having believed that the Morlands were quite wealthy, but she pretends to Catherine that she is merely dissatisfied that they must wait so long. James departs to purchase a ring, and John accompanies him after coyly suggesting marriage to the oblivious Catherine. Isabella immediately begins to flirt with Captain Tilney, Henry's older brother. Innocent Catherine cannot understand her friend's behaviour, but Henry understands all too well, as he knows his brother's character and habits. The flirtation continues even when James returns, much to the latter's embarrassment and distress.
The Tilneys invite Catherine to stay with them for a few weeks at their home, Northanger Abbey. Catherine, in accordance with her novel reading, expects the abbey to be exotic and frightening. Henry teases her about this, as it turns out that Northanger Abbey is pleasant and decidedly not Gothic. However, the house includes a mysterious suite of rooms that no one ever enters; Catherine learns that they were Mrs Tilney's, who died nine years earlier. Catherine decides that, since General Tilney does not now seem to be affected by the loss of his wife, he may have murdered her or even imprisoned her in her chamber.
Catherine persuades Eleanor to show her Mrs Tilney's rooms, but General Tilney suddenly appears. Catherine flees, sure that she will be punished. Later, Catherine sneaks back to Mrs Tilney's rooms, to discover that her over-active imagination has once again led her astray, as nothing is strange or distressing in the rooms at all. Unfortunately, Henry joins her in the corridor and questions why she is there. He guesses her surmises and inferences, and informs her that his father loved his wife in his own way and was truly upset by her death. "What have you been judging from? Remember the country and the age in which we live. Remember that we are English, that we are Christians. Consult your own understanding, your own sense of the probable, your own observation of what is passing around you. Does our education prepare us for such atrocities? Do our laws connive at them? ... Dearest Miss Morland, what ideas have you been admitting?" She leaves, crying, fearing that she has lost Henry's regard entirely.
Realizing how foolish she has been, Catherine comes to believe that, though novels may be delightful, their content does not relate to everyday life. Henry lets her get over her shameful thoughts and actions in her own time and does not mention them to her again.
Soon after this adventure, James writes to inform her that he has broken off his engagement to Isabella and that she has become engaged instead to Captain Tilney. Henry and Eleanor Tilney are shocked but rather skeptical that their brother has actually become engaged to Isabella Thorpe. Catherine is terribly disappointed, realising what a dishonest person Isabella is. A subsequent letter from Isabella herself confirms the Tilney siblings' doubts about the engagement and shows that Frederick Tilney was merely flirting with Isabella. The General goes off to London, and the atmosphere at Northanger Abbey immediately becomes lighter and pleasanter for his absence. Catherine passes several enjoyable days with Henry and Eleanor until, in Henry's absence, the General returns abruptly, in a temper. He forces Eleanor to tell Catherine that the family has an engagement that prevents Catherine from staying any longer and that she must go home early the next morning, in a shocking, inhospitable move that forces Catherine to undertake the journey alone.
At home, Catherine is listless and unhappy. Her parents, unaware of her trials of the heart, try to bring her up to her usual spirits, with little effect. Two days after she returns home, however, Henry pays a sudden unexpected visit and explains what happened. General Tilney (on the misinformation of John Thorpe) had believed her to be exceedingly rich and therefore a proper match for Henry. In London, General Tilney ran into Thorpe again, who, angry at Catherine's refusal of his half-made proposal of marriage, said instead that she was nearly destitute. Enraged, General Tilney returned home to evict Catherine. When Henry returned to Northanger from Woodston, his father informed him of what had occurred and forbade him to think of Catherine again. When Henry learns how she had been treated, he breaks with his father and tells Catherine he still wants to marry her despite his father's disapproval. Catherine is delighted.
Eventually, General Tilney acquiesces, because Eleanor has become engaged to a wealthy and titled man; and he discovers that the Morlands, while not extremely rich, are far from destitute.
Characters.
Catherine Morland: A 17-year-old girl who loves reading Gothic novels. Something of a tomboy in her childhood, her looks are described by the narrator as "pleasing, and, when in good looks, pretty." Catherine lacks experience and sees her life as if she was a heroine in a Gothic novel. She sees the best in people, and to begin with always seems ignorant of other people's malign intentions. She is the devoted sister of James Morland. She is good-natured and frank and often makes insightful comments on the inconsistencies and insincerities of people around her, usually to Henry Tilney, and thus is unintentionally sarcastic and funny. (He is delighted when she says, "I cannot speak well enough to be unintelligible.") She is also seen as a humble and modest character, becoming exceedingly happy when she receives the smallest compliment. Catherine's character grows throughout the novel, as she gradually becomes a real heroine, learning from her mistakes when she is exposed to the outside world in Bath. She sometimes makes the mistake of applying Gothic novels to real life situations; for example, later in the novel she begins to suspect General Tilney of having murdered his deceased wife. Catherine soon learns that Gothic novels are really just fiction and do not always correspond with reality.
James Morland: Catherine's older brother who is in school at the beginning of the story. Assumed to be of moderate wealth, he becomes the love interest of Isabella Thorpe, the younger sister to his friend and Catherine's admirer John Thorpe.
Henry Tilney: A 26-year-old well-read clergyman, the younger son of the wealthy Tilney family. He is Catherine's romantic interest throughout the novel, and during the course of the plot he comes to return her feelings. He is sarcastic, intuitive, fairly handsome and clever, given to witticisms and light flirtations (which Catherine is not always able to understand or reciprocate in kind), but he also has a sympathetic nature (he is a good brother to Eleanor), which leads him to take a liking to Catherine's naïve straightforward sincerity.
John Thorpe: An arrogant and extremely boastful young man who certainly appears distasteful to the likes of Catherine. He is Isabella's brother and he has shown many signs of feelings towards Catherine Morland.
Isabella Thorpe: A manipulative and self-serving young woman on a quest to obtain a well-off husband; at the time, marriage was the accepted way for young women of a certain class to become "established" with a household of their own (as opposed to becoming a dependent spinster), and Isabella lacks most assets (such as wealth or family connections to bring to a marriage) that would make her a "catch" on the "marriage market". Upon her arrival in Bath she is without acquaintance, leading her to immediately form a quick friendship with Catherine Morland. Additionally, when she learns that Catherine is the sister to James Morland (whom Isabella suspects to be worth more financially than he is in reality), she goes to every length to ensure a connection between the two families.
General Tilney: A stern and rigid retired general with an obsessive nature, General Tilney is the sole surviving parent to his three children Frederick, Henry, and Eleanor.
Eleanor Tilney: Henry's sister, she plays little part in Bath, but takes on more importance in Northanger Abbey. A convenient chaperon for Catherine and Henry's times together. Obedient daughter, warm friend, sweet sister, but lonely under her father's tyranny.
Frederick Tilney: Henry's older brother (the presumed heir to the Northanger estate), very handsome and fashionable, an officer in the army who enjoys pursuing flirtations with pretty girls who are willing to offer him some encouragement (though without any ultimate serious intent on his part).
Mr. Allen: A kindly man, with some slight resemblance to Mr. Bennet of "Pride and Prejudice".
Mrs. Allen: Somewhat vacuous, she sees everything in terms of her obsession with clothing and fashion, and has a tendency to utter repetitions of remarks made by others in place of original conversation.
Major themes.
In addition, Catherine Morland realises she is not to rely upon others, such as Isabella, who are negatively influential on her, but to be single-minded and independent. It is only through bad experiences that Catherine really begins to mature and grow up.
Allusions to other works.
Several Gothic novels and authors are mentioned in the book, including Fanny Burney and "The Monk". Isabella Thorpe gives Catherine a list of seven books that are commonly referred to as the "Northanger 'horrid' novels"; these works were initially thought to be of Austen's own invention until the British writers Montague Summers and Michael Sadleir found that they actually did exist. The list is as follows:
All seven of these were republished by the Folio Society in London in 1968, and since 2005 Valancourt Books has released new editions of the first six.
Literary significance and relationship.
"Northanger Abbey" is fundamentally a parody of Gothic fiction. Austen turns the conventions of eighteenth-century novels on their head, by making her heroine a plain and undistinguished girl from a middle-class family, allowing the heroine to fall in love with the hero before he has a serious thought of her, and exposing the heroine's romantic fears and curiosities as groundless. Austen biographer Claire Tomalin speculates that Austen may have begun this book, which is more explicitly comic than her other works and contains many literary allusions that her parents and siblings would have enjoyed, as a family entertainment—a piece of lighthearted parody to be read aloud by the fireside. Moreover, as Joan Aiken writes,
Austen addresses the reader directly in parts, particularly at the end of Chapter 5, where she gives a lengthy opinion of the value of novels, and the contemporary social prejudice against them in favour of drier historical works and newspapers. In discussions featuring Isabella, the Thorpe sisters, Eleanor, and Henry, and by Catherine perusing the library of the General, and her mother's books on instructions on behaviours, the reader gains further insights into Austen's various perspectives on novels in contrast with other popular literature of the time (especially the Gothic novel). Eleanor even praises history books, and while Catherine points out the obvious fiction of the speeches given to important historical characters, Eleanor enjoys them for what they are.
The directness with which Austen addresses the reader, especially at the end of the story, gives a unique insight into Austen's thoughts at the time, which is particularly important due to the fact that a large portion of her letters were burned, at her request, by her sister upon her death.
Adaptations.
Literature.
In 2012, it was announced that HarperCollins had hired Scottish crime writer Val McDermid to adapt "Northanger Abbey" for a modern audience, as a suspenseful teen thriller. McDermid said of the project, "At its heart it's a teen novel, and a satire – that's something which fits really well with contemporary fiction. And you can really feel a shiver of fear moving through it. I will be keeping the suspense – I know how to keep the reader on the edge of their seat. I think Jane Austen builds suspense well in a couple of places, but she squanders it, and she gets to the endgame too quickly. So I will be working on those things."
Historical discoveries.
The book contains an early reference to baseball. ("...Catherine, who had by nature nothing heroic about her, should prefer cricket, baseball, riding on horseback, and running about the country...").
References to "Northanger Abbey".
A passage from the novel appears as the preface of Ian McEwan's "Atonement", thus likening the naive mistakes of Austen's Catherine Morland to those of his own character Briony Tallis, who is in a similar position: both characters have very over-active imaginations, which lead to misconceptions that cause distress in the lives of people around them. Both treat their own lives like those of heroines in fantastical works of fiction, with Miss Morland likening herself to a character in a Gothic novel and young Briony Tallis writing her own melodramatic stories and plays with central characters such as "spontaneous Arabella" based on herself.
Richard Adams quotes a portion of the novel's last sentence for the epigraph to Chapter 50 in his "Watership Down"; the reference to the General is felicitous, as the villain in "Watership Down" is also a General.
See also.
Reception history of Jane Austen

</doc>
<doc id="41523" url="https://en.wikipedia.org/wiki?curid=41523" title="Bath, Somerset">
Bath, Somerset

Bath ( or ; , ), is a city in the ceremonial county of Somerset, England, known for its Roman-built baths. In 2011, the population was 88,859. Bath is in the valley of the River Avon, west of London and south-east of Bristol. The city became a World Heritage Site in 1987.
The city became a spa with the Latin name Aquae Sulis ("the waters of Sulis") c. AD 60 when the Romans built baths and a temple in the valley of the River Avon, although hot springs were known even before then. Bath Abbey was founded in the 7th century and became a religious centre; the building was rebuilt in the 12th and 16th centuries. In the 17th century, claims were made for the curative properties of water from the springs, and Bath became popular as a spa town in the Georgian era. Georgian architecture, crafted from Bath stone, includes the Royal Crescent, Circus, Pump Room and Assembly Rooms where Beau Nash presided over the city's social life from 1705 until his death in 1761. Many of the streets and squares were laid out by John Wood, the Elder, and in the 18th century the city became fashionable and the population grew. Jane Austen lived in Bath in the early 19th century. Further building was undertaken in the 19th century and following the Bath Blitz in World War II.
The city has software, publishing and service-oriented industries. Theatres, museums, and other cultural and sporting venues have helped to make it a major centre for tourism with more than one million staying visitors and 3.8 million day visitors to the city each year. There are several museums including the Museum of Bath Architecture, Victoria Art Gallery, Museum of East Asian Art, and the Holburne Museum. The city has two universities: the University of Bath and Bath Spa University, with Bath College providing further education. Sporting clubs include Bath Rugby and Bath City F.C. while TeamBath is the umbrella name for all of the University of Bath sports teams.
Bath became part of the county of Avon in 1974, and, following Avon's abolition in 1996, has been the principal centre of Bath and North East Somerset.
History.
Iron Age and Roman.
The hills in the locality such as Bathampton Down saw human activity from the Mesolithic period. Several Bronze Age round barrows were opened by John Skinner in the 18th century. Bathampton Camp may have been an Iron Age hill fort or stock enclosure. A long barrow site believed to be from the Beaker people was flattened to make way for RAF Charmy Down.
Archaeological evidence shows that the site of the Roman baths' main spring may have been treated as a shrine by the Britons, and was dedicated to the goddess Sulis, whom the Romans identified with Minerva; the name Sulis continued to be used after the Roman invasion, appearing in the town's Roman name, "Aquae Sulis" (literally, "the waters of Sulis"). Messages to her scratched onto metal, known as curse tablets, have been recovered from the sacred spring by archaeologists. The tablets were written in Latin, and cursed people whom the writers felt had wronged them. For example, if a citizen had his clothes stolen at the baths, he might write a curse, naming the suspects, on a tablet to be read by the goddess.
A temple was constructed in 60–70 AD, and a bathing complex was built up over the next 300 years. Engineers drove oak piles into the mud to provide a stable foundation, and surrounded the spring with an irregular stone chamber lined with lead. In the 2nd century, the spring was enclosed within a wooden barrel-vaulted structure that housed the caldarium (hot bath), tepidarium (warm bath), and frigidarium (cold bath).
The town was later given defensive walls, probably in the 3rd century. After the failure of Roman authority in the first decade of the 5th century, the baths fell into disrepair and were eventually lost as a result of silting.
In March 2012 a hoard of 30,000 silver Roman coins, one of the largest discovered in Britain, was unearthed in an archaeological dig. The coins, believed to date from the 3rd century, were found about 150 m (450 ft) from the Roman baths.
Post-Roman and Medieval.
Bath may have been the site of the Battle of Badon (c. 500 AD), in which King Arthur is said to have defeated the Anglo-Saxons. The town was captured by the West Saxons in 577 after the Battle of Deorham; the Anglo-Saxon poem "The Ruin" may describe the appearance of the Roman site about this time. A monastery was founded at an early date – reputedly by Saint David although more probably in 675 by Osric, King of the Hwicce, perhaps using the walled area as its precinct. Nennius, a 9th-century historian, mentions a "Hot Lake" in the land of the Hwicce along the River Severn, and adds "It is surrounded by a wall, made of brick and stone, and men may go there to bathe at any time, and every man can have the kind of bath he likes. If he wants, it will be a cold bath; and if he wants a hot bath, it will be hot". Bede described hot baths in the geographical introduction to the "Ecclesiastical History" in terms very similar to those of Nennius. King Offa of Mercia gained control of the monastery in 781 and rebuilt the church, which was dedicated to St. Peter.
By the 9th century the old Roman street pattern was lost and Bath was a royal possession. King Alfred laid out the town afresh, leaving its south-eastern quadrant as the abbey precinct. In the Burghal Hidage, Bath is recorded as a burh (borough) and is described as having walls of and was allocated 1000 men for defence. During the reign of Edward the Elder coins were minted in Bath based on a design from the Winchester mint but with 'BAD' on the obverse relating to the Anglo-Saxon name for the town, Baðum, Baðan or Baðon, meaning "at the baths", and this was the source of the present name. Edgar of England was crowned king of England in Bath Abbey in 973.
William Rufus granted the city to a royal physician, John of Tours, who became Bishop of Wells and Abbot of Bath, following the sacking of the city during the Rebellion of 1088. It was papal policy for bishops to move to more urban seats, and John of Tours translated his own from Wells to Bath. The bishop planned and began a much larger church as his cathedral, to which was attached a priory, with the bishop's palace beside it. New baths were built around the three springs. Later bishops returned the episcopal seat to Wells while retaining the name Bath in the title, Bishop of Bath and Wells. St John's Hospital was founded around 1180 by Bishop Reginald Fitz Jocelin and is among the oldest almshouses in England. The 'hospital of the baths' was built beside the hot springs of the Cross Bath, for their health-giving properties and to provide shelter for the poor infirm.
Administrative systems fell within the hundreds. The Bath Hundred had various names including the Hundred of Le Buri. The Bath Foreign Hundred or Forinsecum covered the area outside the city and was later combined into the Bath Forum Hundred. Wealthy merchants had no status within the hundred courts and formed guilds to gain influence. They built the first guildhall probably in the 13th century. Around 1200 the first mayor was appointed.
Early Modern.
By the 15th century, Bath's abbey church was badly dilapidated and Oliver King, Bishop of Bath and Wells, decided to rebuild it on a smaller scale in 1500. The new church was completed just a few years before Bath Priory was dissolved in 1539 by Henry VIII. The abbey church became derelict before being restored as the city's parish church in the Elizabethan era, when the city experienced a revival as a spa. The baths were improved and the city began to attract the aristocracy. A Royal charter granted by Queen Elizabeth I in 1590 confirmed city status.
During the English Civil War, the city was garrisoned for Charles I. Seven thousand pounds was spent on fortifications, but on the appearance of parliamentary forces the gates were thrown open and the city surrendered. It became a significant post for the New Model Army under William Waller. Bath was retaken by royalists following the Battle of Lansdowne fought on the northern outskirts of the city on 5 July 1643. Thomas Guidott, a student of chemistry and medicine at Wadham College, Oxford, set up a practice in the city in 1668. He was interested in the curative properties of the waters, and he wrote "A discourse of Bathe, and the hot waters there. Also, Some Enquiries into the Nature of the water" in 1676. It brought the health-giving properties of the hot mineral waters to the attention of the country, and the aristocracy arrived to partake in them.
Several areas of the city were developed in the Stuart period, and more building took place during Georgian times in response to the increasing number of visitors who required accommodation. Architects John Wood the Elder and his son laid out the new quarters in streets and squares, the identical façades of which gave an impression of palatial scale and classical decorum. Much of the creamy gold Bath stone, a type of limestone used for construction in the city, was obtained from the Combe Down and Bathampton Down Mines owned by Ralph Allen (1694–1764). Allen, to advertise the quality of his quarried limestone, commissioned the elder John Wood to build a country house on his Prior Park estate between the city and the mines. Allen was responsible for improving and expanding the postal service in western England, for which he held the contract for more than forty years. Although not fond of politics, Allen was a civic-minded man and a member of Bath Corporation for many years. He was elected mayor for a single term in 1742.
In the early 18th century, Bath acquired its first purpose-built theatre, the Old Orchard Street Theatre. It was rebuilt as the Theatre Royal, along with the Grand Pump Room attached to the Roman Baths and assembly rooms. Master of ceremonies Beau Nash, who presided over the city's social life from 1705 until his death in 1761, drew up a code of behaviour for public entertainments.
Late Modern.
The population of the city was 40,020 at the 1801 census, making it one of the largest cities in Britain. William Thomas Beckford bought a house in Lansdown Crescent in 1822, and subsequently two adjacent houses to form his residence. Having acquired all the land between his home and the top of Lansdown Hill, he created a garden more than in length and built Beckford's Tower at the top.
Emperor Haile Selassie of Ethiopia spent the four years in exile, from 1936 to 1940, at Fairfield House in Bath. During World War II, between the evening of 25 April and the early morning of 27 April 1942, Bath suffered three air raids in reprisal for RAF raids on the German cities of Lübeck and Rostock, part of the Luftwaffe campaign popularly known as the Baedeker Blitz. During the Bath Blitz, more than 400 people were killed, and more than 19,000 buildings damaged or destroyed. Houses in the Royal Crescent, Circus and Paragon were burnt out along with the Assembly Rooms. A high explosive bomb landed on the east side of Queen Square, resulting in houses on the south side being damaged and the Francis Hotel losing of its frontage. The buildings have all been restored although there are still signs of the bombing.
A postwar review of inadequate housing led to the clearance and redevelopment of areas of the city in a postwar style, often at variance with the local Georgian style. In the 1950s the nearby villages of Combe Down, Twerton and Weston were incorporated into the city to enable the development of housing, much of it council housing. In the 1970s and 1980s it was recognised that conservation of historic buildings was inadequate, leading to more care and reuse of buildings and open spaces. In 1987 the city was selected by UNESCO as a World Heritage Site, recognising its international cultural significance.
Since 2000, major developments have included the Thermae Bath Spa, SouthGate shopping centre and the residential Western Riverside project.
Government.
Historical development.
Bath had long been an ancient borough, having that status since 878 when it became a royal borough (burh) of Alfred the Great, and was reformed into a municipal borough in 1835. It has formed part of the county of Somerset since 878, when ceded to Wessex, having previously been in Mercia (the River Avon had acted as the border between the two kingdoms since 628). However, Bath was made a county borough in 1889, independent of the newly created administrative county and Somerset County Council. Bath became part of Avon when the non-metropolitan county was created in 1974, resulting in its abolition as a county borough and instead becoming a non-metropolitan district with borough status. With the abolition of Avon in 1996, the non-metropolitan district and borough were abolished too, and Bath has since been part of the unitary authority district of Bath and North East Somerset (B&NES). Bath was returned to the ceremonial county of Somerset in 1996, though as B&NES is a unitary authority, it is not part of the area covered by Somerset County Council.
Charter Trustees.
Because Bath is unparished, there is no longer a city council (or parish council) — Bath City Council having ended in 1996 with the abolition of the district of Bath. The City of Bath's ceremonial functions, including its formal status as a city, its twinning arrangements, the mayoralty of Bath – which can be traced back to 1230 – and control of the city's coat of arms, are maintained by the charter trustees of the City of Bath. The councillors elected by the electoral wards that cover Bath (see below) are the trustees, and they elect one of their number as mayor.
The coat of arms includes two silver strips representing the River Avon and the hot springs. The sword of St. Paul is a link to Bath Abbey. The supporters, a lion and a bear, stand on a bed of acorns, a link to Bladud, the subject of the Legend of Bath. The knight's helmet indicates a municipality and the crown is that of King Edgar.
Bath City Forum.
Bath and North East Somerset (B&NES) Council has established the Bath City Forum, compising 12 nominated B&NES councillors representing wards in Bath (and representing a cross-section of political parties), 1 cabinet member of B&NES Council, and up to 13 co-opted members drawn from the communities of the city. The first meeting of the Forum was held on 13 October 2015, at the Guildhall, where the first Chair and Vice-Chair were elected.
Parliamentary elections.
Bath is one of the oldest extant parliamentary constituencies in the United Kingdom, being in continuous existence since the Model Parliament of 1295. Before the Reform Act 1832, Bath elected two members to the unreformed House of Commons, as an ancient parliamentary borough. From 1832 until 1918 it elected two MPs and then was reduced to one.
Historically the constituency covered only the city of Bath, however it was enlarged into some outlying areas between 1997 and 2010. The constituency since 2010 once again covers exactly the city of Bath (it is co-extensive with the unparished area), and is currently represented by Conservative Ben Howlett, who replaced the retiring Liberal Democrat Don Foster at the 2015 general election. Foster's election was a notable result of the 1992 general election, as Chris Patten, the previous Member (and Cabinet Minister) played a major part, as Chairman of the Conservative Party, in re-electing the government of John Major, but failed to defend his marginal seat.
Electoral wards.
The sixteen electoral wards of the Bath and North East Somerset unitary authority within Bath (which are co-extensive with the unparished area) are: Abbey, Bathwick, Combe Down, Kingsmead, Lambridge, Lansdown, Lyncombe, Newbridge, Odd Down, Oldfield, Southdown, Twerton, Walcot, Westmoreland, Weston and Widcombe.
Geography.
Physical geography.
Bath is in the Avon Valley near the southern edge of the Cotswolds, a range of limestone hills designated as an Area of Outstanding Natural Beauty. The hills that surround and make up the city have a maximum altitude of on the Lansdown plateau. Bath has an area of .
The floodplain of the Avon, on which the city centre is built, has an altitude of about above sea level. The river, once an unnavigable series of braided streams broken up by swamps and ponds, has been managed by weirs into a single channel. Periodic flooding, which shortened the life of many buildings in the lowest part of the city, was normal until major flood control works were completed in the 1970s. Kensington Meadows is an area of mixed woodland and open meadow next to the river which has been designated as a local nature reserve.
Water bubbling up from the ground as geothermal springs originates as rain on the Mendip Hills. The rain percolates through limestone aquifers to a depth of between where geothermal energy raises the water's temperature to between 64 and 96 °C (c. 147–205 °F). Under pressure, the heated water rises to the surface along fissures and faults in the limestone. Hot water at a temperature of rises here at the rate of daily, from a geological fault (the Pennyquick fault). In 1983, a new spa-water bore-hole was sunk, providing a clean and safe supply for drinking in the Pump Room. There is no universal definition to distinguish a hot spring from a geothermal spring although, by several definitions, the Bath springs can be considered the only hot springs in the UK. Three of the springs feed the thermal baths.
Climate.
Along with the rest of South West England, Bath has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately . Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea temperatures. The summer months of July and August are the warmest, with mean daily maxima of approximately . In winter, mean minimum temperatures of are common. In the summer the Azores high pressure affects the south-west of England bringing fair weather; however, convective cloud sometimes forms inland, reducing the number of hours of sunshine. Annual sunshine rates are slightly less than the regional average of 1,600 hours. In December 1998 there were 20 days without sun recorded at Yeovilton. Most of the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which is when they are most active. In summer, a large proportion of the rainfall is caused by sun heating the ground, leading to convection and to showers and thunderstorms. Average rainfall is around . About 8–15 days of snowfall is typical. November to March have the highest mean wind speeds, and June to August have the lightest winds. The predominant wind direction is from the south-west.
Demography.
The 2011 census recorded a population of 88,859 for the city of Bath. (This figure represents the combined populations of the 16 wards that are co-extensive with the unparished area that covers the city.) An Office for National Statistics estimate of the population (for mid-2010) for the urban area was put at 97,311.
According to the 2001 census, Bath, together with North East Somerset, which includes areas around Bath as far as the Chew Valley, had a population of 169,040, with an average age of 39.9 (the national average being 38.6). Demography shows according to the same statistics, the district is overwhelmingly populated by people of a white background at 97.2% – significantly higher than the national average of 90.9%. Other ethnic groups in the district, in order of population size, are multiracial at 1%, Asian at 0.5% and black at 0.5% (the national averages are 1.3%, 4.6% and 2.1%, respectively).
The district is largely Christian at 71%, with no other religion reaching more than 0.5%. These figures generally compare with the national averages, though the non-religious, at 19.5%, are significantly more prevalent than the national 14.8%. 7.4% of the population describe themselves as "not healthy" in the last 12 months, compared with a national average of 9.2%; nationally, 18.2% of people describe themselves as having a long-term illness; in Bath it is 15.8%.
An inhabitant of Bath is known as a Bathonian.
Economy.
Industry.
Bath once had an important manufacturing sector, particularly in crane manufacture, furniture manufacture, printing, brass foundries, quarries, dye works and Plasticine manufacture, as well as many mills. Significant Bath companies included Stothert & Pitt, Bath Cabinet Makers and Bath & Portland Stone.
Nowadays, manufacturing is in decline, but the city boasts strong software, publishing and service-oriented industries, being home to companies such as Future Publishing and London & Country mortgage brokers. The city's attraction to tourists has also led to a significant number of jobs in tourism-related industries. Important economic sectors in Bath include education and health (30,000 jobs), retail, tourism and leisure (14,000 jobs) and business and professional services (10,000 jobs). Major employers are the National Health Service, the city's two universities, and the Bath and North East Somerset Council, as well as the Ministry of Defence although a number of MOD offices formerly in Bath have recently moved to Bristol. Growing employment sectors include information and communication technologies and creative and cultural industries where Bath is one of the recognised national centres for publishing, with the magazine and digital publisher Future Publishing employing around 650 people. Others include Buro Happold (400) and IPL Information Processing Limited (250). The city boasts over 400 retail shops, half of which are run by independent specialist retailers, and around 100 restaurants and cafes that are primarily supported by tourism.
Tourism.
One of Bath's principal industries is tourism, with annually more than one million staying visitors and 3.8 million day visitors. The visits mainly fall into the categories of heritage tourism and cultural tourism, aided by the city's selection in 1987 as a World Heritage Site in recognition of its international cultural importance.
All significant stages of the history of England are represented within the city, from the Roman Baths (including their significant Celtic presence), to Bath Abbey and the Royal Crescent, to the more recent Thermae Bath Spa. The size of the tourist industry is reflected in the almost 300 places of accommodation – including more than 80 hotels, two of which have 'five-star' ratings, over 180 bed and breakfasts – many of which are located in Georgian buildings, and two campsites located on the western edge of the city. The city also has about 100 restaurants and a similar number of pubs and bars. Several companies offer open top bus tours around the city, as well as tours on foot and on the river. Since the opening of Thermae Bath Spa in 2006, the city has attempted to recapture its historical position as the only town or city in the United Kingdom offering visitors the opportunity to bathe in naturally heated spring waters.
In the 2010 Google Street View Best Streets Awards, the Royal Crescent took second place in the "Britain's Most Picturesque Street" award, first place being given to The Shambles in York. Milsom Street was also awarded "Britain's Best Fashion Street" in the 11,000-strong vote.
Architecture.
There are many Roman archaeological sites throughout the central area of the city. The baths themselves are about below the present city street level. Around the hot springs, Roman foundations, pillar bases, and baths can still be seen, however all the stonework above the level of the baths is from more recent periods.
Bath Abbey was a Norman church built on earlier foundations. The present building dates from the early 16th century and shows a late Perpendicular style with flying buttresses and crocketed pinnacles decorating a crenellated and pierced parapet. The choir and transepts have a fan vault by Robert and William Vertue. A matching vault was added to the nave in the 19th century. The building is lit by 52 windows.
Most buildings in Bath are made from the local, golden-coloured Bath Stone, and many date from the 18th and 19th century. The dominant style of architecture in Central Bath is Georgian; this style evolved from the Palladian revival style that became popular in the early 18th century. Many of the prominent architects of the day were employed in the development of the city. The original purpose of much of Bath's architecture is concealed by the honey-coloured classical façades; in an era before the advent of the luxury hotel, these apparently elegant residences were frequently purpose-built lodging houses, where visitors could hire a room, a floor, or (according to their means) an entire house for the duration of their visit, and be waited on by the house's communal servants. The masons Reeves of Bath were prominent in the city from the 1770s to 1860s.
The Circus consists of three long, curved terraces designed by the elder John Wood to form a circular space or theatre intended for civic functions and games. The games give a clue to the design, the inspiration behind which was the Colosseum in Rome. Like the Colosseum, the three façades have a different order of architecture on each floor: Doric on the ground level, then Ionic on the piano nobile, and finishing with Corinthian on the upper floor, the style of the building thus becoming progressively more ornate as it rises. Wood never lived to see his unique example of town planning completed as he died five days after personally laying the foundation stone on 18 May 1754.
The most spectacular of Bath's terraces is the Royal Crescent, built between 1767 and 1774 and designed by the younger John Wood. But all is not what it seems; while Wood designed the great curved façade of what appears to be about 30 houses with Ionic columns on a rusticated ground floor, that was the extent of his input. Each purchaser bought a certain length of the façade, and then employed their own architect to build a house to their own specifications behind it; hence what appears to be two houses is sometimes one. This system of town planning is betrayed at the rear of the crescent: while the front is completely uniform and symmetrical, the rear is a mixture of differing roof heights, juxtapositions and fenestration. This "Queen Anne fronts and Mary-Anne backs" architecture occurs repeatedly in Bath. Other fine terraces elsewhere in the city include Lansdown Crescent and Somerset Place on the northern hill.
Around 1770 the neoclassical architect Robert Adam designed Pulteney Bridge, using as the prototype for the three-arched bridge spanning the Avon an original, but unused, design by Andrea Palladio for the Rialto Bridge in Venice. Thus, Pulteney Bridge became not just a means of crossing the river, but also a shopping arcade. Along with the Rialto Bridge and the Ponte Vecchio in Florence, which it resembles, it is one of the very few surviving bridges in Europe to serve this dual purpose. It has been substantially altered since it was built. The bridge was named after Frances and William Pulteney, the owners of the Bathwick estate for which the bridge provided a link to the rest of Bath. The Georgian streets in the vicinity of the river tended to be built high above the original ground level to avoid flooding, with the carriageways supported on vaults extending in front of the houses. This can be seen in the multi-storey cellars around Laura Place South of Pulteney Bridge, in the colonnades below Grand Parade, and in the grated coal holes in the pavement of North Parade. In some parts of the city, such as George Street, and London Road near Cleveland Bridge, the developers of the opposite side of the road did not match this pattern, leaving raised pavements with the ends of the vaults exposed to a lower street below.
The heart of the Georgian city was the Pump Room, which, together with its associated Lower Assembly Rooms, was designed by Thomas Baldwin, a local builder responsible for many other buildings in the city, including the terraces in Argyle Street and the Guildhall. Baldwin rose rapidly, becoming a leader in Bath's architectural history. In 1776 he was made the chief City Surveyor, and in 1780 became Bath City Architect. Great Pulteney Street, where he eventually lived, is another of his works: this wide boulevard, constructed around 1789 and over long and wide, is lined on both sides by Georgian terraces.
In the 1960s and early 1970s some parts of Bath were unsympathetically redeveloped, resulting in the loss of some 18th- and 19th century buildings. This process was largely halted by a popular campaign which drew strength from the publication of Adam Fergusson's "The Sack of Bath". Controversy has revived periodically, most recently with the demolition of the 1930s Churchill House, a neo-Georgian municipal building originally housing the Electricity Board, to make way for a new bus station. This is part of the Southgate redevelopment in which an ill-favoured 1960s shopping precinct, bus station and multi-story car park were demolished and replaced by a new area of mock-Georgian shopping streets. As a result of this and other changes, notably plans for abandoned industrial land along the Avon, the city's status as a World Heritage Site was reviewed by UNESCO in 2009. The decision was made to let Bath keep its status, but UNESCO has asked to be consulted on future phases of the Riverside development, saying that the density and volume of buildings in the second and third phases of the development need to be reconsidered. It also demands that Bath do more to attract world-class architecture in new developments.
Culture.
Bath became the centre of fashionable life in England during the 18th century when its Old Orchard Street Theatre and architectural developments such as Lansdown Crescent, the Royal Crescent, The Circus, and Pulteney Bridge were built.
Bath's five theatres – Theatre Royal, Ustinov Studio, the Egg, the Rondo Theatre, and the Mission Theatre – attract internationally renowned companies and directors and an annual season by Sir Peter Hall. The city has a long-standing musical tradition; Bath Abbey, home to the Klais Organ and the largest concert venue in the city, stages about 20 concerts and 26 organ recitals each year. Another concert venue, the 1,700-seat Art Deco Forum, originated as a cinema. The city holds the annual Bath International Music Festival and Mozartfest, the annual Bath Literature Festival (and its counterpart for children), the Bath Film Festival, the Bath Fringe Festival, the Bath Beer Festival and the Bath Chilli Festival. The Bach Festivals occur at two and a half-year intervals. An annual Bard of Bath competition aims to find the best poet, singer or storyteller.
The city is home to the Victoria Art Gallery, the Museum of East Asian Art, and Holburne Museum, numerous commercial art galleries and antique shops, as well as a number of other museums, among them Bath Postal Museum, the Fashion Museum, the Jane Austen Centre, the Herschel Museum of Astronomy and the Roman Baths. The Bath Royal Literary and Scientific Institution (BRLSI) in Queen Square was founded in 1824 from the Society for the encouragement of Agriculture, Planting, Manufactures, Commerce and the Fine Arts founded in 1777. In September 1864, BRLSI hosted the 34th annual meeting of the British Science Association, which was attended by explorers David Livingstone, Sir Richard Francis Burton, and John Hanning Speke. The history of the city is displayed at the Museum of Bath Architecture, which is housed in a building built in 1765 as the Trinity Presbyterian Church. It was also known as the Countess of Huntingdon's Chapel, as she lived in the attached house from 1707 to 1791.
Bath in the arts.
During the 18th century Thomas Gainsborough and Sir Thomas Lawrence lived and worked in Bath. John Maggs, a painter best known for coaching scenes, was born and lived in Bath with his artistic family.
Jane Austen lived here from 1801 with her father, mother and sister Cassandra, and the family resided at four different addresses until 1806. Jane Austen never liked the city, and wrote to Cassandra, "It will be two years tomorrow since we left Bath for Clifton, with what happy feelings of escape." Bath has honoured her name with the Jane Austen Centre and a city walk. Austen's "Northanger Abbey" and "Persuasion" are set in the city and describe taking the waters, social life, and music recitals.
William Friese-Greene experimented with celluloid and motion pictures in his studio in the 1870s, developing some of the earliest movie camera technology. He is credited as being one of the inventors of cinematography.
Taking the waters is described in Charles Dickens' novel "The Pickwick Papers" in which Pickwick's servant, Sam Weller, comments that the water has "a very strong flavour o' warm flat irons". The Royal Crescent is the venue for a chase between two characters, Dowler and Winkle. Moyra Caldecott's novel "The Waters of Sul" is set in Roman Bath in 72 AD, and "The Regency Detective", by David Lassman and Terence James, revolves around the exploits of Jack Swann investigating deaths in the city during the early 1800s. Richard Brinsley Sheridan's play "The Rivals" takes place in the city, as does Roald Dahl's chilling short story, "The Landlady".
Many films and television programmes have been filmed using its architecture as the backdrop, including the 2004 film of Thackeray's "Vanity Fair", "The Duchess" (2008), "The Elusive Pimpernel" (1950) and "The Titfield Thunderbolt" (1953). In 2012, Pulteney Weir was used as a replacement location during post production of the film adaptation of "Les Misérables". Stunt shots were filmed in October 2012 after footage acquired during the main filming period was found to have errors.
In August 2003 The Three Tenors sang at a concert to mark the opening of the Thermae Bath Spa, a new hot water spa in the city centre, but delays to the project meant the spa actually opened three years later on 7 August 2006. In 2008, 104 decorated pigs were displayed around the city in a public art event called "King Bladud's Pigs in Bath". It celebrated the city, its origins and artists. Decorated pig sculptures were displayed throughout the summer and were auctioned to raise funds for Two Tunnels Greenway.
Parks.
Royal Victoria Park, a short walk from the city centre, was opened in 1830 by the 11-year-old Princess Victoria, and was the first park to carry her name. The public park is overlooked by the Royal Crescent and covers . It has a skatepark, tennis courts, a bowling green, a putting green and a 12- and 18-hole golf course, a pond, open-air concerts, an annual travelling funfair at Easter, and a children's play area. Much of its area is lawn; a notable feature is a ha-ha that segregates it from the Royal Crescent while giving the impression from the Crescent of uninterrupted grassland across the park to Royal Avenue. It has a "Green Flag Award", the national standard for parks and green spaces in England and Wales, and is registered by English Heritage as of National Historic Importance. The botanical gardens were formed in 1887 and contain one of the finest collections of plants on limestone in the West Country. A replica Roman Temple was built at the British Empire Exhibition at Wembley in 1924, and, following the exhibition, was dismantled and rebuilt in Victoria Park in Bath. In 1987 the gardens were extended to include the Great Dell, a disused quarry that contains a collection of conifers.
Other parks include: Alexandra Park on a hill overlooking the city; Parade Gardens, along the river near the abbey in the city centre; Sydney Gardens, an 18th-century pleasure-garden; Henrietta Park; Hedgemead Park; and Alice Park. Jane Austen wrote that "It would be pleasant to be near the Sydney Gardens. We could go into the Labyrinth every day." Alexandra, Alice and Henrietta parks were built into the growing city among the housing developments. There is a linear park following the old Somerset and Dorset Joint Railway line. Cleveland Pools were built around 1815 close to the River Avon, now the oldest surviving public outdoor lido in England, and plans have been submitted for its restoration.
Bath and Queen Victoria.
Victoria Art Gallery and Royal Victoria Park are named after Queen Victoria, who wrote in her journal "The people are really too kind to me.". This feeling seemed to have been reciprocated by the people of Bath: "Lord James O'Brien brought a drawing of the intended pillar which the people of Bath are so kind as to erect in commemoration of my 18th birthday.".
Food.
Several foods have an association with the city. "Sally Lunn buns" (a type of teacake) have long been baked in Bath. They were first mentioned by name in verses printed in the Bath Chronicle, in 1772. At that time they were eaten hot at public breakfasts in Spring Gardens. They can be eaten with sweet or savoury toppings and are sometimes confused with "Bath buns", which are smaller, round, very sweet and very rich. They were associated with the city following The Great Exhibition. Bath buns were originally topped with crushed comfits created by dipping caraway seeds repeatedly in boiling sugar; but today seeds are added to a 'London Bath Bun' (a reference to the bun's promotion and sale at the Great Exhibition). The seeds may be replaced by crushed sugar granules or 'nibs'.
Bath has lent its name to one other distinctive recipe – "Bath Olivers" – a dry baked biscuit invented by Dr William Oliver, physician to the Mineral Water Hospital in 1740. Oliver was an anti-obesity campaigner and author of a ""Practical Essay on the Use and Abuse of warm Bathing in Gluty Cases"". In more recent years, Oliver's efforts have been traduced by the introduction of a version of the biscuit with a plain chocolate coating. "Bath Chaps", the salted and smoked cheek and jawbones of the pig, takes its name from the city and is available from a stall in the daily covered market. Bath Ales brewery is located in Warmley and Abbey Ales are brewed in the city.
Twinning.
Bath is twinned with four other cities in Europe. Twinning is the responsibility of the Charter Trustees and each twinning arrangement is managed by a Twinning Association.
There is also a historic connection with Manly, New South Wales, Australia, which is referred to as a sister city, and there is a partnership arrangement with Beppu, Ōita Prefecture, Japan.
Education.
Bath has two universities, the University of Bath and Bath Spa University. Established in 1966, the University of Bath was named University of the Year by "The Sunday Times" (2011). It offers programs in politics, languages, the physical sciences, engineering, mathematics, architecture, management and technology.
Bath Spa University was first granted degree-awarding powers in 1992 as a university college before being granted university status in August 2005. It offers courses leading to a Postgraduate Certificate in Education. It has schools in the following subject areas: Art and Design, Education, English and Creative Studies, Historical and Cultural Studies, Music and the Performing Arts, Science and the Environment and Social Sciences.
Bath College offers further education, and Norland College provides education and training in childcare.
Sport.
Bath Rugby is a rugby union team in the Aviva Premiership league. It plays in black, blue and white kit at the Recreation Ground in the city, where it has been since the late 19th century, following its establishment in 1865. The team's first major honour was winning the John Player Cup, now sponsored as the LV Cup and also known as the Anglo-Welsh Cup, four years consecutively from 1984 until 1987. The team then led the Courage league in six seasons in eight years between 1988–89 and 1995–96, during which time it also won the renamed Pilkington Cup in 1989, 1990, 1992, 1994, 1995 and 1996. It finally won the Heineken Cup in the 1997–98 season, and topped the Zürich Premiership (now Aviva Premiership) in 2003–04. The team's squad includes several members who also play, or have played in the English national team, including Lee Mears, Rob Webber, Dave Attwood, Nick Abendanon and Matt Banahan. Colston's School, Bristol, has had a large input in the team over the past decade, providing several current 1st XV squad members. The former England Rugby Team Manager and former Scotland national coach Andy Robinson used to play for Bath Rugby team and was captain and later coach. Both of Robinson's predecessors, Clive Woodward and Jack Rowell, as well as his successor Brian Ashton, were also former Bath coaches and managers.
Bath City F.C. is the major football team. Bath City gained promotion to the Conference Premier from the Conference South in 2010. Bath City F.C. play their games at Twerton Park. Until 2009 Team Bath F.C. operated as an affiliate to the University Athletics programme. In 2002, Team Bath became the first university team to enter the FA Cup in 120 years, and advanced through four qualifying rounds to the first round proper. The university's team was established in 1999 while the city team has existed since before 1908 (when it entered the Western League). However, in 2009, the Football Conference ruled that Team Bath would not be eligible to gain promotion to a National division, nor were they allowed to participate in Football Association cup competitions. This ruling led to the decision by the club to fold at the end of the 2008–09 Conference South competition. In their final season, Team Bath F.C. finished 11th in the league.
Bath City narrowly missed out on election to The Football League in 1978. Bath also has Non-League football club Odd Down F.C. who play at Lew Hill Memorial Ground.
Many cricket clubs are based in the city, including Bath Cricket Club, who are based at the North Parade Ground and play in the West of England Premier League. Cricket is also played on the Recreation Ground, just across from where the Rugby is played. The Recreation Ground is also home to Bath Croquet Club, which was re-formed in 1976 and is affiliated with the South West Federation of Croquet Clubs.
The Bath Half Marathon is run annually through the city streets, with over 10,000 runners.
TeamBath is the umbrella name for all of the University of Bath sports teams, including the aforementioned football club. Other sports for which TeamBath is noted are athletics, badminton, basketball, bob skeleton, bobsleigh, hockey, judo, modern pentathlon, netball, rugby union, swimming, tennis, triathlon and volleyball. The City of Bath Triathlon takes place annually at the university.
Transport.
[[File:Bath First 39000 LJ07ECE hybrid bus.jpg|thumb|right|A
diesel/electric hybrid bus in Southgate on a Park and Ride service]]
Bath is approximately south-east of the larger city and port of Bristol, to which it is linked by the A4 road, which runs through Bath, and is a similar distance south of the M4 motorway. In an attempt to reduce the level of car use, park and ride schemes have been introduced, with sites at Odd Down, Lansdown and Newbridge. Paradoxically, a very large increase in city centre parking was provided under the new shopping centre, which necessarily introduces more car traffic. In addition, a bus gate scheme in Northgate aims to reduce private car use in the city centre. National Express operates coach services from Bath Bus Station to a number of cities. Bath also has a network of bus routes run by FirstGroup, with services to surrounding towns and cities. Wessex Bath and the Faresaver Bus company also operate numerous services to surrounding towns. The Bath Bus Company runs open top double-decker bus tours around the city.
The city is connected to Bristol and the sea by the River Avon, navigable via locks by small boats. The river was connected to the River Thames and London by the Kennet and Avon Canal in 1810 via Bath Locks; this waterway – closed for many years but restored in the last years of the 20th century – is now popular with narrowboat users. Bath is on National Cycle Route 4, with one of Britain's first cycleways, the Bristol and Bath Railway Path, to the west, and an eastern route toward London on the canal towpath. Bath is about from Bristol Airport.
Bath is served by the Bath Spa railway station (designed by Isambard Kingdom Brunel), which has regular connections to London Paddington, Bristol Temple Meads, Cardiff Central, Cheltenham, Exeter, Plymouth and Penzance (see Great Western Main Line), and also Westbury, Warminster, Salisbury, Southampton, Portsmouth and Brighton (see Wessex Main Line). Services are provided by First Great Western. There is a suburban station on the main line, Oldfield Park, which has a limited commuter service to Bristol as well as other destinations. Green Park Station was once the terminus of the Midland Railway, and junction for the Somerset and Dorset Joint Railway, whose line, always steam hauled, went under Bear Flat through the Combe Down Tunnel and climbed over the Mendips to serve many towns and villages on its run to Bournemouth. This example of an English rural line was closed by Beeching in March 1966. Its Bath station building, now restored, houses shops, small businesses, the Saturday Bath Farmers Market and parking for a supermarket, while the route of the Somerset and Dorset within Bath has been reused for the Two Tunnels Greenway, a shared use path that extends National Cycle Route 24 into the city.
The Bath Tramways Company was introduced in the late 19th century, opening on 24 December 1880. The gauge cars were horse-drawn along a route from London Road to the Bath Spa railway station, but the system closed in 1902. It was replaced by electric tram cars on a greatly expanded gauge system that opened in 1904. This eventually extended to with routes to Combe Down, Oldfield Park, Twerton, Newton St Loe, Weston and Bathford. There was a fleet of 40 cars, all but 6 being double deck. The first line to close was replaced by a bus service in 1938, and the last went on 6 May 1939. In 2005 a detailed plan was created and presented to the Council to re-introduce trams to Bath, but the plan did not proceed, reportedly due to the focus by the Council on the government-supported busway planned to run from the Newbridge park and ride into the city centre. Part of the justification for the proposed tram re-introduction plan was the pollution from vehicles within the city that was at twice the legal levels, and the heavy traffic congestion due to high car usage.
A transportation study (the Bristol/Bath to South Coast Study) was published in 2004 after being initiated by the Government Office for the South West and Bath and North East Somerset Council. It was undertaken by WSP Global as a result of the de-trunking in 1999 of the A36/A46 trunk road network from Bath to Southampton.
Media.
Bath's local newspaper is the "Bath Chronicle", owned by Local World. Published since 1760, the "Chronicle" was a daily newspaper until mid-September 2007, when it became a weekly.
The BBC Somerset website has featured coverage of news and events within Bath since 2003.
For television, Bath is served by the BBC West studios based in Bristol, and by ITV West (formerly HTV) with studios similarly in Bristol.
Radio stations broadcasting to the city include The Breeze on 107.9FM and Heart West Country (formerly GWR FM) as well as The University of Bath's University Radio Bath, a student-focused radio station available on campus and also online, and Classic Gold 1260, a networked commercial radio station with local programmes.
Bath is sometimes covered by Bristol's local media, including "Bristol Live Magazine".

</doc>
