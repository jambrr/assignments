<doc id="39398" url="https://en.wikipedia.org/wiki?curid=39398" title="Robert Estienne">
Robert Estienne

Robert I Estienne (; 1503 – 7 September 1559), known as "Robertus Stephanus" in Latin and also referred to as "Robert Stephens" by 18th and 19th-century English writers, was a 16th-century printer and classical scholar in Paris. He was a former Catholic who became a Protestant late in his life and the first to print the Bible divided into standard numbered verses.
Life.
Robert was born in Paris, the second son of the famous humanist printer Henri Estienne (the Elder) and became acquainted early on with ancient languages. After Henri's death in 1520 the printing establishment was maintained by his former partner Simon de Colines who also married Robert's mother, the widow Estienne. In 1526 Robert assumed control of his father's printing shop while de Colines established his own firm nearby.
In 1539 Robert adopted as his device an olive branch around which a serpent was twined, and a man standing under an olive-tree, with grafts from which wild branches were falling to the ground, with the words of Romans 11:20, "Noli altum sapere, sed time ..." ("Be not high-minded, but fear.") The latter was called the olive of the Stephens family.
In 1539, he received the distinguishing title of "Printer in Greek to the king." But the official recognition and the crown's approval to his undertaking could not save him from the censure and ceaseless opposition of the divines, and in 1550, to escape the violence of his persecutors, he emigrated to Geneva where he set up his printing house.
With his title of "royal typographer" Estienne made the Paris establishment famous by his numerous editions of grammatical works and other school-books (among them many of Melanchthon's), and of classical and Patristic authors, as Dio Cassius, Cicero, Sallust, Julius Caesar, Justin, Socrates Scholasticus, and Sozomen. Many of these, especially the Greek editions (which were printed with typefaces made by Claude Garamond), were famous for their typographical elegance. The editiones principes which issued from Robert's press were eight in number, viz. Eusebius of Caesarea, including the "Praeparatio evangelica" and the "Demonstratio evangelica" as well as the "Historia ecclesiastica" (1544–1546), Manuel Moschopulus (1545), Dionysius of Halicarnassus (February 1547), Alexander of Tralles (January 1548), Dio Cassius (January 1548), Justin Martyr (1551), Xiphilinus (1551), Appian (1551), the last being completed, after Robert's departure from Paris, by his brother Charles, and appearing under his name. These editions, all in folio, except the Moschopulus, which is in quarto, are unrivalled for beauty. Robert also printed numerous editions of Latin classics, of which perhaps the folio Virgil of 1532 is the most noteworthy, and a large quantity of Latin grammars and other educational works, many of which were written by Maturin Cordier, his friend and co-worker in the cause of humanism.
In 1532, he published the remarkable "Thesaurus linguae latinae", and twice he published the entire Hebrew Bible—"one with the Commentary of Kimchi on the minor prophets, in 13 vols. 4to (quarto) (Paris, 1539-43), another in 10 vols. 16mo (sextodecimo) (ibid. 1544–46)." Both of these editions are rare.
Of more importance are his four editions of the Greek New Testament, 1546, 1549, 1550, and 1551, the last in Geneva. The first two are among the neatest Greek texts known, and are called "O mirificam"; the third is a splendid masterpiece of typographical skill, and is known as the Editio Regia; the edition of 1551 contains the Latin translation of Erasmus and the Vulgate, is not nearly as fine as the other three, and is exceedingly rare. It was in this edition that the division of the New Testament into verses was for the first time introduced.
A number of editions of the Vulgate also appeared from his presses, of which the principal are those of 1528, 1532, 1540 (one of the ornaments of his press), and 1546. His editions, especially that of 1546, containing a new translation at the side of the Vulgate, was the subject of sharp and acrimonious criticism from the clergy.
On his arrival at Geneva, he published a defense against the attacks of the Sorbonne. He issued the French Bible in 1553, and many of John Calvin's writings; the finest edition of the "Institutio" being that of 1553. His fine edition of the Latin Bible with glosses (1556) contained the translation of the Old Testament by Santes Pagninus, and the first edition of Theodore Beza's Latin edition of the New Testament. He died in Geneva.
Sons.
Three of Robert's sons, Henri, Robert, and François, became celebrated as printers. François (b. 1540) printed on his own account in Geneva from 1562–1582, issuing a number of editions of the Bible in Latin and French, and some of Calvin's works. French writers identify him with a printer by the name of Estienne in Normandy, to which he is supposed to have emigrated in 1582.
Robert Estienne Jr. (1530–1570) began to print in Paris on his own account in 1556, and in 1563 received the title of "Typographus regius"; his presses were busily employed in issuing civil documents. He held to the Catholic faith and thus won the support of Charles IX, and by 1563 appears to have fully reconstituted his father's establishment in Paris. His edition of the New Testament of 1568–1569, a reprint of his father's first edition and equal to it in elegance of execution, is now exceedingly rare.

</doc>
<doc id="39399" url="https://en.wikipedia.org/wiki?curid=39399" title="Henri Estienne">
Henri Estienne

Henri Estienne (; 1528 or 1531 – 1598), also known as Henricus Stephanus, was a 16th-century French printer and classical scholar. He was the eldest son of Robert Estienne.
Life.
Estienne was born in Paris.
He displayed in his youth a genuine enthusiasm for Greek and Latin; and his father took special pains with his education, and, as a part of his general training, he undertook in his nineteenth year a protracted journey to Italy, England, and Flanders, where he busied himself in collecting and collating manuscripts for his father's press.
In 1554, he published at Paris his first independent work, the "Anacreon". Then he went again to Italy, helping Aldus at Venice, discovered a copy of Diodorus Siculus at Rome, and returned to Geneva in 1555.
In 1557, he seems to have had a printing establishment of his own, and, in the spirit of modern times, advertised himself as the "Parisian printer" ("typographus parisiensis"). The following year he assumed the title, "illustris viri Huldrici Fuggeri typographus", from his patron, Ulrich Fugger.
In 1559, Henry assumed charge of his father's presses, and distinguished himself as the publisher, and also as the editor and collator of manuscripts. Works of Athenagoras of Athens, Aristotle, and Aeschylus appeared in 1557; Diodorus Siculus, 1559; Xenophon, 1561; Sextus Empiricus, 1562; Thucydides, 1564; Herodotus, both 1566 and 1581; and Sophocles, in 1568. He improved old translations, or made new Latin translations, of many Greek authors.
His most celebrated work, the "Thesaurus graecae linguae", or Greek thesaurus, which served up to the nineteenth century as the basis of Greek lexicography, appeared in four volumes in 1572, with a supplement in two volumes. This work was begun by his father.
Of the editions of the Greek New Testament that went forth from his presses, those of Beza with his commentary deserve mention. A triglot containing the Peshitta appeared in 1569, of which some copies are in existence, bearing the date Lyon, 1571. In 1565, a large French Bible was printed.
Henry's own editions of the Greek New Testament of 1576 and 1587 are noteworthy; the former containing the first scientific treatise on the language of the apostolic writers; the latter, a discussion of the ancient divisions of the text.
In 1578, he published a famous edition of the complete works of Plato, translated by Jean de Serres, with commentary. This work is the source of the standard 'Stephanus numbers' used by scholars today to refer to the works of Plato.
In 1594, he published a concordance of the New Testament, the preparatory studies for which his father had made.
Much earlier, he had translated Calvin's catechism into Greek, which was printed in 1554 in his father's printing room.
He died in Lyon in 1598.
Family.
Henry was married three times, and had fourteen children, of whom three survived him. His son Paul (born 1567), of whose life little is known, assumed control of the presses. Two of Paul's sons were printers — Joseph at La Rochelle, and Antoine (died 1674), who became "Printer to the King" in Paris in 1613. Fronton du Duc's "Chrysostom", and Jean Morin's Greek Bible (3 vols., 1628) were issued from Antoine's presses.
His son Henry succeeded to the title of "Printer to the King" in 1649, and his work closed about 1659. This Henry left no children, and was the last of the family who took active interest in editing and printing.

</doc>
<doc id="39406" url="https://en.wikipedia.org/wiki?curid=39406" title="Central limit theorem">
Central limit theorem

In probability theory, the central limit theorem (CLT) states that, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed, regardless of the underlying distribution. To illustrate what this means, suppose that a sample is obtained containing a large number of observations, each observation being randomly generated in a way that does not depend on the values of the other observations, and that the arithmetic average of the observed values is computed. If this procedure is performed many times, the central limit theorem says that the computed values of the average will be distributed according to the normal distribution (commonly known as a "bell curve"). A simple example of this is that if one flips a coin many times, the probability of getting a given number of heads should follow a normal curve, with mean equal to half the total number of flips.
The central limit theorem has a number of variants. In its common form, the random variables must be identically distributed. In variants, convergence of the mean to the normal distribution also occurs for non-identical distributions or for non-independent observations, given that they comply with certain conditions.
In more general usage, a central limit theorem is any of a set of weak-convergence theorems in probability theory. They all express the fact that a sum of many independent and identically distributed (i.i.d.) random variables, or alternatively, random variables with specific types of dependence, will tend to be distributed according to one of a small set of "attractor distributions". When the variance of the i.i.d. variables is finite, the attractor distribution is the normal distribution. In contrast, the sum of a number of i.i.d. random variables with power law tail distributions decreasing as |"x"|−α−1 where 0 < α < 2 (and therefore having infinite variance) will tend to an alpha-stable distribution with stability parameter (or index of stability) of α as the number of variables grows.
Central limit theorems for independent sequences.
Classical CLT.
Let {"X"1, ..., "Xn"} be a random sample of size "n" — that is, a sequence of independent and identically distributed random variables drawn from distributions of expected values given by µ and finite variances given by σ2. Suppose we are interested in the sample average
of these random variables. By the law of large numbers, the sample averages converge in probability and almost surely to the expected value "µ" as "n" → ∞. The classical central limit theorem describes the size and the distributional form of the stochastic fluctuations around the deterministic number "µ" during this convergence. More precisely, it states that as "n" gets larger, the distribution of the difference between the sample average "Sn" and its limit "µ", when multiplied by the factor (that is ("Sn" − "µ")), approximates the normal distribution with mean 0 and variance "σ"2. For large enough "n," the distribution of "Sn" is close to the normal distribution with mean µ and variance . The usefulness of the theorem is that the distribution of ("Sn" − µ) approaches normality regardless of the shape of the distribution of the individual "Xi"’s. Formally, the theorem can be stated as follows:
Lindeberg–Lévy CLT. Suppose {"X"1, "X"2, ...} is a sequence of i.i.d. random variables with E["Xi"] = "µ" and Var["Xi"] = σ2 < ∞. Then as "n" approaches infinity, the random variables ("Sn" − "µ") converge in distribution to a normal "N"(0, "σ"2):
In the case "σ" > 0, convergence in distribution means that the cumulative distribution functions of ("Sn" − "µ") converge pointwise to the cdf of the N(0, σ2) distribution: for every real number "z",
where Φ("x") is the standard normal cdf evaluated at "x". Note that the convergence is uniform in "z" in the sense that
where sup denotes the least upper bound (or supremum) of the set.
Lyapunov CLT.
The theorem is named after Russian mathematician Aleksandr Lyapunov. In this variant of the central limit theorem the random variables "Xi" have to be independent, but not necessarily identically distributed. The theorem also requires that random variables |"Xi"| have moments of some order (2 + δ), and that the rate of growth of these moments is limited by the Lyapunov condition given below.
Lyapunov CLT. Suppose {"X"1, "X"2, ...} is a sequence of independent random variables, each with finite expected value μ"i" and variance . Define
If for some δ > 0, the "Lyapunov’s condition"
is satisfied, then a sum of ("Xi" − μ"i")/"sn" converges in distribution to a standard normal random variable, as "n" goes to infinity:
In practice it is usually easiest to check the Lyapunov’s condition for δ = 1. If a sequence of random variables satisfies Lyapunov’s condition, then it also satisfies Lindeberg’s condition. The converse implication, however, does not hold.
Lindeberg CLT.
In the same setting and with the same notation as above, the Lyapunov condition can be replaced with the following weaker one (from Lindeberg in 1920).
Suppose that for every ε > 0
where 1{...} is the indicator function. Then the distribution of the standardized sums formula_9 converges towards the standard normal distribution N(0,1).
Multidimensional CLT.
Proofs that use characteristic functions can be extended to cases where each individual "X""i" is a random vector in R"k", with mean vector μ = E("Xi") and covariance matrix Σ (amongst the components of the vector), and these random vectors are independent and identically distributed. Summation of these vectors is being done componentwise. The multidimensional central limit theorem states that when scaled, sums converge to a multivariate normal distribution.
Let
be the "k"-vector. The bold in X"i" means that it is a random vector, not a random (univariate) variable. Then the sum of the random vectors will be
and the average is
and therefore
The multivariate central limit theorem states that
where the covariance matrix Σ is equal to
Generalised theorem.
The central limit theorem states that the sum of a number of independent and identically distributed random variables with finite variances will tend to a normal distribution as the number of variables grows. A generalization due to Gnedenko and Kolmogorov states that the sum of a number of random variables with a power-law tail (Paretian tail) distributions decreasing as |"x"|−α−1 where 0 < α < 2 (and therefore having infinite variance) will tend to a stable distribution formula_16 as the number of summands grows. If α>2 then the sum converges to a stable distribution with stability parameter equal to 2, i.e. a Gaussian distribution.
Central limit theorems for dependent processes.
CLT under weak dependence.
A useful generalization of a sequence of independent, identically distributed random variables is a mixing random process in discrete time; "mixing" means, roughly, that random variables temporally far apart from one another are nearly independent. Several kinds of mixing are used in ergodic theory and probability theory. See especially strong mixing (also called α-mixing) defined by α("n") → 0 where α("n") is so-called strong mixing coefficient.
A simplified formulation of the central limit theorem under strong mixing is:
Theorem. Suppose that "X"1, "X"2, ... is stationary and α-mixing with α"n" = "O"("n"−5) and that E("Xn") = 0 and E("Xn"2) < ∞. Denote "Sn" = "X"1 + ... + "Xn", then the limit
exists, and if σ ≠ 0 then formula_18 converges in distribution to "N"(0, 1).
In fact,
where the series converges absolutely.
The assumption σ ≠ 0 cannot be omitted, since the asymptotic normality fails for "Xn" = "Yn" − "Y""n"−1 where "Yn" are another stationary sequence.
There is a stronger version of the theorem: the assumption E("Xn"12) < ∞ is replaced with and the assumption α"n" = "O"("n"−5) is replaced with formula_20 Existence of such δ > 0 ensures the conclusion. For encyclopedic treatment of limit theorems under mixing conditions see .
Martingale difference CLT.
Theorem. Let a martingale "Mn" satisfy
then formula_23 converges in distribution to N(0,1) as "n" → ∞.
"Caution:" The restricted expectation E("X"; "A") should not be confused with the conditional expectation 
Remarks.
Proof of classical CLT.
For a theorem of such fundamental importance to statistics and applied probability, the central limit theorem has a remarkably simple proof using characteristic functions. It is similar to the proof of a (weak) law of large numbers. For any random variable, "Y", with zero mean and a unit variance (var("Y") = 1), the characteristic function of "Y" is, by Taylor's theorem,
where "o" ("t"2) is "little o notation" for some function of "t" that goes to zero more rapidly than "t"2.
Letting "Yi" be ("Xi" − μ)/σ, the standardized value of "Xi", it is easy to see that the standardized mean of the observations "X"1, "X"2, ..., "X""n" is
By simple properties of characteristic functions, the characteristic function of the sum is:
so that, by the limit of the exponential function () the characteristic function of "Z""n" is
But this limit is just the characteristic function of a standard normal distribution "N"(0, 1), and the central limit theorem follows from the Lévy continuity theorem, which confirms that the convergence of characteristic functions implies convergence in distribution.
Convergence to the limit.
The central limit theorem gives only an asymptotic distribution. As an approximation for a finite number of observations, it provides a reasonable approximation only when close to the peak of the normal distribution; it requires a very large number of observations to stretch into the tails.
The convergence in the Central limit theorem is uniform because the limiting cumulative distribution function is continuous. If the third central moment E(("X"1 − μ)3) exists and is finite, then the speed of convergence is at least on the order of 1/"n"1/2 (see Berry-Esseen theorem). Stein's method can be used not only to prove the central limit theorem, but also to provide bounds on the rates of convergence for selected metrics.
The convergence to the normal distribution is monotonic, in the sense that the entropy of "Z""n" increases monotonically to that of the normal distribution.
The central limit theorem applies in particular to sums of independent and identically distributed discrete random variables. A sum of discrete random variables is still a discrete random variable, so that we are confronted with a sequence of discrete random variables whose cumulative probability distribution function converges towards a cumulative probability distribution function corresponding to a continuous variable (namely that of the normal distribution). This means that if we build a histogram of the realisations of the sum of "n" independent identical discrete variables, the curve that joins the centers of the upper faces of the rectangles forming the histogram converges toward a Gaussian curve as "n" approaches infinity, this relation is known as de Moivre–Laplace theorem. The binomial distribution article details such an application of the central limit theorem in the simple case of a discrete variable taking only two possible values.
Relation to the law of large numbers.
The law of large numbers as well as the central limit theorem are partial solutions to a general problem: "What is the limiting behaviour of "S""n" as "n" approaches infinity?" In mathematical analysis, asymptotic series are one of the most popular tools employed to approach such questions.
Suppose we have an asymptotic expansion of "f"("n"):
Dividing both parts by φ1("n") and taking the limit will produce "a"1, the coefficient of the highest-order term in the expansion, which represents the rate at which "f"("n") changes in its leading term.
Informally, one can say: ""f"("n") grows approximately as "a"1 φ1("n")". Taking the difference between "f"("n") and its approximation and then dividing by the next term in the expansion, we arrive at a more refined statement about "f"("n"):
Here one can say that the difference between the function and its approximation grows approximately as "a"2 φ2("n"). The idea is that dividing the function by appropriate normalizing functions, and looking at the limiting behavior of the result, can tell us much about the limiting behavior of the original function itself.
Informally, something along these lines is happening when the sum, "Sn", of independent identically distributed random variables, "X"1, ..., "Xn", is studied in classical probability theory. If each "Xi" has finite mean μ, then by the law of large numbers, "Sn"/"n" → μ. If in addition each "Xi" has finite variance σ2, then by the central limit theorem,
where ξ is distributed as N(0, σ2). This provides values of the first two constants in the informal expansion
In the case where the "X""i"'s do not have finite mean or variance, convergence of the shifted and rescaled sum can also occur with different centering and scaling factors:
or informally
Distributions Ξ which can arise in this way are called "stable". Clearly, the normal distribution is stable, but there are also other stable distributions, such as the Cauchy distribution, for which the mean or variance are not defined. The scaling factor "bn" may be proportional to "nc", for any "c" ≥ 1/2; it may also be multiplied by a slowly varying function of "n".
The law of the iterated logarithm specifies what is happening "in between" the law of large numbers and the central limit theorem. Specifically it says that the normalizing function formula_35 intermediate in size between n of the law of large numbers and √"n" of the central limit theorem provides a non-trivial limiting behavior.
Alternative statements of the theorem.
Density functions.
The density of the sum of two or more independent variables is the convolution of their densities (if these densities exist). Thus the central limit theorem can be interpreted as a statement about the properties of density functions under convolution: the convolution of a number of density functions tends to the normal density as the number of density functions increases without bound. These theorems require stronger hypotheses than the forms of the central limit theorem given above. Theorems of this type are often called local limit theorems. See Petrov for a particular local limit theorem for sums of independent and identically distributed random variables.
Characteristic functions.
Since the characteristic function of a convolution is the product of the characteristic functions of the densities involved, the central limit theorem has yet another restatement: the product of the characteristic functions of a number of density functions becomes close to the characteristic function of the normal density as the number of density functions increases without bound, under the conditions stated above. However, to state this more precisely, an appropriate scaling factor needs to be applied to the argument of the characteristic function.
An equivalent statement can be made about Fourier transforms, since the characteristic function is essentially a Fourier transform.
Extensions to the theorem.
Products of positive random variables.
The logarithm of a product is simply the sum of the logarithms of the factors. Therefore when the logarithm of a product of random variables that take only positive values approaches a normal distribution, the product itself approaches a log-normal distribution. Many physical quantities (especially mass or length, which are a matter of scale and cannot be negative) are the products of different random factors, so they follow a log-normal distribution.
Whereas the central limit theorem for sums of random variables requires the condition of finite variance, the corresponding theorem for products requires the corresponding condition that the density function be square-integrable.
Beyond the classical framework.
Asymptotic normality, that is, convergence to the normal distribution after appropriate shift and rescaling, is a phenomenon much more general than the classical framework treated above, namely, sums of independent random variables (or vectors). New frameworks are revealed from time to time; no single unifying framework is available for now.
Convex body.
Theorem. There exists a sequence ε"n" ↓ 0 for which the following holds. Let "n" ≥ 1, and let random variables "X"1, ..., "Xn" have a log-concave joint density "f" such that for all "x"1, ..., "xn", and E("Xk"2) = 1 for all "k" = 1, ..., "n". Then the distribution of
is ε"n"-close to N(0, 1) in the total variation distance.
These two ε"n"-close distributions have densities (in fact, log-concave densities), thus, the total variance distance between them is the integral of the absolute value of the difference between the densities. Convergence in total variation is stronger than weak convergence.
An important example of a log-concave density is a function constant inside a given convex body and vanishing outside; it corresponds to the uniform distribution on the convex body, which explains the term "central limit theorem for convex bodies".
Another example: where α > 1 and αβ > 1. If β = 1 then "f"("x"1, …, "xn") factorizes into which means independence of "X"1, …, "Xn". In general, however, they are dependent.
The condition ensures that "X"1, …, "Xn" are of zero mean and uncorrelated; still, they need not be independent, nor even pairwise independent. By the way, pairwise independence cannot replace independence in the classical central limit theorem.
Here is a Berry–Esseen type result.
Theorem. Let "X"1, …, "Xn" satisfy the assumptions of the previous theorem, then 
for all "a" < "b"; here "C" is a universal (absolute) constant. Moreover, for every "c"1, …, "cn" ∈ R such that "c"12 + … + "cn"2 = 1,
The distribution of formula_39 need not be approximately normal (in fact, it can be uniform). However, the distribution of "c"1"X"1 + … + "cnXn" is close to "N"(0, 1) (in the total variation distance) for most of vectors ("c"1, …, "cn") according to the uniform distribution on the sphere "c"12 + … + "cn"2 = 1.
Lacunary trigonometric series.
Theorem (Salem–Zygmund). Let "U" be a random variable distributed uniformly on (0, 2π), and "Xk" = "rk" cos("nkU" + "ak"), where
Then
converges in distribution to "N"(0, 1/2).
Gaussian polytopes.
Theorem Let "A"1, ..., "A""n" be independent random points on the plane R2 each having the two-dimensional standard normal distribution. Let "K""n" be the convex hull of these points, and "Xn" the area of "K""n" Then
converges in distribution to "N"(0, 1) as "n" tends to infinity.
The same holds in all dimensions (2, 3, ...).
The polytope "K""n" is called Gaussian random polytope.
A similar result holds for the number of vertices (of the Gaussian polytope), the number of edges, and in fact, faces of all dimensions.
Linear functions of orthogonal matrices.
A linear function of a matrix "M" is a linear combination of its elements (with given coefficients), "M" ↦ tr("AM") where "A" is the matrix of the coefficients; see Trace (linear algebra)#Inner product.
A random orthogonal matrix is said to be distributed uniformly, if its distribution is the normalized Haar measure on the orthogonal group O("n", R); see Rotation matrix#Uniform random rotation matrices.
Theorem. Let "M" be a random orthogonal "n" × "n" matrix distributed uniformly, and "A" a fixed "n" × "n" matrix such that tr("AA*") = "n", and let "X" = tr("AM"). Then the distribution of "X" is close to N(0, 1) in the total variation metric up to 2/("n" − 1).
Subsequences.
Theorem. Let random variables "X"1, "X"2, … ∈ "L"2(Ω) be such that "Xn" → 0 weakly in "L"2(Ω) and "Xn"2 → 1 weakly in "L"1(Ω). Then there exist integers "n"1 < "n"2 < … such that formula_43 converges in distribution to "N"(0, 1) as "k" tends to infinity.
Random walk on a crystal lattice.
The central limit theorem may be established for the simple random walk on a crystal lattice (an infinite-fold abelian covering graph over a finite graph), and is used for design of crystal structures.
Applications and examples.
Simple example.
A simple example of the central limit theorem is rolling a large number of identical, unbiased dice. The distribution of the sum (or average) of the rolled numbers will be well approximated by a normal distribution. Since real-world quantities are often the balanced sum of many unobserved random events, the central limit theorem also provides a partial explanation for the prevalence of the normal probability distribution. It also justifies the approximation of large-sample statistics to the normal distribution in controlled experiments.
Real applications.
Published literature contains a number of useful and interesting examples and applications relating to the central limit theorem. One source states the following examples:
From another viewpoint, the central limit theorem explains the common appearance of the "Bell Curve" in density estimates applied to real world data. In cases like electronic noise, examination grades, and so on, we can often regard a single measured value as the weighted average of a large number of small effects. Using generalisations of the central limit theorem, we can then see that this would often (though not always) produce a final distribution that is approximately normal.
In general, the more a measurement is like the sum of independent variables with equal influence on the result, the more normality it exhibits. This justifies the common use of this distribution to stand in for the effects of unobserved variables in models like the linear model.
Regression.
Regression analysis and in particular ordinary least squares specifies that a dependent variable depends according to some function upon one or more independent variables, with an additive error term. Various types of statistical inference on the regression assume that the error term is normally distributed. This assumption can be justified by assuming that the error term is actually the sum of a large number of independent error terms; even if the individual error terms are not normally distributed, by the central limit theorem their sum can be well approximated by a normal distribution.
Other illustrations.
Given its importance to statistics, a number of papers and computer packages are available that demonstrate the convergence involved in the central limit theorem.
History.
Tijms writes:
Sir Francis Galton described the Central Limit Theorem as:
The actual term "central limit theorem" (in German: "zentraler Grenzwertsatz") was first used by George Pólya in 1920 in the title of a paper. Pólya referred to the theorem as "central" due to its importance in probability theory. According to Le Cam, the French school of probability interprets the word "central" in the sense that "it describes the behaviour of the centre of the distribution as opposed to its tails". The abstract of the paper "On the central limit theorem of calculus of probability and the problem of moments" by Pólya in 1920 translates as follows.
A thorough account of the theorem's history, detailing Laplace's foundational work, as well as Cauchy's, Bessel's and Poisson's contributions, is provided by Hald. Two historical accounts, one covering the development from Laplace to Cauchy, the second the contributions by von Mises, Pólya, Lindeberg, Lévy, and Cramér during the 1920s, are given by Hans Fischer. Le Cam describes a period around 1935. Bernstein presents a historical discussion focusing on the work of Pafnuty Chebyshev and his students Andrey Markov and Aleksandr Lyapunov that led to the first proofs of the CLT in a general setting.
A curious footnote to the history of the Central Limit Theorem is that a proof of a result similar to the 1922 Lindeberg CLT was the subject of Alan Turing's 1934 Fellowship Dissertation for King's College at the University of Cambridge. Only after submitting the work did Turing learn it had already been proved. Consequently, Turing's dissertation was never published.

</doc>
<doc id="39407" url="https://en.wikipedia.org/wiki?curid=39407" title="Dirac equation">
Dirac equation

In particle physics, the Dirac equation is a relativistic wave equation derived by British physicist Paul Dirac in 1928. In its free form, or including electromagnetic interactions, it describes all spin- massive particles such as electrons and quarks, for which parity is a symmetry, and is consistent with both the principles of quantum mechanics and the theory of special relativity, and was the first theory to account fully for special relativity in the context of quantum mechanics. It accounted for the fine details of the hydrogen spectrum in a completely rigorous way. 
The equation also implied the existence of a new form of matter, "antimatter", previously unsuspected and unobserved and which was experimentally confirmed several years later. It also provided a "theoretical" justification for the introduction of several-component wave functions in Pauli's phenomenological theory of spin; the wave functions in the Dirac theory are vectors of four complex numbers (known as bispinors), two of which resemble the Pauli wavefunction in the non-relativistic limit, in contrast to the Schrödinger equation which described wave functions of only one complex value. Moreover, in the limit of zero mass, the Dirac equation reduces to the Weyl equation.
Although Dirac did not at first fully appreciate the importance of his results, the entailed explanation of spin as a consequence of the union of quantum mechanics and relativity—and the eventual discovery of the positron—represents one of the great triumphs of theoretical physics. This accomplishment has been described as fully on a par with the works of Newton, Maxwell, and Einstein before him. In the context of quantum field theory, the Dirac equation is reinterpreted to describe quantum fields corresponding to spin-½ particles.
Mathematical formulation.
The Dirac equation in the form originally proposed by Dirac is:
where formula_1 is the wave function for the electron of rest mass with spacetime coordinates . The are the components of the momentum, understood to be the momentum operator in the Schrödinger equation. Also, is the speed of light, and is the Planck constant divided by . These fundamental physical constants reflect special relativity and quantum mechanics, respectively.
Dirac's purpose in casting this equation was to explain the behavior of the relativistically moving electron, and so to allow the atom to be treated in a manner consistent with relativity. His rather modest hope was that the corrections introduced this way might have bearing on the problem of atomic spectra. Up until that time, attempts to make the old quantum theory of the atom compatible with the theory of relativity, attempts based on discretizing the angular momentum stored in the electron's possibly non-circular orbit of the atomic nucleus, had failed – and the new quantum mechanics of Heisenberg, Pauli, Jordan, Schrödinger, and Dirac himself had not developed sufficiently to treat this problem. Although Dirac's original intentions were satisfied, his equation had far deeper implications for the structure of matter, and introduced new mathematical classes of objects that are now essential elements of fundamental physics.
The new elements in this equation are the 4 × 4 matrices and , and the four-component wave function . There are four components in because evaluation of it at any given point in configuration space is a bispinor. It is interpreted as a superposition of a spin-up electron, a spin-down electron, a spin-up positron, and a spin-down positron (see below for further discussion).
The 4 × 4 matrices and are all Hermitian and have squares equal to the identity matrix:
and they all mutually anticommute (if and are distinct):
The single symbolic equation thus unravels into four coupled linear first-order partial differential equations for the four quantities that make up the wave function. These matrices, and the form of the wave function, have a deep mathematical significance. The algebraic structure represented by the gamma matrices had been created some 50 years earlier by the English mathematician W. K. Clifford. In turn, Clifford's ideas had emerged from the mid-19th century work of the German mathematician Hermann Grassmann in his "Lineale Ausdehnungslehre" ("Theory of Linear Extensions"). The latter had been regarded as well-nigh incomprehensible by most of his contemporaries. The appearance of something so seemingly abstract, at such a late date, and in such a direct physical manner, is one of the most remarkable chapters in the history of physics.
Making the Schrödinger equation relativistic.
The Dirac equation is superficially similar to the Schrödinger equation for a massive free particle:
The left side represents the square of the momentum operator divided by twice the mass, which is the non-relativistic kinetic energy. Because relativity treats space and time as a whole, a relativistic generalization of this equation requires that space and time derivatives must enter symmetrically, as they do in the Maxwell equations that govern the behavior of light — the equations must be differentially of the "same order" in space and time. In relativity, the momentum and the energy are the space and time parts of a spacetime vector, the four-momentum, and they are related by the relativistically invariant relation
which says that the length of this four-vector is proportional to the rest mass . Substituting the operator equivalents of the energy and momentum from the Schrödinger theory, we get an equation describing the propagation of waves, constructed from relativistically invariant objects,
with the wave function being a relativistic scalar: a complex number which has the same numerical value in all frames of reference. The space and time derivatives both enter to second order. This has a telling consequence for the interpretation of the equation. Because the equation is second order in the time derivative, one must specify initial values both of the wave function itself and of its first time derivative in order to solve definite problems. Since both may be specified more or less arbitrarily, the wave function cannot maintain its former role of determining the probability density of finding the electron in a given state of motion. In the Schrödinger theory, the probability density is given by the positive definite expression
and this density is convected according to the probability current vector
with the conservation of probability current and density following from the continuity equation:
The fact that the density is positive definite and convected according to this continuity equation, implies that we may integrate the density over a certain domain and set the total to 1, and this condition will be maintained by the conservation law. A proper relativistic theory with a probability density current must also share this feature. Now, if we wish to maintain the notion of a convected density, then we must generalize the Schrödinger expression of the density and current so that the space and time derivatives again enter symmetrically in relation to the scalar wave function. We are allowed to keep the Schrödinger expression for the current, but must replace the probability density by the symmetrically formed expression
which now becomes the 4th component of a spacetime vector, and the entire probability 4-current density has the relativistically covariant expression
The continuity equation is as before. Everything is compatible with relativity now, but we see immediately that the expression for the density is no longer positive definite – the initial values of both and may be freely chosen, and the density may thus become negative, something that is impossible for a legitimate probability density. Thus we cannot get a simple generalization of the Schrödinger equation under the naive assumption that the wave function is a relativistic scalar, and the equation it satisfies, second order in time.
Although it is not a successful relativistic generalization of the Schrödinger equation, this equation is resurrected in the context of quantum field theory, where it is known as the Klein–Gordon equation, and describes a spinless particle field (e.g. pi meson). Historically, Schrödinger himself arrived at this equation before the one that bears his name, but soon discarded it. In the context of quantum field theory, the indefinite density is understood to correspond to the "charge" density, which can be positive or negative, and not the probability density.
Dirac's coup.
Dirac thus thought to try an equation that was "first order" in both space and time. One could, for example, formally take the relativistic expression for the energy
replace by its operator equivalent, expand the square root in an infinite series of derivative operators, set up an eigenvalue problem, then solve the equation formally by iterations. Most physicists had little faith in such a process, even if it were technically possible.
As the story goes, Dirac was staring into the fireplace at Cambridge, pondering this problem, when he hit upon the idea of taking the square root of the wave operator thus:
On multiplying out the right side we see that, in order to get all the cross-terms such as to vanish, we must assume
with
Dirac, who had just then been intensely involved with working out the foundations of Heisenberg's matrix mechanics, immediately understood that these conditions could be met if , , and are "matrices", with the implication that the wave function has "multiple components". This immediately explained the appearance of two-component wave functions in Pauli's phenomenological theory of spin, something that up until then had been regarded as mysterious, even to Pauli himself. However, one needs at least 4 × 4 matrices to set up a system with the properties required — so the wave function had "four" components, not two, as in the Pauli theory, or one, as in the bare Schrödinger theory. The four-component wave function represents a new class of mathematical object in physical theories that makes its first appearance here.
Given the factorization in terms of these matrices, one can now write down immediately an equation
with to be determined. Applying again the matrix operator on both side yields
On taking we find that all the components of the wave function "individually" satisfy the relativistic energy–momentum relation. Thus the sought-for equation that is first-order in both space and time is
Setting
we get the Dirac equation as written above.
Covariant form and relativistic invariance.
To demonstrate the relativistic invariance of the equation, it is advantageous to cast it into a form in which the space and time derivatives appear on an equal footing. New matrices are introduced as follows:
and the equation takes the form
where there is an implied summation over the values of the twice-repeated index , and is the 4-gradient. In practice one often writes the gamma matrices in terms of 2 × 2 sub-matrices taken from the Pauli matrices and the 2 × 2 identity matrix. Explicitly the standard representation is
The complete system is summarized using the Minkowski metric on spacetime in the form
where the bracket expression
denotes the anticommutator. These are the defining relations of a Clifford algebra over a pseudo-orthogonal 4-dimensional space with metric signature . The specific Clifford algebra employed in the Dirac equation is known today as the Dirac algebra. Although not recognized as such by Dirac at the time the equation was formulated, in hindsight the introduction of this "geometric algebra" represents an enormous stride forward in the development of quantum theory.
The Dirac equation may now be interpreted as an eigenvalue equation, where the rest mass is proportional to an eigenvalue of the 4-momentum operator, the proportionality constant being the speed of light:
Using formula_27 (pronounced: "d-slash") in Feynman slash notation, which includes the gamma matrices as well as a summation over the spinor components in the derivative itself, the Dirac equation becomes:
In practice, physicists often use units of measure such that , known as natural units. The equation then takes the simple form
A fundamental theorem states that if two distinct sets of matrices are given that both satisfy the Clifford relations, then they are connected to each other by a similarity transformation:
If in addition the matrices are all unitary, as are the Dirac set, then itself is unitary;
The transformation is unique up to a multiplicative factor of absolute value 1. Let us now imagine a Lorentz transformation to have been performed on the space and time coordinates, and on the derivative operators, which form a covariant vector. For the operator to remain invariant, the gammas must transform among themselves as a contravariant vector with respect to their spacetime index. These new gammas will themselves satisfy the Clifford relations, because of the orthogonality of the Lorentz transformation. By the fundamental theorem, we may replace the new set by the old set subject to a unitary transformation. In the new frame, remembering that the rest mass is a relativistic scalar, the Dirac equation will then take the form
If we now define the transformed spinor
then we have the transformed Dirac equation in a way that demonstrates manifest relativistic invariance:
Thus, once we settle on any unitary representation of the gammas, it is final provided we transform the spinor according to the unitary transformation that corresponds to the given Lorentz transformation. The various representations of the Dirac matrices employed will bring into focus particular aspects of the physical content in the Dirac wave function (see below). The representation shown here is known as the "standard" representation – in it, the wave function's upper two components go over into Pauli's 2-spinor wave function in the limit of low energies and small velocities in comparison to light.
The considerations above reveal the origin of the gammas in "geometry", hearkening back to Grassmann's original motivation – they represent a fixed basis of unit vectors in spacetime. Similarly, products of the gammas such as represent "oriented surface elements", and so on. With this in mind, we can find the form of the unit volume element on spacetime in terms of the gammas as follows. By definition, it is
For this to be an invariant, the epsilon symbol must be a tensor, and so must contain a factor of , where is the determinant of the metric tensor. Since this is negative, that factor is "imaginary". Thus
This matrix is given the special symbol , owing to its importance when one is considering improper transformations of spacetime, that is, those that change the orientation of the basis vectors. In the standard representation it is
This matrix will also be found to anticommute with the other four Dirac matrices:
It takes a leading role when questions of "parity" arise, because the volume element as a directed magnitude changes sign under a spacetime reflection. Taking the positive square root above thus amounts to choosing a handedness convention on spacetime .
Conservation of probability current.
By defining the adjoint spinor
where is the conjugate transpose of , and noticing that
we obtain, by taking the Hermitian conjugate of the Dirac equation and multiplying from the right by , the adjoint equation:
where is understood to act to the left. Multiplying the Dirac equation by from the left, and the adjoint equation by from the right, and subtracting, produces the law of conservation of the Dirac current:
Now we see the great advantage of the first-order equation over the one Schrödinger had tried – this is the conserved current density required by relativistic invariance, only now its 4th component is "positive definite" and thus suitable for the role of a probability density:
Because the probability density now appears as the fourth component of a relativistic vector, and not a simple scalar as in the Schrödinger equation, it will be subject to the usual effects of the Lorentz transformations such as time dilation. Thus for example atomic processes that are observed as rates, will necessarily be adjusted in a way consistent with relativity, while those involving the measurement of energy and momentum, which themselves form a relativistic vector, will undergo parallel adjustment which preserves the relativistic covariance of the observed values.
Solutions.
See Dirac spinor for details of solutions to the Dirac equation. Note that since the Dirac operator acts on 4-tuples of square-integrable functions, its solutions should be members of the same Hilbert space. The fact that the energies of the solutions do not have a lower bound is unexpected – see the hole theory section below for more details.
Comparison with the Pauli theory.
The necessity of introducing half-integer spin goes back experimentally to the results of the Stern–Gerlach experiment. A beam of atoms is run through a strong inhomogeneous magnetic field, which then splits into parts depending on the intrinsic angular momentum of the atoms. It was found that for silver atoms, the beam was split in two—the ground state therefore could not be integer, because even if the intrinsic angular momentum of the atoms were as small as possible, 1, the beam would be split into three parts, corresponding to atoms with . The conclusion is that silver atoms have net intrinsic angular momentum of . Pauli set up a theory which explained this splitting by introducing a two-component wave function and a corresponding correction term in the Hamiltonian, representing a semi-classical coupling of this wave function to an applied magnetic field, as so in SI units: (Note that bold faced characters imply Euclidean vectors in 3 dimensions, where as the Minkowski four-vector can be defined as .)
Here and formula_45 represent the components of the electromagnetic four-potential in their standard SI units, and the three sigmas are the Pauli matrices. On squaring out the first term, a residual interaction with the magnetic field is found, along with the usual classical Hamiltonian of a charged particle interacting with an applied field in SI units:
This Hamiltonian is now a 2 × 2 matrix, so the Schrödinger equation based on it must use a two-component wave function. Pauli had introduced the 2 × 2 sigma matrices as pure "phenomenology"— Dirac now had a "theoretical argument" that implied that spin was somehow the consequence of the marriage of quantum mechanics to relativity. On introducing the external electromagnetic 4-vector potential into the Dirac equation in a similar way, known as minimal coupling, it takes the form (in natural units)
A second application of the Dirac operator will now reproduce the Pauli term exactly as before, because the spatial Dirac matrices multiplied by , have the same squaring and commutation properties as the Pauli matrices. What is more, the value of the gyromagnetic ratio of the electron, standing in front of Pauli's new term, is explained from first principles. This was a major achievement of the Dirac equation and gave physicists great faith in its overall correctness. There is more however. The Pauli theory may be seen as the low energy limit of the Dirac theory in the following manner. First the equation is written in the form of coupled equations for 2-spinors with the SI units restored:
so
Assuming the field is weak and the motion of the electron non-relativistic, we have the total energy of the electron approximately equal to its rest energy, and the momentum going over to the classical value,
and so the second equation may be written
which is of order – thus at typical energies and velocities, the bottom components of the Dirac spinor in the standard representation are much suppressed in comparison to the top components. Substituting this expression into the first equation gives after some rearrangement
The operator on the left represents the particle energy reduced by its rest energy, which is just the classical energy, so we recover Pauli's theory if we identify his 2-spinor with the top components of the Dirac spinor in the non-relativistic approximation. A further approximation gives the Schrödinger equation as the limit of the Pauli theory. Thus the Schrödinger equation may be seen as the far non-relativistic approximation of the Dirac equation when one may neglect spin and work only at low energies and velocities. This also was a great triumph for the new equation, as it traced the mysterious that appears in it, and the necessity of a complex wave function, back to the geometry of spacetime through the Dirac algebra. It also highlights why the Schrödinger equation, although superficially in the form of a diffusion equation, actually represents the propagation of waves.
It should be strongly emphasized that this separation of the Dirac spinor into large and small components depends explicitly on a low-energy approximation. The entire Dirac spinor represents an "irreducible" whole, and the components we have just neglected to arrive at the Pauli theory will bring in new phenomena in the relativistic regime – antimatter and the idea of creation and annihilation of particles.
Comparison with the Weyl theory.
In the limit , the Dirac equation reduces to the Weyl equation, which describes relativistic massless spin- particles.
Dirac Lagrangian.
Both the Dirac equation and the Adjoint Dirac equation can be obtained from (varying) the action with a specific Lagrangian density that is given by:
formula_55
If one varies this with respect to one gets the Adjoint Dirac equation. Meanwhile, if one varies this with respect to one gets the Dirac equation.
Physical interpretation.
The Dirac theory, while providing a wealth of information that is accurately confirmed by experiments, nevertheless introduces a new physical paradigm that appears at first difficult to interpret and even paradoxical. Some of these issues of interpretation must be regarded as open questions.
Identification of observables.
The critical physical question in a quantum theory is—what are the physically observable quantities defined by the theory? According to the postulates of quantum mechanics, such quantities are defined by Hermitian operators that act on the Hilbert space of possible states of a system. The eigenvalues of these operators are then the possible results of measuring the corresponding physical quantity. In the Schrödinger theory, the simplest such object is the overall Hamiltonian, which represents the total energy of the system. If we wish to maintain this interpretation on passing to the Dirac theory, we must take the Hamiltonian to be
where, as always, there is an implied summation over the twice-repeated index . This looks promising, because we see by inspection the rest energy of the particle and, in case , the energy of a charge placed in an electric potential . What about the term involving the vector potential? In classical electrodynamics, the energy of a charge moving in an applied potential is
Thus the Dirac Hamiltonian is fundamentally distinguished from its classical counterpart, and we must take great care to correctly identify what is an observable in this theory. Much of the apparent paradoxical behaviour implied by the Dirac equation amounts to a misidentification of these observables.
Hole theory.
The negative solutions to the equation are problematic, for it was assumed that the particle has a positive energy. Mathematically speaking, however, there seems to be no reason for us to reject the negative-energy solutions. Since they exist, we cannot simply ignore them, for once we include the interaction between the electron and the electromagnetic field, any electron placed in a positive-energy eigenstate would decay into negative-energy eigenstates of successively lower energy. Real electrons obviously do not behave in this way, or they would disappear by emitting energy in the form of photons.
To cope with this problem, Dirac introduced the hypothesis, known as hole theory, that the vacuum is the many-body quantum state in which all the negative-energy electron eigenstates are occupied. This description of the vacuum as a "sea" of electrons is called the Dirac sea. Since the Pauli exclusion principle forbids electrons from occupying the same state, any additional electron would be forced to occupy a positive-energy eigenstate, and positive-energy electrons would be forbidden from decaying into negative-energy eigenstates.
If an electron is forbidden from simultaneously occupying positive-energy and negative-energy eigenstates, then the feature known as Zitterbewegung, which arises from the interference of positive-energy and negative-energy states, would have to be considered to be an unphysical prediction of time-dependent Dirac theory. This conclusion may be inferred from the explanation of hole theory given in the preceding paragraph. Recent results have been published in Nature Gerritsma, G. Kirchmair, F. Zaehringer, E. Solano, R. Blatt, and C. Roos, Nature 463, 68-71 (2010) in which the Zitterbewegung feature was simulated in a trapped-ion experiment. This experiment impacts the hole interpretation if one infers that the physics-laboratory experiment is not merely a check on the mathematical correctness of a Dirac-equation solution but the measurement of a real effect whose detectability in electron physics is still beyond reach.
Dirac further reasoned that if the negative-energy eigenstates are incompletely filled, each unoccupied eigenstate – called a hole – would behave like a positively charged particle. The hole possesses a "positive" energy, since energy is required to create a particle–hole pair from the vacuum. As noted above, Dirac initially thought that the hole might be the proton, but Hermann Weyl pointed out that the hole should behave as if it had the same mass as an electron, whereas the proton is over 1800 times heavier. The hole was eventually identified as the positron, experimentally discovered by Carl Anderson in 1932.
It is not entirely satisfactory to describe the "vacuum" using an infinite sea of negative-energy electrons. The infinitely negative contributions from the sea of negative-energy electrons has to be canceled by an infinite positive "bare" energy and the contribution to the charge density and current coming from the sea of negative-energy electrons is exactly canceled by an infinite positive "jellium" background so that the net electric charge density of the vacuum is zero. In quantum field theory, a Bogoliubov transformation on the creation and annihilation operators (turning an occupied negative-energy electron state into an unoccupied positive energy positron state and an unoccupied negative-energy electron state into an occupied positive energy positron state) allows us to bypass the Dirac sea formalism even though, formally, it is equivalent to it.
In certain applications of condensed matter physics, however, the underlying concepts of "hole theory" are valid. The sea of conduction electrons in an electrical conductor, called a Fermi sea, contains electrons with energies up to the chemical potential of the system. An unfilled state in the Fermi sea behaves like a positively charged electron, though it is referred to as a "hole" rather than a "positron". The negative charge of the Fermi sea is balanced by the positively charged ionic lattice of the material.
In quantum field theory.
In quantum field theories such as quantum electrodynamics, the Dirac field is subject to a process of second quantization, which resolves some of the paradoxical features of the equation.
Other formulations.
The Dirac equation can be formulated in a number of other ways.
As a differential equation in one real component.
Generically (if a certain linear function of electromagnetic field does not vanish identically), three out of four components of the spinor function in the Dirac equation can be algebraically eliminated, yielding an equivalent fourth-order partial differential equation for just one component. Furthermore, this remaining component can be made real by a gauge transform.
Curved spacetime.
This article has developed the Dirac equation in flat spacetime according to special relativity. It is possible to formulate the Dirac equation in curved spacetime.
The algebra of physical space.
This article developed the Dirac equation using four vectors and Schrödinger operators. The Dirac equation in the algebra of physical space uses a Clifford algebra over the real numbers, a type of geometric algebra.
See also.
The Dirac equation appears on the floor of Westminster Abbey on the plaque commemorating Paul Dirac's life, which was inaugurated on November 13, 1995.

</doc>
<doc id="39411" url="https://en.wikipedia.org/wiki?curid=39411" title="XYY syndrome">
XYY syndrome

XYY syndrome is a genetic condition in which a human male has an extra male (Y) chromosome, giving a total of 47 chromosomes instead of the more usual 46. This produces a 47,XYY karyotype, which occurs every 1 in 1,000 male births.
Some medical geneticists question whether the term "syndrome" is appropriate for this condition because its clinical phenotype is normal and the vast majority of XYY males do not know their karyotype.Oxford Data Base — XYY total ascertainment: ~ 3% — 934 XYYs (801 XYYs + 133 XYY mosaics) in Britain (population 60 million)</ref>
Signs and symptoms.
Physical traits.
People with the 47,XYY karyotype have an increased growth velocity from early childhood, with an average final height approximately 7 cm (3") above expected final height. In Edinburgh, Scotland, eight 47,XYY boys born 1967–1972 and identified in a newborn screening programme had an average height of 188.1 cm (6'2") at age 18—their fathers' average height was 174.1 cm (5'8½"), their mothers' average height was 162.8 cm (5'4"). The increased gene dosage of three X/Y chromosome pseudoautosomal region (PAR1) SHOX genes has been postulated as a cause of the increased stature seen in all three sex chromosome trisomies: 47,XXX, 47,XXY, and 47,XYY.
Severe acne was noted in a very few early case reports, but dermatologists specializing in acne now doubt the existence of a relationship with 47,XYY.
Testosterone levels (prenatally) are normal in 47,XYY males. Most 47,XYY males have normal sexual development and usually have normal fertility.
Behavioral characteristics.
In contrast to the other common sex chromosome aneuploidies—47,XXX, 45,X (Turner syndrome), and 47,XXY (Klinefelter syndrome)—the average IQ scores of 47,XYY boys identified by newborn screening programs were not reduced compared to the general population. In a summary of six prospective studies of 47,XYY boys identified by newborn screening programmes, twenty-eight 47,XYY boys had an average 100.76 verbal IQ, 108.79 performance IQ, and 105.00 full-scale IQ. In a systematic review including two prospective studies of 47,XYY boys identified by newborn screening programs and one retrospective study of 47,XYY men identified by screening men over 184 cm (6'½") in height, forty-two 47,XYY boys and men had an average 99.5 verbal IQ and 106.4 performance IQ.
In prospective studies of 47,XYY boys identified by newborn screening programs, the IQ scores of 47,XYY boys were usually slightly lower than their siblings. In Edinburgh, fifteen 47,XYY boys with siblings identified in a newborn screening program had an average 104.0 verbal IQ and 106.7 performance IQ, while their siblings had an average 112.9 verbal IQ and 114.6 performance IQ.
Approximately half of 47,XYY boys identified by newborn screening programs had learning difficulties—a higher proportion than found among siblings and above-average-IQ control groups. In Edinburgh, 54% of 47,XYY boys (7 of 13) identified in a newborn screening program received remedial reading teaching compared to 18% (4 of 22) in an above-average-IQ control group of 46,XY boys matched by their father's social class. In Boston, USA 55% of 47,XYY boys (6 of 11) identified in a newborn screening program had learning difficulties and received part-time resource room help compared to 11% (1 of 9) in an above-average-IQ control group of 46,XY boys with familial balanced autosomal chromosome translocations.
Developmental delays and behavioral problems are also possible, but these characteristics vary widely among affected boys and men, are not unique to 47,XYY and are managed no differently from in 46,XY males. Aggression is not seen more frequently in 47,XYY males.
Cause.
,XYY is not inherited, but usually occurs as a random event during the formation of sperm cells. An incident in chromosome separation during anaphase II (of meiosis II) called nondisjunction can result in sperm cells with an extra copy of the Y-chromosome. If one of these atypical sperm cells contributes to the genetic makeup of a child, the child will have an extra Y-chromosome in each of the body's cells.
In some cases, the addition of an extra Y-chromosome results from nondisjunction during cell division during a post-zygotic mitosis in early embryonic development. This can produce 46,XY/47,XYY mosaics.
Epidemiology.
Around 1 in 1,000 boys are born with a 47,XYY karyotype. The incidence of 47,XYY is not affected by advanced paternal or maternal age.
History.
1960s.
In April 1956, "Hereditas" published the discovery by cytogeneticists Joe Hin Tjio and Albert Levan at Lund University in Sweden that the normal number of chromosomes in diploid human cells was 46—not 48 as had been believed for the preceding thirty years. In the wake of the establishment of the normal number of human chromosomes, 47,XYY was the last of the common sex chromosome aneuploidies to be discovered, two years after the discoveries of 47,XXY, 45,X, and 47,XXX in 1959. Even the much less common 48,XXYY had been discovered in 1960, a year before 47,XYY.
Screening for those X chromosome aneuploidies was possible by noting the presence or absence of "female" sex chromatin bodies (Barr bodies) in the nuclei of interphase cells in buccal smears, a technique developed a decade "before" the first reported sex chromosome aneuploidy. An analogous technique to screen for Y-chromosome aneuploidies by noting supernumerary "male" sex chromatin bodies was not developed until 1970, a decade "after" the first reported sex chromosome aneuploidy.
The first published report of a man with a 47,XYY karyotype was by internist and cytogeneticist Avery Sandberg and colleagues at Roswell Park Memorial Institute in Buffalo, New York in 1961. It was an incidental finding in a normal 44-year-old, 6 ft. [183 cm] tall man of average intelligence who was karyotyped because he had a daughter with Down syndrome. Only a dozen isolated 47,XYY cases were reported in the medical literature in the four years following the first report by Sandberg.
Then, in December 1965 and March 1966, "Nature" and "The Lancet" published the first preliminary reports by British cytogeneticist Patricia Jacobs and colleagues at the MRC Human Genetics Unit at Western General Hospital in Edinburgh of a chromosome survey of 315 male patients at The State Hospital outside Carstairs, Lanarkshire—Scotland’s only special security hospital for the developmentally disabled—that found nine patients, ages 17 to 36, averaging almost 6 ft. in height (avg. 5'11", range: 5'7" to 6'2"), had a 47,XYY karyotype, and mischaracterized them as aggressive and violent criminals. Over the next decade, almost all published XYY studies were on height-selected, institutionalized XYY males.
In January 1968 and March 1968, "The Lancet" and "Science" published the first U.S. reports of tall, institutionalized XYY males by Mary Telfer, a biochemist, and colleagues at the Elwyn Institute. Telfer found five tall, developmentally disabled XYY boys and men in hospitals and penal institutions in Pennsylvania, and since four of the five had at least moderate facial acne, reached the erroneous conclusion that acne was a defining characteristic of XYY males. After learning that convicted mass murderer Richard Speck had been karyotyped, Telfer not only incorrectly assumed the acne-scarred Speck was XYY, but reached the false conclusion that Speck was the archetypical XYY male—or "supermale" as Telfer referred to XYY males outside of peer-reviewed scientific journals.Why do men commit crimes of violence? For some, the urge to violence may be inborn—traced to something called the Y chromosome...Once in every 500 male births, for example, the sex chromosome complement is XXY rather than XY, thus erring in the direction of femaleness. The resulting individual, called a Klinefelter male, is usually retarded, unusually tall and sterile.Erring in the other direction, however, is the XYY complement resulting in the "supermale." He is also unusually tall and somewhat retarded, but appears to be highly, perhaps too highly, sexually motivated...We were intrigued by Dr. Jacobs' contention that an extra Y chromosome results in tall stature, mild mental retardation, and severely disordered personality characterized by violent, aggressive behavior. We therefore planned to confirm and extend her studies."Syndrome Status for the XYY"The XXY male has long been thought to display a constellation of symptoms that makes him diagnosable; that is, he has achieved syndrome status. It would seem that the XYY male is fast achieving similar status. His symptoms, as we and other laboratories tend to think of them, are: extremely tall stature, long limbs and strikingly long arm span, facial acne, mild mental retardation, severe mental illness (including psychosis) and aggressive, antisocial behavior with a long history of arrests, frequently beginning at an early age.On reading newspaper accounts of Richard Speck, who murdered eight Chicago student nurses in 1966, we noted all these traits and therefore concluded that Speck was a likely candidate for the XYY disorder. Independently, a cytogenetic laboratory in Chicago confirmed this hunch, reinforcing our inclination to believe that the XYY syndrome is really coming of age. It seems quite possible that in the XYY male, exemplified by Speck, biologists are describing in genetic terms a certain type of defective criminal who has long been explicitly recognized by the forensic psychiatrist.</ref>
In April 1968, "The New York Times"—using Telfer as a main source—introduced the XYY genetic condition to the general public in a three-part series on consecutive days that began with a Sunday front-page story about the planned use of the condition as a mitigating factor in two murder trials in Paris and Melbourne—and falsely reported that Richard Speck was an XYY male and that the condition would be used in an appeal of his murder conviction. The series was echoed the following week by articles—again using Telfer as a main source—in "Time" and "Newsweek", and six months later in "The New York Times Magazine".
In December 1968, the "Journal of Medical Genetics" published the first XYY review article—by Michael Court Brown, director of the MRC Human Genetics Unit—which reported no overrepresentation of XYY males in nationwide chromosome surveys of prisons and hospitals for the developmentally disabled and mentally ill in Scotland, and concluded that studies confined to institutionalized XYY males may be guilty of selection bias, and that long-term longitudinal prospective studies of newborn XYY boys were needed.
In May 1969, at the annual meeting of the American Psychiatric Association, Telfer and her Elwyn Institute colleagues reported that case studies of the institutionalized XYY and XXY males they had found convinced them that XYY males had been falsely stigmatized and that their behavior may not be significantly different from chromosomally normal 46,XY males.
In June 1969, the National Institute of Mental Health (NIMH) Center for Studies of Crime and Delinquency held a two-day XYY conference in Chevy Chase, Maryland. In December 1969, with a grant from the NIMH Center for Studies of Crime and Delinquency, cytogeneticist Digamber Borgaonkar at Johns Hopkins Hospital began a chromosome survey of (predominantly African-American) boys ages 8 to 18 in all Maryland institutions for delinquent, neglected, or mentally ill juveniles, which was suspended from February–May 1970 due to an American Civil Liberties Union (ACLU) lawsuit about the lack of informed consent. Concurrently, through 1974, psychologist John Money at Johns Hopkins Hospital experimented on thirteen XYY boys and men (ages 15 to 37) in an unsuccessful attempt to treat their history of behavior problems by chemical castration using high-dose Depo-Provera—with side-effects of weight gain (avg. 26 lbs.) and suicide.
1970s.
In December 1969, Lore Zech at the Karolinska Institute in Stockholm first reported intense fluorescence of the AT-rich distal half of the long arm of the Y chromosome in the nuclei of metaphase cells treated with quinacrine mustard. In April 1970, Peter Pearson and Martin Bobrow at the MRC Population Genetics Unit in Oxford and Canino Vosa at the University of Oxford reported fluorescent "male" sex chromatin bodies in the nuclei of interphase cells in buccal smears treated with quinacrine dihydrochloride, which could be used to screen for Y chromosome aneuploidies like 47,XYY.
In June 1970, "The XYY Man" was published—the first of seven Kenneth Royce spy novels whose fictional tall, intelligent, nonviolent XYY hero was a reformed expert cat burglar recruited by British intelligence for dangerous assignments—and later adapted into a thirteen-episode British summer television series broadcast in 1976 and 1977. In other fictional television works, a January 1971 episode "By the Pricking of My Thumbs ..." of the British science fiction TV series "Doomwatch" featured an XYY boy expelled from school because his genetic condition led him to be falsely accused of nearly blinding another boy, a November 1993 episode "Born Bad" of the American police procedural TV series "Law & Order" portrayed a 14-year-old XYY sociopathic murderer, and the May 2007 season finale episode "Born To Kill" of the American police procedural TV series "" depicted a 34-year-old XYY serial killer. The false stereotype of XYY boys and men as violent criminals has also been used as a plot device in the horror films "Il gatto a nove code" in February 1971 (dubbed into English as "The Cat o' Nine Tails" in May 1971) and "Alien 3" in May 1992.
In December 1970, at the annual meeting of the American Association for the Advancement of Science (AAAS), its retiring president, geneticist H. Bentley Glass, cheered by the legalization of abortion in New York, envisioned a future where pregnant women would be required by the government to abort XYY "sex deviants". Mischaracterization of the XYY genetic condition was quickly incorporated into high school biology textbooks and medical school psychiatry textbooks, where misinformation still persists decades later.
In the late 1960s and early 1970s, screening of consecutive newborns for sex chromosome abnormalities was undertaken at seven centers worldwide: in Denver (Jan 1964–1974), Edinburgh (Apr 1967–Jun 1979), New Haven (Oct 1967–Sep 1968), Toronto (Oct 1967–Sep 1971), Aarhus (Oct 1969–Jan 1974, Oct 1980–Jan 1989), Winnipeg (Feb 1970–Sep 1973), and Boston (Apr 1970–Nov 1974). The Boston study, led by Harvard Medical School child psychiatrist Stanley Walzer at Children's Hospital, was unique among the seven newborn screening studies in that it only screened newborn "boys" (non-private-ward newborn boys at the Boston Hospital for Women) and was funded in part by grants from the NIMH Center for Studies of Crime and Delinquency.
In 1973, child psychiatrist Herbert Schreier at Children’s Hospital told Harvard Medical School microbiologist Jon Beckwith of Science for the People that he thought Walzer’s Boston XYY study was unethical; Science for the People investigated the study and filed a complaint with Harvard Medical School about the study in March 1974. In November 1974, Science for the People went public with their objections to the Boston XYY study in a press conference and a "New Scientist" article alleging inadequate informed consent, a lack of benefit (since no specific treatment was available) but substantial risk (by stigmatization with a false stereotype) to the subjects, and that the unblinded experimental design could not produce meaningful results regarding the subjects' behavior. In December 1974, the Harvard Standing Committee on Medical Research issued a report supporting the Boston XYY study and in March 1975, the faculty voted 199–35 to allow continuation of the study. After April 1975, screening of newborns was discontinued—changes to informed consent procedures and pressure from additional advocacy groups, including the Children's Defense Fund, having led to the discontinuation of the last active U.S. newborn screening programs for sex chromosome abnormalities in Boston and Denver.
In August 1976, "Science" published a retrospective cohort study by Educational Testing Service psychologist Herman Witkin and colleagues that screened the tallest 16% of men (over 184 cm (6'0") in height) born in Copenhagen from 1944–1947 for XXY and XYY karyotypes, and found an increased rate of minor criminal convictions for property crimes among sixteen XXY and twelve XYY men may be related to the lower intelligence of those with criminal convictions, but found no evidence that XXY or XYY men were inclined to be aggressive or violent.
1980s and later.
The March of Dimes sponsored five international conferences in June 1974, November 1977, May 1981, June 1984, and June 1989 and published articles from the conferences in book form in 1979, 1982, 1986, and 1991 from seven longitudinal prospective cohort studies on the development of over 300 children and young adults with sex chromosome abnormalities identified in the screening of almost 200,000 consecutive births in hospitals in Denver, Edinburgh, New Haven, Toronto, Aarhus, Winnipeg, and Boston from 1964 to 1975. These seven studies—the only unbiased studies of unselected individuals with sex chromosome abnormalities—have replaced the older, biased studies of institutionalized individuals in understanding the development of individuals with sex chromosome abnormalities.
In May 1997, "Nature Genetics" published the discovery by Ercole Rao and colleagues of the X/Y chromosome pseudoautosomal region (PAR1) SHOX gene, haploinsufficiency of which leads to short stature in Turner syndrome (45,X). It was subsequently postulated that the increased gene dosage of three SHOX genes leads to tall stature in the sex chromosome trisomies 47,XXX, 47,XXY, and 47,XYY.
In July 1999, "Psychological Medicine" published a case-control study by Royal Edinburgh Hospital psychiatrist Michael Götz and colleagues that found an increased rate of criminal convictions among seventeen XYY men identified in the Edinburgh newborn screening study compared to an above-average-IQ control group of sixty XY men, which multiple logistic regression analysis indicated was mediated mainly through lowered intelligence.
In June 2002, the "American Journal of Medical Genetics" published results from a longitudinal prospective cohort Denver Family Development Study led by pediatrician and geneticist Arthur Robinson, which found that in fourteen prenatally diagnosed 47,XYY boys (from high socioeconomic status families), IQ scores available for six boys ranged from 100–147 with a mean of 120. For the eleven of fourteen boys with siblings, in nine instances their siblings were stronger academically, but in one case the subject was performing equal to, and in another case superior to, his siblings.

</doc>
<doc id="39412" url="https://en.wikipedia.org/wiki?curid=39412" title="Spoiler effect">
Spoiler effect

The spoiler effect is the effect of vote splitting between candidates or ballot questions with similar ideologies. One spoiler candidate's presence in the election draws votes from a major candidate with similar politics thereby causing a strong opponent of both or several to win. The minor candidate causing this effect is referred to as a "spoiler". However, short of any electoral fraud, this presents no grounds for a legal challenge.
Relationship with other effects.
The spoiler candidate takes votes away from a more viable candidate or candidates, a common effect called vote splitting. Where one opposing candidate is ideologically or politically similar and therefore receives far fewer votes than other opposing candidates to the spoiler candidate, then the vote splitting has a spoiler effect.
In some cases, even though the spoiler candidate cannot win themselves, their influences upon the voters may enable the candidate to determine deliberately which of the more viable candidates wins the election — a situation known as a kingmaker scenario. With a first-past-the-post voting system, this is particularly feasible where a spoiler candidate recommends tactical voting or runs on a false manifesto to bolster the prospects of their secretly preferred winning candidate, which in some jurisdictions and circumstances can amount to electoral fraud.
In a preferential voting system, a voter can feel more inclined to vote for a minor party or independent as their first choice and they can record a preference between the remaining candidates, whether they are in a major or established party or not. For example, voters for a minor left-wing candidate might select a major left-wing candidate as their second choice, thus minimizing the probability that their vote will result in the election of a right-wing candidate, or voters for an independent candidate perceived as libertarian, or simply as the voter prefers that ideology might select a particular libertarian candidate as their second choice, thus minimising the probability of an authoritarian candidate being elected. Approval voting and proportional representation systems can also reduce the spoiler effect.
One of the main functions of political parties is to mitigate the effect of spoiler-prone voting methods by winnowing on a local level the contenders before the election. Each party nominates at most one candidate per office since each party expects to lose if they nominate more than one. In some cases, a party can expect to "lose" by "suffering a rival elected opponent" if they nominate more than zero, where two opponents exist and one is considered a candidate they can "work with" — a party may prefer the candidate who would win if the party nominates zero.
Thus, empirical observations of the frequency of spoiled elections do not provide a good measure of how prone to spoiling a particular voting method is, since the observations omit the relevant information about potential candidates who did not run because of not wanting to spoil the election.
Mathematical definitions.
Possible mathematical definitions for the spoiler effect include failure of the independence of irrelevant alternatives (IIA) axiom, and vote splitting.
Arrow's impossibility theorem states that rank-voting systems are unable to satisfy the independence of irrelevant alternatives criterion without exhibiting other undesirable properties as a consequence. However, different voting systems are affected to a greater or lesser extent by IIA failure. For example, instant runoff voting is considered to have less frequent IIA failure than First Past the Post (also known as Plurality Rule). The independence of Smith-dominated alternatives (ISDA) criterion is much weaker than IIA; unlike IIA, some ranked-ballot voting methods can pass ISDA.
A possible definition of spoiling based on vote splitting is as follows: Let W denote the candidate who wins the election, and let X and S denote two other candidates. If X would have won had S not been one of the nominees, and if (most of) the voters who prefer S over W also prefer X over W (either S>X>W or X>S>W), then S is a spoiler. Here is an example to illustrate: Suppose the voters' orders of preference are as follows:
The voters who prefer S over W also prefer X over W. W is the winner under Plurality Rule, Top Two Runoff, and Instant Runoff. If S is deleted from the votes (so that the 33% who ranked S on top now rank X on top) then X would be the winner (by 65% landslide majority). Thus S is a spoiler with these three voting methods.
Spoiler effect in American elections.
Presidential elections.
Bush, Gore, and Nader (2000 U.S. presidential election).
The 2000 U.S. Presidential election is often cited as an example of the spoiler effect. In that election, Al Gore, the Democratic candidate, received more popular votes than George W. Bush, the Republican candidate, but lost in the electoral college. In the state of Florida, the final certified vote count showed Bush with just 537 more votes than Gore. Because Bush defeated Gore in Florida, he won the state, received more votes in the electoral college, and became president of the United States.
Gore supporters argued that had candidate Ralph Nader, a liberal, not run in the election, the majority of the 97,421 votes he received in Florida would have been cast for Gore. Thus, they contend that Nader's candidacy spoiled the election for Gore by taking away enough votes from Gore in Florida to swing the election to Bush. Their argument is bolstered by a poll of Nader voters, asking them for whom they would have voted had Nader not run, which said 45 percent of Nader voters would have voted for Gore, 27 percent would have voted for Bush, and the rest would not have voted.
Nader himself and many of his supporters argued that most Nader voters would either have chosen another minor party candidate or abstained from voting, had Nader not been on the ballot. It should also be noted that all other third party candidates on the ballot in Florida received more than the 537 vote difference between Bush and Gore. Still, some observers began to refer to the spoiler effect as the "Nader effect" after the 2000 election.
Other alleged spoilers.
These are third-party candidates who have been accused of denying victory to a major nominee in U.S. Presidential Elections:
Other countries.
In New Zealand, there have been two notable cases of the spoiler effect. In the 1984 general election, the free-market New Zealand Party deliberately ran for office in order to weaken support for the incumbent Prime Minister Robert Muldoon. Later on, the 1993 general election saw the New Zealand Labour Party's vote split by The Alliance, which has been attributed to the vagaries of the first past the post electoral system. In response to these problems, New Zealand has since adopted the mixed-member proportional voting system.
Likewise, in France, the 2002 presidential elections have been cited as a case of the spoiler effect: the numerous left-wing candidates, such as Christiane Taubira and Jean-Pierre Chevènement, both from political parties allied to the French Socialist Party, or the three candidates from Trotskyist parties, which altogether totalled around 20%, have been charged with making Lionel Jospin, the P.S. candidate, lose the two-round election in the first round to the benefit of Jean-Marie Le Pen, who was separated from Jospin by only 0.68%. Some also cite the case of some circumscriptions where, although the right and the far-right were voted for by more than half of the voters, the left list still won the election, and accused the Socialist party of benefiting of this phenomenon.
Sports.
In sports, the "spoiler effect" refers to a similar phenomenon, in which a team or individual has been eliminated from the possibility of reaching the postseason, but affects the playoffs or finals anyway by beating a more successful team or individual before the end of the season. For example, a baseball team that is ten games out of contention for a playoff berth could defeat a team that has a playoff berth several times. This could cause the would-be playoff team to be passed by in the rankings by the team directly behind it before the final positions at the end of the season are determined.
In individual participant sports, such as automobile racing, a racer with no hope of obtaining a championship title could prevent a racer with a chance at the title by defeating them, preventing the contending racer from earning critical points toward winning the title. Instead, the title would go to the contender directly behind him in the rankings, provided that second-tier racer is close enough to surpass and they win their own competition.

</doc>
<doc id="39413" url="https://en.wikipedia.org/wiki?curid=39413" title="Trisomy">
Trisomy

A trisomy is a type of polysomy in which there are three instances of a particular chromosome, instead of the normal two. A trisomy is a type of aneuploidy (an abnormal number of chromosomes).
Description and causes.
Most organisms that reproduce sexually have pairs of chromosomes in each cell, with one chromosome inherited from each parent. In such organisms, a process called meiosis creates cells called gametes (eggs or sperm) that have only one set of chromosomes. The number of chromosomes is different for different species. Humans have 46 chromosomes (i.e. 23 pairs of chromosomes). Human gametes have only 23 chromosomes.
If the chromosome pairs fail to separate properly during cell division, the egg or sperm may end up with a second copy of one of the chromosomes. ("See" non-disjunction.) If such a gamete results in fertilization and an embryo, the resulting embryo may also have an entire copy of the extra chromosome.
Terminology.
The number of chromosomes in the cell where trisomy occurs is represented as, for example, 2"n"+1 if one chromosome shows trisomy, 2"n"+1+1 if two show trisomy, etc.
Trisomies are sometimes characterised as "autosomal trisomies" (trisomies of the non-sex chromosomes) and "sex-chromosome trisomies." Autosomal trisomies are described by referencing the specific chromosome that has an extra copy. Thus, for example, the presence of an extra chromosome 21, which is found in Down syndrome, is called trisomy 21.
Human trisomy.
Trisomies can occur with any chromosome, but often result in miscarriage, rather than live birth. For example, Trisomy 16 is the most common trisomy in human pregnancies, occurring in more than 1% of pregnancies; only those pregnancies in which some normal cells occur in addition to the trisomic cells, or mosaic trisomy 16, survive. This condition, however, usually results in spontaneous miscarriage in the first trimester. 
The most common types of autosomal trisomy that survive to birth in humans are: 
Of these, Trisomy 21 and Trisomy 18 are the most common. In rare cases, a fetus with Trisomy 13 can survive, giving rise to Patau syndrome. Autosomal trisomy can be associated with birth defects, intellectual disability and shortened life expectancy.
"Trisomy of sex chromosomes" can also occur and include:
Compared to trisomy of the autosomal chromosomes, trisomy of the sex chromosomes normally has less severe consequences. Individuals may show few or no symptoms and have a normal life expectancy.

</doc>
<doc id="39418" url="https://en.wikipedia.org/wiki?curid=39418" title="Moore's law">
Moore's law

Moore's law () is the observation that the number of transistors in a dense integrated circuit doubles approximately every two years. The observation is named after Gordon E. Moore, the co-founder of Intel and Fairchild Semiconductor, whose 1965 paper described a doubling every year in the number of components per integrated circuit, and projected this rate of growth would continue for at least another decade. In 1975, looking forward to the next decade, he revised the forecast to doubling every two years.
His prediction proved accurate for several decades, and the law was used in the semiconductor industry to guide long-term planning and to set targets for research and development.
Advancements in digital electronics are strongly linked to Moore's law: quality-adjusted microprocessor prices, memory capacity, sensors and even the number and size of pixels in digital cameras.
Digital electronics have contributed to world economic growth in the late twentieth and early twenty-first centuries.
Moore's law describes a driving force of technological and social change, productivity, and economic growth.
The period is often quoted as 18 months because of Intel executive David House, who predicted that chip performance would double every 18 months (being a combination of the effect of more transistors and the transistors being faster).
"Moore's law" is an observation or projection and not a physical or natural law. Although the rate held steady from 1975 until around 2012, the rate was faster during the first decade. In general, it is not logically sound to extrapolate from the historical growth rate into the indefinite future. For example, the 2010 update to the International Technology Roadmap for Semiconductors, predicted that growth would slow around 2013, and Gordon Moore in 2015 foresaw that the rate of progress would reach saturation: "I see Moore’s law dying here in the next decade or so."
Intel stated in 2015 that the pace of advancement has slowed, starting at the 22 nm feature width around 2012, and continuing at 14 nm. Brian Krzanich, CEO of Intel, announced that "our cadence today is closer to two and a half years than two.” This is scheduled to hold through the 10 nm width in late 2017. He cited Moore's 1975 revision as a precedent for the current deceleration, which results from technical challenges and is “a natural part of the history of Moore's law.”
History.
In 1959, Douglas Engelbart discussed the projected downscaling of integrated circuit size in the article "Microelectronics, and the Art of Similitude". Engelbart presented his ideas at the 1960 International Solid-State Circuits Conference, where Moore was present in the audience.
For the thirty-fifth anniversary issue of "Electronics" magazine, which was published on April 19, 1965, Gordon E. Moore, who was working as the director of research and development at Fairchild Semiconductor at the time, was asked to predict what was going to happen in the semiconductor components industry over the next ten years. His response was a brief article entitled, "Cramming more components onto integrated circuits". Within his editorial, he speculated that by 1975 it would be possible to contain as many as 65,000 components on a single quarter-inch semiconductor.
The complexity for minimum component costs has increased at a rate of roughly a factor of two per year. Certainly over the short term this rate can be expected to continue, if not to increase. Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain nearly constant for at least 10 years.
His reasoning was a log-linear relationship between device complexity (higher circuit density at reduced cost) and time.
At the 1975 IEEE International Electron Devices Meeting, Moore revised the forecast rate. Semiconductor complexity would continue to double annually until about 1980 after which it would decrease to a rate of doubling approximately every two years. He outlined several contributing factors for this exponential behavior:
Shortly after 1975, Caltech professor Carver Mead popularized the term "Moore's law".
Despite a popular misconception, Moore is adamant that he did not predict a doubling "every 18 months." Rather, David House, an Intel colleague, had factored in the increasing performance of transistors to conclude that integrated circuits would double in "performance" every 18 months.
-->
In April 2005, Intel offered US$10,000 to purchase a copy of the original "Electronics" issue in which Moore's article appeared. An engineer living in the United Kingdom was the first to find a copy and offer it to Intel.
As a target for industry and a self-fulfilling prophecy.
Although Moore's law initially was made in the form of an observation and forecast, the more widely it became accepted, the more it served as a goal for an entire industry.
This drove both marketing and engineering departments of semiconductor manufacturers to focus enormous energy aiming for the specified increase in processing power that it was presumed one or more of their competitors would soon attain. In this regard, it may be viewed as a self-fulfilling prophecy.
Moore's second law.
As the cost of computer power to the consumer falls, the cost for producers to fulfill Moore's law follows an opposite trend: R&D, manufacturing, and test costs have increased steadily with each new generation of chips. Rising manufacturing costs are an important consideration for the sustaining of Moore's law.
This had led to the formulation of Moore's second law, also called Rock's law, which is that the capital cost of a semiconductor fab also increases exponentially over time.
Enabling factors and future trends.
Enabling factors in the past.
Numerous innovations by scientists and engineers have sustained Moore's law since the beginning of the integrated circuit (IC) era. A few innovations are listed below, as examples of breakthroughs that have advanced integrated circuit technology by more than seven orders of magnitude in less than five decades:
Computer industry technology road maps predict () that Moore's law will continue for several generations of semiconductor chips. Depending on the doubling time used in the calculations, this could mean up to a hundredfold increase in transistor count per chip within a decade. The semiconductor industry technology roadmap uses a three-year doubling time for microprocessors, leading to a tenfold increase in the next decade. Intel was reported in 2005 as stating that the downsizing of silicon chips with good economics can continue during the next decade, and in 2008 as predicting the trend through 2029.
Future trends.
Some of the new directions in research that may allow Moore's law to continue are:
One of the key challenges of engineering future nanoscale transistors is the design of gates. As device dimension shrinks, controlling the current flow in the thin channel becomes more difficult. Compared to FinFETs, which have gate dielectric on three sides of the channel, gate-all-around structure has ever better gate control(see right figure).
Speculation on limits.
On April 13, 2005, Gordon Moore stated in an interview that the projection cannot be sustained indefinitely: "It can't continue forever. The nature of exponentials is that you push them out and eventually disaster happens". He also noted that transistors eventually would reach the limits of miniaturization at atomic levels:
Most semiconductor industry forecasters, including Gordon Moore, expect Moore's law will end by around 2025. On the other hand, a few observers put the theoretical limits of Moore's law centuries (250–600 years) in the future.
Moore viewed his eponymous law as surprising and optimistic: "Moore's law is a violation of Murphy's law. Everything gets better and better."
Consequences and limitations.
Technological change is a combination of more and of better technology. A 2011 study in the journal Science, showed that the peak of the rate of change of the world's capacity to compute information was in the year 1998, when the world's technological capacity to compute information on general-purpose computers grew at 88% per year. Since then, technological change clearly has slowed. In recent times, every new year allowed humans to carry out roughly 60% of the computations that possibly could have been executed by all existing general-purpose computers before that year. This still is exponential, but shows the varying nature of technological change.
The primary driving force of economic growth is the growth of productivity, and Moore's law factors into productivity. Moore (1995) expected that "the rate of technological progress is going to be controlled from financial realities." The reverse could and did occur around the late-1990s, however, with economists reporting that "Productivity growth is the key economic indicator of innovation."
An acceleration in the rate of semiconductor progress contributed to a surge in U.S. productivity growth, which reached 3.4% per year in 1997–2004, outpacing the 1.6% per year during both 1972–1996 and 2005–2013. As economist Richard G. Anderson notes, “Numerous studies have traced the cause of the productivity acceleration to technological innovations in the production of semiconductors that sharply reduced the prices of such components and of the products that contain them (as well as expanding the capabilities of such products).”
While physical limits to transistor scaling such as source-to-drain leakage, limited gate metals, and limited options for channel material have been reached, new avenues for continued scaling are open. The most promising of these approaches rely on using the spin state of electron spintronics, tunnel junctions, and advanced confinement of channel materials via nano-wire geometry. A comprehensive list of available device choices shows that a wide range of device options is open for continuing Moore's law into the next few decades. Spin-based logic and memory options are being developed actively in industrial labs, as well as academic labs.
Another source of improved performance is in microarchitecture techniques exploiting the growth of available transistor count. Out-of-order execution and on-chip caching and prefetching reduce the memory latency bottleneck at the expense of using more transistors and increasing the processor complexity. These increases are described empirically by Pollack's Rule, which states that performance increases due to microarchitecture techniques are square root of the number of transistors or the area of a processor.
For years, processor makers delivered increases in clock rates and instruction-level parallelism, so that single-threaded code executed faster on newer processors with no modification. Now, to manage CPU power dissipation, processor makers favor multi-core chip designs, and software has to be written in a multi-threaded manner to take full advantage of the hardware. Many multi-threaded development paradigms introduce overhead, and will not see a linear increase in speed vs number of processors. This is particularly true while accessing shared or dependent resources, due to lock contention. This effect becomes more noticeable as the number of processors increases. There are cases where a roughly 45% increase in processor transistors has translated to roughly 10–20% increase in processing power.
On the other hand, processor manufacturers are taking advantage of the 'extra space' that the transistor shrinkage provides to add specialized processing units to deal with features such as graphics, video, and cryptography. For one example, Intel's Parallel JavaScript extension not only adds support for multiple cores, but also for the other non-general processing features of their chips, as part of the migration in client side scripting toward HTML5.
A negative implication of Moore's law is obsolescence, that is, as technologies continue to rapidly "improve", these improvements may be significant enough to render predecessor technologies obsolete rapidly. In situations in which security and survivability of hardware or data are paramount, or in which resources are limited, rapid obsolescence may pose obstacles to smooth or continued operations.
Because of the toxic materials used in the production of modern computers, obsolescence if not properly managed, may lead to harmful environmental impacts. On the other hand, obsolescence may sometimes be desirable to a company which can profit immensely from the regular purchase of what is often expensive new equipment instead of retaining one device for a longer period of time. Those in the industry are well aware of this, and may utilize planned obsolescence as a method of increasing profits.
Moore's law has affected the performance of other technologies significantly: Michael S. Malone wrote of a Moore's War following the apparent success of shock and awe in the early days of the Iraq War. Progress in the development of guided weapons depends on electronic technology. Improvements in circuit density and low-power operation associated with Moore's law, also have contributed to the development of technologies including mobile telephones and 3-D printing.
Other formulations and similar observations.
Several measures of digital technology are improving at exponential rates related to Moore's law, including the size, cost, density, and speed of components. Moore wrote only about the density of components, "a component being a transistor, resistor, diode or capacitor," at minimum cost.
Transistors per integrated circuit – The most popular formulation is of the doubling of the number of transistors on integrated circuits every two years. At the end of the 1970s, Moore's law became known as the limit for the number of transistors on the most complex chips. The graph at the top shows this trend holds true today.
Density at minimum cost per transistor – This is the formulation given in Moore's 1965 paper. It is not just about the density of transistors that can be achieved, but about the density of transistors at which the cost per transistor is the lowest.
As more transistors are put on a chip, the cost to make each transistor decreases, but the chance that the chip will not work due to a defect increases. In 1965, Moore examined the density of transistors at which cost is minimized, and observed that, as transistors were made smaller through advances in photolithography, this number would increase at "a rate of roughly a factor of two per year".
Dennard scaling – This suggests that power requirements are proportional to area (both voltage and current being proportional to length) for transistors. Combined with Moore's law, performance per watt would grow at roughly the same rate as transistor density, doubling every 1–2 years. According to Dennard scaling transistor dimensions are scaled by 30% (0.7x) every technology generation, thus reducing their area by 50%. This reduces the delay by 30% (0.7x) and therefore increases operating frequency by about 40% (1.4x). Finally, to keep electric field constant, voltage is reduced by 30%, reducing energy by 65% and power (at 1.4x frequency) by 50%. Therefore, in every technology generation transistor density doubles, circuit becomes 40% faster, while power consumption (with twice the number of transistors) stays the same.
The exponential processor transistor growth predicted by Moore does not always translate into exponentially greater practical CPU performance. Since around 2005–2007, Dennard scaling appears to have broken down, so even though Moore's law continued for several years after that, it has not yielded dividends in improved performance. The primary reason cited for the breakdown is that at small sizes, current leakage poses greater challenges, and also causes the chip to heat up, which creates a threat of thermal runaway and therefore, further increases energy costs.
The breakdown of Dennard scaling prompted a switch among some chip manufacturers to a greater focus on multicore processors, but the gains offered by switching to more cores are lower than the gains that would be achieved had Dennard scaling continued. In another departure from Dennard scaling, Intel microprocessors adopted a non-planar tri-gate FinFET at 22 nm in 2012 that is faster and consumes less power than a conventional planar transistor.
Quality adjusted price of IT equipment – The price of information technology (IT), computers and peripheral equipment, adjusted for quality and inflation, declined 16% per year on average over the five decades from 1959 to 2009.
The rate of quality-adjusted microprocessor price improvement likewise varies, and is not linear on a log scale. Microprocessor price improvement accelerated during the late 1990s, reaching 60% per year (halving every nine months) versus the typical 30% improvement rate (halving every two years) during the years earlier and later. Laptop microprocessors in particular improved 25–35% per year in 2004–2010, and slowed to 15–25% per year in 2010–2013.
The number of transistors per chip cannot explain quality-adjusted microprocessor prices fully. Moore's 1995 paper does not limit Moore's law to strict linearity or to transistor count, “The definition of 'Moore's Law' has come to refer to almost anything related to the semiconductor industry that when plotted on semi-log paper approximates a straight line. I hesitate to review its origins and by doing so restrict its definition.”
Moore (2003) credits chemical mechanical planarization (chip smoothing) with increasing the connectivity of microprocessors from two or three metal layers in the early 1990s to seven in 2003. This progressed to nine metal layers in 2007 and thirteen in 2014. Connectivity improves performance, and relieves network congestion. Just as additional floors may not enlarge a building's footprint, nor is connectivity tallied in transistor count. Microprocessors rely more on communications (interconnect) than do DRAM chips, which have three or four metal layers. Microprocessor prices in the late 1990s improved faster than DRAM prices.
Hard disk drive areal density – A similar observation (sometimes called Kryder's law) was made in 2005 for hard disk drive areal density.
Several decades of rapid progress resulted from the use of error correcting codes, the magnetoresistive effect, and the giant magnetoresistive effect. The Kryder rate of areal density advancement slowed significantly around 2010, because of noise related to smaller grain size of the disk media, thermal stability, and writability using available magnetic fields.
Network capacity – According to Gerry/Gerald Butters, the former head of Lucent's Optical Networking Group at Bell Labs, there is another version, called Butters' Law of Photonics, a formulation that deliberately parallels Moore's law. Butter's law says that the amount of data coming out of an optical fiber is doubling every nine months. Thus, the cost of transmitting a bit over an optical network decreases by half every nine months. The availability of wavelength-division multiplexing (sometimes called WDM) increased the capacity that could be placed on a single fiber by as much as a factor of 100. Optical networking and dense wavelength-division multiplexing (DWDM) is rapidly bringing down the cost of networking, and further progress seems assured. As a result, the wholesale price of data traffic collapsed in the dot-com bubble. Nielsen's Law says that the bandwidth available to users increases by 50% annually.
Pixels per dollar – Similarly, Barry Hendy of Kodak Australia has plotted pixels per dollar as a basic measure of value for a digital camera, demonstrating the historical linearity (on a log scale) of this market and the opportunity to predict the future trend of digital camera price, LCD and LED screens, and resolution.
The great Moore's law compensator (TGMLC), also known as Wirth's law – generally is referred to as bloat and is the principle that successive generations of computer software increase in size and complexity, thereby offsetting the performance gains predicted by Moore's law. In a 2008 article in InfoWorld, Randall C. Kennedy, formerly of Intel, introduces this term using successive versions of Microsoft Office between the year 2000 and 2007 as his premise. Despite the gains in computational performance during this time period according to Moore's law, Office 2007 performed the same task at half the speed on a prototypical year 2007 computer as compared to Office 2000 on a year 2000 computer.
Library expansion – was calculated in 1945 by Fremont Rider to double in capacity every 16 years, if sufficient space were made available. He advocated replacing bulky, decaying printed works with miniaturized microform analog photographs, which could be duplicated on-demand for library patrons or other institutions. He did not foresee the digital technology that would follow decades later to replace analog microform with digital imaging, storage, and transmission media. Automated, potentially lossless digital technologies allowed vast increases in the rapidity of information growth in an era that now sometimes is called an Information Age.
Carlson Curve – is a term coined by "The Economist" to describe the biotechnological equivalent of Moore's law, and is named after author Rob Carlson. Carlson accurately predicted that the doubling time of DNA sequencing technologies (measured by cost and performance) would be at least as fast as Moore's law. Carlson Curves illustrate the rapid (in some cases hyperexponential) decreases in cost, and increases in performance, of a variety of technologies, including DNA sequencing, DNA synthesis, and a range of physical and computational tools used in protein expression and in determining protein structures.
Eroom's Law – is a pharmaceutical drug development observation which was deliberately written as Moore's Law spelled backwards in order to contrast it with the exponential advancements of other forms of technology (such as transistors) over time. The law states that the cost of developing a new drug roughly doubles every nine years.

</doc>
<doc id="39420" url="https://en.wikipedia.org/wiki?curid=39420" title="Right triangle">
Right triangle

A right triangle (American English) or right-angled triangle (British English) is a triangle in which one angle is a right angle (that is, a 90-degree angle). The relation between the sides and angles of a right triangle is the basis for trigonometry.
The side opposite the right angle is called the "hypotenuse" (side "c" in the figure). The sides adjacent to the right angle are called "legs" (or "catheti", singular: "cathetus"). Side "a" may be identified as the side "adjacent to angle B" and "opposed to" (or "opposite") "angle A", while side "b" is the side "adjacent to angle A" and "opposed to angle B".
If the lengths of all three sides of a right triangle are integers, the triangle is said to be a Pythagorean triangle and its side lengths are collectively known as a Pythagorean triple.
Principal properties.
Area.
As with any triangle, the area is equal to one half the base multiplied by the corresponding height. In a right triangle, if one leg is taken as the base then the other is height, so the area of a right triangle is one half the product of the two legs. As a formula the area "T" is
where "a" and "b" are the legs of the triangle.
If the incircle is tangent to the hypotenuse AB at point P, then denoting the semi-perimeter as "s", we have and , and the area is given by
This formula only applies to right triangles.
Altitudes.
If an altitude is drawn from the vertex with the right angle to the hypotenuse then the triangle is divided into two smaller triangles which are both similar to the original and therefore similar to each other. From this:
In equations,
where "a", "b", "c", "d", "e", "f" are as shown in the diagram. Thus
Moreover, the altitude to the hypotenuse is related to the legs of the right triangle by
For solutions of this equation in integer values of "a, b, f", and "c", see here.
The altitude from either leg coincides with the other leg. Since these intersect at the right-angled vertex, the right triangle's orthocenter—the intersection of its three altitudes—coincides with the right-angled vertex.
Pythagorean theorem.
The Pythagorean theorem states that:
In any right triangle, the area of the square whose side is the hypotenuse (the side opposite the right angle) is equal to the sum of the areas of the squares whose sides are the two legs (the two sides that meet at a right angle).
This can be stated in equation form as
where "c" is the length of the hypotenuse, and "a" and "b" are the lengths of the remaining two sides.
Pythagorean triples are integer values of "a, b, c" satisfying this equation.
Inradius and circumradius.
The radius of the incircle of a right triangle with legs "a" and "b" and hypotenuse "c" is
The radius of the circumcircle is half the length of the hypotenuse,
Thus the sum of the circumradius and the inradius is half the sum of the legs:
One of the legs can be expressed in terms of the inradius and the other leg as
Characterizations.
A triangle "ABC" with sides formula_13, semiperimeter "s", area "T", altitude "h" opposite the longest side, circumradius "R", inradius "r", exradii "ra", "rb", "rc" (tangent to "a", "b", "c" respectively), and medians "ma", "mb", "mc" is a right triangle if and only if any one of the statements in the following six categories is true. All of them are of course also properties of a right triangle, since characterizations are equivalences.
Trigonometric ratios.
The trigonometric functions for acute angles can be defined as ratios of the sides of a right triangle. For a given angle, a right triangle may be constructed with this angle, and the sides labeled opposite, adjacent and hypotenuse with reference to this angle according to the definitions above. These ratios of the sides do not depend on the particular right triangle chosen, but only on the given angle, since all triangles constructed this way are similar. If, for a given angle α, the opposite side, adjacent side and hypotenuse are labeled "O", "A" and "H" respectively, then the trigonometric functions are
For the expression of hyperbolic functions as ratio of the sides of a right triangle, see the hyperbolic triangle of a hyperbolic sector.
Special right triangles.
The values of the trigonometric functions can be evaluated exactly for certain angles using right triangles with special angles. These include the "30-60-90 triangle" which can be used to evaluate the trigonometric functions for any multiple of π/6, and the "45-45-90 triangle" which can be used to evaluate the trigonometric functions for any multiple of π/4.
Kepler triangle.
Let "H", "G", and "A" be the harmonic mean, the geometric mean, and the arithmetic mean of two positive numbers "a" and "b" with "a" > "b". If a right triangle has legs "H" and "G" and hypotenuse "A", then
and
where formula_40 is the golden ratio formula_41 Since the sides of this right triangle are in geometric progression, this is the Kepler triangle.
Thales' theorem.
Thales' theorem states that if "A" is any point of the circle with diameter "BC" (except "B" or "C" themselves) "ABC" is a right triangle where "A" is the right angle. The converse states that if a right triangle is inscribed in a circle then the hypotenuse will be a diameter of the circle. A corollary is that the length of the hypotenuse is twice the distance from the right angle vertex to the midpoint of the hypotenuse. Also, the center of the circle that circumscribes a right triangle is the midpoint of the hypotenuse and its radius is one half the length of the hypotenuse.
Medians.
The following formulas hold for the medians of a right triangle:
The median on the hypotenuse of a right triangle divides the triangle into two isosceles triangles, because the median equals one-half the hypotenuse.
The medians "m""a" and "m""b" from the legs satisfy
Euler line.
In a right triangle, the Euler line contains the median on the hypotenuse—that is, it goes through both the right-angled vertex and the midpoint of the side opposite that vertex. This is because the right triangle's orthocenter, the intersection of its altitudes, falls on the right-angled vertex while its circumcenter, the intersection of its perpendicular bisectors of sides, falls on the midpoint of the hypotenuse.
Inequalities.
In any right triangle the diameter of the incircle is less than half the hypotenuse, and more strongly it is less than or equal to the hypotenuse times formula_44
In a right triangle with legs "a", "b" and hypotenuse "c",
with equality only in the isosceles case.
If the altitude from the hypotenuse is denoted "h""c", then
with equality only in the isosceles case.
Other properties.
If segments of lengths "p" and "q" emanating from vertex "C" trisect the hypotenuse into segments of length "c"/3, then
The right triangle is the only triangle having two, rather than one or three, distinct inscribed squares.
Let "h" and "k" ("h" > "k") be the sides of the two inscribed squares in a right triangle with hypotenuse "c". Then
These sides and the incircle radius "r" are related by a similar formula:
The perimeter of a right triangle equals the sum of the radii of the incircle and the three excircles:

</doc>
<doc id="39425" url="https://en.wikipedia.org/wiki?curid=39425" title="Primo Levi">
Primo Levi

Primo Michele Levi (; 31 July 1919 – 11 April 1987) was an Italian Jewish chemist, writer, and Holocaust survivor. He was the author of several books, novels, collections of short stories, essays, and poems. His best-known works include "If This Is a Man" (1947) (U.S.: "Survival in Auschwitz"), his account of the year he spent as a prisoner in the Auschwitz concentration camp in Nazi-occupied Poland; and his unique work, "The Periodic Table" (1975), linked to qualities of the elements, which the Royal Institution of Great Britain named the best science book ever written.
Levi died in 1987 from injuries sustained in a fall from a third-story apartment landing. While his death was officially ruled a suicide, some evidence supports the possibility that the fall was accidental.
Biography.
Early life.
Levi was born in 1919 in Turin, Italy, at Corso Re Umberto 75, into a liberal Jewish family. His father Cesare worked for the manufacturing firm Ganz and spent much of his time working abroad in Hungary, where Ganz was based. Cesare was an avid reader and autodidact. Levi's mother Ester, known to everyone as Rina, was well educated, having attended the . She too was an avid reader, played the piano, and spoke fluent French. The marriage between Rina and Cesare had been arranged by Rina's father. On their wedding day, Rina's father, Cesare Luzzati, gave Rina the apartment at , where Primo Levi lived for almost his entire life.
In 1921 Anna Maria, Levi's sister was born; he was to remain close to her all his life. In 1925 he entered the primary school in Turin. A thin and delicate child, he was shy and thought he was ugly; he excelled academically. His school record includes long periods of absence during which time he was tutored at home, at first by Emilia Glauda and then by Marisa Zini, daughter of philosopher Zino Zini. The children spent summers with their mother in the Waldensian valleys southwest of Turin, where Rina rented a farmhouse. His father remained in the city, partly because of his dislike of the rural life, but also because of his infidelities.
In September 1930 Levi entered the Royal Gymnasium a year ahead of normal entrance requirements. In class he was the youngest, the shortest and the cleverest, as well as being the only Jew. For these reasons, he was bullied. In August 1932, following two years at the Talmud Torah school in Turin, he sang in the local synagogue for his Bar Mitzvah. In 1933, as was expected of all young Italian schoolboys, he joined the Avanguardisti movement for young Fascists. He avoided rifle drill by joining the ski division, and spent every Saturday during the season on the slopes above Turin. As a young boy Levi was plagued by illness, particularly chest infections, but he was keen to participate in physical activity. In his teens, Levi and a few friends would sneak into a disused sports stadium and conduct athletic competitions.
In July 1934 at the age of 14, he sat the exams for the , a Lyceum (sixth form) specialising in the classics, and was admitted that autumn. The school was noted for its well-known anti-Fascist teachers, amongst them the philosopher Norberto Bobbio, and Cesare Pavese, who would later become one of Italy's best-known novelists. Levi continued to be bullied during his time at the Lyceum, although six other Jews were in his class. Upon reading "Concerning the Nature of Things" by Sir William Bragg, Levi decided that he wanted to be a chemist.
In 1937, Levi was summoned before the War Ministry and accused of ignoring a draft notice from the Italian Royal Navy—one day before he was to write a final examination on Italy's participation in the Spanish Civil War, based on a quote from Thucydides: "We have the singular merit of being brave to the utmost degree." Distracted and terrified by the draft accusation, he failed the exam—the first poor grade of his life—and was devastated. His father was able to keep him out of the Navy, however, by enrolling him in the Fascist militia ("Milizia Volontaria per la Sicurezza Nazionale"). He remained a member through his first year of university, until passage of the Italian Racial Laws of 1938 forced his expulsion. Levi later recounted this series of events in the short story "Fra Diavolo on the Po".
At the end of the summer he retook and passed his final examinations, and in October enrolled at the University of Turin to study chemistry. As one of 80 candidates, he spent three months taking lectures, and in February, after passing his "colloquio" (oral examination), he was selected as one of 20 to move on to the full-time chemistry curriculum.
In the liberal period as well as in the first decade of the Fascist regime, Jews held many public positions, and were prominent in literature, science and politics. In 1929 Mussolini signed an agreement with the Catholic Church, the Lateran Treaty, which established Catholicism as the State religion, allowed the Church to influence many sectors of education and public life, and relegated other religions to the status of "tolerated cults". A year later, based on the new restrictions imposed on Italian public life by the Lateran Treaty, the regime promulgated legislation that defined the relations between the State and the Italian Jewish communities. In 1936 Italy's conquest of Ethiopia and the expansion of what the regime regarded as the Italian "colonial empire" brought the question of "race" to the forefront for the first time in the post-unification political narrative. Within the context set by these two events, and the 1940 alliance with Hitler's Germany, the situation of the Jews of Italy changed radically.
In July 1938 a group of prominent Italian scientists and intellectuals published the "Manifesto of Race," a mixture of racial and ideological antisemitic theories from ancient and modern sources. This treatise formed the basis for the Italian Racial Laws of October 1938. After enactment of this Italian anti-Jewish legislation, Italian Jews lost their basic civil rights, their positions in public offices, and their assets. Their books were prohibited and Jewish writers could not publish in magazines owned by Aryans. Jewish students who had begun their course of study were permitted to continue, but new Jewish students were barred from entering university. Levi's having matriculated a year early enabled him to take a degree.
In 1939 Levi began his love affair with hiking in the mountains. His friend Sandro Delmastro taught him how to hike, and they spent many week-ends in the mountains above Turin. Physical exertion, the risk, and the battle with the elements supplied him with an outlet for all the frustrations in his life, as Levi later wrote in the chapter "Iron" of "The Periodic Table" (1975). In June 1940 Italy declared war as an ally of Germany against Britain and France, and the first Allied air raids on Turin began two days later. Levi's studies continued during the bombardments. The family suffered additional strain as his father became bedridden with bowel cancer.
Chemistry.
Because of the new Racial Laws and the increasing intensity of prevalent Fascism, Levi had difficulty finding a supervisor for his graduation thesis, which was on the subject of Walden inversion, a study of the asymmetry of the carbon atom. Eventually taken on by Dr. Nicolò Dallaporta, he graduated in the summer of 1941 with full marks and merit, having submitted additional theses on x-rays and electrostatic energy. His degree certificate bore the remark, "of Jewish race". The racial laws prevented Levi from finding a suitable permanent job after he had graduated.
In December 1941 Levi was clandestinely offered a job at an asbestos mine at San Vittore. The project was to extract nickel from the mine spoil, a challenge he accepted with pleasure. Levi understood that, if successful, he would be aiding the German war effort, which was suffering nickel shortages in the production of armaments. The job required Levi to work under a false name with false papers. In March 1942 while he was working at the mine, his father died.
In June 1942, due to the deteriorating situation in Turin, Levi left the mine and went to work in Milan. He had been recruited through a fellow student at Turin University, who was then working for the Swiss firm of A Wander Ltd on a project to extract an anti-diabetic from vegetable matter. He could take the job because the racial laws did not apply to Swiss companies. It soon became clear that the project had no chance of succeeding, but it was in no one's interest to say so.
In July 1943, King Victor Emmanuel III deposed Mussolini and appointed a new government under Marshal Pietro Badoglio, who signed the Armistice of Cassibile with the Allies. When the armistice was made public on 8 September, the Germans occupied Northern and Central Italy, liberated Mussolini from imprisonment and appointed him as head of the Italian Social Republic, a puppet state in German-occupied northern Italy. Levi returned to Turin to find his mother and sister having taken refuge in their holiday home La Saccarello in the hills outside the city. The three embarked to Saint-Vincent in the Aosta Valley, where they could be hidden. Being pursued as Jews, many of whom had already been interned by the authorities, they moved up the hillside to Amay in the Colle di Joux. Amay was on the route to Switzerland that was followed by Allied prisoners of war and refugees trying to escape the Germans.
The Italian resistance movement became increasingly active in the German-occupied zone. Levi and a number of comrades took to the foothills of the Alps, and in October formed a partisan group in the hope of being affiliated to the liberal "Giustizia e Libertà" resistance movement. Completely untrained for such a venture, he and his companions were arrested by the Fascist militia on 13 December 1943.
When told he would be shot as an Italian partisan, Levi confessed to being Jewish. He was sent to the internment camp at Fossoli near Modena. He recalled that as long as Fossoli was under the control of the Italian Social Republic, rather than Nazi Germany, he was not harmed."We were given, on a regular basis, a food ration destined for the soldiers", Levi's testimony stated, "and at the end of January 1944, we were taken to Fossoli on a passenger train. Our conditions in the camp were quite good. There was no talk of executions and the atmosphere was quite calm. We were allowed to keep the money we had brought with us and to receive money from the outside. We worked in the kitchen in turn and performed other services in the camp. We even prepared a dining room, a rather sparse one, I must admit."- Account held at Yad Vashem.
Auschwitz.
Fossoli was then taken over by the Germans, who started arranging the deportations of the Jews to eastern concentration and death camps. On the second of these transports, on 21 February 1944, Levi and other inmates were transported in twelve cramped cattle trucks to Monowitz, one of the three main camps in the Auschwitz concentration camp complex. Levi (record number 174517) spent eleven months there before the camp was liberated by the Red Army on 18 January 1945. Of the 650 Italian Jews in his transport, Levi was one of twenty who left the camps alive. The average life expectancy of a new entrant at the camp was three months.
Levi knew some German from reading German publications on chemistry; he worked to orient quickly to life in the camp without attracting the attention of the privileged inmates. He used bread to pay a more experienced Italian prisoner for German lessons and orientation in Auschwitz. He was given a smuggled soup ration each day by Lorenzo Perrone, an Italian civilian bricklayer working there as a forced labourer. Levi's professional qualifications were useful: in mid-November 1944, he secured a position as an assistant in IG Farben's Buna Werke laboratory that was intended to produce synthetic rubber. His avoiding hard labour in freezing outdoor temperatures enabled him to survive. He was also able to steal materials from the laboratory and trade them for extra food. Shortly before the camp was liberated by the Red Army, he fell ill with scarlet fever and was placed in the camp's sanatorium (camp hospital). On 18 January 1945, the SS hurriedly evacuated the camp as the Red Army approached, forcing all but the gravely ill on a long death march to a site further from the front, which resulted in the deaths of the vast majority of the remaining prisoners on the march. Levi's illness spared him this fate.
Although liberated on 27 January 1945, Levi did not reach Turin until 19 October 1945. After spending some time in a Soviet camp for former concentration camp inmates, he embarked on an arduous journey home in the company of former Italian prisoners of war who had been part of the Italian Army in Russia. His long railway journey home to Turin took him on a circuitous route from Poland, through Belarus, Ukraine, Romania, Hungary, Austria, and Germany. In later writing, he noted the millions of displaced people on the roads and trains throughout Europe in that period.
Writing career.
1946–1960.
Levi was almost unrecognisable on his return to Turin. Malnutrition edema had bloated his face. Sporting a scrawny beard and wearing an old Red Army uniform, he returned to Corso Re Umberto. The next few months gave him an opportunity to recover physically, re-establish contact with surviving friends and family, and start looking for work. Levi suffered from the psychological trauma of his experiences. Having been unable to find work in Turin, he started to look for work in Milan. On his train journeys, he began to tell people he met stories about his time at Auschwitz.
At a Jewish New Year party in 1946, he met Lucia Morpurgo, who offered to teach him to dance. Levi fell in love with Lucia. At about this time, he started writing poetry about his experiences in Auschwitz.
On 21 January 1946 he started work at DUCO, a Du Pont Company paint factory outside Turin. Because of the extremely limited train service, Levi stayed in the factory dormitory during the week. This gave him the opportunity to write undisturbed. He started to write the first draft of "If This Is a Man". Every day he scribbled notes on train tickets and scraps of paper as memories came to him. At the end of February, he had ten pages detailing the last ten days between the German evacuation and the arrival of the Red Army. For the next ten months, the book took shape in his dormitory as he typed up his recollections each night.
On 22 December 1946, the manuscript was complete. Lucia, who now reciprocated Levi's love, helped him to edit it, to make the narrative flow more naturally. In January 1947, Levi was taking the finished manuscript around to publishers. It was rejected by Einaudi on the advice of Natalia Ginzburg. The social wounds of the war years were still too fresh, and he had no literary experience to give him a reputation as an author.
Eventually Levi found a publisher, Franco Antonicelli, through a friend of his sister's. Antonicelli was an amateur publisher, but as an active anti-Fascist, he supported the idea of the book.
At the end of June 1947, Levi suddenly left DUCO and teamed up with an old friend Alberto Salmoni to run a chemical consultancy from the top floor of Salmoni's parents' house. Many of Levi's experiences of this time found their way into his later writing. They made most of their money from making and supplying stannous chloride for mirror makers, delivering the unstable chemical by bicycle across the city. The attempts to make lipsticks from reptile excreta and a coloured enamel to coat teeth were turned into short stories. Accidents in their laboratory filled the Salmoni house with unpleasant smells and corrosive gases.
In September 1947, Levi married Lucia and a month later, on 11 October, "If This Is a Man" was published with a print run of 2,000 copies. In April 1948, with Lucia pregnant with their first child, Levi decided that the life of an independent chemist was too precarious. He agreed to work for Accatti in the family paint business which traded under the name SIVA. In October 1948, his daughter Lisa was born.
During this period, his friend Lorenzo Perrone declined and died. Lorenzo had been a civilian forced worker in Auschwitz, who for six months had given part of his ration and a piece of bread to Levi without asking for anything in return.The gesture saved Levi's life. In his memoir, Levi contrasted Lorenzo with everyone else in the camp, prisoners and guards alike, as someone who managed to preserve his humanity. After the war, Lorenzo could not cope with the memories of what he had seen and descended into alcoholism. Levi made several trips to rescue his old friend from the streets, but in 1952 Lorenzo died.
In 1950, having demonstrated his chemical talents to Accatti, Levi was promoted to Technical Director at SIVA. As SIVA's principal chemist and trouble shooter, Levi travelled abroad. He made several trips to Germany and carefully engineered his contacts with senior German businessmen and scientists. Wearing short-sleeved shirts, he made sure they saw his prison camp number tattooed on his arm. He engaged them in talking about the depravity of the Nazis and the lack of redemption sought by most Germans, many of whom had been involved in the exploitation of slave labour from occupied countries during the war.
He became involved in organisations pledged to remembering and recording the horror of the camps. In 1954 he visited Buchenwald to mark the ninth anniversary of the camp's liberation from the Nazis. Levi dutifully attended many such anniversary events over the years and recounted his own experiences. In July 1957, his son Renzo was born, almost certainly named after his saviour Lorenzo Perrone.
Despite a positive review by Italo Calvino in "", only 1,500 copies of "If This Is a Man" were sold. In 1958 Einaudi, a major publisher, published it in a revised form and promoted it.
In 1958 Stuart Woolf, in close collaboration with Levi, translated "If This Is a Man" into English, and it was published in the UK in 1959 by Orion Press. Also in 1959 Heinz Riedt, also under close supervision by Levi, translated it into German. As one of Levi's primary reasons for writing the book was to get the German people to realise what had been done in their name, and to accept at least partial responsibility, this translation was perhaps the most significant to him.
1961–1974.
Levi began writing "The Truce" early in 1961; it was published in 1963, almost 16 years after his first book. That year it won the first annual Premio Campiello literary award. It is often published in one volume with "If This Is a Man", as it covers his long return through eastern Europe from Auschwitz. Levi's reputation was growing. He regularly contributed articles to , the Turin newspaper. He worked to gain a reputation as a writer about subjects other than survival of Auschwitz.
In 1963, he suffered his first major bout of depression. At the time he had two young children, a responsible job at a factory where accidents could and did have terrible consequences, he travelled and became a public figure. But, the memory of what happened less than twenty years earlier still burned in his mind. Today the link between such trauma and depression is better understood. Doctors prescribed several different drugs over the years, but these had variable efficacy and side effects.
In 1964 Levi collaborated on a radio play based upon "If This Is a Man" with the state broadcaster RAI, and in 1966 with a theatre production.
He published two volumes of science fiction short stories under the pen name of Damiano Malabaila, which explored ethical and philosophical questions. These imagined the effects on society of inventions which many would consider beneficial, but which, he saw, would have serious implications. Many of the stories from the two books ' ("Natural Histories") (1966) and ' ("Structural Defect") (1971) were later collected and published in English as "The Sixth Day and other Tales".
In 1974 Levi arranged to go into semi-retirement from SIVA in order to have more time to write. He also wanted to escape the burden of responsibility for managing the paint plant.
1975–1987.
In 1975 a collection of Levi's poetry was published under the title ("The Bremen Beer Hall"). It was published in English as "Shema: Collected Poems".
He wrote two other highly praised memoirs, ("Moments of Reprieve") (1978) and ("The Periodic Table") (1975). "Moments of Reprieve" deals with characters he observed during imprisonment. "The Periodic Table" is a collection of short pieces, based in episodes from his life but including two short stories that he wrote before his time in Auschwitz. Each story was related in some way to one of the chemical elements. At London's Royal Institution on 19 October 2006, "The Periodic Table" was voted onto the shortlist for the best science book ever written.
In 1977 at the age of 58, Levi retired as a part-time consultant at the SIVA paint factory to devote himself full-time to writing. Like all his books, "La chiave a stella" (1978), published in the US in 1986 as "The Monkey Wrench" and in the UK in 1987 as "The Wrench," is difficult to categorize. Some reviews describe it as a collection of stories about work and workers told by a narrator who resembles Levi. Others have called it a novel, created by the linked stories and characters. Set in a FIAT-run company town in Russia called Togliattigrad, it portrays the engineer as a hero on whom others depend. The underlying philosophy is that pride in one's work is necessary for fulfillment. The engineer Faussone travels the world as an expert in erecting cranes and bridges. Left-wing critics said he did not describe the harsh working conditions on the assembly lines at FIAT. However, it brought Levi a wider audience in Italy. "The Wrench" won the Strega Prize in 1979. Most of the stories involve the solution of industrial problems by the use of troubleshooting skills; many stories come from the author's personal experience.
In 1984 Levi published his only novel, "If Not Now, When?"— or his second novel, if "The Monkey Wrench" is counted. It traces the fortunes of a group of Jewish partisans behind German lines during World War II as they seek to survive and continue their fight against the occupier. With the ultimate goal of reaching Palestine to take part in the development of a Jewish national home, the partisan band reaches Poland and then German territory. There the surviving members are officially received as displaced persons in territory held by the Western allies. Finally, they succeed in reaching Italy, on their way to Palestine. The novel won both the and the .
The book was inspired by events during Levi's train journey home after release from the camp, narrated in "The Truce". At one point in the journey, a band of Zionists hitched their wagon to the refugee train. Levi was impressed by their strength, resolve, organisation, and sense of purpose.
Levi became a major literary figure in Italy, and his books were translated into many other languages. "The Truce" became a standard text in Italian schools. In 1985, he flew to the United States for a 20-day speaking tour. Although he was accompanied by Lucia, the trip was very draining for him.
In the Soviet Union his early works were not accepted by censors as he had portrayed Soviet soldiers as slovenly and disorderly rather than heroic. In Israel, a country formed partly by Jewish survivors who lived through horrors similar to those Levi described, his works were not translated and published until after his death.
In March 1985 he wrote the introduction to the re-publication of the autobiography of Rudolf Höss, who was commandant of Auschwitz concentration camp from 1940 to 1943. In it he writes, "It's filled with evil . . . and reading it is agony."
Also in 1985 a volume of his essays, previously published in , was published under the title ("Other People's Trades"). Levi used to write these stories and hoard them, releasing them to "" at the rate of about one a week. The essays ranged from book reviews and ponderings about strange things in nature, to fictional short stories.
In 1986 his book "" ("The Drowned and the Saved"), was published. In it he tried to analyse why people behaved the way they did at Auschwitz, and why some survived whilst others perished. In his typical style, he makes no judgments but presents the evidence and asks the questions. For example, one essay examines what he calls "The Grey Area", those Jews who did the Germans' dirty work for them and kept the rest of the prisoners in line. He questioned, what made a concert violinist behave as a callous taskmaster?
Also in 1986 another collection of short stories, previously published in , was assembled and published as (some of which were published in the English volume "The Mirror Maker").
At the time of his death in April 1987, Levi was working on another selection of essays called "The Double Bond," which took the form of letters to . These essays are very personal in nature. Approximately five or six chapters of this manuscript exist. Carole Angier, in her biography of Levi, describes how she tracked some of these essays down. She wrote that others were being kept from public view by Levi's close friends, to whom he gave them, and they may have been destroyed.
In March 2007 "Harper's Magazine" published an English translation of Levi's story , about a fictitious weapon that is fatal at close range but harmless more than a meter away. It originally appeared in his 1971 book , but was published in English for the first time by "Harper's".
"A Tranquil Star", a collection of seventeen stories translated into English by Ann Goldstein and Alessandra Bastagli [http://www2.wwnorton.com/catalog/spring07/006468.htm was published in April 2007.
In 2015, Penguin published The Complete Works of Primo Levi, ed. Ann Goldstein. This is the first time that Levi's entire oeuvre has been translated into English. 
Views on Nazism and antisemitism.
Levi wrote "If This Is a Man" to bear witness to the horrors of the Nazis' attempt to exterminate the Jewish people and others. In turn, he read many accounts by witnesses and survivors, and attended meetings of survivors, becoming a prominent symbolic figure for anti-fascists in Italy.
Levi visited over 130 schools to talk about his experiences in Auschwitz. He was shocked by revisionist attitudes that tried to rewrite the history of the camps as less horrific, what is now referred to as Holocaust denial. His view was that the Nazi death camps and the attempted annihilation of the Jews was a horror unique in history because the goal was the complete destruction of a race by one that saw itself as superior. He noted that it was highly organized and mechanized; it entailed the degradation of Jews to the point of using their ashes as materials for paths.
With the publication in the late 1960s and 1970s of the works of Aleksandr Solzhenitsyn, the world learned that the Soviet regime used camps (gulags) to imprison a wide range and millions of dissidents, who might be detained in hard labor for as much as twenty years, if they survived the harsh conditions. Similarities with the "Lager" included hard physical work and poor rations. Levi rejected, however, the idea that "The Gulag Archipelago" and the system of the Nazi ' (; see Nazi concentration camps) were equivalent. The death rate in the gulags was estimated at 30% at worst, he wrote, while in the "Lager" he estimated that it was 90–98%. The goal of the ' was the extermination of the Jewish race in Europe. No one was excluded. No-one could renounce Judaism; the Nazis treated Jews as a racial group rather than as a religious one. Of the many children deported to the camps, almost all died. The purpose of the Nazi camps was not the same as that of the Soviet gulags, Levi wrote in an appendix to "If This Is a Man", though it is a "lugubrious comparison between two models of hell".
Levi, along with most of Turin's Jewish intellectuals, had not been religiously observant before World War II. The Fascist race laws and the Nazi camps impressed on him his identity as a Jew. Levi wrote in clear, dispassionate style about his experiences in Auschwitz, with an embrace of whatever humanity he found, showing no lasting hatred of the Germans. Some commentators suggested that he had forgiven the Germans, but Levi denied this.
Death.
Levi died on 11 April 1987 after a fall from the interior landing of his third-storey apartment in Turin to the ground floor below. The coroner ruled his death a suicide. Three of his biographers (Angier, Thomson and Anissimov) agreed. In his later life, Levi indicated that he was suffering from depression; factors likely included responsibility for his elderly mother and mother-in-law, with whom he was living, and lingering traumatic memories of his experiences. The Nobel laureate and Holocaust survivor Elie Wiesel said, at the time, "Primo Levi died at Auschwitz forty years later".
The Oxford sociologist Diego Gambetta has argued, however, that the suicide conclusion is not justified by either factual or inferred evidence. Levi left no suicide note, nor any other indication that he was considering suicide. Documents and testimony suggested that he had plans for both the short- and longer-term at the time. After visiting the apartment complex, Gambetta concluded that a more plausible explanation is that Levi lost his balance and fell accidentally, as he had complained to his physician of dizziness in the days preceding his death. The Nobel laureate Rita Levi-Montalcini, a close friend of Levi, agreed. "As a chemical engineer he might have chosen a better way of the world than jumping into a narrow stairwell with the risk of remaining paralyzed."
Further reading.
Giffuni, Cathe. "An English Bibliography of the Writings of Primo Levi," Bulletin of Bibliography, Vol. 50 No. 3 September 1993, pp. 213–221.

</doc>
<doc id="39430" url="https://en.wikipedia.org/wiki?curid=39430" title="Four Horsemen of the Apocalypse">
Four Horsemen of the Apocalypse

The Four Horsemen of the Apocalypse are described in the last book of the New Testament of the Bible, called the Book of Revelation of Jesus Christ to John the Apostle, at . The chapter tells of a book or scroll in God's right hand that is sealed with seven seals. The Lamb of God, or Lion of Judah (Jesus Christ), opens the first four of the seven seals, which summons four beings that ride out on white, red, black, and pale horses. Though theologians and popular culture differ on the first horseman, the four riders are often seen as symbolizing Conquest or Pestilence (and less frequently, the Christ or the Antichrist), War, Famine, and Death, respectively. The Christian apocalyptic vision is that the four horsemen are to set a divine apocalypse upon the world as harbingers of the Last Judgment. One reading ties the four horsemen to the history of the Roman Empire subsequent to the era in which the Book of Revelation was written. That is, they are a symbolic prophecy of the subsequent history of the empire.
White Horse.
Based on the above passage, a common translation into English, the white rider is generally referred to as "Conquest". The name could also be construed as "Victory," as in the translation found in the Jerusalem Bible (the Greek words are derived from the verb νικάω, to conquer or vanquish). He carries a bow, and wears a victor's crown.
The rider has also been called "Pestilence", particularly in popular culture (see below).
As righteous.
Irenaeus, an influential Christian theologian of the 2nd century, was among the first to interpret this horseman as Christ himself, his white horse representing the successful spread of the gospel. Various scholars have since supported this notion, citing the later appearance, in Revelation 19, of Christ mounted on a white horse, appearing as The Word of God. Furthermore, earlier in the New Testament, the Book of Mark indicates that the advance of the gospel may indeed precede and foretell the apocalypse. The color white also tends to represent righteousness in the Bible, and Christ is in other instances portrayed as a conqueror.
However, opposing interpretations argue that the first of the four horsemen is probably not the horseman of Revelation 19. They are described in significantly different ways, and Christ's role as the Lamb who opens the seven seals makes it unlikely that he would also be one of the forces released by the seals.
Besides Christ, the horseman could represent the Holy Spirit. The Holy Spirit was understood to have come upon the Apostles at Pentecost after Jesus' departure from Earth. The appearance of the Lion in Revelation 5 shows the triumphant arrival of Jesus in Heaven, and the white horseman could represent the sending of the Holy Spirit by Jesus and the advance of the gospel of Jesus Christ.
Other interpretations relying on comparative religious research ascribe the first horseman as guiding for "the right path"; Mahabharata Lord Krishna was a charioteer to Arjuna by riding on white horses, while Arjuna himself was an archer.
As infectious disease.
Under another interpretation, the first horseman is called Pestilence, and is associated with infectious disease and plague. It appears at least as early as 1906, when it is mentioned in the Jewish Encyclopedia. The interpretation is common in popular culture references to the Four Horsemen.
The origin of this interpretation is unclear. Some translations of the Bible mention "plague" (e.g. the NIV) or "pestilence" (e.g. the RSV) in connection with the riders in the passage following the introduction of the fourth rider; cf. "They were given power over a fourth of the earth to kill by sword, famine, plague, and by the wild beasts of the earth." ( NASB). However, it is a matter of debate as to whether this passage refers to the fourth rider, or to the four riders as a whole.
Vicente Blasco Ibáñez, in his 1916 novel "The Four Horsemen of the Apocalypse" (filmed in 1921 and in 1962), provides an early example of this interpretation, writing "The horseman on the white horse was clad in a showy and barbarous attire. [...] While his horse continued galloping, he was bending his bow in order to spread pestilence abroad. At his back swung the brass quiver filled with poisoned arrows, containing the germs of all diseases."
This interpretation exists in Kevin Kauffmann's "Forsaken Comedy" trilogy. In this depiction, a human named Niccolo contracts leprosy, dies, and falls to Hell where he rises through the ranks to become the Horseman of Pestilence, under Lucifer's tutelage.
As evil.
One interpretation, which was held by evangelist Billy Graham, casts the rider of the white horse as the Antichrist, or a representation of false prophets, citing differences between the white horse in Revelation 6 and Jesus on the white Horse in Revelation 19. In Revelation 19, Jesus has many crowns. In Revelation 6 the rider has just one. A crown given, not taken. This indicates a third person giving authority to the rider to accomplish his work.
As empire prosperity.
According to Edward Bishop Elliott's interpretation, that the four horsemen represent a prophecy of the subsequent history of the Roman Empire, the white color of this horse signifies triumph, prosperity and health in the political Roman body. For the next 80 or 90 years succeeding the banishment of the apostle John to Patmos covering the successive reigns of the emperors Nerva, Trajan, Hadrian and the two Antonines (Antoninus Pius and Marcus Aurelius), a golden age of prosperity, union, civil liberty and good government unstained with civil blood unfolded. The agents of this prosperity personified by the rider of the white horse are these five emperors wearing crowns that reigned with absolute authority and power under the guidance of virtue and wisdom, the armies being restrained by their firm and gentle hands.
This interpretation points out that the bow was preeminently a weapon of the inhabitants of the island of Crete and not of the Roman Empire in general. The Cretans were renowned for their archery skills. The significance of the rider of the white horse holding a bow indicates the place of origin of the line of emperors ruling during this time. This group of emperors can be classed together under one and the same head and family whose origins were from Crete.
According to this interpretation, this period in Roman history, remarkable, both at its commencement and at its close, illustrated the glory of the empire where its limits were extended though not without occasional wars which were always uniformly triumphant and successful on the frontiers. The triumphs of the Emperor Trajan, the Roman Alexander, added to the empire Dacia, Armenia, Mesopotamia, and other provinces during the course of the first 20 years of the period which deepened the impression on the minds of the barbarians of the invincibility of the Roman Empire. Roman war progressed triumphantly into the invader's own territory, and the Parthian war was successfully ended by the total overthrow of those people. Roman conquest is demonstrated even in the most mighty of these wars, the Marcomannic succession of victories under the second Antonine unleashed on the German barbarians, driven into their forests and reduced to Roman submission.
Red Horse.
The rider of the second horse is often taken to represent War (he is often pictured holding a sword upwards as though ready for battle) or mass slaughter. His horse's color is red (πυρρός, from πῦρ, fire); and in some translations, the colour is specifically a "fiery" red. The color red, as well as the rider's possession of a great sword, suggests blood that is to be spilled. The sword held upward by the second horseman may represent war or a declaration of war, as seen in heraldry. In military symbolism swords held upward, especially crossed swords held upward, signify war and entering into battle. (See for example the historical and modern images, as well as the , of Jeanne of Arc.)
The second horseman may represent civil war as opposed to the war of conquest that the first horseman is sometimes said to bring. Other commentators have suggested it might also represent persecution of Christians.
As empire division.
According to Edward Bishop Elliott's interpretation of the four horsemen as symbolic prophecy of the history of the Roman Empire, the second seal is opened and the Roman nation that experienced joy, prosperity and triumph is made subject to the red horse which depicts war and bloodshed — Civil War. Peace left the Roman earth resulting in the killing of one another as insurrection crept into and permeated the Empire beginning shortly into the reign of the Emperor Commodus.
Elliott points out that Commodus, who had nothing to wish and everything to enjoy, that beloved son of Marcus who ascended the throne with neither competitor to remove nor enemies to punish, became the slave of his attendants who gradually corrupted his mind. His cruelty degenerated into habit and became the ruling passion of his soul.
Elliott further recites that, after the death of Commodus, a most turbulent period lasting 92 years unfolded during which time 32 emperors and 27 pretenders to the Empire hurled each other from the throne by incessant civil warfare. The sword was a natural, universal badge among the Romans, of the military profession. The apocalyptic figure indicated by the great sword indicated an undue authority and unnatural use of it. Military men in power, whose vocation was war and weapon the sword, rose by it and also fell. The unrestrained military, no longer subject to the Senate, transformed the Empire into a system of pure military despotism.
Black Horse.
The third horseman rides a black horse and is popularly understood to be Famine as the horseman carries a pair of balances or weighing scales, indicating the way that bread would have been weighed during a famine. Other authors interpret the third horseman as the "Lord as a Law-Giver" holding Scales of Justice. In the passage it is read that the indicated price of grain is about ten times normal (thus the famine interpretation popularity), with an entire day's wages (a denarius) buying enough wheat for only one person, or enough of the less nutritious barley for three, so that workers would struggle to feed their families.
Of the four horsemen, the black horse and its rider are the only ones whose appearance is accompanied by a vocal pronunciation. John hears a voice, unidentified but coming from among the four living creatures, that speaks of the prices of wheat and barley, also saying "and see thou hurt not the oil and the wine". This suggests that the black horse's famine is to drive up the price of grain but leave oil and wine supplies unaffected (though out of reach of the ordinary worker). One explanation for this is that grain crops would have been more naturally susceptible to famine years or locust plagues than olive trees and grapevines, which root more deeply. The statement might also suggest a continuing abundance of luxuries for the wealthy while staples such as bread are scarce, though not totally depleted; such selective scarcity may result from injustice and the deliberate production of luxury crops for the wealthy over grain, as would have happened during the time "Revelation" was written. Alternatively, the preservation of oil and wine could symbolize the preservation of the Christian faithful, who used oil and wine in their sacraments.
As empire oppression.
According to Edward Bishop Elliott's interpretation, through this third seal, the black horse is unleashed — aggravated distress and mourning. A choenix of wheat for a denarius is not the price of famine but of scarcity. Three choenixes of barley for a denarius produces a loaf of barley bread above 5 pounds in weight. This amount of bread will sustain a man above starvation. The balance in the rider's hand is not associated with a man's weighing out bits of bread in scanty measure for his family's eating but in association with the buying and selling of corn and other grains. The balance during the time of the apostle John's exile in Patmos was commonly a symbol of justice since it was used to weigh out the grains for a set price. The balance of justice held in the hand of the rider of the black horse signified the aggravation of the other previous evil, the bloodstained red of the Roman aspect into the darker blackness of distress.
The black horse rider is instructed not to harm the oil and the wine which signifies that this scarcity should not fall upon the superfluities, such as oil and wine, which men can live without, but upon the necessities of life — bread.
In history, the distress upon the Roman Empire results from excessive taxation. During the reign of Emperor Caracalla, whose sentiments were very different from the Antonines being inattentive, or rather averse, to the welfare of the people, he found himself under the necessity of gratifying the greed and excessive lifestyle which he had excited in the Army. During his reign, he crushed every part of the empire under the weight of his iron scepter. Old as well as new taxes were at the same time levied in the provinces. In the course of this history, the land tax, the taxes for services and the heavy contributions of corn, wine, oil and meat were exacted from the provinces for the use of the court, army and capital. This noxious weed not totally eradicated again sprang up with the most luxurious growth and going forward darkened the Roman world with its deadly shade.
In reality, the rise to power of the Emperor Maximin, whose cruelty was derived from a different source being raised as a barbarian from the district of Thrace, expanded the distress on the empire beyond the confines of the illustrious senators or bold adventurers who in the court or army exposed themselves to the whims of fortune. This tyrant, stimulated by the insatiable desires of the soldiers, attacked the public property at length. Every city of the empire was destined to purchase corn for the multitudes as well as supply expenses for the games. By the Emperor's authority, the whole mass of wealth was confiscated for use by the Imperial treasury — temples stripped of their most valuable offerings of gold, silver and statues which were melted down and coined into money.
Pale Horse.
The fourth and final horseman is named Death. Known as "the pale rider", of all the riders, he is the only one to whom the text itself explicitly gives a name. Unlike the other three, he is not described carrying a weapon or other object, instead he is followed by Hades (the resting place of the dead). However, illustrations commonly depict him carrying a scythe (like the Grim Reaper), sword, or other implement.
The color of Death's horse is written as "khlōros" (χλωρός) in the original Koine Greek, which can mean either green/greenish-yellow or pale/pallid. The color is often translated as "pale", though "ashen", "pale green", and "yellowish green" are other possible interpretations (the Greek word is the root of "chlorophyll" and "chlorine"). Based on uses of the word in ancient Greek medical literature, several scholars suggest that the color reflects the sickly pallor of a corpse. In some modern artistic depictions, the horse is distinctly green.
The verse beginning "they were given power over a fourth of the earth" is generally taken as referring to Death and Hades, although some commentators see it as applying to all four horsemen.
As empire destruction.
This fourth, pale horse, was the personification of death with Hades following him jaws open receiving the victims slain by death. Its commission was to kill upon the Roman Earth with all of the four judgements of God — with sword, famine, pestilence and wild beasts. The deadly pale and livid appearance displays a hue symptomatic of approaching empire dissolution. According to Edward Bishop Elliott, an era in Roman history commencing within about 15 years after the death of Alexander Severus strongly marks every point of this terrible emblem. Edward Gibbon speaks of a period from the celebration of the great secular games by the Emperor Philip to the death of Gallienus as the 20 years of shame and misfortune, of confusion and calamity, as a time when the ruined empire approached the last and fatal moment of its dissolution. Every instant of time in every province of the Roman world was afflicted by military tyrants and barbarous invaders — the sword from within and without. 
According to Elliott, famine, the inevitable consequence of carnage and oppression, which demolished the produce of the present as well as the hope of future harvests, produced the environment for an epidemic of diseases, the effects of scanty and unwholesome food. That furious plague, which raged from the year 250 to the year 265, continued without interruption in every province, city and almost every family in the empire. During a portion of this time, 5000 persons died daily in Rome; and many towns that escaped the attacks of barbarians were entirely depopulated.
In reality, the strength of Aurelian had on every side crushed the enemies of Rome, yet after his death they revived with an increase of numbers and fury. During the following year, hosts of the Alani that spread themselves over Pontus, Cappadocia, Cilicia and Galatia etched their course by the flames of cities and villages they pillaged.
As for the wild beasts of the earth, according to Elliott, it is a well-known law of nature that they quickly occupy the scenes of waste and depopulation — where the reign of man fails and the reign of beast begins. After the reign of Gallienus and 20 or 30 years had passed, the multiplication of the animals had risen to such an extent in parts of the empire that they made it a crying evil.
One notable point of apparent difference between the prophecy and history might seem to be expressly limited to the fourth part of the Roman earth, but in the history of the period the devastations of the pale horse extended over at all. The fourth seal prophecy seems to mark the malignant climax of the evils of the two preceding seals to which no such limitation is attached. Turning to that remarkable reading in Jerome's Latin Vulgate which reads "over the four parts of the earth," it requires that the Roman empire should have some kind of quadripartition. Dividing from the central or Italian fourth, three great divisions of the Empire separated into the West, East and Illyricum under Posthumus, Aureolus and Zenobia respectively — divisions that were later legitimized by Diocletian.
Diocletian ended this long period of anarchy, but the succession of civil wars and invasions caused much suffering, disorder and crime which brought the empire into a state of moral lethargy from which it never recovered. After the plague had abated, the empire suffered from general distress, and its condition was very much like that which followed after the black death of the Middle Ages. Talent and art had become extinct in proportion to the desolation of the world.
Interpretations.
[[File:Durer Revelation Four Riders.jpg|thumb|upright|"The Horsemen of the Apocalypse", depicted in a woodcut by Albrecht Dürer (ca. 1497–98), ride forth as a group, with an angel heralding them, to bring Death, Famine, War, and Conquest unto man.
Futurist interpretation.
Some Christians interpret the horsemen as a prophecy of a future Tribulation, during which many on earth will die as a result of multiple catastrophes. The Four Horsemen are the first in a series of "Seal" judgements. This is when God will judge the Earth, and is giving the World a chance to repent before they die.
Historicist interpretation.
According to E.B. Elliott, the first seal, as revealed to John by the angel, was to signify what was to happen soon after John seeing the visions in Patmos and that the second, third and fourth seals in like manner were to have commencing dates each in chronological sequence following the preceding seal. Its general subject is the decline and fall, after a previous prosperous era, of the Empire of Heathen Rome. The first four seals of Revelation, represented by four horses and horsemen, are fixed to events, or changes, within the Roman earth.
Preterist interpretation.
Some modern scholars interpret Revelation from a preterist point of view, arguing that its prophecy and imagery apply only to the events of the first century of Christian history. In this school of thought, Conquest, the white horse's rider, is sometimes identified as a symbol of Parthian forces: Conquest carries a bow, and the Parthian Empire was at that time known for its mounted warriors and their skill with bow and arrow. Parthians were also particularly associated with white horses. Some scholars specifically point to Vologases I, a Parthian shah who clashed with the Roman Empire and won one significant battle in 62 AD.
Revelation's historical context may also influence the depiction of the black horse and its rider, Famine. In 92 AD, the Roman emperor Domitian attempted to curb excessive growth of grapevines and encourage grain cultivation instead, but there was major popular backlash against this effort, and it was abandoned. Famine's mission to make wheat and barley scarce but "hurt not the oil and the wine" could be an allusion to this episode. The red horse and its rider, who take peace from the earth, might represent the prevalence of civil strife at the time Revelation was written; internecine conflict ran rampant in the Roman Empire during and just prior to the 1st century AD.
Other interpretations.
Artwork which shows the horsemen as a group, such as the famous woodcut by Albrecht Dürer, suggests an interpretation where all four horsemen represent different aspects of the same tribulation.
American Protestant Evangelical interpreters regularly see ways in which the horsemen, and Revelation in general, speak to contemporary events. Some who believe Revelation applies to modern times can interpret the horses based on various ways their colors are used. Red, for example, often represents Communism, the white horse and rider with a crown representing Catholicism, Black has been used as a symbol of Capitalism, while Green represents the rise of Islam. Pastor Irvin Baxter Jr. of Endtime Ministries espouses such a belief.
Some equate the four horsemen with the angels of the four winds. "(See Michael, Gabriel, Raphael, and Uriel, angels often associated with four cardinal directions)"
Other Biblical references.
Zechariah.
The Book of Zechariah twice mentions colored horses; in the first passage there are three colors (red, speckled/brown, and white), and in the second there are four teams of horses (red, black, white, and finally dappled/"grisled and bay") pulling chariots. The second set of horses are referred to as "the four spirits of heaven, going out from standing in the presence of the Lord of the whole world."
They are described as patrolling the earth, and keeping it peaceful. It may be assumed that when the tribulation begins, the peace is taken away, so their job is to terrify the places in which they patrol.
Ezekiel.
The four living creatures of Revelation 4:6-8 are very similar to the four living creatures in Ezekiel 1:5-12. In Revelation each of the living creatures summons a horseman, where in Ezekiel the living creatures follow wherever the spirit leads, without turning.
In Ezekiel 14:21, the Lord enumerates His "four disastrous acts of judgment" (ESV), sword, famine, wild beasts, and pestilence, against the idolatrous elders of Israel. A symbolic interpretation of the four horsemen links the riders to these judgments, or the similar judgments in 6:11-12.

</doc>
<doc id="39431" url="https://en.wikipedia.org/wiki?curid=39431" title="New Scientist">
New Scientist

New Scientist is a UK-based weekly English-language international science magazine, founded in 1956. Since 1996 it has run a website.
Sold in retail outlets and on subscription, the magazine covers current developments, news, reviews and commentary on science and technology. It also prints speculative articles, ranging from the technical to the philosophical. There is a readers' letters section which discusses recent articles, and discussions also take place on the website.
Readers contribute observations on examples of pseudoscience to Feedback, and questions and answers on scientific and technical topics to Last Word; extracts from the latter have been compiled into several books.
"New Scientist" is based in London and publishes editions in the UK, the United States, and Australia.
History.
The magazine was founded in 1956 by Tom Margerison, Max Raison and Nicholas Harrison as "The New Scientist", with Issue 1 on 22 November, priced one shilling (£0.05 as 20 shillings in the £) (£ today).
The British monthly science magazine "Science Journal", published 1965–71, was merged with "New Scientist" to form "New Scientist and Science Journal".
Originally, the cover had a text list of articles rather than a picture. Pages were numbered sequentially for an entire quarterly volume, as is the norm for academic journals (i.e., so that the first page of a March issue could be 651 instead of 1). Later issues numbered pages separately. Until the 1970s, colour was not used except for on the cover. From the beginning of 1961 ""The"" was dropped from the title. From 1965, the front cover was illustrated. 
Since its first issue, New Scientist has written about the applications of science, through its coverage of technology. For example, the first issue included an article "Where next from Calder Hall?" on the future of nuclear power in the UK, a topic that it has covered throughout its history. In 1964 there was a regular "Science in British Industry" section with several items. 
An article published on the magazine's 10th anniversary issues provides some anecdotes on the founding of the magazine.
In 1970, the company Albert E. Reed acquired "New Scientist" when it merged with IPC Magazines, retaining the magazine when it sold most of its consumer magazines in a management buyout to what is now IPC Media.
Throughout most of its history, New Scientist has published cartoons as light relief and comment on the news, with contributions from such long-time regular contributors as Mike Peyton and David Austin. The Grimbledon Down comic strip, by the renowned cartoonist Bill Tidy, appeared from 1970 to 1994. 
Ariadne, which later moved to "Nature", commented weekly on the lighter side of science and technology, with the plausible but impractical humorous inventions of (fictitious) inventor Daedalus, often developed by the (fictitious) DREADCO corporation.
Issues of "(The) New Scientist" from Issue 1 to the end of 1989 have been made free to read online. Subsequent issues require a subscription.
In the first half of 2013, the international circulation of New Scientist averaged 125,172. While this was a 4.3% reduction on the previous year's figure, it was a much smaller reduction in circulation than many mainstream magazines of similar or greater circulation. For the 2014 UK circulation fell by 3.2% but stronger international sales, increased the circulation to 129,585. See also #Website below.
Modern format.
"New Scientist" currently contains the following sections: Leader, News, Technology, Opinion (interviews, point-of-view articles and letters), Features (including cover article), CultureLab (book and event reviews), Feedback (humour), The Last Word (questions and answers) and Jobs & Careers. A Tom Gauld cartoon appears on the Letters page. 
There are 51 issues a year; the Christmas and New Year double issue covers two weeks. The double issue in 2014 was the 3,000th edition of the magazine.
Staff and contributors.
Editor-in-chief is Jeremy Webb and the editor is Sumit Paul-Choudhury. Consultants include Fred Pearce (environment) and Marcus Chown (cosmology). 
Simon Ings and former editor Alun Anderson are contributors.
Advertising.
"New Scientist" runs advertisements for jobs and academic opportunities in science and technology. Originally in a "Classified Advertisements" section with subsections "Official Appointments", "Appointments and Situations Vacant", and "Travel" (coach holidays and prices), the section became "NewScientist Jobs".
Most advertising is full-page between sections.
Website.
The "New Scientist" website carries blogs, reports and news articles; users with free-of-charge registration have limited access to new content and can receive emailed "New Scientist" newsletters. Subscribers to the print edition have full access to all articles and the archive of past content that has so far been digitised.
The magazine had a weekly podcast, SciPod, which was discontinued in October 2007. In 2004 "NewScientist.com" added a subdomain, "nomoresocks" (No More Socks), where visitors could search for, rate, and discuss innovative gifts. Falling interest in the site resulted in its being discontinued in 2005.
From mid-2006 some "New Scientist" content was made available to users of Newsvine, a community-driven social news website. From mid-December 2009 to March 2010 non-subscribers could read up to seven articles per month.
In November 2009 "New Scientist" started The S Word, a blog providing a forum for the discussion of "The science of politics – and vice versa". It was so named because "Despite the central role that science plays in our world, politicians often seem reluctant to engage with it", with the aim of the blog being to help "persuade politicians that 'the s word' belongs at the heart of political debate".
The technology, environment and space sites were discontinued in 2008, with the content being integrated into the main site.
Online readership takes various forms. Overall global views of an online database of over 100,000 articles are 8.0m by 3.6m unique users according to Adobe Reports & Analytics, . On social media there are 1.47m+ Twitter followers, 2.3m+ Facebook likes and 365,000+ Google+ followers .
Spin-offs.
"New Scientist" has published books derived from its content, many of which are selected questions and answers from the "Last Word" section of the magazine and website -
Other books published by New Scientist include -
In 2012 "Arc", "a new digital quarterly from the makers of "New Scientist", exploring the future through the world of science fiction" and fact was launched. In the same year the magazine launched a dating service, NewScientistConnect, operated by The Dating Lab.
A Dutch edition of the New Scientist was launched in June 2015, replacing the former "Natuurwetenschap & Techniek (NWT)" magazine. The monthly magazine is published by Veen Media and sold in the Netherlands and Belgium.
Criticism.
Greg Egan's criticism of the EmDrive article.
In September 2006, "New Scientist" was criticised by science fiction writer Greg Egan, who wrote that "a sensationalist bent and a lack of basic knowledge by its writers" was making the magazine's coverage sufficiently unreliable "to constitute a real threat to the public understanding of science". In particular, Egan found himself "gobsmacked by the level of scientific illiteracy" in the magazine's coverage of Roger Shawyer's "electromagnetic drive", where "New Scientist" allowed the publication of "meaningless double-talk" designed to bypass a fatal objection to Shawyer's proposed space drive, namely that it violates the law of conservation of momentum. Egan urged others to write to "New Scientist" and pressure the magazine to raise its standards, instead of "squandering the opportunity that the magazine's circulation and prestige provides".
The editor of "New Scientist", then Jeremy Webb, replied defending the article, saying that it is "an ideas magazine—that means writing about hypotheses as well as theories".
"Darwin was wrong" cover.
In January 2009, "New Scientist" ran a cover with the title "Darwin was wrong". The actual story stated that specific details of Darwin's evolution theory had been shown incorrectly, mainly the shape of phylogenetic trees of interrelated species, which should be represented as a web instead of a tree. Some evolutionary biologists who actively oppose the intelligent design movement thought the cover was both sensationalist and damaging to the scientific community. Jerry Coyne, author of the book "Why Evolution Is True", called for a boycott of the magazine, which was supported by evolutionary biologists Richard Dawkins and P.Z. Myers.

</doc>
<doc id="39432" url="https://en.wikipedia.org/wiki?curid=39432" title="Stephen Cook">
Stephen Cook

Stephen Arthur Cook, (born December 14, 1939) is an American-Canadian computer scientist and mathematician who has made major contributions to the fields of complexity theory and proof complexity. He is currently a university professor at the University of Toronto, Department of Computer Science and Department of Mathematics.
Biography.
Cook received his Bachelor's degree in 1961 from the University of Michigan, and his Master's degree and Ph.D. from Harvard University, respectively in 1962 and 1966. He joined the University of California, Berkeley, mathematics department in 1966 as an assistant professor, and stayed there until 1970 when he was denied reappointment. In a speech celebrating the 30th anniversary of the Berkeley EECS department, fellow Turing Award winner and Berkeley professor Richard Karp said that, "It is to our everlasting shame that we were unable to persuade the math department to give him tenure." Cook joined the faculty of University of Toronto, Computer Science and Mathematics Departments in 1970 as an associate professor, where he was promoted to professor in 1975 and Distinguished Professor in 1985.
Research.
Stephen Cook is considered one of the forefathers of computational complexity theory.
During his PhD, Cook worked on complexity of functions, mainly on multiplication. In his seminal 1971 paper "The Complexity of Theorem Proving Procedures", Cook formalized the notions of polynomial-time reduction (a.k.a. Cook reduction) and NP-completeness, and proved the existence of an NP-complete problem by showing that the Boolean satisfiability problem (usually known as SAT) is NP-complete. This theorem was proven independently by Leonid Levin in the Soviet Union, and has thus been given the name the Cook-Levin theorem. The paper also formulated the most famous problem in computer science, the P vs. NP problem. Informally, the "P vs. NP" question asks whether every optimization problem whose answers can be efficiently verified for correctness/optimality can be solved optimally with an efficient algorithm. Given the abundance of such optimization problems in everyday life, a positive answer to the "P vs. NP" question would likely have profound practical and philosophical consequences.
Cook conjectures that there are optimization problems (with easily checkable solutions) which cannot be solved by efficient algorithms, i.e., P is not equal to NP. This conjecture has generated a great deal of research in computational complexity theory, which has considerably improved our understanding of the inherent difficulty of computational problems and what can be computed efficiently. Yet, the conjecture remains open and is among the seven famous Millennium Prize Problems.
In 1982, Cook received the prestigious Turing award for his contributions to complexity theory. His citation reads:
In his "Feasibly Constructive Proofs and the Propositional Calculus" paper published in 1975, he introduced the equational theory PV (standing for Polynomial-time Verifiable) to formalize the notion of proofs using only polynomial-time concepts. He made another major contribution to the field in his 1979 paper, joint with his student Robert A. Reckhow, "The Relative Efficiency of Propositional Proof Systems", in which they formalized the notions of p-simulation and efficient propositional proof system, which started an area now called propositional proof complexity. They proved that the existence of a proof system in which every true formula has a short proof is equivalent to NP = coNP. Cook co-authored a book with his student Phuong The Nguyen in this area titled "Logical Foundations of Proof Complexity".
His main research areas are complexity theory and proof complexity, with excursions into programming language semantics, parallel computation, and artificial intelligence. Other areas which he has contributed to include bounded arithmetic, bounded reverse mathematics, complexity of higher type functions, complexity of analysis, and lower bounds in propositional proof systems.
Some other contributions.
He named the complexity class NC after Nick Pippenger. The complexity class SC is named after him. The definition of the complexity class AC0 and its hierarchy AC are also introduced by him.
According to Don Knuth the KMP algorithm was inspired by Cook's automata for recognizing concatenated palindromes in linear time.
Awards and honors.
Cook was awarded a Steacie Fellowship in 1977, a Killam Research Fellowship in 1982, and received the CRM-Fields-PIMS prize in 1999. He has won John L. Synge Award and Bernard Bolzano Medal, and is a fellow of the Royal Society of London and Royal Society of Canada. Cook was elected to membership in the National Academy of Sciences (United States) and the American Academy of Arts and Sciences.
Cook won the ACM Turing Award in 1982. 
Association for Computing Machinery honored him as a Fellow of ACM in 2008 for his
"fundamental contributions to the theory of computational complexity".
The Government of Ontario appointed him to the Order of Ontario in 2013, the highest honor in Ontario. He has won the 2012 Gerhard Herzberg Canada Gold Medal for Science and Engineering, the highest honor for scientist and engineers in Canada. The Herzberg Medal is awarded by NSERC for "both the sustained excellence and overall influence of research work conducted in Canada in the natural sciences or engineering". He was named an Officer of the Order of Canada in 2015.
Also, Stephen Cook has been granted the BBVA Foundation Frontiers of Knowledge Award 2015 in the Information and Communication Technologies category “for his important role in identifying what computers can and cannot solve efficiently,” in the words of the jury’s citation. His work, it continues, “has had a dramatic impact in all fields where complex computations are crucial.”
Cook has supervised numerous MSc students, and 33 PhD students have completed their degrees under his supervision.
Personal life.
Cook currently lives with his wife in Toronto. They have two sons named Gordon and James. He plays the violin and enjoys sailing. He is often called by his short name Steve Cook.

</doc>
<doc id="39434" url="https://en.wikipedia.org/wiki?curid=39434" title="Tony Hoare">
Tony Hoare

Sir Charles Antony Richard Hoare FRS FREng (born 11 January 1934), commonly known as Tony Hoare or C. A. R. Hoare, is a British computer scientist. He developed the sorting algorithm quicksort in 1959/1960. He also developed Hoare logic for verifying program correctness, and the formal language Communicating Sequential Processes (CSP) to specify the interactions of concurrent processes (including the dining philosophers problem) and the inspiration for the occam programming language.
Biography.
Born in Colombo, Ceylon (now Sri Lanka) to British parents, Tony Hoare's father was a colonial civil servant and his mother was the daughter of a tea planter. Hoare was educated in England at the Dragon School in Oxford and the King's School in Canterbury. He then studied Classics and Philosophy ("Greats") at Merton College, Oxford. On graduating in 1956 he did 18 months National Service in the Royal Navy, where he learned Russian. He returned to Oxford University in 1958 to study for a postgraduate certificate in Statistics, and it was here that he began computer programming, having been taught Autocode on the Ferranti Mercury by Leslie Fox. He then went to Moscow State University as a British Council exchange student, where he studied machine translation under Andrey Kolmogorov.
In 1960, he left the Soviet Union and began working at Elliott Brothers, Ltd, a small computer manufacturing firm, where he implemented ALGOL 60 and began developing major algorithms. He became the Professor of Computing Science at the Queen's University of Belfast in 1968, and in 1977 returned to Oxford as the Professor of Computing to lead the Programming Research Group in the Oxford University Computing Laboratory (now Department of Computer Science, University of Oxford), following the death of Christopher Strachey. He is now an Emeritus Professor there, and is also a principal researcher at Microsoft Research in Cambridge, England.
Hoare's most significant work has been in the following areas: his sorting and selection algorithm (Quicksort and Quickselect), Hoare logic, the formal language Communicating Sequential Processes (CSP) used to specify the interactions between concurrent processes, structuring computer operating systems using the monitor concept, and the axiomatic specification of programming languages.
In 1982, he was elected a Fellow of the Royal Society. He was elected in 2005 as a Fellow of the Royal Academy of Engineering.
Apologies and retractions.
Speaking at a conference in 2009, he apologised for inventing the null reference:
For many years under his leadership his Oxford department worked on formal specification languages such as CSP and Z. These did not achieve the expected take-up by industry, and in 1995 Hoare was led to reflect upon the original assumptions:

</doc>
<doc id="39442" url="https://en.wikipedia.org/wiki?curid=39442" title="Anahuac (Aztec)">
Anahuac (Aztec)

Anahuac, 1.5 miles above sea level between 19° and 20° north latitude and 98°45’ to 99°20’ west longitude, is the ancient core of Mexico. Anahuac is a Nahuatl name which means "close to water." It can be broken down like this: A(tl) + nahuac. Atl means 'water' and nahuac, which is a relational word that can be affixed to a noun, means "close to." Anahuac is sometimes used interchangeably with "Valley of Mexico", but Anahuac properly designates the south-central part of the 8,000 km2 (3,000 mi2) Valley, where well-developed prehispanic culture traits had created distinctive landscapes now hidden by the urban sprawl of Mexico City. (""Valley of Mexico"" is misnamed. It is a closed basin of internal drainage, not a valley.) 
Boundaries.
According to the 1911 Encyclopædia Britannica, Anahuac is "limited by the traditional and vaguely defined boundaries of an ancient American empire or confederation of that name previous to the Spanish conquest.

</doc>
<doc id="39443" url="https://en.wikipedia.org/wiki?curid=39443" title="Aragon">
Aragon

Aragon ( or , Spanish and , or ) is an autonomous community in Spain, coextensive with the medieval Kingdom of Aragon. Located in northeastern Spain, the Aragonese autonomous community comprises three provinces (from north to south): Huesca, Zaragoza, and Teruel. Its capital is Zaragoza (also called "Saragossa" in English). The current Statute of Autonomy declares Aragon a "nationality" of Spain.
Aragon's northern province of Huesca borders France and is positioned in the middle of the Pyrenees. Within Spain, the community is flanked by Catalonia to the east, Valencia and Castile–La Mancha to the south, and Castile and León, La Rioja, and Navarre to the west.
Covering an area of , the region's terrain ranges diversely from permanent glaciers to verdant valleys, rich pasture lands and orchards, through to the arid steppe plains of the central lowlands. Aragon is home to many rivers—most notably, the river Ebro, Spain's largest river in volume, which runs west-east across the entire region through the province of Zaragoza. It is also home to the Aneto, the highest mountain in the Pyrenees.
, the population of Aragon was 1,317,847, with slightly more than half of it living in Zaragoza, its capital city. The economy of Aragon generates () a GDP of €33,162 million which represents 3.13% of Spain's national GDP, and is currently 6th in per capita production behind Madrid, Basque Country, Navarre, Catalonia and La Rioja.
In addition to its three provinces, Aragon is subdivided into 33 comarcas or counties; all with a rich geopolitical and cultural history from its pre-Roman, Celtic and Roman days; and from the four centuries of Islamic period as "Marca Superior" of Al-Andalus or kingdom (or taifa) of Saraqustah, and as lands that once belonged to the Frankish Marca Hispanica; and counties that later formed the Kingdom of Aragon and eventually the empire or Crown of Aragon.
Demographics.
Population.
, half of Aragon's population, 50.45%, live in the capital city of Zaragoza. Huesca is the only other city in the region with a population greater than 50,000.
The majority of Aragonese citizens, 71.8%, live in the province of Zaragoza; 17.1% in Huesca and 11.1% in Teruel. The population density of the region is the second lowest in Spain: only 26,8/km2; after Castilla La Mancha. The most densely populated areas are around the valley of the river Ebro, particularly around Zaragoza, and in the Pyrenean foothills, while the areas with the fewest inhabitants tend to be those that are higher up in the Pyrenean mountains, and in most of the southern province of Teruеl.
Only four cities have more than 20,000 inhabitants: Zaragoza 700,000; Huesca 50,000; Teruel 35,000 and Calatayud 20,000.
Language.
Spanish is the native language in most of Aragon, and it is the only official language, understood and spoken by virtually everyone in the region. In addition to it, the Aragonese language continues to be spoken in several local varieties in the mountainous northern counties of the Pyrenees, particularly in western Ribagorza, Sobrarbe, Jacetania and Somontano; it is enjoying a resurgence of popularity as a tool for regional identity. In the easternmost areas of Aragon, along the border with Catalonia, varieties of the Catalan language are spoken, including the comarcas of eastern Ribagorza, La Litera, Bajo Cinca, Bajo Aragón-Caspe, Bajo Aragón and Matarraña. The strip-shaped Catalan-speaking area in Aragon is often called "La Franja".
Geography.
With such a low population density large areas of Aragon remain wild and relatively untouched. It is a land of extreme natural contrasts, both in climate and geologically, from the green valleys and snow-capped peaks of the Pyrenees to the dry plains and lonely hilly areas of the south.
Orography.
Aragon's Pyrenees include splendid and varied mountain landscapes with soaring peaks, deep canyons, dense forests and spectacular waterfalls. Its rugged peaks include the Aneto (3,404 m), the highest in the range, the misty Monte Perdido (3,355 m), Perdiguero (3,221 m), Cotiella (2,912 m) and many others.
Ordesa y Monte Perdido National Park, near the border with France, boasts some of the most spectacular scenery in Europe with its canyons, frozen lake caverns, numerous waterfalls and varied wildlife many species of which are endemic to the Pyrenees. The park is also one of the last sanctuaries of birds of prey in the range. Many beautiful mountain butterflies and flowers can be seen in the summer, while during winter the region is a paradise for skiers.
The principal valleys in the mountains include those of Hecho, Canfranc, Tena, Benasque and others. The green valleys hide pretty villages with nice Romanesque churches and typical Pyrenean houses with flowers on the balconies. The oldest Romanesque cathedral in Spain is located in the medieval town of Jaca in the very northern part of Huesca Province.
In the Pyrenean foothills, or pre-Pyrenees, the Mallos de Riglos are a famous natural rock formation. Ancient castles nestle on lonely hills, the most famous being the magnificent Loarre Castle.
Further south, the Ebro valley, irrigated by the river Ebro, is a rich and fertile agricultural area covered with vast fields of wheat, barley and other fruit and vegetable crops. Many beautiful and little-known settlements, castles and Roman ruins dot the landscape here. Some of the most notable towns here include Calatayud, Daroca, Sos del Rey Catolico, Caspe and others.
South of Zaragoza and the Ebro valley, the elevation rises again into the Sistema Ibérico, a complex system of mountain ranges that separates the Ebro valley from the Meseta Central and plains of Castile–La Mancha. The highest massif in this range is the Moncayo (2,313 m) and, despite getting less snow than in the Pyrenees, it has several ski resorts.
Climate.
Aragon's climate can be defined as continental moderate. Temperatures are determined mainly by altitude, ranging from cold or very cold in winter and cool in summer in the mountains to the north (Pyrenees) and to the south and west (Iberian range), to mild in winter and hot in summer in the central lowlands. Rainfall is also very variable, with very low mean values in the central areas and increasingly higher values in mountain areas, especially in the high Pyrenees.
In the middle of Aragon, which is only above sea level, the annual average temperature is around . To the north and south of the Ebro valley, where the elevation rises to above sea level, the temperature drops by two degrees. In the mountains, between and observed temperatures are between .
The cierzo wind is very common in the central area of Aragon, around the Ebro valley, during the autumn and winter.
Territorial division.
Aragon is divided into three provinces from north to south, named after their capitals: Huesca, Zaragoza and Teruel. The provinces are further divided into 33 comarcas, three of which are in more than one province. There are a total of 732 municipalities in the region.
History.
Aragon is named after the Aragón river, a tributary of the Ebro.
Formation of the kingdom.
Before Aragon came into being as a self-proclaimed kingdom in 1035, the northern counties of Jaca, Sobrarbe and Ribagorza were all counties and appanages suzerain to the Kingdom of Navarre. King Sancho set out on his will the primacy of Pamplona over all appanages (domains for the personal management of his offspring) including Castile, but his younger children set off on separate paths instead, establishing their own kingdoms. Ramiro I was for the first time named king of Aragon in 1035. Later, after his brother Gonzalo's death, he was also named king of Sobrarbe and Ribagorza in 1044. The new kingdom grew quickly, conquering territories from the Moorish kingdoms to the south.
Huesca was taken in 1096 and Zaragoza in 1118. According to Aragonese law, the monarch had to swear allegiance to the Kingdom's laws before being accepted as king. Like other Pyrenean and Basque realms (and unlike Castile), the Aragonese justice and decision making system was based on Pyrenean consuetudinary law, the King was considered "primus inter pares" ('first among equals') within the nobility. A nobleman with the title "Justicia" acted as ombudsman and was responsible for ensuring that the King obeyed the Aragonese laws. An old saying goes, "en Aragón antes de Rey hubo Ley" ("in Aragon Law came before King"), similar to the saying in Navarre, "antes fueron Leyes que Reyes", with much the same meaning.
Union with the County of Barcelona and its dominions in the Langue d'Oc.
The dynastic union in 1137 between Petronila, Queen of Aragon, and Ramon Berenguer IV, Count of Barcelona, produced a son, Alfonso II of Aragon who inherited all their respective territories creating the Crown of Aragon which included all lands and people, titles and states previously outside of the Kingdom of Aragon. The Crown of Aragon was effectively abolished after the dynastic union with Castile (1469, see below) but the title continued to be used until 1714. The dynasty of the Kings of Aragon (called by some present-day historians "Kings of Aragon and Counts of Barcelona") ruled the present administrative region of Aragon, Catalonia, and later the Balearic Islands, Valencia, Sicily, Naples and Sardinia (see Aragonese Empire).
The monarch was known as King of Aragon and also held the titles of King of Valencia, King of Majorca (for a time), Count of Barcelona, Lord of Montpellier, and (temporarily) Duke of Athens and Neopatria. Each of these titles gave him sovereignty over the specific region, and the titles changed as territories were lost and won.
Union with Castile.
Despite the dynastic union with Castile following the marriage of Isabella I of Castile and Ferdinand II of Aragon at the end of the 15th century following which most former kingdoms in Spain were progressively consolidated during the 16th and 17th centuries, Aragon lasted as a separate kingdom with its own laws and institutions until 1707 when Philip V, the first Bourbon king of Spain, invaded Aragon with his army and forced the signature of the Nueva Planta decrees, making Spain into a more centralized state and forcing the use of Castilian language.
Under the Bourbon dynasty.
During the War of the Spanish Succession the advancing army of German, British and Dutch troops defeated the Spanish Army in the battle of Saragossa in 1710. As a result of the battle Philip V was forced to abandon Madrid, retreating to Valladolid.
During the Peninsular War, the Aragonese capital was the site of two fierce sieges. During the siege in 1808, the Spanish under General Palafox defeated a superior French force. In 1809, during a particularly bloody siege, the Spaniards were overwhelmed by superior enemy forces. Almost 30,000 of the garrison and citizens of Zaragoza (from a total of 32,000) perished rather than surrender the city. Two weeks after they breached the walls, the French were still forced to fight for each house, square, church and convent.
Modern history.
During the Spanish Civil War, Aragon saw the establishment of various anarchist communes. The particularly harsh winter of 1937 to 1938 saw the Battle of Teruel, one of the most bloody of the war, which ended in a Nationalist victory.
In 1982 Aragon became an autonomous community within the new Spanish democratic state. In Summer 2008, the international exposition of Expo 2008 was held in Zaragoza.
Symbols.
The current Coat of arms of Aragon was first documented in 1499. Its fourth quarter, the Coat of arms of the Crown of Aragon, features on the Coat of Arms of Spain, as well as the flags and heraldry of several territories in Spain and abroad which were ruled by the Crown of Aragon, such as Catalonia, the Balearic Islands and Languedoc-Roussillon. The flag of modern Aragon, adopted in 1983, has the arms over the Crown arms.
The official Aragonese anthem is the "Himno de Aragón", with music composed by the Aragonese Antón García Abril and lyrics by various poets of the region. It is sung in Spanish with no official translation into Aragonese or Catalan.
Aragon Day (, , ) is celebrated on 23 April, St George's Day, the patron of Aragon since the 15th century. The flag is made in flowers in the Plaza de Aragón in the capital, Zaragoza.
Culture.
Some medieval monuments of Teruel and Zaragoza are protected by UNESCO as part of the World Heritage Sites "Mudéjar Architecture of Aragon".
The traditional dance of Aragon is known as jota and is one of the faster Spanish dances. It is also the most widespread in Aragon and the exact style and music depend on the area.
There are other less popular dances named "paloteaos" similar to the sword/stick dances of other regions.
The music to one local dance, "The Dance of Majordomos" of Benasque, was so enjoyed by Rafael del Riego on a visit to the town that he ordered it to be copied resulting in the "Hymn of Riego" .
Typical Aragonese instruments include the stringed drum or "Chicotén", bagpipes such as the "gaita de boto", oboes such as the "Dulzaina", and small flutes like the "Chiflo". Some instruments have been lost, such as the "trompa de Ribagorza", although there have been efforts to reconstruct them. In contrast to other Pyrenean regions, the "Chicotén" and "Chiflo" never have stopped being played.
The Carnival of Bielsa (Huesca) has ancient origins and includes a group of men carrying long sticks, wearing skirts, cowbells and boucard/goat-like horns and skins with black-painted faces called "Trangas" symbolising "virility" who surround another man wearing skins playing the part of a bear called "l'onso". In Aragonese mythology the bear carried souls between the world of the living and the world of the dead. Trangas dance with young females named "madamas" symbolising "purity" and wearing colourful dresses. Other traditional figures include a horse rider named "Caballé".
Cuisine.
With its lush Pyrenean pastures, lamb, beef, and dairy products are, not surprisingly, predominant in Aragonese cuisine. Also of note is its ham from Teruel; olive oil from Empeltre and Arbequina; longaniza from Graus; rainbow trout and salmon, boar, truffles and wild mushrooms from the upper river valleys of the Jacetania, Gallego, Sobrarbe, and Ribagorza regions; and wines from Cariñena, Somontano, Calatayud, and Campo de Borja; and fruit, especially peaches, from its fertile lower valleys. The region also features a unique local haggis, known as chireta, several interesting seafood dishes, including various crab pastes, which developed from an old superstition that crabs help prevent illness, and sweets such as "Adoquines del Pilar" and "Frutas de Aragón". There are also other sweets like "Tortas de alma" from Teruel and "Trenza de Almudevar" or "Castañas de Huesca" from Huesca.
Economy.
Aragon is among the richest autonomous regions in Spain, with GDP per capita above the nation's average. The traditional agriculture-based economy from the mid-20th century has been greatly transformed in the past several decades and now service and industrial sectors are the backbone of the economy in the region.
The well-developed irrigation system around the Ebro has greatly supported the productive agriculture. The most important crops include wheat, barley, rye, fruit and grapes. Livestock-breeding is essential especially in the northern areas, where the lush meadows provide excellent conditions for sheep and cattle. The main livestock are cattle, 334,600; sheep, 2,862,100; pigs, 3,670,000; goats, 78,000; and poultry, 20,545,000.
The chief industrial centre is the capital Zaragoza, where the largest factories are located. The largest plant is the Opel automotive plant with 8,730 employees and production of 200,000 per year. It supports many related industries in the area. Other large plants in the city include factories for trains and household appliances. Mining of iron ore and coal is developed to the south, near Ojos Negros. Electricity production is concentrated to the north where numerous hydro power plants are located along the Pyrenean rivers and in the 1,150 MW Teruel Power Plant. There is an aluminium refinery in the town of Sabiñánigo. The main centres of electronics industry are Zaragoza, Huesca and Benabarre. Chemical industry is developed in Zaragoza, Sabiñánigo, Monzón, Teruel, Ojos Negros, Fraga, Benabarre and others.
The transport infrastructure has been greatly improved. There are more than of motorways which run from Zaragoza to Madrid, Teruel, Basque country, Huesca and Barcelona. The condition of the other roads is also good. there are 520,000 cars in Aragon. Through the territory of the province runs the new high-speed railway between Madrid and Barcelona with siding from Zaragoza to Huesca, which is going to be continued to the French border. There is an International Airport at Zaragoza, as well as several smaller airports at Huesca, Caudé, Santa Cilia de Jaca and Villanueva de Gállego.
Government and politics.
Current political organization.
As an autonomous community of Spain, Aragon has an elected regional parliament (, , ) with 67 seats. It meets in the Aljafería, a Moorish palace in the capital city, Zaragoza. The Parliament chooses a President for the "Diputación General de Aragón" or Aragon Government, for a four-year term. The current president (since July 2015) is Javier Lambán of the PSOE. Nationally, Aragon elects 13 Deputies and 14 Senators to the Cortes Generales.
In addition to the Spanish-based political parties, there are a number of Aragón-based parties, such as the Chunta Aragonesista, a left-wing Aragonese nationalist party, and the Aragonese Party, more conservative. Chunta Aragonesista had a seat in Spain's national Congress of Deputies from 2000 to 2008, while the centrist Aragonese Party has three national senators, who are in coalition with the ruling People's Party.
In a 2011 regional government survey, 47.6% of the population wanted greater autonomy for Aragon, while 35.2% were satisfied with its current level of autonomy. A total of 6% wanted an end to autonomy and 3.2% wanted full independence.
Historic.
Aragon in the Middle Ages was the hub of the wider Crown of Aragon. The Crown was represented in the region from 1517 by a viceroy.
In 1479, King Ferdinand II of Aragon married Isabella I of Castile, a kingdom covering much of the rest of modern Spain. However, until the Nueva Planta decrees of 1707, Aragon maintained its own separate laws and institutions.
Media.
Aragon has media set-ups in television, radio and numerous newspapers.
Television.
On April 21, 2006, regional television broadcasts in Aragon officially began with the launch of Aragón TV. The law which established the CARTV (Aragon Corporation Radio and Television) dated from 1987, but various political disputes delayed the project for several legislatures.
During the years that Aragon had no public television, several media groups sought to supplement their absence. For one TVE-Aragon, taking the Territorial Centre in Zaragoza, produced several programs and educational activities with the Aragonese town. As for private groups, there were several projects. The most widely accepted for many years had been Antena Aragón, which came to be regarded as regional television. This channel was created in 1998 and disappeared in 2005 shortly after having to leave the Media Production Center (CPA), as this was built by the DGA for future public television host Aragon. With the push for the creation of public television, Antena Aragón merged with RTVA (Radio Television Aragonesa) belonging to the Herald Group. Merging RTVA Antena Aragón and led to channel ZTV (Zaragoza Television). Moreover, Antena 3 Televisión aired for several years, and off to Aragon, a news report fully Aragonese, having a central issue in the Pinares de Venecia in Zaragoza, within the premises of the Theme Park of Zaragoza .
Aragón TV was launched in 2006 after spending a season broadcasting a letter and a loop with images of Aragonese villages and audio of regional radio programs.
Radio.
Aragon Radio, began broadcasting on 18 August 2005 at 5PM with the sound of drums and drums of Calanda and a group song Zaragoza "The Fish". Estimates of its audience range from 20,000 listeners, according to the latest EMG, to 70,000, according to private findings. The channel has regional news bulletins every hour from 7AM to midnight and coverage of sports.
Sport.
Aragon's most successful football (soccer) club is Real Zaragoza. The club was founded in 1932 and has played at its current ground, La Romareda, since 1957. Real Zaragoza have won six Copa del Rey titles from 1964 to 2004, and the 1995 European Cup Winners' Cup. Smaller clubs in the region include CD Teruel and SD Huesca.
Skiing is popular in the Pyrenean north of Aragon, at resorts such as Formigal and Candanchú. The Aragonese city of Jaca in the Pyrennes bid to host the Winter Olympics from 2002 to 2014. Zaragoza was considering a bid for the 2022 Winter Olympics, but dropped it in 2011 to strengthen the chance of Barcelona winning the games.
The Ciudad del Motor de Aragón, also known as Motorland Aragón, is a motorsport race track located near Alcañiz in Aragon. It is home to the Aragon motorcycle Grand Prix.

</doc>
<doc id="39445" url="https://en.wikipedia.org/wiki?curid=39445" title="Anti-psychiatry">
Anti-psychiatry

Anti-psychiatry is the view that psychiatric treatments are often more damaging than helpful to patients, and a movement opposing such treatments for almost two centuries. It considers psychiatry a coercive instrument of oppression due to an unequal power relationship between doctor and patient, and a highly subjective diagnostic process.
Anti-psychiatry originates in an objection to what some view as dangerous treatments. Examples include electroconvulsive therapy, insulin shock therapy, and brain lobotomy. and the over-prescription of potentially dangerous pharmaceutical drugs. An immediate concern is the significant increase in prescribing psychiatric drugs for children. There were also concerns about mental health institutions. Every society, including Western society, permits involuntary treatment or involuntary commitment of mental patients.
In the 1960s, there were many challenges to psychoanalysis and mainstream psychiatry, where the very basis of psychiatric practice was characterized as repressive and controlling. Psychiatrists involved in this challenge included Jacques Lacan, Thomas Szasz, Giorgio Antonucci, R. D. Laing, Franco Basaglia, Theodore Lidz, Silvano Arieti, and David Cooper. Others involved were Michel Foucault and Erving Goffman. Cooper coined the term "anti-psychiatry" in 1967, and wrote the book "Psychiatry and Anti-psychiatry" in 1971. Thomas Szasz introduced the definition of mental illness as a myth in the book "The Myth of Mental Illness" (1961), Giorgio Antonucci introduced the definition of psychiatry as a prejudice in the book "I pregiudizi e la conoscenza critica alla psichiatria" (1986).
Contemporary issues of anti-psychiatry include freedom versus coercion, mind versus brain, nature versus nurture, personal liberty and the right to be different. Some ex-patient groups have become anti-psychiatric, often referring to themselves as "survivors" rather than patients.
History.
Precursors.
The first widespread challenge to the prevailing medical approach in Western countries occurred in the late 18th century. Part of the progressive Age of Enlightenment, a "moral treatment" movement challenged the harsh, pessimistic, somatic (body-based) and restraint-based approaches that prevailed in the system of hospitals and "madhouses" for people considered mentally disturbed, who were generally seen as wild animals without reason. Alternatives were developed, led in different regions by ex-patient staff, physicians themselves in some cases, and religious and lay philanthropists. The moral treatment was seen as pioneering more humane psychological and social approaches, whether or not in medical settings; however, it also involved some use of physical restraints, threats of punishment, and personal and social methods of control. And as it became the establishment approach in the 19th century, opposition to its negative aspects also grew.
According to Michel Foucault, there was a shift in the perception of madness, whereby it came to be seen as less about delusion, i.e. disturbed judgment about the truth, than about a disorder of regular, normal behaviour or will. Foucault argued that, prior to this, doctors could often prescribe travel, rest, walking, retirement and generally engaging with nature, seen as the visible form of truth, as a means to break with artificialities of the world (and therefore delusions). Another form of treatment involved nature's opposite, the theatre, where the patient's madness was acted out for him or her in such a way that the delusion would reveal itself to the patient.
According to Foucault, the most prominent therapeutic technique instead became to confront patients with a healthy sound will and orthodox passions, ideally embodied by the physician. The cure then involved a process of opposition, of struggle and domination, of the patient's troubled will by the healthy will of the physician. It was thought the confrontation would lead not only to bring the illness into broad daylight by its resistance, but also to the victory of the sound will and the renunciation of the disturbed will. "We must apply a perturbing method, to break the spasm by means of the spasm... We must subjugate the whole character of some patients, subdue their transports, break their pride, while we must stimulate and encourage the others" (Esquirol, J.E.D., 1816). Foucault also argued that the increasing internment of the "mentally ill" (the development of more and bigger asylums) had become necessary not just for diagnosis and classification but because an enclosed place became a requirement for a treatment that was now understood as primarily the contest of wills, a question of submission and victory.
The techniques and procedures of the asylums at this time included "isolation, private or public interrogations, punishment techniques such as cold showers, moral talks (encouragements or reprimands), strict discipline, compulsory work, rewards, preferential relations between the physician and his patients, relations of vassalage, of possession, of domesticity, even of servitude between patient and physician at times". Foucault summarised these as "designed to make the medical personage the 'master of madness'" through the power the physician's will exerts on the patient. The effect of this shift then served to inflate the power of the physician relative to the patient, correlated with the rapid rise of internment (asylums and forced detention).
Other analyses suggest that the rise of asylums was primarily driven by industrialization and capitalism, including the breakdown of the traditional family structures. And that by the end of the 19th century, psychiatrists often had little power in the overrun asylum system, acting mainly as administrators who rarely attended to patients, in a system where therapeutic ideals had turned into mindless institutional routines. In general, critics point to negative aspects of the shift toward so-called "moral treatments", and the concurrent widespread expansion of asylums, medical power and involuntary hospitalization laws, in a way that was to play an important conceptual part in the later anti-psychiatry movement.
Various 19th-century critiques of the newly emerging field of psychiatry overlap thematically with 20th-century anti-psychiatry, for example in their questioning of the medicalisation of "madness". Those critiques occurred at a time when physicians had not yet achieved hegemony through psychiatry, however, so there was no single, unified force to oppose. Nevertheless, there was increasing concern at the ease with which people could be confined, with frequent reports of abuse and illegal confinement. For example, Daniel Defoe, the author of "Robinson Crusoe", had previously argued for more government oversight of "madhouses" and for due process prior to involuntary internment. He later argued that husbands used asylum hospitals to incarcerate their disobedient wives, and in a subsequent pamphlet that wives even did the same to their husbands. It was also proposed that the role of asylum keeper be separated from doctor, to discourage exploitation of patients. There was general concern that physicians were undermining personhood by medicalizing problems, by claiming they alone had the expertise to judge it, and by arguing that mental disorder was physical and hereditary. The Alleged Lunatics' Friend Society arose in England in the mid-19th century to challenge the system and campaign for rights and reforms. In the United States, Elizabeth Packard published a series of books and pamphlets describing her experiences in the Illinois insane asylum to which her husband had had her committed.
Throughout, the class nature of mental hospitals, and their role as agencies of control, were well recognized. And the new psychiatry was partially challenged by two powerful social institutions – the church and the legal system. These trends have been thematically linked to the later 20th century anti-psychiatry movement.
As psychiatry became more professionally established during the nineteenth century (the term itself was coined in 1808 in Germany, as "Psychiatriein") and developed allegedly more invasive treatments, opposition increased. In the Southern US, black slaves and abolitionists encountered Drapetomania, a pseudo-scientific diagnosis for why slaves ran away from their masters.
There was some organized challenge to psychiatry in the late 1870s from the new speciality of neurology. Practitioners criticized mental hospitals for failure to conduct scientific research and adopt the modern therapeutic methods such as nonrestraint. Together with lay reformers and social workers, neurologists formed the National Association for the Protection of the Insane and the Prevention of Insanity. However, when the lay members questioned the competence of asylum physicians to even provide proper care at all, the neurologists withdrew their support and the association floundered.
Early 1900s.
It has been noted that "the most persistent critics of psychiatry have always been former mental hospital patients", but that very few were able to tell their stories publicly or to confront the psychiatric establishment openly, and those who did so were commonly considered so extreme in their charges that they could seldom gain credibility. In the early 20th century, ex-patient Clifford W. Beers campaigned to improve the plight of individuals receiving public psychiatric care, particularly those committed to state institutions, publicizing the issues in his book, "A Mind that Found Itself" (1908). While Beers initially condemned psychiatrists for tolerating mistreatment of patients, and envisioned more ex-patient involvement in the movement, he was influenced by Adolf Meyer and the psychiatric establishment, and toned down his hostility since he needed their support for reforms.
His reliance on rich donors and his need for approval from experts led him to hand over to psychiatrists the organization he helped found, the National Committee for Mental Hygiene which eventually became the National Mental Health Association. In the UK, the National Society for Lunacy Law Reform was established in 1920 by angry ex-patients who sought justice for abuses committed in psychiatric custody, and were aggrieved that their complaints were patronisingly discounted by the authorities, who were seen to value the availability of medicalized internment as a 'whitewashed' extrajudicial custodial and punitive process. In 1922, ex-patient Rachel Grant-Smith added to calls for reform of the system of neglect and abuse she had suffered by publishing "The Experiences of an Asylum Patient". In the US, We Are Not Alone (WANA) was founded by a group of patients at Rockland State Hospital in New York, and continued to meet as an ex-patient group.
In the 1920s extreme hostility to psychiatrists and psychiatry was expressed by the French playwright and theater director Antonin Artaud, in particular, in his book on van Gogh. To Artaud, who was himself to spend a fair amount of time in a straitjacket, imagination was reality. Much influenced by the Dada and surrealist enthusiasms of the day, he considered dreams, thoughts and visions no less real than the "outside" world. To Artaud, reality appeared little more than a convenient consensus, the same kind of consensus an audience accepts when they enter a theater and, for a time, are happy to pretend what they're seeing is real.
In this era before Penicillin was discovered, eugenics was popular. People believed diseases of the mind could be passed on so compulsory sterilization of the mentally ill was enacted in many countries.
In the 1930s several controversial medical practices were introduced, including inducing seizures (by electroshock, insulin or other drugs) or cutting parts of the brain apart (lobotomy). In the US, between 1939 and 1951, over 50,000 lobotomy operations were performed in mental hospitals. But lobotomy was ultimately seen as too invasive and brutal.
Holocaust documenters argued that the medicalization of social problems and systematic euthanasia of people in German mental institutions in the 1930s provided the institutional, procedural, and doctrinal origins of the mass murder of the 1940s. The Nazi programs were called Action T4 and Action 14f13. The Nuremberg Trials convicted a number of psychiatrists who held key positions in Nazi regimes. To mention are the ideas of a Swiss psychiatrist: "A not so easy question to be answered is whether it should be allowed to destroy lives objectively 'unworthy of living' without the expressed request of its bearers. (...) Even in incurable mentally ill ones suffering seriously from hallucinations and melancholic depressions and not being able to act, to a medical colleague I would ascript the right and in serious cases the duty to shorten — often for many years — the suffering" (Bleuler, Eugen, 1936: "Die naturwissenschaftliche Grundlage der Ethik". Schweizer Archiv Neurologie und Psychiatrie, Band 38, Nr.2, S. 206).
1940s and 1950s.
The post-World War II decades saw an enormous growth in psychiatry; many Americans were persuaded that psychiatry and psychology, particularly psychoanalysis, were a key to happiness. Meanwhile, most hospitalized mental patients received at best decent custodial care, and at worst, abuse and neglect.
The psychoanalyst Jacques Lacan has been identified as an influence on later anti-psychiatry theory in the UK, and as being the first, in the 1940s and 50s, to professionally challenge psychoanalysis to reexamine its concepts and to appreciate psychosis as understandable. Other influences on Lacan included poetry and the surrealist movement, including the poetic power of patients' experiences. Critics disputed this and questioned how his descriptions linked to his practical work. The names that came to be associated with the anti-psychiatry movement knew of Lacan and acknowledged his contribution even if they did not entirely agree. The psychoanalyst Erich Fromm is also said to have articulated, in the 1950s, the secular humanistic concern of the coming anti-psychiatry movement. In "The Sane Society" (1955), Fromm wrote ""An unhealthy society is one which creates mutual hostility distrust, which transforms man into an instrument of use and exploitation for others, which deprives him of a sense of self, except inasmuch as he submits to others or becomes an automaton"..."Yet many psychiatrists and psychologists refuse to entertain the idea that society as a whole may be lacking in sanity. They hold that the problem of mental health in a society is only that of the number of 'unadjusted' individuals, and not of a possible unadjustment of the culture itself".
In the 1950s new psychiatric drugs, notably the antipsychotic chlorpromazine, slowly came into use. Although often accepted as an advance in some ways, there was opposition, partly due to serious adverse effects such as tardive dyskinesia, and partly due their "chemical straitjacket" effect and their alleged use to control and intimidate patients. Patients often opposed psychiatry and refused or stopped taking the drugs when not subject to psychiatric control. There was also increasing opposition to the large-scale use of psychiatric hospitals and institutions, and attempts were made to develop services in the community.
In the 1950s in the United States, a right-wing anti-mental health movement opposed psychiatry, seeing it as liberal, left-wing, subversive and anti-American or pro-Communist. There were widespread fears that it threatened individual rights and undermined moral responsibility. An early skirmish was over the Alaska Mental Health Bill, where the right wing protestors were joined by the emerging Scientology movement.
The field of psychology sometimes came into opposition with psychiatry. Behaviorists argued that mental disorder was a matter of learning not medicine; for example, Hans Eysenck argued that psychiatry "really has no role to play". The developing field of clinical psychology in particular came into close contact with psychiatry, often in opposition to its methods, theories and territories.
1960s.
Coming to the fore in the 1960s, "anti-psychiatry" (a term first used by David Cooper in 1967) defined a movement that vocally challenged the fundamental claims and practices of mainstream psychiatry. While most of its elements had precedents in earlier decades and centuries, in the 1960s it took on a national and international character, with access to the mass media and incorporating a wide mixture of grassroots activist organizations and prestigious professional bodies.
Cooper was a South African psychiatrist working in Britain. A trained Marxist revolutionary, he argued that the political context of psychiatry and its patients had to be highlighted and radically challenged, and warned that the fog of individualized therapeutic language could take away people's ability to see and challenge the bigger social picture. He spoke of having a goal of "non-psychiatry" as well as anti-psychiatry. It has been suggested that Cooper may have seen psychiatry as analogous to apartheid.
The psychiatrists R D Laing (from Scotland), Theodore Lidz (from America), Silvano Arieti (from Italy) and others, argued that "schizophrenia" and psychosis were understandable, and resulted from injuries to the inner self-inflicted by psychologically invasive "schizophrenogenic" parents or others. It was sometimes seen as a transformative state involving an attempt to cope with a sick society. Laing, however, partially dissociated himself from his colleague Cooper's term "anti-psychiatry". Laing had already become a media icon through bestselling books (such as "The Divided Self" and "The Politics of Experience") discussing mental distress in an interpersonal existential context; Laing was somewhat less focused than his colleague Cooper on wider social structures and radical left wing politics, and went on to develop more romanticized or mystical views (as well as equivocating over the use of diagnosis, drugs and commitment). Although the movement originally described as anti-psychiatry became associated with the general counter-culture movement of the 1960s, Lidz and Arieti never became involved in the latter. Franco Basaglia promoted anti-psychiatry in Italy and secured reforms to mental health law there.
Laing, through the Philadelphia Association founded with Cooper in 1965, set up over 20 therapeutic communities including Kingsley Hall, where staff and residents theoretically assumed equal status and any medication used was voluntary. Non-psychiatric Soteria houses, starting in the United States, were also developed as were various ex-patient-led services.
Psychiatrist Thomas Szasz argued that "mental illness" is an inherently incoherent combination of a medical and a psychological concept. He opposed the use of psychiatry to forcibly detain, treat, or excuse what he saw as mere deviance from societal norms or moral conduct. As a libertarian, Szasz was concerned that such usage undermined personal rights and moral responsibility. Adherents of his views referred to "the myth of mental illness", after Szasz's controversial 1961 book of that name (based on a paper of the same name that Szasz had written in 1957 that, following repeated rejections from psychiatric journals, had been published in the American Psychologist in 1960). Although widely described as part of the main anti-psychiatry movement, Szasz actively rejected the term and its adherents; instead, in 1969, he collaborated with Scientology to form the Citizens Commission on Human Rights. It was later noted that the view that insanity was not in most or even in any instances a "medical" entity, but a moral issue, was also held by Christian Scientists and certain Protestant fundamentalists, as well as Szasz. Szasz was not a Scientologist himself and was non-religious; he commented frequently on the parallels between religion and psychiatry.
Erving Goffman, Deleuze, Guattari and others criticized the power and role of psychiatry in society, including the use of "total institutions" and the use of models and terms that were seen as stigmatizing. The French sociologist and philosopher Foucault, in his 1961 publication "Madness and Civilization: A History of Insanity in the Age of Reason", analyzed how attitudes towards those deemed "insane" had changed as a result of changes in social values. He argued that psychiatry was primarily a tool of social control, based historically on a "great confinement" of the insane and physical punishment and chains, later exchanged in the moral treatment era for psychological oppression and internalized restraint. American sociologist Thomas Scheff applied labeling theory to psychiatry in 1966 in "Being Mentally Ill". Scheff argued that society views certain actions as deviant and, in order to come to terms with and understand these actions, often places the label of mental illness on those who exhibit them. Certain expectations are then placed on these individuals and, over time, they unconsciously change their behavior to fulfill them.
Observation of the abuses of psychiatry in the Soviet Union in the so-called Psikhushka hospitals also led to questioning the validity of the practice of psychiatry in the West. In particular, the diagnosis of many political dissidents with schizophrenia led some to question the general diagnosis and punitive usage of the label schizophrenia. This raised questions as to whether the schizophrenia label and resulting involuntary psychiatric treatment could not have been similarly used in the West to subdue rebellious young people during family conflicts.
Since 1970.
New professional approaches were developed as an alternative or reformist complement to psychiatry. "The Radical Therapist", a journal begun in 1971 in North Dakota by Michael Glenn, David Bryan, Linda Bryan, Michael Galan and Sara Glenn, challenged the psychotherapy establishment in a number of ways, raising the slogan "Therapy means change, not adjustment." It contained articles that challenged the professional mediator approach, advocating instead revolutionary politics and authentic community making. Social work, humanistic or existentialist therapies, family therapy, counseling and self-help and clinical psychology developed and sometimes opposed psychiatry.
Psychoanalysis was increasingly criticized as unscientific or harmful. Contrary to the popular view, critics and biographers of Freud, such as Alice Miller, Jeffrey Masson and Louis Breger, argued that Freud did not grasp the nature of psychological trauma. Non-medical collaborative services were developed, for example therapeutic communities or Soteria houses.
The psychoanalytically trained psychiatrist Szasz, although professing fundamental opposition to what he perceives as medicalization and oppressive or excuse-giving "diagnosis" and forced "treatment", was not opposed to other aspects of psychiatry (for example attempts to "cure-heal souls", although he also characterizes this as non-medical). Although generally considered anti-psychiatry by others, he sought to dissociate himself politically from a movement and term associated with the radical left-wing. In a 1976 publication "Anti-psychiatry: The paradigm of a plundered mind", which has been described as an overtly political condemnation of a wide sweep of people, Szasz claimed Laing, Cooper and all of anti-psychiatry consisted of "self-declared socialists, communists, or at least anti-capitalists and collectivists". While saying he shared some of their critique of the psychiatric system, Szasz compared their views on the social causes of distress/deviance to those of anti-capitalist anti-colonialists who claimed that Chilean poverty was due to plundering by American companies, a comment Szasz made not long after a CIA-backed coup had deposed the democratically elected Chilean president and replaced him with Pinochet. Szasz argued instead that distress/deviance is due to the flaws or failures of individuals in their struggles in life.
The anti-psychiatry movement was also being driven by individuals with adverse experiences of psychiatric services. This included those who felt they had been harmed by psychiatry or who felt that they could have been helped more by other approaches, including those compulsorily (including via physical force) admitted to psychiatric institutions and subjected to compulsory medication or procedures. During the 1970s, the anti-psychiatry movement was involved in promoting restraint from many practices seen as psychiatric abuses.
The gay rights movement continued to challenge the classification of homosexuality as a mental illness and in 1974, in a climate of controversy and activism, the American Psychiatric Association membership (following a unanimous vote by the trustees in 1973) voted by a small majority (58%) to remove it as an illness category from the DSM, replacing it with a category of "sexual orientation disturbance" and then "ego-dystonic homosexuality," which was deleted in 1987, although "gender identity disorder" (a widely used term for gender dysphoria) and a wide variety of "paraphilias" remain. It has been noted that gay activists at the time adopted many of Szasz's arguments against the psychiatric system, but also that Szasz had written in 1965 that: "I believe it is very likely that homosexuality is, indeed, a disease in the second sense of psychosexual immaturity and perhaps sometimes even in the stricter sense condition somewhat similar to ordinary organic maladies perhaps caused by genetic error or endocrine imbalance. Nevertheless, if we believe that by categorising homosexuality as a disease we have succeeded in removing it from the realm of moral judgement, we are in error."
Increased legal and professional protections, and a merging with human rights and disability rights movements, added to anti-psychiatry theory and action.
Anti-psychiatry came to challenge a "biomedical" focus of psychiatry (defined to mean genetics, neurochemicals and pharmaceutic drugs). There was also opposition to the increasing links between psychiatry and pharmaceutical companies, which were becoming more powerful and were increasingly claimed to have excessive, unjustified and underhand influence on psychiatric research and practice. There was also opposition to the codification of, and alleged misuse of, psychiatric diagnoses into manuals, in particular the American Psychiatric Association, which publishes the "Diagnostic and Statistical Manual of Mental Disorders".
Anti-psychiatry increasingly challenged alleged psychiatric pessimism and institutionalized alienation regarding those categorized as mentally ill. An emerging consumer/survivor movement often argues for full recovery, empowerment, self-management and even full liberation. Schemes were developed to challenge stigma and discrimination, often based on a social model of disability; to assist or encourage people with mental health issues to engage more fully in work and society (for example through social firms), and to involve service users in the delivery and evaluation of mental health services. However, those actively and openly challenging the fundamental ethics and efficacy of mainstream psychiatric practice remained marginalized within psychiatry, and to a lesser extent within the wider mental health community.
Three authors came to personify the movement against psychiatry, and two of these were practicising psychiatrists. The initial and most influential of these was Thomas Szasz who rose to fame with his book "The Myth of Mental Illness", although Szasz himself did not identify as an anti-psychiatrist. The well-respected R D Laing wrote a series of best-selling books, including "The Divided Self". Intellectual philosopher Michel Foucault challenged the very basis of psychiatric practice and cast it as repressive and controlling. The term "anti-psychiatry" was coined by David Cooper in 1967. In parallel with the theoretical production of the mentioned authors, the Italian physician Giorgio Antonucci questioned the basis themselves of psychiatry through the dismantling of the psychiatric hospitals" Osservanza" and "Luigi Lolli" and the liberation – and restitution to life – of the people there secluded.
Challenges to psychiatry.
Civilization as a cause of distress.
In recent years, psychotherapists David Smail and Bruce E. Levine, considered part of the anti-psychiatry movement, have written widely on how society, culture, politics and psychology intersect. They have written extensively of the "embodied nature" of the individual in society, and the unwillingness of even therapists to acknowledge the obvious part played by power and financial interest in modern Western society. They argue that feelings and emotions are not, as is commonly supposed, features of the individual, but rather responses of the individual to their situation in society. Even psychotherapy, they suggest, can only change feelings in as much as it helps a person to change the "proximal" and "distal" influences on their life, which range from family and friends, to the workplace, socio-economics, politics and culture.
R. D. Laing emphasized family nexus as a mechanism whereby individuals become victimized by those around them, and spoke about a dysfunctional society.
Evolution research.
One evolutionary argument against psychology and psychiatry is from the study of swarm intelligence. There is evidence that since the same number of individuals with certain characteristics is enough to carry out the same function in the swarm regardless of the size of the swarm, the ideal percentage of "special" individuals decreases with increased group size. Therefore, global stabilizing selection maintaining the same percentage of psychiatric conditions in all human populations is not possible, given the differences in group size that already existed based on food availability across climates in the Paleolithic and became even greater upon the invention of agriculture. If a condition was only present in 1% of humans, which is what psychiatry claims to be a culturally universal figure for multiple diagnoses including schizophrenia and psychopathy, small Stone Age bands would at any given time be at a significant risk of not having a single member with any given 1% condition. If at least one member with each 1% diagnosis was essential for any group's survival, random chance would in few generations have ensured human extinction in the Paleolithic. What behaviors are necessary for a group's survival also varies depending on the group's lifestyle, ensuring a divergence-enhancing weak niche construction as opposed to the divergence-hampering strong niche construction believed in by psychiatry. Advocates of this evolutionary antipsychiatry tend not to sympathize with the Church of Scientology but instead point at similarities between psychiatry and scientology, such as both arbitrarily and often moralizingly deciding what they consider normal or pathological, scientology's belief in retained body thetans after going clear resembling psychiatry's belief in sane people also having human flaws, both claiming to have the only cure, both demanding significant amounts of money for their treatment, both having very accommodative claims that are extremely difficult to impossible to test scientifically, both sometimes resorting to coercive treatment, scientology's use of fists and buckets of cold water doing similar harm as psychiatry's use of drugs and electroconvulsive therapy, and both explaining human behavior today with self-inconsistent and archaeologically invalid stories about human pre-history.
Inadequacy of clinical interviews used to diagnose 'diseases'.
An etiology common to bipolar spectrum disorders has not been identified. Patients cannot be identified just by clinical interviews. A neurobiological basis of bipolar disorder has not been discovered. In making a bipolar spectrum disorder diagnosis based solely on a clinical interview, a false positive cannot be avoided.
Psychiatrists have been trying to differentiate mental disorders based on clinical interviews since the era of Kraepelin, but now realize that their diagnostic criteria are imperfect. Tadafumi Kato writes, "We psychiatrists should be aware that we cannot identify 'diseases' only by interviews. What we are doing now is just like trying to diagnose diabetes mellitus without measuring blood sugar."
Normality and illness judgments.
In 2013, psychiatrist Allen Frances said that "psychiatric diagnosis still relies exclusively on fallible subjective judgments rather than objective biological tests".
Reasons have been put forward to doubt the ontic status of mental disorders. Mental disorders engender ontological skepticism on three levels:
In the scientific and academic literature on the definition or classification of mental disorder, one extreme argues that it is entirely a matter of value judgements (including of what is normal) while another proposes that it is or could be entirely objective and scientific (including by reference to statistical norms). Common hybrid views argue that the concept of mental disorder is objective but a "fuzzy prototype" that can never be precisely defined, or alternatively that it inevitably involves a mix of scientific facts and subjective value judgments.
One remarkable example of psychiatric diagnosis being used to reinforce cultural bias and oppress dissidence is the diagnosis of drapetomania. In the US prior to the American Civil War, physicians such as Samuel A. Cartwright diagnosed some slaves with drapetomania, a mental illness in which the slave possessed an irrational desire for freedom and a tendency to try to escape. By classifying such a dissident mental trait as abnormal and a disease, psychiatry promoted cultural bias about normality, abnormality, health, and unhealth. This example indicates the probability for not only cultural bias but also confirmation bias and bias blind spot in psychiatric diagnosis and psychiatric beliefs.
It has been argued by philosophers like Foucault that characterizations of "mental illness" are indeterminate and reflect the hierarchical structures of the societies from which they emerge rather than any precisely defined qualities that distinguish a "healthy" mind from a "sick" one. Furthermore, if a tendency toward self-harm is taken as an elementary symptom of mental illness, then humans, "as a species", are arguably insane in that they have tended throughout recorded history to destroy their own environments, to make war with one another, etc.
Psychiatric labeling.
Mental disorders were first included in the sixth revision of the International Classification of Diseases (ICD-6) in 1949. Three years later, the American Psychiatric Association created its own classification system, DSM-I. The definitions of most psychiatric diagnoses consist of combinations of phenomenological criteria, such as symptoms and signs and their course over time. Expert committees combined them in variable ways into categories of mental disorders, defined and redefined them again and again over the last half century.
The majority of these diagnostic categories are called "disorders" and are not validated by biological criteria, as most medical diseases are; although they purport to represent medical diseases and take the form of medical diagnoses. These diagnostic categories are actually embedded in top-down classifications, similar to the early botanic classifications of plants in the 17th and 18th centuries, when experts decided a priori about which classification criterion to use, for instance, whether the shape of leaves or fruiting bodies were the main criterion for classifying plants. Since the era of Kraepelin, psychiatrists have been trying to differentiate mental disorders by using clinical interviews.
In 1972, psychologist David Rosenhan published the Rosenhan experiment, a study questioning the validity of psychiatric diagnoses. The study arranged for eight individuals with no history of psychopathology to attempt admission into psychiatric hospitals. The individuals included a graduate student, psychologists, an artist, a housewife, and two physicians, including one psychiatrist. All eight individuals were admitted with a diagnosis of schizophrenia or bipolar disorder. Psychiatrists then attempted to treat the individuals using psychiatric medication. All eight were discharged within 7 to 52 days. In a later part of the study, psychiatric staff were warned that pseudo-patients might be sent to their institutions, but none were actually sent. Nevertheless, a total of 83 patients out of 193 were believed by at least one staff member to be actors. The study concluded that individuals without mental disorders were indistinguishable from those suffering from mental disorders.
Critics such as Robert Spitzer placed doubt on the validity and credibility of the study, but did concede that the consistency of psychiatric diagnoses needed improvement. It is now realized that the psychiatric diagnostic criteria are not perfect. To further refine psychiatric diagnosis, according to Tadafumi Kato, the only way is to create a new classification of diseases based on the neurobiological features of each mental disorder. On the other hand, according to Heinz Katsching, neurologists are advising psychiatrists just to replace the term "mental illness" by "brain illness."
There are recognized problems regarding the diagnostic reliability and validity of mainstream psychiatric diagnoses, both in ideal and controlled circumstances and even more so in routine clinical practice (McGorry "et al.". 1995). Criteria in the principal diagnostic manuals, the DSM and ICD, are inconsistent. Some psychiatrists who criticize their own profession say that comorbidity, when an individual meets criteria for two or more disorders, is the rule rather than the exception. There is much overlap and vaguely defined or changeable boundaries between what psychiatrists claim are distinct illness states.
There are also problems with using standard diagnostic criteria in different countries, cultures, genders or ethnic groups. Critics often allege that Westernized, white, male-dominated psychiatric practices and diagnoses disadvantage and misunderstand those from other groups. For example, several studies have shown that African Americans are more often diagnosed with schizophrenia than Caucasians, and women more than men. Some within the anti-psychiatry movement are critical of the use of diagnosis as it conforms with the biomedical model.
Tool of social control.
According to Franco Basaglia, Giorgio Antonucci, Bruce E. Levine and Edmund Schönenberger whose approach pointed out the role of psychiatric institutions in the control and medicalization of deviant behaviors and social problems, psychiatry is used as the provider of scientific support for social control to the existing establishment, and the ensuing standards of deviance and normality brought about repressive views of discrete social groups. According to Mike Fitzpatrick, resistance to medicalization was a common theme of the gay liberation, anti-psychiatry, and feminist movements of the 1970s, but now there is actually no resistance to the advance of government intrusion in lifestyle if it is thought to be justified in terms of public health.
Moreover, the pressure for medicalization also comes from society itself. Feminists, who once opposed state intervention as oppressive and patriarchal, now demand more coercive and intrusive measures to deal with child abuse and domestic violence. According to Richard Gosden, the use of psychiatry as a tool of social control is becoming obvious in preventive medicine programmes for various mental diseases. These programmes are intended to identify children and young people with divergent behavioral patterns and thinking and send them to treatment before their supposed mental diseases develop. Clinical guidelines for best practice in Australia include the risk factors and signs which can be used to detect young people who are in need of prophylactic drug treatment to prevent the development of schizophrenia and other psychotic conditions.
Psychiatry and the pharmaceutical industry.
Critics of psychiatry commonly express a concern that the path of diagnosis and treatment in contemporary society is primarily or overwhelmingly shaped by profit prerogatives, echoing a common criticism of general medical practice in the United States, where many of the largest psychopharmaceutical producers are based.
Psychiatric research has demonstrated varying degrees of efficacy for improving or managing a number of mental health disorders through either medications, psychotherapy, or a combination of the two. Typical psychiatric medications include stimulants, antidepressants, hypnotic minor tranquilizers and neuroleptics (antipsychotics).
On the other hand, organizations such as MindFreedom International and World Network of Users and Survivors of Psychiatry maintain that psychiatrists exaggerate the evidence of medication and minimize the evidence of adverse drug reaction. They and other activists believe individuals are not given balanced information, and that current psychiatric medications do not appear to be specific to particular disorders in the way mainstream psychiatry asserts; and psychiatric drugs not only fail to correct measurable chemical imbalances in the brain, but rather induce undesirable side effects. For example, though children on Ritalin and other psycho-stimulants become more obedient to parents and teachers, critics have noted that they can also develop abnormal movements such as tics, spasms and other involuntary movements. This has not been shown to be directly related to the therapeutic use of stimulants, but to neuroleptics. The diagnosis of attention deficit hyperactivity disorder on the basis of inattention to compulsory schooling also raises critics' concerns regarding the use of psychoactive drugs as a means of unjust social control of children.
The influence of pharmaceutical companies is another major issue for the anti-psychiatry movement. As many critics from within and outside of psychiatry have argued, there are many financial and professional links between psychiatry, regulators, and pharmaceutical companies. Drug companies routinely fund much of the research conducted by psychiatrists, advertise medication in psychiatric journals and conferences, fund psychiatric and healthcare organizations and health promotion campaigns, and send representatives to lobby general physicians and politicians. Peter Breggin, Sharkey, and other investigators of the psycho-pharmaceutical industry maintain that many psychiatrists are members, shareholders or special advisors to pharmaceutical or associated regulatory organizations.
There is evidence that research findings and the prescribing of drugs are influenced as a result. A United Kingdom cross-party parliamentary inquiry into the influence of the pharmaceutical industry in 2005 concludes: "The influence of the pharmaceutical industry is such that it dominates clinical practice" and that there are serious regulatory failings resulting in "the unsafe use of drugs; and the increasing medicalization of society". The campaign organization "No Free Lunch" details the prevalent acceptance by medical professionals of free gifts from pharmaceutical companies and the effect on psychiatric practice. The ghostwriting of articles by pharmaceutical company officials, which are then presented by esteemed psychiatrists, has also been highlighted. Systematic reviews have found that trials of psychiatric drugs that are conducted with pharmaceutical funding are several times more likely to report positive findings than studies without such funding.
The number of psychiatric drug prescriptions have been increasing at an extremely high rate since the 1950s and show no sign of abating. In the United States antidepressants and tranquilizers are now the top selling class of prescription drugs, and neuroleptics and other psychiatric drugs also rank near the top, all with expanding sales. As a solution to the apparent conflict of interests, critics propose legislation to separate the pharmaceutical industry from the psychiatric profession.
John Read and Bruce E. Levine have advanced the idea of socioeconomic status as a significant factor in the development and prevention of mental disorders such as schizophrenia and have noted the reach of pharmaceutical companies through industry sponsored websites as promoting a more biological approach to mental disorders, rather than a comprehensive biological, psychological and social model.
Electroconvulsive therapy.
Psychiatrists may advocate psychiatric drugs, psychotherapy or more controversial interventions such as electroshock or psychosurgery to treat mental illness. Electroconvulsive therapy (ECT) is administered worldwide typically for severe mental disorders. Across the globe it has been estimated that approximately 1 million patients receive ECT per year. Exact numbers of how many persons per year have ECT in the United States are unknown due to the variability of settings and treatment. Researchers' estimates generally range from 100,000 to 200,000 persons per year.
Some persons receiving ECT die during the procedure (ECT is performed under a general anaesthetic, which always carries a risk). Leonard Roy Frank writes that estimates of ECT-related death rates vary widely. The lower estimates include: • 1 in 10,000 (Boodman’s first entry in 1996) • 1 in 1,000 (Impastato’s first entry in 1957) • 1 in 200, among the elderly, over 60 (Impastato’s in 1957) Higher estimates include: • 1 in 102 (Martin’s entry in 1949) • 1 in 95 (Boodman’s first entry in 1996) • 1 in 92 (Freeman and Kendell’s entry in 1976) • 1 in 89 (Sagebiel’s in 1961) • 1 in 69 (Gralnick’s in 1946) • 1 in 63, among a group undergoing intensive ECT (Perry’s in 1963–1979) • 1 in 38 (Ehrenberg’s in 1955) • 1 in 30 (Kurland’s in 1959) • 1 in 9, among a group undergoing intensive ECT (Weil’s in 1949) • 1 in 4, among the very elderly, over 80 (Kroessler and Fogel’s in 1974–1986).
Political abuse of psychiatry.
Psychiatrists around the world have been involved in the suppression of individual rights by states wherein the definitions of mental disease had been expanded to include political disobedience. Nowadays, in many countries, political prisoners are sometimes confined to mental institutions and abused therein. Psychiatry possesses a built-in capacity for abuse which is greater than in other areas of medicine. The diagnosis of mental disease can serve as proxy for the designation of social dissidents, allowing the state to hold persons against their will and to insist upon therapies that work in favour of ideological conformity and in the broader interests of society. In a monolithic state, psychiatry can be used to bypass standard legal procedures for establishing guilt or innocence and allow political incarceration without the ordinary odium attaching to such political trials.
Under the Nazi regime in the 1940s, the 'duty to care' was violated on an enormous scale. In Germany alone 300,000 individuals that had been deemed mentally ill, work-shy or feeble-minded were sterilized. An additional 200,000 were euthanized. These practices continued in territories occupied by the Nazis further afield (mainly in eastern Europe), affecting thousands more. From the 1960s up to 1986, political abuse of psychiatry was reported to be systematic in the Soviet Union, and to surface on occasion in other Eastern European countries such as Romania, Hungary, Czechoslovakia, and Yugoslavia. A "mental health genocide" reminiscent of the Nazi aberrations has been located in the history of South African oppression during the apartheid era. A continued misappropriation of the discipline was subsequently attributed to the People's Republic of China.
K. Fulford, A. Smirnov, and E. Snow state: "An important vulnerability factor, therefore, for the abuse of psychiatry, is the subjective nature of the observations on which psychiatric diagnosis currently depends." In an article published in 1994 by American psychiatrist Thomas Szasz on the "Journal of Medical Ethics" he stated that "the classification by slave owners and slave traders of certain individuals as Negroes was scientific, in the sense that whites were rarely classified as blacks. But that did not prevent the 'abuse' of such racial classification, because (what we call) its abuse was, in fact, its use." Szasz argued that the spectacle of the Western psychiatrists loudly condemning Soviet colleagues for their abuse of professional standards was largely an exercise in hypocrisy. Szasz states that K. Fulford, A. Smirnov, and E. Snow, who correctly emphasize the value-laden nature of psychiatric diagnoses and the subjective character of psychiatric classifications, fail to accept the role of psychiatric power. He stated that psychiatric abuse, such as people usually associated with practices in the former USSR, was connected not with the misuse of psychiatric diagnoses, but with the political power built into the social role of the psychiatrist in democratic and totalitarian societies alike. Musicologists, drama critics, art historians, and many other scholars also create their own subjective classifications; however, lacking state-legitimated power over persons, their classifications do not lead to anyone’s being deprived of property, liberty, or life. For instance, plastic surgeon’s classification of beauty is subjective, but the plastic surgeon cannot treat his or her patient without the patient’s consent, therefore, there "cannot" be any political abuse of plastic surgery.
The bedrock of political medicine is coercion masquerading as medical treatment. What transforms coercion into therapy are physicians "diagnosing" the person’s condition an "illness," "declaring" the intervention they impose on the victim a "treatment," and legislators and judges "legitimating" these categorizations as "illnesses" and "treatments." In the same way, physician-eugenicists advocated killing certain disabled or ill persons as a form of treatment for both society and patient long before the Nazis came to power.
From the commencement of his political career, Hitler put his struggle against "enemies of the state" in medical rhetoric. In 1934, addressing the Reichstag, Hitler declared, "I gave the order… to burn out down to the raw flesh the ulcers of our internal well-poisoning." The entire German nation and its National Socialist politicians learned to think and speak in such terms. Werner Best, Reinhard Heydrich’s deputy, stated that the task of the police was "to root out all symptoms of disease and germs of destruction that threatened the political health of the nation… addition to Jews, most the germs were weak, unpopular and marginalized groups, such as gypsies, homosexuals, beggars, 'antisocials', 'work-shy', and 'habitual criminals'."
In spite of all the evidence, people underappreciate or, more often, ignore the political implications of the therapeutic character of Nazism and of the use of medical metaphors in modern democracies. Dismissed as an "abuse of psychiatry", this practice is a touchy subject not because the story makes psychiatrists in Nazi Germany look bad, but because it highlights the dramatic similarities between pharmacratic controls in Germany under Nazism and those that have emerged in the US under the free market economy.
The Swiss lawyer Edmund Schönenberger claims that the strongholds of psychiatry have absolutely nothing to do with “care”, the law or justice – instead, they are nothing other than instruments of domination. Fundamental criticism of coercive psychiatry
"Therapeutic State".
The "Therapeutic State" is a phrase coined by Szasz in 1963. The collaboration between psychiatry and government leads to what Szasz calls the "therapeutic state", a system in which disapproved actions, thoughts, and emotions are repressed ("cured") through pseudomedical interventions. Thus suicide, unconventional religious beliefs, racial bigotry, unhappiness, anxiety, shyness, sexual promiscuity, shoplifting, gambling, overeating, smoking, and illegal drug use are all considered symptoms or illnesses that need to be cured. When faced with demands for measures to curtail smoking in public, binge-drinking, gambling or obesity, ministers say that "we must guard against charges of nanny statism." The "nanny state" has turned into the "therapeutic state" where nanny has given way to counselor. Nanny just told people what to do; counselors also tell them what to think and what to feel. The "nanny state" was punitive, austere, and authoritarian, the therapeutic state is touchy-feely, supportive—and even more authoritarian. According to Szasz, "the therapeutic state swallows up everything human on the seemingly rational ground that nothing falls outside the province of health and medicine, just as the theological state had swallowed up everything human on the perfectly rational ground that nothing falls outside the province of God and religion."
Faced with the problem of "madness," Western individualism proved to be ill-prepared to defend the rights of the individual: modern man has no more right to be a madman than medieval man had a right to be a heretic because if once people agree that they have identified the one true God, or Good, it brings about that they have to guard members and nonmembers of the group from the temptation to worship false gods or goods. A secularization of God and the medicalization of good resulted in the post-Enlightenment version of this view: once people agree that they have identified the one true reason, it brings about that they have to guard against the temptation to worship unreason—that is, madness.
Civil libertarians warn that the marriage of the State with psychiatry could have catastrophic consequences for civilization. In the same vein as the separation of church and state, Szasz believes that a solid wall must exist between psychiatry and the State.
"Total Institution".
In his book "Asylums", Erving Goffman coined the term 'Total Institution' for mental hospitals and similar places which took over and confined a person's whole life. Goffman placed psychiatric hospitals in the same category as concentration camps, prisons, military organizations, orphanages, and monasteries. In "Asylums" Goffman describes how the institutionalisation process socialises people into the role of a good patient, someone ‘dull, harmless and inconspicuous’; it in turn reinforces notions of chronicity in severe mental illness.
Law.
While the insanity defense is the subject of controversy as a viable excuse for wrongdoing, Szasz and other critics contend that being committed in a psychiatric hospital can be worse than criminal imprisonment, since it involves the risk of compulsory medication with neuroleptics or the use of electroshock treatment. Moreover, while a criminal imprisonment has a predetermined and known time of duration, patients are typically committed to psychiatric hospitals for indefinite durations, an unjust and arguably outrageous imposition of fundamental uncertainty. It has been argued that such uncertainty risks aggravating mental instability, and that it substantially encourages a lapse into hopelessness and acceptance that precludes recovery.
Involuntary hospitalization.
Critics see the use of legally sanctioned force in involuntary commitment as a violation of the fundamental principles of free or open societies. The political philosopher John Stuart Mill and others have argued that society has no right to use coercion to subdue an individual as long as he or she does not harm others. Mentally ill people are essentially no more prone to violence than sane individuals, despite Hollywood and other media portrayals to the contrary. The growing practice, in the United Kingdom and elsewhere, of Care in the Community was instituted partly in response to such concerns. Alternatives to involuntary hospitalization include the development of non-medical crisis care in the community.
In the case of people suffering from severe psychotic crises, the American Soteria project used to provide what was argued to be a more humane and compassionate alternative to coercive psychiatry. The Soteria houses closed in 1983 in the United States due to lack of financial support. However, similar establishments are presently flourishing in Europe, especially in Sweden and other North European countries.
The physician Giorgio Antonucci, during his activity as a director of the "Ospedale Psichiatrico Osservanza" of Imola, refused any form of coercion and any violation of the fundamental principles of freedom, questioning the basis of psychiatry itself.
Psychiatry as pseudoscience and failed enterprise.
Many of the above issues lead to the claim that psychiatry is a pseudoscience. According to some philosophers of science, for a theory to qualify as science it needs to exhibit the following characteristics:
Psychiatrist Colin A. Ross and Alvin Pam maintain that biopsychiatry does not qualify as a science on many counts.
Stuart A. Kirk has argued that psychiatry is a failed enterprise, as mental illness has grown, not shrunk, with about 20% of American adults diagnosable as mentally ill in 2013.
Diverse paths.
Szasz has since (2008) re-emphasized his disdain for the term anti-psychiatry, arguing that its legacy has simply been a "catchall term used to delegitimize and dismiss critics of psychiatric fraud and force by labeling them 'antipsychiatrists'". He points out that the term originated in a meeting of four psychiatrists (Cooper, Laing, Berke and Redler) who never defined it yet "counter-label their discipline as anti-psychiatry", and that he considers Laing most responsible for popularizing it despite also personally distancing himself. Szasz describes the deceased (1989) Laing in vitriolic terms, accusing him of being irresponsible and equivocal on psychiatric diagnosis and use of force, and detailing his past "public behavior" as "a fit subject for moral judgment" which he gives as "a bad person and a fraud as a professional".
Daniel Burston, however, has argued that overall the published works of Szasz and Laing demonstrate far more points of convergence and intellectual kinship than Szasz admits, despite the divergence on a number of issues related to Szasz being a libertarian and Laing an existentialist; that Szasz employs a good deal of exaggeration and distortion in his criticism of Laing's personal character, and unfairly uses Laing's personal failings and family woes to discredit his work and ideas; and that Szasz's "clear-cut, crystalline ethical principles are designed to spare us the agonizing and often inconclusive reflections that many clinicians face frequently in the course of their work". Szasz has indicated that his own views came from libertarian politics held since his teens, rather than through experience in psychiatry; that in his "rare" contacts with involuntary mental patients in the past he either sought to discharge them (if they were not charged with a crime) or "assisted the prosecution in securing conviction" (if they were charged with a crime and appeared to be prima facie guilty); that he is not opposed to consensual psychiatry and "does not interfere with the practice of the conventional psychiatrist", and that he provided "listening-and-talking ("psychotherapy")" for voluntary fee-paying clients from 1948 until 1996, a practice he characterizes as non-medical and not associated with his being a psychoanalytically trained psychiatrist.
The gay rights or gay liberation movement is often thought to have been part of anti-psychiatry in its efforts to challenge oppression and stigma and, specifically, to get homosexuality removed from the American Psychiatric Association's (APA) Diagnostic and Statistical Manual of Mental Disorders. However, a psychiatric member of APA's Gay, Lesbian, and Bisexual Issues Committee has recently sought to distance the two, arguing that they were separate in the early 70s protests at APA conventions and that APA's decision to remove homosexuality was scientific and happened to coincide with the political pressure. Reviewers have responded, however, that the founders and movements were closely aligned; that they shared core texts, proponents and slogans; and that others have stated that, for example, the gay liberation critique was "made possible by (and indeed often explicitly grounded in) traditions of antipsychiatry".
In the clinical setting, the two strands of anti-psychiatry—criticism of psychiatric knowledge and reform of its practices—were never entirely distinct. In addition, in a sense, anti-psychiatry was not so much a demand for the end of psychiatry, as it was an often self-directed demand for psychiatrists and allied professionals to question their own judgements, assumptions and practices. In some cases, the suspicion of non-psychiatric medical professionals towards the validity of psychiatry was described as anti-psychiatry, as well the criticism of "hard-headed" psychiatrists towards "soft-headed" psychiatrists. Most leading figures of anti-psychiatry were themselves psychiatrists, and equivocated over whether they were really "against psychiatry", or parts thereof. Outside the field of psychiatry, however—e.g. for activists and non-medical mental health professionals such as social workers and psychologists—'anti-psychiatry' tended to mean something more radical. The ambiguous term "anti-psychiatry" came to be associated with these more radical trends, but there was debate over whether it was a new phenomenon, whom it best described, and whether it constituted a genuinely singular movement. In order to avoid any ambiguity intrinsic to the term anti-psychiatry, a current of thought that can be defined as Critique of the basis of psychiatry, radical and unambiguous, aims for the complete elimination of psychiatry. The main representative of the Critique of the basis of psychiatry is an Italian physician, Giorgio Antonucci.
In the 1990s, a tendency was noted among psychiatrists to characterize and to regard the anti-psychiatric movement as part of the past, and to view its ideological history as flirtation with the polemics of radical politics at the expense of scientific thought and enquiry. It was also argued, however, that the movement contributed towards generating demand for grassroots involvement in guidelines and advocacy groups, and to the shift from large mental institutions to community services. Additionally, community centers have tended in practice to distance themselves from the psychiatric/medical model and have continued to see themselves as representing a culture of resistance or opposition to psychiatry's authority. Overall, while antipsychiatry as a movement may have become an anachronism by this period and was no longer led by eminent psychiatrists, it has been argued that it became incorporated into the mainstream practice of mental health disciplines. On the other hand, mainstream psychiatry became more biomedical, increasing the gap between professionals.
Henry Nasrallah claims that while he believes anti-psychiatry consists of many historical exaggerations based on events and primitive conditions from a century ago, "antipsychiatry helps keep us honest and rigorous about what we do, motivating us to relentlessly seek better diagnostic models and treatment paradigms. Psychiatry is far more scientific today than it was a century ago, but misperceptions about psychiatry continue to be driven by abuses of the past. The best antidote for antipsychiatry allegations is a combination of personal integrity, scientific progress, and sound evidence-based clinical care".
A criticism was made in the 1990s that three decades of anti-psychiatry had produced a large literature critical of psychiatry, but little discussion of the deteriorating situation of the mentally troubled in American society. Anti-psychiatry crusades have thus been charged with failing to put suffering individuals first, and therefore being similarly guilty of what they blame psychiatrists for. The rise of anti-psychiatry in Italy was described by one observer as simply "a transfer of psychiatric control from those with medical knowledge to those who possessed socio-political power". 
Critics of this view, however, from an anti-psychiatry perspective, are quick to point to the industrial aspects of psychiatric treatment itself as a primary causal factor in this situation that is described as "deteriorating". The numbers of people labeled "mentally ill", and in treatment, together with the severity of their conditions, have been going up primarily due to the direct efforts of the mental health movement, and mental health professionals, including psychiatrists, and not their detractors. Envisioning "mental health treatment" as violence prevention has been a big part of the problem, especially as you are dealing with a population that is not significantly more violent than any other group and, in fact, are less so than many. 
Some components of antipsychiatric theory have in recent decades been reformulated into a critique of "corporate psychiatry", heavily influenced by the pharmaceutical industry. A recent editorial about this was published in the "British Journal of Psychiatry" by Moncrieff, arguing that modern psychiatry has become a handmaiden to conservative political commitments. David Healy is a psychiatrist and professor in Psychological Medicine at Cardiff University School of Medicine, Wales. He has a special interest in the influence of the pharmaceutical industry on medicine and academia.
In the meantime, members of the psychiatric consumer/survivor movement continued to campaign for reform, empowerment and alternatives, with an increasingly diverse representation of views. Groups often have been opposed and undermined, especially when they proclaim to be, or when they are labelled as being, "anti-psychiatry". However, as of the 1990s, more than 60 percent of ex-patient groups reportedly support anti-psychiatry beliefs and consider themselves to be "psychiatric survivors". Although anti-psychiatry is often attributed to a few famous figures in psychiatry or academia, it has been pointed out that consumer/survivor/ex-patient individuals and groups preceded it, drove it and carried on through it.
A schism exists among those critical of conventional psychiatry between radical abolitionists and more moderate reformists. Laing, Cooper and others associated with the initial anti-psychiatry movement stopped short of actually advocating for the abolition of coercive psychiatry. Thomas Szasz, from near the beginning of his career, crusaded for the abolition of forced psychiatry. Today, realizing that coercive psychiatry marginalizes and oppresses people with its harmful, controlling, and abusive practices, many who identify as anti-psychiatry activists are proponents of the complete abolition of non-consensual and coercive psychiatry. Furthermore, as there is little evidentiary basis to support the field's medical pretensions, many contemporary anti-psychiatry activists envision, and see themselves as working towards, an eventual end to the profession itself.

</doc>
<doc id="39448" url="https://en.wikipedia.org/wiki?curid=39448" title="Magnavox">
Magnavox

Magnavox (Latin for "great voice") is an American electronics company originally founded in the United States. Today it is a subsidiary of electronics corporation Philips. 
Magnavox was founded in 1917 by Edwin Pridham and Peter L. Jensen, inventor of the moving-coil loudspeaker two years earlier at their lab in Napa, California. Magnavox later produced the Odyssey, the world's first home video game console.
Magnavox is currently the brand name worn by a line of products made by Funai under license from trademark owner Philips.
History.
Shortly after its launch, Magnavox became a major consumer electronics and defense company. It manufactured radios, TVs, and record players. In the 1960s Magnavox manufactured the first plasma panels for the military and for computer applications.
In 1972, Magnavox introduced the Odyssey, which was the world's first home video game console. The introduction of it triggered the beginning of the home video game console market. In 1974, the Magnavox Company was acquired by Philips, and all Philips consumer electronics in the US under the Norelco name began rebranding them under the Magnavox name; Philips acquired the similar-sounding company Philco in 1981, and Philips was able to freely use the Philips name, alternating with the Magnavox name for some electronics, with the personal care business continuing to use the Norelco name.
In the late 1970s, Philips developed "Laser Disc" technology, producing an optically read, 12 inch disc that would contain recorded video material. In the early 1980s, Philips worked with Sony to invent a standard for optical audio discs (CDs), using the technology developed for the "Laser Disc".
Teamed with Sony, Philips used the Magnavox brand name to introduce the CD-DA standard and equipment for consumer audio with the Magnavox player sold in department stores while the Sony CDP-101 went to high-end audio stores.
Philips later acquired Magnavox's consumer electronics division in 1974, to ensure nationwide distribution for their VLP (later renamed LaserVision) Videodisc technology.
During the late 1970s the company released the Odyssey², also known as the Philips Videopac.
In the early 1980s, Philips merged Sylvania, Philco and Magnavox into one division headquartered in Knoxville, Tennessee, with a manufacturing plant in Greeneville, Tennessee. The Sylvania plant in Batavia, New York was closed and all operations moved to Greeneville. Philips also abandoned the Sylvania trademark which is owned by Osram.
In the late 1980s, Magnavox sold the Magnavox/Philips VideoWriter with some success. First released in 1985, the VideoWriter was a standalone fixed-application word processing machine (electronic typewriter).
In the late 1990s, some Philips electronics were marketed under the brand name "Philips Magnavox", in an attempt to increase brand awareness of the Philips name in the United States. While it did work to a degree, it also caused confusion to the consumer as to the difference between "Philips Magnavox" products and "Philips" products, resulting in Philips marketing the 2 brands separately again.
The defense group, centered around Fort Wayne, Indiana, remained independent under the Magnavox Electronic Systems name, first under Philips and later in the Carlyle Group, until it was acquired by Hughes Electronics in 1995. The three areas of business of the MESC operation during the late '80s and early '90s were C-Cubed (Command, Control, and Communication), Electronic Warfare, and Sonobuoys. When Hughes Electronics sold its aerospace and defense operations to Raytheon, the former Magnavox defense operations were transferred as well. Shortly thereafter, Raytheon spun off the sonobuoy operation to form Under Sea Systems Inc (USSI), in Columbia City, Indiana. In 1998, Raytheon sold USSI to a British defense consortium named Ultra Electronics The company is currently a wholly owned subsidiary of Ulta manufacturing water and acoustic sensing and communications devices for military and civil defense.
Among the defense products Magnavox manufactured the AN/ARC-164 UHF radio, AN/SSQ-53 series sonobuoys, AN/ALQ-128 EW equipment, AN/SSQ-62 series sonobuoys, and the Advanced Field Artillery Data System (AFATDS).
The brand also has worked with Funai with their televisions after the Philips Magnavox name was popular.
In Australia, the rights to the Magnavox brand are not owned by Philips but by Mistral Ltd, a Hong Kong trading company that uses it to sell audio/video equipment of a different make.
In Europe, the brand Magnavox was briefly used in the 1990s by Philips on budget consumer electronics to replace traditional local brand names (such as Aristona, Erres, Hornyphon, Radiola, Siera). Since no one recognised the brand name, it was soon discontinued.

</doc>
<doc id="39449" url="https://en.wikipedia.org/wiki?curid=39449" title="Mikhail Bulgakov">
Mikhail Bulgakov

Mikhaíl Afanasyevich Bulgakov (; , ; – March 10, 1940) was a Russian writer and playwright active in the first half of the 20th century. He is best known for his novel "The Master and Margarita", which has been called one of the masterpieces of the 20th century.
Life and work.
Early life.
Mikhail Bulgakov was born on May 15, 1891, in Kiev, Russian Empire. He was one of seven children (the oldest of three brothers) of Afanasiy Bulgakov, an assistant professor at the Kiev Theological Academy, and Varvara Mikhailovna, a former teacher. Both of his grandfathers were clergymen in the Russian Orthodox Church. Afanasiy Bulgakov was born in Bryansk Oblast, Russia, where his father was a priest, and he moved to Kiev to study in the academy. Varvara Bulgakova was born in Karachev, Russia. From childhood Bulgakov was drawn to theater. At home, he wrote comedies, which his brothers and sisters acted out.
In 1901 Bulgakov joined the First Kiev Gymnasium, where he developed an interest in Russian and European literature (his favourite authors at the time being Gogol, Pushkin, Dostoyevsky, Saltykov-Shchedrin, and Dickens), theatre and opera. The teachers of the Gymnasium exerted a great influence on the formation of his literary taste. After the death of his father in 1907, Mikhail's mother, a well-educated and extraordinarily diligent person, assumed responsibility for his education. After graduation from the Gymnasium in 1909, Bulgakov entered the Medical Faculty of Kiev University, which he finished with special commendation. He then took a position as a physician at the Kiev Military Hospital.
In 1913, Bulgakov married Tatiana Lappa. At the outbreak of the First World War, he volunteered with the Red Cross as a medical doctor and was sent directly to the front, where he was badly injured at least twice. Bulgakov's suffering from these wounds had deleterious long-term effects. To suppress chronic pain, especially in the abdomen, he injected himself with morphine. Over the next year his addiction grew stronger. In 1918, he abandoned morphine and never used it again. "Morphine," a book released in 1926, is his account of that trying period.
In 1916, Bulgakov graduated from the Medical Department of Kiev University and after serving as a surgeon at Chernovtsy hospital, was appointed provincial physician to Smolensk province. His life in those days is reflected in his "A Country Doctor's Notebook." In September 1917 Bulgakov was moved to the hospital in Vyazma, near Smolensk. In February 1918, he returned to Kiev, where he opened a private practice at his home at Andreyevsky Descent, 13. Here he lived through the Russian Civil War and witnessed ten coups. Successive governments drafted the young doctor into their service while two of his brothers were serving in the White Army against the Bolsheviks.
In February 1919 he was mobilised as an army physician by the Ukrainian People's Army and assigned to the Northern Caucasus. There, he became seriously ill with typhus and barely survived. In the Caucasus he started working as a journalist, but when they were invited to return as doctors by the French and German governments, Bulgakov was refused permission to leave Russia because of the typhus. That was when he last saw his family; after the Civil War and the rise of the Soviets most of his relatives emigrated to Paris.
Career.
After illness Bulgakov abandoned his career as a doctor for that of a writer. In his autobiography, he recalled how he started writing: "Once in 1919 when I was traveling at night by train I wrote a short story. In the town where the train stopped, I took the story to the publisher of the newspaper who published the story". Though his first fiction efforts were made in Kiev, he only decided to leave medicine to pursue his love of literature in 1919. His first book was an almanac of feuilletons called "Future Perspectives", written and published the same year. In December 1919 Bulgakov moved to Vladikavkaz. He wrote and saw his first two plays, "Self Defence" and "The Turbin Brothers", being produced for the city theater stage with great success.
After travelling through the Caucasus, Bulgakov headed for Moscow, intending "to remain here forever". It was difficult to find work in the capital, but he was appointed secretary to the literary section of Glavpolitprosvet (Central Committee of the Republic for Political Education). In September 1921 Bulgakov and his wife settled near Patriarch's Ponds, close to Mayakovskaya metro station on Bolshaya Sadovaya street, 10. To make a living, he started working as a correspondent and feuilletons writer for the newspapers "Gudok", "Krasnaia Panorama" and "Nakanune", based in Berlin. For the almanac "Nedra", he wrote "Diaboliad", "The Fatal Eggs" (1924), and "Heart of a Dog" (1925), works that combined bitter satire and elements of science fiction and were concerned with the fate of a scientist and the misuse of his discovery. The most significant features of Bulgakov's satire, such as a skillful blending of fantastic and realistic elements, grotesque situations, and a concern with important ethical issues, had already taken shape; these features were developed further in his most famous novel.
Between 1922 and 1926 Bulgakov wrote several plays (including "Zoyka's Apartment"), none of which were allowed production at the time. "The Run", treating the horrors of a fratricidal war, was personally banned by Joseph Stalin after the Glavrepertkom (Department of Repertoire) decided that it "glorified emigration and White generals". In 1925 Bulgakov divorced his first wife and married Lyubov Belozerskaya.
When one of Moscow's theatre directors severely criticised Bulgakov, Stalin personally protected him, saying that a writer of Bulgakov's quality was above "party words" like "left" and "right". Stalin found work for the playwright at a small Moscow theatre, and next the Moscow Art Theatre (MAT). On October 5, 1926, "Days of the Turbins", the play which continued the theme of "The White Guard" (the fate of Russian intellectuals and officers of the Tsarist Army caught up in revolution and Civil war) was premièred at the MAT Stalin liked it very much and reportedly saw it at least 15 times.
"Ivan Vasilievich", "Last Days (Pushkin)", and "Don Quixote" were banned. The premier of another, "Moliere (The Cabal of Hypocrites)", in which Bulgakov plunged "into fairy Paris of the XVII century", received bad reviews in "Pravda" and the play was withdrawn from the theater repertoire. In 1928, "Zoyka's Apartment" and "The Purple Island" were staged in Moscow; both comedies were accepted by public with great enthusiasm, but critics again gave them bad reviews. By March 1929 Bulgakov's career was ruined when Government censorship prevented the publication of any of his work and staging of any of his plays.
In despair, Bulgakov first wrote a personal letter to Joseph Stalin (July 1929), then on March 28, 1930, a letter to the Soviet government. He requested permission to emigrate if the Soviet Union could not find use for him as a writer. In his autobiography, Bulgakov claimed to have written to Stalin out of desperation and mental anguish, never intending to post the letter. He received a phone call directly from the Soviet leader, who asked the writer whether he really desired to leave the Soviet Union. Bulgakov replied that a Russian writer cannot live outside of his homeland. Stalin gave him permission to continue working at the Art Theater; on May 10, 1930, he re-joined the theater, as stage director's assistant. Later he adapted Gogol's "Dead Souls" for stage.
In 1932, Bulgakov married for the third time, to Yelena Shilovskaya, who would prove to be inspiration for the character Margarita in his most famous novel, which he started working on in 1928. During the last decade of his life, Bulgakov continued to work on "The Master and Margarita", wrote plays, critical works, stories, and made several translations and dramatisations of novels, librettos. Many of them were not published, other ones were "torn to pieces" by critics. Much of his work (ridiculing the Soviet system) stayed in his desk drawer for several decades. The refusal of the authorities to let him work in the theatre and his desire to see his family who were living abroad, whom he had not seen for many years, led him to seek drastic measures. Despite his new work, the projects he worked on at the theatre were often prohibited, and he was strained and unhappy.
Last years.
In the late 1930s he joined the Bolshoi Theatre as a librettist and consultant. He left after perceiving that none of his works would be produced there. Stalin's favor protected Bulgakov from arrests and execution, but he could not get his writing published. His novels and dramas were subsequently banned and, for the second time, Bulgakov's career as playwright was ruined. When his last play "Batum" (1939), a complimentary portrayal of Stalin's early revolutionary days, was banned before rehearsals, Bulgakov requested permission to leave the country but was refused.
In poor health, Bulgakov devoted his last years to what he called his "sunset" novel. 1937-1939 for Bulgakov were stressful years as he veered from glimpses of optimism, believing the publication of his masterpiece could still be possible, to bouts of depression, when he felt as if there were no hope. On June 15, 1938, when the manuscript was nearly finished, Bulgakov wrote in a letter to his wife:
"In front of me 327 pages of the manuscript (about 22 chapters). The most important remains - editing, and it's going to be hard, I will have to pay close attention to details. Maybe even re-write some things... 'What's its future?' you ask? I don't know. Possibly, you will store the manuscript in one of the drawers, next to my 'killed' plays, and occasionally it will be in your thoughts. Then again, you don't know the future. My own judgement of the book is already made and I think it truly deserves being hidden away in the darkness of some chest..."
In 1939 Mikhail Bulgakov organized a private reading of "The Master and Margarita" to his close circle of friends. Yelena Bulgakova remembered 30 years later, "When he finally finished reading that night, he said: 'Well, tomorrow I am taking the novel to the publisher!' and everyone was silent", "...Everyone sat paralyzed. Everything scared them. P. (P. A. Markov, in charge of the literature division of MAT) later at the door fearfully tried to explain to me that trying to publish the novel would cause terrible things", she wrote in her diary (May 14, 1939).
Mikhail Bulgakov died from nephrosclerosis (an inherited kidney disorder) on March 10, 1940. He was buried in the Novodevichy Cemetery in Moscow. His father had died of the same disease, and from his youth Bulgakov had guessed his future mortal diagnosis.
Early works.
During his life, Bulgakov was best known for the plays he contributed to Konstantin Stanislavsky's and Nemirovich-Danchenko's Moscow Art Theatre. Stalin was known to be fond of the play "Days of the Turbins" (Дни Турбиных) (1926), which was based on Bulgakov's novel "The White Guard". His dramatization of Molière's life in "The Cabal of Hypocrites" (Кабала святош) (1936) is still performed by the Moscow Art Theatre. Even after his plays were banned from the theatres, Bulgakov wrote a comedy about Ivan the Terrible's visit into 1930s Moscow. His play "Batum" (1939) about the early years of Stalin was prohibited by the premier himself.
Bulgakov began writing prose with "The White Guard" (Белая гвардия) (1924, partly published in 1925, first full edition 1927–1929, Paris) – a novel about a life of a White Army officer's family in civil war Kiev. In the mid-1920s, he came to admire the works of H. G. Wells and wrote several stories with elements of science fiction, notably "The Fatal Eggs" (Роковые яйца) (1924) and "Heart of a Dog" (Собачье сердце) (1925). He intended to compile his stories of the mid-twenties (published mostly in medical journals) that were based on his work as a country doctor in 1916–1918 into a collection titled "Notes of a Young Doctor" (Записки юного врача), but he died before he could publish it.
"The Fatal Eggs" tells of the events of a Professor Persikov, who, in experimentation with eggs, discovers a red ray that accelerates growth in living organisms. At the time, an illness passes through the chickens of Moscow, killing most of them, and to remedy the situation, the Soviet government puts the ray into use at a farm. Due to a mix-up in egg shipments, the Professor ends up with chicken eggs, while the government-run farm receives the shipment of ostrich, snake and crocodile eggs ordered by the Professor. The mistake is not discovered until the eggs produce giant monstrosities that wreak havoc in the suburbs of Moscow and kill most of the workers on the farm. The propaganda machine turns on Persikov, distorting his nature in the same way his "innocent" tampering created the monsters. This tale of a bungling government earned Bulgakov his label of counter-revolutionary.
"Heart of a Dog" features a professor who implants human testicles and a pituitary gland into a dog named Sharik (means "Little Balloon" or "Little Ball" - a popular Russian nickname for a male dog). The dog becomes more and more human as time passes, resulting in all manner of chaos. The tale can be read as a critical satire of liberal nihilsm and the communist mentality. It contains a few bold hints to the communist leadership; e.g. the name of the drunkard donor of the human organ implants is Chugunkin ("chugun" is cast iron) which can be seen as a parody on the name of Stalin ("stal'" is steel). It was adapted as a comic opera called "The Murder of Comrade Sharik" by William Bergsma in 1973. In 1988 an award-winning movie version "Sobachye Serdtse" was produced by Lenfilm, starring Yevgeniy Yevstigneyev, Roman Kartsev and Vladimir Tolokonnikov.
"The Master and Margarita".
"The Master and Margarita" (Мастер и Маргарита), which Bulgakov began writing in 1928 and which was finally published by his widow in 1966, twenty-six years after his death, led to an international appreciation of his work. The book contributed a number of sayings to the Russian language, for example, "Manuscripts don't burn" and "second-grade freshness". A destroyed manuscript of the Master is an important element of the plot. Bulgakov had to rewrite the novel from memory after he burned the draft manuscript.
The novel is a critique of Soviet society and its literary establishment. The work is appreciated for its philosophical undertones and for its high artistic level, thanks to its picturesque descriptions (especially of old Jerusalem), lyrical fragments and style. It is a frame narrative involving two characteristically related time periods, or plot lines: a retelling of the gospels and a description of contemporary Moscow .
The novel begins with Satan visiting Moscow in the 1930s, joining a conversation between a critic and a poet debating the existence of Jesus Christ and the Devil. It develops into an all-embracing indictment of the corruption, greed, narrow-mindedness, and widespread paranoia of Soviet Russia. Published more than 25 years after Bulgakov's death, and more than ten years after Stalin's, the novel firmly secured Bulgakov's place among the pantheon of great Russian writers .
A story within the story portrays the interrogation of Jesus Christ by Pontius Pilate and the Crucifixion.
Political views.
Lesley Milne points out that one of "Bulgakov's semi-autobiographical heroes affirms in almost the same breath that he is 'monarchist by conviction' and 'against the death penalty'".
"White Guard" also depicts the Ukrainian nationalistic leaders of Ukraine after the Russian Revolution as cowardly, cruel, anti-Semitic and treacherous.
Legacy.
Exhibitions and museums.
Mikhail Bulgakov Museum, Kiev.
The Mikhail Bulgakov Museum (Bulgakov House) in Kiev has been converted to a literary museum with some rooms devoted to the writer, as well as some to his works. This was his family home, the model for the house of the Turbin family in his play
The Bulgakov Museums in Moscow.
In Moscow, two museums honor the memory of Mikhail Bulgakov and "The Master and Margarita". Both are situated in Bulgakov's old apartment building on Bolshaya Sadovaya street nr. 10, in which parts of "The Master and Margarita" are set. Since the 1980s, the building has become a gathering spot for Bulgakov's fans, as well as Moscow-based Satanist groups, and had various kinds of graffiti scrawled on the walls. The numerous paintings, quips, and drawings were completely whitewashed in 2003. Previously the best drawings were kept as the walls were repainted, so that several layers of different colored paints could be seen around the best drawings.
There is a rivalry between the two museums, mainly maintained by the later established official Museum M.A. Bulgakov, which invariably presents itself as "the first and only Memorial Museum of Mikhail Bulgakov in Moscow".
The Bulgakov House.
The Bulgakov House (Russian: Музей - театр "Булгаковский Дом") is situated at the ground floor. This museum has been established as a private initiative on May 15, 2004.
The "Bulgakov House" contains personal belongings, photos, and several exhibitions related to Bulgakov's life and his different works. Various poetic and literary events are often held, and excursions to "Bulgakov's Moscow" are organised, some of which are animated with living characters of "The Master and Margarita". The "Bulgakov House" also runs the "Theatre M.A. Bulgakov" with 126 seats, and the "Café 302-bis".
The Museum M.A. Bulgakov.
In the same building, in apartment number 50 on the fourth floor, is a second museum that keeps alive the memory of Bulgakov, the Museum M.A. Bulgakov (Russian: Музей М. А. Булгаков). This second museum is a government initiative, and was founded on March 26, 2007.
The Museum M.A. Bulgakov contains personal belongings, photos, and several exhibitions related to Bulgakov's life and his different works. Various poetic and literary events are often held.

</doc>
<doc id="39451" url="https://en.wikipedia.org/wiki?curid=39451" title="Microware">
Microware

Microware was a US (Clive, IA) corporation that produced the OS-9 real-time operating system.
Microware Systems Corporation existed as a separate entity from 1977 until September 2001, when it was bought by RadiSys Corp., and became a division of that company. The rights to Microware OS-9 and related software were purchased by a group of Distributors on March 1, 2013. The new owner is Microware LP. Microware initially produced a version of BASIC and a real-time kernel for the Motorola 6800 processor, and was asked by Motorola to develop what turned into BASIC09 for the then-new Motorola 6809 processor. Having written BASIC09, they decided it needed an operating system underlying it, and created the first version of OS-9.
OS-9 went on to versions for the 68000 family of processors and, rewritten mostly in C, to the Intel 80x86, PowerPC, ARM, MIPS, and some of the Hitachi SuperH (SH) series processors. Initially, in the days of the SS-50 and SS-50C, bus systems such as SWTPC, Gimix, and Smoke Signal Broadcasting, OS-9 was used more as a general purpose microcomputer operating system, and had a large, active hobbyist user population, and industrial and embedded system users. This was especially true when OS-9 was available for popular 6809-based computers such as the FM-7, FM-77, and the Tandy TRS-80 Color Computer and its near-clone, the Dragon. Over time, Microware concentrated on industrial customers and neglected the hobbyist base that was porting a great many Unix packages and utilities to OS-9.

</doc>
<doc id="39464" url="https://en.wikipedia.org/wiki?curid=39464" title="Jefferies tube">
Jefferies tube

Jefferies tubes, in the "Star Trek" fictional universe, are narrow tunnels or corridors inside a starship. They can be vertically or horizontally oriented, and form a network that allows travel throughout large volumes of a starship even when the turbolifts are not functioning. Plumbing, power, and other infrastructure utilities are frequently routed through them.
The term "Jefferies tube" was originally an inside joke among the original "Star Trek" production staff, a reference to art director Matt Jefferies, the man who designed the original starship "Enterprise". The term was used frequently throughout ', '. and "". The term first became officially used in the Star Trek: The Original Series script of "Journey to Babel", but did not become canon until stated in the episode "The Hunted" of Star Trek: The Next Generation season three. Matt Jefferies is quoted as saying, "Somebody hung the name Jefferies Tube on it (the prop). It wasn't me, but the name stuck and I used it in some of my sketches!" 
Another in-joke reportedly appearing in the Jefferies tube sets on the original "Star Trek" series are labels on the pipes marked "G.N.D.N.". This stands for "Goes Nowhere, Does Nothing." The labels are usually written so small as to be invisible to the audience, but can be seen in certain scenes from the "Star Trek" films.
Types of Tubes.
22nd Century.
These tubes were characterized as being circular shaped, small, and poorly lit. Crewmembers traveling along one to repair an engineering or electrical pipe would have to walk bent over in the cramped space. The vertical tubes were lit behind the ladders so the crewmembers could see their path.
23rd Century.
Although still circular shaped, the Jefferies tubes in TOS were better lit and less cramped. In this century, they have the added feature of having diagonal tubes -originally referred to in creator Matt Jefferies sketches as "power shafts." The diagonal tubes had the added function of system controls, conduits, engineering circuits, and could act as passageways through the nacelle pylons to the ship's warp nacelles. The vertical tubes, also known as gangways, were also equipped with three-way ladders, which could allow multiple crewmembers to climb during a time of emergency which can be seen in the episode "Amok Time".
24th Century.
The name of "Jefferies tube" is officially established in episode "Disaster" in Star Trek: The Next Generation. In the previous centuries, they were referred to as "access tunnels", "service chutes", or "access tubes". By the late 23rd century, the tubes had less of a cramped shape, which carried over into the 24th century. The other main features of the tubes were that they became more simplified and had less exposed tubing within. Instead, the vital electrical systems were hidden behind removable panels. Like the 22nd century, the vertical tubes were fitted with dim lighting behind the ladders so the crewmembers could see where to step.
Life on Ship.
The Jefferies tubes have been described as "relatively cramped and provided only enough room for a single technician." Besides their original engineering purpose, the tubes can also be used for recreation, maintenance, training, transportation, and security.
In the episode "Lessons" in , the character Neela Daren uses the fourth intersection of Jefferies tube 25 on the Enterprise-D to have an acoustic "sweet spot" where she could practice her musical instruments. Also in it is shown in episode "Learning Curve" that the Jefferies tubes were used for physical fitness training.
Within the graphic novel Spock and Kirk climb through a Jefferies tube to reach his trapped crewmembers without using the main hallways or turbolifts. This illustrates the concept that the Jefferies tubes can be navigated as passageways to connect to different sections of the ship during Alert status and reduced power scenarios since the turbolifts may not be functional or prohibited. In one panel, Spock turns back to Kirk and makes a reference to how small and cramped the tubes are, saying that, "his (the alien Keenser) small size would be an advantage in the Jefferies tubes." 
In the novel "Star Trek: The Next Generation: Losing the Peace", the character Trys Chen recounts how in her childhood she explored the Jefferies tubes, stating that "even on the smallest vessels, there were literally kilometers of the service tunnels". Later on in the book, when Chen joins Starfleet she displays how some of her duties were to repair the inside of the Jefferies tubes that she used to explore when she was younger. This shows that the Jefferies tubes could be used for educational purposes as well as for their practical purpose of exposing core electrical wiring and tubing for easy access, as well as transportation from one point of the ship to the other.

</doc>
<doc id="39467" url="https://en.wikipedia.org/wiki?curid=39467" title="Adam Oehlenschläger">
Adam Oehlenschläger

Adam Gottlob Oehlenschläger (14 November 1779 – 20 January 1850) was a Danish poet and playwright. He introduced romanticism into Danish literature.
Biography.
He was born in Vesterbro, then a suburb of Copenhagen, on 14 November 1779. His father, a Schleswiger by birth, was at that time organist, and later became keeper, of the royal palace of Frederiksberg; he was a very brisk and cheerful man. The poet's mother, on the other hand, who was partly German by extraction, suffered from depression, which afterwards deepened into melancholy madness.
Oehlenschläger and his sister Sofia were allowed their own way throughout their childhood, and were taught nothing, except to read and write, until their twelfth year. At the age of nine, Oehlenschläger began to make fluent verses. Three years later, while walking in Frederiksberg Gardens, he attracted the notice of the poet Edvard Storm, and the result of the conversation was that he received a nomination to the college called Posterity's High School, an important institution of which Storm was the principal. Storm himself taught the class of Scandinavian mythology, and thus Oehlenschläger received his earliest bias towards the poetical religion of his ancestors.
Oehlenschläger was confirmed in 1795, and was to have been apprenticed to a tradesman in Copenhagen. To his great delight there was a hitch in the preliminaries, and he returned to his father's house. He now, in his eighteenth year, suddenly took up study with great zeal, but soon again abandoned his books for the stage, where he was offered a small position. In 1797 he made his appearance on the boards in several successive parts, but soon discovered that he possessed no real histrionic talent. The brothers Ørsted, with whom he had formed an intimacy that proved quite profitable to him, persuaded him to quit the stage, and in 1800 he entered the University of Copenhagen as a student. He was doomed, however, to disturbance in his studies, first from the death of his mother, next from his inveterate tendency towards poetry, and finally from the First Battle of Copenhagen in April 1801, which, however, inspired a dramatic sketch ("April the Second 1801") which is the first thing of the kind by Oehlenschläger that we possess.
In the summer of 1802, when Oehlenschläger had an old Scandinavian romance, as well as a volume of lyrics, in the press, the young Norse philosopher, Henrik Steffens, came back to Copenhagen after a long visit to Schelling in Germany, full of new romantic ideas. His lectures at the university, in which Goethe and Schiller were revealed to the Danish public for the first time, created a great sensation. Steffens and Oehlenschläger met one day at Dreier's Club, and after a conversation of sixteen hours the latter went home, suppressed his two coming volumes, and wrote at a sitting his splendid poem "Guldhornene", in a manner totally new to Danish literature. The result of his new enthusiasm speedily showed itself in a somewhat hasty volume of poems, published in 1803, now chiefly remembered as containing the lovely piece called "Sanct Hansaften-Spil".
The next two years saw the production of several exquisite works, in particular the epic of "Thors Reise til Jotunheim", the charming poem in hexameters called "Langelandsreisen", and the bewitching piece of fantasy "Aladdin" (1805). At the age of twenty-six, Oehlenschläger was universally recognised, even by the opponents of the romantic revival, as the leading poet of Denmark. He now collected his "Poetical Writings" in two volumes. He found no difficulty in obtaining a grant for foreign travel from the government, and he left his native country for the first time, joining Steffens at Halle in August 1805. Here he wrote the first of his great historical tragedies, "Hakon Jarl", which he sent off to Copenhagen, and then proceeded for the winter months to Berlin, where he associated with Humboldt, Fichte, and the leading men of the day, and met Goethe for the first time.
In the spring of 1806 he went on to Weimar, where he spent several months in daily intercourse with Goethe. The autumn of the same year he spent with Tieck in Dresden, and proceeded in December to Paris. Here he resided eighteen months and wrote his three famous masterpieces, "Baldur hin Gode" (1808), "Palnatoke" (1809), and "Axel og Valborg" (1810). Oehlenschläger had also made his own translation of "Aladdin" into German, adding some extra new material which does not appear in the 1805 edition; this revised version was published in Amsterdam in 1808. Ferruccio Busoni later used the text of this translation for the last (choral) movement of his Piano Concerto Op. 39. Later editions of Oehlenschläger's play do not contain this text.
In July 1808 he left Paris and spent the autumn and winter in Switzerland as the guest of Madame de Staël at Coppet, in the midst of her circle of wits. In the spring of 1809 Oehlenschläger went to Rome to visit Bertel Thorvaldsen, and in his house wrote his tragedy of "Correggio." He hurriedly returned to Denmark in the spring of 1810, partly to take the chair of aesthetics at the University of Copenhagen, partly to marry the sister-in-law of Rahbek, to whom he had been long betrothed. His first course of lectures dealt with his Danish predecessor Johannes Ewald, the second with Schiller. From this time forward his literary activity became very great; in 1811 he published the Oriental tale of "Ali og Gulhyndi", and in 1812 the last of his great tragedies, "Stærkodder".
From 1814 to 1819 he, or rather his admirers, were engaged in a long and angry controversy with Baggesen, who represented the old didactic school. This contest seems to have disturbed the peace of Oehlenschläger's mind and to have undermined his genius. His talent may be said to have culminated in the glorious cycle of verse-romances called "Helge", published in 1814. The tragedy of "Hagbarth og Signe", (1815), showed a distinct falling-off in style. In 1817 he went back to Paris, and published "Hroars Saga" and the tragedy of "Fostbrødrene". In 1818 he was again in Copenhagen, and wrote the idyll of "Den lille Hyrdedreng" and the Eddaic cycle called "Nordens Guder". His next productions were the tragedies of "Erik og Abel" (1820) and "Væringerne i Miklagaard" (1826), and the epic of "Hrolf Krake" (1829). His last volumes were "Tordenskjold" (1833), "Dronning Margrethe" (1833), "Sokrates" (1835), "Olaf den Hellige" (1836), "Knud den Store" (1838), "Dina" (1842), "Erik Glipping" (1843), and "Kiartan og Gudrun" (1847). On his seventieth birthday, 14 November 1849, a public festival was arranged in his honour, and he was decorated by the king of Denmark under circumstances of great pomp. He died on 20 January 1850 and was buried in the cemetery of Frederiksberg. Immediately after his death his "Recollections" were published in two volumes.
Legacy.
With the exception of Ludvig Holberg, no Danish writer before 1870 has exercised so wide an influence as Oehlenschläger. His great work was to awaken in the breasts of his countrymen an enthusiasm for the poetry and religion of their ancestors, and this he performed to so complete an extent that his name remains to this day synonymous with Scandinavian romance. He supplied his countrymen with romantic tragedies at the very moment when all eyes were turned to the stage, and when the old-fashioned pieces were felt to be inadequate. His plays, partly no doubt in consequence of his own early familiarity with acting, fulfilled the stage requirements of the day, and were popular beyond all expectation. The earliest are the best: Oehlenschlager's dramatic masterpiece being, without doubt, his first tragedy, "Hakon Jarl". In his poems and plays alike his style is limpid, elevated, profuse; his flight is sustained at a high pitch without visible excitement. His fluent tenderness and romantic zest have been the secrets of his extreme popularity. Although his inspiration came from Germany, he is not much like a German poet, except when he is consciously following Goethe; his analogy is rather to be found among English poets than his contemporaries. His mission towards antiquity reminds us of Scott; he sometimes has touches of exquisite diction and of overwrought sensibility which recall Coleridge. In his wide ambition and profuseness he possessed some characteristics of Robert Southey, although his style has far more vitality. With all his faults he was a very great writer, and one of the principal pioneers of the romantic movement in Europe.
In 1829 he was publicly crowned with laurel as the "king of Nordic poetry" and the "Scandinavian King of Song" (by Bishop Esaias Tegnér, who would be his Swedish parallel) in the cathedral of Lund, Sweden, based on a vast production of poetry, theatre plays and prose, inspired by Johann Wolfgang von Goethe, Gottlieb Fichte, and Friedrich von Schelling. (See also Jens Immanuel Baggesen)
He wrote the song "Der er et yndigt land", which is now the national anthem of Denmark.
Sources.
Attribution

</doc>
<doc id="39470" url="https://en.wikipedia.org/wiki?curid=39470" title="Nottingham">
Nottingham

Nottingham ( ) is a city in Nottinghamshire, England, south of Sheffield and north of Leicester.
Nottingham has links to the legend of Robin Hood and to the lace-making, bicycle (notably Raleigh bikes) and tobacco industries. It was granted its city charter in 1897 as part of Queen Victoria's Diamond Jubilee celebrations. Nottingham is a tourist destination; in 2011, visitors spent over £1.5 billion - the thirteenth highest amount in England's 111 statistical territories.
In 2013, Nottingham had an estimated population of 310,837 with the wider urban area, which includes many of the city's suburbs, having a population of 729,977. Its urban area is the largest in the East Midlands and the second largest in the Midlands. The population of the Nottingham/Derby metropolitan area is estimated to be 1,543,000. Its metropolitan economy is the seventh largest in the United Kingdom with a GDP of $50.9bn (2014). The city is also ranked as a sufficiency-level world city by the Globalization and World Cities Research Network.
Nottingham has an award-winning public transport system, including the largest publicly owned bus network in England and is also served by Nottingham railway station and the modern Nottingham Express Transit tram system.
It is also a major sporting centre, and in October 2015 was named 'Home of English Sport'. The National Ice Centre, National Watersports Centre, and Trent Bridge international cricket ground are all based in or around the city, which is also the home of professional football, rugby, ice hockey and cricket teams, and the Aegon Nottingham Open, an international tennis tournament on the ATP and WTA tours. This accolade came just over a year after Nottingham was named as the UK's first City of Football.
On 11 December 2015, Nottingham was named a UNESCO City of Literature, joining Norwich, Melbourne, Prague and Barcelona as one of only a handful in the world. The title reflects Nottingham's literary heritage, with Lord Byron, DH Lawrence and Alan Sillitoe having links to the city.
It has two universities, the University of Nottingham and Nottingham Trent University, which are attended by over 60,000 students.
History.
In Anglo-Saxon times the area was part of the Kingdom of Mercia, and was known in the Brythonic language as "Tigguo Cobauc", meaning "Place of Caves" (known also as "City of Caves"). In Welsh it is known poetically as "Y Ty Ogofog" and Irish as " Na Tithe Uaimh " "The Cavey Dwelling". When it fell under the rule of a Saxon chieftain named Snot it became known as "Snotingaham"; the homestead of Snot's people ("Inga" = the people of; "Ham" = homestead). Some authors derive "Nottingham" from "Snottenga", caves, and "ham", but "this has nothing to do with the English form".
Nottingham Castle was constructed in 1068 on a sandstone outcrop by the River Leen. The Anglo-Saxon settlement was originally confined to the area today known as the Lace Market and was surrounded by a substantial defensive ditch and rampart, which fell out of use following the Norman Conquest and was filled by the time of the Domesday Survey (1086). Following the Norman Conquest the Saxon settlement developed into the English Borough of Nottingham and housed a Town Hall and Law Courts. A settlement also developed around the castle on the hill opposite and was the French borough supporting the Normans in the castle. Eventually, the space between was built on as the town grew and the Old Market Square became the focus of Nottingham several centuries later. Defences, consisted initially of a ditch and bank in the early 12th century. The ditch was later widened, in the mid 13th century, and a stone wall built around much of the perimeter of the town. A short length of the wall survives, and is visible at the northern end of Maid Marian Way, and is protected as a Scheduled Monument.
On the return of Richard the Lionheart from the Crusades, the Castle was occupied by supporters of Prince John, including the Sheriff of Nottingham. It was besieged by Richard and, after a sharp conflict, was captured. In the legends of Robin Hood, Nottingham Castle is the scene of the final showdown between the Sheriff and the hero outlaw.
By the 15th century Nottingham had established itself as a centre of a thriving export trade in religious sculpture made from Nottingham Alabaster. The town became a county corporate in 1449 giving it effective self-government, in the words of the charter, "for eternity". The Castle and Shire Hall were expressly excluded and remained as detached Parishes of Nottinghamshire.
One of those highly impressed by Nottingham in the late 18th century was the German traveller C. P. Moritz, who wrote in 1782, "Of all the towns I have seen outside London, Nottingham is the loveliest and neatest. Everything had a modern look, and a large space in the centre was hardly less handsome than a London square. A charming footpath leads over the fields to the highway, where a bridge spans the Trent... Nottingham... with its high houses, red roofs and church steeples, looks excellent from a distance."
During the Industrial Revolution, much of Nottingham's prosperity was founded on the textile industry; in particular, the city became an internationally important centre of lace manufacture. In 1831 citizens rioted in protest against the Duke of Newcastle's opposition to the Reform Act 1832, setting fire to his residence, Nottingham Castle.
In common with the UK textile industry, Nottingham's textile sector fell into decline in the decades following World War II. Little textile manufacture now takes place in Nottingham, however, many of the former industrial buildings in the Lace Market district have been restored and put to new uses.
Nottingham was one of the boroughs reformed by the Municipal Corporations Act 1835, and at that time consisted of the parishes of St Mary, St Nicholas and St Peter. It was expanded in 1877 by adding the parishes of Basford, Brewhouse Yard, Bulwell, Radford, Sneinton, Standard Hill and parts of the parishes of West Bridgford, Carlton, Wilford (North Wilford). In 1889 Nottingham became a county borough under the Local Government Act 1888. City status was awarded as part of the Diamond Jubilee celebrations of Queen Victoria, being signified in a letter from the prime minister, the Marquess of Salisbury to the mayor, dated 18 June 1897. Nottingham was extended in 1933 by adding Bilborough and Wollaton, parts of the parishes of Bestwood Park and Colwick, and a recently developed part of the Beeston Urban District. A further boundary extension was granted in 1951 when Clifton and Wilford (south of the River Trent) were incorporated into the city.
Demographic evolution of Nottingham
Electric trams were introduced to the city in 1901; they served the city for 35 years until the trolleybus network was expanded in 1936. Trams were reintroduced after 68 years when a new network opened in 2004.
In the sporting world, Nottingham is home to the world's oldest professional football club, Notts County, which was formed in 1862. The town's other football club, Nottingham Forest, (under manager Brian Clough) had a period of success between 1977 and 1993; winning the First Division, four League Cups, a UEFA Super Cup and two European Cups. During this time Forest signed Trevor Francis, Britain's first £1million footballer, who joined the club in February 1979 from Birmingham City.
The city was the site of race riots in 1958, centred on the St Ann's neighbourhood.
During the second half of the 20th century Nottingham saw urban growth with the development of new public and private housing estates and new urban centres, which have engulfed former rural villages such as Bilborough, Wollaton, Gedling and Bramcote. South of the river there has also been expansion with new areas such as Edwalton and West Bridgford, adding to Nottingham's urban sprawl. Although this growth slowed towards the end of the century, the modern pressures for more affordable and council housing is back on the political agenda and there is now pressure on the Green Belt which surrounds the city.
Government.
Local government.
Nottingham City Council is a unitary authority based at Nottingham Council House in Old Market Square. It consists of 55 councillors, representing 20 wards, who are elected every four years; the last elections being held on 5 May 2011.
The city also has ceremonial Lord Mayor who is selected by city councillors from among themselves. The position is ceremonial and has no formal power or authority.
The City of Nottingham's boundaries are tightly drawn and exclude several suburbs and satellite towns that are usually considered part of Greater Nottingham. The western suburbs of Beeston, Stapleford and Eastwood are administered by Broxtowe borough council. Further west still, the Nottingham urban district extends into Derbyshire where Ilkeston and Long Eaton are administered by Erewash borough council, and Ripley by Amber Valley. To the north, Hucknall is controlled by Ashfield district council, while in the east Arnold and Carlton form part of the borough of Gedling. South of the river, the suburb of West Bridgford lies in Rushcliffe, as do the outlying villages of Ruddington and Tollerton and the town of Bingham. In December 2011, Rushcliffe, was named one of the 20 most desirable places to live in the UK by the Halifax Building Society. It was one of only four places outside the south of the country to appear in the top 50.
UK Parliament.
Nottingham has three UK parliamentary constituency seats within its boundaries. Nottingham North has been represented since 1987 by Labour MP Graham Allen, Nottingham East since 2010 by Labour MP Chris Leslie and Nottingham South since 2010 by Labour MP Lilian Greenwood.
European Parliament.
Nottingham lies within the East Midlands European parliamentary constituency. In 2014, it elected five MEPs: Margot Parker (UKIP), Roger Helmer (UKIP), Andrew Lewer (Conservative), Emma McClarkin (Conservative) and Glenis Willmott (Labour).
Other.
Emergency services are provided by Nottinghamshire Police, Nottinghamshire Fire and Rescue Service and East Midlands Ambulance Service.
Geography.
Nottingham is situated on an area of low hills along the lower valley of the River Trent, and is surrounded by the Sherwood Forest in the north, the Nottinghamshire, Derbyshire and Yorkshire Coalfield in the west, and the Trent and Belvoir Vales in the east and south.
Climate.
There are weather reporting stations close to Nottingham – the former "Nottingham Weather Centre", at Watnall, about north-west of the city centre; and the University of Nottingham's agricultural campus at Sutton Bonington, about to the south-west of the city centre. The highest temperature recorded in Nottingham (Watnall) stands at , whilst at Sutton Bonington stands at both recorded on 3 August 1990, and the record high minimum temperature is recorded in August 2004. On average, a temperature of 25 °C (77 °F) or above is recorded on 11.0 days per year at Watnall (1981–2010), and the warmest day of the year reaches an average of .
For the period 1981–2010 Nottingham (Watnall) recorded on average 42.9 days of air frost per year, and Sutton Bonington 47.1. The lowest recorded temperature in Nottingham (Watnall) is recorded in January 1963 and January 1987. The record low maximum temperature is recorded in January 1963. For the period of 1981-2010, the coldest temperature of the year reaches an average of 
Architecture.
The geographical centre of Nottingham is usually defined as the Old Market Square, the second largest city square in the UK. The square is dominated by the Council House, which replaced The Nottingham Exchange Building, built in 1726. The Council House was built in the 1920s to display civic pride, ostentatiously using baroque columns and placing stone statues of two lions at the front to stand watch over the square. The Exchange Arcade, on the ground floor, is an upmarket shopping centre containing boutiques.
Tall office buildings line Maid Marian Way. The Georgian area around Oxford and Regent Streets is dominated by small professional firms. The Albert Hall faces the Gothic revival St Barnabas' Roman Catholic Cathedral by Pugin. Nottingham Castle and its grounds are located further south in the western third of the city. The central third descends from the University district in the north, past Nottingham Trent University's Gothic revival Arkwright Building. The University also owns many other buildings in this area. The Theatre Royal on Theatre Square, with its pillared façade, was built in 1865. King and Queen Streets are home to striking Victorian buildings designed by such architects as Alfred Waterhouse and Watson Fothergill.
To the south, is Broadmarsh Shopping Centre. The Canal-side further south of this is adjacent to Nottingham railway station and home to numerous redeveloped 19th-century industrial buildings, reused as bars and restaurants.
The eastern third of the city centre contains the Victoria Shopping Centre, built in the 1970s on the site of the demolished Victoria Railway Station. All that remains of the old station is the clock tower and the station hotel, now the Nottingham Hilton Hotel. The 250 feet-high Victoria Centre flats stand above the shopping centre and are the tallest buildings in the city. The eastern third contains Hockley Village. Hockley is where many of Nottingham's unique, independent shops are to be found. It is also home to two alternative cinemas.
Lace Market.
The Lace Market area just south of Hockley has streets with four to seven-story red brick warehouses, iron railings and red phone boxes.
Buildings have been converted into apartments, bars and restaurants. Adams Building, built by Thomas Chambers Hine for Thomas Adams (1817–1873), is currently used by New College Nottingham. St. Mary's Church, on High Pavement, is the largest medieval building still standing in Nottingham. The Georgian-built Shire Hall is home to the Galleries of Justice and was Nottingham's main court and prison building.
Pubs.
"Ye Olde Trip To Jerusalem" (the "Trip"), partially built into the cave system beneath Nottingham Castle, is a contender for the title of England's Oldest Pub, as it is supposed to have been established in 1189. "The Bell Inn" in the Old Market Square, and "Ye Olde Salutation Inn" (the "Salutation") in Maid Marian Way have both disputed this claim. The "Trip"'s current timber building probably dates back to the 17th or 18th century, but the caves are certainly older and may have been used to store beer and water for the castle during medieval times. There are also caves beneath the "Salutation" that date back to the medieval period, although they are no longer used as beer cellars. The "Bell Inn" is probably the oldest of the three pub buildings still standing, according to dendrochronology, and has medieval cellars that are still used to store beer.
Education.
Over 61,000 students attend the city's two universities, Nottingham Trent University and the University of Nottingham, both of which have several campuses in the city. In 2011/12, Nottingham Trent University had 27,930 students, and the University of Nottingham had 35,630. The University of Nottingham Medical School is part of the Queen's Medical Centre.
Three further education colleges are located in Nottingham. Bilborough College is solely a sixth form college. Central College was formed from the merger of South Nottingham College and Castle College. New College was formed from a merger of four smaller further education colleges.. Nottingham also has dozens of sixth-form colleges and academies that provide education and training for adults aged over 16.
Nottingham also has a number of independent schools, with Nottingham High School – which was founded in 1513 –being the city's oldest educational establishment.
Economy.
In 2010, Nottingham City Council announced that as part of their economic development strategy for the city, their target sectors would include low-carbon technologies, digital media, life sciences, financial and business services and retail and leisure.
Nottingham is home to the headquarters of several companies. One is Boots the Chemists (now Alliance Boots). Other large companies include Chinook Sciences, GM (cricket bats), Pedigree pet food company, American clothing VF Cooperation, Chinese-made automobiles Changan, the credit reference agency Experian, the energy company E.ON UK, the tobacco company Imperial Tobacco, the betting company Gala Group, the amusement and gambling-machine manufacturer Bell-Fruit-Games, the engineering company Siemens, the sportswear manufacturers Speedo, the high-street opticians Vision Express and Specsavers, the games and publishing company Games Workshop, the PC software developer Serif Europe (publisher of PagePlus and other titles), the Web hosting provider Heart Internet, the American credit card company Capital One, and the national law firm Browne Jacobson. Nottingham is also the home of the Nottingham Building Society (set up in 1849), the offices of HM Revenue and Customs, the Driving Standards Agency, BBC East Midlands offices, and formerly, the Government Office for the East Midlands.
Nottingham was made one of the UK's six science cities in 2005 by the then chancellor of the Exchequer (later prime minister), Gordon Brown. Among the science based industries within the city is BioCity. Founded as a joint venture between Nottingham Trent University and the University of Nottingham, it is the UK's biggest bioscience innovation and incubation centre, housing around 80 science-based companies.
Until recently cycle manufacturing was a major industry, the city being the birthplace of Raleigh Cycles in 1886, later joined by Sturmey-Archer, the developer of three-speed hub gears. However, Raleigh's factory on Triumph Road, famous as the location for the filming of "Saturday Night and Sunday Morning", was demolished in Summer 2003 to make way for the University of Nottingham's expansion of its Jubilee Campus. The schools and aerial photographers, H Tempest Ltd were Nottingham-based for many years, until relocating to St. Ives (Cornwall) around 1960.
Nottingham is also host to the UK's first and only local authority-owned and not-for-profit energy company; Robin Hood Energy.
In 2015, Nottingham was also ranked as being in the top 10 UK cities for job growth (2004–13), in the public and private sectors. And in the same year, it was revealed more new companies were started in Nottingham in 2014/15 than any other UK city, with a 68% year-on-year increase.
Shopping.
In 2014, Nottingham came seventh in CACI's Retail Footprint rankings of retail expenditure in the UK, behind the West End of London, Glasgow, Birmingham, Manchester and Liverpool. This is a slip of four places since 2010, primarily due to major developments in other parts of the UK and a relative lack of investment in Nottingham. However, this is likely to change as the owners of the two main shopping centres, Intu, have plans to upgrade and extend them both.
There are two main shopping centres in Nottingham: the Victoria Centre and the Broadmarsh Centre. The Victoria Centre was established on the site of the former Nottingham Victoria railway station, and was the first to be built in the city, with parking for up to 2,400 cars on several levels, and a bus station.
Nottingham City Council, owners of the Broadmarsh Centre, have been attempting to redevelop it for "almost two decades". Work on redeveloping Broadmarsh, at a cost of £400 million (creating 400 stores, 136,000 m2 of shopping space), was due to start in 2008. However, the downturn in the economy meant that redevelopment was delayed throughout from 2008 to 2010. In the light of the Victoria Centre's redevelopment plans, Westfield announced in 2011 that it was once again planning a £500 million development of Broadmarsh, which would start in 2012. This, however, did not take place either. Broadmarsh was finally sold to Capital Shopping Centres, the owners of the Victoria Centre. The purchase prompted an investigation by the Office of Fair Trading and the Competition Commission, who were concerned that the company's monopoly over the city's shopping centres could have a negative impact on competition. CSC subsequently rebranded itself and the centres use the "Intu" name. Although the new owners wished to start the planned development of the Victoria Centre, Nottingham City Council insisted that Broadmarsh must have priority, with the Council offering £50 million towards its redevelopment. The deputy leader of Nottingham City Council said the Council would withhold planning permission for the development of the Victoria Centre until they saw "bulldozers going into the Broadmarsh Centre."
Smaller shopping centres in the city are The Exchange Arcade, the Flying Horse Walk and newer developments in Trinity Square and The Pod. The Bridlesmith Gate area has numerous designer shops, and is the home of the original Paul Smith boutique. There are various side streets and alleys that hide some interesting and often overlooked buildings and shops – such as Poultry Walk, West End Arcade and Hurts Yard. These are home to many specialist shops, as is Derby Road, near the Roman Catholic Cathedral and once the antiques area.
Nottingham has a number of department stores including the House of Fraser, John Lewis, and Debenhams.
Enterprise zone.
In March 2011 the government announced the creation of Nottingham Enterprise Zone, an enterprise zone sited on part of the Boots Estate. In March 2012 Nottingham Science Park, Beeston Business Park and Nottingham Medipark were added to the zone. In December 2014 the government announced that the zone would be expanded again, to include Infinity Park Derby, a planned business park for aerospace, rail and automotive technology adjacent to the Rolls-Royce site in Sinfin, Derby.
Creative Quarter.
The Creative Quarter is a project started by Nottingham City Council as part of the Nottingham City Deal. Centred on the east of the city (including the Lace Market, Hockley, Broadmarsh East, the Island site and BioCity), the project aims at creating growth and jobs. In July 2012, the government contributed £25 million towards a £45 million venture capital fund, mainly targeted at the Creative Quarter.
Culture.
Theatres.
Nottingham has two large-capacity theatres, the Nottingham Playhouse and the Theatre Royal, which together with the neighbouring Royal Concert Hall forms the Royal Centre. The city also contains smaller theatre venues such as the Nottingham Arts Theatre, the Lace Market Theatre and New Theatre.
Galleries and museums.
The city contains several notable museums and art galleries including:
Cinemas.
There is a Cineworld and a Showcase in the city. Independent cinemas include the Broadway Cinema, Savoy Cinema, (a four-screen Art Deco cinema), as well an Arthouse cinema in Hockley.
Music and entertainment.
Nottingham has several large music and entertainment venues including the Royal Concert Hall, Rock City and the Nottingham Arena
The 2,500-capacity Nottingham Royal Concert Hall and 10,000-capacity Nottingham Arena attract major international music acts and comedy artistes. Nottingham also has a selection of smaller venues, including the 800-capacity Albert Hall, Ye Olde Salutation Inn, Seven (formerly Junktion 7), Rescue Rooms, The Bodega and The Old Angel. Nottingham contains the rock music venue Rock City. Nottingham's City Ground played host to rock band R.E.M. in 2005, the first time a concert had been staged at the football stadium.
The city has an active classical music scene, with long-established ensembles such as the city's Symphony Orchestra, Philharmonic Orchestra, Nottingham Harmonic Society, Bach Choir, Early Music Group Musica Donum Dei and the Symphonic Wind Orchestra giving regular performances in the city.
The Sumac Centre is a social centre in Forest Fields. There are a number of live music venues promoting rock and metal music in the city, including The Central, The Old Angel, The Maze, The Chameleon, The Corner and Ye Olde Salutation Inn. Sixties Blues-rock band Ten Years After formed in Nottingham, as did the 70s pop act Paper Lace. Since the beginning of the 2010s, the city has produced a number of artists to gain media attention, including; Jake Bugg, London Grammar, Indiana, Sleaford Mods, Natalie Duncan, Dog Is Dead, Saint Raymond, Childhood, Rue Royale, Spotlight Kid and Amber Run.
Wollaton Park in Nottingham hosts an annual family-friendly music event called Splendour. In 2009 it was headlined by Madness and The Pogues. The following year it was headlined by The Pet Shop Boys and featured, among others, Calvin Harris, Noisettes, Athlete and OK Go. In 2011 it featured headline acts Scissor Sisters, Blondie, Eliza Doolittle and Feeder. In 2012, performers included Dizzee Rascal, Razorlight, Katy B, and Hard-Fi. In 2014, Wollaton Park hosted the first ever No Tomorrow Festival, featuring the likes of Sam Smith, London Grammar and Clean Bandit.
Nottingham is known for hip hop. Rofl Audio Recording Studios opened in 2013.
Arts and crafts.
The Hockley Arts Market runs alongside Sneinton Market.
Food.
There are several hundred restaurants in Nottingham, with there being several AA rosette winning restaurants in 2010 Iberico World Tapas, situation in the city centre, was awarded a Bib Gourmand in the 2013 Michelin Guide.
Sat Bains on the edge of the city near Clifton Bridge is a two star Michelin restaurant.
Tourism.
In 2010, the city was named as one of the "Top 10 Cities to Visit in 2010" by DK Travel. In 2013 it was estimated the city received 247,000 overseas visitors.
There is a Robin Hood Pageant in Nottingham in October. The city is home to the Nottingham Robin Hood Society, founded in 1972 by Jim Lees and Steve and Ewa Theresa West.
In February 2008, a Ferris wheel was put up in the Old Market Square and was an attraction of Nottingham City Council's "Light Night" on 8 February. The wheel returned to Nottingham in February 2009 to mark another night of lights, activities, illuminations and entertainment. Initially marketed as the Nottingham Eye, it was later redubbed as the Nottingham Wheel, to avoid any association with the London Eye. It was seen again in 2010 and 2015.
People.
Many local businesses and organisations use the worldwide fame of Robin Hood to represent or promote their brands. Many residents converse in the East Midlands dialect. The friendly term of greeting "Ay-up midduk" is a humorous example of the local dialect. but with an unclear origin.
Miscellaneous.
Nottingham is home to the GameCity annual videogame festival, which attracts leading industry speakers from around the world. In addition, in 2015 the National Videogame Arcade was opened in the Hockley area of the city; being "the UK's first cultural centre for videogames".
In 2013, Nottingham was named the most haunted city in England, reflecting its historical past.
Nottingham has hosted an annual Asian Mela in every summer since about 1989. Nottingham also hosts a parade on St Patrick's Day, Fireworks at the Chinese New Year, Holi in the Park celebrating Hinduism, a West Indian-style Carnival, and several Sikh events.
Nottingham has featured in a number of fictional works.
Sport.
Nottingham is home to two professional football clubs: Notts County and Nottingham Forest. Their two football grounds, on opposite sides of the River Trent, are noted for geographically being the closest in English league football. Notts County, formed in 1862, is the oldest professional football club in the world. They were also among the Football League's founder members in 1888. For most of their history they have played their home games at Meadow Lane, which currently holds some 20,000 spectators, all seated. They currently play in Football League Two – the Fourth tier of English league football – and most recently played top division football in May 1992. Nottingham Forest, who currently play in the Football League Championship, were English league champions in 1978 and won the European Cup twice over the next two seasons under the management of Brian Clough, who was the club's manager from January 1975 to May 1993, leading them to four Football League Cup triumphs in that time. They have played at the City Ground, on the south bank of the River Trent, since 1898. Nottingham Forest joined the Football League in 1892, four years after its inception when it merged with the rival Football Alliance, and 100 years later, they were among the FA Premier League's founder members in 1992 – though they have not played top division football since May 1999. The City Ground played host to group stage games in the 1996 European Football Championships.
Nottingham won the title of 2015 City of Football after five months of campaigning, which resulted in £1.6m in funding for local football ventures and to encourage more people to play the sport. Nottingham was selected to be a host city for the England 2018 FIFA World Cup bid. It was proposed that if the bid were successful, the city would have received a new Nottingham Forest Stadium.
Nottinghamshire County Cricket Club play at Trent Bridge – an international cricket venue. The club were 2010 Cricket County Champions. Trent Bridge cricket ground is a host of Test Cricket, and was one of the venues for the 2009 ICC World Twenty20.
The Rugby team, Nottingham R.F.C., have played their home games at League One, Notts County's Meadow Lane stadium since 2006. In January 2015 they will play home matches at their training base, Lady Bay Sports Ground. Currently in the RFU Championship, if Nottingham are promoted to the Rugby Premiership they will return to Meadow Lane for home matches. Nottingham Outlaws are an amateur Rugby League club who play in the Rugby League Conference National Division.
The city was the birthplace and training location for ice dancers Torvill and Dean, who won Gold at the 1984 Sarajevo Olympics. The National Ice Centre, opened by Jane Torvill, is a national centre for ice sports. The square in-front of the centre is named "Bolero Square" after Torvill and Dean's perfect 6.0 performance. Nottingham is home to the Nottingham Panthers ice hockey team.
Other sporting events in the city include the annual tennis Aegon Trophy (which is staged at the City of Nottingham Tennis Centre), the Robin Hood Marathon, Milk Race, the Great Nottinghamshire Bike Ride and the Outlaw Triathlon. Nottingham also has three Roller derby teams: Nottingham Roller Girls, the Hellfire Harlots (women's teams)
Transport.
Nottingham is served by East Midlands Airport (formerly known as Nottingham East Midlands Airport until it reverted to its original name), near Castle Donington in North West Leicestershire, just under south-west of the city centre.
Nottingham is also well connected by road and rail. The M1 motorway passes to the west, and the city has railservices run from Nottingham railway station run by CrossCountry, East Midlands Trains and Northern Rail.
The reintroduction of trams in 2004 made Nottingham one of only six English cities to have a light rail system. The trams run from the city centre to Hucknall in the north, with a spur to the Phoenix Park Park and Ride close to Junction 26 of the M1. Two new lines opened in 2015 extending the network to the southern suburbs of Wilford and Clifton and the western suburbs of Beeston and Chilwell.
The city has the largest public bus network in the UK, In September 2010, Nottingham was named "England's least car-dependent city" by the Campaign for Better Transport with London and Manchester in second and fourth place respectively. In November 2010, Nottingham City Council won Transport Authority of the Year by the UK Bus Awards, for services for providing safer and sustainable public transport.
Nottingham's waterways, now primarily used for leisure, have been extensively used for transport in the past.
Crime.
Nottingham is served by Nottinghamshire Police and has a Crown Court and Magistrates' Court.
Laurie Macdonald of "Inside One" magazine observes that the city's former high crime rate earned it the nickname "Shottingham", but that by 2013 this image was outdated. The article was written in response to a uSwitch survey that had found south Nottinghamshire to be the fourth best place to live in the UK in terms of living standards. Crime in Nottingham had also fallen by three-quarters since 2007.
Religion.
The traditional requirement of city status is a (Church of England) cathedral. Nottingham, however, does not have one, having only been designated a city in 1897, in celebration of Queen Victoria's Diamond Jubilee. From around AD 1100 Nottingham was part of the Diocese of Lichfield, controlled as an archdeaconry from Lichfield Cathedral in Staffordshire. However, in 1837 the archdeaconry was placed under the control of the Diocese of Lincoln. In 1884 it became part of the newly created Diocese of Southwell, which it, and the city, are still part of today. The bishop is based at Southwell Minster, north-east of the city.
Despite not having a cathedral, Nottingham has three notable historic Anglican parish churches, all of which date back to the Middle Ages. St. Mary the Virgin, in the Lace Market, is the oldest and largest. The church dates from the eighth or ninth centuries, but the present building is at least the third on the site, dating primarily from 1377 to 1485. St. Mary's is considered the mother church of the city and civic services are held here, including the welcome to the new Lord Mayor of Nottingham each year. It is a member of the Greater Churches Group. St. Peter's in the heart of the city is the oldest building in continuous use in Nottingham, with traces of building starting in 1180. St. Nicholas' is the third.
A variety of chapels and meeting rooms are in the town. Many of these grand buildings have been demolished, including Halifax Place Wesleyan Chapel, but some have been re-used, notably High Pavement Chapel which is now a public house. The national headquarters of the Congregational Federation is in Nottingham.
Nottingham is one of 18 British cities that do not have an Anglican cathedral. It is, however, home to the Roman Catholic Cathedral of St. Barnabas, which was designed by Augustus Pugin and consecrated in 1844. It is the cathedral church for the Roman Catholic Diocese of Nottingham.
Today there are places of worship for all major religions, including Christianity and Islam with 32 Mosques in Nottingham. The Nottingham Inter-faith Council works to make connections between faith groups and show the wider public the importance of spiritual aspects of life and the contribution faith groups make to the community.
Nottingham has 30,000 Muslims, 15,000 Sikhs, 8,000 Hindus and 2,000 Jews.
Demography.
The city of Nottingham has a population at 312,900 with the Greater Nottingham population at 729,977 and the Metro population at 1,543,000. The city of Nottingham has a density of 4,073/km2.
65.4% are White British, 6.1% are European/North American, 13.1% Asian, 4.3% African, 1.6% Middle Eastern, 1.1% South/Central American and 8.2% of West Indian origins. Nottingham is a very multi-cultural city with people from 93 different countries and 101 spoken languages with cuisines, religious institutions/places of worship, businesses and supermarkets all over Nottingham especially situated in Hyson Green, Forest Fields, Carrington, Radford, Lenton, Meadows, Dunkirk, Rylands, St Ann's, Sneinton, Aspley, Broxtowe, City, Basford, Bakersfield, Carlton and Arnold.
Media.
Television.
The BBC has its East Midlands headquarters in Nottingham on London Road. BBC East Midlands Today is broadcast from the city every weeknight at 18:30.
From 1983-2005 Central Television (the ITV region for the East Midlands) had a studio complex on Lenton Lane, producing programmes for various networks and broadcasting regional news.
The city was recently granted permission by OFCOM to set up its own local television station. After a tender process, Confetti College was awarded the licence. The station was declared open by Prince Harry in April 2013 and "Notts TV" began broadcast in spring 2014.
Radio.
In addition to the national commercial and BBC radio stations, the Nottingham area is served by licensed commercial radio stations (though all broadcast to a wider area than the city).
Radio stations include:
Student Radio.
The city's two universities both broadcast their own student radio stations. Nottingham Trent University's FlyFM is based at the university's city campus and is broadcast online. Nottingham University's University Radio Nottingham is broadcast around the main and Sutton Bonnington campuses on medium wave (AM), as well as over the internet.
Newspapers and magazines.
Nottingham's main local newspaper, the Nottingham Post, is owned by Northcliffe Media and is published daily from Monday to Saturday each week.
A local culture and listings magazine called "LeftLion" is available free from many sites around the city, whilst a complimentary, bi-monthly glossy magazine is also available from a number of outlets across the city called "Life&Style Magazine". This consists of features typically focused on the area's interest in fashion, entertainment and politics.
Student tabloid, The Tab also publishes online content and has teams at both universities.
Film.
Nottingham has been used as a location in many locally, nationally, and internationally produced films. Movies that have been filmed (partly or entirely) in Nottingham include:
Twin cities.
Nottingham is twinned with the following cities:

</doc>
<doc id="39473" url="https://en.wikipedia.org/wiki?curid=39473" title="History of Alabama">
History of Alabama

Alabama became a state of the United States of America on December 14, 1819. After, the Indian wars and removals of the early 19th century forced most Native Americans out of the state, white settlers arrived in large numbers, bringing or importing African-American slaves in the domestic trade.
In antebellum Alabama, wealthy planters created large cotton plantations based in the fertile central Black Belt of the upland region, which depended on the labor of enslaved African Americans. Tens of thousands of slaves were transported to and sold in the state by slave traders who purchased them in the Upper South. Elsewhere in Alabama, poorer whites practiced subsistence farming. By 1860 blacks (nearly all slaves) comprised 45 percent of the state's 964,201 people.
The state's wealthy planters considered slavery essential to their economy. As one of the largest slaveholding states, Alabama was among the first six states to secede. It declared its secession in January 1861 and joined the Confederate States of America in February. During the ensuing American Civil War Alabama had moderate levels of warfare. The population suffered economic losses and hardships as a result of the war. Lincoln's Emancipation Proclamation freed all enslaved people in Confederate states. The Southern capitulation in 1865 ended the Confederate state government. A decade of Reconstruction began, a controversial time that has a range of interpretation. Its biracial government established the first public schools and welfare institutions in the state.
After the war, planters worked to get their vast cotton plantations back into production. African Americans chose to exert some independence as free tenant farmers and sharecroppers, rather than working in labor gangs. Wherever possible, African-American women left the fields. Small farms, which produced general crops before the war, turned to cotton as a cash crop. The market for cotton was overloaded, and prices dropped 50%.
For 35 years after the Civil War, Alabama was a rich, heavily rural state, with an economy based on cotton and sharecropping. Its legislature failed to invest in infrastructure, so many of its farmers were isolated from more lucrative markets. At Reconstruction's end, whites known as "Redeemer" Democrats regained control of the state legislature by both legal and extralegal means (including violence and harassment) to re-establish political and social dominance over African Americans. In 1901, Democrats passed a state Constitution that effectively disfranchised most African Americans (who in 1900 comprised more than 45 percent of the state's population), as well as tens of thousands of poor whites. By 1941, a total 600,000 poor whites and 520,000 African Americans had been disfranchised. In addition, despite massive population changes in the state that accompanied urbanization and industrialization, the rural-dominated legislature refused to redistrict from 1901 to the 1960s, leading to massive malapportionment in Congressional and state representation. For decades, a rural minority dominated the state, and the needs of urban, middle class and industrial interests were not addressed.
African Americans living in Alabama experienced the inequities of disfranchisement, segregation, violence, and underfunded schools. Tens of thousands of African Americans from Alabama joined the Great Migration out of the South from 1915 to 1930 and moved to better opportunities in industrial cities, mostly in the North, especially the Midwest. The black exodus escalated steadily in the first three decades of the 20th century; 22,100 emigrated from 1900 to 1910; 70,800 between 1910 and 1920; and 80,700 between 1920 and 1930.
As a result of African-American disenfranchisement and rural control, state politics were dominated by Democrats into the 1980s as part of the "Solid South." Alabama produced a number of national leaders.
The New Deal farm programs increased the price of cotton, and World War II finally brought prosperity, as the state developed a manufacturing and service base. Cotton faded in importance and mechanization beginning in the 1930s reduced the need for farm labor. Following years of struggles after passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965, segregation was abolished and African Americans could again exercise their constitutional right to vote.
Beginning in the late 1990s, conservative whites began to shift to the Republican Party. The election of Guy Hunt as Governor in 1986 marked the shift of the white majority to becoming a Republican stronghold in Presidential elections; its voters also leaned Republican in statewide elections. The Democratic Party still dominated local and legislative offices, but total Democratic dominance had ended. In terms of organization, the parties are about evenly matched.
Indigenous peoples, early history.
Precontact.
At least 12,000 years ago, Native Americans or Paleo-Indians appeared in what is today referred to as "The South". Paleo-Indians in the Southeast were hunter-gatherers who pursued a wide range of animals, including the megafauna, which became extinct following the end of the Pleistocene age. The Woodland period from 1000 BCE to 1000 CE was marked by the development of pottery and the small-scale horticulture of the Eastern Agricultural Complex.
The Mississippian culture arose as the cultivation of Mesoamerican crops of corn and beans led to crop surpluses and population growth. Increased population density gave rise of urban centers and regional chiefdoms, of which the greatest was the city known as Cahokia, in present-day Illinois near the confluence of the Illinois and Mississippi rivers. Its population of 20,000 to 30,000 at its peak exceeded any of the later European cities in North America until 1800. Stratified societies developed, with hereditary religious and political elites, and flourished in what is now the Midwestern, Eastern, and Southeastern United States from 800 to 1500 C.E.
Trade with the Northeast indigenous peoples via the Ohio River began during the Burial Mound Period (1000 BC–AD 700) and continued until European contact. The agrarian Mississippian culture covered most of the state from 1000 to 1600 AD, with one of its major centers being at the Moundville Archaeological Site in Moundville, Alabama, the second-largest complex of this period in the United States. Some 29 earthwork mounds survive at this site.
Analysis of artifacts recovered from archaeological excavations at Moundville were the basis of scholars' formulating the characteristics of the Southeastern Ceremonial Complex (SECC). Contrary to popular belief, the SECC appears to have no direct links to Mesoamerican culture, but developed independently. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples; it is one of the primary means by which their religion is understood.
The early historic Muscogee are considered likely descendants of the mound builders of the Mississippian culture along the Tennessee River in modern Tennessee, Georgia and Alabama. They may have been related to the Utinahica of southern Georgia. At the time the Spanish made their first forays inland from the shores of the Gulf of Mexico, many political centers of the Mississippians were already in decline, or abandoned. The Alabama region is best described as a collection of moderately sized native chiefdoms (such as the Coosa chiefdom on the Coosa River), interspersed with completely autonomous villages and tribal groups. The earliest Spanish explorers encountered settlements of the late Mississippian culture, beginning on April 2, 1513, with Juan Ponce de León's Florida landing and in 1526 with Lucas Vázquez de Ayllón expedition in South Carolina.
Among the historical tribes of Native American people living in the area of present-day Alabama at the time of European contact were the Muskogean-speaking Alabama ("Alibamu"), Chickasaw, Choctaw, Creek, Koasati, and Mobile peoples. Also in the region were the Iroquoian-speaking Cherokee, who migrated south from the Great Lakes area, based on their language's similarity to those of the Iroquois League. The history of Alabama's Native American peoples is reflected in many of its place names.
European colonization.
The Spanish were the first Europeans to enter Alabama, claiming land for their Crown. They named the region La Florida, which extended to the southeast peninsular state now bearing the name.
Although a member of Pánfilo de Narváez's expedition of 1528 may have entered southern Alabama, the first fully documented visit was by explorer Hernando de Soto. In 1539 he made an arduous expedition along the Coosa, Alabama and Tombigbee rivers.
The English also laid claims to the region north of the Gulf of Mexico. Charles II of England included the territory of modern Alabama in the Province of Carolina, with land granted to certain of his favorites by the charters of 1663 and 1665. English traders from Carolina frequented the valley of the Alabama River as early as 1687 to trade with its Native American peoples for deerskins.
The French also colonized the region. In 1702 they founded a settlement on the Mobile River near its mouth, constructing "Fort Louis." For the next nine years this was the French seat of government of New France, or "La Louisiane" (Louisiana). In 1711, Fort Louis was abandoned to floods. Settlers rebuilt a fort on higher ground known as "Fort Conde". This was the start of what developed as present-day Mobile, the first permanent European settlement in Alabama.
The French and the English contested the region, each attempting to forge strong alliances with Indian tribes. To strengthen their position, defend their Indian allies, and draw other tribes to them, the French established the military posts of "Fort Toulouse", near the junction of the Coosa and Tallapoosa rivers, and "Fort Tombecbe" on the Tombigbee River.
The French and the English engaged in competition for Indian trade in what is now the state of Alabama between roughly the 1690s and the 1750s (at which point the French and Indian War broke out. Though the French claimed the territory as their own and attempted to rule it from Fort Toulouse so as to engage in trade with the Indians, English traders based out of the Carolinas were everywhere, engaging in trade right under the French's nose. Particularly frustrating to the French was the fact that the Chickasaw virtually always favored the English in this contest. Overall, during this time the English proved to be the better colonizers and better traders. Their advantage came from the fact that their central government in London largely left them alone to engage in trade as they saw fit and did not hamper their efforts with excessive regulation as the French government did to their colonists. On this note Edmund Burke would later note that English colonists in America would owe their freedom "to its carelessness than to its design". This was a policy referred to as "salutary neglect". It reflected the larger fact as well that Englishmen at home were accustomed to a greater degree of freedom than were Frenchman.
The English Crown's grant of Georgia to Oglethorpe and his associates in 1732 included a portion of what is now northern Alabama. In 1739, Oglethorpe visited the Creek Indians west of the Chattahoochee River and made a treaty with them.
The 1763 Treaty of Paris, which ended the Seven Years' War after France's defeat by Britain, resulted in France ceding its territories east of the Mississippi to Britain. Great Britain came into undisputed control of the region between the Chattahoochee and the Mississippi rivers. The portion of Alabama below the 31st parallel became a part of British West Florida. The portion north of this line became a part of the "Illinois Country", set apart by the British Crown for use by Indians. In 1767, the province of West Florida was extended northward to 32°28'N latitude.
More than a decade later, during the American Revolutionary War, the British informally ceded this region to Spain. By the Treaty of Versailles, September 3, 1783, Great Britain ceded West Florida to Spain. By the Treaty of Paris (1783), signed the same day, Britain ceded to the newly established United States all of this province north of the 31°N, thus laying the foundation for a long controversy.
By the Treaty of Madrid, in 1795, Spain ceded to the United States the lands east of the Mississippi between 31°N and 32°28'N. Three years later, in 1798, Congress organized this district as the Mississippi Territory. A strip of land 12 or 14 miles wide near the present northern boundary of Alabama and Mississippi was claimed by South Carolina, as part of the eastern colonies' previous hopeful extensions to the west. In 1787, during constitutional negotiations, South Carolina ceded this claim to the federal government. Georgia likewise claimed all the lands between the 31st and 35th parallels from its present western boundary to the Mississippi River, and did not surrender its claim until 1802. Two years later, the boundaries of Mississippi Territory were extended so as to include all of the Georgia cession.
In 1812, Congress added the Mobile District of West Florida to the Mississippi Territory, claiming that it was included in the Louisiana Purchase. The following year, General James Wilkinson occupied the Mobile District with a military force. The Spanish did not resist. Thus the whole area of the present state of Alabama was taken under the jurisdiction of the United States. Several Native American tribes still occupied most of the land, with some formal ownership recognized by treaty with the United States. Five of the major tribes became known as the Five Civilized Tribes for their adoption of elements of European-American culture.
In 1817, the Mississippi Territory was divided. The western portion, which had attracted population more quickly, became the state of Mississippi. The eastern portion became the Alabama Territory, with St. Stephens on the Tombigbee River as its temporary seat of government.
Conflict between the Indians of Alabama and American settlers increased rapidly in the early 19th century because the Americans kept encroaching on Native American territories. The great Shawnee chief Tecumseh visited the region in 1811, seeking to forge an Indian alliance among these tribes to join his resistance in the Great Lakes area. With the outbreak of the War of 1812, Britain encouraged Tecumseh's resistance movement, in the hope of expelling American settlers from west of the Appalachians. Several tribes were divided in opinion.
The Creek tribe fell to civil war (1813-1804). Violence between Creeks and Americans escalated, culminating in the Fort Mims massacre. Full-scale war between the United States and the "Red Stick" Creeks began; they were the more traditional members of their society who resisted US encroachment. The Chickasaw, Choctaw, Cherokee Nation, and other Creek factions remained neutral to or allied with the United States during the war; some warriors from among the bands served with American troops. Volunteer militias from Georgia, South Carolina, and Tennessee marched into Alabama, fighting the Red Sticks.
Later, federal troops became the main fighting force for the United States. General Andrew Jackson was the commander of the American forces during the Creek War and in the continuing effort against the British in the War of 1812. His leadership and military success during the wars made him a national hero. The Treaty of Fort Jackson (August 9, 1814) ended the Creek War. By the terms of the treaty the Creek, Red Sticks and neutrals alike, ceded about one-half of the present state of Alabama to the United States. Due to later cessions by the Cherokee, Chickasaw, and Choctaw in 1816, they retained only about one-quarter of their former territories in Alabama.
Early statehood.
In 1820, Alabama was admitted as the 22nd state to the Union. Its constitution provided for equal suffrage for white men, a standard it abandoned in its constitution of 1901, which reduced suffrage of poor whites and most blacks.
One of the first problems of the new state was finance. Since the amount of money in circulation was not sufficient to meet the demands of the increasing population, a system of state banks was instituted. State bonds were issued and public lands were sold to secure capital, and the notes of the banks, loaned on security, became a medium of exchange. Prospects of an income from the banks led the legislature of 1836 to abolish all taxation for state purposes. The Panic of 1837 wiped out a large portion of the banks' assets, leaving the state poor. Next came revelations of grossly careless and corrupt management. In 1843 the banks were placed in liquidation. After disposing of all their available assets, the state assumed the remaining liabilities, for which it had pledged its faith and credit.
In 1830 Congress passed the Indian Removal Act under the leadership of President Andrew Jackson, forcing the removal of southeastern tribes, including the Five Civilized Tribes of Creek, Cherokee, Choctaw, Chickasaw, and Seminole. In 1832, the national government provided for the removal of the Creek via the Treaty of Cusseta. Before the removal occurred between 1834 and 1837, the state legislature defined counties from the lands to be ceded, and European-American settlers flocked in before the Native Americans had left.
Until 1832, there was only one party in the state, the Republican. The question of nullification caused a division that year into the (Jackson) Democratic party and the State's Rights (Calhoun Democratic) party. About the same time the Whig party emerged as an opposition party. It drew support from planters and townsmen, while the Democrats were strongest among poor farmers and Catholic communities (descendants of French and Spanish colonists) in the Mobile area. For some time, the Whigs were almost as numerous as the Democrats, but they never secured control of the state government. The State's Rights faction were in a minority; nevertheless, under their active and persistent leader, William L. Yancey (1814–1863), they prevailed upon the Democrats in 1848 to adopt their most radical views.
During the agitation over the Wilmot Proviso, which would bar slavery from territory acquired from Mexico as a result of the Mexican War (1848), Yancey induced the Democratic State Convention of 1848 to adopt what was known as the "Alabama Platform". It declared that neither Congress nor the government of a territory had the right to interfere with slavery in a territory, that those who held opposite views were not Democrats, and that the Democrats of Alabama would not support a candidate for the presidency if he did not agree with them. This platform was endorsed by conventions in Florida and Virginia and by the legislatures of Georgia and Alabama.
Tensions related to slavery divided many state delegations in Congress, as this body tried to determine the futures of territories beyond the Mississippi River. Following the Congressional passage of the Compromise of 1850, which assigned certain territories as slave or free, in Alabama, people became realigned politically. The State's Rights faction, joined by many Democrats, founded the Southern Rights Party, which demanded the repeal of the Compromise, advocated resistance to future encroachments, and prepared for secession. The Whigs were joined by the remaining Democrats and called themselves the "Unionists". The party unwillingly accepted the Compromise and denied that the Constitution provided for secession.
Since the turn of the 19th century, development of large cotton plantations had taken place across the upland Black Belt after the invention of the cotton gin made short-staple cotton profitable. Cotton had added dramatically to the state's wealth. The owners' wealth depended on the labor of hundreds of thousands of enslaved African Americans, many initially transported in the domestic trade from the Upper South. In other parts of the state, the soil supported only subsistence farming. Most of the yeoman farmers owned few or no slaves. By 1860 the success of cotton production led to planters' holding 435,000 enslaved African Americans, who made up 45% of the state's population.
As reflected in white universal suffrage at the time of statehood, the early Alabama settlers were noted for a spirit of frontier democracy and egalitarianism, and their fierce defense of the republican values of civic virtue and opposition to corruption. Thus J. Mills Thornton argues that Whigs worked for positive state action to benefit society as a whole, while the Democrats feared any increase of power in government, or in state-sponsored institutions as central banks. Fierce political battles raged in Alabama on issues ranging from banking to the removal of the Creek Indians. Thornton suggested the overarching issue in the state was how to protect liberty and equality for white people. Fears that Northern agitators threatened their value system and slavery as the basis of their wealthy economy made voters ready to secede when Abraham Lincoln was elected in 1860.
Secession and Civil War, 1861-1865.
The "Unionists" were successful in the elections of 1851 and 1852. Passage of the Kansas-Nebraska Bill and uncertainty about agitation against slavery led the State Democratic convention of 1856 to revive the "Alabama Platform". When the Democratic National Convention at Charleston, South Carolina, failed to approve the "Alabama Platform" in 1860, the Alabama delegates, followed by those of the other "cotton states", withdrew. Upon the election of Abraham Lincoln, Governor Andrew B. Moore, as previously instructed by the legislature, called a state convention. Many prominent men had opposed secession. In North Alabama, there was an attempt to organize a neutral state to be called Nickajack. With President Lincoln's call to arms in April 1861, most opposition to secession ended.
On January 11, 1861, the State of Alabama adopted the ordinances of secession from the Union (by a vote of 61-39).
Alabama joined the Confederate States of America, which government was first organized at Montgomery on February 4, 1861. the CSA set up its temporary capital in Montgomery and selected Jefferson Davis as president. In May 1861, the Confederate government abandoned Montgomery before the sickly season began, and relocated to Richmond, Virginia, the capital of that state.
Governor Moore energetically supported the Confederate war effort. Even before hostilities began, he seized Federal facilities, sent agents to buy rifles in the Northeast, and scoured the state for weapons. Despite some resistance in the northern part of the state, Alabama joined the Confederate States of America (CSA). Congressman Williamson R. W. Cobb was a Unionist and pleaded for compromise. When he ran for the Confederate congress in 1861, he was defeated. (In 1863, with war-weariness growing in Alabama, he was elected on a wave of antiwar sentiment.)
Some idea of the current transportation patterns, and severe internal logistics problems faced by the Confederacy, can be seen by tracing Jefferson Davis' journey from his plantation Mississippi to Montgomery in the next state. With few roads and railroads, he traveled by steamboat from his plantation on the Mississippi River down to Vicksburg, where he boarded a train to Jackson, Mississippi. He took another train north to Grand Junction, then a third train east to Chattanooga, Tennessee, and a fourth train south to the main hub at Atlanta, Georgia. He took another train to the Alabama border, and a last one to Montgomery in the center of the state.
As the war proceeded, the Federals seized ports along the Mississippi River, burned trestles and railroad bridges, and tore up track. The frail Confederate railroad system faltered and virtually collapsed for want of repairs and replacement parts.
In the early part of the Civil War, Alabama was not the scene of military operations. The state contributed about 120,000 men to the Confederate service, practically all the white male population capable of bearing arms. Most were recruited locally and served with men they knew, which built esprit and strengthened ties to home. Medical conditions were severe for all soldiers. About 15% of fatalities were from disease, more than the 10% from battle. Alabama had few well-equipped hospitals, but it had many women who volunteered to nurse the sick and wounded. Soldiers were poorly equipped, especially after 1863. Often they pillaged the dead for boots, belts, canteens, blankets, hats, shirts and pants. Uncounted thousands of slaves were impressed to work for Confederate troops; they took care of horses and equipment, cooked and did laundry, hauled supplies, and helped in field hospitals. Other slaves built defensive installations, especially those around Mobile. They graded roads, repaired railroads, drove supply wagons, and labored in iron mines, iron foundries and even in the munitions factories. The service of slaves was involuntary: their unpaid labor was impressed from their unpaid masters. About 10,000 slaves escaped and joined the Union army, along with 2,700 white men.
Thirty-nine Alabamians attained flag rank, most notably Lieutenant General James Longstreet and Admiral Raphael Semmes. Josiah Gorgas, who came to Alabama from Pennsylvania, was the chief of ordnance for the Confederacy. He located new munitions plants in Selma, which employed 10,000 workers until the Union soldiers burned the factories down in 1865. Selma Arsenal made most of the Confederacy's ammunition. The Selma Naval Ordnance Works made artillery, turning out a cannon every five days. The Confederate Naval Yard built ships and was noted for launching the CSS "Tennessee" in 1863 to defend Mobile Bay. Selma's Confederate Nitre Works procured niter for the Nitre and Mining Bureau, for gunpowder, from limestone caves. When supplies were low, it advertised for housewives to save the contents of their chamber pots—as urine was a rich source of nitrogen.
In 1863, Union forces secured a foothold in northern Alabama in spite of the opposition of General Nathan B. Forrest. From 1861, the Union blockade shut Mobile, and, in 1864, the outer defenses of Mobile were taken by a Union fleet; the city itself held out until April 1865.
Losses.
Alabama soldiers fought in hundreds of battles; the state's losses at the Battle of Gettysburg were 1,750 dead plus more captured or wounded; the "Alabama Brigade" took 781 casualties. Governor Lewis E. Parsons in July 1865 made a preliminary estimate of losses. Nearly all the white men served, some 122,000 he said, of whom 35,000 died in the war and another 30,000 were seriously disabled. The next year Governor Robert M. Patton estimated that 20,000 veterans had returned home permanently disabled, and there were 20,000 widows and 60,000 orphans. With cotton prices low, the value of farms shrank, from $176 million in 1860 to only $64 million in 1870. The livestock supply shrank too, as the number of horses fell from 127,000 to 80,000, and mules 111,000 to 76,000. The overall population remained the same—the growth that might have been expected was neutralized by death and emigration.
Reconstruction, 1865-1875.
According to the Presidential plan of reorganization, a provisional governor for Alabama was appointed in June 1865. A state convention met in September of the same year, and declared the ordinance of secession null and void and slavery abolished. A legislature and a governor were elected in November, and the legislature was at once recognized by President Andrew Johnson, but not by Congress, which refused to seat the delegation. Johnson ordered the Army to allow the inauguration of the governor after the legislature ratified the Thirteenth Amendment in December, 1865. But the legislature's passage of Black Codes to control the freedmen who were flocking from the plantations to the towns, and its rejection of the Fourteenth Amendment to grant suffrage, intensified Congressional hostility to the Presidential plan.
In 1867, the congressional plan of Reconstruction was completed and Alabama was placed under military government. The freedmen were enrolled as voters. Only whites who could swear the Ironclad oath could be voters; that is they had to swear they had never voluntarily supported the Confederacy. This provision was insisted upon by the whites in the northern hill counties so they could control local government. As a result, Republicans controlled 96 of the 100 seats in the state constitutional convention. The new Republican party, made up of freedmen, Union sympathizers (scalawags), and northerners who had settled in the South (carpetbaggers), took control two years after the war ended. The constitutional convention in November 1867 framed a constitution which conferred universal manhood suffrage and imposed the iron-clad oath, so that whites who had supported the Confederacy were temporarily prohibited from holding office. The Reconstruction Acts of Congress required every new constitution to be ratified by a majority of the legal voters of the state. Most whites boycotted the polls and the new constitution fell short. Congress enacted that a majority of the votes cast should be sufficient. Thus the constitution went into effect, the state was readmitted to the Union in June 1868, and a new governor and legislature were elected.
Many whites resisted postwar changes, complaining that the Republican governments were notable for legislative extravagance and corruption. But the Republican biracial coalition created the first system of public education in the state, which would benefit poor white children as well as freedmen. They also created charitable public institutions, such as hospitals and orphanages, to benefit all citizens. The planters had not made public investment but kept their wealth for themselves. As the state tried to improve institutions and infrastructure for the future, the state debt and state taxes rose. The state endorsed railway bonds at the rate of $12,000 and $16,000 a mile until the state debt had increased from eight million to seventeen million dollars. The native whites united, peeled many Scalawags away from the Republican coalition, formed a Conservative party, and elected a governor and a majority of the lower house of the legislature in 1870, in an election characterized by widespread violence and fraud. As the new administration was overall a failure, in 1872, voters re-elected Republicans.
By 1874, however, the power of the Republicans was broken, and conservative Democrats regained power in all state offices. A commission appointed to examine the state debt found it to be $25,503,000; by compromise, it was reduced to $15,000,000. A new constitution was adopted in 1875, which omitted the guarantee of the previous constitution that no one should be denied suffrage on account of race, color or previous condition of servitude. Its provisions forbade the state to engage in internal improvements or to give its credit to any private enterprise, an anti-industrial stance that persisted and that limited the state's progress for decades into the 20th century.
In the South the interpretation of the tumultuous 1860s has differed sharply by race. Americans often interpreted great events in religious terms. Historian Wilson Fallin contrasts the interpretation of Civil War and Reconstruction in white versus black using Baptist sermons in Alabama. Whites preachers expressed the view that:
In sharp contrast, Black preachers interpreted the Civil War, emancipation and Reconstruction as:
Democratic politics and disfranchisement 1874-1901.
After 1874, the Democratic party had constant control of the state administration. The Republican Party by then was chiefly supported by African Americans. Republicans held no local or state offices, but the party did have some federal patronage. It failed to make nominations for office in 1878 and 1880 and endorsed the ticket of the Greenback party in 1882.
The development of mining and manufacturing was accompanied by economic distress among the farming classes, which found expression in the Jeffersonian Democratic party, organized in 1892. The regular Democratic ticket was elected and the new party was merged into the Populist party. In 1894, the Republicans united with the Populists, elected three congressional representatives, and secured control of many of the counties. They did not succeed in carrying the state. They Populist coalition had less success in the next campaigns. Partisanship became intense, and Democratic charges of corruption of the black electorate were matched by Republican and Populist accusations of fraud and violence by Democrats.
Despite opposition by Republicans and Populists, Democrats completed their dominance with passage of a new constitution in 1901 that restricted suffrage and effectively disenfranchised most African Americans and many poor whites, through requirements for voter registration, such as poll taxes, literacy tests and restrictive residency requirements. From 1900 to 1903, the number of white registered voters fell by more than 40,000, from 232,821 to 191,492, despite a growth in population. By 1941 a total of more whites than blacks had been disenfranchised: 600,000 whites to 520,000 blacks. This was due mostly to effects of the cumulative poll tax.
The damage to the African-American community was severe and pervasive, as nearly all its eligible citizens lost the ability to vote. In 1900 45% of Alabama's population were African American: 827,545 citizens. In 1900 fourteen Black Belt counties (which were primarily African American) had more than 79,000 voters on the rolls. By June 1, 1903, the number of registered voters had dropped to 1,081. While Dallas and Lowndes counties were each 75% black, between them only 103 African-American voters managed to register. In 1900 Alabama had more than 181,000 African Americans eligible to vote. By 1903 only 2,980 had managed to "qualify" to register, although at least 74,000 black voters were literate. The shut out was long-lasting. The effects of segregation suffered by African Americans were severe. At the end of WWII, for instance, in the black Collegeville community of Birmingham, only eleven voters in a population of 8,000 African Americans were deemed "eligible" to register to vote. Disfranchisement also meant that blacks and poor whites could not serve on juries, so were subject to a justice system in which they had no part.
Progressive era 1900-1930.
The Progressive Movement in Alabama, while not as colorful or successful as in some other states, drew upon the energies of a rapidly growing middle class, and flourished from 1900 to the late 1920s. B. B. Comer (1848 – 1927) was the state's most prominent progressive leader, especially during his term as governor (1907-1911). Middle-class reformers placed high on their agenda the regulation of railroads, and a better school system, with compulsory education and the prohibition of child labor. Comer sought 20 different railroad laws, to strengthen me railroad commission, reduce free passes handed out to grasping politicians, lobbying, and secret rebates to favored shippers. The Legislature approved his package, except for a provision that tried to forbid freight trains operating on Sundays. The result was a reduction in both freight and passenger rates. Railroads fought back vigorously in court, and in the arena of public opinion. The issue was fiercely debated for years, making Alabama laggard among the southern states in terms of controlling railroad rates. Finally in 1914 a compromise was reached, in which the railroads accepted the reduced passenger rates, but were free to seek higher freight rates through the court system.
Progressive reforms cost money, especially for the improved school system. Eliminating the inefficiencies of the tax collection system helped a bit. Reformers wanted to end the convict lease system, but it was producing a profit to the government of several hundred thousand dollars a year. That was too lucrative to abolish; however the progressives did move control over convict lease from the counties to a statewide system. Finally the Legislature increased statewide funding for the schools, and established the policy of at least one high school in every county; by 1911 half the counties operated public high schools for whites. Compulsory education was opposed by working-class families who wanted their children to earn money, and who distrusted the schooling the middle class was so insistent upon. But it finally passed in 1915; it was enforced for whites only and did not apply to farms. By 1910 Alabama still lagged with 62 percent of its children in school, compared to a national average of 71 percent.
The progressives worked hard to upgrade the hospital and public health system, with provisions to require the registration of births and deaths to provide the information needed. When the Rockefeller foundation identified the hookworm as a critical element in draining energy out of Southern workers, Alabama discovered hookworm cases in every county, with rates as high as 60 percent. The progressive genius for organization, and devotion to the public good, was least controversial in the public health area, and probably most successful there. Prohibition was a favorite reform for Protestant churches across this entire country, and from 1870s to the 1920s Alabama passed a series of a more restrictive laws that were demanded by the Women's Christian Temperance Union (WCTU) and other reform elements.
Middle-class business and professional activists in the cities were frustrated with the old-fashioned politicized city governments, and demanded a commission formed in which municipal affairs would be very largely run by experts rather than politicians. Emmet O'Neal, elected governor 1910, made the commission system his favored reform, and secure its passage by the legislature in 1911. The cities of Birmingham, Montgomery and Mobile quickly adopted the commission form
Women energized by the prohibition wars turned their crusading energies to woman suffrage. They were unable to overcome male supremacy until the national movement passed the 19th amendment and they got the vote in 1920.
Railroads and industry.
Birmingham was founded on June 1, 1871 by real estate promoters who sold lots near the planned crossing of the Alabama & Chattanooga and South & North railroads. The site was notable for the nearby deposits of iron ore, coal, and limestone—the three principal raw materials used in making steel. Its founders adopted the name of England's principal industrial city to advertise the new city as a center of iron and steel production. Despite outbreaks of cholera, the population of this 'Pittsburgh of the South' grew from 38,000 to 132,000 from 1900 to 1910, attracting rural white and black migrants from all over the region. Birmingham experienced such rapid growth that it was nicknamed "The Magic City." By the 1920s, Birmingham was the 19th largest city in the U.S and held more than 30% of the population of the state. Heavy industry and mining were the basis of the economy. Chemical and structural constraints limited the quality of steel produced from Alabama's iron and coal. These materials did, however, combine to make ideal foundry iron. Because of low transportation and labor costs, Birmingham quickly became the largest and cheapest foundry iron-producing area. By 1915 twenty-five percent of the nation's foundry pig iron was produced in Birmingham.
New South, 1914-1945.
Despite Birmingham's powerful industrial growth and its contributions to the state economy, its citizens, and those of other newly developing areas, were underrepresented in the state legislature for years. The rural-dominated legislature refused to redistrict state House and Senate seats from 1901 to the 1960s. In addition, the state legislature had a senate based on one for each county. The state legislative delegations controlled counties. This led to a stranglehold on the state by a white rural minority. The contemporary interests of urbanizing, industrial cities and tens of thousands of citizens were not adequately represented in the government. One result was that Jefferson County, home of Birmingham's industrial and economic powerhouse, contributed more than one-third of all tax revenue to the state. It received back only 1/67th of the tax money, as the state legislature ensured taxes were distributed equally to each county regardless of population.
From 1910-1940, tens of thousands of African Americans migrated out of Alabama in the Great Migration to seek jobs, education for their children, and freedom from lynching in northern and midwestern cities, such as St. Louis, Chicago, Detroit, and Cleveland. These cities had many industrial jobs, but the migrants also had to compete with new waves of European immigrants. The rate of population growth in Alabama dropped from 20.8% in 1900 and 16.9% in 1910, to 9.8% in 1920, reflecting the impact of the outmigration. Formal disenfranchisement was ended only after the mid-1960s after African Americans led the Civil Rights Movement and gaining Federal legislation to protect their voting and civil rights. But the state devised new ways to reduce their political power. By that time, African Americans comprised a smaller minority than at the turn of the century, and a majority in certain rural counties.
A rapid pace of change across the country, especially in growing cities, combined with new waves of immigration and migration of rural whites and blacks to cities, all contributed to a volatile social environment and the rise of a second Ku Klux Klan (KKK) in the South and Midwest after 1915. In many areas it represented itself as a fraternal group to give aid to a community. Feldman (1999) has shown that the second KKK was not a mere hate group; it showed a genuine desire for political and social reform on behalf of poor whites. For example, Alabama Klansmen such as Hugo Black were among the foremost advocates of better public schools, effective Prohibition enforcement, expanded road construction, and other "progressive" measures to benefit poor whites. By 1925, the Klan was a powerful political force in the state, as urban politicians such as J. Thomas Heflin, David Bibb Graves, and Hugo Black manipulated the KKK membership against the power of the "Big Mule" industrialists and especially the Black Belt planters who had long dominated the state.
In 1926, Bibb Graves, a former chapter head, won the governor's office with KKK members' support. He led one of the most progressive administrations in the state's history, pushing for increased education funding, better public health, new highway construction, and pro-labor legislation. At the same time, KKK vigilantes---thinking they enjoyed governmental protection—launched a wave of physical terror across Alabama in 1927, targeting both blacks and whites. The conservative elite counterattacked. The major newspapers kept up a steady, loud attack on the Klan as violent and unAmerican. Sheriffs cracked down on Klan violence, and a national scandal among Klan leaders in the 1920s turned many members away. The counterattack worked. The state voted for Democratic candidate Al Smith in 1928, although he was Roman Catholic (a target of the KKK), and the Klan's official membership plunged to under six thousand by 1930.
Civil Rights Movement and redistricting, 1945-1975.
Following service in World War II, many African-American veterans became activists for civil rights, wanting their rights under the law as citizens. The Montgomery Bus Boycott from 1955 to 1956 was one of the most significant African-American protests against the policy of racial segregation in the state. Although constituting a majority of bus passengers, African Americans were discriminated against in seating policy. The protest nearly brought the city bus system to bankruptcy and changes were negotiated. The legal challenge was settled in "Browder v. Gayle" (1956), a case in which the United States District Court for the Middle District of Alabama found the segregation policy to be unconstitutional under Fourteenth Amendment provisions for equal treatment; it ordered that public transit in Alabama be desegregated.
The rural white minority's hold on the legislature continued, however, suppressing attempts by more progressive elements to modernize the state. A study in 1960 concluded that because of rural domination, "A minority of about 25 per cent of the total state population is in majority control of the Alabama legislature." Given the legislature's control of the county governments, the rural interests had even more power. Legislators and others filed suit in the 1960s to secure redistricting and reapportionment. It took years and Federal court intervention to achieve the redistricting necessary to establishing "one man, one vote" representation, as a result of "Baker v. Carr" (1962) and "Reynolds v. Sims" (1964). The court ruled that, in addition to the states having to redistrict to reflect decennial censuses in congressional districts, both houses of state governments had to be based on representation by population districts, rather than by geographic county as the state senate had been, as the senate's make-up prevented equal representation. These court decisions caused redistricting in many northern and western states as well as the South, where often rural interests had long dominated state legislatures and prevented reform.
In 1960 on the eve of important civil rights battles, 30% of Alabama's population was African American or 980,000.
As Birmingham was the center of industry and population in Alabama, in 1963 civil rights leaders chose to mount a campaign there for desegregation. Schools, restaurants and department stores were segregated; no African Americans were hired to work in the stores where they shopped or in the city government supported in part by their taxes. There were no African-American members of the police force. Despite segregation, African Americans had been advancing economically. But from 1947 to 1965, Birmingham suffered "about 50 racially motivated bomb attacks." Independent groups affiliated with the KKK bombed transitional residential neighborhoods to discourage blacks' moving into them; in 19 cases, they bombed black churches with congregations active in civil rights, and the homes of their ministers.)
To help with the campaign and secure national attention, the Rev. Fred Shuttlesworth invited members of the Southern Christian Leadership Conference (SCLC) to Birmingham to help change its leadership's policies. Non-violent action had produced good results in some other cities. The Rev. Martin Luther King, Jr., Rev. Wyatt Tee Walker, his executive director; and other leaders came to Birmingham to help.
In the spring and summer of 1963, national attention became riveted on Birmingham. The media covered the series of peaceful marches that the Birmingham police, headed by Police Commissioner Bull Connor, attempted to divert and control. He invited high school students to join the marches, as King intended to fill the jails with nonviolent protesters to make a moral argument to the United States. Dramatic images of Birmingham police using police dogs and powerful streams of water against children protesters filled newspapers and television coverage, arousing national outrage. The 16th Street Baptist Church bombing during a Sunday service, which killed four Africa-American girls, caused a national outcry and gained support for the civil rights cause in the state. 16th Street Baptist Church had been a rallying point and staging area for civil rights activities in Birmingham prior to the bombing. Finally, Birmingham leaders King and Shuttlesworth agreed to end the marches when the businessmen's group committed to end segregation in stores and public facilities.
Before his November 1963 assassination, President John F. Kennedy had supported civil rights legislation. In 1964 when President Lyndon Johnson helped secure its passage and signed the Civil Rights Act. The Selma to Montgomery marches in 1965 attracted national and international press and TV coverage. The nation was horrified to see peaceful protesters beaten as they entered the county. That year, Johnson helped achieve passage of the 1965 Voting Rights Act to gain federal oversight and enforcement to ensure the ability of all citizens to vote.
Court challenges related to "one man, one vote" and the Voting Rights Act of 1965 finally provided the groundwork for Federal court rulings. In 1972 the federal court required the legislature to create a statewide redistricting plan in order to correct the imbalances in representation in the legislature related to population patterns. Redistricting, together with federal oversight of voter registration and election practices, enabled hundreds of thousands of Alabama citizens, both white and black, to vote and participate for the first time in the political system.
Twenty first century, 2000-present.
In 2015, state budget reductions of $83 million caused five parks to be closed per Alabama Department of Conservation and Natural Resources ($3 million) and service cuts at driver license offices.

</doc>
<doc id="39476" url="https://en.wikipedia.org/wiki?curid=39476" title="History of Andorra">
History of Andorra

Andorra claims it is the last independent survivor of the Marca Hispanica, the buffer states created by Charlemagne to keep the Islamic Moors from advancing into Christian France. Tradition holds that Charlemagne granted a charter to the Andorran people in return for their fighting the Moors. In the 9th century, Charlemagne's grandson, Charles the Bald, named the Count of Urgell as overlord of Andorra. A descendant of the count later gave the lands to the Diocese of Urgell, headed by Bishop of Urgell.
Early history.
In the 11th century, fearing military action by neighboring lords, the bishop placed himself under the protection of the Lord of Caboet, a Catalan nobleman. Later, the Count of Foix became heir to the Lord of Caboet through marriage, and a dispute arose between the French Count and the Catalan bishop over Andorra.
In 1278, the conflict was resolved by the signing of a pareage ("pariatges"), which provided that Andorra's sovereignty be shared between the Count of Foix and the Bishop of La Seu d'Urgell (Catalonia, Spain). The pareage, a feudal institution recognizing the principle of equality of rights shared by two rulers, gave the small state its territory and political form. In return, Andorra pays an annual tribute or "questia" to the co-rulers consisting of four hams, forty loaves of bread, and some wine. As of the year 2012, Andorra's borders have remained unchanged since 1278.
Andorra was briefly annexed to the Crown of Aragon twice, in 1396 and 1512.
In 1505, Germaine of Foix married Ferdinand V of Castile, thereby bringing the lordship of Andorra under Spanish rule. On taking over the kingdom in 1519, Emperor Charles V granted the lordship of Les Valls, as it was then known, to Germaine of Foix’s line in perpetuity. Henry III of Navarre, who was also count of Foix, in 1589 ascended the French throne as Henry IV, and by an edict of 1607 established the head of the French state, along with the bishop of Urgel, as co-princes of Andorra.
In 1793, the French revolutionary government refused the traditional Andorran tribute as smacking of feudalism and renounced its suzerainty, despite the wish of the Andorrans to enjoy French protection and avoid being under exclusively Spanish influence.
Andorra remained neutral during the Napoleonic Wars. Napoleon restored the co-principality in 1806 after the Andorrans petitioned him to do so. French title to the principality subsequently passed from the kings to the president of France. In the period 1812–13, the French Empire annexed Catalonia and divided it in four departments. Andorra was also annexed and made part of the district of Puigcerdà (département of Sègre).
20th century.
In 1933, France occupied Andorra as a result of social unrest before elections. On July 12, 1934, an adventurer named Boris Skossyreff issued a proclamation in Urgel, declaring himself Boris I, sovereign prince of Andorra, simultaneously declaring war on the Bishop of Urgell. He was arrested by Spanish authorities on July 20 and ultimately expelled from Spain. From 1936 to 1940, a French detachment was garrisoned in Andorra to prevent influences of the Spanish Civil War and Franco's Spain.
During World War II, Andorra remained neutral and was an important smuggling route from Spain into France. The French Resistance used Andorra as part of their route to get downed airmen out of France. 
In 1943, Andorra carried out its first execution since the 19th century, that of Antoni Arenis for double fratricide by firing squad (because a trained executioner was unavailable to operate the legal method - Garrote).
In 1958, Andorra declared peace with Germany, having been forgotten on the Treaty of Versailles that ended World War I and, the conflict being extended by the lack of a peace treaty, remaining legally at war.
Long an impoverished land having little contact with any nations other than adjoining France and Spain, Andorra after World War II achieved considerable prosperity through a developing tourist industry. This development, abetted by improvements in transport and communications, has tended to break down Andorra’s isolation and to bring Andorrans into the mainstream of European history. Public demands for democratic reforms led to the extension of the franchise to women in the 1970s and to the creation of new and more fully autonomous organs of government in the early 1980s.
Modern history.
Andorra formally became a parliamentary democracy in May 1993 following approval of a new constitution by a popular referendum in March 1993. The new constitution retained the French and Spanish co-princes although with reduced, and narrowly defined powers. Civil rights were greatly expanded including the legalisation of political parties and trade unions, and provision was made for an independent judiciary. Andorra entered into a customs union with the European Communities (now the EU) in 1991 and was admitted to the UN on 28 July 1993. The country
has been seeking ways to improve its export potential and increase its economic ties with its European neighbours. The financial services sector of the economy is highly important, given Andorra’s status as a tax haven and its banking secrecy laws.

</doc>
